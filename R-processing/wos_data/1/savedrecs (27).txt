FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Amini, SM
AF Amini, Seyedeh Moloud
TI Head circumference measurement with deep learning approach based on
   multi-scale ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Ultrasound Imaging; Image segmentation; Medical imaging;
   Fetal Head Segmentation
ID FETAL; SEGMENTATION
AB Checking up on the health of the fetus during pregnancy is an important issue that should be taken into account. Ultrasound imaging, as one useful medical imaging technique, helps specialists to monitor and diagnose the natural fetal growth process. Head Circumference (HC) measurement is considered as one of the remarkable criteria in fetus health assessment. In this study, I proposed a model to automatically extract the fetal head parameters based on three main phases, including pm-processing, fetal head extraction, and post-processing. In the fetal head extraction phase, I suggested a deep learning-based network based on multi-scale ultrasound images to diagnose and segment the fetal head using a loss function L-DeepLinkNet weights the fetal head border pixels during algorithm learning to improve the performance of fetal head parameter extraction methods by reducing the number of required parameters and training time. According to experimental results, the accuracy of segmentation and the power of network training have significantly increased, which leads my proposed method has better performance in terms of two evaluation criteria for HC measurement such as Hausdorff, and the absolute difference compared to other previous methods, and better efficiency than the Link-Net model in all criteria due to multi-scalability and fewer network layers.
C1 [Amini, Seyedeh Moloud] Waterloo Univ, Dept Elect & Comp Engn, Waterloo, ON, Canada.
C3 University of Waterloo
RP Amini, SM (corresponding author), Waterloo Univ, Dept Elect & Comp Engn, Waterloo, ON, Canada.
EM moloud.amini@uwaterloo.ca
CR Amin J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1453-8
   Cerrolaza JJ, 2018, LECT NOTES COMPUT SC, V11070, P383, DOI 10.1007/978-3-030-00928-1_44
   Cerrolaza JJ, 2018, I S BIOMED IMAGING, P564, DOI 10.1109/ISBI.2018.8363639
   Cerrolaza JJ, 2017, LECT NOTES COMPUT SC, V10554, P25, DOI 10.1007/978-3-319-67561-9_3
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen HC, 2012, ULTRASOUND MED BIOL, V38, P811, DOI 10.1016/j.ultrasmedbio.2012.01.025
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Emami A., 2020, 2020 25 INT COMP C C, P1
   Feng S, 2012, AUTOMATIC FETAL WEIG
   Gomez A, 2017, LECT NOTES COMPUT SC, V10554, P33, DOI 10.1007/978-3-319-67561-9_4
   Jardim SMGVB, 2005, ULTRASOUND MED BIOL, V31, P243, DOI 10.1016/j.ultrasmedbio.2004.11.003
   Kim HP, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/ab21ac
   Li J, 2018, IEEE J BIOMED HEALTH, V22, P215, DOI 10.1109/JBHI.2017.2703890
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loughna P, 2009, ULTRASOUND, V17, P160, DOI 10.1179/174313409X448543
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Namburete AIL, 2018, MED IMAGE ANAL, V46, P1, DOI 10.1016/j.media.2018.02.006
   Namburete AIL, 2015, MED IMAGE ANAL, V21, P72, DOI 10.1016/j.media.2014.12.006
   Perez-Gonzalez JL, 2014, IFMBE PROC, V49, P329, DOI 10.1007/978-3-319-13117-7_85
   Ponomarev GV, 2012, P CHALLENGE US BIOME
   Rafiei S, 2018, IEEE IMAGE PROC, P2067, DOI 10.1109/ICIP.2018.8451238
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rueda S, 2014, IEEE T MED IMAGING, V33, P797, DOI 10.1109/TMI.2013.2276943
   Schmidt U, 2014, EUR J OBSTET GYN R B, V178, P153, DOI 10.1016/j.ejogrb.2014.03.047
   Shrimali V, 2009, IEEE ENG MED BIO, P459, DOI 10.1109/IEMBS.2009.5334470
   Sobhaninia Z., 2018, ARXIV PREPRINT ARXIV
   Sobhaninia Z., 2020, 28 IR C EL ENG ICEE
   Sobhaninia Z, 2019, IEEE ENG MED BIO, P6545, DOI [10.1109/EMBC.2019.8856981, 10.1109/embc.2019.8856981]
   Torrents-Barrena J, 2019, MED IMAGE ANAL, V51, P61, DOI 10.1016/j.media.2018.10.003
   van den Heuvel TLA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200412
   Wang J, 2021, MOBILE NETW APPL, V26, P351, DOI 10.1007/s11036-020-01672-7
   Wu LY, 2017, I S BIOMED IMAGING, P663, DOI 10.1109/ISBI.2017.7950607
   Yang X, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105519
   Zeng Y, 2021, J DIGIT IMAGING, V34, P134, DOI 10.1007/s10278-020-00410-5
   Zhang J, 2020, Medical Imaging with Deep Learning
NR 35
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 APR 15
PY 2022
DI 10.1007/s11047-022-13107-4
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0N0PV
UT WOS:000782551400002
DA 2024-07-18
ER

PT J
AU Li, JF
   Xiao, DG
   Yang, QW
AF Li, Jianfang
   Xiao, Degui
   Yang, Qiuwei
TI Efficient multi-model integration neural network framework for nighttime
   vehicle detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nighttime vehicle detection; Deep learning; Ensemble learning; Salient
   feature maps; Image enhancement
ID TRACKING
AB A vehicle detection system is a core ADAS function for automatic driving. However, owing to the low-light environment, nighttime vehicle detection is a big challenge. Current techniques have the limitation of not being able to fully extract the nighttime vehicle features. To solve the problem, this study proposes a nighttime framework, which employs multiple means to enhance nighttime vehicle information. First, multiple image enhancement techniques are used to rich the training datasets, and an improved Bio-Inspired Multi-Exposure Fusion (BIMEF) algorithm is proposed to improve the quality of the nighttime images. Then, the multi-scale salient feature maps of highlight vehicle regions are combined with vehicle visual feature maps to enhance vehicle information during detection. At last, an ensemble algorithm is proposed to combine multiple networks to provide richer vehicle visual features. Experiment results show the effectiveness of our method in terms of accuracy and speed. Additionally, our method is robust in multiple complex night scenes.
C1 [Li, Jianfang; Xiao, Degui; Yang, Qiuwei] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
C3 Hunan University
RP Li, JF (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
EM lijianfang@hnu.edu.cn; dgxiao@hnu.edu.cn; yangqiuwei@hnu.edu.cn
FU National Key Program of China [2017YFB0202905]; National Natural Science
   Foundation of China [61272062]; Science and Technology Project of
   Changsha City [q2004012]
FX The work described in this article was supported by a grant from
   National Key Program of China 2017YFB0202905 and The National Natural
   Science Foundation of China (61272062). We also thank for the sponsor of
   Science and Technology Project of Changsha City (q2004012).
CR Acunzo David, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P654, DOI 10.1109/ITSC.2007.4357724
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen L, 2017, IEEE T INTELL TRANSP, V18, P3303, DOI 10.1109/TITS.2017.2683641
   Chen W, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1123
   Cheng H, 2006, INT C PATT RECOG, P662
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Cui JZ, 2010, IEEE INT VEH SYM, P871, DOI 10.1109/IVS.2010.5548101
   Dailey D. J., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P98, DOI 10.1109/6979.880967
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo EQ, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P759, DOI 10.1109/ICCSNT.2015.7490853
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Jo Y, 2014, SENSORS-BASEL, V14, P14050, DOI 10.3390/s140814050
   Kuang HL, 2018, IEEE T INTELL TRANSP, V19, P814, DOI 10.1109/TITS.2017.2702665
   Kuang HL, 2016, IEEE INTELL SYST, V31, P57, DOI 10.1109/MIS.2016.17
   Li GF, 2019, NEURAL COMPUT APPL, V31, P9013, DOI 10.1007/s00521-019-04147-3
   Li GJ, 2020, INFORM SCIENCES, V518, P238, DOI 10.1016/j.ins.2020.01.015
   Li ZY, 2017, J VIS COMMUN IMAGE R, V44, P1, DOI [10.1016/j.jvcir.2017.01.012, 10.16339/j.cnki.hdxbzkb.2017.11.001]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   López A, 2008, LECT NOTES COMPUT SC, V5259, P113, DOI 10.1007/978-3-540-88458-3_11
   Milella A, 2011, IEEE INT C INT ROBOT, P255, DOI 10.1109/IROS.2011.6048156
   Mo YY, 2019, NEUROCOMPUTING, V355, P13, DOI 10.1016/j.neucom.2019.04.005
   Nai K, 2019, KNOWL-BASED SYST, V181, DOI 10.1016/j.knosys.2019.05.032
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362
   Nelson BN, 2001, IEEE T FUZZY SYST, V9, P53, DOI 10.1109/91.917114
   Niknejad HT, 2011, IEEE INT C INTELL TR, P1560, DOI 10.1109/ITSC.2011.6082826
   Niknejad HT, 2011, IEEE INT C INT ROBOT, P4442, DOI 10.1109/IROS.2011.6048502
   Paidi V, 2020, IET INTELL TRANSP SY, V14, P1295, DOI 10.1049/iet-its.2019.0468
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sivaraman S, 2014, MACH VISION APPL, V25, P599, DOI 10.1007/s00138-011-0388-y
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Sun ZH, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1019, DOI 10.1109/ICDSP.2002.1028263
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Xiao DG, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013002
   Xiao DG, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105584
   Xiao DF, 2017, MULTIMED TOOLS APPL, V76, P10575, DOI 10.1007/s11042-015-3091-6
   Xiao DG, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416600053
   Ying Z., 2017, ARXIV PREPRINT ARXIV
   Zhang XT, 2011, IEEE INT C INTELL TR, P1555, DOI 10.1109/ITSC.2011.6083135
NR 50
TC 1
Z9 1
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32675
EP 32699
DI 10.1007/s11042-022-12857-5
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000782544600004
DA 2024-07-18
ER

PT J
AU Hossain, MY
   Zaman, L
AF Hossain, Md Yousuf
   Zaman, Loutfouz
TI NCCollab: collaborative behavior tree authoring in game development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Behavior tree; Collaboration; Game AI; Game development; Unity engine
AB Game development is a collective process in which a variety of different professionals from different backgrounds collaborate together not only by means of conversational interaction but also collaborative participation, one of which is programming. While collaborative and pair programming solutions exist for text-based programming languages, visual programming has not enjoyed as much attention. These solutions would not only address advanced forms of business communication among team members but could find their use in distance learning, which would have been useful during the pandemic. In our work, we propose a solution for collaborative behavioral animation of NPCs using behavior trees through synchronous and asynchronous modes of collaboration. We conducted a user study with 12 moderately skilled game development university students who were placed in groups of two and engaged in joint fixed behavior tree development tasks using the synchronous and asynchronous modes and auxiliary features of live preview, access and restoration of previous states from behavior tree history, conflict resolution, and instant messaging. Participants also completed a control task where no collaboration was involved and auxiliary features were not available. Feedback form Creativity Support Index, a self-developed questionnaire, and a semi-structured interview were collected. Additionally, task completion times were logged. The results indicate that the two collaborative modes provide expected improvement over the control condition. No significant differences were found between the two collaborative modes. However, the semi-structed interview revealed that the synchronous mode could be useful for quick prototyping, while the asynchronous mode - for most other situations.
C1 [Hossain, Md Yousuf; Zaman, Loutfouz] Ontario Tech Univ, 2000 Simcoe St North, Oshawa, ON L1G 0C5, Canada.
RP Hossain, MY (corresponding author), Ontario Tech Univ, 2000 Simcoe St North, Oshawa, ON L1G 0C5, Canada.
EM yousuffahim8@gmail.com; loutfouz.zaman@ontariotechu.ca
FU NSERC
FX This research was supported by NSERC Discovery.
CR Alanen M, 2003, LECT NOTES COMPUT SC, V2863, P2
   [Anonymous], KOD VIS PROGR LANG C
   [Anonymous], TOT BEG GUID GAM AI
   [Anonymous], 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology
   [Anonymous], DISC NEW WAY CHAT FR
   [Anonymous], 1992, Proceedings of the 1992 ACM Conference on Computer Supported Cooperative Work (CSCW'92), DOI DOI 10.1145/143457.143468
   Asana, AS PROJ MAN SOFTW ON
   Berland M, 2015, INT J COMP-SUPP COLL, V10, P425, DOI 10.1007/s11412-015-9217-z
   Bremm S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P31, DOI 10.1109/VAST.2011.6102439
   Caine K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P981, DOI 10.1145/2858036.2858498
   Card SK, 2006, IEEE CONF VIS ANAL, P3
   Carra E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356550
   Chen HT, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1965000
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Chirigati F., 2013, Proceedings of the Joint EDBT/ICDT 2013 Workshops, P323, DOI DOI 10.1145/2457317.2457373
   Dadgari D, 2010, NOVEL USER INTERFACE
   Dobas J, 2018, WEB3D 2018: THE 23RD INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3208806.3208809
   Dobos J, 2012, WEB3D 2012, P121
   Dobos J, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P47
   Dobos J, 2012, SIGGRAPH '12: SPECIAL INTEREST GROUP ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES CONFERENCE, DOI 10.1145/2343045.2343064
   Fan HF, 2012, PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON SUPPORTING GROUP WORK, P107
   Field A., 2013, DISCOVERING STAT USI
   Firefox, Bugzilla
   Galy E, 2018, ERGONOMICS, V61, P517, DOI 10.1080/00140139.2017.1369583
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gomez J. A. G., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P275, DOI 10.1109/VAST.2011.6102471
   Graham M, 2010, INFORM VISUAL, V9, P235, DOI 10.1057/ivs.2009.29
   Guerra-G├│mez JA., 2012, P DIGITAL RES SOC 20, V2012, P640
   Guerra-Gómez JA, 2013, TRANSPORT RES REC, P48, DOI 10.3141/2392-06
   Guerra-Gómez JA, 2013, IEEE T VIS COMPUT GR, V19, P2566, DOI 10.1109/TVCG.2013.231
   HART S G, 1988, P139
   Hegde Rajesh, 2008, 2008 23rd IEEE/ACM International Conference on Automated Software Engineering, P178, DOI 10.1109/ASE.2008.28
   Herman I, 1999, LECT NOTES COMPUT SC, V1731, P392
   Hoek AVD, 2004, ICSE 2004, DOI [10.1049/IC:20040207, DOI 10.1049/IC:20040207]
   Johansson A, 2012, 2012 17TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES (CGAMES), P253, DOI 10.1109/CGames.2012.6314584
   Kolovos DS, 2009, 2009 ICSE WORKSHOP ON COMPARISON AND VERSIONING OF SOFTWARE MODELS, P1, DOI 10.1109/CVSM.2009.5071714
   Marcotte Ryan, 2017, Computer Games Journal, V6, P171, DOI 10.1007/s40869-017-0040-9
   Moss R., 7 examples of game AI that every developer should study
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Namata G.M., 2007, Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, P939
   Nosek JT, 1998, COMMUN ACM, V41, P105, DOI 10.1145/272287.272333
   Pettersson I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174035
   Rasmussen J., 2016, ARE BEHAV TREES THIN
   Renger M, 2008, LECT NOTES BUS INF P, V10, P61
   Santoni C, 2018, IEEE COMPUT GRAPH, V38, P71, DOI 10.1109/MCG.2018.042731660
   Schmeil Andreas., 2009, Electronic Journal of Knowledge Management, V7, P637
   Sharp Helen, 2007, Interaction Design: Beyond Human Computer Interaction, V2
   Slack, WELC YOUR NEW HQ
   Soroush Ghorashi, P 9 INT WORKSH COOP, DOI [10.1145/2897586.2897613, DOI 10.1145/2897586.2897613]
   Tanimoto S. L., 1990, Journal of Visual Languages and Computing, V1, P127, DOI 10.1016/S1045-926X(05)80012-6
   Team collaboration software | Backlog, TEAM COLL SOFTW
   Unity Technologies, Unity real-time development platform
   Valsamakis Y, 2020, S VIS LANG HUM CEN C, DOI 10.1109/vl/hcc50065.2020.9127253
   Zacharis NZ, 2011, IEEE T EDUC, V54, P168, DOI 10.1109/TE.2010.2048328
   Zaman L., 2011, SOCIETY, P183
   Zaman L, 2017, PROCEEDINGS OF THE 2017 ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG 17), P67, DOI 10.1145/3103010.3103013
   Zaman L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1201, DOI 10.1145/2702123.2702398
NR 57
TC 2
Z9 2
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4671
EP 4708
DI 10.1007/s11042-022-12307-2
EA APR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000783454600013
PM 35437419
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Rathi, RN
   Mustafi, A
AF Rathi, R. N.
   Mustafi, A.
TI The importance of Term Weighting in semantic understanding of text: A
   review of techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Term weighting; Word embedding; Term weighting techniques
ID LANGUAGE; FREQUENCY; CLASSIFICATION; EXTRACTION; SCHEMES; MODEL; LAW
AB In this paper we review a wide spectrum of techniques which have been proposed in literature to enable acceptable recognition of language and text by machines. We discuss many techniques which have been proposed by researchers in the field of term weighting and explore the mathematical foundations of these methods. Term weighting schemes have broadly been classified as supervised and statistical methods and we present numerous examples from both categories to highlight the difference in approaches between the two broad categories. We pay particular attention to the Vector Space Model and its variants which form the basis of many of the other methods which have been discussed in the paper.
C1 [Rathi, R. N.; Mustafi, A.] Birla Inst Technol, Mesra, India.
C3 Birla Institute of Technology Mesra
RP Rathi, RN (corresponding author), Birla Inst Technol, Mesra, India.
EM raunakrathi.rathi@gmail.com; abhijit@bitmesra.ac.in
OI Mustafi, Abhijit/0000-0003-3454-0470; Rathi, Raunak/0000-0002-1387-4191
CR Alaya, 2017, ARXIV 170308619, V39, P4760
   Aljaber B, 2010, INFORM RETRIEVAL, V13, P101, DOI 10.1007/s10791-009-9108-x
   Altincay H, 2010, PATTERN RECOGN LETT, V31, P1310, DOI 10.1016/j.patrec.2010.03.012
   [Anonymous], 2008, COLING 2008 P WORKSH, DOI DOI 10.3115/1613172.1613178
   [Anonymous], 2004, ENTROPY-SWITZ
   Aquino GO, 2015, J COMPUT SCI TECHNOL, V15, P55
   Azam N, 2012, EXPERT SYST APPL, V39, P4760, DOI 10.1016/j.eswa.2011.09.160
   Bafna P, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P61, DOI 10.1109/ICEEOT.2016.7754750
   Baldwin T, 2016, ARXIV 160705368, V20, P723
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bengio Y, 2008, IEEE T NEURAL NETWOR, V19, P713, DOI 10.1109/TNN.2007.912312
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bougouin A, 2013, THESIS NATL U IRELAN, V24, P1532
   Brinker K, 2010, ARXIV 170308619, V39, P4760
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Campos R, 2020, INFORM SCIENCES, V509, P257, DOI 10.1016/j.ins.2019.09.013
   Carvalho, 2020, ARXIV 200307193
   Chen KW, 2016, EXPERT SYST APPL, V66, P245, DOI 10.1016/j.eswa.2016.09.009
   Chirawichitchai N., 2010, Proceedings 2010 8th International Conference on ICT and Knowledge Engineering (ICT & Knowledge Engineering 2010), P19, DOI 10.1109/ICTKE.2010.5692907
   Dai A, 2015, ARXIV 150707998, V58, P239
   Dai ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1533, DOI 10.1145/3397271.3401204
   Debole F, 2004, STUD FUZZ SOFT COMP, V138, P81
   Deng ZH, 2004, LECT NOTES COMPUT SC, V3007, P588
   Devlin J., 2018, BERT PRE TRAINING DE
   Eun-Soon YOU, 2015, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V20, P121
   Ferguson Paul, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P552, DOI 10.1007/978-3-642-28997-2_62
   Goldberg Y, 2014, ARXIV 14023722, V31, P721
   Huang C, 2006, IEEE DATA MINING, P275
   Huang WY, 2015, AAAI CONF ARTIF INTE, P2404
   Jimenez S, 2018, J INTELL FUZZY SYST, V34, P2887, DOI 10.3233/JIFS-169475
   Kombrink S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2888
   Krapivin, 2009, INFORM PROCESS MANAG, V24, P1532
   Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110
   Li Juanzi, 2007, Wuhan University Journal of Natural Sciences, V12, P917, DOI 10.1007/s11859-007-0038-4
   Li XM, 2018, INFORM PROCESS MANAG, V54, P1345, DOI 10.1016/j.ipm.2018.05.009
   Lilleberg J, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P136, DOI 10.1109/ICCI-CC.2015.7259377
   Liu Y, 2009, EXPERT SYST APPL, V36, P690, DOI 10.1016/j.eswa.2007.10.042
   Lv YH, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1103
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mladeni'c, 1998, COMPUT SPEECH LANG, V21, P492
   Mnih A, 2012, ARXIV 12066426, V12, P917
   Mnih Andriy, 2009, Advances in Neural Information Processing Systems, P1081
   Mooney R.J., 2005, SIGKDD Explor. Newsl., V7, P3, DOI [DOI 10.1145/1089815.1089817, 10.1145/1089815.1089817]
   Morin F, 2005, P AISTATS, V5, P246
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters, 2018, ARXIV 1802005365
   Piantadosi ST, 2014, PSYCHON B REV, V21, P1112, DOI 10.3758/s13423-014-0585-6
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Robertson, 2009, PROBABILISTIC RELEVA, P98
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Robertson S. E., 1995, NIST, V109, P109
   ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302
   Rong X, 2014, ARXIV 14112738, V31, P1103
   Sabbah T, 2017, APPL SOFT COMPUT, V58, P193, DOI 10.1016/j.asoc.2017.04.069
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441
   SALTON G., 1980, Proceeding: SIGIR '80 Proceedings of the 3rd annual ACM conference on Research and development in information retrieval, P9
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Schutz A, 2008, THESIS NATL U IRELAN, V24, P1532
   Schwenk H., 2006, P COLINGACL 2006 MAI, P723
   Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Siencnik SK, 2015, P 20 NORD C COMP LIN, V109, P239
   Soucy P, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1130
   Tsai FS, 2011, EXPERT SYST APPL, V38, P14094, DOI 10.1016/j.eswa.2011.04.218
   Tsai RTH, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S1-S3
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JH, 2007, LECT NOTES COMPUT SC, V4426, P857
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86
   Wang ZB, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P98, DOI 10.1109/DSC.2016.110
   Whissell JS, 2011, INFORM RETRIEVAL, V14, P466, DOI 10.1007/s10791-011-9163-y
   Wilson A., 2010, HUMAN LANGUAGE TECHN, P465
   Wilson EB, 1927, J AM STAT ASSOC, V22, P209, DOI 10.2307/2276774
   Yang Gao, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P221, DOI 10.1007/978-3-642-37456-2_19
   Yang K., 2016, 26 INT C COMP LING, P2238
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zipf George Kingsley, 2016, HUMAN BEHAV PRINCIPL
NR 84
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9761
EP 9783
DI 10.1007/s11042-022-12538-3
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000783454600012
PM 35437420
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gupta, R
   Nanda, SJ
AF Gupta, Rachana
   Nanda, Satyasai Jagannath
TI Cloud detection in satellite images with classical and deep neural
   network approach: A review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Cloud detection; Textural feature; Neural network; Evolutionary
   algorithm; Convolutional neural network; Remote sensing
ID REMOTE-SENSING IMAGES; CO-OCCURRENCE MATRIX; DETECTION ALGORITHM; SHADOW
   DETECTION; LANDSAT IMAGERY; PRECIPITATION ESTIMATION;
   SPATIAL-RESOLUTION; RADIATIVE-TRANSFER; SOLAR IRRADIANCE; AVHRR IMAGERY
AB This article introduces a review on implementations of various methods to perform cloud detection and its related applications such as detection of cloud shadow, types of cloud and cloud removal from multi-spectral satellite images. The cloud detection concept started with the basic sensitive parameters of clouds. These parameters have been reported based on albedo, spectral and textural parameters in the decade of 1980. With this parameters, a new era of Neural Network (NN) approach has been stimulated from 1992 for cloud classification. A summary of their empirical results are provided for various published works based on NN approach from 1970 to 2020. Moreover, the present article embodies experimental analysis of cloud detection using NN based classifier on multi-spectral satellite images with distinguish mathematical model of learning rules and number of hidden layers. The analysis is verified on L8, AVHRR, NOAA and GOES satellite images. The result demonstrates improved performance of NN approach with two layer perceptron architecture with Levenberg-Marquardt learning rule for cloud detection in terms of ellapse time. However, potential of self-organizing feature map (SOFM), an unsupervised NN approach, is observed in terms of accuracy over supervised learning architecture. The cloud detection algorithm is further discussed with convolutional neural network (CNN) as a deep learning algorithm to extract the local and global features from limited number of spectral bands to raise the performance accuracy of the approach.
C1 [Gupta, Rachana; Nanda, Satyasai Jagannath] Malaviya Natl Inst Technol, Dept Elect & Commun Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Gupta, R (corresponding author), Malaviya Natl Inst Technol, Dept Elect & Commun Engn, Jaipur 302017, Rajasthan, India.
EM 2015rec9517@mnit.ac.in; sjnanda.ece@mnit.ac.in
RI Nanda, Satyasai Jagannath/N-5095-2017
OI Nanda, Satyasai Jagannath/0000-0002-4005-5589
CR Ackerman SA, 2008, J ATMOS OCEAN TECH, V25, P1073, DOI 10.1175/2007JTECHA1053.1
   Alonso-Montesinos J, 2016, RENEW ENERG, V97, P155, DOI 10.1016/j.renene.2016.05.066
   [Anonymous], 2009, P 28 S EUR ASS REM S
   [Anonymous], 2005, INT C MACH LEARN ICM, DOI 10.1145/1102351.1102355
   ARKING A, 1964, SCIENCE, V143, P569, DOI 10.1126/science.143.3606.569
   Azimi-Sadjadi MR, 2000, INT GEOSCI REMOTE SE, P669, DOI 10.1109/IGARSS.2000.861666
   AzimiSadjadi MR, 1996, INT GEOSCI REMOTE SE, P1105, DOI 10.1109/IGARSS.1996.516582
   Bai T, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090715
   Bankert RL, 2007, J APPL METEOROL CLIM, V46, P36, DOI 10.1175/JAM2451.1
   BANKERT RL, 1994, J APPL METEOROL, V33, P909, DOI 10.1175/1520-0450(1994)033<0909:CCOAII>2.0.CO;2
   Bankert RLL, 1996, J APPL METEOROL, V35, P2036, DOI 10.1175/1520-0450(1996)035<2036:ITANNC>2.0.CO;2
   BELL GJ, 1981, MON WEATHER REV, V109, P2158, DOI 10.1175/1520-0493(1981)109<2158:TNIRRB>2.0.CO;2
   Berendes TA, 1999, J GEOPHYS RES-ATMOS, V104, P6199, DOI 10.1029/98JD02584
   Bloshchinskiy VD, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.034506
   Bowker D.E., 1985, SPECTRAL REFLECTANCE
   Brown M, 2000, IEEE T GEOSCI REMOTE, V38, P2346, DOI 10.1109/36.868891
   Cai WW, 2021, MULTIMED TOOLS APPL, V80, P11291, DOI 10.1007/s11042-020-10188-x
   Cerdeña A, 2007, J ATMOS OCEAN TECH, V24, P52, DOI 10.1175/JTECH1943.1
   Chai D, 2019, REMOTE SENS ENVIRON, V225, P307, DOI 10.1016/j.rse.2019.03.007
   CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2
   Chen PY, 2002, INT J REMOTE SENS, V23, P2939, DOI 10.1080/01431160110075631
   Chen PY, 2003, J GEOPHYS RES-ATMOS, V108, DOI 10.1029/2003JD003554
   Chen Y, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7050181
   Cheng HY, 2017, ATMOS MEAS TECH, V10, P199, DOI 10.5194/amt-10-199-2017
   Cheng Q, 2014, ISPRS J PHOTOGRAMM, V92, P54, DOI 10.1016/j.isprsjprs.2014.02.015
   Chethan HK, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P688, DOI 10.1109/ARTCom.2009.43
   COAKLEY JA, 1982, J GEOPHYS RES-OCEANS, V87, P4917, DOI 10.1029/JC087iC07p04917
   Coakley JA, 1914, REFLECTANCE ALBEDO S
   Cote S, 1995, INT J REMOTE SENS, V16, P3695, DOI 10.1080/01431169508954656
   CRANE RG, 1984, INT J REMOTE SENS, V5, P213, DOI 10.1080/01431168408948799
   Cromwell E, 2019, IEEE WINT CONF APPL, P619, DOI 10.1109/WACV.2019.00071
   Deng CW, 2019, IEEE GEOSCI REMOTE S, V16, P608, DOI 10.1109/LGRS.2018.2878239
   DESBOIS M, 1984, ANN GEOPHYS, V2, P599
   Dev S, 2019, USNC-URSI RADIO SCI, P113, DOI [10.1109/usnc-ursi.2019.8861850, 10.1109/USNC-URSI.2019.8861850]
   EBERT E, 1987, J CLIM APPL METEOROL, V26, P1412, DOI 10.1175/1520-0450(1987)026<1412:APRTFD>2.0.CO;2
   Faure T, 2001, REMOTE SENS ENVIRON, V77, P123, DOI 10.1016/S0034-4257(01)00199-7
   Faure T, 2001, J GEOPHYS RES-ATMOS, V106, P14961, DOI 10.1029/2001JD900058
   Faure T, 2001, J GEOPHYS RES-ATMOS, V106, P14465, DOI 10.1029/2000JD900686
   Feijt A, 2000, J APPL METEOROL, V39, P1017, DOI 10.1175/1520-0450(2000)039<1017:CDUMIA>2.0.CO;2
   Filippi AM, 2009, IEEE T GEOSCI REMOTE, V47, P771, DOI 10.1109/TGRS.2008.2004708
   Fisher A, 2014, REMOTE SENS-BASEL, V6, P776, DOI 10.3390/rs6010776
   FLEMING JR, 1974, J ATMOS SCI, V31, P2182, DOI 10.1175/1520-0469(1974)031<2182:REOCC>2.0.CO;2
   Garand L, 1988, J CLIMATE, V1, P20, DOI 10.1175/1520-0442(1988)001<0020:AROOCP>2.0.CO;2
   Giuffrida G, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142205
   GOES, 2020, IM DAT SETS
   GRANT IP, 1969, PROC R SOC LON SER-A, V313, P199, DOI 10.1098/rspa.1969.0188
   Greaves J R., 1970, Technique development to permit optimum use of satellite radiation data
   Guo JH, 2021, IEEE T GEOSCI REMOTE, V59, P700, DOI 10.1109/TGRS.2020.2991398
   Guo YN, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12061056
   Gupta Rachana, 2019, 2019 International Conference on Information Technology (ICIT), P348, DOI 10.1109/ICIT48102.2019.00068
   Gupta R., 2014, ECG ACQUISITION AUTO, DOI 10.1007/978-81-322-1557-8
   Gupta R, 2019, IEEE C EVOL COMPUTAT, P522, DOI [10.1109/cec.2019.8790355, 10.1109/CEC.2019.8790355]
   Gupta R, 2019, APPL SOFT COMPUT, V79, P203, DOI 10.1016/j.asoc.2019.03.042
   GUTMAN G, 1987, INT J REMOTE SENS, V8, P859, DOI 10.1080/01431168708948694
   Hagolle O, 2010, REMOTE SENS ENVIRON, V114, P1747, DOI 10.1016/j.rse.2010.03.002
   He QJ, 2011, INT J REMOTE SENS, V32, P6811, DOI 10.1080/01431161.2010.523730
   He QJ, 2013, INT J REMOTE SENS, V34, P2876, DOI 10.1080/01431161.2012.755275
   Hinton G. E., 2012, 12070580 ARXIV
   HOLYER RJ, 1989, IEEE T GEOSCI REMOTE, V27, P46, DOI 10.1109/36.20274
   Hong Y, 2004, J APPL METEOROL, V43, P1834, DOI 10.1175/JAM2173.1
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hsu K-L, 1997, RAINFALL ESTIMATION
   Hsu KL, 1999, WATER RESOUR RES, V35, P1605, DOI 10.1029/1999WR900032
   Hsu KL, 1997, J APPL METEOROL, V36, P1176, DOI 10.1175/1520-0450(1997)036<1176:PEFRSI>2.0.CO;2
   Hughes MJ, 2014, REMOTE SENS-BASEL, V6, P4907, DOI 10.3390/rs6064907
   Hulley GC, 2008, GEOPHYS RES LETT, V35, DOI 10.1029/2008GL034644
   HUNT GE, 1973, Q J ROY METEOR SOC, V99, P346, DOI 10.1256/smsqj.42012
   Islam MJ, 2017, APPL SOFT COMPUT, V59, P182, DOI 10.1016/j.asoc.2017.04.050
   Jacobowitz H, 1970, THESIS MIT
   Jang JD, 2006, INT J REMOTE SENS, V27, P719, DOI 10.1080/01431160500106892
   Jang JD, 2004, INT J REMOTE SENS, V25, P4541, DOI 10.1080/01431160310001657533
   Jedlovec GJ, 2008, IEEE T GEOSCI REMOTE, V46, P1705, DOI 10.1109/TGRS.2008.916208
   Jensen J.R., 2009, Remote sensing of the environment: An earth resource perspective 2/e
   Jeppesen JH, 2019, REMOTE SENS ENVIRON, V229, P247, DOI 10.1016/j.rse.2019.03.039
   Ji SP, 2021, IEEE T GEOSCI REMOTE, V59, P732, DOI 10.1109/TGRS.2020.2994349
   Johnston Travis, 2017, P MACHINE LEARNING H
   Kaminsky EJ, 1997, INT J REMOTE SENS, V18, P741, DOI 10.1080/014311697218737
   Kazantzidis A, 2011, ATMOS RES, V102, P452, DOI 10.1016/j.atmosres.2011.09.015
   Knottenberg H., 1982, ANN METEOROL, P145
   Kohonen T., 2012, Self-Organization and Associative Memory
   Kristollari V, 2020, PROC SPIE, V11524, DOI 10.1117/12.2571111
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuenning JA, 1978, LAB INVESTIGATION RA
   KUHN PM, 1963, MON WEA REV, V91, P635, DOI DOI 10.1175/1520-0493(1963)0912.3.CO;2
   Landsat, 2020, IM DAT SETS
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LEE J, 1990, IEEE T GEOSCI REMOTE, V28, P846, DOI 10.1109/36.58972
   Lee KB, 2017, IEEE T SEMICONDUCT M, V30, P135, DOI 10.1109/TSM.2017.2676245
   Lee Y, 2004, J ATMOS OCEAN TECH, V21, P159, DOI 10.1175/1520-0426(2004)021<0159:CCOSRD>2.0.CO;2
   Lewis HG, 1997, INT J REMOTE SENS, V18, P899, DOI 10.1080/014311697218827
   Lewis HG., 1995, ARL TATNALL NEURAL N
   Li HY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010152
   Li PF, 2015, NEUROCOMPUTING, V169, P34, DOI 10.1016/j.neucom.2014.09.102
   Li QY, 2011, J ATMOS OCEAN TECH, V28, P1286, DOI 10.1175/JTECH-D-11-00009.1
   Li YS, 2020, REMOTE SENS ENVIRON, V250, DOI 10.1016/j.rse.2020.112045
   Li Z., 2018, ISPRS Ann. Photogramm., Remote Sens. Spatial Inf. Sci., VIV-3, P149, DOI [10.5194/isprs-annals-IV-3-149-2018, DOI 10.5194/ISPRS-ANNALS-IV-3-149-2018]
   Li ZW, 2019, ISPRS J PHOTOGRAMM, V150, P197, DOI 10.1016/j.isprsjprs.2019.02.017
   LILJAS E, 1986, USE AVHRR 3 7 MICROM
   LIOU KN, 1973, J GEOPHYS RES, V78, P1409, DOI 10.1029/JC078i009p01409
   LIOU RJ, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P4327, DOI 10.1109/ICNN.1994.374963
   Lissens G, 2000, INT GEOSCI REMOTE SE, P834, DOI 10.1109/IGARSS.2000.861719
   Liu HZ, 2021, IEEE T BIG DATA, V7, P341, DOI 10.1109/TBDATA.2018.2867485
   LO RC, 1971, MON WEATHER REV, V99, P599, DOI 10.1175/1520-0493(1971)099<0599:AIOCDF>2.3.CO;2
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Mateo-García G, 2020, ISPRS J PHOTOGRAMM, V160, P1, DOI 10.1016/j.isprsjprs.2019.11.024
   Mazzoni D, 2007, REMOTE SENS ENVIRON, V107, P149, DOI 10.1016/j.rse.2006.06.021
   Melgani F, 2006, IEEE T GEOSCI REMOTE, V44, P442, DOI 10.1109/TGRS.2005.861929
   Miller SW, 1997, J APPL METEOROL, V36, P1346, DOI 10.1175/1520-0450(1997)036<1346:AANNCC>2.0.CO;2
   MILLER WT, 1990, P IEEE, V78, P1561, DOI 10.1109/5.58338
   MINNIS P, 1987, J GEOPHYS RES-ATMOS, V92, P4051, DOI 10.1029/JD092iD04p04051
   MINNIS P, 1984, J CLIM APPL METEOROL, V23, P1032, DOI 10.1175/1520-0450(1984)023<1032:DVORCA>2.0.CO;2
   Mohajerani S, 2019, INT GEOSCI REMOTE SE, P1029, DOI [10.1109/IGARSS.2019.8898776, 10.1109/igarss.2019.8898776]
   Morales G, 2018, LECT NOTES COMPUT SC, V11141, P280, DOI 10.1007/978-3-030-01424-7_28
   MURAO H, 1993, IEEE IJCNN, P1211
   Navin MS, 2020, MULTIMED TOOLS APPL, V79, P29751, DOI 10.1007/s11042-020-09531-z
   Neubauer C, 1998, IEEE T NEURAL NETWOR, V9, P685, DOI 10.1109/72.701181
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   NOAA, 2020, ENV VIS LAB
   OF TIROS-N, 1979, DAT EXTR CAL TIR N N
   Palsson F, 2017, IEEE GEOSCI REMOTE S, V14, P639, DOI 10.1109/LGRS.2017.2668299
   Parikh J., 1977, Remote Sensing of Environment, V6, P67, DOI 10.1016/0034-4257(77)90007-4
   PEAK JE, 1994, J APPL METEOROL, V33, P605, DOI 10.1175/1520-0450(1994)033<0605:SOSIUH>2.0.CO;2
   Peak JE., 1991, APPL NEURAL NETWORKS
   PICKETT RM, 1970, PICTURE PROCESSING P, P289
   Raschke E., 1987, Advances in space research, V7, P137, DOI DOI 10.1016/0273-1177(87)90136-0
   Rossow WB, 1989, J CLIMATE, V2, P201, DOI 10.1175/1520-0442(1989)002<0201:MCPFSA>2.0.CO;2
   Rossow WB, 1989, J CLIMATE, V2, P419, DOI 10.1175/1520-0442(1989)002<0419:GSCVFS>2.0.CO;2
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   SAUNDERS RW, 1988, INT J REMOTE SENS, V9, P123, DOI 10.1080/01431168808954841
   Savory T.H., 1928, The Biology of Spiders
   SCHIFFER RA, 1983, B AM METEOROL SOC, V64, P779
   Sedano F, 2011, ISPRS J PHOTOGRAMM, V66, P588, DOI 10.1016/j.isprsjprs.2011.03.005
   Segal-Rozenhaimer M, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111446
   SEZE G, 1991, INT J REMOTE SENS, V12, P877, DOI 10.1080/01431169108929702
   Shao ZF, 2019, IEEE T GEOSCI REMOTE, V57, P4062, DOI 10.1109/TGRS.2018.2889677
   Shen HF, 2014, ISPRS J PHOTOGRAMM, V96, P224, DOI 10.1016/j.isprsjprs.2014.06.011
   SHENK WE, 1976, MON WEATHER REV, V104, P284, DOI 10.1175/1520-0493(1976)104<0284:AMCTIM>2.0.CO;2
   Shi MY, 2016, INT GEOSCI REMOTE SE, P701, DOI 10.1109/IGARSS.2016.7729176
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Slawinski O., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P283, DOI 10.1109/IJCNN.1991.155190
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Stowe L. L., 1988, Journal of Climate, V1, P445, DOI 10.1175/1520-0442(1988)001<0445:NGCCPI>2.0.CO;2
   Strahler A. H., 1999, MODIS DOCUMENTATION, V23, P42
   Sun L, 2020, INT J REMOTE SENS, V41, P1349, DOI 10.1080/01431161.2019.1667548
   SZEJWACH G, 1982, J APPL METEOROL, V21, P384, DOI 10.1175/1520-0450(1982)021<0384:DOSTCC>2.0.CO;2
   Tian B, 2000, IEEE T NEURAL NETWOR, V11, P903, DOI 10.1109/72.857771
   Tuia D, 2018, INT GEOSCI REMOTE SE, P4351, DOI 10.1109/IGARSS.2018.8517312
   Walder P, 2000, INT J REMOTE SENS, V21, P1693, DOI 10.1080/014311600209977
   Wallach I, 2015, ARXIV PREPRINT ARXIV
   Wang L, 2018, WATER-SUI, V10, DOI 10.3390/w10111666
   Watmough GR, 2011, INT J APPL EARTH OBS, V13, P220, DOI 10.1016/j.jag.2010.11.006
   Wei J, 2020, REMOTE SENS ENVIRON, V248, DOI 10.1016/j.rse.2020.112005
   WELCH RM, 1988, J GEOPHYS RES-ATMOS, V93, P12663, DOI 10.1029/JD093iD10p12663
   WELCH RM, 1988, J APPL METEOROL, V27, P341, DOI 10.1175/1520-0450(1988)027<0341:MSCFOT>2.0.CO;2
   WELCH RM, 1992, J APPL METEOROL, V31, P405, DOI 10.1175/1520-0450(1992)031<0405:PCASCU>2.0.CO;2
   WELCH RM, 1989, J GEOPHYS RES-ATMOS, V94, P14767, DOI 10.1029/JD094iD12p14767
   Wen Y, 2020, MULTIMED TOOLS APPL, V79, P34531, DOI 10.1007/s11042-020-08945-z
   Widrow B., 1960, IRE WESCON Conv. Rec
   Wu X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111853
   Xie F, 2017, IEEE J-STARS
   Xie FY, 2017, IEEE J-STARS, V10, P3631, DOI 10.1109/JSTARS.2017.2686488
   YAMAMOTO G, 1970, J ATMOS SCI, V27, P282, DOI 10.1175/1520-0469(1970)027<0282:RTIWCI>2.0.CO;2
   Yan ZY, 2018, IEEE GEOSCI REMOTE S, V15, P1600, DOI 10.1109/LGRS.2018.2846802
   Yanan G., 2020, J PHYS C SERIES, V1617
   Yang JY, 2019, IEEE T GEOSCI REMOTE, V57, P6195, DOI 10.1109/TGRS.2019.2904868
   Yang J, 2012, J ATMOS OCEAN TECH, V29, P527, DOI 10.1175/JTECH-D-11-00002.1
   YHANN SR, 1995, IEEE T GEOSCI REMOTE, V33, P590, DOI 10.1109/36.387575
   Yin Z, 2020, ARXIV200610358
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   YOSHIDA T, 1994, IEEE T GEOSCI REMOTE, V32, P1103, DOI 10.1109/36.312899
   Young MJ., 1967, J APPL METEOR CLIMAT, V6, P573, DOI [10.1175/1520-0450(1967)0062.0.CO;2, DOI 10.1175/1520-0450(1967)006,0573:VIETCC.2.0.CO;2]
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Yu JC, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132106
   Yuan K, 2017, IEEE IMAGE PROC, P61, DOI 10.1109/ICIP.2017.8296243
   Zhan YJ, 2017, IEEE GEOSCI REMOTE S, V14, P1785, DOI 10.1109/LGRS.2017.2735801
   Zhang J, 2019, J GEOVIS SPAT ANAL, V3, DOI 10.1007/s41651-019-0037-y
   Zhang JX, 2013, REMOTE SENS-BASEL, V5, P3749, DOI 10.3390/rs5083749
   Zhong B, 2017, IEEE J-STARS, V10, P4898, DOI 10.1109/JSTARS.2017.2734912
   Zhou Y, 2016, IEEE GEOSCI REMOTE S, V13, P1935, DOI 10.1109/LGRS.2016.2618840
   Zhu HJ, 2016, OPTIK, V127, P742, DOI 10.1016/j.ijleo.2015.10.144
   Zhu Z, 2015, REMOTE SENS ENVIRON, V159, P269, DOI 10.1016/j.rse.2014.12.014
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zi Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060877
   Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202
NR 188
TC 8
Z9 8
U1 8
U2 69
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31847
EP 31880
DI 10.1007/s11042-022-12078-w
EA APR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000010
DA 2024-07-18
ER

PT J
AU Serrano, R
   Morillo, P
   Casas, S
   Cruz-Neira, C
AF Serrano, Ramiro
   Morillo, Pedro
   Casas, Sergio
   Cruz-Neira, Carolina
TI An empirical evaluation of two natural hand interaction systems in
   augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Natural interaction; Gesture tracking; HoloLens;
   Magic leap
ID ENVIRONMENTS; HOLOLENS; DESIGN
AB Human-computer interaction based on hand gesture tracking is not uncommon in Augmented Reality. In fact, the most recent optical Augmented Reality devices include this type of natural interaction. However, due to hardware and system limitations, these devices, more often than not, settle for semi-natural interaction techniques, which may not always be appropriate for some of the tasks needed in Augmented Reality applications. For this reason, we compare two different optical Augmented Reality setups equipped with hand tracking. The first one is based on a Microsoft HoloLens (released in 2016) and the other one is based on a Magic Leap One (released more than two years later). Both devices offer similar solutions for the visualization and registration problems but differ in the hand tracking approach, since the former uses a metaphoric hand-gesture tracking and the latter relies on an isomorphic approach. We raise seven research questions regarding these two setups, which we answer after performing two task-based experiments using virtual elements, of different sizes, that are moved using natural hand interaction. The questions deal with the accuracy and performance achieved with these setups and also with user preference, recommendation and perceived usefulness. For this purpose, we collect both subjective and objective data about the completion of these tasks. Our initial hypothesis was that there would be differences, in favor of the isomorphic and newer setup, in the use of hand interaction. However, the results surprisingly show that there are very small objective differences between these setups, and the isomorphic approach is not significantly better in terms of accuracy and mistakes, although it allows a faster completion of one of the tasks. In addition, no remarkable statistically significant differences can be found between the two setups in the subjective datasets gathered through a specific questionnaire. We also analyze the opinions of the participants in terms of usefulness, preference and recommendation. The results show that, although the Magic Leap-based system gets more support, the differences are not statistically significant.
C1 [Serrano, Ramiro] Univ Arkansas UALR, Emerging Analyt Ctr EAC, Little Rock, AR 72204 USA.
   [Morillo, Pedro; Casas, Sergio] Univ Valencia UV, Dept Comp Sci, Valencia, Spain.
   [Cruz-Neira, Carolina] Univ Cent Florida, Dept Comp Sci, Agere Chair, Orlando, FL 32816 USA.
C3 University of Valencia; State University System of Florida; University
   of Central Florida
RP Casas, S (corresponding author), Univ Valencia UV, Dept Comp Sci, Valencia, Spain.
EM Sergio.Casas@uv.es
RI Casas Yrurzum, Sergio/S-3693-2017; Serrano Vergel, Ramiro/KLY-8327-2024
OI Casas Yrurzum, Sergio/0000-0002-0396-4628; 
FU CRUE-CSIC
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Affolter R, 2019, J FORENSIC RADIOL IM, V16, P5, DOI 10.1016/j.jofri.2018.11.003
   Al Janabi HF, 2020, SURG ENDOSC, V34, P1143, DOI 10.1007/s00464-019-06862-3
   Al-Kalbani M, 2016, INT SYM MIX AUGMENT, P84, DOI 10.1109/ISMAR.2016.14
   Aliprantis John., 2019, VIPERC@ IRCDL, P50
   Anderson R, 2019, IEEE SOUTHEASTCON, DOI 10.1109/southeastcon42311.2019.9020354
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Asgary A, 2020, IEEE T ENG MANAGE, V67, P545, DOI 10.1109/TEM.2019.2932291
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Borja EF, 2018, LECT NOTES COMPUT SC, V10851, P211, DOI 10.1007/978-3-319-95282-6_16
   Chaconas N, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P33, DOI 10.1109/VR.2018.8446320
   Chen ZR, 2017, IEEE SYS MAN CYBERN, P206, DOI 10.1109/SMC.2017.8122603
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Cui N, 2017, PROC SPIE, V10049, DOI 10.1117/12.2251625
   Dascano, 2018, MAGIC LEAP ONE AR LE, P27
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Frutos-Pascual M, 2019, LECT NOTES COMPUT SC, V11749, P287, DOI 10.1007/978-3-030-29390-1_16
   Gibby JT, 2019, INT J COMPUT ASS RAD, V14, P525, DOI 10.1007/s11548-018-1814-7
   Gimeno J, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P21, DOI 10.1109/ISMAR-Adjunct.2018.00024
   Hanna MG, 2018, ARCH PATHOL LAB MED, V142, P638, DOI 10.5858/arpa.2017-0189-OA
   Hartholt A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P205, DOI 10.1145/3349537.3352766
   Hoover M., 2018, THESIS IOWA STATE U
   ISHII H, 1994, COMMUN ACM, V37, P83, DOI 10.1145/179606.179687
   Ishiyama H, 2016, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2016.7504716
   Khalaf AS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P397, DOI 10.1145/3343055.3360758
   Kuhlemann I, 2017, HEALTHC TECHNOL LETT, V4, P184, DOI 10.1049/htl.2017.0061
   Kyriakou Panayiotis, 2019, Digital Applications in Archaeology and Cultural Heritage, V12, DOI 10.1016/j.daach.2018.e00088
   Lee J, 2019, INT J HUM-COMPUT INT, V35, P751, DOI 10.1080/10447318.2018.1489581
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Lia H, 2018, PROC SPIE, V10576, DOI 10.1117/12.2293934
   Ling FF, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1044, DOI [10.1109/VR.2019.8798315, 10.1109/vr.2019.8798315]
   Liu HM, 2016, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2016.24
   Liu Y, 2018, IEEE MULTIMEDIA, V25, P8, DOI 10.1109/MMUL.2018.2873473
   Lu G, 2012, VIRTUAL REAL-LONDON, V16, P243, DOI 10.1007/s10055-011-0195-9
   Macaranas A, 2015, INTERACT COMPUT, V27, P357, DOI 10.1093/iwc/iwv003
   Maniam P, 2020, J VIS COMMUN MED, V43, P17, DOI 10.1080/17453054.2019.1671813
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   McMahan RP, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P11, DOI 10.1109/3DUI.2010.5444727
   Microsoft, 2016, 2 HANDS GESTURE
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Munsinger B, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI [10.1145/3359996.3364274, 10.1109/vs-games.2019.8864548]
   NaturalPoint Inc, OPT MOT CAPT SYST
   Ni T, 2011, INT J HUM-COMPUT ST, V69, P551, DOI 10.1016/j.ijhcs.2011.05.001
   O'Connor TF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179766
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Portales C., 2016, Handbook of Research on Human-Computer Interfaces, Developments, and Applications, P216, DOI DOI 10.4018/978-1-5225-0435-1.CH009
   Pratt P, 2018, EUR RADIOL EXP, V2, DOI 10.1186/s41747-017-0033-2
   Prilla Michael., 2019, AIS Transactions on Human-Computer Interaction, V11, P157
   Quandt M, P DELBA 2020 WORKSH
   Rae E, 2018, PROC SPIE, V10576, DOI 10.1117/12.2293680
   Ramos M.S., 2019, Development of mixed reality applications using the magic leap one device
   Romanus T, 2020, ARXIV PREPRINT ARXIV
   Sadri S, 2019, INT SYM MIX AUGMENT, P93, DOI 10.1109/ISMAR.2019.00-21
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   SERRANO R, 2020, IN PRESS
   Sorensen S, 2019, PROC EUR CONF GAME, P649
   Stemasov E, 2020, ARXIV PREPRINT ARXIV
   Teng C C., 2019, Proceedings of the 3rd International Conference on Medical and Health Informatics. ICMHI'19. Association for Computing Machinery, P49, DOI DOI 10.1145/3340037.3340050
   Tian Y, 2018, MULTIMED TOOLS APPL, V77, P16561, DOI 10.1007/s11042-017-5228-2
   Valentini PP, 2018, INT J INTERACT DES M, V12, P1157, DOI 10.1007/s12008-018-0461-0
   Vuletic T, 2019, INT J HUM-COMPUT ST, V129, P74, DOI 10.1016/j.ijhcs.2019.03.011
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xue H, 2019, COMPUTERS, V8, DOI 10.3390/computers8010009
   Yang CK, 2020, VIRTUAL REAL-LONDON, V24, P527, DOI 10.1007/s10055-019-00415-8
   Zhang W., 2020, IOP C SERIES MAT SCI
   Zuo Y, 2020, SURG INNOV, V27, P193, DOI 10.1177/1553350619893236
NR 67
TC 7
Z9 8
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31657
EP 31683
DI 10.1007/s11042-022-12864-6
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779973300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Tamboli, AI
   Kokate, RD
AF Tamboli, Allabakash Isak
   Kokate, Rajendra D.
TI Query based relevant music genre retrieval using adaptive artificial
   neural network for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query based music genre retrieval (Q-MGR); Adaptive artificial neural
   network (AANN); Grasshopper optimization algorithm (GOA); Mel frequency
   cepstral coefficients (MFCC)
ID INFORMATION-RETRIEVAL; RECOMMENDATION; SELECTION
AB In the case of digital music industry, current major internet stores contain millions of tracks, which complicate search, retrieval and discovery of music relevant for a user. To facilitate the advancement in multimedia applications, an efficient Query based Music Genre Retrieval (Q-MGR) strategy constructed by AANN (Adaptive Artificial Neural Network) is followed in this paper. Here, the proposed Q-MGR approach is done in three steps. Firstly, the few relevant features that are capable of distinguishing variety of signals are extracted. In second step, the AANN is trained with few music query signals to produce the prediction model for enabling the query based music retrieval. Here, the AANN is modelled to develop dynamic prediction model using Grasshopper Optimization algorithm (GOA), where, the optimal number of hidden layers and its neurons are found. Finally, the retrieval step is done with the predicted network model. Moreover, the proposed methodology is implemented in the working platform of MATLAB and the results are analysed with the recent literature works.
C1 [Tamboli, Allabakash Isak] SGGSIE & T, Dept Elect & Telecommun, Nanded, Maharashtra, India.
   [Kokate, Rajendra D.] Coll Engn, Dept Instrumentat & Control Engn, Pune, Maharashtra, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology; College
   of Engineering Pune
RP Tamboli, AI (corresponding author), SGGSIE & T, Dept Elect & Telecommun, Nanded, Maharashtra, India.
EM allabakashisaktamboli0204@gmail.com; rdk.instru@coep.ac.in
RI Tamboli, Allabakash Isak/KHW-4443-2024
OI Tamboli, Allabakash Isak/0009-0003-5584-0066
CR Andjelkovic I, 2018, INT J HUM COMPUT STU
   Bayle Y, 2019, MULTIMED TOOLS APPL, V78, P2703, DOI 10.1007/s11042-018-5797-8
   Bogdanov D, 2013, INFORM PROCESS MANAG, V49, P13, DOI 10.1016/j.ipm.2012.06.004
   Borjian N, 2017, INT J MULTIMED INF R, V6, P155, DOI 10.1007/s13735-017-0125-z
   Choi K, 2018, IEEE TETCI, V2, P139, DOI 10.1109/TETCI.2017.2771298
   Costa YMG, 2012, SIGNAL PROCESS, V92, P2723, DOI 10.1016/j.sigpro.2012.04.023
   Foleis JH, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106127
   Goulart AJH, 2012, EGYPT INFORM J, V13, P59, DOI 10.1016/j.eij.2012.03.001
   Huang YF, 2014, DATA KNOWL ENG, V92, P60, DOI 10.1016/j.datak.2014.07.005
   Hyung Z, 2017, INFORM PROCESS MANAG, V53, P1185, DOI 10.1016/j.ipm.2017.04.006
   Lim SC, 2012, IEEE T CONSUM ELECTR, V58, P1262, DOI 10.1109/TCE.2012.6414994
   Raposo F, 2016, IEEE-ACM T AUDIO SPE, V24, P1119, DOI 10.1109/TASLP.2016.2541299
   Rosner A, 2018, J INTELL INF SYST, V50, P363, DOI 10.1007/s10844-017-0464-5
   Saari P, 2016, IEEE T AFFECT COMPUT, V7, P122, DOI 10.1109/TAFFC.2015.2462841
   Saari P, 2011, IEEE T AUDIO SPEECH, V19, P1802, DOI 10.1109/TASL.2010.2101596
   Sánchez-Moreno D, 2016, EXPERT SYST APPL, V66, P234, DOI 10.1016/j.eswa.2016.09.019
   Shen JL, 2019, MULTIMEDIA SYST, V25, P639, DOI 10.1007/s00530-019-00613-z
   Urbano J, 2013, J INTELL INF SYST, V41, P345, DOI 10.1007/s10844-013-0249-4
   Yu Y, 2020, NEUROCOMPUTING, V372, P84, DOI 10.1016/j.neucom.2019.09.054
   Zheng L, 2015, SOFT COMPUT, V19, P1567, DOI 10.1007/s00500-014-1307-8
NR 20
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31603
EP 31629
DI 10.1007/s11042-022-12351-y
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000017
DA 2024-07-18
ER

PT J
AU Hu, WB
   Wu, XJ
   Xu, TY
AF Hu, Wen-Bo
   Wu, Xiao-Jun
   Xu, Tian-Yang
TI One-step kernelized sparse clustering on grassmann manifolds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subspace clustering; Grassmann manifolds; Kernelized method
ID LOW-RANK; SUBSPACE; SEGMENTATION; ALGORITHM; ROBUST
AB Sparse Subspace Clustering (SSC) based clustering methods have achieved great success since these methods could effectively explore the low-dimensional subspace structure embedded in the original data. However, most existing subspace clustering methods are designed for vectorial data from linear spaces, thus not suitable for high dimensional data (such as imageset or video) with the non-linear manifold structure. In this paper, we propose a unified framework about kernelized sparse subspace clustering on Grassmann manifolds, which can learn the optimal affinity graph with the best clustering index matrix. The experimental results on six public datasets illustrate that the proposed method is obviously better than most related clustering methods based on Grassmann manifolds.
C1 [Hu, Wen-Bo] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Wu, Xiao-Jun] Jiangnan Univ, Sch IoT Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Hu, Wen-Bo; Wu, Xiao-Jun] Jiangsu Prov Engn Lab Pattern Recognit & Computat, Jiangnan, Peoples R China.
   [Xu, Tian-Yang] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 Jiangnan University; Jiangnan University; University of Surrey
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch IoT Engn, Wuxi 214122, Jiangsu, Peoples R China.; Wu, XJ (corresponding author), Jiangsu Prov Engn Lab Pattern Recognit & Computat, Jiangnan, Peoples R China.
EM wu_xiaojun@jiangnan.edu.cn
RI Xu, Tianyang/AAE-1982-2019
OI Xu, Tianyang/0000-0002-9015-3128; Wu, Xiao-Jun/0000-0002-0310-5778
FU National Natural Science Foundation of China [62020106012, U1836218,
   61672265]; 111 Project of Ministry of Education of China [B12018]
FX This work was supported by the National Natural Science Foundation of
   China (62020106012, U1836218, 61672265), and the 111 Project of Ministry
   of Education of China (B12018).
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Fathi A, 2008, PROC CVPR IEEE, P3064
   Gruber A, 2004, PROC CVPR IEEE, P707
   Guo JP, 2021, INT C PATT RECOG, P907, DOI 10.1109/ICPR48806.2021.9412242
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Harandi M, 2013, IEEE I CONF COMP VIS, P3120, DOI 10.1109/ICCV.2013.387
   Harandi MT, 2014, LECT NOTES COMPUT SC, V8695, P408, DOI 10.1007/978-3-319-10584-0_27
   Hu WB, 2020, NEURAL PROCESS LETT, V52, P849, DOI 10.1007/s11063-020-10274-z
   Jayasumana S, 2014, PROC CVPR IEEE, P3802, DOI 10.1109/CVPR.2014.480
   Ji P, 2017, ADV NEUR IN, V30
   Ji P, 2015, IEEE I CONF COMP VIS, P4687, DOI 10.1109/ICCV.2015.532
   Kang Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2312
   Kang Z, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105102
   Kang Z, 2019, KNOWL-BASED SYST, V163, P510, DOI 10.1016/j.knosys.2018.09.009
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu TC, 2017, IEEE ANN INT CONF CY, P920, DOI 10.1109/CYBER.2017.8446507
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Piao XL, 2019, PROC CVPR IEEE, P12067, DOI 10.1109/CVPR.2019.01235
   Rao SR, 2008, PROC CVPR IEEE, P743
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Shi J., 2010, IEEE T PATTERN ANAL, V22, P905
   Shirazi S, 2012, IEEE IMAGE PROC, P781, DOI 10.1109/ICIP.2012.6466976
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Song K, 2021, IEEE T PATTERN ANAL
   Song K, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107560
   Tsakiris MC, 2018, IEEE T PATTERN ANAL, V40, P482, DOI 10.1109/TPAMI.2017.2678477
   Wang BY, 2021, IEEE T MULTIMEDIA, V23, P216, DOI 10.1109/TMM.2020.2975394
   Wang BY, 2015, LECT NOTES COMPUT SC, V9003, P81, DOI 10.1007/978-3-319-16865-4_6
   Wang XQ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3925
   Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2
   Yin M, 2016, PROC CVPR IEEE, P5157, DOI 10.1109/CVPR.2016.557
   Zhan K, 2019, IEEE T KNOWL DATA EN, V31, P1984, DOI 10.1109/TKDE.2018.2872061
   Zhan SH, 2019, NEURAL NETWORKS, V109, P56, DOI 10.1016/j.neunet.2018.10.001
NR 45
TC 2
Z9 2
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31017
EP 31038
DI 10.1007/s11042-022-12495-x
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500005
DA 2024-07-18
ER

PT J
AU Cao, WM
   Zheng, CT
   Yan, ZY
   He, ZH
   Xie, WX
AF Cao, Wenming
   Zheng, Canta
   Yan, Zhiyue
   He, Zhihai
   Xie, Weixin
TI Geometric machine learning: research and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Geometric deep learning; Convolutional neural
   network; Graph; Manifold
ID NEURAL-NETWORKS; DIMENSIONALITY REDUCTION; LAPLACIAN EIGENMAPS
AB Over the last decade, deep learning has revolutionized many traditional machine learning tasks, ranging from computer vision to natural language processing. Although deep learning has achieved excellent performance, it does not perform as well as expected on geometric (non-Euclidean domain) data. Recently, many studies on extending deep learning approaches for graphs and manifolds have merged. In this article, we aim to provide a comprehensive overview of geometric deep learning and comparative methods. First, we introduce the related work and history of the geometric deep learning field and the theoretical background. Next, we summarize the evaluation of the methods of graph and manifold. We further discuss the applications and benchmark datasets of these methods across various research domains. Finally, we propose potential research directions and challenges in this rapidly growing field.
C1 [Cao, Wenming; Zheng, Canta; Yan, Zhiyue; Xie, Weixin] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.
   [He, Zhihai] Univ Missouri, Dept Elect & Comp Engn, Video Proc & Commun Lab, Columbia, MO 65211 USA.
C3 Shenzhen University; University of Missouri System; University of
   Missouri Columbia
RP Zheng, CT; Xie, WX (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.
EM wmcao@szu.edu.cn; 1900432031@email.szu.edu.cn;
   1810263026@email.szu.edu.cn; hezhi@missouri.edu; wxxie@szu.edu.cn
RI cao, wenming/Y-5293-2019; Yan, Zhiyue/JMQ-4383-2023
OI Yan, Zhiyue/0000-0003-0207-1294
FU National Natural Science Foundation of China [61771322, 61871186];
   Fundamental Research Foundation of Shenzhen [JCYJ20190808160815125]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61771322 and Grant 61871186 and in part
   by the Fundamental Research Foundation of Shenzhen under Grant
   JCYJ20190808160815125.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Ahmed A., 2013, P 22 INT C WORLD WID, P37, DOI [10.1145/2488388.2488393, DOI 10.1145/2488388.2488393]
   Albishre K, 2015, 2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 3, P98, DOI 10.1109/WI-IAT.2015.90
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2017, ARXIV170202181
   [Anonymous], 2009, P 26 ANN INT C MACHI, DOI DOI 10.1145/1553374.1553494
   Atwood J, 2016, ADV NEUR IN, V29
   Bastings J., 2017, P 2017 C EMP METH NA, P1957, DOI 10.18653/v1/d17-1209
   Battaglia, 2018, ARXIV180601261
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bo D., 2021, ARXIV210100797
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boscaini D, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12693
   Boscaini D, 2016, ADV NEUR IN, V29
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cao S., 2015, P 24 ACM INT C INFOR, P891
   Cao WM, 2020, IEEE ACCESS, V8, P35929, DOI 10.1109/ACCESS.2020.2975067
   Caragea Cornelia, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P311, DOI 10.1007/978-3-319-06028-6_26
   Chen Jianfei, 2017, ARXIV171010568
   Chen Ming, 2020, ICML
   Chen XL, 2018, PROC CVPR IEEE, P7239, DOI 10.1109/CVPR.2018.00756
   Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188467
   Coley CW, 2017, J CHEM INF MODEL, V57, P1757, DOI 10.1021/acs.jcim.6b00601
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   De Cao N., 2018, ICML 2018 WORKSH THE
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P417, DOI 10.1145/3308558.3313488
   Fout A, 2017, ADV NEUR IN, V30
   Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947
   Gao Hongyang, 2019, ARXIV190505178
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   GORI M, 2005, IEEE IJCNN, P729, DOI DOI 10.1109/IJCNN.2005.1555942
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo M, 2018, LECT NOTES COMPUT SC, V11205, P673, DOI 10.1007/978-3-030-01246-5_40
   Hamaguchi T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1802
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henaff M., 2015, ARXIV150605163
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hjelm R. Devon, 2018, LEARNING DEEP REPRES
   Hu W., 2019, ARXIV190512265
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137
   JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573
   Jin XB, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23020219
   Kim D., 2021, INT C LEARN REPR ICL
   Kipf T. N., 2016, ARXIV161107308, V1050, P21
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ktena Sofia Ira, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P469, DOI 10.1007/978-3-319-66182-7_54
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee JB, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3363574
   Lee J, 2019, PR MACH LEARN RES, V97
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Li YP, 2019, IEEE ACCESS, V7, P129815, DOI 10.1109/ACCESS.2019.2940217
   Litany O, 2017, IEEE I CONF COMP VIS, P5660, DOI 10.1109/ICCV.2017.603
   Liu Z., 2020, SYNTH LECT ARTIF INT, V14, P1, DOI DOI 10.2200/S00980ED1V01Y202001AIM045
   Liu ZQ, 2019, AAAI CONF ARTIF INTE, P4424
   Lovasz L, 1993, BOLYAI MATH STUD, V1, P9
   Ma Y, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P719, DOI 10.1145/3397271.3401092
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   McCallum A., 2017, CORA DATASET
   Monti F, 2017, ADV NEUR IN, V30
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Narasimhan M, 2018, ADV NEUR IN, V31
   Niepert M, 2016, PR MACH LEARN RES, V48
   Ou MD, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1105, DOI 10.1145/2939672.2939751
   Pan SR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2609
   Parisot Sarah, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P177, DOI 10.1007/978-3-319-66179-7_21
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Pham T, 2016, ARXIV160904508
   Pitner G, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371899
   Qi CR, 2017, ADV NEUR IN, V30
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Rahimi A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2009
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   RHEE S, 2018, ARXIV171105859, P3527
   Rong Yu, 2019, 8 INT C LEARNING REP
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ruder S., 2016, ARXIV
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santoro A, 2017, ADV NEUR IN, V30
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Shchur O, 2019, ARXIV190912201
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tailor S. A., 2021, ARXIV210401481, P1
   Tang J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1165, DOI 10.1145/2783258.2783307
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tang Jiliang, 2012, KDD, P253, DOI [10.1145/2339530.2339574, DOI 10.1145/2339530.2339574]
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thekumparampil K. K., 2018, Attention-Based Graph Neural Network for SemiSupervised Learning
   Tu K, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2357, DOI 10.1145/3219819.3220068
   van der Merwe R, 2019, ARCH REC, V40, P239, DOI 10.1080/23257962.2017.1388224
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic Petar, 2017, ARXIV171010903, DOI DOI 10.48550/ARXIV.1710.10903
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang R, 2019, IEEE ACCESS, V7, P12755, DOI 10.1109/ACCESS.2019.2892822
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P349
   Wilensky U, 2006, COGNITION INSTRUCT, V24, P171, DOI 10.1207/s1532690xci2402_1
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Ying R, 2018, ADV NEUR IN, V31
   Yu F., 2015, ARXIV
   Zhang JN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4264
   Zhang JN, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P339
   Zhang S, 2020, ARXIV200510150
   Zhang ZC, 2019, TRANSPORT RES C-EMER, V105, P297, DOI 10.1016/j.trc.2019.05.039
   Zhang ZY, 2003, LECT NOTES COMPUT SC, V2690, P477
   Zhou J, 2018, ARTIF CELL NANOMED B, V46, pS1016, DOI 10.1080/21691401.2018.1442841
   Zilly JG, 2017, PR MACH LEARN RES, V70
   Zitnik M, 2018, BIOINFORMATICS, V34, P457, DOI 10.1093/bioinformatics/bty294
NR 138
TC 3
Z9 3
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30545
EP 30597
DI 10.1007/s11042-022-12683-9
EA APR 2022
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900005
DA 2024-07-18
ER

PT J
AU Biswas, B
   Ghosh, SK
   Ghosh, A
AF Biswas, Biswajit
   Ghosh, Swarup Kr
   Ghosh, Anupam
TI A novel intuitionistic-near fuzzy sets based image fusion approach:
   development on hybrid MPI plus OpenMP parallel model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Massage passing interface (MPI); OpenMP; Infrared image;
   Visual image; Intutionistic fuzzy set; Near set; Fuzzy entropy
ID SHEARLET TRANSFORM; ALGORITHM
AB Image fusion is used to extract relevant features from different image modalities like infrared and visual images and to combine them into a single image effectively. In this article, we have introduced a hybrid-parallel intuitionistic-near set based fusion scheme through near feature map approach. The proposed hybrid-parallel fusion scheme fully utilizes distributed memory parallelism and OpenMP for shared-memory parallelism. First, the fuzzy image representation based intuitionistic fuzzy theory is considered. Second, the principal features in the infrared and visual images are mapped using near-fuzzy set. Third, final fusion features are measured from decomposed multiple image blocks through domain decomposition strategy and image features are extracted via a defined probe function. After that, the near features have been computed from both the original images via intuitionistic entropy-based probe function, the ultimate fusion image is achieved through perceptual threshold limit on the membership grades in the fuzzy space. Finally, the resultant fused image is obtained through defuzzification. A hybrid MPI and OpenMP model is adopted to reduce inter-node communication and parallelized codes. The experimental result shows that the proposed method effectively combines the relevant information of both source images and provides a high resolution image.
C1 [Biswas, Biswajit] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
   [Ghosh, Swarup Kr] Sister Nivedita Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Ghosh, Anupam] Netaji Subhash Engn Coll, Dept Comp Sci & Engn, Kolkata, India.
C3 University of Calcutta; Netaji Subhash Engineering College Kolkata
RP Ghosh, SK (corresponding author), Sister Nivedita Univ, Dept Comp Sci & Engn, Kolkata, India.
EM biswajit.cu.08@gmail.com; swarupg1@gmail.com;
   anupam.ghosh@rediffmail.com
OI Ghosh, Dr. Swarup Kr/0000-0002-9312-4189; Ghosh,
   Anupam/0000-0003-2166-3957
CR Aggarwal J K., 1993, Multisensor Fusion for Computer Vision
   Atanassov K., 1999, STUDIES FUZZINESS SO, V1999, DOI 10.1007/978-3-7908-1870-3
   Balasubramaniam P, 2014, INFORM FUSION, V20, P21, DOI 10.1016/j.inffus.2013.10.011
   Barney B., 2010, Introduction to Parallel Computing
   Bova SW, 2001, COMPUT SCI ENG, V3, P22, DOI 10.1109/5992.947105
   Burillo P, 1996, ENTROPY INTUITIONIST, P3
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chaira T, 2012, APPL SOFT COMPUT, V12, P1259, DOI 10.1016/j.asoc.2011.12.011
   Chaira T, 2011, APPL SOFT COMPUT, V11, P1711, DOI 10.1016/j.asoc.2010.05.005
   Chao Z, 2018, PHYS MEDICA, V48, P11, DOI 10.1016/j.ejmp.2018.03.008
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   David, 2000, C TEMPLATE IMAGE PRO
   Dubois D, 1980, Fuzzy sets and systems
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Gropp W., 1999, Using MPI-2: Advanced Features of the Message Passing Interface, Vsecond
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   Jiang Q, 2018, IEEE SENS J, V18, P2494, DOI 10.1109/JSEN.2018.2791642
   Kirk D., 2010, PROGRAMMING MASSIVEL, P900
   Kong WW, 2015, INFRARED PHYS TECHN, V71, P87, DOI 10.1016/j.infrared.2015.02.008
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Manchanda M, 2018, J VIS COMMUN IMAGE R, V51, P76, DOI 10.1016/j.jvcir.2017.12.011
   MPICH, 2016, MESSAGE PASSING INTE
   Pal S., 1989, IEEE T SYST MAN CYB, V11, P501
   Peters JF, 2009, INFORM SCIENCES, V179, P3091, DOI 10.1016/j.ins.2009.04.018
   Quinn M.J., 2003, Parallel Programming in C with MPI and OpenMP
   Rahman MA, 2017, DIGIT SIGNAL PROCESS, V60, P1, DOI 10.1016/j.dsp.2016.08.004
   SIEGEL LJ, 1982, IEEE T COMPUT, V31, P208, DOI 10.1109/TC.1982.1675976
   Szmidt E, 2000, FUZZY SET SYST, V114, P505, DOI 10.1016/S0165-0114(98)00244-9
   Tuncer, 2007, LNCSE, V67, P401
   YAGER RR, 1980, INFORM CONTROL, V44, P236, DOI 10.1016/S0019-9958(80)90156-4
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   [支晓斌 ZHI Xiaobin], 2008, [模糊系统与数学, Fuzzy Systems and Mathematics], V22, P96
NR 34
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29699
EP 29730
DI 10.1007/s11042-022-12333-0
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500013
DA 2024-07-18
ER

PT J
AU Deng, WW
   Xiang, T
   Liao, XF
AF Deng, Weiwei
   Xiang, Tao
   Liao, Xiaofeng
TI STEAC: Towards secure, traceable, and efficient cryptographic access
   control scheme in smart healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart healthcare; Access control; CP-ABE; Multimedia Security;
   Blockchain
ID ATTRIBUTE-BASED ENCRYPTION; PARADIGM
AB Smart Healthcare (SHC) plays an increasingly greater role in improving the quality of health care, which has been widely concerned by researchers, hospitals and governments. In SHC, it is crucial that a patient's health data is readily accessible to authorized nurses, doctors, and emergency services. To realize the easy access while protecting the privacy of patients' data, ciphertext-policy attribute-based encryption (CP-ABE) has been widely used to achieve secure data sharing and support fine-grained access control. However, the existing CP-ABE schemes have three flaws for SHC. First, CP-ABE with partially hidden of access policies may also leak user's attribute privacy. Second, malicious user may disclose patient's health records and these records can not be traced. Third, it is less efficient that the data user, who does not have right to access data, downloads the whole ciphertext. In this paper, we design STEAC to address the above problems. To solve the first problem, we introduce the garbled Bloom filter method to realize fully hidden of access policies. For solving the second problem, we use the transaction-based blockchain scheme to trace the ciphertext storage and access. And before the real decryption, a decryption test operation is added to overcome the third flaw. Finally, security analysis and comprehensive performance evaluation also demonstrate STEAC is secure in standard model and is also more efficient than the previous schemes.
C1 [Deng, Weiwei; Xiang, Tao; Liao, Xiaofeng] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 100044, Peoples R China.
   [Deng, Weiwei; Xiang, Tao; Liao, Xiaofeng] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University; Chongqing University
RP Xiang, T (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 100044, Peoples R China.; Xiang, T (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM dwwdyxiang@126.com; txiang@cqu.edu.cn; xfliao@cqu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023; Xiang, Tao/N-3706-2016
OI Xiang, Tao/0000-0002-9439-4623; Xiang, Tao/0000-0002-0022-3082
FU National Key R&D Program of China [2018AAA0100101]; National Natural
   Science Foundation of China [61932006, U20A20176]; Chongqing Technology
   Innovation and Application Development Project [cstc2020jscx-msxm1841]
FX This work is supported by National Key R&D Program of China (No.
   2018AAA0100101), National Natural Science Foundation of China (Nos.
   61932006, U20A20176), and Chongqing Technology Innovation and
   Application Development Project (No. cstc2020jscx-msxm1841).
CR Avdoshin S, 2018, P FUT TECHN C
   Baker SB, 2017, IEEE ACCESS, V5, P26521, DOI 10.1109/ACCESS.2017.2775180
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Cao Z., 2010, IACR CRYPTOLOGY EPRI, V2010, P374
   Cha JC, 2003, LECT NOTES COMPUT SC, V2567, P18
   Chang SH, 2016, IT PROF, V18, P14, DOI 10.1109/MITP.2016.48
   Cheung L, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P456
   De Caro A, 2011, IEEE SYMP COMP COMMU
   Dong C., 2013, P 2013 ACM SIGSAC C, P789
   Dorri Ali, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P618, DOI 10.1109/PERCOMW.2017.7917634
   Fan YJ, 2014, IEEE T IND INFORM, V10, P1568, DOI 10.1109/TII.2014.2302583
   Gao S, 2020, IEEE T VEH TECHNOL, V69, P5784, DOI 10.1109/TVT.2020.2967099
   Gramoli V, 2020, FUTURE GENER COMP SY, V107, P760, DOI 10.1016/j.future.2017.09.023
   Hathaliya JJ, 2020, COMPUT COMMUN, V153, P311, DOI 10.1016/j.comcom.2020.02.018
   Karunarathne SM, 2021, IEEE INTERNET COMPUT, V25, P37, DOI 10.1109/MIC.2021.3051675
   Kwon H, 2017, MULTIMED TOOLS APPL, V76, P19507, DOI 10.1007/s11042-015-3187-z
   Lai J., 2012, P 7 ACM S INF COMP C, P18, DOI [10.1145/2414456.2414465, DOI 10.1145/2414456.2414465]
   Lai JZ, 2011, LECT NOTES COMPUT SC, V6672, P24, DOI 10.1007/978-3-642-21031-0_3
   Li J, 2018, COMPUT SECUR, V72, P1, DOI 10.1016/j.cose.2017.08.007
   Li Q, 2020, HTAC FINE GRAINED PO, V8
   Li RN, 2019, IEEE T SERV COMPUT, V12, P762, DOI 10.1109/TSC.2018.2853167
   Liu X, 2019, MULTIMED TOOLS APPL
   Majumder S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010130
   Mubarakali A, 2020, MULTIMED TOOLS APPL, V79, P3943, DOI 10.1007/s11042-019-7494-7
   Nishide T, 2008, LECT NOTES COMPUT SC, V5037, P111, DOI 10.1007/978-3-540-68914-0_7
   Phuong TVX, 2016, IEEE T INF FOREN SEC, V11, P35, DOI 10.1109/TIFS.2015.2475723
   Pramanik MI, 2017, EXPERT SYST APPL, V87, P370, DOI 10.1016/j.eswa.2017.06.027
   Qi L., 2018, WIREL COMMUN MOB COM, V2018, P1
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Solanas A, 2014, IEEE COMMUN MAG, V52, P74, DOI 10.1109/MCOM.2014.6871673
   Sun JF, 2020, IEEE INTERNET THINGS, V7, P6566, DOI 10.1109/JIOT.2020.2974257
   Waters B, 2011, LECT NOTES COMPUT SC, V6571, P53, DOI 10.1007/978-3-642-19379-8_4
   Xu BY, 2017, ENTERP INF SYST-UK, V11, P17, DOI 10.1080/17517575.2015.1053416
   Yang K, 2017, IEEE INTERNET THINGS, V4, P563, DOI 10.1109/JIOT.2016.2571718
   Zhang YH, 2018, IEEE INTERNET THINGS, V5, P2130, DOI 10.1109/JIOT.2018.2825289
   Zhang YH, 2017, INFORM SCIENCES, V379, P42, DOI 10.1016/j.ins.2016.04.015
   Zhang Yinghui., 2013, ASIACCS, P511, DOI [10.1145/2484313.2484381, DOI 10.1145/2484313.2484381]
NR 39
TC 4
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30069
EP 30092
DI 10.1007/s11042-022-12805-3
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500018
DA 2024-07-18
ER

PT J
AU Li, N
   Li, LQ
   Jiao, JC
   Xu, W
   Qi, WJ
   Yan, XH
AF Li, Ning
   Li, Liqun
   Jiao, Jichao
   Xu, Wei
   Qi, Wangjing
   Yan, Xiaohu
TI Research status and development trend of image camouflage effect
   evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camouflage effect evaluation; Subjective assessment; Linear weighted
   model; Neural network; Visual attention mechanism
ID NEURAL-NETWORK; FEATURES; DESIGN; COLOR
AB In today's military operations, camouflage generally uses feature reduction techniques such as camouflage net, low emission coating and camouflage pattern to minimize its detectability and optimize the survivability of high-value assets. However, there is no internationally recognized standard method and procedure to evaluate camouflage equipment and techniques. This paper briefly introduces the existing subjective evaluation methods such as professional evaluation, image-based interpretation, discovery probability equation, and objective evaluation methods such as linear weighted model, neural network model, human visual attention mechanism and multi-attribute decision-making. The application scenarios, advantages and disadvantages of each method are analyzed, and the future development trend of camouflage evaluation model in deep learning, dynamic target camouflage evaluation and hyperspectral field is pointed out.
C1 [Li, Ning; Li, Liqun; Jiao, Jichao; Qi, Wangjing; Yan, Xiaohu] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
   [Xu, Wei] China Elect Technol Grp Corp, Res Inst 22, Qingdao, Peoples R China.
C3 Beijing University of Posts & Telecommunications; China Electronics
   Technology Group
RP Li, LQ (corresponding author), Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
EM lnmmdsy@sina.com; liqun_li@bupt.edu.cn; jiaojichao@gmail.com;
   xuw@crirp.ac.cn; 905474813@qq.com; 2317631813@qq.com
RI Qi, Wang/GZM-0551-2022; 棋, 王/JUV-2984-2023; wang, qi/HGV-1859-2022;
   wang, qi/HTN-8786-2023
OI Li, Liqun/0000-0003-3666-7918
CR Atanassov K., 2016, INT J BIOAUTOM, V20
   Augustyn Jason S., 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P2028, DOI 10.1518/107118108X353192
   Brunyé TT, 2017, APPL ERGON, V62, P259, DOI 10.1016/j.apergo.2017.03.010
   Chen Q, 2010, INFORMATION-TOKYO, V13, P67
   Cheng XP, 2018, INFRARED PHYS TECHN, V95, P213, DOI 10.1016/j.infrared.2018.11.001
   Cheng XP, 2018, PROC SPIE, V10964, DOI 10.1117/12.2506095
   Cui, 2010, INFRARED LASER ENG, V39, P1179
   Dehui, 2018, J PHYS C SERIES, V1060
   Dubois D., 2005, P 4 C EUR SOC FUZZ L, P314
   Dunau P, 2015, PROC SPIE, V9653, DOI 10.1117/12.2194088
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fang Hao, 2019, LASER OPTOELECTRON P, V56
   Gan Y, 2020, IEEE ACCESS, V8
   [甘源滢 Gan Yuanying], 2019, [应用光学, Journal of Applied Optics], V40, P1050
   Gretzmacher FM, 1998, P SOC PHOTO-OPT INS, V3375, P58, DOI 10.1117/12.327177
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hogervorst MA, 2010, P SOC PHOTO-OPT INS, V7662, DOI 10.1117/12.850423
   Hou C.X., 2019, SEC S NOV TECHNO XRA, V11068, p1L
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hu Jianghua, 2007, CHINA TEST TECHNOL, P67
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia, 2011, J APPL SCI, P294
   Jia Q, 2020, MULTIMED TOOLS APPL, V79, P22047, DOI 10.1007/s11042-020-09002-5
   Jiao, 2016, RES CAMOUFLAGE EVALU
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Jun Yu, 2020, 2020 International Conference on Computer Network, Electronic and Automation (ICCNEA), P111, DOI 10.1109/ICCNEA50255.2020.00032
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li, 2019, LASER INFRARED, P761
   Liao HC, 2014, INT J INF TECH DECIS, V13, P47, DOI 10.1142/S0219622014500035
   Lin CJ, 2014, IMAGING SCI J, V62, P337, DOI 10.1179/1743131X13Y.0000000057
   Lin CJ, 2019, COLOR RES APPL, V44, P740, DOI 10.1002/col.22404
   Lv, 2019, 2019 2 INT C INF SYS, P471
   Mondal A, 2017, INT J COMPUT VISION, V122, P116, DOI 10.1007/s11263-016-0959-5
   Nyberg S, 2001, OPT ENG, V40, P1869, DOI 10.1117/1.1390295
   Prasetyo YT, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON INDUSTRIAL AND BUSINESS ENGINEERING (ICIBE 2019), P321, DOI 10.1145/3364335.3364399
   Prasetyo YT, 2020, P 2020 2 INT C MAN S
   Pu, 2017, CHIN SOC OPT ENG C H, V10255
   Qi J, 2011, 2011 INT C E BUS E G, P1
   Qin JF, 2016, MATEC WEB CONF, V61, DOI 10.1051/matecconf/20166106013
   Racek, 2018, TARGET BACKGROUND SI, V10794
   Ramsey, 2018, ALGORITHMS TECHNOLOG, V10644
   Ronconi P., 2007, GUIDELINES CAMOUFLAG
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Selj, 2015, TARGET BACKGROUND SI, V9653
   Shi, 2015, SCI IND, V000, P94
   Skurowski P, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P244, DOI 10.1109/IPAS.2018.8708858
   Toet, 2020, INT SOC OPTICS PHOTO, V11536
   TRAVEN HGC, 1991, IEEE T NEURAL NETWOR, V2, P366, DOI 10.1109/72.97913
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Volonakis TN, 2018, COMPUT IND, V99, P173, DOI 10.1016/j.compind.2018.03.013
   Wang, 2020, 2020 IEEE INT C INF, V1, P1393
   Wang, 2015, APPL HYPERSPECTRAL I
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   Wang X, 2018, A target camouflage effect evaluation method and system based on artificial interpretation, Patent No. [cn108647365a [P], 108647365]
   Wang Z., 2014, Research on Background Based Camouflage Design and Comprehensive Evaluation Method
   [王展 Wang Zhan], 2013, [兵工学报, Acta Armamentarii], V34, P1250
   Xue, 2005, OPT TECHNOL, P449
   Xue F, 2018, NEUROCOMPUTING, V274, P106, DOI 10.1016/j.neucom.2016.07.081
   Xue F, 2016, MULTIMED TOOLS APPL, V75, P4065, DOI 10.1007/s11042-015-2946-1
   Xue F, 2015, MULTIMEDIA SYST, V21, P169, DOI 10.1007/s00530-014-0368-y
   Yang, 2020, DEF TECHNOL
   Yu, 2009, SHIP ELECT COUNTERME, P55
   Zavvartorbati A, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.045008
   Zhang, 2014, PREDICTIVE CODING CO, DOI 10.1007/978-3-642-37835-5_2
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao X., 2019, Infrared and Laser Engineering, V48, P116
NR 67
TC 4
Z9 4
U1 5
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29939
EP 29953
DI 10.1007/s11042-022-12287-3
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500010
DA 2024-07-18
ER

PT J
AU Liang, D
   Geng, QX
   Sun, H
   Zhou, HY
   Kaneko, S
AF Liang, Dong
   Geng, Qixiang
   Sun, Han
   Zhou, Huiyu
   Kaneko, Shun'ichi
TI Inferred box harmonization and aggregation for degraded face detection
   in crowds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Degraded face; Video surveillance
ID OBJECT DETECTION; CONTEXT
AB Since objects usually keep a certain distance from the surveillance camera, small object detection is a practical issue. Detecting small objects is also one of the remaining challenges in the computer vision community. The current detectors usually leverage a more robust backbone network, build one or more multi-scale feature pyramids, or define a more precise anchor-box screening criteria. However, the distinguishable features are scarce due to the appearance degradation and a shallow resolution. In this paper, we leverage high-level context to enhance anchor-based detectors' capabilities for small and crowded face detection. We first define face co-occurrence prior based on density maps (FCP-DM) to explore extensive high-level contextual information. We propose a score-size-specific non-maximum suppression ((SNMS)-N-3) to replace the traditional non-maximum suppression at the end of anchor-based detectors. Our approach is plug and play and model-independent, which could be concatenated into the existing anchor-based face detectors without extra learning. Compared to the prior art on the WIDER FACE hard set, our method increases an Average Precision of 0.1%-1.3%, while on Crowd Face, which we make for testing small and crowded face detection, it raises an Average Precision of 1% - 6%. Codes and dataset have been available online.
C1 [Liang, Dong; Geng, Qixiang; Sun, Han] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Zhou, Huiyu] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
   [Kaneko, Shun'ichi] Metatec Cooperat, Yokohama, Kanagawa 2200004, Japan.
C3 Nanjing University of Aeronautics & Astronautics; University of
   Leicester
RP Liang, D (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM liangdong@nuaa.edu.cn
RI Liang, Dong/AAO-7160-2020; Zhou, Huiyu/O-2692-2014
OI Liang, Dong/0000-0003-2784-3449; Zhou, Huiyu/0000-0003-1634-9840
CR [Anonymous], 2018, CHINESE C BIOMETRIC
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Hosang J, 2016, LECT NOTES COMPUT SC, V9796, P192, DOI 10.1007/978-3-319-45886-1_16
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   ROSENFELD A, 1971, IEEE T COMPUT, VC 20, P562, DOI 10.1109/T-C.1971.223290
   Rothe R, 2015, LECT NOTES COMPUT SC, V9003, P290, DOI 10.1007/978-3-319-16865-4_19
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Stewart R, 2016, PROC CVPR IEEE, P2325, DOI 10.1109/CVPR.2016.255
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719
   Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0
   Wu TP, 2019, IEEE IMAGE PROC, P3297, DOI [10.1109/ICIP.2019.8803548, 10.1109/icip.2019.8803548]
   Xiang W, 2018, IEEE WINT CONF APPL, P1784, DOI 10.1109/WACV.2018.00198
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang T., 2018, Advances in Neural Information Processing Systems
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
   Zhu Y, 2020, TINAFACE STRONG UT S
NR 35
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35411
EP 35430
DI 10.1007/s11042-022-12319-y
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000777241700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Triki, A
   Bouaziz, B
   Mahdi, W
   Hamed, H
   Gaikwad, J
AF Triki, Abdelaziz
   Bouaziz, Bassem
   Mahdi, Walid
   Hamed, Hamdi
   Gaikwad, Jitendra
TI Deep learning based approach for digitized herbarium specimen
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Digitized herbarium specimen image; Specimen image
   semantic segmentation; Coarse segmentation
ID IMAGES
AB As herbarium specimens are largely digitized and freely available in online portals, botanists aim to examine their taxonomic aspects to identify the plant specimen regions and generate their morphological data. Nevertheless, different uninformative visual information within the digitized herbarium specimen, such as scale-bar, color pallet, specimen label, envelopes, bar-code, and stamp, represent a source of visual noise. Thus, their identification requires unique detection methods as they are mostly placed at different locations and orientations within the herbarium sheet. Given a collection of digitized herbarium specimen images gathered from the Herbarium Haussknecht of Jena, Germany, we present in this paper a deep learning-based approach for specimen image semantic segmentation. Two different pipelines were involved in this work: (i) coarse segmentation and (ii) fine segmentation. Throughout the whole process, we describe the ground truth annotation used for training our deep learning architecture. The experimental results demonstrate that our proposed model outperforms the other architectures such as SegNet, Squeeze-SegNet, U-Net, and DeepLabv3. Its accuracy achieves 91% compared to 82%, 80%, 86%, and 90% obtained by SegNet, Squeeze-SegNet, U-Net, and DeepLabv3, respectively.
C1 [Triki, Abdelaziz; Bouaziz, Bassem; Mahdi, Walid] Univ Sfax, MIRACL Lab Sfax, Sfax, Tunisia.
   [Hamed, Hamdi; Gaikwad, Jitendra] Friedrich Schiller Univ, Jena, Germany.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Friedrich Schiller University of Jena
RP Triki, A (corresponding author), Univ Sfax, MIRACL Lab Sfax, Sfax, Tunisia.
EM abdelaziz.triki@yahoo.fr
RI BOUAZIZ, Bassem/J-4608-2016; MAHDI, Walid/HOF-7688-2023
OI BOUAZIZ, Bassem/0000-0002-3692-9482; MAHDI, Walid/0000-0003-3465-0397;
   Triki, Abdelaziz/0000-0001-5818-2941
FU German ministry of education and research (BMBF); Tunisian ministry of
   higher education and research (MESR)
FX Supported by the German ministry of education and research (BMBF) and
   Tunisian ministry of higher education and research (MESR).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Beghin T., 2010, ADV CONCEPTS INTELLI, V6475, DOI [10.1007/9783-642-17691-3-32, DOI 10.1007/9783-642-17691-3-32]
   Borges LM, 2020, METHODS ECOL EVOL, V11, P1296, DOI 10.1111/2041-210X.13450
   Borsch T., 2020, Res Ideas Outcomes, V6, pe50675, DOI [10.3897/rio.6.e50675, DOI 10.3897/RIO.6.E50675]
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Cerutti G, 2013, COMPUT VIS IMAGE UND, V117, P1482, DOI 10.1016/j.cviu.2013.07.003
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Figueira R, 2019, BIODIVERSITY OF ANGOLA: SCIENCE & CONSERVATION: A MODERN SYNTHESIS, P513, DOI 10.1007/978-3-030-03083-4_19
   Jiang XQ, 2012, MEAS SCI TECHNOL, V23, DOI 10.1088/0957-0233/23/1/015003
   Kommineni V.K., 2020, BIODIVERS INF SCI ST, V4, DOI DOI 10.3897/BISS.4.59061
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lee JW, 2019, 2019 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P17
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   McAllister CA, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2017.0403
   Nanfack G, 2018, PROC SPIE, V10696, DOI 10.1117/12.2309497
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Olsen A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-38343-3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P1028, DOI 10.1109/ICACEA.2015.7164858
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Valliammal N, 2012, PLANT LEAF SEGMENTAT
   Vukadinovic D, 2015, WATERSHED SUPERVISED
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Weaver WN, 2020, APPL PLANT SCI, V8, DOI 10.1002/aps3.11367
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113
   Yu F., 2015, ARXIV
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
NR 31
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28689
EP 28707
DI 10.1007/s11042-022-12935-8
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900015
DA 2024-07-18
ER

PT J
AU Al Shalchi, NFA
   Rahebi, J
AF Al Shalchi, Nassrallah Faris Abdukader
   Rahebi, Javad
TI Human retinal optic disc detection with grasshopper optimization
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grasshopper optimization algorithm; Optic disc detection; Retinal images
ID BLOOD-VESSELS; SEGMENTATION; IMAGES
AB A growing number of qualified ophthalmologists are promoting the need to use computer-based retinal eye processing image recognition technologies. There are different methods and algorithms in retinal images for detecting optic discs. Much attention has been paid in recent years using intelligent algorithms. In this paper, in the human retinal images, we used the Grasshopper optimization algorithm to implement a new automated method for detecting an optic disc. The clever algorithm is influenced by the social nature of the grasshopper, the intelligent Grasshopper algorithm. Include this algorithm; the population contains the grasshoppers, each of which has a common luminance or exercise score. In this method, two-by-two insects are compared, so it could be shown that less attractive insects shift towards more attractive insects. Finally, one of the most attractive insects is selected, and this insect gives an optimum solution to the problem. Here, we used the light intensity of the retinal pixels instead of grasshopper illuminations. According to local variations, the effect of these insects also indicates different light intensity values in images. Since the brightest area "represents the optic disc in retinal images, all insects travel to the brightest area, which leads to the determined position for an optic disc in the image. The performance was evaluated on 210 images, reflecting three Open to the public and sequentially distributed datasets DIARETDB1 89 images, STARE 81 images, and DRIVE 40 images. The results of the proposed algorithm implementation give a 99.51% accuracy rate in the DiaRetDB1 dataset, 99.67% in the STARE dataset, and 99.62% in the DRIVE dataset. The results of the implementation show the strong capacity and accuracy of the proposed algorithm for detecting the optic disc from retinal images. Also, the recorded time required for (OD) detection in these images is180.14 s for the DiaRetDB1, 65.13s for STARE, and 80.64s for DRIVE, respectively. These are average values for the times.
C1 [Al Shalchi, Nassrallah Faris Abdukader] Altinbas Univ, Elect & Comp Engn Dept, Istanbul, Turkey.
   [Rahebi, Javad] Istanbul Topkapi Univ, Software Engn Dept, Istanbul, Turkey.
C3 Altinbas University; Istanbul Topkapi University
RP Al Shalchi, NFA (corresponding author), Altinbas Univ, Elect & Comp Engn Dept, Istanbul, Turkey.
EM nassrallah2018@gmail.com; cevatrahebi@topkapi.edu.tr
CR Abdullah AS, 2020, MED BIOL ENG COMPUT, V58, P25, DOI 10.1007/s11517-019-02032-8
   Abdullah AS, 2018, MED BIOL ENG COMPUT, V56, P2015, DOI 10.1007/s11517-018-1840-1
   Abdullah M, 2016, PEERJ, V2016, P1
   Abed S, 2019, J ENG RES-KUWAIT, V7, P161
   Bharkad S, 2017, BIOMED SIGNAL PROCES, V31, P483, DOI 10.1016/j.bspc.2016.09.009
   Bin Gui, 2018, Procedia Computer Science, V131, P311, DOI 10.1016/j.procs.2018.04.169
   Albargathe SMBK, 2021, MULTIMED TOOLS APPL, V80, P2565, DOI 10.1007/s11042-020-09646-3
   Dietter J, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.04.012
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Lalonde M, 2001, IEEE T MED IMAGING, V20, P1193, DOI 10.1109/42.963823
   Lupascu CA, 2008, COMP MED SY, P17, DOI 10.1109/CBMS.2008.15
   Martinez M., 2019, PAPEL CEIC, V2019, P1, DOI [10.1387/pceic.20616, DOI 10.1387/PCEIC.20616]
   Patton N, 2006, PROG RETIN EYE RES, V25, P99, DOI 10.1016/j.preteyeres.2005.07.001
   Rahebi J, 2016, MED BIOL ENG COMPUT, V54, P453, DOI 10.1007/s11517-015-1330-7
   Reza MN, 2018, BIOMED SIGNAL PROCES, V45, P274, DOI 10.1016/j.bspc.2018.05.027
   Roychowdhury S, 2016, IEEE J BIOMED HEALTH, V20, P1562, DOI 10.1109/JBHI.2015.2473159
   Salazar-Gonzalez A, 2014, IEEE J BIOMED HEALTH, V18, P1874, DOI 10.1109/JBHI.2014.2302749
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shaikha Hawkar Kheder, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P23, DOI 10.1109/ICOASE.2019.8723835
   Siddalingaswamy PC, 2011, THESIS MIT MANIPAL
   Sinthanayothin C, 1999, BRIT J OPHTHALMOL, V83, P902, DOI 10.1136/bjo.83.8.902
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tobin KW, 2007, IEEE T MED IMAGING, V26, P1729, DOI 10.1109/TMI.2007.902801
   Welfer D, 2013, PATTERN RECOGN LETT, V34, P476, DOI 10.1016/j.patrec.2012.12.011
   Welfer D, 2010, COMPUT BIOL MED, V40, P124, DOI 10.1016/j.compbiomed.2009.11.009
NR 26
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24937
EP 24955
DI 10.1007/s11042-022-12838-8
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771379200001
DA 2024-07-18
ER

PT J
AU Jiang, LW
   Quan, HY
   Xie, T
   Qian, JB
AF Jiang, Liangwei
   Quan, Haiyan
   Xie, Tao
   Qian, Junbing
TI Fish recognition in complex underwater scenes based on targeted sample
   transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fish classification; Complex underwater environment; Convolution neural
   network; Transfer learning; Pre-training model
AB Fish population survey based on classification and recognition is an effective means to study water ecosystem. However, the identification of fish in the sea and other waters will be interfered by corals, reefs and other organisms. The great variety of fish also make it more difficult to distinguish. In order to improve the effect of fish recognition in the complex underwater environment, this paper proposes a method based on targeted sample transfer learning. The designed CNN is used to train the simple background fish data after background re-processing to obtain the pre-training model. By using transfer learning and interlayer fusion mechanism, the feature extraction layer of the pre-training model is frozen and fused with the new feature extraction layer in parallel, then, combined with pooling layer, a new feature extractor is formed, finally, connected to the classifier and output part to construct a new network, which is used to identify 10 kinds of fish with complex background. Compared with the original CNN model, the accuracy of the new network is improved by about 5%, reaching 91.33%. The experimental results show that the model can improve the ability of fish classification and recognition in complex underwater scenes, and can provide support for the study of fishery resources distribution.
C1 [Jiang, Liangwei; Quan, Haiyan] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming, Yunnan, Peoples R China.
   [Xie, Tao; Qian, Junbing] Kunming Univ Sci & Technol, Fac Civil Aviat & Aeronaut, Kunming, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology
RP Qian, JB (corresponding author), Kunming Univ Sci & Technol, Fac Civil Aviat & Aeronaut, Kunming, Yunnan, Peoples R China.
EM 1226160701@qq.com
CR Ainapure A, 2020, PROCEDIA MANUF, V48, P1088, DOI 10.1016/j.promfg.2020.05.149
   Albahli S, 2020, J X-RAY SCI TECHNOL, V28, P841, DOI 10.3233/XST-200720
   Arthington AH, 2016, AQUAT CONSERV, V26, P838, DOI 10.1002/aqc.2712
   Azamfar M, 2020, MECH MACH THEORY, V151, DOI 10.1016/j.mechmachtheory.2020.103932
   Boom BJ, 2012, INT C PATT RECOG, P1542
   Chan A, 2019, IEEE UNDERWATER TECH, DOI 10.1109/ut.2019.8734464
   Chan A, 2017, IEEE UNDERWATER TECH
   Chen, 2019, J FUQING BRANCH FUJI
   Dai YL, 2018, J INTELL FUZZY SYST, V34, P1631, DOI 10.3233/JIFS-169457
   French B, 2021, ECOL INDIC, V124, DOI 10.1016/j.ecolind.2021.107415
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Hodgson G, 2001, B MAR SCI, V69, P861
   Huang YK, 2020, J INTELL FUZZY SYST, V39, P7403, DOI 10.3233/JIFS-200771
   LI J, J INTELL FUZZY SYST, P1
   Li JM, 2020, INTELL DATA ANAL, V24, P363, DOI 10.3233/IDA-194487
   Macias-Garcia E, 2021, INTEGR COMPUT-AID E, V28, P191, DOI 10.3233/ICA-200640
   Maruyama T, 2018, J X-RAY SCI TECHNOL, V26, P885, DOI 10.3233/XST-18386
   Masoudi B, 2021, INTELL DATA ANAL, V25, P527, DOI 10.3233/IDA-205113
   Pundhir S, 2020, J INTELL FUZZY SYST, V39, P665, DOI 10.3233/JIFS-191618
   Qin HW, 2016, NEUROCOMPUTING, V187, P49, DOI 10.1016/j.neucom.2015.10.122
   Qiu CC, 2018, 2018 OCEANS - MTS/IEEE KOBE TECHNO-OCEANS (OTO)
   Salman A, 2016, LIMNOL OCEANOGR-METH, V14, P570, DOI 10.1002/lom3.10113
   Wang LF, 2018, FISH OCEANOGR, V27, P571, DOI 10.1111/fog.12279
   XI Q, 2019, MEASUREMENT
   Yang F, 2019, J X-RAY SCI TECHNOL, V27, P1033, DOI 10.3233/XST-190570
   Yousaf W, 2021, J INTELL FUZZY SYST, V40, P3849, DOI 10.3233/JIFS-190660
   Zeiler M. D., 2012, CoRR
   Zheng Z, 2021, MEASUREMENT, V177, DOI 10.1016/j.measurement.2021.109285
NR 28
TC 3
Z9 3
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25303
EP 25317
DI 10.1007/s11042-022-12525-8
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300012
DA 2024-07-18
ER

PT J
AU Rajak, S
   Bose, D
   Saha, A
   Chowdhury, C
AF Rajak, Sajan
   Bose, Debasish
   Saha, Anindita
   Chowdhury, Chandreyee
TI A human activity recognition framework for grossly labeled smartphone
   sensing data through combining genetic algorithm with multiple instance
   multiple label learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Feature selection; MIML; Smartphone; Genetic
   algorithm; Activity sequence
ID FEATURE-SELECTION; SYSTEM
AB Human Activity Recognition through smartphones plays a crucial role in several medical state-of-affairs like patient monitoring, eldercare, and post-surgery recovery. Most of these works require precisely labeled accelerometer data for training supervised learning classifiers. Precise labeling of smartphone sensing data is difficult in real life due to the non-uniform gait of individual users with unpredictable activity transitions in between. Selecting an optimal number of features for the classification of such grossly labeled smartphone accelerometer instances is hardly investigated in the literature. Hence, a semi-supervised learning approach, that combines Multi-Instance Multi-label (MIML) learning with a Genetic Algorithm (GA) is proposed here. Rather than labeling a single instance, activity bags are designed for classification. GA selects the optimal sets of features for such grossly labeled bags of featured instances. MIML-kNN is chosen to be the classifier that is integrated with GA to predict the single, double or triple activity combinations that are often performed in daily life. Interestingly, the proposed framework can also predict component activities from an unknown activity combination even when it is not trained with such combinations. The framework is implemented for a real dataset collected from 8 users and it is found to be working adequately with less than half the set of features giving an average precision of 94% for even triple and double activity combinations.
C1 [Rajak, Sajan; Bose, Debasish; Chowdhury, Chandreyee] Jadavpur Univ, Dept CSE, Kolkata, India.
   [Saha, Anindita] Techno Main SaltLake, Kolkata, India.
C3 Jadavpur University
RP Chowdhury, C (corresponding author), Jadavpur Univ, Dept CSE, Kolkata, India.
EM chandreyee.chowdhury@gmail.com
RI SAHA, ANINDITA/IUN-2218-2023
CR Baldominos A, 2017, IEEE C EVOL COMPUTAT, P2185, DOI 10.1109/CEC.2017.7969569
   Batool M., 2019, 2019 International Conference on Applied and Engineering Mathematics, P145, DOI DOI 10.1109/ICAEM.2019.8853770
   Bouaguel W, 2016, PROC ADAPT LEARN OPT, V5, P75, DOI 10.1007/978-3-319-27000-5_6
   Chen JC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030692
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   CHOWDHARY CL, 2013, WORLD APPL SCI J, V26, P45, DOI DOI 10.5829/idosi.wasj.2013.26.01.283
   Dernbach S., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P214, DOI 10.1109/IE.2012.39
   El-Maaty AMA, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1027, DOI 10.1109/SSCI.2018.8628702
   Fang HQ, 2014, ISA T, V53, P1629, DOI 10.1016/j.isatra.2014.06.008
   Gashi S., 2021, HUMAN ACTIVITY RECOG, P75
   Guan XZ, 2016, PR MACH LEARN RES, V48
   Gupta P, 2014, IEEE T BIO-MED ENG, V61, P1780, DOI 10.1109/TBME.2014.2307069
   Hu Y, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720971513
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Li JH, 2019, C IND ELECT APPL, P2356, DOI [10.1109/iciea.2019.8834380, 10.1109/ICIEA.2019.8834380]
   Lu ZC, 2017, LECT NOTES COMPUT SC, V10637, P21, DOI 10.1007/978-3-319-70093-9_3
   Mohamed R, 2018, J INF COMMUN TECHNOL, V17, P209
   Nguyen TDT, 2018, INT CONF KNOWL SYS, P123, DOI 10.1109/KSE.2018.8573335
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Peng LY, 2017, IEEE T BIO-MED ENG, V64, P1369, DOI 10.1109/TBME.2016.2604856
   Jesse R, 2017, PATTERN RECOGN, V63, P45, DOI 10.1016/j.patcog.2016.09.015
   Saha J, 2021, WIRELESS PERS COMMUN, V117, P923, DOI 10.1007/s11277-020-07903-0
   Saha J, 2021, MULTIMED TOOLS APPL, V80, P9895, DOI 10.1007/s11042-020-10046-w
   Saha J, 2018, INFORMATION, V9, DOI 10.3390/info9040094
   Saputri TRD, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/706287
   Savvaki S, 2017, IEEE J BIOMED HEALTH, V21, P1554, DOI 10.1109/JBHI.2017.2716112
   Shoaib M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040426
   Stikic M, 2009, IEEE INT SYM WRBL CO, P85, DOI 10.1109/ISWC.2009.24
   Stikic M, 2009, LECT NOTES COMPUT SC, V5561, P156, DOI 10.1007/978-3-642-01721-6_10
   Toda T, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P863, DOI 10.1145/2638728.2641297
   Vaizman Y., 2017, PROC ACM INTERACT MO, V1, P1, DOI 10.1145/3161192
   Vecchio A, 2017, IEEE SENSOR LETT, V1, DOI 10.1109/LSENS.2017.2726759
   Wang HJ, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718772785
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   Wannenburg J, 2017, IEEE T SYST MAN CY-S, V47, P3142, DOI 10.1109/TSMC.2016.2562509
   Woznowski PR, 2016, IOTBD: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND BIG DATA, P369, DOI 10.5220/0005932503690377
   Zainudin MNS, 2017, PROC INT CONF COMP, P669
   Zhang M, 2013, IEEE J BIOMED HEALTH, V17, P553, DOI 10.1109/JBHI.2013.2253613
   Zhang ML, 2010, PROC INT C TOOLS ART, P207, DOI 10.1109/ICTAI.2010.102
   Zolfaghari S, 2016, ACSIS-ANN COMPUT SCI, V8, P1435, DOI 10.15439/2016F132
NR 44
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24887
EP 24911
DI 10.1007/s11042-022-12261-z
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300001
DA 2024-07-18
ER

PT J
AU Li, Z
   Shao, HY
   Niu, L
   Xue, NA
AF Li, Zhen
   Shao, Hanyang
   Niu, Liang
   Xue, Nian
TI PLA: progressive learning algorithm for efficient person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ReID; Progressive learning; Bayesian optimization; Computational
   efficiency
AB Inthis paper, we study the problem of Person Re-Identification (ReID) for large-scale applications in the real-world scenarios. Recently most research efforts on ReID have been mainly devoted to building complicated part models, which however introduce considerably high computational cost and memory consumption, inhibiting its practicability in large-scale applications in practice. This paper aims to develop a novel learning strategy to find efficient feature embeddings while maintaining the balance of accuracy and model complexity. More specifically, we find by enhancing the classical triplet loss together with cross-entropy loss, our method can explore the hard examples and build a discriminant feature embedding yet compact enough for large-scale applications. Our training process is carried out progressively using Bayesian optimization, and we call it the Progressive Learning Algorithm (PLA). Extensive experiments on three large-scale datasets show that our PLA is comparable or better than the-state-of-the-arts. In particular, on the challenging Market-1501 dataset, we achieve Rank-1 = 94.7%/mAP= 89.4% while saving at least 30% parameters than strong part models. Finally, extra experimental results indicate that current neural network backbones can benefit from our PLA with an average performance improvement of approximately 2.23% and 1.63% regarding mAP and Rank-1, respectively.
C1 [Li, Zhen; Shao, Hanyang] Shanghai Grandhonor Informat Technol Co Ltd, Dept Comp Vis & Deep Learning, Shanghai 200333, Peoples R China.
   [Niu, Liang; Xue, Nian] NYU, Tandon Sch Engn, Dept Comp Sci & Engn, New York, NY 10003 USA.
   [Li, Zhen] Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing 210016, Peoples R China.
C3 New York University; New York University Tandon School of Engineering;
   Nanjing University of Aeronautics & Astronautics
RP Xue, NA (corresponding author), NYU, Tandon Sch Engn, Dept Comp Sci & Engn, New York, NY 10003 USA.
EM lizh0019@gmail.com; hansoluo757@gmail.com; liang.niu@nyu.edu;
   nian.xue@nyu.edu
RI Xue, Nian/HRA-6550-2023; Xue, Nian/AAE-3262-2021
OI Xue, Nian/0000-0001-6108-2562; 
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, ARXIV180105339
   [Anonymous], 2016, arXiv preprint arXiv:1611.05244
   [Anonymous], 2014, QUEEN MARY RES ONLIN, DOI DOI 10.5244/C.28.48
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Chen WH, 2017, AAAI CONF ARTIF INTE, P3988
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chu HF, 2019, MULTIMED TOOLS APPL, V78, P27067, DOI 10.1007/s11042-017-4817-4
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Fu D., 2021, CVPR, P14750, DOI 10.1109/cvpr46437.2021.01451
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hermans Alexander, 2017, ARXIV170307737
   Hsu Charles C.-H, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P921, DOI 10.1109/ICASI.2017.7988590
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071936
   Karras T, 2018, P INT C LEARN REPR I
   Khajuria Rishi, 2020, Journal of Multimedia Information System, V7, P1
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Khan SU, 2024, MULTIMED TOOLS APPL, V83, P15079, DOI 10.1007/s11042-020-10145-8
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kingma D. P., 2014, arXiv
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2020, 2020 25 INT C PATT R
   Liang WQ, 2021, IEEE T IMAGE PROCESS, V30, P6392, DOI 10.1109/TIP.2021.3092578
   Lit Z., 2021, 2021 International Joint Conference on Neural Networks (IJCNN), P1
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   MAO C, 2017, 9 AS C MACH LEARN, P487
   Nvidia, 2017, Nvidia tensorrt: Programmable inference accelerator
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Rosasco L, 2004, NEURAL COMPUT, V16, P1063, DOI 10.1162/089976604773135104
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tan MX, 2019, PR MACH LEARN RES, V97
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang D., 2018, ARXIV PREPRINT ARXIV
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xue N, 2021, PEDESTRIAN DETECTION
   Xue NA, 2020, ANN COMPUT SECURITY, P304, DOI 10.1145/3427228.3427254
   Yang XJ, 2020, MULTIMED TOOLS APPL, V79, P9299, DOI 10.1007/s11042-019-7387-9
   Yao H., 2017, ARXIV170700798
   Yuan CH, 2019, MULTIMED TOOLS APPL, V78, P21145, DOI 10.1007/s11042-019-7446-2
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 73
TC 2
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24493
EP 24513
DI 10.1007/s11042-022-12022-y
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960100004
DA 2024-07-18
ER

PT J
AU Birara, M
   Gebremeskel, GB
AF Birara, Muluken
   Gebremeskel, Gebeyehu Belay
TI Augmenting machine learning for Amharic speech recognition: a paradigm
   of patient's lips motion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Speech recognition; Lips motion; Average feature;
   Saturated component
AB The method of automatic lip motion recognition is an essential input for visual speech detection. It is a technological approach to demystify people who are hard to hear, deaf, and a challenge of silent communication in day-to-day life. However, the recognition process is a challenge in terms of pronunciation variation, speech speeds, gesture variation, color, makeup, the video quality of the camera, and the way of feature extraction. This paper proposed a solution for automatic lip motion recognition by identifying lip movements and characterizing their association with the spoken words for the Amharic language spoken using the information available in lip movements. The input video is converting into consecutive image frames. We use a Viola-Jones object detection algorithm to gain YIQ color space and apply the saturation components to detect lip images from the face area. Sobel's edge detection and morphological image operations implement to identify and extract the exact contour of the lip. We applied ANN and SVM classifiers on averaging shape information features, and we gained 65.71% and 66.43% classification accuracies of ANN and SVM, respectively. The findings presented in the Amharic Speech Recognition is the newly introduced technology to enhance the academic and linguistic skills of hearing-problem people, health domain experts, physicians, researchers, etc. The future research work presents in the light of the findings.
C1 [Birara, Muluken; Gebremeskel, Gebeyehu Belay] Bahir Dar Univ, Bahir Dar Inst Technol, Poly Campus,POB 37, Bahir Dar, Ethiopia.
C3 Bahir Dar University
RP Gebremeskel, GB (corresponding author), Bahir Dar Univ, Bahir Dar Inst Technol, Poly Campus,POB 37, Bahir Dar, Ethiopia.
EM Mulubira2@gmail.com; Ge.be09@yahoo.com
CR Abate S.T., 2005, INTERSPEECH
   Acharya T., 2005, Image processing: principles and applications, P1
   [Anonymous], 2020, Feature Extraction and Image Processing
   Assefa D, 2006, AMHARIC SPEECH TRAIN
   Aybar E, 2006, SOBEL EDGE DETECTION, P3
   Badura S., 2015, INT VIRTUAL SCI C IN, P96
   Bender, 1976, LANGUAGE ETHIOPIA
   Borde P, 2015, INT J SPEECH TECHNOL, V18, P167, DOI 10.1007/s10772-014-9257-1
   Dabre K, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P317, DOI 10.1109/CSCITA.2014.6839279
   de la Cuesta AG, 2008, 2008 INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P83, DOI 10.1109/IMVIP.2008.13
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Hayward K, 1999, HDB INT PHON ASS GUI
   Heracleous P, 2009, IEEE SIGNAL PROC LET, V16, P339, DOI 10.1109/LSP.2009.2016011
   Ichino M, 2014, I C CONT AUTOMAT ROB, P958, DOI 10.1109/ICARCV.2014.7064435
   Jixin L, 1998, EMPIRICAL COMP SVMS, P4
   Kalra A, 2016, 2016 INTERNATIONAL CONFERENCE ON MICRO-ELECTRONICS AND TELECOMMUNICATION ENGINEERING (ICMETE), P305, DOI 10.1109/ICMETE.2016.49
   Kim D., 2013, SOBEL OPERATOR CANNY, P1, DOI DOI 10.1186/1687-1847-2013-103
   Kopparapu S. K., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P126, DOI 10.1109/NCVPRIPG.2011.34
   Liu H, 2010, 2 INT C INFORM ENG C, V2, DOI 10.1109/ICIECS.2010.5677823
   Liu J, 2006, INT J COMPUT SCI NET, V6, P57
   Liu X, 2014, IEEE T INF FOREN SEC, V9, P233, DOI 10.1109/TIFS.2013.2293025
   Marathe, 2019, INT J ELECT COMP ENG, V9, P289
   Najafian M, 2020, SPEECH COMMUN, V122, P44, DOI 10.1016/j.specom.2020.05.003
   Peymanfard Javad, 2021, ARXIV210404784 CSCV, P1
   Pironkov G, 2020, COMPUT SPEECH LANG, V64, DOI 10.1016/j.csl.2020.101103
   Poomhiran L, 2021, ENG TECHNOL APPL SCI, V11, P6986, DOI 10.48084/etasr.4102
   Ren JC, 2012, KNOWL-BASED SYST, V26, P144, DOI 10.1016/j.knosys.2011.07.016
   Saitoh T, 2006, INT S INTELL SIGNAL, P287, DOI [10.1109/ISPACS.2006.364888, DOI 10.1109/ISPACS.2006.364888]
   Saitoh T, 2011, IEEJ T ELECTR ELECTR, V6, P289, DOI 10.1002/tee.20658
   Saranya G., 2020, INT J ELECT COMPUT E, V10, P4217, DOI DOI 10.11591/IJECE.V10I4.PP4217-4225
   Sengupta S., 2012, IJAIS, V4, P18, DOI [10.5120/ijais12-450677, DOI 10.5120/IJAIS12-450677]
   Sharma H, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1715, DOI 10.1109/ICACCI.2015.7275860
   Shatnawi M. Q., 2020, INT J ELECT COMPUTER, V10, P4363
   Singh K., 2019, INT J ELECTR COMPUT, V9, P660, DOI [DOI 10.11591/IJECE.V9I1.PP660-666, 10.11591/ijece.v9i1]
   Sowjanya KS., 2015, INT J ADVANC RES COM, V5, P456
   Stavros P, 2020, ARXIV190401954 CSCV, P1
   Swami JU., 2021, J EMERG TECHNOL INNO, V8, P1424
   Talha KS, 2013, IOP CONF SER-MAT SCI, V53, DOI 10.1088/1757-899X/53/1/012016
   Teferi D, 2007, PATTERN RECOGN LETT, V28, P2143, DOI 10.1016/j.patrec.2007.06.007
   Ullendorff Edward., 1973, ETHIOPIANS INTRO COU, V3d
   Vazifehdan M, 2019, J KING SAUD UNIV-COM, V31, P175, DOI 10.1016/j.jksuci.2018.01.002
   Vincent O., 2009, P 2009 SITE C INF SC, P97
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang J, 2010, 2010 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Werda S., 2007, International Journal of Computing Information Sciences, V5, P62
   Wright C, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-0102-6
   Xu G, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, PROCEEDINGS, P60, DOI 10.1109/ISCID.2009.22
   Yang JF, 2004, INT C PATT RECOG, P632
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yargic A, 2013, LIP READING APPL MS, DOI 10.1109/INISTA.2013.6577656
   Yau W. C, 2008, VIDEO ANAL MOUTH MOV
   Yimama, 1997, ETHIOPIA J LANGUAGE, P1
   Yu DH, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P210, DOI 10.1109/IMVIP.2007.35
   Zhang YH, 2020, IEEE INT CONF AUTOMA, P356, DOI 10.1109/FG47880.2020.00134
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zheng GL, 2014, INT SYM COMPUT INTEL, P293, DOI 10.1109/ISCID.2014.110
NR 57
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24377
EP 24397
DI 10.1007/s11042-022-12399-w
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000008
DA 2024-07-18
ER

PT J
AU Joshi, I
   Utkarsh, A
   Singh, P
   Dantcheva, A
   Roy, SD
   Kalra, PK
AF Joshi, Indu
   Utkarsh, Ayush
   Singh, Pravendra
   Dantcheva, Antitza
   Roy, Sumantra Dutta
   Kalra, Prem Kumar
TI On restoration of degraded fingerprints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprints; Restoration; Denoising; Biometrics; Deep convolutional
   neural networks; Attention mechanism; Feature recalibration
ID IMAGE-ENHANCEMENT; ORIENTATION; ALGORITHM; TRACKING; FILTER
AB The state-of-the-art fingerprint matching systems achieve high accuracy on good quality fingerprints. However, degraded fingerprints obtained due to poor skin conditions of subjects or fingerprints obtained around a crime scene often have noisy background and poor ridge structure. Such degraded fingerprints pose problem for the existing fingerprint recognition systems. This paper presents a fingerprint restoration model for a poor quality fingerprint that reconstructs a binarized fingerprint image with an improved ridge structure. In particular, we demonstrate the effectiveness of channel refinement in fingerprint restoration. The state-of-the-art channel refinement mechanisms, such as Squeeze and Excitation (SE) block, in general, create SE- block introduce redundancy among channel weights and degrade the performance of fingerprint enhancement models. We present a lightweight attention mechanism that performs channel refinement by reducing redundancy among channel weights of the convolutional kernels. Restored fingerprints generated after introducing proposed channel refinement unit obtain improved quality scores on standard fingerprint quality assessment tool. Furthermore, restored fingerprints achieve improved fingerprint matching performance. We also illustrate that the idea of introducing a channel refinement unit is generalizable to different deep architectures. Additionally, to quantify the ridge preservation ability of the model, standard metrics: Dice score, Jaccard Similarity, SSIM and PSNR are computed with the ground truth and the output of the model (CR-GAN). An ablation study is conducted to individually quantify the improvement of generator and discriminator sub-networks of CR-GAN through channel refinement. Experiments on the publicly available IIITD- MOLF, Rural Indian Fingerprint Database and a private rural fingerprint database demonstrate the efficacy of the proposed attention mechanism.
C1 [Joshi, Indu; Roy, Sumantra Dutta; Kalra, Prem Kumar] Indian Inst Technol Delhi, New Delhi, India.
   [Joshi, Indu; Roy, Sumantra Dutta; Kalra, Prem Kumar] INRIA Sophia Antipolis France, Biot, India.
   [Singh, Pravendra] Indian Inst Technol Roorkee, Roorkee, Uttar Pradesh, India.
   [Dantcheva, Antitza] INRIA Sophia Antipolis, Biot, France.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Joshi, I (corresponding author), Indian Inst Technol Delhi, New Delhi, India.; Joshi, I (corresponding author), INRIA Sophia Antipolis France, Biot, India.
EM indu.joshi@cse.iitd.ac.in; ayushutkarsh@gmail.com;
   pravendra.singh@cs.iitr.ac.in; antitza@inria.fr; sumantra@ee.iitd.ac.in;
   pkalra@cse.iitd.ac.in
RI Dutta Roy, Sumantra/AAQ-6401-2021; Singh, Pravendra/ABC-9247-2020
OI Dutta Roy, Sumantra/0000-0002-2141-5067; Singh,
   Pravendra/0000-0003-1001-2219
FU French Government (National Research Agency, ANR) [ANR-18-CE92-0024];
   Raman-Charpak Fellowship 2019; Agence Nationale de la Recherche (ANR)
   [ANR-18-CE92-0024] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX The authors are grateful to Prof. Phalguni Gupta from IIT Kanpur for
   sharing the private rural Indian fingerprint database used in this
   research. The authors thank the HPC facility of Inria Sophia Antipolis
   for the computational resources used in this research. The authors
   acknowledge the efforts of Adithya Anand from IIT Delhi in preparing the
   training dataset. This work is partly supported by the French Government
   (National Research Agency, ANR) under grant agreement ANR-18-CE92-0024.
   I. Joshi is partially supported by the Raman-Charpak Fellowship 2019.
CR [Anonymous], 2011, IEEE INT C
   [Anonymous], 2015, NIST BIOMETRIC IMAGE
   Ansari A. H., 2011, Master's Thesis
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Cappelli R, 2011, IEEE T PATTERN ANAL, V33, P1051, DOI 10.1109/TPAMI.2010.228
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Ferreira M, 2016, INT J ADV MANUF TECH, V85, P57, DOI 10.1007/s00170-014-6026-x
   Ghafoor M, 2014, IET IMAGE PROCESS, V8, P417, DOI 10.1049/iet-ipr.2013.0528
   Gottschlich C, 2012, IET BIOMETRICS, V1, P105, DOI 10.1049/iet-bmt.2012.0003
   Gottschlich C, 2012, IEEE T IMAGE PROCESS, V21, P2220, DOI 10.1109/TIP.2011.2170696
   Gupta R, 2020, INFORM SCIENCES, V530, P201, DOI 10.1016/j.ins.2020.01.031
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Horapong K, 2021, PROGR CORRECTIVE FEE
   Hsieh CT, 2003, PATTERN RECOGN, V36, P303, DOI 10.1016/S0031-3203(02)00032-8
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jia F, 2021, IEEE SIGNAL PROC LET, V28, P1600, DOI 10.1109/LSP.2021.3100263
   Jirachaweng S, 2007, LECT NOTES COMPUT SC, V4642, P96
   Joshi I., 2022, DIGITAL IMAGE ENHANC
   Joshi I, 2021, AI DEEP LEARNING BIO, P51
   Joshi I, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533712
   Joshi I, 2021, IEEE WINT C APPL COM, P60, DOI 10.1109/WACVW52041.2021.00011
   Joshi I, 2019, IEEE WINT CONF APPL, P895, DOI 10.1109/WACV.2019.00100
   Karabulut D, 2020, MULTIMED TOOLS APPL, V79, P18569, DOI 10.1007/s11042-020-08750-8
   Li DD, 2018, IEEE SIGNAL PROC LET, V25, P1815, DOI 10.1109/LSP.2018.2877008
   Li J, 2018, SIGNAL PROCESS-IMAGE, V60, P52, DOI 10.1016/j.image.2017.08.010
   Liu MH, 2021, IEEE T INF FOREN SEC, V16, P1709, DOI 10.1109/TIFS.2020.3039058
   Liu SX, 2017, PATTERN RECOGN, V67, P164, DOI 10.1016/j.patcog.2017.02.012
   Manickam A, 2019, MULTIMED TOOLS APPL, V78, P3065, DOI 10.1007/s11042-018-5633-1
   Medeiros A.G., 2020, INT JOINT C NEUR NET, P1
   Mnih V, 2014, ADV NEUR IN, V27
   NFIQ 2.0, 2016, NIST FING IM QUAL
   Le NT, 2020, IEEE ACCESS, V8, P6602, DOI 10.1109/ACCESS.2020.2964035
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Park Jongchan, 2018, arXiv preprint arXiv:1807.06514
   Puri C, 2010, LECT NOTES COMPUT SC, V6005, P55
   QIAN P, 2019, IEEE T MED IMAGING, P1
   Ramos R, 2018, SIBGRAPI, P266, DOI 10.1109/SIBGRAPI.2018.00041
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy R, 2000, HALARCHIVESOUVERTESF
   Sahasrabudhe M, 2014, IND C COMP VIS GRAPH, P1
   Sankaran A, 2015, IEEE ACCESS, V3, P653, DOI 10.1109/ACCESS.2015.2428631
   Schuch P, 2016, INT CONF IMAG PROC
   Schuch P, 2018, IET BIOMETRICS, V7, P102, DOI 10.1049/iet-bmt.2016.0088
   Sharma RP, 2019, IMAGE VISION COMPUT, V83-84, P1, DOI 10.1016/j.imavis.2019.02.006
   Singh P, 2020, IEEE WINT CONF APPL, P873, DOI 10.1109/WACV45572.2020.9093305
   Svoboda J, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P429, DOI 10.1109/BTAS.2017.8272727
   Tiwari K, 2014, LECT NOTES COMPUT SC, V8833, P199, DOI 10.1007/978-3-319-12484-1_22
   Turroni F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P152, DOI 10.1109/ICB.2012.6199773
   Vaswani A, 2017, ADV NEUR IN, V30
   Vatsa M., 2010, INT WORKSHOP EMERGIN, P1
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang W, 2008, PATTERN RECOGN LETT, V29, P301, DOI 10.1016/j.patrec.2007.10.004
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong WJ, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107203
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu DQ, 2020, IET BIOMETRICS, V9, P194, DOI 10.1049/iet-bmt.2019.0121
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P955, DOI 10.1109/TPAMI.2013.184
   Yao C, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI [10.1109/ICIICII.2016.0012, 10.1109/ICIICII.2016.49]
   Yoon S, 2010, PROC SPIE, V7667, DOI 10.1117/12.851411
NR 64
TC 4
Z9 4
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35349
EP 35377
DI 10.1007/s11042-021-11863-3
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000770549800015
DA 2024-07-18
ER

PT J
AU Chen, HJ
   Wang, W
   Li, JJ
   Mo, H
   Chen, JH
AF Chen, Hongjiang
   Wang, Wei
   Li, Jingjian
   Mo, Hong
   Chen, Jianhua
TI Phase-based side information generation in distributed video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Side information generation; Phase-based
   method; Steerable pyramid decomposition
ID OPTICAL-FLOW
AB In distributed video coding, the quality of side information (SI) directly affects the final compression efficiency and rate-distortion performance. In the process of generating SI, many methods require accurate pixel matching and produce intermediate frames based on calculating motion vectors. As a result, they perform poorly in scenarios such as light changes, motion blur, and so on. In this case, phase-based frame interpolation for video (PBFI) is proved to be effective. And it has the advantages of simple implementation and easy parallelization. However, this method cannot get a good result when interpolating the video sequence of large motion. This paper proposes a phase-based SI generation method, which applies PBFI to distributed video coding and improves it from two aspects. (1) Move the high frequency information to the low frequency, reduce the proportion of the high frequency components, so that more frequency components can be interpolated in phase; (2) By correcting the phase difference again, more accurate phase shift information can be obtained when facing the video sequence of large motion. Simulation results show that the proposed method can effectively improve the quality of the generated SI. Thereby the overall performance of the distributed video coding system can be improved.
C1 [Chen, Hongjiang; Wang, Wei; Li, Jingjian; Mo, Hong; Chen, Jianhua] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Yunnan, Peoples R China.
C3 Yunnan University
RP Chen, JH (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Yunnan, Peoples R China.
EM chj@mail.ynu.edu.cn; weiwang@mail.ynu.edu.cn;
   li_jingjian@mail.ynu.edu.cn; www_mofeng58@163.com; chenjh@ynu.edu.cn
RI Chen, Jianhua/AAA-5738-2022
OI Chen, Jianhua/0000-0002-3637-2565; Wang, Wei/0000-0002-2129-4736; Chen,
   Hongjiang/0000-0002-6323-0108
FU National Natural Science Foundation of China [61861045]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61861045.
CR Artigas J., 2007, P PCS, P1
   Cao Y, 2018, IET IMAGE PROCESS, V12, P354, DOI 10.1049/iet-ipr.2017.0892
   Dash B, 2018, MULTIMED TOOLS APPL, V77, P27301, DOI 10.1007/s11042-018-5921-9
   Dash B, 2018, MULTIMED TOOLS APPL, V77, P15221, DOI 10.1007/s11042-017-5103-1
   Didyk P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508376
   Dufaux F, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/508167
   Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944
   Luong HV, 2012, IEEE T IMAGE PROCESS, V21, P4782, DOI 10.1109/TIP.2012.2215621
   Jun DS, 2019, DISPLAYS, V59, P21, DOI 10.1016/j.displa.2019.05.002
   Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747
   Rupa S, 2014, AEU-INT J ELECTRON C, V68, P201, DOI 10.1016/j.aeue.2013.08.005
   Shen YC, 2017, IEEE SENS J, V17, P1872, DOI 10.1109/JSEN.2017.2653100
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Taheri YM, 2019, MULTIMED TOOLS APPL, V78, P20697, DOI 10.1007/s11042-019-7249-5
   Wadhwa N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461966
   Wang W, 2021, MULTIMED TOOLS APPL, V80, P26713, DOI 10.1007/s11042-021-10870-8
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zhou JW, 2019, SIGNAL PROCESS-IMAGE, V76, P118, DOI 10.1016/j.image.2019.03.016
NR 20
TC 0
Z9 0
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21295
EP 21312
DI 10.1007/s11042-022-12589-6
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700001
DA 2024-07-18
ER

PT J
AU Mishra, NK
   Singh, A
   Singh, PK
AF Mishra, Nitin Kumar
   Singh, Aditya
   Singh, Pramod Kumar
TI Multi-label personality trait identification from text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality trait identification; Feature selection; ANOVA's
   F-statistic; Chi-square; Mutual information; Multi-label classification
ID FEATURE-SELECTION; CLASSIFICATION; RECOGNITION; PERFORMANCE; PREDICTION
AB Understanding the personality is beneficial for many purposes, e.g., it is natural to predict a user's personality before offering him or her any services. The personality is intrinsic in the behavior of a person in all aspects, such as text writing. Some work has been proposed in recent times for correctly classifying a person's personality from the text. However, it is still a significant challenge as the achieved accuracy is low; therefore, the proposed work addresses this issue. Effective feature selection techniques provide better classification accuracy in multi-label classification and personality traits identification as multi-label classification problem requires efficacy of feature selection methods. Therefore, to improve the accuracy using feature selection technique, this paper proposes a method for personality trait recognition from textual data called P ersonality T rait Classification based on L inguistic and F eature selection as M ulti-label classification (PTLFM). It combines analysis of variance's F-statistic, Chi-square, and Mutual information with the sequential feature selection wrapper method to rank features. These three criteria apprehend different aspects of the dataset. The experimental results demonstrate that the proposed PTLFM method achieves higher accuracy across all the personality traits than the prevailing state-of-the-art machine learning and deep learning models. PTLFM provides an impressive absolute improvement of 2.23% and 3.84% of comparative improvement over the existing prevalent method, with more than 90% of features discarded. Furthemore, the proposed PTLFM achieves a percentage gain compared to the competitive methods across different personality traits Extraversion, Neuroticism, Agreeableness, Conscientiousness, and Openness in absolute terms 1.17, 1.94, 2.35, 1.64, and 0.35 respectively, and in comparative terms 2.01, 3.27, 4.14, 2.86, and 0.56 respectively. The results suggest that although deep learning is a popular paradigm, it does not always lead to a better predictive performance than machine learning models in all the problem domains.
C1 [Mishra, Nitin Kumar; Singh, Pramod Kumar] ABV Indian Inst Informat Technol & Management Gwa, Computat Intelligence & Data Min Res CIDMR Lab, Gwalior 474015, India.
   [Singh, Aditya] Vellore Inst Technol, Vellore 632014, Tamil Nadu, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   Vellore Institute of Technology (VIT); VIT Vellore
RP Mishra, NK (corresponding author), ABV Indian Inst Informat Technol & Management Gwa, Computat Intelligence & Data Min Res CIDMR Lab, Gwalior 474015, India.
EM nkmishra0701@gmail.com; aditya.singh2016a@vitalumn.ac.in;
   pksingh@iiitm.ac.in
RI MISHRA, nitin/ACM-1866-2022
OI MISHRA, nitin/0000-0001-7614-0622; Singh, Pramod
   Kumar/0000-0003-0019-1436
CR Al Marouf A, 2020, IEEE T COMPUT SOC SY, V7, P587, DOI 10.1109/TCSS.2020.2966910
   [Anonymous], 2016, SAAIP IJCAI
   [Anonymous], P 14 INT C MACH LEAR
   Arya R, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100399
   Bergner RM, 2020, NEW IDEAS PSYCHOL, V57, DOI 10.1016/j.newideapsych.2019.100759
   Bhardwaj S, 2016, MULTIMED TOOLS APPL, V75, P13237, DOI 10.1007/s11042-015-2793-0
   Capretz LF, 2010, IT PROF, V12, P6, DOI 10.1109/MITP.2010.33
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Dhelim S, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106227
   El-Demerdash K., 2021, EGYPT INFORM J, V1, P1
   Elngar A.A., 2020, J INF TECHNOL MANAGE, V12, P3, DOI 10.22059/JITM.2020.78884
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Aguilar AG, 2016, INT J TOUR RES, V18, P210, DOI 10.1002/jtr.1997
   Gulseven O., 2019, OPEN PSYCHOL J, V12, P84, DOI [10.2174/1874350101912010084, DOI 10.2174/1874350101912010084]
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Lerner M.J., 2003, Handbook of PSYCHOLOGY, V5
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23
   Mehta Y, 2020, ARTIF INTELL REV, V53, P2313, DOI 10.1007/s10462-019-09770-z
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mishra NK, 2021, INFORM SCIENCES, V563, P342, DOI 10.1016/j.ins.2021.03.001
   Mishra NK, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102240
   Mishra Rohit, 2020, Intelligent Systems Design and Applications. Proceedings of 18th International Conference on Intelligent Systems Design and Applications (ISDA 2018). Advances in Intelligent Systems and Computing (AISC 940), P673, DOI 10.1007/978-3-030-16657-1_63
   Mohammad SM, 2015, COMPUT INTELL-US, V31, P301, DOI 10.1111/coin.12024
   Myers Isabel Briggs, 1998, MBTI Manual: A Guide to the Development and Use of the Myers-Briggs Type Indicator
   Pennebaker J.W., 2001, Linguistic inquiry and word count: LIWC 2001, V71, P1
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pohjalainen J, 2015, COMPUT SPEECH LANG, V29, P145, DOI 10.1016/j.csl.2013.11.004
   Quercia D., 2012, P ACM 2012 C COMPUTE, P955, DOI DOI 10.1145/2145204.2145346
   Rifkin R, 2004, J MACH LEARN RES, V5, P101
   Sharma Annapurna, 2021, Expert Systems with Applications, V164, DOI 10.1016/j.eswa.2020.114004
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tayarani M, 2019, IEEE T AFFECT COMPUT
   Thakur D, 2015, INT CONF COMM SYST, P1103, DOI 10.1109/CSNT.2015.136
   Vuttipittayamongkol P, 2020, INFORM SCIENCES, V509, P47, DOI 10.1016/j.ins.2019.08.062
   Wang CF, 2011, J KNOWL MANAG, V15, P802, DOI 10.1108/13673271111174339
   Wang Y, 2020, J ADV TRANSP, V2020
   Xue D, 2018, APPL INTELL, V48, P4232, DOI 10.1007/s10489-018-1212-4
   Zhao JH, 2020, PATTERN RECOGN LETT, V138, P397, DOI 10.1016/j.patrec.2020.07.035
   Zhao SC, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3233184
NR 40
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21503
EP 21519
DI 10.1007/s11042-022-12548-1
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700007
DA 2024-07-18
ER

PT J
AU Girija, OK
   Elayidom, MS
AF Girija, O. K.
   Elayidom, Sudheep M.
TI Mammogram pectoral muscle removal and classification using histo-sigmoid
   based ROI clustering and SDNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pre-processing; Filtering; Fuzzy C-means ROI clustering; Hough
   transform; Discrete cosine transform; DNN classification
ID BREAST; SEGMENTATION; ALGORITHM; NETWORK
AB Mammograms are the images used by radiologists to diagnose breast cancer. Breast cancer is one of the most common cancers in women. The early detection of breast cancer reduces the risk of death. Mammograms are an efficient breast imaging technique for breast cancer screening. One of the early screening methods of breast cancer that is still used today is mammograms due to their low cost. Unfortunately, this low cost accompanied by a low-performance rate also. Nowadays, the specific characterization of breast cancer images is a troublesome task. To overcome all the existing drawbacks, this research study develops a new algorithm for Mammogram Pectoral Muscle Removal using Histo-sigmoid based ROI Clustering and Classification using SDNN. Initially, the input breast image is first taken from the data set and pre-processed with wiener filtering. After that, Histo-sigmoid based ROI clustering is applied for the expulsion of the pectoral muscle. From that point, feature extraction using Hough transform and DCT. At last, the Support value-based adaptive deep neural network (SDNN) classifier clusters the mammogram pictures into normal, malignant, and benign classes accurately. Experimental results show that our proposed approach accomplishes the extreme classification accuracy outcome of MIAS Dataset is 99% and DDSM is 98%. Comparable to the MA_CNN, which achieves 96%. The SGR and Gestalt psychology had less Accuracy 94% and 94%.
C1 [Girija, O. K.; Elayidom, Sudheep M.] CUSAT, Div Comp Sci & Engn, Sch Engn, Kochi, Kerala, India.
C3 Cochin University Science & Technology
RP Girija, OK (corresponding author), CUSAT, Div Comp Sci & Engn, Sch Engn, Kochi, Kerala, India.
EM girijaok@gmail.com
RI Elayidom, Sudheep M/AAQ-9356-2021
OI Elayidom, Sudheep M/0000-0003-3836-7425
CR Agnes SA, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1494-z
   Al-masni MA, 2017, IEEE ENG MED BIO, P1230, DOI 10.1109/EMBC.2017.8037053
   [Anonymous], 2018, SEGMENTATION MAMMOGR
   [Anonymous], 2014, 2014 IEEE 9 INT C IN
   Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Benhassine NE, 2020, INT J IMAG SYST TECH, V30, P45, DOI 10.1002/ima.22352
   Chakravarthy SRS, 2022, IRBM, V43, P49, DOI 10.1016/j.irbm.2020.12.004
   Chowdhary CL, 2016, INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION COMMUNICATION TECHNOLOGY & COMPUTING, 2016, DOI 10.1145/2979779.2979800
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Elmoufidi A, 2016, INT S UB NETW
   Halalli B, CLASSIFICATION BREAS
   He N, 2016, EUR J RADIOL, V85, P392, DOI 10.1016/j.ejrad.2015.11.029
   Heidari M, 2020, IEEE T MED IMAGING, V39, P1235, DOI 10.1109/TMI.2019.2946490
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Kaur P., 2019, Informatics in Medicine Unlocked, V16, DOI [DOI 10.1016/J.IMU.2019.01.001, 10.1016/j.imu.2019.01.001]
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855
   Lbachir IA, 2021, MULTIMED TOOLS APPL, V80, P9493, DOI 10.1007/s11042-020-09991-3
   Liu CC, 2012, COMPUT MATH APPL, V64, P1100, DOI 10.1016/j.camwa.2012.03.028
   Mathan K, 2018, DES AUTOM EMBED SYST, V22, P225, DOI 10.1007/s10617-018-9205-4
   Mughal B, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4638-5
   Mustra M, 2016, MED BIOL ENG COMPUT, V54, P1003, DOI 10.1007/s11517-015-1411-7
   Pandey D, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e01042
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0043-3
   Parthasarathy P., 2018, Int. J. Comput. Appl, V42, P222, DOI [10.1080/1206212X.2018.1457471, DOI 10.1080/1206212X.2018.1457471]
   Rahimeto S, 2021, EVOL SYST-GER, V12, P519, DOI 10.1007/s12530-019-09310-8
   Reddy GRB, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1728-1
   Samala RK, 2019, IEEE T MED IMAGING, V38, P686, DOI 10.1109/TMI.2018.2870343
   Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345
   Sarangi S, 2021, MED BIOL ENG COMPUT, V59, P947, DOI 10.1007/s11517-021-02348-4
   Sheba KU, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1444320
   Shen RB, 2018, J DIGIT IMAGING, V31, P680, DOI 10.1007/s10278-018-0068-9
   Shrivastava N, 2020, MULTIMED TOOLS APPL, V79, P26467, DOI 10.1007/s11042-020-09220-x
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Singh VP, 2017, TECHNOL HEALTH CARE, V25, P709, DOI 10.3233/THC-170851
   Vijayarajeswari R, 2019, MEASUREMENT, V146, P800, DOI 10.1016/j.measurement.2019.05.083
   Wang Y, 2014, NEUROCOMPUTING, V144, P107, DOI 10.1016/j.neucom.2013.11.050
   Wei CH, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20150802
   Yousefikamal P., 2019, COMPUTER VISION PATT, V2019, P1
   Zhang YD, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102439
NR 41
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20993
EP 21026
DI 10.1007/s11042-022-12599-4
EA MAR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500003
DA 2024-07-18
ER

PT J
AU Hakim, A
   Marsland, S
   Guesgen, HW
AF Hakim, Ayesha
   Marsland, Stephen
   Guesgen, Hans W.
TI Computational representation and analysis of emotion dynamics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion dynamics; Emotion transition; Emotion recognition; Statistical
   Shape Models; Activation-evaluation space
ID FACIAL EXPRESSIONS; INTENSITY PROFILES; RECOGNITION; IDENTITY; MODEL;
   ANGER; FACE
AB Human emotions are dynamic in nature. The intensity with which they are felt changes over time, and they have a natural timescale of expression, from onset to decay. Further, emotions shade from one to another, and many feelings are built up of blends of pure emotions. In order to represent this complex reality visually, a variety of models of the space of emotions have been introduced in the psychology literature. In this paper we present a computational approach to transforming facial expressions of emotions into positions in one of these models, the activation-evaluation space. This enables the study of emotion dynamics from facial expressions, including the transitions between emotion states and changes in emotion intensity through time, based on a set of shape models for different emotions. We consider different ways to build these shape models, and then show how to represent each frame of emotion in the activation-evaluation space, and analyse sequences of emotions from video by following temporal trajectories in that space. We demonstrate the approach on a standard dataset and compare it to human annotations, with promising results.
C1 [Hakim, Ayesha] Muhammad Nawaz Shareef Univ Agr Multan, Dept Comp Sci, Multan, Pakistan.
   [Marsland, Stephen] Victoria Univ Wellington, Sch Math & Stat, Wellington, New Zealand.
   [Guesgen, Hans W.] Massey Univ, Sch Fundamental Sci, Massey, New Zealand.
C3 Victoria University Wellington; Massey University
RP Hakim, A (corresponding author), Muhammad Nawaz Shareef Univ Agr Multan, Dept Comp Sci, Multan, Pakistan.
EM ayesha.hakim@mnsuam.edu.pk; stephen.marsland@vuw.ac.nz;
   h.w.guesgen@massey.ac.nz
RI Guesgen, Hans/ACC-1443-2022; Hakim, Ayesha/AAE-3469-2019
OI Hakim, Ayesha/0000-0002-8031-5568
CR Agbolade O, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3153-2
   Bansal Akhil, 2013, Multimodal Pattern Recognition of Social Signals in Human-Computer-Interaction. First IAPR TC3 Workshop, MPRSS 2012. Revised Selected Papers, P19, DOI 10.1007/978-3-642-37081-6_3
   Bartlett MS, 2004, IEEE SYS MAN CYBERN, P592
   Bindu MH, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN IMAGE AND SIGNAL PROCESSING, P351, DOI 10.1109/CIISP.2007.369194
   BLUMBERG SH, 1991, MERRILL PALMER QUART, V37, P183
   Braathen B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P360, DOI 10.1109/AFGR.2002.1004180
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Costantini E., 2005, P 10 INT C INT US IN P 10 INT C INTELLIGE, P20
   DMello S., 2012, ENCY SCI LEARNING, P2325, DOI DOI 10.1007/978-1-4419-1428-6
   DMello S, 2010, P ANN M COGN SCI SOC, V32
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 1999, Handbook of cognition and emotion, V4, P5
   Ekman P., 2007, Emotions revealed: Recognizing faces and feelings to improve communication and emotional life, V2nd ed.
   Ekman P., 1978, Facial action coding system
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fisher N. I., 1993, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345
   Gu SM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00781
   Guha T, 2018, IEEE T AFFECT COMPUT, V9, P14, DOI 10.1109/TAFFC.2016.2578316
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Gunes H, 2006, INT C PATT RECOG, P1148
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Hakim A, 2012, P 27 C IM VIS COMP N, P352
   Hakim A., 2018, J APPL COMPUT INF TE, V11, P1
   Hakim A, 2013, INT CONF AFFECT, P517, DOI 10.1109/ACII.2013.91
   Hakim A, 2013, INT CONF AFFECT, P185, DOI 10.1109/ACII.2013.37
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Heylen J, 2015, COGNITION EMOTION, V29, P168, DOI 10.1080/02699931.2014.896783
   Hoeksma JB, 2007, EMOTION, V7, P638, DOI 10.1037/1528-3542.7.3.638
   Hoque ME, 2012, IEEE T AFFECT COMPUT, V3, P323, DOI 10.1109/T-AFFC.2012.11
   Huang ZC, 2017, INTERSPEECH, P3301, DOI 10.21437/Interspeech.2017-1707
   Huang ZC, 2015, INT CONF AFFECT, P733, DOI 10.1109/ACII.2015.7344650
   Hupont I., 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P2045, DOI 10.1109/ICSMC.2010.5641717
   Hutto DD, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01217
   Izard C.E., 1991, PSYCHOL EMOTIONS
   Jenke R, 2018, COGN SYST RES, V49, P128, DOI 10.1016/j.cogsys.2018.01.004
   Jin J, 1996, COMPUTATION SPECIAL
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Karg Michelle, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P238, DOI 10.1109/ROMAN.2009.5326288
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Kipp M., 2001, Proceedings of the European Conference on Speech Communication and Technology, P1367
   Kirkland T, 2012, EMOTION, V12, P268, DOI 10.1037/a0024218
   Krumhuber EG, 2021, BEHAV RES METHODS, V53, P686, DOI 10.3758/s13428-020-01443-y
   Kuiper NH., 1960, NEDERL AKAD WETENS A, V63, P38, DOI DOI 10.1016/S1385-7258(60)50006-0
   Kuppens P, 2017, CURR OPIN PSYCHOL, V17, P22, DOI 10.1016/j.copsyc.2017.06.004
   Mahoor MH, 2009, PROC CVPR IEEE, P833
   MARDIA KV, 1975, J R STAT SOC B, V37, P349
   Mariooryad S, 2012, IEEE IMAGE PROC, P2605, DOI 10.1109/ICIP.2012.6467432
   Martinez AM, 2017, SPRING SER CHALLENGE, P183, DOI 10.1007/978-3-319-57021-1_6
   Martins P, 2009, IEEE IMAGE PROC, P3341, DOI 10.1109/ICIP.2009.5413914
   Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165
   Nguyen D, 2017, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2017.140
   Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005
   Oravecz Z, 2011, PSYCHOL METHODS, V16, P468, DOI 10.1037/a0024375
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Picard RW, 2002, INTERACT COMPUT, V14, P141, DOI 10.1016/S0953-5438(01)00055-8
   Qian B, 2004, 1 IASTED INT C FIN E, P203
   Résibois M, 2018, COGNITION EMOTION, V32, P259, DOI 10.1080/02699931.2017.1298993
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer KR, 2009, PHILOS T R SOC B, V364, P3459, DOI 10.1098/rstb.2009.0141
   Schmidt KL, 2001, YEARB PHYS ANTHROPOL, V44, P3, DOI 10.1002/ajpa.20001
   Senecal S, 2016, COMPUT ANIMAT VIRT W, V27, P311, DOI 10.1002/cav.1714
   Steephen JE, 2013, IEEE T AFFECT COMPUT, V4, P197, DOI 10.1109/T-AFFC.2013.2
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Uddin M T, 2020, ARXIV201014705
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Verduyn P, 2009, COGNITION EMOTION, V23, P1427, DOI 10.1080/02699930902949031
   WATSON GS, 1961, BIOMETRIKA, V48, P109, DOI 10.2307/2333135
   Whissell C. M., 1989, The Measurement of Emotions, P113, DOI 10.1016/B978-0-12-558704-4.50011-6
   Wöllmer M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2362
   Yik M, 2011, EMOTION, V11, P705, DOI 10.1037/a0023980
   Zhang CS, 2017, J SYST ENG ELECTRON, V28, P784, DOI 10.21629/JSEE.2017.04.18
   Zhou GT, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P412
NR 76
TC 0
Z9 0
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21111
EP 21133
DI 10.1007/s11042-022-12490-2
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500002
DA 2024-07-18
ER

PT J
AU Trivedi, VK
   Shukla, PK
   Pandey, A
AF Trivedi, Vijay Kumar
   Shukla, Piyush Kumar
   Pandey, Anjana
TI Automatic segmentation of plant leaves disease using min-max hue
   histogram and k-mean clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast stretching; Fuzzy filter; Hue histogram; HSI color model;
   K-mean clustering; Segmentation
ID IMAGE-ENHANCEMENT; RECOGNITION; SUPERPIXEL; ALGORITHMS
AB Automatic segmentation of plant image's leaf diseases has recently become a popular area of study worldwide. The suggested approach automatically segments various areas of leaf disease from images of the plant, which can then be combined with machine learning or deep learning techniques to improve system accuracy. Our suggested method consists of three stages: Preprocessing is applied in the first stage where a rank order fuzzy (ROF) filter is proposed that reduces the background noise from the plant picture. In the next stage, disease spot detection is performed using proposed min-max hue histogram based techniques. Disease spot identification prior to segmentation helps in proper segmentation of k-mean clustering. The K-means clustering is then performed in the next stage to segment the leaf pictures into uniform regions. These segments are transformed into HSI color spaces and the segment with the largest hue value is extracted as the disease segment. The proposed methodology is implemented in Matlab 18a and studies are carried out on various plant images. The proposed ROF filter demonstrates superior results to the other state-of-the-art filters. The filter is also resistant to very large noise levels, and shows meaningful details at noise levels of 95%. Besides, our hue-based spot detection is compared with the existing method and it can be shown by the suggested approach, the diseases have been found mostly correctly. The segmentation accuracy of the proposed method is calculated using the Jaccard coefficient, Sensitivity and Positive Prediction Rate. Our proposed system achieved high Jaccard coefficient value of 0.7747.
C1 [Trivedi, Vijay Kumar; Shukla, Piyush Kumar] UIT RGPV, DoCSE, Bhopal, India.
   [Pandey, Anjana] UIT RGPV, SoIT, Bhopal, India.
C3 Rajiv Gandhi Technological University; Rajiv Gandhi Technological
   University
RP Trivedi, VK (corresponding author), UIT RGPV, DoCSE, Bhopal, India.
EM vkt911@gmail.com
RI Shukla, Dr. Piyush Kumar/GVT-3949-2022; user, user/GLQ-6797-2022
OI Shukla, Dr. Piyush Kumar/0000-0002-3715-3882; Trivedi,
   Vijay/0000-0001-5856-8991
CR Al Bashish D., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P113, DOI 10.1109/ICSIP.2010.5697452
   [Anonymous], 2012, PLANT SCI REV
   [Anonymous], 2012, INT J ADV RES COMPUT
   Archana KS, 2018, Int JEngTechnol, V7, P182, DOI [10.14419/ijet.v7i3.27.17756, DOI 10.14419/IJET.V7I3.27.17756]
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Bashir S., 2012, IOSR J Electron Commun Eng, V2, P31, DOI [10.9790/2834-0263134, DOI 10.9790/2834-0263134]
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Bora Dibya Jyoti, 2015, INT J EMERGING TECHN, V5
   Camargo A, 2009, BIOSYST ENG, V102, P9, DOI 10.1016/j.biosystemseng.2008.09.030
   Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755
   Chitade A, 2010, INT J ENG SCI TECHNO
   Devi R, INT J ENG TECHNOLOGY, V7, P206, DOI 10.14419/ijet.v7i1.1.9456
   Dhaware C. G., 2017, 2017 INT C COMP COMM, P1
   El Sghair M., 2017, INT J AGR SCI, V2, P1
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Goncharov P., 2018, ARCHITECTURE BASIC P
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Inbarani HH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010188
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Jayanthi MGS, 2020, J INTELL SYST, V29, P35, DOI 10.1515/jisys-2017-0415
   Khandelwal Ines, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P295, DOI 10.1007/978-981-13-1135-2_23
   Li J, 2018, CHIN CONTR CONF, P9159, DOI 10.23919/ChiCC.2018.8482813
   Mahlein AK, 2016, PLANT DIS, V100, P241, DOI 10.1094/PDIS-03-15-0340-FE
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mokhtar NR, 2009, LECT NOTES ENG COMP, P807
   Naik SK, 2003, IEEE T IMAGE PROCESS, V12, P1591, DOI 10.1109/TIP.2003.819231
   Nayagam A., 2018, IJARCCE, V7, P87, DOI [10.17148/IJARCCE.2018.71118, DOI 10.17148/IJARCCE.2018.71118]
   Nikam SD, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P1323, DOI 10.1109/IIC.2015.7150953
   Pathak SS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING AND TECHNOLOGY (ICETECH), P163
   Pertot I, 2012, COMPUT ELECTRON AGR, V84, P144, DOI 10.1016/j.compag.2012.02.014
   Piyush Chaudhary., 2012, Int Comput Sci Telecommun, V3
   Purushothaman J., 2016, IEEE C
   Rundo L, 2018, SMART INNOV SYST TEC, V69, P23, DOI 10.1007/978-3-319-56904-8_3
   Saravanan G, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P462, DOI 10.1109/ICCSP.2016.7754179
   Savary S, 2006, ANNU REV PHYTOPATHOL, V44, P89, DOI 10.1146/annurev.phyto.44.070505.143342
   Shrivastava S, 2016, MULTIMED TOOLS APPL
   Singh V, 2017, INF PROCESS AGR
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Thailambal G., 2020, EUR J MOL CLIN MED, V7, P5447
   Thangaraj V, 2012, WSEAS T SIGNAL PROCE, P8
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   Trivedi Vijay Kumar, 2020, IET Conference Proceedings, V2020, DOI 10.1049/icp.2021.0953
   Utaminingrum F, 2013, KOR-JPN JT WORKS FR, P11, DOI 10.1109/FCV.2013.6485451
   Zhang SW, 2019, NEURAL COMPUT APPL, V31, P1225, DOI 10.1007/s00521-017-3067-8
   Zhang SW, 2018, OPTIK, V157, P866, DOI 10.1016/j.ijleo.2017.11.190
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
NR 47
TC 15
Z9 17
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20201
EP 20228
DI 10.1007/s11042-022-12518-7
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600013
DA 2024-07-18
ER

PT J
AU Dida, H
   Charif, F
   Benchabane, A
AF Dida, Hedifa
   Charif, Fella
   Benchabane, Abderrazak
TI Registration of computed tomography images of a lung infected with
   COVID-19 based in the new meta-heuristic algorithm HPSGWO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Computed tomography; Ground-glass opacity; Particle swarm
   optimization; Grey wolf optimizer; Image registration
ID CHEST CT; FILTER
AB Computed tomography (CT) helps the radiologist in the rapid and correct detection of a person infected with the coronavirus disease 2019 (COVID-19), and this by showing the presence of the ground-glass opacity in the lung of with the virus. Tracking the evolution of the spread of the ground-glass opacity (GGO) in the lung of the person infected with the virus needs to study more than one image in different times. The various CT images must be registration to identify the evolution of the ground glass in the lung and to facilitate the study and identification of the virus. Due to the process of registration images is essentially an improvement problem, we present in this paper a new HPSGWO algorithm for registration CT images of a lung infected with the COVID-19. This algorithm is a hybridization of the two algorithms Particle swarm optimization (PSO) and Grey wolf optimizer (GWO). The simulation results obtained after applying the algorithm to the test images show that the proposed approach achieved high-precision and robust registration compared to other methods such as GWO, PSO, Firefly Algorithm (FA), and Crow Searcha Algorithms (CSA).
C1 [Dida, Hedifa; Charif, Fella; Benchabane, Abderrazak] Kasdi Merbah Univ, Fac New Informat & Commun Technol, Dept Elect & Telecommun, Ouargla, Algeria.
C3 Universite Kasdi Merbah Ouargla
RP Dida, H (corresponding author), Kasdi Merbah Univ, Fac New Informat & Commun Technol, Dept Elect & Telecommun, Ouargla, Algeria.
EM dida.hedifa@univ-ouargla.dz
RI BENCHABANE, Abderrazak/Y-8297-2019; Charif, Fella/ABD-6988-2020
OI BENCHABANE, Abderrazak/0000-0001-8436-5805; Charif,
   Fella/0000-0002-3601-6077
CR Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Altabeeb AM, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105728
   Anter AM, 2019, EXPERT SYST APPL, V118, P340, DOI 10.1016/j.eswa.2018.10.009
   Ball AK, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106438
   Bashiri FS, 2019, MULTIMODAL MED IMAGE, P12, DOI [10.3390/jimaging5010005, DOI 10.3390/JIMAGING5010005]
   Bavirisetti DP, 2017, INT J IMAG SYST TECH, V27, P227, DOI 10.1002/ima.22228
   Bennis F, 2020, MODEL OPTIM SCI TECH, V16, P1, DOI 10.1007/978-3-030-26458-1
   Bozorg-Haddad O., 2018, STUDIES COMPUTATIONA
   Cai JH, 2020, IEEE ACCESS, V8, P88200, DOI 10.1109/ACCESS.2020.2992903
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Chung MS, 2020, EUR RADIOL, V30, P2182, DOI [10.1148/radiol.2020200230, 10.1007/s00330-019-06574-1]
   Dida H, 2020, 4 INT C INT COMP DAT, V1, P0, DOI 10.1109/ICDS50568.2020.9268771
   Dong JY, 2018, INFORM SCIENCES, V423, P66, DOI 10.1016/j.ins.2017.09.059
   Du K.L., 2016, SEARCH OPTIMIZATION, DOI DOI 10.1007/978-3-319-41192-7
   Ferrante E, 2017, MED IMAGE ANAL, V39, P101, DOI 10.1016/j.media.2017.04.010
   Goshtasby. AA, 2003, 2 D 3 D IMAGE REGIST, DOI 10.16309/j.cnki.issn.1007-1776.03.004
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Hussien AG, 2020, IEEE ACCESS, V8, P173548, DOI 10.1109/ACCESS.2020.3024108
   Kaveh A., 2019, METAHEURISTICS OUTLI, V1st, DOI DOI 10.1007/978-3-030-04067-3
   Kearney V, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada66
   Khalilpourazari S, 2020, NEURAL COMPUT APPL, V32, P7725, DOI 10.1007/s00521-019-04530-0
   Li Y, 2020, AM J ROENTGENOL, V214, P1280, DOI 10.2214/AJR.20.22954
   Majhi SK, 2020, EVOL INTELL, V13, P345, DOI 10.1007/s12065-019-00294-7
   Mungmungpuntipantip R, 2020, AM J ROENTGENOL, V215, pW13, DOI 10.2214/AJR.20.23141
   Ozdemir G, 2019, ARTIF INTELL REV, V52, P1629, DOI 10.1007/s10462-017-9595-x
   Prithi S, 2021, WIRELESS PERS COMMUN, V117, P545, DOI 10.1007/s11277-020-07882-2
   Saha SK, 2019, BIOMED SIGNAL PROCES, V47, P288, DOI 10.1016/j.bspc.2018.08.034
   Senel FA, 2019, ENG COMPUT-GERMANY, V35, P1359, DOI 10.1007/s00366-018-0668-5
   Shekhawat S, 2020, ISA T, V99, P210, DOI 10.1016/j.isatra.2019.09.004
   Tu Q, 2019, APPL SOFT COMPUT, V76, P16, DOI 10.1016/j.asoc.2018.11.047
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Wang F, 2021, SWARM EVOL COMPUT, V60, DOI 10.1016/j.swevo.2020.100808
   Wang MN, 2019, J MED BIOL ENG, V39, P1, DOI 10.1007/s40846-018-0390-1
   Wang WC, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113216
   Wu JR, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113340
   Wu S, 2020, ALIGN MULTIMODAL LUM
   Yin XR, 2019, IEEE T MED IMAGING, V38, P2903, DOI 10.1109/TMI.2019.2917258
   Yin ZL, 2020, AM J ROENTGENOL, V215, P1065, DOI 10.2214/AJR.20.23214
   Zhou M, 2017, DEFECT DETECTION PRI, P1
NR 42
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18955
EP 18976
DI 10.1007/s11042-022-12658-w
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000767089800005
PM 35287378
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mohapatra, A
   Thota, N
   Prakasam, P
AF Mohapatra, Asutosh
   Thota, Nithin
   Prakasam, P.
TI Fake news detection and classification using hybrid BiLSTM and
   self-attention model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Deep learning; BiLSTM; Self-attention; Word embedding
AB Living in the twenty-first century, from shopping to reading news articles everything has changed, everything has become online. Anyone can access most of everything with a single touch from a cell phone. Internet is the new normal, everyone is very much attached to it. Reading news online is something very common among people of all age groups, thousands of articles are being published on various online media portals online every hour. These articles are not necessarily genuine always, sometimes false information is written knowingly and sometimes knowingly. It is very much needed to keep these articles away from the users. Many kinds of research have been conducted using traditional mathematical models and sequential neural networks to detect this fraud news online. In most of these studies, the news is being analysed in a unidirectional way. Therefore, a need of changing current mechanisms is required to increases the accuracy of false news detection. In this paper, we propose a Bi-LSTM based (Bidirectional long short term memory) deep learning approach by adding self-attention on top of it. This helps in developing a higher clarity, which is the most challenging part of the deep learning paradigm. The classification result demonstrated that the proposed hybrid deep learning model outperforms existing models with an accuracy score of 98.65%.
C1 [Mohapatra, Asutosh; Thota, Nithin; Prakasam, P.] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Prakasam, P (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM asutosh.mohapatra79@gmail.com; thota.nithin2017@vitstudent.ac.in;
   pralcasamp@gmail.com
RI P, Prakasam/B-3075-2016; p, p/JED-5004-2023
OI P, Prakasam/0000-0002-2471-6375; 
CR Agarwal A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1178, DOI [10.1109/ICICCS48265.2020.9121030, 10.1109/iciccs48265.2020.9121030]
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Ajao O, 2018, SMSOCIETY'18: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON SOCIAL MEDIA AND SOCIETY, P226, DOI 10.1145/3217804.3217917
   Al-Zaman MS, 2021, JOURNAL MEDIA, V2, P100, DOI 10.3390/journalmedia2010007
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], 2010, MPLUS TECHNICAL APPE
   Aslam N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5557784
   Berinsky AJ, 2017, BRIT J POLIT SCI, V47, P241, DOI 10.1017/S0007123415000186
   Bhutani B, 2019, 2019 12 INT C CONT C, P1, DOI DOI 10.1109/IC3.2019.8844880
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Celliers Marlie, 2020, Responsible Design, Implementation and Use of Information and Communication Technology. 19th IFIP WG 6.11 Conference on e-Business, e-Services, and e-Society, I3E 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12067), P223, DOI 10.1007/978-3-030-45002-1_19
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/pra2.2015.145052010082
   Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Gorrell G., 2019, P 13 INT WORKSH SEM, P845, DOI [DOI 10.18653/V1/S19-2147, 10.18653/v1/S19-2147]
   Gundapu S, 2021, ARXIV PREPRINT ARXIV
   Hiramath Chaitra K., 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P411, DOI 10.1109/ICAIT47043.2019.8987258
   Islam MR, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00696-x
   Jang SM, 2018, COMPUT HUM BEHAV, V80, P295, DOI 10.1016/j.chb.2017.11.034
   Kaliyar RohitKumar., 2018, 4 INT C COMPUTING CO, P1, DOI 10.1109/CCAA.2018.8777343
   Kulkarni Prasad, 2021, ITM Web of Conferences, V40, DOI 10.1051/itmconf/20214003003
   Kumar S., 2018, CLIMATE SMART AGR PO
   Kyriakides G, 2019, ARXIV200511074
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Li YZ, 2017, ADV NEUR IN, V30
   Nasir J.A., 2021, International Journal of Information Management Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Pennycook G, 2020, J PERS, V88, P185, DOI 10.1111/jopy.12476
   Qawasmeh E, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P383, DOI [10.1109/SNAMS.2019.8931873, 10.1109/snams.2019.8931873]
   Qi Y., 2018, HLT NAACL, P529, DOI 10.18653/v1/N18-2084
   Reddy Prannay, 2019, J ADV RES DYNAMICAL, V1, P942
   Saikh T., 2019, P 16 INT C NAT LANG, P230, DOI DOI 10.48550/ARXIV.2005.04938
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 37
TC 12
Z9 13
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18503
EP 18519
DI 10.1007/s11042-022-12764-9
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800001
DA 2024-07-18
ER

PT J
AU Fu, JY
   Gan, ZH
   Chai, XL
   Lu, Y
AF Fu, Jiangyu
   Gan, Zhihua
   Chai, Xiuli
   Lu, Yang
TI Cloud-decryption-assisted image compression and encryption based on
   compressed sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Cloud; Image compression and encryption schemes;
   Double random phase encoding
ID CHAOTIC SYSTEM; ALGORITHM; SCHEME; SECURE
AB In this paper, we propose a new image compression and encryption scheme (ICES) based on compressed sensing (CS) and double random phase encoding (DRPE), as well as a joint decryption on the cloud and user side. In the encryption, the plain image is firstly decomposed into approximate component and detail components by discrete wavelet transform (DWT), then the approximate component is scrambled, and detail components are compressed using a measurement matrix constructed by the Logistic-tent system. Secondly, the scrambled approximate component and compressed detail components are combined into a complex matrix, and then it is subjected to DRPE to get the amplitude and phase matrices. Subsequently, the resulting matrices are performed random pixel scrambling and diffusion to obtain the final cipher image. During the decryption, the cipher image is first partially decrypted on the cloud, and then fully decrypted to recover the original image on the user side, and we can judge whether the cloud has cheated us by comparing the contour similarity between the approximate component and the detail component returned by the cloud to the user, which not only significantly shortens the decryption time, but also effectively prevents malicious deception of the cloud. Experimental results and performance analyses demonstrate its effectiveness and efficiency.
C1 [Fu, Jiangyu; Chai, Xiuli; Lu, Yang] Henan Univ, Sch Artificial Intelligence, Kaifeng 475004, Peoples R China.
   [Gan, Zhihua] Henan Univ, Intelligent Data Proc Engn Res Ctr Henan Prov, Sch Software, Inst Intelligent Network Syst, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli; Lu, Yang] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Henan University
RP Lu, Y (corresponding author), Henan Univ, Sch Artificial Intelligence, Kaifeng 475004, Peoples R China.; Gan, ZH (corresponding author), Henan Univ, Intelligent Data Proc Engn Res Ctr Henan Prov, Sch Software, Inst Intelligent Network Syst, Kaifeng 475004, Peoples R China.; Lu, Y (corresponding author), Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
EM gzh@henu.edu.cn; lyhenu@126.com
OI gan, zhihua/0000-0002-1138-1887
FU National Natural Science Foundation of China [61802111, 61872125,
   61871175]; Science and Technology Foundation of Henan Province of China
   [182102210027, 182102410051]; China Postdoctoral Science Foundation
   [2018 T110723]; Key Scientific Research Projects for Colleges and
   Universities of Henan Province [19A413001]; Natural Science Foundation
   of Henan Province [182300410164]; Graduate Education Innovation and
   Quality Improvement Project of Henan University [SYL18020105]; Henan
   Higher Education Teaching Reform Research and Practice Project (Graduate
   Education) [2019SJGLX080Y]; Key Science and Technology Project of Henan
   Province [201300210400, 212102210094]
FX All the authors are deeply grateful to the editors for smooth and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. This work is supported by the National Natural Science
   Foundation of China (Grant No. 61802111, 61872125, 61871175), Science
   and Technology Foundation of Henan Province of China (Grant No.
   182102210027, 182102410051), China Postdoctoral Science Foundation
   (Grant No. 2018 T110723), Key Scientific Research Projects for Colleges
   and Universities of Henan Province (Grant No. 19A413001), Natural
   Science Foundation of Henan Province (Grant No. 182300410164), Graduate
   Education Innovation and Quality Improvement Project of Henan University
   (Grant No. SYL18020105), Henan Higher Education Teaching Reform Research
   and Practice Project (Graduate Education) (Grant No. 2019SJGLX080Y), and
   the Key Science and Technology Project of Henan Province (Grant No.
   201300210400, 212102210094).
CR Anand A, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P159, DOI 10.1109/ICICCS.2016.7542294
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P31581, DOI 10.1007/s11042-018-6112-4
   Candès EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x
   Chai XL, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108041
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P8065, DOI 10.1007/s00521-019-04312-8
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chen JX, 2019, NONLINEAR DYNAM, V96, P301, DOI 10.1007/s11071-019-04791-3
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen MJ, 2019, J MOD OPTIC, V66, P1416, DOI 10.1080/09500340.2019.1628316
   Chen TG, 2016, OPT LASER TECHNOL, V84, P118, DOI 10.1016/j.optlastec.2016.05.012
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Gong LH, 2018, OPT LASER TECHNOL, V103, P48, DOI 10.1016/j.optlastec.2018.01.007
   Hu GQ, 2017, INFORM SCIENCES, V387, P132, DOI 10.1016/j.ins.2016.09.045
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Jha DP, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P86, DOI 10.1109/ICICCS.2016.7542316
   Khedr WI, 2020, MULTIMED TOOLS APPL, V79, P16797, DOI 10.1007/s11042-019-7235-y
   Li LL, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2919576
   Liang YR, 2020, INT J AUTOM COMPUT, V17, P292, DOI 10.1007/s11633-018-1159-2
   Liu L, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010082
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Ma S, 2019, IEEE ACCESS, V7, P30344, DOI 10.1109/ACCESS.2019.2901302
   Pan C, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/6572105
   Patel U, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960227
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P11857, DOI 10.1007/s11042-018-6745-3
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Song YJ, 2019, NONLINEAR DYNAM, V95, P2235, DOI 10.1007/s11071-018-4689-9
   Telem ANK, 2021, MULTIMED TOOLS APPL, V80, P19011, DOI 10.1007/s11042-021-10549-0
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Weber A., 1997, The usc-sipi image database
   Xian YJ, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106202
   Xie YQ, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090819
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Yang FF, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107373
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang H, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115829
   Zhang R, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720912949
   Zhang Y, 2020, INFORM SCIENCES, V526, P180, DOI 10.1016/j.ins.2020.03.054
   Zhang YS, 2021, IEEE T IND INFORM, V17, P3401, DOI 10.1109/TII.2020.3008914
   Zhang YS, 2020, IEEE T IND INFORM, V16, P7566, DOI 10.1109/TII.2019.2957404
   Zhang YS, 2020, IEEE T IND INFORM, V16, P6641, DOI 10.1109/TII.2020.2966511
   Zhang YS, 2019, INFORM SCIENCES, V496, P150, DOI 10.1016/j.ins.2019.05.024
   Zhang YS, 2018, IEEE INTERNET THINGS, V5, P3442, DOI 10.1109/JIOT.2017.2781737
   Zhang YS, 2017, IEEE INTERNET THINGS, V4, P1380, DOI 10.1109/JIOT.2017.2732357
   Zhang Z, 2020, MULTIMED TOOLS APPL, V79, P14777, DOI 10.1007/s11042-018-7062-6
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
NR 59
TC 7
Z9 8
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17401
EP 17436
DI 10.1007/s11042-022-12607-7
EA MAR 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900023
DA 2024-07-18
ER

PT J
AU Kumar, HSS
   Karibasappa, K
AF Kumar, Santhosh H. S.
   Karibasappa, K.
TI An effective hybrid deep learning with adaptive search and rescue for
   brain tumor detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor detection; Deep learning; Classification; Segmentation;
   Feature extraction; Feature selection
ID CONVOLUTIONAL NEURAL-NETWORK; FEATURES; FUSION; ALGORITHM
AB Medical image processing is a challenging and complex field. Moreover, the brain tumor is one of the significant factors for death in human beings. Therefore, detection of brain tumor at the initial stage is very essential. In this paper, a hybrid deep belief neural network with adaptive search and rescue algorithm (DBN-ASAR) is proposed to classify the tumor images and the normal images from the MRI brain images. Pre-processing is the initial process, in which the Fuzzy based Fast averaging peer group (FFAPG) filtering approach is proposed to eliminate the impulsive noises from the MRI brain images. In features extraction, discrete wavelet transform with Gabor filter (DWT-GF) is used to extract the texture and shape features from the images effectively. From these extracted features, only the optimal features are selected to decrease the dimensionality. Hybrid feature selection approach is proposed to obtain the optimal features and dimensionality reduction. Next phase is the classification, in which the selected features are trained using deep belief network (DBN). Adaptive search and rescue (ASAR) algorithm is combined with DBN model to obtain the optimal classification solution; thus the normal and tumor images are classified. From the classified images, only the tumor images are fed as input for the segmentation process. Using threshold with tree growth algorithm (TTGA), the tumor region is detected effectively from the tumor images. MATLAB tool is used for the experimentation of proposed model. Figshare, BRATS 2013, 2015 and 2018 datasets are utilized for the evaluation of proposed work. Accuracy, precision, sensitivity, F-measure, specificity, DSC, NPV and FPR are the performance metrics considered to evaluate the efficiency of the proposed approach. The simulation results proved that the performance of the proposed method is better than the state-of-the-art methods.
C1 [Kumar, Santhosh H. S.] NTT Data Canada, Halifax, NS, Canada.
   [Karibasappa, K.] Graph Era Deemed Be Univ, Dehra Dun 248002, Uttarakhand, India.
C3 Graphic Era University
RP Kumar, HSS (corresponding author), NTT Data Canada, Halifax, NS, Canada.
EM santhosh043@gmail.com; KwadikiKaibasappa.cse@geu.ac.in
CR Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   Amin J, 2020, PATTERN RECOGN LETT, V129, P115, DOI 10.1016/j.patrec.2019.11.016
   Amin J, 2020, COGN SYST RES, V59, P304, DOI 10.1016/j.cogsys.2019.10.002
   Arnal J, 2020, INT J FUZZY SYST, V22, P2599, DOI 10.1007/s40815-020-00953-3
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Casini L., 2020, SPRINGERBRIEFS ETHIC
   Chandra SK, 2020, MULTIMED TOOLS APPL, V79, P2653, DOI 10.1007/s11042-019-08374-7
   Chaudhary Atish, 2020, International Journal of Information Technology, V12, P141, DOI 10.1007/s41870-018-0255-4
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Cheraghalipour A, 2018, ENG APPL ARTIF INTEL, V72, P393, DOI 10.1016/j.engappai.2018.04.021
   Deb D, 2021, MULTIMED TOOLS APPL, V80, P2621, DOI 10.1007/s11042-020-09810-9
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Han C, 2020, SMART INNOV SYST TEC, V151, P291, DOI 10.1007/978-981-13-8950-4_27
   Harifi S, 2019, EVOL INTELL, V12, P211, DOI 10.1007/s12065-019-00212-x
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Kalagy T, 2020, INT REV PSYCHIATR, V32, P685, DOI 10.1080/09540261.2020.1803219
   Kalpana R, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102903
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Kaur G, 2020, ADV INTELL SYST, V1042, P451, DOI 10.1007/978-981-32-9949-8_31
   Khan H, 2020, COMPUT COMMUN, V153, P196, DOI 10.1016/j.comcom.2020.01.013
   Kumar DM, 2021, J AMB INTEL HUM COMP, V12, P2867, DOI 10.1007/s12652-020-02444-7
   Kumar GA, 2021, MULTIMED TOOLS APPL, V80, P19715, DOI 10.1007/s11042-020-08760-6
   Lahmiri Salim, 2013, Journal of Medical Engineering, DOI 10.1155/2013/104684
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Preethi S, 2021, MULTIMED TOOLS APPL, V80, P14789, DOI 10.1007/s11042-021-10538-3
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Shabani A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/2482543
   Sharif M, 2020, NEURAL COMPUT APPL, V32, P15975, DOI 10.1007/s00521-019-04679-8
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Sharif M, 2020, COGN SYST RES, V59, P273, DOI 10.1016/j.cogsys.2019.10.001
   Sharma M., 2020, DEEP LEARNING TECHNI, P347
   Shen LZ, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101953
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Vijh S, 2020, LECT NOTE DATA ENG, V32, P171, DOI 10.1007/978-3-030-25797-2_8
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Yin B, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101728
   Zhang JJ, 2021, NEUROCOMPUTING, V421, P195
NR 42
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17669
EP 17701
DI 10.1007/s11042-022-12474-2
EA MAR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900009
DA 2024-07-18
ER

PT J
AU Qin, XF
   Guo, HY
   He, CX
   Zhang, XD
AF Qin, Xiaofei
   Guo, Haiyang
   He, Changxiang
   Zhang, Xuedian
TI Lightweight human pose estimation: CVC-net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Lightweight; Cost-effective; Channel attention
ID MODELS
AB Most of existing methods in the field of Human Pose Estimation take high accuracy as main research goal, however, reducing model complexity and improving detection speed are also very important for Human Pose Estimation, especially when running on edge devices with weak computing capability. The core motivation of this article is to reduce the model size of original Human Pose Estimation network while maintaining its performance. To achieve this goal, we present a lightweight Human Pose Estimation network for RGB image input. The network follows Stacked Hourglass network architecture and it is named Capable and Vigorous Campstool Network (CVC-Net). Specifically: 1. In order to reduce the number of model parameters, we proposed a new residual block named Res2Net_depth block, and used it to replace the residual blocks in Hourglass network. 2. We used three techniques to further improve model performance, namely channel attention mechanism, PixelShuffle up-sampling method and a newly designed Cross-Stage Heatmap Fusion method. 3. In coordinate regression step, we adopted Differentiable Spatial to Numerical Transform model combined with Euclidean distance loss, so that the model can be trained end-to-end. We evaluated the CVC-Net on widely-used datasets of different scales, e.g., LSP, MPII and COCO. In Single-Person Pose Estimation tasks, CVC-Net achieved 93.4% in PCK@0.2 score on LSP test set, and 91.6% in PCKh@0.5 score on MPII test set, with only about 4.2 M parameters. In Multi-Person Pose Estimation task, the combination of YOLOv3 and CVC-Net obtained 69.4mAP on COCO test-dev, and inference speed reached 22 FPS on a GTX1660Ti GPU machine. The experimental results showed that CVC-Net can greatly reduce the number of model parameters while ensuring quite high accuracy.
C1 [Qin, Xiaofei; Zhang, Xuedian] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Qin, Xiaofei; Zhang, Xuedian] Shanghai Key Lab Contemporary Opt Syst, Shanghai 200093, Peoples R China.
   [Qin, Xiaofei; Zhang, Xuedian] Minist Educ, Key Lab Biomed Opt Technol & Devices, Shanghai 200093, Peoples R China.
   [Guo, Haiyang] Univ Shanghai Sci & Technol, Sch Mech Engn, Shanghai 200093, Peoples R China.
   [He, Changxiang] Univ Shanghai Sci & Technol, Coll Sci, Shanghai 200093, Peoples R China.
   [Zhang, Xuedian] Tongji Univ, Shanghai Inst Intelligent Sci & Technol, Shanghai 200092, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; University of Shanghai for Science &
   Technology; Tongji University
RP Zhang, XD (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.; Zhang, XD (corresponding author), Shanghai Key Lab Contemporary Opt Syst, Shanghai 200093, Peoples R China.; Zhang, XD (corresponding author), Minist Educ, Key Lab Biomed Opt Technol & Devices, Shanghai 200093, Peoples R China.; Zhang, XD (corresponding author), Tongji Univ, Shanghai Inst Intelligent Sci & Technol, Shanghai 200092, Peoples R China.
EM obmmd_zxd@163.com
FU Artificial Intelligence Program of Shanghai [2019-RGZN-01077]
FX Artificial Intelligence Program of Shanghai [grant numbers
   2019-RGZN-01077].
CR Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen YH, 2017, AIP CONF PROC, V1812, DOI [10.1063/1.4975898, 10.1109/ICCV.2017.137]
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Chu X., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1831, DOI DOI 10.1109/CVPR.2017.601
   Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gao S, 2019, ABS190401169V2 CORR
   Garg D., 2018, MULTIMED TOOLS APPL, V77, P1
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Kocabas M, 2018, LECT NOTES COMPUT SC, V11215, P437, DOI 10.1007/978-3-030-01252-6_26
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li W, 2019, ABS190100148V4 CORR
   Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16
   Lin YH, 2019, PROC CVPR IEEE, P9109, DOI 10.1109/CVPR.2019.00933
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nalepa J, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102994
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nibali A., 2018, CORR
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Nie XC, 2018, PROC CVPR IEEE, P2100, DOI 10.1109/CVPR.2018.00224
   Ning G, 2017, ABS170502407V2 CORR
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J, 2018, ABS180402767V1 CORR
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sahu P, 2019, IEEE J BIOMED HEALTH, V23, P960, DOI 10.1109/JBHI.2018.2879834
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun K, 2017, IEEE I CONF COMP VIS, P5600, DOI 10.1109/ICCV.2017.597
   Tang ZQ, 2018, LECT NOTES COMPUT SC, V11207, P348, DOI 10.1007/978-3-030-01219-9_21
   Tarasiewicz T, 2020, IEEE IMAGE PROC, P2386, DOI 10.1109/ICIP40778.2020.9191209
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang Y., 2011, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, page, V1385-1392, P2011, DOI DOI 10.1109/CVPR.2011.5995741
   Zhang F, 2019, PROC CVPR IEEE, P3512, DOI 10.1109/CVPR.2019.00363
   Zhang H, 2019, ABS190101760 CORR
   Zhang Z., 2019, ABS191110346V2 CORR
NR 67
TC 6
Z9 8
U1 9
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17615
EP 17637
DI 10.1007/s11042-022-12245-z
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900021
DA 2024-07-18
ER

PT J
AU Yi, ZR
   Yao, DY
   Li, GJ
   Ai, JY
   Xie, W
AF Yi, Zeren
   Yao, Dongyi
   Li, Guojin
   Ai, Jiaoyan
   Xie, Wei
TI Detection and localization for lake floating objects based on CA-faster
   R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection; Localization; CA network; Faster R-CNN; Floating objects
ID NETWORKS
AB As a general trend, unmanned ships have been gradually replacing humans and served as the cleaner of lakes. To work properly, those unmanned ships need to detect and localize lake floating objects that need to be collected. Compared to conventional image-based objects, lake floating objects are too small to detect. Meanwhile, because most conventional algorithms depend on bounding-boxes to detect the object, their results - it is hard to detect the accurate location of floating objects. To this end, this paper proposes a detection and localization algorithm based on CA-Faster R-CNN (Class Activation-Faster Regions with Convolutional Neural Network). Specifically, for an image with objects on it, the proposed algorithm detects and classifies objects with Faster R-CNN and localize objects with CA network. The experimental results show that, compared with the Faster R-CNN algorithm, this algorithm can reduce the positioning error without affecting the recognition accuracy, thereby can be used for the detection and localization of floating objects on the water surface. Compared with Faster R-CNN algorithm, the positioning accuracy of CA-Faster R-CNN algorithm is improved by 6.29 pixels. Also, the proposed algorithm remains a great potential for other objects that shared similar challenges with lake floating objects.
C1 [Yi, Zeren; Yao, Dongyi; Li, Guojin; Ai, Jiaoyan] Guangxi Univ, Sch Elect Engn, Nanning 530004, Peoples R China.
   [Yi, Zeren; Xie, Wei] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510641, Peoples R China.
C3 Guangxi University; South China University of Technology
RP Li, GJ (corresponding author), Guangxi Univ, Sch Elect Engn, Nanning 530004, Peoples R China.
EM lgjgx@163.com
OI li, guojin/0000-0001-7464-8561
FU Guangxi Innovation-driven Development Special Project of China
   [AA17202032-2]; Key-Area Research and Development Program of Guangdong
   Province of China [2018B010108001]; Key-Area Research and Development
   Program of Foshan City [2020001006812]
FX This work was supported in part by the Guangxi Innovation-driven
   Development Special Project of China under grant no. AA17202032-2, in
   part by the Key-Area Research and Development Program of Guangdong
   Province of China under grant no. 2018B010108001, and in part by
   Key-Area Research and Development Program of Foshan City under the grant
   no. 2020001006812.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agrawal P, 2013, NATURE INSPIRED MOBILE ROBOTICS, P171
   Arcos-García A, 2018, NEUROCOMPUTING, V316, P332, DOI 10.1016/j.neucom.2018.08.009
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Dai JF, 2016, ADV NEUR IN, V29
   Deng L, 2019, ELECT TEST, P133, DOI [10.16520/j.cnki.1000-8519.2019.17.057, DOI 10.16520/J.CNKI.1000-8519.2019.17.057]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang Jing, 2017, Transactions of Beijing Institute of Technology, V37, P1235, DOI 10.15918/j.tbit1001-0645.2017.12.005
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu G, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/1214301
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li YF, 2017, J BEIJING U POSTS TE, V40, P72, DOI [10.13190/j.jbupt.2017.s.016, DOI 10.13190/J.JBUPT.2017.S.016]
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8
   Novatel, 2003, GPS POS ACC MEAS POS, P1
   Nowozin S, 2014, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2014.77
   Pan C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102138
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sharma R, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.063007
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tang W., 2019, Sci. Technol. Eng, V19, P136, DOI [10.3969/j.issn.1671-1815.2019.03.023, DOI 10.3969/J.ISSN.1671-1815.2019.03.023]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wan L, 2015, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2015.7298686
   Wang Yan-Qing, 2011, Acta Automatica Sinica, V37, P1029, DOI 10.3724/SP.J.1004.2011.01029
   Wang ZL, 2008, IEEE ASME INT C ADV, P1343, DOI 10.1109/AIM.2008.4601857
   Wei JR., 2017, SHIP SCI TECHNOL, V39, P159, DOI [10.3404/j.issn.1672-7649.2017.10A.054, DOI 10.3404/J.ISSN.1672-7649.2017.10A.054]
   [谢家兴 Xie Jiaxing], 2014, [环境工程学报, Chinese Journal of Environmental Engineering], V8, P2371
   Xue P., 2017, J XIAN U SCI TECHNOL, V37, P731, DOI [10.13800/j.cnki.xakjdxxb.2017.0520, DOI 10.13800/J.CNKI.XAKJDXXB.2017.0520]
   [杨观赐 Yang Guanci], 2018, [自动化学报, Acta Automatica Sinica], V44, P2238
   [杨柳 Yang Liu], 2016, [计算机应用与软件, Computer Applications and Software], V33, P138
   [叶晓杰 Ye Xiaojie], 2018, [激光与红外, Laser and Infrared], V48, P119
   Yildirimoglu M, 2013, TRANSPORT RES B
   [余莉 Yu Li], 2002, [计算机研究与发展, Computer Research and Development], V39, P1325
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   [朱远清 ZHU Yuanqing], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P234
NR 43
TC 8
Z9 9
U1 8
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17263
EP 17281
DI 10.1007/s11042-022-12686-6
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200008
DA 2024-07-18
ER

PT J
AU Khmag, A
AF Khmag, Asem
TI Digital image noise removal based on collaborative filtering approach
   and singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise removal; Singular value decomposition; Low-rank approximation;
   Coefficient matrix; Soft thresholding; Image restoration
ID HIDDEN MARKOV-MODELS; MATRIX; MINIMIZATION; ALGORITHM; SPARSE; SVD
AB Image denoising is a crucial step in order to improve digital image quality. Furthermore, the digital image in sparse format especially in low-rank structure has been utilized in several multimedia applications. Non-local similarity algorithm is used to increase the level of noise removal methods and improve the image visual quality due to the pivotal correlation in the image inter-patches, and intra-correlation with a low-rank prior of the texture itself where the second generation wavelet is exploited to develop a similar coefficients to the image matrix. In order to solve the burden of selected contaminated pixels in the sub-patches, the singular value shrinkage is used to guarantee the elimination of high noisy pixels. Furthermore, the proposed method uses random matrix in order to practically choose the level of singular value threshold. As the experimental results depicts, the proposed algorithm has superior performance in peak signal to noise ratio (PSNR), structural similarity index (SSIM), image quality assessment (IQA) and figure of merit (FOM) in comparison with state of the art noise removal techniques and can recover better details and less artifacts and blurring. In addition, to show the quality of complexity time of the proposed method, execution time of the proposed method and several denoising methods has been examined.
C1 [Khmag, Asem] Univ Zawia, Fac Engn, Dept Comp Syst Engn, Zawia, Libya.
RP Khmag, A (corresponding author), Univ Zawia, Fac Engn, Dept Comp Syst Engn, Zawia, Libya.
EM a.khmag@zu.edu.ly
RI Khmag, Asem/AAH-1051-2019
OI Khmag, Asem/0000-0002-1360-5346
CR Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139
   Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730
   Gao HT, 2020, MULTIMED TOOLS APPL, V79, P9657, DOI 10.1007/s11042-017-5399-x
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Huo FC, 2021, MULTIMED TOOLS APPL, V80, P14101, DOI 10.1007/s11042-020-10428-0
   Kalaiselvi, 2016, INT J APPL ENG RES, V10, P76
   Khmag A., 2018, TELKOMNIKA (Telecommun. Comput. Electron. Control), V16, P915
   Khmag A, 2018, VISUAL COMPUT, V34, P1661, DOI 10.1007/s00371-017-1439-9
   Khmag A, 2018, MULTIMED TOOLS APPL, V77, P20065, DOI 10.1007/s11042-017-5425-z
   Khmag A, 2017, VISUAL COMPUT, V33, P1141, DOI 10.1007/s00371-016-1273-5
   Khmag A, 2016, IEEJ T ELECTR ELECTR, V11, P339, DOI 10.1002/tee.22223
   Knaus C, 2013, IEEE IMAGE PROC, P440, DOI 10.1109/ICIP.2013.6738091
   Nadakuditi RR, 2014, IEEE T INFORM THEORY, V60, P3002, DOI 10.1109/TIT.2014.2311661
   Owen AB, 2009, ANN APPL STAT, V3, P564, DOI 10.1214/08-AOAS227
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Sadiq BO, 2015, ARXIV PREPRINT ARXIV
   Shabalin AA, 2013, J MULTIVARIATE ANAL, V118, P67, DOI 10.1016/j.jmva.2013.03.005
   Wang S., 2012, PROC ASI C COMPUT VI, P231
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
NR 25
TC 9
Z9 9
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16645
EP 16660
DI 10.1007/s11042-022-12774-7
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100015
DA 2024-07-18
ER

PT J
AU Rajput, SS
AF Rajput, Shyam Singh
TI Mixed Gaussian-Impulse noise robust face hallucination via noise
   suppressed low-and-high resolution space-based neighbor representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Position-patch based reconstruction; Face hallucination; Noise robust;
   Image super-resolution
ID SUPERRESOLUTION; ALGORITHM
AB An intelligent surveillance system poses a lot of challenges in the processing of captured noisy low-resolution (LR) images. To defeat such challenges, face super-resolution (SR) also called face hallucination techniques are getting prominence in recent years. Although, the present SR models are not good enough to handle the complicated noise e.g., mixed Gaussian-Impulse (MGI) noise, often present in the captured LR images. Therefore, a new MGI noise-robust face hallucination algorithm using noise suppressed low-and-high resolution space-based neighbor representation (NSLHNR) is proposed in this paper. The proposed algorithm first suppresses the effect of outliers from the SR process by overlooking them from the reconstruction weight calculation process. It assists in controlling the square reconstruction error. Further, it also accomplishes the HR space-based neighbor representation to counterbalance the losses caused due to high-density MGI noise in a relationship of input and training LR images. These additions make the proposed algorithm capable to preserve sharp edges, texture, and the individual characteristics of the input face in the output. The performance measured through the experiments performed on the benchmark datasets and surveillance images shows the better reconstruction capability of the proposed algorithm over the compared state-of-the-art models.
C1 [Rajput, Shyam Singh] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Rajput, SS (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM ershyamrajput@gmail.com
RI Rajput, Shyam Singh/AAU-4448-2020
OI Rajput, Shyam Singh/0000-0002-1244-7366
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Huang H, 2011, IEEE T CIRC SYST VID, V21, P1363, DOI 10.1109/TCSVT.2011.2163461
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jia K, 2008, IEEE T IMAGE PROCESS, V17, P873, DOI 10.1109/TIP.2008.922421
   Jiang JJ, 2017, IEEE T CYBERNETICS, V47, P3991, DOI 10.1109/TCYB.2016.2594184
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Park JS, 2008, IEEE T IMAGE PROCESS, V17, P1806, DOI 10.1109/TIP.2008.2001394
   Rajput Shyam Singh, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P252, DOI 10.1109/TBIOM.2019.2939808
   Rajput S.S., 2018, 2018 C INFORM COMMUN, P1, DOI 10.1109/IC-SEE.2018.8646265
   Rajput SS, 2020, MULTIMED TOOLS APPL, V79, P23909, DOI 10.1007/s11042-020-09072-5
   Rajput SS, 2019, MULTIMED TOOLS APPL, V78, P25407, DOI 10.1007/s11042-019-07791-y
   Rajput SS, 2019, APPL INTELL, V49, P1324, DOI 10.1007/s10489-018-1340-x
   Rajput SS, 2018, INFORM SCIENCES, V463, P227, DOI 10.1016/j.ins.2018.06.050
   Rajput SS, 2018, SIGNAL PROCESS, V147, P233, DOI 10.1016/j.sigpro.2018.01.030
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wang ZY, 2014, IEEE T CIRC SYST VID, V24, P802, DOI 10.1109/TCSVT.2013.2290574
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang J, 2008, IEEE IMAGE PROC, P1264, DOI 10.1109/ICIP.2008.4711992
   Yu X, 2018, IEEE T IMAGE PROCESS, V27, P2747, DOI 10.1109/TIP.2018.2808840
   Zhang J, 2008, IEEE INT CON AUTO SC, P1, DOI 10.1109/COASE.2008.4626431
   Zhang W, 2011, IEEE T IMAGE PROCESS, V20, P2769, DOI 10.1109/TIP.2011.2142001
   Zhu S, 2016, DEEP CASCADED BI NET
NR 42
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15997
EP 16019
DI 10.1007/s11042-022-12154-1
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000763256600010
DA 2024-07-18
ER

PT J
AU Lu, T
   Xiang, Y
   Zhang, L
   Zhang, JQ
AF Lu, Ting
   Xiang, Yan
   Zhang, Li
   Zhang, Jiqun
TI Sentence constituent-aware attention mechanism for end-to-end
   aspect-based sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentence constituent; Attention mechanism; Aspect-based sentiment
   analysis; Aspect term-polarity co-extraction; Transformer; Deep learning
AB End-to-end aspect-based sentiment analysis aims to complete aspect terms extraction and aspect sentiment classification simultaneously. Most existing methods ignore the sematic connection between the two subtasks. In this paper, we solve the problem by inducing constituents from input sentences, and propose a novel model based on sentence constituent-aware attention mechanism for end-to-end aspect-based sentiment analysis. Our framework mainly involves three layers. The first layer gets word representations by the pre-trained language model. Followed by the proposed sentence constituent-aware attention layer to induce constituents from the input sentence. With the operation of inducing constituents, the words in the same constituent are constrained to attend to each other, making the aspect term pay more attention to its corresponding opinion. Finally, a simple linear classification layer is adopted to predict the unified tags. Experimental results demonstrate that the proposed model outperforms other baselines on four benchmark datasets.
C1 [Lu, Ting; Xiang, Yan; Zhang, Li; Zhang, Jiqun] Kunming Univ Sci & Technol, Dept Informat Engn & Automat, Kunming, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology
RP Xiang, Y (corresponding author), Kunming Univ Sci & Technol, Dept Informat Engn & Automat, Kunming, Yunnan, Peoples R China.
EM 50691012@qq.com
FU National Natural Science Foundation of China [62162037]; General
   Projects of Basic Research in Yunnan Province [202001AT070047]
FX This work was supported by National Natural Science Foundation of China
   (62162037) and General Projects of Basic Research in Yunnan Province
   (202001AT070047).
CR [Anonymous], 2018, ARXIV180507889
   [Anonymous], 2017, P 2017 C EMPIRICAL M
   Bie Y, 2021, BIG DATA MIN ANAL, V4, P195, DOI 10.26599/BDMA.2021.9020003
   Chen Peng, 2017, P 2017 C EMP METH NA, P452, DOI [10.18653/v1/D17-1047, DOI 10.18653/V1/D17-1047]
   Fan FF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3433
   He RD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P504
   He RD, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P579
   He RD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P388, DOI 10.18653/v1/P17-1036
   Li K., 2020, P 58 ANN M ASS COMPU, P7056
   Li X., 2019, P 5 WORKSH NOIS US G, P34
   Li X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4194
   Li X, 2019, AAAI CONF ARTIF INTE, P6714
   Li X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P946
   Li Z, 2019, AAAI CONF ARTIF INTE, P4253
   Liang YL, 2021, NEUROCOMPUTING, V454, P291, DOI 10.1016/j.neucom.2021.05.028
   Liu LY, 2018, AAAI CONF ARTIF INTE, P5253
   Xu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3561
   Luo HS, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P591
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4068
   Mitchell M., 2013, P 2013 C EMPIRICAL M, P1643
   Rostami M, 2020, ABS200803543 CORR
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Tang D, 2016, P C EMP METH NAT LAN, P214, DOI DOI 10.18653/V1/D16-1021
   Wang BL, 2018, AAAI CONF ARTIF INTE, P5537
   Wang S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P957
   Wang XY, 2021, NEUROCOMPUTING, V455, P178, DOI 10.1016/j.neucom.2021.03.100
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Xu H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Xue W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2514
   Zhang M., 2015, P 2015 C EMP METH NA, P612, DOI [10.18653/v1/D15-1073, DOI 10.18653/V1/D15-1073, 10.18653/v1/d15-1073]
NR 31
TC 1
Z9 2
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15333
EP 15348
DI 10.1007/s11042-022-12487-x
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600021
DA 2024-07-18
ER

PT J
AU Tay, CZ
   Lim, KH
   Phang, JTS
AF Tay, Chuan Zhi
   Lim, King Hann
   Phang, Jonathan Then Sien
TI Markerless gait estimation and tracking for postural assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Gait recognition; Postural assessment; Markerless
   motion capture
AB Postural assessment is crucial in the sports screening system to reduce the risk of severe injury. The capture of the athlete's posture using computer vision attracts huge attention in the sports community due to its markerless motion capture and less interference in the physical training. In this paper, a novel markerless gait estimation and tracking algorithm is proposed to locate human key-points in spatial-temporal sequences for gait analysis. First, human pose estimation using OpenPose network to detect 14 core key-points from the human body. The ratio of body joints is normalized with neck-to-pelvis distance to obtain camera invariant key-points. These key-points are subsequently used to generate a spatial-temporal sequences and it is fed into Long-Short-Term-Memory network for gait recognition. An indexed person is tracked for quick local pose estimation and postural analysis. This proposed algorithm can automate the capture of human joints for postural assessment to analyze the human motion. The proposed system is implemented on Intel Up Squared Board and it can achieve up to 9 frames-per-second with 95% accuracy of gait recognition.
C1 [Tay, Chuan Zhi; Lim, King Hann; Phang, Jonathan Then Sien] Curtin Univ Malaysia, Dept Elect & Comp Engn, CDT 250, Sarawak 98009, Malaysia.
C3 Curtin University Malaysia
RP Tay, CZ (corresponding author), Curtin Univ Malaysia, Dept Elect & Comp Engn, CDT 250, Sarawak 98009, Malaysia.
EM tcz3103@gmail.com; glkhan@curtin.edu.my;
   jonathanpts@postgrad.curtin.edu.my
RI Lim, Hann/AAI-9930-2020
OI Lim, Hann/0000-0002-5679-7747; Tay, Chuan Zhi/0000-0002-8616-9960
FU NVIDIA Corporation; CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. We would like to gratefully acknowledge the support of
   NVIDIA Corporation with the donation of the the Quadro P6000 GPU used
   for this research.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2015, INFORM MEDIA TECHNOL, DOI 10.2197/ipsjtcva.7.121
   Barris S, 2008, SPORTS MED, V38, P1025, DOI 10.2165/00007256-200838120-00006
   Beravs Tadej, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P212, DOI 10.1109/Humanoids.2011.6100914
   Bialkowski A, 2013, IEEE COMPUT SOC CONF, P984, DOI 10.1109/CVPRW.2013.143
   Blanchard N, 2019, IEEE WINT CONF APPL, P1366, DOI 10.1109/WACV.2019.00150
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chumanov ES, 2012, GAIT POSTURE, V36, P231, DOI 10.1016/j.gaitpost.2012.02.023
   Colyer SL, 2018, SPORTS MED-OPEN, V4, DOI 10.1186/s40798-018-0139-y
   Dugan Sheila A, 2005, Phys Med Rehabil Clin N Am, V16, P603, DOI 10.1016/j.pmr.2005.02.007
   Foundation, 2019, ARTHR NUMB, P16
   Girshick Ross, 2018, Detectron
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hamer P, 2009, POSTURE
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jin Sheng, 2017, ICCV PoseTrack Workshop
   Joshi K, 2020, PROCEDIA COMPUT SCI, V167, P2374, DOI 10.1016/j.procs.2020.03.290
   Kim K, 2010, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2010.5540128
   Konstantinou E, 2019, AUTOMAT CONSTR, V103, P168, DOI 10.1016/j.autcon.2019.01.018
   Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821
   Li YX, 2021, IEEE T CIRC SYST VID, V31, P2315, DOI 10.1109/TCSVT.2020.3023080
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Ning G., 2018, P EUR C COMP VIS ECC, P227
   OSOKIN D, 2019, ARXIV181112004, P744
   Phang JTS, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P175, DOI 10.1145/3310986.3311006
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Promrit Nuttachot., 2019, P 2019 2 ARTIFICIAL, P117, DOI DOI 10.1145/3375959.3375981
   Punzi L, 2016, RMD OPEN, V2, DOI 10.1136/rmdopen-2016-000279
   Quinn TJ, 2021, J STRENGTH COND RES, V35, P2511, DOI 10.1519/JSC.0000000000003206
   Raju JP, 2019, INT C E BUS TEL, P177
   Reyes-Ortiz JL, 2012, HUMAN ACTIVITY RECOG
   Richards J., 2013, Tidy's Physiotherapy, P331, DOI DOI 10.1016/B978-0-7020-4344-4.00015-8
   Romanov, 2002, NICHOLAS ROMANOVS PO
   Sweeting K, 2007, AUST FAM PHYSICIAN, V36, P398
   Valdes AM, 2013, ANN RHEUM DIS, V72, P1687, DOI 10.1136/annrheumdis-2012-202562
   Wang JB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P374, DOI 10.1145/3343031.3350910
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 41
TC 4
Z9 4
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12777
EP 12794
DI 10.1007/s11042-022-12026-8
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Huang, CF
   Yao, SH
AF Huang, Chih-Fang
   Yao, Shu-Huan
TI Algorithmic composition for pop songs based on lyrics emotion retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2-D emotional plane; Valence and arousal coordinate; Algorithmic
   composition; Music and emotion; Support vector machine (SVM);
   Algorithmic composition based on lyrics emotion (ACBLE)
AB Musical composition is difficult for people due to the complicated composition theories and the combination of artistic conception with emotion-based ideas. A 2-D emotional plane which can define the valence and arousal coordinate has been developed. With the proposed algorithmic composition, it is possible to perform the mapping technique between music and emotion based on a song's segment emotion retrieval. The proposed emotion-based algorithmic music composition uses song lyrics' emotion retrieval to classify several music idea segments and also uses the mapping technology between musical and emotional aesthetics. To analyze the lyrics, the system automatically segments the sentences, then calculates various feature values via emotional vocabulary, and finally conducts Support Vector Machine (SVM) assortments based on the lyrics emotion dataset. The proposed Algorithmic Composition Based on Lyrics Emotion (ACBLE) for pop songs study composes songs using the lyrics that have been released. According to survey feedback, satisfaction with the songs is 3.33. The system can enable anyone who has no knowledge of music theory, easily compose a song. Some demos finally demonstrate the results. Therefore, the proposed method can be applied to fields including pop music composition, background music, musical health, and educational music.
C1 [Huang, Chih-Fang] Kainan Univ, Dept Hlth & Mkt, 1 Kainan Rd, Taoyuan 33857, Taiwan.
   [Yao, Shu-Huan] Natl Chiao Tung Univ, Master Program Sound & Mus Innovat Technol, 1001 Univ Rd, Hsinchu 33010, Taiwan.
C3 Nan Kai University Technology; National Yang Ming Chiao Tung University
RP Huang, CF (corresponding author), Kainan Univ, Dept Hlth & Mkt, 1 Kainan Rd, Taoyuan 33857, Taiwan.
EM jeffh.me83g@gmail.com; johnny751219@gmail.com
OI Huang, Chih-Fang/0000-0002-0111-0653
FU Science and Technology project of Taiwan [108-2511-H-424 -001 -MY3]
FX The authors would like to appreciate the support fromMinistry of Science
   and Technology project of Taiwan: 108-2511-H-424 -001 -MY3.
CR Amrit C, 2017, EXPERT SYST APPL, V88, P402, DOI 10.1016/j.eswa.2017.06.035
   An YJ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P635
   [Anonymous], 2006, P INT SOC MUSICAL IN
   Bai JJ, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P121, DOI 10.1109/ICCI-CC.2017.8109740
   Bayu Qhansa Di'Ayu Putri, 2019, 2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P5, DOI 10.1109/ISRITI48646.2019.9034651
   Chauhan VK, 2019, ARTIF INTELL REV, V52, P803, DOI 10.1007/s10462-018-9614-6
   Chou, SILENCE
   CKIP, 2019, CHIN WORDS SEGM SYST
   Dai HD, 2019, IEEE T IND ELECTRON, V66, P7706, DOI 10.1109/TIE.2018.2880703
   De Prisco R, 2020, EVOL COMPUT, V28, P489, DOI 10.1162/evco_a_00265
   Dharsini SV., 2020, J Comput Theor Nanosci, V17, P1662
   Fukayama Satoru, 2010, P 7 SOUND MUS COMP C, P299
   Grekow J, 2018, CONTENT BASED MUSIC, P27
   Junyi, 2019, JIEBA DATABASE
   KKBOX International Limited, 2019, KKBOX
   Kotagiri Raju S., 2018, INT J PURE APPL MATH, V118, P321
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Liao W-F, 2016, THESIS SHIH CHIEN U, P1
   Nakamura K., 2020, J INF P, V28, P248
   Niu, 2019, HOWNET KNOWLEDGE DAT
   Shih, 2009, COMPONENTS ANAL APPL
   Sinica A, 2019, NLPLAB
   Srinilta S, 2017, P INT MULT ENG COMP
   Sun WC, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4302425
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Tien, 2015, LITTLE LUCKY
   Wang J., 2019, PROC INT CONFNEW INT, P25, DOI DOI 10.5281/ZENODO.3672854
   Weiss, 2021, INT SOC MUSIC INFORM
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
NR 29
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12421
EP 12440
DI 10.1007/s11042-022-12408-y
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400013
DA 2024-07-18
ER

PT J
AU Zhao, YX
   Hu, B
   Wang, Y
   Yin, XM
   Jiang, YY
   Zhu, XL
AF Zhao, Yuxue
   Hu, Bo
   Wang, Ying
   Yin, Xiaomeng
   Jiang, Yuanyuan
   Zhu, Xiuli
TI Identification of gastric cancer with convolutional neural networks: a
   systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Classification; Convolutional neural network; Detection; Diagnosis;
   Gastric cancer
ID ARTIFICIAL-INTELLIGENCE; DIAGNOSTIC ERRORS; CLASSIFICATION; ENDOSCOPY;
   SEGMENTATION
AB The identification of diseases is inseparable from artificial intelligence. As an important branch of artificial intelligence, convolutional neural networks play an important role in the identification of gastric cancer. We conducted a systematic review to summarize the current applications of convolutional neural networks in the gastric cancer identification. The original articles published in Embase, Cochrane Library, PubMed and Web of Science database were systematically retrieved according to relevant keywords. Data were extracted from published papers. A total of 27 articles were retrieved for the identification of gastric cancer using medical images. Among them, 19 articles were applied in endoscopic images and 8 articles were applied in pathological images. 16 studies explored the performance of gastric cancer detection, 7 studies explored the performance of gastric cancer classification, 2 studies reported the performance of gastric cancer segmentation and 2 studies analyzed the performance of gastric cancer delineating margins. The convolutional neural network structures involved in the research included AlexNet, ResNet, VGG, Inception, DenseNet and Deeplab, etc. The accuracy of studies was 77.3 - 98.7%. Good performances of the systems based on convolutional neural networks have been showed in the identification of gastric cancer. Artificial intelligence is expected to provide more accurate information and efficient judgments for doctors to diagnose diseases in clinical work.
C1 [Zhao, Yuxue; Wang, Ying; Zhu, Xiuli] Qingdao Univ, Sch Nursing, Dept Med, 15 Ningde Rd, Qingdao 266073, Peoples R China.
   [Hu, Bo] Qingdao Municipal Hosp, Dept Thorac Surg, Qingdao, Peoples R China.
C3 Qingdao University; Qingdao Municipal Hospital
RP Zhu, XL (corresponding author), Qingdao Univ, Sch Nursing, Dept Med, 15 Ningde Rd, Qingdao 266073, Peoples R China.
EM 15820022927@163.com
RI jiang, anyi/GPT-0379-2022; Xiuli, Zhu/AAM-1226-2021; Jiang,
   Yuan/JED-3759-2023
OI xiu li, zhu/0000-0003-3533-8581
FU Project of Research Planning Foundation on Humanities and Social
   Sciences of the Ministry of Education [20YJAZH144]
FX The study was supported by Project of Research Planning Foundation on
   Humanities and Social Sciences of the Ministry of Education [grant
   numbers 20YJAZH144].
CR Acs B, 2020, J INTERN MED, V288, P62, DOI 10.1111/joim.13030
   Ali H, 2018, COMPUT METH PROG BIO, V157, P39, DOI 10.1016/j.cmpb.2018.01.013
   An P, 2020, GASTRIC CANCER, V23, P884, DOI 10.1007/s10120-020-01071-7
   Bang CS, 2020, J MED INTERNET RES, V22, DOI 10.2196/21983
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Cho BJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061858
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Cho KO, 2020, KOREAN J PHYSIOL PHA, V24, P89, DOI 10.4196/kjpp.2020.24.1.89
   Cooper LAD, 2018, J PATHOL, V244, P512, DOI 10.1002/path.5028
   Dohi O, 2020, DIGEST ENDOSC, V32, P191, DOI 10.1111/den.13540
   Florea A, 2020, J GASTROINTEST CANC, V51, P965, DOI 10.1007/s12029-019-00328-4
   Gao Y, 2019, CHINESE MED J-PEKING, V132, P2804, DOI 10.1097/CM9.0000000000000532
   Gonçalves WGE, 2020, BMJ OPEN GASTROENTER, V7, DOI 10.1136/bmjgast-2019-000371
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Pham HHN, 2019, AM J PATHOL, V189, P2428, DOI 10.1016/j.ajpath.2019.08.014
   Hoogenboom SA, 2020, TECH INNOVAT GASTROI, V22, P42, DOI 10.1016/j.tgie.2019.150634
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Hu BL, 2019, BIOMED OPT EXPRESS, V10, P6370, DOI 10.1364/BOE.10.006370
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Y, 2017, IEEE J BIOMED HEALTH, V21, P1625, DOI 10.1109/JBHI.2017.2691738
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Ikenoyama Y, 2021, DIGEST ENDOSC, V33, P141, DOI 10.1111/den.13688
   Jeyaraj PR, 2019, J CANCER RES CLIN, V145, P829, DOI 10.1007/s00432-018-02834-7
   Jin P, 2020, J CANCER RES CLIN, V146, P2339, DOI 10.1007/s00432-020-03304-9
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Katai H, 2018, GASTRIC CANCER, V21, P144, DOI 10.1007/s10120-017-0716-7
   Kim JW, 2018, CLIN ENDOSC, V51, P527, DOI 10.5946/ce.2018.186
   Kosaraju SC, 2020, METHODS, V179, P3, DOI 10.1016/j.ymeth.2020.05.012
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni U, 2021, NEURAL NETWORKS, V136, P28, DOI 10.1016/j.neunet.2020.12.022
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Li SQ, 2017, COMPUT BIOL MED, V84, P156, DOI 10.1016/j.compbiomed.2017.03.017
   Li YP, 2019, BIOMED OPT EXPRESS, V10, P4999, DOI 10.1364/BOE.10.004999
   Liang QK, 2019, IEEE J BIOMED HEALTH, V23, P1205, DOI 10.1109/JBHI.2018.2850040
   Ling TS, 2021, ENDOSCOPY, V53, P469, DOI 10.1055/a-1229-0920
   Liu XQ, 2020, NEUROCOMPUTING, V392, P253, DOI 10.1016/j.neucom.2018.10.100
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P821, DOI 10.1016/j.gie.2020.06.034
   Lui TKL, 2020, ENDOSC INT OPEN, V8, pE139, DOI 10.1055/a-1036-6114
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Min JK, 2019, GUT LIVER, V13, P388
   Mishra R, 2018, J COMPUT BIOL, V25, P313, DOI 10.1089/cmb.2017.0153
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Nagao S, 2020, GASTROINTEST ENDOSC, V92, P866, DOI 10.1016/j.gie.2020.06.047
   Qu J, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8961781
   Rantalainen M, 2016, SCI REP-UK, V6, DOI 10.1038/srep38037
   Samek W., 2017, ARXIV PREPRINT ARXIV
   Shibata T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113842
   Shinozaki S, 2019, THER ADV GASTROENTER, V12, DOI 10.1177/1756284819885246
   Singh H, 2017, BMJ QUAL SAF, V26, P484, DOI 10.1136/bmjqs-2016-005401
   Singh H, 2014, BMJ QUAL SAF, V23, P727, DOI 10.1136/bmjqs-2013-002627
   Song ZG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18147-8
   Sumiyama K, 2017, GASTRIC CANCER, V20, pS20, DOI 10.1007/s10120-016-0659-4
   Sun MY, 2019, IEEE ACCESS, V7, P75530, DOI 10.1109/ACCESS.2019.2918800
   Suzuki H, 2016, GASTRIC CANCER, V19, P198, DOI 10.1007/s10120-015-0469-0
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Toyoizumi H, 2009, GASTROINTEST ENDOSC, V70, P240, DOI 10.1016/j.gie.2008.10.064
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Wang H, 2019, INT J PROD RES, V57, P6795, DOI 10.1080/00207543.2018.1464232
   Wang SJ, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101549
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu XJ, 2020, EUR J RADIOL, V128, DOI 10.1016/j.ejrad.2020.109041
   Xu Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1685-x
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Zhao XQ, 2021, INT J COAL PREP UTIL, V41, P830, DOI [10.1080/19392699.2018.1536045, 10.1007/s11548-017-1696-0]
   Zhu LF, 2019, J CANCER, V10, P3533, DOI 10.7150/jca.22462
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 73
TC 11
Z9 11
U1 8
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11717
EP 11736
DI 10.1007/s11042-022-12258-8
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400011
PM 35221775
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chattopadhyay, S
   Dey, A
   Singh, PK
   Ahmadian, A
   Sarkar, R
AF Chattopadhyay, Soham
   Dey, Arijit
   Singh, Pawan Kumar
   Ahmadian, Ali
   Sarkar, Ram
TI A feature selection model for speech emotion recognition using
   clustering-based population generation with hybrid of equilibrium
   optimizer and atom search optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; CEOAS algorithm; Feature selection;
   Equilibrium optimization; Atom search optimization; Meta-heuristic
ID CLASSIFICATION; NETWORKS
AB Speech plays an important role among the human communication and also a dominant source of medium for human computer interaction (HCI) to exchange information. Hence, it has always been an important research topic in the fields of Artificial Intelligence (AI) and Machine Learning (ML). However, in the traditional machine learning approach, when the dimension of the feature vector becomes quite large, it takes a huge amount of storage space and processing time for the learning algorithms. To address this problem, we have proposed a hybrid wrapper feature selection algorithm, called CEOAS, using clustering-based Equilibrium Optimizer (EO) and Atom Search Optimization (ASO) algorithm for recognizing different human emotions from speech signals. We have extracted Linear Prediction Coding (LPC) and Linear Predictive Cepstral Coefficient (LPCC) from the audio signals. Our proposed model helps to reduce the feature dimension as well as improves the classification accuracy of the learning model. The model has been evaluated on four standard benchmark datasets namely, SAVEE, EmoDB, RAVDESS, and IEMOCAP and impressive recognition accuracies of 98.01%, 98.72%, 84.62% and 74.25% respectively have been achieved which are better than many state-of-the-art algorithms.
C1 [Chattopadhyay, Soham] Jadavpur Univ, Dept Elect Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
   [Dey, Arijit] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata 700064, W Bengal, India.
   [Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Jadavpur Univ Second Campus,Plot 8,LB Block, Kolkata 700106, W Bengal, India.
   [Ahmadian, Ali] Natl Univ Malaysia, Inst IR 4 0, Bangi 43600, Malaysia.
   [Ahmadian, Ali] Near East Univ, Dept Math, Mersin 10, Nicosia, Trnc, Turkey.
   [Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
C3 Jadavpur University; Maulana Abul Kalam Azad University of Technology;
   Jadavpur University; Universiti Kebangsaan Malaysia; Near East
   University; Jadavpur University
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Jadavpur Univ Second Campus,Plot 8,LB Block, Kolkata 700106, W Bengal, India.
EM chattopadhyaysoham99@gmail.com; arijjitdey3413@gmail.com;
   pawansingh.ju@gmail.com; ahmadian.hosseini@gmail.com; ramjucse@gmail.com
RI Ahmadian, Ali/N-3697-2015; Sarkar, Ram/AAX-3822-2020; SINGH, PAWAN
   KUMAR/E-3408-2013
OI Ahmadian, Ali/0000-0002-0106-7050; Sarkar, Ram/0000-0001-8813-4086;
   SINGH, PAWAN KUMAR/0000-0002-9598-7981; dey, arijit/0000-0003-2990-7696;
   CHATTOPADHYAY, SOHAM/0000-0001-6890-2965
CR [Anonymous], 2013, THESIS
   Barros P, 2015, IEEE-RAS INT C HUMAN, P582, DOI 10.1109/HUMANOIDS.2015.7363421
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Boigne J., 2020, ARXIV201105585
   Bookstein A, 2002, INFORM RETRIEVAL, V5, P353, DOI 10.1023/A:1020499411651
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chatterjee B, 2020, IEEE ACCESS, V8, P75393, DOI 10.1109/ACCESS.2020.2988157
   Chen LF, 2020, INFORM SCIENCES, V509, P150, DOI 10.1016/j.ins.2019.09.005
   Chibelushi ClaudeC., 2003, CVONLINE ON LINE COM, V9
   Cummins N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P478, DOI 10.1145/3123266.3123371
   Da Silva R., 2020, ANAIS 17 ENCONTRO NA, P342
   Daneshfar F, 2020, APPL ACOUST, V166, DOI 10.1016/j.apacoust.2020.107360
   Das A., 2021, APPL CUCKOO SEARCH A, P207
   Dey A, 2020, HYBRID META HEURISTI, V8
   Emary E, 2015, ADV INTELL SYST, V334, P1, DOI 10.1007/978-3-319-13572-4_1
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Ghosh KK, 2020, IEEE ACCESS, V8, P83548, DOI 10.1109/ACCESS.2020.2991543
   Ghosh M, 2020, J INTELL SYST, V29, P1598, DOI 10.1515/jisys-2019-0062
   Gideon J, 2016, INT CONF ACOUST SPEE, P2359, DOI 10.1109/ICASSP.2016.7472099
   Goldberg D.E., 1986, Engineering Optimization via Genetic Algorithm, P471
   Golilarz NA, 2019, IEEE ACCESS, V7, P149398, DOI 10.1109/ACCESS.2019.2945596
   Guha R, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106341
   Guha R, 2020, J INTELL SYST, V29, P1453, DOI 10.1515/jisys-2019-0064
   Guha S, 2020, IEEE ACCESS, V8, P182868, DOI 10.1109/ACCESS.2020.3028121
   Gupta H, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P498, DOI 10.1109/CONFLUENCE.2016.7508171
   Hajarolasvadi N, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050479
   Huang JS, 2019, IEEE ACCESS, V7, P92871, DOI 10.1109/ACCESS.2019.2928017
   Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jackson P., 2014, Surrey audio-visual expressed emotion (savee) database
   Karan B, 2020, BIOCYBERN BIOMED ENG, V40, P249, DOI 10.1016/j.bbe.2019.05.005
   Lai HL, 2020, IEEE ACCESS, V8, P119516, DOI 10.1109/ACCESS.2020.3005664
   Latif S, 2019, INTERSPEECH, P3920, DOI 10.21437/Interspeech.2019-3252
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Lu ZY, 2020, INT CONF ACOUST SPEE, P7149, DOI [10.1109/icassp40776.2020.9052937, 10.1109/ICASSP40776.2020.9052937]
   Mahdhaoui Ammar, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4488, DOI 10.1109/ICPR.2010.1090
   Mao S, 2020, ARXIV200806665
   Mao S, 2020, ARXIV200805259
   Mukherjee H, 2020, INT J MACH LEARN CYB, V11, P1, DOI 10.1007/s13042-019-00928-3
   Muthusamy H, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120344
   Nagarajan S, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102763
   Nantasri Panuwit, 2020, 2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P41, DOI 10.1109/ECTI-CON49241.2020.9158221
   Navyasri M, 2018, SMART INNOV SYST TEC, V84, P437, DOI 10.1007/978-3-319-63645-0_50
   Nematollahi AF, 2020, SOFT COMPUT, V24, P1117, DOI 10.1007/s00500-019-03949-w
   Nguyen D, 2018, META TRANSFER LEARNI
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Osman I.H., 1997, J Oper Res Soc, V48, P657, DOI [DOI 10.1057/PALGRAVE.JORS.2600781, 10.1057/palgrave.jors.2600781]
   Pao TL, 2005, LECT NOTES COMPUT SC, V3784, P279
   Patil A, 2020, INTELLIGENT VOICE AS
   Pepino L, 2020, INT CONF ACOUST SPEE, P6484, DOI [10.1109/ICASSP40776.2020.9054709, 10.1109/icassp40776.2020.9054709]
   Qazi H., 2020, INT J ENG ADV TECHNO, V9, P1126, DOI [10.35940/ijeat.E1027.069520, DOI 10.35940/IJEAT.E1027.069520]
   Rajak R, 2019, TENCON IEEE REGION, P301, DOI 10.1109/TENCON.2019.8929459
   Rajasekhar B, 2020, DATA TECHNOL APPL, V54, P297, DOI 10.1108/DTA-07-2019-0120
   Rana R, 2019, EUR J CANCER CARE, V28, DOI 10.1111/ecc.13033
   REN ZS, 2018, DCASE 2018 WORKSH P, DOI DOI 10.1145/3275219.3275230
   Saha S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082816
   Saldanha Jennifer C., 2020, Advances in Control Instrumentation Systems. Select Proceedings of CISCON 2019. Lecture Notes in Electrical Engineering (LNEE 660), P51, DOI 10.1007/978-981-15-4676-1_5
   Ortega MGS, 2020, J AMB INTEL HUM COMP, V11, P3187, DOI 10.1007/s12652-019-01485-x
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Sheikh KH, 2020, IEEE ACCESS, V8, P158125, DOI 10.1109/ACCESS.2020.3019809
   Shetty S, 2020, ADV INTELL SYST, V1042, P463, DOI 10.1007/978-981-32-9949-8_32
   Singh A, 2020, INT J INFORM TECHNOL, V6
   Su BH, 2020, INTERSPEECH, P506, DOI 10.21437/Interspeech.2020-1733
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Wang KX, 2020, NEUROCOMPUTING, V398, P257, DOI 10.1016/j.neucom.2020.02.085
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu CH, 2011, IEEE T AFFECT COMPUT, V2, P10, DOI 10.1109/T-AFFC.2010.16
   Wu W, 2020, ARXIV201014102
   Yogesh CK, 2017, EXPERT SYST APPL, V69, P149, DOI 10.1016/j.eswa.2016.10.035
   Yu Y, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050713
   Zamil AAA, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P281, DOI [10.1109/ICREST.2019.8644168, 10.1109/icrest.2019.8644168]
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhao WG, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103300
   Zhao WG, 2019, KNOWL-BASED SYST, V163, P283, DOI 10.1016/j.knosys.2018.08.030
   Zhu Y, 2018, IEEE T AFFECT COMPUT, V9, P578, DOI 10.1109/TAFFC.2017.2650899
NR 81
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9693
EP 9726
DI 10.1007/s11042-021-11839-3
EA FEB 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000756332700002
DA 2024-07-18
ER

PT J
AU Das, R
   Singh, TD
AF Das, Ringki
   Singh, Thoudam Doren
TI Assamese news image caption generation using attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News caption generation; CNN-LSTM architecture; Attention mechanism;
   Assamese news; Resource-constrained language
AB In recent times, neural networks and deep learning have made significant contributions in various research domains. In the present work, we report automatic caption generation of an image using these techniques. Automatic image caption generation is an artificial intelligence problem that receives attention from both computer vision and natural language processing researchers. Most of the caption generation tasks exist in the English language and no work has been reported yet in Assamese to the best of our knowledge. Assamese is an Indo-European language spoken by 14 million speakers in the North-East region of India. This paper reports the image caption generation on the Assamese news domain. A quality image captioning system requires an annotated training corpus. However, there is no such standard dataset available for this resource-constrained language. Therefore, we built a dataset of 13000 images collected from various online local Assamese e-newspapers. We employ two different architectures for generating the news image caption. The first model is based on CNN-LSTM and the second model is based on the attention mechanism. These models are evaluated both qualitatively and quantitatively. Qualitative analysis of the generated captions is carried out in terms of fluency and adequacy scores based on a standard rating scale. The quantitative result is evaluated using the BLEU and CIDEr evaluation metrics. We observe that the attention mechanism-based model outperforms the CNN-LSTM based model for our task.
C1 [Das, Ringki; Singh, Thoudam Doren] Natl Inst Technol, Dept Comp Sci & Engn, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Das, R (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Silchar, India.
EM ringkidas@gmail.com; doren@cse.nits.ac.in
CR Amritkar C, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Batra V, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1726
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Dhir R, 2019, COMPUT SIST, V23, P693, DOI [10.13053/cys-23-3-3269, 10.13053/CyS-23-3-3269]
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Feng YS, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1239
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Gorokhovatskyi O, 2018, 2018 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P459, DOI 10.1109/DSMP.2018.8478540
   Haripriya B, IMAGE CAPTIONING USI
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Holzinger A., 2021, ARXIV210300519
   Kamal A. H., 2020, ARXIV201008066
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kohakade AK., 2014, INT J COMPUT APPL, V100, P7
   Lu D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4013
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Mansimov Elman, 2015, ARXIV151102793
   Meetei LS, 2019, LECT NOTES COMPUT SC, V11941, P405, DOI 10.1007/978-3-030-34869-4_44
   Meetei LS, 2019, P 6 WORKSH AS TRANSL, P181, DOI DOI 10.18653/V1/D19-5224
   Miyazaki T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1780
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Peng H., 2016, GENERATING CHINESE C
   Prajapati K, AUTOCAPTION GENERATI
   Rahman M, 2019, PROCEDIA COMPUT SCI, V154, P636, DOI 10.1016/j.procs.2019.06.100
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2021, LECT NOTES NETWORKS, V170, DOI 10.1007/978-981-33-4084-8_7
   Soh M., 2016, LEARNING CNN LSTM AR
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
NR 38
TC 14
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10051
EP 10069
DI 10.1007/s11042-022-12042-8
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800002
DA 2024-07-18
ER

PT J
AU Alqahtani, G
   Alothaim, A
AF Alqahtani, Ghadah
   Alothaim, Abdulrahman
TI Predicting emotions in online social networks: challenges and
   opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Emotion analysis; Emotion recognition; Online social
   networks; Sentiment analysis; Systematic literature review
ID SENTIMENT ANALYSIS; MODEL; CLASSIFICATION; RECOGNITION; SPEECH; TWEETS;
   IMAGES
AB Online social networking has become a popular means of information exchange and social interactions. Users of these platforms generate massive amounts of data about their relationships, behaviors, interests, opinions, locations visited, items purchased, and subjective experiences of various aspects of life. Moreover, these platforms enable people from wide-ranging social and cultural backgrounds to synergize and interact. One interesting area of research is the emotional dimensions contained in this user-generated content, specifically, emotion detection and prediction, which involve the extraction and analysis of emotions in social network data. This study aimed to provide a comprehensive overview and better understanding of the current state of research regarding emotion detection in online social networks by performing a systematic literature review (SLR). SLRs help identify the gaps, challenges, and opportunities in a field of study through a careful examination of current research to understand the methods and results, ultimately highlighting methodological concerns that can be used to improve future work in the field. Hence, we collected and analyzed studies that focused on emotion in social network posts and discussed various topics published in digital databases between 2010 and December 2020. Over 239 articles were initially included in the collection, and after the selection process and application of our quality criteria, 104 articles were examined, and the results showed a robust extant body of literature on the text-based emotion analysis model, while the image-based requires more attention as well as the multiple modality emotion analysis.
C1 [Alqahtani, Ghadah; Alothaim, Abdulrahman] King Saud Univ, Coll Comp & Informat Sci, Informat Syst Dept, POB 51178, Riyadh 11543, Saudi Arabia.
C3 King Saud University
RP Alqahtani, G (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Informat Syst Dept, POB 51178, Riyadh 11543, Saudi Arabia.
EM ghadahalqahtani94@gmail.com; othaim@ksu.edu.sa
OI Alothaim, Abdulrahman/0000-0001-6794-5701; AlQahtani,
   Ghadah/0000-0001-8091-5494
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Abdullah M, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P835, DOI 10.1109/ICMLA.2018.00134
   Akaichi J, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P886, DOI 10.1109/SocialCom.2013.135
   Akuma S, 2016, COMPUT HUM BEHAV, V60, P138, DOI 10.1016/j.chb.2016.02.064
   Al-Hajjar D, 2015, 2015 IEEE JORDAN CONFERENCE ON APPLIED ELECTRICAL ENGINEERING AND COMPUTING TECHNOLOGIES (AEECT)
   Alhamid MF, 2017, IEEE INT SYM MULTIM, P378, DOI 10.1109/ISM.2017.76
   Alm CO, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   Almehmadi A, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P987, DOI 10.1109/SocialCom.2013.158
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   Ancourt C., 2019, SURVEY AI BASED MULT
   Anjaria M., 2014, P 6 INT C COMM SYST, P1
   [Anonymous], 2014, ACM SIGKDD WORKSH HL
   [Anonymous], 2012, P INT AAAI C WEB SOC
   [Anonymous], 2012, EACL 2012
   [Anonymous], Proceedings of the 14th Koli calling international conference on computing education research, DOI [DOI 10.1145/2674683.2674699, 10.1145/2674683.2674699]
   Ashkezari-Toussi S, 2019, CITIES, V86, P113, DOI 10.1016/j.cities.2018.09.009
   Baali M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0252-x
   Bahrainian SA, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY - WORKSHOPS (WI-IAT), VOL 3, P26, DOI 10.1109/WI-IAT.2013.145
   Balahur A, 2011, LECT NOTES COMPUT SC, V6677, P611, DOI 10.1007/978-3-642-21111-9_69
   BANKS D, 1994, J CLASSIF, V11, P121, DOI 10.1007/BF01201026
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Estrada MLB, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113265
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bernabé-Moreno J, 2015, PROCEDIA COMPUT SCI, V55, P960, DOI 10.1016/j.procs.2015.07.107
   Bin Tareaf R, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P860, DOI 10.1109/HPCC/SmartCity/DSS.2018.00143
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Bravo-Marquez F., 2019, AffectiveTweets: a WEKA package for analyzing affect in tweets
   Bravo-Marquez F, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P536, DOI [10.1109/WI.2016.0091, 10.1109/WI.2016.90]
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Brest P., 2010, PROBLEM SOLVING DECI
   Broad C.D., 1954, Journal of Aesthetics and Art Criticism, P203, DOI [DOI 10.2307/425913, 10.2307/425913, DOI 10.1111/1540_6245.JAAC13.2.0203]
   Buechel S., 2017, 15 C EUR CHAPT ASS C, P578, DOI 10.18653/V1/E17-2092
   Butts CT, 2008, ASIAN J SOC PSYCHOL, V11, P13, DOI 10.1111/j.1467-839X.2007.00241.x
   Cai WJ, 2018, IEEE INT CON MULTI
   Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Chen HC, 2010, IEEE INTELL SYST, V25, P74, DOI 10.1109/MIS.2010.75
   Chen YL, 2017, DECIS SUPPORT SYST, V101, P40, DOI 10.1016/j.dss.2017.05.014
   Chopade C., 2015, International Journal of Science and Research IJSR, V4, P409
   Clos J, 2017, LECT NOTES COMPUT SC, V10193, P527, DOI 10.1007/978-3-319-56608-5_44
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   Corchs S, 2019, INT J MACH LEARN CYB, V10, P2057, DOI 10.1007/s13042-017-0734-0
   Coviello L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090315
   Dai WH, 2015, INFORM MANAGE-AMSTER, V52, P777, DOI 10.1016/j.im.2015.02.003
   Daugherty PR, 2018, Human + Machine: Reimagining Work in the Age of AI
   De Choudhury Munmun, 2013, ICWSM, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998, DOI 10.3109/01460862.2013.798190]
   Degenne A., 1999, INTRO SOCIAL NETWORK
   Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4040
   Deng J, 2016, COMM COM INF SC, V663, P652, DOI 10.1007/978-981-10-3005-5_54
   Deshpande M, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P858, DOI 10.1109/ISS1.2017.8389299
   Devlin J., 2018, BERT PRE TRAINING DE
   Diaz-Aviles E., 2012, 2012 Eighth Latin American Web Congress (LA-WEB), P40, DOI 10.1109/LA-WEB.2012.9
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Felbo B., 2017, P 2017 C EMP METH NA, P1615, DOI DOI 10.18653/V1/D17-1169
   Ferrari R., 2015, REV GEN PSYCHOL, V24, P230, DOI [DOI 10.1037/1089-2680.1.3.311, 10.1179/2047480615Z.000000000329, DOI 10.1179/2047480615Z.000000000329, https://doi.org/10.1179/2047480615Z.000000000329]
   Gaind B., 2019, ARXIV190108458
   Gajarla, 2015, GEORG I TECHNOL
   García-Crespo A, 2010, J INF TECHNOL-UK, V25, P178, DOI 10.1057/jit.2010.1
   Garcia-Garcia J.M., 2017, ACM INT C P SER OCT, P1, DOI [10.1145/3123818.3123852, DOI 10.1145/3123818.3123852, 10.1145/3123818, DOI 10.1145/3123818]
   Garton L., 1997, J. Comput.-Mediat. Commun, V3, DOI DOI 10.1111/J.1083-6101.1997.TB00062.X
   Geetha S., 2019, Advances in Big Data and Cloud Computing. Proceedings of ICBDCC18. Advances in Intelligent Systems and Computing (AISC 750), P251, DOI 10.1007/978-981-13-1882-5_23
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Grunspan DZ, 2014, CBE-LIFE SCI EDUC, V13, P167, DOI 10.1187/cbe.13-08-0162
   Gupta N, 2013, COMPUT INTELL-US, V29, P489, DOI 10.1111/j.1467-8640.2012.00454.x
   Hasan M., 2014, EMOTEX: Detecting emotions in Twitter messages, P1
   Hasan M, 2019, INT J DATA SCI ANAL, V7, P35, DOI 10.1007/s41060-018-0096-z
   Hirat R., 2015, International Bulletin of Mathematical Research, V2, P180
   Huang J, 2020, PREP BIOCHEM BIOTECH, V50, P191, DOI 10.1080/10826068.2019.1692215
   Hussien WA, 2016, INT CONF COMP SCI
   Illendula A, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P439, DOI 10.1145/3308560.3316549
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Jindal S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P447, DOI 10.1109/INFOP.2015.7489424
   Kao ECC, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P70, DOI 10.1109/ICIME.2009.113
   Karamibekr M, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P264, DOI 10.1109/SocialCom.2013.44
   Karyotis C, 2018, INFORM SCIENCES, V433, P448, DOI 10.1016/j.ins.2017.02.004
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Kramer ADI, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P287
   LEAVITT HJ, 1951, J ABNORM SOC PSYCH, V46, P38, DOI 10.1037/h0057189
   Li F., 2020, IEEE INTERNET THINGS
   Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Loia V, 2014, KNOWL-BASED SYST, V58, P75, DOI 10.1016/j.knosys.2013.09.024
   Lövheim H, 2012, MED HYPOTHESES, V78, P341, DOI 10.1016/j.mehy.2011.11.016
   Lu JS, 2019, ADV NEUR IN, V32
   Luyckx K, 2012, BIOMED INFORM INSIGH, V5, P61, DOI 10.4137/BII.S8966
   Malighetti C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120924771
   Manoharan DS, 2020, J INF TECHNOL-UK, V2, P100, DOI DOI 10.36548/JITDW.2020.2.003
   Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009
   Mashal SX, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P155, DOI 10.1109/ICCMC.2017.8282664
   McStay Andrew., 2018, Emotional AI: The Rise of Empathic Media
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Meo R, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/2996187
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Plaza-del-Arco FM, 2020, FUTURE GENER COMP SY, V110, P1000, DOI 10.1016/j.future.2019.09.034
   Moers T., 2018, INT C AGENTS ARTIFIC, P361
   Mohammad S., 2018, P 12 INT WORKSHOP SE, P1, DOI DOI 10.18653/V1/S18-1001
   Mohammad S. M., 2017, EMOTION INTENSITIES
   Mohammad Saif., 2012, Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, SemEval'12, P246
   Mohammad SM, 2015, INFORM PROCESS MANAG, V51, P480, DOI 10.1016/j.ipm.2014.09.003
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Nagarsekar U, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P316, DOI 10.1109/RAICS.2013.6745494
   Naik D, 2020, INT C INN COMM SERV, P63
   Otte E, 2002, J INF SCI, V28, P441, DOI 10.1177/016555150202800601
   Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4
   Peng KC, 2015, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2015.7298687
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Petrovic S., 2010, P NAACL HLT WORKSHOP, P25, DOI DOI 10.1371/journal.pcbi.1004513
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Radford A., 2017, LEARNING GENERATE RE
   Rambocas M., 2013, Marketing research: The role of sentiment analysis
   Rangel F, 2016, INFORM PROCESS MANAG, V52, P73, DOI 10.1016/j.ipm.2015.06.003
   Rao YH, 2014, NEURAL NETWORKS, V58, P29, DOI 10.1016/j.neunet.2014.05.007
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sailunaz K, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2019.05.009
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2
   Saini S, 2018, INT CONF INFORM RETR, P25
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Serrat O, 2017, KNOWLEDGE SOLUTIONS, P39
   Seyeditabari A., 2018, ARXIV180600674
   Shahheidari S, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P144, DOI 10.1109/CISIS.2013.31
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037//0022-3514.52.6.1061
   Singh VK, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P712, DOI 10.1109/iMac4s.2013.6526500
   Sintsova V, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P393, DOI 10.1109/ICDMW.2014.146
   Spielberger C.D., 2004, Encyclopedia of applied psychology
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Suttles Jared, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P121, DOI 10.1007/978-3-642-37256-8_11
   Takahashi Y, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1142
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Thanapattheerakul T, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION TECHNOLOGY (IAIT2018), DOI 10.1145/3291280.3291788
   Tsytsarau M, 2012, DATA MIN KNOWL DISC, V24, P478, DOI 10.1007/s10618-011-0238-6
   Tuveri F, 2014, STUD COMPUT INTELL, V515, P51, DOI 10.1007/978-3-642-40621-8_3
   Unterkalmsteiner M, 2012, IEEE T SOFTWARE ENG, V38, P398, DOI 10.1109/TSE.2011.26
   Valkanas George, 2013, Human-Computer Interaction and Knowledge Discovery in Complex, Unstructured, Big Data. Third International Workshop, HCI-KDD 2013. Held at SouthCHI 2013. Proceedings: LNCS 7947, P89, DOI 10.1007/978-3-642-39146-0_9
   Valkanas G, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P639, DOI 10.1145/2505515.2505572
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vogt T, 2008, LECT NOTES COMPUT SC, V4868, P75, DOI 10.1007/978-3-540-85099-1_7
   Wan XJ, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P24, DOI 10.1109/WI-IAT.2012.54
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P587, DOI 10.1109/SocialCom-PASSAT.2012.119
   Wang XH, 2015, IEEE T AFFECT COMPUT, V6, P286, DOI 10.1109/TAFFC.2015.2400917
   Wegner DM, 1995, SOC COGNITION, V13, P319, DOI 10.1521/soco.1995.13.3.319
   Wikarsa L, 2016, INT C WIR TEL
   Williams G, 2017, 2017 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION 2017), P2, DOI 10.1109/SEmotion.2017.1
   Wimmer A, 2006, AM SOCIOL REV, V71, P867, DOI 10.1177/000312240607100601
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   Wu BY, 2017, IEEE T MULTIMEDIA, V19, P1670, DOI 10.1109/TMM.2017.2655881
   Xu BH, 2018, IEEE T AFFECT COMPUT, V9, P255, DOI 10.1109/TAFFC.2016.2622690
   Xu BH, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P15, DOI 10.1145/2911996.2912006
   Xu GX, 2020, FUTURE GENER COMP SY, V102, P347, DOI 10.1016/j.future.2019.07.007
   Xu P., 2020, ARXIV200809378
   Xu Peng, 2018, ARXIV180904505
   Yadollahi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057270
   Yang J, 2014, PROC INT C TOOLS ART, P424, DOI 10.1109/ICTAI.2014.71
   Yassine M., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P1136, DOI 10.1109/ICDMW.2010.75
   Ying W., 2019, Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019), P316
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   Zhang Y, 2010, PROC INT CONF DATA, P1157, DOI 10.1109/ICDE.2010.5447819
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 160
TC 6
Z9 6
U1 5
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9567
EP 9605
DI 10.1007/s11042-022-12345-w
EA FEB 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000753241100001
DA 2024-07-18
ER

PT J
AU Chen, WK
   Chang, JR
   Chen, LS
   Hsu, RY
AF Chen, Wen-Kuo
   Chang, Jing-Rong
   Chen, Long-Sheng
   Hsu, Rui-Yang
TI Using refined kano model and decision trees to discover learners' needs
   for teaching videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cueing; Emotional design; Learning videos; Refined Kano Model;
   Decision trees
ID EMOTIONAL DESIGN; SCIENCE; PERFORMANCE; ATTENTION; FEATURES; PICTURES;
   TEXT
AB With the advancement of technology and the spread of the COVID19 epidemic, learning can no longer only be done through face-to-face teaching. Numerous digital learning materials have appeared in large numbers, changing people's learning mode. In the era of information explosion, how to capture the learners' attention to teaching videos and improve learning effectiveness is the common goal of every designer of e-leaning teaching content. Previous researches focused on the analysis of learning effectiveness and satisfaction. Instructional designers only provided design elements with high learning effectiveness or high satisfaction, and lacked in-depth analysis of the learners' perspectives. The opinions of these e-learning users are often the key to the success of online teaching videos. Therefore, this study aims at the design elements that will be used in the teaching film. The operation mode of the piano mechanism will be employed as the content of the teaching film. Based on eight elements including arrow cueing, dynamic arrow cueing, spreading-color cueing, contrary to cueing, font style, color application, anthropomorphic, and audiovisual complementarity, we use Refined Kano Model to analyze learners' needs of categorization of each element, and discover learners' expectations for teaching videos. In addition, this study also conducts in-depth data analysis through decision trees algorithm, and stratification analyses using different variables (such as design expertise, using frequency, and usage experience, etc.) to find out the key design factors that affect learners' learning. Depending on the learner's background, the use of e-learning experience, using frequency, and the length of the learning video, our results could provide for reference when designing teaching videos. Instructional designers can better understand how to effectively use design elements, so that the teaching videos can achieve the best learning effect.
C1 [Chen, Wen-Kuo] Chaoyang Univ Technol, Dept Mkt & Logist Management, Taichung 413310, Taiwan.
   [Chang, Jing-Rong; Chen, Long-Sheng; Hsu, Rui-Yang] Chaoyang Univ Technol, Dept Informat Management, Taichung 413310, Taiwan.
C3 Chaoyang University of Technology; Chaoyang University of Technology
RP Chen, LS (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung 413310, Taiwan.
EM wkchen@cyut.edu.tw; chrischang@cyut.edu.tw; lschen@cyut.edu.tw;
   j5520310@gmail.com
RI Chen, Long-Sheng/AAK-1264-2021; Chen, Long-Sheng/GSD-6470-2022
OI Chen, Long-Sheng/0000-0002-2967-9956
FU Ministry of Science and Technology of Taiwan, R.O.C. [MOST
   110-2410-H-324-003]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan, R.O.C. (Grant No MOST 110-2410-H-324-003).
CR Abachi HR, 2014, COMPUT HUM BEHAV, V30, P491, DOI 10.1016/j.chb.2013.06.018
   Al-Hoqani WMA, 2021, MATER TODAY-PROC, DOI 10.1016/j.matpr.2021.01.708
   ALI S, 2021, MULTIMED TOOLS APPL
   [Anonymous], 1998, COLL STUD J
   [Anonymous], 2006, P 9 IASTED INT C COM
   [Anonymous], 2015, NEW VISION ED UNLOCK
   [Anonymous], 2017, P 1 INT C ENG RES PR
   [Anonymous], 2010, HDB RES HUMAN PERFOR, DOI DOI 10.4018/978-1-60566-782-9.CH011
   Apichaya N., 2019, J U BABYLON PURE APP, V27, P345
   Arvidsson A., 2019, Introduction to Digital Media
   Beege M, 2020, COMPUT EDUC, V156, DOI 10.1016/j.compedu.2020.103955
   Boucheix JM, 2010, LEARN INSTR, V20, P123, DOI 10.1016/j.learninstruc.2009.02.015
   Brame CJ, 2016, CBE-LIFE SCI EDUC, V15, DOI 10.1187/cbe.16-03-0125
   Canham M, 2010, LEARN INSTR, V20, P155, DOI 10.1016/j.learninstruc.2009.02.014
   Chen LS, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P572, DOI 10.1109/IEA.2019.8714873
   Chen SH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010085
   Chen XL, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/7140797
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   Dalacosta K, 2009, COMPUT EDUC, V52, P741, DOI 10.1016/j.compedu.2008.11.018
   Daumiller M, 2021, LEARN INSTR, V76, DOI 10.1016/j.learninstruc.2021.101458
   de Koning BB, 2009, EDUC PSYCHOL REV, V21, P113, DOI 10.1007/s10648-009-9098-7
   Desmet P., 2002, Designing Emotions
   Dominici G, 2013, BUS HORIZONS, V56, P87, DOI 10.1016/j.bushor.2012.09.011
   Expósito A, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103709
   Ferreira DC, 2018, OMEGA-INT J MANAGE S, V80, P58, DOI 10.1016/j.omega.2017.08.009
   Fredrickson BL, 2005, COGNITION EMOTION, V19, P313, DOI 10.1080/02699930441000238
   Frijda Nico, 1993, Handbook of emotions p, P381
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Hamoud AK, 2018, INT J INTERACT MULTI, V5, P26, DOI 10.9781/ijimai.2018.02.004
   Harp SF, 1997, J EDUC PSYCHOL, V89, P92, DOI 10.1037/0022-0663.89.1.92
   Hegarty M, 2010, J EXP PSYCHOL LEARN, V36, P37, DOI 10.1037/a0017683
   Heidig S, 2015, COMPUT HUM BEHAV, V44, P81, DOI 10.1016/j.chb.2014.11.009
   Höffler TN, 2007, LEARN INSTR, V17, P722, DOI 10.1016/j.learninstruc.2007.09.013
   Ilgaz H, 2014, COMPUT HUM BEHAV, V39, P1, DOI 10.1016/j.chb.2014.06.008
   Imhof B, 2013, COMPUT EDUC, V65, P45, DOI 10.1016/j.compedu.2013.01.017
   Kabra R., 2011, Int J Comput Appl, V36, P8
   Kano N., 1984, Journal of The Japanese Society for Quality Control, V31, P147, DOI [DOI 10.20684/QUALITY.14.2_147, 10.20684/quality.14.2_147]
   Knautz K, 2012, KNOWL INFO-STUD INFO, P343
   Kumar Jeya Amantha, 2016, International Journal of Modern Education and Computer Science, V8, P54, DOI 10.5815/ijmecs.2016.05.07
   Kumins NH, 2021, AM J SURG, V221, P780, DOI 10.1016/j.amjsurg.2020.08.011
   LAZARUS RS, 1991, AM PSYCHOL, V46, P352, DOI 10.1037/0003-066X.46.4.352
   Lidwell W., 2003, Universal principles of design
   Lohr L.L., 2007, Creating graphics for learning and performance: Lessons in visual literacy
   Lowe R, 2004, LEARN INSTR, V14, P257, DOI 10.1016/j.learninstruc.2004.06.003
   Lu, 2021, ADV INTELLIGENT SYST, V1303, DOI 10.1007/978-981-33-4572-0_171
   Matthew LB., 2019, CONTEMP EDUC PSYCHOL, V58, P1
   Mautone PD, 2007, J EDUC PSYCHOL, V99, P640, DOI 10.1037/0022-0663.99.3.640
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, V2nd, P31, DOI [https://doi.org/10.1017/CBO9781139547369.005, DOI 10.1017/CBO9780511816819.004, 10.1017/cbo9780511816819.004]
   Mayer RE, 2019, APPL COGNITIVE PSYCH, V33, P152, DOI 10.1002/acp.3482
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P223
   Moridis CN, 2008, J EDUC COMPUT RES, V39, P313, DOI 10.2190/EC.39.4.a
   M┬u├eller G., 2015, INSTR SCI, V43, P443
   Nezlek JB, 2008, EMOTION, V8, P145, DOI 10.1037/1528-3542.8.1.145
   Norman D.A., 2004, EMOTIONAL DESIGN WHY
   Nuguri SS, 2021, MULTIMED TOOLS APPL, V80, P16827, DOI 10.1007/s11042-020-09051-w
   Oatley K., 1987, Cogn Emot, V1, P29, DOI DOI 10.1080/02699938708408362
   Pass F, 2014, CAMBRIDGE HDB MULTIM, P39
   Pi ZL, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103713
   Plass JL, 2014, LEARN INSTR, V29, P128, DOI 10.1016/j.learninstruc.2013.02.006
   Rebollo C, 2022, MULTIMED TOOLS APPL, V81, P14851, DOI 10.1007/s11042-021-10821-3
   REID DJ, 1986, BRIT J EDUC PSYCHOL, V56, P294, DOI 10.1111/j.2044-8279.1986.tb03042.x
   Renkl A, 2017, EDUC PSYCHOL REV, V29, P599, DOI 10.1007/s10648-015-9340-4
   Rodrigues H, 2019, COMPUT EDUC, V136, P87, DOI 10.1016/j.compedu.2019.03.007
   Salmerón L, 2020, COMPUT EDUC, V148, DOI 10.1016/j.compedu.2019.103796
   Scheiter K., 2005, LEARN INSTR, V36, P26
   Scholl BJ, 2009, COMPUTATION, COGNITION, AND PYLYSHYN, P49
   Shoukot A., 2019, EUROPEAN J ED STUDIE, V6, P114
   Skukauskaite A, 2021, LEARN CULT SOC INTER, V29, DOI 10.1016/j.lcsi.2021.100499
   Tsai CY, 2020, MULTIMED TOOLS APPL, V79, P31981, DOI 10.1007/s11042-020-09584-0
   Um ER, 2008, THESIS NEW YORK U
   Um E, 2012, J EDUC PSYCHOL, V104, P485, DOI 10.1037/a0026609
   Uzun AM, 2018, COMPUT EDUC, V119, P112, DOI 10.1016/j.compedu.2018.01.002
   Wang JH, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103779
   Yang CC, 2005, TOTAL QUAL MANAG BUS, V16, P1127, DOI 10.1080/14783360500235850
   Yeh TM, 2014, HUM FACTOR ERGON MAN, V24, P172, DOI 10.1002/hfm.20358
   Yu Z., LECT NOTES COMPUTER, V12791, DOI 10.1007/978-3-030-78358-7_11
NR 76
TC 7
Z9 7
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8317
EP 8347
DI 10.1007/s11042-021-11744-9
EA FEB 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749407700001
PM 35125926
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Shi, PF
   Lu, L
   Fan, XN
   Xin, YX
   Ni, JJ
AF Shi, Pengfei
   Lu, Liang
   Fan, Xinnan
   Xin, Yuanxue
   Ni, Jianjun
TI A novel underwater sonar image enhancement algorithm based on
   approximation spaces of random sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sonar image enhancement; Random sets; Dark channel theory
ID CONTRAST ENHANCEMENT; WAVELET TRANSFORM
AB Underwater environment is complex and random. The images obtained from underwater by sonar always have uneven background gray distribution and fuzzy details of boundary. Hence the low-quality sonar images need to be enhanced before analysis. This paper presents a sonar image enhancement algorithm based on the approximation spaces of random sets. First of all, the knowledge representation of the underwater image is constructed by the approximation spaces of random sets. According to the background knowledge, the image is divided by the upper and lower approximation space of the random set. Then the optimal partition is obtained according to the approximate equivalence relation of the upper and lower approximation. Based on the optimal partition, an improved dark channel theory is presented to enhance each region of the image. After that, sonar images with different backgrounds are used to test the proposed method. The experimental results show that the gray distribution of the sonar image enhanced by this algorithm is more uniform and the boundary details are clearer. The proposed algorithm has the advantage of solving the optimal division for the set of pixels with approximate grayscale. Moreover, the proposed algorithm can get better image enhancement effect in the premise of maintaining the texture of the sonar images.
C1 [Shi, Pengfei; Lu, Liang; Fan, Xinnan; Xin, Yuanxue; Ni, Jianjun] Hohai Univ, Coll IOT Engn, Changzhou 213022, Jiangsu, Peoples R China.
C3 Hohai University
RP Fan, XN (corresponding author), Hohai Univ, Coll IOT Engn, Changzhou 213022, Jiangsu, Peoples R China.
EM shipf@hhu.edu.cn; lul@hhu.edu.cn; fanxn@hhuc.edu.cn; xinyx@hhu.edu.cn;
   njjhhuc@gmail.com
FU National Natural Science Foundation of China [61801169, 61801168,
   61873086]; Applied Basic Research Programs of Changzhou [CJ20200061];
   Fundamental Research Funds for the Central Universities [B210202090]
FX This work was funded by the National Natural Science Foundation of China
   (grant numbers 61801169, 61801168, 61873086), the Applied Basic Research
   Programs of Changzhou (CJ20200061) and the Fundamental Research Funds
   for the Central Universities(B210202090).
CR Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   Carneiro P, 2019, IEEE LAT AM T, V17, P851, DOI 10.1109/TLA.2019.8891954
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Fan C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030623
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Ghani ASA, 2018, OCEAN ENG, V162, P224, DOI 10.1016/j.oceaneng.2018.05.027
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li H, 2016, MED PHYS, V43, P1795, DOI 10.1118/1.4943567
   Liu T, 2015, MECH SYST SIGNAL PR, V62-63, P366, DOI 10.1016/j.ymssp.2015.03.010
   Nason G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137662
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Priyadharsini R, 2018, MULTIDIM SYST SIGN P, V29, P1845, DOI 10.1007/s11045-017-0533-5
   Rahnemoonfar M, 2019, IEEE J OCEANIC ENG, V44, P132, DOI 10.1109/JOE.2017.2780707
   Sdiri B, 2019, IEEE T MED IMAGING, V38, P33, DOI 10.1109/TMI.2018.2853808
   Shi ZH, 2020, IET IMAGE PROCESS, V14, P747, DOI 10.1049/iet-ipr.2019.0992
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Teng L, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2902959
   Tian JY, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050662
   Wang JW, 2016, PATTERN RECOGN, V57, P31, DOI 10.1016/j.patcog.2016.03.021
   Wang XY, 2018, INT J AGR BIOL ENG, V11, P170, DOI 10.25165/j.ijabe.20181102.3357
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yoon KS, 2019, IET IMAGE PROCESS, V13, P15, DOI 10.1049/iet-ipr.2018.5675
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhao F, 2016, INFRARED PHYS TECHN, V76, P408, DOI 10.1016/j.infrared.2016.03.022
NR 27
TC 3
Z9 4
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4569
EP 4584
DI 10.1007/s11042-020-10187-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7J4MT
UT WOS:000904556500001
DA 2024-07-18
ER

PT J
AU Jiang, RQ
   Feng, SS
   Zhang, SJ
   Li, X
   Yao, Y
   Zhang, HX
AF Jiang, Runqing
   Feng, Shanshan
   Zhang, Shoujia
   Li, Xi
   Yao, Yan
   Zhang, Huaxiang
TI A personalized recommendation method based on collaborative ranking with
   random walk
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized recommendation; Collaborative ranking; Random walk model
ID ALGORITHM; TOP
AB To improve the performance of recommender systems in a practical manner, many hybrid recommendation approaches have been proposed. Recently, some researchers apply the idea of ranking to recommender systems which yield plausible results. Collaborative ranking is a popular ranking based method, it regards that unrated items have lower rankings than rated items for a user. Unfortunately, the existing collaborative ranking approaches only focus on the partial associations with users and items, and thus fail to detect some features that could potentially improve the performance of the recommender systems. For this reason, these methods continue to suffer from data sparsity and do not work well for recommending an interesting item to an individual user. To address these issues, we present an Assembled Collaborative Ranking with Random Walk (ACR-RW) approach based on the combination of collaborative ranking and random walk method, which can be used to rank items according to expected user preferences by detecting both absolute and relative correlative information, in order to recommend top-ranked items to potentially interested users. On the basis of ACR-RW, we can improve the collaborative ranking approaches by adding absolute relationship information and defining the partial order relationship in assemblages rather than the global, so as to better describe and predict one user's preference. Finally, we implement experiments on three real-world datasets, and the results show that our approach consistently outperforms all other comparative approaches, demonstrating its effectiveness for recommendation tasks.
C1 [Jiang, Runqing; Feng, Shanshan; Zhang, Shoujia; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Li, Xi] Shandong Normal Univ, Primary Sch, Jinan, Peoples R China.
   [Yao, Yan] Qilu Univ Technol, Shandong Acad Sci, Sch Comp Sci & Technol, Jinan, Peoples R China.
C3 Shandong Normal University; Shandong Normal University; Qilu University
   of Technology
RP Feng, SS (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
EM runqingjiang@163.com; fsw16869@foxmail.com; sdnusjzhang@163.com;
   lixixi1984@hotmail.com; yaoyan@qlu.edu.cn; huaxzhang@163.com
RI Yao, Yan/GQH-5561-2022
OI YAO, Yan/0000-0002-0115-7996; Yao, Yan/0000-0003-4830-8648
FU Taishan Scholar Project of Shandong of China; National Natural Science
   Foundation of China [U1836216]
FX This work was supported in part by Taishan Scholar Project of Shandong
   of China, and the National Natural Science Foundation of China under
   Grant U1836216.
CR [Anonymous], 2007, C NEUR INF PROC SYST
   [Anonymous], 2004, Proceedings of the international ACM SIGIR conference on Research and development in information retrieval(SIGIR), DOI [10.1145/1008992.1009051, DOI 10.1145/1008992.1009051]
   [Anonymous], 2012, Advances in Neural Information Processing Systems
   Balakrishnan Suhrid, 2012, P 5 ACM INT C WEB SE, P143, DOI DOI 10.1145/2124295.2124314
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Christakopoulou K, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P205, DOI 10.1145/2736277.2741678
   Elkahky A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P278, DOI 10.1145/2736277.2741667
   Feng SS, 2019, KNOWL-BASED SYST, V171, P56, DOI 10.1016/j.knosys.2019.02.002
   Feng YF, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2421, DOI 10.1145/3340531.3412729
   Guo Guibing, 2015, UMAP workshops
   Hazrati N, 2019, EXPERT SYST APPL, V116, P161, DOI 10.1016/j.eswa.2018.09.013
   He X, 2020, ARXIV 170805024
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Huang C, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P339, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00066
   Hwang TG, 2016, MULTIMED TOOLS APPL, V75, P12843, DOI 10.1007/s11042-016-3526-8
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kouadria A, 2020, ARAB J SCI ENG, V45, P2835, DOI 10.1007/s13369-019-04180-3
   Lee J, 2016, INFORM SCIENCES, V348, P290, DOI 10.1016/j.ins.2016.02.005
   Lee J, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P85, DOI 10.1145/2566486.2567970
   Li G, 2016, NEUROCOMPUTING, V204, P17, DOI 10.1016/j.neucom.2015.08.129
   Li X, 2020, P 11 IFIP TC 12 INT, P67
   Liang DW, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P59, DOI 10.1145/2959100.2959182
   Liu SH, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P861, DOI 10.1145/3077136.3080663
   Liu W, 2020, WORLD WIDE WEB, V23, P131, DOI 10.1007/s11280-019-00681-1
   Liu Z, 2020, INT J COMPUT INT SYS, V13, P24, DOI 10.2991/ijcis.d.200114.001
   Manju G, 2020, INT J INTELL INF TEC, V16, P24, DOI 10.4018/IJIIT.2020040102
   Pan W., 2013, P 23 INT JOINT C ART, P2691, DOI DOI 10.5555/2540128.2540516
   Pan WK, 2015, KNOWL-BASED SYST, V73, P173, DOI 10.1016/j.knosys.2014.09.013
   Park D, 2015, PR MACH LEARN RES, V37, P1907
   Park H, 2017, IEEE INT CONF BIG DA, P756, DOI 10.1109/BigData.2017.8257991
   Peña FJ, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P438, DOI 10.1145/3383313.3412207
   Rafailidis D, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P785, DOI 10.1145/2911451.2914711
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Rudin C, 2009, J MACH LEARN RES, V10, P2233
   Shao YX, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1797, DOI 10.1145/3318464.3380562
   Shi Y., 2012, P 6 ACM C RECOMMENDE, P139, DOI [10.1145/2365952.2365981, DOI 10.1145/2365952.2365981]
   Song B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1353, DOI 10.1145/3269206.3271715
   Tian DP, 2020, INT J MACH LEARN CYB, V11, P417, DOI 10.1007/s13042-019-00983-w
   Tong HH, 2006, IEEE DATA MINING, P613
   Vahedian F, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P230, DOI 10.1145/3079628.3079685
   Wang C, 2020, AAAI CONF ARTIF INTE, V34, P6127
   Wu LW, 2018, PR MACH LEARN RES, V80
   Xu B, 2020, SOFT COMPUT, V24, P1707, DOI 10.1007/s00500-019-03998-1
   Yang JH, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P140, DOI 10.1145/3240323.3240381
   Yatnalkar G, 2020, PROCEDIA COMPUT SCI, V170, P626, DOI 10.1016/j.procs.2020.03.135
   Yu M, 2022, NEURAL COMPUT APPL, V34, P2503, DOI 10.1007/s00521-021-05933-8
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 47
TC 2
Z9 2
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7345
EP 7363
DI 10.1007/s11042-022-11980-7
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000748678300001
DA 2024-07-18
ER

PT J
AU Leite, L
AF Leite, Luis
TI Pull-the-strings Generic mapping model for digital puppetry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Interaction design; Digital puppetry; Performance animation; Node-base
   interfaces; Real-time mapping
AB Pull-the-Strings presents a mapping model for digital puppetry based on a transparent framework to support generic device controllers and generic tools. Digital puppetry requires a creative interaction design, in particular in the way designers map the puppet to the puppeteer using specific devices. This process depends on a constantly changing interface technology, which limits the reuse of devices and mappings. This paper proposes a methodology and a set of tools that facilitate the mapping process, and promote the recycling of technologies. A flexible and generic environment independent from device specifications. By abstracting the hardware layer, the artist is motivated to think in terms of signal flow, establishing relations through meaningful mappings instead of handling the diverse specifications of each device and application. Pull-the-Strings is a data-flow ecosystem that focus on the functional usage of control signals. It provides a scalable environment for building semantic blocks that connect, transform and generate signals for the manipulation of virtual objects. Its goal is to make technology as transparent as possible, facilitating connections and reducing the obstacles between the performer and the performing object. On the other hand, it proposes an interaction design space that takes into account the manipulation and perception distance, responding to the specifications of the digital puppetry medium. This model was evaluated comparing a set of tools and methods with experienced and non-experienced users.
C1 [Leite, Luis] UniMAD, ESMAD P Porto, Porto, Portugal.
C3 Instituto Politecnico do Porto
RP Leite, L (corresponding author), UniMAD, ESMAD P Porto, Porto, Portugal.
EM luisleite@esmad.ipp.pt
RI Barbosa da Costa Leite, Luís Miguel/S-8287-2016
OI Barbosa da Costa Leite, Luís Miguel/0000-0001-5507-2237
CR Anson E., 1982, Computer Graphics, V16, P107, DOI 10.1145/965145.801269
   Bleser F D., 2002, NodeBox
   Bodenheimer B., 1997, The process of motion capture: Dealing with the data Computer Animation and Simulation'97, P3
   Card S.K., 1990, P SIGCHI C HUMAN FAC, P117, DOI 10.1145/97243.97263
   Coduys T, INT C SOUND MUS COMP, P194
   Francis Penny., 2011, Puppetry: A Reader in Theatre Practice
   Hinckley K, 2012, HUM FACTORS ERGON, P95
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   LEite Luis, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3095804
   Leite L., 2018, THESIS U PORTO
   Leite L., 2017, Matlit, V6, DOI DOI 10.14195/2182-8830_6-1_13
   Leite L, 2020, INT C LIV INT TRONDH
   Leite L.M., 2016, Proceedings of the 1st International Workshop on Multimedia Alternate Realities, P3
   Lucey S, 2010, IMAGE VISION COMPUT, V28, P781, DOI 10.1016/j.imavis.2009.09.009
   Morrison JP., 2013, FLOW BASED PROGRAMMI
   Rudraraju V., 2011, TOOL CONFIGURING MAP, P1
   Walther-Franks B, 2014, ENTERTAIN COMPUT, V5, P271, DOI 10.1016/j.entcom.2014.08.007
   Wright M, 2001, ICMC
NR 18
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JAN 26
PY 2022
DI 10.1007/s11042-021-11876-y
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP5QS
UT WOS:000748678300007
DA 2024-07-18
ER

PT J
AU Koc, M
   Sut, SK
   Serhatlioglu, I
   Baygin, M
   Tuncer, T
AF Koc, Mustafa
   Sut, Suat Kamil
   Serhatlioglu, Ihsan
   Baygin, Mehmet
   Tuncer, Turker
TI Automatic prostate cancer detection model based on ensemble VGGNet
   feature generation and NCA feature selection using magnetic resonance
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble VGG; Prostate cancer diagnosis; MRI image processing; NCA;
   Biomedical image classification
ID COMPUTER-AIDED DIAGNOSIS; MRI
AB Prostate cancer is one of the most common types of cancer in men and its frequency is 28 per hundred thousand in the world. This cancer is detected using Magnetic Resonance Imaging (MRI). By using these images, an automatic prostate cancer diagnosis model must be introduced to simplify diagnosis process. A new MRI image dataset were collected from Firat University Hospital retrospectively. This image corpus contains malign and benign prostate cancer images. A novel transfer learning based model is presented for this dataset. Deep feature generation, feature selection with neighborhood component analysis (NCA) and classification are the primary phases of these model. (i) Deep features of the used prostate MRI images are extracted using VGG16 and VGG19 networks. These networks are pre-trained and they were trained on ImageNet dataset. Three fully connected layers (fc6, fc7 and fc8) of these networks are used to generate features and the generated features are merged. (ii) NCA selects top 500 features and (iii) the features chosen are classified using Cubic k nearest neighbors (kNN) algorithm. By deploying the presented ensemble VGG feature generator and NCA selector based technique, 98.01% accuracy was calculated. Moreover, other widely used performance evaluation metrics and confusion matrices were given to evaluate this model comprehensively. Results and findings obviously denoted the success of the recommended ensemble VGG feature generator and NCA selector based prostate cancer classification model.
C1 [Koc, Mustafa; Sut, Suat Kamil] Firat Univ, Med Fac, Dept Radiol, Elazig, Turkey.
   [Serhatlioglu, Ihsan] Firat Univ, Med Fac, Dept Biophys, Elazig, Turkey.
   [Baygin, Mehmet] Ardahan Univ, Coll Engn, Dept Comp Engn, Ardahan, Turkey.
   [Tuncer, Turker] Firat Univ, Coll Technol, Dept Digital Forens Engn, Elazig, Turkey.
C3 Firat University; Firat University; Ardahan University; Firat University
RP Baygin, M (corresponding author), Ardahan Univ, Coll Engn, Dept Comp Engn, Ardahan, Turkey.
EM mkoc@firat.edu.tr; sksut@firat.edu.tr; iserhatlioglu@firat.edu.tr;
   mehmetbaygin@ardahan.edu.tr; turkertuncer@firat.edu.tr
RI TUNCER, Turker/W-4846-2018; Serhatlioglu, Ihsan/V-9821-2018; Baygin,
   Mehmet/AAT-5720-2021
OI Baygin, Mehmet/0000-0001-6449-8950
CR Abbasi AA, 2020, COGN NEURODYNAMICS, V14, P523, DOI 10.1007/s11571-020-09587-5
   Ahdoot M, 2020, NEW ENGL J MED, V382, P917, DOI 10.1056/NEJMoa1910038
   Akbari H, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.7.076005
   Aldoj N, 2020, EUR RADIOL, V30, P1243, DOI 10.1007/s00330-019-06417-z
   Alkadi R, 2019, J DIGIT IMAGING, V32, P793, DOI 10.1007/s10278-018-0160-1
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2018, Prostate cancer statistics
   [Anonymous], Prostate MR Image Database
   Azizi S, 2018, IEEE T MED IMAGING, V37, P2695, DOI 10.1109/TMI.2018.2849959
   Barry MJ, 2017, MED CLIN N AM, V101, P787, DOI 10.1016/j.mcna.2017.03.009
   Carrington AM, DEEP ROC ANAL AUC BA
   Carroll PH, 2018, J NATL COMPR CANC NE, V16, P620, DOI 10.6004/jnccn.2018.0036
   Culp MB, 2020, EUR UROL, V77, P38, DOI 10.1016/j.eururo.2019.08.005
   Duran-Lopez L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041122
   Duran-Lopez L, 2020, IEEE ACCESS, V8, P128613, DOI 10.1109/ACCESS.2020.3008868
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Galbusera F, 2019, JOR SPINE, V2, DOI 10.1002/jsp2.1044
   Han WC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66849-2
   Holzinger Andreas, 2021, I Com (Berl), V19, P171, DOI 10.1515/icom-2020-0024
   Iqbal S, 2021, IEEE ACCESS, V9, P27085, DOI 10.1109/ACCESS.2021.3057654
   Ishioka J, 2018, BJU INT, V122, P411, DOI 10.1111/bju.14397
   Jafari-Khouzani K, 2003, IEEE T BIO-MED ENG, V50, P697, DOI 10.1109/TBME.2003.812194
   Kiraly Atilla P., 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P489, DOI 10.1007/978-3-319-66179-7_56
   Lemaître G, 2015, COMPUT BIOL MED, V60, P8, DOI 10.1016/j.compbiomed.2015.02.009
   Li MS, 2021, RADIOLOGY, V299, P362, DOI 10.1148/radiol.2021201852
   Litjens G., 2017, Cancer Imaging Arch
   Litjens G, 2014, IEEE T MED IMAGING, V33, P1083, DOI 10.1109/TMI.2014.2303821
   Liu SF, 2017, PROC SPIE, V10134, DOI 10.1117/12.2277121
   Mendhiratta N, 2016, FUTURE ONCOL, V12, P2431, DOI 10.2217/fon-2016-0169
   Rawla P, 2019, WORLD J ONCOL, V10, P63, DOI 10.14740/wjon1191
   Schneeberger David, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P209, DOI 10.1007/978-3-030-57321-8_12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stabile A, 2020, NAT REV UROL, V17, P41, DOI 10.1038/s41585-019-0212-4
   Sumathipala Y, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.4.044507
   Tsehay YK, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254423
   Tuncer T, 2020, BIOCYBERN BIOMED ENG, V40, P211, DOI 10.1016/j.bbe.2019.05.006
   Tuncer T, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123143
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Uthappa PP, 2019, IEEE ENG MED BIO, P899, DOI [10.1109/embc.2019.8856912, 10.1109/EMBC.2019.8856912]
   Wang YZ, 2018, INT C PATT RECOG, P3814, DOI 10.1109/ICPR.2018.8545754
   Wulczyn E, 2020, PREDICTING PROSTATE
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Yoo S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55972-4
   Zhao HX, 2013, EUR J RADIOL, V82, pE641, DOI 10.1016/j.ejrad.2013.07.004
NR 45
TC 8
Z9 9
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7125
EP 7144
DI 10.1007/s11042-022-11906-3
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700009
DA 2024-07-18
ER

PT J
AU Chen, TZ
   Zhu, KN
   Yang, MC
AF Chen, Taizhou
   Zhu, Kening
   Yang, Ming Chieh
TI Deep-learning-based unobtrusive handedness prediction for one-handed
   smartphone interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handedness prediction; LSTM; Smartphone interaction; Motion sensor;
   Single hand
AB The handedness (i.e. the side of the holding and operating hand) is an important contextual information to optimise the one-handed smartphone interaction. In this paper, we present a deep-learning-based technique for unobtrusive handedness prediction in one-handed smartphone interaction. Our approach is built upon a multilayer LSTM (Long-Short-Term Memory) neural network, and processes the built-in motion-sensor data of the phone in real time. Compared to the existing approaches, our approach eliminates the need of extra user actions (e.g., on-screen tapping and swiping), and predicts the handedness based on the picking-up action and the holding posture before the user performs any operation on the screen. Our approach is able to predict the handedness when a user is sitting, standing, and walking at an accuracy of 97.4%, 94.6%, and 92.4%, respectively. We also show that our approach is robust to the turbulent noise with an average accuracy of 94.6% for the situations of users in the transportation tools (e.g., bus, train, and scooter). Furthermore, the presented approach can classify users' real-life single-handed smartphone usage into left- and right-handed with an average accuracy of 89.2%.
C1 [Chen, Taizhou; Zhu, Kening; Yang, Ming Chieh] City Univ Kong Kong, Sch Creat Media, Hong Kong, Peoples R China.
   [Zhu, Kening] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
C3 Shenzhen Research Institute, City University of Hong Kong; City
   University of Hong Kong
RP Zhu, KN (corresponding author), City Univ Kong Kong, Sch Creat Media, Hong Kong, Peoples R China.; Zhu, KN (corresponding author), City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
EM taizhou.chen@my.cityu.edu.hk; keninzhu@cityu.edu.hk
RI Chen, Taizhou/JCE-3988-2023; Zhu, Kening/AAI-8826-2020; Chen,
   Taizhou/GLS-7899-2022
OI Zhu, Kening/0000-0001-6740-4921; CHEN, Taizhou/0000-0002-7005-4560
FU Young Scientists Scheme of the National Natural Science Foundation of
   China [61907037]; Centre for Applied Computing and Interactive Media
   (ACIM) of School of Creative Media, City University of Hong Kong;
   National Natural Science Foundation of China [62172346]; Guangdong Basic
   and Applied Basic Research Foundation [2021A1515011893]; Applied
   Research Grant [9667189]
FX This research was partially supported by the Young Scientists Scheme of
   the National Natural Science Foundation of China (Project No. 61907037),
   the Applied Research Grant (Project No. 9667189), and the Centre for
   Applied Computing and Interactive Media (ACIM) of School of Creative
   Media, City University of Hong Kong. This work was also partially
   supported the National Natural Science Foundation of China (Project No.
   62172346), and the Guangdong Basic and Applied Basic Research Foundation
   (Project No. 2021A1515011893)
CR Alexander N, 2014, P ACM CHI 14 C HUM F
   ALLUM JHJ, 1978, J NEUROPHYSIOL, V41, P557, DOI 10.1152/jn.1978.41.3.557
   [Anonymous], 2015, ADJUNCT P 28 ANN ACM, DOI DOI 10.1145/2815585.2815722
   Avery J, 2019, IHM 2019 ACT 31E C F, P1, DOI [10.1145/3366550.3372253, DOI 10.1145/3366550.3372253]
   Bagesteiro LB, 2002, J NEUROPHYSIOL, V88, P2408, DOI 10.1152/jn.00901.2001
   BALOGUN J A, 1992, Physiotherapy Theory and Practice, V8, P89, DOI 10.3109/09593989209108086
   Beuter A, 2000, INT J NEUROSCI, V101, P9, DOI 10.3109/00207450008986489
   Buschek D, 2017, LECT NOTES COMPUT SC, V10515, P184, DOI 10.1007/978-3-319-67687-6_13
   Carroll A., 2017, Understanding and reducing smartphone energy consumption
   Chang Y, 2014, UIST 2014 ADJ PUBL 2, P115, DOI [10.1145/2658779.2658803, DOI 10.1145/2658779.2658803]
   [陈忠平 Chen Zhongping], 2015, [高分子通报, Polymer Bulletin], P67
   Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784
   Durgun, 2018, 19 NAT AN C 1 INT ME
   Fernández C, 2017, IEEE INT CONF MOB, P520, DOI 10.1109/MASS.2017.74
   Goel M., 2013, Proceedings of the SIGCHI Conference on Human Factors inComputing Systems. CHI '13, P2795, DOI DOI 10.1145/2470654.2481386
   Goel M, 2016, GRIPSENSE USING BUIL, P545, DOI 10.1145/2380116.2380184
   Guo HS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081314
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S., 1997, LONG SHORT TERM MEMO, V9, P32
   Huang YH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275108
   Le HV, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P779, DOI 10.1145/3242587.3242605
   Karlson A., 2008, HDB RES USER INTERFA, P86, DOI DOI 10.4018/978-1-59904-871-0.CH006
   Karlson A.K., 2005, Proc. of CHI '05, P201, DOI DOI 10.1145/1054972.1055001
   Karlson AK, 2007, LECT NOTES COMPUT SC, V4662, P324
   Kim K., 2006, Proc. IAAI, P1789
   Kim NS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317853
   Kim N, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P105, DOI 10.1145/3123024.3123090
   Kingma D. P., 2014, arXiv
   KOPEC JA, 1990, J EPIDEMIOL COMMUN H, V44, P179, DOI 10.1136/jech.44.3.179
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kubo Yuki, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130934
   Laudani L, 2006, J ELECTROMYOGR KINES, V16, P603, DOI 10.1016/j.jelekin.2006.08.001
   Le HuyViet., 2016, P 2016 CHI C EXTENDE, P2576
   LE HV, 2017, P 19 INT C HUM COMP
   Lee WH, 2017, PROCEEDINGS OF THE 22ND ACM SYMPOSIUM ON ACCESS CONTROL MODELS AND TECHNOLOGIES (SACMAT'17), P67, DOI 10.1145/3078861.3078870
   Li WHA, 2017, INT J MOB HUM COMPUT, V9, P16, DOI 10.4018/IJMHCI.2017010102
   Li WHA, 2016, INT J MOB HUM COMPUT, V8, P1, DOI 10.4018/IJMHCI.2016010101
   Lim H, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P675, DOI 10.1145/2957265.2961857
   Löchtefeld M, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P245, DOI 10.1145/2836041.2836066
   McAuley JH, 2000, BRAIN, V123, P1545, DOI 10.1093/brain/123.8.1545
   Nelavelli K, 2018, ADAPTIVE APP DESIGN
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Papadatou-Pastou M, 2021, EUR J PSYCHOL EDUC, V36, P511, DOI 10.1007/s10212-020-00485-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Lim Tan, 2019, 10th International Conference on Robotics, Vision, Signal Processing and Power Applications. Enabling Research and Innovation Towards Sustainability. Lecture Notes in Electrical Engineering (LNEE 547), P19, DOI 10.1007/978-981-13-6447-1_3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Taylor B, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P917
   Taylor BT, 2008, CHI 08 HUM FACT COMP, P3459, DOI [10.1145/1358628.1358874, DOI 10.1145/1358628.1358874]
   Wimmer Raphael., 2009, P 3 INT C TANGIBLE E, P359, DOI DOI 10.1145/1517664.1517736
   Wong Pui Chung, 2016, SIGGRAPH ASIA 2016 M, DOI [DOI 10.1145/2999508.2999522, 10.1145/ 2999508.2999522]
   Wright R. E., 1995, Reading and Understanding Multivariate Statistics, P217
   Yao SC, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P351, DOI 10.1145/3038912.3052577
   YU C, 2019, C HUM FACT COMP SYST
   Zhu KN, 2017, INT J HUM-COMPUT INT, V33, P443, DOI 10.1080/10447318.2016.1275432
NR 57
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4941
EP 4964
DI 10.1007/s11042-021-11844-6
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000743863400002
DA 2024-07-18
ER

PT J
AU Avsar, E
   Avsar, YÖ
AF Avsar, Ercan
   Avsar, Yagmur Ozinal
TI Moving vehicle detection and tracking at roundabouts using deep learning
   with trajectory union
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entry; exit matrix; DeepSORT; Roundabout; Kalman filter; Vehicle
   tracking; YOLO
AB The number of vehicles and turning movements at roundabouts provide important information for planning, design and operational analysis of roundabouts. The visual data collected through video cameras make it possible to determine such information via computer-based methods. In this work, a method for detecting, counting, and tracking vehicles in roundabout videos is proposed. There are two main contributions of the method, (i) only the moving vehicles are considered for tracking (moving vehicle detection) and (ii) the vehicle tracks output by the object tracking algorithms are processed to reduce the false track rate (trajectory union). The vehicle detection is performed using YOLOv4, and vehicle tracking throughout the video is accomplished by either Kalman filter or DeepSORT algorithm. The output of the proposed method is compared with both manual counting results and benchmark tracking results where the entry/exit matrix is generated using only YOLOv4 and an object tracker. In a 20-min video with 297 vehicles, absolute error reached by the proposed method is 14 vehicles which corresponds to normalized absolute error percentage of 1.571%. In the same video, the same error metrics obtained by the benchmark method are 33 vehicles and 3.704%. This error tends to increase together with the rate of vehicles in the video or number of legs in the roundabout. However, the rate of increment in the error is much lower than the rate of increment in the number of vehicles in the video. In addition, lower error rates are obtained when DeepSORT is used as the vehicle tracker.
C1 [Avsar, Ercan] Dokuz Eylul Univ, Dept Comp Engn, TR-35390 Izmir, Turkey.
   [Avsar, Yagmur Ozinal] Dokuz Eylul Univ, Dept Civil Engn, TR-35390 Izmir, Turkey.
C3 Dokuz Eylul University; Dokuz Eylul University
RP Avsar, E (corresponding author), Dokuz Eylul Univ, Dept Comp Engn, TR-35390 Izmir, Turkey.
EM ercan.avsar@deu.edu.tr; yagmur.ozinal@deu.edu.tr
RI Avsar, Ercan/AFQ-0445-2022; shen, jickie/GSN-7389-2022; Ozinal Avsar,
   Yagmur/V-5824-2018
OI Avsar, Ercan/0000-0002-1356-2753; Ozinal Avsar,
   Yagmur/0000-0002-8083-6494
CR Abd-Elmagid MA, 2019, IEEE GLOB COMM CONF, DOI [10.1109/globecom38437.2019.9013924, 10.1109/itce.2019.8646549, 10.1109/ITCE.2019.8646549]
   Ammour N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040312
   Artesea, 2007, INT ARCH PHOTOGRAMME, P6
   Awang S, 2018, LECT NOTES ELECTR EN, V449, P52, DOI 10.1007/978-981-10-6451-7_7
   Bassani M, 2020, J TRAFFIC TRANSP ENG, V7, P482, DOI 10.1016/j.jtte.2019.01.005
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bui KHN, 2020, LECT NOTES ARTIF INT, V12034, P152, DOI 10.1007/978-3-030-42058-1_13
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Carranza-García M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010089
   Dai Z, 2019, IEEE ACCESS, V7, P64460, DOI 10.1109/ACCESS.2019.2914254
   Dinh H, 2017, J MOD TRANSP, V25, P12, DOI 10.1007/s40534-017-0124-z
   Fernández-Sanjurjo M, 2019, LECT NOTES COMPUT SC, V11868, P273, DOI 10.1007/978-3-030-31321-0_24
   Fernández-Sanjurjo M, 2019, ENG APPL ARTIF INTEL, V85, P410, DOI 10.1016/j.engappai.2019.07.005
   Harikrishnan PM, 2021, MULTIMED TOOLS APPL, V80, P3153, DOI 10.1007/s11042-020-09666-z
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Huang L, 2017, IEEE INT CONF BIG DA, P1153, DOI 10.1109/BigData.2017.8258041
   Ismail K., PRESENTED 89 ANN M T
   Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0
   Bui KHN, 2020, IEEE COMPUT SOC CONF, P2466, DOI 10.1109/CVPRW50498.2020.00297
   Khalkhali MB, 2022, IEEE T INTELL TRANSP, V23, P3766, DOI 10.1109/TITS.2021.3050878
   Khan MA, 2018, PROCEDIA COMPUT SCI, V130, P636, DOI 10.1016/j.procs.2018.04.114
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mohamed E, 2021, ARXIV PREPRINT ARXIV
   Murugan AS, 2018, MULTIMED TOOLS APPL, V77, P23273, DOI 10.1007/s11042-018-5671-8
   Mussone L, 2011, COMP ANAL VEHICULAR
   Mussone L, 2011, P 18 IFACWORLD C, V44, P14922
   Mussone L, 2013, J ADV TRANSPORT, V47, P581, DOI 10.1002/atr.184
   [宁欣 Ning Xin], 2019, [智能系统学报, CAAI Transactions on Intelligent Systems], V14, P121
   Ning X, 2018, LECT NOTES COMPUT SC, V11306, P441, DOI 10.1007/978-3-030-04224-0_38
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   St-Aubin P, 2015, TRANSPORT RES C-EMER, V58, P363, DOI 10.1016/j.trc.2015.04.007
   Sudha D, 2020, SOFT COMPUT, V24, P17417, DOI 10.1007/s00500-020-05042-z
   Sun MJ, 2017, J VIS COMMUN IMAGE R, V49, P412, DOI 10.1016/j.jvcir.2017.10.002
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Unzueta L, 2012, IEEE T INTELL TRANSP, V13, P527, DOI 10.1109/TITS.2011.2174358
   Wang JX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161869
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu YJ, 2006, IEEE SYS MAN CYBERN, P4631, DOI 10.1109/ICSMC.2006.385034
   Xin J, 2017, IEEE INT CON MULTI, P613, DOI 10.1109/ICME.2017.8019329
   Yang KL, 2020, IEEE INT VEH SYM, P457, DOI [10.1109/IV47402.2020.9304706, 10.1109/iv47402.2020.9304706]
   Yang KL, 2021, IEEE T IMAGE PROCESS, V30, P1866, DOI 10.1109/TIP.2020.3048682
   Yang KL, 2020, IEEE T INTELL TRANSP, V21, P4171, DOI 10.1109/TITS.2019.2938965
   Yang KL, 2019, IEEE INT VEH SYM, P446, DOI 10.1109/IVS.2019.8814042
   Zhang JX, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01750-4
   Zhang SH, 2017, IEEE I CONF COMP VIS, P3687, DOI 10.1109/ICCV.2017.396
   Zhang YJ, 2017, J PHYS CONF SER, V887, DOI 10.1088/1742-6596/887/1/012068
   Zhang ZM, 2016, IEEE IJCNN, P2267, DOI 10.1109/IJCNN.2016.7727480
NR 50
TC 11
Z9 11
U1 4
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6653
EP 6680
DI 10.1007/s11042-021-11804-0
EA JAN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742803700002
DA 2024-07-18
ER

PT J
AU Munir, N
   Khan, M
   Ismail, AKH
   Hussain, I
AF Munir, Noor
   Khan, Majid
   Ismail, Abd Al Karim Haj
   Hussain, Iqtadar
TI Cryptanalysis and Improvement of Novel Image Encryption Technique Using
   Hybrid Method of Discrete Dynamical Chaotic Maps and Brownian Motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chosen-ciphertext attack; Known-plaintext attack;
   Chosen-plaintext attack; Chaotic map
ID SYSTEM
AB Recently, an encryption technique depending on discrete dynamical chaotic maps and Brownian motion was offered. The authors of the understudy cryptosystem claim the security of encryption structure by some statistical analysis. We report cryptanalysis of a recently proposed scheme by using some cryptographic attacks. The attacks performed in this work are chosen-plaintext attack, known-plaintext attack, and chosen-ciphertext attack. The offered procedure is cryptanalyzed by taking just one chosen-plain image, one chosen-cipher image, and only one pair of plaintext and ciphertext, which shows the scheme's vulnerability. Moreover, we have offered an improved cryptosystem depending on the Basin chaotic map, Gingerbread man map, and Brownian motion, providing a robust security level.
C1 [Munir, Noor; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Munir, Noor; Khan, Majid; Ismail, Abd Al Karim Haj] Ajman Univ, Dept Math & Sci, POB 346, Ajman, U Arab Emirates.
   [Ismail, Abd Al Karim Haj] Ajman Univ, Nonlinear Dynam Res Ctr NDRC, Ajman, U Arab Emirates.
   [Hussain, Iqtadar] Qatar Univ, Math Program, Dept Math Stat & Phys, Coll Arts & Sci, Doha 2713, Qatar.
C3 Ajman University; Ajman University; Qatar University
RP Munir, N (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.; Munir, N (corresponding author), Ajman Univ, Dept Math & Sci, POB 346, Ajman, U Arab Emirates.
EM noormunirist1@gmail.com
RI Khan, Majid/T-9408-2019; HAJ ISMAIL, ABD AL KARIM/AAD-9991-2019
OI Khan, Majid/0000-0001-5454-3770; HAJ ISMAIL, ABD AL
   KARIM/0000-0003-4941-5154
FU Ajman University [2021-IRG-HBS-12]
FX The third author acknowledges Ajman University for supporting the
   research, Internal Research Grant No: [DGSR Ref. 2021-IRG-HBS-12].
CR Abdulla AA., 2014, LECT NOTES COMPUTER, DOI [10.1007/978-3-319-14054-4_10, DOI 10.1007/978-3-319-14054-4_10]
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Advanced Encryption Standard (AES), 2001, FED INF PROC STAND, DOI [10.6028/NIST.FIPS.197.197, DOI 10.6028/NIST.FIPS.197.197]
   Ahmad M, 2018, J INTELL FUZZY SYST, V34, P1323, DOI 10.3233/JIFS-169428
   Alghafis A, 2021, MULTIMED TOOLS APPL, V80, P7967, DOI 10.1007/s11042-020-10142-x
   Alghafis A, 2020, INT J THEOR PHYS, V59, P1227, DOI 10.1007/s10773-020-04402-7
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   El Hanouti I, 2021, MULTIMED TOOLS APPL, V80, P13801, DOI 10.1007/s11042-020-10289-7
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2019, INT J THEOR PHYS, V58, P2720, DOI 10.1007/s10773-019-04162-z
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Li CQ, 2005, EURASIP J APPL SIG P, V2005, P1277, DOI 10.1155/ASP.2005.1277
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   Munir Noor, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P48, DOI 10.1109/ICAEM.2018.8536308
   Munir N, 2021, IEEE ACCESS, V9, P105678, DOI 10.1109/ACCESS.2021.3099004
   Munir N, 2021, INTEGRATION, V79, P41, DOI 10.1016/j.vlsi.2021.03.004
   Munir N, 2020, WIREL NETW, DOI 10.1007/s11276-020-02361-9
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Walter Tuchman, 1997, INTERNET BESIEGED CO, P275
   Waseem HM, 2018, INT J THEOR PHYS, V57, P3584, DOI 10.1007/s10773-018-3872-6
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
NR 34
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6571
EP 6584
DI 10.1007/s11042-021-11810-2
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742610700001
DA 2024-07-18
ER

PT J
AU Bhaumik, G
   Verma, M
   Govil, MC
   Vipparthi, SK
AF Bhaumik, Gopa
   Verma, Monu
   Govil, Mahesh Chandra
   Vipparthi, Santosh Kumar
TI HyFiNet: Hybrid feature attention network for hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Deep learning; Convolutional neural network;
   HyFiNet; REEM; HyAttention
ID MOTION; LOCALIZATION
AB In this paper, we propose a portable CNN network: a hybrid feature attention network (HyFiNet) for precise hand gesture recognition. HyFiNet is designed by stacking four multi-scale refined edge extraction modules (REEMs). The REEM module is introduced to capture the refined edge information of hand gestures by incorporating hybrid feature attention (HyAttention) block. The HyAttention block is intended to focus on efficient salient features from multi-receptive fields and acquire knowledge of discriminable semantic structure for hand poses. As a resultant, multi-scale feature and hybrid feature attention mechanisms cohesively improve the performance of hand gesture recognition with a minimum computational cost. The efficiency of the proposed network is validated using six benchmark datasets: MUGD, Finger Spelling, NUS-I, NUS-II, HGR-I and Triesch, by adopting two validation schemes: person dependent and person independent. Furthermore, seven supplementary experiments are also performed for an ablation study to analyze the effectiveness of each module in the proposed network. The experimental results and visual representation indicate a substantial increase in accuracy compared to the existing state-of-the-art networks.
C1 [Bhaumik, Gopa; Govil, Mahesh Chandra] Natl Inst Technol Sikkim, CSE Dept, Sikkim, India.
   [Verma, Monu; Vipparthi, Santosh Kumar] Malaviya Natl Inst Technol Jaipur, CSE Dept, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Sikkim; National Institute of Technology (NIT System);
   Malaviya National Institute of Technology Jaipur
RP Bhaumik, G (corresponding author), Natl Inst Technol Sikkim, CSE Dept, Sikkim, India.
EM gopa.bhaumik09@nitsikkim.ac.in
RI Vipparthi, Santosh Kumar/AAV-8694-2020
OI Vipparthi, Santosh Kumar/0000-0002-5672-3537; , Gopa/0000-0002-3481-717X
CR Abavisani M, 2019, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2019.00126
   Abdelnasser H, 2015, IEEE CONF COMPUT, P17, DOI 10.1109/INFCOMW.2015.7179321
   Abdulhussein A., 2020, Eng. Technol. J., V38, P926, DOI 10.30684/etj.v38i6a.533
   Adthya V., 2020, Procedia Computer Science, V171, P2353, DOI 10.1016/j.procs.2020.04.255
   Al-Hammadi M, 2020, IEEE ACCESS, V8, P79491, DOI 10.1109/ACCESS.2020.2990434
   [Anonymous], 2011, MVA
   [Anonymous], 2011, Res Lett Inf Math Sci
   [Anonymous], 2017, ASL FINGER SPELLING
   ASIFULLAH K, 2020, ARTIF INTELL REV, P1
   Bao PJ, 2017, IEEE T CONSUM ELECTR, V63, P251, DOI 10.1109/TCE.2017.014971
   Bhaumik Gopa, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0640, DOI 10.1109/ICCSP48568.2020.9182207
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chevtchenko SF, 2018, APPL SOFT COMPUT, V73, P748, DOI 10.1016/j.asoc.2018.09.010
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Fang B, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM 2019), P390, DOI [10.1109/icarm.2019.8834314, 10.1109/ICARM.2019.8834314]
   Florensa Carlos., 2017, P 2017 IEEE 24 INT C, P1, DOI DOI 10.1109/INTERCON.2017.8079727
   Gamal HM, 2013, 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P274, DOI 10.1109/ICCES.2013.6707218
   Ganguly Biswarup, 2020, Computational Advancement in Communication Circuits and Systems. Proceedings of ICCACCS 2018. Lecture Notes in Electrical Engineering (LNEE 575), P139, DOI 10.1007/978-981-13-8687-9_13
   Gupta HP, 2016, IEEE SENS J, V16, P6425, DOI 10.1109/JSEN.2016.2581023
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Islam MZ, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P324, DOI [10.1109/iciev.2019.8858563, 10.1109/ICIEV.2019.8858563]
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Krisandria Kevin Nathanael, 2019, 2019 International Electronics Symposium (IES). Proceedings, P254, DOI 10.1109/ELECSYM.2019.8901607
   Lahiani H, 2018, PROCEDIA COMPUT SCI, V126, P254, DOI 10.1016/j.procs.2018.07.259
   Li YT, 2014, PATTERN RECOGN, V47, P80, DOI 10.1016/j.patcog.2013.05.028
   Li Y, 2018, INFORM SCIENCES, V441, P66, DOI 10.1016/j.ins.2018.02.024
   Liu FL, 2019, ARTIF INTELL REV, V52, P563, DOI 10.1007/s10462-019-09703-w
   Liu K, 2016, J REAL-TIME IMAGE PR, V11, P201, DOI 10.1007/s11554-013-0333-6
   Lu DL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1349, DOI 10.1109/ROBIO.2016.7866514
   Mohanty A., 2016, P INT C COMP VIS IM, V2, P449
   Muthukumar K, 2017, ADV NATURAL APPL SCI, V11, P314
   Naidu C., 2016, Ijsr, V5, P436
   OKAN K, 2019, 14 IEEE INT C AUT FA, P1
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Pan TY, 2022, IEEE T CYBERNETICS, V52, P3172, DOI 10.1109/TCYB.2020.3007173
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Pramod Kumar P, 2017, SCHOLARBANK NUS REPO, DOI 10.25540/6PR9-R5HS
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sedmidubsky J, 2021, IEEE ACCESS, V9, P64241, DOI 10.1109/ACCESS.2021.3075766
   Simao M, 2016, IEEE IND ELEC, P5322, DOI 10.1109/IECON.2016.7793333
   Song W, 2019, IEEE T BIOMED CIRC S, V13, P1563, DOI 10.1109/TBCAS.2019.2953998
   Su H, 2020, ADV ROBOTICS, V34, P985, DOI 10.1080/01691864.2020.1713886
   Sykora P, 2014, AASRI PROC, V9, P19, DOI 10.1016/j.aasri.2014.09.005
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Triesch J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P170, DOI 10.1109/AFGR.1996.557260
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Wei WT, 2019, PATTERN RECOGN LETT, V119, P131, DOI 10.1016/j.patrec.2017.12.005
   Yamashita T, 2014, IEEE IMAGE PROC, P853, DOI 10.1109/ICIP.2014.7025171
   YingYing C. H. E. N., 2021, Patent No. [10,992,774, 10992774]
   Youdong Ding, 2011, 2011 International Conference on Multimedia Technology, P3171
   Yu B, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5910
   Zeng W, 2018, MULTIMED TOOLS APPL, V77, P28185, DOI 10.1007/s11042-018-5998-1
   Zhan F, 2019, 2019 IEEE 20TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2019), P295, DOI 10.1109/IRI.2019.00054
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 59
TC 17
Z9 17
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4863
EP 4882
DI 10.1007/s11042-021-11623-3
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000740429700026
DA 2024-07-18
ER

PT J
AU Hao, PC
   Yang, M
   Zheng, NN
AF Hao, Pengcheng
   Yang, Meng
   Zheng, Nanning
TI Subjective low-light image enhancement based on a foreground saliency
   map model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image; Saliency map; Depth map; CNN; Image enhancement
ID HISTOGRAM EQUALIZATION
AB Most existing low-light image enhancement methods enhance whole low-light image indiscriminately with the neglect of its subjective content, which may lead to over-enhancement and noise amplification problems in background. In this paper, we explore the challenging subjective low-light image enhancement problem. To this end, we first develop a novel foreground saliency detection model to measure the subjective content of low-light images. It is achieved by learning a saliency map and a depth map of low-light images based on CNN technique, and then fusing the two maps based on the Guided filter. Then, we incorporate the foreground saliency map model into a general retinex-based low-light image enhancement framework. Experimental results show that the proposed method well improves the subjective perception of low-light images without amplifying the noise in background compared with existing methods.
C1 [Hao, Pengcheng; Yang, Meng; Zheng, Nanning] Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Yang, M (corresponding author), Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
EM mengyang@mail.xjtu.edu.cn
FU National Key R&D Program of China [2021YFB2401904]
FX This work was supported by the National Key R&D Program of China (Grant
   No. 2021YFB2401904).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Ban SW, 2011, NEUROCOMPUTING, V74, P1916, DOI 10.1016/j.neucom.2010.07.033
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruce N., 2010, Journal of Vision, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Cheng FY, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fan Q, 2016, NEUROCOMPUTING, V175, P81, DOI 10.1016/j.neucom.2015.10.030
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rahman, 2002, P IEEE INT C IM PROC
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shen L., 2017, ARXIV PREPRINT ARXIV, P171102488
   Tavakoli HR, 2017, LECT NOTES COMPUT SC, V10116, P287, DOI 10.1007/978-3-319-54407-6_19
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang N, 2012, PROC SPIE, V8334, DOI 10.1117/12.946095
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang YF, 2016, NEUROCOMPUTING, V177, P373, DOI 10.1016/j.neucom.2015.10.124
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Yan H, 2018, NEUROCOMPUTING, V280, P86, DOI 10.1016/j.neucom.2017.08.074
   Yu F., 2015, ARXIV
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 40
TC 3
Z9 4
U1 4
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4961
EP 4978
DI 10.1007/s11042-021-11590-9
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700039
DA 2024-07-18
ER

PT J
AU Mondal, B
   Singh, JP
AF Mondal, Bhaskar
   Singh, Jyoti Prakash
TI A lightweight image encryption scheme based on chaos and diffusion
   circuit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Pseudorandom bit sequence generator; Encryption;
   Chaotic map; Diffusion circuit
ID ALGORITHM; DNA; PERMUTATION
AB The Internet of Things (IoT) devices is being deployed in almost all aspects of human life starting from smart home, health monitoring, smart metering, to smart garbage collection and industrial applications. These devices sense and collects data from the environment and send it to other high power computing devices called fog nodes or to the cloud. One of the major challenges in this process is secure communication of data as the IoT devices are having low processing power, memory and energy constraints. This paper proposes a lightweight encryption technique for images using chaotic maps and diffusion circuits. The chaotic maps are used to control the generation of random number sequences which are used for permutation and substitution of the pixel values in images. Both permutation and substitution of the pixel values are done in one scan of the image only reducing the time complexity. The substitution operations are simple bit-wise operations reducing the computational overhead. The scheme is tested by several statistical and security tests to ensure its strength against attacks.
C1 [Mondal, Bhaskar; Singh, Jyoti Prakash] Natl Inst Technol Patna, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, JP (corresponding author), Natl Inst Technol Patna, Patna, Bihar, India.
EM bhaskar.cs@nitp.ac.in; jps@nitp.ac.in
RI Singh, Jyoti Prakash/I-4953-2016; Mondal, Dr. Bhaskar/Q-6376-2018
OI Singh, Jyoti Prakash/0000-0002-3742-7484; Mondal, Dr.
   Bhaskar/0000-0001-6863-9183
CR Akhavan A, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-126
   Amigó JM, 2007, PHYS LETT A, V366, P211, DOI 10.1016/j.physleta.2007.02.021
   Bai T, 2019, FUTURE GENER COMP SY, V92, P800, DOI 10.1016/j.future.2018.01.031
   Bi MH, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2661581
   Çavusoglu Ü, 2019, CLUSTER COMPUT, V22, P1211, DOI 10.1007/s10586-018-02895-w
   Chen JX, 2014, OPTIK, V125, P2472, DOI 10.1016/j.ijleo.2013.12.001
   Daemen Joan., 1991, Journal of Cryptology, V4, P3, DOI DOI 10.1007/BF00630563
   Dhanda SS, 2020, WIRELESS PERS COMMUN, V112, P1947, DOI 10.1007/s11277-020-07134-3
   Essaid M, 2019, J INF SECUR APPL, V47, P173, DOI 10.1016/j.jisa.2019.05.006
   Hamza R, 2018, IEEE ACCESS, V6, P60160, DOI 10.1109/ACCESS.2017.2762405
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kamrani A, 2020, MULTIMED TOOLS APPL, V79, P20263, DOI 10.1007/s11042-020-08879-6
   LAI XJ, 1991, LECT NOTES COMPUT SC, V473, P389
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Liu P, 2019, MULTIMED TOOLS APPL, V78, P14823, DOI 10.1007/s11042-018-6758-y
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mondal B, 2019, INT J ADV INTELL PAR, V13, P67, DOI [DOI 10.1504/IJAIP.2019.099944, 10.1504/IJAIP.2019.099944]
   Mondal B., 2017, ICICCS, P261, DOI [10.15439/2017R47, DOI 10.15439/2017R47]
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Montero-Canela R, 2020, AD HOC NETW, V97, DOI 10.1016/j.adhoc.2019.102005
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Nesa N, 2019, J INF SECUR APPL, V47, P320, DOI 10.1016/j.jisa.2019.05.017
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Premkumar R, 2019, MULTIMED TOOLS APPL, V78, P9577, DOI 10.1007/s11042-018-6534-z
   Rayappan D, 2021, WIREL NETW, V27, P981, DOI 10.1007/s11276-020-02486-x
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P5083, DOI 10.1007/s12652-020-01813-6
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Wang XY, 2020, MULTIMED TOOLS APPL, V79, P19005, DOI 10.1007/s11042-020-08810-z
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang Q, 2009, 2009 FOURTH INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, PROCEEDINGS, P75, DOI 10.1109/BICTA.2009.5338151
NR 39
TC 18
Z9 18
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34547
EP 34571
DI 10.1007/s11042-021-11657-7
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000740429700006
DA 2024-07-18
ER

PT J
AU Li, SW
   Liu, F
   Wei, J
AF Li, Shiwen
   Liu, Feng
   Wei, Jian
TI Underwater image restoration based on exponentiated mean local variance
   and extrinsic prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image restoration; Exponentiated mean local variance;
   Boundary constraint; Transmission map
ID ENHANCEMENT; QUALITY; COLOR
AB Due to the absorption and scattering of light when it travels in water, underwater imaging has various problems, such as color distortion and low contrast. In general, it is difficult to accurately estimate the transmission map of underwater image during the restoration process, while it is easy to introduce external noise. In view of the above two problems, firstly, we estimate the original transmission map of underwater images by the intrinsic boundary constraint based on the scene radiance. Then, we develop a novel variational framework combined with the exponentiated mean local variance and extrinsic prior of transmission map for keeping the image edge and removing noise. Finally, we make quantitative and qualitative analyses of the restored underwater images. The experiments demonstrate that the method proposed in this paper has certain advantages compared with other methods. In quantitative comparison, our proposed method has higher image quality evaluation score. For qualitative analysis, the images restored using our method not only have natural colors and good contrast, but the details of the images are also well maintained.
C1 [Li, Shiwen; Liu, Feng; Wei, Jian] Nanjing Univ Posts & Telecommun, 66 Xin Mofan Rd, Nanjing 210003, Peoples R China.
   [Li, Shiwen] Heyuan Polytech, Sch Elect & Informat Engn, Univ Town East Ring Rd, Heyuan 517000, Peoples R China.
   [Liu, Feng; Wei, Jian] Jiangsu Key Lab Image Proc & Image Commun, 66 Xin Mofan Rd, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Liu, F (corresponding author), Nanjing Univ Posts & Telecommun, 66 Xin Mofan Rd, Nanjing 210003, Peoples R China.; Liu, F (corresponding author), Jiangsu Key Lab Image Proc & Image Commun, 66 Xin Mofan Rd, Nanjing 210003, Peoples R China.
EM lishiwen1015@126.com; liuf@njupt.edu.cn
FU Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX20_0722]
FX This work was supported by Postgraduate Research & Practice Innovation
   Program of Jiangsu Province KYCX20_0722.
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Barbosa WV, 2018, IEEE IMAGE PROC, P3933, DOI 10.1109/ICIP.2018.8451356
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Chen XY, 2019, IEEE T IND ELECTRON, V66, P9350, DOI 10.1109/TIE.2019.2893840
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Gould RW, 1999, APPL OPTICS, V38, P2377, DOI 10.1364/AO.38.002377
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Hou GJ, 2020, MULTIMED TOOLS APPL, V79, P20199, DOI 10.1007/s11042-020-08759-z
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liang Z, 2021, NEUROCOMPUTING, V425, P160, DOI 10.1016/j.neucom.2020.03.091
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Nishanth KN., 2019, INT C EL COMM AER TE, P186
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   Wu YH, 2019, IET IMAGE PROCESS, V13, P2448, DOI 10.1049/iet-ipr.2018.6208
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
NR 33
TC 2
Z9 2
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4935
EP 4960
DI 10.1007/s11042-021-11269-1
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000739790800007
DA 2024-07-18
ER

PT J
AU Zhang, LM
   Li, H
   Zhu, R
   Du, P
AF Zhang, Liming
   Li, Heng
   Zhu, Rui
   Du, Ping
TI An infrared and visible image fusion algorithm based on ResNet-152
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image fusion; ResNet-152; Infrared image; Visible
   image
AB The fusion of infrared and visible images can obtain a combined image with hidden objective and rich visible details. To improve the details of the fusion image from the infrared and visible images by reducing artifacts and noise, an infrared and visible image fusion algorithm based on ResNet-152 is proposed. First, the source images are decomposed into the low-frequency part and the high-frequency part. The low-frequency part is processed by the average weighting strategy. Second, the multi-layer features are extracted from high-frequency part by using the ResNet-152 network. Regularization L1, convolution operation, bilinear interpolation upsampling and maximum selection strategy on the feature layers to obtain the maximum weight layer. Multiplying the maximum weight layer and the high-frequency as new high-frequency. Finally, the fusion image is reconstructed by the low-frequency and the high-frequency. Experiments show that the proposed method can obtain more details from the image texture by retaining the significant features of the images. In addition, this method can effectively reduce artifacts and noise. The consistency in the objective evaluation and visual observation performs superior to the comparative algorithms.
C1 [Zhang, Liming; Li, Heng; Zhu, Rui; Du, Ping] Lanzhou Jiaotong Univ, Fac Geomat, Lanzhou 730070, Peoples R China.
   [Zhang, Liming; Li, Heng; Zhu, Rui; Du, Ping] Natl Local Joint Engn Res Ctr Technol & Applicat, Lanzhou 730070, Peoples R China.
C3 Lanzhou Jiaotong University
RP Zhang, LM (corresponding author), Lanzhou Jiaotong Univ, Fac Geomat, Lanzhou 730070, Peoples R China.; Zhang, LM (corresponding author), Natl Local Joint Engn Res Ctr Technol & Applicat, Lanzhou 730070, Peoples R China.
EM zlm@lzjtu.edu.cn
RI Zhang, Liqun/JDN-3523-2023; Du, Pingwu/G-3329-2010; Zhang,
   Li/GWM-7501-2022; zhu, rui/GTK-1978-2022; zhang, lin/IZQ-4870-2023
FU Natural Science Foundation Committee, China [41761080, 41930101];
   Guidance Project of Gansu Colleges and Universities [2019C-04]
FX This work is funded by the Natural Science Foundation Committee, China
   (No. 41761080, and No. 41930101) and Industrial Support and Guidance
   Project of Gansu Colleges and Universities, No. 2019C-04.
CR Du PJ, 2020, J GEOVIS SPAT ANAL, V4, DOI 10.1007/s41651-020-00048-5
   Haghighat M, 2014, I C APPL INF COMM TE, P424
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang Y, 2017, CHIN SOC OPT ENG C H
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Li H, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103039
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu CH, 2017, INFRARED PHYS TECHN, V83, P94, DOI 10.1016/j.infrared.2017.04.018
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Liu SP, 2007, J INFRARED MILLIM W, V26, P217
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Toet Alexander, 2014, Figshare
   Wang MC, 2019, J GEOVIS SPAT ANAL, V3, DOI 10.1007/s41651-019-0039-9
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   WU Yiquan, 2017, Acta Optica Sinica, V37, DOI 10.3788/AOS201737.0810001
   Xu L., 2017, LASER OPTOELECTRONIC, V54, P111
   Yin HT, 2015, NEUROCOMPUTING, V148, P600, DOI 10.1016/j.neucom.2014.07.003
   Zhang QH, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.5.057006
   Zhu P, 2017, INFRARED PHYS TECHN, V81, P282, DOI 10.1016/j.infrared.2017.01.013
NR 27
TC 23
Z9 25
U1 4
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9277
EP 9287
DI 10.1007/s11042-021-11549-w
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000737741900002
DA 2024-07-18
ER

PT J
AU Lee, E
   Park, J
   Koo, HI
   Cho, NI
AF Lee, Eunji
   Park, Jaewoo
   Koo, Hyung Il
   Cho, Nam Ik
TI Deep-learning and graph-based approach to table structure recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Document analysis; Graph-based approach; Table
   understanding
AB Table structure recognition is a key component in document understanding. Many prior methods have addressed this problem with three sequential steps: table detection, table component extraction, and structure analysis based on pairwise relations. However, they have limitations in addressing complexly structured tables and/or practical scenarios (e.g., scanned documents). In this paper, we propose a novel graph-based table structure recognition framework. In order to handle complex tables, we formulate tables as planar graphs, whose faces are cell-regions. Then, we compute vertex (junction) confidence maps and line fields with the heatmap regression networks having a small number of parameters (about 1M) and reconstruct tables by solving a constrained optimization problem. We demonstrate the robustness of the proposed system through experiments on ICDAR 2019 dataset and on challenging table images. Experimental results show that the proposed method outperforms the conventional method for a range of scenarios and delivers good generalization performance.
C1 [Lee, Eunji; Park, Jaewoo; Cho, Nam Ik] Seoul Natl Univ, Dept Elect & Comp Engn, INMC, Seoul 08826, South Korea.
   [Koo, Hyung Il] Ajou Univ, Dept Elect & Comp Engn, Suwon 16499, South Korea.
   [Cho, Nam Ik] Seoul Natl Univ, Sch Data Sci, Seoul 08826, South Korea.
C3 Seoul National University (SNU); Ajou University; Seoul National
   University (SNU)
RP Koo, HI (corresponding author), Ajou Univ, Dept Elect & Comp Engn, Suwon 16499, South Korea.
EM hikoo@ajou.ac.kr
RI Cho, Nam Ik/I-5029-2014
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2021-0-01062]; LG AI
   Research
FX This work was supported in part by the Institute of Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT) (No. 2021-0-01062, Development of personal
   information processing technology for collection/utilization of
   high-quality and trusted training data for autonomous driving), and in
   part by LG AI Research.
CR [Anonymous], 2017, arXiv
   Bhowmik S, 2021, MULTIMED TOOLS APPL, V80, P8471, DOI 10.1007/s11042-020-09832-3
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chi Zewen, 2019, ARXIV190804729
   Couasnon Bertrand, 2014, Handbook of Document Image Processing and Recognition, P647
   Deng Y., 2016, arXiv preprint arXiv:1609.04938, V10, P32
   Gilani A, 2017, PROC INT CONF DOC, P771, DOI 10.1109/ICDAR.2017.131
   Hirayama Y., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P583, DOI 10.1109/ICDAR.1995.601964
   Itonori K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P765, DOI 10.1109/ICDAR.1993.395625
   Khan Saqib Ali, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1366, DOI 10.1109/ICDAR.2019.00220
   Kieninger T, 1999, LECT NOTES COMPUT SC, V1655, P255
   Kieninger TG, 1998, P SOC PHOTO-OPT INS, V3305, P22, DOI 10.1117/12.304642
   Koo HI, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.3.033014
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Le Vine N, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851886
   Li MH, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1918
   Liangcai Gao, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1510, DOI 10.1109/ICDAR.2019.00243
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Paliwal Shubham Singh, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P128, DOI 10.1109/ICDAR.2019.00029
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Prasad D, 2020, IEEE COMPUT SOC CONF, P2439, DOI 10.1109/CVPRW50498.2020.00294
   Qasim Shah Rukh, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P142, DOI 10.1109/ICDAR.2019.00031
   Raja Sachin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P70, DOI 10.1007/978-3-030-58604-1_5
   Schreiber S, 2017, PROC INT CONF DOC, P1162, DOI 10.1109/ICDAR.2017.192
   Seo W, 2015, INT J DOC ANAL RECOG, V18, P47, DOI 10.1007/s10032-014-0226-7
   Shigarov A., 2016, P 2016 ACM S DOC ENG, P119
   Siddiqui Shoaib Ahmed, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1403, DOI 10.1109/ICDAR.2019.00226
   Siddiqui Shoaib Ahmed, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1397, DOI 10.1109/ICDAR.2019.00225
   Siddiqui SA, 2018, IEEE ACCESS, V6, P74151, DOI 10.1109/ACCESS.2018.2880211
   Tensmeyer Chris, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P114, DOI 10.1109/ICDAR.2019.00027
   Vanhoucke Vincent, 2014, ICLR invited talk, V1, P2
   Wang YL, 2004, PATTERN RECOGN, V37, P1479, DOI 10.1016/j.patcog.2004.01.012
   Zanibbi R., 2004, International Journal on Document Analysis and Recognition, V7, P1, DOI 10.1007/s10032-004-0120-9
   Zheng XY, 2021, IEEE WINT CONF APPL, P697, DOI 10.1109/WACV48630.2021.00074
   Zhong Xu, 2019, ARXIV191110683
NR 36
TC 7
Z9 7
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5827
EP 5848
DI 10.1007/s11042-021-11819-7
EA DEC 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000736409100003
DA 2024-07-18
ER

PT J
AU De, S
   Bhaumik, J
   Giri, D
AF De, Supriyo
   Bhaumik, Jaydeb
   Giri, Debasis
TI A secure image encryption scheme based on three different chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Multi-dimensional Chaos; Pseudo-random key; Randomness
   test; Avalanche effect; Differential attack
ID ALGORITHM; PERMUTATION
AB In the current decade, chaos based image encryption has distinctly captured a remarkable position in multimedia data security. In this paper, a hybrid chaos based image encryption scheme has been developed. A two-dimensional ecological chaotic map, namely Bed-dington, Free and Lawton (BFL) map has been combined with logistic map and Chebyshev map to generate a pseudo-random keystream for image encryption. In addition, an image substitution technique based on logistic map has been proposed. The random nature of keystream has been successfully tested by employing DIEHARD and NIST randomness test suites. Furthermore, the scheme has also been verified by histogram, correlation, global entropy, local entropy, key sensitivity and differential attack analyses. The proposed scheme achieves average 41.6% and 8.5% improvement in correlation value of cipher image and plaintext sensitivity, respectively, compared to Sheela et al.'s scheme.
C1 [De, Supriyo] Saroj Mohan Inst Technol, Guptipara 712512, W Bengal, India.
   [Bhaumik, Jaydeb] Jadavpur Univ, Kolkata 700032, W Bengal, India.
   [Giri, Debasis] Maulana Abul Kalam Azad Univ Technol, Nadia 741249, W Bengal, India.
C3 Jadavpur University; Maulana Abul Kalam Azad University of Technology
RP De, S (corresponding author), Saroj Mohan Inst Technol, Guptipara 712512, W Bengal, India.
RI De, Supriyo/HRB-3694-2023; Giri, Debasis/ABF-6428-2022
OI Giri, Debasis/0000-0003-3033-3036; De, Supriyo/0000-0003-1329-9884
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2002, CRYPTOGRAPHY THEORY
   [Anonymous], HDR DATASET COMPUTAT
   BEDDINGTON JR, 1975, NATURE, V255, P58, DOI 10.1038/255058a0
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Chen JX, 2015, OPT COMMUN, V341, P263, DOI 10.1016/j.optcom.2014.12.045
   Dey D, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.52
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   GEISEL T, 1984, PHYS LETT A, V105, P263, DOI 10.1016/0375-9601(84)90993-9
   Hikal NA, 2020, J KING SAUD UNIV-COM, V32, P870, DOI 10.1016/j.jksuci.2018.09.006
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Li CH, 2018, MULTIMED TOOLS APPL, V77, P19193, DOI 10.1007/s11042-017-5391-5
   Mendoza SA, 2018, CHAOS SOLITON FRACT, V106, P86, DOI 10.1016/j.chaos.2017.11.011
   Nicholson A. J., 1935, Proceedings of the Zoological Society of London, P551
   Nottingham Trent University UK, UCID IM DAT
   RICKER W. E., 1954, JOUR FISH RES BD CANADA, V11, P559
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Taneja N, 2012, MULTIMED TOOLS APPL, V61, P281, DOI 10.1007/s11042-011-0837-7
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Taneja N, 2011, INT J WAVELETS MULTI, V9, P317, DOI 10.1142/S0219691311004092
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   University of California San Diego, STARE IM DAT
   University of Southern California, USC SIPI IMAGE DATAB
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang XP, 2014, NONLINEAR DYNAM, V78, P359, DOI 10.1007/s11071-014-1445-7
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 32
TC 12
Z9 13
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5485
EP 5514
DI 10.1007/s11042-021-11696-0
EA DEC 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000734142900001
DA 2024-07-18
ER

PT J
AU Yadav, P
AF Yadav, Poonam
TI Hybridized optimization oriented fast negative sequential patterns
   mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Positive sequential pattern; Negative sequential pattern; Optimization
   algorithm; GWO; FF
ID ALGORITHM
AB Recently, negative sequential patterns (NSP) (like missing medical treatments) mining is important in data mining research since it includes negative correlations between item sets, which are overlooked by positive sequential pattern mining (PSP) (for instance, utilization of medical service). Yet, discovering the NSP is very complex than finding PSP because of the important problem complexity occurred by high computational cost, non-occurring elements, as well as huge search space in evaluating NSC, and most of the NSP based existing works are inefficient. Therefore, this paper intends to propose a fast NSP mining algorithm for the disease prediction model. This model includes Data normalization, Data separation based on labels, and Pattern recognition phases. In the midst of data separation, the maximum occurring data is optimally selected using a new algorithm that hybridizes the FireFly (FF) algorithm and Grey Wolf Optimization (GWO). This proposed Firefly induced Grey Wolf optimization (F-GWO) algorithm automatically selects the maximum occurring information as per the PSP support. The proposed model is compared over other conventional methods with varied measures. Especially, the computation cost of our model is 46.87%, 6.27%, 9.37%, 2.76%, and 66.62% better than the existing GA, ABC, PSO, FF, and GWO models respectively.
C1 [Yadav, Poonam] DAV Coll Engn & Technol, Kanina 123027, Haryana, India.
RP Yadav, P (corresponding author), DAV Coll Engn & Technol, Kanina 123027, Haryana, India.
EM poonam.y2002@gmail.com
CR Alkan OK, 2015, IEEE T KNOWL DATA EN, V27, P2645, DOI 10.1109/TKDE.2015.2420557
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Huynh B, 2017, IEEE ACCESS, V5, P17392, DOI 10.1109/ACCESS.2017.2739749
   Bojja GR., 2020, EARLY PUBLIC OUTLOOK
   Buddhakulsomsiri J, 2009, COMPUT IND ENG, V57, P137, DOI 10.1016/j.cie.2008.11.006
   Cai GC, 2014, EXPERT SYST APPL, V41, P3514, DOI 10.1016/j.eswa.2013.10.057
   Cao LB, 2016, ARTIF INTELL, V235, P156, DOI 10.1016/j.artint.2016.03.001
   Chen YC, 2015, IEEE T KNOWL DATA EN, V27, P3318, DOI 10.1109/TKDE.2015.2454515
   Cheng YT, 2017, IEEE J BIOMED HEALTH, V21, P303, DOI 10.1109/JBHI.2017.2657802
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chithra S., 2018, J. Comput. Mech. Power Syst. Control, V1, P18
   Cui YD, 2013, INT J PROD ECON, V144, P432, DOI 10.1016/j.ijpe.2013.03.011
   Dong X., 2011, CIKM'11, P825
   Dong XJ, 2018, PATTERN RECOGN, V84, P13, DOI 10.1016/j.patcog.2018.06.016
   Fournier-Viger P., 2017, DATA SCI PATTERN REC, V1, P54, DOI DOI 10.1007/978-3-030-04921-8_4
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Gong Y., 2015, OPEN AUTOMAT CONTROL, V7, P934, DOI DOI 10.2174/1874444301507010934
   Gong YS, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417500021
   Hsueh SC, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1213, DOI 10.1109/APSCC.2008.183
   Huang JW, 2008, IEEE T KNOWL DATA EN, V20, P1153, DOI 10.1109/TKDE.2008.37
   Kaneiw K, 2011, INT J APPROX REASON, V52, P881, DOI 10.1016/j.ijar.2011.03.002
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Khare V. K., 2013, INT J COMPUTER APPL, V77, P18
   Kim C, 2007, J SYST SOFTWARE, V80, P1726, DOI 10.1016/j.jss.2006.12.562
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lee NCJ, 2018, ORAL ONCOL, V85, P35, DOI 10.1016/j.oraloncology.2018.08.001
   McCall J, 2005, J COMPUT APPL MATH, V184, P205, DOI 10.1016/j.cam.2004.07.034
   Min F, 2020, INFORM SCIENCES, V507, P715, DOI 10.1016/j.ins.2018.04.013
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Murugan T. Senthil, 2018, International Journal of Wireless and Mobile Computing, V14, P296
   Pedersen MEH, 2010, APPL SOFT COMPUT, V10, P618, DOI 10.1016/j.asoc.2009.08.029
   Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424, DOI 10.1109/TKDE.2004.77
   Rastogi V., 2012, INT J LATEST TRENDS, V1, P24
   Roy RG, 2020, ROBOTICA, V38, P1539, DOI 10.1017/S0263574719001620
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Vinolin V., 2019, MULTIMEDIA RES, V2, P10, DOI DOI 10.46253/J.MR.V2I2.A2
   Wagh MB., 2019, J NETW COMMUN SYST, V2, P34, DOI DOI 10.46253/JNACS.V2I1.A4
   Xu TT, 2018, IEEE ACCESS, V6, P23839, DOI 10.1109/ACCESS.2018.2827167
   Yu CC, 2005, IEEE T KNOWL DATA EN, V17, P136, DOI 10.1109/TKDE.2005.13
   Zhang JS, 2016, IEEE ACM T COMPUT BI, V13, P855, DOI 10.1109/TCBB.2015.2495132
   Zheng Z., 2009, DATA MINING ANAL, P63
   Zheng ZG, 2010, LECT NOTES ARTIF INT, V6118, P262
   Zhu JQ, 2016, IEEE T KNOWL DATA EN, V28, P1790, DOI 10.1109/TKDE.2016.2541149
NR 45
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5279
EP 5303
DI 10.1007/s11042-021-11773-4
EA DEC 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000730528900001
DA 2024-07-18
ER

PT J
AU Majdabadi, MM
   Choi, Y
   Deivalakshmi, S
   Ko, S
AF Majdabadi, Mahdiyar Molahasani
   Choi, Younhee
   Deivalakshmi, S.
   Ko, Seokbum
TI Capsule GAN for prostate MRI super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Capsule network; Generative Adversarial Network (GAN); MRI; Prostate
   cancer; Super resolution
ID CANCER
AB Prostate cancer is a prevalent disease among adult men. One in seven Canadian men is diagnosed with this cancer in their lifetime. Super-Resolution (SR) can facilitate early diagnosis and potentially save many lives. In this paper, a robust and accurate model is proposed for prostate MRI SR. For the first time, MSG-GAN and CapsGAN are utilized simultaneously for high-scale medical SR. The model is trained on the Prostate-Diagnosis and PROSTATEx datasets. The proposed model outperformed the state-of-the-art prostate SR model in all similarity metrics with substantial margins. For 8 x SR, 19.77, 0.60, and 0.79 are achieved for Peak Signal-to-Noise Ratio (PSNR), Structural SIMilarity index metric (SSIM), and Multi-Scale Structural SIMilarity index metric (MS-SSIM), respectively. A new task-specific similarity assessment is introduced as well. A classifier is trained for severe cancer detection. The drop in the accuracy of this model when dealing with super-resolved images is used to evaluate the ability of medical detail reconstruction of the SR models. The proposed model surpassed state-of-the-art work with a 6% margin. The model is also more compact in comparison with the related architecture and has 45% less number of trainable parameters. The proposed SR model is a step towards an efficient and accurate general medical SR platform.
C1 [Majdabadi, Mahdiyar Molahasani; Ko, Seokbum] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
   [Choi, Younhee] Int Rd Dynam, Saskatoon, SK, Canada.
   [Deivalakshmi, S.] Natl Inst Technol, Dept Elect & Comp Engn, Trichy, India.
C3 University of Saskatchewan; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli
RP Ko, S (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
EM seokbum.ko@usask.ca
RI Molahasani Majdabadi, Mahdiyar/AHE-4246-2022; Ko, Seokbum/H-8366-2012
OI Ko, Seokbum/0000-0002-9287-317X; Deivalakshmi, S/0000-0002-7019-9807
CR Akbari H, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.7.076005
   Amaranageswarao G, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102819
   Amaranageswarao G, 2020, APPL INTELL, V50, P2177, DOI 10.1007/s10489-020-01670-y
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bloch Nicolas B, 2015, CANC IMAGING ARCHIVE
   Brenner DR, 2020, CAN MED ASSOC J, V192, pE199, DOI 10.1503/cmaj.191292
   Brock A., 2018, INT C LEARN REPR
   Castro-Zunti R, 2020, COMPUT MED IMAG GRAP, V82, DOI 10.1016/j.compmedimag.2020.101718
   Chae KJ, 2020, ACAD RADIOL, V27, pE55, DOI 10.1016/j.acra.2019.05.018
   Chaudhari AS, 2018, MAGN RESON MED, V80, P2139, DOI 10.1002/mrm.27178
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haghanifar A., 2020, 2020 IEEE INT S CIRC, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ibrahim, 2020, NORMAL PROSTATE MRI
   Islam MM, 2013, INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2012, VOL 1: ADVANCES IN AEROSPACE TECHNOLOGY, P1
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Karnewar Animesh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7796, DOI 10.1109/CVPR42600.2020.00782
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kasivisvanathan V, 2018, NEW ENGL J MED, V378, P1767, DOI 10.1056/NEJMoa1801993
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ko SB, 2020, ARXIV PREPRINT ARXIV
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li ZJ, 2017, LECT NOTES COMPUT SC, V10541, P325, DOI 10.1007/978-3-319-67389-9_38
   Liau J, 2019, CURR RADIOL REP, V7, DOI 10.1007/s40134-019-0318-8
   Litjens G., 2017, Cancer Imaging Arch
   Ma Y, 2021, NUCL INSTRUM METH A, V992, DOI 10.1016/j.nima.2021.165053
   Majdabadi MM, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Marini A, 2006, J INVEST DERMATOL, V126, P422, DOI 10.1038/sj.jid.5700073
   Majdabadi MM, 2020, MULTIMED TOOLS APPL, V79, P31205, DOI 10.1007/s11042-020-09489-y
   Park J, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aacdd4
   Peeters RR, 2004, INT J IMAG SYST TECH, V14, P131, DOI 10.1002/ima.20016
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Reda I, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533034618775530
   Rousseau F, 2010, MED IMAGE ANAL, V14, P594, DOI 10.1016/j.media.2010.04.005
   Sabour S, 2017, ADV NEUR IN, V30
   Shi W, 2018, US Patent App, Patent No. [15/706,428, 15706428]
   Sood R, 2019, I S BIOMED IMAGING, P1688, DOI [10.1109/isbi.2019.8759237, 10.1109/ISBI.2019.8759237]
   Sood R, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P326, DOI 10.1109/ICMLA.2018.00055
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Y, 2020, ULTRASOUND MED BIOL, V46, P1119, DOI 10.1016/j.ultrasmedbio.2020.01.001
   Yuhua Chen, 2018, 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), P739, DOI 10.1109/ISBI.2018.8363679
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
NR 48
TC 9
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4119
EP 4141
DI 10.1007/s11042-021-11697-z
EA NOV 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000723529100002
DA 2024-07-18
ER

PT J
AU Chen, JY
   Chen, SL
   Hu, XL
AF Chen, Jinyue
   Chen, Silu
   Hu, Xianliang
TI Image segmentation by phase-field models with local information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Local information; Phase-field; Double well
   potential; Intensity inhomogeneity
ID ACTIVE CONTOURS; MUMFORD
AB We proposed an improved phase-field model with local information for image segmentation. In our approach, a new double well potential function containing local contributions is taken into account. The advantages of the new scheme are in two folders. Firstly, the affection of noise could be reduced in image segmentation with intensity inhomogeneity. Secondly, a more stable boundary evolution could be achieved compared with the traditional way. Segmentation results for several different types of images are reported. We compare the segmentation results with the classical model for two-dimensional images. In the segmentation of three-dimensional magnetic resonance brain images, the accuracy comparisons are presented by the Dice and Jaccard similarity coefficients. Compared with the classical model, our model has higher segmentation accuracy and better stability of boundary evolution.
C1 [Chen, Jinyue; Chen, Silu; Hu, Xianliang] Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Hu, XL (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou 310027, Peoples R China.
EM jychen0527@zju.edu.cn; silu-chen@zju.edu.cn; xlhu@zju.edu.cn
RI CHEN, Silu/P-2671-2019
CR ALLEN SM, 1979, ACTA METALL MATER, V27, P1085, DOI 10.1016/0001-6160(79)90196-2
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Bourdin B, 2003, ESAIM CONTR OPTIM CA, V9, P19, DOI 10.1051/cocv:2002070
   CAHN JW, 1958, J CHEM PHYS, V28, P258, DOI 10.1063/1.1744102
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Deepa V, 2015, International Research Journal of Engineering and Technology, V8, P913
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Thai DH, 2018, APPL MATH COMPUT, V335, P146, DOI 10.1016/j.amc.2018.04.023
   EAGLEN RH, 1985, AM J PHYS ANTHROPOL, V66, P307, DOI 10.1002/ajpa.1330660308
   Esedoglu S, 2006, J COMPUT PHYS, V211, P367, DOI 10.1016/j.jcp.2005.05.027
   Garcke H, 2015, SIAM J SCI COMPUT, V37, pA1846, DOI 10.1137/140969269
   Hou ZJ, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/49515
   Jung YM, 2007, SIAM J APPL MATH, V67, P1213, DOI 10.1137/060662708
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kay DA, 2009, IEEE T IMAGE PROCESS, V18, P2330, DOI 10.1109/TIP.2009.2026678
   Kostopoulos S, 2007, COMPUT GRAPH-UK, V31, P493, DOI 10.1016/j.cag.2007.01.020
   Li CM, 2007, PROC CVPR IEEE, P339
   Li Y, 2011, COMPUT MATH APPL, V62, P737, DOI 10.1016/j.camwa.2011.05.054
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Takezawa A, 2014, J COMPUT PHYS, V257, P216, DOI 10.1016/j.jcp.2013.09.051
   Takezawa A, 2010, J COMPUT PHYS, V229, P2697, DOI 10.1016/j.jcp.2009.12.017
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Zhao SF, 2014, COMPUT GRAPH-UK, V38, P239, DOI 10.1016/j.cag.2013.11.004
   Zosso D, 2017, INVERSE PROBL IMAG, V11, P577, DOI 10.3934/ipi.2017027
NR 31
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 3039
EP 3057
DI 10.1007/s11042-021-11718-x
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000718706700001
DA 2024-07-18
ER

PT J
AU Chen, GY
   Krzyzak, A
   Xie, WF
AF Chen, Guang Yi
   Krzyzak, Adam
   Xie, Wen Fang
TI Hyperspectral face recognition with histogram of oriented gradient
   features and collaborative representation-based classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral face recognition; Minimum noise fraction (MNF); Histogram
   of oriented gradients (HOG); Collaborate representation-based classifier
   (CRC)
ID IMAGERY
AB Hyperspectral face recognition plays an important role in remote sensing. However, it faces many challenges such as difficulty in data acquisition, low signal to noise ratio (SNR), and high dimensionality. In this paper, we develop a novel method for hyperspectral face recognition by extracting histogram of oriented features (HOG) and using collaborate representation-based classifier (CRC) to classify unknown face data cubes. To improve overall classification rates, we also implement noise reduction in hyperspectral face data cubes. We also crop the face images by a bounding box and use this bounding box image to classify the testing faces. Experiments show that our new method outperforms several existing methods for both the PolyU-HSFD dataset and the CMU-HSFD dataset for hyperspectral face recognition. The contribution of this paper is the following: We introduce the MNF-based denoising method in this paper, which is new to the best of our knowledge. We also combine it with HOG features and CRC classifier so that better recognition rate can be achieved.
C1 [Chen, Guang Yi; Krzyzak, Adam] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada.
   [Xie, Wen Fang] Concordia Univ, Dept Mech Ind & Aerosp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Chen, GY (corresponding author), Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada.
EM guang_c@encs.concordia.ca; krzyzak@encs.concordia.ca;
   wfxie@encs.concordia.ca
RI Xie, Wen-Fang/AFM-0704-2022
OI Chen, Guangyi/0000-0002-4811-2402
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P97, DOI 10.1002/wics.51
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Andersson F, 2005, SIAM J APPL MATH, V65, P818, DOI 10.1137/S0036139903436005
   [Anonymous], 2016, ARXIV160503428
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Chen GY, 2019, J INTELL FUZZY SYST, V37, P635, DOI 10.3233/JIFS-17283
   Chen GY, 2017, IET IMAGE PROCESS, V11, P266, DOI 10.1049/iet-ipr.2016.0722
   Chen GY, 2017, IET BIOMETRICS, V6, P36, DOI 10.1049/iet-bmt.2015.0103
   Chen GY, 2014, CAN J REMOTE SENS, V40, P60, DOI 10.1080/07038992.2014.917582
   Chen GY, 2011, CAN J REMOTE SENS, V37, P590, DOI 10.5589/m12-002
   Chen GY, 2011, IEEE T GEOSCI REMOTE, V49, P973, DOI 10.1109/TGRS.2010.2075937
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   LEE JB, 1990, IEEE T GEOSCI REMOTE, V28, P295, DOI 10.1109/36.54356
   Luo GC, 2016, CAN J REMOTE SENS, V42, P106, DOI 10.1080/07038992.2016.1160772
   Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148
   Pan Z, 2007, OPT ENG, V46, DOI 10.1117/1.2757197
   Shen LL, 2012, INT C PATT RECOG, P1574
   Sun SY, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/597245
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Uzair M, 2015, IEEE T IMAGE PROCESS, V24, P1127, DOI 10.1109/TIP.2015.2393057
   Vinayak B., 2014, HYPERSPECTRAL FACE R
   Wang H, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.10.103102
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 29
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2299
EP 2310
DI 10.1007/s11042-021-11691-5
EA OCT 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000710608700005
DA 2024-07-18
ER

PT J
AU Han, YH
   Huang, YG
   Pan, L
   Zheng, YB
AF Han, Yahui
   Huang, Yonggang
   Pan, Lei
   Zheng, Yunbo
TI Learning multi-level and multi-scale deep representations for privacy
   image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image privacy; Multi-level features; Multi-scale features; Feature
   aggregation
AB Privacy image classification can help people detect privacy images when people share images. In this paper, we propose a novel method using multi-level and multi-scale features for privacy image classification. We first use CNN (Convolutional Neural Network) to extract multi-levels features. Then, max-pooling layers are employed to obtain multi-scale features at each level. Finally, we propose two feature aggregation models, called Privacy-MSML and Privacy-MLMS to fuse those features for image privacy classification. In Privacy-MSML, multi-scale features of the same level are first integrated and then the integrated features are fused. In Privacy-MLMS, multi-level features of the same scale are first integrated and then the integrated features are fused. Our experiments on a real-world dataset demonstrate the proposed method can achieve better performance compared with the state-of-the-art solutions.
C1 [Han, Yahui; Huang, Yonggang; Zheng, Yunbo] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Pan, Lei] Deakin Univ, Sch Informat Technol, Melbourne, Vic 3004, Australia.
C3 Beijing Institute of Technology; Deakin University
RP Huang, YG (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM l.pan@deakin.edu.au
RI Huang, Yonggang/AAI-8032-2020; Pan, Lei/ITT-0556-2023; Pan,
   Lei/ADH-0321-2022
OI Huang, Yonggang/0000-0001-9899-8590; Pan, Lei/0000-0002-4691-8330; Pan,
   Lei/0000-0002-4691-8330
FU National Natural Science Foundation of China [61972035]
FX This work is supported by the National Natural Science Foundation of
   China (No.61972035 and No.U19B2020).
CR Cho K., 2014, ARXIV14061078
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G., 2017, ARXIV170400109
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lampinen A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3217
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mazzia Alessandra., 2012, Proceedings of the Eighth Symposium on Usable Privacy and Security, page, P13, DOI [DOI 10.1145/2335356.2335374, 10.1145/2335356.2335374]
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ning X, 2018, IEEE T IMAGE PROCESS, V27, P2575, DOI 10.1109/TIP.2018.2806229
   Rakhlin A, 2016, Convolutional Neural Networks for Sentence Classification
   Rao TR, 2020, NEURAL PROCESS LETT, V51, P2043, DOI 10.1007/s11063-019-10033-9
   Sheehan KB, 2002, INFORM SOC, V18, P21, DOI 10.1080/01972240252818207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spyromitros-Xioufis E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P71, DOI 10.1145/2911996.2912018
   Squicciarini Anna., 2014, Proceedings of the 25th ACM Conference on Hypertext and Social Media, HT'14, P136
   Tonge A, 2020, ACM T WEB, V14, DOI 10.1145/3386082
   Tonge A, 2018, AAAI CONF ARTIF INTE, P8167
   Tonge A, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1317, DOI 10.1145/3184558.3191572
   Tonge A, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1829, DOI 10.1145/3308558.3313691
   Tran L., 2016, P AAAI C ART INT, V30, DOI DOI 10.1609/AAAI.V30I1.10169
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y, 2011, LECT NOTES COMPUT SC, V6740, P146, DOI 10.1007/978-3-642-21599-5_11
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zerr S, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P35, DOI 10.1145/2348283.2348292
   Zhu XG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3595
NR 32
TC 5
Z9 5
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2259
EP 2274
DI 10.1007/s11042-021-11667-5
EA OCT 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000710608700004
DA 2024-07-18
ER

PT J
AU Almahmoud, S
   Hammo, B
   Al-Shboul, B
   Obeid, N
AF Almahmoud, Sawsan
   Hammo, Bassam
   Al-Shboul, Bashar
   Obeid, Nadim
TI A hybrid approach for identifying non-human traffic in online digital
   advertising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Click fraud detection; Illegitimate bots; Non-human traffic; Ontology;
   Web traffic ontology
ID FRAUD DETECTION; SPAM; ONTOLOGY
AB Click fraud is a serious problem facing online advertising business. The malicious intent of clicking online ads either committed by humans or by non-humans, forced financial losses on advertisers utilizing pay-per-click advertising. Non-human traffic is usually designed to inflate web traffic for fraudulent purposes. In this paper, we demonstrate a hybrid approach consisting of two-level fingerprint applied in two phases to detect illegitimate non-human traffic. The first-level fingerprint is a pattern generated using immutable information about a user navigating a website's pages. It will be used in the first traffic illegitimacy detection phase to infer rules about illegitimate non-human traffic from a developed ontology about web traffic legitimacy. The second-level fingerprint is generated using behavioral ad click patterns, which will be used in the second detection phase by applying a Machine-Learning (ML) algorithm. To test the proposed approach, a real commercial website for ads, called Waseet.com, was used. The access logs of the website server were utilized for the purpose of this research. The experiments show that our proposed hybrid approach using the ontology of web traffic illegitimacy and the ML k-NN classifier detects around (98.6%) of fake clicks.
C1 [Almahmoud, Sawsan] Univ Jordan, King Abdullah II Sch Informat Technol, Dept Comp Sci, Amman 11942, Jordan.
   [Hammo, Bassam; Obeid, Nadim] Univ Jordan, King Abdullah II Sch Informat Technol, Dept Comp Informat Syst, Amman 11942, Jordan.
   [Hammo, Bassam] Princess Sumaya Univ Technol, King Hussein Sch Comp Sci, Amman, Jordan.
   [Al-Shboul, Bashar] Univ Jordan, King Abdullah II Sch Informat Technol, Dept Informat Technol, Amman 11942, Jordan.
C3 University of Jordan; University of Jordan; Princess Sumaya University
   for Technology; University of Jordan
RP Al-Shboul, B (corresponding author), Univ Jordan, King Abdullah II Sch Informat Technol, Dept Informat Technol, Amman 11942, Jordan.
EM bashar.shboul@gmail.com
RI Hammo, Bassam/GRR-6624-2022; Obeid, Nadim/B-8076-2011; Al-Shboul,
   Bashar/C-8036-2015
OI Obeid, Nadim/0000-0001-9218-0923; Al-Shboul, Bashar/0000-0002-5214-6429
CR Alexopoulos P, 2007, ICE-B 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON E-BUSINESS, P269
   Alhabash S., 2017, Digital Advertising: Theory and Research, P285
   Ali MA, 2019, FUTURE GENER COMP SY, V100, P408, DOI 10.1016/j.future.2019.03.041
   Almahmoud S, 2019, LECT NOTES COMPUT SC, V11684, P663, DOI 10.1007/978-3-030-28374-2_57
   Alrwais SA, 2012, 28TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2012), P21
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2019, WASEET CLASSIFIED AD
   [Anonymous], 2008, P 4 INT WORKSH ADV I, DOI DOI 10.1145/1451983.1451985
   Attigeri Girija, 2018, Procedia Computer Science, V135, P369, DOI 10.1016/j.procs.2018.08.186
   Baader F., 2003, DESCRIPTION LOGIC HD
   Baarder F, 2003, DESCRIPTION LOGIC HD, P43
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Carvalho RN., 2010, UNCERTAINTY REASONIN, P19
   Chakraborty M, 2016, INFORM PROCESS MANAG, V52, P1053, DOI 10.1016/j.ipm.2016.04.009
   Chen YZ, 2017, COMPUT SECUR, V67, P164, DOI 10.1016/j.cose.2017.02.010
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dong F, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P257, DOI 10.1145/3236024.3236045
   Drummond N, 2005, 8 INT PROT C
   El Orche A, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEMS & SECURITY (NISS19), DOI 10.1145/3320326.3320369
   El-Atawy Sameh S., 2016, P 2 AFR MIDDL E C SO, P40, DOI [10.1145/2944165.2944172, DOI 10.1145/2944165.2944172]
   Fang L, 2007, LECT NOTES COMPUT SC, V4489, P1048
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gabryel M, 2019, LECT NOTES ARTIF INT, V11509, P350, DOI 10.1007/978-3-030-20915-5_32
   Gabryel M, 2018, COMM COM INF SC, V920, P437, DOI 10.1007/978-3-319-99972-2_36
   Guarino N., 2009, HDB ONTOLOGIES, P1, DOI [DOI 10.1007/978-3-540-92673-30, 10.1007/978-3-540-92673-3_0, DOI 10.1007/978-3-540-92673-3_0]
   Gupta N, 2019, 14 AS PAC INT C INF, P24
   Haider CMR, 2018, J NETW COMPUT APPL, V112, P126, DOI 10.1016/j.jnca.2018.02.021
   Hlomani H., 2014, Semantic Web Journal, V1, P1
   Imperva Incapsula, 2017, BOT TRAFFIC REPORT 2
   Iqbal MS, 2016, IEEE HI ASS SYS ENGR, P157, DOI 10.1109/HASE.2016.17
   Kampichler C, 2010, ECOL INFORM, V5, P441, DOI 10.1016/j.ecoinf.2010.06.003
   Kaur R, 2018, J NETW COMPUT APPL, V112, P53, DOI 10.1016/j.jnca.2018.03.015
   Kerremans K, 2005, 2005 PORTUGUESE CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P106, DOI 10.1109/EPIA.2005.341275
   Kheir N., 2012, DATA PRIVACY MANAGEM, P187
   Minastireanu Elena-Adriana., 2019, J INFORM ASSUR CYBER, V2019, P1, DOI [10.5171/2019.263928, DOI 10.5171/2019.263928]
   Mladenow A, 2015, LECT NOTES COMPUT SC, V9357, P109, DOI 10.1007/978-3-319-24315-3_11
   Mungamuru B, 2008, LECT NOTES COMPUT SC, V5143, P187, DOI 10.1007/978-3-540-85230-8_16
   Nagaraja S, 2019, PROCEEDINGS OF THE 2019 CONFERENCE ON SECURITY AND PRIVACY IN WIRELESS AND MOBILE NETWORKS (WISEC '19), P105, DOI 10.1145/3317549.3323407
   Obeid M, 2019, LECT NOTES ARTIF INT, V11606, P376, DOI 10.1007/978-3-030-22999-3_33
   Papadopoulos P, 2019, ARXIV PREPRINT ARXIV
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Ramaki A.A., 2012, International Journal of Security Privacy and Trust Management IJSPTM, V1, P1
   Segal MR, 2004, Machine Learning Benchmarks and Random Forest Regression
   Singh M, 2019, DIGIT INVEST, V28, P14, DOI 10.1016/j.diin.2018.12.005
   Steinbach M, 2009, CH CRC DATA MIN KNOW, P151
   Stenberg D, 2018, EVERYTHING CUR
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tang XB, 2018, KNOWL ORGAN, V45, P205, DOI 10.5771/0943-7444-2018-3-205
   Thejas GS, 2019, PROCEEDINGS OF THE 2019 ANNUAL ACM SOUTHEAST CONFERENCE (ACMSE 2019), P176, DOI 10.1145/3299815.3314453
   La VH, 2016, INT CON ADV INFO NET, P147, DOI 10.1109/AINA.2016.41
   Wang AH, 2010, LECT NOTES COMPUT SC, V6166, P335, DOI 10.1007/978-3-642-13739-6_25
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Zarras A, 2014, PROCEEDINGS OF THE 2014 ACM INTERNET MEASUREMENT CONFERENCE (IMC'14), P373, DOI 10.1145/2663716.2663719
   Zhang MX, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P941
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zhu X., 2017, FRAUD PREVENTION ONL, DOI [10.1007/978-3-319-56793-8, DOI 10.1007/978-3-319-56793-8]
NR 59
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1685
EP 1718
DI 10.1007/s11042-021-11533-4
EA OCT 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000706037800001
DA 2024-07-18
ER

PT J
AU Dash, DP
   Kolekar, MH
   Jha, K
AF Dash, Deba Prasad
   Kolekar, Maheshkumar H.
   Jha, Kamlesh
TI Surface EEG based epileptic seizure detection using wavelet based
   features and dynamic mode decomposition power along with KNN classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Epilepsy; Seizure; Dynamic mode decomposition; KNN classifier; SVM
   classifier
ID SIGNALS
AB The seizure is defined as the sudden synchronous activity of the number of neurons resulting in abnormal body symptoms. This paper proposes a technique for the auto-detection of epileptic seizures using an online surface EEG database. The features were extracted for every 5 seconds window from the online surface EEG signal. Authors used dynamic mode decomposition power feature calculated from the multichannel EEG signal and Power spectral density, variance, and Katz fractal dimension features evaluated from wavelet packet decomposition coefficients for seizure detection. The K-nearest neighbor (KNN) classifier was used for classification. The KNN classifier was trained separately for each signal feature. The proposed system achieved good classification accuracy in seizure detection using a simple KNN classifier. The approach is further verified using the All India Institute of Medical Sciences (AIIMS) Patna seizure database and online seizure EEG database collected from neurology and sleep center, Hauz Khas, New Delhi. Different types of seizures were considered for validation of the model. KNN classifier-based approach achieved 98.99%, 99.69%, and 96.25% classification accuracy in detecting seizures from the online surface EEG seizure database, AIIMS Patna EEG seizure database, and online seizure database collected from neurology and sleep center, Hauz Khas, New Delhi. Support vector machine classifier was further evaluated for accuracy in seizure detection from the EEG signal collected at neurology and sleep center, Hauz Khas, New Delhi available online and achieved 95.5% accuracy in preseizure-seizure EEG segment classification and 96.5% accuracy in interseizure-seizure EEG segment classification. SVM Radial Basis Function (RBF) kernel based approach achieved highest accuracy compared to linear and polynomial kernel based approach.
C1 [Dash, Deba Prasad; Kolekar, Maheshkumar H.] Indian Inst Technol, Patna, Bihta, India.
   [Jha, Kamlesh] All India Inst Med Sci, Patna, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System); All India Institute of Medical Sciences
   (AIIMS) Patna
RP Dash, DP (corresponding author), Indian Inst Technol, Patna, Bihta, India.
EM dpdash.srf14@iitp.ac.in; mahesh@iitp.ac.in; drkamleshjha@gmail.com
RI Dash, Deba/AAZ-3306-2021
OI Dash, Deba Prasad/0000-0002-4441-696X; jha, kamlesh/0000-0003-0525-9444
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Acharya UR, 2012, BIOMED SIGNAL PROCES, V7, P401, DOI 10.1016/j.bspc.2011.07.007
   Ahmed R, 2017, COMPUT BIOL MED, V82, P100, DOI 10.1016/j.compbiomed.2017.01.017
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2010, P 27 INT C MACH LEAR, DOI DOI 10.5555/3104322.3104446
   [Anonymous], 2015, IEEE REG 10 C
   BENTLEY PM, 1994, ELECTRON COMMUN ENG, V6, P175, DOI 10.1049/ecej:19940401
   Bogaarts JG, 2016, MED BIOL ENG COMPUT, V54, P1285, DOI 10.1007/s11517-016-1468-y
   Chandel G, 2019, IRBM, V40, P103, DOI 10.1016/j.irbm.2018.12.002
   Chen SN, 2019, IEEE ACCESS, V7, P61046, DOI 10.1109/ACCESS.2019.2915610
   Dash D.P., 2017, INDIAN J PUBLIC HLTH, V8
   El-Khoribi Reda A, 2018, COMPUTING RES REPOSI, P1
   Fergus P, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/986736
   Garner DM., 2018, Rom J Diabetes Nutr Metab Dis, V25, P289, DOI [10.2478/rjdnmd-2018-0034, DOI 10.2478/RJDNMD-2018-0034]
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gupta AK, 2021, TRAIT SIGNAL, V38, P473, DOI 10.18280/ts.380227
   Gupta AK, 2019, TRAIT SIGNAL, V36, P425, DOI 10.18280/ts.360507
   Hassanin A, 2015, GENETICS OF CATTLE, 2ND EDITION, P1, DOI 10.1079/9781780642215.0001
   Humairani A., 2021, Journal of Physics: Conference Series, V1844, DOI 10.1088/1742-6596/1844/1/012019
   Kiranyaz S, 2014, J BIOMED INFORM, V49, P16, DOI 10.1016/j.jbi.2014.02.005
   Kolekar MH, 2015, IEEE T BROADCAST, V61, P195, DOI 10.1109/TBC.2015.2424011
   Le Douget JE, 2017, IEEE ENG MED BIO, P475, DOI 10.1109/EMBC.2017.8036865
   Leber, 2011, MANAGEMENT EPILEPSY
   Mahmoodian N, 2019, SEIZURE-EUR J EPILEP, V66, P4, DOI 10.1016/j.seizure.2019.02.001
   Murillo-Fuentes JJ, 2017, ARXIV170510060
   Raghu S, 2017, COGN NEURODYNAMICS, V11, P51, DOI 10.1007/s11571-016-9408-y
   Sharma N, 2019, IRBM, V40, P113, DOI 10.1016/j.irbm.2018.11.007
   Shoeb A.H., 2009, Application of Machine Learning to Epileptic Seizure Onset Detection and Treatment, DOI DOI 10.1016/J.BSPC.2020.101856
   Solaija MSJ, 2018, IEEE ACCESS, V6, P38683, DOI 10.1109/ACCESS.2018.2853125
   Swami P, 2016, EXPERT SYST APPL, V56, P116, DOI 10.1016/j.eswa.2016.02.040
   Temko A, 2011, CLIN NEUROPHYSIOL, V122, P464, DOI 10.1016/j.clinph.2010.06.034
   Tian XB, 2019, IEEE T NEUR SYS REH, V27, P1962, DOI 10.1109/TNSRE.2019.2940485
   Tu JH., 2014, J COMPUT DYNAM, V1, P391, DOI DOI 10.3934/JCD.2014.1.391
   Wu YX, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169833
   Yuan Q, 2017, SEIZURE-EUR J EPILEP, V50, P99, DOI 10.1016/j.seizure.2017.05.018
   Yuvaraj R, 2018, CONF REC ASILOMAR C, P368, DOI 10.1109/ACSSC.2018.8645301
   Asmat Z, 2017, COMPUT BIOL MED, V88, P132, DOI 10.1016/j.compbiomed.2017.07.010
   Zhang YL, 2012, COMM COM INF SC, V308, P179
   Zhou MN, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00095
NR 39
TC 6
Z9 6
U1 6
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42057
EP 42077
DI 10.1007/s11042-021-11487-7
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000696465800006
DA 2024-07-18
ER

PT J
AU Demotte, P
   Wijegunarathna, K
   Meedeniya, D
   Perera, I
AF Demotte, P.
   Wijegunarathna, K.
   Meedeniya, D.
   Perera, I
TI Enhanced sentiment extraction architecture for social media content
   analysis using capsule networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Capsule networks; Twitter; Sentiment analysis; Social
   media content analysis
AB Recent research has produced efficient algorithms based on deep learning for text-based analytics. Such architectures could be readily applied to text-based social media content analysis. The deep learning techniques, which require comparatively fewer resources for language modeling, can be effectively used to process social media content data that change regularly. Convolutional Neural networks and recurrent neural networks based approaches have reported prominent performance in this domain, yet their limitations make them sub-optimal. Capsule networks sufficiently warrant their applicability in language modelling tasks as a promising technique beyond their initial usage of image classification. This study proposes an approach based on capsule networks for social media content analysis, especially for Twitter. We empirically show that our approach is optimal even without the use of any linguistic resources. The proposed architectures produced an accuracy of 86.87% for the Twitter Sentiment Gold dataset and an accuracy of 82.04% for the CrowdFlower US Airline dataset, indicating state-of-the-art performance. Hence, the research findings indicate noteworthy accuracy enhancement for text processing within social media content analysis.
C1 [Demotte, P.; Wijegunarathna, K.; Meedeniya, D.; Perera, I] Univ Moratuwa, Dept Comp Sci & Engn, Moratuwa, Sri Lanka.
C3 University Moratuwa
RP Meedeniya, D (corresponding author), Univ Moratuwa, Dept Comp Sci & Engn, Moratuwa, Sri Lanka.
EM dulanim@cse.mrt.ac.lk
RI Meedeniya, Dulani/P-3381-2016
OI Meedeniya, Dulani/0000-0002-4520-3819; Demotte,
   Piyumal/0000-0001-8144-580X
CR Abeysinghe C., 2021, Machine Learning-Based Approaches, V2, P23
   Abuzayed A., 2021, P 6 ARABIC NATURAL L, P312
   Ankit, 2018, Procedia Computer Science, V132, P937, DOI 10.1016/j.procs.2018.05.109
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Cai MM, 2018, IEEE INT SM C CONF
   Cruz JCB, 2020, ARXIV PREPRINT ARXIV
   Das Sushree, 2018, Procedia Computer Science, V132, P956, DOI 10.1016/j.procs.2018.05.111
   Dumitrescu SD, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4324
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Johnson R., 2015, P 2015 C N AM CHAPT, P103, DOI DOI 10.3115/V1/N15-1011
   Kag A., 2019, P INT C LEARN REPR, P1
   Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033
   Koehn P., 2017, ARXIV170603872, P28, DOI DOI 10.18653/V1/W17-3204
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Masala Mihai, 2020, P 28 INT C COMPUTATI, P6626
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Nazir F, 2019, MULTIMED TOOLS APPL, V78, P3553, DOI 10.1007/s11042-018-6437-z
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Perera, 2020, ARXIV PREPRINT ARXIV
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Sabour S, 2017, ADV NEUR IN, V30
   Saif H., 2013, 1 INTERANTIONAL WORK
   Sanh, 2019, P 5 WORKSH EN EFF MA
   Wang X., 2016, P COL 2016 26 INT C, P2428
   Wang YQ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1165, DOI 10.1145/3178876.3186015
   Zettlemoyer L., 2019, CORR
   Zhang C, 2019, PROC CVPR IEEE, P5312, DOI 10.1109/CVPR.2019.00546
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang YZ, 2019, APPL INTELL, V49, P3093, DOI 10.1007/s10489-019-01441-4
   Zhang YZ, 2018, LECT NOTES COMPUT SC, V10772, P316, DOI 10.1007/978-3-319-76941-7_24
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
   Zhang Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P317
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhao W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3110
NR 43
TC 14
Z9 14
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8665
EP 8690
DI 10.1007/s11042-021-11471-1
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000696465800008
PM 34545274
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Meena, KB
   Tyagi, V
AF Meena, Kunj Bihari
   Tyagi, Vipin
TI Image splicing forgery detection using noise level estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise level estimation; SLIC segmentation; Image forgery detection;
   k-means clustering; Image splicing
ID NETWORK
AB Digital image forgery has become one of the serious issues in today's era. Digital images can be forged in several ways. Image splicing is a simple and most commonly used forgery technique. In image splicing, two or more images are used to create a single composite image. However, the detection of image splicing forgery is not easy. Motivated by the fact that the images captured from different devices show different noise levels, this paper proposes a new method to detect and localize the image splicing forgery based on noise level estimation. In the proposed method, initially, the input image is divided into irregular-shaped superpixel blocks using the Simple Linear Iterative Clustering technique. Secondly, the PCA-based image estimator is used to estimate the noise level from the superpixel blocks. Finally, the k-means clustering technique is used to cluster the blocks into authentic and spliced blocks based on the noise levels. The experimental results performed on the CUISDE dataset demonstrate that the proposed method can localize the image splicing forgery with better accuracy as compared to existing state-of-the-art methods.
C1 [Meena, Kunj Bihari; Tyagi, Vipin] Jaypee Univ Engn & Technol, Guna, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Guna, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686; Meena, Kunj Bihari/0000-0001-8159-9024
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bi Xiuli, 2020, D-unet: A dual-encoder u-net for image splicing forgery detection and localization
   Chen HP, 2018, LECT NOTES COMPUT SC, V11166, P608, DOI 10.1007/978-3-030-00764-5_56
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Jaiswal AK, 2020, MULTIMED TOOLS APPL, V79, P11837, DOI 10.1007/s11042-019-08480-6
   Jiang P, 2016, PATTERN RECOGN LETT, V78, P8, DOI 10.1016/j.patrec.2016.03.026
   Julliand Thibaut, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P3, DOI 10.1007/978-3-319-31960-5_1
   Kakar P, 2011, IEEE T MULTIMEDIA, V13, P443, DOI 10.1109/TMM.2011.2121056
   Kanwal N, 2020, MULTIMED TOOLS APPL, V79, P12829, DOI 10.1007/s11042-020-08621-2
   Liu B, 2020, INFORM SCIENCES, V526, P133, DOI 10.1016/j.ins.2020.03.099
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Liu XH, 2012, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2012.6466947
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Meena Kunj Bihari, 2021, Journal of Physics: Conference Series, V1714, DOI 10.1088/1742-6596/1714/1/012038
   Meena K. B., 2019, Advances in Computing and Data Sciences. ICACDS 2019. Communications in Computer and Information Science, V1045, DOI [https://doi.org/10.1007/978-981-13-9939-8_7, DOI 10.1007/978-981-13-9939-8_7]
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Meena KB, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.107025
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Meena KB, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P385, DOI 10.1109/ICIIP47207.2019.8985711
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Pan XF, 2012, IEEE INT SYMP CIRC S
   Petteri, 2008, DEPENDENCE PARAMETER
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rao MP, 2014, IEEE T INF FOREN SEC, V9, P583, DOI 10.1109/TIFS.2014.2302895
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Tyagi V., 2018, UNDERSTANDING DIGITA
   Tyagi V., 2020, SPRINGER INT C ADV C, P212
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xiaofeng Wang, 2020, 2020 International Conference on Computing, Networking and Communications (ICNC), P79, DOI 10.1109/ICNC47757.2020.9049720
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
   Zhu N, 2018, SIGNAL PROCESS-IMAGE, V68, P181, DOI 10.1016/j.image.2018.07.012
NR 45
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13181
EP 13198
DI 10.1007/s11042-021-11483-x
EA SEP 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000695454400001
DA 2024-07-18
ER

PT J
AU Yan, LY
   Sheng, MH
   Wang, CZ
   Gao, R
   Yu, H
AF Yan, Lingyu
   Sheng, Menghan
   Wang, Chunzhi
   Gao, Rong
   Yu, Han
TI Hybrid neural networks based facial expression recognition for smart
   city
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; Facial expression recognition; Sparse Autoencoder (SAE);
   Convolutional Neural Network (CNN)
AB With the development of science and technology and the progress of human beings, intelligence is gradually integrated into human daily life. The smart city uses innovative technology to manage and operate cities intelligently. Through the research of facial expression recognition technology, this paper explores the application of facial expression recognition in smart city construction. In this paper, a hybrid neural network structure is proposed, which includes Sparse Autoencoder and Convolutional Neural Network (SCNN). The network reconstructs the input data by Sparse Autoencoder, so as to learn the approximate value between the original data and the reconstructed data, and obtain more high-dimensional abstract features. Then, combined with the Convolutional Neural Network, the features are further extracted and dimensionally reduced. The model can effectively solve the problem that the shallow network structure can not fully extract image features and train the model with a small number of samples. In this paper, CK+, FER2013 and Oulu-CASIA databases are used for Cross-Validation of the model. The experimental results show that the model has achieved good results in both databases. Compared with other methods, the accuracy of this model has been greatly improved.
C1 [Yan, Lingyu; Sheng, Menghan; Wang, Chunzhi; Gao, Rong] Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
   [Yu, Han] Fiberhome Telecommun Technol Co Ltd, Wuhan Fiberhome Tech Serv Co Ltd, Wuhan, Peoples R China.
C3 Hubei University of Technology
RP Yan, LY (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
EM yanlingyu@hbut.edu.cn; smh11942@163.com; chunzhiwang@vip.163.com
FU National Natural Science Foundation of China [61772180]; Key R&D plan of
   Hubei Province [2020BHB004, 2020BAB012]; Natural Science Foundation of
   Hubei Province [2020CFB798]
FX This work is funded by the National Natural Science Foundation of China
   under Grant No.61772180, the Key R&D plan of Hubei Province(2020BHB004,
   2020BAB012) and Natural Science Foundation of Hubei Province
   No.2020CFB798. No other author has reported a potential conflict of
   interest relevant to this article.
CR [Anonymous], 2017, 2017 INT ART INT
   [Anonymous], 2018, 2018 INT C COMP SCI
   Cugu I., 2019, P 2019 9 INT C IMAGE, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Gan YL, 2020, IEEE ACCESS, V8, P7383, DOI 10.1109/ACCESS.2020.2963913
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Hu XD, 2020, DEF TECHNOL, V16, P1116, DOI 10.1016/j.dt.2019.12.002
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jain DK, 2017, PATTERN RECOGN LETT, V139, P1
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Keskar N. S., 2016, ABS160904836
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kuo CM, 2018, IEEE COMPUT SOC CONF, P2202, DOI 10.1109/CVPRW.2018.00286
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leng X, 2014, J CHEM PHARM, VRespp, P2589
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu YP, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040712
   Mehrabian A., 2008, COMMUN THEOR, V6, P200
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Pramerdorfer C, 2016, ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang L, 2014, INT J AUTOM COMPUT, V11, P459, DOI 10.1007/s11633-014-0835-0
   Yan L, 2018, MULTIMED TOOLS APPL
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang YC, 2020, IEEE T PARALL DISTR, V31, P2302, DOI 10.1109/TPDS.2020.2991030
NR 35
TC 5
Z9 5
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 319
EP 342
DI 10.1007/s11042-021-11530-7
EA SEP 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000694787500002
DA 2024-07-18
ER

PT J
AU Tong, JH
   Dou, QY
   Yang, HR
   Jeon, G
   Yang, XM
AF Tong, Jiahui
   Dou, Qingyu
   Yang, Haoran
   Jeon, Gwanggil
   Yang, Xiaomin
TI Lightweight refined networks for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Single image super-resolution (SISR); Deep
   learning; Receptive field; Contextual information
AB Recently, software architectures applied to physical agents have become a boost from the emerging Artificial Intelligence(AI). In these smart physical agents, simultaneously image information processing appears vital in particular. Single Image Super Resolution(SISR) serves as the foundation of the image process, presenting its prospects driven by deep learning(DL) methods. In these DL methods, convolutional layers are stacked to implement a mapping between the original low resolution(LR) image and the high resolution(HR) image. Despite improved performances, convolution neural networks(CNN) based methods with large parameters are so complex and time-consuming, which is difficult to apply in mobile devices. To tackle the above issue, we propose Distillation Information Block(DIB) and Feature Information Refined Block(FIRB). In our proposed Lightweight Refined Networks for single image Super-Resolution(LRSR), to lengthen our network with fewer parameters increased, the proposed DIB grasps more information by using a large receptive field. To enhance the information utilization, we build FIRB to refine advanced features and recover more details. Furthermore, with the compact structure, the execution time can be comparatively reduced with higher performance. We conduct extensive experiments on different datasets, which demonstrate that the proposed method performs comparatively better compared with the state-of-the-art lightweight methods.
C1 [Tong, Jiahui; Yang, Haoran; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Tong, Jiahui; Yang, Haoran; Yang, Xiaomin] Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Sichuan, Peoples R China.
   [Dou, Qingyu] Sichuan Univ, West China Hosp, Ctr Gerontol & Geriatr, Chengdu, Peoples R China.
   [Jeon, Gwanggil] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
C3 Sichuan University; Sichuan University; Sichuan University; Xidian
   University; Incheon National University
RP Jeon, G (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.; Jeon, G (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
EM ddqqking@126.com; gjeon@inu.ac.kr
RI yang, xiao/HJI-7815-2023
FU Sichuan University [2020SCUNG205]
FX This work was partially supported by the funding from Sichuan University
   under grant 2020SCUNG205.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   [Anonymous], 2016, PRUNING CONVOLUTIONA
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Ellery A., 2016, AUTONOMOUS NAVIGATIO, DOI [10.1007/978-3-642-03259-2_9, DOI 10.1007/978-3-642-03259-2_9]
   Foley J.D., 1990, Computer graphics: Principles and practice
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hinton G. E., 2012, 12070580 ARXIV
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Isobe Takashi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8005, DOI 10.1109/CVPR42600.2020.00803
   Keys RG, 2003, IEEE T ACOUST SPEECH, V29
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim S, 2013, MULTIMED TOOLS APPL, V65, P181, DOI 10.1007/s11042-013-1428-6
   Kingma D. P., 2014, arXiv
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu F., 2021, PERS UBIQUIT COMPUT, P1
   Luo Y, 2017, IEEE INT SYMP ELEC
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mattmann CA, 2013, NATURE, V493, P473, DOI 10.1038/493473a
   Rousseau F, 2010, MED IMAGE ANAL, V14, P594, DOI 10.1016/j.media.2010.04.005
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Thurnhofer-Hemsi K, 2020, INTEGR COMPUT-AID E, V27, P233, DOI 10.3233/ICA-200620
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 38
TC 1
Z9 1
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3439
EP 3458
DI 10.1007/s11042-021-11318-9
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000692489400002
DA 2024-07-18
ER

PT J
AU Mandal, AB
   Das, TK
AF Bhaduri Mandal, Arkaprava
   Das, Tanmoy Kanti
TI jForge: An adversarial method to deceive JPEG forgery localization
   schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial forensics; Localization; DCT estimation; Double JPEG
   compression
ID ANTI-FORENSICS; COMPRESSION HISTORY; IDENTIFICATION; QUALITY
AB Automatic localization of tampered regions of a JPEG image has attracted lots of attention in recent times. It is known that the statistical signatures of single and Double JPEG (DJPEG) compression are distinct, and the presence of both the signatures inside an image is proof of manipulation. Automatic localization of tampered regions is carried out by segregating the singly and doubly compressed regions of an image. However, the robustness of the localization process is questionable as very few attempts are made to highlight their vulnerabilities. Here, we propose an adversarial framework, known as jForge, through which one can create a DJPEG compressed image that only bears the signatures of a single compression, and it renders the localization process ineffective. jForge removes the footprints of JPEG compression using model-based approximation techniques. Arguably, this is the first successful attempt to model the DC coefficients of an image, and it employs polynomial regression of two variables to accomplish the same. Similarly, AC coefficients have been approximated using low degree polynomials. We have mounted jForge on three popular forgery localization schemes, and none of them is effective against it. This raises serious doubt regarding the efficacy of the statistical signature-based paradigm of forgery localization.
C1 [Bhaduri Mandal, Arkaprava; Das, Tanmoy Kanti] Natl Inst Technol Raipur, Dept Comp Applicat, GE Rd, Raipur 492010, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Mandal, AB (corresponding author), Natl Inst Technol Raipur, Dept Comp Applicat, GE Rd, Raipur 492010, Chhattisgarh, India.
EM abmandal.phd2017.ca@nitrr.ac.in; tkdas.mca@nitrr.ac.in
CR alZahir S, 2020, MULTIMED TOOLS APPL, V79, P28643, DOI 10.1007/s11042-020-09502-4
   Barni M, 2018, EUR SIGNAL PR CONF, P962, DOI 10.23919/EUSIPCO.2018.8553305
   Barni M, 2015, LECT NOTES COMPUT SC, V9023, P31, DOI 10.1007/978-3-319-19321-2_3
   Bhardwaj D, 2018, SIGNAL PROCESS-IMAGE, V68, P155, DOI 10.1016/j.image.2018.07.011
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Chen ZP, 2017, SIGNAL PROCESS-IMAGE, V57, P8, DOI 10.1016/j.image.2017.04.008
   Chu XY, 2015, IEEE T IMAGE PROCESS, V24, P1087, DOI 10.1109/TIP.2015.2390137
   Cristin R, 2018, IET IMAGE PROCESS, V12, P1439, DOI 10.1049/iet-ipr.2017.1120
   Dalmia N, 2018, SIGNAL PROCESS-IMAGE, V61, P9, DOI 10.1016/j.image.2017.10.011
   Das TK, 2018, MULTIMED TOOLS APPL, V77, P31835, DOI 10.1007/s11042-018-6170-7
   Das TK, 2004, IEEE SIGNAL PROC LET, V11, P446, DOI 10.1109/LSP.2004.824028
   Fahmy G, 2015, IEEE I C ELECT CIRC, P37, DOI 10.1109/ICECS.2015.7440243
   Fan W, 2014, IEEE T INF FOREN SEC, V9, P1211, DOI 10.1109/TIFS.2014.2317949
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Farooq S, 2017, COMPUT ELECTR ENG, V62, P459, DOI 10.1016/j.compeleceng.2017.05.008
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Huang HY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0469-9
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li HD, 2015, MULTIMED TOOLS APPL, V74, P6729, DOI 10.1007/s11042-014-1927-0
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lukas Jan., 2003, P DFRWS
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Mandal AB, 2019, LECT NOTES COMPUT SC, V11952, P307, DOI 10.1007/978-3-030-36945-3_17
   Mayer O, 2020, IEEE T INF FOREN SEC, V15, P1331, DOI 10.1109/TIFS.2019.2924552
   Milani S, 2012, INT CONF ACOUST SPEE, P2253, DOI 10.1109/ICASSP.2012.6288362
   Nasiri M, 2019, J VIS COMMUN IMAGE R, V58, P323, DOI 10.1016/j.jvcir.2018.12.007
   Niu YK, 2019, SIGNAL PROCESS-IMAGE, V76, P89, DOI 10.1016/j.image.2019.04.016
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Sallee P, 2004, MATLAB JPEG TOOLBOX
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   Uehara T, 2006, IEEE T IMAGE PROCESS, V15, P3592, DOI 10.1109/TIP.2006.881939
   Valenzise G., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1949, DOI 10.1109/ICIP.2011.6115854
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Wei WM, 2012, COMM COM INF SC, V345, P45
   Yang JQ, 2015, DIGIT SIGNAL PROCESS, V41, P90, DOI 10.1016/j.dsp.2015.03.014
   Yerushalmy I, 2011, INT J COMPUT VISION, V92, P71, DOI 10.1007/s11263-010-0403-1
   Zheng LL, 2019, J VIS COMMUN IMAGE R, V58, P380, DOI 10.1016/j.jvcir.2018.12.022
   Zhu N, 2018, SIGNAL PROCESS-IMAGE, V68, P181, DOI 10.1016/j.image.2018.07.012
NR 49
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22807
EP 22832
DI 10.1007/s11042-021-11265-5
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000681210700001
DA 2024-07-18
ER

PT J
AU Lai, HL
   Yan, XM
AF Lai, Helang
   Yan, Xueming
TI Multimodal sentiment analysis with asymmetric window multi-attentions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Asymmetric window; Multi-attentions; Neural network;
   Multimodal
ID NETWORK; RECOGNITION; FUSION
AB Multimodal sentiment analysis is an actively developing field of research. The main research problem in this domain is to model both intra-modality and inter-modality dynamics. However, most of the current work cannot do well with these two aspects of dynamics. In this study, we introduce a novel model to achieve this. The novelty of our model is to represent the asymmetric weights of contexts at a particular timestamp using asymmetric windows. Further, multiple separate attentions are performed on the contexts, producing an updated representation of the particular timestamp. Each representation corresponding to one of the modes multiplies a weight vector controlled by a neural network. All multiplied results are merged with an addition operation. Experiments on the MOSI dataset show our model outperforms the compared methods.
C1 [Lai, Helang] Guangdong Justice Police Vocat Coll, Guangzhou 510520, Peoples R China.
   [Lai, Helang] South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Peoples R China.
   [Yan, Xueming] Guangdong Univ Foreign Studies, Guangzhou Key Lab Multilingual Intelligent Proc, Guangzhou 510000, Peoples R China.
   [Yan, Xueming] Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Sch Cyber Secur, Guangzhou 510000, Peoples R China.
C3 South China Normal University; Guangdong University of Foreign Studies;
   Guangdong University of Foreign Studies
RP Yan, XM (corresponding author), Guangdong Univ Foreign Studies, Guangzhou Key Lab Multilingual Intelligent Proc, Guangzhou 510000, Peoples R China.; Yan, XM (corresponding author), Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Sch Cyber Secur, Guangzhou 510000, Peoples R China.
EM xueming126@126.com
FU Science and Technology Program of Guangzhou [202102020878]; National
   Natural Science Foundation of China [62006053]; Special Innovation
   Project of Guangdong Education Department [2018KQNCX072]; Youth
   Innovative Talents Project in Guangdong Universities [2020KQNCX186];
   Fourth College Level Project of Guangdong Justice Police Vocational
   College [2020YB16]; 13th Five-Year Plan of Guangdong Institute of Higher
   Education Research on Higher Education of Young Teachers in Colleges and
   Universities [19GGZ070]
FX This research was supported in part by Science and Technology Program of
   Guangzhou (202102020878), National Natural Science Foundation of China
   (62006053), Special Innovation Project of Guangdong Education Department
   (2018KQNCX072), the Youth Innovative Talents Project in Guangdong
   Universities (2020KQNCX186), the Fourth College Level Project of
   Guangdong Justice Police Vocational College (2020YB16), the 13th
   Five-Year Plan of Guangdong Institute of Higher Education Research on
   Higher Education of Young Teachers in Colleges and Universities in 2019
   (19GGZ070), and thanks Ziang Liu for revising the english grammar of the
   paper.
CR Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Cavallari S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P377, DOI 10.1145/3132847.3132925
   Cho K., 2014, ARXIV14061078
   Datcu D, 2015, EMOTION RECOGNITION: A PATTERN ANALYSIS APPROACH, P411
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   Ebrahimi M, 2017, IEEE INTELL SYST, V32, P70, DOI 10.1109/MIS.2017.3711649
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Mekhaldi D, 2012, MULTIMED TOOLS APPL, V61, P353, DOI 10.1007/s11042-011-0842-x
   Mittal T, 2020, AAAI CONF ARTIF INTE, V34, P1359
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P284, DOI 10.1145/2993148.2993176
   Pandeya YR, 2021, MULTIMED TOOLS APPL, V80, P2887, DOI 10.1007/s11042-020-08836-3
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Perez-Rosas V., 2013, P ANN M ASS COMP LIN, P973
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Poria S, 2015, NEURAL NETWORKS, V63, P104, DOI 10.1016/j.neunet.2014.10.005
   Pun T, 2006, IEEE T NEUR SYS REH, V14, P210, DOI 10.1109/TNSRE.2006.875544
   Rajagopalan SS, 2016, LECT NOTES COMPUT SC, V9911, P338, DOI 10.1007/978-3-319-46478-7_21
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Shan C., 2007, Proc. British Machine Vision Conference, P1
   Sohrab F, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107648
   Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457
   Song Y, 2012, PROC CVPR IEEE, P2120, DOI 10.1109/CVPR.2012.6247918
   Tsai HY-H, 2018, ARXIV180606176
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Wang Weiran., 2015, Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37. ICML'15, P1083
   Wörtwein T, 2017, INT CONF AFFECT, P15, DOI 10.1109/ACII.2017.8273573
   Xing FZ, 2018, ARTIF INTELL REV, V50, P49, DOI 10.1007/s10462-017-9588-9
   Xu C, 2013, ARXIV PREPRINT ARXIV
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Young T, 2018, AAAI CONF ARTIF INTE, P4970
   Yu W, 2021, EUR SIGNAL PR CONF, P341, DOI 10.23919/Eusipco47968.2020.9287841
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   Zadeh A., 2016, ABS160606259 CORR
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zadeh Amir, 2018, Proc AAAI Conf Artif Intell, V2018, P5642
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zeng ZH, 2007, IEEE T MULTIMEDIA, V9, P424, DOI 10.1109/TMM.2006.886310
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 51
TC 5
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19415
EP 19428
DI 10.1007/s11042-021-11234-y
EA JUL 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000676052800001
DA 2024-07-18
ER

PT J
AU Patil, N
   Patil, PN
   Rao, PV
AF Patil, Naganagouda
   Patil, Preethi N.
   Rao, P. V.
TI Convolution neural network and deep-belief network (DBN) based automatic
   detection and diagnosis of Glaucoma
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fundus images; Glaucoma; Convolutional neural networks; Machine
   learning; Deep belief network
ID OPTICAL COHERENCE TOMOGRAPHY; IDENTIFICATION; IMAGES; SEGMENTATION;
   SYSTEM; DISC
AB Diagnosis of Glaucoma eye disease is a challenging task for CADx (computer-aided diagnostics) systems. An automatic CADx framework is developed for diagnosing glaucoma eye disease by handcrafted feature-based segmentation in retinal images. In this manuscript, automatic glaucoma eye disease detection based on deep learning (DL), with deep-belief network (DBN) is proposed. In addition, a contextualizing DL structure is proposed for obtaining various levels of portraying fundus images to separate among glaucoma and non-glaucoma modes, where the network uses output of other CNNs as information of context to support performance. The3 existing machine learning models are (1) SVM (support vector machine) (2) RF (random forest)(3) k-NN (k-nearest neighbor), which is executed and assessed on tests. The efficiency of the Glaucoma-Deep model is analyzed by the statistical measures like sensitivity, specificity, accuracy, precision. Finally, an official conclusion executed through the softmax straight classifier is to divide glaucoma and non-glaucoma retinal fundus images.
C1 [Patil, Naganagouda] Visvesvaraya Technol Univ, T John Inst Technol, Dept ECE, Belagavi, India.
   [Patil, Preethi N.] RV Coll Engn, Dept Comp Applicat, Bangalore, Karnataka, India.
   [Rao, P. V.] VBIT, Dept Elect & Commun Engn, Hyderabad, TS, India.
C3 Visvesvaraya Technological University; R.V. College of Engineering
RP Patil, N (corresponding author), Visvesvaraya Technol Univ, T John Inst Technol, Dept ECE, Belagavi, India.
EM ncpatil@gmail.com
RI Patil, Preethi N/AAS-8695-2021; Penugonda, Venkateswara/AAA-3956-2019;
   Patil, Preethi N/AAF-6691-2019
OI Patil, Preethi N/0000-0002-1024-5621
CR Acharya UR, 2017, COMPUT BIOL MED, V88, P72, DOI 10.1016/j.compbiomed.2017.06.022
   Acharya UR, 2015, BIOMED SIGNAL PROCES, V15, P18, DOI 10.1016/j.bspc.2014.09.004
   Asaoka R, 2019, AM J OPHTHALMOL, V198, P136, DOI 10.1016/j.ajo.2018.10.007
   Bechar ME, 2018, MULTIDIM SYST SIGN P, V29, P979, DOI 10.1007/s11045-017-0483-y
   Butt Nadeem Hafeez, 2016, Taiwan J Ophthalmol, V6, P119, DOI 10.1016/j.tjo.2016.01.004
   Chandrawati R, 2017, ADV MATER, V29, DOI 10.1002/adma.201604932
   de Sousa JA, 2017, MULTIMED TOOLS APPL, V76, P19173, DOI 10.1007/s11042-017-4608-y
   Devasia Thresiamma, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 104), P659, DOI 10.1007/978-981-13-1921-1_64
   Dong ZM, 2017, PROG RETIN EYE RES, V57, P76, DOI 10.1016/j.preteyeres.2016.11.001
   Ekinci G, 2017, SENSOR ACTUAT A-PHYS, V268, P32, DOI 10.1016/j.sna.2017.10.054
   Elseid A., 2018, CIIT INT J DIGIT IMA, V10, P10, DOI [10.4258/hir.2018.24.1.53, DOI 10.4258/HIR.2018.24.1.53]
   Faust O, 2017, PHYS MEDICA, V33, P1, DOI 10.1016/j.ejmp.2016.12.005
   Fu HZ, 2017, IEEE T MED IMAGING, V36, P1930, DOI 10.1109/TMI.2017.2703147
   Gour N, 2020, PATTERN RECOGN LETT, V137, P3, DOI 10.1016/j.patrec.2019.04.004
   Guo JP, 2019, IEEE ACCESS, V7, P8527, DOI 10.1109/ACCESS.2018.2890544
   Guo LY, 2015, COMPUT IND, V69, P72, DOI 10.1016/j.compind.2014.09.005
   Gupta Divakar, 2016, Taiwan J Ophthalmol, V6, P3, DOI 10.1016/j.tjo.2016.01.003
   Hagiwara Y, 2018, COMPUT METH PROG BIO, V165, P1, DOI 10.1016/j.cmpb.2018.07.012
   High-Resolution Fundus (HRF), IM DAT
   Issac A, 2015, COMPUT METH PROG BIO, V122, P229, DOI 10.1016/j.cmpb.2015.08.002
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kavya N, 2017, CONF REC ASILOMAR C, P1471, DOI 10.1109/ACSSC.2017.8335600
   Koh JEW, 2017, COMPUT BIOL MED, V84, P89, DOI 10.1016/j.compbiomed.2017.03.008
   Lavinsky F, 2017, OPHTHALMOLOGY, V124, pS76, DOI 10.1016/j.ophtha.2017.10.011
   Lee WJ, 2017, OPHTHALMOLOGY, V124, P1383, DOI 10.1016/j.ophtha.2017.03.013
   Araujo JDL, 2019, MULTIMED TOOLS APPL, V78, P12987, DOI 10.1007/s11042-018-6429-z
   Maheshwari S, 2019, COMPUT BIOL MED, V105, P72, DOI 10.1016/j.compbiomed.2018.11.028
   Mahiba C, 2019, MEASUREMENT, V135, P762, DOI 10.1016/j.measurement.2018.12.032
   Maksoud EAA, 2019, MACHINE LEARNING IN BIO-SIGNAL ANALYSIS AND DIAGNOSTIC IMAGING, P19, DOI 10.1016/B978-0-12-816086-2.00002-3
   Mohamed NA, 2019, BIOMED SIGNAL PROCES, V53, DOI [10.1016/j.bspc.2019.01.003, 10.1080/09291016.2019.1629167]
   Mvoulana A, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101643
   Mythili S., 2020, HKIE T, V27, P25, DOI DOI 10.33430/V27N1THIE-2018-0024
   Ohlemacher SK, 2016, STEM CELLS, V34, P1553, DOI 10.1002/stem.2356
   Perdomo O, 2018, LECT NOTES COMPUT SC, V11039, P319, DOI 10.1007/978-3-030-00949-6_38
   Raghavendra U, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1427-x
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Raghavendra U, 2018, BIOCYBERN BIOMED ENG, V38, P170, DOI 10.1016/j.bbe.2017.11.002
   Saba T, 2018, MICROSC RES TECHNIQ, V81, P1105, DOI 10.1002/jemt.23094
   Sarathi MP, 2016, BIOMED SIGNAL PROCES, V25, P108, DOI 10.1016/j.bspc.2015.10.012
   Serener A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P74, DOI 10.1109/tiptekno.2019.8894965
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Shi Y, 2019, OPHTHALMOL GLAUCOMA, V2, P136, DOI 10.1016/j.ogla.2019.02.006
   Shinoj VK, 2016, MED ENG PHYS, V38, P1383, DOI 10.1016/j.medengphy.2016.09.014
   Soorya M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1260-2
   Transpire Online, 2019, NOV NUM OPT ALG INSP
   Yu S, 2019, COMPUT MED IMAG GRAP, V74, P61, DOI 10.1016/j.compmedimag.2019.02.005
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 47
TC 9
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29481
EP 29495
DI 10.1007/s11042-021-11087-5
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000667613100002
DA 2024-07-18
ER

PT J
AU Abrar, M
   Zuhaira, B
   Anjum, A
AF Abrar, M.
   Zuhaira, B.
   Anjum, A.
TI Privacy-preserving data collection for 1: M dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data; Privacy; Privacy-preserving; Privacy mechanism; Privacy violation;
   Composite slicing; l-anatomy
AB Generation of humongous data in recent times is due to the ever-growing sources, primarily the Internet of Things, which is then collected to develop effective Artificial Intelligence (AI) and machine learning (ML) solutions. Though such data provides useful insight on various trends that eventually results in better quality of life, collecting such data raises privacy concerns for data owners. Preserving the privacy of individuals during the process of data collection is an important problem specifically in the context of 1:M datasets (an individual can have multiple records). Therefore, a novel privacy-preserving data collection protocol, for 1: M datasets has been proposed in this paper. The privacy-preserving mechanism ensures data safety from external and internal privacy breaches and its effective usage in micro data analysis through AI and ML methods. The use of the leader election algorithm and the notion of l-anatomy minimize the risk of privacy disclosures and enabled us to achieve higher computational efficiency.
C1 [Abrar, M.; Zuhaira, B.; Anjum, A.] Comsats Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Anjum, A.] Southern Univ Sci & Technol, Dept Comp Sci & Engn, 1088 Xueyuan Ave, Shenzhen 518055, Guangdong, Peoples R China.
C3 COMSATS University Islamabad (CUI); Southern University of Science &
   Technology
RP Anjum, A (corresponding author), Comsats Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.; Anjum, A (corresponding author), Southern Univ Sci & Technol, Dept Comp Sci & Engn, 1088 Xueyuan Ave, Shenzhen 518055, Guangdong, Peoples R China.
EM adeelanjum2001@hotmail.com
RI Zuhaira, Behjat/GSE-3021-2022; Anjum, Adeel/L-4391-2013
OI Anjum, Adeel/0000-0001-5083-0019
FU National Natural Science Foundation of China (NSFC) [61950410603]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) Project No.61950410603.
CR Andreou A., 2017, P IEEE ACM INT C ADV, P163, DOI [DOI 10.1145/3110025.3110046.25G, 10.1145/3110025.3110046, DOI 10.1145/3110025.3110046]
   Anjum A, 2019, SUSTAIN CITIES SOC, V45, P213, DOI 10.1016/j.scs.2018.11.037
   Bertino E, 2007, EFFICIENT K ANONYMIZ
   Boulos GW, 2009, MONDRIAN MUL DIMENSI
   Brickell J, 2006, EFFICIENT ANONYMITY
   Casas-Roma J, 2017, ARTIF INTELL REV, V47, P341, DOI 10.1007/s10462-016-9484-8
   Chen Q, 2016, INFORM UNDEFINED 201
   Clarke A, 2014, P ANN HICSS, P2908, DOI 10.1109/HICSS.2014.363
   CORNELIUS C, MOBISYS 08 P 6 INT C
   Fung BCM, 2007, IEEE T KNOWL DATA EN, V19, P711, DOI 10.1109/TKDE.2007.1015
   Fung Benjamin C. M., 2010, Introduction to Privacy-Preserving Data Publishing: Concepts and Techniques
   Ghinita G., 2007, FAST DATA ANONYMIZAT
   Gong QY, 2017, KNOWL-BASED SYST, V115, P15, DOI 10.1016/j.knosys.2016.10.012
   Hao X, 2018, FINDING QUASI IDENTI
   Isaak J, 2018, COMPUTER, V51, P56, DOI 10.1109/MC.2018.3191268
   Jayabalan, 2017, STUDY K ANONYMITY L
   Khan A., 2015, J SCI, V4, P426
   Khan A, 2019, EFFICIENT PRIVACY PR
   Khan R, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8416823
   Kim S, 2017, ANONYMIZATION PROTOC
   LeFevre Kristen., 2005, Incognito: Efficient full-domain k-anonymity
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Liu Y, 2010, PRISENSE PRIVACY PRE
   Luo ET, 2018, IEEE COMMUN MAG, V56, P163, DOI 10.1109/MCOM.2018.1700364
   Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P3, DOI [DOI 10.1145/1217299.1217302, 10.1109/icde.2006.1, DOI 10.1109/ICDE.2006.1]
   Machanavajjhala A., 2006, L DIVERSITY PRIVACY
   Malik S, 2013, MODELING ANAL STATE
   Mehmood Z, 2019, HIGHLY ROBUST HYBRID
   Nergiz M. E., 2007, P 2007 ACM SIGMOD IN, P665, DOI [DOI 10.1145/1247480.1247554, 10.1145/1247480.1247554]
   Ni W, 2017, ANONYMIZING 1 M MICR
   Poulis Giorgos, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P353, DOI 10.1007/978-3-642-40994-3_23
   Puthal D, 2012, SECURE DATA COLLECTI
   Raissi C, 2011, DISTRIBUTED PRIVACY
   Sarfaraz, 2018, FEATURE SELECTION BA
   Shin M, 2011, PERVASIVE MOB COMPUT, V7, P16, DOI 10.1016/j.pmcj.2010.04.001
   Sun L, 2011, EXTENDED K ANONYMITY
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Tao YD, 2008, LECT NOTES COMPUT SC, V5094, P205
   Terrovitis M, 2008, PROC VLDB ENDOW, V1, P115, DOI 10.14778/1453856.1453874
   Triandopoulos N, 2008, ANONYSENSE OPPORTUNI
   Uou ODY, 2005, ANONYMITY PRESERVING
   Vanasiwala JN, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2018), P394, DOI 10.1109/ICCMC.2018.8487483
   Wong R. C.-W., 2006, 12 ACM SIGKDD INT C, P754, DOI DOI 10.1145/1150402.1150499
   Xia Z., 2019, PRIVACY PRESERVING R
   Xue M, 2011, INT C DAT SYST ADV A
   Yang Z, 2009, K ANONYMOUS DATA COL
   Yang Z., 2005, ACM SIGKDD, P334
   Yao L, 2021, IEEE T NEUR NET LEAR, V32, P3330, DOI 10.1109/TNNLS.2019.2958184
   Yu D, 2020, AGGREGATE QUERY ANSW
   Zhong S, 2005, PRIVACY ENHANCING K
NR 50
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31335
EP 31356
DI 10.1007/s11042-021-10562-3
EA JUN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000659401100002
DA 2024-07-18
ER

PT J
AU Bao, ZJ
   Xue, R
   Jin, YD
AF Bao, Zhenjie
   Xue, Ru
   Jin, Yadong
TI Image scrambling adversarial autoencoder based on the asymmetric
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transmission security; Image scrambling; Adversarial autoencoder;
   Asymmetric encryption
ID SEMI-TENSOR PRODUCT; ALGORITHM; MATRIX; PERMUTATION
AB For the purpose of information transmission security, image scrambling is to encrypt the image by changing the image pixel values and pixel positions. Based on the asymmetric encryption, we propose a model of Image Scrambling Adversarial Autoencoder. Firstly, we describe an encoder-decoder framework to imitate the procedure of image scramble, descramble and the key generation. Secondly, we employ the generator network of CycleGAN as the encoder and decoder structure of our method to transfer the secret image to totally meaningless image and reconstruct it. Thirdly, the parameters of the encoder and decoder can be regarded as the public key and private key. Then, the patchGANs discriminator is used to distinguish encoded images and evenly distributed noise by image blocks. Moreover, we combine the encode-then-decode loss function with the adversarial loss function by an adjustable parameter in order to make the model training results more stable. Experiments show that our method can accomplish automatic image scrambling in ten different scenes which include Africa people and villages, beach, buildings, buses, dinosaurs, elephants, flowers, horses, mountains and glaciers, food. Compared with 3D Arnold transformation and CycleGAN, scrambled pixels by our method are more evenly distributed intuitively. What is more, extensive experiments show that the proposed method can address security requirements partly and achieve a good encryption efficiency. In addition, contrast experimental results show that the combination of the encode-then-decode loss function and the adversarial loss function is essential to achieve the ideal results of image scrambling and restoration.
C1 [Bao, Zhenjie; Xue, Ru; Jin, Yadong] Xizang Minzu Univ, Sch Informat Engn, Xianyang, Shaanxi, Peoples R China.
C3 Xizang Minzu University
RP Xue, R (corresponding author), Xizang Minzu Univ, Sch Informat Engn, Xianyang, Shaanxi, Peoples R China.
EM 928009239@qq.com; rxue@xzmu.edu.cn
RI 鲍, 震杰/HKD-9006-2023
OI Bao, Zhenjie/0000-0001-5499-2883
FU National Key Research and Development Project of China [2017YFB1402100];
   Natural Science Foundation of Xizang Autonomous Region of China
   [XZ2018ZR G-64]
FX This study is supported in part by the National Key Research and
   Development Project of China under Grant 2017YFB1402100, in part by the
   Natural Science Foundation of Xizang Autonomous Region of China under
   Grant XZ2018ZR G-64.
CR AprilPyone MM, 2019, IEEE 8 GLOB C CONS E, P667
   BAEK J., 2000, ACISP, P49, DOI DOI 10.1007/10718964
   Battisti F, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/938515
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen J, 2019, IEEE ACCESS, V7, P181083, DOI 10.1109/ACCESS.2019.2959031
   Daras Giannis, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14519, DOI 10.1109/CVPR42600.2020.01454
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Dong J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103430
   Feng L, 2015, J VIS COMMUN IMAGE R, V33, P104, DOI 10.1016/j.jvcir.2015.09.002
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308
   Hamza YA, 2019, INTERNATIONAL CONFERENCE OF INFORMATION AND COMMUNICATION TECHNOLOGY (ICICT 2019), P134, DOI 10.1145/3321289.3321323
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidari S, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2122-4
   Hu F., 2016, An Image Compression and Encryption Scheme Based on Deep Learning
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Kocher P. C., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P104
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu ZJ, 2010, OPT LASER ENG, V48, P800, DOI 10.1016/j.optlaseng.2010.02.005
   Luo H, 2004, J IMAGE GRAPHICS, V10, P79, DOI 10.013
   Makhzani A., 2015, ARXIV
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Martin A., 2017, ARXIV170107875
   Miller V. S., 1985, ADV CRYPTOLOGY CRYPT, P417, DOI DOI 10.1007/3-540-39799-X_31
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Pellegrini A, 2010, DES AUT TEST EUROPE, P855
   Qi DX, 2000, SCI CHINA SER E, V43, P304, DOI 10.1007/BF02916835
   Qin YY, 2019, IOP C SER EARTH ENV, V252, DOI 10.1088/1755-1315/252/5/052007
   Tanaka M., 2018, IEEE International Conference on Consumer Electronics-Taiwan, P1
   Taneja N, 2011, INT J WAVELETS MULTI, V9, P317, DOI 10.1142/S0219691311004092
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tang, 2017, J CHANGSHA AERONAUTI, V17, P90, DOI [10.13829/j.cnki.issn.16719654.2017.02.022, DOI 10.13829/J.CNKI.ISSN.16719654.2017.02.022]
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tetsuji, 2020, ARXIV200107761
   Tianyu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8382, DOI 10.1109/CVPR42600.2020.00841
   Ulyanov Dmitry, 2016, arXiv
   Uppu R, 2019, QUANTUM SCI TECHNOL, V4, DOI 10.1088/2058-9565/ab479f
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu C, 2019, OPT COMMUN, V431, P203, DOI 10.1016/j.optcom.2018.09.034
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiong GQ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/8087958
   Xu WH, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2695398
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yousaf MA, 2020, IEEE ACCESS, V8, P39781, DOI 10.1109/ACCESS.2020.2975880
   Yuan XF, 2018, IEEE T IND INFORM, V14, P3235, DOI 10.1109/TII.2018.2809730
   Zenuni, 2012, J SCI TECHNOL, V2, P9
   Zhang H., 2018, ARXIV180508318
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 69
TC 13
Z9 13
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28265
EP 28301
DI 10.1007/s11042-021-11043-3
EA JUN 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657212500006
DA 2024-07-18
ER

PT J
AU Li, DH
   Cui, JZ
   Bai, YF
   Chen, CC
AF Li, Dahui
   Cui, Jianzhao
   Bai, Yunfei
   Chen, Changcui
TI Research on anti-conflict extraction method of multimedia video
   information based on machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Multimedia video information; Information conflict;
   Information scheduling; Information extraction
AB In order to solve the problems of long time, poor denoising performance, low quality of multimedia video information and low efficiency of information extraction in current methods of extracting multimedia video information. An anti-collision extraction method of multimedia video information based on machine learning is proposed, which combines K-SVD algorithm and Batch-OMP algorithm to remove noise in multimedia video information. Considering the error concealment method used by decoder, channel condition, importance and lifetime of multimedia video information package, C uses improved proportional fair scheduling algorithm to complete the scheduling of multimedia video information. It calculates the time curve of multimedia video information, gets the local extremum points in the time curve, determines the length and location of the extracted video clips according to the local extremum points, calculates the importance of the video clips, and completes the extraction of multimedia video information according to the importance. In order to verify the effectiveness of the proposed method, a simulation experiment is carried out. The experimental results show that compared with the traditional methods, the proposed method has better denoising performance and higher information extraction efficiency. The above results show that the proposed method has good application prospects.
C1 [Li, Dahui; Cui, Jianzhao; Bai, Yunfei; Chen, Changcui] Qiqihar Univ, Sch Comp & Control Engn, 42 Culture St, Qiqihar 161000, Heilongjiang, Peoples R China.
C3 Qiqihar University
RP Li, DH (corresponding author), Qiqihar Univ, Sch Comp & Control Engn, 42 Culture St, Qiqihar 161000, Heilongjiang, Peoples R China.
EM dahuilii@tom.com
CR Atkinson-Abutridy J, 2004, IEEE INTELL SYST, V19, P22, DOI 10.1109/MIS.2004.4
   Bang I, 2017, IEEE T WIREL COMMUN, V16, P7460, DOI 10.1109/TWC.2017.2748942
   Eriksson E, 2016, IEEE T MOBILE COMPUT, V15, P1743, DOI 10.1109/TMC.2015.2465390
   Feng H, 2016, IEEE T INFORM THEORY, V62, P7299, DOI 10.1109/TIT.2016.2614687
   Jin Y., 2017, APPL ELECT TECH, V43, P110
   Lee GB, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030659
   [李玲慧 Li Linghui], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P1
   Lewis P, 2016, ENVIRON BIOL FISH, V95, P431
   Li GR, 2016, MULTIMEDIA SYST, V22, P115, DOI 10.1007/s00530-014-0402-0
   Li HJ, 2016, MULTIMEDIA SYST, V22, P405, DOI 10.1007/s00530-014-0404-y
   Ruan WH., 2016, AUTOM INSTRUM, V3, P40
   [汪荣贵 Wang Ronggui], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1652
   Wang S., 2017, NEUROCOMPUTING, V277
   Wang Wanliang, 2017, Journal of Zhejiang University of Technology, V45, P14
   Yajnanarayana V, 2017, IEEE T MOBILE COMPUT, P1
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yu LX., 2016, COMPUT SIMUL, V34, P398
   Zhang D, 2016, REV SCI INSTRUM, V87, P516
   Zhang Y., 2017, J CHINA ACAD ELECT I, V12, P246
NR 19
TC 0
Z9 0
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22701
EP 22718
DI 10.1007/s11042-019-07755-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100018
DA 2024-07-18
ER

PT J
AU Ullah, W
   Muhammad, K
   Ul Haq, I
   Ullah, A
   Khattak, SU
   Sajjad, M
AF Ullah, Waseem
   Muhammad, Khan
   Ul Haq, Ijaz
   Ullah, Amin
   Ullah Khattak, Saeed
   Sajjad, Muhammad
TI Splicing sites prediction of human genome using machine learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical data; Big data analysis; Computer-aided diagnosis; Genomics;
   Machine learning; Pattern recognition; Splicing sites
ID SEQUENCE-BASED PREDICTOR; SUPPORT VECTOR MACHINE; TRANSLATION INITIATION
   SITE; AMINO-ACID-COMPOSITION; PSEUDO TRINUCLEOTIDE; COMPUTATIONAL
   METHOD; DEFECT PREDICTION; GENERAL-FORM; DNA-SEQUENCE; IDENTIFICATION
AB The accurate splice site prediction has several applications in the field of medical sciences and biochemistry. For instance, any mutation affecting the splice site will lead to genetic diseases and cancer such as Lynch syndrome and breast cancer. For this purpose, collecting the Ribonucleic Acid (RNA) samples is an efficient and convenient method to detect the involvement of splicing defects in disease formation. Therefore, the present study aims to develop an accurate and robust Computer-Aided Diagnosis (CAD) method for swift and precise targeting of splice site sequences. A composite features-based model is proposed by integrating three different sample representation methods i.e., Dinucleotide Composition (DNC), Trinucleotide Composition (TNC) and Tetranucleotide Composition (TetraNC) for precise splice site prediction after converting the DNA sequences into numerical descriptors. The precision and accuracy of these features are analyzed by applying different machine learning algorithms such as Support Vector Machine (SVM), K-Nearest Neighbor (KNN) and Naive Bayes (NB). Results show that the proposed model of composite features vector with SVM classifier achieved an accuracy of 95.20% and 97.50% for donor and acceptor sites datasets, respectively.
C1 [Ullah, Waseem; Ul Haq, Ijaz; Ullah, Amin] Sejong Univ, Intelligent Media Lab, Seoul 143747, South Korea.
   [Muhammad, Khan] Sejong Univ, Dept Software, Visual Analyt Knowledge Lab, Seoul 143747, South Korea.
   [Ullah Khattak, Saeed] Univ Peshawar, Ctr Biotechnol & Microbiol, Peshawar, Pakistan.
   [Sajjad, Muhammad] Islamia Coll Peshawar, Dept Comp Sci, Peshawar, Pakistan.
C3 Sejong University; Sejong University; University of Peshawar; University
   of Peshawar
RP Muhammad, K (corresponding author), Sejong Univ, Dept Software, Visual Analyt Knowledge Lab, Seoul 143747, South Korea.; Sajjad, M (corresponding author), Islamia Coll Peshawar, Dept Comp Sci, Peshawar, Pakistan.
EM waseem@sju.ac.kr; khanmuhammad@sju.ac.kr; ijazulhaq@sju.ac.kr;
   qamin3797@sju.ac.kr; khattak@uop.edu.pk; muhammad.sajjad@icp.edu.pk
RI ULLAH, Waseem/ABE-6599-2021; Haq, ijaz ul/AAK-5306-2020; Sajjad,
   Muhammad/L-5269-2016; Khan, Muhammad/IXN-8470-2023; Ullah,
   Amin/AAH-5034-2020; Muhammad, Khan/L-9059-2016; Ullah,
   Amin/JPA-6034-2023
OI Sajjad, Muhammad/0000-0001-5646-0338; Ullah, Amin/0000-0001-7538-2689;
   Muhammad, Khan/0000-0003-4055-7412; Muhammad, Khan/0000-0002-5302-1150;
   Haq, Ijaz Ul/0000-0001-8201-7372; ullah, Waseem/0000-0001-5191-9023
CR Ali F, 2016, J THEOR BIOL, V403, P30, DOI 10.1016/j.jtbi.2016.05.011
   Angermueller C, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1189-z
   [Anonymous], 2013, J. Biomed. Sci. Eng, DOI DOI 10.4236/JBISE.2013.64054
   Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951
   Burke B, 2014, CURR TOP DEV BIOL, V109, P1, DOI 10.1016/B978-0-12-397920-9.00006-8
   Cai YD, 2003, BIOPHYS J, V84, P3257, DOI 10.1016/S0006-3495(03)70050-2
   Cao DS, 2013, BIOINFORMATICS, V29, P960, DOI 10.1093/bioinformatics/btt072
   Cartegni L, 2003, NUCLEIC ACIDS RES, V31, P3568, DOI 10.1093/nar/gkg616
   Chaki J, 2019, MULTIMED TOOLS APPL, P1
   Chen W, 2015, MOL BIOSYST, V11, P2620, DOI 10.1039/c5mb00155b
   Chen W, 2015, BIOINFORMATICS, V31, P119, DOI 10.1093/bioinformatics/btu602
   Chen W, 2014, ANAL BIOCHEM, V462, P76, DOI 10.1016/j.ab.2014.06.022
   Chen W, 2014, BIOMED RES INT-UK, V2014, DOI 10.1155/2014/623149
   Chen W, 2013, NUCLEIC ACIDS RES, V41, DOI 10.1093/nar/gks1450
   Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466
   Chou KC, 2001, PROTEINS, V42, P136, DOI 10.1002/1097-0134(20010101)42:1<136::AID-PROT130>3.0.CO;2-F
   Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035
   Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006
   Chou KC, 2009, CURR PROTEOMICS, V6, P262, DOI 10.2174/157016409789973707
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui Y, 2013, BIOCHEM BIOPH RES CO, V431, P221, DOI 10.1016/j.bbrc.2012.12.131
   Du PF, 2014, INT J MOL SCI, V15, P3495, DOI 10.3390/ijms15033495
   Feng PM, 2013, ANAL BIOCHEM, V442, P118, DOI 10.1016/j.ab.2013.05.024
   Fernández M, 2012, NUCLEIC ACIDS RES, V40, DOI 10.1093/nar/gks149
   Firpi HA, 2010, BIOINFORMATICS, V26, P1579, DOI 10.1093/bioinformatics/btq248
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Garhwal AS, 2019, MULTIMED TOOLS APPL, V78, P9537, DOI 10.1007/s11042-018-6551-y
   Goel N, 2015, PROCEDIA COMPUT SCI, V57, P358, DOI 10.1016/j.procs.2015.07.350
   Guo SH, 2014, BIOINFORMATICS, V30, P1522, DOI 10.1093/bioinformatics/btu083
   Henderson J, 1997, J COMPUT BIOL, V4, P127, DOI 10.1089/cmb.1997.4.127
   Hill ST, 2018, NUCLEIC ACIDS RES, V46, P8105, DOI 10.1093/nar/gky567
   Hoang T, 2020, GENOMICS, V112, P1847, DOI 10.1016/j.ygeno.2019.10.018
   Iqbal M, 2016, COMPUT METH PROG BIO, V128, P1, DOI 10.1016/j.cmpb.2016.02.006
   Jian XQ, 2014, GENET MED, V16, P497, DOI 10.1038/gim.2013.176
   Kabir M, 2017, CHEMOMETR INTELL LAB, V167, P78, DOI 10.1016/j.chemolab.2017.05.001
   Kabir M, 2015, COMPUT BIOL MED, V66, P252, DOI 10.1016/j.compbiomed.2015.09.010
   Kandaswamy KK, 2011, J THEOR BIOL, V270, P56, DOI 10.1016/j.jtbi.2010.10.037
   Kanrar, 2019, ARXIV PREPRINT ARXIV
   Kulakovskiy IV, 2013, NUCLEIC ACIDS RES, V41, pD195, DOI 10.1093/nar/gks1089
   Li C, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6120406
   Li WY, 2017, AER ADV ENG RES, V128, P1
   Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77
   Lin H, 2014, NUCLEIC ACIDS RES, V42, P12961, DOI 10.1093/nar/gku1019
   Liu B, 2016, NEUROCOMPUTING, V217, P46, DOI 10.1016/j.neucom.2015.12.138
   Liu B, 2015, NUCLEIC ACIDS RES, V43, pW65, DOI 10.1093/nar/gkv458
   Maji S, 2014, CURR BIOINFORM, V9, P76, DOI 10.2174/1574893608999140109121721
   Meher PK, 2016, ALGORITHM MOL BIOL, V11, DOI 10.1186/s13015-016-0078-4
   Moles-Fernández A, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00366
   Naito T, 2019, HUM MUTAT, V40, P1261, DOI 10.1002/humu.23794
   Nanni L, 2006, BIOINFORMATICS, V22, P1207, DOI 10.1093/bioinformatics/btl055
   Nazari I, 2019, CHEMOMETR INTELL LAB, V193, DOI 10.1016/j.chemolab.2019.103811
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Ogura H, 1997, COMPUT BIOL MED, V27, P67, DOI 10.1016/S0010-4825(96)00044-3
   Pashaei E, 2017, HEALTH TECHNOL-GER, V7, P141, DOI 10.1007/s12553-016-0157-z
   Pertea M, 2001, NUCLEIC ACIDS RES, V29, P1185, DOI 10.1093/nar/29.5.1185
   Pollastro P, 2002, INT J MOD PHYS C, V13, P1105, DOI 10.1142/S0129183102003796
   Qiu WR, 2014, INT J MOL SCI, V15, P1746, DOI 10.3390/ijms15021746
   Quang D, 2019, METHODS, V166, P40, DOI 10.1016/j.ymeth.2019.03.020
   Reese MG, 1997, J COMPUT BIOL, V4, P311, DOI 10.1089/cmb.1997.4.311
   Rhine CL, 2018, PLOS GENET, V14, DOI 10.1371/journal.pgen.1007231
   Richhariya B, 2019, ADV INTELL SYST, V748, P569, DOI 10.1007/978-981-13-0923-6_49
   Schäffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994
   Tahir M, 2017, COMPUT METH PROG BIO, V146, P69, DOI 10.1016/j.cmpb.2017.05.008
   Tahir M, 2016, MOL BIOSYST, V12, P2587, DOI 10.1039/c6mb00221h
   Tanveer M, 2019, INFORM SCIENCES, V494, P311, DOI 10.1016/j.ins.2019.04.032
   Tanveer M, 2016, KNOWL-BASED SYST, V94, P70, DOI 10.1016/j.knosys.2015.11.011
   Tayara H, 2019, CHEMOMETR INTELL LAB, V188, P63, DOI 10.1016/j.chemolab.2019.03.002
   Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254
   Touati R, 2019, MULTIMED TOOLS APPL, V78, P13047, DOI 10.1007/s11042-018-6455-x
   Vaz-Drago R, 2017, HUM GENET, V136, P1093, DOI 10.1007/s00439-017-1809-4
   Waris M, 2016, NEUROCOMPUTING, V199, P154, DOI 10.1016/j.neucom.2016.03.025
   Xiao X, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030869
   Xu QZ, 2019, CLUSTER COMPUT, V22, pS2731, DOI 10.1007/s10586-017-1436-9
   Xu ZC, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08523-8
   Zhang MQ, 1997, P NATL ACAD SCI USA, V94, P565, DOI 10.1073/pnas.94.2.565
   Zhang XHF, 2003, GENOME RES, V13, P2637, DOI 10.1101/gr.1679003
   Zhang Y, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-5350-1
   Zhang ZQ, 2019, BRIEF FUNCT GENOMICS, V18, P41, DOI 10.1093/bfgp/ely030
   Zou J, 2019, NAT GENET, V51, P12, DOI 10.1038/s41588-018-0295-5
NR 79
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30439
EP 30460
DI 10.1007/s11042-021-10619-3
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000652455300002
DA 2024-07-18
ER

PT J
AU Lee, C
   Kang, SG
   Nayyar, A
AF Lee, Changkyu
   Kang, Shin-Gak
   Nayyar, Anand
TI Location-proximity-based clustering method for peer-to-peer multimedia
   streaming services with multiple sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer to peer networking; Video conferencing; Multi-view video streaming;
   Clustering
ID VIDEO
AB Social distancing to reduce the spread of coronavirus disease 2019 (COVID-19) made a huge increase in the global OTT market, and OTT service providers get millions of new subscribers. Recently OTT service providers are extending their service to video broadcasting. As a one type of video broadcasting, this paper covers multimedia streaming with multiple sources. Multimedia streaming with multiple sources has multiple sources, and receivers can select one specific source to watch the video from the source. Sources include cameras capturing different angles of same event or location, cameras in geographical locations, etc. For delivering video to rapidly increasing number of users, multimedia streaming with multiple sources system needs efficient and scalable delivery method. Tree-based Peer-to-peer (P2P) networking has been investigated as the delivery solution of multimedia streaming with multiple sources, and set-top boxes or mobile apps of OTT service can be used as peers connecting the subscriber of OTT service. However, the scalability of the tree-based P2P networking is limited by the out-degree of a tree that branches linearly with the number of users. Hence, this study proposes clustering peers based on the location proximity of the peers to enhance the scalability of the P2P multimedia streaming with multiple sources. By clustering peers, one or more peers can be grouped into a virtual peer with an aggregated uplink/downlink capacity. This paper describes P2P multimedia streaming with multiple sources and algorithms for the proposed clustering method. Two applications which are one-view multiparty video conferencing and multi-view video streaming are introduced, and considerations for applying the proposed method to the applications are also discussed. The experimental results show that location-proximity-based clustering is effective in achieving a scalable P2P multimedia streaming with multiple sources by reducing the out-degree of a tree for the introduced applications. The proposed clustering leads improvement in the maximum achievable video bit rate, the average viewing video bit rate, and perceived delay.
C1 [Lee, Changkyu; Kang, Shin-Gak] Univ Sci & Technol UST, Dept ICT, Daejeon, South Korea.
   [Lee, Changkyu; Kang, Shin-Gak] Elect & Telecommun Res Inst ETRI, Protocol Engn Ctr PEC, Daejeon, South Korea.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 University of Science & Technology (UST); Electronics &
   Telecommunications Research Institute - Korea (ETRI); Duy Tan University
RP Lee, C (corresponding author), Univ Sci & Technol UST, Dept ICT, Daejeon, South Korea.; Lee, C (corresponding author), Elect & Telecommun Res Inst ETRI, Protocol Engn Ctr PEC, Daejeon, South Korea.
EM changkyu.lee@etri.re.kr; sgkang@etri.re.kr; anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146
FU ICT R&D programs of MSIP/IITP [2016-0-00192]
FX This work was supported by the ICT R&D programs of MSIP/IITP.
   [2016-0-00192, Standards development for service control and contents
   delivery for smart signage services].
CR Akkus IE, 2011, J NETW COMPUT APPL, V34, P137, DOI 10.1016/j.jnca.2010.08.006
   Bae SH, 2013, IEEE T BROADCAST, V59, P209, DOI 10.1109/TBC.2013.2247171
   Bharambe AR, 2006, IEEE INFOCOM SER, P2884
   Chen MH, 2012, IEEE ACM T NETWORK, V20, P1681, DOI 10.1109/TNET.2012.2201166
   IEEE, 2017, 8216 IEEE HTTP RFC
   ISO/IEC, 2014, Rep. 23009-1. ISO/IEC JTCI/SC29/WG11
   ITU-T, 2010, ITU T RECOMMENDATION
   Kumar R, 2007, IEEE INFOCOM SER, P919, DOI 10.1109/INFCOM.2007.112
   Kurdoglu E, 2016, IEEE T MULTIMEDIA, V18, P90, DOI 10.1109/TMM.2015.2496872
   Liu Y, 2009, INT CON DISTR COMP S, P423, DOI 10.1109/ICDCS.2009.50
   Manzillo MP, 2012, IEEE T PARALL DISTR, V23, P1030, DOI 10.1109/TPDS.2011.249
   National Institute of Standards and Technology, 1995, FED INF PROC STAND P
   Ponec M, 2011, IEEE T MULTIMEDIA, V13, P856, DOI 10.1109/TMM.2011.2161759
   Shen HY, 2015, IEEE T PARALL DISTR, V26, P1509, DOI 10.1109/TPDS.2014.2327033
   Tu XP, 2008, ACM T INTERNET TECHN, V8, DOI 10.1145/1323651.1323653
   Wu WM, 2017, IEEE ACCESS, V5, P25474, DOI 10.1109/ACCESS.2017.2768798
   Xin xin Chen, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P149, DOI 10.1109/ICISE.2009.358
   Xu Y, 2014, IEEE ACM T NETWORK, V22, P826, DOI 10.1109/TNET.2013.2260354
   Zhang, 2004, 2004 SIGCOMM AS WORK
   Zhang, 2011, P INT C COMP INF SCI, P809
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhao YX, 2014, IEEE T PARALL DISTR, V25, P73, DOI 10.1109/TPDS.2013.12
NR 22
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23051
EP 23090
DI 10.1007/s11042-021-10985-y
EA MAY 2021
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000652106200003
PM 34025208
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Javidani, A
   Mahmoudi-Aznaveh, A
AF Javidani, Ali
   Mahmoudi-Aznaveh, Ahmad
TI Learning representative temporal features for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video classification; Human action recognition; Deep learning;
   Multi-Channel time series; One dimensional convolutional neural network
   (1D-CNN)
ID MOTION
AB In this paper, a novel video classification method is presented that aims to recognize different categories of third-person videos efficiently. Our motivation is to achieve a light model that could be trained with insufficient training data. With this intuition, the processing of the 3-dimensional video input is broken to 1D in temporal dimension on top of the 2D in spatial. The processes related to 2D spatial frames are being done by utilizing pre-trained networks with no training phase. The only step which involves training is to classify the 1D time series resulted from the description of the 2D signals. As a matter of fact, optical flow images are first calculated from consecutive frames and described by pre-trained CNN networks. Their dimension is then reduced using PCA. By stacking the description vectors beside each other, a multi-channel time series is created for each video. Each channel of the time series represents a specific feature and follows it over time. The main focus of the proposed method is to classify the obtained time series effectively. Towards this, the idea is to let the machine learn temporal features. This is done by training a multi-channel one dimensional Convolutional Neural Network (1D-CNN). The 1D-CNN learns the features along the only temporal dimension. Hence, the number of training parameters decreases significantly which would result in the trainability of the method on even smaller datasets. It is illustrated that the proposed method could reach the state-of-the-art results on two public datasets UCF11, jHMDB and competitive results on HMDB51.
C1 [Javidani, Ali] Queens Univ, Dept Elect & Comp Engn, Kingston, ON, Canada.
   [Javidani, Ali; Mahmoudi-Aznaveh, Ahmad] Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
C3 Queens University - Canada; Shahid Beheshti University
RP Javidani, A (corresponding author), Queens Univ, Dept Elect & Comp Engn, Kingston, ON, Canada.; Javidani, A (corresponding author), Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
EM alijavidanii@gmail.com
RI Javidani, Ali/AAW-5623-2021; Mahmoudi-Aznaveh, Ahmad/AAC-1996-2022
OI Javidani, Ali/0000-0002-1502-5548
CR [Anonymous], 2017, PROC PACIFIC RIM S I
   Bourdev, 2014, ARXIV14120767, V2, P7
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng Yu, 2018, ARXIV PREPRINT ARXIV
   Cherian A, 2017, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR.2017.172
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Cho J, 2014, PATTERN RECOGN, V47, P1813, DOI 10.1016/j.patcog.2013.12.004
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Csurka G, 2011, COMM COM INF SC, V229, P28
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Diba A., 2017, Temporal 3D ConvNets: New architecture and transfer learning for video classification
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   El-Nouby A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P31, DOI 10.1109/CRV.2018.00015
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Feichtenhofer C, 2016, ADV NEUR IN, V29
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Ghanem, 2017, END TO END SINGLE ST, V2, P7
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang, 2017, RETHINKING SPATIOTEM, V1, P5
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Iqbal A, 2017, LECT NOTES COMPUT SC, V10496, P126, DOI 10.1007/978-3-319-66709-6_11
   Javidani A, 2018, IRAN CONF ELECTR ENG, P1629, DOI 10.1109/ICEE.2018.8472580
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Liu ZK, 2017, IEEE IMAGE PROC, P870, DOI 10.1109/ICIP.2017.8296405
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthies L, 2016, SPIE DEFENSE SECURIT
   Nazir S, 2018, PATTERN RECOGN LETT, V103, P39, DOI 10.1016/j.patrec.2017.12.024
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Patel CI, 2018, COMPUT ELECTR ENG, V70, P284, DOI 10.1016/j.compeleceng.2016.06.004
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Piergiovanni AJ, 2017, AAAI CONF ARTIF INTE, P4247
   Ravanbakhsh M., 2015, ARXIV PREPRINT ARXIV
   Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691
   Salakhutdinov, 2015, ARXIV151104119
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Simonyan K, 2014, ADV NEUR IN, V27
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun C, 2019, PROC CVPR IEEE, P273, DOI 10.1109/CVPR.2019.00036
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Yan A, 2019, PROC CVPR IEEE, P7914, DOI 10.1109/CVPR.2019.00811
   Yang K, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356149
   Zhang PF, 2018, LECT NOTES COMPUT SC, V11213, P136, DOI 10.1007/978-3-030-01240-3_9
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhu Y, 2019, LECT NOTES COMPUT SC, V11363, P363, DOI 10.1007/978-3-030-20893-6_23
   Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316
NR 72
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3145
EP 3163
DI 10.1007/s11042-021-11022-8
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000651019100001
DA 2024-07-18
ER

PT J
AU Mohan, HM
   Rao, P
   Kumara, HCS
   Manasa, S
AF Mohan, H. M.
   Rao, P., V
   Kumara, H. C. Shivaraj
   Manasa, S.
TI Non-invasive technique for real-time myocardial infarction detection
   using faster R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Myocardial infarction; Vital signs; Mean average precision; Average
   recall; Faster region convolution neural network
ID FALL DETECTION
AB The medical history explores that Myocardial Infarction has been one of the leading factors of death in human beings since several decades globally. The researchers' key tasks are to emerge a novel real-time health vision-based monitoring system with added measurement features like high accuracy, robust, reliable, low-cost, low power with high data security. The main purpose of this research is to bestow an advanced non-invasive algorithmic approach for detecting the chest pain posture and fall posture based vital signs of Myocardial Infarction and analyzing the performance of a Faster Region-based Convolution Neural Network algorithm. This object detection computer vision technique is simulated for 3000 three-dimensional real-life indoor environment RGB color images for two datasets Nanyang Technological University Red Blue Green, and Depth dataset and private dataset-RMS trained datasets using TensorFlow object detection Application Programming Interface. The 3D RGB Images of NTU RGB database used for Vital Signs of Myocardial Infarction performance analysis is an improved approach. The simulation results have been compared with the existing works. The demonstrated results of ResNet-101 Faster RCNN showed the evaluated metric values: high mean precision and average recall value is a major contribution in this work.
C1 [Mohan, H. M.] Visvesvaraya Technol Univ, T John Inst Technol, Dept ECE, Belagavi, India.
   [Rao, P., V] Vignana Bharathi Inst Technol, Dept ECE, Hyderabad, India.
   [Kumara, H. C. Shivaraj] Skillmine Technolgy Consulting Private Ltd, Bangalore, Karnataka, India.
   [Manasa, S.] Visvesvaraya Technol Univ, Dayananda Sagar Acad, Dept EEE, Belagavi, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University
RP Mohan, HM (corresponding author), Visvesvaraya Technol Univ, T John Inst Technol, Dept ECE, Belagavi, India.
EM mohanhm@gmail.com; shivrajepe@gmail.com; manasa.s.athresha@gmail.com
CR Azimi I, 2016, 2016 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS), P19, DOI 10.1109/IWBIS.2016.7872884
   Balla C, 2018, CARDIOLOGY, V140, P52, DOI 10.1159/000487936
   Bizopoulos P, 2019, IEEE REV BIOMED ENG, V12, P168, DOI 10.1109/RBME.2018.2885714
   Chen T, 2020, NEURAL PROCESS LETT, V51, P1599, DOI 10.1007/s11063-019-10159-w
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   David AR, 2010, LANCET, V375, P718, DOI 10.1016/S0140-6736(10)60294-2
   Fog Computing in Healthcare, REV DISC, V5, P9206
   GORLIN R, 1965, CIRCULATION, V32, P138, DOI 10.1161/01.CIR.32.1.138
   Heberden W, 1987, CLIN CARDIOL, V10, P211, DOI [10.1002/clc.4960100314, DOI 10.1002/CLC.4960100314]
   Hildreth CJ, 2003, J AM MED ASS, V290
   Hur T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113910
   Jia, 2020, IEEE 5 INT C IM VIS
   Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J, 2022, IEEE T ENG MANAGE, V69, P1902, DOI 10.1109/TEM.2019.2940702
   Lin HY, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P285, DOI [10.1109/ICS.2016.0064, 10.1109/ICS.2016.63]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Lu KL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101995
   Lu Y, 2018, CANCER RES, V78, P5135, DOI 10.1158/0008-5472.CAN-18-0494
   Malik MA, 2013, PAK J MED SCI, V29, P565, DOI 10.12669/pjms.292.2921
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Moniruzzaman MD, 2020, FASTER R CNN BASED D
   Mshali H, 2018, INT J IND ERGONOM, V66, P26, DOI 10.1016/j.ergon.2018.02.002
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Panju AA, 1998, JAMA-J AM MED ASSOC, V280, P1256, DOI 10.1001/jama.280.14.1256
   Patel A, 2018, J AM COLL CARDIOL, V71, P808, DOI 10.1016/j.jacc.2017.10.104
   Pharm FEAB, 2015, HEALTHC INFORM RES, V21, P315, DOI 10.4258/hir.2015.21.4.315
   Prati A, 2019, J AMB INTEL SMART EN, V11, P5, DOI 10.3233/AIS-180510
   Profis, CNET
   Psaltopoulou T, 2017, HELL J CARDIOL, V58, P32, DOI 10.1016/j.hjc.2017.01.022
   Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rojas-Albarracín G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235065
   Sahoo SP, 2019, EXPERT SYST APPL, V115, P524, DOI 10.1016/j.eswa.2018.08.014
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Siegersma KR, 2019, NETH HEART J, V27, P403, DOI 10.1007/s12471-019-01311-1
   Smith Karen L, 2002, Emerg Med (Fremantle), V14, P255, DOI 10.1046/j.1442-2026.2002.00340.x
   Sokolova MV, 2013, J INTELL FUZZY SYST, V24, P215, DOI 10.3233/IFS-2012-0548
   Stern S, 2003, CIRCULATION, V108, pE99, DOI 10.1161/01.CIR.0000086898.96021.B9
   Stone EE, 2015, IEEE J BIOMED HEALTH, V19, P290, DOI 10.1109/JBHI.2014.2312180
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tang D, 2015, EXPERT SYST APPL, V42, P4540, DOI 10.1016/j.eswa.2015.01.016
   United Nations, 2019, POP PROSP
   Vaquero LM, 2014, ACM SIGCOMM COMP COM, V44, P27, DOI 10.1145/2677046.2677052
   Vijayakumar M., 2018, FOG COMPUTING BASED
   Vilela PH, 2020, LOOKING FOG COMPUTIN
   World Health Organization, 2019, WORLD HLTH STAT OV
   Xu YZ, 2017, J ADV TRANSPORT, DOI 10.1155/2017/2823617
   Yang QM, 2018, COMPUT ELECTRON AGR, V155, P453, DOI 10.1016/j.compag.2018.11.002
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Yu G, 2017, P ACM INTERACTIVE MO, V1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
NR 54
TC 9
Z9 9
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26939
EP 26967
DI 10.1007/s11042-021-10957-2
EA MAY 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000650124400001
DA 2024-07-18
ER

PT J
AU Yamni, M
   Daoui, A
   El Ogri, O
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF Yamni, M.
   Daoui, A.
   El Ogri, O.
   Karmouni, H.
   Sayyouri, M.
   Qjidaa, H.
TI Accurate 2D and 3D images classification using translation and scale
   invariants of Meixner moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meixner polynomials; Translation and scale invariants of Meixner
   moments; 2D and 3D invariant descriptors; Pattern recognition; Image
   classification
ID PATTERN-RECOGNITION; CHARLIER MOMENTS; FAST COMPUTATION; KRAWTCHOUK;
   RECONSTRUCTION
AB Discrete orthogonal moments such as Meixner moments are powerful tools for characterizing image shape features for applications in pattern recognition and image classification. However, in the pattern recognition theory, classification of 2D/3D shapes regardless of their position, size, and orientation represents an important problem. In this paper, a new fast and accurate method is presented to obtain Meixner moments that are invariant to translation and uniform/non-uniform scaling directly from Meixner polynomials. These new invariants of Meixner moments are computed more quickly and require no numerical approximation, unlike the classical invariants of Meixner moments which are computed from geometric moments. This method is extended to compute the three-dimensional of Meixner invariant moments to translation and scaling. The results of experimental studies using scaled uniformly/non-uniformly and translated binary and gray-scale images are discussed to further verify the validity of the new invariants of Meixner moments for classification tasks.
C1 [Yamni, M.; El Ogri, O.; Karmouni, H.; Qjidaa, H.] Sidi Mohamed Ben Abdellah Fez Univ, Dhar El Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
   [Daoui, A.; Sayyouri, M.] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Engn Syst & Applicat Lab, BP 72,My Abdallah Ave Km 5,Imouzzer Rd, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Yamni, M (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Dhar El Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
EM mohamed.yamni@usmba.ac.ma; achraf.daoui@usmba.ac.ma;
   omar.elogri@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020; Yamni, Mohamed/AAD-8740-2022; Ogri, Omar
   El/AFC-5868-2022; DAOUI, Achraf/AAE-7012-2022; Karmouni,
   Hicham/ACB-0232-2022
OI Sayyouri, Mhamed/0000-0002-1615-419X; Ogri, Omar El/0000-0003-4807-0641;
   DAOUI, Achraf/0000-0002-2326-9550; Karmouni, Hicham/0000-0001-9225-8380;
   Yamni, Mohamed/0000-0002-9436-8361
CR Abdulhussain SH, 2017, INT J IMAGE DATA FUS, V8, P293, DOI 10.1080/19479832.2017.1326405
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Bin TJ, 2008, IMAGE VISION COMPUT, V26, P563, DOI 10.1016/j.imavis.2007.07.003
   CAVE, SOFTW COIL 20 COL OB
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Comtet, 2012, ADV COMBINATORICS AR
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Doulamis A, 2015, ISPRS ANN PHOTO REM, P61, DOI 10.5194/isprsannals-II-5-W3-61-2015
   El Fadili H, 2003, EURASIP J APPL SIG P, V2003, P902, DOI 10.1155/S1110865703305062
   El Ogri O, 2020, MULTIMED TOOLS APPL, V79, P23261, DOI 10.1007/s11042-020-09084-1
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hmimid A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013026
   Hosny KM, 2007, APPL MATH COMPUT, V189, P1214, DOI 10.1016/j.amc.2006.12.025
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ioannidou A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3042064
   Jahid T, 2019, J MATH IMAGING VIS, V61, P534, DOI 10.1007/s10851-018-0860-7
   Jahid T, 2018, MULTIMED TOOLS APPL, V77, P19811, DOI 10.1007/s11042-017-5371-9
   Karmouni H, 2020, MULTIMED TOOLS APPL, V79, P29121, DOI 10.1007/s11042-020-09351-1
   Karmouni H, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P99
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kyriakaki G., 2014, Int. J. Herit. Digit. Era, V3, P431, DOI DOI 10.1260/2047-4970.3.2.431
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   LUO LM, 1994, IEEE T CIRC SYST VID, V4, P552, DOI 10.1109/76.340199
   Mademlis A, 2009, PATTERN RECOGN, V42, P2447, DOI 10.1016/j.patcog.2009.04.024
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nikiforov AF, 1991, CLASSICAL ORTHOGONAL, P18
   Papakostas GA, 2010, IMAGE VISION COMPUT, V28, P414, DOI 10.1016/j.imavis.2009.06.011
   Sayyouri M, 2015, I C COMP SYST APPLIC
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   Wang X, 2018, PATTERN RECOGN, V77, P458, DOI 10.1016/j.patcog.2017.10.012
   Yamni M, 2021, DIGIT SIGNAL PROCESS, V108, DOI 10.1016/j.dsp.2020.102878
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yamni M, 2019, PROCEDIA COMPUT SCI, V148, P418, DOI 10.1016/j.procs.2019.01.054
   Yang B, 2011, PATTERN RECOGN LETT, V32, P1283, DOI 10.1016/j.patrec.2011.03.012
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zarpalas D, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/23912
   Zhi RC, 2018, INFORM PROCESS LETT, V130, P30, DOI 10.1016/j.ipl.2017.09.010
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
NR 47
TC 12
Z9 12
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26683
EP 26712
DI 10.1007/s11042-020-10311-y
EA MAY 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648233300002
DA 2024-07-18
ER

PT J
AU Shahid, E
   Arain, QA
AF Shahid, Eman
   Arain, Qasim Ali
TI Indoor positioning: "an image-based crowdsource machine learning
   approach"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global positioning system; Indoor positioning system; Principal
   component analysis scale-invariant feature transform; Robust
   crowdsourcing-based indoor localization system radio frequency; Radio
   frequency identification; Received signal strength indication; Wireless
   local area networking; Wireless sensor network; Location-based services;
   Locality sensitive hashing learning vector quantization;
   Non-line-of-sight
AB Various technologies have been utilized today for recognizing client or user in the indoor areas. These technologies incorporate RSSI, Bluetooth Low Energy Beacons, Ultrasound waves, Vision-based advances, for example, fixed camera recordings QR codes, remote gadgets, etc. RSSI fingerprinting technique requires more effort and it is also expensive to be used for indoor localization frameworks working in real-time. In this research, indoor localization based on images is investigated as an option in contrast to other indoor positioning techniques using these days. Image-based indoor positioning is more affordable than RSSI based technologies being utilized. A mobile phone camera is utilized to take the pictures of area inside the building to find the user inside the building. Sensor data from various sensors isn't required or no extra framework is required to find the client in the building utilizing indoor positioning based on an image. Microsoft Azure Custom Vision Services are utilized to locate the client; MS Azure classifies the pictures in one of the labels made. Strategy's attainability is demonstrated by various investigations and accomplished accuracy and review is recorded above 90%. The average precision of the trained model is recorded above 95%.
C1 [Shahid, Eman; Arain, Qasim Ali] Mehran Univ Engn & Technol, Dept Software Engn, Jamshoro, Sindh, Pakistan.
C3 Mehran University Engineering & Technology
RP Arain, QA (corresponding author), Mehran Univ Engn & Technol, Dept Software Engn, Jamshoro, Sindh, Pakistan.
EM emanshahid4010@gmail.com; qasim.arain@faculty.muet.edu.pk
OI Arain, Qasim Ali/0000-0003-2095-7435
CR Aizawa, 2010, IMAGE BASED INDOOR P
   Al Nuaimi K., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P185, DOI 10.1109/INNOVATIONS.2011.5893813
   Bano G, 2019, INT CONF INF COMMUN, P129, DOI [10.1109/ICICT47744.2019.9001991, 10.1109/icict47744.2019.9001991]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Caso G, 2019, INTELL DAT CENT SYST, P129, DOI 10.1016/B978-0-12-813189-3.00007-1
   Deak G, 2012, COMPUT COMMUN, V35, P1939, DOI 10.1016/j.comcom.2012.06.004
   Farah I, 2019, ICEIT 2019
   Feng, 2015, IMAGE BASED LOCALIZA
   Goldoni Emanuele, 2010, 2010 European Wireless Conference (EW), P71, DOI 10.1109/EW.2010.5483396
   2015, RSSI CONSTRUCT RADIO
   Insoft, 2019, INDOOR POSITIONING S
   Jung SH, 2018, IEEE T SYST MAN CY-S, V48, P906, DOI 10.1109/TSMC.2016.2626797
   Kamangar ZU, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND INFORMATION ENGINEERING (ICSIE 2019), P15, DOI 10.1145/3328833.3328838
   Khowaja, 2020, INT J COMPUTER IJC, V36, P34
   Koyuncu H, 2010, INT J COMPUT SCI NET, V10, P121
   Lategahn H., 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P1, DOI 10.1109/ICVES.2012.6294279
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492
   Li N, 2011, ADV ENG INFORM, V25, P535, DOI 10.1016/j.aei.2011.02.004
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Malavalli, 2017, INDOOR LOCALIZATIONS
   Manley, 2015, MACHINE LEARNING IND
   Peng YT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103419
   Sana, 2013, IOSR J ELECT ELECT E, V6, P69, DOI [10.9790/1676-0636976, DOI 10.9790/1676-0636976]
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Sinha D, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P63, DOI 10.1109/CRV.2014.17
   Taj S, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND INFORMATION ENGINEERING (ICSIE 2019), P42, DOI 10.1145/3328833.3328837
   Tu W, 2017, ROBUST CROWDSOURCING
   Werner M., 2011, 2011 International Conference on Indoor Positioning and Indoor Navigation, P1
   Wu CS, 2015, IEEE T MOBILE COMPUT, V14, P444, DOI 10.1109/TMC.2014.2320254
   Zheng X, 2012, IEEE VTS VEH TECHNOL
NR 30
TC 6
Z9 6
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26213
EP 26235
DI 10.1007/s11042-021-10906-z
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645497000003
DA 2024-07-18
ER

PT J
AU Bouteghrine, B
   Tanougast, C
   Sadoudi, S
AF Bouteghrine, Belqassim
   Tanougast, Camel
   Sadoudi, Said
TI Novel image encryption algorithm based on new 3-d chaos map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image encryption; Correlation; Entropy; Key space; Security
   analysis
AB Several proposals of chaos-based algorithms have been proposed for secure communication and image encryption. In this paper, a new algorithm for colour image encryption has been proposed. The algorithm is based on a new 3-dimensional (3-D) discrete time chaos system which performs the diffusion and confusion processes. The novelty of the proposed work is the new 3-D map defined by five nonlinear terms and three control parameters to ensure better chaotic properties. Moreover, the proposed new map is used to perform 3-stage encryption algorithm which achieves better performance while preserving the traditional confusion-diffusion structure. Security analysis of the proposed algorithm is investigated and compared to some existing methods in terms of key space, metric entropy and correlation. Simulated results of our encryption algorithm prove its performance and suitability for colour image encryption.
C1 [Bouteghrine, Belqassim; Tanougast, Camel] Univ Lorraine, Lcoms, F-57070 Metz, France.
   [Sadoudi, Said] Ecole Mil Polytech, Algiers 16000, Algeria.
C3 Universite de Lorraine; Ecole Military Polytechnic
RP Bouteghrine, B (corresponding author), Univ Lorraine, Lcoms, F-57070 Metz, France.
EM belqassim.bouteghrine@univ-lorraine.fr; camel.tanougast@univ-lorraine.fr
RI Tanougast, Camel/V-7936-2018
OI Tanougast, Camel/0000-0002-5399-1683; Bouteghrine,
   Belqassim/0000-0003-0875-9583
CR Al Shehhi H, 2014, ANN CONF PRIV SECUR, P172, DOI 10.1109/PST.2014.6890937
   AlShaikh M, 2017, MULTIMED TOOLS APPL, V76, P8937, DOI 10.1007/s11042-016-3499-7
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Anandkumar R., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P204, DOI 10.1109/I-SMAC.2018.8653652
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Elert G., 1999, HE CHAOS HYPERTEXTBO
   Elhadj Z, 2008, FRONT PHYS CHINA, V3, P195, DOI 10.1007/s11467-008-0017-z
   Fan J, 2008, NONLINEAR TIME SERIE
   Farajallah M, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500218
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Hua ZY, 2014, IEEE SYS MAN CYBERN, P3229, DOI 10.1109/SMC.2014.6974425
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiang Y, 2016, I COMP CONF WAVELET, P66, DOI 10.1109/ICCWAMTIP.2016.8079806
   Jiansheng Guo, 2010, 2010 Proceedings of the Third International Symposium on Information Processing (ISIP 2010), P169, DOI 10.1109/ISIP.2010.65
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kumar A, 2013, INT J COMPUT SCI ENG, V3, P11
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Mousa A, 2013, JAP EGY CONF ELECTR, P154, DOI 10.1109/JEC-ECC.2013.6766404
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Prusty Agyan Kumar, 2013, 2013 International Conference on Advanced Computing and Communication Systems (ICACCS), P1, DOI 10.1109/ICACCS.2013.6938729
   Savi MA, 2007, PHYS LETT A, V364, P389, DOI 10.1016/j.physleta.2006.11.095
   Sekertekin Y, 2016, 2016 24TH TELECOMMUNICATIONS FORUM (TELFOR), P667
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sinha RK, 2018, 2018 INT C CURRENT T, P1
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Yuan LG, 2019, NONLINEAR DYNAM, V96, P615, DOI 10.1007/s11071-019-04810-3
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zheng JR, 2018, ADV MATER SCI ENG, V2018, DOI 10.1155/2018/7278014
   Zhu CY, 2019, MICROSC MICROANAL, V25, P912, DOI 10.1017/S1431927619000710
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 42
TC 21
Z9 23
U1 6
U2 97
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25583
EP 25605
DI 10.1007/s11042-021-10773-8
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642049400001
DA 2024-07-18
ER

PT J
AU Ye, ZF
   Khan, R
   Naqvi, N
   Islam, MS
AF Ye, Zhongfu
   Khan, Rashid
   Naqvi, Nuzhat
   Islam, M. Shujah
TI A novel automatic image caption generation using bidirectional
   long-short term memory framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; inception v3; B-LSTM; P-MFO optimization; Bleu score
ID SEMANTIC ATTENTION; ALGORITHM
AB Image Captioning, the process of generating a textual description of an image, has emerged as a hot research due to its practical importance in many domains. It is a challenging task as it uses both Natural Language Processing and Computer Vision related fields to generate the captions. Despite the fact that the literature has reported notable image captioning methodologies, they still lag in accomplishing the substantial performance level for diverse datasets. This paper proposes an image caption generating mechanism based on Optimized Bidirectional Long Short-Term Memory (B-LSTM) model. We propose a variant of Moth Flame Optimization (PMFO), termed here as Proposed Moth Flame Optimization (PMFO), which has logarithmic spiral update based on correlation. The performance of the proposed model is demonstrated on benchmark datasets like Flicker 8 k, Flicker30k, VizWik and COCO datasets using renowned metrics such as CIDEr, BLEU, SPICE and ROUGH. The performance analysis proves that the B-LSTM achieves better performance on caption generation than state-of-the-art methods.
C1 [Ye, Zhongfu; Khan, Rashid; Naqvi, Nuzhat; Islam, M. Shujah] Univ Sci & Technol China, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ye, ZF (corresponding author), Univ Sci & Technol China, Hefei, Anhui, Peoples R China.
EM yezf@ustc.edu.cn
RI khan, Rashid/HSF-9463-2023; KHAN, RASHID MUMTAZ/HHZ-3812-2022
OI khan, Rashid/0000-0002-2410-044X; KHAN, RASHID
   MUMTAZ/0000-0001-6097-098X; Sameem, M Shujah Islam/0000-0003-3768-6045
FU Fundamental Research Funds for the Central Universities [WK2350000002]
FX This research is supported by the Fundamental Research Funds for the
   Central Universities (Grant no. WK2350000002).
CR Amritkar C, 2018, IMAGE CAPTION GENERA
   Anuranji R, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102729
   Chandanapalli S.B., 2019, Journal of Networking and Communication Systems, V2, P40, DOI DOI 10.46253/JNACS.V2I3.A5
   Chen XH, 2020, PATTERN RECOGN LETT, V132, P132, DOI 10.1016/j.patrec.2018.12.018
   Christie G, 2017, COMPUT VIS IMAGE UND, V163, P101, DOI 10.1016/j.cviu.2017.09.001
   Duijts, 2017, GENERATION R STUDY
   Fan C, 2018, J VIS COMMUN IMAGE R, V55, P40, DOI 10.1016/j.jvcir.2018.05.008
   Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118
   Guan JN, 2018, SIGNAL PROCESS-IMAGE, V63, P141, DOI 10.1016/j.image.2018.02.005
   He XW, 2019, NEUROCOMPUTING, V328, P48, DOI 10.1016/j.neucom.2018.02.106
   He XW, 2019, PATTERN RECOGN LETT, V119, P229, DOI 10.1016/j.patrec.2017.10.018
   Huang GS, 2019, NEURAL PROCESS LETT, V49, P683, DOI 10.1007/s11063-018-9836-2
   Jamieson M, 2012, COMPUT VIS IMAGE UND, V116, P842, DOI 10.1016/j.cviu.2012.03.002
   Ji QG, 2019, ALGORITHMS, V12, DOI 10.3390/a12030051
   Kahn CE, 2009, J AM MED INFORM ASSN, V16, P380, DOI 10.1197/jamia.M2945
   Karpathy A, 2014, ADV NEUR IN, V27
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Liu MF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102178
   Liu Q, 2018, COMPUT IND, V97, P47, DOI 10.1016/j.compind.2018.01.015
   Lokesh Kumar R., 2019, J COMPUT MECH POWER, V2, P1, DOI [10.46253/jcmps.v2i3.a1, DOI 10.46253/JCMPS.V2I3.A1]
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Manti S, 2019, ACTA PAEDIATR, V108, P740, DOI 10.1111/apa.14574
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Nabati M, 2020, COMPUT VIS IMAGE UND, V190, DOI 10.1016/j.cviu.2019.102840
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar BR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P606
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Shetty R, 2018, IEEE MULTIMEDIA, V25, P34, DOI 10.1109/MMUL.2018.112135923
   Spoletini P, 2014, OPERATIONAL SEMANTIC
   Swamy S. M., 2013, IET CHENN 4 INT C SU, DOI [DOI 10.1049/IC.2013.0361, 10.1049/ic.2013.0361]
   Tan YH, 2019, NEUROCOMPUTING, V333, P86, DOI 10.1016/j.neucom.2018.12.026
   Wu CL, 2018, SIGNAL PROCESS-IMAGE, V67, P100, DOI 10.1016/j.image.2018.06.002
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu N, 2019, J VIS COMMUN IMAGE R, V58, P477, DOI 10.1016/j.jvcir.2018.12.027
   Yuan AH, 2019, NEUROCOMPUTING, V330, P17, DOI 10.1016/j.neucom.2018.10.059
   Zhao DX, 2019, NEUROCOMPUTING, V329, P476, DOI 10.1016/j.neucom.2018.11.004
   Zheng H, 2019, IET COMPUT VIS, V13, P294, DOI 10.1049/iet-cvi.2018.5005
   Zhou XL, 2020, NEUROCOMPUTING, V390, P217, DOI 10.1016/j.neucom.2019.04.099
   Zhu XX, 2018, NEUROCOMPUTING, V319, P55, DOI 10.1016/j.neucom.2018.08.069
NR 40
TC 7
Z9 8
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25557
EP 25582
DI 10.1007/s11042-021-10632-6
EA APR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000641192300001
DA 2024-07-18
ER

PT J
AU Xiang, HY
   Liu, LF
AF Xiang, Hongyue
   Liu, Lingfeng
TI A novel image encryption algorithm based on improved key selection and
   digital chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic dynamical degradation; Image encryption; Image seed; Feedback
ID SYSTEM
AB Chaotic systems are widely used in various fields, but under the finite precision device, chaotic systems would fall into a cycle and subsequently the performance degrade. Thus, the suppression method of the dynamic degradation of digital chaos is receiving increasing attention. This paper proposes a new improvement model to suppress the dynamical degradation under finite computing accuracy equipment. By using the difference between two maps of the same type but with different initial values, and the state feedback function to improve the performance of the digital chaotic map and extend the time before the chaotic map enters the cycle. Take the 1D Logistic map and x-dimensional of Baker map as examples to prove the effectiveness of the improvement model. Then we proposed a new key selection method, in what part of information of the image would be selected by using a chaotic map to generate a special value. The special value would be used as part of the key. Based this method, a new image encryption algorithm was proposed. The information entropy of the image encrypted by our encryption algorithm is 7.9972, the NPCR and UACI are 0.996095 and 0.334635, respectively, what both are very close to ideal values. The experimental simulation results show that the image encryption scheme exhibits good performances and high security and effectively resists various attacks.
C1 [Xiang, Hongyue; Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU National Natural Science Foundation of China [61862042]; Innovation
   Special Fund Designated for Graduate Students of Jiangxi Province
   [YC2019-S101]
FX This work is supported by the National Natural Science Foundation of
   China (61862042); Innovation Special Fund Designated for Graduate
   Students of Jiangxi Province (YC2019-S101).
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Anand A, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P159, DOI 10.1109/ICICCS.2016.7542294
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Ben ZH, 2016, I COMP CONF WAVELET, P28, DOI 10.1109/ICCWAMTIP.2016.8079799
   Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Flores-Vergara A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030268
   Fuh CC, 2011, J VIB CONTROL, V17, P215, DOI 10.1177/1077546309350898
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Jiang N, 2019, INT J THEOR PHYS, V58, P979, DOI 10.1007/s10773-018-3989-7
   Khlebodarova TM, 2017, J BIOINF COMPUT BIOL, V15, DOI 10.1142/S0219720016500426
   Kohli, 2013, COMPUTER SCI
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu BC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4926937
   Liu LF, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500591
   Liu LF, 2018, IET SIGNAL PROCESS, V12, P22, DOI 10.1049/iet-spr.2016.0584
   Liu LF, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501036
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu YQ, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741750033X
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Patro KAK, 2019, MICROSYST TECHNOL, V25, P2331, DOI 10.1007/s00542-018-4121-x
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Souyah A, 2016, NONLINEAR DYNAM, V84, P715, DOI 10.1007/s11071-015-2521-3
   Tong XJ, 2014, NONLINEAR DYNAM, V78, P2277, DOI 10.1007/s11071-014-1564-1
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   XIAOJUN T, 2015, NONLINEAR DYNAM, V80, P1493, DOI DOI 10.1007/s11071-015-1957-9
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
NR 40
TC 12
Z9 13
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22135
EP 22162
DI 10.1007/s11042-021-10807-1
EA MAR 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631328600001
DA 2024-07-18
ER

PT J
AU Sarkar, A
   Singh, BK
AF Sarkar, Arpita
   Singh, Binod K.
TI Design of a hybrid approach using a revocable technique and
   steganographic text color coding technique for fingerprint template
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Cryptography; Fingerprint; Biometric template; Biometric
   template protection techniques; Revocability; Diversity
AB The most crucial matter to be taken care of while deploying biometric systems is the security of the biometric template. Several algorithms that do not store the original template have been formulated in recent years to protect biometric templates from various attacks. Most of the existing algorithms offer a trade-off between matching performance and biometric template security. Moreover, it is believed that no single template protection scheme is capable of satisfying security, diversity, revocability and performance at the same time. Present research work proposes a two-step hybrid template protection scheme, where first step is the creation of a transformed template from the original template, and the second step is conceal the value of transformed template by applying the text steganography.The effectiveness of the proposed method is well established by thorough experimental analysis, which illustrates that the recognition performance is well maintained as the original template executes.
C1 [Sarkar, Arpita; Singh, Binod K.] NIT Jamshedpur, Dept CSE, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Sarkar, A (corresponding author), NIT Jamshedpur, Dept CSE, Jamshedpur, Jharkhand, India.
EM 24arpitasarkar@gmail.com; bksingh.cse@nitjsr.ac.in
RI Singh, Binod/AAB-8663-2019; Sarkar, Arpita/JFL-1710-2023
OI Singh, Binod/0000-0002-2697-8918; 
CR Abdul W, 2020, COMPUT J, V63, P479, DOI 10.1093/comjnl/bxz047
   Abikoye OC, 2020, MULTIMED TOOLS APPL, V79, P23483, DOI 10.1007/s11042-020-08971-x
   Abou, 2020, MULTIMED TOOLS APPL
   Amritha G, 2013, INT J COMPUT TRENDS, V4
   [Anonymous], SCI WORLD J
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383110
   [Anonymous], 1883, J SCI MILITAIRES
   Boult T, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P560
   Bringer J, 2008, SCI COMPUT PROGRAM, V74, P43, DOI 10.1016/j.scico.2008.09.016
   Chedded A, 2009, STEGANOFLAGE NEW IMA
   Chin YJ, 2014, INFORM FUSION, V18, P161, DOI 10.1016/j.inffus.2013.09.001
   DreSSler Kevin, 2017, Semantic Web - Interoperability, Usability, Applicability, V8, P185, DOI 10.3233/SW-150209
   Ezhilarasan, 2018, INT J ENG TECHNOL, V7, P2609, DOI [10.14419/ijet.v7i4.11485, DOI 10.14419/IJET.V7I4.11485]
   Feng YC, 2008, PROC SPIE, V6944, DOI 10.1117/12.778652
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Ghany KKA, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P941, DOI 10.1109/ASONAM.2012.167
   Guo ZH, 2010, IEEE IMAGE PROC, P4521, DOI 10.1109/ICIP.2010.5653119
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Hua-Hong Zhu, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P560, DOI 10.1109/ICMLC.2012.6358984
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Kant C, 2020, PROCEDIA COMPUT SCI, V167, P932, DOI 10.1016/j.procs.2020.03.392
   Karthi Govindharaju, 2016, SECURING BIOMETRIC T
   Kingslin S., 2015, INDIAN J SCI TECHNOL, V8, P1
   Lavanya N, 2012, NT J COMPUT SCI INFO, V3
   Legay A, 2018, NOVEL TEXT STEGANOGR, V10694, P217, DOI [10.1007/978-3-319-76687-4_15, DOI 10.1007/978-3-319-76687-4_15]
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Malkhasyan N, 2013, INT J BINFORMATION T, V20
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Monwar MM, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P84
   Nafea O, 2016, COMPUT J, V59, P1392, DOI 10.1093/comjnl/bxv107
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nguyen TAT, 2019, ADV INTELLIGENT SYST, V935
   Ntalianis Klimis, 2011, EURASIP J INFORM SEC, V2011, P12
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ouda O, 2011, IEICE T INF SYST, VE94D, P1768, DOI 10.1587/transinf.E94.D.1768
   Patel HM, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1087, DOI 10.1109/WiSPNET.2016.7566304
   Poonguzhali N, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATICS AND ANALYTICS (ICIA' 16), DOI 10.1145/2980258.2980355
   Rakheja P, 2020, J MOD OPTIC, V67, P592, DOI 10.1080/09500340.2020.1760384
   Ramakrishnan BK, 2016, SECUR COMMUN NETW, V9, P6066, DOI 10.1002/sec.1757
   Rathgeb C, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0049-9
   Shiu HJ, 2018, LECT NOTES COMPUT SC, V10694, P217, DOI 10.1007/978-3-319-76687-4_15
   Siswanto A., 2020, INT J COMMUNICATION, V12, P1
   Tabassum M., 2020, LECT NOTES I COMPUTE, V325, DOI [10.1007/978-3-030-52856-0_9, DOI 10.1007/978-3]
   Wang Na, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P2233, DOI 10.1109/ICIEA.2010.5515145
   Wong WJ, 2014, P INT C EL INF COMM, P1
   Yuan L, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1545, DOI 10.1109/CSE.2014.286
   Zakaria Y, 2019, MULTIMED TOOLS APPL, V78, P32333, DOI 10.1007/s11042-019-07824-6
   Zhao DD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4519548
NR 51
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20641
EP 20670
DI 10.1007/s11042-021-10690-w
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000626425600005
DA 2024-07-18
ER

PT J
AU Mosleh, M
   Setayeshi, S
   Barekatain, B
   Mosleh, M
AF Mosleh, Mahdi
   Setayeshi, Saeed
   Barekatain, Behrang
   Mosleh, Mohammad
TI A novel audio watermarking scheme based on fuzzy inference system in DCT
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copyright protection; Audio watermarking; High capacity; Fuzzy inference
   system; Singular value decomposition
AB Digital watermarking technology provides an effective potential solution to copyright protection and authentication of digital media. In this article, a new design of audio watermarking is introduced which is able to make compromise between transparency, robustness, and capacity by means of the synergy between fuzzy inference system, Singular Value Decomposition (SVD), and Fibonacci's sequence in Discrete Cosine Transform (DCT). In the embedding phase, the proposed method, first of all, finds proper segments for inserting watermark data by helping fuzzy inference system with energy, zero-crossing rate (ZCR), and music edge features. Then, the watermark bits are embedded in the suitable segments based on collaboration of SVD technique and Fibonacci sequence in DCT domain. The proposed watermark extraction is performed in blind manner. The results on five Blues, Electronic, Classic, Jazz and Rock audio files show that the proposed method has high transparency (in average SNR = 49.80 dB) with payload of 598.34 bps. Moreover, robustness tests against Stirmark attacks show that the average of error rate is 1.3644, which means the proposed scheme has high stability in the digital signal processing attacks.
C1 [Mosleh, Mahdi; Setayeshi, Saeed; Barekatain, Behrang; Mosleh, Mohammad] Islamic Azad Univ, NajafAbad Branch, Fac Comp Engn, Najafabad, Iran.
   [Setayeshi, Saeed] Amirkabir Univ Technol, Fac Energy Engn & Phys, Tehran, Iran.
   [Barekatain, Behrang] Islamic Azad Univ, NajafAbad Branch, Big Data Res Ctr, Najafabad, Iran.
   [Mosleh, Mohammad] Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
C3 Islamic Azad University; Amirkabir University of Technology; Islamic
   Azad University; Islamic Azad University
RP Setayeshi, S (corresponding author), Islamic Azad Univ, NajafAbad Branch, Fac Comp Engn, Najafabad, Iran.; Setayeshi, S (corresponding author), Amirkabir Univ Technol, Fac Energy Engn & Phys, Tehran, Iran.
EM Setayesh@aut.ac.ir
RI mosleh/AAN-7415-2021; Setayeshi, Saeed/JPY-2228-2023; Barekatain,
   Behrang/J-2799-2013
OI Setayeshi, Saeed/0000-0002-1415-222X; Barekatain,
   Behrang/0000-0001-5344-6282; mosleh, mahdi/0000-0003-0419-1142
CR Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   [Anonymous], 2007, Audio Signal Processing and Coding
   Arnold M, 2014, IEEE T INF FOREN SEC, V9, P411, DOI 10.1109/TIFS.2013.2293952
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Chen ST, 2015, IET SIGNAL PROCESS, V9, P166, DOI 10.1049/iet-spr.2013.0399
   Cox I., 2007, DIGITAL WATERMARKING, P142
   Dhar PK, 2014, INT J SPEECH TECHNOL, V17, P133, DOI 10.1007/s10772-013-9214-4
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Faragallah OS, 2018, WIRELESS PERS COMMUN, V98, P2009, DOI 10.1007/s11277-017-4960-2
   Hosseinpour, 2013, INT J TECHNICAL PHYS, V5, P18
   Hu HT, 2017, CIRC SYST SIGNAL PR, V36, P1890, DOI 10.1007/s00034-016-0383-7
   Hu HT, 2017, CLUSTER COMPUT, V20, P805, DOI 10.1007/s10586-017-0770-2
   Hu HT, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P748, DOI 10.1109/IIH-MSP.2014.191
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu HT, 2014, SIGNAL PROCESS, V105, P316, DOI 10.1016/j.sigpro.2014.05.003
   Hu P, 2016, ELECTRON LETT, V52, P5, DOI 10.1049/el.2015.1508
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Jeyhoon M, 2017, MULTIMED TOOLS APPL, V76, P3343, DOI 10.1007/s11042-016-3934-9
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Jindal H, 2018, WIREL NETW, V24, P3241, DOI 10.1007/s11276-017-1532-z
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   Jindal H, 2017, AD HOC SENS WIREL NE, V39, P1
   Jindal H, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P251, DOI 10.1109/PDGC.2014.7030751
   Kansal V., 2013, Scientific Engineering Research, V4, P2580
   Karajeh H, 2018, MULTIMED TOOLS APPL
   Karajeh H, 2019, ANALOG INTEGR CIRC S, V99, P571, DOI 10.1007/s10470-018-1332-0
   Kaur A, 2018, MULTIMEDIA SYST, V24, P341, DOI 10.1007/s00530-017-0545-x
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kim C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155336
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Koshy, 2017, FIBONACCI LUCAS NUMB, DOI [10.1002/9781118742327, DOI 10.1002/9781118742327]
   Kumsawat P., 2010, 2010 10th International Symposium on Communications and Information Technologies (ISCIT 2010), P481, DOI 10.1109/ISCIT.2010.5664889
   Lei BY, 2015, SIGNAL PROCESS, V113, P80, DOI 10.1016/j.sigpro.2014.11.007
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lerch A., 2002, 3ALPHA
   Li RK, 2016, IET SIGNAL PROCESS, V10, P266, DOI 10.1049/iet-spr.2014.0388
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Mohsenfar SM, 2015, MULTIMED TOOLS APPL, V74, P759, DOI 10.1007/s11042-013-1694-3
   Mosleh M, 2016, FRONT INFORM TECH EL, V17, P1320, DOI 10.1631/FITEE.1500297
   Mourya G, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P187, DOI 10.1109/NGCT.2015.7375109
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Pourhashemi SM, 2021, NEURAL COMPUT APPL, V33, P6161, DOI 10.1007/s00521-020-05389-2
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
   Yuan XC, 2015, INFORM SCIENCES, V298, P159, DOI 10.1016/j.ins.2014.11.040
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
NR 56
TC 11
Z9 12
U1 5
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20423
EP 20447
DI 10.1007/s11042-021-10686-6
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700007
DA 2024-07-18
ER

PT J
AU Nandhini, S
   Ashokkumar, K
AF Nandhini, S.
   Ashokkumar, K.
TI Improved crossover based monarch butterfly optimization for tomato leaf
   disease classification using convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep learning; Tomato leaf disease
   classification; Crossover based monarch butterfly optimization;
   Parameter optimization
ID IDENTIFICATION; SEVERITY
AB To identify a plant disease accurately one should have a lot of experience and in-depth knowledge in a particular field. Identifying the plant diseases using manual intervention is often erroneous, time-consuming, and not a cost-effective option. Shallow Machine learning architectures were widely deployed for the automatic identification of the tomato leaf diseases, but their feature extraction process is highly time-consuming. Nowadays, the power of Deep Learning is been exploited by various researchers to identify the diseases present in plants. This paper utilizes a CNN approach to classify four different types of leaf diseases(bacterial spot, septoria leaf spot, late blight, and tomato mosaic virus) in a tomato plant without using any manual intervention. A dataset comprising of 6208 images of four classes of leaf diseases was acquired from the Plant Village database for classification. CNN is considered an effective option for solving a wide range of image processing tasks but its architecture is a little bit complex. To minimize this complexity and optimize the parameters present in the CNN, a binary solution encoding scheme is proposed using an Improved Crossover based Monarch Butterfly Optimization (ICRMBO) algorithm. This solution encoding technique implemented here eliminates the need for manual effort for designing the CNN architecture. Two convolutional architectures namely Vgg16 and Inception V3 were used in this work and they were optimized using the ICRMBO algorithm. The Inception V3 and Vgg16 architectures are widely deployed in this work to ease the training process, improve the generalization ability of the CNN network, and increase the classification accuracy. The overall test accuracies obtained for both the Vgg16 and Inception V3 was 99.98% and 99.94% when optimized with the ICRMBO algorithm. The proposed method augmented the performance in terms of high precision, sensitivity, and specificity values and obtained an overall classification accuracy of 99%. The significance and effectiveness of the proposed method over other methods are identified through the comparative analysis conducted.
C1 [Nandhini, S.; Ashokkumar, K.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Nandhini, S (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM snandhini.id@gmail.com
RI Nandhini, S/AAU-8111-2021; SN, Nandhini/AAU-8550-2021; S,
   Nandhini/HNR-3036-2023
OI Nandhini, S/0000-0002-8849-5284; SN, Nandhini/0000-0002-8849-5284; S,
   Nandhini/0000-0002-8849-5284
CR Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Ashourloo D, 2016, IEEE J-STARS, V9, P4344, DOI 10.1109/JSTARS.2016.2575360
   Ballester P, 2016, AAAI CONF ARTIF INTE, P1124
   Chouhan SS, 2020, ARCH COMPUT METHOD E, V27, P611, DOI [10.1007/s11831-019-09324-0, 10.33552/abeb.2018.01.000510]
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   da Costa AZ, 2020, BIOSYST ENG, V190, P131, DOI 10.1016/j.biosystemseng.2019.12.003
   Darwish A, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100616
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hughes D., 2015, ABS151108060 CORR
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Kavitha D, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4132
   Leibetseder A, 2017, LECT NOTES COMPUT SC, V10550, P70, DOI 10.1007/978-3-319-67543-5_7
   Li GD, 2020, REMOTE SENS LETT, V11, P195, DOI 10.1080/2150704X.2019.1697001
   Li M, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE & EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P711, DOI 10.1109/ITIME.2009.5236329
   Liang QK, 2019, COMPUT ELECTRON AGR, V157, P518, DOI 10.1016/j.compag.2019.01.034
   Marston S, 2011, DECIS SUPPORT SYST, V51, P176, DOI 10.1016/j.dss.2010.12.006
   Nagaraju M, 2020, INT J SYST ASSUR ENG, V11, P547, DOI 10.1007/s13198-020-00972-1
   Nazki H, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105117
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Rangarajan AK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59108-x
   Ravikumar S, 2021, J AMB INTEL HUM COMP, V12, P7475, DOI 10.1007/s12652-020-02424-x
   RAVIKUMAR S, 2021, J AMB INTEL HUM COMP
   Ravikumar S, 2016, ASIAN J INF TECHNOL, V15, P1799, DOI DOI 10.36478/AJIT.2016.1799.1815
   Rejeesh MR, 2020, MULTIMED TOOLS APPL, V79, P28411, DOI 10.1007/s11042-020-09234-5
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Rubanga DP, 2020, ARXIV PREPRINT ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Sundararaj V, 2020, PROG PHOTOVOLTAICS, V28, P1128, DOI 10.1002/pip.3315
   Sundararaj V, 2019, INT J BIOMED ENG TEC, V31, P325, DOI 10.1504/IJBET.2019.103242
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Tanzi L, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2136
   Tanzi L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041507
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Verma S, 2020, J DISCRET MATH SCI C, V23, P273, DOI 10.1080/09720529.2020.1721890
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Yu F, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.1860
   Zhang Y, 2020, IEEE ACCESS, V8, P56607, DOI 10.1109/ACCESS.2020.2982456
NR 42
TC 33
Z9 34
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18583
EP 18610
DI 10.1007/s11042-021-10599-4
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300004
DA 2024-07-18
ER

PT J
AU Mahalingam, T
AF Mahalingam, T.
TI A hybridization of SKH and RKFCM clustering optimization algorithm for
   efficient moving object exploration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Refined kernel fuzzy c means (RKFCM); Krill herd; Stud krill herd;
   Decision tree; Genetic algorithm
ID TRACKING; HYBRID
AB Object detection is a really crucial application of image processing. It is of essential value for object active surveillance and various other applications. Hence, the object detection has been extensively investigated. Refined Kernel fuzzy c-means system still carries a couple of downsides, for instance, to reduce the convergence level, obtaining stuck in the regional area minima and problem to initiation level of sensitiveness. To conquer the over problems, the following suggested strategy for stud krill herd Clustering Optimization Algorithm. This paper stands for an optimizing approach to global optimizing utilizing a unique variation of KH (Krill Herd). This approach is termed as Stud Krill Herd (SKH).The stud krill herd Clustering Optimization procedure utilizes to find the optimal centroid. At first, the background and foreground area partition is finished by hybridization of refined kernel fuzzy c means algorithm (RKFCM) with stud krill herd Clustering Optimization procedure. The suggested new strategy is scholarly and furthermore dynamic clustering system for dividing the moving object. This research study performs recommended a reliable object detection making use of hybridization of stud krill herd Clustering optimizing and RKFCM. Moving object tracing is done via the blob detection which happens under the tracing phase. The assessment phase has characteristic abstraction and categorization. High and appearance-based and quality based attributes are mined from fine-tuned frames whichever attended to classification. Considering that categorization we are developing usage of J48 (C4.5) i.e., decision tree based classification. The effectiveness of the advised method is analyzed through prior approaches k-NN and MLP in regard to accuracy, f-measure, ROC and recall.
C1 [Mahalingam, T.] Sathyabama Univ, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Mahalingam, T (corresponding author), Sathyabama Univ, Chennai, Tamil Nadu, India.
EM lingamrajthen@gmail.com
RI thangaraj, mahalingam/AAG-3346-2021
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Adewusi EA, 2012, J INFORMAT ENG APPL, V2
   Alavi, 2013, META HEURISTIC APPL
   Alavi, 2013, META HEURISTICS WATE
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Allin, 2010, ICTACT J IMAGE VIDEO, V1, DOI [10.21917/ijivp.2010.0007, DOI 10.21917/IJIVP.2010.0007]
   [Anonymous], 2000, Evolutionary computation
   Arvanitidou MG, 2013, SIGNAL PROCESS-IMAGE, V28, P1420, DOI 10.1016/j.image.2013.09.008
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Bouguessa M, 2006, PATTERN RECOGN LETT, V27, P1419, DOI 10.1016/j.patrec.2006.01.015
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   [崔东文 Cui Dongwen], 2017, [水利水电科技进展, Advances in Science and Technology of Water Resources], V37, P72
   Duan H, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/712752
   Faieghi MR, 2012, COMMUN NONLINEAR SCI, V17, P1021, DOI 10.1016/j.cnsns.2011.03.043
   Farnad B, 2018, APPL MATH MODEL, V55, P652, DOI 10.1016/j.apm.2017.10.001
   Fei MJ, 2015, NEUROCOMPUTING, V152, P413, DOI 10.1016/j.neucom.2014.09.060
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Gandomi AH, 2011, INFORM SCIENCES, V181, P5227, DOI 10.1016/j.ins.2011.07.026
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Goldberg DE., 1998, OPTIMIZATION MACHINE
   He H, 2012, NEUROCOMPUTING, V81, P49, DOI 10.1016/j.neucom.2011.11.001
   Hong X, 2012, NEUROCOMPUTING, V82, P216, DOI 10.1016/j.neucom.2011.11.016
   Horng, 2009, P INT MULT ENG COMP, V1, P978, DOI [10.1016/j.eswa.2009.12.050, DOI 10.1016/J.ESWA.2009.12.050]
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Hou L, 2015, INT CONF ACOUST SPEE, P2249, DOI 10.1109/ICASSP.2015.7178371
   Hsieh TJ, 2012, NEUROCOMPUTING, V82, P196, DOI 10.1016/j.neucom.2011.11.020
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Jadhav AN, 2016, J TEKNOL, V78, P65
   Javed S., 2017, P S APPL COMP APR, P89
   Jiang YZ, 2017, APPL SOFT COMPUT, V52, P1181, DOI 10.1016/j.asoc.2016.09.008
   Khatib W, 1998, LECT NOTES COMPUT SC, V1498, P683, DOI 10.1007/BFb0056910
   Kim SW, 2013, MACH VISION APPL, V24, P1015, DOI 10.1007/s00138-012-0448-y
   Lai CC., 2004, INT J HYBRID INTELL, V1, P143
   Le Capitaine H, 2011, ADV INTEL SYS RES, P1074
   Li X, 2003, P SOC PHOTO-OPT INS, V5032, P995, DOI 10.1117/12.481375
   Li YL, 2009, LECT NOTES COMPUT SC, V5552, P135
   Lu HC, 2012, NEUROCOMPUTING, V89, P178, DOI 10.1016/j.neucom.2012.02.017
   Mahalingam T, 2019, MULTIMED TOOLS APPL, V78, P26633, DOI 10.1007/s11042-019-07768-x
   Maulik U, 2010, COMPUT OPER RES, V37, P1369, DOI 10.1016/j.cor.2009.02.025
   Minematsu T., 2015, FRONT COMP VIS FCV 2, DOI [10.1109/FCV.2015.7103752, DOI 10.1109/FCV.2015.7103752]
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Muangkote N, 2017, EXPERT SYST APPL, V90, P272, DOI 10.1016/j.eswa.2017.08.029
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sharma S, 2018, INT J REMOTE SENS, V39, P2702, DOI 10.1080/01431161.2018.1430403
   Silva VVR, 2005, ENG APPL ARTIF INTEL, V18, P575, DOI 10.1016/j.engappai.2005.01.001
   Simpson, 2015, ARXIV PREPRINT ARXIV
   Song J, 2017, J Inf Hiding Multim Signal Process, V8, P578
   Talatahari S, 2013, NEURAL COMPUT APPL, V23, P1297, DOI 10.1007/s00521-012-1072-5
   Thangaraj M, 2019, WIRELESS PERS COMMUN, V107, P939, DOI 10.1007/s11277-019-06310-4
   Tsai CY, 2007, LECT NOTES COMPUT SC, V4705, P1107
   Wang H, 2013, PROCEEDINGS OF THE 5TH (2013) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS I AND II, P1, DOI 10.1109/ijcnn.2013.6706812
   Wei YH, 2015, ADV DATA ANAL CLASSI, V9, P197, DOI 10.1007/s11634-014-0182-6
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Ye ZW, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P728
   Yin PY, 1997, SIGNAL PROCESS, V60, P305, DOI 10.1016/S0165-1684(97)00080-7
   Zhang CS, 2010, EXPERT SYST APPL, V37, P4761, DOI 10.1016/j.eswa.2009.11.003
   Zhang DQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2189, DOI 10.1109/ICMLC.2003.1259869
NR 61
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18381
EP 18412
DI 10.1007/s11042-020-10237-5
EA FEB 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700004
OA hybrid
DA 2024-07-18
ER

PT J
AU Goh, KCW
   Ng, RBC
   Wong, YK
   Ho, NJH
   Chua, MCH
AF Goh, Kenneth C. W.
   Ng, Raymond B. C.
   Wong, Yoke-Keong
   Ho, Nicholas J. H.
   Chua, Matthew C. H.
TI Aerial filming with synchronized drones using reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aerial filming; Autonomous drones; Swarm formation control; Deep
   reinforcement learning
AB Usage of multiple drones is necessary for aerial filming applications to ensure redundancy. However, this could inevitably contribute to higher risks of collisions, especially when the number of drones increases. Hence, this motivates us to explore various autonomous flight formation control methods that have the potential to enable multiple drones to effectively track a specific target at the same time. In this paper, we designed a model-free deep reinforcement learning algorithm, which is mainly based on the Deep Recurrent Q-Network concept, for the aforementioned purposes. The proposed algorithm was expanded into single and multi-agent types that enable multiple drones tracking while maintaining formation and preventing collision. The involved rewards in these approaches are two-dimensional in nature and are dependent on the communication system. Using Microsoft AirSim simulator, a virtual environment that includes four virtual drones was developed for experimental purposes. A comparison was made among various methods during the simulations, and the results concluded that the recurrent, single-agent model is the most effective method, being 33% more effective than its recurrent, multi-agent counterparts. The poor performance of the non-recurrent, single-agent baseline model also suggests that the recurrent elements in the network are essential to enable desirable multiple-drones flight.
C1 [Goh, Kenneth C. W.; Ng, Raymond B. C.; Wong, Yoke-Keong; Ho, Nicholas J. H.; Chua, Matthew C. H.] Natl Univ Singapore, Inst Syst Sci, Singapore, Singapore.
C3 National University of Singapore
RP Ho, NJH (corresponding author), Natl Univ Singapore, Inst Syst Sci, Singapore, Singapore.
EM e0402085@u.nus.edu; e0402084@u.nus.edu; yokekeong.wong@u.nus.edu;
   nicholas.ho@nus.edu.sg; mattchua@nus.edu.sg
RI Chua, Matthew/P-6434-2014
OI Ho, Nicholas/0000-0001-7522-2984; Matthew, Chua/0000-0002-5200-5079
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abughalieh KM, 2019, MULTIMED TOOLS APPL, V78, P9149, DOI 10.1007/s11042-018-6508-1
   Alam MS, 2019, MULTIMED TOOLS APPL, V78, P35119, DOI 10.1007/s11042-019-08067-1
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chollet F., KERAS
   Choudhury S, 2018, ARXIV180809563
   Cunha, 2017, MULTIDRONE
   Epic Games, 2020, Unreal Engine
   Esmukov, GEOCODING LIB PYTHON
   French Sally., 2018, MarketWatch
   GALVANE Q, 2017, ARXIV171204353
   Galvane Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181975
   Hausknecht M., 2017, ARXIV150706527
   Hong S, 2019, AUTONOMOUS UAV NAVIG
   Huang C, 2018, IEEE INT C INT ROBOT, P4692, DOI 10.1109/IROS.2018.8594333
   Huang C, 2018, IEEE INT CONF ROBOT, P7039, DOI 10.1109/ICRA.2018.8460703
   Huynh, 2017, TRAINING DETECTING O
   James S., 2019, ARXIV PREPRINT ARXIV
   JOUBERT N, 2016, ARXIV161001691
   Karl M., 2020, ARXIV200308876
   Karney CFF, 2013, J GEODESY, V87, P43, DOI 10.1007/s00190-012-0578-z
   Kostrikov Ilya, 2020, ARXIV200413649
   Krishnan S., 2019, ARXIV190600421
   Kwak J, 2019, MULTIMED TOOLS APPL, V78, P27175, DOI 10.1007/s11042-019-7703-4
   Liu, GUANGZHOU, P2480, DOI [10.23919/ChiCC.2019.8865177, DOI 10.23919/CHICC.2019.8865177]
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P27933, DOI 10.1007/s11042-019-07864-y
   Ma Z., 2019, ARXIV190912271
   Mademlis I, 2019, IEEE SIGNAL PROC MAG, V36, P147, DOI 10.1109/MSP.2018.2875190
   Microsoft, 2020, OPEN SOURCE SIMULATO
   Microsoft, 2019, MICROSOFT DRONE RESC
   Nägeli T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073712
   Nägeli T, 2017, IEEE ROBOT AUTOM LET, V2, P1696, DOI 10.1109/LRA.2017.2665693
   Nikolaidis, 2017, MULTIDRONE
   Passalis N, 2019, NEUROCOMPUTING, V335, P37, DOI 10.1016/j.neucom.2019.01.046
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rising, 2015, FLIGHT EVOLVED
   Sabetghadam B, 2019, 2019 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR), DOI 10.1109/ecmr.2019.8870950
   Tefas, 2017, MULTIDRONE
   Torres-Gonzalez A., 2017, ADV INTELLIGENT SYST, P337, DOI DOI 10.1007/978-3-319-70833-1_28
   Tzutalin, 2020, LABELIMG IS GRAPHICA
   Wang T, 2019, MULTIMED TOOLS APPL, V78, P4347, DOI 10.1007/s11042-018-5739-5
   Wang W, 2019, ARXIV190402319
   Yang H, 2018, COMPUT GRAPH FORUM, V37, P191, DOI 10.1111/cgf.13559
   Zanol R, 2019, IEEE WCNC
   Zhang K., 2019, ARXIV191110635, DOI DOI 10.1007/978-3-030-60990-0_12
NR 45
TC 5
Z9 8
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18125
EP 18150
DI 10.1007/s11042-020-10388-5
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618132200002
OA Bronze
DA 2024-07-18
ER

PT J
AU Yaliniz, G
   Ikizler-Cinbis, N
AF Yaliniz, Gokhan
   Ikizler-Cinbis, Nazli
TI Using independently recurrent networks for reinforcement learning based
   unsupervised video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Recurrent neural networks; Reinforcement learning;
   Unsupervised learning
ID KEYFRAME SELECTION
AB Sigmoid and hyperbolic activation functions in long short-term memory (LSTM) and gated recurrent unit (GRU) based models used in recent studies on video summarization, may cause gradient decay over layers. Moreover, interpreting and developing network models are difficult because of entanglement of neurons on recurrent neural network (RNN). To solve these issues, in this study, we propose a method that uses deep reinforcement learning together with independently recurrent neural networks (IndRNN) for unsupervised video summarization. In this method, Leaky Rectified Linear Unit (Leaky ReLU) is used as an activation function to deal with decaying gradient and dying neuron problems. The model, which does not rely on any labels or user interaction, is designed with a reward function that jointly accounts for uniformity, diversity and representativeness of generated summaries. In this way, our model can create summaries as uniform as possible, has more layers and can be trained with more steps without having any problem related to gradients. Based on the experiments conducted on two benchmark datasets, we observe that, compared to the state-of-the-art methods on video summarization task, better summarization performance can be obtained.
C1 [Yaliniz, Gokhan; Ikizler-Cinbis, Nazli] Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
C3 Hacettepe University
RP Ikizler-Cinbis, N (corresponding author), Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
EM gokhanyaliniz@gmail.com; nazli@cs.hacettepe.edu.tr
OI Ikizler-Cinbis, Nazli/0000-0002-8644-2875
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [116E685]
FX This project was partially supported by a grant from The Scientific and
   Technological Research Council of Turkey (TUBITAK) with project no
   116E685.
CR [Anonymous], 2018, PROC EAR C COMPUT VI
   Casas LL, 2019, LECT NOTES COMPUT SC, V11296, P67, DOI 10.1007/978-3-030-05716-9_6
   Chakraborty S, 2015, IEEE WINT CONF APPL, P702, DOI 10.1109/WACV.2015.99
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   del Molino AG, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P600, DOI 10.1145/3240508.3240599
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Elfeki M, 2019, IEEE WINT CONF APPL, P754, DOI 10.1109/WACV.2019.00085
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu TJ, 2019, IEEE WINT CONF APPL, P1579, DOI 10.1109/WACV.2019.00173
   Girgensohn A, 2000, MULTIMED TOOLS APPL, V11, P347, DOI 10.1023/A:1009630817712
   Gong BQ, 2014, ADV NEUR IN, V27
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Huang C, 2020, IEEE T CIRC SYST VID, V30, P577, DOI 10.1109/TCSVT.2019.2890899
   Huang SY, 2019, IEEE T IMAGE PROCESS, V28, P2654, DOI 10.1109/TIP.2018.2889265
   Ji Z, 2019, INFORM SCIENCES, V478, P152, DOI 10.1016/j.ins.2018.09.050
   Ju Z., 2016, 2016 IEEE INT C MULT, P1
   King DB, 2015, ACS SYM SER, V1214, P1
   Kweon IS, 2018, ARXIV181109791
   Lal S, 2019, IEEE WINT CONF APPL, P471, DOI 10.1109/WACV.2019.00056
   Lee HC, 2003, SIGNAL PROCESS-IMAGE, V18, P1, DOI 10.1016/S0923-5965(02)00089-9
   Lei J, 2019, IEEE T CIRC SYST VID, V29, P2126, DOI 10.1109/TCSVT.2018.2860797
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Mahasseni B, 2017, PROC CVPR IEEE, P2982, DOI 10.1109/CVPR.2017.318
   Panagiotakis Costas, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P305, DOI 10.1007/978-3-030-45442-5_38
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   PARLETT B, 1964, MATH COMPUT, V18, P464, DOI 10.2307/2003770
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang L, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P40, DOI 10.1145/3317640.3317658
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu JX, 2018, MULTIMED TOOLS APPL, V77, P29245, DOI 10.1007/s11042-018-5953-1
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yao T, 2016, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2016.112
   Yuan L, 2019, AAAI CONF ARTIF INTE, P9143
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang L., 2018, P EUR C COMP VIS ECC, P184
   Zhang YJ, 2019, MULTIMED TOOLS APPL, V78, P35237, DOI 10.1007/s11042-019-08175-y
   Zhang YJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040750
   Zhang Yujia, 2018, BRIT MACH VIS C BMVC
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhong SH, 2019, NEUROCOMPUTING, V332, P224, DOI 10.1016/j.neucom.2018.12.040
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
NR 53
TC 8
Z9 10
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17827
EP 17847
DI 10.1007/s11042-020-10293-x
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617417600004
DA 2024-07-18
ER

PT J
AU Wang, P
   Wang, ZW
   Lv, D
   Zhang, CL
   Wang, YH
AF Wang, Ping
   Wang, Zhiwen
   Lv, Dong
   Zhang, Chanlong
   Wang, Yuhang
TI Low illumination color image enhancement based on Gabor filtering and
   Retinex theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinex theory; Low illumination; Image enhancement; Image fusion
AB Aiming at the shortcomings of traditional Retinex image enhancement algorithms, such as poor texture detail retention, halo, over-enhancement and hue mutation, a low-illuminance color image enhancement algorithm based on Gabor filter and Retinex theory is proposed. The algorithm extracts the luminance I component from the HSI color space of the original image, and then performs MSRCR (Retinex algorithm for color restoration) enhancement on the luminance I component to obtain an enhanced luminance I component and color reproduction image. On the other hand, the original image is enhanced by a SSR (Single Scale Retinex Algorithm) based on the Gabor filter in the RGB color space to obtain an enhanced image with better texture and edge details. Then, the two images enhanced in two different ways are weighted and merged to obtain the final enhanced image. This algorithm is compared with the SSR algorithm based on Gamma correction, the MSR (multi-scale Retinex algorithm) based on bilateral filtering and the improved MSRCR algorithm. Taking mean square error, information entropy, and average gradient as evaluation indicators, the experimental results show that the image information processed by this algorithm is rich in color, rich in color, and color is closer to the original image, effectively reducing the occurrence of halo and excessive enhancement. This algorithm has certain reference significance for the enhancement of low-light color images.
C1 [Wang, Ping; Lv, Dong] Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Liuzhou 545000, Guangxi, Peoples R China.
   [Wang, Zhiwen] Guangxi Univ Sci & Technol, Coll Comp Sci & Commun Engn, Liuzhou 545000, Guangxi, Peoples R China.
   [Wang, Zhiwen; Zhang, Chanlong; Wang, Yuhang] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541000, Peoples R China.
C3 Guangxi University of Science & Technology; Guangxi University of
   Science & Technology; Guangxi Normal University
RP Wang, ZW (corresponding author), Guangxi Univ Sci & Technol, Coll Comp Sci & Commun Engn, Liuzhou 545000, Guangxi, Peoples R China.; Wang, ZW (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541000, Peoples R China.
EM 1391158356@qq.com; wzw69@126.com; 1933510334@qq.com; zchyp@163.com;
   343364527@qq.com
RI WANG, JIAXUAN/JMP-8599-2023; li, xinke/JTU-3633-2023; zhang,
   weijie/JQX-1450-2023
OI wang, zhiwen/0000-0003-2309-7282
FU National Natural Science Foundation of China [6192007, 61462008,
   61751213, 61866004]; Key projects of Guangxi Natural Science Foundation
   [2018GXNSFDA294001, 2018GXNSFDA281009]; Natural Science Foundation of
   Guangxi [2018GXNSFAA294050, 2017GXNSFAA198365]; Innovation Team Project
   of Guangxi University of Science and Technology [gxkjdx201504];
   Innovation Project for College Students of Guangxi University of Science
   and Technology [GKYC201708]; Research Fund of Guangxi Key Lab of
   Multi-source Information Mining Security [MIMS19-04]
FX This research was funded by the National Natural Science Foundation of
   China, grant number 6192007, 61462008, 61751213, 61866004; the Key
   projects of Guangxi Natural Science Foundation, grant number
   2018GXNSFDA294001,2018GXNSFDA281009; the Natural Science Foundation of
   Guangxi, grant number 2018GXNSFAA294050, 2017GXNSFAA198365; 2015
   Innovation Team Project of Guangxi University of Science and Technology,
   grant number gxkjdx201504; Innovation Project for College Students of
   Guangxi University of Science and Technology, grant number GKYC201708;
   Research Fund of Guangxi Key Lab of Multi-source Information Mining &
   Security, grant number MIMS19-04.
CR Cai J., 2018, IEEE T IMAGE PROCESS, V1, P1
   Dong J.W., 2018, SCI TECHNOL ENG, V18, P238, DOI [10.3969/j.issn.1671-1815.2018.22.035, DOI 10.3969/J.ISSN.1671-1815.2018.22.035]
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Hongan L., 2018, J HARBIN ENG U, V39, P2001
   Huijuan T., 2020, ACTA PHOTONICA SINIC, V49, P173
   Jang CY, 2012, ADAPTIVE SELECTION W
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kwon HJ, 2014, DIGIT SIGNAL PROCESS, V30, P74, DOI 10.1016/j.dsp.2014.03.008
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lu C., 2015, J LANZHOU JIAOTONG U, V34, P55
   Ma J., 2017, INT J MODERN PHYS B, V31, P16
   Mingfu Z., 2013, LASER MAGAZINE, V34, P1
   Ruoya Z., 2017, MODERN COMPUTER PROF, V29, P78
   Shen L., 2017, ARXIV171102488
   Wang H, 2017, CHIN OPT, V10, P438, DOI 10.3788/CO.20171004.0438
   Wei L.U., 2019, SCI TECHNOL ENG, V19, P151, DOI 10.3969/j.issn.1671-1815.2019.13.024
   Xiaofang W., 2020, EXPT TECHNOLOGY MANA, V37, P92
   Xujia Q., 2016, SMALL MICROCOMPUTER, V37, P168
   Yang Y., 2018, Comput. Sci. Explor, V12, P1021
   Ying H., 2010, COMPUT ENG APPL, V46, P172
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhongyuan C., 2015, LASER MAGAZINE, V36, P90
   Zirui G, 2012, THESIS WUHAN U TECHN, P11
NR 23
TC 36
Z9 42
U1 15
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17705
EP 17719
DI 10.1007/s11042-021-10607-7
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616915300006
DA 2024-07-18
ER

PT J
AU Pawar, MD
   Kokate, RD
AF Pawar, Manju D.
   Kokate, Rajendra D.
TI Convolution neural network based automatic speech emotion recognition
   using Mel-frequency Cepstrum coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Feature extraction; Speech emotion
   recognition; Energy; Pitch
ID EXTRACTION; FEATURES; MFCC
AB A significant role is played by Speech Emotion Recognition (SER) with different applications in affective computing and human-computer interface. In literature, the most adapted technique for recognition of emotion was based on simple feature extraction using a simple classifier. Most of the methods in the literature has limited efficiency for the recognition of emotion. Hence for solving these drawbacks, five various models based on Convolution Neural Network (CNN) was proposed in this paper for recognition of emotion through signals obtained on speech. In the methodology which was proposed, seven different emotions are recognised with the utilisation of CNN with feature extraction methods includes disgust, normal, fear Joy, Anger, Sadness and surprise. Initially, the speech emotion signals are collected from the database such as berlin database. After that, feature extraction is considered, and it is carried out by the Pitch and Energy, Mel-Frequency Cepstral Coefficients (MFCC) and Mel Energy Spectrum Dynamic Coefficients (MEDC). The mentioned feature extraction process is widely used for classifying the speech data and perform better in performance. Mel-cepstral coefficients utilise less time for shaping the spectral with adequate data and offers better voice quality. The extracted features are used for the recognition purpose by CNN network. In the proposed CNN network, either one or more pairs of convolutions, besides, max-pooling layers remain present. With the utilisation of the CNN network, the emotions are recognised through the input speech signal. The proposed method is implemented in MATLAB, and it will be contrasted with the existing method such as Linear Prediction Cepstral Coefficient (LPCC) with the K-Nearest Neighbour (KNN) classifier to test the samples for optimal performance evaluation. The Statistical measurements are utilised for analysing the performance such as accuracy, precision, specificity, recall, sensitivity, error rate, receiver operating characteristics (ROC) curve, an area under curve (AUC), and False Positive Rate (FPR).
C1 [Pawar, Manju D.] Maharashtra Inst Technol, Aurangabad, Maharashtra, India.
   [Kokate, Rajendra D.] Govt Coll Engn, Jalgaon, Maharashtra, India.
RP Pawar, MD (corresponding author), Maharashtra Inst Technol, Aurangabad, Maharashtra, India.
EM manjupawar2583@gmail.com
RI kokate, Rajendra Dagduba/AAX-2320-2021
CR [Anonymous], BERLIN DATASET
   [Anonymous], 2018, J. Comput. Theor. Nanosci., DOI DOI 10.1166/JCTN.2018.7447
   Bandela SR, 2020, RADIOENGINEERING, V29, P353, DOI 10.13164/re.2020.0353
   Ben Alex S, 2020, CIRC SYST SIGNAL PR, V39, P5681, DOI 10.1007/s00034-020-01429-3
   Chauhan HB., 2015, INT J INNOV RES COMP, V3, P822
   Chen LF, 2020, INFORM SCIENCES, V509, P150, DOI 10.1016/j.ins.2019.09.005
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Errattahi R, 2018, PROCEDIA COMPUT SCI, V128, P32, DOI 10.1016/j.procs.2018.03.005
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Frigieri EP, 2016, APPL ACOUST, V113, P230, DOI 10.1016/j.apacoust.2016.06.027
   Hakanpää T, 2019, J VOICE, V33, P501, DOI 10.1016/j.jvoice.2018.01.012
   Huang ZW, 2015, FRONT INFORM TECH EL, V16, P358, DOI 10.1631/FITEE.1400323
   Jiang W, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122730
   Kadiri SR, 2017, SPEECH COMMUN, V86, P52, DOI 10.1016/j.specom.2016.11.005
   Koduru A, 2020, INT J SPEECH TECHNOL, V23, P45, DOI 10.1007/s10772-020-09672-4
   Lalitha S, 2015, PROCEDIA COMPUT SCI, V70, P29, DOI 10.1016/j.procs.2015.10.020
   Li Q, 2020, IEEE ACCESS, V8, P48720, DOI 10.1109/ACCESS.2020.2979799
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Mao X, 2008, 2008 IEEE PAC AS WOR
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mohamed MS, 2021, ENDOCRINE, V71, P3, DOI 10.1007/s12020-020-02536-6
   Motamed S, 2017, BIOL INSPIR COGN ARC, V19, P32, DOI 10.1016/j.bica.2016.12.002
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Paul SBS, 2021, INTEGRATION, V76, P69, DOI 10.1016/j.vlsi.2020.09.002
   Rani P, 2015, International journal of computer applications, V4, P11
   Ravi J., 2012, International Journal of Advanced Networking and Applications, V3, P1402
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   Song P, 2016, SPEECH COMMUN, V83, P34, DOI 10.1016/j.specom.2016.07.010
   Sun YX, 2015, BIOMED SIGNAL PROCES, V18, P80, DOI 10.1016/j.bspc.2014.10.008
   Yang S, 2017, 2015 34 CHINESE CONT, DOI [10.1109/ChiCC.2015.7260254, DOI 10.1109/CHICC.2015.7260254]
   Ying S, 2018, FUTURE GENER COMP SY, V81, P291, DOI 10.1016/j.future.2017.10.002
   Yogesh CK, 2017, EXPERT SYST APPL, V69, P149, DOI 10.1016/j.eswa.2016.10.035
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 35
TC 25
Z9 26
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15563
EP 15587
DI 10.1007/s11042-020-10329-2
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615174300008
DA 2024-07-18
ER

PT J
AU Phadikar, BS
   Phadikar, A
   Thakur, SS
AF Phadikar, Baisakhi Sur
   Phadikar, Amit
   Thakur, Subro S.
TI A comprehensive assessment of content-based image retrieval using
   selected full reference image quality assessment algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Image quality model; Full reference
ID HISTOGRAM TEXTURE FEATURES
AB In the area of full-reference (FR) objective 'image quality assessment' (IQA), a huge amount of improvement has been done in the last few years that can calculate image quality, consistently. Contrarily, query-based image/video databases and search engines retrieve related data using 'ranking and indexing' depending on stored content. It is also to be noted that both techniques use feature extraction to achieve their goal. The efficiency of seven selected FR-IQA schemes is described in this article for the retrieval of an image signal. Extensive tests are done on two freely accessible databases. The comparison results express that mean-structural-similarity-index-measure (MSSIM), and feature-similarity-index-measure (FSIM) offer superior outcome than other IQA models. Our assessment outcome and the related thought will be very much useful for the researchers to understand the latest application areas of the IQA model in the area of image searching and retrieval.
C1 [Phadikar, Baisakhi Sur; Thakur, Subro S.] MCKV Inst Engn, Dept Comp Sci & Engn, Howrah, WB, India.
   [Phadikar, Amit] MCKV Inst Engn, Dept Informat Technol, Howrah, WB, India.
RP Phadikar, A (corresponding author), MCKV Inst Engn, Dept Informat Technol, Howrah, WB, India.
EM baisakhi.sp@gmail.com; amitphadikar@rediffmail.com;
   subro_thakur@yahoo.com
RI Phadikar, Amit/CAE-9495-2022
CR Al-Mohamade A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6010002
   [Anonymous], 2011, INT J INF TECHNOL KN
   Bekhet S, 2020, MULTIMED TOOLS APPL, V79, P6265, DOI 10.1007/s11042-019-08539-4
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Duan GY, 2011, PHYSCS PROC, V22, P471, DOI 10.1016/j.phpro.2011.11.073
   Eom M., 2007, INT J ELECT COMPUT E, V1, P1385
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Hussain DM, 2020, MULTIMED TOOLS APPL, V79, P3683, DOI 10.1007/s11042-018-6708-8
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Jose S, 2014, INT J COMPUT APPL, V99, P1
   Kumar Vidit, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P1120, DOI 10.1109/SPIN48934.2020.9071334
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liu X, 2020, IEEE T IND INFORM, V16, P5379, DOI 10.1109/TII.2019.2947435
   Liu X, 2019, IEEE INTERNET THINGS, V6, P5962, DOI 10.1109/JIOT.2018.2847731
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu ZM, 2005, LECT NOTES ARTIF INT, V3682, P573
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   Malik F, 2013, INT ARAB J INF TECHN, V10, P616
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mohamed A, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P237, DOI 10.1109/CW.2009.61
   Mokhtar F, 2019, B ELECT ENG INF, V8, P527
   Nezamabadi-pour H., 2007, INT J COMPUT CONTROL, V1, P759
   Nezamabadi-pour H, 2005, PROC WRLD ACAD SCI E, V3, P98
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Ouahi H, 2014, INT J COMPUT APPL, V90, P27
   Ouahi H, 2015, INT J COMP SCI INF T, V6, P1888
   Phadikar BS, 2018, PATTERN ANAL APPL, V21, P469, DOI 10.1007/s10044-016-0589-0
   Phadikar BS, 2016, P 5 INT C COMP COMM, P167
   Phadikar BS, 2016, LECT NOTES NETWORKS, V11, P197
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Singh N, 2012, PROC TECH, V4, P245, DOI 10.1016/j.protcy.2012.05.037
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Tyagi V., 2017, Content-based image retrieval, DOI [10.1007/978-981-10-6759-4, DOI 10.1007/978-981-10-6759-4]
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 45
TC 1
Z9 2
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15619
EP 15646
DI 10.1007/s11042-021-10573-0
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615174300007
DA 2024-07-18
ER

PT J
AU Nowak, M
   Michonski, J
   Sitnik, R
AF Nowak, Marta
   Michonski, Jakub
   Sitnik, Robert
TI Filling cavities in point clouds representing human body surface using
   Bezier patches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Full body scanning; Parametric surfaces; Bezier patches;
   Hole filling; Cavity filling
AB In this paper we introduce a cavity reconstructing algorithm for 3D surface scans (CRASS) developed for filling cavities in point clouds representing human body surfaces. The presented method uses Bezier patches to reconstruct missing data. The source of input data for the algorithm was an 8-directional structured light scanning system for the human body. Typical 3D scan representing human body consists of about 1 million points with average sampling density of 1 mm. The paper describes the complete scan processing pipeline: data pre-processing, boundary selection, cavity extraction and reconstruction, and a post-processing step to smooth and resample resulting geometry. The developed algorithm was tested on simulated and scanned 3D input data. Quality assessment was made based on simulated cavities, reconstructed using presented method and compared to original 3D geometry. Additionally, comparison to the state-of-the-art screened Poisson method is presented. Values' ranges of parameters influencing result of described method were estimated for sample scans and comprehensively discussed. The results of the quantitative assessment of the reconstruction were lower than 0,5 of average sampling density.
C1 [Nowak, Marta; Michonski, Jakub; Sitnik, Robert] Warsaw Univ Technol, Fac Mechatron, Virtual Real Techn Div, Inst Micromech & Photon, Ul Sw Andrzeja Boboli 8, PL-02525 Warsaw, Poland.
C3 Warsaw University of Technology
RP Nowak, M (corresponding author), Warsaw Univ Technol, Fac Mechatron, Virtual Real Techn Div, Inst Micromech & Photon, Ul Sw Andrzeja Boboli 8, PL-02525 Warsaw, Poland.
EM m.nowak@mchtr.pw.edu.pl; j.michonski@mchtr.pw.edu.pl;
   r.sitnik@mchtr.pw.edu.pl
RI Sitnik, Robert/GRX-9372-2022; Sitnik, Robert/AAE-6183-2022
OI Sitnik, Robert/0000-0002-8156-5462; Sitnik, Robert/0000-0002-8156-5462
FU National Centre for Research and Development [PBS3/B9/43/2015]
FX This study is partially supported by the project PBS3/B9/43/2015 funded
   by the National Centre for Research and Development.
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Centin M, 2015, COMPUT AIDED GEOM D, V35-36, P42, DOI 10.1016/j.cagd.2015.03.006
   Chalmoviansky P, 2003, LECT NOTES COMPUT SC, V2768, P196
   Cignoni P, 2008, ERCIM NEWS, P45
   Cohen, 2004, UUCS04019 SCH COMP U
   Dai Angela, 2019, PROC CVPR IEEE, P5574, DOI DOI 10.1109/CVPR.2019.00572
   Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125
   Davis J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P428, DOI 10.1109/TDPVT.2002.1024098
   de Berg M., 2008, COMPUTATIONAL GEOMET, V3rd, DOI [10.1007/978-3-540-77974-2_1, DOI 10.1007/978-3-540-77974]
   Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916
   Ebrahim M.A.B., 2015, INT J SCI RES, V4, P323
   Gallier J., 2000, Curves and Surfaces in Geometric Modeling
   Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488
   Glinkowski W, 2009, J BIOMED OPT, V14, DOI 10.1117/1.3210782
   Guennebaud G., 2010, Eigen
   Guo XY, 2018, VISUAL COMPUT, V34, P93, DOI 10.1007/s00371-016-1316-y
   Hanocka R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392415
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3267347
   Hirshberg DA, 2012, LECT NOTES COMPUT SC, V7577, P242, DOI 10.1007/978-3-642-33783-3_18
   Kambadakone AR, 2009, RADIOL CLIN N AM, V47, P161, DOI 10.1016/j.rcl.2008.11.003
   Karaszewski M, 2012, ROBOT AUTON SYST, V60, P1205, DOI 10.1016/j.robot.2012.05.005
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Lenar J, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.5.056014
   Li HB, 2018, COMPUT VIS IMAGE UND, V169, P108, DOI 10.1016/j.cviu.2018.01.009
   Li XZ, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P334, DOI 10.1109/CMCE.2010.5610505
   Markiewicz L, 2017, EXPERT SYST APPL, V85, P366, DOI 10.1016/j.eswa.2017.04.052
   Michonski J, 2016, SCOLIOSIS SPINAL DIS, V11, DOI 10.1186/s13013-016-0099-2
   Pérez E, 2016, INT J AP MAT COM-POL, V26, P885, DOI 10.1515/amcs-2016-0063
   Quinsat Y, 2015, INT J ADV MANUF TECH, V81, P411, DOI 10.1007/s00170-015-7185-0
   Saakes D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P6058, DOI 10.1145/2858036.2858282
   Wang DN, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P11
   Wang HN, 2007, IMAGE VISION COMPUT, V25, P103, DOI 10.1016/j.imavis.2005.12.006
   Williams F, 2019, PROC CVPR IEEE, P10122, DOI 10.1109/CVPR.2019.01037
   Zaidi H, 2011, PHYS MED BIOL, V56, P3091, DOI 10.1088/0031-9155/56/10/013
   Zhou Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061278
NR 36
TC 3
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15093
EP 15134
DI 10.1007/s11042-020-10120-3
EA FEB 2021
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000009
OA hybrid
DA 2024-07-18
ER

PT J
AU Mukhopadhyay, S
   Hossain, S
   Ghosal, SK
   Sarkar, R
AF Mukhopadhyay, Souradeep
   Hossain, Sabbir
   Ghosal, Sudipta Kr
   Sarkar, Ram
TI Secured image steganography based on Catalan transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Catalan transform; Inverse Catalan transform; Steganography; PSNR;
   Payload
ID WAVELET TRANSFORM
AB Transform domain steganography methods are always preferable than spatial domain methods to the research community due to following advantages: better feature identification, improved security and higher robustness. In this paper, an integer sequence named Catalan Transform (CT) has been exploited in the image steganography domain. At the outset, the cover image is decomposed into 2 x 2 non-overlapping blocks in row major order. Then, each such block i.e., 4-pixel group is converted into transform domain using CT. Secret bits are embedded into the transformed components in varying proportions which facilitates us to achieve a payload in the range of 1 to 4 bpp. Inverse Catalan Transform (ICT) is applied over transformed cum embedded quadruples to generate the stego-pixels in spatial domain. Successive embedding operation over an entire image ensures the formation of stego-image. Experimental results confirm that the Peak Signal to Noise Ratio (PSNR) values obtained by the proposed method are always above the acceptable level (i.e., 30 dB) and at the same time, it outperforms many state-of-the-art methods. Other metrics such as Mean Squared Error (MSE), Structural Similarity Index Measure (SSIM), Normalized Cross Correlation (NCC) and Global histograms with similarity measure have also been computed which prove the effectiveness of the proposed scheme. The robustness of the stego-images has further been tested using the StegExpose tool and it is found that the tool is unable to detect the presence of secret data. The code of this work is available at: https://github.com/Souradeep150/Catalan-based-Steganography.
C1 [Mukhopadhyay, Souradeep; Hossain, Sabbir; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Ghosal, Sudipta Kr] Nalhati Govt Polytech, Dept Comp Sci & Technol, Birbhum 731243, W Bengal, India.
C3 Jadavpur University
RP Ghosal, SK (corresponding author), Nalhati Govt Polytech, Dept Comp Sci & Technol, Birbhum 731243, W Bengal, India.
EM sudipta.ghosal@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Akhtar N, 2017, P 3 INT C COMP INT C, P1, DOI [10.1109/CIACT.2017.7977371, DOI 10.1109/CIACT.2017.7977371]
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Al-Jarrah M, 2018, **DATA OBJECT**, DOI [10.17632/sp4g8h7v8k.1, DOI 10.17632/SP4G8H7V8K.1]
   Alafandy KA, 2016, HIGH SECURITY DHATA
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Bandyopadhyay SK., 2013, P 5 INT C COMP INT C
   Bánoci V, 2011, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE - RADIOELEKTRONIKA 2011, P241
   Barry P, 2005, J INTEGER SEQ, V8
   Boehm Benedikt, 2014, ARXIV14106656
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Emam MM, 2016, INT J ADV COMPUT SC, V7, P361
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gashkov SB, 2015, MATH NOTES+, V97, P531, DOI 10.1134/S0001434615030256
   Ghosal S., 2014, ADV MODELL ANAL B, V57, P68
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2013, PROC TECH, V10, P95, DOI 10.1016/j.protcy.2013.12.341
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   Hajizadeh H, 2013, IRAN CONF ELECTR ENG
   Jothy N, 2016, 10 INT C INT SYST CO, DOI [10.1109/ISCO.2016.7726948., DOI 10.1109/ISCO.2016.7726948]
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Kamya Suraj, 2020, WATERMARK DCT MATLAB
   Kang YH, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719852031
   Kuo W-C, 2013, SMART INNOV SYST TEC, V21, P131, DOI [10.1007/978-3-642-35473-1_14, DOI 10.1007/978-3-642-35473-1_14]
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Mandal JK, 2018, J INF SECUR APPL, V46, DOI [10.1016/j.jisa.2018.04.003, DOI 10.1016/J.JISA.2018.04.003]
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Nazari M, 2020, MULTIMED TOOLS APPL, V79, P13693, DOI 10.1007/s11042-019-08415-1
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Redely H. S. Manjunatha, 2011, International Journal of Advanced Networking and Applications, V3, P1203
   Seyyedi SA, 2014, INT J SECUR APPL, V8, P183, DOI 10.14257/ijsia.2014.8.4.17
   Shet KS, 2019, MULTIMED TOOLS APPL, V78, P18309, DOI 10.1007/s11042-019-7187-2
   Shin N, 1999, LECT NOTES COMPUTER, V1768
   Stanley, 2005, PAIRS VALUES CHI SQU, P1
   Wang CC, 2018, MULTIMED TOOLS APPL, V77, P6327, DOI 10.1007/s11042-017-4541-0
   Weber A.G., 2019, The USC-SIPI Image Database: Version 5, Original Release
   Xiang LY, 2017, IEICE T INF SYST, VE100D, P313, DOI 10.1587/transinf.2016EDP7358
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
   Zhang X., 2011, FTRA INT C SEC TRUST
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
NR 46
TC 20
Z9 20
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14495
EP 14520
DI 10.1007/s11042-020-10424-4
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611466000002
DA 2024-07-18
ER

PT J
AU Rincy, NT
   Gupta, R
AF Rincy, N. Thomas
   Gupta, Roopam
TI An efficient feature subset selection approach for machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Machine learning algorithms; Proposed CAPPER
   approach; CFS approach; Wrapper approach; Datasets
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; CLASSIFICATION;
   ALGORITHM; SVR; OPTIMIZATION; NETWORK; LIBRARY; SEARCH
AB This literature introduces CAPPER, an efficient hybrid feature subset selection approach which is the combination of feature subsets from the Correlation-based feature selection (CFS) and Wrapper approaches. CFS is basically a filter approach that appraises the merits of subset attributes by classifying the feature ability according to the amount of redundancy between them and the feature subset selection for Wrappers that examines the attributes by applying the induction of various machine learning algorithms. For the evaluation of metrics, the CAPPER approach is tested on the different domains of datasets. The reduced, highly merit and accurate feature subsets obtained from CAPPER approach are then trained with the machine learning algorithm and evaluated by cross-validation for the set of attributes. Moreover, a statistical approach is applied for the significance of the result. It was observed that the CAPPER approach surpasses the CFS and Wrapper approaches on different domains of datasets.
C1 [Rincy, N. Thomas] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Dept Comp Sci & Engn, Bhopal, MP, India.
   [Gupta, Roopam] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Dept Informat Technol, Bhopal, MP, India.
C3 Rajiv Gandhi Technological University; Rajiv Gandhi Technological
   University
RP Rincy, NT (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Dept Comp Sci & Engn, Bhopal, MP, India.
EM rinc_thomas@rediffmail.com; roopamgupta@rgtu.net
OI Thomas, Rincy/0000-0001-8110-5514
CR Acharya N, 2018, SOFT COMPUT, V22, P4407, DOI 10.1007/s00500-017-2635-2
   Aha D.W., 1994, P 1994 AAAI WORKSHOP, P106
   AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500
   ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P1
   [Anonymous], 1999, WEKA DATA MINING TOO
   [Anonymous], 1997, TECHNICAL REPORT
   [Anonymous], 1991, TECH REP
   BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Breiman L, 1996, OUT OF BAG ESTIMATIO
   Cannady J., 1998, P 21 NATL INFORM SYS, P368
   Cardie C, 1995, P 1 INT C KNOWL DISC, P25
   CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164, DOI 10.1007/BFb0017012
   Cherkauer K. J., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P315
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dash M., 1997, Intelligent Data Analysis, V1
   Dash M, 1998, LECT NOTES ARTIF INT, V1531, P238
   DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Domingos P, 1997, ARTIF INTELL REV, V11, P227, DOI 10.1023/A:1006508722917
   Domingos P., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P105
   Dua D, 2019, UCI MACHINE LEARNING
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fournier-Viger P, 2016, LECT NOTES ARTIF INT, V9853, P36, DOI 10.1007/978-3-319-46131-1_8
   Friedman J., 2001, SPRINGER SERIES STAT, V1
   GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1
   Hall MA, 1998, PROGRESS IN CONNECTIONIST-BASED INFORMATION SYSTEMS, VOLS 1 AND 2, P855
   Hindy H, 2018, CORR, P1
   Hong WC, 2013, INT J ELEC POWER, V44, P604, DOI 10.1016/j.ijepes.2012.08.010
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Hyafil L., 1976, Information Processing Letters, V5, P15, DOI 10.1016/0020-0190(76)90095-8
   John G. H., 1997, THESIS
   John G.H., 1994, P 11 INT C MACH LEAR, P121
   Kar Pragma, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P417, DOI 10.1007/978-981-13-1742-2_41
   KAVITHA P, 2014, J THEORETICAL APPL I, V62, P1
   KIRA K, 1992, MACHINE LEARNING /, P249
   Kittler J., 1986, FEATURE SELECTION EX, P59
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kohavi R, 1995, LECT NOTES ARTIF INT, V912, P174
   KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412
   Kohavi R., 1994, RSSC '94. The Third International Workshop on Rough Sets and Soft Computing. Conference Proceedings, P310
   Koller D, 1996, MACHINE LEARNING, P248
   Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171
   KYBURG HE, 1991, J PHILOS, V88, P434, DOI 10.2307/2026705
   Langley P., 1994, P AAAI FALL S REL, P127
   Langley P, 1994, COMPUTATIONAL LEARNI, V4, P17
   Langley P., 1994, Proceedings of the Tenth international conference on Uncertainty in artificial intelligence, P399, DOI DOI 10.1016/B978-1-55860-332-5.50055-9
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783
   Liu H., 1998, KLUWER INT SER ENG C, P17
   Liu H., 1996, P 13 INT C MACHINE L, P319
   Malik AJ, 2018, CLUSTER COMPUT, V21, P667, DOI 10.1007/s10586-017-0971-8
   Mladenic D, 1999, MACHINE LEARNING, PROCEEDINGS, P258
   Moore Andrew W, 1994, P 11 INT C MACH LEAR, P190, DOI DOI 10.1016/B978-1-55860-335-6.50031-3
   Moore AW, 1992, COMPUTATIONAL LEARNI, V3
   Pazzani MichaelJ., 1996, International Workshop on Artificial Intelligence and Statistics, P239, DOI DOI 10.1007/978-1-4612-2404-4_23
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Provan GM, 1996, LEARNING DATA, P291
   Quinlan, 1993, 4 5 PROGRAMS MACHINE
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Revathi S., 2013, INT J ENG RES TECHNO, V2, P1848
   Russel S., 1995, Pearson Series, V1st, DOI [10.1017/S0269888900007724, DOI 10.1017/S0269888900007724]
   Singh M., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P453
   Skalak D., 1994, Proceedings of the Eleventh International Conference on Machine Learning, P293, DOI [https://doi.org/10.1016/B978-1-55860-335-6.50043-X, DOI 10.1016/B978-1-55860-335-6.50043-X, 10.1016/B978-1-55860-335-6.50043-X]
   Tavallaee M., 2009, P 2009 IEEE S COMPUT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Tay FEH, 2002, IEEE T KNOWL DATA EN, V14, P666, DOI 10.1109/TKDE.2002.1000349
   Vafaie H, 1995, PROC INT C TOOLS ART, P8, DOI 10.1109/TAI.1995.479372
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
NR 77
TC 8
Z9 8
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12737
EP 12830
DI 10.1007/s11042-020-10011-7
EA JAN 2021
PG 94
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100011
DA 2024-07-18
ER

PT J
AU Arun, PL
   Kumar, RMS
AF Arun, P. L.
   Kumar, R. Mathusoothana S.
TI Non-linear Sorenson-Dice Exemplar Image Inpainting Based Bayes
   Probability for Occlusion Removal in Remote Traffic Control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bayes conditional probability; Non-linear Gaussian bilateral filtering;
   Occlusion removal; Remote sensing images; Sorenson-Dice exemplar image
   inpainting; Traffic sign
AB Occlusion removal is a significant problem to be resolved in a remote traffic control system to enhance road safety. However, the conventional techniques do not recognize traffic signs well due to the vehicles are occluded. Besides occlusion removal was not performed in existing techniques with a less amount of time. In order to overcome such limitations, Non-linear Gaussian Bilateral Filtered Sorenson-Dice Exemplar Image Inpainting Based Bayes Conditional Probability (NGBFSEII-BCP) Method is proposed. Initially, a number of remote sensing images are taken as input from Highway Traffic Dataset. Then, the NGBFSEII-BCP method applies the Non-Linear Gaussian Bilateral Filtering (NGBF) algorithm for removing the noise pixels in input images. After preprocessing, the NGBFSEII-BCP method is used to remove the occlusion in the input images. Finally, NGBFSEII-BCP Method applies Bayes conditional probability to find operation status and thereby gets higher road safety using remote sensing images. The technique conducts the simulation evaluation using metrics such as peak signal to noise ratio, computational time, and detection accuracy. The simulation result illustrates that the NGBFSEII-BCP Method increases the detection accuracy by 20% and reduces the computation time by 32% as compared to state-of-the-art works.
C1 [Arun, P. L.] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kanyakumari, India.
   [Kumar, R. Mathusoothana S.] Noorul Islam Ctr Higher Educ, Dept Informat Technol, Kanyakumari, India.
RP Arun, PL (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kanyakumari, India.
EM aplpgme@gmail.com; rmsskdhujaa@gmail.com
CR [Anonymous], 2018, REMOTE SENS
   Arun PL, 2019, J ADV RES DYN CONTRO, V11, P1052
   Balali V, 2015, VIS ENG, V3, P1, DOI [DOI 10.1186/S40327-015-0027-1, 10.1186/s40327-015-0027-1]
   Chandel H., 2015, International Journal of Computer Applications, V120, DOI [DOI 10.5120/21264-3857, 10.5120/21264-3857]
   Erdélyi A, 2018, MULTIMED TOOLS APPL, V77, P2285, DOI 10.1007/s11042-016-4337-7
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   Gulati I, 2019, INT J RECENT TECHNO, V8, P213
   Huang PD, 2017, IEEE T INTELL TRANSP, V18, P2364, DOI 10.1109/TITS.2016.2639582
   Jadhav P., 2016, Int. Res. J. Eng. Technol. (IRJET), V3, P1207
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu CS, 2016, IET INTELL TRANSP SY, V10, P354, DOI 10.1049/iet-its.2015.0099
   Liu W., 2018, ARAB J GEOSCI, V11, P1
   Moutakki Z, 2017, TRANSP TELECOMMUN J, V18, P297, DOI 10.1515/ttj-2017-0027
   REENA S, 2016, INDIAN J SCI TECHNOL, V9, pNI983, DOI DOI 10.17485/ijst/2016/v9i48/108013
   Shreve M, 2015, IEEE INT C INTELL TR, P638, DOI 10.1109/ITSC.2015.110
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   Srinivas P., 2013, International Journal of Computer Science and Information Technologies, V4, P17
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Wali SB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/250461
   Wan YW, 2014, TRANSPORT RES C-EMER, V44, P202, DOI 10.1016/j.trc.2014.02.018
   Zhang W, 2008, IEEE T INTELL TRANSP, V9, P161, DOI 10.1109/TITS.2008.915647
   Zhang Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091118
   Zheng C, 2017, IEEE T GEOSCI REMOTE, V55, P3015, DOI 10.1109/TGRS.2017.2658731
   Zhou LC, 2016, IEEE J-STARS, V9, P3478, DOI 10.1109/JSTARS.2016.2514610
   Zhu YY, 2016, NEUROCOMPUTING, V214, P758, DOI 10.1016/j.neucom.2016.07.009
NR 25
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11523
EP 11538
DI 10.1007/s11042-020-10060-y
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700008
OA hybrid
DA 2024-07-18
ER

PT J
AU Hemavathi, R
   Kumaraswamy, R
AF Hemavathi, R.
   Kumaraswamy, R.
TI Voice conversion spoofing detection by exploring artifacts estimates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice biometrics; Spoofing attacks; Convolutional Neural network;
   Time-frequency representations; Voice Conversion; Spoof detection
ID SPEAKER VERIFICATION; SOURCE SEPARATION; SPEECH; COUNTERMEASURE;
   DECOMPOSITION; NUMBER
AB Automatic speaker verification or voice biometrics is an approach to verify the person's claimed identity through his/her voice. Voice biometrics finds its application in mobile banking and forensics. With the increased usage of speaker verification systems, studying the spoofing threats to speaker verification systems and building proper countermeasure is gaining attention. Spoofing is a genuine challenge as it leads to increase in the false alarm rate, i.e. an impostor is incorrectly accepted as genuine speaker. To make voice biometrics viable for practical applications there is a need to detect spoofing attack. Voice conversion spoofing is a technique where the imposter speaker's speech is converted to desired speaker's speech using signal processing approaches. Studies show that voice conversion introduces artifacts in resultant speech, hence, this paper proposes a novel approach to detect voice conversion spoofing attack by estimating artifact estimates from the given speech signal. To obtain artifact estimate from speech signal non-negative matrix factorization based source separation technique is employed. Later, Convolutional Neural Network based binary classifier is built to classify artifact estimates of input speech as natural and synthetic speech. Experiments are conducted on voice conversion challenge 2016 and voice conversion challenge 2018 database. Results show that proposed technique gives excellent performance by detecting wide range of unknown attacks. The proposed systems are compared to state of art spoof detection systems based on Constant Q Cepstrum Coefficients and Linear Frequency Cepstral Coefficients and results show the proposed system give relatively equivalent and/or better performance. Validation results for various noises is studied using NOIZEUS database and results show the efficiency of the proposed system in noisy environments.
C1 [Hemavathi, R.; Kumaraswamy, R.] Siddaganga Inst Technol, Dept Elect & Commun Engn, Tumakuru, India.
   [Hemavathi, R.; Kumaraswamy, R.] Visveswaraya Technol Univ, Belagavi 572103, Karnataka, India.
C3 Siddaganga Institute of Technology; Visvesvaraya Technological
   University
RP Hemavathi, R (corresponding author), Siddaganga Inst Technol, Dept Elect & Commun Engn, Tumakuru, India.; Hemavathi, R (corresponding author), Visveswaraya Technol Univ, Belagavi 572103, Karnataka, India.
EM hemavathir@sit.ac.in
OI Kumaraswamy, R/0000-0001-9409-9125
FU Women scientist scheme-A, Department of science and technology,
   Government of India [SR/WOS-A/ET-69/2016]
FX First author would like to thank Women scientist scheme-A, Department of
   science and technology, Government of India for providing financial
   assistance vide reference number SR/WOS-A/ET-69/2016.
CR Abe M., 1990, Journal of the Acoustical Society of Japan (E), V11, P71, DOI 10.1250/ast.11.71
   Alegre F, 2013, INTERSPEECH, P940
   [Anonymous], 2012, Interspeech
   Bonastre J-F, 2007, ARTIFICIAL IMPOSTOR
   Campbell WM, 2007, IEEE T AUDIO SPEECH, V15, P2085, DOI 10.1109/TASL.2007.902874
   Chen LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1859, DOI 10.1109/TASLP.2014.2353991
   Erro D, 2010, IEEE T AUDIO SPEECH, V18, P922, DOI 10.1109/TASL.2009.2038663
   Gao B, 2013, IEEE T CIRCUITS-I, V60, P662, DOI 10.1109/TCSI.2012.2215735
   Gao B, 2011, IEEE T AUDIO SPEECH, V19, P961, DOI 10.1109/TASL.2010.2072500
   Hanilçi C, 2016, SPEECH COMMUN, V85, P83, DOI 10.1016/j.specom.2016.10.002
   Hautamäki RG, 2015, SPEECH COMMUN, V72, P13, DOI 10.1016/j.specom.2015.05.002
   Hemavathi R, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Hu K, 2013, IEEE T AUDIO SPEECH, V21, P120, DOI 10.1109/TASL.2012.2215591
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006
   Khor LC, 2005, NONSPARSE APPROACH U
   Kinnunen T, 2006, IEEE T AUDIO SPEECH, V14, P277, DOI 10.1109/TSA.2005.853206
   Krishna PKM, 2017, IET SIGNAL PROCESS, V11, P579, DOI 10.1049/iet-spr.2016.0450
   Kumar MKP, 2015, INT J SPEECH TECHNOL, V18, P649, DOI 10.1007/s10772-015-9309-1
   Kumar MKP, 2017, INT J SPEECH TECHNOL, V20, P109, DOI 10.1007/s10772-016-9392-y
   Lau YW, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P145
   Li WF, 2014, IEEE-ACM T AUDIO SPE, V22, P2244, DOI 10.1109/TASLP.2014.2364130
   Lorenzo-Trueba J., 2018, P SPEAK LANG REC WOR, P195, DOI 10.21437/Odyssey.2018-28
   Masuko T, 1997, INT CONF ACOUST SPEE, P1611, DOI 10.1109/ICASSP.1997.598807
   Masuko T, 1996, INT CONF ACOUST SPEE, P389, DOI 10.1109/ICASSP.1996.541114
   Molla MKI, 2007, IEEE T AUDIO SPEECH, V15, P893, DOI 10.1109/TASL.2006.885254
   MORGAN DP, 1995, INT CONF ACOUST SPEE, P828, DOI 10.1109/ICASSP.1995.479822
   Patel TB, 2017, IEEE J-STSP, V11, P618, DOI 10.1109/JSTSP.2016.2647201
   Prasanna SRM, 2005, INDICON 2005 PROCEEDINGS, P19
   Sahidullah M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2087
   Shao Y, 2003, 2003 P ICASSP 03 200, V2, pII
   Smaragdis P, 2007, IEEE T AUDIO SPEECH, V15, P1, DOI 10.1109/TASL.2006.876726
   Swamy RK, 2007, IEEE SIGNAL PROC LET, V14, P481, DOI 10.1109/LSP.2006.891333
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Toda T, 2016, INTERSPEECH, P1632, DOI 10.21437/Interspeech.2016-1066
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   Wang DLL, 1999, IEEE T NEURAL NETWOR, V10, P684, DOI 10.1109/72.761727
   Wu Z., 2014, IEEE APSIPA ASC, P1, DOI 10.1109/APSIPA.2014.7041636
   Wu ZZ, 2016, IEEE-ACM T AUDIO SPE, V24, P768, DOI 10.1109/TASLP.2016.2526653
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Yegnanarayana B, 2009, IEEE T AUDIO SPEECH, V17, P1196, DOI 10.1109/TASL.2009.2016230
   Zhang XL, 2017, IEEE-ACM T AUDIO SPE, V25, P1075, DOI 10.1109/TASLP.2017.2687104
NR 41
TC 4
Z9 4
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23561
EP 23580
DI 10.1007/s11042-020-10212-0
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000605548700002
DA 2024-07-18
ER

PT J
AU Kumar, K
AF Kumar, Krishan
TI Text query based summarized event searching interface system using deep
   learning over cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; DNA sequence; Searching; Event summarization; Local
   alignment; Text query; Video
ID VIDEO
AB In the digital era, the growth of multimedia data is increasing at a rapid pace, which demands both effective and efficient summarization techniques. Such advanced techniques are required so that the users can quickly access the video content, recorded by multiple cameras for a certain period. At present, it is very challenging to manage and search a huge amount of multiview video data, which contains the inter-views dependencies, significant illumination changes, and many low-active frames. This work highlights an efficient summarization technique to summarize and then search the events in such multi-view videos over cloud through text query. Deep learning framework is employed to extract the features of moving objects in the frames. The inter-views dependencies among multiple views of the video are captured via local alignment. Parallel Virtual Machines (VMs) in the Cloud environment have been used to process the multiple video clip independently at a time. Object tracking is applied to filter the low-active frames. Experimental Results indicate that the model successfully reduces the video content, while preserving the momentous information in the form of the events. A computing analysis also indicates that it meets the requirement of real-time applications.
C1 [Kumar, Krishan] Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, K (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
EM kkberwal10@gmail.com
RI Berwal, Krishan/AAC-3473-2020
OI Berwal, Krishan/0000-0002-7068-6541
CR Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   Ayguade E, 2007, SMITH WATERMAN ALGOR
   Chen KW, 2011, IEEE T MULTIMEDIA, V13, P625, DOI 10.1109/TMM.2011.2131639
   Dumont E, 2009, INT WORK CONTENT MUL, P44, DOI 10.1109/CBMI.2009.49
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   GYGLI M, 2015, PROC CVPR IEEE, P3090, DOI DOI 10.1109/CVPR.2015.7298928
   Hao YB, 2017, IEEE T IMAGE PROCESS, V26, P5531, DOI 10.1109/TIP.2017.2737329
   Hong RC, 2017, IEEE T IMAGE PROCESS, V26, P4128, DOI 10.1109/TIP.2017.2710635
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuanar SK, 2015, IEEE T MULTIMEDIA, V17, P1166, DOI 10.1109/TMM.2015.2443558
   Kumar K, 2018, IETE TECHNICAL REV
   Kumar K, 2018, ADV INTELL SYST, V709, P383, DOI 10.1007/978-981-10-8633-5_38
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Kumar K, 2016, IEEE CONF CLOUD COMP, P95, DOI [10.1109/CCEM.2016.025, 10.1109/CCEM.2016.24]
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Michael G, 1991, SEQUENCE ANAL PRIMER, P169
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Panda R, 2017, IEEE T MULTIMEDIA, V19, P2010, DOI 10.1109/TMM.2017.2708981
   Panda R, 2017, IEEE T IMAGE PROCESS, V26, P4712, DOI 10.1109/TIP.2017.2708902
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Taherkhani A, 2018, IEEE T NEUR NET LEAR, V29, P5394, DOI 10.1109/TNNLS.2018.2797801
   Tong W, 2016, IEEE T INF FOREN SEC, V11, P2255, DOI 10.1109/TIFS.2016.2581313
   Wang C, 2017, IEEE T IMAGE PROCESS, V26, P5825, DOI 10.1109/TIP.2017.2750410
   Wong SC, 2017, IEEE T IMAGE PROCESS, V26, P4669, DOI 10.1109/TIP.2017.2696744
   Xu BH, 2016, IEEE MULTIMEDIA, V23, P23, DOI 10.1109/MMUL.2016.18
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 35
TC 40
Z9 40
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11079
EP 11094
DI 10.1007/s11042-020-10157-4
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604816700002
DA 2024-07-18
ER

PT J
AU Wu, T
   Cao, YH
   Wu, ZS
   Wu, JJ
   Qu, T
   Zhang, JP
AF Wu, Tao
   Cao, Yun-Hua
   Wu, Zhen-Sen
   Wu, Jia-Ji
   Qu, Tan
   Zhang, Jin-Peng
TI Deep learning for inversion of significant wave height based on actual
   sea surface backscattering coefficient model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocean surface waves; Significant wave height; Backscattering coefficient
   model; Deep learning technology; Inversion
ID NEURAL-NETWORKS; SCATTERING; CLASSIFICATION; APPROXIMATION; VALIDITY;
   SPECTRUM
AB Ocean waves are complex systems with the contributions of wind waves and swells. The study on interaction mechanism between electromagnetic wave and actual sea surface is of significant importance in ocean remote sensing and engineering application, which is also helpful in the prediction and inversion of wave information. In this paper, an efficient model for estimating backscattering coefficient is built, considering the characteristics of the wind-wave regime based on the inverse wave age. The backscattering coefficient results have been verified by comparing with the data collected in Lingshan Island during the period of October and November 2014 at low grazing angles and the Ku-band measurements at moderate grazing angles. The results indicate perfect agreement (within about 2 dB) with field data. Deep learning is an excellent method that can be used not only for classification but also for inversion and fitting of non-linear functions. In order to simulate the application of actual radar detection and inversion technology, the inversion of significant wave height from actual sea surface backscattering coefficients train data sets has been performed by using deep learning technology. The accuracy of 99.01% has been achieved under the condition of three hidden layers and iterating 100 times. The root mean square errors of the test data sets are less than 0.10, which indicates that deep learning is available in the inversion of significant wave height.
C1 [Wu, Tao; Cao, Yun-Hua; Wu, Zhen-Sen] Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
   [Wu, Jia-Ji; Qu, Tan] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Zhang, Jin-Peng] China Res Inst Radiowave Propagat, Qingdao 266107, Peoples R China.
C3 Xidian University; Xidian University
RP Cao, YH (corresponding author), Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
EM twu@stu.xidian.edu.cn; yhcao@mail.xidian.edu.cn
RI Wu, Zhenhua/M-9894-2017; Wu, Tao/HNQ-6402-2023
OI Wu, Zhenhua/0000-0003-4552-883X; Wu, Tao/0000-0003-0018-5490; Wu,
   Tao/0000-0002-7035-7414
CR Andreas EL, 2007, OCEAN ENG, V34, P1328, DOI 10.1016/j.oceaneng.2006.08.004
   [Anonymous], 2013, APPL MATH SCI
   [Anonymous], 2015, P 3 INT C LEARN REPR
   Chehri A, 2013, SENSORS-BASEL, V13, P3066, DOI 10.3390/s130303066
   Cuomo S, 2017, EXPERT SYST APPL, V79, P101, DOI 10.1016/j.eswa.2017.02.034
   Dee DP, 2011, Q J ROY METEOR SOC, V137, P553, DOI 10.1002/qj.828
   Elfouhaily T, 1997, J GEOPHYS RES-OCEANS, V102, P15781, DOI 10.1029/97JC00467
   Franceschetti G, 2002, IEEE T GEOSCI REMOTE, V40, P1935, DOI 10.1109/TGRS.2002.803798
   Geng J, 2018, IEEE T GEOSCI REMOTE, V56, P2255, DOI 10.1109/TGRS.2017.2777868
   Goda Y., 1999, Coast Eng. J., V41, P1, DOI DOI 10.1142/S0578563499000024
   Hanley KE, 2010, J PHYS OCEANOGR, V40, P1263, DOI 10.1175/2010JPO4377.1
   Hwang PA, 2012, J ATMOS OCEAN TECH, V29, P116, DOI 10.1175/JTECH-D-11-00075.1
   Jeon G, 2016, INFORM SCIENCES, V354, P112, DOI 10.1016/j.ins.2016.03.016
   Jeon G, 2009, IEEE T FUZZY SYST, V17, P1245, DOI 10.1109/TFUZZ.2009.2026638
   Kumar NK, 2017, OCEAN ENG, V129, P605, DOI 10.1016/j.oceaneng.2016.10.033
   LYGRE A, 1986, J PHYS OCEANOGR, V16, P2052, DOI 10.1175/1520-0485(1986)016<2052:MEEOTD>2.0.CO;2
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pan XY, 2018, INT J REMOTE SENS, V39, P607, DOI 10.1080/01431161.2017.1390269
   Panahi R, 2015, OCEAN ENG, V105, P104, DOI 10.1016/j.oceaneng.2015.06.017
   PIERSON WJ, 1964, J GEOPHYS RES, V69, P5181, DOI 10.1029/JZ069i024p05181
   Rikka S, 2018, INT J REMOTE SENS, V39, P1256, DOI 10.1080/01431161.2017.1399475
   Schroeder L, 2003, IEEE J OCEANIC ENG, V10, P346
   Shang RH, 2018, IEEE J-STARS, V11, P2834, DOI 10.1109/JSTARS.2018.2836909
   SOARES CG, 1991, OCEAN ENG, V18, P167
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   THORSOS EI, 1989, J ACOUST SOC AM, V86, P261, DOI 10.1121/1.398342
   THORSOS EI, 1988, J ACOUST SOC AM, V83, P78, DOI 10.1121/1.396188
   Toporkov JV, 2000, IEEE T GEOSCI REMOTE, V38, P1616, DOI 10.1109/36.851961
   Torsethaugen K, 2004, INT OFFSHORE POLAR E, P76
   Wu T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082450
   Wu ZS, 2009, PROG ELECTROMAGN RES, V89, P39, DOI 10.2528/PIER08111803
   Zhang YS, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/10/108402
   Zheng CW, 2015, RENEW SUST ENERG REV, V43, P381, DOI 10.1016/j.rser.2014.11.001
NR 33
TC 3
Z9 4
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34173
EP 34193
DI 10.1007/s11042-019-07967-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000044
DA 2024-07-18
ER

PT J
AU Nazari, M
   Mehrabian, M
AF Nazari, Mahboubeh
   Mehrabian, Mahshid
TI A novel chaotic IWT-LSB blind watermarking approach with flexible
   capacity for secure transmission of authenticated medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Identity authentication; Medical image watermarking; Integer wavelet
   transform; Least significant bit; Chaotic sequence; Encryption;
   Telemedicine
ID HARMONIC FOURIER MOMENTS; ROBUST; SCHEME; DWT; PROTECTION; TRANSFORM;
   SVD; SYSTEM
AB Nowadays, secure medical data transmission is an essential issue in telemedicine through unsecured channels. Watermarking methods are widely used to provide optimal security for medical image transmission. In this method, a secure and blind watermarking algorithm based on Integer Wavelet Transform (IWT), Least Significant Bit (LSB), and chaotic sequences (ILC) with a high capacity for grayscale medical and non-medical images is ILC. In this scheme, the high-level security is achieved by chaotic sequences that are applied for watermark encryption and determining the location of host blocks and host coefficients in the embedding process. At first, the cover medical image is divided into two distinct parts: the region of interest (ROI) and the region of non-interest (RONI) areas. Due to the high sensitivity of the ROI data in disease diagnosis, no embedding is done in this area. An ROI integrity check data (ICR), produced by some significant features from ROI, to detect tampered blocks inside this area. The main watermark, which is the encryption of ICR along with the patient's personal and medical information, is embedded in the middle-frequency at the first and second levels of IWT sub-bands. Furthermore, to verify the watermark, integrity check data (ICW) is produced and sent along with other essential data to the receiver. For identifying authentication purposes, the physician's signature is embedded at the third level (LL3) sub-band of IWT which has the highest energy and robustness. Moreover, the algorithm is flexible for using different sizes of text watermarks and it guarantees a high payload capacity. It is noteworthy the maximum lengths of text watermarks used in the method for 512x512 and 1024x1024 images are 47,784 and 164,620 bits, respectively. Although the size of the embedded watermark increases with the size of the ROI area, the image transparency remains almost constant and also the watermark is extracted with a bit error rate of zero. By doing various analyses, the experimental results represent superior imperceptibility by an average PSNR value of 75 dB. This method provides high imperceptibility and robustness against various attacks compared with state-of-the-art algorithms.
C1 [Nazari, Mahboubeh; Mehrabian, Mahshid] Imam Reza Int Univ, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
RP Mehrabian, M (corresponding author), Imam Reza Int Univ, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM mahboubeh.nazari@imamreza.ac.ir; mehrabianm598@gmail.com
CR ALabaichi A., 2020, Int. J. Electr. Comput. Eng., V10, P2088, DOI [10.11591/ijece.v10i1.pp935-946, DOI 10.11591/IJECE.V10I1.PP935-946]
   Alnazzawi T, 2019, INT J ADV COMPUT SC, V10, P191
   Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Arora M, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-019-2130-3
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   CHUNPENG W, 2016, SIGNAL PROCESS-IMAGE, V45, P10
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Ernawan F., 2019, Int. J. Electr. Computer Eng., V9, P2185, DOI [DOI 10.11591/IJECE.V9I3.PP2185-2195, 10.11591/ijece.v9i3.pp2185-2195]
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Gupta S., 2012, Int. J. Mod. Educ. Comput. Sci., V4, P27
   Khadam U, 2019, IEEE ACCESS, V7, P64955, DOI 10.1109/ACCESS.2019.2916674
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Liu XY, 2019, MULTIMED TOOLS APPL, V78, P6355, DOI 10.1007/s11042-018-6361-2
   Lu Feng, 2016, International Journal of Computer Theory and Engineering, V8, P58, DOI 10.7763/IJCTE.2016.V8.1020
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Nazari M, 2020, MULTIMED TOOLS APPL, V79, P13693, DOI 10.1007/s11042-019-08415-1
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Prasanth Vaidya S., 2020, Smart Computing Paradigms: New Progresses and Challenges. Proceedings of ICACNI 2018. Advances in Intelligent Systems and Computing (AISC 766), P11, DOI 10.1007/978-981-13-9683-0_2
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Salimi L, 2020, MULTIMED TOOLS APPL, V79, P11357, DOI 10.1007/s11042-019-08455-7
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Sivasubramanian N, 2020, COMPUTING, V102, P1365, DOI 10.1007/s00607-020-00797-7
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5108
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wu XQ, 2019, MULTIMED TOOLS APPL, V78, P8463, DOI 10.1007/s11042-018-6877-5
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 48
TC 32
Z9 34
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10615
EP 10655
DI 10.1007/s11042-020-10032-2
EA NOV 2020
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000593002700002
DA 2024-07-18
ER

PT J
AU Guo, CX
AF Guo, Cuixiang
TI Research on sports video retrieval algorithm based on semantic feature
   extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Semantic feature extraction; Signalling; Vector index;
   Gaussian mixture model
ID CLASSIFICATION; SEGMENTATION
AB Traditional content-based video retrieval algorithms usually only used the low-level features of video images, and the content description is not enough, which leads to the unsatisfactory Retrieval results. This paper studied how to combine the low-level features and semantic features of video, improved the existing index structure, and designed an efficient sports video retrieval algorithm. The experimental results show that the proposed algorithm can meet the real-time requirements and improve the accuracy and recall rate compared with the existing methods. In addition, the proposed sports video index combined with semantic features is better than the existing index in both query time and query results.
C1 [Guo, Cuixiang] Shandong Polytech, Jinan 250104, Peoples R China.
C3 Qilu University of Technology
RP Guo, CX (corresponding author), Shandong Polytech, Jinan 250104, Peoples R China.
EM guocuixiang@sdp.edu.cn
FU Social Science Planning Research Project of Shandong Province: Research
   on family Education problems and Countermeasures from the perspective of
   social Network [18CJYZ07]
FX This work is supported by Social Science Planning Research Project of
   Shandong Province: Research on family Education problems and
   Countermeasures from the perspective of social Network (grant no.
   18CJYZ07).
CR Ahmad J, 2018, COMPUT IND, V98, P23, DOI 10.1016/j.compind.2018.02.005
   Aljutaili D.S., 2018, INT J COMPUT INF SCI, V12, P346
   Basati Z, 2018, INT AGROPHYS, V32, P225, DOI 10.1515/intag-2017-0008
   Bin S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020482
   Bin S, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16234683
   Bougiatiotis K, 2018, EXPERT SYST APPL, V96, P86, DOI 10.1016/j.eswa.2017.11.050
   Chen ZX, 2017, IEEE T MULTIMEDIA, V19, P1996, DOI 10.1109/TMM.2017.2705918
   Ding Bin, 2013, Journal of Networks, V8, P1774, DOI 10.4304/jnw.8.8.1774-1780
   Ekin A, 2004, IEEE T MULTIMEDIA, V6, P839, DOI 10.1109/TMM.2004.837238
   Federolf P, 2014, SCAND J MED SCI SPOR, V24, P491, DOI 10.1111/j.1600-0838.2012.01455.x
   Franco A, 2007, MULTIMEDIA SYST, V12, P533, DOI 10.1007/s00530-006-0070-9
   Jian CF, 2018, TRAIT SIGNAL, V35, P243, DOI 10.3166/TS.35.243-252
   Kuo CM, 2010, INT J INNOV COMPUT I, V6, P2787
   Lei T, 2014, IET IMAGE PROCESS, V8, P44, DOI 10.1049/iet-ipr.2013.0062
   Montazer GA, 2017, NEURAL PROCESS LETT, V46, P681, DOI 10.1007/s11063-017-9614-6
   Mujtaba G, 2018, J BIOMED INFORM, V82, P88, DOI 10.1016/j.jbi.2018.04.013
   Naemura M, 2000, IEEE T BROADCAST, V46, P181, DOI 10.1109/11.892154
   Pan YS, 2018, MULTIMED TOOLS APPL, V77, P24891, DOI 10.1007/s11042-018-5712-3
   Singh V. P., 2018, INT J COMPUTATIONAL, V8, DOI [10.1504/IJCVR.2018.091979, DOI 10.1504/IJCVR.2018.091979]
   Sun GX, 2018, TRAIT SIGNAL, V35, P205
   Sun GX, 2018, MULTIMED TOOLS APPL, V77, P4295, DOI 10.1007/s11042-017-4766-y
   Wei BC, 2014, IEEE MULTIMEDIA, V21, P41, DOI 10.1109/MMUL.2013.65
   Zhu L, 2011, IET GENER TRANSM DIS, V5, P119, DOI 10.1049/iet-gtd.2010.0057
NR 23
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21941
EP 21955
DI 10.1007/s11042-020-10178-z
EA NOV 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000592635700001
DA 2024-07-18
ER

PT J
AU Kaur, S
   Aggarwal, H
   Rani, R
AF Kaur, Sukhpal
   Aggarwal, Himanshu
   Rani, Rinkle
TI Diagnosis of Parkinson's disease using deep CNN with transfer learning
   and data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson&apos; s disease; Generative Adversarial Network; Alex-Net;
   Transfer learning; Overfitting
ID CONVOLUTIONAL NEURAL-NETWORKS; DIFFERENTIAL-DIAGNOSIS; SELECTION
AB Parkinson's disease (PD) is one of the main types of neurological disorders affected by progressive brain degeneration. Early detection and prior care may help patients to improve their quality of life, although this neurodegenerative disease has no known cure. Magnetic Resonance (MR) Imaging is capable of detecting the structural changes in the brain due to dopamine deficiency in Parkinson's disease subjects. Deep learning algorithms provide cutting-edge results for various machine learning and computer vision tasks. We have proposed an approach to classify MR images of healthy and Parkinson's disease patients using deep convolution neural network. However, these algorithms require a large training dataset to perform well on a particular task. To this effect, we have applied a deep convolution neural network classifier that incorporates transfer learning and data augmentation techniques to improve the classification. To increase the size of training data, GAN-based data augmentation is used. A total of 504 images are collected, and 360 images are used to augment data. The increased data set of this model is as many as 4200 images, and the produced images are of good quality by using this data set for the detection of peak signal-to-noise ratio (PSNR) having an innovative value in the norm of real images. The pre-trained Alex-Net architecture helps in refining the diagnosis process. The MR images are trained and tested to provide accuracy measures through the transfer learned Alex-Net Model. The results are addressed to demonstrate that the fine-tuning of the final layers corresponds to an average classification accuracy of 89.23%. The experimental findings show that the proposed method offers an improved diagnosis of Parkinson's disease compared to state-of-the-art research.
C1 [Kaur, Sukhpal; Aggarwal, Himanshu] Punjabi Univ, Dept Comp Sci & Engn, Patiala 147002, Punjab, India.
   [Rani, Rinkle] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Punjabi University; Thapar Institute of Engineering & Technology
RP Kaur, S (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Patiala 147002, Punjab, India.
EM sukhpal91@gmail.com; himanshu.pup@gmail.com; raggarwal@thapar.edu
RI Aggarwal, Rinkle/AAT-4740-2020; Aggarwal, Himanshu/GOE-5647-2022
OI AGGARWAL, HIMANSHU/0000-0003-1782-8376
CR Aarsland D, 2016, PARKINSONISM RELAT D, V22, pS144, DOI 10.1016/j.parkreldis.2015.09.034
   Abas M.A.H., 2018, Int. J. Eng. Technol, V7, P90, DOI DOI 10.14419/IJET.V7I4.11.20781
   Abós A, 2017, SCI REP-UK, V7, DOI 10.1038/srep45347
   Abu Mallouh A, 2019, IMAGE VISION COMPUT, V88, P41, DOI 10.1016/j.imavis.2019.05.001
   Adeli E, 2016, NEUROIMAGE, V141, P206, DOI 10.1016/j.neuroimage.2016.05.054
   Amoroso N, 2018, MED IMAGE ANAL, V48, P12, DOI 10.1016/j.media.2018.05.004
   Babu GS, 2014, EXPERT SYST APPL, V41, P478, DOI 10.1016/j.eswa.2013.07.073
   Chaudhuri KR, 2009, LANCET NEUROL, V8, P464, DOI 10.1016/S1474-4422(09)70068-7
   Cigdem O, 2018, COMP PERFORMANCES PD
   Dawud AM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4629859
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Focke NK, 2011, HUM BRAIN MAPP, V32, P1905, DOI 10.1002/hbm.21161
   FOX SH, 2011, MOVEMENT DISORD S3
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gavrilov Andrei Dmitri, 2018, International Journal of Software Science and Computational Intelligence, V10, P19, DOI 10.4018/IJSSCI.2018100102
   Ghafoorian M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05300-5
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Gil David., 2009, Global Journal of Computer Science and Technology, V9, P63
   GU J, 2018, PATTERN RECOGN
   Hopes L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147947
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Islam J., 2017, Novel deep learning based multi-class classification method for alzheimer's disease detection using brain MRI data
   Jiang W, 2020, EURO J COMPUT OPTIM, V8, P85, DOI 10.1007/s13675-019-00115-7
   Kassani SH, 2019, I C INF COMM TECH CO, P519, DOI 10.1109/ictc46691.2019.8939878
   Kaur S, 2021, ADV INTELLIGENT SYST, P1164, DOI 10.1007/978-981-15-4992-2_30
   Kaur S, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01078-1
   Kaur S, 2019, J MED IMAG HEALTH IN, V9, P602, DOI 10.1166/jmihi.2019.2570
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Kokil Priyanka, 2019, IETE Journal of Education, V60, P14, DOI 10.1080/09747338.2019.1613936
   Kolar Z, 2018, AUTOMAT CONSTR, V89, P58, DOI 10.1016/j.autcon.2018.01.003
   Konidaris F, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P48, DOI 10.5220/0007363900480059
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Mak E, 2017, NEUROBIOL AGING, V55, P78, DOI 10.1016/j.neurobiolaging.2017.03.012
   Mäntylä MV, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P83, DOI 10.1145/2568225.2568245
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Motta D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234959
   Naseer A, 2020, NEURAL COMPUT APPL, V32, P839, DOI 10.1007/s00521-019-04069-0
   Pansombut T, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7519603
   Pereira CR, 2017, CONVOLUTIONAL NEURAL, DOI 10.1007/978-3-319-50478-019
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Poewe W, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.13
   Provost J.-S., 2015, Frontiers in Systems Neuroscience, V9
   Rana B, 2015, INT J IMAG SYST TECH, V25, P245, DOI 10.1002/ima.22141
   Rana B, 2015, EXPERT SYST APPL, V42, P4506, DOI 10.1016/j.eswa.2015.01.062
   Sakr GE, 2016, 2016 IEEE INTERNATIONAL MULTIDISCIPLINARY CONFERENCE ON ENGINEERING TECHNOLOGY (IMCET), P207, DOI 10.1109/IMCET.2016.7777453
   Salvatore C, 2014, J NEUROSCI METH, V222, P230, DOI 10.1016/j.jneumeth.2013.11.016
   Saranyaraj D, 2020, MULTIMED TOOLS APPL, V79, P11013, DOI 10.1007/s11042-018-6560-x
   Schlegl T, 2019, MED IMAGE ANAL, V54, P30, DOI 10.1016/j.media.2019.01.010
   Shams S, 2018, LECT NOTES COMPUT SC, V11071, P859, DOI 10.1007/978-3-030-00934-2_95
   Shinde S, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101748
   Singh G, 2015, J NEUROSCI METH, V256, P30, DOI 10.1016/j.jneumeth.2015.08.011
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Soltaninejad S, 2018, ABS180607489 ARXIV
   Tabanor K, 2016, MOL PHARMACEUT, V13, P379, DOI 10.1021/acs.molpharmaceut.5b00607
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Wang D, 2019, CELLULAR STRUCTURE I, DOI 10.1101/544130
   Wang SH, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00205
   Weng Y, 2019, IEEE ACCESS, V7, P64223, DOI 10.1109/ACCESS.2019.2917207
   Wu KB, 2018, NEUROCOMPUTING, V318, P102, DOI 10.1016/j.neucom.2018.08.036
   Xu J, 2019, CLIN EEG NEUROSCI, V50, P423, DOI 10.1177/1550059419865679
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yoo Y, 2019, KNOWL-BASED SYST, V178, P74, DOI 10.1016/j.knosys.2019.04.019
   Zhen X, 2017, PHYS MED BIOL, V62, P8246, DOI 10.1088/1361-6560/aa8d09
NR 63
TC 23
Z9 23
U1 5
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10113
EP 10139
DI 10.1007/s11042-020-10114-1
EA NOV 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590232700002
DA 2024-07-18
ER

PT J
AU Shreemali, U
   Chakraborty, A
AF Shreemali, Utkarsh
   Chakraborty, Anirban
TI Robust gait based human identification on incomplete and multi-view
   sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Gait based person recognition; Person
   re-identification; View invariance; Missing data
ID RECOGNITION; REPRESENTATION; IMAGE; MODEL
AB Gait based person identification is an important research area in the field of video surveillance. The major challenges faced by gait recognition systems in real-life scenarios include view variance, occlusion and resultant unavailability of a complete sequence containing a gait cycle. In this work, we propose a novel robust gait recognition framework capable of handling these challenges. We show how Gait-Energy-Images (GEIs) can be accurately constructed from largely incomplete input silhouette sequences. This provides an immediate advantage over current literature that assumes availability of complete sequences. We then highlight the shortcoming of most of the current view-invariant models that perform sub-optimal transformation of probe and gallery sequences captured in different views for comparison. We propose a model which jointly estimates and learns the optimal transformation for comparison of probe and gallery GEIs. Through extensive experiments, we show that our proposed framework is able to outperform most state-of-the-art methods on multiple benchmarks.
C1 [Shreemali, Utkarsh; Chakraborty, Anirban] Indian Inst Sci, Dept Computat & Data Sci, Bangalore, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Chakraborty, A (corresponding author), Indian Inst Sci, Dept Computat & Data Sci, Bangalore, Karnataka, India.
EM utkarshs@iisc.ac.in; anirban@iisc.ac.in
FU Pratiksha Trust, Bangalore; Start-up Research Grant (SRG) from SERB,
   DST, India [SRG/2019/001938]
FX This work is partially supported by 1. Pratiksha Trust, Bangalore and 2.
   Start-up Research Grant (SRG) from SERB, DST, India to Anirban
   Chakraborty (Project file number: SRG/2019/001938).
CR Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117582
   Babaee M, 2019, NEUROCOMPUTING, V338, P116, DOI 10.1016/j.neucom.2019.01.091
   Ballas Nicolas, 2015, ARXIV151106432
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Ben XY, 2012, NEUROCOMPUTING, V97, P44, DOI 10.1016/j.neucom.2012.06.022
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Boulgouris NV, 2007, PATTERN RECOGN, V40, P1763, DOI 10.1016/j.patcog.2006.11.012
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   De Marsico M, 2019, COMPUT ELECTR ENG, V80, DOI 10.1016/j.compeleceng.2019.106501
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   González I, 2016, J BIOMED INFORM, V62, P210, DOI 10.1016/j.jbi.2016.07.009
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Huang GB, 2004, IEEE IJCNN, P985
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Kyrarini M, 2015, IEEE INT SYM MED MEA, P375, DOI 10.1109/MeMeA.2015.7145231
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   López-Fernández D, 2016, IMAGE VISION COMPUT, V48-49, P1, DOI 10.1016/j.imavis.2016.01.003
   Luo J, 2020, IEEE ACCESS, V8, P32485, DOI 10.1109/ACCESS.2020.2973898
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Ma XY, 2017, PROCEEDINGS OF THE FOURTH INTERNATIONAL SYMPOSIUM - MANAGEMENT, INNOVATION & DEVELOPMENT, BK ONE & TWO, P300
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Marín-Jiménez MJ, 2017, IEEE IMAGE PROC, P106, DOI 10.1109/ICIP.2017.8296252
   Muramatsu D, 2014, P 20TH KOREA JAPAN J, P222
   Nandi GC, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1013, DOI 10.1109/TENCON.2016.7848159
   Ortells J, 2017, MACH VISION APPL, V28, P15, DOI 10.1007/s00138-016-0798-y
   Patil Prithvi., 2019, IEEE, P1, DOI DOI 10.1109/ICASERT.2019.8934463
   Phinyomark A, 2018, J MED BIOL ENG, V38, P244, DOI 10.1007/s40846-017-0297-2
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2018, IEEE T AUTOM SCI ENG, V15, P104, DOI 10.1109/TASE.2016.2594191
   Shiraga Kohei, 2016, ICB, P1, DOI DOI 10.1109/ICB.2016.7550060
   Sokolova A, 2017, ARXIV 1710 06512
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tang J, 2014, SENSORS-BASEL, V14, P6124, DOI 10.3390/s140406124
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
NR 55
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10141
EP 10166
DI 10.1007/s11042-020-10132-z
EA NOV 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590232700003
DA 2024-07-18
ER

PT J
AU Zangar, I
   Mnasri, Z
   Colotte, V
   Jouvet, D
AF Zangar, Imene
   Mnasri, Zied
   Colotte, Vincent
   Jouvet, Denis
TI Duration modelling and evaluation for Arabic statistical parametric
   speech synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parametric Arabic speech synthesis; Duration modelling; Deep neural
   network; Objective and subjective evaluation
ID SEGMENTAL DURATION; SYNTHESIS SYSTEM
AB Sound duration is responsible for rhythm and speech rate. Furthermore, in some languages phoneme length is an important phonetic and prosodic factor. For example, in Arabic, gemination and vowel quantity are two important characteristics of the language. Therefore, accurate duration modelling is crucial for Arabic TTS systems. This paper is interested in improving the modelling of phone duration for Arabic statistical parametric speech synthesis using DNN-based models. In fact, since a few years, DNN have been frequently used for parametric speech synthesis, instead of HMM. Therefore, several variants of DNN-based duration models for Arabic are investigated. The novelty consists in training a specific DNN model for each class of sounds, i.e. short vowels, long vowels, simple consonants and geminated consonants. The main idea behind this choice is the improvement that we already achieved in the quality of Arabic parametric speech synthesis by the introduction of two specific features of Arabic, i.e. gemination and vowel quantity into the standard HTS feature set. Both objective and subjective evaluations show that using a specific model for each class of sounds leads to a more accurate modelling of the phone duration in Arabic parametric speech synthesis, outperforming the state-of-the-art duration modelling systems.
C1 [Zangar, Imene; Mnasri, Zied] Univ Tunis El Manar, Dept Elect Engn, Ecole Natl Ingenieurs Tunis, BP 37, Tunis 1002, Tunisia.
   [Colotte, Vincent; Jouvet, Denis] Univ Lorraine, CNRS, INRIA, LORIA, F-54000 Nancy, France.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Lorraine; Inria; Centre National de la Recherche
   Scientifique (CNRS)
RP Mnasri, Z (corresponding author), Univ Tunis El Manar, Dept Elect Engn, Ecole Natl Ingenieurs Tunis, BP 37, Tunis 1002, Tunisia.
EM imene.zangar@enit.utm.tn; zied.mnasri@enit.utm.tn;
   vincent.colotte@loria.fr; denis.jouvet@loria.fr
FU CMCU (Comite mixte de cooperation universitaire) [15G1405]
FX This research work was conducted in the framework of PHC-Utique Program,
   financed by CMCU (Comite mixte de cooperation universitaire), grant
   No.15G1405.
CR Abdel-Hamid O, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1332
   Abdelmalek R, 2016, INT MULTICONF SYST, P1, DOI 10.1109/SSD.2016.7473681
   [Anonymous], 1999, P EUROSPEECH
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2020, WAVENET
   [Anonymous], 2016, THESIS
   [Anonymous], 2018, MERLIN TOOLKIT
   [Anonymous], 1975, STRUCTURE PROCESSP, DOI DOI 10.1007/978-3-642-81000-8_
   [Anonymous], 2018, HTS TOOLKIT
   Boukadida F, 2005, P SCI EL TEL INF TEC, P1
   Campbell WN, 1993, P EUR C SPEECH COMM, P1332
   Chen B, 2017, INTERSPEECH, P789, DOI 10.21437/Interspeech.2017-1144
   Chen B, 2017, INTERSPEECH, P794, DOI 10.21437/Interspeech.2017-1152
   DIMOLITSAS S, 1995, IEEE T SPEECH AUDI P, V3, P421, DOI 10.1109/89.466653
   DUTOIT T, 1993, SPEECH COMMUN, V13, P435, DOI 10.1016/0167-6393(93)90042-J
   Fernandez R, 2014, INTERSPEECH, P805
   Gao BY, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2266
   GRIFFIN DW, 1988, IEEE T ACOUST SPEECH, V36, P1223, DOI 10.1109/29.1651
   Halabi N, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P734
   Henter GE, 2016, INT CONF ACOUST SPEE, P5130, DOI 10.1109/ICASSP.2016.7472655
   Houidhek A., 2017, LTC 2017 - 8th Language Technology Conference, P1
   Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110
   Imai S., 1983, Electr. Commun. Jpn., V66, P10, DOI [DOI 10.1002/ECJA.4400660203, DOI 10.1002/ecja.4400660203]
   Ishimatsu Y, 2001, SP200181 IEICE
   Kawahara H, 1997, INT CONF ACOUST SPEE, P1303, DOI 10.1109/ICASSP.1997.596185
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Lazaridis A, 2014, EPFLREPORT198140
   Lu H, 2009, INT CONF ACOUST SPEE, P4033, DOI 10.1109/ICASSP.2009.4960513
   Mixdorff H, 2002, THESIS
   Mnasri Z, 2009, INT REV COMPUT SOFTW, V4, P533
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Moungsri D, 2017, INT CONF ACOUST SPEE, P5495, DOI 10.1109/ICASSP.2017.7953207
   Newman D., 1984, Journal of the American Oriental Society, V46, P1
   Ogbureke U, 2012, P SAPA SCALE C WORKS
   Pan S, 2011, P ANN SUMM C AS PAC
   Rao KS, 2007, COMPUT SPEECH LANG, V21, P282, DOI 10.1016/j.csl.2006.06.003
   Riedi M, 1997, P EUR 97, P2627
   Riley M.D., 1990, The ESCA Workshop on Speech Synthesis, P229
   Rosen KM, 2005, J PHONETICS, V33, P411, DOI 10.1016/j.wocn.2005.02.001
   RUBIN P, 1981, J ACOUST SOC AM, V70, P321, DOI 10.1121/1.386780
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Shinoda K., 1997, Proc. of EUROSPEECH, P99
   Silen H, 2010, P INT C SPEECH PROS, P1
   Sola J, 1997, IEEE T NUCL SCI, V44, P1464, DOI 10.1109/23.589532
   THORPE LA, 1993, IEEE WORKSH SPEECH C, P73
   VANSANTEN JPH, 1994, COMPUT SPEECH LANG, V8, P95, DOI 10.1006/csla.1994.1005
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   [吴义坚 WU Yijian], 2006, [中文信息学报, Journal of Chinese Information Processing], V20, P75
   Wu Z., 2016, P SSW, P202
   Yoshida T, 1998, INTERNATIONAL ELECTRON DEVICES MEETING 1998 - TECHNICAL DIGEST, P29, DOI 10.1109/IEDM.1998.746239
   Yu K, 2010, INT CONF ACOUST SPEE, P4238, DOI 10.1109/ICASSP.2010.5495690
   Zaki A, 2002, P JOURN ET PAR NANC, P89
   Zangar I., 2018, P INT C SPEECH PROS, P597, DOI DOI 10.21437/SPEECHPROSODY.2018-121
   Zen H., 2004, P INTERSPEECH 2004 I, P1393
   Zen HG, 2015, INT CONF ACOUST SPEE, P4470, DOI 10.1109/ICASSP.2015.7178816
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
NR 58
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8331
EP 8353
DI 10.1007/s11042-020-09901-7
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000584348700005
DA 2024-07-18
ER

PT J
AU Sayyouri, M
   Karmouni, H
   Hmimid, A
   Azzayani, A
   Qjidaa, H
AF Sayyouri, Mhamed
   Karmouni, Hicham
   Hmimid, Abdeslam
   Azzayani, Ayoub
   Qjidaa, Hassan
TI A fast and accurate computation of 2D and 3D generalized Laguerre
   moments for images analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generalized Laguerre polynomials; Generalized Laguerre moments; Matrix
   multiplication; Fast computation; 2D and 3D image reconstruction
ID FAST RECURSIVE COMPUTATION; GEOMETRIC MOMENTS; RECOGNITION; KRAWTCHOUK
AB In this paper, we will present a new set of 2D and 3D continuous orthogonal moments based on generalized Laguerre orthogonal polynomials (GLPs) for 2D and 3D image analysis. However, the computation of the generalized Laguerre orthogonal moments (GLMs) is limited by the problems of discretization of the continuous space of the polynomials, approximation of the integrals by finite sums and of too high computation time. To remedy these problems, we will propose a new method for the fast and the precise computation of 2D and 3D GLMs. This method is based on the development of an exact calculation of the double and triple integrals which define the 2D and 3D GLMs, and on the matrix calculation to accelerate the processing time of the images instead of the direct calculation. In addition to the theoretical results obtained, several experiments are carried out to validate the efficiency of the 2D and 3D GLMs descriptors in terms of computation precision and accuracy and in terms of acceleration of computation time and 2D/3D image reconstruction. The experimental results clearly show the advantages and the effectiveness of GLMs compared to the continuous orthogonal moments of Legendre, Chebyshev, Gegenbauer and Gaussian-Hermite.
C1 [Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Engn Syst & Applicat Lab, BP 72,My Abdallah Ave Km,5 Imouzzer Rd, Fes, Morocco.
   [Karmouni, Hicham; Hmimid, Abdeslam; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Dhar El Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
   [Azzayani, Ayoub] Mohammed 5 Univ, Fac Jurid Econ & Social Sci Sale, Finance Entrepreneurship & Dev Lab, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Mohammed V University in Rabat
RP Sayyouri, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Engn Syst & Applicat Lab, BP 72,My Abdallah Ave Km,5 Imouzzer Rd, Fes, Morocco.
EM mhamed.sayyouri@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   abdeslam_ph@yahoo.fr; ayoubsaha@gmail.com; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020; Azzayani, Ayoub/ABA-5051-2022; Karmouni,
   Hicham/ACB-0232-2022
OI Sayyouri, Mhamed/0000-0002-1615-419X; Azzayani,
   Ayoub/0000-0003-2869-2662; Karmouni, Hicham/0000-0001-9225-8380; Hassan,
   qjidaa/0000-0003-4505-5243
CR Abdulhussain SH, 2018, J MATH IMAGING VIS, V60, P285, DOI 10.1007/s10851-017-0758-9
   Abramowiz M, 1965, Hand Book of Mathematical Functions
   [Anonymous], 2017, MULTIMED TOOLS APPL
   Asli BHS, 2013, DIGIT SIGNAL PROCESS, V23, P1738, DOI 10.1016/j.dsp.2013.05.004
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   Benouini R, 2018, MULTIMED TOOLS APPL, P1
   Buchanan J., 1992, NUMERICAL METHODS AN
   Canterakis N., 1999, 11 SCAND C IM AN, P35
   El Ogri O, 2020, MULTIMED TOOLS APPL, V79, P23261, DOI 10.1007/s11042-020-09084-1
   Farokhi S, 2015, INFORM SCIENCES, V316, P234, DOI 10.1016/j.ins.2015.04.030
   Fu B, 2008, IMAGING SCI J, V56, P333, DOI 10.1179/174313108X299552
   Hosny KM, 2007, PATTERN RECOGN, V40, P3597, DOI 10.1016/j.patcog.2007.04.014
   Hosny KM, 2007, APPL MATH COMPUT, V189, P1214, DOI 10.1016/j.amc.2006.12.025
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P1305, DOI 10.1016/j.patrec.2011.03.011
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   Hosny KM, 2010, INFORM SCIENCES, V180, P2299, DOI 10.1016/j.ins.2010.02.006
   Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5
   Jahid T., 2018, J MATH IMAGING VIS, P1
   Jahid T, 2018, MULTIMED TOOLS APPL, P1
   Karmouni H., 2018, INT C ADV INT SYST S, P261
   Karmouni H., 2018, ADV INTELLIGENT SYST, V915
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5
   Long M, 2019, MULTIMED TOOLS APPL, V78, P489, DOI 10.1007/s11042-017-5101-3
   Mesbah A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061621
   Papakostas GA, 2008, PATTERN RECOGN, V41, P1895, DOI 10.1016/j.patcog.2007.11.015
   Sayyouri M, 2019, J REAL TIME IMAGE PR, P1
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Spiliotis IM, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013020
   Spiliotis IM, 2020, J PARALLEL DISTR COM, V137, P134, DOI 10.1016/j.jpdc.2019.11.006
   Upneja R, 2015, PATTERN RECOGN, V48, P1836, DOI 10.1016/j.patcog.2014.11.012
   Wee CY, 2007, IET COMPUT VIS, V1, P66, DOI 10.1049/iet-cvi:20070016
   Wu CH, 2001, PATTERN RECOGN, V34, P1319, DOI 10.1016/S0031-3203(00)00100-X
   Wu G, 2019, PATTERN RECOGN LETT, V128, P137, DOI 10.1016/j.patrec.2019.08.031
   Wu H, 2013, 2013 INTERNATIONAL CONFERENCE ON APPLIED SOCIAL SCIENCE (ICASS 2013), VOL 4, P120
   Xia T, 2007, J OPT SOC AM A, V24, P50, DOI 10.1364/JOSAA.24.000050
   Yang LR, 1996, PATTERN RECOGN, V29, P1061, DOI 10.1016/0031-3203(95)00147-6
   Zhang DY, 2017, J INF SECUR APPL, V36, P135, DOI 10.1016/j.jisa.2017.09.003
   Zhang DY, 2017, J VIS COMMUN IMAGE R, V48, P281, DOI 10.1016/j.jvcir.2017.07.006
   Zhang H, 2010, IEEE T IMAGE PROCESS, V19, P596, DOI 10.1109/TIP.2009.2036702
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9
NR 45
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7887
EP 7910
DI 10.1007/s11042-020-09921-3
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000001
DA 2024-07-18
ER

PT J
AU Zhou, JC
   Liu, ZZ
   Zhang, WD
   Zhang, DH
   Zhang, WS
AF Zhou, Jingchun
   Liu, Zhenzhen
   Zhang, Weidong
   Zhang, Dehuan
   Zhang, Weishi
TI Underwater image restoration based on secondary guided transmission map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image restoration; Underwater imaging; Guided filter; Auto
   level
ID ENHANCEMENT
AB The color distortion and low contrast of underwater images are caused by the absorption of light by water and the scattering of suspended particles. So, we propose an underwater image restoration method based on secondary guided transmission map, which can effectively restore the color, visibility and natural appearance of underwater image. We use improved guided filter to refine the transmission map. Firstly, the rough transmission map is decomposed into the basic image and the detail image by the guided filter. And then refined transmission map is reconstructed after processing the images respectively. Finally, auto level processing is conducted on the restored image to improve the contrast of the image. In order to evaluate the effectiveness of our method, qualitative and quantitative comparisons and application test are carried out. Experimental results demonstrate that compared with several state-of-the-art methods, the proposed method can get genuine color, natural appearance, and the improvement of visibility and contrast.
C1 [Zhou, Jingchun; Liu, Zhenzhen; Zhang, Weidong; Zhang, Dehuan; Zhang, Weishi] Dalian Maritime Univ, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Zhang, WS (corresponding author), Dalian Maritime Univ, Dalian, Peoples R China.
EM 630790387@qq.com; teesiv@dlmu.edu.cn
RI Zhang, Weidong/AAU-3038-2020; Zhou, Jingchun/AAF-6817-2019
OI Zhang, Weidong/0000-0003-2495-4469; Zhou, Jingchun/0000-0002-4111-6240
FU National Natural Science Foundation of China [61702074]; Liaoning
   Provincial Natural Science Foundation of China [20170520196];
   Fundamental Research Funds for the Central Universities [3132019354]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61702074, in part by the Liaoning
   Provincial Natural Science Foundation of China under Grant 20170520196,
   in part by the Fundamental Research Funds for the Central Universities
   under Grant 3132019205, and in part by the Fundamental Research Funds
   for the Central Universities under Grant 3132019354.
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He DM, 2004, OPT LASER ENG, V41, P217, DOI 10.1016/S0143-8166(02)00138-0
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hou WL, 2008, OPT EXPRESS, V16, P9958, DOI 10.1364/OE.16.009958
   Hu HF, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2791517
   Huang BJ, 2016, OPT EXPRESS, V24, P9826, DOI 10.1364/OE.24.009826
   [黄宇晴 Huang Yuqing], 2017, [北京航空航天大学学报, Journal of Beijing University of Aeronautics and Astronautics], V43, P592
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Lee HS, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081220
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2016, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2016.7532707
   Li JR, 2018, MULTIMED TOOLS APPL, V77, P10823, DOI 10.1007/s11042-017-5300-y
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Lu XK, 2018, MULTIMED TOOLS APPL, V77, P15521, DOI 10.1007/s11042-017-5131-x
   Ma D, 2022, INFORM TECHNOL DEV, V28, P297, DOI 10.1080/02681102.2020.1801566
   Mathias A, 2019, OPTIK, V192, DOI 10.1016/j.ijleo.2019.06.025
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Yang M, 2020, IEEE J OCEANIC ENG, V45, P521, DOI 10.1109/JOE.2018.2886093
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhou JC, 2019, IEEE ACCESS, V7, P122459, DOI 10.1109/ACCESS.2019.2934981
NR 32
TC 31
Z9 33
U1 3
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7771
EP 7788
DI 10.1007/s11042-020-10049-7
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000005
DA 2024-07-18
ER

PT J
AU Kumar, DM
   Satyanarayana, D
   Prasad, MNG
AF Kumar, D. Maruthi
   Satyanarayana, D.
   Prasad, M. N. Giri
TI An improved Gabor wavelet transform and rough K-means clustering
   algorithm for MRI brain tumor image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Preprocessing; Feature extraction; Gabor wavelet
   transform; Oppositional fruit fly algorithm; Rough K-means
ID CLASSIFICATION
AB Image processing is significant in the medical field which provides detailed information about medical images and image segmentation is an essential part of medical image processing. In the medical field, various modalities have been utilized such as X-ray, CT scan and MRI, etc. MRI provides accurate results than other techniques. Our proposed technique is highly focused on tumor identification using MRI image segmentation. The proposed methodology consists of five stages namely, pre-processing, feature extraction, feature selection, classification, and segmentation. Initially, input MRI images are given to the preprocessing stage to fit the images for further processing. In this preprocessing phase, the input images are converted into a transform domain with the aid of Improved Gabor Wavelet Transform (IGWT). Then, GLCM related features are extracted and important features are selected with the help of the Oppositional fruit fly algorithm (OFFA). Then, the selected features are given to the support vector machine (SVM) classifier to classify an image as normal or abnormal. After the classification process, the abnormal images are selected and given to the segmentation process. For segmentation, in this paper, we utilized an effective rough k-means algorithm. The performance of the proposed methodology is evaluated in terms of Sensitivity, Specificity, and Accuracy. The experimental results show that our proposed method attained better results compared to existing work.
C1 [Kumar, D. Maruthi; Prasad, M. N. Giri] Jawaharlal Nehru Technol Univ Anantapur, Dept ECE, Ananthapuramu, Andhra Pradesh, India.
   [Satyanarayana, D.] Rajeev Gandhi Mem Coll Engn & Technol, Dept ECE, Nandyal, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Kumar, DM (corresponding author), Jawaharlal Nehru Technol Univ Anantapur, Dept ECE, Ananthapuramu, Andhra Pradesh, India.
EM maruthikumar870@gmail.com
RI donti, satyanarayana/ABG-7737-2021
OI donti, satyanarayana/0000-0002-9453-2803
CR Al-Dmour H, 2018, NEUROCOMPUTING, V275, P546, DOI 10.1016/j.neucom.2017.08.051
   Angulakshmi M, 2018, J KING SAUD U COMP I
   [Anonymous], 2016, IOSR J ELECT COMMUN
   Bharathi R, 2015, INT J EMERG TECHNOL, V13, P560
   Borole V.Y., 2015, Int J Emerging Trends Technol Comput Sci, V4, P28, DOI [10.2749/IJETTCS.361.944, DOI 10.2749/IJETTCS.361.944]
   Chanchlani A, 2017, IMP J INTERDISCIP RE, V3
   Ergen B, 2014, P SCI WORLD J HIND P, P1
   Kaur G, 2016, INFINITE STUD, V6
   Kumaran N., 2013, INT J ADV RES SCI TE, V2, P2320
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Liu YH, 2012, J MED BIOL ENG, V32, P22, DOI 10.5405/jmbe.813
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mahajan Gunwanti S, INT J ADV ENG TECHNO, V6, P2531
   Malviya MAM., 2014, INT J ENG, V3, P53
   MANIKANDAN R, 2013, MIDDLE EAST J SCI RE, V14, P669, DOI DOI 10.5829/idosi.mejsr.2013.14.5.73122
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Noureen E., 2014, IOSR J ELECT ELECT E, V9, P14, DOI [10.9790/1676-09531419, DOI 10.9790/1676-09531419]
   Patel J., 2014, Adv. Electron. Electr. Eng, V4, P279
   Potdukhe B., 2016, INT J INNOV RES COMP, V4, P3025
   Sauwen N, 2016, NEUROIMAGE-CLIN, V12, P753, DOI 10.1016/j.nicl.2016.09.021
   Shingade S., 2017, TECHNIQUES, V4, P16
   Singh P., 2017, INT J ENG RES, V6, P261, DOI DOI 10.5958/2319-6890.2017.00015.0
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Verma R., 2015, INT J SCI ENG TECHNO, V4, P3710
NR 35
TC 20
Z9 20
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6939
EP 6957
DI 10.1007/s11042-020-09635-6
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583495800003
DA 2024-07-18
ER

PT J
AU Yang, WC
   Jiang, JJ
   Chen, CH
AF Yang, Wen-Chao
   Jiang, Jiajun
   Chen, Chung-Hao
TI A fast source camera identification and verification method based on
   PRNU analysis for use in video forensic investigations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source camera identification; Forensic science; Video forensic
   investigation; Photo-response non-uniformity
AB Due to the rapid development of digital and cloud technologies, everyone can easily shoot and spread digital videos via email or social media. However, it is difficult for law enforcement to trace the origin of those digital videos, while some videos or images containing illegal information such as personal privacy, obscene pornography, and national security-related content. Recently, a significant breakthrough is achieved by using Photo-Response Non-Uniformity (PRNU) noise to characterize the camera sensor. However, PRNU analysis is often carried out on a frame-by-frame basis. As a result, the processing time is unbearable when treating a large set of videos and devices. In this paper, we propose a novel video forensic method considering both cameras rolling and I-frame of videos to improve the processing time and accuracy. Experimental results demonstrate that our proposed method is at a minimum of 15 times on average faster than the most wildly used method, PRNU analysis, and reduce the false positive rate as compared to existing methods used in the field of the forensic examination.
C1 [Yang, Wen-Chao] Cent Police Univ, Dept Forens Sci, Taoyuan, Taiwan.
   [Jiang, Jiajun; Chen, Chung-Hao] Old Dominion Univ, Dept Elect & Comp Engn, Norfolk, VA USA.
C3 Old Dominion University
RP Yang, WC (corresponding author), Cent Police Univ, Dept Forens Sci, Taoyuan, Taiwan.
EM una135@mail.cpu.edu.tw
RI Jiang, Jiajun/AAA-5636-2020; Yang, Wen-Chao/JAO-2312-2023
OI Jiang, Jiajun/0000-0003-0250-8249; Yang, Wen-Chao/0000-0002-2120-2774
FU National Science Council, Taiwan, Republic of China [MOST
   107-2221-E-015-003-MY2, MOST 109-2221-E-015-002-]
FX This work on this paper was supported by the National Science Council,
   Taiwan, Republic of China (MOST 107-2221-E-015-003-MY2, MOST
   109-2221-E-015-002-).
CR Bestagini P, 2019, IEEE INT C IM PROC I
   Chen MY, 2007, INT J SECUR APPL, V1, P1
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cortiana A, 2011, PROC SPIE, V7880, DOI 10.1117/12.872489
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Du M., 2017, J Forensic Sci Med., V3, P139, DOI [DOI 10.4103/JFSM.JFSM_8_17, 10.4103/jfsm.jfsm817, DOI 10.4103/JFSM.JFSM817]
   Goljan M., 2016, Electronic Imaging, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.8.MWSF-086, DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-086]
   GOLJAN M., 2009, MEDIA FORENSICS SECU, V7254, DOI DOI 10.1117/12.805701
   Goljan M, 2012, PROC SPIE, V8303, DOI 10.1117/12.909659
   Iuliani M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030649
   Kang XG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-19
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Kivanc Mihcak M., 1999, Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 1999), V6, P3253, DOI DOI 10.1109/ICASSP.1999.757535
   Kurosawa K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P537, DOI 10.1109/ICIP.1999.817172
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   Li CT, 2012, IEEE T CIRC SYST VID, V22, P260, DOI 10.1109/TCSVT.2011.2160750
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Lin XF, 2016, IEEE T INF FOREN SEC, V11, P126, DOI 10.1109/TIFS.2015.2478748
   Lukas J., 2005, P IEEE INT C IM PROC, V3, P65
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   McCloskey S, 2008, IEEE COMP SOC C COMP, P23, DOI [10.1109/CVPRW.2008.4562986, DOI 10.1109/CVPRW.2008.4562986]
   Öktem R, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/42472
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Spy Blog-Watching Them Watching Us, 2019, OP ALG CHILD RAP CON
   Taspinar S, 2016, IEEE INT WORKS INFOR
   Wei-Hong Chuang, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1953, DOI 10.1109/ICIP.2011.6115855
   Yang WC, 2017, MICROB CELL FACT, V16, DOI 10.1186/s12934-017-0687-8
NR 27
TC 10
Z9 10
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6617
EP 6638
DI 10.1007/s11042-020-09763-z
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000582172700002
DA 2024-07-18
ER

PT J
AU Lee, DH
AF Lee, Dong-Hyun
TI CNN-based single object detection and tracking in videos and its
   application to drone detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Object tracking; Convolutional neural network; Drone
   detection
AB This paper presents convolutional neural network (CNN)-based single object detection and tracking algorithms. CNN-based object detection methods are directly applicable to static images, but not to videos. On the other hand, model-free visual object tracking methods cannot detect an object until a ground truth bounding box of the target is provided. Moreover, many annotated video datasets of the target object are required to train both the object detectors and visual trackers. In this work, three simple yet effective object detection and tracking algorithms for videos are proposed to efficiently combine a state-of-the-art object detector and visual tracker for circumstances in which only a few static images of the target are available for training. The proposed algorithms are tested using a drone detection task and the experimental results demonstrated their effectiveness.
C1 [Lee, Dong-Hyun] Kumoh Natl Inst Technol, Elect Engn, Dept IT Convergence Engn, Gumi, Gyeongbuk, South Korea.
C3 Kumoh National University Technology
RP Lee, DH (corresponding author), Kumoh Natl Inst Technol, Elect Engn, Dept IT Convergence Engn, Gumi, Gyeongbuk, South Korea.
EM donglee@kumoh.ac.kr
FU National Research Foundation of Korea (NRF) - Korean government (MIST)
   [2017R1C1B5017125, 2019R1F1A1040709]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MIST) (No.2017R1C1B5017125
   and No.2019R1F1A1040709)
CR Aker C, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2017.8078539
   [Anonymous], 2019, MINER PROCESS EXTR M
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Cheng L., 2019, METALL MAT T B, P1
   Coluccia A, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/AVSS.2019.8909876
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Hassanin AAIM, 2019, MULTIMED TOOLS APPL, V78, P34437, DOI 10.1007/s11042-019-08097-9
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kang K, 2017, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2017.101
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Kouicem DE, 2017, JOURNEE DOCTORANTS, P51
   Kristan M., 2019, P IEEE CVF INT C COM
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liu MS, 2018, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2018.00596
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Niu J., 2019, IEEE Transactions on Mobile Computing
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Park J, 2017, INT C CONTR AUTOMAT, P696, DOI 10.23919/ICCAS.2017.8204318
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rozantsev A, 2017, IEEE T PATTERN ANAL, V39, P879, DOI 10.1109/TPAMI.2016.2564408
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saqib M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/AVSS.2017.8078541
   Shi XF, 2018, IEEE COMMUN MAG, V56, P68, DOI 10.1109/MCOM.2018.1700430
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tasaka N, 2021, INT J CONTROL, V94, P1166, DOI 10.1080/00207179.2019.1637544
   Thai VP, 2019, INTEG COMMUN NAVIG, DOI 10.1109/icnsurv.2019.8735240
   Wang Y, 2019, MULTIMED TOOLS APPL, V78, P31633, DOI 10.1007/s11042-019-07851-3
   Wei XY, 2019, OCEANS-IEEE
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
NR 36
TC 19
Z9 20
U1 26
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34237
EP 34248
DI 10.1007/s11042-020-09924-0
EA OCT 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000577990600003
DA 2024-07-18
ER

PT J
AU Zhu, YX
   Zhang, MM
   Peng, YJ
   Asl, AB
AF Zhu, Yuxiang
   Zhang, Mingmin
   Peng, Yanjun
   Asl, Arsineh Boodaghian
TI Detailed wrinkle generation of virtual garments from a single image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image retrieval; Garment modeling; Wrinkle generation
AB The presence of proper wrinkles is important while modeling realistic virtual garments. Unlike previously used full 3D information methods, our approach achieves detailed garment generation from a single image. First, we retrieve a garment image similar to the initial virtual garment based on content-based image retrieval (CBIR) method. Then, we preprocess the image with a combination of human body reshaping, image segmentation and shape recovery, to obtain the 3D wrinkle details. Finally, the garment height are synthesized into the virtual garment. For better suit the posture of the human body, excess garment energy are released to remove the unmatched wrinkles. We apply our method to various styles of virtual garments, and it enable virtual characters in general pose to be dressed in these garments and complete wrinkle generation. Compared with existing garment modeling methods, the experimental results show that the proposed method could quickly capture the realistic wrinkles of virtual garments with less manual operation and achieve more realistic wrinkles for virtual garments.
C1 [Zhu, Yuxiang] Huanghuai Univ, Coll Informat Engn, Zhumadian 463000, Henan, Peoples R China.
   [Zhu, Yuxiang; Peng, Yanjun] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
   [Zhu, Yuxiang] Huanghuai Univ, Henan Prov Key Lab Smart Lighting, Zhumadian 463000, Henan, Peoples R China.
   [Zhang, Mingmin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Asl, Arsineh Boodaghian] Karlstad Univ, Informat Syst, Karlstad, Sweden.
C3 Huanghuai University; Shandong University of Science & Technology;
   Huanghuai University; Zhejiang University; Karlstad University
RP Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
EM pengyanjuncn@163.com
RI zhang, mm/IWV-4201-2023; Boodaghian Asl, Arsineh/T-2359-2019; Zhang,
   Miao/JXY-8985-2024
OI Boodaghian Asl, Arsineh/0000-0002-1985-3690; Zhu,
   Yuxiang/0000-0002-3567-7316
FU National Key Research and Development Program of China [2018YFB1004902];
   Natural Science Foundation of Shandong Province [ZR2017FM054]; National
   Natural Science Foundation of China [61976126]
FX This work is supported by the National Key Research and Development
   Program of China under Grant No. 2018YFB1004902, the Natural Science
   Foundation of Shandong Province under Grant No. ZR2019MF003, the Natural
   Science Foundation of Shandong Province under Grant No. ZR2017FM054, the
   National Natural Science Foundation of China under Grant No. 61976126.
CR Aguiar ED, 2010, ACM T GRAPHIC, V29, P106
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2010, P EUR C COMP VIS ECC
   Berthouzoz F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461975
   Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698
   Chen W, 2015, AUDITING-J PRACT TH, V34, P1, DOI 10.2308/ajpt-50986
   Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Guo JM, 2015, CNN BASED HASHING IM
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P721, DOI 10.1016/j.cad.2012.03.006
   Popa T, 2009, COMPUT GRAPH FORUM, V28, P427, DOI 10.1111/j.1467-8659.2009.01382.x
   Robson C, 2011, COMPUT GRAPH-UK, V35, P604, DOI 10.1016/j.cag.2011.03.002
   Rohmer D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866183
   Seddati O, 2017, IEEE INT CONF COMP V, P1246, DOI 10.1109/ICCVW.2017.150
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520
   Wang HM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201320
   Wang HM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778844
   Yang S, 2018, ACM T GRAPHIC, V37, P1
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Zhang MM, 2015, MULTIMED TOOLS APPL, V74, P3137, DOI 10.1007/s11042-013-1774-4
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou B, 2013, COMPUT GRAPH FORUM, V32, P85, DOI 10.1111/cgf.12215
   Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863
   Zhu YX, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/8069373
   Zurdo Javier S, 2012, IEEE T VISUALIZATION, V19, P149
NR 29
TC 1
Z9 1
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4053
EP 4071
DI 10.1007/s11042-020-09917-z
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572865900004
DA 2024-07-18
ER

PT J
AU Bakhshi, A
   Chalup, S
   Harimi, A
   Mirhassani, SM
AF Bakhshi, Ali
   Chalup, Stephan
   Harimi, Ali
   Mirhassani, Seyed Mostafa
TI Recognition of emotion from speech using evolutionary cepstral
   coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Mel filterbank; Cepstral coefficients; Speech emotion
   recognition
ID SPECTRAL FEATURES; FEATURE-EXTRACTION; NEURAL-NETWORK; CLASSIFICATION;
   ALGORITHM; FUSION; MFCC
AB An optimal representation of acoustic features is an ongoing challenge in automatic speech emotion recognition research. In this study, we proposed Cepstral coefficients based on evolutionary filterbanks as emotional features. It is difficult to guarantee that an individual optimized filterbank provides the best representation for emotion classification. Consequently, we employed six HMM-based binary classifiers that used a specific filterbank, which was optimized by a genetic algorithm to categorize the data into seven emotion classes. These optimized classifiers were applied in a hierarchical manner and outperformed conventional Mel Frequency Cepstral Coefficients in terms of overall emotion classification accuracy. The proposed method using evolutionary-based Cepstral coefficients achieved a weighted average recall of 87.29% on the Berlin database while the same approach but using conventional Cepstral features achieved only 79.63%.
C1 [Bakhshi, Ali; Chalup, Stephan] Univ Newcastle, Sch Elect Engn & Comp, Newcastle, NSW, Australia.
   [Harimi, Ali] Islamic Azad Univ, Dept Elect Engn, Shahrood Branch, Shahrood, Iran.
   [Mirhassani, Seyed Mostafa] Univ Malaya, Dept Biomed Engn, Kuala Lumpur, Malaysia.
C3 University of Newcastle; Islamic Azad University; Universiti Malaya
RP Bakhshi, A (corresponding author), Univ Newcastle, Sch Elect Engn & Comp, Newcastle, NSW, Australia.
EM ali.bakhshi@uon.edu.au; stephan.chalup@newcastle.edu.au;
   a.harimi@iau-shahrood.ac.ir; mostafamirhassani@gmail.com
RI CHALUP, STEPHAN KONRAD/G-7560-2013; Harimi, Ali/AAN-5438-2021; Bakhshi,
   Ali/AAH-9557-2021; Chalup, Stephan/A-9780-2008
OI Bakhshi, Ali/0000-0002-5408-0777; Chalup, Stephan/0000-0002-7886-3653
FU UNIPRS scholarship at The University of Newcastle
FX Ali Bakhshi was supported by a UNIPRS scholarship at The University of
   Newcastle for his PhD.
CR Aggarwal RK, 2012, INT J SPEECH TECHNOL, V15, P191, DOI 10.1007/s10772-012-9133-9
   Ananthapadmanaba T.V., 1982, SPEECH COMMUN, V1, P167, DOI [DOI 10.1016/0167-6393(82)90015-2, 10.1016/0167-6393(82)90015-2]
   Anne K., 2015, ACOUSTIC MODELING EM, DOI DOI 10.1007/978-3-319-15530-2_4
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, ARXIV170803920
   [Anonymous], 2005, DATABASE GERMAN EMOT
   [Anonymous], 2002, TOOLK HMM
   [Anonymous], 2007, 8 ANN C INT SPEECH C
   [Anonymous], 2013, INT J ADV ROBOT SYST, DOI DOI 10.5772/55403
   Arroabarren I, 2007, IEEE T AUDIO SPEECH, V15, P320, DOI 10.1109/TASL.2006.872607
   Back T, 1998, GENETIC ALGORITHMST
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Bao W, 2014, INT CONF SIGN PROCES, P583, DOI 10.1109/ICOSP.2014.7015071
   Batliner A., 2008, P SAT WORKSH LREC, V28
   Bitouk D, 2010, SPEECH COMMUN, V52, P613, DOI 10.1016/j.specom.2010.02.010
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Charbuillet C, 2009, SPEECH COMMUN, V51, P724, DOI 10.1016/j.specom.2009.01.005
   Charbuillet C, 2007, LECT NOTES ARTIF INT, V4885, P105
   Dandapat S, 2017, 23 NAT C COMM NCC, P1
   Dandapat S, 2016, 2016 INT C SIGN PROC, P1
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Demircan S, 2018, NEURAL COMPUT APPL, V29, P59, DOI 10.1007/s00521-016-2712-y
   Demuynck K, 1998, 5 INT C SPOK LANG PR
   Dua M, 2018, ENG SCI TECHNOL, V21, P389, DOI 10.1016/j.jestch.2018.04.005
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Graves A, 2014, END TO END SPEECH RE
   Grimm M, 2007, SPEECH COMMUN, V49, P787, DOI 10.1016/j.specom.2007.01.010
   Holland I.H., 1975, ADAPTATION NATURAL A
   Huang LX, 2011, J CENT SOUTH UNIV T, V18, P1595, DOI 10.1007/s11771-011-0877-1
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jackson P., 2014, Surrey audio-visual expressed emotion (savee) database
   JANKOWSKI CR, 1995, IEEE T SPEECH AUDI P, V3, P286, DOI 10.1109/89.397093
   John RDeller., 2000, DISCRETE TIME PROCES
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Kalinli O, 2016, INTERSPEECH, P3613, DOI 10.21437/Interspeech.2016-1557
   Kerkeni L., 2018, INT C AG ART INT ICA, V2, P175
   Khan A, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1017, DOI 10.1109/WiSPNET.2017.8299916
   Koduru A, 2020, INT J SPEECH TECHNOL, V23, P45, DOI 10.1007/s10772-020-09672-4
   Koolagudi K, 2013, ROBUST EMOTION RECOG
   Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
   Kwon OW, 2004, SIGNAL PROCESS, V84, P1005, DOI 10.1016/j.sigpro.2004.03.004
   Lalitha S, 2015, PROCEDIA COMPUT SCI, V70, P29, DOI 10.1016/j.procs.2015.10.020
   Li LF, 2013, INT CONF AFFECT, P312, DOI 10.1109/ACII.2013.58
   Likitha MS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2257, DOI 10.1109/WiSPNET.2017.8300161
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Lotjidereshgi R, 2017, INT CONF ACOUST SPEE, P5135, DOI 10.1109/ICASSP.2017.7953135
   Lugger M, 2008, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2008.4518767
   Milton A, 2014, COMPUT SPEECH LANG, V28, P727, DOI 10.1016/j.csl.2013.08.004
   Mirhassani SM, 2016, DIGIT SIGNAL PROCESS, V49, P116, DOI 10.1016/j.dsp.2015.11.004
   Pavao M, 2001, BMC CANCER, V1, DOI 10.1186/1471-2407-1-15
   Pohjalainen Jouni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P980, DOI 10.1109/ICASSP.2014.6853743
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Scherer S, 2007, CLASSIFIER FUSION EM
   Sekkate S, 2019, COMPUTERS, V8, DOI 10.3390/computers8040091
   Semwal N, 2017, IEEE INT C ID SEC BE, P1
   Shahzadi A, 2015, TURK J ELECTR ENG CO, V23, P2056, DOI 10.3906/elk-1302-90
   Shahzadi A, 2013, MALAYS J COMPUT SCI, V26, P140
   SHIRANI A, 2016, INT J IMAGE GRAPHICS, V8, P4
   Sinith MS, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P139, DOI 10.1109/RAICS.2015.7488403
   Skowronski MD, 2002, INT CONF ACOUST SPEE, P801
   Slaney M., 1998, Interval Res. Corp. Tech. Rep, V10, P1194
   Sreenivasa R, 2012, EMOTION RECOGNITION
   Story B. H., 2002, Acoustical Science and Technology, V23, P195, DOI 10.1250/ast.23.195
   Sun YX, 2017, MULTIMED TOOLS APPL, V76, P8305, DOI 10.1007/s11042-016-3487-y
   Sun YX, 2015, BIOMED SIGNAL PROCES, V18, P80, DOI 10.1016/j.bspc.2014.10.008
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Vignolo LD, 2011, APPL SOFT COMPUT, V11, P3419, DOI 10.1016/j.asoc.2011.01.012
   Vlasenko B, 2007, P INTERSPEECH COMB A
   Wen G, 2017, RANDOM DEEP BELIEF N
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Yang N, 2017, INT J SPEECH TECHNOL, V20, P27, DOI 10.1007/s10772-016-9364-2
   Yoon SA, 2019, MULTIMED TOOLS APPL, V78, P2345, DOI 10.1007/s11042-018-6329-2
   Yüncü E, 2014, INT C PATT RECOG, P773, DOI 10.1109/ICPR.2014.143
   Zaidan Noor Aina, 2016, Advances in Machine Learning and Signal Processing, MALSIP 2015. Proceedings: LNEE 387, P141, DOI 10.1007/978-3-319-32213-1_13
   Zao L, 2014, IEEE SIGNAL PROC LET, V21, P620, DOI 10.1109/LSP.2014.2311435
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang ZX, 2019, INT CONF ACOUST SPEE, P6705, DOI 10.1109/ICASSP.2019.8682896
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhou X, 2016, 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD), P841, DOI [10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0133, 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.42]
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 82
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35739
EP 35759
DI 10.1007/s11042-020-09591-1
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000570470200001
DA 2024-07-18
ER

PT J
AU Li, TY
   Bing, B
   Wu, XX
AF Li, Tianyu
   Bing, Bing
   Wu, Xinxiao
TI Boundary discrimination and proposal evaluation for temporal action
   proposal generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal action proposal generation; Temporal action localization;
   Action proposal evaluation
AB Temporal action proposal generation for temporal action localization aims to capture temporal intervals that are likely to contain actions from untrimmed videos. Prevailing bottom-up proposal generation methods locate action boundaries (the start and the end) with high classifying probabilities. But for many actions, motions at boundaries are not discriminative, which makes action segments and background segments be classified into boundary classes, thereby generating low-overlap proposals. In this work, we propose a novel method that generates proposals by evaluating the continuity of video frames, and then locates the start and the end with low continuity. Our method consists of two modules: boundary discrimination and proposal evaluation. The boundary discrimination module trains a model to understand the relationship between two frames and uses the continuity of frames to generate proposals. The proposal evaluation module removes background proposals via a classification network, and evaluates the integrity of proposals with probability features by an integrity network. Extensive experiments are conducted on two challenging datasets: THUMOS14 and ActivityNet 1.3, and the results demonstrate that our method outperforms the state-of-the-art proposal generation methods.
C1 [Li, Tianyu; Bing, Bing; Wu, Xinxiao] Beijing Inst Technol BIT, Beijing Lab Intelligent Informat Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
RP Wu, XX (corresponding author), Beijing Inst Technol BIT, Beijing Lab Intelligent Informat Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
EM 3120181002@bit.edu.cn; zhubing@bit.edu.cn; wuxinxiao@bit.edu.cn
FU Natural Science Foundation of China (NSFC) [61673062]
FX This work was supported in part by the Natural Science Foundation of
   China (NSFC) under grants No. 61673062.
CR Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gao J., 2017, ARXIV170704818
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Karaman S, 2014, ECCV THUMOS Workshop, V1, P5
   Kingma D. P., 2014, arXiv
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li L, 2019, PR ELECTROMAGN RES S, P4047, DOI [10.1109/PIERS-Spring46901.2019.9017829, 10.1109/piers-spring46901.2019.9017829]
   Lin T., 2017, P IEEE INT C COMP VI
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Mettes P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P427, DOI 10.1145/2671188.2749404
   Olszewska J. I., 2016, INT C AG ART INT, P302
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Oneata D., 2014, The lear submission at thumos
   Paszke Adam, 2017, Pytorch
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Singh G., 2016, ActivityNet Large Scale Activity Recognition Challenge
   Wang L, 2014, IEEE INT CONF VLSI
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Xiong Y., 2017, CoRR
   Yuan ZH, 2017, PROC CVPR IEEE, P3215, DOI 10.1109/CVPR.2017.342
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 40
TC 2
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2123
EP 2139
DI 10.1007/s11042-020-09703-x
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700008
DA 2024-07-18
ER

PT J
AU Sergio, GC
   Lee, M
AF Sergio, Gwenaelle Cunha
   Lee, Minho
TI Scene2Wav: a deep convolutional sequence-to-conditional SampleRNN for
   emotional scene musicalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sequence-to-conditional SampleRNN; Convolutional neural network; Deep
   recurrent neural network; Domain transformation; Emotional music
   generation
ID RECOGNITION
AB This paper presents Scene2Wav, a novel deep convolutional model proposed to handle the task of music generation from emotionally annotated video. This is important because when paired with the appropriate audio, the resulting music video is able to enhance the emotional effect it has on viewers. The challenge lies in transforming the video to audio domain and generating music. Our proposed encoder Scene2Wav uses a convolutional sequence encoder to embed dynamic emotional visual features from low-level features in the colour space, namely Hue, Saturation and Value. The decoder Scene2Wav is a proposed conditional SampleRNN which uses that emotional visual feature embedding as condition to generate novel emotional music. The entire model is fine-tuned in an end-to-end training fashion to generate a music signal evoking the intended emotional response from the listener. By taking into consideration the emotional and generative aspect of it, this work is a significant contribution to the field of Human-Computer Interaction. It is also a stepping stone towards the creation of an AI movie and/or drama director, which is able to automatically generate appropriate music for trailers and movies. Based on experimental results, this model can effectively generate music that is preferred to the user when compared to the baseline model and able to evoke correct emotions.
C1 [Sergio, Gwenaelle Cunha; Lee, Minho] Kyungpook Natl Univ, Sch Elect Engn, 80 Daehakro, Daegu 41566, South Korea.
C3 Kyungpook National University
RP Lee, M (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, 80 Daehakro, Daegu 41566, South Korea.
EM gwena.cs@gmail.com; mholee@gmail.com
OI Lee, Minho/0000-0002-0441-7087
CR [Anonymous], 2006, UNDERSTANDING EMOTIO
   [Anonymous], 2018, ARXIV180808311
   [Anonymous], 2016, arXiv
   Bravo F, 2012, INT S COMP MUS MOD R, P366
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Çevikalp H, 2017, SIG PROCESS COMMUN
   Chang JD, 2010, J COMPUT, V20, P63
   Cho K., 2014, ARXIV14061078
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Heinichen JohannDavid., 1728, GEN BASS COMPOSITION
   Ishiguro MA, 2010, THESIS
   Jaimovich J., 2012, International Symposium on Computer Music Modeling and Retrieval, P19, DOI [DOI 10.1007/978-3-642-41248-6_2, DOI 10.1007/978-3-642-41248-6]
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Manocha P, 2020, INTERSPEECH, P2852, DOI 10.21437/Interspeech.2020-1191
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Morriss-Kay GM, 2010, J ANAT, V216, P158, DOI 10.1111/j.1469-7580.2009.01160.x
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Neubig G, 2017, ARXIV170301619
   Oord A., 2016, ARXIV160903499
   Savage TM., 2013, An Introduction to digital Multimedia: Jones
   Schubart CFD, 1806, CHRIST FRIED DAN SCH
   Sergio GC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8478527
   Sergio GC, 2016, LECT NOTES COMPUT SC, V9948, P74, DOI 10.1007/978-3-319-46672-9_9
   Sergio Gwenaelle Cunha, 2018, 2018 INT JOINT C NEU, P1
   Shan MK, 2009, EXPERT SYST APPL, V36, P7666, DOI 10.1016/j.eswa.2008.09.042
   Singh J. F., 2012, PAINT2SOUND
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Sotelo J., 2017, Char2wav: End-to-end speech synthesis
   Steblin Rita., 2005, HIST KEY CHARACTERIS
   Ullrich K., 2017, P INT SOC MUSIC INFO
   van der Wel E, 2017, ARXIV170704877
   van der Zwaag MD, 2009, 3 INT C AFF COMP INT, P1
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang ZQ, 2017, CHIN CONTR CONF, P11104, DOI 10.23919/ChiCC.2017.8029130
   Yang XS, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293876
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Zhang Q, 2012, NEUROCOMPUTING, V86, P33, DOI 10.1016/j.neucom.2011.12.034
   Zhang Q, 2012, COGN SYST RES, V14, P37, DOI 10.1016/j.cogsys.2010.12.012
   Zhao W, 2014, INT CONF PERVAS COMP, P1
   Zlatintsi A, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0194-1
NR 43
TC 3
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1793
EP 1812
DI 10.1007/s11042-020-09636-5
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100004
DA 2024-07-18
ER

PT J
AU Gruosso, M
   Capece, N
   Erra, U
AF Gruosso, Monica
   Capece, Nicola
   Erra, Ugo
TI Human segmentation in surveillance video with deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Image processing;
   Background subtraction; Semantic segmentation
ID SEMANTIC SEGMENTATION
AB Advanced intelligent surveillance systems are able to automatically analyze video of surveillance data without human intervention. These systems allow high accuracy of human activity recognition and then a high-level activity evaluation. To provide such features, an intelligent surveillance system requires a background subtraction scheme for human segmentation that captures a sequence of images containing moving humans from the reference background image. This paper proposes an alternative approach for human segmentation in videos through the use of a deep convolutional neural network. Two specific datasets were created to train our network, using the shapes of 35 different moving actors arranged on background images related to the area where the camera is located, allowing the network to take advantage of the entire site chosen for video surveillance. To assess the proposed approach, we compare our results with an Adobe Photoshop tool called Select Subject, the conditional generative adversarial network Pix2Pix, and the fully-convolutional model for real-time instance segmentation Yolact. The results show that the main benefit of our method is the possibility to automatically recognize and segment people in videos without constraints on camera and people movements in the scene (Video, code and datasets are available at http://graphics.unibas.it/www/HumanSegmentation/index.md.html).
C1 [Gruosso, Monica; Erra, Ugo] Univ Basilicata, Dept Math Comp Sci & Econ, Potenza, Italy.
   [Capece, Nicola] Univ Basilicata, Sch Engn, Potenza, Italy.
C3 University of Basilicata; University of Basilicata
RP Erra, U (corresponding author), Univ Basilicata, Dept Math Comp Sci & Econ, Potenza, Italy.
EM monica.gruosso@unibas.it; nicola.capece@unibas.it; ugo.erra@unibas.it
RI Gruosso, Monica/AAC-5804-2021; Capece, Nicola/U-1110-2019; Erra,
   Ugo/X-3889-2019
OI Gruosso, Monica/0000-0001-9609-8919; Capece, Nicola/0000-0002-1544-3977;
   Erra, Ugo/0000-0003-2942-7131
FU Universita degli Studi della Basilicata within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi della Basilicata
   within the CRUI-CARE Agreement.
CR Abbas Q, 2018, MULTIMED TOOLS APPL, V77, P20415, DOI 10.1007/s11042-017-5438-7
   Anthimopoulos M, 2019, IEEE J BIOMED HEALTH, V23, P714, DOI 10.1109/JBHI.2018.2818620
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banterle F, 2012, COMPUT GRAPH FORUM, V31, P19, DOI 10.1111/j.1467-8659.2011.02078.x
   Batenburg KJ, 2009, IEEE T MED IMAGING, V28, P676, DOI 10.1109/TMI.2008.2010437
   Bhole C, 2016, IMAGE VISION COMPUT, V51, P58, DOI 10.1016/j.imavis.2016.04.007
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Capece N, 2019, SIGNAL PROCESS-IMAGE, V77, P28, DOI 10.1016/j.image.2019.05.013
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Ess A, 2009, BMVC, V1, P2
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fernández-Caballero A, 2011, EXPERT SYST APPL, V38, P2577, DOI 10.1016/j.eswa.2010.08.047
   Ge F, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762250
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gruosso M, 2019, INT CONF COGN INFO, P137, DOI [10.1109/CogInfoCom47531.2019.9089897, 10.1109/coginfocom47531.2019.9089897]
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   He K., 2011, CVPR, P2049, DOI DOI 10.1109/CVPR.2011.5995495
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hernandez A., 2010, Computer Vision and Pattern Recognition Workshop, P33
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang F, 2018, NEURAL COMPUT APPL, V29, P1257, DOI 10.1007/s00521-017-3158-6
   Karacan L, 2015, IEEE I CONF COMP VIS, P424, DOI 10.1109/ICCV.2015.56
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kenney J, 2009, IEEE INT CONF ROBOT, P1343
   Kingma D. P., 2014, arXiv
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maggiori E, 2017, INT GEOSCI REMOTE SE, P5157, DOI 10.1109/IGARSS.2017.8128163
   Migniot C., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3149, DOI 10.1109/ICIP.2011.6116335
   Morar Anca, 2012, 2012 IEEE 8 INT C IN, P213, DOI DOI 10.1109/ICCP.2012.6356188
   Nam Y, 2012, MULTIMED TOOLS APPL, V57, P315, DOI 10.1007/s11042-010-0677-x
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Novikov AA, 2018, IEEE T MED IMAGING, V37, P1865, DOI 10.1109/TMI.2018.2806086
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Rosenblatt F., 1961, AD0256582 CORN AER L
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sasaki Y., 2007, Teach Tutor Mater, V1, P1
   Sengupta S, 2020, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR42600.2020.00236
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song CF, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P474, DOI 10.1109/ACPR.2015.7486548
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Tesema FB, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE (ICCAI 2018), P98, DOI 10.1145/3194452.3194471
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tseng YH, 2018, IEEE POSITION LOCAT, P1047, DOI 10.1109/PLANS.2018.8373485
   Vineet V, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.80
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang SH, 2019, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2019.00098
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083
   Zhao T, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P9, DOI 10.1109/MOTION.2002.1182207
   Zhao WQ, 2019, IEEE T SYST MAN CY-S, V49, P1254, DOI 10.1109/TSMC.2017.2724440
   Zhou Y. T., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P71, DOI 10.1109/ICNN.1988.23914
NR 66
TC 29
Z9 29
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1175
EP 1199
DI 10.1007/s11042-020-09425-0
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566665500004
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Krishna, O
   Aizawa, K
   Irie, G
AF Krishna, Onkar
   Aizawa, Kiyoharu
   Irie, Go
TI Computational attention model for children, adults and the elderly
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency; Eye-tracking; Human visual system; Fixation dispersion; Depth
   bias
ID SALIENT OBJECT DETECTION; VISUAL-ATTENTION; EYE-MOVEMENTS; SCENE;
   MATURATION; CHILDHOOD; SCANPATHS; MECHANISM; AGE
AB Computational models of saliency estimation have been studied in a wide range of research fields, including visual perception, image processing, computer vision, multimedia, and their intersections. However, most of them seek to simulate scene viewing by adults only, and the impact of observer's age has rarely been considered. In this paper, we quantitatively analyze age-related differences in gaze landing positions during scene viewing. From the results, we draw the following three conclusions: child observers focus more on the foreground in a scene, i.e., locations that are near, while elderly observers tend to explore the background, i.e., locations farther in the scene; adult observers are more explorative than child and elder ones; and adult observers have significantly lower center bias compared to child and elderly observers. Based on these observations, we developed a novel computational model for age-dependent saliency estimation. The prediction accuracy suggests that our model better fits collected eye-gaze data of observers belonging to different age groups than several existing models do.
C1 [Krishna, Onkar; Aizawa, Kiyoharu] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
   [Krishna, Onkar; Irie, Go] NTT Corp, NTT Commun Sci Labs, Yokohama, Kanagawa, Japan.
C3 University of Tokyo; Nippon Telegraph & Telephone Corporation
RP Krishna, O (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.; Krishna, O (corresponding author), NTT Corp, NTT Commun Sci Labs, Yokohama, Kanagawa, Japan.
EM onkarkris@gmail.com; aizawa@hal.t.u-tokyo.ac.jp; goirie@ieee.org
FU JST CREST [JPMJCR1686]
FX We thank Dr. Alpher Ack for providing the gaze data used in this study.
   This work is supported by JST CREST, JPMJCR1686.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Açik A, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00207
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Berga D, 2018, ARXIV181106308
   Beurskens R, 2012, EXP BRAIN RES, V217, P117, DOI 10.1007/s00221-011-2978-3
   Binda P, 2018, ANNU REV VIS SCI, V4, P193, DOI 10.1146/annurev-vision-091517-034317
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Dowiasch S, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00046
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Edwards JD, 2006, ARCH CLIN NEUROPSYCH, V21, P275, DOI 10.1016/j.acn.2006.03.001
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Gautier J, 2012, COGN COMPUT, V4, P141, DOI 10.1007/s12559-012-9138-3
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Helo A, 2014, VISION RES, V103, P83, DOI 10.1016/j.visres.2014.08.006
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jansen L, 2009, J VISION, V9, DOI 10.1167/9.1.29
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2011, J VISION, V11, DOI 10.1167/11.4.14
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kirkorian HL, 2017, CHILD DEV, V88, P1284, DOI 10.1111/cdev.12651
   Krishna O, 2018, GAZE DISTRIBUTION AN, V13
   Krishna O., 2017, ELECT IMAGING, V2017, P224
   Krishna O, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119885
   Krishna O, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1917, DOI 10.1109/ICASSP.2018.8461773
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kummerer M., 2014, ARXIV14111045
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Le Meur O, 2017, IEEE T IMAGE PROCESS, V26, P4777, DOI 10.1109/TIP.2017.2722238
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Leifman G, 2017, IEEE I CONF COMP VIS, P1707, DOI 10.1109/ICCV.2017.188
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu XQ, 2018, IEEE T IMAGE PROCESS, V27, P106, DOI 10.1109/TIP.2017.2755766
   Luna B, 2004, CHILD DEV, V75, P1357, DOI 10.1111/j.1467-8624.2004.00745.x
   Ma CY, 2015, J VISION, V15, DOI 10.1167/15.6.19
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Polat Uri, 2012, SCI REPORTS, V2, P1
   Rogé J, 2005, INVEST OPHTH VIS SCI, V46, P1774, DOI 10.1167/iovs.04-0540
   Sekuler AB, 2000, EXP AGING RES, V26, P103, DOI 10.1080/036107300243588
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Strenk SA, 2005, PROG RETIN EYE RES, V24, P379, DOI 10.1016/j.preteyeres.2004.11.001
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   VELICHKOVSKY B, 1996, ADV PSYCHOL, V116, P125, DOI 10.1016/S0166-4115(96)80074-4
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423
   Wilming N, 2017, SCI DATA, V4, DOI 10.1038/sdata.2016.126
   WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774
   Ygge J, 2005, ANN NY ACAD SCI, V1039, P480, DOI 10.1196/annals.1325.049
   Zhang L., 2016, IEEE T CYBERNETICS, V47, P3243
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
NR 63
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1055
EP 1074
DI 10.1007/s11042-020-09474-5
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566665500002
DA 2024-07-18
ER

PT J
AU Rashmi, BS
   Nagendraswamy, HS
AF Rashmi, B. S.
   Nagendraswamy, H. S.
TI Video shot boundary detection using block based cumulative approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block; Cumulative; Fuzzy set; Gradient; Histogram; Relative Standard
   Deviation; Threshold; Shot boundary detection
ID SCENE CHANGE DETECTION; EDGE-DETECTION
AB Video data is becoming an indispensable part of today's Big Data due to evolution of social web and mobile technology. Content based video analysis has become crucial for video management. Shot boundary detection is one of the most essential task in video content analysis. In view of this, an efficient shot boundary detection approach to detect abrupt and gradual transition in videos is proposed in this work. The approach extracts block based Mean Cumulative Sum Histogram (MCSH) from each edge gradient fuzzified frame as a combination of local and global feature. The relative standard deviation (RSD) statistical measure is applied on the obtained MCSH to detect abrupt and gradual shots in the video. Efficacy of the proposed method is measured by conducting experiments on TRECVID 2001, TRECVID 2007 and VideoSeg datasets. The proposed method shows relatively a good performance when compared to some of the state-of-the-art shot boundary detection approaches.
C1 [Rashmi, B. S.; Nagendraswamy, H. S.] Univ Mysore, DoS Comp Sci, Mysore 570006, Karnataka, India.
   [Rashmi, B. S.] Karnataka State Open Univ, Dept Informat Technol, Mysore 570006, Karnataka, India.
C3 University of Mysore
RP Rashmi, BS (corresponding author), Univ Mysore, DoS Comp Sci, Mysore 570006, Karnataka, India.; Rashmi, BS (corresponding author), Karnataka State Open Univ, Dept Informat Technol, Mysore 570006, Karnataka, India.
EM rashmibsrsh@compsci.uni-mysore.ac.in
RI S, Rashmi B/ABN-9247-2022
OI S, Rashmi B/0009-0008-7919-0594
CR Abdesselam Abdelhamid, 2013, Lecture Notes on Software Engineering, V1, P360, DOI 10.7763/LNSE.2013.V1.77
   Abdulhussain SH, 2019, MULTIMED TOOLS APPL, V78, P20361, DOI 10.1007/s11042-019-7364-3
   Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   Adjeroh D, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/859371
   Alshennawy A.A., 2009, Int. J. Comput. Inform. Eng., V3, P540
   [Anonymous], 2017, IJCAI
   [Anonymous], 2003, NOTEBOOK PAPERS TREC
   [Anonymous], 2016, COMPUT INTELL NEUROS
   barkhoda Wafa, 2009, Proceedings of the 2009 International Multiconference on Computer Science and Information Technology (IMCSIT), P7, DOI 10.1109/IMCSIT.2009.5352742
   Bezdek JC, 1998, IEEE T FUZZY SYST, V6, P52, DOI 10.1109/91.660808
   Bhaumik H, 2017, Intelligent Analysis of Multimedia Information, P282, DOI 10.4018/978-1-5225-0498-6.ch011
   Bhaumik H, 2016, APPL SOFT COMPUT, V46, P1008, DOI 10.1016/j.asoc.2016.03.022
   Camarena JG, 2010, PATTERN RECOGN LETT, V31, P1842, DOI 10.1016/j.patrec.2010.01.008
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dadashi R, 2013, COMPUT VIS IMAGE UND, V117, P807, DOI 10.1016/j.cviu.2013.03.002
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   Ford RM, 2000, MULTIMEDIA SYST, V8, P37, DOI 10.1007/s005300050003
   Gygli M., 2018, 2018 INT C CONT BAS, P1
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Hassanien A., 2017, Large-scale, fast and accurate shot boundary detection through spatio-temporal convolutional neural networks
   Heng WJ, 2001, J VIS COMMUN IMAGE R, V12, P217, DOI 10.1006/jvci.2001.0457
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jadon RS, 2001, PATTERN RECOGN LETT, V22, P1359, DOI 10.1016/S0167-8655(01)00041-1
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   Jiang XH, 2013, NEUROCOMPUTING, V116, P102, DOI 10.1016/j.neucom.2011.11.037
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Lee MH, 2006, EXPERT SYST APPL, V31, P13, DOI 10.1016/j.eswa.2005.09.031
   Lee MS, 2001, PATTERN RECOGN, V34, P711, DOI 10.1016/S0031-3203(00)00007-8
   Li ZJ, 2016, PROCEEDINGS 2016 FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2016), P15, DOI 10.1109/ICMIP.2016.24
   Lian SG, 2011, SOFT COMPUT, V15, P469, DOI 10.1007/s00500-009-0527-9
   Lopez-Molina C, 2011, COMPUT VIS IMAGE UND, V115, P1571, DOI 10.1016/j.cviu.2011.07.003
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Mahmoud MS, 2017, FUZZY CONTROL ESTIMA
   Melin P, 2010, EXPERT SYST APPL, V37, P8527, DOI 10.1016/j.eswa.2010.05.023
   Cirne MVM, 2018, MULTIMED TOOLS APPL, V77, P857, DOI 10.1007/s11042-016-4300-7
   PAL SK, 1983, IEEE T PATTERN ANAL, V5, P69, DOI 10.1109/TPAMI.1983.4767347
   Perez-Ornelas F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131161
   Prasertsakul P, 2020, MULTIMED TOOLS APPL, V79, P17403, DOI 10.1007/s11042-019-08378-3
   Prewitt J.M.S., 1970, OBJECT ENHANCEMENT E
   Priya GGL, 2012, PROC TECH, V1, P247, DOI 10.1016/j.protcy.2012.10.030
   Qing-Ge Ji, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P273, DOI 10.1109/PCSPA.2010.73
   Rashmi B. S., 2018, International Journal of Computer Vision and Image Processing, V8, P27, DOI 10.4018/IJCVIP.2018040102
   Rashmi BS, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P201, DOI 10.1109/ICACCI.2016.7732047
   Rashmi BS, 2016, P INT C INF AN, P69
   Sasithradevi A, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102754
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Sobel I., 1968, STANF ART PROJ, P271
   Stanchev P.L., 2003, INT J INF THEORIES A, V10, P363
   Tao D, 2009, SEMANTIC MINING TECH
   Thounaojam DM, 2017, INT J MULTIMED INF R, V6, P167, DOI 10.1007/s13735-017-0123-1
   Tizhoosh HR, 2002, 2002 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY PROCEEDINGS, P239, DOI 10.1109/NAFIPS.2002.1018062
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang D, 2001, LECT NOTES COMPUT SC, V2195, P63
   Zhang DC, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023029
   Zheng J, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P266, DOI 10.1109/ISIMP.2004.1434051
NR 59
TC 17
Z9 17
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 641
EP 664
DI 10.1007/s11042-020-09697-6
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566043200003
DA 2024-07-18
ER

PT J
AU Kulshreshtha, P
   Guha, T
AF Kulshreshtha, Prakhar
   Guha, Tanaya
TI Dynamic character graph via online face clustering for movie analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online clustering; Face clustering; Media content analysis; Character
   graph; Narrative structure
ID REPRESENTATION; TRACKING
AB An effective approach to automated movie content analysis involves building a network (graph) of its characters. Existing work usually builds a static character graph to summarize the content using metadata, scripts or manual annotations. We propose an unsupervised approach to building adynamiccharacter graph that captures the temporal evolution of character interaction. We refer to this as thecharacter interaction graph(CIG). Our approach has two components: (i) an online face clustering algorithm that discovers the characters in the video stream as they appear, and (ii) simultaneous creation of a CIG using the temporal dynamics of the resulting clusters. We demonstrate the usefulness of the CIG for two movie analysis tasks: narrative structure (acts) segmentation and major character retrieval. Our evaluation on full-length movies containing more than 5000 face tracks shows that the proposed approach achieves superior performance for both the tasks.
C1 [Kulshreshtha, Prakhar] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Guha, Tanaya] Univ Warwick, Coventry, W Midlands, England.
C3 Carnegie Mellon University; University of Warwick
RP Guha, T (corresponding author), Univ Warwick, Coventry, W Midlands, England.
EM pkulshre@andrew.cmu.edu; tanaya.guha@warwick.ac.uk
OI Guha, Tanaya/0000-0003-2167-4891
CR Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P4381, DOI 10.1109/TIP.2015.2463223
   Cinbis RG, 2011, IEEE I CONF COMP VIS, P1559, DOI 10.1109/ICCV.2011.6126415
   Du M, 2012, LECT NOTES COMPUT SC, V7578, P167, DOI 10.1007/978-3-642-33786-4_13
   Everingham M., 2006, HELLO MY NAME IS BUF
   Field Syd., 2007, Screenplay: The foundations of screenwriting
   Guha T, 2015, INT CONF ACOUST SPEE, P2264, DOI 10.1109/ICASSP.2015.7178374
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kulshreshtha P, 2018, IEEE IMAGE PROC, P2670, DOI 10.1109/ICIP.2018.8451343
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   McKee R., 1997, SUBSTANCE STRUCTURE
   Mitra A, 2014, ARXIV14096080
   Mitra A, 2017, IEEE T PATTERN ANAL, V39, P430, DOI 10.1109/TPAMI.2016.2557785
   Park SB, 2012, MULTIMED TOOLS APPL, V59, P601, DOI 10.1007/s11042-011-0725-1
   Ramakrishna A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1669, DOI 10.18653/v1/P17-1153
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharff Stefan., 1982, The Elements of Cinema: Toward a Theory of Cinesthetic Impact
   Sharma V, 2017, SIMPLE EFFECTIVE TEC
   Shun Zhang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P497, DOI 10.1007/978-3-319-48890-5_49
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tran QD, 2015, J UNIVERS COMPUT SCI, V21, P796
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wu BY, 2017, PATTERN RECOGN, V64, P361, DOI 10.1016/j.patcog.2016.10.022
   Wu BY, 2013, IEEE I CONF COMP VIS, P2856, DOI 10.1109/ICCV.2013.355
   Wu BY, 2013, PROC CVPR IEEE, P3507, DOI 10.1109/CVPR.2013.450
   Xiao SJ, 2014, LECT NOTES COMPUT SC, V8694, P123, DOI 10.1007/978-3-319-10599-4_9
   Yeh MC, 2014, IEEE MULTIMEDIA, V21, P22, DOI 10.1109/MMUL.2014.24
   Zhang ZP, 2016, LECT NOTES COMPUT SC, V9907, P236, DOI 10.1007/978-3-319-46487-9_15
NR 30
TC 2
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33103
EP 33118
DI 10.1007/s11042-020-09449-6
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000002
OA hybrid
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Liu, SJ
   Sun, R
   Fang, LG
   Yu, B
AF Fu, Zhengxin
   Liu, Sijia
   Sun, Rui
   Fang, Liguo
   Yu, Bin
TI Distributed color QR code with high-capability and fast decoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color QR code; Standard QR code decoder; Secret sharing; Set threshold;
   High reading efficiency; High secret storage capacity
AB Considering incompatibility between the color QR code and the standard QR code decoder and insecurity of information storage in the open network environment, this paper proposes a distributed color QR code by analyzing the decoding process of the QR code, which employs the Shamir's (k,n) secret sharing algorithm to ensure the security of the secret information and sets threshold to achieve compatibility with the standard decoder. Furthermore, we analyze the influence of threshold values on the performance of the proposed scheme, and determine the valid threshold value interval of the algorithm. Experimental results show that the proposed scheme is feasible with a fast reading speed and high secret storage capacity within the threshold interval.
C1 [Fu, Zhengxin; Liu, Sijia; Sun, Rui; Fang, Liguo; Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University
RP Liu, SJ (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
EM 1559776364@qq.com
RI Liu, Sijia/HZL-9543-2023
FU National Natural Science Foundation of China [61602513]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No.61602513.
CR [Anonymous], 2008, HIGH CAPACITY COLOR
   [Anonymous], 2006, 180042006 ISOIEC
   Bielza C, 2014, DICT BIOINFORMATICS
   Bulan Orhan, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7254, DOI 10.1117/12.807742
   Bulan O, 2008, PROC SPIE, V6819, DOI 10.1117/12.767408
   Bulan O, 2012, IEEE T IMAGE PROCESS, V21, P405, DOI 10.1109/TIP.2011.2155078
   Bulan O, 2011, IEEE T IMAGE PROCESS, V20, P1337, DOI 10.1109/TIP.2010.2092437
   Bulan O, 2010, IEEE T IMAGE PROCESS, V19, P2070, DOI 10.1109/TIP.2010.2046795
   Grillo A., 2010, Proceedings 2010 International Multiconference on Computer Science and Information Technology (IMCSIT 2010), P709
   Hashorva E, 2013, BERNOULLI, V19, P886, DOI 10.3150/12-BEJ463
   Kato H, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P529, DOI 10.1109/ISPACS.2009.5383786
   Kikuchi M, 2013, I S INTELL SIG PROC, P26, DOI 10.1109/ISPACS.2013.6704516
   Nurwono K., 2009, P 7 INT C ADV MOB CO, P267, DOI DOI 10.1145/1821748.1821799
   Onoda T, 2011, European, Patent No. 1916619
   Parikh Devi., 2008, Workshop on Applications of Computer Vision, P1
   Querini M., 2013, INT J COMPUTER SCI A, V10, P78
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tack-Don H., 2006, US Patent, Patent No. [7, 020, 327, 7020327]
   Taveerad N, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P645, DOI 10.1109/SITIS.2015.42
   Vavassori P, 2000, IEEE T MAGN, V36, P2993, DOI 10.1109/20.908652
   Wei W, 2017, FUTURE GENER COMP SY, V78
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xin L, 2018, ACTA MATH SIN, V7, P1
   Yamada I, 2017, ARXIV170304914V2
   Yang ZB, 2018, IEEE T IMAGE PROCESS, V27, P6093, DOI 10.1109/TIP.2018.2855419
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
NR 26
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32471
EP 32485
DI 10.1007/s11042-020-09469-2
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000001
DA 2024-07-18
ER

PT J
AU Mohammed, AA
   Salih, DA
   Saeed, AM
   Kheder, MQ
AF Mohammed, Aree A.
   Salih, Dilman A.
   Saeed, Ari M.
   Kheder, Mohammed Q.
TI An imperceptible semi-blind image watermarking scheme in DWT-SVD domain
   using a zigzag embedding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-blind watermarking; Transform domain; Zigzag embedding; Attacks
ID ROBUST; DCT
AB This research work presents a semi-blind image watermarking scheme based on transforms domain DWT-SVD using an efficient embedding technique. This scheme provides a high level of robustness and imperceptibility for digital image copyright protection. In the embedding process, the watermark data (logo and image in this research) is first transformed into the frequency domain using the DWT algorithm for one pass. Then, the LL-band values are also transformed by the SVD algorithm. S values (diagonal matrix) are prepared for inserting into the cover images. Differently, the cover images (SD and HD quality) are also transformed by DWT for two levels of decomposition. During the insertion process, the watermark bits are embedding into the HL2 and HH2 bands of the cover image using the zigzag technique to improve the imperceptibility. Moreover, the obtained watermarked images are subjected to different attacks (geometric, image processing, and jpeg compression) to show the robustness of the proposed scheme. Finally, the extraction process needs only the watermarked image and the U and V values of SVD transforms (semi-blind watermarking) to reconstruct the original watermark. The performance parameters for the robustness and imperceptibility involved in this work are PSNR and Normalized Correlation Coefficient NCC metrics. Computational cost is also calculated for both embedding and extracting watermark process for different cover image types. Test results indicate that the proposed scheme has a better performance when the watermark data is embedding in a zigzag way.
C1 [Mohammed, Aree A.; Kheder, Mohammed Q.] Univ Sulaimani, Coll Sci, Comp Sci Dept, Sulaimani, Krg, Iraq.
   [Mohammed, Aree A.; Salih, Dilman A.; Saeed, Ari M.] Univ Halabja, Coll Sci, Comp Sci Dept, Halabja, Krg, Iraq.
C3 University of Sulimanyah
RP Mohammed, AA (corresponding author), Univ Sulaimani, Coll Sci, Comp Sci Dept, Sulaimani, Krg, Iraq.
EM aree.ali@univsul.edu.iq
OI Saeed, Ari/0000-0003-1350-9386
FU Sulaimani university; Halabja university
FX This research is a part of the research work between the University of
   Sulaimani and Halabja in Kurdistan Region of Iraq. Special thanks to the
   college of science at both universities for providing a healthy
   environment to fulfill this project. We would also like to express our
   deep gratitude for generous support and funds by the presidency of
   Sulaimani and Halabja universities.
CR Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abdallah Emad E, 2007, P GRAPHICS INTERFACE
   Abdallah Emad E, 2009, SIGNAL IMAGE VIDEO P
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Chrysochos E, 2014, SIGNAL IMAGE VIDEO P, V8, P843, DOI 10.1007/s11760-012-0307-3
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gupta R, 2018, MULTIMED TOOLS APPL, V77, P19235, DOI 10.1007/s11042-017-5351-0
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Hurrah Nasir N., 2017, 2017 4 INT C IM INF
   IS Coaxial, 2008, DIGITAL WATERMARKING
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lee YS, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8357251
   Minamoto Teruya, 2011, INT C SIGN PROC IM P
   Moeinaddini E, 2018, MULTIMED TOOLS APPL, V77, P26083, DOI 10.1007/s11042-018-5838-3
   Mohammed AA, 2018, MULTIMED TOOLS APPL, V77, P2791, DOI 10.1007/s11042-017-4427-1
   Mohammed Aree Ali, 2011, IJCSS, V5
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Nasir I, 2010, SIGNAL IMAGE VIDEO P, V4, P145, DOI 10.1007/s11760-009-0106-7
   Ntalianis KS, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P188, DOI 10.1109/ICCE.2002.1013985
   Pal Arup Kumar, 2018, International Journal of Information and Computer Security, V10, P321
   Piva Alessandro, 2000, P 2000 INT C IM PROC, V3
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Prakash B, 2018, SYNTHESIS OF MEDICINAL AGENTS FROM PLANTS, P25, DOI 10.1016/B978-0-08-102071-5.00002-7
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Rahman Md Maklachur, 2017, GLOBAL J RES ENG
   Rai Sandeep, 2019, DATA ENG APPL, P129
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Reddy B, 2015, IJERT, V3.1, P1
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Savakar D. G., 2017, Pattern Recognition and Image Analysis, V27, P511, DOI 10.1134/S1054661817030257
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Shaji C, 2019, IMAGING SCI J, V67, P202, DOI 10.1080/13682199.2019.1592892
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tay R, 2002, 2002 45 MIDW S CIRC, V3
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   ZHOU X, 2018, SYMMETRY-BASEL, V10
NR 38
TC 18
Z9 18
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32095
EP 32118
DI 10.1007/s11042-020-09694-9
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400006
DA 2024-07-18
ER

PT J
AU Abbas, Q
   Ibrahim, MEA
AF Abbas, Qaisar
   Ibrahim, Mostafa E. A.
TI DenseHyper: an automatic recognition system for detection of
   hypertensive retinopathy using dense features transform and
   deep-residual learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypertensive retinopathy; Retinal fundus images; Features selection;
   Deep-neural network; Convolutional neural network; Transfer learning;
   Residual neural network
ID IMAGE CLASSIFICATION; DIAGNOSIS; SEGMENTATION; NETWORKS; ARTERIES;
   VESSELS; FUSION; RATIO
AB High blood pressure and diabetes are associated with a retinal abnormality known as Hypertensive Retinopathy (HR). The severity-level and duration of hypertension are straightly related to the incidence of HR-eye disease. The HR damages the pathological lesions of eyes such as arteriolar narrowing, retinal hemorrhage, macular edema, cotton wool spots, and blood vessels. In the early stages, it is important to detect and diagnose HR to prevent eye blindness. Currently, there are few computerize systems developed to recognize HR. However, those systems focused on extracting features through hand-craft and deep-learning models (DLMs) based techniques. As a result, the complex image processing algorithms are required in case of hand-crafted features and it is difficult to define generalized features by DLMs to recognize HR. Moreover, the classification accuracy is not up-to-the-mark even though by using deep-feature techniques as observed in state-of-the-art HR diagnostics systems. To solve these problems, a novel hypertensive retinopathy (DenseHyper) system is developed to detect the HR based on a proposed trained features layer (TF-L) and dense feature transform layer (DFT-L) to the deep residual learning (DRL) methods. The DenseHyper system consists of different multilayer dense architecture by integrating of TF-L by convolutional neural network (CNN) to learn features from different lesions, and generate specialized features by DFT-L. To develop DenseHyper system, a learning based dense feature transform (DFT) approach was integrated to increase classification accuracy. Three online sources besides one private data are gathered to test and compare the DenseHyper system. To show the performance of the DenseHyper system, the statistical analysis is also performed on 4270 retinal fundus images through sensitivity (SE), specificity (SP), accuracy (ACC) and area under the receiver operating curve (AUC) metrics. The significant results were achieved compare to state-of-the-art methods. On average, the SE of 93%, SP of 95%, ACC of 95% and 0.96 of AUC values were obtained through a 10-fold cross-validation test. Experimental results confirm the applicability of the DenseHyper system to accurately diagnosis of hypertensive retinopathy.
C1 [Abbas, Qaisar; Ibrahim, Mostafa E. A.] Al Imam Muhammad Ibn Saud Islamic Univ IMSIU, Dept Comp Sci, Riyadh 11432, Saudi Arabia.
   [Ibrahim, Mostafa E. A.] Benha Univ, Benha Fac Engn, Dept Elect Engn, Banha, Egypt.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU); Egyptian Knowledge
   Bank (EKB); Benha University
RP Abbas, Q (corresponding author), Al Imam Muhammad Ibn Saud Islamic Univ IMSIU, Dept Comp Sci, Riyadh 11432, Saudi Arabia.
EM qaisarabbasphd@gmail.com
RI Muhammad Abas, Qaisar Abbas/GPX-7906-2022; Muhammad Abas, Qaisar
   Abbas/ABI-6501-2020; Ibrahim, Mostafa/HNQ-0489-2023; Abbas,
   Qaisar/AAC-9673-2021; Abbas, Qaisar/AAZ-2785-2020
OI Muhammad Abas, Qaisar Abbas/0000-0002-0361-1363; Muhammad Abas, Qaisar
   Abbas/0000-0002-0361-1363; Ibrahim, Mostafa/0000-0003-0730-6857; 
FU Al Imam Muhammad Ibn Saud Islamic University (IMSIU) [360905]
FX This study was funded by Al Imam Muhammad Ibn Saud Islamic University
   (IMSIU) (grant number 360905).
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   Abbas Q, 2019, ARTIF INTELL REV, V52, P39, DOI 10.1007/s10462-018-9633-3
   Abbas Q, 2018, MULTIMED TOOLS APPL, V77, P20415, DOI 10.1007/s11042-017-5438-7
   Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Abbasi-Sureshjani S, 2016, I S BIOMED IMAGING, P189, DOI 10.1109/ISBI.2016.7493241
   Agurto C, 2014, IEEE ENG MED BIO, P5406, DOI 10.1109/EMBC.2014.6944848
   Akagi S, 2018, J CARDIOL, V72, P466, DOI 10.1016/j.jjcc.2018.04.014
   Akbar S, 2018, ARTIF INTELL MED, V90, P15, DOI 10.1016/j.artmed.2018.06.004
   Akbar S, 2018, COMPUT METH PROG BIO, V154, P123, DOI 10.1016/j.cmpb.2017.11.014
   AlBadawi S, 2018, LECT NOTES COMPUT SC, V10882, P659, DOI 10.1007/978-3-319-93000-8_75
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Canziani A, 2017, ARXIVABS160507678
   Cavallari M, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/752957
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gamella-Pozuelo L, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001218
   Gao Y, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/2745183
   García-Floriano A, 2019, COMPUT ELECTR ENG, V75, P218, DOI 10.1016/j.compeleceng.2017.11.008
   Goswami S, 2017, ADV INTELL SYST, V458, P451, DOI 10.1007/978-981-10-2035-3_46
   Grisan E, 2008, IEEE T MED IMAGING, V27, P310, DOI 10.1109/TMI.2007.904657
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Holm S, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.1.014503
   Irshad S, 2014, CAIRO INT BIOM ENG, P121, DOI 10.1109/CIBEC.2014.7020932
   Irshad S, 2014, CAIRO INT BIOM ENG, P133, DOI 10.1109/CIBEC.2014.7020937
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Keshavarzian A, 2019, FUTURE GENER COMP SY, V101, P14, DOI 10.1016/j.future.2019.06.009
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Liu C, 2019, INT J RADIAT ONCOL, V104, P924, DOI 10.1016/j.ijrobp.2019.03.017
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Manikis G.C., 2011, P 2011 E HLTH BIOENG, P1
   Mozaffarian D, 2015, CIRCULATION, V131, pE29, DOI 10.1161/CIR.0000000000000152
   Muramatsu C, 2011, COMPUT MED IMAG GRAP, V35, P472, DOI 10.1016/j.compmedimag.2011.03.002
   Narasimhan K, 2012, PROCEDIA ENGINEER, V38, P980, DOI 10.1016/j.proeng.2012.06.124
   Nath M. K., 2012, Proceedings of the 2012 2nd National Conference on Computational Intelligence and Signal Processing (CISP 2012), P81, DOI 10.1109/NCCISP.2012.6189682
   Niu D, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P208, DOI 10.1109/SIPROCESS.2017.8124534
   Noronha K, 2013, INT J COMPUTER APPL, V1, P7
   Ortíz D, 2010, IEEE ENG MED BIO, P5649, DOI 10.1109/IEMBS.2010.5628047
   Pires R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096814
   Prentasic P, 2015, INT SYMP IMAGE SIG, P188, DOI 10.1109/ISPA.2015.7306056
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rosendorff C, 1998, J AM COLL CARDIOL, V65, P2038
   Saez M, 2012, COMPUT METH PROG BIO, V108, P367, DOI 10.1016/j.cmpb.2012.02.008
   Sahoo A.K., 2020, Nature inspired computing for data science, P201, DOI [DOI 10.1007/978-3-030-33820-6_8, 10.1007/978-3-030-33820-68, DOI 10.1007/978-3-030-33820-68]
   Sengupta S, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101758
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro TA, 2019, IEEE ACCESS, V7, P71696, DOI 10.1109/ACCESS.2019.2920616
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Syahputra M.F, 2018, J PHYS C SERIES, V978
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Tramontan L, 2009, IFMBE PROC, V25, P141, DOI 10.1007/978-3-642-03891-4_38
   Triwijoyo BK, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012039
   Triwijoyo BK, 2017, PROCEDIA COMPUT SCI, V116, P166, DOI 10.1016/j.procs.2017.10.066
   Vaghefi E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43670-0
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wahab H, 2014, INT CONF IMAG PROC, P81
   WANG LJ, 2016, J ELECT ENG, V11, P7
   Welikala RA, 2017, COMPUT BIOL MED, V90, P23, DOI 10.1016/j.compbiomed.2017.09.005
   Wiharto W, 2019, IOP C SERIES MAT SCI, V620
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Yao ZJ, 2016, INT SYM COMPUT INTEL, P406, DOI [10.1109/ISCID.2016.1100, 10.1109/ISCID.2016.99]
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhao MH, 2018, IEEE T IND ELECTRON, V65, P4290, DOI 10.1109/TIE.2017.2762639
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
   Zou XC, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/7496735
NR 68
TC 25
Z9 26
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31595
EP 31623
DI 10.1007/s11042-020-09630-x
EA AUG 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100007
DA 2024-07-18
ER

PT J
AU Ullah, W
   Ullah, A
   Ul Haq, I
   Muhammad, K
   Sajjad, M
   Baik, SW
AF Ullah, Waseem
   Ullah, Amin
   Ul Haq, Ijaz
   Muhammad, Khan
   Sajjad, Muhammad
   Baik, Sung Wook
TI CNN features with bi-directional LSTM for real-time anomaly detection in
   surveillance networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Deep learning; LSTM; Intelligent surveillance
   networks; Smart surveillance; Crime detection
ID ABNORMAL EVENT DETECTION; LOCALIZATION
AB In current technological era, surveillance systems generate an enormous volume of video data on a daily basis, making its analysis a difficult task for computer vision experts. Manually searching for unusual events in these massive video streams is a challenging task, since they occur inconsistently and with low probability in real-world surveillance. In contrast, deep learning-based anomaly detection reduces human labour and its decision making ability is comparatively reliable, thereby ensuring public safety. In this paper, we present an efficient deep features-based intelligent anomaly detection framework that can operate in surveillance networks with reduced time complexity. In the proposed framework, we first extract spatiotemporal features from a series of frames by passing each one to a pre-trained Convolutional Neural Network (CNN) model. The features extracted from the sequence of frames are valuable in capturing anomalous events. We then pass the extracted deep features to multi-layer Bi-directional Long Short-term Memory (BD-LSTM) model, which can accurately classify ongoing anomalous/normal events in complex surveillance scenes of smart cities. We performed extensive experiments on various anomaly detection benchmark datasets to validate the functionality of the proposed framework within complex surveillance scenarios. We reported a 3.41% and 8.09% increase in accuracy on UCF-Crime and UCFCrime2Local datasets compared to state-of-the-art methods.
C1 [Ullah, Waseem; Ullah, Amin; Ul Haq, Ijaz; Baik, Sung Wook] Sejong Univ, Digital Contents Res Inst, Intelligent Media Lab, Seoul, South Korea.
   [Muhammad, Khan] Sejong Univ, Dept Software, Seoul, South Korea.
   [Sajjad, Muhammad] Islamia Coll Peshawar, Dept Comp Sci, Peshawar, Pakistan.
C3 Sejong University; Sejong University; University of Peshawar
RP Baik, SW (corresponding author), Sejong Univ, Digital Contents Res Inst, Intelligent Media Lab, Seoul, South Korea.
EM sbaik@sejong.ac.kr
RI Haq, ijaz ul/AAK-5306-2020; Sajjad, Muhammad/GZL-4962-2022; Ullah,
   Amin/AAH-5034-2020; Muhammad, Khan/L-9059-2016; Ullah,
   Amin/JPA-6034-2023; Sajjad, Muhammad/L-5269-2016; ULLAH,
   Waseem/ABE-6599-2021; Khan, Muhammad/IXN-8470-2023
OI Sajjad, Muhammad/0000-0003-0006-1156; Ullah, Amin/0000-0001-7538-2689;
   Muhammad, Khan/0000-0003-4055-7412; Sajjad,
   Muhammad/0000-0001-5646-0338; ullah, Waseem/0000-0001-5191-9023;
   Muhammad, Khan/0000-0002-5302-1150
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2019-0-00136]
FX "This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (2019-0-00136, Development of AI-Convergence
   Technologies for Smart City Industry Productivity Innovation)."
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Al Ridhawi I, 2020, SUSTAIN CITIES SOC, V56, DOI 10.1016/j.scs.2020.102080
   Al-Smadi M, 2018, J COMPUT SCI-NETH, V27, P386, DOI 10.1016/j.jocs.2017.11.006
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P22787, DOI 10.1007/s11042-017-4488-1
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.308
   Benezeth Y, 2009, PROC CVPR IEEE, P2450
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Cheng KW, 2016, MULTIMED TOOLS APPL, V75, P15101, DOI 10.1007/s11042-015-2453-4
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Gianchandani U, Weakly-supervised spatiotemporal anomaly detection
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He CK, 2018, MULTIMED TOOLS APPL, V77, P29573, DOI 10.1007/s11042-017-5255-z
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jing Huo, 2012, Intelligent Data Engineering and Automated Learning - IDEAL 2012. Proceedings 13th International Conference, P76, DOI 10.1007/978-3-642-32639-4_10
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Landi Federico, 2019, ARXIV190110364
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Muhammad K, 2020, IEEE INTERNET THINGS, V7, P4455, DOI 10.1109/JIOT.2019.2950469
   Rabiee H, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P95, DOI 10.1109/AVSS.2016.7738074
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sak H, 2014, INTERSPEECH, P338
   Shao J, 2016, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR.2016.606
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Wang T, 2018, MULTIMED TOOLS APPL, V77, P17375, DOI 10.1007/s11042-017-5309-2
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yu Y, 2020, IEEE T VERY LARGE SC
   Zhang J, 2019, AAAI CONF ARTIF INTE, P9185
   Zhang T, 2017, MULTIMED TOOLS APPL, V76, P1419, DOI 10.1007/s11042-015-3133-0
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu Y., 2019, ARXIV190710211, P1
NR 41
TC 111
Z9 113
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16979
EP 16995
DI 10.1007/s11042-020-09406-3
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000561259400001
DA 2024-07-18
ER

PT J
AU Youssef, S
   el Shehaby, M
   Fayed, S
AF Youssef, Sherin
   el Shehaby, Mohamed
   Fayed, Salema
TI A Smart multi-view panoramic imaging integrating stitching with
   geometric matrix relations among surveillance cameras (SMPI)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance camera; Compression; Stitching; Mosaicking; Reconstruction;
   Projective transformation matrix; Homography
ID STRUCTURAL SIMILARITY
AB Reducing data stored and transferred is a critical topic in the modern era, particularly after the evolution in multimedia applications and surveillance systems worldwide. Motivated by the massive amount of data generated by surveillance cameras and the enormous number of redundant pixels produced among them, this paper introduces a novel model entitled: "A Smart Multi-View Panoramic Imaging integrating stitching with geometric matrix relations among surveillance cameras (SMPI)." The introduced model aims to create a novel feedback real-time stitching system to reduce the storing and transferring of redundant data generated by neighboring surveillance cameras for an extra level of compression. Moreover, the panoramic view is mostly a better monitoring option rather than multiple monitors in complicated surveillance cameras' control rooms. The proposed system, in this paper, merges feature extraction stitching techniques with geometric relational matrix calculations to reduce the time complexity limitations of traditional mosaicking. Additionally, the proposed work introduces a real-time algorithm to reconstruct images of each camera from the panoramic view, and a novel algorithm for ordering cameras' frames before stitching is recommended for producing a panoramic view without any human interference. The experimental work tests numerous state of the art feature extraction algorithms for stitching, Scale Invariant Feature Transform (SIFT), Speed Up Robust Feature (SURF) and Oriented FAST and Rotated BRIEF (ORB) with different orders of stitching. The amount of compression per image after reconstruction is also analyzed. The suggested model was implemented and tested using a vast number of benchmark datasets. Evaluation measures have been used to indicate the efficiency of the recommended system. The proposed model's algorithm has recorded a low time processing per frame while keeping high accurate results. It was found that the recommended Efficient Stitching Algorithm (ESA) produced an average of 46 panoramas per second, and the reconstruction phase could reach a rate of 90 frames per second, which is significantly higher than the 30 frames per second standard video format system. These results give our model an excellent advantage for the effective processing of more scalable systems with a higher number of frames per second. The proposed system created panoramas with an average of 99% similarities with the traditional mosaicking systems while being highly faster than these conventional methods. Compression ratios and data rate savings, reflecting the gain in data stored and transferred, were calculated, reporting an average of 2.66 and 0.62 per frame, respectively, when applied to standard datasets. The results illustrated that the proposed system gives a dramatic reduction in the volume of data stored/transferred and showed that the creating of mosaics and the reconstruction was made in proper processing time. Experimental outcomes also showed that, for the suggested methods, the produced frames after reconstruction have a high similarity percentage compared with original ones before stitching, which indicates that the proposed approach is efficient enough to preserve the essential features of cameras' frames without significant information loss.
C1 [Youssef, Sherin; el Shehaby, Mohamed; Fayed, Salema] Arab Acad Sci Technol & Maritime Transport, Coll Engn, Dept Comp Engn, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Arab Academy for Science, Technology &
   Maritime Transport
RP el Shehaby, M (corresponding author), Arab Acad Sci Technol & Maritime Transport, Coll Engn, Dept Comp Engn, Alexandria, Egypt.
EM sherin@aast.edu; shehaby@aast.edu
OI el Shehaby, Mohamed/0000-0003-2958-0064
CR Adel E., 2014, International Journal of Computer Applications, V99, P1, DOI DOI 10.5120/17374-7818
   [Anonymous], 2000, APS COMM NETW MULTIM
   Bajpai P, 2018, IEEE INT CONF MULTI
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bergler M, 2018, INFORM AKTUELL, P322
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Dissanayake V, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P609
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Girod Bernd, 1993, P207
   Gonçalves H, 2011, IEEE T GEOSCI REMOTE, V49, P2589, DOI 10.1109/TGRS.2011.2109389
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Kale P., 2015, INT J COMPUTER SCI I, V6, P284
   Li AG, 2017, INT C INTEL HUM MACH, P415, DOI 10.1109/IHMSC.2017.205
   Lin CH, 2018, IEEE ICCE
   Liu LM, 2009, IEEE T CIRC SYST VID, V19, P453, DOI 10.1109/TCSVT.2009.2017074
   Liu YH, 2016, INT ARCH PHOTOGRAMM, V41, P527, DOI 10.5194/isprsarchives-XLI-B3-527-2016
   Luo BC, 2018, IEEE T VIS COMPUT GR, V24, P1545, DOI 10.1109/TVCG.2018.2794071
   Luo Juan, 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P495, DOI 10.1109/IPTA.2010.5586723
   Ma BY, 2019, COMP MATER SCI, V158, P1, DOI 10.1016/j.commatsci.2018.10.044
   Marr B., 2015, BIG DATA USING SMART
   Martens JB, 1998, SIGNAL PROCESS, V70, P155, DOI 10.1016/S0165-1684(98)00123-6
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Natthavut V, 2015, P 3 IIAE INT C INT S, P106
   Pacot M, 2018, ASIAN J BUSINESS TEC
   Pan X, 2010, IEEE CUST INTEGR CIR
   Pang YW, 2012, NEUROCOMPUTING, V85, P6, DOI 10.1016/j.neucom.2011.12.006
   Pedro L, 2010, SEGMENTATION FEATURE, P1
   Pons AM, 1999, DISPLAYS, V20, P93, DOI 10.1016/S0141-9382(99)00009-8
   Qin YY, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P204, DOI 10.1109/PIC.2014.6972325
   Qinglin H, P 10 INT C GRAPH IM
   Ramaswamy A, 2018, IEEE IMAGE PROC, P91, DOI 10.1109/ICIP.2018.8451671
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923
   Sengupta A, 2018, IEEE CONSUM ELECTR M, V7, P119, DOI 10.1109/MCE.2017.2743239
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Su JM, 2016, IEEE INT CONF MULTI
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   [佟雨兵 TONG Yubing], 2006, [中国图象图形学报, Journal of Image and Graphics], V11, P1758
   Wang B, 2017, INT CONF SOFTW ENG, P680, DOI 10.1109/ICSESS.2017.8343005
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Xiang TZ, 2018, PATTERN RECOGN, V83, P481, DOI 10.1016/j.patcog.2018.06.013
   Xie RP, 2018, AUTOMAT CONSTR, V90, P265, DOI 10.1016/j.autcon.2018.02.021
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yan WX, 2015, INT CONF CONTR AUTO, P245, DOI 10.1109/ICCAIS.2015.7338670
   Yu XY, 2018, PROC SPIE, V10806, DOI 10.1117/12.2502820
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhuo L, 2016, NEUROCOMPUTING, V173, P511, DOI 10.1016/j.neucom.2015.06.055
NR 49
TC 2
Z9 3
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30917
EP 30981
DI 10.1007/s11042-020-09432-1
EA AUG 2020
PG 65
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900005
DA 2024-07-18
ER

PT J
AU Ju, AK
   Guo, YB
   Li, T
AF Ju, Ankang
   Guo, Yuanbo
   Li, Tao
TI MCKC: a modified cyber kill chain model for cognitive APTs analysis
   within Enterprise multimedia network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber kill chain model; APT detection; Bi-directional analysis
AB The emerging cyber security threats pose many challenges to security analysts of enterprise multimedia environments when analysts attempting to analyze and reconstruct advanced persistent threats (APTs). APTs analysis activities are both time-consuming and labor-intensive. Attack modeling technology represented by kill chain can reduce the burden of manual provenience analysis. However, existing Cyber Kill Chain models represent attacks as several stages solidly, and they cannot reflect the characteristics of progressive penetration. It is difficult for security analysts to automate the correlation analysis of attack events in practical usage. In this paper, we first analyze current Cyber Kill Chain models and heterogeneous data sources for APTs detection. Then we propose MCKC (Modified Cyber Kill Chain model) that can be used for standardized correlation analysis. MCKC organizes sub-chains into a recursive structure, and different kill chain penetration processes in the same attack scenario are better connected The proposed MCKC model offers a novel approach for bi-directional attack analysis: forward analysis and backward reasoning which can facilitate threat detection effectively without relying too much on expert knowledge. The advantage of MCKC model is that it is more suitable for cognitive reasoning and APTs scenario reconstruction. Compared with existing models MCKC gives a feasible technological process for threat analysis. The result of case study shows that the modified kill chain model is effective in discovering security events and reconstructing APT attacks.
C1 [Ju, Ankang; Guo, Yuanbo; Li, Tao] Zhengzhou Inst Informat Sci & Technol, Zhengzhou 450001, Peoples R China.
C3 PLA Information Engineering University
RP Ju, AK (corresponding author), Zhengzhou Inst Informat Sci & Technol, Zhengzhou 450001, Peoples R China.
EM jusissp@yeah.net
RI Guo, Yuan/HKV-9606-2023
OI Ju, Ankang/0000-0002-7818-4482
CR Ahmed Amirul Aslam, 2017, UTM COMPUTING P INNO, V2
   Albeshri A., 2018, ANAL TECHNIQUES DECI
   Bada M, 2019, A P A CYBER SECURITY
   Bayley I, 2014, CHALLENGES FORMAL FR, DOI 10.1007%2F978-3-319-04447-7_4
   Bryant BD, 2017, COMPUT SECUR, V67, P198, DOI 10.1016/j.cose.2017.03.003
   Caltagirone S., 2013, Technical Report
   Daimi K., 2018, COMPUTER NETWORK SEC, DOI DOI 10.1007/978-3-319-58424-9
   Hutchins EM, 2011, LIFE COURSE PERSPECT, V1, P1
   Lallie HS, 2018, IEEE T INF FOREN SEC, V13, P1110, DOI 10.1109/TIFS.2017.2771238
   Mandiant APT, 2013, 1 REPORT
   Siadati H, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1273, DOI 10.1145/3133956.3134003
   Strom BE, 2017, MTR170202
   Syed Z, 2017, AAAI WORKSH ART INT
NR 13
TC 5
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29923
EP 29949
DI 10.1007/s11042-020-09444-x
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227100001
DA 2024-07-18
ER

PT J
AU Guo, JJ
   Yuan, CH
   Zhao, ZQ
   Feng, P
   Luo, YH
   Wang, TJ
AF Guo, Jingjuan
   Yuan, Caihong
   Zhao, Zhiqiang
   Feng, Ping
   Luo, Yihao
   Wang, Tianjiang
TI Object detector with enriched global context information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Global context information; Pyramid pooling features
AB How to add more context information and bring more accurate detection is an important problem to be considered in object detection. In this paper, we propose a new object detector with enriched global context information by a pyramid feature pool module and several global activation blocks, named EGCI-Net, which is a one-stage object detector from scratch as DSOD.The global activation blocks are added into the backbone sub network of the detector to weaken the local information of the detected object feature maps and increase the global context of them. And the pyramid feature pool module produces multi-scale global context features to supervise the pyramid features by multi-scale global average pooling. Then the features obtained by the main structure are fused with the pyramid pooling features to merge into the final multibox detector. We have evaluated our detector on the Pascal VOC and MS COCO datasets. The experimental results show that our proposed detector achieves better results than DSOD and exceeds most of the existing excellent detectors, especially detects partially occluded objects and small objects well.
C1 [Guo, Jingjuan; Luo, Yihao; Wang, Tianjiang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Guo, Jingjuan; Zhao, Zhiqiang] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Feng, Ping] Guizhou Univ Finance & Econ, Int Joint Res Ctr Data Sci & High Performance Com, Guiyang 550025, Peoples R China.
C3 Huazhong University of Science & Technology; Jiujiang University; Henan
   University; Guizhou University of Finance & Economics
RP Guo, JJ; Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.; Guo, JJ (corresponding author), Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
EM jj_guo@hust.edu.cn; yuanch@hust.edu.cn; zq_zhao@hust.edu.cn;
   fengping_m19@foxmail.com; luoyihao@hust.edu.cn; tjwang_00@foxmail.com
FU Natural Science Foundation of China [61572214, U1536203]
FX This work is supported by the Natural Science Foundation of China (Grant
   61572214 and U1536203).
CR [Anonymous], P INT C COMP VIS ICC
   [Anonymous], 2017, ARXIV171010749
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chen Y., 2017, ARXIV171203149
   Cheng-Yang F, 2017, ARXIV170106659
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huo YF, 2017, IEEE INT SYMP ELEC
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Leng QM, 2020, IEEE T GEOSCI REMOTE, V58, P5847, DOI 10.1109/TGRS.2020.2971716
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W., 2015, ARXIV150604579
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao ZF, 2018, IEEE T MULTIMEDIA, V20, P2593, DOI 10.1109/TMM.2018.2865686
   Shen Z, 2018, ARXIV180909294
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shen Zhiqiang, 2017, ARXIV171200886
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2016, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR.2016.525
   Szegedy C., 2017, AAAI, V4, P12
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian LC, 2018, IEEE T MULTIMEDIA, V20, P2249, DOI 10.1109/TMM.2018.2803526
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang SG, 2018, IEEE T MULTIMEDIA, V20, P3148, DOI 10.1109/TMM.2018.2829602
   Woo S, 2018, IEEE WINT CONF APPL, P1093, DOI 10.1109/WACV.2018.00125
   Xiang W., 2017, ARXIV170708682
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 51
TC 6
Z9 6
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29551
EP 29571
DI 10.1007/s11042-020-09500-6
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400011
DA 2024-07-18
ER

PT J
AU Jayapriya, K
   Jacob, IJ
   Mary, NAB
AF Jayapriya, K.
   Jacob, I. Jeena
   Mary, N. Ani Brown
TI Person re-identification using prioritized chromatic texture (PCT) with
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep learning; Convolutional neural network;
   XQDA
AB Person re-identification (re-ID) helps to identify a person's attention in different cameras. But this is not an easy task, due to distance, illumination and lack of dataset. Nowadays, this field attracts many researchers because of its varied applications. Here, the information of both local texture and global color representations are concatenated with an original raw image. This concatenated information is gathered by finding the maximum value of chrominance in terms of HSV, texture in terms of Scale Invariant Local Ternary Pattern (SILTP) for each pixel and original raw image. SILTP is well known for its illumination invariant texture description. Convolutional Neural Network (CNN) is used in the proposed work to extract the features from the concatenated information. The proposed Prioritized Chromatic Texture Image (PCTimg) is concatenated with original raw image and fed into CNN. Here, finally a six dimensionalfeature is fed into CNN to extract the deep features. Cross-view Quadratic Discriminant Analysis (XQDA) similarity metric algorithm is employed to re-identify a person.Multiscale Retinex algorithm is used for pre-processing the images.To address the challenges in terms of view point deflection, a sliding window is formed for describing local details of a person in the SILTP feature extraction phase. The HSV helps to incorporate the human color perception. The triplet loss function is used to learn the similarity and the dissimilarity of the training images. The performance analysis of the proposed work is improvedwhen compared to the existingworks.
C1 [Jayapriya, K.] Vin Solut, Tirunelveli, India.
   [Jacob, I. Jeena] GITAM Univ, Dept CSE, Bangalore, Karnataka, India.
   [Mary, N. Ani Brown] SarahTucker Coll, Tirunelveli, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Jayapriya, K (corresponding author), Vin Solut, Tirunelveli, India.
EM kjp.jayapriya@gmail.com; Jeni.neha@gmail.com; anibrownvimal@gmail.com
RI Jacob, I.Jeena/AAE-8426-2020; Mary, Ani Brown/AAZ-5896-2020
OI Jacob, I.Jeena/0000-0001-6706-1017; Brown Mary, Ani/0000-0002-6029-4472
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Jingyi LV, 2020, IMAGE VISION COMPUTI, V95
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Kavakli-Thorne M., 2019, ARXIV190405992
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Layne R, 2013, P 4 ACM IEEE INT WOR
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018
   Martinel N., 2014, ECCV WORKSH VIS SURV
   Mary NAB, 2019, MULTIMED TOOLS APPL, V78, P11387, DOI 10.1007/s11042-018-6673-2
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Subramaniam A, 2016, ADV NEUR IN, V29
   Subramanyam AV, 2019, IEEE SIGNAL PROC LET, V26, P154, DOI 10.1109/LSP.2018.2882301
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Varior RR, 2016, IEEE T IMAGE PROCESS, V25, P3395, DOI 10.1109/TIP.2016.2531280
   Wang C, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2298973
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang X, 2015, IEEE T CIRCUITS SYST
   Wu L., 2016, ARXIV160107255
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2015, J LATEX CLASS FILES, V14
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 52
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29399
EP 29410
DI 10.1007/s11042-020-09528-8
EA AUG 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400003
DA 2024-07-18
ER

PT J
AU Abed, R
   Bahroun, S
   Zagrouba, E
AF Abed, Rahma
   Bahroun, Sahbi
   Zagrouba, Ezzeddine
TI KeyFrame extraction based on face quality measurement and convolutional
   neural network for efficient face recognition in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyframe extraction; Face quality assessment; Face in Video Recognition;
   Convolution Neural Network; Content Based Video Retrieval
AB Indexing is the process of extracting a compact, significant and pertinent signature that describes the content of the data. This field has a broad spectrum of promising applications, such as the Face in Video Recognition (FiVR). Motivating the interest of researchers around the world. Since the video has a huge amount of data, the process of extracting the relevant frames becomes necessary and an essential step prior to performing face recognition. In this context, we propose a new method for extracting keyframes from videos based on face quality and deep learning for a face recognition task. The first step is the face detection using MTCNN detector, which detects five landmarks (the eyes, the two corners of the mouth and the nose). It limits face boundaries in a bounding box, and provides a confidence score. This method has two steps. The first step aims to generate the face quality score of each face in the data set prepared for the learning step. To generate quality scores, we use three face feature extractor including Gabor, LBP and HoG. The second step consist on training a deep Convolutional Neural Network in a supervised manner in order to select frames having the best face quality. The obtained results show the effectiveness of the proposed method compared to the methods of the state of the art.
C1 [Abed, Rahma; Bahroun, Sahbi; Zagrouba, Ezzeddine] Univ Tunis El Manar, Lab LIMTIC, Inst Super Informatqiue, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.
C3 Universite de Tunis-El-Manar
RP Abed, R (corresponding author), Univ Tunis El Manar, Lab LIMTIC, Inst Super Informatqiue, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.
EM rahma.abed@etudiant-isi.utm.tn; sahbi.bahroun@isi.utm.tn;
   ezzeddine.zagrouba@uvt.tn
RI Zagrouba, Ezzeddine/D-7896-2014
OI Zagrouba, Ezzeddine/0000-0002-2574-9080; ABED, rahma/0000-0003-1560-1848
CR Adam F, 2007, 4 CAN C COMP ROB VIS, P488
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Akram A, 2018, IEEE ACCESS, V6, P37084, DOI 10.1109/ACCESS.2018.2852709
   Anantharajah K, 2013, INT C DIG IM COMP TE, P1
   [Anonymous], 2016, SPR GEOL, DOI DOI 10.1007/978-981-10-1064-4_20
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2015, INT CONF CLOUD COMP, DOI DOI 10.1109/CLOUDCOM.2015.99
   Barr JR, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412660024
   Best-Rowden L, 2018, IEEE T INF FOREN SEC, V13, P3064, DOI 10.1109/TIFS.2018.2799585
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Bunyak F, 2005, IEEE INT C IM PROC
   Cament LA, 2015, PATTERN RECOGN, V48, P3371, DOI 10.1016/j.patcog.2015.05.017
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Carcagnì P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P90, DOI 10.1109/LSP.2014.2347419
   Clevert D., 2016, ARXIV151107289
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng WH, 2017, IEEE SIGNAL PROC LET, V24, P1877, DOI 10.1109/LSP.2017.2726105
   Dhamecha TI, 2016, ADV FACE DETECT FAC, P279
   Dubey AK, 2019, J INFORM OPTIM SCI, V40, P547, DOI 10.1080/02522667.2019.1582875
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu TC, 2017, IEEE INT WORKS MACH
   Gharbi H, 2017, INT CONF ACOUST SPEE, P1502, DOI 10.1109/ICASSP.2017.7952407
   Gui J., 2020, ARXIV200106937
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Guraya FFE, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P508, DOI 10.1109/DCABES.2010.160
   Huang C, 2019, ARXIV191112296
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang GB, 2008, WORKSH FAC REAL LIF
   Huang RB, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/6795352
   Javed S, 2017, ARXIV190401740, P4
   Javier H-O, 2019, ARXIV190401740
   Jian M, 2019, NEUROCOMPUTING, V328, P147, DOI 10.1016/j.neucom.2018.03.077
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kaavya S, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D P, 2015, 3 INT C LEARN REPR I
   Kini M, 2019, ADV COMPUT TECHNOL I, V1, P1
   Krizhevsky A., 2011, P EUR S ART NEUR NET, V1, P2
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu Y, 2018, PROC CVPR IEEE, P2080, DOI 10.1109/CVPR.2018.00222
   Matteo F, 2012, IEEE T INFORM FOREN, V7, P1204
   Mei W, 2018, COMPUTERS
   Mejda C, 2016, COMPUTERS, V5
   Muhammad K, 2018, PATTERN RECOGN LETT
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nasrollahi K, 2011, INT J IMAGE GRAPH, V11, P207, DOI 10.1142/S0219467811004068
   Nasrollahi K, 2008, LECT NOTES COMPUT SC, V5372, P10, DOI 10.1007/978-3-540-89991-4_2
   Nikitin M., 2014, FACE QUALITY ASSESSM, P111
   Pan L., 2015, INT J MULTIMED UBIQU, V10, P385
   Parkhi OM, 2015, BRIT MACH VISION C B
   Patiland PU, 2016, INT J ELECT ELECT RE, V4, P35
   Podlesnaya A, 2016, P SAI INT SYST C, P359
   Qi X, 2018, INT CONF BIOMETR, P132, DOI 10.1109/ICB2018.2018.00030
   Qi X, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY, AND BEHAVIOR ANALYSIS (ISBA)
   Ramachandran P, 2018, SEARCHING ACTIVATION
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shao Z, 2019, IEEE T CIRC SYST TEC
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Solina F., 2003, INT C COMP VIS COMP, P38
   Struc V, 2013, INT EL COMP SCI C ER, P121
   Taigman MLY, 2014, IEEE C COMP VIS PATT, P1891
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vignesh S, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P577, DOI 10.1109/GlobalSIP.2015.7418261
   Vishal A, 2018, ARXIV181104346
   Wang HJ, 2018, IEEE ACCESS, V6, P6001, DOI 10.1109/ACCESS.2017.2784842
   Wang WH, 2015, LECT NOTES COMPUT SC, V8944, P812, DOI 10.1007/978-3-319-15554-8_73
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wu X, 2017, TSINGHUA SCI TECHNOL, V22, P660, DOI 10.23919/TST.2017.8195348
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Xie XD, 2006, IEEE T IMAGE PROCESS, V15, P2481, DOI 10.1109/TIP.2006.877435
   Xu CF, 2017, NEUROCOMPUTING, V222, P62, DOI 10.1016/j.neucom.2016.10.010
   YANG JL, 2017, PROC CVPR IEEE, P5216, DOI DOI 10.1109/CVPR.2017.554
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao Z, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8918995
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 87
TC 6
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23157
EP 23179
DI 10.1007/s11042-020-09385-5
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000556646300005
DA 2024-07-18
ER

PT J
AU Utke, M
   Zadtootaghaj, S
   Schmidt, S
   Bosse, S
   Möller, S
AF Utke, Markus
   Zadtootaghaj, Saman
   Schmidt, Steven
   Bosse, Sebastian
   Moeller, Sebastian
TI NDNetGaming-development of a no-reference deep CNN for gaming video
   quality prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Gaming video; Quality assessment
ID VISUAL MASKING; IMAGE
AB Gaming video streaming services are growing rapidly due to new services such as passive video streaming of gaming content, e.g. Twitch.tv, as well as cloud gaming, e.g. Nvidia GeForce NOW and Google Stadia. In contrast to traditional video content, gaming content has special characteristics such as extremely high and special motion patterns, synthetic content and repetitive content, which poses new opportunities for the design of machine learning-based models to outperform the state-of-the-art video and image quality approaches for this special computer generated content. In this paper, we train a Convolutional Neural Network (CNN) based on an objective quality model, VMAF, as ground truth and fine-tuned it based on subjective image quality ratings. In addition, we propose a new temporal pooling method to predict gaming video quality based on frame-level predictions. Finally, the paper also describes how an appropriate CNN architecture can be chosen and how well the model performs on different contents. Our result shows that among four popular network architectures that we investigated, DenseNet performs best for image quality assessment based on the training dataset. By training the last 57 convolutional layers of DenseNet based on VMAF values, we obtained a high performance model to predict VMAF of distorted frames of video games with a Spearman's Rank correlation (SRCC) of 0.945 and Root Mean Score Error (RMSE) of 7.07 on the image level, while achieving a higher performance on the video level leading to a SRCC of 0.967 and RMSE of 5.47 for the KUGVD dataset. Furthermore, we fine-tuned the model based on subjective quality ratings of images from gaming content which resulted in a SRCC of 0.93 and RMSE of 0.46 using one-hold-out cross validation. Finally, on the video level, using the proposed pooling method, the model achieves a very good performance indicated by a SRCC of 0.968 and RMSE of 0.30 for the used gaming video dataset.
C1 [Utke, Markus; Zadtootaghaj, Saman; Schmidt, Steven; Moeller, Sebastian] Tech Univ Berlin, Berlin, Germany.
   [Bosse, Sebastian] Fraunhofer Heinrich Hertz Inst, Berlin, Germany.
C3 Technical University of Berlin; Fraunhofer Gesellschaft
RP Zadtootaghaj, S (corresponding author), Tech Univ Berlin, Berlin, Germany.
EM markus.utke@campus.tu-berlin.de; saman.zadtootaghaj@qu.tu-berlin.de;
   steven.schmidt@tu-berlin.de; sebastian.bosse@hhi.fraunhofer.de;
   sebastian.moeller@tu-berlin.de
RI Bosse, Sebastian/HNR-3792-2023
OI Moller, Sebastian/0000-0003-3057-0760; Schmidt,
   Steven/0000-0001-6620-1997; Zadtootaghaj, Saman/0000-0002-6028-8507
FU European Union [871793]
FX This project has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreement No 871793.
CR [Anonymous], SUBJ VID QUAL ASS ME
   [Anonymous], 2002, REC BT 50 19
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P5217, DOI 10.1109/TIP.2017.2729891
   Barman N., 2018, INT J NETW MANAG, V2018, P1, DOI DOI 10.1109/NETGAMES.2018.8463362
   Barman N, 2020, INT J NETW MANAG, V30, DOI 10.1002/nem.2054
   Barman N, 2019, IEEE ACCESS, V7, P74511, DOI 10.1109/ACCESS.2019.2920477
   Barman N, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P7, DOI 10.1145/3210424.3210434
   Bosse S, 2019, DIGIT SIGNAL PROCESS, V91, P54, DOI 10.1016/j.dsp.2018.12.005
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bovik A., 2017, ROBUST PERFORMANCE S
   Choi LK, 2018, SIGNAL PROCESS-IMAGE, V67, P182, DOI 10.1016/j.image.2018.06.009
   Chollet F., 2015, Keras: Deep learning library for theano and tensorflow
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Göring S, 2019, IEEE INT SYM MULTIM, P1, DOI 10.1109/ISM46123.2019.00010
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   ITU-T, 2008, ITU T P910 SUBJECTIV
   ITU-T, 2016, METH SUBJ ASS VID QU, P913
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Rao RRR, 2019, ADAPTIVE VIDEO STREA, P1203
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2018.00474, DOI 10.1109/CVPR.2018.00474]
   Schiano F, 2018, IEEE INT CONF ROBOT, P3669, DOI 10.1109/ICRA.2018.8460792
   Seufert M, 2013, INT WORK QUAL MULTIM, P52, DOI 10.1109/QoMEX.2013.6603210
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   SPERLING G, 1965, J OPT SOC AM, V55, P541, DOI 10.1364/JOSA.55.000541
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Venkatanath N, 2015, IEEE Twenty-First Nat. Conf. Comm, V2015, P1, DOI DOI 10.1109/NCC.2015.7084843
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zadtootaghaj S, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P213, DOI 10.1145/3339825.3391872
   Zadtootaghaj S, 2018, IEEE INT SYM MULTIM, P131, DOI 10.1109/ISM.2018.00031
NR 36
TC 18
Z9 20
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3181
EP 3203
DI 10.1007/s11042-020-09144-6
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000552190000009
OA hybrid
DA 2024-07-18
ER

PT J
AU Garg, S
   Mankad, SH
AF Garg, Sanjay
   Mankad, Sapan H.
TI Voice liveness detection under feature fusion and cross-environment
   scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Anti-spoofing; Countermeasures; Replay attacks;
   Liveness detection
ID SPEAKER VERIFICATION; COUNTERMEASURES; COEFFICIENTS; CHALLENGES; TRENDS
AB Detecting playback spoofing attacks in speaker verification system is a big challenge. Recent studies on ASVspoof challenges show that replay attacks are the most difficult to recognize. Reasonable performance is expected from such antispoofing systems to avoid malicious access attempts on voice biometrics enabled systems for possible commercial deployment. We present a study on filterbank based short-term cepstral features for liveness detection to counter replay spoofing attacks on speaker verification systems. These systems are evaluated on ASVspoof 2017 version 2.0 dataset. Experimental investigation is carried out on standalone and fused features to assess the performance of the antispoofing systems using spoofing detection equal error rate (EER). Improvement of 20.47%and 21.51%is obtained over baseline system using standalone and fused approaches, respectively. We also explore the impact of proposed static inverted Mel frequency cepstral coefficients (IMFCC) based system under mismatched conditions by training and testing it in different environments (with different background conditions) alongwith other systems. Results show that the proposed system outperforms other systems used in this study in all experiments.
C1 [Garg, Sanjay; Mankad, Sapan H.] Nirma Univ, Inst Technol, CSE Dept, Ahmadabad, Gujarat, India.
C3 Nirma University
RP Mankad, SH (corresponding author), Nirma Univ, Inst Technol, CSE Dept, Ahmadabad, Gujarat, India.
EM sgarg@nirmauni.ac.in; sapanmankad@nirmauni.ac.in
RI Mankad, Sapan/GVU-3026-2022; Mankad, Sapan/AAD-4963-2021; Garg,
   Sanjay/ABA-1398-2020
OI Mankad, Sapan/0000-0002-1499-0725; Garg, Sanjay/0000-0002-2279-9373
CR Alam J, 2017, EUR SIGNAL PR CONF, P101, DOI 10.23919/EUSIPCO.2017.8081177
   Alegre F., 2014, 2014 International Conference of the Biometrics Special Interest Group (BIOSIG), P1
   Alkan M, 2017, SURV REV, V49, P370, DOI 10.1080/00396265.2016.1180777
   [Anonymous], 2012, 20 ACM C MULTIMEDIA
   Asbai N, 2013, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP 2013), P30
   Chaudhari Puja Ramesh, 2018, Computational Signal Processing and Analysis. Select Proceedings of ICNETS2: LNEE 490, P195, DOI 10.1007/978-981-10-8354-9_17
   Das RK, 2017, PATTERN RECOGN LETT, V98, P26, DOI 10.1016/j.patrec.2017.08.004
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Delgado H., 2018, Asvspoof 2017 version 2.0: meta-data analysis and baseline enhancements
   Hanilçi C, 2018, MULTIMED TOOLS APPL, V77, P16099, DOI 10.1007/s11042-017-5181-0
   Hanilçi C, 2017, 2017 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P1187
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Kamble M, 2018, AS PAC SIGN INF PROC
   Kinnunen T, 2017, INT CONF ACOUST SPEE, P5395, DOI 10.1109/ICASSP.2017.7953187
   Kumar K, 2011, INT CONF ACOUST SPEE, P4784
   Mankad SH, 2019, LECT NOTES COMPUT SC, V11942, P400, DOI 10.1007/978-3-030-34872-4_44
   Mankad SH, 2018, TENCON IEEE REGION, P2473, DOI 10.1109/TENCON.2018.8650091
   Muckenhirn H, 2017, IEEE-ACM T AUDIO SPE, V25, P2098, DOI 10.1109/TASLP.2017.2743340
   Patel TB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2062
   Poddar A, 2018, IET BIOMETRICS, V7, P91, DOI 10.1049/iet-bmt.2017.0065
   Rao KR, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4020-6629-0
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Revathi A, 2019, MULTIMED TOOLS APPL, V78, P1569, DOI 10.1007/s11042-018-6258-0
   Sahidullah M., 2015, INTERSPEECH
   Sanchez J, 2015, IEEE T INF FOREN SEC, V10, P810, DOI 10.1109/TIFS.2015.2398812
   Saratxaga I, 2016, SPEECH COMMUN, V81, P30, DOI 10.1016/j.specom.2016.04.001
   Sriskandaraja K, 2017, ASIAPAC SIGN INFO PR, P1195, DOI 10.1109/APSIPA.2017.8282211
   Tian XH, 2016, INT CONF ACOUST SPEE, P2119, DOI 10.1109/ICASSP.2016.7472051
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   Todisco Massimiliano, 2019, INTERSPEECH 2019 20
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Witkowski M, 2017, INTERSPEECH, P27, DOI 10.21437/Interspeech.2017-776
   Wu ZZ, 2017, IEEE J-STSP, V11, P588, DOI 10.1109/JSTSP.2017.2671435
   Wu ZZ, 2016, IEEE-ACM T AUDIO SPE, V24, P768, DOI 10.1109/TASLP.2016.2526653
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Yoon SH, 2020, IEEE ACCESS, V8, P36080, DOI 10.1109/ACCESS.2020.2974290
   Yu H, 2017, IEEE ACCESS, V5, P4779, DOI 10.1109/ACCESS.2017.2687041
NR 37
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26951
EP 26967
DI 10.1007/s11042-020-09281-y
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000549798800001
DA 2024-07-18
ER

PT J
AU Shrivastava, N
   Bharti, J
AF Shrivastava, Neeraj
   Bharti, Jyoti
TI Breast tumor detection and classification based on density
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; Mammography; Seed region growing; Threshold; Image
   segmentation; Seed point; Magnetic resonance images
ID DEEP LEARNING APPROACH; SEGMENTATION; MASS
AB Breast cancer is the most widely disease in women and is considered one of the biggest causes of death in women. Early detection, classification, and diagnosis of this cancer are essential to reduce the death cases. The efficiency of the diagnosis of breast cancer depends on the accuracy of the segmentation of the tumor and its classification. Before the segmentation of mammogram images, it is necessary to extract the Region of Interest (ROI) because it can assume a significant job in the efficiency of tumor detection. In this study, the method of automatic extraction of ROI from the mammogram image is presented. After that, the preprocessing of both mammogram and MR images has been done which removes the noise and enhances the contrast of the images. On the processed images, segmentation of tumors from mammograms as well as Magnetic Resonance Imaging (MRI) breast images has been performed using automatic seed point extraction and threshold calculation in Seeded Region Growing (SRG). After the successful detection of breast tumor area, classification of the tumor as benign or malignant has been done. The test was performed on three publicly available data sets; RIDER breast MR Images, Mammographic Image Analysis Society (MIAS), and Digital Database for Screening Mammography (DDSM). The test showed that classification accuracy is better than previously accessible cutting edge techniques, which is 91.4%. The proposed method not only detects the shape and size of the tumor from both mammograms and MR Images but also efficiently classifies the tumor as benign or malignant.
C1 [Shrivastava, Neeraj; Bharti, Jyoti] MANIT, Dept Comp Sci & Engn, Bhopal, India.
   [Shrivastava, Neeraj] IES, IPSA, Dept Comp Sci & Engn, Indore, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Shrivastava, N (corresponding author), MANIT, Dept Comp Sci & Engn, Bhopal, India.; Shrivastava, N (corresponding author), IES, IPSA, Dept Comp Sci & Engn, Indore, India.
EM neeraj0209@gmail.com; jyoti2202@gmail.com
RI Bharti, Dr.jyoti/B-8557-2017; SHRIVASTAVA, NEERAJ/AAD-6109-2019
OI Bharti, Dr.jyoti/0000-0003-0237-9029; SHRIVASTAVA,
   NEERAJ/0000-0001-6090-6048
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], 2020, CANC FACTS FIG 2015
   [Anonymous], 2013, INT J RECENT TECHNOL
   [Anonymous], P IEEE C COMP VIS PA
   AqilBurney S. M., 2014, Int. J. Comput. Appl., V96, P1, DOI [10.5120/16779-6360, DOI 10.5120/16779-6360]
   Badawy SM, 2017, INT J ADV COMPUT SC, V8, P117, DOI 10.14569/IJACSA.2017.081016
   Chu JH, 2015, MED PHYS, V42, P3859, DOI 10.1118/1.4921612
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Comelli A, 2017, LECT NOTES COMPUT SC, V10484, P706, DOI 10.1007/978-3-319-68560-1_63
   Dhungel N, 2017, MED IMAGE ANAL, V37, P114, DOI 10.1016/j.media.2017.01.009
   Fan D, P 27 INT JOINT C ART, P698
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gallego-Ortiz C, 2016, RADIOLOGY, V278, P679, DOI 10.1148/radiol.2015150241
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Isa NAM, 2008, SOFT COMP IND APPL, p[49, 1]
   Jui-Ying C, 2019, MEDICINE, V98, P1
   Kalavathi P, 2014, INT J EMERG TRENDS T, V3, P251
   Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0
   Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855
   Liu L, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI), P79, DOI 10.1109/BMEI.2015.7401477
   Maitra IK, 2012, COMPUT METH PROG BIO, V107, P175, DOI 10.1016/j.cmpb.2011.05.007
   Mao N, 2019, J AM COLL RADIOL, V16, P485, DOI 10.1016/j.jacr.2018.09.041
   Melouah A., 2015, IPAC 15 BATN ALG NOV, P1, DOI 10.1145/2816839.2816892
   Padhi DR, 2018, INDIAHCI'18: PROCEEDINGS OF THE 9TH INDIAN CONFERENCE ON HUMAN COMPUTER INTERACTION, P29, DOI 10.1145/3297121.3297125
   Petitjean C, 2011, MED IMAGE ANAL, V15, P169, DOI 10.1016/j.media.2010.12.004
   Phophalia A., 2012, ASIAN J COMPUT SCI I, V2, P89
   Ponnusamy J, 2016, INT J PRINTING PACKA, V21, P1428
   Ponnusamy JAR, 2016, ACAD J CANC RES, V9, P75
   Prabha D S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI 10.17485/ijst/2016/v9i8/87907
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Saleek MM, 2018, ADV INTELLIGENT SYST, V640, P331
   Samala RK, 2019, IEEE T MED IMAGING, V38, P686, DOI 10.1109/TMI.2018.2870343
   Shah NN., 2014, INT J COMPUT APPL, V87, P114
   Shao HY, 2015, IEEE IMAGE PROC, P1424, DOI 10.1109/ICIP.2015.7351035
   Shrivastava Neeraj, 2020, IEIE Transactions on Smart Processing & Computing, V9, P119
   Shrivastava N, 2022, IETE J RES, V68, P2463, DOI 10.1080/03772063.2019.1710583
   Shrivastava N, 2016, COMM COM INF SC, V628, P143, DOI 10.1007/978-981-10-3433-6_18
   Suckling J., MAMMOGRAPHIC IMAGE A
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Wang H, HINDWAI J HEALTHCARE, V2018, P1
   Wang J, 2018, PATTERN RECOGN, V78, P12, DOI 10.1016/j.patcog.2018.01.009
   Wang ZQ, 2016, NEURAL COMPUT APPL, V27, P227, DOI 10.1007/s00521-014-1764-0
   Wei JL, 2019, INT C ELECTR MACH SY, P1246, DOI [10.1109/icems.2019.8921503, 10.1109/edssc.2019.8753979]
   Yousefikamal P., 2019, COMPUTER VISION PATT, V2019, P1
   Zhang J, 2020, P IEEE INT C COMP VI, P1
   Zhao JJ, 2019, PROCEEDINGS OF THE 2ND ACM SIGSOFT INTERNATIONAL WORKSHOP ON SOFTWARE QUALITIES AND THEIR DEPENDENCIES (SQUADE' 19), P1, DOI 10.1145/3340495.3342749
NR 48
TC 16
Z9 17
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26467
EP 26487
DI 10.1007/s11042-020-09220-x
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549313700003
DA 2024-07-18
ER

PT J
AU Feng, YQ
   Wang, LW
AF Feng, Yanqing
   Wang, Lunwen
TI Speeding up the tracking and updating of the convolutional residual
   tracking networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Visual tracking; Residual network; Correlation filter
ID OBJECT TRACKING
AB The convolutional residual tracking networks (CREST) uses a single-layer convolutional network as the implicit correlation filter, which can perform end-to-end training and has the advantages of simple model structure and high tracking accuracy. However, the forward and backward convolution computation in its base layer is too excessive, resulting in its slow tracking speed. In addition, the back-propagation algorithm is adopted as the fine-tuning method during online updating, thus the parameter updating efficiency is quite slow. When the object appearance changes rapidly, there is a large risk of losing the tracked object. In this paper, we improve the residual convolutional network model and its training method. The improved model explicitly uses the base layer as a correlation filter and uses the frequency domain parameters to describe the base layer. When updating online, the base layer is pre-trained using the standard learning method of the correlation filter to efficiently learn the main information of the object appearance, and then the back-propagation algorithm is utilized to optimize the entire model. Thus, both the forward and backward convolution computation in the improved base layer can be conducted efficiently in the frequency domain, which significantly reduces the amount of computation and improves the tracking speed and online update efficiency. Extensive experiments on the evaluation data sets validate the effectiveness of the improved method.
C1 [Feng, Yanqing; Wang, Lunwen] Natl Univ Def Technol, Coll Elect Engn, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, LW (corresponding author), Natl Univ Def Technol, Coll Elect Engn, Changsha, Hunan, Peoples R China.
EM fengyanqingnudt@nudt.edu.cn; wanglunwenmust@nudt.edu.cn
FU special region of national defence-related science and technology
   innovation of China [17-H863-01-ZT-003-204-03]
FX This work was supported in part by the special region of national
   defence-related science and technology innovation of China
   (17-H863-01-ZT-003-204-03). The authors would like to thank the
   associate editor and anonymous reviewers for their valuable comments and
   suggestions to improve this paper.
CR [Anonymous], ARXIV170100392
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Ionescu C, 2015, IEEE I CONF COMP VIS, P2965, DOI 10.1109/ICCV.2015.339
   Lederer C, 2014 BRIT MACH VIS C, P1
   Li KP, 2020, IEEE T IMAGE PROCESS, V29, P3311, DOI 10.1109/TIP.2019.2959249
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang N., ARXIV150104587
   Wang N, 2013, P ADV NEURAL INFORM
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
NR 23
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41343
EP 41360
DI 10.1007/s11042-020-09290-x
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000547247600001
DA 2024-07-18
ER

PT J
AU Khan, MA
   Akram, T
   Sharif, M
   Javed, K
   Raza, M
   Saba, T
AF Khan, Muhammad Attique
   Akram, Tallha
   Sharif, Muhammad
   Javed, Kashif
   Raza, Mudassar
   Saba, Tanzila
TI An automated system for cucumber leaf diseased spot detection and
   classification using improved saliency method and deep features
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Disease segmentation; Deep features; Features
   selection; Feature classification
ID COLOR; HISTOGRAM; FUSION
AB In the agriculture farming business, weeds, pests, and other plant diseases are the major reason for monetary misfortunes around the globe. It is an imperative factor, as it causes a significant diminution in both quality and capacity of crop growing. Therefore, detection and taxonomy of various plants diseases are crucial, and it demands utmost attention. However, this loss can be minimized by detecting crops diseases at their earlier stages. In this article, we are primarily focusing on a cucumber leaf diseases detection and classification method, which is comprised of five stages including image enhancement, infected spots segmentation, deep features extraction, feature selection, and finally classification. Image enhancement is performed as a pre-processing step, which efficiently improves the local contrast and makes infected regions more visible, which is later segmented with a novel Sharif saliency-based (SHSB) method. The segmentation results are further improved by fusing active contour segmentation and proposed saliency method. This step is much important for correct and useful feature extraction. In this work, pre-trained models- VGG-19 & VGG-M are utilized for features extraction and later select the most prominent features based on three selected parameters - local entropy, local standard deviation, and local interquartile range method. These refined features are finally fed to multi-class support vector machine for diseases identification. To prove the authenticity of the proposed algorithm, five cucumber leaf diseases are considered and classified to achieve classification accuracy of 98.08% in 10.52 seconds. Additionally, the proposed method is also compared with the recent techniques so as to prove its authenticity.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
   [Khan, Muhammad Attique; Sharif, Muhammad; Raza, Mudassar] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Punjab, India.
   [Akram, Tallha] COMSATS Univ Islamabad, Dept Elect Engn, Wah Campus, Islamabad, Pakistan.
   [Javed, Kashif] SMME NUST, Dept Robot, Islamabad, Pakistan.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
C3 NITEC University; COMSATS University Islamabad (CUI); COMSATS University
   Islamabad (CUI); National University of Sciences & Technology -
   Pakistan; Prince Sultan University
RP Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.; Khan, MA (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Punjab, India.
EM attique.khan440@gmail.com; muhammadsharifmalik@yahoo.com;
   tsaba@psu.edu.sa
RI Khan, Dr. Muhammad Attique/AAX-2644-2021; Akram, Tallha/KPB-3017-2024;
   Sharif, Muhammad/AAB-8376-2022; Sharif, Muhammad/ACD-2598-2022; Saba,
   Tanzila/D-4593-2018; Raza, Mudassar/I-4000-2015; khan,
   sajid/HGE-2406-2022
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Akram,
   Tallha/0000-0003-4578-3849; Sharif, Muhammad/0000-0002-7258-8400; Saba,
   Tanzila/0000-0003-3138-3801; Raza, Mudassar/0000-0001-9124-9298; 
CR Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   [Anonymous], 2014, INF TECHNOL J, DOI DOI 10.3923/itj.2014.2129.2136
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Bai XB, 2019, COMPUT ELECTRON AGR, V158, P211, DOI 10.1016/j.compag.2019.02.002
   Camargo A, 2009, BIOSYST ENG, V102, P9, DOI 10.1016/j.biosystemseng.2008.09.030
   Cao ZT, 2017, LECT NOTES COMPUT SC, V10530, P121, DOI 10.1007/978-3-319-67434-6_14
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Dong P., 2013, OPEN J APPL SCI, V3, P27, DOI DOI 10.4236/OJAPPS.2013.31B006
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Gavhale KR, 2014, IOSR journal of computer engineering (iosr-jce), V16, P10, DOI [DOI 10.9790/0661-16151016, 10.9790/0661-16151016]
   Haijian Y, 2016, T CHINESE SOC AGR MA, V5, P36
   Hollins P, 2017, PROC EUR CONF GAME, P262
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Kaur RP, 2016, INT J COMPUT MAT SCI, V5, DOI 10.1142/S2047684116500093
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Y, 2005, IEEE IJCNN, P849
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Ma JC, 2017, COMPUT ELECTRON AGR, V142, P110, DOI 10.1016/j.compag.2017.08.023
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Patil J K, 2011, Int. J. Eng. Trends Technol, V2, P73
   Sabrol H., 2016, INT J COMPUT SCI INF, V14, P622
   Samajpati BJ, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1015, DOI 10.1109/ICCSP.2016.7754302
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sofka M, 2006, IEEE T MED IMAGING, V25, P1531, DOI 10.1109/TMI.2006.884190
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian YW, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P262, DOI 10.1109/CISP.2008.29
   Wang X, 2015, INT C INF TECHN MAN, P112115
   Wong TT, 2017, IEEE T KNOWL DATA EN, V29, P2417, DOI 10.1109/TKDE.2017.2740926
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Zhang C, 2016, APPL ENG AGRIC, V32, P713, DOI 10.13031/aea.32.11148
   Zhang SW, 2017, COMPUT ELECTRON AGR, V140, P338, DOI 10.1016/j.compag.2017.06.016
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhang SW, 2016, NEUROCOMPUTING, V205, P341, DOI 10.1016/j.neucom.2016.04.034
   Zhou B, 2015, 3 INT C MAT MECH MAN
NR 41
TC 66
Z9 67
U1 4
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18627
EP 18656
DI 10.1007/s11042-020-08726-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800061
DA 2024-07-18
ER

PT J
AU Yook, J
   Kim, K
   Son, BC
   Park, S
AF Yook, Juhye
   Kim, Kwangki
   Son, Byung Chang
   Park, Sejin
TI A translating program usability analysis of alternative multimedia
   mathematics materials for the blind
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind; Reading disability; Alternative multimedia materials; Visual
   expressions in mathematics; Braille-graphics translation
AB The purpose of this study is to analyze the performance of the braille translation program on formulas, graphs, and tables of middle school mathematics. To do so, the forms of expression and the degrees and accuracy in the EBS braille math workbooks and in the braille conversion of EBS general math workbooks by using braille translation software were analyzed. As a result, there were omissions of 4 decorative visual data in the linear equations, 6 required and decorative visual data in the direct proportions, and 7 required and decorative visual data in the number of diagonals of the polygons in the EBS braille workbook files. There were 2 marked omissions of graphs in the direct proportions and graphs, and 3 unmarked omissions of pictures in the diagonals of the polygons, in the EBS braille math workbook files. There were 2 inadequate full translation of formulas in the solving linear equations, 2 unmarked omissions of graphs in the direct proportions and graphs, and in the diagonal of the polygons, there were 5 unmarked omissions of formulas and 3 unmarked omissions of formulas, translated from the EBS general math workbooks. The study showed braille errors in EBS braille math workbooks and braille translation errors by the braille translation program in math formulas, pictures, and graphs of EBS general math workbooks. The study presented specific braille translation errors occurred and the reasons as to math formulas, pictures, and graphs. The limitation of the study was that the proper types and ways of braille-translation of visual materials in math were not addressed. Braille translation programs used in Korea should be all comparatively analyzed and an improvement solution should be designed with the participation of blind users and braille translators in the future study.
C1 [Yook, Juhye; Son, Byung Chang; Park, Sejin] Korea Nazarene Univ, Dept Rehabil Technol, Wolbong Ro 48, Cheonan Si 31172, Chungnam Do, South Korea.
   [Kim, Kwangki] Korea Nazarene Univ, Dept IT Convergence, Wolbong Ro 48, Cheonan Si 31172, Chungnam Do, South Korea.
RP Kim, K (corresponding author), Korea Nazarene Univ, Dept IT Convergence, Wolbong Ro 48, Cheonan Si 31172, Chungnam Do, South Korea.
EM jhyook@kornu.ac.kr; k2kim@kornu.ac.kr; bcson@kornu.ac.kr;
   psj0357@naver.com
FU National Research Foundation of Korea (NRF) - MSIT
   [NRF-2018R1A4A1025559]
FX This research was supported by the National Research Foundation of Korea
   (NRF) funded by the MSIT (NRF-2018R1A4A1025559).
CR Agün RS, 2004, MULTIMED TOOLS APPL, V24, P29, DOI 10.1023/B:MTAP.0000033982.50288.14
   Kim D. I., 2013, J HCI SOC KOREA, V2013, P944
   Kim YH, 2015, TOX RESEARCH, V31, P157, DOI 10.5487/TR.2015.31.2.157
   Kim Young-il, 2018, [The Korean Journal of Visual Impairment, 시각장애연구], V34, P1, DOI 10.35154/kjvi.2018.34.3.1
   Korea Eudcational Broadcasting System (EBS) Editing Department, 2018, MIDDL SCH NEW LEARN, V1
   Korea Eudcational Broadcasting System (EBS) for the Disabled Homepage, 2018, MIDDL SCH NEW LEARN, V1
   류현, 2015, [Journal of Special Education: Theory and Practice, 특수교육저널:이론과 실천], V16, P361
   이재화, 2012, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V15, P951
   Lee Kyung Rhym, 2012, [Special Education Research, 특수교육], V11, P59
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   National Institute of Korean Language, 2018, 2017 REV KOR BRAILL
   National Institute of Korean Language, 2017, 2017 REV KOR MATH BR
   Park H-S, 2018, THESIS
   Quax P, 2016, MULTIMED TOOLS APPL, V75, P4383, DOI 10.1007/s11042-015-2481-0
   Yook Juhye, 2019, [Journal of Rehabilitation Research, 재활복지], V23, P47
NR 15
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34643
EP 34659
DI 10.1007/s11042-020-09153-5
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000542539100002
DA 2024-07-18
ER

PT J
AU Panchal, HD
   Shah, HB
AF Panchal, Hitesh D.
   Shah, Hitesh B.
TI Video tampering dataset development in temporal domain for video forgery
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frame deletion; Frame insertion; Frame duplication; TDTVD; Smart
   tampering; Multiple tampering
AB Videos are tampered by the forgers to modify or remove their content for malicious purpose. Many video authentication algorithms are developed to detect this tampering. At present, very few standard and diversified tampered video dataset is publicly available for reliable verification and authentication of forensic algorithms. In this paper, we propose the development of total 210 videos for Temporal Domain Tampered Video Dataset (TDTVD) using Frame Deletion, Frame Duplication and Frame Insertion. Out of total 210 videos, 120 videos are developed based on Event/Object/Person (EOP) removal or modification and remaining 90 videos are created based on Smart Tampering (ST) or Multiple Tampering. 16 original videos from SULFA and 24 original videos from YouTube (VTD Dataset) are used to develop different tampered videos. EOP based videos include 40 videos for each tampering type of frame deletion, frame insertion and frame duplication. ST based tampered video contains multiple tampering in a single video. Multiple tampering is developed in three categories (1) 10-frames tampered (frame deletion, frame duplication or frame insertion) at 3-different locations (2) 20-frames tampered at 3- different locations and (3) 30-frames tampered at 3-different locations in the video. Proposed TDTVD dataset includes all temporal domain tampering and also includes multiple tampering videos. The resultant tampered videos have video length ranging from 6 s to 18 s with resolution 320X240 or 640X360 pixels. The database is comprised of static and dynamic videos with various activities, like traffic, sports, news, a ball rolling, airport, garden, highways, zoom in zoom out etc. This entire dataset is publicly accessible for researchers, and this will be especially valuable to test their algorithms on this vast dataset. The detailed ground truth information like tampering type, frames tampered, location of tampering is also given for each developed tampered video to support verifying tampering detection algorithms. The dataset is compared with state of the art and validated with two video tampering detection methods.
C1 [Panchal, Hitesh D.] Gujarat Technol Univ, Nr Vishwakarma Govt Engn Coll, Nr Visat Three Rd,Visat Gandhinagar Highway, Ahmadabad 382424, Gujarat, India.
   [Panchal, Hitesh D.] Govt Polytech, Elect & Commun Engn Dept, Near Panjra Pol, Ahmadabad 380015, Gujarat, India.
   [Shah, Hitesh B.] GH Patel Coll Engn & Technol, Elect & Commun Engn Dept, Bakrol Rd, Anand 388120, Gujarat, India.
C3 Gujarat Technological University
RP Panchal, HD (corresponding author), Gujarat Technol Univ, Nr Vishwakarma Govt Engn Coll, Nr Visat Three Rd,Visat Gandhinagar Highway, Ahmadabad 382424, Gujarat, India.; Panchal, HD (corresponding author), Govt Polytech, Elect & Commun Engn Dept, Near Panjra Pol, Ahmadabad 380015, Gujarat, India.
EM hdpanchal.phd@gmail.com; hiteshshah@gcet.ac.in
RI SHAH, HITESH/AFJ-6810-2022
OI PANCHAL, HITESHKUMAR/0000-0002-6783-0442
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ardizzone E, 2015, IMAGE ANAL PROCESSIN, V9279, P665, DOI [10.1007/978-3-319-23231-7, DOI 10.1007/978-3-319-23231-7]
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   COVERAGE-A NOVEL DATABASE FOR COPY-MOVE FORGERY DETECTION Advanced Digital Sciences Center, 2016, COV NOV DAT COPY MOV
   DAvino D., 2017, Media Watermarking, Security, and Forensics 2017, Burlingame, CA, USA, 29 January 2017-2 February 2017, V29, P92
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gupta P, 2019, EMERGING TRENDS EXPE, DOI [10.1007/978-981-13-2285-3, DOI 10.1007/978-981-13-2285-3]
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Lo Presti L, 2014, MULTIMED TOOLS APPL, V68, P777, DOI 10.1007/s11042-012-1079-z
   Qadir Ghulam, 2012, Surrey university library for forensic analysis (SULFA) of video content, P121
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Le TT, 2017, IEEE IMAGE PROC, P2094, DOI 10.1109/ICIP.2017.8296651
   Wang Q., 2014, J. Comput. Commun, V2, P51, DOI [DOI 10.4236/jcc.2014.24008, 10.4236/jcc.2014.24008, DOI 10.4236/JCC.2014.24008]
   Wang W, 2013, IEEE INT CON DIS, P244, DOI 10.1109/ICDCSW.2013.69
   Zampoglou M, 2019, LECT NOTES COMPUT SC, V11295, P374, DOI 10.1007/978-3-030-05710-7_31
   Zampoglou M, 2015, IEEE INT CONF MULTI
NR 23
TC 12
Z9 12
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24553
EP 24577
DI 10.1007/s11042-020-09205-w
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542548200002
DA 2024-07-18
ER

PT J
AU Li, LL
   Si, YJ
   Wang, LL
   Jia, ZH
   Ma, HB
AF Li, Liangliang
   Si, Yujuan
   Wang, Linli
   Jia, Zhenhong
   Ma, Hongbing
TI A novel approach for multi-focus image fusion based on SF-PAPCNN and
   ISML in NSST domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Spatial frequency (SF); Parameter-adaptive
   pulse coupled neural network (PAPCNN); Sum-modified-laplacian (SML);
   Nonsubsampled shearlet transform (NSST)
ID CONTOURLET TRANSFORM; ENHANCEMENT; SIMILARITY; NETWORK; FILTER
AB In order to further improve the contrast and sharpness of fused image, a novel multi-focus image fusion algorithm based on spatial frequency-motivated parameter-adaptive pulse coupled neural network (SF-PAPCNN) and improved sum-modified-laplacian (ISML) in nonsubsampled shearlet transform (NSST) domain is proposed in this paper. In its procedural steps, at first, the source images are decomposed into low-frequency and high-frequency components by NSST. The low-frequency components are fused by SF-PAPCNN model, the PAPCNN is designed to estimate the PCNN parameters adaptively according to the input information, and the high-frequency components are fused by ISML model. Finally, the inverse NSST is employed to the fused coefficients to reconstruct the fused image. The superiority of the proposed fusion technique is confirmed by many analytical experimentations on the gray and color multi-focus image data sets. Compared with the state-of-the-art image fusion methods, the proposed fusion algorithm has superior performance in terms of visual inspection and objective evaluation.
C1 [Li, Liangliang; Si, Yujuan] Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.
   [Si, Yujuan] Jilin Univ, Zhuhai Coll, Sch Elect Informat Engn, Zhuhai 519041, Peoples R China.
   [Wang, Linli] Xinxiang Univ, Sch Math & Informat Sci, Xinxiang 453003, Henan, Peoples R China.
   [Jia, Zhenhong] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Ma, Hongbing] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Jilin University; Jilin University; Xinxiang University; Xinjiang
   University; Tsinghua University
RP Si, YJ (corresponding author), Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.; Si, YJ (corresponding author), Jilin Univ, Zhuhai Coll, Sch Elect Informat Engn, Zhuhai 519041, Peoples R China.
EM siyj@jlu.edu.cn
RI Li, Chun/KBC-9591-2024
OI Li, Liangliang/0000-0001-7354-7494
FU Science and Technology Development Plan Project of Jilin Province
   [20170414017GH, 20190302035GX]; Natural Science Foundation of Guangdong
   Province [2016A030313658]; Innovation and Strengthening School Project
   (provincial key platform and major scientific research project) by
   Guangdong Government [2015KTSCX175]; Zhuhai Government [2015YXXK02-2];
   Guangdong Government Funds [2016GDYSZDXK036]
FX This work was supported by the Science and Technology Development Plan
   Project of Jilin Province under Grant Nos. 20170414017GH and
   20190302035GX; the Natural Science Foundation of Guangdong Province
   under Grant No. 2016A030313658; the Innovation and Strengthening School
   Project (provincial key platform and major scientific research project)
   supported by Guangdong Government under Grant No. 2015KTSCX175; the
   Premier-Discipline Enhancement Scheme Supported by Zhuhai Government
   under Grant No. 2015YXXK02-2; the Premier Key-Discipline Enhancement
   Scheme Supported by Guangdong Government Funds under Grant No.
   2016GDYSZDXK036.
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Chen Y, 2019, MICRON, V123, DOI 10.1016/j.micron.2019.102684
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chen Y, 2011, IEEE T NEURAL NETWOR, V22, P880, DOI 10.1109/TNN.2011.2128880
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Du CB, 2019, OPTIK, V176, P567, DOI 10.1016/j.ijleo.2018.09.089
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fan D. P., 2020, IEEE T NEURAL NETWOR
   Fu ZZ, 2016, INFRARED PHYS TECHN, V77, P114, DOI 10.1016/j.infrared.2016.05.012
   Gu K, 2020, IEEE T EMERG TOP COM, V8, P1
   Gu K, 2020, IEEE T NETW SERV MAN, V17, P332, DOI 10.1109/TNSM.2019.2941869
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   He GQ, 2019, IET COMPUT VIS, V13, P240, DOI 10.1049/iet-cvi.2018.5496
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KJ, 2019, SOFT COMPUT, V23, P4685, DOI 10.1007/s00500-018-3118-9
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   Kong WW, 2018, ELECTRON LETT, V54, P1282, DOI 10.1049/el.2018.5415
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li LL, 2020, J MED IMAG HEALTH IN, V10, P1785, DOI 10.1166/jmihi.2020.3111
   Li LL, 2019, MULTIMED TOOLS APPL, V78, P18077, DOI 10.1007/s11042-019-7203-6
   Li QL, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072143
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li WS, 2017, J MED IMAG HEALTH IN, V7, P16, DOI 10.1166/jmihi.2017.1980
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu D, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063036
   Liu SQ, 2019, IEEE ACCESS, V7, P56367, DOI 10.1109/ACCESS.2019.2900376
   Liu SQ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/156043
   Liu XB, 2019, INT J THEOR PHYS, V58, P734, DOI 10.1007/s10773-018-3971-4
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu ZY, 2020, NEUROCOMPUTING, V387, P210, DOI 10.1016/j.neucom.2020.01.045
   Liu ZH, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107456
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Piao Y, 2020, P 34 AAAI C ART INT
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Tan W, 2018, APPL OPTICS, V57, P10092, DOI 10.1364/AO.57.010092
   Wan W, 2018, SIGNAL IMAGE VIDEO P, V12, P959, DOI 10.1007/s11760-018-1240-x
   Wu ZP, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/2167871
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yang YY, 2019, IEEE ROBOT AUTOM LET, V4, P1647, DOI 10.1109/LRA.2019.2896917
   Ye FJ, 2019, MULTIMED TOOLS APPL, V78, P14683, DOI 10.1007/s11042-018-6850-3
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhan K, 2017, ARCH COMPUT METHOD E, V24, P573, DOI 10.1007/s11831-016-9182-3
   Zhan K, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033014
   Zhang J, 2020, P IEEE C COMP VIS PA
   Zhang LH, 2020, MULTIMED TOOLS APPL, V79, P13647, DOI 10.1007/s11042-019-08586-x
   Zhang P, 2018, INFRARED PHYS TECHN, V93, P223, DOI 10.1016/j.infrared.2018.08.004
   Zhao JA, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P2239, DOI [10.1109/ITNEC.2019.8729040, 10.1109/itnec.2019.8729040]
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
NR 59
TC 20
Z9 22
U1 1
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24303
EP 24328
DI 10.1007/s11042-020-09154-4
EA JUN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541402000003
DA 2024-07-18
ER

PT J
AU Kerfa, D
   Saidane, A
AF Kerfa, Djoudi
   Saidane, AbdelKader
TI An efficient algorithm for fast block matching motion estimation using
   an adaptive threshold scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block matching algorithm; Threshold; Motion estimation
ID SEARCH ALGORITHM
AB A new block-matching algorithm for fast motion estimation is proposed. The so-called Star Diamond Search with Adaptive Threshold(SDth)is two steps algorithm. Adaptive threshold for matching errors eliminates invalid blocks early from motion estimation procedure. Then it performs a search for final motion vector with a Star Diamond Algorithm. Proposed SD(th)algorithm has been implemented and tested using several video sequences. SD(th)algorithm is also compared with previous search methods to demonstrate its utility.
C1 [Kerfa, Djoudi; Saidane, AbdelKader] Natl Polytech Sch Oran, Elect Engn Dept, CaSiCCE Lab, Maurice Audin Ex ENSET, BP 1523 El MNaouar, Es Senia 31000, Algeria.
RP Kerfa, D (corresponding author), Natl Polytech Sch Oran, Elect Engn Dept, CaSiCCE Lab, Maurice Audin Ex ENSET, BP 1523 El MNaouar, Es Senia 31000, Algeria.
EM djoudi.kerfa@enp-oran.dz; abdelkader.saidande@enp-oran.dz
OI /0000-0002-0615-9464
CR [Anonymous], 1981, P NAT TEL C NEW ORL
   Basher HA, 2011, IEEE SOUTHEASTCON, P384, DOI 10.1109/SECON.2011.5752971
   DEVOS L, 1989, IEEE T CIRCUITS SYST, V36, P1309, DOI 10.1109/31.44347
   Gangodkar Durgaprasad, 2011, International Journal of Information and Communication Technology, V3, P131, DOI 10.1504/IJICT.2011.041744
   Kerfa D, 2019, PROC SPIE, V10996, DOI 10.1117/12.2505732
   Kerfa D, 2016, MULTIMED TOOLS APPL, V75, P3161, DOI 10.1007/s11042-014-2428-x
   Kim BG, 2006, PATTERN RECOGN LETT, V27, P1325, DOI 10.1016/j.patrec.2006.01.004
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lu JH, 1997, IEEE T CIRC SYST VID, V7, P429, DOI 10.1109/76.564122
   Manap RA, 2010, 2010 2 INT C COMP EN, pV3
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P2447, DOI 10.1007/s11042-018-6353-2
   Pandian S. Immanuel Alex, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P43, DOI 10.1007/978-981-13-1927-3_5
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Richardson IEG, 2010, H 264 MPEG 4 VIDEO C
   Ryong-Baek, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/715651
   Saha A, 2018, PERS UBIQUIT COMPUT, V22, P163, DOI 10.1007/s00779-017-1058-5
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   Wang X, 2010, 2ND INTERNATIONAL SYMPOSIUM ON COMPUTER NETWORK AND MULTIMEDIA TECHNOLOGY (CNMT 2010), VOLS 1 AND 2, P89
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yasakethu SLP, 2018, MULTIMED TOOLS APPL, V77, P30683, DOI 10.1007/s11042-018-6157-4
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 21
TC 9
Z9 10
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24173
EP 24184
DI 10.1007/s11042-020-09040-z
EA JUN 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541201200002
DA 2024-07-18
ER

PT J
AU Billah, M
   Waheed, S
AF Billah, Mustain
   Waheed, Sajjad
TI Minimum redundancy maximum relevance (mRMR) based feature selection from
   endoscopic images for automatic gastrointestinal polyp detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minimum redundancy maximum relevance (mRMR); Video endoscopy; Ensemble
   classifier; Feature selection; Convolutional Neural Network (CNN); Color
   Wavelet (CW); Feature extraction
AB In this paper, a computer based system has been proposed as a support to gastrointestinal polyp detection. It can detect and classify gastrointestinal polyps from endoscopic video. Color wavelet (CW) features and convolutional neural network (CNN) features of endoscopic video frames are extracted. Mutual information based feature selection technique-Minimum redundancy maximum relevance (mRMR) is used to scale down feature vector. Instead of using a single classifier, Bootstrap Aggregrating (Bagging)- an ensemble classifier is used. Proposed system has been assessed against different public databases and our own datasets. Evaluation shows that, the system outperforms the existing methods.
C1 [Billah, Mustain; Waheed, Sajjad] Mawlana Bhashani Sci & Technol Univ MBSTU, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
C3 Mawlana Bhashani Science & Technology University
RP Billah, M (corresponding author), Mawlana Bhashani Sci & Technol Univ MBSTU, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
EM mustainbillahx@gmail.com; swaheed.iu@gmail.com
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Anguelov D, 2016, SSD SINGLE SHOT MULT
   [Anonymous], 2013, AM J SCI ENG
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Berrendero JR, 2016, J STAT COMPUT SIM, V86, P891, DOI 10.1080/00949655.2015.1042378
   Billah M, 2018, BIOMED ENG LETT, V8, P69, DOI 10.1007/s13534-017-0048-x
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Darrell R Girshick T., 2014, Rich feature hierarchies for accurate object detection and semantic segmentation. arXiv
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS., 2007, INT J INF TECHNOLOGY, V13, P46
   Kopelman Y, 2019, J GASTROENTEROL COMP, V3, P101
   Li BU, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2326, DOI 10.1109/ROBIO.2009.5420455
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Mehmood R., 2017, J APPL ENVIRON BIOL, V7, P118
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Nagito ATJHS, 2019, INT SOC OPTICS PHOTO, V11049, p110492O
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   Redmon A., 2017, P IEEE C COMP VIS PA, P7263, DOI 10.1109/cvpr.2017.690
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sun MJ, 2019, J MED IMAG HEALTH IN, V9, P126, DOI 10.1166/jmihi.2019.2550
   Unler A, 2011, INFORM SCIENCES, V181, P4625, DOI 10.1016/j.ins.2010.05.037
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 30
TC 23
Z9 23
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23633
EP 23643
DI 10.1007/s11042-020-09151-7
EA JUN 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539889900002
DA 2024-07-18
ER

PT J
AU Kaya, Y
AF Kaya, Yasin
TI A novel method for optic disc detection in retinal images using the
   cuckoo search algorithm and structural similarity index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optic disc localization; Cuckoo search algorithm; Structural similarity
   index; Medical imaging
ID DIGITAL FUNDUS IMAGES; NERVE HEAD; SEGMENTATION; VESSELS; MODEL
AB Accurate and reliable optic disk (OD) localization is vital for eye disease monitoring and fundus image analysis. This paper describes a novel technique to localize the OD in retinal images using the cuckoo search algorithm and the structural similarity index measure (SSIM). SSIM uses the average OD value to compare with candidate OD. Hence, the average OD values were calculated from randomly selected images. The average OD values and the colored retina fundus images were given as input to the proposed algorithm. The adaptive histogram equalization method was applied to ensure that the brightness and contrast values in all images were within a similar range. Next, candidate OD centers were calculated using the search algorithm and the similarity value between each candidate OD and the average OD was determined. Finally, the computed similarity was maximized by the search algorithm and the true OD center was found. The performance of the OD detection algorithm was evaluated on three public datasets. The experimental results showed that proposed method achieved comparable performance, without employing complex image pre-processing, compared with the state-of-the-art techniques. Specifically, the accuracy of 100%, 100%, and 97.5% were obtained for ONHSD, DRIONS and DRIVE datasets, respectively.
C1 [Kaya, Yasin] Adana Alparslan Turkes Sci & Technol Univ, Dept Comp Engn, Adana, Turkey.
C3 Adana Alparslan Turkes Science & Technology University
RP Kaya, Y (corresponding author), Adana Alparslan Turkes Sci & Technol Univ, Dept Comp Engn, Adana, Turkey.
EM ykaya@atu.edu.tr
RI KAYA, Yasin/E-8858-2018
OI KAYA, Yasin/0000-0002-9074-0189
CR Abdullah AS, 2020, MED BIOL ENG COMPUT, V58, P25, DOI 10.1007/s11517-019-02032-8
   Abed S, 2019, J ENG RES-KUWAIT, V7, P161
   Abed S, 2016, APPL SOFT COMPUT, V49, P146, DOI 10.1016/j.asoc.2016.08.015
   Aquino A, 2010, IEEE T MED IMAGING, V29, P1860, DOI 10.1109/TMI.2010.2053042
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Dai BS, 2017, PATTERN RECOGN, V64, P226, DOI 10.1016/j.patcog.2016.11.017
   Foracchia M, 2004, IEEE T MED IMAGING, V23, P1189, DOI 10.1109/TMI.2004.829331
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Jintasuttisak T, 2014, INT C CONTR AUTOMAT, P692, DOI 10.1109/ICCAS.2014.6987868
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kande GB, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P535
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Lu SJ, 2011, IEEE T MED IMAGING, V30, P2126, DOI 10.1109/TMI.2011.2164261
   Lu SJ, 2011, IEEE T BIO-MED ENG, V58, P88, DOI 10.1109/TBME.2010.2086455
   Luo ZL, 2019, TRAIT SIGNAL, V36, P265, DOI 10.18280/ts.360310
   Morales S, 2013, IEEE T MED IMAGING, V32, P786, DOI 10.1109/TMI.2013.2238244
   Park M., 2006, INT C COMPUTER GRAPH, P141
   Pereira C, 2013, MED BIOL ENG COMPUT, V51, P295, DOI 10.1007/s11517-012-0994-5
   Rahebi J, 2016, MED BIOL ENG COMPUT, V54, P453, DOI 10.1007/s11517-015-1330-7
   Rasta Seyed Hossein, 2015, J Med Signals Sens, V5, P40
   Sekhar S, 2008, I S BIOMED IMAGING, P1577, DOI 10.1109/ISBI.2008.4541312
   Sevik U, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.4.046006
   Sivaprasad S, 2012, SURV OPHTHALMOL, V57, P347, DOI 10.1016/j.survophthal.2012.01.004
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu D, 2006, IEEE T BIO-MED ENG, V53, P341, DOI 10.1109/TBME.2005.862571
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Youssif AAHAR, 2008, IEEE T MED IMAGING, V27, P11, DOI 10.1109/TMI.2007.900326
   Yu S, 2018, IEEE J BIOMED HEALTH, V22, P886, DOI 10.1109/JBHI.2017.2710201
   Zhang DB, 2016, IEEE J BIOMED HEALTH, V20, P333, DOI 10.1109/JBHI.2014.2365514
   Zhou W, 2020, INT J MACH LEARN CYB, V11, P55, DOI 10.1007/s13042-019-00939-0
NR 32
TC 11
Z9 11
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23387
EP 23400
DI 10.1007/s11042-020-09080-5
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977500001
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Wang, GD
   Pan, ZK
   Zhang, JH
   Zhai, GT
AF Wang, Ziying
   Wang, Guodong
   Pan, Zhenkuan
   Zhang, Jiahua
   Zhai, Guangtao
TI Fast stripe noise removal from hyperspectral image via multi-scale
   dilated unidirectional convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Multi-scale dilated convolution; Residual strategy;
   Stripe noise removal; Unidirectional convolution
ID MODIS DATA; WAVELET
AB Hyperspectral images (HSIs) are often contaminated by noises due to the multi-detector imaging systems, which greatly affects the subsequent HSIs interpretation and application. The 3D HSIs deliver extra spectral information, which makes the most existing destriping algorithms hardly satisfied, and the complete stripes removal and less test time consuming remain to be overcome. To meet these challenges, we present a multi-scale dilated unidirectional convolution network (MsDUC) with the following contributions. First, the deep learning-based method can fully exploit and preserve spatial-spectral correlations in 3D HSIs while the conventional methods failed to realize it. Second, different dilated convolution learns different scale features, so the introduced multi-scale dilated convolution could get more contextual information for the final restoration. Third, the clear directional signature of stripe noise and the unidirectional total variation (UTV) model inspired us to put forward the unidirectional convolution to capture the directional signature of stripe, meanwhile, the less trainable parameters and the utilized residual strategy speed up the learning process. Experimental results have shown that our method outperforms many of the state-of-the-art methods in both image restoration performance and test running time. Our code can be download from.
C1 [Wang, Ziying; Wang, Guodong; Pan, Zhenkuan; Zhang, Jiahua] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
   [Zhai, Guangtao] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
C3 Qingdao University; Shanghai Jiao Tong University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
EM doctorwgd@gmail.com
RI Zhai, Guangtao/X-5949-2019
OI Zhai, Guangtao/0000-0001-8165-9322; Wang, Ziying/0009-0002-8825-0612
FU Natural Science Foundation of Shandong Province [ZR2019MF050]; "Taishan
   Scholar" Project of Shandong Province
FX This work was supported by the Natural Science Foundation of Shandong
   Province (No. ZR2019MF050) and "Taishan Scholar" Project of Shandong
   Province.
CR Acito N, 2011, IEEE T GEOSCI REMOTE, V49, P1325, DOI 10.1109/TGRS.2010.2081370
   Arad B, 2016, LECT NOTES COMPUT SC, V9911, P19, DOI 10.1007/978-3-319-46478-7_2
   Bouali M, 2011, IEEE T GEOSCI REMOTE, V49, P2924, DOI 10.1109/TGRS.2011.2119399
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Carfantan H, 2010, IEEE T GEOSCI REMOTE, V48, P1860, DOI 10.1109/TGRS.2009.2033587
   Chang Y, 2019, IEEE T GEOSCI REMOTE, V57, P667, DOI 10.1109/TGRS.2018.2859203
   Chang Y, 2015, IEEE T IMAGE PROCESS, V24, P1852, DOI 10.1109/TIP.2015.2404782
   Chang Y, 2014, IEEE GEOSCI REMOTE S, V11, P1051, DOI 10.1109/LGRS.2013.2285124
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Datt B, 2003, IEEE T GEOSCI REMOTE, V41, P1246, DOI 10.1109/TGRS.2003.813206
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Freiberger M, 2010, APPL OPTICS, V49, P3741, DOI 10.1364/AO.49.003741
   Gadallah FL, 2000, INT J REMOTE SENS, V21, P2505, DOI 10.1080/01431160050030592
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   KAUTSKY J, 1984, COMPUT VISION GRAPH, V26, P271, DOI 10.1016/0734-189X(84)90213-5
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu XX, 2018, IEEE T GEOSCI REMOTE, V56, P808, DOI 10.1109/TGRS.2017.2755016
   Liu XX, 2016, ISPRS ANN PHOTO REM, V3, P57, DOI 10.5194/isprsannals-III-6-57-2016
   Liu XX, 2016, IEEE T GEOSCI REMOTE, V54, P3049, DOI 10.1109/TGRS.2015.2510418
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724
   Münch B, 2009, OPT EXPRESS, V17, P8567, DOI 10.1364/OE.17.008567
   Pande-Chhetri R, 2011, ISPRS J PHOTOGRAMM, V66, P620, DOI 10.1016/j.isprsjprs.2011.04.003
   Rakwatin P, 2007, IEEE T GEOSCI REMOTE, V45, P1844, DOI 10.1109/TGRS.2007.895841
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Roth S, 2005, PROC CVPR IEEE, P860
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shen HF, 2009, IEEE T GEOSCI REMOTE, V47, P1490, DOI 10.1109/TGRS.2008.2005780
   Shi WZ, 2017, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.2017.8296427
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tarabalka Y, 2010, IEEE T SYST MAN CY B, V40, P1267, DOI 10.1109/TSMCB.2009.2037132
   Torres J, 2001, OPT ENG, V40, P1309, DOI 10.1117/1.1383996
   Wang W, 2019, IEEE I CONF COMP VIS, P2142, DOI 10.1109/ICCV.2019.00223
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei YL, 2018, IEEE T FUZZY SYST, V26, P504, DOI 10.1109/TFUZZ.2017.2686352
   Xiao PF, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2854303
   Yan LX, 2012, OPT LETT, V37, P2778, DOI 10.1364/OL.37.002778
   Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yu F., 2015, ARXIV
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 48
TC 2
Z9 2
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23007
EP 23022
DI 10.1007/s11042-020-09065-4
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538196300001
DA 2024-07-18
ER

PT J
AU Datta, B
   Dutta, K
   Roy, S
AF Datta, Biswajita
   Dutta, Koushik
   Roy, Sudipta
TI Data hiding in virtual bit-plane using efficient Lucas number sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Number system; Virtual bit-planes; Fibonacci number;
   Lucas number; Lexicographical ordering
ID STEGANOGRAPHY; ALGORITHM
AB This paper introduces a steganography technique using the concept of virtual bit-plane. Purposely another number system has been used in this technique instead of binary to hide the target data. After that embedding of target data is done on different bit-planes. Here for conversion, Lucas Number system is used. The Lucas sequence is almost similar to Fibonacci, instead 1 and 2 it starts with 2 and 1. It helps to increase robustness by embedding data at the second bit-plane with a slight change of +/- 1. Here for embedding target data, Blue and Green channels of RGB color image are used. Red channel is used as indicator for proper extraction of target data at the receiver side. The indicator is used to avoid lexicographically higher order to consider for number representation. It may seem that the use of two channels for embedding reduces the capacity. But it does not really happen. The skip of pixel to follow Zekendrof's rule for handling redundant representation by other existing methods, make the proposed one more capacitive than other. In order to establish its efficiency over the state-of-art-works the proposed method is analyzed by using different parameters and compared with relevant techniques. It has been found from the tested result that the proposed one is better. The stego quality of the method is also maintained along with the robustness and capacity. The PSNR of the proposed method is within the acceptable range, even in the highest embedding capacity.
C1 [Datta, Biswajita] St Thomas Coll Engn & Technol, Dept Comp Sci & Engn, Kolkata, India.
   [Datta, Biswajita; Roy, Sudipta] Calcutta Univ, Dept Comp Sci & Engn, Technol Campus, Kolkata 700098, India.
   [Dutta, Koushik] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Roy, Sudipta] Washington Univ, PRTTL, St Louis, MO 63110 USA.
C3 University of Calcutta; Jadavpur University; Washington University
   (WUSTL)
RP Roy, S (corresponding author), Calcutta Univ, Dept Comp Sci & Engn, Technol Campus, Kolkata 700098, India.; Roy, S (corresponding author), Washington Univ, PRTTL, St Louis, MO 63110 USA.
EM biswa.jita@gmail.com; koushik.it.22@gmail.com; sudiptaroy0l@yahoo.com
RI Dutta, Koushik Nandan/HJA-9904-2022; Roy, Sudipta/T-5231-2019
OI Roy, Sudipta/0000-0001-5161-9311
CR Abdulla A. A., 2014, P SPIE, V9120
   Abdulla Alan A., 2014, LECT NOTES COMPUTER, P151
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   [Anonymous], 1972, Fibonacci Quart.
   Aroukatos Nikolaos George, 2014, International Journal of Advanced Computer Science, V4, P544
   Aroukatos N. G., 2012, P 9 INT C INF TECHN
   Battisti F., 2006, P 3 INT C COMP DEV C
   Brown J.L., 1969, FIBONACCI QUART, V7, P243
   Cachin C, 2004, INFORM COMPUT, V192, P41, DOI 10.1016/j.ic.2004.02.003
   Cao WJ, 2012, IEEE SYS MAN CYBERN, P1185, DOI 10.1109/ICSMC.2012.6377892
   Cha SH, 2002, PATTERN RECOGN, V35, P1355, DOI 10.1016/S0031-3203(01)00118-2
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Crandall R., 2005, Prime numbers: A computational perspective, DOI 10.1007/0-387-28979-8
   Dey Sandipan, 2007, 2007 3rd International Symposium on Information Assurance and Security, P101
   Dey S, 2010, INT J COMPUT SCI APP, V7, P1
   Dey S, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P473
   Dumitrescu D., 2017, IACR CRYPTOLOGY EPRI, P341
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Hoggatt V. E., 1969, Fibonacci and Lucas Numbers
   HOGGATT VE, 1982, FIBONACCI QUART, V20, P193
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Hussain M, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060041
   Ker AD, 2008, PROC SPIE, V6819, DOI 10.1117/12.766820
   Kutter M., 1999, P SOC PHOTO-OPT INS, V3657, P219
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Mammi E, 2008, PROC SPIE, V6982, DOI 10.1117/12.780605
   Mammi E, 2009, PROC SPIE, V7245, DOI 10.1117/12.807535
   Michiel Hazewinkel:., 2001, Encyclopedia of Mathematics
   Patsakis Constantinos, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P18, DOI 10.1109/ICACTE.2010.5579623
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   PUNDDANGE S, 2017, INDIAN J SCI TECHNOL, V10
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Saeed MA, 2016, IEEE INT CONF INTELL, P1, DOI 10.1109/INTELSE.2016.7475142
   Nguyen TD, 2013, INT C INFO SCI APPL
   Vyas A, 2015, RES J PHARM BIOL CHE, V6, P5
   Weisstein W., ZECKENDORFS THEOREM
   Westfeld A., 1999, LECT NOTES COMPUTER, P61, DOI [10.1007/107197245, DOI 10.1007/107197245]
NR 40
TC 4
Z9 4
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22673
EP 22703
DI 10.1007/s11042-020-08979-3
EA MAY 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789500004
DA 2024-07-18
ER

PT J
AU Xu, JC
   Du, QF
AF Xu, Jincheng
   Du, Qingfeng
TI Learning neural networks for text classification by exploiting label
   relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text classification; Label relations; Hierarchical agglomerative
   clustering
AB Text classification has been a fundamental problem in the realm of Natural Language Processing (NLP), and a variety of approaches have been proposed with the development of deep learning. Despite recent progress, most existing approaches deal with the problem of multi-class text classification in a flat way, assuming that text labels are semantically independent. This assumption doesn't always hold in realistic settings, since there usually exist hierarchical or within-layer dependencies in the latent label space, especially when we consider larger label sets. In this paper, we propose a label clustering algorithm to exploit the underlying structure of label relations, and express the stacked concept relationships in the form of a two-layer label space. Next, we present two different neural network structures to capture inter-layer and intra-layer label relations. The first model HSNN organizes a group of local classifiers in a hierarchical way according to the exploited label space, while the second model LSNN takes advantages of text representations in different granularity levels and the bidirectional inferences with recurrent connections to make predictions. Finally, we evaluate our methods on three benchmark datasets. The results empirically demonstrate that both models are capable of leveraging the exploited label relations to improve text classification performance.
C1 [Xu, Jincheng; Du, Qingfeng] Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
C3 Tongji University
RP Xu, JC (corresponding author), Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
EM xujincheng@tongji.edu.cn; du_cloud@tongji.edu.cn
RI Du, Qing/HKN-6976-2023
OI Xu, Jincheng/0000-0002-9687-6028
CR [Anonymous], 2018, INT C LEARN REPR
   Cerri R, 2014, J COMPUT SYST SCI, V80, P39, DOI 10.1016/j.jcss.2013.03.007
   Chen M., 2017, Graph Convolutional Networks for Classification with a Structured Label Space
   Chung Junyoung, 2014, ARXIV14123555
   CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P76
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Deng ZW, 2016, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2016.516
   Ding N, 2015, IEEE I CONF COMP VIS, P1161, DOI 10.1109/ICCV.2015.138
   EIBAND M, 2018, BERT PRETRAINING DEE, P211
   Grauman Kristen., 2011, Advances in neural information processing systems, P621
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu HX, 2016, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2016.323
   Hwang S., 2012, Annu. Conf. Neural Inform. Process. Syst. (NIPS), P1718
   Joulin A., 2016, P 15 C EUR CHAPT ASS, V1, P427
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Kingma D. P., 2014, arXiv
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ordonez V, 2013, IEEE I CONF COMP VIS, P2768, DOI 10.1109/ICCV.2013.344
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
   SONG J, 2017, ARXIV170802478
   Song J., 2018, ARXIV181211004
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Zhang TY, 2018, AAAI CONF ARTIF INTE, P6053
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
NR 31
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22551
EP 22567
DI 10.1007/s11042-020-09063-6
EA MAY 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000559642600001
DA 2024-07-18
ER

PT J
AU El-Kfafy, HS
   Abd-Elnaby, M
   Rihan, M
   Nassar, MAE
   El-Fishawy, AS
   Dessouky, MI
   El-Rabaie, ESM
   Abd El-Samie, FE
AF El-Kfafy, Hala Shawky
   Abd-Elnaby, Mohamed
   Rihan, Mohamed
   Nassar, Mohamed Abd-Elsalam
   El-Fishawy, Adel S.
   Dessouky, Moawad, I
   El-Rabaie, El-Sayed M.
   Abd El-Samie, Fathi E.
TI Efficient remote access system based on decoded and decompressed speech
   signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote access system; LPC; Decimation; Maximum entropy; Regularized
   solution; CS; SI
AB This paper investigates the effect of both decoding and decompression on the Speaker Identification (SI) in a remote access system. The coding and compression processes are used for the communication purpose as a normal action taken for voice communication over Internet or mobile networks. In the proposed system, the speech signal is coded with the Linear Predictive Coding (LPC) technique. Also, the speech signal is compressed using two techniques. The first technique depends on decimation process to compress the signal. The signal can be recovered using inverse solutions. The inverse solutions include maximum entropy and regularized reconstruction. The second technique is the Compressive Sensing (CS) and the speech signal can be reconstructed using linear programming. The coded or compressed speech signal is transmitted into the receiver via a wireless communication channel. At the receiver, the received signal is decoded or decompressed, and then SI is performed on the decoded or decompressed speech signal. The performance of coding and compression techniques is evaluated using some metrics such as Perceptual Evaluation of Speech Quality (PESQ) and Dynamic Time Warping (DTW). The objective of SI is to achieve the security needed for the remote access system, and this security can be increased using coding and compression processes. In the SI system, the feature vectors are captured from different discrete transforms such as Discrete Wavelet Transform (DWT), Discrete Cosine Transform (DCT), and Discrete Sine Transform (DST), besides the time domain. The recognition rate for all transforms is computed to evaluate the performance of the SI system.
C1 [El-Kfafy, Hala Shawky; Abd-Elnaby, Mohamed; Rihan, Mohamed; Nassar, Mohamed Abd-Elsalam; El-Fishawy, Adel S.; Dessouky, Moawad, I; El-Rabaie, El-Sayed M.; Abd El-Samie, Fathi E.] Menouf Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia, Egypt.
   [Abd-Elnaby, Mohamed] Taif Univ, Coll Comp & Informat Technol, Dept Comp Engn, Al Hawiya 21974, Saudi Arabia.
   [Abd El-Samie, Fathi E.] Princess NourahBint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Taif University;
   Princess Nourah bint Abdulrahman University
RP El-Kfafy, HS (corresponding author), Menouf Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia, Egypt.
EM h.kfafy@yahoo.com; moh_naby@yahoo.com;
   mohamed.elmelegy@el-eng.menofia.edu.eg; nassar54@yahoo.com;
   aelfishawy@hotmail.com; dr_moawad@yahoo.com; srabiel@yahoo.com;
   fathi_sayed@yahoo.com
RI Elmeligy, Mohamed Rihan Emam/AAB-7907-2022; Rihan,
   Mohamed/ACT-2475-2022; Elmeligy, Mohamed/AAW-3702-2020; Sayed,
   Fathi/HRA-4752-2023; Nassar, Mohamed/IQW-5116-2023
OI Elmeligy, Mohamed Rihan Emam/0000-0003-4030-2559; Sayed,
   Fathi/0000-0001-8749-9518; El-Fishawy, Adel/0000-0003-1567-457X;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Abd El-Samie FE, 2011, SPRINGERBRIEF SPEECH, P1, DOI 10.1007/978-1-4419-9698-5_1
   ADEL H, ECG SIGNAL COMPRESSI
   AHMED S, 2011, COMPRESSIVE SENSING
   ANDREWS HC, 1977, DIGITAL IMAGE RESTAU
   Apasiba A., 2016, Int. J. Comput. Appl., V136, P35
   BACHU RG, 2008, ASEE ZONE C P, P1
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Bradbury J, 2000, Linear predictive coding
   Desai S., 2013, International Journal of Emerging Technology and Advanced Engineering, V3, P18
   El-Khamy SE, 2005, OPT ENG, V44, DOI 10.1117/1.2042947
   GALATSANOS NP, 1989, IEEE T ACOUST SPEECH, V37, P415, DOI 10.1109/29.21708
   Hohage T., 2002, LECT NOTES INVERSE P
   Honda M., 2003, NTT Technical Review, V1, P24
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Ikram M, 2016, P 2016 INTERNET MEAS, P349, DOI DOI 10.1145/2987443.2987471
   Jagtap SK, 2015, PROCEDIA COMPUT SCI, V49, P253, DOI 10.1016/j.procs.2015.04.251
   Kabanikhin SI, 2019, J INVERSE ILL-POSE P, V27, P453, DOI 10.1515/jiip-2019-5001
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   OCINNEIDE A, 2008, LINEAR PREDICTION PR
   PELEG N, 2009, LINEAR PREDICTION CO
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Shin JH, 1998, IEEE T CONSUM ELECTR, V44, P1042, DOI 10.1109/30.713232
   SINGH N, 2018, P DIAL 2018 NAT C DI, P5
   Spratling MW, 2017, BRAIN COGNITION, V112, P92, DOI 10.1016/j.bandc.2015.11.003
   Taylor P., 2009, Text-to-Speech Synthesis
   Tirumala SS, 2017, EXPERT SYST APPL, V90, P250, DOI 10.1016/j.eswa.2017.08.015
   Tsilifis P, 2019, J COMPUT PHYS, V380, P29, DOI 10.1016/j.jcp.2018.12.010
   Vaidyanathan P.P., 2007, SYNTHESIS LECT SIGNA, V2, P1, DOI DOI 10.2200/S00086ED1V01Y200712SPR003
NR 29
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22293
EP 22324
DI 10.1007/s11042-019-08150-7
EA MAY 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534441900002
DA 2024-07-18
ER

PT J
AU Naz, F
   Shoukat, IA
   Ashraf, R
   Iqbal, U
   Rauf, A
AF Naz, Farah
   Shoukat, Ijaz Ali
   Ashraf, Rehan
   Iqbal, Umer
   Rauf, Abdul
TI An ASCII based effective and multi-operation image encryption method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image stenography; Image decryption; Key generation;
   ASCII; MSE; PSNR
ID HYBRID GENETIC ALGORITHM; CHAOS; MAP; PERMUTATION; MODEL
AB The main challenge for American Standard Code for Information Interchange (ASCII) based image encryption methods is to increase security with less computational cost. Earlier, well known image encryption techniques are not only deficient in performance but also lacked in embedding of confidential data in an image using ASCII based methods. Therefore, this study aims to contribute an ASCII based efficient and secure image encryption method having additional feature of embedding confidential data in an image. Moreover, the embedding process is not static but it is dynamic as compared to the existing work. The novelty of proposed method encompasses optimal security, effective encryption speed and randomized embedding of secret data in an image even of having multi-operations. The proposed method was evaluated experimentally with variety of tests such as Pixel correlation analysis, Number of Pixels Change Rate (NPCR), Unified Average Changing Intensity (UACI), Histogram, Entropy, Peak Signal to Noise Ratio (PSNR), and Mean Square Error (MSE) including encryption decryption time. Thus the experimental results show that the proposed method is optimally secure and outperformed in image encryption as well as in randomized embedding of confidential data than the existing techniques.
C1 [Naz, Farah; Shoukat, Ijaz Ali; Iqbal, Umer; Rauf, Abdul] Riphah Int Univ, Riphah Coll Comp, Faisalabad Campus, Faisalabad, Pakistan.
   [Ashraf, Rehan] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
C3 National Textile University - Pakistan
RP Iqbal, U (corresponding author), Riphah Int Univ, Riphah Coll Comp, Faisalabad Campus, Faisalabad, Pakistan.
EM Farahnaz236@yahoo.com; i.shoukat@riphahfsd.edu.pk; rehan@ntu.edu.pk;
   Umeriqbal@riphahfsd.edu.pk; abdulrauf2000.pk@gmail.com
RI Shoukat, Dr. Ijaz Ali/F-1802-2011
OI Shoukat, Dr. Ijaz Ali/0000-0002-2456-6952
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Dhiman R., 2017, ENCRYPTION DECOMPOSE
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Eom S, 2018, MATHEMATICS-BASEL, V6, DOI 10.3390/math6100202
   Gayathri J, 2018, MULTIMED TOOLS APPL, V77, P24751, DOI 10.1007/s11042-018-5675-4
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Gurubaran BS, 2016, PROCEDIA COMPUT SCI, V93, P791, DOI 10.1016/j.procs.2016.07.296
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jiayong Tang, 2017, International Journal of High Performance Computing and Networking, V10, P515
   Jizhong Wang, 2018, International Journal of High Performance Computing and Networking, V12, P111
   Kaurav M, 2018, ARTIF CELL NANOMED B, V46, pS818, DOI 10.1080/21691401.2018.1513941
   Khan JS, 2017, INFORMATICA-LITHUAN, V28, P629, DOI 10.15388/Informatica.2017.149
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Lou YH, 2019, IEEE INT CON MULTI, P19, DOI 10.1109/ICME.2019.00012
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Sneha PS., 2019, J AMBIENT INTELL HUM, V2, P65
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Sun SL, 2019, IEEE ACCESS, V7, P123049, DOI 10.1109/ACCESS.2019.2937767
   Talarposhti KM, 2016, OPT LASER ENG, V81, P21, DOI 10.1016/j.optlaseng.2016.01.006
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2019, NONLINEAR DYNAM, V95, P2797, DOI 10.1007/s11071-018-4723-y
   Wang XY, 2017, INF SECUR J, V26, P7, DOI 10.1080/19393555.2016.1272725
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wen WY, 2016, MULTIMED TOOLS APPL, V75, P3553, DOI 10.1007/s11042-015-2464-1
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang J., 2019, International Journal of High Performance Computing and Networking, V13, P321, DOI 10.1504/IJHPCN.2019.098573
   Zhang X, 2017, KSII T INTERNET INFO, V11
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
NR 53
TC 10
Z9 10
U1 9
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22107
EP 22129
DI 10.1007/s11042-020-08897-4
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000533180600003
DA 2024-07-18
ER

PT J
AU Rabidas, R
   Arif, W
AF Rabidas, Rinku
   Arif, Wasim
TI Characterization of mammographic masses based on local photometric
   attributes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Mammography; Mass classification; ODCM; Local attributes
ID CLASSIFICATION; TRANSFORM; FEATURES
AB This paper proposes Local Photometric Attributes (LPA) for the characterization of mammographic masses as benign or malignant. LPA measures the local information over the optical density image which suppresses the background region and provides more details about the mass lesion. The evaluation of the proposed approach is conducted by incorporating the mammograms of two benchmark databases-mini-MIAS and DDSM where a ten-fold cross validation technique is employed with different classifiers-Fishers Linear Discriminant Analysis, Random forest, and Support vector machine after filtering the optimal set of features by utilizing stepwise logistic regression method. The best performance achieved by the introduced approach in terms of an area under the receiver operating characteristic (ROC) curve (A(z) value) and accuracy (A(cc)) are 0.94 and 86.90%, respectively for the mini-MIAS dataset while the same for the DDSM dataset are 0.89 and 80.76%, respectively. The competitive nature of the proposed scheme is evident by comparing the obtained results with schemes in the state-of-the-arts.
C1 [Rabidas, Rinku] Assam Univ Silchar, Dept Elect & Commun Engn, Silchar 788011, Assam, India.
   [Arif, Wasim] Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
C3 Assam University; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Rabidas, R (corresponding author), Assam Univ Silchar, Dept Elect & Commun Engn, Silchar 788011, Assam, India.
EM rabidas.rinku@gmail.com
RI Arif, Wasim/AAY-3723-2021
OI Arif, Dr Wasim/0000-0003-3065-7663
CR Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Bojar K., 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P111, DOI 10.1049/cp:20080293
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buciu I, 2011, BIOMED SIGNAL PROCES, V6, P370, DOI 10.1016/j.bspc.2010.10.003
   Calas Maria Julia Gregorio, 2012, Radiol Bras, V45, P46, DOI 10.1590/S0100-39842012000100011
   CHAKRABORTY J, 2012, IEEE Symp Comput Med Syst, P1, DOI 10.1109/CBMS.2012.6266308
   Chakraborty J, 2013, INT CONF BIOMED, P111, DOI 10.1109/BMEI.2013.6746917
   Dhurjaty S, 2016, PROC SPIE, V9783, DOI 10.1117/12.2217196
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   ELTOUKHY M, 2018, J AMBIENT INTELLIGEN
   Görgel P, 2013, COMPUT BIOL MED, V43, P765, DOI 10.1016/j.compbiomed.2013.03.008
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   HOMER MJ, MAMMOGRAPHIC INTERPR
   Liu X., 2010, 4th International Conference on Bioinformatics and Biomedical Engineering, P1
   Malek J, 2013, NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT ENVIRONMENTS (IE 2013), P9, DOI 10.1109/IE.2013.34
   Midya A, 2018, J MED BIOL ENG, V38, P457, DOI 10.1007/s40846-017-0316-3
   Midya A, 2015, I S BIOMED IMAGING, P411, DOI 10.1109/ISBI.2015.7163899
   Mudigonda NR, 2000, IEEE T MED IMAGING, V19, P1032, DOI 10.1109/42.887618
   Muramatsu C, 2016, COMPUT BIOL MED, V72, P43, DOI 10.1016/j.compbiomed.2016.03.007
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pomponiu V, 2014, PROC SPIE, V9035, DOI 10.1117/12.2044281
   PRAMANIK S, 2019, IEEE T INSTRUMENTATI, P1
   Pramanik S, 2019, IEEE T MED IMAGING, V38, P572, DOI 10.1109/TMI.2018.2867620
   RABIDAS R, 2018, P SPIE MED IM
   RABIDAS R, 2016, P SPIE MED IMAGING, V9785
   Rabidas R, 2018, IEEE J BIOMED HEALTH, V22, P826, DOI 10.1109/JBHI.2017.2715021
   Rabidas R, 2017, IET COMPUT VIS, V11, P22, DOI 10.1049/iet-cvi.2016.0163
   Ramsey F.L., 1997, STAT SLEUTH COURSE M
   Sahiner B, 1998, MED PHYS, V25, P516, DOI 10.1118/1.598228
   Sahiner B, 2001, MED PHYS, V28, P1455, DOI 10.1118/1.1381548
   Sameti M, 2009, IEEE J-STSP, V3, P46, DOI 10.1109/JSTSP.2008.2011163
   Serifovic-Trbalic A, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P228, DOI 10.1109/MIPRO.2014.6859566
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Suhail Z, 2018, IET COMPUT VIS, V12, P1060, DOI 10.1049/iet-cvi.2018.5244
   Sun L., 2010, 4th International Conference on Bioinformatics and Biomedical Engineering (iCBBE), P1
   Tahmasbi A, 2011, COMPUT BIOL MED, V41, P726, DOI 10.1016/j.compbiomed.2011.06.009
   Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097
   Tan MX, 2014, INT J COMPUT ASS RAD, V9, P1005, DOI 10.1007/s11548-014-0992-1
   Vadivel A, 2013, COMPUT BIOL MED, V43, P259, DOI 10.1016/j.compbiomed.2013.01.004
   Vapnik, 2000, NATURE STAT LEARNING, DOI [DOI 10.1007/978-1-4757-3264-1, 10.1080/00401706.1996.10484565, DOI 10.1080/00401706.1996.10484565]
   Wei CH, 2012, COMPUT METH PROG BIO, V106, P234, DOI 10.1016/j.cmpb.2010.09.002
   Xiaoming Liu, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P33, DOI 10.1109/BMEI.2011.6098328
   Zhang XY, 2017, 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P793, DOI 10.23919/SICE.2017.8105545
   2016, ACS GLOB CANC FACTS
NR 45
TC 5
Z9 5
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21967
EP 21985
DI 10.1007/s11042-020-08959-7
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000533058700001
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
   Geetha, K
   Revathi, A
AF Sasikaladevi, N.
   Geetha, K.
   Revathi, A.
TI RIGID- reversible lightweight, high payload semantically secured
   e-record hiding technique for smart city applications using
   pseudo-random matrices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic health records; Pseudo-random binary matrix; Blum-Blum-Shub;
   Semantic security
ID MEDICAL IMAGES; HIGH-CAPACITY; SEQUENCE GENERATOR; WATERMARKING;
   INTERNET; STEGANOGRAPHY; INFORMATION; ROBUST; THINGS
AB An emerging paradigm for instituting smart city that incorporates information and communication technologies demands an exponential rise in networked infrastructure and advancement of IoT. The physical world has to be monitored in real-time to introduce smart services to the public in the areas of healthcare, entertainment, education, environment, transportation, etc., Conventional healthcare is profoundly transforming into electronic healthcare that anticipates a high degree of security and privacy. Computationally efficient, highly secured algorithms are to be developed to protect electronic health records used in real-time communication for telediagnosis and treatment. This necessitates the proposed scheme named as RIGID (Reversible lIght weiGht hIgh payloaD) for ensuring reversible data mechanism to handle high payload for processing electronic health record in smart city applications by using Pseudo Random Matrices(PRM) and scrambling technique. PRBM has been employed to find the position for permutation and Pseudo Random Number matrix (PRNM) can aid substitution. The proposed RIGID scheme has endorsed a promising result when tested with standard benchmark medical / images and a set of images chosen at random from UCID repository by supporting high payload and reversibility. This scheme is capable of detecting most of the intrusions caused by signal processing and geometric attacks. Experimental investigations disclose the proposed project as an ideal choice for the exchange of EHR in IoT based healthcare system for smart city applications.
C1 [Sasikaladevi, N.] SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
   [Geetha, K.; Revathi, A.] SASTRA Deemed Univ, Dept ECE, Sch EEE, Thanjavur, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
EM sasikalade@gmail.com
RI KRISHNAN, GEETHA/IUO-9520-2023
OI KRISHNAN, GEETHA/0000-0002-8546-2719; Arunachalam,
   Revathi/0000-0001-9515-3592; , Sasikaladevi N/0000-0002-0841-502X
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P10883, DOI 10.1007/s11042-014-2212-y
   Ahmed I, 2017, 2017 FOURTH HCT INFORMATION TECHNOLOGY TRENDS (ITT), P84, DOI 10.1109/CTIT.2017.8259572
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], FUTUR GENER COMPUT S
   BLUM L, 1986, SIAM J COMPUT, V15, P364, DOI 10.1137/0215025
   Blum M., 1985, P ADV CRYPTOLOGY, P289
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Clohessy T, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017100101
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   François M, 2014, COMMUN NONLINEAR SCI, V19, P887, DOI 10.1016/j.cnsns.2013.08.032
   Gómez J, 2016, PROCEDIA COMPUT SCI, V83, P90, DOI 10.1016/j.procs.2016.04.103
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hu HP, 2013, COMPUT PHYS COMMUN, V184, P765, DOI 10.1016/j.cpc.2012.11.017
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Karajeh H, 2019, MULTIMED TOOLS APPL, V78, P18395, DOI 10.1007/s11042-019-7214-3
   Kodali RK, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P411, DOI 10.1109/RAICS.2015.7488451
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Öztürk I, 2015, NONLINEAR DYNAM, V80, P1147, DOI 10.1007/s11071-015-1932-5
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Parah SA, 2017, MULTIDIM SYST SIGN P, V28, P549, DOI 10.1007/s11045-015-0358-z
   Rangel-Espinoza K, 2018, MULTIMED TOOLS APPL, V77, P13047, DOI 10.1007/s11042-017-4931-3
   Santos A, 2014, PROC TECH, V16, P1351, DOI 10.1016/j.protcy.2014.10.152
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Takpor T., 2015, P WORLD C ENG
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
NR 38
TC 1
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12289
EP 12306
DI 10.1007/s11042-019-08475-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400045
DA 2024-07-18
ER

PT J
AU Moustafa, AN
   Gomaa, W
AF Moustafa, Abdullah N.
   Gomaa, Walid
TI Gate and common pathway detection in crowd scenes and anomaly detection
   using motion units and LSTM predictive models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd scene analysis; Motion units; MUs; Long short term memory (LSTM);
   LSTM predictive models; Tracklets; Trajectory formation; Anomaly
   detection; Video surveillance
ID FLOW
AB In this paper, we propose two approaches to analyze the crowd scenes. The first one is motion units and meta-tracking based approach (MUDAM Approach). In this approach, the scene is divided into a number of dynamic divisions with coherent motion dynamics called the motion units (MUs). By analyzing the relationships between these MUs using a proposed continuation likelihood, the scene entrance and exit gates are retrieved. A meta-tracking procedure is then applied and the scene dominant motion pathways are retrieved. To overcome the limitations of the MUDAM approach, and detect some of the anomalies, that may happen in these scenes, we proposed another new LSTM based approach. In this approach, the scene is divided into a number of static overlapped spatial regions named super regions (SRs), which cover the whole scene. Long Short Term Memory (LSTM) is used in defining a predictive model for each of the scene SRs. Each LSTM predictive model uses its SR tracklets in the training, such that, it can capture the whole motion dynamics of that SR. Using apriori known scene entrance segments, the proposed LSTM predictive models are applied and the scene dominant motion pathways are retrieved. an anomaly metric is formulated to be used with the LSTM predictive models to detect the scene anomalies. Prototypes of our proposed approaches were developed and evaluated on the challenging New York Grand Central station scene, in addition to four other crowded scenes. Four types of anomalies that may happen in the crowded scenes were defined in the context, and our proposed LSTM based approach was used in detecting these anomalies. Experimental results on anomalies detection were applied too on a number of data sets. Ov erall, the proposed approaches managed to outperform the state of the art methods in retrieving the scene gates and common pathways, in addition to detecting motion anomalies.
C1 [Moustafa, Abdullah N.; Gomaa, Walid] Egypt Japan Univ Sci & Technol, Cyber Phys Syst Lab, Alexandria, Egypt.
   [Moustafa, Abdullah N.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
   [Gomaa, Walid] Alexandria Univ, Fac Engn, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egypt-Japan University of Science &
   Technology; Egyptian Knowledge Bank (EKB); Menofia University; Egyptian
   Knowledge Bank (EKB); Alexandria University
RP Moustafa, AN (corresponding author), Egypt Japan Univ Sci & Technol, Cyber Phys Syst Lab, Alexandria, Egypt.; Moustafa, AN (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM abdalla.moustafa@ejust.edu.eg; walid.gomaa@ejust.edu.eg
FU Science and Technology Development Fund STDF 992 (Egypt) [42519]
FX This work is Funded by the Science and Technology Development Fund STDF
   992 (Egypt); Project id: 42519 - "Automatic Video Surveillance System
   for Crowd Scenes".
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   [Anonymous], 2016, P INT JOINT C ART IN
   [Anonymous], 1991, CMUCS91132
   [Anonymous], 2006, Unusual crowd activity dataset of university of minnesota
   Arias-Castro E., 2016, Journal of Machine Learning Research, V17, P1487
   Chacon J. E., 2013, COMP BANDWIDTH SELEC
   Chen K, 2016, IEEE T INTELL TRANSP, V17, P1968, DOI 10.1109/TITS.2016.2516586
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   El-Basioni BMM, 2017, WIREL COMMUN MOB COM, P1, DOI 10.1155/2017/7493269
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hassanein AS, 2018, COMPUTER VISION IMAG
   Hu M, 2008, INT C PATT RECOG, P9
   Jodoin PM, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P1, DOI 10.1109/AVSS.2013.6636607
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Pele O, 2010, LECT NOTES COMPUT SC, V6312, P749, DOI 10.1007/978-3-642-15552-9_54
   Saleemi I, 2010, PROC CVPR IEEE, P2069, DOI 10.1109/CVPR.2010.5539884
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Su H., 2016, PROC IJCAI, V1, P2
   Su H, 2013, IEEE T INF FOREN SEC, V8, P1575, DOI 10.1109/TIFS.2013.2277773
   Topkaya IS, 2016, SIGNAL IMAGE VIDEO P, V10, P795, DOI 10.1007/s11760-015-0817-x
   Tripathi G, 2019, VISUAL COMPUT, V35, P753, DOI 10.1007/s00371-018-1499-5
   Wang CJ, 2013, CHINA COMMUN, V10, P144, DOI 10.1109/CC.2013.6506940
   Wang XF, 2014, OPTIK, V125, P924, DOI 10.1016/j.ijleo.2013.07.166
   Wen ZQ, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4024
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xue H., 2017, INT C DIG IM COMP TE, P1
   Yi S, 2015, PROC CVPR IEEE, P3488, DOI 10.1109/CVPR.2015.7298971
   Zhou B, 2011, RANDOM FIELD TOPIC M
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
   Zhuang NF, 2017, IEEE INT SYM MULTIM, P61, DOI 10.1109/ISM.2017.19
   Zou Y, 2015, IEEE IMAGE PROC, P4456, DOI 10.1109/ICIP.2015.7351649
NR 42
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20689
EP 20728
DI 10.1007/s11042-020-08840-7
EA APR 2020
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528521300004
DA 2024-07-18
ER

PT J
AU Ashokkumar, SR
   MohanBabu, G
   Anupallavi, S
AF Ashokkumar, S. R.
   MohanBabu, G.
   Anupallavi, S.
TI A KSOM based neural network model for classifying the epilepsy using
   adjustable analytic wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epilepsy; Electroencephalogram (EEG); Adjustable analytic wavelet
   transform (AAWT); Fractal dimension; Kohonen self-organizing network map
   (KSOM)
ID SEIZURE DETECTION; EEG SIGNALS; AUTOMATIC DETECTION; SPIKE DETECTION;
   TIME-SERIES; CLASSIFICATION; PREDICTION; DIAGNOSIS
AB Epilepsy is a nervous disorder occurring in the cerebral cortex location of the brain which is caused by irregular harmonization of neurons. Since the existence of this disorder is between the neurons, it is tedious to diagnose correctly. Research works of epilepsy mostly done on an Electroencephalogram (EEG) signals for analyzing the neuron activity of the brain during seizures. Analyzing the continuing EEG reports manually for a patient affected by epilepsy is time-consuming, and it needs a large storage volume. The proposed paper is based on a unique method for detecting epileptic seizures by Adjustable Analytic Wavelet Transform (AAWT). This work is also focused on testing the practicability of utilizing the Kohonen network maps for predicting the dynamics of the brain states in the form of the trajectory which may provide the occurrence of the seizure event. AAWT is applied on each EEG signal to decompose EEG signals into the sub-band signals. The fractal dimension is applied to these sub-bands signals as a discriminating feature due to its nonlinear chaotic trait. The received solutions are fed into Kohonen self-organizing network map (KSOM) to get a stable performance rate for the categorization of an epileptic seizure. The results proved that the introduced methodology achieved 98.72% sensitivity, 93.90% specificity, 93.03% selectivity, and 94.12% efficiency than the existing models and provided promising classification accuracy.
C1 [Ashokkumar, S. R.; MohanBabu, G.; Anupallavi, S.] SSM Inst Engn & Technol, Dept Elect & Commun Engn, Dindigul, India.
RP Ashokkumar, SR (corresponding author), SSM Inst Engn & Technol, Dept Elect & Commun Engn, Dindigul, India.
EM srashokkumar1987@gmail.com; shamyubabu@gmail.com;
   anupallavi1991@gmail.com
RI S, Anu Pallavi/AAA-6301-2022; S R, Ashokkumar/ABJ-4705-2022; G,
   Mohanbabu/AAC-5641-2022
OI S R, Ashokkumar/0000-0001-7171-3313; 
CR Accardo A, 1997, BIOL CYBERN, V77, P339, DOI 10.1007/s004220050394
   Acharya UR, 2013, KNOWL-BASED SYST, V45, P147, DOI 10.1016/j.knosys.2013.02.014
   Acharya UR, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500093
   Altunay S, 2010, EXPERT SYST APPL, V37, P5661, DOI 10.1016/j.eswa.2010.02.045
   Andrzejak RG, 2012, PHYS REV E, V86, DOI 10.1103/PhysRevE.86.046206
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], INT J SCI RES
   [Anonymous], INT MULT
   [Anonymous], EEG PRATICA CLFNICA
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], COMPUTATIONAL INTELL
   [Anonymous], 2018, 2018 9 IFIP INT C NE, DOI DOI 10.1109/NTMS.2018.8328728
   [Anonymous], 2017, ENTROPY SWITZ, DOI DOI 10.3390/E19030092
   [Anonymous], IINT C HELD PHIL MAY
   [Anonymous], BIOINF BIOM WORKSH B
   [Anonymous], INT J TECHNOLOGY ENG
   [Anonymous], INT J INNOVATIVE RES
   [Anonymous], P IF GIS 2009 20 MAY
   [Anonymous], INT J EMERGING DEV
   [Anonymous], 2013, INT J COMPUT INTELL
   [Anonymous], CLIN NEUROPHYSIOL
   [Anonymous], P INT C HELD HONG KO
   Anupriya K, 2018, PROC IEEE INT SOFT, P208
   Azevedo CR, 2015, INT CONF ELECTR ENG
   Bajaj V, 2012, IEEE T INF TECHNOL B, V16, P1135, DOI 10.1109/TITB.2011.2181403
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Bayram I, 2013, IEEE T SIGNAL PROCES, V61, P1131, DOI 10.1109/TSP.2012.2232655
   Bhati D, 2017, DIGIT SIGNAL PROCESS, V62, P259, DOI 10.1016/j.dsp.2016.12.004
   Bhattacharyya A, 2018, NEURAL COMPUT APPL, V29, P47, DOI 10.1007/s00521-016-2646-4
   BULLMORE ET, 1994, ELECTROEN CLIN NEURO, V91, P337, DOI 10.1016/0013-4694(94)00181-2
   D'Alessandro M, 2003, IEEE T BIO-MED ENG, V50, P603, DOI 10.1109/TBME.2003.810706
   Faust O, 2015, SEIZURE-EUR J EPILEP, V26, P56, DOI 10.1016/j.seizure.2015.01.012
   Fu K, 2015, BIOMED SIGNAL PROCES, V18, P179, DOI 10.1016/j.bspc.2015.01.002
   Gajic D, 2015, FRONT COMPUT NEUROSC, V9, DOI [10.3389/fncom.7015.00038, 10.3389/fncom.2015.00038]
   Ghosh-Dastidar S, 2008, IEEE T BIO-MED ENG, V55, P512, DOI 10.1109/TBME.2007.905490
   Guo L, 2010, J NEUROSCI METH, V191, P101, DOI 10.1016/j.jneumeth.2010.05.020
   HIGUCHI T, 1988, PHYSICA D, V31, P277, DOI 10.1016/0167-2789(88)90081-4
   Hoya T., 2003, International Symposium on Independent Component Analysis and Blind Signal Separation, P197
   Hsu WY, 2010, J NEUROSCI METH, V189, P295, DOI 10.1016/j.jneumeth.2010.03.030
   James CJ, 1999, CLIN NEUROPHYSIOL, V110, P2049, DOI 10.1016/S1388-2457(99)00168-6
   James CJ, 1997, P IEEE EMBS, V18, P913, DOI 10.1109/IEMBS.1996.652638
   KATZ MJ, 1988, COMPUT BIOL MED, V18, P145, DOI 10.1016/0010-4825(88)90041-8
   Kiviluoto K, 1996, IEEE IJCNN, P294, DOI 10.1109/ICNN.1996.548907
   KOHONEN T, 1977, NEUROSCIENCE, V2, P1065, DOI 10.1016/0306-4522(77)90129-4
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kumar TS, 2015, BIOMED SIGNAL PROCES, V15, P33, DOI 10.1016/j.bspc.2014.08.014
   Kurnar M, 2017, BIOMED SIGNAL PROCES, V31, P301, DOI 10.1016/j.bspc.2016.08.018
   Kurth C, 2000, ANN BIOMED ENG, V28, P1362, DOI 10.1114/1.1331312
   Lehnertz K, 2008, J BIOL PHYS, V34, P253, DOI 10.1007/s10867-008-9090-3
   Li Y, 2016, NEUROCOMPUTING, V193, P106, DOI 10.1016/j.neucom.2016.01.062
   Li Y, 2011, IEEE T CONTR SYST T, V19, P656, DOI 10.1109/TCST.2010.2052257
   Lima CAM, 2011, ARTIF INTELL MED, V53, P83, DOI 10.1016/j.artmed.2011.07.003
   Lin CJ, 2009, NEUROCOMPUTING, V72, P1121, DOI 10.1016/j.neucom.2008.02.017
   Liu HS, 2002, IEEE T BIO-MED ENG, V49, P1557, DOI 10.1109/TBME.2002.805477
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   MARCIANI MG, 1992, INT J NEUROSCI, V66, P53, DOI 10.3109/00207459208999789
   Martis RJ, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500238
   Martis RJ, 2012, INT J NEURAL SYST, V22, DOI 10.1142/S012906571250027X
   McKight P. E., 2010, CORSINI ENCY PSYCHOL, DOI [10.1002/97804704792, DOI 10.1002/9780470479216.CORPSY0491, 10.1002/9780470479216.corpsy0491]
   Ocak H, 2009, EXPERT SYST APPL, V36, P2027, DOI 10.1016/j.eswa.2007.12.065
   Orosco L., 2011, Mintaze Kerem Gunel, Management of Epilepsy-Research, Results and Treatment, P3
   PANETRAYMOND D, 1990, ELECTROEN CLIN NEURO, V75, P474, DOI 10.1016/0013-4694(90)90134-6
   Peker M, 2016, IEEE J BIOMED HEALTH, V20, P108, DOI 10.1109/JBHI.2014.2387795
   PICKOVER CA, 1986, COMPUT GRAPH, V10, P51, DOI 10.1016/0097-8493(86)90068-3
   Polat K, 2007, APPL MATH COMPUT, V187, P1017, DOI 10.1016/j.amc.2006.09.022
   Runarsson TP, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 2, PROCEEDINGS, P673
   Samiee K, 2015, IEEE T BIO-MED ENG, V62, P541, DOI 10.1109/TBME.2014.2360101
   Schad A, 2008, CLIN NEUROPHYSIOL, V119, P197, DOI 10.1016/j.clinph.2007.09.130
   Schomer DL, 2011, Niedermeyer's Electroencephalography: Basic Principles, Clinical Applications, and Related Fields, V7e
   Scolaro GR, 2011, BIOSIGNALS 2011, P504
   Sharif MS, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/105610
   Sharma M, 2017, KNOWL-BASED SYST, V118, P217, DOI 10.1016/j.knosys.2016.11.024
   Shen M, 2000, IEE P-SCI MEAS TECH, V147, P374, DOI 10.1049/ip-smt:20000847
   Singh RK., 2014, Int. J. Eng. Res. Gen. Sci, V2, P683
   Srinivasan V, 2007, IEEE T INF TECHNOL B, V11, P288, DOI 10.1109/TITB.2006.884369
   Su M.-C., 2002, TAMKANG J SCI ENG, V5, P35
   Subasi A, 2005, EXPERT SYST APPL, V29, P343, DOI 10.1016/j.eswa.2005.04.007
   Subasi A, 2006, EXPERT SYST APPL, V31, P320, DOI 10.1016/j.eswa.2005.09.027
   Swami P, 2016, EXPERT SYST APPL, V56, P116, DOI 10.1016/j.eswa.2016.02.040
   Tzallas AT, 2009, IEEE T INF TECHNOL B, V13, P703, DOI 10.1109/TITB.2009.2017939
   Uthayakumar R, 2013, FRACTALS, V21, DOI 10.1142/S0218348X13500114
   VIGLIONE S S, 1975, Electroencephalography and Clinical Neurophysiology, V39, P435
   Wang T, 2004, CLIN NEUROPHYSIOL, V115, P2744, DOI 10.1016/j.clinph.2004.06.022
   Wilson SB, 2002, CLIN NEUROPHYSIOL, V113, P1873, DOI 10.1016/S1388-2457(02)00297-3
   Zhang CL, 2015, MECH SYST SIGNAL PR, V64-65, P162, DOI 10.1016/j.ymssp.2015.03.030
NR 85
TC 15
Z9 15
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10077
EP 10098
DI 10.1007/s11042-019-7359-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600019
OA Bronze
DA 2024-07-18
ER

PT J
AU Chen, R
   Xu, YA
AF Chen, Rong
   Xu, Yong-an
TI Threshold optimization selection of fast multimedia image segmentation
   processing based on Labview
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Threshold optimization selection; Fast multimedia image; Segmentation
   processing
ID ALGORITHM
AB With the continuous improvement of computer technology information level, multimedia image processing technology is constantly updating and progressing, and it is more and more urgent to quickly perform multimedia image recognition processing. Multimedia image recognition is an important issue in image processing. Image segmentation is the basic premise for visual analysis and pattern recognition of multimedia images. The multimedia image recognition segmentation algorithm based on threshold selection is simple in calculation and has high computational efficiency, which makes it widely used in multimedia real-time image processing systems. However, due to the variety of threshold selection, it directly affects multimedia image segmentation effectiveness. In this paper, the research and discussion on some features of the multimedia image segmentation recognition algorithm based on threshold selection and its application are carried out. The segmentation effect of the maximum entropy method and the operation time of logarithmic entropy are studied. Then, the exponential entropy is used instead of the pair. The numerical entropy is improved, and the two-dimensional maximum entropy method is improved. Combined with the Otsu method, the information of the gray level of the 4 neighbourhood pixels is added. Experimental results show that the method used in this paper can effectively shorten the calculation time, highlight the edge features, and increase the threshold automatic selection accuracy and robustness.
C1 [Chen, Rong] Jiangsu Agrianim Husb Vocat Coll, Taizhou 225300, Jiangsu, Peoples R China.
   [Xu, Yong-an] Yangzhou Univ, Coll Informat Engn, Yangzhou 225000, Jiangsu, Peoples R China.
C3 Jiangsu Agri-animal Husbandry Vocational College; Yangzhou University
RP Chen, R (corresponding author), Jiangsu Agrianim Husb Vocat Coll, Taizhou 225300, Jiangsu, Peoples R China.
EM rongc@jsahvc.edu.cn; xuyongan@yzu.edu.cn
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Alam JM, 2017, COMPUT FLUIDS, V146, P143, DOI 10.1016/j.compfluid.2017.01.015
   Borsos A, 2017, ORG PROCESS RES DEV, V21, P511, DOI 10.1021/acs.oprd.6b00242
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dixon JL, 2016, AM J SURG, V211, P1095, DOI 10.1016/j.amjsurg.2015.08.023
   Fan R. Y., 2014, ADV MAT RES, V989, P2462, DOI DOI 10.4028/www.scientific.net/AMR.989-994.2462
   Graca C, 2017, J REAL-TIME IMAGE PR, V13, P227, DOI 10.1007/s11554-015-0517-3
   He JG, 2013, APPL MECH MATER, V433-435, P288, DOI 10.4028/www.scientific.net/AMM.433-435.288
   Hussain Khalid, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0040-0
   Jiang YZ, 2015, SOFT COMPUT, V19, P2605, DOI 10.1007/s00500-014-1425-3
   Lertrusdachakul I, 2015, INT J ADV MANUF TECH, V78, P1201, DOI 10.1007/s00170-014-6290-9
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Madhloom HT, 2012, J MED SYST, V36, P2149, DOI 10.1007/s10916-011-9679-0
   Mastriani M., 2004, J MEAS SCI REV, V4, P1, DOI DOI 10.48550/ARXIV.1608.01993
   Michalski A, 2016, MED SCI MONITOR, V22, P3994, DOI 10.12659/MSM.894147
   Muk KS, 2016, INT J NANOMED, V11, P13
   Naidu M. S. R., 2018, Alexandria Engineering Journal, V57, P1643, DOI 10.1016/j.aej.2017.05.024
   Panda R, 2017, APPL SOFT COMPUT, V50, P94, DOI 10.1016/j.asoc.2016.11.011
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Song YH, 2016, J MED IMAG HEALTH IN, V6, P1750, DOI 10.1166/jmihi.2016.1884
   Stolojescu-Crisan C, 2013, ADV ELECTR COMPUT EN, V13, P85, DOI 10.4316/AECE.2013.03014
   TARIQ W, 1993, P SOC PHOTO-OPT INS, V1901, P16, DOI 10.1117/12.144794
   Wang YG, 2017, OCEAN ENG, V134, P119, DOI 10.1016/j.oceaneng.2017.02.029
   Wang ZZ, 2018, IEEE T CIRC SYST VID, V28, P2220, DOI 10.1109/TCSVT.2017.2719122
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
NR 25
TC 3
Z9 3
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9451
EP 9467
DI 10.1007/s11042-019-07775-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600062
DA 2024-07-18
ER

PT J
AU Guo, XD
AF Guo, Xin-di
TI Cognitive psychological analysis based on multilayer semantics of web
   video and feature extraction of psychological images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive psychological analysis; Multilayer video semantics; Feature
   extraction; Psychological images
AB In order to improve the accuracy of psychological analysis by extracting network video and image features, it is difficult to analyze video semantics and blur the boundaries of psychological images. In order to solve the above problems, this paper proposes a cognitive psychological analysis algorithm based on multi-layer semantics and feature extraction of psychological images in network video. Firstly, this algorithm proposes a hierarchical semantic description of network video. It can be divided into two stages: network video layering and semantic template based on layering. Then, the algorithm divides the mental image into multiple segmentation. Each segmentation focuses on the impact of different network video and different types of image features on data convergence. At the same time, interface blurring processing mechanism and image data semantic hierarchical classification method are designed. Finally, the simulation results show that the proposed algorithm is credible, feasible and effective.
C1 [Guo, Xin-di] Baotou Med Coll, Dept Psychol, Sch Basic Med & Forens Pathol, Baotou 014030, Inner Mongolia, Peoples R China.
C3 Baotou Medical College
RP Guo, XD (corresponding author), Baotou Med Coll, Dept Psychol, Sch Basic Med & Forens Pathol, Baotou 014030, Inner Mongolia, Peoples R China.
EM 545975077@qq.com
CR Akfirat S, 2016, SOC INDIC RES, V127, P413, DOI 10.1007/s11205-015-0953-2
   EAGLY AH, 1983, AM PSYCHOL, V38, P971
   Fang XZ, 2018, IEEE T NEUR NET LEAR, V29, P5228, DOI 10.1109/TNNLS.2018.2796133
   Gorman C.A., 2018, Consulting Psychology Journal: Practice and Research, V70, P129, DOI DOI 10.1037/CPB0000102
   Guo XQ, 2017, J KIDNEY CANCER VHL, V4, P1, DOI 10.15586/jkcvhl.2017.56
   Gustafsson M, 2016, EUR J CLIN PHARMACOL, V72, P987, DOI 10.1007/s00228-016-2058-5
   Hou SJ, 2017, PATTERN RECOGN, V68, P66, DOI 10.1016/j.patcog.2017.03.003
   Jayarajah U, 2017, INDIAN J PSYCHOL MED, V39, P63, DOI 10.4103/0253-7176.198944
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Jeunet C, 2016, PROG BRAIN RES, V228, P3, DOI 10.1016/bs.pbr.2016.04.002
   Kim H, 2018, IEEE T MULTIMEDIA, V20, P2415, DOI 10.1109/TMM.2018.2806224
   Liu YQ, 2018, IET SOFTW, V12, P520, DOI 10.1049/iet-sen.2018.0006
   Manzoor T, 2018, IEEE CONTR SYST LETT, V2, P163, DOI 10.1109/LCSYS.2017.2777898
   Mathew J, 2018, IEEE ACCESS, V6, P3433, DOI 10.1109/ACCESS.2017.2745903
   McKay D, 2018, BEHAV THER, V49, P286, DOI 10.1016/j.beth.2017.07.002
   Pawar K, 2019, WORLD WIDE WEB, V22, P571, DOI 10.1007/s11280-018-0582-1
   Seyedhosseini M, 2016, IEEE T PATTERN ANAL, V38, P951, DOI 10.1109/TPAMI.2015.2473846
   Shishikui Y, 2018, IEEE T BROADCAST, V64, P498, DOI 10.1109/TBC.2018.2829118
   Stratou G, 2017, IEEE T AFFECT COMPUT, V8, P190, DOI 10.1109/TAFFC.2016.2614300
   Wei Z, 2019, IEEE T INSTRUM MEAS, V68, P197, DOI 10.1109/TIM.2018.2834058
   Wolfe SE, 2017, WATER INT, V42, P1, DOI 10.1080/02508060.2016.1248093
   Ye XM, 2018, TSINGHUA SCI TECHNOL, V23, P561, DOI 10.26599/TST.2018.9010021
   Yu LL, 2019, IET IMAGE PROCESS, V13, P57, DOI 10.1049/iet-ipr.2018.5488
   Yue GH, 2018, IEEE T IND ELECTRON, V65, P2525, DOI 10.1109/TIE.2017.2739708
   Zhuang YT, 2018, IEEE T CIRC SYST VID, V28, P76, DOI 10.1109/TCSVT.2016.2606648
NR 25
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9207
EP 9223
DI 10.1007/s11042-019-7245-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600047
DA 2024-07-18
ER

PT J
AU Liu, YL
AF Liu, Yuling
TI RETRACTED: Research on multimedia play mode and image optimization based
   on compensation factor adaptive model (Retracted article. See vol. 81,
   pg. 39823, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Compensation factor self-adaptation; Multimedia playback; Image
   optimization
ID VIDEO; SELECTION
AB When traditional multimedia network video image is compressed and transmitted to compensate, because of the different loss of video image features in the acquisition process, the error of compressed transmission compensation is large and the efficiency is low. Firstly, the NLMS algorithm and the improved NLMS algorithm are analyzed. To solve the problem that the compensation factor in the algorithm is too large due to the severe network shake, the NLMS algorithm is further improved by adaptively adjusting the compensation factor coefficient with the change of the network and the prediction error. The research shows that the multimedia playback mode and the image optimization system software structure based on the compensation factor adaptive model realize the dynamic adaptation of the system to various network conditions and the image optimization function during video playback by adopting the bandwidth adaptive strategy and method.. The conclusion shows that in the multimedia network video image compression transmission, the improved compensation method has higher performance in multimedia network video image optimization and real-time compression transmission compensation, which has certain advantages compared with the traditional compensation method.
C1 [Liu, Yuling] Chongqing Coll Elect Engn, Sch Digital Media, Chongqing 401331, Peoples R China.
C3 Chongqing College of Electronic Engineering
RP Liu, YL (corresponding author), Chongqing Coll Elect Engn, Sch Digital Media, Chongqing 401331, Peoples R China.
EM liuyulingO107@163.com
CR Aggarwal CC, 1998, INT J INTELL SYST, V13, P1113, DOI 10.1002/(SICI)1098-111X(199812)13:12<1113::AID-INT3>3.0.CO;2-O
   Chen Jian, 2014, [自动化学报, Acta Automatica Sinica], V40, P2316
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Dahmane A, 2015, SIGNAL IMAGE VIDEO P, V9, P1871, DOI 10.1007/s11760-014-0676-x
   Dang CT, 2014, IEEE T IMAGE PROCESS, V23, P2704, DOI 10.1109/TIP.2014.2320814
   De Faria JWV, 2016, J NEUROSURG, P1, DOI DOI 10.3171/2015
   Domanski M, 2013, IEEE T IMAGE PROCESS, V22, P3517, DOI 10.1109/TIP.2013.2266580
   Geldhof GJ, 2015, INT J BEHAV DEV, V39, P171, DOI 10.1177/0165025414560447
   Kordelas GA, 2016, IEEE T MULTIMEDIA, V18, P155, DOI 10.1109/TMM.2015.2505905
   Kuo YH, 2014, MULTIMED TOOLS APPL, V72, P1803, DOI 10.1007/s11042-013-1480-2
   Lee A, 2015, J REAL-TIME IMAGE PR, V12, P1
   Li W, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P171, DOI 10.1109/BigMM.2015.14
   Li XJ, 2016, MULTIMED TOOLS APPL, V75, P6431, DOI 10.1007/s11042-015-2579-4
   Li Y, 2015, IEICE ELECTRON EXPR, V12, DOI 10.1587/elex.12.20140921
   Lin L, 2015, IEEE T PATTERN ANAL, V37, P959, DOI 10.1109/TPAMI.2014.2359888
   Madi A, 2014, DISPLAYS, V35, P6, DOI 10.1016/j.displa.2013.10.003
   Rui L, 2016, J SENSORS, V2016, P1, DOI [10.1155/2016/6365959, DOI 10.1155/2016/6365959]
   Schuwerk C, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2835176
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun YC, 2014, MULTIMED TOOLS APPL, V72, P1411, DOI 10.1007/s11042-013-1434-8
   Yang J, 2015, MULTIMED TOOLS APPL, V75, P1
   Yi CY, 2015, IEEE T VEH TECHNOL, V64, P781, DOI 10.1109/TVT.2014.2322072
   Zhang QN, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457454
NR 23
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9315
EP 9330
DI 10.1007/s11042-019-7478-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600054
DA 2024-07-18
ER

PT J
AU Verma, OP
   Jain, N
   Pal, SK
AF Verma, Om Prakash
   Jain, Nitin
   Pal, Saibal Kumar
TI Design and analysis of an optimal ECC algorithm with effective access
   control mechanism for big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Elliptic curve cryptography; Fuzzy c means; Grasshopper
   optimization; Access control mechanism; Map reduce
ID DATA-STORAGE; SECURITY; PRIVACY; PERFORMANCE
AB Big data is a high volume data, as it comprises complex and large volume of information. A successful solution is to redistribute the data to a cloud server that has the capacity of storing and processing big data in an effective manner. The main intention of the research is to secure storage of big data and effective access control mechanism. The main stages of the proposed method are map reduce framework, secure storage process and access control mechanism process. Map Reduce is a distributed programming framework used to process big data. In mapper, the input dataset is grouped using hybrid kernel fuzzy c means (HKFCM) clustering algorithm. Finally, the reduced output is fed to the data owner for secure storage. In secure storage process, the suggested method utilizes optimal elliptic curve cryptography (OECC). Here the fundamental values are optimally selected by Modified grasshopper optimization algorithm (MGOA). In the access control mechanism, the effective policy update is proposed along with data storage construction and data deconstruction stage. The routine of the recommended method is assessed using memory and execution time by differentiating the number data size, number cluster size and the number of mapper. The proposed method attains the minimum time and memory utilization when compared to the existing method. The suggested method is implemented in cloud sim with Hadoop Map-reduce framework.
C1 [Verma, Om Prakash] Delhi Technol Univ, Dept ECE, Delhi, India.
   [Jain, Nitin] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
   [Pal, Saibal Kumar] DRDO, Directorate Informat Technol & Cyber Secur, New Delhi, India.
C3 Delhi Technological University; Delhi Technological University; Defence
   Research & Development Organisation (DRDO)
RP Jain, N (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM garg.nitin007@gmail.com
RI Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X
CR [Anonymous], 2013, INT J EMERG TECHNOL
   [Anonymous], IEEE EMERG TOP COM
   [Anonymous], CONTROL PROTECT SENS
   Assunçao MD, 2015, J PARALLEL DISTR COM, V79-80, P3, DOI 10.1016/j.jpdc.2014.08.003
   Batista BG, 2017, FUTURE GENER COMP SY, V68, P260, DOI 10.1016/j.future.2016.09.018
   Bui DM, 2017, J PARALLEL DISTR COM, V102, P103, DOI 10.1016/j.jpdc.2016.11.011
   Chen G, 2015, BIG DATA RES, V2, P65, DOI 10.1016/j.bdr.2015.01.002
   Fugkeaw S, 2018, FUTURE GENER COMP SY, V79, P364, DOI 10.1016/j.future.2017.06.014
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Hu C., 2015, INT C SECURITY PRIVA, P418
   Kshetri N, 2014, TELECOMMUN POLICY, V38, P1134, DOI 10.1016/j.telpol.2014.10.002
   Li P, 2016, IEEE CLOUD COMPUT, V3, P34, DOI 10.1109/MCC.2016.107
   Perera C, 2015, IT PROF, V17, P32, DOI 10.1109/MITP.2015.34
   Ramachandran M, 2016, INT J INFORM MANAGE, V36, P580, DOI 10.1016/j.ijinfomgt.2016.03.008
   Shanmugapriya E, 2019, SOFT COMPUT, V23, P2585, DOI 10.1007/s00500-019-03857-z
   Singh S, 2016, J NETW COMPUT APPL, V75, P200, DOI 10.1016/j.jnca.2016.09.002
   Tan ZY, 2014, IEEE CLOUD COMPUT, V1, P27, DOI 10.1109/MCC.2014.53
   Thiyagarajan VS, 2017, WIRELESS PERS COMMUN, V97, P6239, DOI 10.1007/s11277-017-4836-5
   Wang ZW, 2017, J COMPUT SYST SCI, V89, P41, DOI 10.1016/j.jcss.2016.12.006
   Xiong H, 2017, GIGASCIENCE, V6, DOI 10.1093/gigascience/gix012
   Yan Z, 2017, INFORM SCIENCES, V387, P53, DOI 10.1016/j.ins.2016.12.034
   Yang K, 2017, IEEE INTERNET THINGS, V4, P563, DOI 10.1109/JIOT.2016.2571718
   Yang LT, 2017, INFORM SCIENCES, V387, P254, DOI 10.1016/j.ins.2016.10.017
   Yang Y, 2018, Inf Sci, P1
   Zheng Yan, 2016, IEEE Transactions on Big Data, V2, P138, DOI 10.1109/TBDATA.2016.2587659
   Zhou W, 2018, J COMPUT SCI-NETH, V26, P409, DOI 10.1016/j.jocs.2017.01.003
NR 26
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9757
EP 9783
DI 10.1007/s11042-019-7677-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600003
DA 2024-07-18
ER

PT J
AU Zhang, WQ
   Tang, SL
   Su, JJ
   Xiao, J
   Zhuang, YT
AF Zhang, Wenqiao
   Tang, Siliang
   Su, Jiajie
   Xiao, Jun
   Zhuang, Yueting
TI Tell and guess: cooperative learning for natural image caption
   generation with hierarchical refined attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image caption; Cooperative learning; Hierarchical refined attention
AB Automatically generating a natural language description of an image is one of the most fundamental and challenging problems in Multimedia Intelligence because it translates information between two different modalities, while such translation requires the ability to understand both modalities. The existing image captioning models have already achieved remarkable performance. However, they heavily rely on the Encoder-Decoder framework is a directional translation which is hard to be further improved. In this paper, we designed the "Tell and Guess" Cooperative Learning model with a Hierarchical Refined Attention mechanism (CL-HRA) that bidirectionally improves the performance to generate more informative captions. The Cooperative Learning (CL) method combines an image caption module (ICM) with an image retrieval module (IRM) - the ICM is responsible for the "Tell" function, which generates informative and natural language descriptions for a given image. While the IRM will "Guess" and try to select that image from a lineup of images based on the given description. Such cooperation mutually improves the learning of two modules. On the other hand, the Hierarchical Refined Attention (HRA) learns to selectively attend the high-level attributes and the low-level visual features, then incorporate them into CL to fulfill the objective gaps from image to caption. The HRA can pay different attention at the different semantic levels to refine the visual representation, while the CL with the human-like mindset is more interpretable to generate a more related caption for the corresponding image. The experimental results on Microsoft COCO dataset show the effectiveness of CL-HRA in terms of several popular image caption generation metrics.
C1 [Zhang, Wenqiao; Tang, Siliang; Su, Jiajie; Xiao, Jun; Zhuang, Yueting] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Tang, SL (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM wenqiaozhang@zju.edu.com; siliang@zju.edu.cn; 3170103241@zju.edu.cn;
   junx@cs.zju.edu.cn; yzhuang@cs.zju.edu.cn
RI zhang, yimeng/JLL-7337-2023
FU NSFC [61751209, U1611461]; Hikvision-Zhejiang University Joint Research
   Center; Chinese Knowledge Center of Engineering Science and Technology
   (CKCEST); Engineering Research Center of Digital Library, Ministry of
   Education
FX This work has been supported in part by NSFC (No. 61751209, U1611461),
   Hikvision-Zhejiang University Joint Research Center, Chinese Knowledge
   Center of Engineering Science and Technology (CKCEST), Engineering
   Research Center of Digital Library, Ministry of Education.
CR Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680
   ALAHMADI R, 2018, ELEVENTH INT C MACHI
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chang YS, 2018, MULTIMED TOOLS APPL, V77, P2959, DOI 10.1007/s11042-017-4593-1
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen H, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P606, DOI 10.1109/ITME.2018.00139
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Chung Junyoung, 2014, ARXIV14123555
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Gao JY, 2018, PROC CVPR IEEE, P6576, DOI 10.1109/CVPR.2018.00688
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jacobsen J.H., 2017, ICML WORKSH PRINC AP
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Li Qing, 2018, ARXIV180109041
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SMITH JR, 2013, P 51 ANN M ASS COMP, V1, P1374
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang LQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020646
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3081, DOI 10.1109/ICASSP.2018.8461507
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu HY, 2018, PROC CVPR IEEE, P6006, DOI 10.1109/CVPR.2018.00629
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ML, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, VOLS 1 AND 2, P718
NR 40
TC 18
Z9 18
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16267
EP 16282
DI 10.1007/s11042-020-08832-7
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000521917400004
DA 2024-07-18
ER

PT J
AU Khaldi, B
   Aiadi, O
   Lamine, KM
AF Khaldi, Belal
   Aiadi, Oussama
   Lamine, Kherfi Mohammed
TI Image representation using complete multi-texton histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texton theory; Texture perception; Image representation; Features
   extraction
ID PREATTENTIVE TEXTURE-DISCRIMINATION; FEATURES; CLASSIFICATION; COLOR;
   STATISTICS; PATTERNS; ROTATION; FOURIER
AB Texture is a fundamental aspect which is often used to represent the visual content of images. Psychologists stated that color and texture have a close relationship via fundamental micro-structures called textons. Textons are considered as atoms for pre-attentive human visual perception. Based on texton theory, many literature works have tried to develop efficient models for image recognition. In this paper, we put forward a texton-based method, called Complete Multi-Texton Histogram (CMTH), that has the ability to discriminate both texture and non-texture color images. CMTH incorporates information about the color, edge orientation and texton distribution within the image. The proposed CMTH has been extensively examined on five publicly available datasets. Three of these datasets were intended to evaluate texture discrimination, namely: Vistex, Outex, and Batik whereas the two others were intended to evaluate heterogeneous image discrimination, namely: Corel10K and UKBench. The proposed method has been evaluated via image classification and retrieval tasks. The obtained results have shown that our proposed descriptor significantly outperforms the state of the art methods in both classification and retrieval.
C1 [Khaldi, Belal; Aiadi, Oussama] UKMO, Dept Comp Sci & Informat Technol, Ghardaia Rd,BP 511, Ouargla 30000, Algeria.
   [Lamine, Kherfi Mohammed] Lab Rech Math & Informat Appl LAMIA, 3351 Blvd Forges,CP 500, Trois Rivieres, PQ G9A 5H7, Canada.
RP Khaldi, B (corresponding author), UKMO, Dept Comp Sci & Informat Technol, Ghardaia Rd,BP 511, Ouargla 30000, Algeria.
EM khaldi.belal@univ-ouargla.dz
RI Khaldi, Belal/Q-5220-2019; aiadi, oussama/AAW-7992-2021
OI Khaldi, Belal/0000-0002-4905-5139; 
CR ADE F, 1983, SIGNAL PROCESS, V5, P451, DOI 10.1016/0165-1684(83)90008-7
   [Anonymous], TECHNICAL REPORT
   [Anonymous], P 2 INT C ART INT IN
   [Anonymous], 1994, Digital Image Processing Methods
   [Anonymous], P 9 SPAN S PATT REC
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Banerji Sugata, 2011, Proceedings of the 2011 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV 2011), P537
   Bu X, 2019, PATTERN RECOGN
   Chen J, 2008, LECT NOTES COMPUT SC, V5018, P1, DOI 10.1007/978-3-540-79723-4_1
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Florindo JB, 2016, PATTERN RECOGN LETT, V84, P239, DOI 10.1016/j.patrec.2016.09.013
   Gangeh MJ, 2010, LECT NOTES COMPUT SC, V6363, P595
   Goutsias J., 2000, HDB MEDICAL IMAGING, V2, P175
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jalaja K., 2005, IGARSS 2005. IEEE International Geoscience and Remote Sensing Symposium
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   JULESZ B, 1981, BIOL CYBERN, V41, P131, DOI 10.1007/BF00335367
   JULESZ B, 1987, READINGS COMPUTER VI, P243
   Kannala J, 2012, INT C PATT RECOG, P1363
   Khaldi B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053007
   Kumari Y.S., 2017, J IMAGE GRAPH SIGNAL, V10, P60
   Kumari YS, 2018, INT J IMAGE GRAPHICS, V10
   Ledoux A, 2015, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2015.7351036
   Li Qiang, 2010, Microcomputer Information, P83
   Lin HC, 1999, IMAGE VISION COMPUT, V17, P51, DOI 10.1016/S0262-8856(98)00085-7
   Lin HC, 1997, PATTERN RECOGN LETT, V18, P433, DOI 10.1016/S0167-8655(97)00030-5
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   LOHMANN AW, 1993, J OPT SOC AM A, V10, P2181, DOI 10.1364/JOSAA.10.002181
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Mikolajczyk Krystian., 2003, BRIT MACHINE VISION, V2, P779
   Minarno AE, 2018, TELKOMNIKA, V16
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Nister D, 2006, COMP SOC C COMP VIS, V2
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Prakash M. J., 2013, Int J Signal Process, Image Process Pattern Recognit, V6, P81
   Raza A, 2019, MULTIMED TOOLS APPL, V78, P2719, DOI 10.1007/s11042-018-5795-x
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Thiran JP, 1996, IEEE T BIO-MED ENG, V43, P1011, DOI 10.1109/10.536902
   Tiwari D, 2017, COMPUT ELECTR ENG, V62, P485, DOI 10.1016/j.compeleceng.2016.11.008
   Tiwari D, 2016, COMPUT VIS IMAGE UND, V150, P58, DOI 10.1016/j.cviu.2016.04.010
   Toyoda T., 2005, 4 INT WORKSH TEXT AN, V12, P131
   Vadivel A, 2007, PATTERN RECOGN LETT, V28, P974, DOI 10.1016/j.patrec.2007.01.004
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   VENOT A, 1984, COMPUT VISION GRAPH, V28, P176, DOI 10.1016/S0734-189X(84)80020-1
   WANG S, 1981, IEEE T SYST MAN CYB, V11, P360, DOI 10.1109/TSMC.1981.4308692
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   WOOD EJ, 1990, TEXT RES J, V60, P212, DOI 10.1177/004051759006000404
   Wu YQ., 2009, ELECT DEVICES M IEDM, P1
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou XS, 2001, PATTERN RECOGN LETT, V22, P457, DOI 10.1016/S0167-8655(00)00124-0
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
NR 63
TC 10
Z9 10
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8267
EP 8285
DI 10.1007/s11042-019-08350-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100064
DA 2024-07-18
ER

PT J
AU Meena, KB
   Tyagi, V
AF Meena, Kunj Bihari
   Tyagi, Vipin
TI A hybrid copy-move image forgery detection technique based on
   Fourier-Mellin and scale invariant feature transforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery; Image forgery detection; Copy-move forgery; Keypoint;
   Passive forgery detection; CMFD
AB In digital images, the most common forgery is copy-move image forgery in which some region(s) of an image is replicated within the image. The copy-move forgery detection (CMFD) techniques fall under two categories; keypoint-based and block-based. The keypoint-based techniques perform well under rotation and scaling but show very poor performance in the case of smooth images. On the contrary, the block-based techniques perform better in smooth images but are comparatively more time demanding. In this paper, a hybrid technique has been proposed by combining the block-based technique using Fourier-Mellin Transform (FMT) and a keypoint-based technique using Scale Invariant Feature Transform (SIFT). In this technique, the input image to be checked for forgery is first divided into texture and smooth regions. Then the keypoints are extracted from the texture part of the image using the SIFT descriptor, and the FMT is applied on the smooth part of the image. Extracted features are then matched to detect the duplicated regions of the image. The experimental results illustrate that the proposed technique performs better in comparison to other state-of-the-art CMFD techniques under various geometric transformations and post-processing operations in reasonable time.
C1 [Meena, Kunj Bihari; Tyagi, Vipin] Jaypee Univ Engn & Technol, Dept CSE, Raghogarh Guna 473226, MP, India.
   [Tyagi, Vipin] Jaypee Univ Engn & Technol, Fac Math Sci, Raghogarh Guna 473226, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Dept CSE, Raghogarh Guna 473226, MP, India.; Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Fac Math Sci, Raghogarh Guna 473226, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Meena, Kunj Bihari/ABF-5314-2020; Tyagi, Vipin/I-2451-2013
OI Meena, Kunj Bihari/0000-0001-8159-9024; Tyagi, Vipin/0000-0003-4994-3686
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Chen B., 2018, IEEE ACCESS, V99, P1
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Guo N, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P212, DOI 10.1109/ICACC.2010.5486938
   Hu W, 2016, CHIN CONT DECIS CONF, P349, DOI 10.1109/CCDC.2016.7531008
   Jaberi M, 2014, MACH VISION APPL, V25, P451, DOI 10.1007/s00138-013-0522-0
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Meena K. B., 2019, Advances in Computing and Data Sciences. ICACDS 2019. Communications in Computer and Information Science, V1045, DOI [https://doi.org/10.1007/978-981-13-9939-8_7, DOI 10.1007/978-981-13-9939-8_7]
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Saini M, 2011, INT C IM INF PROC, V2011, P1
   Shin Yong-Dal, 2013, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V16, P411, DOI 10.9717/kmms.2013.16.4.411
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P7563, DOI 10.1007/s11042-017-4507-2
   Tyagi V., 2018, UNDERSTANDING DIGITA
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P2311, DOI 10.1007/s11042-018-6354-1
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Wu QM, 2011, IEEE SIGNAL PROC LET, V18, P559, DOI 10.1109/LSP.2011.2163507
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
   Zhang Z, 2017, KSII T INTERNET INF, V11, P4567, DOI 10.3837/tiis.2017.09.021
   ZHAO J, 2013, MATH PROBL ENG, V4, P1
   Zhong JL, 2016, NONLINEAR DYNAM, V84, P189, DOI 10.1007/s11071-015-2374-9
NR 41
TC 33
Z9 34
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8197
EP 8212
DI 10.1007/s11042-019-08343-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100060
DA 2024-07-18
ER

PT J
AU Ning, M
   Fu, WN
AF Ning, Ma
   Fu, Weina
TI Feature fusion analysis of big cognitive data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data analysis; Cognitive data; Data feature; Fusion analysis
ID WHEAT
AB Cognitive computing is one kind of affective social computing, and becomes a research hotspot now. The traditional feature fusion method has the disadvantages to process big cognitive data, such as high redundancy, less efficient operation, increased energy consumption during data fusion, and reduced survival cycle of the data analysis. Therefore, a data feature fusion method based on BP neural network is proposed in this paper. First, the cognitive data features of big data analysis are extracted. Secondly, the data feature fusion method based on BP neural network is used to fuse the cognitive data features of big data analysis. It overcomes the shortcomings of the traditional method, such as reducing the redundancy of data transmission, improving the efficiency of operation, reducing the energy consumption in fusion process, and prolonging the life cycle. The experimental results show that the energy consumption of the operation can be effectively reduced by using the proposed method.
C1 [Ning, Ma] Anhui Open Univ, Coll Comp & Commun, Hefei 230022, Peoples R China.
   [Fu, Weina] Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010012, Peoples R China.
C3 Inner Mongolia Agricultural University
RP Fu, WN (corresponding author), Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010012, Peoples R China.
EM fwn0124@yeah.net
CR Castaldi F, 2016, INT J REMOTE SENS, V37, P4317, DOI 10.1080/01431161.2016.1212423
   Chen CC, 2019, FUTURE GENER COMP SY, V96, P628, DOI 10.1016/j.future.2017.02.028
   Chen CC, 2018, INTERACT LEARN ENVIR, V26, P664, DOI 10.1080/10494820.2017.1385488
   Farias RC, 2016, IEEE T SIGNAL PROCES, V64, P4830, DOI 10.1109/TSP.2016.2576425
   Forzieri G, 2010, J HYDRAUL ENG, V136, P855, DOI 10.1061/(ASCE)HY.1943-7900.0000254
   Gengler S, 2016, MATH GEOSCI, V48, P79, DOI 10.1007/s11004-015-9585-y
   Hollinger GA, 2015, IEEE T ROBOT, V31, P55, DOI 10.1109/TRO.2014.2378411
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   Kabir G, 2015, KNOWL-BASED SYST, V85, P159, DOI 10.1016/j.knosys.2015.05.002
   [康丽萍 Kang Liping], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P854
   Lee MH, 2015, PATTERN RECOGN, V48, P2725, DOI 10.1016/j.patcog.2015.03.010
   Lin Y, 2016, J SUPERCOMPUT, V72, P2874, DOI 10.1007/s11227-016-1681-3
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Lu MY, 2019, SOFT COMPUT, V23, P9175, DOI 10.1007/s00500-018-3602-2
   Medhane DV, 2017, COMPUT ELECTR ENG, V58, P126, DOI 10.1016/j.compeleceng.2017.01.025
   Novelli A, 2016, REMOTE SENS LETT, V7, P476, DOI 10.1080/2150704X.2016.1154219
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Radak J, 2016, IEEE T INTELL TRANSP, V17, P184, DOI 10.1109/TITS.2015.2464707
   Sangaiah AK, 2018, COMPUT ELECTR ENG, V71, P833, DOI 10.1016/j.compeleceng.2017.07.022
   Sangaiah AK, 2015, APPL SOFT COMPUT, V30, P628, DOI 10.1016/j.asoc.2015.02.019
   [唐菁敏 Tang Jingmin], 2016, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V38, P703
   Vishwasrao MD, 2017, IEEE T SUST COMPUT, V2, P49, DOI 10.1109/TSUSC.2017.2690378
   Wang SL, 2015, AUSTRALAS J EDUC TEC, V31, P470
NR 27
TC 1
Z9 1
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5461
EP 5475
DI 10.1007/s11042-019-7536-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900002
DA 2024-07-18
ER

PT J
AU Rana, S
   Kamra, R
   Sur, A
AF Rana, Shuvendu
   Kamra, Rohit
   Sur, Arijit
TI Motion vector based video steganography using homogeneous block
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Steganography; Motion vector; Steganalysis; MPEG2
ID DIGITAL WATERMARKING; SEARCH ALGORITHM; STEGANALYSIS; SCHEME; TRANSFORM
AB In recent steganographic literature, video steganography becomes popular due to its capability of accommodating higher payload. Since the video is transmitted mostly in a compressed format, compressed domain parameters are a natural choice for data embedding. In this paper, a motion vector based video steganographic method is proposed. For embedding the secret bit stream, the embedding motion vectors are selected for the homogeneous regions of the reference frame. Since homogeneous or smooth regions contain macro blocks with similar prediction error blocks, it helps to reduce the chance of detection by masking the embedding noise with similar prediction error among neighbouring macro blocks. The efficient search window and polar orientation based embedding technique are used to improve the imperceptibility against standard steganalysis schemes. A set of experiments is been carried out to justify the efficacy of the proposed scheme over the related existing steganographic methods.
C1 [Rana, Shuvendu] Univ Strathclyde, Elect & Elect Engn, Glasgow G1 1XQ, Lanark, Scotland.
   [Rana, Shuvendu; Kamra, Rohit; Sur, Arijit] IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
C3 University of Strathclyde; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Rana, S (corresponding author), Univ Strathclyde, Elect & Elect Engn, Glasgow G1 1XQ, Lanark, Scotland.; Rana, S (corresponding author), IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM shuvendu@ieee.org; rohit121292@gmail.com; arijit@iitg.ernet.in
RI Rana, Shuvendu/ACC-7002-2022; Sur, Arijit/AAB-4216-2020
OI Rana, Shuvendu/0000-0002-8372-5669; 
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Juaid N. A, 2018, ENHANCING PC DATA SE
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Avcibas I, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P517, DOI 10.1109/MMSP.2001.962785
   Budhia U, 2006, IEEE T INF FOREN SEC, V1, P502, DOI 10.1109/TIFS.2006.885020
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chebbo S, 2010, IEEE INT C IM PROC T, P177, DOI DOI 10.1109/IPTA.2010.5586728
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Chen CH, 2006, IEEE IMAGE PROC, P105, DOI 10.1109/ICIP.2006.312383
   Ding-Yu Fang, 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C)
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   GHANBARI M, 1990, IEEE T COMMUN, V38, P950, DOI 10.1109/26.57512
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Jainsky JS, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P161
   Liang YR, 2020, INT J AUTOM COMPUT, V17, P292, DOI 10.1007/s11633-018-1159-2
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087
   Pankajakshan V, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P287
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Sadat ES, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040244
   Solanki K., 2007, 9 INT WORKSH INF HID
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Sur A, 2015, MULTIMED TOOLS APPL, V74, P10479, DOI 10.1007/s11042-014-2181-1
   Tasdemir Kasim, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P260
   Wang Jue, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P500, DOI 10.1109/ICCSN.2011.6013642
   Wang P, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1555, DOI 10.1109/ICALIP.2008.4590271
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Xuansen He, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P822, DOI 10.1109/CSSE.2008.359
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zahariadis T, 1996, EUR SIGN PROC C 1996, P1
   Zhang C, 2008, P 4 INT C WIR COMM N, P1
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
NR 51
TC 12
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5881
EP 5896
DI 10.1007/s11042-019-08525-w
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900020
DA 2024-07-18
ER

PT J
AU Malik, A
   Sikka, G
   Verma, HK
AF Malik, Aruna
   Sikka, Geeta
   Verma, Harsh K.
TI A Reversible Data Hiding Scheme for Interpolated Images Based on Pixel
   Intensity Range
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Pixel intensity; Image interpolation; PSNR;
   Embedding capacity
ID WATERMARKING
AB In this paper, we propose a novel interpolation and a new reversible data hiding scheme for upscaling the original image and hiding secret data into the upscaled/interpolated image. This data hiding scheme considers the characteristics of the human visual system while embedding the secret data so that the existence of the secret data is not detected even after embedding a large amount of secret data. The proposed hiding scheme first divides pixel intensity ranges into groups and then adaptively embeds the secret data bits into the pixels based on the pixel intensity values. Therefore, the proposed scheme is able to maintain the visual quality of the stego-image. Experimental results show that the achieved PSNR by the proposed interpolation method is more than 30 dB for all the test images. Further, the results prove that the proposed data hiding scheme has superior performance than all the existing interpolation-based data hiding schemes.
C1 [Malik, Aruna; Sikka, Geeta; Verma, Harsh K.] Natl Inst Technol, Dept Comp Sci Engn, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Malik, A (corresponding author), Natl Inst Technol, Dept Comp Sci Engn, Jalandhar, Punjab, India.
EM arunacsrke@gmail.com; sikkag@nitj.ac.in; vermah@nitj.ac.in
RI Malik, Aruna/GOH-0709-2022; Verma, Harsh Kumar/Y-4606-2019; Malik,
   Aruna/AAL-1997-2020; Sikka, Geeta/X-8526-2019
OI Malik, Aruna/0000-0003-1136-6828; Verma, Harsh
   Kumar/0000-0003-4826-6150; 
CR Ajeeshvali N., 2012, International Journal of Image, Graphics and Signal Processing, V4, P26, DOI 10.5815/ijigsp.2012.12.04
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   [Anonymous], 2008, 5 IEEE INT WORKSH SI
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Benhfid A, 2016, INT CONF MULTIMED, P157, DOI 10.1109/ICMCS.2016.7905641
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gutub A, 2018, J COMPUTER HARDWARE, V1
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu J, 2015, COMPUTER ELECT ENG
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Katzenbeisser S., 2000, The EDP Audit, Control, and Security Newsletter, V26, P1, DOI [10.1201/1079/43263.28.6.20001201/30373.5, DOI 10.1201/1079/43263.28.6.20001201/30373.5]
   Kumar R., 2018, INT J MULTIMED INTEL, V3, P146, DOI [10.1504/IJMIS.2018.096356, DOI 10.1504/IJMIS.2018.096356]
   Kumar R., 2015, INT J FORENSIC COMPU, V10, P8, DOI DOI 10.5769/J201501001
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P903, DOI [10.1109/SPIN.2019.8711635, 10.1109/spin.2019.8711635]
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1399, DOI 10.1109/CCAA.2016.7813937
   Kumar R, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P53, DOI 10.1109/SPIN.2016.7566661
   Lee C.F., 2010, INF HIDING MULTIMED, V1, P310
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee CF, 2010, INT J INNOV COMPUT I, V6, P5485
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Lu TC, 2018, SIGNAL PROCESS, V142, P244, DOI 10.1016/j.sigpro.2017.07.025
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Lu ZM, 2000, ELECTRON LETT, V36, P1201, DOI 10.1049/el:20000876
   Malik Aruna, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P828, DOI 10.1109/ICACCCN.2018.8748668
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P24107, DOI 10.1007/s11042-016-4186-4
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P13025, DOI 10.1007/s11042-016-3707-5
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Shaik A, 2019, MULTIMED TOOLS APPL, V78, P9717, DOI 10.1007/s11042-018-6544-x
   Sudipta M, 2018, MULTIMEDIA TOOLS APP, P1
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Wahed MA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212093
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang B, 2011, P INT J ELECT COMMUN, V65, P814, DOI DOI 10.1016/J.AEUE.2011.01.014
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhang Xidong, 2016, CHINAS POPULATION RE, V07, P76, DOI DOI 10.1007/s11042-016-3521-0
NR 55
TC 26
Z9 26
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18005
EP 18031
DI 10.1007/s11042-020-08691-2
EA FEB 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000515925400001
DA 2024-07-18
ER

PT J
AU Sathiyamurthi, P
   Ramakrishnan, S
AF Sathiyamurthi, P.
   Ramakrishnan, S.
TI Speech encryption algorithm using FFT and 3D-Lorenz-logistic chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech encryption; Fast Fourier transform; Logistic map; 3D-Lorenz map
ID SEPARATION
AB In this paper a new speech encryption method using Fast Fourier Transform (FFT) and multiple chaotic maps has been developed for secured speech communication. In order to improve the drawbacks namely residual intelligibility in encrypted signal, poor quality in decrypted signal, low key space and high computational complexity that prevail in the exist speech encryption methods, a novel speech encryption algorithm based on a three dimension (3D) Lorenz-Logistic map has been developed. A new 3D Lorenz-Logistic map has been introduced by feeding Logistic map in 3D Lorenz map to obtain three different random number sequences. Totally eight initial and controlling parameters of 3D Lorenz-Logistic map are used as key values. The behavior of chaotic map is totally changed by changing the key values which generates highly randomized number sequence. Permutation and substitution plays vital role in this method. The input speech is applied to FFT to obtain real as well as imaginary values. Two random number sequences of the 3D Lorenz-Logistic map are used to permute the real and imaginary values of input speech signal. Remaining one random number sequence is used to permute a reference speech sample which is used for substitution of permuted real values of speech signal. The reverse process of permutation and substitution is used for recovering the desired signal. The Inverse Fast Fourier Transform (IFFT) is applied to reconstruct the original signal. The performance of the proposed method is verified using histogram analysis, spectrogram analysis, correlation analysis, signal to noise ratio analysis, NSCR (Number of Samples Changing Rate) and UACI (Unified Averaged Changed Intensity) analysis, key space and key sensitivity analysis, computational complexity measure, Perceptual Evaluation of Speech Quality (PESQ) analysis and subjective evaluation of speech quality. The results evidence that the proposed speech encryption method provides better security system with robust decryption quality.
C1 [Sathiyamurthi, P.; Ramakrishnan, S.] Dept Informat Technol, Pollachi, Tamil Nadu, India.
   [Sathiyamurthi, P.; Ramakrishnan, S.] Dr Mahalingam Coll Engn & Technol, Pollachi, Tamil Nadu, India.
RP Sathiyamurthi, P (corresponding author), Dept Informat Technol, Pollachi, Tamil Nadu, India.; Sathiyamurthi, P (corresponding author), Dr Mahalingam Coll Engn & Technol, Pollachi, Tamil Nadu, India.
EM sathyamurthi.bit@gmail.com; ram_f77@yahoo.com
RI S, Ramakrishnan/A-1134-2012; , Dr.P.Sathiyamurthi/AFH-3769-2022
OI S, Ramakrishnan/0000-0002-8224-4812; Pattusamy,
   Sathiyamurthi/0000-0001-8885-7153
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Amin M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3360179
   [Anonymous], 2010, NIST SPECIAL PUBLICA
   Anto Steffi A, 2013, INT J ADV RES COMPUT, V4, P312
   Azzaz MS, 2013, COMMUN NONLINEAR SCI, V18, P2035, DOI 10.1016/j.cnsns.2012.12.018
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Benrhouma O, 2013, IMAGE VIDEO PROCESS, V9, P1281, DOI DOI 10.1007/S11760-013-0570-Y
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Boccaletti S, 2002, PHYS REP, V366, P1, DOI 10.1016/S0370-1573(02)00137-0
   BROWN R, 1994, PHYS REV E, V49, P3784, DOI 10.1103/PhysRevE.49.3784
   Cambareri V, 2015, IEEE T SIGNAL PROCES, V63, P2183, DOI 10.1109/TSP.2015.2407315
   Chen X, 2016, ADV DIFFER EQU-NY, DOI 10.1186/s13662-016-0799-1
   Corrêa MV, 2000, INT J BIFURCAT CHAOS, V10, P1019, DOI 10.1142/S0218127400000724
   Dachselt F., 2001, IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications, V48
   Gleick J, 1988, CHOAS MAKING NEW SCI
   Gopalakrishnan T, 2017, IETE J RES, V63, P172, DOI 10.1080/03772063.2016.1251855
   Hamza R, 2018, IEEE ACCESS, V6, P60160, DOI 10.1109/ACCESS.2017.2762405
   Hasan F.S., 2016, ENG TECH J, V34, P2152
   Hato Eman, 2013, AL MUSTANSIRIYAH J S, V24, P357
   IIT New Delhi, 2004, Indian Patent, Patent No. [0158-0104, 01580104]
   Jui-Cheng Yen, 1999, 1999 IEEE Workshop on Signal Processing Systems. SiPS 99. Design and Implementation (Cat. No.99TH8461), P430, DOI 10.1109/SIPS.1999.822348
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Kaur H., 2012, INT J COMPUT SCI COM, V3, P151
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kwon OW, 2004, SIGNAL PROCESS, V84, P1005, DOI 10.1016/j.sigpro.2004.03.004
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Lin QH, 2004, 2004 INTERNATIONAL CONFERENCE ON COMMUNICATION, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P1013, DOI 10.1109/ICCCAS.2004.1346350
   Lin QH, 2006, IEEE T CIRCUITS-I, V53, P1320, DOI 10.1109/TCSI.2006.875164
   Mosa E, 2010, INT J SPEECH TECHNOL, V13, P231, DOI 10.1007/s10772-010-9081-1
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Parlitz U, 1992, INT J BIFURCAT CHAOS, V2, P973, DOI 10.1142/S0218127492000823
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Saad Saad Najim Al, 2014, INT J COMPUTER APPL, V93, P19, DOI DOI 10.5120/16203-5488
   Salamon M, 2012, APPL CRYPTOGRAPHY NE, P295
   Sathiyamurthi P, 2019, J TEST EVAL, V47, P3028, DOI 10.1520/JTE20170283
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Satti M, 2009, IEEE T BROADCAST, V55, P270, DOI 10.1109/TBC.2009.2014993
   Sayed WS, 2019, MULTIMED TOOLS APPL, V78, P16097, DOI 10.1007/s11042-018-6946-9
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Strogatz S. H., 1994, NONLINEAR DYNAMICS C
   Sun Y, 2009, IEEE 4 INT WORK SIGN, DOI [10.1109/IWSDA.2009.5346421, DOI 10.1109/IWSDA.2009.5346421]
   TAO H, 2006, INT C COMMUN CIRCUIT, V1, P280
   Tiejun Zhang, 2014, Advanced Materials Research, V981, P327, DOI 10.4028/www.scientific.net/AMR.981.327
   TIMIT, AC PHON CONT SPEECH
   Venkat M., 2006, INT J NETW SECUR, V7, P15
   YAN X, 2013, SIVIP, V9, P499, DOI DOI 10.1007/s11760-013-0465-y
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
   Yuan HM, 2017, SIGNAL PROCESS-IMAGE, V52, P87, DOI 10.1016/j.image.2017.01.002
   Zeng L, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-257
   Zeng YM, 1997, DYNAM CONTROL, V7, P143, DOI 10.1023/A:1008275800168
   Zhang TJ, 2015, INT J SECUR APPL, V9, P217, DOI 10.14257/ijsia.2015.9.7.19
   Zhao HR, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/687568
NR 56
TC 30
Z9 32
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17817
EP 17835
DI 10.1007/s11042-020-08729-5
EA FEB 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516466200002
DA 2024-07-18
ER

PT J
AU Sharma, S
   Kumar, V
AF Sharma, Sahil
   Kumar, Vijay
TI Voxel-based 3D face reconstruction and its application to face
   recognition using sequential deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face reconstruction; Voxel; Sequential deep learning; Face recognition;
   Gender; Emotion; Occlusion
ID BIDIRECTIONAL LSTM; CLASSIFICATION; DATABASE; IMAGE
AB In this paper, a novel 3D face reconstruction technique is proposed along with a sequential deep learning-based framework for face recognition. It uses the voxels generated from the voxelization process. It uses the reflection principle for generating the reconstructed point in 3D using the mid-face plane. From the reconstructed face, a sequential deep learning framework is developed to recognize gender, emotion, occlusion, and person. The developed framework utilizes the concepts of variational autoencoders, bidirectional long short-term memory, and triplet loss training. The sequential deep learning model extracts and refines the reconstructed voxels by generating deep features. The support vector machine is applied to deep features for the final prediction. The proposed 3D face recognition system is compared with the three well-known deep learning approaches over three occluded datasets. Experimental results show that the proposed 3D face recognition technique is invariant to occlusion and facial expression. The proposed technique recognizes the gender with accuracy of 97.28%, 92.12%, and 94.44%, emotion with accuracy of 94.57%, 87.78%, and 89.95%, occlusion with accuracy of 94.02%, 81.26%, and 89.85% and person face with accuracy of 90.01%, 78.21%, and 85.68% for Bosphorus, UMBDB and KinectFaceDB datasets respectively. The proposed framework performs better than state-of-the-art approaches in terms of computational time as well as face recognition accuracy.
C1 [Sharma, Sahil] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Kumar, Vijay] Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur, India.
C3 Thapar Institute of Engineering & Technology; National Institute of
   Technology (NIT System); National Institute of Technology Hamirpur
RP Sharma, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM sahil301290@gmail.com; vijaykumarchahar@gmail.com
RI Sharma, Sahil/AAE-2833-2022; Sharma, Sahil/JXM-8658-2024; Sharma,
   Sahil/AAI-2846-2021; Chahar, Vijay Kumar/A-2782-2015
OI Sharma, Sahil/0000-0002-3187-4929; Sharma, Sahil/0000-0002-6694-3365;
   Chahar, Vijay Kumar/0000-0002-3460-6989
CR [Anonymous], 2019, HDB RES DEEP LEARNIN
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2017, CORR
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2019, MULTIMEDIA TOOLS APP
   [Anonymous], 2018, ADV INTELLIGENT SYST
   [Anonymous], 2019, CONF FAIRN ACC TRANS, DOI DOI 10.1145/3347447.3356752
   [Anonymous], 2012, INT C MACH LEARN, DOI DOI 10.1016/J.NEUNET.2005.06.042
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Cao X, 2018, PROC CVPR IEEE, P4635, DOI 10.1109/CVPR.2018.00487
   Da Costa CR, 2015, NATURAL FILLER AND FIBRE COMPOSITES: DEVELOPMENT AND CHARACTERISATION, P1
   di Bernardo M, 2011, IEEE INT SYMP CIRC S, P2713
   Dou PF, 2018, PATTERN RECOGN, V81, P515, DOI 10.1016/j.patcog.2018.03.002
   Eigen D, 2014, ADV NEUR IN, V27
   Feng ZH, 2018, IEEE INT CONF AUTOMA, P780, DOI 10.1109/FG.2018.00123
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Haq EU, 2017, 2017 14TH WEB INFORMATION SYSTEMS AND APPLICATIONS CONFERENCE (WISA 2017), P172, DOI 10.1109/WISA.2017.68
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Huang C, 2020, IEEE T PATTERN ANAL, V42, P2781, DOI 10.1109/TPAMI.2019.2914680
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942
   Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Kingma DP, 2013, ARXIV
   Li HR, 2019, AAAI CONF ARTIF INTE, P9963
   Liu F, 2017, FRONT INFORM TECH EL, V18, P1978, DOI 10.1631/FITEE.1700253
   Liu ZH, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419560019
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   MacKay D., 2003, INFORM THEORY INFERE
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Nair V, 2008, LECT NOTES COMPUT SC, V5163, P971, DOI 10.1007/978-3-540-87536-9_99
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3
   Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Richhariya B, 2019, APPL SOFT COMPUT, V76, P53, DOI 10.1016/j.asoc.2018.11.046
   Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma S, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918502123
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Stoykova E, 2007, IEEE T CIRC SYST VID, V17, P1568, DOI 10.1109/TCSVT.2007.909975
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tian GZ, 2019, IEEE INT CONF MULTI, P366, DOI 10.1109/ICMEW.2019.00069
   Tsai HH, 2018, SOFT COMPUT, V22, P4389, DOI 10.1007/s00500-017-2634-3
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Xu CH, 2004, INT C PATT RECOG, P342, DOI 10.1109/ICPR.2004.1334122
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
   Xu Y, 2014, NEUROCOMPUTING, V131, P191, DOI 10.1016/j.neucom.2013.10.025
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Yu LA, 2018, APPL SOFT COMPUT, V69, P192, DOI 10.1016/j.asoc.2018.04.049
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhou XL, 2019, IEEE INT CON MULTI, P850, DOI 10.1109/ICME.2019.00151
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
   Zia MS, 2018, MULTIMED TOOLS APPL, V77, P25537, DOI 10.1007/s11042-018-5806-y
NR 63
TC 23
Z9 26
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17303
EP 17330
DI 10.1007/s11042-020-08688-x
EA FEB 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516318400002
DA 2024-07-18
ER

PT J
AU Veronica, BKJ
AF Veronica, Benita K. J.
TI An effective neural network model for lung nodule detection in CT images
   with optimal fuzzy model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LN detection; ROI extraction; Segmentation; FCM; Feature extraction;
   Classification; ANN
ID FALSE-POSITIVE REDUCTION; SEGMENTATION; CLASSIFICATION; CANCER; LEVEL;
   CNNS
AB Cancer disease is assumed as a gathering of diseases which is initiated because of uncontrolled cell growth. An early analysis of Lung Nodules (LN) can possibly enhance the prognosis and in future can save numerous lives every year. In the proposed research work, the LN detection from the ELCAP lung image database is analyzed by image segmentation and classification techniques. Initially, the exact portion of the lung image is achieved and then it is subjected to pre-processing where the image contrast level is enhanced by the imadjust function of MATLAB. Next to that, the potential nodules are segmented by the Fuzzy C-Means (FCM) and then some features are extracted for effective classification. Based on the selected or extracted feature sets, the images are classified as two types (nodule detected and normal lung) by the proposed classifier i.e. Artificial Neural Network (ANN) with weight optimization. The performances of the proposed algorithm and classifier are tested on the chosen datasets in terms of sensitivity, specificity and accuracy. The results demonstrate that ANN with Oppositional based Ant Lion Optimization (OALO) algorithm achieves high accuracy and less execution time compared to existing algorithms.
C1 [Veronica, Benita K. J.] Mother Teresa Univ, Kodaikanal, Tamil Nadu, India.
C3 Mother Teresa Women's University
RP Veronica, BKJ (corresponding author), Mother Teresa Univ, Kodaikanal, Tamil Nadu, India.
EM benita.mca@gmail.com
RI Veronica/AAT-6611-2021
OI , DrBenita/0000-0002-5501-7382
CR Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   [Anonymous], 2014, IOSR J ELECT COMMUNI, DOI DOI 10.9790/2834-09136975
   Asuntha A, 2016, J Chem Pharm Res, V8, P351
   Badura P, 2014, COMPUT BIOL MED, V53, P230, DOI 10.1016/j.compbiomed.2014.08.005
   Netto SMB, 2017, MULTIMED TOOLS APPL, V76, P18929, DOI 10.1007/s11042-017-4414-6
   Bhuvaneswari P, 2015, PROC MAT SCI, V10, P433, DOI 10.1016/j.mspro.2015.06.077
   Bong CW, 2012, ENG OPTIMIZ, V44, P327, DOI 10.1080/0305215X.2011.639369
   Cao M, 2018, MULTIMED TOOLS APPL
   da Silva GLF, 2017, MULTIMED TOOLS APPL, V76, P19039, DOI 10.1007/s11042-017-4480-9
   De Pinho Pinheiro CA, 2019, MULTIMED TOOLS APPL
   Eun H, 2018, COMPUT METH PROG BIO, V165, P215, DOI 10.1016/j.cmpb.2018.08.012
   da Silva GLF, 2018, COMPUT METH PROG BIO, V162, P109, DOI 10.1016/j.cmpb.2018.05.006
   Froz BR, 2017, EXPERT SYST APPL, V69, P176, DOI 10.1016/j.eswa.2016.10.039
   Gonçalves L, 2016, EXPERT SYST APPL, V61, P1, DOI 10.1016/j.eswa.2016.05.024
   Guo ZP, 2020, MULTIMED TOOLS APPL, V79, P14919, DOI 10.1007/s11042-019-08357-8
   Hafez AI, 2015, INT CONF SOFT COMPUT, P19, DOI 10.1109/SOCPAR.2015.7492775
   Javaid M, 2016, COMPUT METH PROG BIO, V135, P125, DOI 10.1016/j.cmpb.2016.07.031
   John J, 2016, PROC TECH, V24, P957, DOI 10.1016/j.protcy.2016.05.209
   Keshani M, 2013, COMPUT BIOL MED, V43, P287, DOI 10.1016/j.compbiomed.2012.12.004
   Liu XL, 2018, PATTERN RECOGN, V77, P262, DOI 10.1016/j.patcog.2017.12.022
   Majhi Santosh Kumar, 2018, Karbala International Journal of Modern Science, V4, P347, DOI 10.1016/j.kijoms.2018.09.001
   Naqi SM, 2019, MULTIMED TOOLS APPL
   Nithila EE, 2017, ENG SCI TECHNOL, V20, P1192, DOI 10.1016/j.jestch.2016.12.006
   Rehman MZU, 2018, BIOMED SIGNAL PROCES, V41, P140, DOI 10.1016/j.bspc.2017.11.017
   Shakir H, 2018, COMPUT BIOL MED, V96, P214, DOI 10.1016/j.compbiomed.2018.03.015
   Shen SW, 2015, COMPUT BIOL MED, V57, P139, DOI 10.1016/j.compbiomed.2014.12.008
   Shi Z., 2018, MULTIMED TOOLS APPL
   Tsubakimoto M, 2018, EUR J RADIOL, V100, P108, DOI 10.1016/j.ejrad.2018.01.021
   Wozniak M, 2018, COMPUT METH PROG BIO, V161, P173, DOI 10.1016/j.cmpb.2018.04.025
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie YT, 2018, INFORM FUSION, V42, P102, DOI 10.1016/j.inffus.2017.10.005
   Yuan JJ, 2018, COMPUT GRAPH-UK, V70, P288, DOI 10.1016/j.cag.2017.07.020
   Zhang JJ, 2018, BIOMED SIGNAL PROCES, V43, P138, DOI 10.1016/j.bspc.2018.01.011
   Zhang JJ, 2019, J VISION, V19, DOI 10.1167/19.2.2
   Zhou T, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8052436
   Zhu XY, 2020, MULTIMED TOOLS APPL, V79, P1585, DOI 10.1007/s11042-019-08158-z
NR 36
TC 18
Z9 18
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14291
EP 14311
DI 10.1007/s11042-020-08618-x
EA FEB 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000520049300001
DA 2024-07-18
ER

PT J
AU Shine, L
   Jiji, CV
AF Shine, Linu
   Jiji, C., V
TI Automated detection of helmet on motorcyclists from traffic surveillance
   videos: a comparative analysis using hand-crafted features and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Helmet detection; Motorcycle classification; Foreground segmentation;
   Vehicle tracking
ID DETECTION ALGORITHM; CLASSIFICATION
AB The higher mortality rate in motorcycle accidents is attributed to negligence in wearing a helmet by two-wheeler riders. Identification of helmetless riders in real-time is an essential task to prevent the occurrence of such events. This paper presents an automated system to identify motorcyclists without a helmet from traffic surveillance videos in real-time. The problem becomes more challenging when computational resources are limited. We have compiled a custom dataset for developing an automated helmet detection algorithm. The proposed system uses a two-stage classifier to extract motorcycles from surveillance videos. Detected motorcycles are further fed to a helmet identification stage. We present two algorithms for classifying riders with and without a helmet, one based on hand-crafted features and the other based on deep convolutional neural network (CNN). Our experiments show that the proposed CNN model gives the best performance in terms of accuracy while the feature-based model gives faster detection. Most importantly, to ensure the light-weightiness of the proposed system all the computations are performed in CPUs only.
C1 [Shine, Linu; Jiji, C., V] Coll Engn Trivandrum, Dept Elect & Commun Engn, Comp Vis Lab, Trivandrum, Kerala, India.
C3 College of Engineering, Trivandrum
RP Shine, L (corresponding author), Coll Engn Trivandrum, Dept Elect & Commun Engn, Comp Vis Lab, Trivandrum, Kerala, India.
EM linushine@cet.ac.in; jijicv@cet.ac.in
RI Shine, Linu/HKF-2276-2023; V, Jiji C/O-8644-2019
OI V, Jiji C/0000-0002-6667-226X; Shine, Linu/0000-0003-4526-6075
CR Ramirez-Quintana JA, 2015, PATTERN RECOGN, V48, P1137, DOI 10.1016/j.patcog.2014.09.009
   [Anonymous], 2012, HDB SOFT COMPUT VIDE
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Chiranjeevi P, 2017, IEEE T CYBERNETICS, V47, P2544, DOI 10.1109/TCYB.2016.2585600
   Chiu C.-C., 2007, 8 INT WORK IMAGE ANA, P32, DOI [10.1109/WIAMIS.2007.60., DOI 10.1109/WIAMIS.2007.60]
   Chiverton J, 2012, IET INTELL TRANSP SY, V6, P259, DOI 10.1049/iet-its.2011.0138
   Cuevas C, 2017, IEEE T IMAGE PROCESS, V26, P1127, DOI 10.1109/TIP.2016.2642779
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Di Stefano L, 2004, LECT NOTES COMPUT SC, V3212, P437
   DILLENCOURT MB, 1992, J ACM, V39, P253, DOI 10.1145/128749.128750
   Fisher R., 2003, GAUSSIAN SMOOTHING
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He ZW, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P580, DOI 10.1109/ITSC.2004.1398965
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Leelasantitham A, 2008, 2008 8TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS, PROCEEDINGS, P439, DOI 10.1109/ITST.2008.4740302
   Li XX, 2015, NUMER LINEAR ALGEBR, V22, P845, DOI 10.1002/nla.1981
   Mccarthy MG., 2007, Comparative analysis of motorcycle accident data from OTS and MAIDS, TRL
   Mukhtar A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P452, DOI 10.1109/ICSIPA.2015.7412234
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pedregosa F, 2011, LEARN RES, V2830
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Silva R R V E, 2017, MULTIMEDIA TOOLS APP, P1
   Silva Romuere., 2013, CLEI Electronic Journal, V16, P4
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   TEKNOMO K, 2015, ARXIV151000889
   Vishnu C, 2017, IEEE IJCNN, P3036, DOI 10.1109/IJCNN.2017.7966233
   Waranusast R, 2013, INT CONF IMAG VIS, P35, DOI 10.1109/IVCNZ.2013.6726989
   World Health Organization, 2021, Immunization, vaccines and biologicals-Immunization financing indicators
   Wu H, 2018, COMPUT IND, V100, P267, DOI 10.1016/j.compind.2018.03.037
   Yamaleeva A. A., 2009, Sel'skokhozyaistvennaya Biologiya, P65
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 39
TC 26
Z9 27
U1 3
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14179
EP 14199
DI 10.1007/s11042-020-08627-w
EA FEB 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000513035300001
DA 2024-07-18
ER

PT J
AU Kumar, BKS
   Swamy, MNS
   Ahmad, MO
AF Kumar, B. K. Shreyamsha
   Swamy, M. N. S.
   Ahmad, M. Omair
TI Robust coding in a global subspace model and its collaboration with a
   local model for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Robust coding (RC); Weighted least squares (WLS);
   Principle component analysis (PCA); RC distance; Observation model
   update; Occlusion map
ID OBJECT TRACKING
AB The sparse representation-based trackers has attracted much attention in the research community due to its superior performance in spite of its computational complexity. But the assumption that the coding residual follows either the Gaussian or the Laplacian distribution may not accurately describe the coding residual in practical visual tracking scenarios. To deal with such issues as well as to improve the performance of the visual tracking, a novel generative tracker is proposed in a Bayesian inference framework by introducing robust coding (RC) into the PCA reconstruction. Also, it is proposed to collaborate the global and local PCA subspace appearance models to enhance the tracking performance. Further, a robust RC distance is proposed to differentiate the candidate samples from the subspace, and a novel observation likelihood is defined based on both global and local RC distances. In addition, a robust occlusion map generation and a novel appearance model update mechanism are proposed. The quantitative and qualitative performance evaluations on the OTB-50 and VOT2016 dataset demonstrate that the proposed method performs favorably against several methods based on particle filter framework.
C1 [Kumar, B. K. Shreyamsha; Swamy, M. N. S.; Ahmad, M. Omair] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
EM omair@encs.concordia.ca
RI KUMAR, BURAGADDA KIRAN/ABH-3848-2020; B. K., Shreyamsha
   Kumar/F-1624-2010
OI KUMAR, BURAGADDA KIRAN/0000-0003-2950-1709; B. K., Shreyamsha
   Kumar/0000-0002-3781-0635; Swamy, M.N.Srikanta/0000-0002-3989-5476
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Black J., 2003, In Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance VS-PETS, P125
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Grabner H., 2008, ECCV, p[234, 247]
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang M., 2012, INT J DIGITAL CONTEN, V6, P467
   Jiang M. - X., 2013, MATH PROBL ENG, V2013, P1
   Jun Yan, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P1, DOI 10.1109/ICCRD.2011.5764232
   Krishna MV, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, DRIVES AND ENERGY SYSTEMS (PEDES)
   KUMAR BKS, 2016, IEEE INT SYMP CIRC S, P986, DOI DOI 10.1109/ISCAS.2016.7527408
   Lasserre J., 2006, CVPR, V1, P87
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Pundir M, 2016, INT CONF CLOUD ENG, P12, DOI 10.1109/IC2E.2016.31
   Qu P., 2014, INT J SIGNAL PROCESS, V7, P23, DOI DOI 10.14257/ijsip.2014.7.2.03
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shreyamsha Kumar BK, 2015, IEEE INT SYMP CIRC S, P1194, DOI 10.1109/ISCAS.2015.7168853
   Sun MH, 2015, IEEE IMAGE PROC, P2855, DOI 10.1109/ICIP.2015.7351324
   Wang D, 2016, IEEE T CIRC SYST VID, V26, P1709, DOI 10.1109/TCSVT.2015.2462012
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P5166, DOI 10.1109/TIP.2015.2478399
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang D, 2012, IEEE SIGNAL PROC LET, V19, P711, DOI 10.1109/LSP.2012.2215320
   Wang FL, 2015, COMM COM INF SC, V525, P438, DOI 10.1007/978-3-662-47791-5_49
   Wang H, 2016, INT J ELECTROCHEM, V2016, DOI 10.1155/2016/4261012
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zhang X, 2018, ISPRS J PHOTOGRAMM, V140, P77, DOI 10.1016/j.isprsjprs.2017.07.009
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou T, 2018, IEEE T CYBERNETICS, V48, P2643, DOI 10.1109/TCYB.2017.2747998
   Zhou T, 2017, NEUROCOMPUTING, V226, P221, DOI 10.1016/j.neucom.2016.11.055
   Zhou T, 2015, IEEE IMAGE PROC, P725, DOI 10.1109/ICIP.2015.7350894
   Zhuang BH, 2016, NEUROCOMPUTING, V218, P61, DOI 10.1016/j.neucom.2016.08.070
NR 41
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4525
EP 4551
DI 10.1007/s11042-019-7685-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500016
DA 2024-07-18
ER

PT J
AU Liu, QX
   Su, XY
   Zhang, L
   Huang, H
AF Liu, Qiongxin
   Su, Xiangyang
   Zhang, Lei
   Huang, Hua
TI Panoramic video stitching of dual cameras based on spatio-temporal seam
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam; Panoramic video; Video stitching; Graph-cut; Parallax; Linear
   fusion
ID IMAGE
AB This paper proposes a panoramic video stitching algorithm based on seam optimization, which aims at stitching two videos taken by two wide-angle cameras into a single 720-degree video. The use of only two cameras makes the parallax of the dual videos very large, while previous stitching methods based on deformation or seams incur problems like distortion, blur and ghost. To solve these problems, we improve the graph-cut algorithm to compute the optimal seams in the overlapped regions. For the spatial and temporal consistency of the panoramic video, foreground detection and Gaussian filter are employed to generate a sequence of smooth seams. Besides, a quantitative evaluation on the seam quality is proposed for the linear fusion of the stitched frames. Compared with previous methods, our work can effectively reduce the distortion, blur and ghost artifacts, as well as maintain good spatial and temporal consistency of the panoramic video as evidenced by the experiments.
C1 [Liu, Qiongxin; Su, Xiangyang; Zhang, Lei; Huang, Hua] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Zhang, L (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
EM summer@bit.edu.cn; iamsuxiangyang@163.com; leizhang@bit.edu.cn;
   huahuang@bit.edu.cn
RI Huang, Hua/M-9684-2013
OI Huang, Hua/0000-0003-2587-1702
CR [Anonymous], 2016, SIGGRAPH ASIA
   [Anonymous], 2014, P 14 ANN NONV MEM TE, DOI DOI 10.1109/NVMTS.2014.7060834
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   CHANG CH, 2014, PROC CVPR IEEE, P3254, DOI DOI 10.1109/CVPR.2014.422
   Chen T, 2009, ACM T GRAPHIC, P89
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Halake K, 2016, J IND ENG CHEM, V35, P1, DOI 10.1016/j.jiec.2016.01.003
   He B., 2015, Sensors (Switzerland), V16, P1, DOI DOI 10.3390/s16010001
   Jia Q, 2016, PATTERN RECOGN, V52, P358, DOI 10.1016/j.patcog.2015.11.003
   Jiang W, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301374
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lee WT, 2017, COMPUT GRAPH FORUM, V36, P115, DOI 10.1111/cgf.13277
   Li HJ, 2012, NEUROCOMPUTING, V95, P72, DOI 10.1016/j.neucom.2011.06.040
   Lin KM, 2016, COMPUT GRAPH FORUM, V35, P479, DOI 10.1111/cgf.12848
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   [卢嘉铭 Lu Jiaming], 2017, [计算机科学, Computer Science], V44, P18
   Perazzi F, 2015, COMPUT GRAPH FORUM, V34, P57, DOI 10.1111/cgf.12541
   Shieh JY, 2014, INT J ENG TECHNOL IN, V4, P260
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Xu W, 2013, MULTIMEDIA SYST, V19, P407, DOI 10.1007/s00530-013-0316-2
   Yong J, 2017, COMPUTER APPL SOFTWA, V34, P182
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 30
TC 7
Z9 8
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3107
EP 3124
DI 10.1007/s11042-018-6337-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700004
DA 2024-07-18
ER

PT J
AU Muruganantham, A
   Gandhi, GM
AF Muruganantham, A.
   Gandhi, G. Meera
TI Framework for Social Media Analytics based on Multi-Criteria Decision
   Making (MCDM) model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media analytics; Centrality measures; Spreading size; MAE; RMSE;
   Twitter data set
ID USER INFLUENCE
AB The Social, Mobile, Analytics and Cloud (SMAC) explosion in recent times changed the way the customers look at and collaborate businesses through large world of data or information, often described as "Big Data". With over 1590 million active users, social media such as Facebook, Twitter, WhatsApp, Instagram, LinkedIn etc. send or receive messages or post or access new content every day. Businesses or enterprises understand and extract useful insights from social media platform and transforming it into useful information or knowledge along with their enterprise business data for strategic decision making. A framework for Social Media Analytics based on Multi-Criteria Decision Making (MCDM) model is proposed for social media data and our comprehensive study on large-scale twitter dataset experiment explains how MCDM (TOPSIS) method outperforms against the standard centrality methods using predicted Spreading Size. Two well-known metrics such as MAE (Mean Absolute Error), and RMSE (Root Mean Square Error) are applied to measure prediction accuracy of our MCDM based method against standard methods. TOPSIS (MCDM based) experiences least error accuracy of 9% in MAE and 16% in RMSE than the standard methods to prove that the proposed approach works better than the standard methods.
C1 [Muruganantham, A.; Gandhi, G. Meera] Sathyabama Inst Sci & Technol, Fac Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Muruganantham, A (corresponding author), Sathyabama Inst Sci & Technol, Fac Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM amuruganantham@gmail.com; drmeeragandhii@gmail.com
RI g, meeragandhi/P-8441-2016; A, Muruganantham/I-2939-2014
OI A, Muruganantham/0000-0001-6968-5886
CR Amiri MP, 2010, EXPERT SYST APPL, V37, P6218, DOI 10.1016/j.eswa.2010.02.103
   [Anonymous], 2009, P 3 WORKSH SOC NETW
   [Anonymous], 1992, Fuzzy Multiple Attribute Decision Making: Methods and Applications
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Behzadian M, 2012, EXPERT SYST APPL, V39, P13051, DOI 10.1016/j.eswa.2012.05.056
   Behzadian M, 2010, EUR J OPER RES, V200, P198, DOI 10.1016/j.ejor.2009.01.021
   Bentes AV, 2012, J BUS RES, V65, P1790, DOI 10.1016/j.jbusres.2011.10.039
   Brodka P, 2013, ARXIV13021369
   Cha  M., 2010, ICWSM, P10
   Di Gangi PM, 2009, DECIS SUPPORT SYST, V48, P303, DOI 10.1016/j.dss.2009.04.004
   Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P57, DOI 10.1145/502512.502525
   Gandhi M, 2015, PROCEDIA COMPUT SCI, V57, P1179, DOI 10.1016/j.procs.2015.07.411
   Ghosh R, 2010, SNA KDD P KSS WORKSH
   Gobeck J, 2006, TIOT, P497
   Grul D, 2004, WWW, P491
   Han H, 2018, EXPERT SYST APPL, V103, P133, DOI 10.1016/j.eswa.2018.03.003
   Hwang C-L, 1981, MULTIPLE ATTRIBUTE D
   Hyoseop Shin, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P105, DOI 10.1109/WIIAT.2008.391
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kempe D, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kiron D., 2013, MIT Sloan Management Review, V54, P1
   Kohavi R, 2002, COMMUN ACM, V45, P45, DOI 10.1145/545151.545177
   Kumar A, 2017, RENEW SUST ENERG REV, V69, P596, DOI 10.1016/j.rser.2016.11.191
   Li JX, 2014, EXPERT SYST APPL, V41, P5115, DOI 10.1016/j.eswa.2014.02.038
   Li L, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2757282
   Li Q, 2014, PHYSICA A, V404, P47, DOI 10.1016/j.physa.2014.02.041
   Mini TV, 2017, INT CONF ADV COMPU, P19, DOI 10.1109/ICoAC.2017.7951738
   Muruganantham A, 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i32/95171, DOI 10.17485/ijst/2016/v9i32/95171]
   Mustafa RU, 2017, MALAYS J COMPUT SCI, V30, P63
   Petz G, 2015, INFORM PROCESS MANAG, V51, P510, DOI 10.1016/j.ipm.2014.07.011
   Richardson M., 2002, P 8 ACM SIGKDD INT C, P61, DOI DOI 10.1145/775047.775057
   Riquelme F, 2016, INFORM PROCESS MANAG, V52, P949, DOI 10.1016/j.ipm.2016.04.003
   Song X., 2007, P 16 INT C WORLD WID, P191, DOI DOI 10.1145/1242572.1242599
   Song Xiaodan., 2006, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '06, P509, DOI [10.1145/1148170.1148258, DOI 10.1145/1148170.1148258>(2006)]
   Spertus Ellen, 2005, Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, P678, DOI DOI 10.1145/1081870.1081956
   Tran KT, 2013, INTRO WEB SERVICES J
   Uzunkaya C, 2015, WORLD CONFERENCE ON TECHNOLOGY, INNOVATION AND ENTREPRENEURSHIP, P1890, DOI 10.1016/j.sbspro.2015.06.429
   Vasuki V, 2011, ACM T INTELL SYS TEC
   Velasquez M., 2013, INT J OPERATIONS RES, V10, P56
   Wang XT, 2008, OMEGA-INT J MANAGE S, V36, P45, DOI 10.1016/j.omega.2005.12.003
NR 40
TC 16
Z9 17
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3913
EP 3927
DI 10.1007/s11042-019-7470-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700045
DA 2024-07-18
ER

PT J
AU Zhao, HY
   Zhou, FX
   Liu, HP
AF Zhao, Hongyan
   Zhou, Fangxin
   Liu, Huaping
TI Deep learning for diplomatic video analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Faster-RCNN; Diplomatic video; U; S; Embassy in China; Mediated public
   diplomacy
ID MEDIATED PUBLIC DIPLOMACY; NETWORK
AB In this paper, we focus on putting Faster-RCNN into practice to solve the problem of diplomatic video analysis, as the part of Mediated Public Diplomacy. Diplomatic video uploaded by U.S. Embassy in China is our research target. Using Faster-RCNN, we get 56,781 object detection results from those diplomatic videos. Then we use statistical tools to test the abnormal distribution of the object category "person", clustering the above results so as to analyze the hidden strategic purposes in these diplomatic videos. Then we give an abstract of these videos: they mainly focus on common people's high-quality life in the U.S. Strategic purposes are: the U.S. takes advantage of the repeating occurrence of common people to make "people to people" diplomacy in order to win hearts and minds of audience. Attractive personal life is depicted in the video so as to build a strong, harmonious and happy U.S. national image. These procedures are elaborately designed, which is a latent agenda setting process, and a fruitful frame construction attempt. By this way, the U.S. successfully bridge the culture gap and accomplish its goal of global hegemony.
C1 [Zhao, Hongyan] Univ Int Business & Econ, Sch Int Relat, Beijing, Peoples R China.
   [Zhou, Fangxin] Univ Int Business & Econ, Sch Int Trade & Econ, Beijing, Peoples R China.
   [Liu, Huaping] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 University of International Business & Economics; University of
   International Business & Economics; Tsinghua University
RP Liu, HP (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
EM hpliu@.tsinghua.edu.cn
CR [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], J MULTIMEDIA TOOLS A
   [Anonymous], 2017, IMPLEMENTATION FASTE
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Entman RM, 2008, INT J PRESS/POLIT, V13, P87, DOI 10.1177/1940161208314657
   Fang YC, 2019, CLIN GERONTOLOGIST, V42, P495, DOI 10.1080/07317115.2018.1461164
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   [华纯 Hua Chun], 2011, [计算机工程与设计, Computer Engineering and Design], V32, P3000
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kendrick A, 2004, J ADVERTISING RES, V44, P297, DOI 10.1017/S0021849904040255
   Le THN, 2016, IEEE COMPUT SOC CONF, P46, DOI 10.1109/CVPRW.2016.13
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu HP, 2019, IEEE T SYST MAN CY-S, V49, P766, DOI 10.1109/TSMC.2017.2736248
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Ren Y, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3598316
   Shamsolmoali P, 2018, MULTIMED TOOLS APPL, P1
   Sheafer T, 2009, POLIT COMMUN, V26, P447, DOI 10.1080/10584600903297240
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
NR 21
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4811
EP 4830
DI 10.1007/s11042-018-6650-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500032
DA 2024-07-18
ER

PT J
AU Malathkar, NV
   Soni, SK
AF Malathkar, Nithin Varma
   Soni, Surender Kumar
TI A near lossless and low complexity image compression algorithm based on
   fixed threshold DPCM for capsule endoscopy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless capsule endoscopy; Image compression; YEN colour space;
   Adaptive threshold DPCM; Uniform quantization; Signed Golomb-Rice code
ID COLOR FILTER ARRAY; DESIGN; SYSTEM; IMPLEMENTATION; SPACE
AB Compression chip plays a vital role in a wireless capsule endoscopy. It compresses the captured image data to support the limited bandwidth of wireless capsule endoscopy and save the power utilized for transmitting data. This work proposed a near-lossless and low complexity image compression algorithm for wireless capsule endoscopy to provide a high quality image at a good compression ratio with less computational complexity. The algorithm follows four steps, first corner clipping, second RGB-YEN color transform, third fixed threshold DPCM and finally signed Golomb Rice code. The proposed algorithm has a competitive compression ratio of 60.9% compared to other works. It is better than standard JPEG-LS in term of memory usage and computational complexity.
C1 [Malathkar, Nithin Varma; Soni, Surender Kumar] Natl Inst Technol Hamirpur, E&CE Dept, Hamirpur 177005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Malathkar, NV (corresponding author), Natl Inst Technol Hamirpur, E&CE Dept, Hamirpur 177005, India.
EM nithinvarma.a3@gmail.com; surender.soni@gmail.com
RI soni, surender/AAD-9998-2022; Malathkar, Nithin Varma/AAO-3732-2020
OI Soni, Surender Kumar/0000-0003-1181-4299
FU Ministry of Electronics and Information Technology. Government of India,
   India
FX The authors have received financial support from Ministry of
   Electr2onics and Information Technology. Government of India, India.
CR [Anonymous], TCM8230MD IM SENS
   [Anonymous], MT9V011 IM SENS
   Chen SL, 2018, J REAL-TIME IMAGE PR, V14, P803, DOI 10.1007/s11554-015-0553-z
   Chen SL, 2016, IEEE ACCESS, V4, P10235, DOI 10.1109/ACCESS.2016.2638475
   Chen XK, 2009, IEEE T BIOMED CIRC S, V3, P11, DOI 10.1109/TBCAS.2008.2006493
   Chung KH, 2008, IEEE T IMAGE PROCESS, V17, P134, DOI 10.1109/TIP.2007.914153
   Ciuti Gastone, 2011, IEEE Rev Biomed Eng, V4, P59, DOI 10.1109/RBME.2011.2171182
   Cyriac M, 2013, INT J BIOMED ENG TEC, V13, P17, DOI 10.1504/IJBET.2013.057711
   Dung LR, 2008, 2008 IEEE BIOMEDICAL CIRCUITS AND SYSTEMS CONFERENCE - INTELLIGENT BIOMEDICAL SYSTEMS (BIOCAS), P61, DOI 10.1109/BIOCAS.2008.4696874
   Fante KA, 2016, CIRC SYST SIGNAL PR, V35, P1677, DOI 10.1007/s00034-015-0136-z
   Gerber J, 2007, GASTROINTEST ENDOSC, V66, P1188, DOI 10.1016/j.gie.2007.06.003
   Khan TH, 2011, ELECTRON LETT, V47, P1217, DOI 10.1049/el.2011.2211
   Khan TH, 2014, SENSORS-BASEL, V14, P20779, DOI 10.3390/s141120779
   Khan TH, 2014, SIGNAL PROCESS-IMAGE, V29, P345, DOI 10.1016/j.image.2013.12.001
   Khan TH, 2011, VLSI DES, DOI 10.1155/2011/343787
   Khan TH, 2013, J REAL-TIME IMAGE PR, V8, P5, DOI 10.1007/s11554-011-0208-7
   Kim S, 2014, IEEE T IMAGE PROCESS, V23, P445, DOI 10.1109/TIP.2013.2293428
   Lee D, 2012, SIGNAL PROCESS-IMAGE, V27, P637, DOI 10.1016/j.image.2012.02.017
   Li Siqing, 2017, Journal of Shanghai Jiaotong University (Science), V22, P156, DOI 10.1007/s12204-017-1815-7
   Lin MC, 2006, BIOMED ENG ONLINE, V5, DOI 10.1186/1475-925X-5-14
   Liu G, 2016, MED BIOL ENG COMPUT, V54, P1779, DOI 10.1007/s11517-016-1472-2
   Mohammed SK, 2017, IEEE ACCESS, V5, P13823, DOI 10.1109/ACCESS.2017.2726997
   *NORD SEM, 2017, NRF24L01 TRANSC
   *ONI VIS, OVM7690 CAM CUB
   PATTANAIK SK, 2006, INT C CYB INT SYST
   Raja A, 2019, CLUSTER COMPUT, V22, P12069, DOI 10.1007/s10586-017-1556-2
   Shabani A, 2017, SIGNAL PROCESS-IMAGE, V59, P83, DOI 10.1016/j.image.2017.03.003
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Turcza P, 2019, J REAL-TIME IMAGE PR, V16, P1425, DOI 10.1007/s11554-016-0653-4
   Turcza P, 2017, BIOMED SIGNAL PROCES, V38, P1, DOI 10.1016/j.bspc.2017.04.006
   Turcza P, 2013, IEEE J BIOMED HEALTH, V17, P1046, DOI 10.1109/JBHI.2013.2266101
   Turcza P, 2011, SENSOR ACTUAT A-PHYS, V172, P552, DOI 10.1016/j.sna.2011.09.026
   Wahid K, 2008, IEEE IJCNN, P2761, DOI 10.1109/IJCNN.2008.4634186
   Wang Z, 2017, ADVANCED AND EMERGING POLYBENZOXAZINE SCIENCE AND TECHNOLOGY, P301, DOI 10.1016/B978-0-12-804170-3.00018-4
   Wu J, 2009, IEEE ENG MED BIO, P3727, DOI 10.1109/IEMBS.2009.5334819
   Xiang X, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2194032
   Xie X, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/82160
   Xie X, 2006, IEEE J SOLID-ST CIRC, V41, P2390, DOI 10.1109/JSSC.2006.882884
NR 38
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8145
EP 8160
DI 10.1007/s11042-019-08347-w
EA JAN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356500006
DA 2024-07-18
ER

PT J
AU Nesam, JJJ
   Sivanantham, S
AF Nesam, J. Jean Jenifer
   Sivanantham, S.
TI Efficient half-precision floating point multiplier targeting color space
   conversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Area efficient multiplication; Color space conversion; Data length
   reduction; FPGA implementation; Half-precision floating point; NBPR
   algorithm
ID FAST ALGORITHM; DESIGN; POWER; FPGA
AB Color Space Conversion (CSC) in image processing applications, demands computationally simple floating point multipliers consuming less area and power. This necessitates the design and realization of the same meeting the aforesaid concerns. This paper makes one such contribution in the form of a New Bit Pair Recoding (NBPR) algorithm for realizing a Data Length Reduction (DLR)-based 16-bit Half-Precision Floating Point Multiplier (HPFPM). This algorithm with merged partial product addition achieves partial product height reduction from n to n/4 for an n x n multiplier by evading 2's complement, negative encoding and sign extension. HPFPM is implemented on both Application Specific Integration Circuit (ASIC) with TSMC 180, 130 and 65 nm technologies and Xilinx-Virtex-5 and Virtex-7 Field Programmable Gate Array (FPGA) families. HPFPM synthesized on TSMC 65nm consumes 51% and 55.8% of area and power respectively, with 0.6835% error when compared with full width half-precision multiplier. Also, HPFPM for RGB-YUV-RGB and RGB-YCbCr-RGB conversion reduces the area, power consumption by 11%, 12% respectively, with 93.2% improved accuracy, when compared with truncated 32-bit single-precision floating point multipliers (SPFPMs). The converted image is evaluated using Peak-Signal-to-Noise-Ratio (PSNR) and Mean Square Error (MSE) in Matlab for quantifying HPFPM suitability for CSC in imaging.
C1 [Nesam, J. Jean Jenifer; Sivanantham, S.] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Sivanantham, S (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM jean.jenifernesam@gmail.com; ssivanantham@vit.ac.in
RI ; S, Sivanantham/A-2416-2014
OI nesam, jean jenifer/0000-0003-4027-8165; S,
   Sivanantham/0000-0002-1010-5178
CR Ahmad A, 2012, IET SIGNAL PROCESS, V6, P862, DOI 10.1049/iet-spr.2011.0392
   [Anonymous], 2002, BT7095 ITUR
   [Anonymous], IM DAT
   Antelo E, 2017, IEEE T CIRCUITS-I, V64, P409, DOI 10.1109/TCSI.2016.2561518
   Bensaali F, 2004, LECT NOTES COMPUT SC, V3203, P991
   Borwankar RM, 2017, MIDWEST SYMP CIRCUIT, P969, DOI 10.1109/MWSCAS.2017.8053087
   Cho KJ, 2004, IEEE T VLSI SYST, V12, P522, DOI 10.1109/TVLSI.2004.825853
   Ehsan S, 2009, INT C COMP ELEC ENG, P635, DOI 10.1109/ICCEE.2009.138
   Gonzalez-Navarro S, 2013, IEEE T COMPUT, V62, P1460, DOI 10.1109/TC.2012.79
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Hormigo J, 2017, IEEE T CIRCUITS-II, V64, P319, DOI 10.1109/TCSII.2016.2563798
   Jaiswal MK, 2013, MICROELECTRON J, V44, P421, DOI 10.1016/j.mejo.2013.02.021
   Jean JJN, 2017, INT C MICR DEV CIRC, P1
   Jiang XY, 2013, MICROPROCESS MICROSY, V37, P1183, DOI 10.1016/j.micpro.2013.08.007
   Juan Xue, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P422
   Khang TN, 2013, INTEL HALF PRECISION
   Kuang SR, 2013, J SIGNAL PROCESS SYS, V72, P43, DOI 10.1007/s11265-012-0695-1
   Lacassagne L, 2005, CAMP 2005: Seventh International Workshop on Computer Architecture for Machine Perception , Proceedings, P198
   Liu WQ, 2017, IEEE T COMPUT, V66, P1435, DOI 10.1109/TC.2017.2672976
   Liu YF, 2015, MULTIMED TOOLS APPL, V74, P6041, DOI 10.1007/s11042-014-1906-5
   Liu ZG, 2014, COMPUT ELECTR ENG, V40, P1405, DOI 10.1016/j.compeleceng.2013.01.011
   Mallikarjun S., 2015, ELECT COMPUTER COMMU, P1
   Narayanamoorthy S, 2015, IEEE T VLSI SYST, V23, P1180, DOI 10.1109/TVLSI.2014.2333366
   Nesam J. Jean, 2016, INDIAN J SCI TECHNOL, V9, P1
   Patrick K, 2012, PERFORMANCE BENEFITS
   Pool J, 2008, PR IEEE COMP DESIGN, P60, DOI 10.1109/ICCD.2008.4751841
   Saadat H, 2018, IEEE T COMPUT AID D, V37, P2623, DOI 10.1109/TCAD.2018.2857262
   Pham TH, 2019, IEEE T VLSI SYST, V27, P747, DOI 10.1109/TVLSI.2018.2881105
   Tong JYF, 2000, IEEE T VLSI SYST, V8, P273, DOI 10.1109/92.845894
   Venkatachalam S, 2017, IEEE T VLSI SYST, V25, P1782, DOI 10.1109/TVLSI.2016.2643639
   Warden P., 2015, WHY ARE 8 BITS ENOUG
   Wu KY, 2013, INT J COMPUT SCI ENG, V8, P306
   Xu N, 2009, I SYMP CONSUM ELECTR, P248
   Yahiaoui R, 2017, IEEE T IND ELECTRON, V64, P9487, DOI 10.1109/TIE.2017.2708028
   Yang Y, 2007, IEEE T CONSUM ELECTR, V53, P1490, DOI 10.1109/TCE.2007.4429242
   Zhang XY, 2012, IEEE IMAGE PROC, P197, DOI 10.1109/ICIP.2012.6466829
   Zhang ZJ, 2018, IEEE T CIRCUITS-II, V65, P236, DOI 10.1109/TCSII.2017.2709801
   Zuras D., 2008, 7542008 IEEE, V754-2008, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2008.5976968]
NR 38
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 89
EP 117
DI 10.1007/s11042-019-08040-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600005
DA 2024-07-18
ER

PT J
AU Wang, WQ
AF Wang, Weiqing
TI An efficient multiple-bit reversible data hiding scheme without shifting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; histogram shifting; LSB; carrier image;
   information security; watermarking
ID HISTOGRAM-MODIFICATION; DIFFERENCE EXPANSION; IMAGE WATERMARKING
AB For the past few years, the data-hiding schemes are growing rapidly. Generally, data hiding performs well on common images but it does not provide satisfying results on distortion sensitive images such as medical, military, or forensic images. This is because embedding data into an image can cause permanent distortion after extraction (irreversible). As a solution, a certain scheme is required for the process of embedding data into an image, such as reversible data hiding (RDH). One well-known RDH scheme is difference expansion (DE), which is simple, easy to implement. Due to the local correlation between two neighboring pixels, conventional DE-based schemes utilize some empirical criteria to embed one bit into one of the pixels, which does not fully consider the correlations of pixels in neighborhood. In this study, an efficient multiple-bit reversible data hiding scheme without shifting (EMRDH), is proposed, focusing on increasing capacity and visual quality of data hiding. Firstly, a pixel is taken as an embeddable pixel (EP)or a non-embeddable pixel (NEP) according to its relations with the left and right neighbors, and then the EP is substituted with a new pixel consisting of flag-bits, offset-bits and embedding bits, without the difference histogram and expansion processes. With the flag-bits and embedding bits, the embedded data can be extracted without any error while the EP or NEP can be losslessly recovered with the flag-bits, offset-bits. Experimental results show that the proposed scheme has higher capacity, better visual quality and lower computational complexity compared with previous works.
C1 [Wang, Weiqing] Southwest Univ, Coll Business, Rongchang Campus, Chongqing 402460, Peoples R China.
C3 Southwest University - China
RP Wang, WQ (corresponding author), Southwest Univ, Coll Business, Rongchang Campus, Chongqing 402460, Peoples R China.
EM wwqlhy@163.com
RI liao, xingyu/KHE-4272-2024; zhu, zhu/JDN-0159-2023; yin,
   yue/JQV-9753-2023
FU National Natural Science Foundation of China [61304255]; Scientific and
   Technological Project of Chongqing Municipal Education Commission
   [KJ1401118]
FX This study was partially funded by the National Natural Science
   Foundation of China under Grant No. 61304255, and the Scientific and
   Technological Project of Chongqing Municipal Education Commission under
   Grant No. KJ1401118.
CR [Anonymous], MATH PROBL ENG
   [Anonymous], 2016, INT J MULTIMED UBIQU
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Cao LJ, 2013, VISUAL COMPUT, V29, P231, DOI 10.1007/s00371-012-0732-x
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen HS, 2016, SIGNAL PROCESS-IMAGE, V46, P1, DOI 10.1016/j.image.2016.04.006
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Fei P, 2013, SECUR COMMUN NETW, V6, P1117, DOI 10.1002/sec.680
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu CL, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P433
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Liu SH, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3990
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   TIAN J, 2002, P WORKSH MULT SEC
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Xuan GR, 2009, LECT NOTES COMPUT SC, V5510, P84
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yi H., 2009, 2009 9 INT C EL MEAS
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhou Lu, 2009, Journal of Computer Applications, V29, P990, DOI 10.3724/SP.J.1087.2009.00990
NR 39
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 555
EP 579
DI 10.1007/s11042-019-08065-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600022
DA 2024-07-18
ER

PT J
AU Wu, HY
   Wang, Y
   Liu, JY
   Qiu, JL
   Zhang, XL
AF Wu, Huiyue
   Wang, Yu
   Liu, Jiayi
   Qiu, Jiali
   Zhang, Xiaolong (Luke)
TI User-defined gesture interaction for in-vehicle information systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User-defined gestures; Elicitation study; Legacy bias; Gesture
   disagreement; Gesture-based user interaction for in-vehicle information
   system
ID VOCABULARY; TRACKING
AB Gesture elicitation study, a technique emerging from the field of participatory design, has been extensively applied in emerging interaction and sensing technologies in recent years. However, traditional gesture elicitation study often suffers from the gesture disagreement and legacy bias problem and may not generate optimal gestures for a target system. This paper reports a research project on user-defined gestures for interacting with in-vehicle information systems. The main contribution of our research lies in a 3-stage, participatory design method we propose for deriving more reliable gestures than traditional gesture elicitation methods. Using this method, we generated a set of user-defined gestures for secondary tasks in an in-vehicle information system. Drawing on our research, we develop a set of design guidelines for freehand gesture design. We highlight the implications of this work for the gesture elicitation for all gestural interfaces.
C1 [Wu, Huiyue; Liu, Jiayi; Qiu, Jiali] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.
   [Wu, Huiyue] Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Peoples R China.
   [Wang, Yu] Sun Yat Sen Univ, Dept Med Oncol, State Key Lab Oncol South China, Canc Ctr Collaborat Innovat Ctr,Canc Med, Guangzhou, Peoples R China.
   [Zhang, Xiaolong (Luke)] Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16802 USA.
C3 Sun Yat Sen University; Sun Yat Sen University; State Key Lab Oncology
   South China; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University
RP Wu, HY (corresponding author), Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.; Wu, HY (corresponding author), Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Peoples R China.
EM wuhuiyue@mail.sysu.edu.cn
RI lu, yuting/IIS-2826-2023; ZHANG, XIAOLONG/IZQ-4553-2023; wang,
   yan/GSE-6489-2022; wang, ying/GQY-5077-2022
OI Wu, Huiyue/0000-0001-7027-518X; Zhang, Xiaolong/0000-0002-6828-4930
FU National Natural Science Foundation of China [61772564, 61772468]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments. This work was supported by the National Natural
   Science Foundation of China under Grant No. 61772564, 61772468.
CR Akyol Suat., 2000, IAPR MVA Workshop, P349
   Alpern M., 2003, CHI 03 EXTENDED ABST, P932, DOI [10.1145/765891.766078, DOI 10.1145/765891.766078]
   Angelini L., 2014, AUTOMOTIVEUI 14, P1
   [Anonymous], USER INTERFACE INTER
   [Anonymous], 2005, ONLINE SUBMISS
   [Anonymous], P HCI
   Bach KM, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1139
   Buchanan S., 2013, P ACM INT C INT TABL, P231, DOI [10.1145/2512349.2512825, DOI 10.1145/2512349.2512825]
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Chan E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3403, DOI 10.1145/2858036.2858589
   Chen Z, 2018, INT J HUM-COMPUT INT, V34, P238, DOI 10.1080/10447318.2017.1342943
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Choi E, 2014, APPL ERGON, V45, P1196, DOI 10.1016/j.apergo.2014.02.010
   Cockburn A, 2013, P SIGCHI C HUM FACT, P955, DOI [10.1145/2468356.2468527, DOI 10.1145/2468356.2468527, DOI 10.1145/2468356]
   Connell S., 2013, P ACM C INTERACTION, P277, DOI DOI 10.1145/2485760.2485823
   Döring T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P483
   Dong HW, 2015, IEEE ACCESS, V3, P543, DOI 10.1109/ACCESS.2015.2432679
   Feng ZQ, 2013, PATTERN RECOGN, V46, P590, DOI 10.1016/j.patcog.2012.07.019
   Findlater L., 2012, P SIGCHI C HUMAN FAC, P2679, DOI DOI 10.1145/2207676.2208660
   Freeman FG, 2000, APPL PSYCHOPHYS BIOF, V25, P103, DOI 10.1023/A:1009566809021
   Gheran BF, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P623, DOI 10.1145/3196709.3196741
   Grijincu Daniela, 2014, P 9 ACM INT C INT TA, P25, DOI DOI 10.1145/2669485.2669511
   Hoff L, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P86, DOI 10.1145/2839462.2839472
   Kray C., 2010, Proc. of MobileHCI '10, P239, DOI DOI 10.1145/1851600.1851640
   Kühnel C, 2011, INT J HUM-COMPUT ST, V69, P693, DOI 10.1016/j.ijhcs.2011.04.005
   Kulshreshth A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1093, DOI 10.1145/2556288.2557122
   Kurdyukova E., 2012, Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces, IUI '12, New York, NY, USA, P93, DOI [10.1145/2166966.2166984, DOI 10.1145/2166966.2166984]
   Lee G. A., 2015, CHI EA 15 P 33 ANN A, P959
   Löcken A, 2012, MULTIMEDIA SYST, V18, P15, DOI 10.1007/s00530-011-0240-2
   Loehmann S, 2013, LECT NOTES COMPUT SC, V8119, P538
   Lou XL, 2018, INT J HUM-COMPUT INT, V34, P519, DOI 10.1080/10447318.2017.1370811
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Montero CalkinS., 2010, P 12 INT C HUMAN COM, P275
   Morris M.R., 2012, P 2012 ACM INT C INT, P95, DOI [DOI 10.1145/2396636.2396651, 10.1145/2396636.2396651]
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI [DOI 10.1145/2591689, 10.1145/2591689]
   Nebeling M., 2014, P 9 ACM INT C INTERA, P15, DOI DOI 10.1145/2669485.2669497
   Nielsen M., 2004, Gesture-Based Communication in Human-Computer Interaction, P105
   Obaid Mohammad, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P367, DOI 10.1007/978-3-642-34103-8_37
   Rahman ASMM, 2011, DIVANET 11: PROCEEDINGS OF THE FIRST ACM INTERNATIONAL SYMPOSIUM ON DESIGN AND ANALYSIS OF INTELLIGENT VEHICULAR NETWORKS AND APPLICATIONS, P69
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Riener A., 2011, Workshop UX in Cars, Interact, P5
   Riener A, 2012, COMPUTER, V45, P42, DOI 10.1109/MC.2012.108
   Rovelo G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4077, DOI 10.1145/2556288.2557113
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Seyed Teddy, 2012, P 2012 ACM INT C INT, P41, DOI [10.1145/2396636.2396643, DOI 10.1145/2396636.2396643]
   Shimon SSA, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3822, DOI 10.1145/2858036.2858385
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tung YC, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3327, DOI 10.1145/2702123.2702214
   Valdes C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4107, DOI 10.1145/2556288.2557373
   Vatavu RD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1325, DOI 10.1145/2702123.2702223
   Vatavu RD, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3390, DOI 10.1145/2858036.2858228
   Vatavu Radu-Daniel, 2012, P 10 EUR C INT TV VI, P45, DOI [10.1145/2325616.2325626, DOI 10.1145/2325616.2325626]
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wobbrock J.O., 2005, P CHI 05 HUM FACT CO, P1869, DOI [DOI 10.1145/1056808.1057043, 10.1145/1056808.1057043]
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wu HY, 2019, INT J HUM-COMPUT INT, V35, P1102, DOI 10.1080/10447318.2018.1510607
   Wu HY, 2016, MULTIMED TOOLS APPL, V75, P733, DOI 10.1007/s11042-014-2323-5
   Yang C, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P297, DOI 10.1109/ICCE.2012.6161876
   Yee W, 2009, LECT NOTES COMPUT SC, V5611, P291, DOI 10.1007/978-3-642-02577-8_32
   Zaiti IA, 2015, PERS UBIQUIT COMPUT, V19, P821, DOI 10.1007/s00779-015-0863-y
   Zobl M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P541
NR 63
TC 17
Z9 19
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 263
EP 288
DI 10.1007/s11042-019-08075-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600012
DA 2024-07-18
ER

PT J
AU Capuano, A
   Rinaldi, AM
   Russo, C
AF Capuano, Andrea
   Rinaldi, Antonio M.
   Russo, Cristiano
TI An ontology-driven multimedia focused crawler based on linked open data
   and deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Focused crawling; Knowledge engineering; Document analysis; Multimedia
   processing; Ontologies; Document classification; Convolutional neural
   networks; Linked open data
ID SEMANTIC SIMILARITY; INTEGRATION; FEATURES
AB Web-page indexing and classification have been studied extensively starting from the early WWW years. A smart intelligent web agent called focused crawler is a specific software able to seek web pages that are relevant to a particular topic domain. In this article we propose a novel approach to focused crawling based on the use of both textual and multimedia web page content. In our approach we define a novel strategy to choose if a web page should be further explored. We implement our framework in a system which aims to improve the crawling task using semantic based techniques and combining the results with novel technologies like convolutional neural networks and linked open data. Our framework uses ontologies to correlate different topics and understanding their relationships. The correlation among topics is used to improve a textual topic detection step. These results are combined with multimedia analysis and classification based on convolutional neural networks to extract image features. Experimental results are also presented and discussed in order to measure the effectiveness of our framework compared with other approaches using a ground truth composed of web pages about a specific domain.
C1 [Capuano, Andrea; Rinaldi, Antonio M.; Russo, Cristiano] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.
   [Rinaldi, Antonio M.] IKNOS LAB Intelligent & Knowledge Syst LUPT, Naples, Italy.
C3 University of Naples Federico II
RP Rinaldi, AM (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Naples, Italy.; Rinaldi, AM (corresponding author), IKNOS LAB Intelligent & Knowledge Syst LUPT, Naples, Italy.
EM and.capuano@gmail.com; antoniomaria.rinaldi@unina.it;
   cristiano.russo@studenti.unina.it
RI Rinaldi, Antonio M./O-7452-2019
OI Rinaldi, Antonio M./0000-0001-7003-4781; Russo,
   Cristiano/0000-0002-8732-1733
CR Abualigah L., 2015, INT J COMPUTER SCI E, V5, P19, DOI [10.5121/ijcsea.2015.5102, DOI 10.5121/ijcsea.2015.5102]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Aggarwal CharuC., 2012, MINING TEXT DATA, DOI [10.1007/978-1-4614-3223-4_6, DOI 10.1007/978-1-4614-3223-4_6]
   Albanese M, 2005, LECT NOTES COMPUT SC, V3665, P17
   [Anonymous], 2017, BRIEF SURVEY TEXT MI
   [Anonymous], 1999, MODERN INFORM RETRIE
   [Anonymous], 2017, DEEPLEARNING4J OPEN
   [Anonymous], 2002, P 11 WWW
   [Anonymous], 2014, P 31 INT C INT C MAC
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Batsakis S, 2009, DATA KNOWL ENG, V68, P1001, DOI 10.1016/j.datak.2009.04.002
   Bergman M. K., 2001, Journal of Electronic Publishing, V7, DOI 10.3998/3336451.0007.104
   Caldarola E. G., 2015, P 4 INT C DAT MAN TE, P362
   Caldarola EG., 2016, Commun. Comput. Inform. Sci, V631, P80, DOI [10.1007/978-3-319-52758-16, DOI 10.1007/978-3-319-52758-16]
   Caldarola EG, 2017, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P296, DOI 10.5220/0006484102960305
   Caldarola EG, 2018, ADV INTELL SYST, V561, P63, DOI 10.1007/978-3-319-56157-8_4
   Caldarola EG, 2016, PROCEEDINGS OF 2016 IEEE 17TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IEEE IRI), P384, DOI 10.1109/IRI.2016.58
   Caldarola EG, 2015, 2015 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT (IC3K), P104
   Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3
   Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1
   de Kunder Maurice, 2016, HENTET
   Diligenti Michelangelo., 2000, VLDB
   Du YJ, 2015, APPL SOFT COMPUT, V36, P392, DOI 10.1016/j.asoc.2015.07.026
   Ehrig Marc., 2003, Proceedings of the 2003 ACM symposium on Applied computing, SAC '03, P1174, DOI [10.1145/952532.952761, DOI 10.1145/952532.952761]
   Fan Y, 2015, EXPLOITING LOCAL FEA
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Hassan T., 2017, P INT WORKSHOP SEMAN, P1, DOI [10.1145/3066911.3066912, DOI 10.1145/3066911.3066912]
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kosala Raymond., 2000, SIGKDD EXPLOR NEWSL, V2, P1
   Kozanidis L, 2008, LECT NOTES COMPUT SC, V5039, P376
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Liao YH, 2009, BMC MICROBIOL, V9, DOI 10.1186/1471-2180-9-172
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Mendes Pablo N, 2011, P 7 INT C SEM SYST, P1, DOI [DOI 10.1145/2063518.2063519, 10.1145/2063518.2063519]
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mohammad L, 2019, FEATURE SELECTION EN
   Najork M., 2001, P 10 INT C WORLD WID, P114
   Novak Blaz., 2004, Proceedings of SIKDD, V5558, P55
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875
   Picariello A, 2007, LECT NOTES COMPUT SC, V4653, P730
   Purificato E, 2018, MULTIMED TOOLS APPL, V77, P27447, DOI 10.1007/s11042-018-5931-7
   Qi XG, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459357
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rinaldi AM, 2018, IEEE INT C SEMANT CO, P363, DOI 10.1109/ICSC.2018.00074
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Sharma DK, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P719, DOI 10.1109/NGCT.2015.7375215
   Simonyan K., 2014, 14091556 ARXIV
   Sinha, 2007, 10 INT C INF TECHN I, P289
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Yang SY, 2010, EXPERT SYST APPL, V37, P5381, DOI 10.1016/j.eswa.2010.01.018
   Yohanes B W, 2013, TELKOMNIKA TELECOMMU, V9, P403, DOI DOI 10.12928/telkomnika.v9i3.730
   Zhang F, 2016, IMAGE RETRIEVAL BASE
   Zhi TC, 2016, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2016.7532802
   Zhou ZH, 2017, NATL SCI REV, V4, P1, DOI 10.1093/nsr/nww087
NR 59
TC 24
Z9 24
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7577
EP 7598
DI 10.1007/s11042-019-08252-2
EA DEC 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164400002
DA 2024-07-18
ER

PT J
AU Koushkaki, HR
   Salehi, MR
   Abiri, E
AF Koushkaki, Hassan Rahmanian
   Salehi, Mohammad Reza
   Abiri, Ebrahim
TI Color-based feature extraction with application to facial recognition
   using tensor-matrix and tensor-tensor analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Developing tensor Analysis; Color feature extraction; Tensor-Matrix
   decomposition; Tensor-tensor decomposition; Face recognition
ID FACE RECOGNITION; DECOMPOSITIONS; FACTORIZATION; PCA
AB In this article, two main goals are investigated. 1) Developing the capabilities of tensor analysis into machine learning and pattern recognition applications such as facial recognition. 2) Answering a controversial question about the usefulness of the color information for face recognition despite small color sub-space which facial pictures possess. Firstly, an algorithm based on merely color information, extracted by tensor-matrix decomposition, is proposed. The proposed method reveals the potential of this kind of information. Secondly, another algorithm is proposed which utilizes both color and structural information by which the recognition rate is improved. Finally, by presenting the third algorithm based on tensor-tensor analysis and introducing the Eigen-Tensor concept, the task is fulfilled. The third algorithm is able to extract the color information and accomplish the dimensionality reduction simultaneously. To validate their robustness, these three proposed algorithms are evaluated by three different databases with different properties. The results represent the capabilities of tensor-tensor analysis, in comparison with other approaches. It is also proven that in spite of using the ordinary classifiers, the recognition rate more than 94% is achievable.
C1 [Koushkaki, Hassan Rahmanian; Salehi, Mohammad Reza; Abiri, Ebrahim] Shiraz Univ Technol SUTECH, Elect & Elect Engn Dept, Shiraz, Iran.
   [Salehi, Mohammad Reza] Reg Informat Ctr Sci & Technol RICeST, Co Dept 2, Jam E Jam Ave, Shiraz, Iran.
C3 Shiraz University of Technology
RP Salehi, MR (corresponding author), Shiraz Univ Technol SUTECH, Elect & Elect Engn Dept, Shiraz, Iran.; Salehi, MR (corresponding author), Reg Informat Ctr Sci & Technol RICeST, Co Dept 2, Jam E Jam Ave, Shiraz, Iran.
EM h.rahmanian@sutech.ac.ir; salehi@sutech.ac.ir; abiri@sutech.ac.ir
RI Rahmanian'Koushkaki, Hassan/KRX-7812-2024
OI Rahmanian'Koushkaki, Hassan/0000-0002-4545-1476
CR Adachi Kohei, 2018, MATRIX BASED INTRO M, pE1
   Alzu'bi S., 2010, ADV ARTIFICIAL INTEL, V2010
   AlZu'bi S, 2019, MULTIMED TOOLS APPL
   Bader B.W., 2007, Tensor decompositions and their application
   Bowen RM, 2014, LINEAR ALGEBRA 1
   Briefs S, 2016, MATRIX TENSOR FACTOR
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Choi JY, 2011, PATTERN RECOGN, V44, P412, DOI 10.1016/j.patcog.2010.08.020
   Choi JY, 2009, IEEE T SYST MAN CY B, V39, P1217, DOI 10.1109/TSMCB.2009.2014245
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Eldén L, 2007, FUND ALGORITHMS, V4, pIX, DOI 10.1137/1.9780898718867
   Fallis A., 2013, J CHEM INF MODEL, V53, P1689, DOI [DOI 10.1017/CBO9781107415324.004, 10.1017/CBO9781107415324.004]
   Geometry R, 2013, ANAL MULTIVARIATE HI
   Hu KX, 2014, VISUAL COMPUT, V30, P685, DOI 10.1007/s00371-014-0962-1
   Iozzi A, 2014, MULTILINEAR ALGEBRA
   Jing XY, 2010, IEEE IMAGE PROC, P3841, DOI 10.1109/ICIP.2010.5654099
   Kemp R, 1996, PERCEPTION, V25, P37, DOI 10.1068/p250037
   Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I
   Kilmer ME, 2013, 3 ORDER TENSORS OPER, V34
   Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020
   Kim YD, 2007, LECT NOTES COMPUT SC, V4642, P19
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kroonenberg P.M., 2007, Applied Multiway Data Analysis
   Lajevardi SM, 2012, IEEE T IMAGE PROCESS, V21, P3721, DOI 10.1109/TIP.2012.2197628
   Liu CJ, 2008, IEEE T INF FOREN SEC, V3, P213, DOI 10.1109/TIFS.2008.923824
   Liu ZM, 2010, PATTERN RECOGN, V43, P2882, DOI 10.1016/j.patcog.2010.03.003
   Liu ZH, 2017, NEURAL PROCESS LETT, V45, P913, DOI 10.1007/s11063-016-9550-x
   Lu H., 2013, Multilinear subspace learning: dimensionality reduction of multidimensional data
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   Mahmoud S, 2011, 3D MULTIRESOLUTION S
   Man JY, 2011, LECT NOTES COMPUT SC, V7098, P58, DOI 10.1007/978-3-642-25449-9_8
   Martin A., 1997, The DET Curve in Assessment of Detection Task Performance
   Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229
   Martinez A., 2000, AR FACE DATABASE
   Martinez A. M., 2018, P NATL ACAD SCI USA
   Matrix N, 2008, NONNEGATIVE MATRIX F
   Morup M, 2011, WIRES DATA MIN KNOWL, V1, P24, DOI 10.1002/widm.1
   Paredes BR, 2014, MULTITASK TRANSFER L
   Qi L., 2018, ADV MECH MATH, V39, DOI DOI 10.1007/978-981-10-8058-6
   Rabanser S., 2017, INTRO TENSOR DECOMPO
   Rahmanian Koushkaki H, 2017, MULTIMED TOOLS APPL
   Rezghi M, 2011, LINEAR ALGEBRA APPL, V435, P422, DOI 10.1016/j.laa.2010.03.032
   Sakata T, 2016, SPRINGERBRIEFS STAT
   Shashua A, 2007, TENSOR METHODS MACHI
   Shen XB, 2018, J VIS COMMUN IMAGE R, V53, P161, DOI 10.1016/j.jvcir.2018.03.004
   Sidiropoulos ND, 2017, MACH LEARN, V65
   Smilde A., 2004, MULTIWAY ANAL APPL C
   Sun YF, 2014, MULTIMED TOOLS APPL, V73, P2063, DOI 10.1007/s11042-013-1638-y
   Thomaz CE, 2018, FEI FACE DATABASE
   Torres L., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P627, DOI 10.1109/ICIP.1999.817191
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vasilescu M.A.O, 2012, THESIS
   Wang CWC, 2008, 2008 19 INT C PATT R, P8
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wang SJ, 2011, IEEE T IMAGE PROCESS, V20, P2490, DOI 10.1109/TIP.2011.2121084
   Wu F, 2016, PATTERN RECOGN, V60, P630, DOI 10.1016/j.patcog.2016.06.010
   Xiang XG, 2015, NEUROCOMPUTING, V152, P231, DOI 10.1016/j.neucom.2014.10.074
   Xiao K, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190850
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2008, IEEE T NEURAL NETWOR, V19, P2088, DOI 10.1109/TNN.2008.2003187
NR 60
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5829
EP 5858
DI 10.1007/s11042-019-08177-w
EA DEC 2019
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000508715000001
DA 2024-07-18
ER

PT J
AU Li, JY
   Yu, H
   Zhang, LY
   Wen, GQ
AF Li, Jiaye
   Yu, Hao
   Zhang, Leyuan
   Wen, Guoqiu
TI Double weighted K-nearest voting for label aggregation in crowdsourcing
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowdsourcing; K-nearest neighbor; Label aggregation
ID QUALITY
AB In this article, we propose a new voting strategy in crowdsourcing learning by avoiding the effects of missing labels and poor workers. To achieve this, we apply K-nearest neighbor idea and fitting learning to consider the importance of neighbor sample labels and the importance of workers, respectively. Specifically, we apply different weights to different neighbors based on the distance of the sample neighbors, which is important for the neighbor sample labels. At the same time, we propose an effective worker model to consider the importance of workers by removing redundant workers. In addition, we use an alternate iterative optimization algorithm to solve our proposed model. The experimental results show that the proposed algorithm achieves better performance in label aggregation accuracy than the comparison algorithm.
C1 [Li, Jiaye; Zhang, Leyuan; Wen, Guoqiu] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Yu, Hao] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Guangxi Normal University; Central South University
RP Wen, GQ (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM jiaye_ligxnu@126.com; yhgxnu@gmail.com; wenguoqiu2008@163.com
RI Zhang, Leyuan/KEJ-5622-2024; wang, zhenhui/JMQ-0550-2023; Liu,
   Gui/JHU-8707-2023; Yu, Hao/L-7551-2019
OI Yu, Hao/0000-0003-2862-8054
FU China Key Research Program [2016YFB1000905]; National Natural Science
   Foundation of China [61836016]; Natural Science Foundation of China
   [61876046, 61573270, 81701780, 61672177]; Project of Guangxi Science and
   Technology [GuiKeAD17195062]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011, 2017GXNSFBA198221]; Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing; Guangxi High Institutions Program of Introducing 100
   High-Level Overseas Talents; Guangxi Key Lab of Multisource Information
   Mining Security [18-A-01-01]; PhD research startup foundation of Guangxi
   Normal University [2017BQ17]; Guangxi Graduate Education [YCSW2019073,
   JXYJSKT-2019-005, JXYJSKT-2019-006]
FX This work is partially supported by the China Key Research Program
   (Grant No: 2016YFB1000905), the Key Program of the National Natural
   Science Foundation of China (Grant No: 61836016), the Natural Science
   Foundation of China (Grants No: 61876046, 61573270, 81701780 and
   61672177), the Project of Guangxi Science and Technology
   (GuiKeAD17195062), the Guangxi Natural Science Foundation (Grant No:
   2015GXNSFCB139011, 2017GXNSFBA198221), the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; the Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents, the Research Fund of
   Guangxi Key Lab of Multisource Information Mining & Security
   (18-A-01-01), the PhD research startup foundation of Guangxi Normal
   University (Grants No: 2017BQ17), and Innovation Project of Guangxi
   Graduate Education (grants No: YCSW2019073, JXYJSKT-2019-005 and
   JXYJSKT-2019-006).
CR Barbosa NM, 2019, REHUMANIZED CROWDSOU
   Chawla S, 2019, GAME ECON BEHAV, V113, P80, DOI 10.1016/j.geb.2015.09.001
   Cohensius G., 2018, ARXIV180606257
   Daniel F, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148148
   Dawid A. P., 1979, J ROY STAT SOC C, P28
   Deng ZY, 2016, NEUROCOMPUTING, V195, P143, DOI 10.1016/j.neucom.2015.08.112
   Estellés-Arolas E, 2012, J INF SCI, V38, P189, DOI 10.1177/0165551512437638
   Feng JH, 2014, LECT NOTES COMPUT SC, V8422, P453, DOI 10.1007/978-3-319-05813-9_30
   Foody G, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030080
   Ghezzi A, 2018, INT J MANAG REV, V20, P343, DOI 10.1111/ijmr.12135
   Han B, 2019, IEEE T NEUR NET LEAR, V30, P3774, DOI 10.1109/TNNLS.2019.2899045
   Ho Chien-Ju, 2012, 26 AAAI C ART INT
   Jin Y, 2018, LECT NOTES ARTIF INT, V10938, P128, DOI 10.1007/978-3-319-93037-4_11
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Li CQ, 2019, ENG APPL ARTIF INTEL, V82, P184, DOI 10.1016/j.engappai.2019.04.004
   Li GL, 2016, IEEE T KNOWL DATA EN, V28, P2296, DOI 10.1109/TKDE.2016.2535242
   Li JY, 2018, LECT NOTES COMPUT SC, V11140, P596, DOI 10.1007/978-3-030-01421-6_57
   Li SY, 2019, IEEE T KNOWL DATA EN, V31, P1369, DOI 10.1109/TKDE.2018.2857766
   Li SY, 2018, LECT NOTES ARTIF INT, V11012, P232, DOI 10.1007/978-3-319-97304-3_18
   Liu X, 2012, PROC VLDB ENDOW, V5, P1040, DOI 10.14778/2336664.2336676
   Man-Ching Yuen, 2011, Proceedings of the 2011 IEEE International Conference on Internet of Things and 4th IEEE International Conference on Cyber, Physical and Social Computing (iThings/CPSCom 2011), P409, DOI 10.1109/iThings/CPSCom.2011.128
   Provost F, 2010, P SIGKDD WORKSH HUM, V64, P67
   Qiu C, 2018, LECT NOTES ARTIF INT, V11013, P165, DOI 10.1007/978-3-319-97310-4_19
   Shah NB, 2015, PR MACH LEARN RES, V37, P10
   Snow R, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751
   Song JH, 2018, KNOWL-BASED SYST, V159, P244, DOI 10.1016/j.knosys.2018.07.010
   Tao DP, 2019, IEEE T NEUR NET LEAR, V30, P163, DOI 10.1109/TNNLS.2018.2836969
   Wright P, 2012, ADVOCATE J NAT TERTI, V19, P32
   Yan Y., 2011, PROC 28 INT C MACH L
   Yu J., 2018, P APSIPA ANN SUMM C, P12
   Zhang H, 2018, LECT NOTES ARTIF INT, V11013, P228, DOI 10.1007/978-3-319-97310-4_26
   Zhang J. Y., 2019, IEEE T NEURAL NETWOR
   Zhang SC, 2020, NEUROCOMPUTING, V391, P234, DOI 10.1016/j.neucom.2018.11.101
   Zhang SC, 2018, WORLD WIDE WEB, V21, P1787, DOI 10.1007/s11280-018-0619-5
   Zheng HC, 2011, INT J ELECTRON COMM, V15, P57, DOI 10.2753/JEC1086-4415150402
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou D, 2012, INT C NEUR INF PROC
   Zhou D., 2013, ARXIV13105764
   Zhu X, SYSTEMS MAN CYBERN A, DOI [10.1109/TKDE.2018.2858782, DOI 10.1109/TKDE.2018.2858782]
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhuang YF, 2017, INT CONF SOFTW ENG, P194, DOI 10.1109/ICSESS.2017.8342895
NR 43
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33357
EP 33374
DI 10.1007/s11042-019-08054-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600036
DA 2024-07-18
ER

PT J
AU Lu, A
   Huo, Y
   Zhou, JB
AF Lu, Ali
   Huo, Ying
   Zhou, Jingbo
TI A multimedia stereo calibration algorithm based on rectangular pyramidal
   method used to aid visual navigation of ALVs under low illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous land vehicle (ALV); Visual navigation; Stereo vision; Stereo
   calibration; Multimedia images; Collinear equation; Rectangular
   pyramidal method
ID CAMERA; VISION
AB In order to measure and reconstruct accurate three-dimension (3D) data for visual aided navigation of autonomous land vehicles (ALVs), a multimedia stereo calibration algorithm which is suitable for normal scene and especially for low illumination scene is proposed. Firstly, an expression of object-point re-projection errors is derived by the collinear equation model, and the non-linear least square algorithm (NLS) is introduced to iteratively optimize external parameters for individual camera. A rectangular pyramidal method enforcing the rectangular geometric constraint is presented, to produce more stable initial parameter values. Then, according to imaging-point correspondences between the left and right camera, a re-projection error model is constructed for this stereo calibration system, of which all parameters are further optimized and calculated through the calibrated results of two separate cameras. Experimental results show that the proposed algorithm can achieve re-projection errors of no more than 0.5 pixels and converge fast usually with less than 10 interation times, whether under normal illumination or low illumination, so it can get better performance and realize a rapid re-calibration.
C1 [Lu, Ali; Huo, Ying; Zhou, Jingbo] Nanjing Inst Technol, Sch Comp Engn, Key Lab Multimedia, Nanjing 211167, Peoples R China.
   [Lu, Ali] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
C3 Nanjing Institute of Technology; Southeast University - China
RP Lu, A (corresponding author), Nanjing Inst Technol, Sch Comp Engn, Key Lab Multimedia, Nanjing 211167, Peoples R China.; Lu, A (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM luali@njit.edu.cn; huoy@njit.edu.cn; jbzhou2013@aliyun.com
OI A li, Lu/0000-0003-3419-4328
FU National Natural Science Foundation for Youth of China (NSFC) [61403188,
   61802174, 61703209]; Natural Science Foundation for Youth of JiangSu
   Province [BK20181016]; Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China [18KJB520019]; Nanjing Institute of
   Technology School Fund [CKJB201705, CKJA201803]
FX This work is supported by the National Natural Science Foundation for
   Youth of China (NSFC) under Grants No.61403188, No. 61802174, No.
   61703209, the Natural Science Foundation for Youth of JiangSu Province
   under Grant No. BK20181016, the Natural Science Foundation of the
   Jiangsu Higher Education Institutions of China under Grant No.
   18KJB520019, Nanjing Institute of Technology School Fund (CKJB201705,
   CKJA201803).
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Bellutta P, 2000, P IEEE INT VEH C DEA
   Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27
   Cai Z, 2005, IEEE INT C ROB BIOM, P658
   Dang T, 2009, IEEE T IMAGE PROCESS, V18, P1536, DOI 10.1109/TIP.2009.2017824
   Fang YJ, 2002, IEEE T INTELL TRANSP, V3, P196, DOI 10.1109/TITS.2002.802926
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Gai SY, 2018, OPT LASER ENG, V104, P126, DOI 10.1016/j.optlaseng.2017.09.025
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2012.6224570
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Ito E., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P801
   JIAN Y, 2018, J OPT SOC AM A, V35, P221
   Jin DF, 2019, OPT REV, V26, P269, DOI 10.1007/s10043-019-00496-5
   Jin DF, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.10.104109
   Kreso I., 2015, 10 INT C COMP VIS TH
   Lee MR, 2019, MULTIMED TOOLS APPL, V78, P6827, DOI 10.1007/s11042-018-6394-6
   Liu Z, 2017, OPT EXPRESS, V25, P15268, DOI 10.1364/OE.25.015269
   Matthies L, 2002, ROBOT AUTON SYST, V40, P163, DOI 10.1016/S0921-8890(02)00241-5
   Okada K, 2003, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P131, DOI 10.1109/MFI-2003.2003.1232645
   Portalés C, 2019, MULTIMED TOOLS APPL, V78, P1457, DOI 10.1007/s11042-018-6253-5
   Ranft B, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1941, DOI 10.1109/ITSC.2014.6957990
   Strau T, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2623, DOI 10.1109/ITSC.2014.6958110
   Sun J, 2017, OPT COMMUN, V390, P7, DOI 10.1016/j.optcom.2016.12.056
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Wang J, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.4.041307
   Wang MS, 2005, 2005 IEEE International Symposium on Computational Intelligence in Robotics and Automation, Proceedings, P3
   Wang YL, 2019, MULTIMED TOOLS APPL, V78, P12223, DOI 10.1007/s11042-018-6763-1
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 29
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34673
EP 34687
DI 10.1007/s11042-019-08188-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800020
DA 2024-07-18
ER

PT J
AU Zhan, Y
   Su, YJ
   Wang, X
   Pei, QQ
AF Zhan, Yang
   Su, Yujie
   Wang, Xiang
   Pei, Qingqi
TI Three-dimensional Prediction-Error Histograms Based Reversible Data
   Hiding Algorithm for Color Images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image; Reversible data hiding; Prediction-error group; Correlation
ID EXPANSION; SCHEME; PARTITION
AB Reversible watermarking technologies have rapidly developed in recent years, but there are few research achievements in the area of reversible watermarking technology for color images. Thus, in this study, a reversible data hiding (RDH) algorithm for color images was constructed based on three-dimensional (3D) histogram shifting. The algorithm improves the peak signal-to-noise ratio and reduces distortion by using rhombus prediction to predict the pixel values of each of the RGB channels of a color image to establish 3D prediction-error groups, and by modifying the mappings of the prediction-error groups in the prediction-error histogram such that mappings with high distortion are rejected and new mappings can be constructed. The experimental results proved that, under the condition of the same embedding capacity, the proposed color image-purposed algorithm, which takes advantage of the correlations between RGB channels, can yield lower distortion than conventional RDH algorithms for color images.
C1 [Zhan, Yang; Su, Yujie; Wang, Xiang; Pei, Qingqi] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Wang, X (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
EM wangxiang@xidian.edu.cn
RI Su, Yujie/ACF-0070-2022
OI Su, Yujie/0000-0001-9036-3347; Wang, Xiang/0000-0001-5900-8486
FU Key Basic Research Plan in Shaanxi Province [2017ZDXM-GY-014]
FX This work was supported by the Key Basic Research Plan in Shaanxi
   Province (Grant No. 2017ZDXM-GY-014).
CR Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   He W, 2017, OPTIK INT J LIGHT EL
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Jiang RQ, 2018, MULTIMED TOOLS APPL, V77, P5263, DOI 10.1007/s11042-017-4430-6
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010049
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
NR 29
TC 5
Z9 5
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35289
EP 35311
DI 10.1007/s11042-019-07962-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800047
DA 2024-07-18
ER

PT J
AU Prasad, S
   Pal, AK
AF Prasad, Shiv
   Pal, Arup Kumar
TI A tamper detection suitable fragile watermarking scheme based on novel
   payload embedding strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Hamming codes; Logistic-map; Tamper detection
ID IMAGE AUTHENTICATION SCHEME
AB Intentional tampering in digital image content is one of the common malpractices in the current digital arena. So in this paper, the authors have proposed a novel fragile watermarking scheme for the localization of tampered image content effectively. Proposed fragile watermarking scheme detects forged image content robustly in block level of two consecutive pixels. In this work, the watermark embedding procedure is comprised of two phases- i.e., authentication code generation from some selected salient bits of each pixel of the original image content, and encryption of the authentication code before realizing it for embedding into the insignificant bits of each pixel in the original cover image. The authentication code is computed from each block using Hamming Code. Subsequently, the encrypted code is concealed into the pixels of that particular block using the suggested payload embedding strategy i.e., pixel adjustment process. The proposed fragile watermarking procedure ensures the high level of security since the encrypted authentication code is embedded into the cover image through an indirect mechanism i.e. block-level pixel adjustment process. This scheme has been implemented and tested on several grayscale images in order to confirm the tampering detection capability against various image manipulation attacks. The experimental results exhibit better performance in terms of various perceptual quality measures like peak signal to noise ratio, structural similarity index, and image fidelity. Further, the presented results demonstrate that the scheme is suitable for detecting whether a concerned image has undergone any form of tampering or not and achieves standard results in terms of false-positive rate, false-negative rate, true positive rate, tamper detection accuracy, and normalized cross-correlation.
C1 [Prasad, Shiv; Pal, Arup Kumar] Indian Sch Mines, Dept Comp Sci & Engn, Indian Inst Technol, Dhanbad 826004, Jbarlchand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Prasad, S (corresponding author), Indian Sch Mines, Dept Comp Sci & Engn, Indian Inst Technol, Dhanbad 826004, Jbarlchand, India.
EM psad.shiv@gmail.com; arupkrpal@gmail.com
RI PRASAD, SHIV/AAK-1104-2021; Pal, Arup Kumar/I-2496-2016
OI PRASAD, SHIV/0000-0002-9439-5765; 
CR Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Chan CS, 2007, PATTERN RECOGN, V40, P681, DOI 10.1016/j.patcog.2006.05.018
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Chang YF, 2013, OPTO-ELECTRON REV, V21, P182, DOI 10.2478/s11772-013-0088-4
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   He HJ, 2007, 2007 SECOND INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P216, DOI 10.1109/BICTA.2007.4806454
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Lu C., 2005, MULTIMEDIA SECURITY
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Peng YY, 2018, J INF SECUR APPL, V40, P236, DOI 10.1016/j.jisa.2018.04.007
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Ranade SK., 2017, INT J ADV RES COMPUT, V6, P1058
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Sreenivas K, 2017, J VIS COMMUN IMAGE R, V49, P164, DOI 10.1016/j.jvcir.2017.09.001
   Suthaharan S, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/829516
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   William S., 2007, CRYPTOGRAPHY NETWORK
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xiao D, 2012, OPT COMMUN, V285, P2596, DOI 10.1016/j.optcom.2012.02.002
   Yin ZX, 2016, COGN COMPUT, V8, P890, DOI 10.1007/s12559-016-9408-6
NR 26
TC 31
Z9 31
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1673
EP 1705
DI 10.1007/s11042-019-08144-5
EA NOV 2019
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495055800003
DA 2024-07-18
ER

PT J
AU Dong, GH
   Zhang, X
   Lan, L
   Wang, SW
   Luo, ZG
AF Dong, Guohua
   Zhang, Xiang
   Lan, Long
   Wang, Shiwei
   Luo, Zhigang
TI Label guided correlation hashing for large-scale cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Cross-modal hashing; Generalized canonical
   correlation analysis; Supervised learning
ID SEMANTIC CORRELATION
AB With the explosive growth of multimedia data such as text and image, large-scale cross-modal retrieval has attracted more attention from vision community. But it still confronts the problems of the so-called "media gap" and search efficiency. Looking into the literature, we find that one leading type of existing cross-modal retrieval methods has been broadly investigated to alleviate the above problems by capturing the correlations across modalities as well as learning hashing codes. However, supervised label information is usually independently considered in the process of either generating hashing codes or learning hashing function. To this, we propose a label guided correlation cross-modal hashing method (LGCH), which investigates an alternative way to exploit label information for effective cross-modal retrieval from two aspects: 1) LGCH learns the discriminative common latent representation across modalities through joint generalized canonical correlation analysis (GCCA) and a linear classifier; 2) to simultaneously generate binary codes and hashing function, LGCH introduces an adaptive parameter to effectively fuse the common latent representation and the label guided representation for effective cross-modal retrieval. Moreover, each subproblem of LGCH has the elegant analytical solution. Experiments of cross-modal retrieval on three multi-media datasets show LGCH performs favorably against many well-established baselines.
C1 [Dong, Guohua; Wang, Shiwei; Luo, Zhigang] Natl Univ Def Technol, Sci & Technol Parallel & Distributed Lab, Changsha 410073, Hunan, Peoples R China.
   [Dong, Guohua; Zhang, Xiang; Lan, Long; Wang, Shiwei; Luo, Zhigang] Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   [Zhang, Xiang; Lan, Long] Natl Univ Def Technol, Inst Quantum Informat, Changsha 410073, Hunan, Peoples R China.
   [Zhang, Xiang; Lan, Long] Natl Univ Def Technol, State Key Lab High Performance Comp, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China; National University of Defense Technology
   - China; National University of Defense Technology - China
RP Luo, ZG (corresponding author), Natl Univ Def Technol, Sci & Technol Parallel & Distributed Lab, Changsha 410073, Hunan, Peoples R China.; Zhang, X; Lan, L; Luo, ZG (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.; Zhang, X; Lan, L (corresponding author), Natl Univ Def Technol, Inst Quantum Informat, Changsha 410073, Hunan, Peoples R China.; Zhang, X; Lan, L (corresponding author), Natl Univ Def Technol, State Key Lab High Performance Comp, Changsha 410073, Hunan, Peoples R China.
EM zhangxiang08@nudt.edu.cn; long.lan@nudt.edu.cn; zgluo@nudt.edu.cn
RI Zhang, Xiangyu/ABC-2896-2021
OI Zhang, Xiangyu/0000-0003-3716-4722
FU National Natural Science Foundation of China [61806213, U1435222]
FX This work was supported by the National Natural Science Foundation of
   China [61806213, U1435222]
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], AAAI C ART INT
   [Anonymous], 2004, P 20 ACM S COMP
   [Anonymous], 2011, P ICML
   [Anonymous], ARXIV0609071
   [Anonymous], 2017, IEEE T CIRCUITS SYST
   [Anonymous], 2017, ARXIV170202519
   [Anonymous], INT C NEUR INT PROC
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Clinchant S., 2011, ICMR, P44
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Dong GH, 2018, IEEE INT CON MULTI
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   HORST P, 1961, J CLIN PSYCHOL, V17, P331, DOI 10.1002/1097-4679(196110)17:4<331::AID-JCLP2270170402>3.0.CO;2-D
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Long MS, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P579, DOI 10.1145/2911451.2911493
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma D, 2013, IEEE IMAGE PROC, P3986, DOI 10.1109/ICIP.2013.6738821
   MIRSKY L, 1975, MONATSH MATH, V79, P303, DOI 10.1007/BF01647331
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Shen XB, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178119
   Shen XB, 2018, IEEE T NEUR NET LEAR, V29, P4324, DOI 10.1109/TNNLS.2017.2763967
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang Xiaodong, 2011, Proceedings of the 2011 International Conference on Business Management and Electronic Information (BMEI 20111), P1, DOI 10.1109/ICBMEI.2011.5918026
   Wang XC, 2013, IEEE T IMAGE PROCESS, V22, P2646, DOI 10.1109/TIP.2013.2255300
   Wang XC, 2011, IEEE T IMAGE PROCESS, V20, P2627, DOI 10.1109/TIP.2011.2114354
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu BT, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3946
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Yang EK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1064
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P213, DOI 10.1145/3206025.3206042
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 59
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30895
EP 30922
DI 10.1007/s11042-019-7192-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200068
DA 2024-07-18
ER

PT J
AU Gong, XN
   Yang, Z
   Wang, DY
   Qi, YL
   Guo, YA
   Ma, YD
AF Gong, Xiaonan
   Yang, Zhen
   Wang, Deyuan
   Qi, Yunliang
   Guo, Yanan
   Ma, Yide
TI Breast density analysis based on glandular tissue segmentation and mixed
   feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Breast density; Threshold segmentation; Feature
   extraction; SVM
ID DIGITAL MAMMOGRAPHY; FEATURE-SELECTION; CANCER; RISK; STATISTICS;
   MACHINE
AB Breast cancer poses a threat to the lives of many women. Breast density is a closely related indicator of breast cancer risk. The aim of this paper is to propose a classification system for breast density, which can appropriately segment the glandular tissue from the whole breast and to achieve a better classification result. A new threshold method is applied to segment the breast glandular tissue. The gray level co-occurrence matrix (GLCM) is implemented to extract the texture features of the glandular tissue. Meanwhile, we obtain three statistical features (mean, skewness, kurtosis). In addition, the calculated breast density that is served as a new feature is added to the feature vectors. The mixed feature vectors are classified by Support Vector Machine (SVM) and Ultimate Learning Machine (ELM). Ten-fold cross-validation is used to verify the classifier performance. The system using the SVM achieves 96.19% accuracy for three density types in the MIAS database and achieves 96.35% accuracy of four density types in the DDSM database. The accuracy in the database mixed with the local database was 95.01% and there are three density types in the mixed database. The experimental results indicate that the system proposed has a better performance in breast density classification. The system proposed in this paper can be considered to help the physician to classify breast density.
C1 [Gong, Xiaonan; Yang, Zhen; Wang, Deyuan; Qi, Yunliang; Guo, Yanan; Ma, Yide] Lanzhou Univ, Sch Informat Sci Engn, 222 Tianshui South Rd, Lanzhou 730000, Gansu, Peoples R China.
C3 Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci Engn, 222 Tianshui South Rd, Lanzhou 730000, Gansu, Peoples R China.
EM ydma@lzu.edu.cn
RI Yang, Zhen/GWQ-4960-2022; Guo, yanan/KPY-7899-2024
FU Natural Science Foundation of Gansu Province [18JR3RA288]; Fundamental
   Research Funds for the Central Universities of China
FX This work is jointly supported by the Natural Science Foundation of
   Gansu Province (No.18JR3RA288) and the Fundamental Research Funds for
   the Central Universities of China (No.lzujbky-2017-it72 and
   No.lzujbky-2018-it61).
CR Anguita Davide, 2009, Proceedings of the 2009 International Conference on Data Mining. DMIN 2009, P291
   [Anonymous], KEY FACTS BREAST CAN
   [Anonymous], ELM 2013 INT S
   [Anonymous], SEGMENTATION METHOD
   [Anonymous], INT WORK DIG MAMM
   [Anonymous], ELM 2010 P
   [Anonymous], BREAST DENSITY CLASS
   [Anonymous], INSTR MEAS TECHN C
   [Anonymous], ENG MED BIOL SOC 200
   [Anonymous], ADV COMPUTER ASSISTE
   [Anonymous], 2007, P 28 AS C REM SENS A
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], 2011, IEEE INT S BIOM IM N
   [Anonymous], 2017, Cancer Facts Figures
   [Anonymous], INT C BIOM ENG INF
   [Anonymous], 1 INT S CONTR COMM S
   [Anonymous], P 2005 IEEE INT JOIN
   [Anonymous], INT C COMP SUST GLOB
   [Anonymous], 2017, U.S. Breast Cancer Statistics
   [Anonymous], INT C INF SCI CONTR
   [Anonymous], MAMMOGRAPHIC DENSITY
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], LEARNING KERNELS SUP
   [Anonymous], 2001, MIUA
   [Anonymous], DIGITAL IMAGE PROCES
   Boehm A, 2013, 2013 INTERNATIONAL CONFERENCE ON PRIVACY AND SECURITY IN MOBILE SYSTEMS (PRISMS)
   Bovis K., 2002, Proceedings of the 4th Int Workshop on Digital Mammography, P177
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   de Oliveira JEE, 2011, WORLD J RADIOL, V3, P24, DOI 10.4329/wjr.v3.i1.24
   Giuliano Vincenzo, 2013, ISRN Radiol, V2013, P235270, DOI 10.5402/2013/235270
   Gubern-Mérida A, 2015, IEEE J BIOMED HEALTH, V19, P349, DOI 10.1109/JBHI.2014.2311163
   Guo YN, 2016, COMPUT METH PROG BIO, V130, P31, DOI 10.1016/j.cmpb.2016.02.019
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He WD, 2011, BIOMED SIGNAL PROCES, V6, P321, DOI 10.1016/j.bspc.2011.03.008
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kohavi R., 1995, INT JOINT C ART INT, V2, P1137, DOI DOI 10.1067/MOD.2000.109031
   Kumar I, 2017, BIOCYBERN BIOMED ENG, V37, P217, DOI 10.1016/j.bbe.2017.01.001
   Kumar I, 2015, PROCEDIA COMPUT SCI, V70, P76, DOI 10.1016/j.procs.2015.10.042
   Liberman L, 2002, RADIOL CLIN N AM, V40, P409, DOI 10.1016/S0033-8389(01)00017-3
   Lin SW, 2008, APPL SOFT COMPUT, V8, P1505, DOI 10.1016/j.asoc.2007.10.012
   Machida Y, 2015, BREAST CANCER-TOKYO, V22, P253, DOI 10.1007/s12282-015-0602-2
   Malkov S, 2016, BREAST CANCER RES, V18, DOI 10.1186/s13058-016-0778-1
   Manduca A, 2009, CANCER EPIDEM BIOMAR, V18, P837, DOI 10.1158/1055-9965.EPI-08-0631
   Marchette DJ, 1997, PATTERN RECOGN, V30, P1547, DOI 10.1016/S0031-3203(96)00173-2
   MARTIN JE, 1979, AM J ROENTGENOL, V132, P737, DOI 10.2214/ajr.132.5.737
   Nagata C, 2005, BRIT J CANCER, V92, P2102, DOI 10.1038/sj.bjc.6602643
   Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514
   Oliver A, 2015, J DIGIT IMAGING, V28, P604, DOI 10.1007/s10278-015-9777-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petroudi S, 2013, IEEE INT C BIOINF BI
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Philip Chang K., 2001, The digital database for screening mammography
   Remes V, 2015, 2015 INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA UNDERSTANDING (IWCIM)
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Sivaramakrishna R, 2001, ACAD RADIOL, V8, P250, DOI 10.1016/S1076-6332(03)80534-2
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Sohn G, 2014, J BREAST CANCER, V17, P174, DOI 10.4048/jbc.2014.17.2.174
   Strand F, 2016, BREAST CANCER RES, V10, DOI 10.1186/s13058-016-0761-x
   Subashini TS, 2010, COMPUT VIS IMAGE UND, V114, P33, DOI 10.1016/j.cviu.2009.09.009
   Tzikopoulos SD, 2011, COMPUT METH PROG BIO, V102, P47, DOI 10.1016/j.cmpb.2010.11.016
   van Engeland S, 2006, IEEE T MED IMAGING, V25, P273, DOI 10.1109/TMI.2005.862741
   Wang J, 2017, J DIGIT IMAGING, V30, P215, DOI 10.1007/s10278-016-9922-9
   WOLFE JN, 1976, CANCER-AM CANCER SOC, V37, P2486, DOI 10.1002/1097-0142(197605)37:5<2486::AID-CNCR2820370542>3.0.CO;2-8
   Yaffe MJ, 2008, BREAST CANCER RES, V10, DOI 10.1186/bcr2102
   Zhang W, 2015, PROCEEDINGS OF THE 2015 FIRST INTERNATIONAL CONFERENCE ON RELIABILITY SYSTEMS ENGINEERING 2015 ICRSE
   Zhili Chen, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P351, DOI 10.1109/BMEI.2011.6098279
NR 71
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31185
EP 31214
DI 10.1007/s11042-019-07917-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000010
DA 2024-07-18
ER

PT J
AU Ju, CH
   Wang, J
   Zhou, GL
AF Ju, Chunhua
   Wang, Jie
   Zhou, Guanglan
TI The commodity recommendation method for online shopping based on data
   mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Online shopping; Commodity recommendation; Similarity;
   Requirement analysis
ID BEHAVIOR
AB With the development of E-commerce, more and more people have strong desire to buy goods on the online shopping platform. But they often need to spend more time searching for satisfactory goods because of the large amount of data. We propose a commodity recommendation model of online shopping based on data mining method in this paper. At first, we calculate the similarity between online shopping data of users' behavior record and commodity rate, and identify the user with highest similarity as the friend of target user. Then we utilize the data of browsing history and collection commodity to analyze the recent demands of target user, and produce a demand list from the target user. After that, we search for specific commodities in friend's shopping record according to the target user demand list, and make recommendation for the target user. Taking Taobao as the research object, we conclude that the proposed method is more accurate, and the accuracy value of our methods reached 0.315 at the condition of P@N equalling to 15 from the experiment results.
C1 [Ju, Chunhua] Zhejiang Gongshang Univ, Sch Management Sci, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Jie] Zhejiang Gongshang Univ, Sch Business Adm, Hangzhou 310018, Zhejiang, Peoples R China.
   [Zhou, Guanglan] Zhejiang Gongshang Univ, Sch Stat, Modern Business Res Ctr, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University; Zhejiang
   Gongshang University
RP Zhou, GL (corresponding author), Zhejiang Gongshang Univ, Sch Stat, Modern Business Res Ctr, Hangzhou 310018, Zhejiang, Peoples R China.
EM 306601046@qq.com
FU Zhejiang Province Public Welfare Technology Application Research Project
   [LGN18G010001]; China Postdoctoral Fund [2018 M632497]; Zhejiang
   Postdoctoral Fund [2017-117]; Key Project of Social Science Fund
   [16ZDA053]; Philosophy and Social Science Foundation of Zhejiang
   Province [17YJA630125, 17NDJC107YB, 16NDJC189YB]; Natural Science
   Foundation of China [71203196, 71401156, 71671165, 71702164]; Zhijiang
   Scholar Program [G665]; Zhejiang First class discipline A- Management
   Science, Zhejiang Gongshang University Postdoctoral Fund
FX The authors thank Dr. Wanqiong Tao who participated in writing or
   editing of the manuscript. This paper is supported by Zhejiang Province
   Public Welfare Technology Application Research Project (LGN18G010001),
   China Postdoctoral Fund (2018 M632497), Zhejiang Postdoctoral Fund
   (2017-117), Key Project of Social Science Fund (No. 16ZDA053),
   Philosophy and Social Science Foundation of Zhejiang Province
   (17YJA630125, 17NDJC107YB, 16NDJC189YB), Natural Science Foundation of
   China (No. 71203196, 71401156, 71671165, 71702164), Zhijiang Scholar
   Program (G665), Zhejiang First class discipline A- Management Science,
   Zhejiang Gongshang University Postdoctoral Fund. The authors thank them
   heartedly for supporting the paper funds.
CR [Anonymous], 2018, SIZE CHINAS ONLINE S
   [Anonymous], 2000, International Journal of Retail Distribution Management, DOI DOI 10.1108/09590550010306737
   [Anonymous], 2018, QUANTITY INTERNET US
   Chen X, 2016, J MUDANJIANG NORMAL, V9401, P32
   Hasan B, 2016, COMPUT HUM BEHAV, V54, P224, DOI 10.1016/j.chb.2015.07.056
   Jhamb Y, 2017, INFORM PROCESS MANAG, V53, P559, DOI 10.1016/j.ipm.2017.01.001
   Jiang M, 2014, IEEE T KNOWL DATA EN, V26, P2789, DOI 10.1109/TKDE.2014.2300487
   Li H, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416590163
   Lim YJ, 2016, PROC ECON FINANC, V35, P401, DOI 10.1016/S2212-5671(16)00050-2
   Lv X-l, 2007, STAT INFORM FORUM, V22, P29
   Malik G., 2013, Business Perspectives Research, V2, P13, DOI [10.1177/2278533720130102, DOI 10.1177/2278533720130102]
   Moe WW, 2004, MANAGE SCI, V50, P326, DOI 10.1287/mnsc.1040.0153
   Sismeiro C, 2004, J MARKETING RES, V41, P306, DOI 10.1509/jmkr.41.3.306.35985
   Sun ZB, 2015, J SYST SOFTWARE, V99, P109, DOI 10.1016/j.jss.2014.09.019
   Xu CH, 2018, INFORM PROCESS MANAG, V54, P463, DOI 10.1016/j.ipm.2018.02.005
NR 15
TC 5
Z9 7
U1 2
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30097
EP 30110
DI 10.1007/s11042-018-6980-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200026
DA 2024-07-18
ER

PT J
AU Lee, TF
   Diao, YY
   Hsieh, YP
AF Lee, Tian-Fu
   Diao, Yin-Yu
   Hsieh, Yi-Pei
TI A ticket-based multi-server biometric authentication scheme using
   extended chaotic maps for telecare medical information systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; TMIS; Key agreement; Multi-server; Biometrics
ID KEY-AGREEMENT; USER AUTHENTICATION; EFFICIENT
AB With the development of technology, medical activities have gradually changed from traditional in-hospital diagnostic to telemedicine on the internet. These days, to accommodate security and efficiency in telemedicine, many authentication schemes were proposed for Telemedicine Medical Information Systems. Most of these authentication mechanisms usually rely on an online third party such that many schemes suffered from security vulnerabilities including limited bandwidth, impersonation attack, etc. For example, when the demand for authentication services suddenly increases, the third party bandwidth may overload so that the system broken and fails to serve correctly. Additionally, malicious legal insiders may easily obtain information of other participants, and then perform impersonation attacks. To prevent these weaknesses, this study develops a secure and efficient authentication scheme by using extended chaotic maps. The proposed scheme enables legal participants to directly authenticate and communicate each other without the help of an online trusted third party. It is also suitable for multi-server environment, and patients only register their identities to a center management server once. Then they can get services from all service providers in this system by using a registration ticket issued by the center management server. Accordingly, the limited bandwidth capability problems can be eliminated. Additionally, it has been shown that extended chaotic maps computations are more efficient than modular exponential computations or scalar multiplications on an elliptic curve. The proposed scheme not only provides more security properties, but also is more efficient than related schemes.
C1 [Lee, Tian-Fu; Diao, Yin-Yu] Tzu Chi Univ, Dept Med Informat, 701,Zhongyang Rd,Sec 3, Hualien 97004, Taiwan.
   [Lee, Tian-Fu] Tzu Chi Univ, Inst Med Sci, 701,Zhongyang Rd,Sec 3, Hualien 97004, Taiwan.
   [Hsieh, Yi-Pei] Tzu Chi Univ Sci & Technol, Dept Informat Technol & Management, 880,Chien Kuo Rd,Sec 2, Hualien 97005, Taiwan.
C3 Tzu Chi University; Tzu Chi University; Tzu Chi University of Science &
   Technology
RP Lee, TF (corresponding author), Tzu Chi Univ, Dept Med Informat, 701,Zhongyang Rd,Sec 3, Hualien 97004, Taiwan.; Lee, TF (corresponding author), Tzu Chi Univ, Inst Med Sci, 701,Zhongyang Rd,Sec 3, Hualien 97004, Taiwan.
EM jackytflee@mail.tcu.edu.tw; 105325116@gms.tcu.edu.tw;
   hsiehyp@tcust.edu.tw
RI Lee, Tian-Fu/AAT-4423-2020
FU Tzu Chi Unversity [TCRPP107013]
FX This work was supported by Tzu Chi Unversity, under Contract No.
   TCRPP107013.
CR Bergamo P, 2005, IEEE T CIRCUITS-I, V52, P1382, DOI 10.1109/TCSI.2005.851701
   Chaudhry SA, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0592-4
   Giri D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0145-7
   Huh JH, 2019, J SUPERCOMPUT, V75, P1831, DOI 10.1007/s11227-018-2342-5
   Irshad A, 2018, ARAB J SCI ENG, V43, P811, DOI 10.1007/s13369-017-2764-z
   Irshad A, 2018, MULTIMED TOOLS APPL, V77, P1167, DOI 10.1007/s11042-016-4236-y
   Irshad A, 2016, J SUPERCOMPUT, V72, P1623, DOI 10.1007/s11227-016-1688-9
   Islam SKH, 2014, NONLINEAR DYNAM, V78, P2261, DOI 10.1007/s11071-014-1584-x
   Jiang P, 2015, FRONT COMPUT SCI-CHI, V9, P142, DOI 10.1007/s11704-014-3125-7
   Jiang Q, 2016, NONLINEAR DYNAM, V83, P2085, DOI 10.1007/s11071-015-2467-5
   Kocarev L, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P28
   Konstantinidis EI, 2016, IEEE J BIOMED HEALTH, V20, P189, DOI 10.1109/JBHI.2014.2378814
   Lee CC, 2013, NONLINEAR DYNAM, V71, P201, DOI 10.1007/s11071-012-0652-3
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Shen H, 2015, J AMB INTEL HUM COMP, V6, P825, DOI 10.1007/s12652-015-0305-8
   허준호, 2015, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V18, P742, DOI 10.9717/kmms.2015.18.6.742
   Tan ZW, 2016, SECUR COMMUN NETW, V9, P1384, DOI 10.1002/sec.1424
   Tsai JL, 2015, INT J COMMUN SYST, V28, P1955, DOI 10.1002/dac.2829
   Vanden Abeele V.A., 2006, CHI 06 EXTENDED ABST, P1469
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhu H, 2005, KSII T INTERNET INF, V9, P811
NR 21
TC 10
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31649
EP 31672
DI 10.1007/s11042-019-07949-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000031
DA 2024-07-18
ER

PT J
AU Neelima, N
   Kumar, YR
AF Neelima, N.
   Ravi Kumar, Yada
TI Optimal clustering based outlier detection and cluster center
   initialization algorithm for effective tone mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Outlier; K-means; Density based multi scale data
   condensation; Weight based center approach
ID MODEL; COMPRESSION
AB The high dynamic range (HDR) imaging and displaying a wide range of imaging levels in the imaging industry is found in the world using devices with limited dynamic range. Generally, the clustering system plays an important role in tone mapping. Clustering is a combination of similar properties based on their properties. Maximum detection and cluster core initiation is a major problem in the cluster; has been used to remove and identify abnormal data from the database. The data value can be represented by the value data outside the boundary of the sample data. In this paper, we have suggested clustering-based release detection and cluster core initialization protocols for open tone mapping, which uses the modified K-object clustering algorithm in the cluster the data sets. A density-based multi-level data suppression (DBMSDC) algorithm is used the early cluster centers calculated using the DBMSDC algorithm have been found to be very close to the desired cluster centers. Exposure has been detected using a weight based center approach and the change K-material clustering has been removed. Test results show that the proposed methods reach advanced and efficient solutions, while the art tone mapping protocols.
C1 [Neelima, N.] CMR Inst Technol, Elect & Commun Engn, Hyderabad, Telangana, India.
   [Ravi Kumar, Yada] DLRL, SINT E Div, Hyderabad, Telangana, India.
C3 Defence Research & Development Organisation (DRDO); Defence Electronics
   Research Laboratory (DLRL)
RP Neelima, N (corresponding author), CMR Inst Technol, Elect & Commun Engn, Hyderabad, Telangana, India.
EM nnelima1229@gmail.com
CR Amundadottir ML, 2017, BUILD ENVIRON, V113, P5, DOI 10.1016/j.buildenv.2016.09.033
   Benzi M, 2018, COMPUT VIS IMAGE UND, V168, P21, DOI 10.1016/j.cviu.2017.11.013
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Eilertsen G, 2017, COMPUT GRAPH FORUM, V36, P565, DOI 10.1111/cgf.13148
   Fang HM, 2015, IET COMPUT VIS, V9, P937, DOI 10.1049/iet-cvi.2015.0047
   Gao XH, 2015, COMPUT GRAPH-UK, V52, P171, DOI 10.1016/j.cag.2015.05.028
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   Hadizadeh H, 2018, IEEE T MULTIMEDIA, V20, P392, DOI 10.1109/TMM.2017.2740023
   Hsiao PY, 2010, IEEE T IND ELECTRON, V57, P1799, DOI 10.1109/TIE.2010.2040556
   Huh JH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040093
   Huo YQ, 2016, IET IMAGE PROCESS, V10, P198, DOI 10.1049/iet-ipr.2014.0782
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Khan IR, 2018, IEEE T IND ELECTRON, V65, P3469, DOI 10.1109/TIE.2017.2760247
   Khan SS, 2013, EXPERT SYST APPL, V40, P7444, DOI 10.1016/j.eswa.2013.07.002
   Khan SS, 2004, PATTERN RECOGN LETT, V25, P1293, DOI 10.1016/j.patrec.2004.04.007
   Lee S, 2019, J SUPERCOMPUT, V75, P4267, DOI 10.1007/s11227-018-2440-4
   Li CS, 2011, PROCEDIA ENGINEER, V24, P324, DOI 10.1016/j.proeng.2011.11.2650
   Li H, 2018, COMPUT VIS IMAGE UND, V168, P37, DOI 10.1016/j.cviu.2017.11.001
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Malm H, 2007, IEEE I CONF COMP VIS, P1395
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Marsi S, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/80971
   Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856
   Nafchi HZ, 2015, IEEE SIGNAL PROC LET, V22, P1026, DOI 10.1109/LSP.2014.2381458
   Ok J, 2017, J VIS COMMUN IMAGE R, V43, P61, DOI 10.1016/j.jvcir.2016.12.008
   Oskarsson M, 2017, J MATH IMAGING VIS, V57, P225, DOI 10.1007/s10851-016-0677-1
   Patel V. A., 2017, NAT C COMP VIS PATT, P220
   Scheunders P, 1997, PATTERN RECOGN LETT, V18, P1379, DOI 10.1016/S0167-8655(97)00116-5
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Shibata T, 2016, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2016.300
   Shin S, 2017, J SOC INF DISPLAY, V25, P621, DOI 10.1002/jsid.612
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Wang L, 2007, J SOC INF DISPLAY, V15, P731, DOI 10.1889/1.2785206
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Warrant E, 2014, P IEEE, V102, P1411, DOI 10.1109/JPROC.2014.2332533
   Zhang E., 2015, Applied Mathematics & Information Sciences, V9, P411
NR 38
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31057
EP 31075
DI 10.1007/s11042-019-07907-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000004
DA 2024-07-18
ER

PT J
AU Fan, HY
   Meng, FB
   Liu, YT
   Kong, FZ
   Ma, JS
   Lv, ZH
AF Fan, Huaiyu
   Meng, Fanbin
   Liu, Yutang
   Kong, Fanzhi
   Ma, Junshan
   Lv, Zhihan
TI A novel breast ultrasound image automated segmentation algorithm based
   on seeded region growing integrating gradual equipartition threshold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seed selection; Iterative Quadtree decomposition; Breast ultrasound
   lesions; Seeded region growing
AB Automatic breast ultrasound (BUS) lesions segmentation based on seeded region growing (SRG) algorithm needs to solve two critical procedures: automatic selection of seed points and the segmentation threshold without manual intervention. For the former procedure, we establish two constraints combining iterative quadtree decomposition (QTD) and the gray characteristics of the lesion to locate the seed inside the lesion. For the latter procedure, the gradual equipartition algorithm according to the maximum change rate of the extracted region is adopted to take infinite approximation to the optimal threshold. The method is testified with 96 BUS lesion images. Quantitative results demonstrate that the proposed method can automatically find out the seed within the lesion with an accuracy rate of 92.27%. More importantly the average time consumed by the proposed algorithm is 12.02 s. Under the condition of large image samples, the efficiency is higher than that of manual segmentation.
C1 [Fan, Huaiyu; Ma, Junshan] Univ Shanghai Sci & Technol, Shanghai Key Lab Modem Opt Syst, Shanghai 200093, Peoples R China.
   [Fan, Huaiyu; Meng, Fanbin; Liu, Yutang; Kong, Fanzhi] Jining Med Univ, Dept Med Informat Engn, Jining 276826, Shandong, Peoples R China.
   [Lv, Zhihan] Qingdao Univ, Qingdao 266071, Shandong, Peoples R China.
C3 University of Shanghai for Science & Technology; Jining Medical
   University; Qingdao University
RP Ma, JS (corresponding author), Univ Shanghai Sci & Technol, Shanghai Key Lab Modem Opt Syst, Shanghai 200093, Peoples R China.
EM usstma@sina.com
RI Lv, Zhihan/GLR-6000-2022; Lyu, Zhihan/I-3187-2014; Kong,
   Fanzhi/F-5240-2011; Meng, Fanbin/I-4559-2019
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074; 
FU National Basic Research Program of China [2011CB707504]; Colleges and
   universities domestic visiting scholar project of young backbone
   teachers in Shandong province; Student Innovation Training Program of
   Jining Medical University; Industry-university collaborative education
   project of the department of higher education, ministry of education
   [201701020089]; National innovation and entrepreneurship training
   program for college students [201610443082]; Jining medical college
   student scientific research project [JYXS2017KJ031]
FX This work is supported in part by the National Basic Research Program of
   China (2011CB707504), Colleges and universities domestic visiting
   scholar project of young backbone teachers in Shandong province and
   Student Innovation Training Program of Jining Medical University,
   Industry-university collaborative education project of the department of
   higher education, ministry of education (201701020089), National
   innovation and entrepreneurship training program for college students
   (201610443082), Jining medical college student scientific research
   project (JYXS2017KJ031).
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Al-Faris AQ, 2014, J DIGIT IMAGING, V27, P133, DOI 10.1007/s10278-013-9640-5
   Cheng HD, 2010, PATTERN RECOGN, V43, P299, DOI 10.1016/j.patcog.2009.05.012
   Fan HY, 2017, MULTIMED TOOLS APPL, V76, P3505, DOI 10.1007/s11042-016-3761-z
   Korfiatis VC, 2017, COMPUT BIOL MED, V87, P358, DOI 10.1016/j.compbiomed.2017.06.016
   Liu B, 2009, ULTRASOUND MED BIOL, V35, P1309, DOI 10.1016/j.ultrasmedbio.2008.12.007
   Madabhushi A, 2003, IEEE T MED IMAGING, V22, P155, DOI 10.1109/TMI.2002.808364
   Malek AA, 2010, PROCD SOC BEHV, V8, P634, DOI 10.1016/j.sbspro.2010.12.088
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Poonguzhali S, 2006, 2006 INTERNATIONAL CONFERENCE ON BIOMEDICAL AND PHARMACEUTICAL ENGINEERING, VOLS 1 AND 2, P88
   Shan J., 2008, 2008 19 INT C PATT R, P1, DOI DOI 10.1109/ICPR.2008.4761336
   Shan J, 2012, ULTRASOUND MED BIOL, V38, P262, DOI 10.1016/j.ultrasmedbio.2011.10.022
   Xian M, 2017, INT J COMPUTER ASSIS, V12, P1
   Yap MH, 2008, J APPL CLIN MED PHYS, V9, P181, DOI 10.1120/jacmp.v9i4.2741
NR 14
TC 8
Z9 10
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27915
EP 27932
DI 10.1007/s11042-019-07884-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000051
DA 2024-07-18
ER

PT J
AU Guo, JM
   Markoni, H
AF Guo, Jing-Ming
   Markoni, Herleeyandi
TI Driver drowsiness detection using hybrid convolutional neural network
   and long short-term memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness detection; Face detection; Convolutional neural networks;
   Long short-term memory; Time skip combination long short-term memory
AB Drowsiness and fatigue of the drivers are amongst the significant causes of the car accidents. Every year the number of deaths and fatalities are tremendously increasing due to multifaceted issues and henceforth requires an intelligent processing system for accident avoidance. In relevant with this, an effective driver drowsiness detection system is proposed. The main challenges are robustness of the algorithm towards variation of the human face and real-time processing capability. The first challenge pertaining to the facial variation has been handled well using conventional image processing and handcraft features of computer vision algorithms. Yet, variations such as facial expression, lighting condition, intra-class variation, and pose variation are additional issues that conventional method failed to address. Deep learning is an alternative solution which provides a better performance by learning features automatically. Thus, this paper proposed a new concept for handling the real-time driver drowsiness detection using the hybrid of convolutional neural network (CNN) and long short-term memory (LSTM). The performance of the system has been tested using the public drowsy driver dataset from ACCV 2016 competition. The results show that it can outperform the former schemes in the literature.
C1 [Guo, Jing-Ming; Markoni, Herleeyandi] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jmguo@seed.net.tw; D10607809@mail.ntust.edu.tw
OI Markoni, Herleeyandi/0000-0002-6247-408X
CR [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], DRIVER DROWSINESS DE
   [Anonymous], IEEE T FUZZY SYST
   [Anonymous], 2016, ADAPT COMPUT MACH LE
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2001, RAPID OBJECT DETECTI
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], ARXIV170604488
   [Anonymous], DRIVER DROWSINESS DE
   [Anonymous], MSTN MULTISTAGE SPAT
   Campos Victor, 2017, ARXIV170806834
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khushaba RN, 2011, IEEE T BIO-MED ENG, V58, P121, DOI 10.1109/TBME.2010.2077291
   Lin M., 2013, P 2 INT C LEARNING R
   Ma C.-Y., 2017, ARXIV170310667
   Miao YJ, 2016, INT CONF ACOUST SPEE, P2284, DOI 10.1109/ICASSP.2016.7472084
   Sahayadhas A, 2012, SENSORS-BASEL, V12, P16937, DOI 10.3390/s121216937
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Unser M., 2017, ARXIV171004011
   Wei Zhang, 2012, Tsinghua Science and Technology, V17, P354
   Yu JT, 2016, IEEE INT SYMP NANO, P165, DOI 10.1145/2950067.2950071
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 29
TC 41
Z9 45
U1 2
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29059
EP 29087
DI 10.1007/s11042-018-6378-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JB9EM
UT WOS:000488884200001
DA 2024-07-18
ER

PT J
AU Kaur, K
   Jindal, N
   Singh, K
AF Kaur, Kanwarpreet
   Jindal, Neeru
   Singh, Kulbir
TI Improved homomorphic filtering using fractional derivatives for
   enhancement of low contrast and non-uniformly illuminated images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Homomorphic filtering; Fractional derivative; Fractional Fourier
   transform; Peak signal to noise ratio; Universal image quality index
ID FOURIER-TRANSFORM; HISTOGRAM EQUALIZATION
AB The main objective of the image enhancement is to improve the visual appearance or quality of an image. In this paper, the proposed scheme aims to improve the performance of the homomorphic filtering by employing the fractional derivatives with Discrete Fourier Transform (DFT) and Fractional Fourier Transform (FrFT). FrFT in combination with fractional derivative provides two fractional orders as extra degrees of freedom, thus, providing more design flexibility. This paper uses Grunwald-Letnikov (GL) fractional derivative to enhance the high and mid frequency components non-linearly while preserving the low frequency components. In the proposed approach, modification of homomorphic filtering technique is done on the basis of fractional derivative and FrFT to enhance the low contrast and non-uniformly illuminated images. The effectiveness of the proposed work is evaluated on the basis of various image assessment parameters such as PSNR, information entropy, universal image quality index, etc. on several images of different sizes. The proposed scheme outperforms the existing state-of-the-art techniques by providing better image visual quality and image information in terms of average PSNR and entropy values. The improvement in the average PSNR and information entropy is in the range 0.2635-50.37 dB and 0.02-42% respectively for standard images as well as for images with different contrast and illumination conditions.
C1 [Kaur, Kanwarpreet; Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM kkaur_phd16@thapar.edu; neeru.jindal@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019; Kaur, Kanwarpreet/HDM-5640-2022; Kaur,
   Kanwarpreet/AFS-2888-2022
OI Singh, Kulbir/0000-0001-8070-3395; Kaur, Kanwarpreet/0000-0002-6617-077X
CR Adelmann HG, 1998, COMPUT BIOL MED, V28, P169, DOI 10.1016/S0010-4825(98)00004-3
   Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P10883, DOI 10.1007/s11042-014-2212-y
   ALMEIDA LB, 1994, IEEE T SIGNAL PROCES, V42, P3084, DOI 10.1109/78.330368
   [Anonymous], SEGMENTATION REGIONS
   [Anonymous], 2017, The USC-SIPI Image Database
   [Anonymous], 2003, H264 MPEG 4 VIDEO CO
   [Anonymous], 2019, VIP ILLUMINATION SAL
   Bourne R, 2010, FUNDAMENTALS OF DIGITAL IMAGING IN MEDICINE, P109, DOI 10.1007/978-1-84882-087-6_6
   Chen SQ, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540058
   Chwyl B, 2015, IEEE IMAGE PROC, P1970, DOI 10.1109/ICIP.2015.7351145
   Faraji MR, 2015, IET COMPUT VIS, V9, P390, DOI 10.1049/iet-cvi.2014.0200
   Gao CB, 2015, INT J MACH LEARN CYB, V6, P35, DOI 10.1007/s13042-014-0247-z
   Garg V, 2012, INT J ADV COMPUT SC, V3, P130
   Goel N, 2016, IET SIGNAL PROCESS, V10, P173, DOI 10.1049/iet-spr.2015.0035
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Guan JL, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141857001X
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Karamizadeh S., 2015, TELKOMNIKA INDONESIA, V13, P314
   Kumar S, 2017, CIRC SYST SIGNAL PR, V36, P1493, DOI 10.1007/s00034-016-0364-x
   Kumar S, 2013, CIRC SYST SIGNAL PR, V32, P1875, DOI 10.1007/s00034-012-9548-1
   Lee SL, 2016, 2016 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P1, DOI 10.1109/APCCAS.2016.7803880
   Lin LH, 2018, CURR MED IMAGING, V14, P64, DOI 10.2174/1573405613666171003151036
   LINGASWAMY S, 2018, MULTIMED TOOLS APPL, V77, P1
   Oldham K., 1974, The Fractional Calculus, DOI DOI 10.1017/S0308210500019648
   Ortigueira M. D., 2011, FRACTIONAL CALCULUS
   Ozaktas H.M., 2001, FRACTIONAL FOURIER T
   Pei SC, 1998, SIGNAL PROCESS, V67, P99, DOI 10.1016/S0165-1684(98)00024-3
   Pei SC, 2000, IEEE T SIGNAL PROCES, V48, P1338, DOI 10.1109/78.839981
   Prabhakar CJ., 2012, INT J MACHINE INTELL, V4, P217
   Proakis J G., 2013, Digital Signal Processing (Pearson Custom Library)
   Pu T, 2018, IET COMPUT VIS, V12, P424, DOI 10.1049/iet-cvi.2017.0259
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Ramani M, 2013, CLIN PERINATOL, V40, P1, DOI 10.1016/j.clp.2012.12.001
   Saxena R., 2005, Journal of the Indian Institute of Science, V85, P11
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh G, 2018, MULTIMED TOOLS APPL, V77, P485, DOI 10.1007/s11042-016-4290-5
   Singh K, 2013, IEEE J EM SEL TOP C, V3, P330, DOI 10.1109/JETCAS.2013.2272837
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Suman S, 2017, MULTIDIM SYST SIGN P, V28, P709, DOI 10.1007/s11045-015-0369-9
   Tao L., 2017, 2017 IEEE VISUAL COM, P1
   Tao L, 2017, IEEE IMAGE PROC, P3215, DOI 10.1109/ICIP.2017.8296876
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Tseng C.- C., 2017, P IEEE 6 GLOBAL C CO, P1
   Vishwakarma A. K., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P171, DOI 10.1109/CSNT.2012.45
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Zhou SB, 2015, MULTIMED TOOLS APPL, V74, P6827, DOI 10.1007/s11042-014-1931-4
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 50
TC 8
Z9 10
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27891
EP 27914
DI 10.1007/s11042-019-7621-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000050
DA 2024-07-18
ER

PT J
AU Liu, H
   Chau, LP
AF Liu, Hui
   Chau, Lap-Pui
TI Deepsea video descattering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deepsea videos; Image enhancement; Robust principal component analysis;
   Descattering
AB This paper presents a new "marine snow" removal method for deepsea videos based on robust temporal-spatial decomposition. For deepsea videos, the contents of adjacent frames are almost identical or change very little except for the rapidly moving "marine snow" as well as noise, indicating that there exists high temporal-spatial correlation between the successive frames. Based on this observation, we first robustly approximate the deepsea video to recover its background using online robust principal component analysis in a sub-video-by-sub-video manner. Since the structure information of background cannot be well preserved during the background modeling, we further extract such information from the approximation error to compensate the obtained background, which is also formulated as a constrained convex optimization problem. The experimental results demonstrate that our proposed method can achieve comparable or even better results than the state of the art approach.
C1 [Liu, Hui] Nanyang Technol Univ, Maritime Inst, Singapore 639798, Singapore.
   [Chau, Lap-Pui] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Liu, H (corresponding author), Nanyang Technol Univ, Maritime Inst, Singapore 639798, Singapore.
EM liuhui.csu@gmail.com; elpchau@ntu.edu.sg
RI Chau, Lap-Pui/A-5149-2011
OI Chau, Lap-Pui/0000-0003-4932-0593
FU Singapore Maritime Institute (SMI)
FX The authors would like to thank the Singapore Maritime Institute (SMI)
   for kindly funding this research project and Fugro Subsea Technologies
   Pte Ltd providing technical platform for testing and evaluation under
   the SMI Deepwater Technology R&D Programme.
CR [Anonymous], IEEE T PATTERN ANAL
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Feng Jiashi, 2013, Advances in Neural Information Processing Systems, P404
   Kim JH, 2015, IEEE T IMAGE PROCESS, V24, P2658, DOI 10.1109/TIP.2015.2428933
   Tan RT, 2008, 2006 IEEE COMPUTER S, P1
   TREIBITZ T, 2006, P IEEE CVPR, V2, P1861
   Treibitz T, 2012, IEEE T IMAGE PROCESS, V21, P4662, DOI 10.1109/TIP.2012.2208978
   Treibitz T, 2009, IEEE T PATTERN ANAL, V31, P385, DOI 10.1109/TPAMI.2008.85
NR 10
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28919
EP 28929
DI 10.1007/s11042-017-5474-3
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700031
DA 2024-07-18
ER

PT J
AU Zhao, HM
   Ren, JC
   Zhan, J
   Xiao, YY
   Zhao, SY
   Lei, FY
   Assaad, M
   Li, CY
AF Zhao, Huimin
   Ren, J. -C.
   Zhan, Jin
   Xiao, Yinyin
   Zhao, Sophia Y.
   Lei, Fangyuan
   Assaad, Maher
   Li, Chunying
TI Compressive sensing based secret signals recovery for effective image
   Steganalysis in secure communications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing (CS); Image steganalysis; Secret signal recovery;
   Secure communication
ID SALIENCY DETECTION; RANDOM PROJECTIONS; CLASSIFICATION
AB Conventional image steganalysis mainly focus on presence detection rather than the recovery of the original secret messages that were embedded in the host image. To address this issue, we propose an image steganalysis method featured in the compressive sensing (CS) domain, where block CS measurement matrix senses the transform coefficients of stego-image to reflect the statistical differences between the cover and stego- images. With multi-hypothesis prediction in the CS domain, the reconstruction of hidden signals is achieved efficiently. Extensive experiments have been carried out on five diverse image databases and benchmarked with four typical stegographic algorithms. The comprehensive results have demonstrated the efficacy of the proposed approach as a universal scheme for effective detection of stegography in secure communications whilst it has greatly reduced the numbers of features requested for secret signal reconstruction.
C1 [Zhao, Huimin; Zhan, Jin; Xiao, Yinyin; Lei, Fangyuan; Li, Chunying] GPNU, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Zhao, Huimin; Ren, J. -C.; Zhao, Sophia Y.] Guangzhou Key Lab Digital Content Proc & Secur Te, Guangzhou, Guangdong, Peoples R China.
   [Ren, J. -C.; Lei, Fangyuan] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Lanark, Scotland.
   [Assaad, Maher] Ajman Univ, Coll Engn, Dubai, U Arab Emirates.
C3 University of Strathclyde; Ajman University
RP Zhao, HM (corresponding author), GPNU, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.; Zhao, HM (corresponding author), Guangzhou Key Lab Digital Content Proc & Secur Te, Guangzhou, Guangdong, Peoples R China.
EM Zhaohuimin66@yahoo.com
RI zhen, wang/KBA-3844-2024
OI Assaad, Maher/0000-0002-1584-8747; Ren, Jinchang/0000-0001-6116-3194
FU National Natural Science Foundation of China [61672008, 61772144];
   Guangdong Provincial Application-oriented Technical Research and
   Development Special fund project [2016B010127006, 2017A050501039];
   Natural Science Foundation of Guangdong Province [2016A030311013,
   2015A030313672]; International Scientific and Technological Cooperation
   Projects of Education Department of Guangdong Province [2015KGJHZ021];
   Scientific and Technological Projects of Guangdong Province
   [2017A050501039]
FX This work was partly supported by the National Natural Science
   Foundation of China (61672008, 61772144), Guangdong Provincial
   Application-oriented Technical Research and Development Special fund
   project (2016B010127006, 2017A050501039), the Natural Science Foundation
   of Guangdong Province (2016A030311013, 2015A030313672), International
   Scientific and Technological Cooperation Projects of Education
   Department of Guangdong Province (2015KGJHZ021), and the Scientific and
   Technological Projects of Guangdong Province (2017A050501039).
CR AlKhateeb J, 2008, 5 IEEE INT MULT SYST, P1, DOI 10.1109/SSD.2008.4632863
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2017, FINGERPRINT VERIFICA
   [Anonymous], 2012, LECT NOTES COMPUTER
   [Anonymous], 2017, STEGANOGRAPHY SOFTWA
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Davenport MA, 2010, IEEE J-STSP, V4, P445, DOI 10.1109/JSTSP.2009.2039178
   Dong J, 2008, LECT NOTES COMPUT SC, V5041, P87
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2011, IEEE T SIGNAL PROCES, V59, P4053, DOI 10.1109/TSP.2011.2161982
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao P., 2006, COMPUT APPL SOFTW, V23, P134
   Gill K, 2011, P IEEE INT C IM CRIM
   Holub V., 2013, P SOC PHOTO-OPT INS, V8665, P1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Kodovsky J, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P123, DOI 10.1145/1411328.1411352
   Li B, 2008, PROC SPIE, V6819, DOI 10.1117/12.765817
   Li YB, 2016, INT J SECUR APPL, V10, P119, DOI 10.14257/ijsia.2016.10.5.11
   Lu W, 2010, P IEEE 17 INT C IM P, P68
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Patsakis Constantinos., 2014, Journal of Information Hiding and Multimedia Signal Processing, V5, P20
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qiao T, 2017, IEEE T GEOSCI REMOTE, V55, P119, DOI 10.1109/TGRS.2016.2598065
   Ren JC, 2014, J VIS COMMUN IMAGE R, V25, P1558, DOI 10.1016/j.jvcir.2014.07.001
   Ren JC, 2007, SIGNAL PROCESS, V87, P541, DOI 10.1016/j.sigpro.2006.06.013
   Sullivan G., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P437, DOI 10.1109/ICASSP.1993.319841
   Wang Q, 2013, IEEE INT WORKS INFOR, P67, DOI 10.1109/WIFS.2013.6707796
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2018, NEUROCOMPUTING, V287, P68, DOI 10.1016/j.neucom.2018.01.076
   Yan YJ, 2018, PATTERN RECOGN, V79, P65, DOI 10.1016/j.patcog.2018.02.004
   Zabalza J, 2014, IEEE T AERO ELEC SYS, V50, P2304, DOI 10.1109/TAES.2014.130082
   Zhang AZ, 2018, IEEE T CYBERNETICS, V48, P436, DOI 10.1109/TCYB.2016.2641986
   Zhao H, 2017, MAG CONCRETE RES, V69, P649, DOI 10.1680/jmacr.16.00333
   Zhou Y, 2016, COGN COMPUT, V8, P877, DOI 10.1007/s12559-016-9424-6
NR 38
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29381
EP 29394
DI 10.1007/s11042-018-6065-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700053
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Bommisetty, RM
   Prakash, O
   Khare, A
AF Bommisetty, Reddy Mounika
   Prakash, Om
   Khare, Ashish
TI Video superpixels generation through integration of curvelet transform
   and simple linear iterative clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Superpixel; Simple linear iterative clustering;
   Curvelet transform; Structural content; Achievable segmentation accuracy
ID IMAGE SEGMENTATION; WAVELET TRANSFORM; MEAN SHIFT; COMBINATION
AB Superpixel generation finds wide variety of applications in the field of image processing, particularly brain tumour detection, human body pose estimation, person re-identification as a pre-processing step. In this paper, we present a novel superpixel segmentation approach through integration of curvelet transform and conventional Simple Linear Iterative Clustering (SLIC) for image and video. The proposed algorithm follows a two-step framework, clustering in curvelet and spatial domain separately. It performs conventional Simple Linear Iterative clustering on curvelet coefficients obtained at different decomposition levels of R, G, B components as well as directly on R, G, B components to get initial boundaries of superpixels. We obtain final boundaries of superpixels by taking the high probable boundaries from the initial formed boundaries. By incorporation of curvelets in five different scales the proposed method is capable of generating superpixels with high boundary adherence even in the presence of background change, object motion and noise. Superpixels generated by the proposed method are homogeneous in regions of complex texture and weak boundaries. The method has been tested on different images taken from Berkeley segmentation dataset and frames of several other videos. The algorithm under study is evaluated in terms of ten evaluation parameters: boundary recall, boundary precision, quality percentage, detection percentage, accuracy, Jaccard index, specificity, figure of merit, structural content, achievable segmentation accuracy. The results are tabulated, shown graphically and discussed in detail. The critical analysis of results show sound performance of the proposed method over other state-of- art methods.
C1 [Bommisetty, Reddy Mounika; Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
   [Prakash, Om] Nirma Univ, Inst Technol, Nirma, India.
C3 University of Allahabad; Nirma University
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
EM khare@allduniv.ac.in
RI Bommisetty, Reddy Mounika Mounika/AAX-2071-2021; Prakash,
   Om/AAL-4460-2021; Khare, Ashish/D-4566-2012
OI Bommisetty, Reddy Mounika Mounika/0000-0001-6215-0897; Prakash,
   Om/0000-0001-6395-9989; 
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Andrade F, 2015, 2015 20TH SYMPOSIUM ON SIGNAL PROCESSING, IMAGES AND COMPUTER VISION (STSIVA)
   [Anonymous], 2004, P 2004 IEEE COMPUTER
   [Anonymous], 2012, P FOR BILDV
   [Anonymous], 2015, ARXIV150904232
   Benesova W., 2014, C MACHINE VISION MAC, P1
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai Tang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P765, DOI 10.1109/ICME.2012.184
   Fu P, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121237
   Galasso F, 2013, IEEE I CONF COMP VIS, P3527, DOI 10.1109/ICCV.2013.438
   Giordano D, 2015, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2015.7299114
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Guo YH, 2018, MEASUREMENT, V119, P28, DOI 10.1016/j.measurement.2018.01.025
   Jampani V, 2018, LECT NOTES COMPUT SC, V11211, P363, DOI 10.1007/978-3-030-01234-2_22
   Khare M., 2014, J SCI TECHNOL, V52, P29
   Khare M, 2017, MULTIMED TOOLS APPL, V76, P1247, DOI 10.1007/s11042-015-3068-5
   Khare M, 2014, IET IMAGE PROCESS, V8, P334, DOI 10.1049/iet-ipr.2012.0428
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liu CJ, 2013, APPL MECH MATER, V311, P196, DOI 10.4028/www.scientific.net/AMM.311.196
   Liu DS, 2017, ADV SOC SCI EDUC HUM, V61, P21
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu JM, 2017, CEREB CORTEX, P1
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Machairas V, 2015, IEEE T IMAGE PROCESS, V24, P3707, DOI 10.1109/TIP.2015.2451011
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Neubert P, 2014, INT C PATT RECOG, P996, DOI 10.1109/ICPR.2014.181
   Nigam S, 2016, MULTIMED TOOLS APPL, V75, P17303, DOI 10.1007/s11042-015-3000-z
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   Poornima K., 2012, INT J SOFT COMPUT EN, V2, P294
   Prakash O, 2018, OPTIK, V157, P1267, DOI 10.1016/j.ijleo.2017.12.061
   Rao SR, 2010, LECT NOTES COMPUT SC, V5994, P135
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Welikala RA, 2016, COMPUT BIOL MED, V71, P67, DOI 10.1016/j.compbiomed.2016.01.027
   Yang DW, 2017, CHIN CONTR CONF, P5396, DOI 10.23919/ChiCC.2017.8028210
NR 42
TC 6
Z9 6
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25185
EP 25219
DI 10.1007/s11042-019-7554-z
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900069
DA 2024-07-18
ER

PT J
AU Li, F
   Wang, TY
   Cosman, PC
AF Li, Fan
   Wang, Taiyu
   Cosman, Pamela C.
TI Joint rate adaptation and resource allocation for real-time H.265/HEVC
   video transmission over uplink OFDMA systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video communication; Wireless resource allocation; Encoding rate
   adaptation; Video packet scheduling; OFDMA
ID CROSS-LAYER DESIGN; POWER ALLOCATION; WIRELESS VIDEO; SUBCARRIER
AB We consider multiuser video communication over uplink orthogonal frequency-division multiple access (OFDMA) systems. A cross-layer algorithm of joint bit allocation, packet scheduling and wireless resource assignment are proposed to minimize the end-to-end expected video distortion. Video rate adaptation is performed under the wireless resource constraints. The target number of encoding bits for each video packet is obtained to minimize the estimated distortion based on the online content-based rate-distortion function. Due to the inaccuracy of the rate control algorithm in H.265/HEVC encoding, the actual number of bits may differ from the target. Accordingly, the actual encoder distortion may deviate from the estimated distortion. Then, we propose an iterative algorithm to re-assign wireless resources based on the actual number of encoded bits to obtain the final resource allocation policy and packet scheduling decision. Numerical simulation results show that our proposed approach significantly outperforms the baseline algorithms in terms of received video quality.
C1 [Li, Fan; Wang, Taiyu] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
   [Cosman, Pamela C.] Univ Calif San Diego, Dept Elect & Comp Engn, San Diego, CA 92103 USA.
C3 Xi'an Jiaotong University; University of California System; University
   of California San Diego
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
EM lifan@mail.xjtu.edu.cn; wangtaiyu@stu.xjtu.edu.cn; pcosman@eng.ucsd.edu
RI Wang, Taiyu/KHD-6835-2024
FU National Science Foundation of China [61671365]; Joint Foundation of
   Ministry of Education of China [6141A02022344]
FX This research work was supported in part by the National Science
   Foundation of China Project No. 61671365, and Joint Foundation of
   Ministry of Education of China No. 6141A02022344.
CR [Anonymous], 2012, JCTVC K0103 RATE CON
   [Anonymous], 2014, HEVC TEST MODEL 15 0
   Awad MK, 2010, IEEE T VEH TECHNOL, V59, P2394, DOI 10.1109/TVT.2010.2044820
   Biagioni A, 2009, IEEE J SEL AREA COMM, V27, P217, DOI 10.1109/JSAC.2009.090212
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cicalò S, 2014, IEEE T MULTIMEDIA, V16, P848, DOI 10.1109/TMM.2014.2300442
   Dani M.N., 2017, 2017 IEEE Globecom Workshops (GC Wkshps), P1
   de la Fuente A, 2018, IEEE T BROADCAST, V64, P695, DOI 10.1109/TBC.2017.2781121
   Feng T, 2008, IEEE T COMMUN, V56, P2007, DOI 10.1109/TCOMM.2008.060596
   Gao L, 2008, IEEE T WIREL COMMUN, V7, P1507, DOI 10.1109/TWC.2008.061059
   He LJ, 2014, IEEE T WIREL COMMUN, V13, P6768, DOI 10.1109/TWC.2014.2364603
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Ji X, 2009, IEEE T CIRC SYST VID, V19, P1549, DOI 10.1109/TCSVT.2009.2026812
   Jung YH, 2018, IEEE T CIRC SYST VID, V28, P2024, DOI 10.1109/TCSVT.2017.2701503
   Kim K, 2005, IEEE COMMUN LETT, V9, P526, DOI [10.1109/LCOMM.2005.1437359, 10.1109/LCOMM.2005.06018]
   Le H, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1277, DOI 10.1109/PIMRC.2015.7343495
   Li F., 2009, POWERTECH 2009 IEEE, P1
   Li F, 2018, IEEE T MULTIMEDIA, V20, P1154, DOI 10.1109/TMM.2017.2764329
   Li F, 2012, IEEE T VEH TECHNOL, V61, P2753, DOI 10.1109/TVT.2012.2195511
   Ng CY, 2008, IEEE T WIREL COMMUN, V7, P1667, DOI 10.1109/TWC.2008.060723
   Qian L, 2017, IEEE T BROADCAST, V63, P20, DOI 10.1109/TBC.2016.2623240
   Rohling H, 1999, P IEEE, V87, P1778, DOI 10.1109/5.790637
   Sabir MF, 2009, IEEE T IMAGE PROCESS, V18, P90, DOI 10.1109/TIP.2008.2005819
   Tseng SM, 2018, IEEE ACCESS, V6, P50559, DOI 10.1109/ACCESS.2018.2869420
   Wang DW, 2013, IEEE T COMMUN, V61, P2060, DOI 10.1109/TCOMM.2013.032013.120053
   Wu DW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P522, DOI 10.1109/ICYCS.2008.120
   Wu PH, 2015, IEEE T VEH TECHNOL, V64, P3233, DOI 10.1109/TVT.2014.2350002
   Zhang HX, 2011, IEEE J SEL AREA COMM, V29, P197, DOI 10.1109/JSAC.2011.110119
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang ZL, 2018, IEEE T MOBILE COMPUT, V17, P577, DOI 10.1109/TMC.2016.2638844
   Zhou N, 2010, IEEE T WIREL COMMUN, V9, P1912, DOI 10.1109/TWC.2010.06.081595
NR 31
TC 8
Z9 9
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26807
EP 26831
DI 10.1007/s11042-019-07868-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700068
OA Green Published
DA 2024-07-18
ER

PT J
AU Sun, QM
   Yang, S
   Sun, CY
   Yang, WK
AF Sun, Qiming
   Yang, Sen
   Sun, Changyin
   Yang, Wankou
TI Exploiting aggregate channel features for urine sediment detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urine sediment detection; Aggregate channel features; Adaboost;
   Preprocessing; SVM
AB Urine sediment examination refers to the use of microscopes to examine various tangible components in urine sediment, e.g. red blood cells (RBCs), white blood cells (WBCs), tube, and crystal, etc., having a very important role in infectious diseases and circulatory diseases diagnosis. The traditional method about urine sediment analysis depends on the observation of medical staffs. So the workload is particularly large and inefficient, and relevant staff need to own some experience. Recently, the automation of urine sediment analysis can be realized. However, due to the complexity of the urine sediment microscopic image, the accuracy and efficiency of the automatic recognition for the tangible components are still very low. To solve this problem, we investigate channel features to urine sediment detection which include diverse feature types like color channel features and gradient magnitude, etc. We propose aggregate channel features plus (ACF+) detector which is based on aggregate channel features (ACF) for urine sediment detection. We adopt improved Adaboost classifier. The input image does not require any preprocessing and the specific ingredients such as RBCs can be detected directly with a high precision and efficiency. On the testing set, our proposed ACF+ detector suppresses several competitive baselines e.g. Support Vector Machine (SVM) combined with Histogram of Oriented Gradient (HOG), vanilla ACF, and ACDS. In terms of speed, it runs 3FPS on 2592 x 2048 images.
C1 [Sun, Qiming; Yang, Sen; Sun, Changyin; Yang, Wankou] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Sun, Qiming; Yang, Sen; Sun, Changyin; Yang, Wankou] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Yang, WK (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM wkyang@seu.edu.cn
RI SUN, CHANG/GXM-3680-2022; sun, chang/ITV-6759-2023
FU National Science Foundation of China [61473086, 61773117, 61603080]
FX This work was partly supported by National Science Foundation of China
   under no. 61473086, no. 61773117 and no. 61603080.
CR [Anonymous], BIOINF BIOM ENG 2009
   [Anonymous], BIOMEDICAL OPTICS BI
   [Anonymous], AS C REM SENS 9 BANG
   [Anonymous], COMPLEXITY
   [Anonymous], 2009, P BRIT MACH VIS C
   [Anonymous], SOFT COMPUTING IND A
   [Anonymous], SPIE MED IMAGING
   [Anonymous], MACH LEARN CYB P 200
   [Anonymous], 2013, BIOMED ENG INT CONF
   [Anonymous], T I ELECT COMMUN E D
   Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dong LY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P556, DOI 10.1109/ICMA.2007.4303603
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   GOLDBERG M, 1987, PHOTOGRAMMETRIA, V42, P87, DOI 10.1016/0031-8663(87)90044-5
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Ponce J, 2006, LECT NOTES COMPUT SC, V4170, P29
   Rajaguru H, 2014, INT J IMAG SYST TECH, V24, P16, DOI 10.1002/ima.22074
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Shenasa M., 2009, CARDIAC MAPPING, V3rd, P1
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Xian Jiang, 2007, 2007 1st International Conference on Bioinformatics and Biomedical Engineering, P1028
   Yang B., 2014, BIOMETRICS IJCB 2014, P1
NR 29
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23883
EP 23895
DI 10.1007/s11042-018-6241-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900006
DA 2024-07-18
ER

PT J
AU Tomás, D
   Gutiérrez, Y
   Badii, A
   Tiemann, M
   Aisopos, F
AF Tomas, David
   Gutierrez, Yoan
   Badii, Atta
   Tiemann, Marco
   Aisopos, Fotis
TI Socialising around media Improving the second screen experience through
   semantic analysis, context awareness and dynamic communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social TV; Second screen; Semantic analysis; Entity linking; Sentiment
   analysis; Context awareness; Community detection; Dynamic communities
ID MODEL; TV; TELEVISION; POWER
AB SAM is a social media platform that enhances the experience of watching video content in a conventional living room setting, with a service that lets the viewer use a second screen (such as a smart phone) to interact with content, context and communities related to the main video content. This article describes three key functionalities used in the SAM platform in order to create an advanced interactive and social second screen experience for users: semantic analysis, context awareness and dynamic communities. Both dataset-based and end user evaluations of system functionalities are reported in order to determine the effectiveness and efficiency of the components directly involved and the platform as a whole.
C1 [Tomas, David; Gutierrez, Yoan] Univ Alicante, Dept Software & Comp Syst, Carretera San Vicente del Raspeig S-N, Alicante 03690, Spain.
   [Badii, Atta; Tiemann, Marco] Univ Reading, Dept Comp Sci, Reading RG6 6AH, Berks, England.
   [Aisopos, Fotis] Natl Tech Univ Athens, Distributed Knowledge & Media Syst Grp, Zografou Campus, GR-15773 Athens, Greece.
C3 Universitat d'Alacant; University of Reading; National Technical
   University of Athens
RP Tiemann, M (corresponding author), Univ Reading, Dept Comp Sci, Reading RG6 6AH, Berks, England.
EM dtomas@dlsi.ua.es; ygutierrez@dlsi.ua.es; atta.badii@reading.ac.uk;
   marco.tiemann@gmail.com; fotais@mail.ntua.gr
RI Gutiérrez, Yoan/H-2888-2015
OI Gutiérrez, Yoan/0000-0002-4052-7427; Tiemann, Marco/0000-0003-0782-0274
FU European Commission [FP7-611312]; Spanish Government under project REDES
   [TIN2015-65136-C2-2-R]; Generalitat Valenciana [PROMETEU/2018/089]
FX This work has been partially funded by the European Commission under the
   Seventh (FP7 2007-2013) Framework Programme for Research and
   Technological Development through the SAM (FP7-611312) project, by the
   Spanish Government under project REDES (TIN2015-65136-C2-2-R) and by the
   Generalitat Valenciana under project (PROMETEU/2018/089).
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Aisopos F, 2016, GECON C EC GRIDS CLO
   AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], 2015, CEUR Workshop Proceedings
   [Anonymous], 2013, P 10 C OP RES AR INF
   [Anonymous], 2013, 2 JOINT C LEX COMP S
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI [10.1145/2433396.2433471, DOI 10.1145/2433396.2433471]
   [Anonymous], 2013, LIMOSINE PROJECT INT
   [Anonymous], 2010, Synthesis Lectures Data Mining Knowl. Discovery, DOI DOI 10.2200/S00298ED1V01Y201009DMK003
   [Anonymous], 2012, NOTUBE BRINGING WEB
   [Anonymous], 2005, THESIS
   Aroyo L., 2011, Proceedings of the 1st IEEE First International Conference on Consumer Electronics - Berlin (IEEE ICCE-Berlin 2011), P269, DOI 10.1109/ICCE-Berlin.2011.6031805
   Batra S., 2012, International Journal of Soft Computing and Engineering (IJSCE), V2, P509
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Cesar P, 2008, LECT NOTES COMPUT SC, V5066, P168, DOI 10.1007/978-3-540-69478-6_22
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chorianopoulos K, 2008, MULTIMED TOOLS APPL, V36, P1, DOI 10.1007/s11042-006-0081-8
   Courtois C., 2012, P 10 EUROPEAN C INTE, P153, DOI DOI 10.1145/2325616.2325646
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   Davis F. D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results, DOI DOI 10.1016/S0378-7206(01)00143-4
   Fernandez J., 2015, P TASS 2015 WORKSH S, P93
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   FORGY CL, 1982, ARTIF INTELL, V19, P17, DOI 10.1016/0004-3702(82)90020-0
   Geerts D., 2014, INT C INTERACTIVE EX, P95, DOI [10.1145/2602299.2602312, DOI 10.1145/2602299.2602312]
   Giglietto F, 2014, J COMMUN, V64, P260, DOI 10.1111/jcom.12085
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Greene D, 2010, 2010 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2010), P176, DOI 10.1109/ASONAM.2010.17
   Guthrie Guthrie David David, LREC, V6 6, P1222
   Haykin S., 1994, NEURAL NETWORKS COMP
   Holmes G, 1999, LECT NOTES ARTIF INT, V1747, P1
   Holmes M.E., 2012, S EYE TRACKING RES A, P397, DOI DOI 10.1145/2168556.2168646
   Hu H, 2015, IEEE NETWORK, V29, P43, DOI 10.1109/MNET.2015.7293304
   Hu H, 2014, IEEE MULTIMEDIA, V21, P10, DOI 10.1109/MMUL.2014.2
   Jaiswal G, 2013, IOSR J ENG IOSRJEN
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Karypis G, 1998, J PARALLEL DISTR COM, V48, P96, DOI 10.1006/jpdc.1997.1404
   Kohavi R, 1995, LECT NOTES ARTIF INT, V912, P174
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Martínez V, 2015, 2015 7TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT (IC3K), P316
   McAuley J, 2014, ACM T KNOWL DISCOV D, V8, P73, DOI 10.1145/2556612
   Mitchell Keith, 2010, P 8 EUR C INT TV VID, P283, DOI [10.1145/1809777.1809833, DOI 10.1145/1809777.1809833]
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Ng HT, 1997, AI MAG, V18, P45
   Paliouras G, 2015, USER COMMUNITY DISCO
   Pang B., 2007, INFORM RETRIEVAL, V2, P1, DOI DOI 10.1561/1500000011
   Papadopoulos S, 2012, DATA MIN KNOWL DISC, V24, P515, DOI 10.1007/s10618-011-0224-z
   Pynta P, 2014, J ADVERTISING RES, V54, P71, DOI 10.2501/JAR-54-1-071-080
   Rao DSP, 2013, MEASURING THE REAL SIZE OF THE WORLD ECONOMY: THE FRAMEWORK, METHODOLOGY, AND RESULTS OF THE INTERNATIONAL COMPARISON PROGRAM-ICP, P93
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Satuluri V, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P737
   Snousy M B. A., 2011, Egyptian Informatics Journal, V12, P73, DOI [DOI 10.1016/J.EIJ.2011.04.003, DOI 10.1016/j.eij.2011.04.003]
   Tantipathananandh C., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1236, DOI 10.1109/ICDM.2011.67
   Tomás D, 2015, ECHALLENGES E-2015 CONFERENCE PROCEEDINGS
   Vanattenhoven J, 2017, MULTIMED TOOLS APPL, V76, P5661, DOI 10.1007/s11042-016-3646-1
   ZHAO S, 2011, INT WORKSHOP FUTURE, V2, P11
NR 59
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25539
EP 25568
DI 10.1007/s11042-019-7706-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700014
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Wu, HB
   Li, FY
   Qin, C
   Wei, WM
AF Wu, Haibin
   Li, Fengyong
   Qin, Chuan
   Wei, Weimin
TI Separable reversible data hiding in encrypted images based on scalable
   blocks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Image recovery; Scalable
   blocks
ID SECURITY
AB This paper proposes a new separable reversible data hiding method for encrypted images. Proposed scheme employs the pixel redundancy of natural images to construct embedding space. First, cover image is divided into multiple blocks with different scales. According to the pixel average value of each block, the lowest two bits of every pixel are vacated as reserved rooms. Subsequently, the whole image is encrypted by using stream cipher and the secret messages are finally embedded into the reserved rooms by the embedding key. Proposed scheme is separable in the sense that the recipient can achieve different function by the following ways: (a) If the recipient has only decryption key, an approximation plaintext image containing the embedded information can be obtained. (b) If the recipient has only embedded key, secret messages can be extracted correctly. (c) If the recipient has both decryption key and embedded key, he can not only extract the secret messages, but recover the original cover image perfectly. Extensive experiments are performed to show that our proposed schemes outperform existing reversible data hiding schemes in terms of visual quality, embedding capacity and security performance, even if a large-scale image database is used.
C1 [Wu, Haibin; Li, Fengyong; Wei, Weimin] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
C3 Shanghai University of Electric Power; University of Shanghai for
   Science & Technology
RP Li, FY (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
EM whb2333@foxmail.com; fyli@shiep.edu.cn; qin@usst.edu.cn; afoe@163.com
RI Qin, Chuan/C-1106-2017; Wu, Haibin/KPY-5216-2024
OI Qin, Chuan/0000-0002-0370-4623; Wu, Haibin/0000-0001-8473-9854
FU Natural Science Foundation of China [61602295]; Natural Science
   Foundation of Shanghai [16ZR1413100]; Foreign Visiting Scholar Program
   of Shanghai Municipal Education Commission
FX This work was supported by Natural Science Foundation of China under
   Grants (61602295), Natural Science Foundation of Shanghai (16ZR1413100)
   and the Foreign Visiting Scholar Program of Shanghai Municipal Education
   Commission.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huh JH, 2019, J SUPERCOMPUT, V75, P3123, DOI 10.1007/s11227-018-2496-1
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni Z, 2003, P 2003 INT S CIRC SY, pII912
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 32
TC 21
Z9 21
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25349
EP 25372
DI 10.1007/s11042-019-07769-w
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700007
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
AF Al-Otum, Hazem Munawer
TI Image watermarking based on inter-tree coefficients differencing in
   paired wavelet-packets tree constructions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Wavelets; Wavelet packets and copyright protection
ID DOMAIN
AB Recently, image watermarking has been used as a tremendous mean for copyright protection of images and multimedia as well. This work presents an image watermarking technique for copyright protection of grayscale images, and is based on the exploitation of the properties of the wavelet packet decomposition (WPD). Here, the input image is applied to WPD, then, modified trees are constructed in such a manner to gather WPD coefficients sharing the same spatial locations at different frequency subbands. The obtained new trees are reorganized in pairs and a differencing step, between the inter-tree coefficients, is performed. The result is compared to a bi-level threshold. At the embedding stage, few locations are modified while most of the locations are left unchanged. To improve the technique security, a content-dependent watermark is implemented and the threshold is made adaptive to the host under consideration. Simulation results have shown superior output watermarking quality with a PSNR > 48 dB as well as high robustness against a wide variety of attacks including moderate-to-severe image compression, filtering, noise addition and enhancement manipulations. Moreover, the technique has demonstrated a low computational cost due to the used approach in selecting the reorganized WPD coefficients.
C1 [Al-Otum, Hazem Munawer] Jordan Univ Sci & Technol, EE Dept, Fac Engn, Ramtha, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, EE Dept, Fac Engn, Ramtha, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Al-Otum H, 2018, MULTIMED TOOLS APPL, P1
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Barve A., 2014, INT J ADV RES COMPUT, V4, P92
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coifman R.R., 1992, Wavelet analysis and signal processing
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Dabas P, 2013, INT J COMPUT APPL, V71
   Dietl WM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2043, DOI 10.1109/ICME.2004.1394666
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Hadizadeh H, 2016, PATTERN RECOGN LETT, V80, P144, DOI 10.1016/j.patrec.2016.06.010
   Hämmerle-Uhl J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P213, DOI 10.1109/ICME.2008.4607409
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Maatouk MN, 2014, IET IMAGE PROCESS, V8, P708, DOI 10.1049/iet-ipr.2013.0546
   ORuanaidh JJK, 1996, IEE P-VIS IMAGE SIGN, V143, P250, DOI 10.1049/ip-vis:19960711
   Rawat S, 2012, OPT COMMUN, V285, P2563, DOI 10.1016/j.optcom.2012.01.067
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sangeetha N, 2018, OPTIK, V160, P380, DOI 10.1016/j.ijleo.2018.01.136
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh RK, 2015, PROCEDIA COMPUT SCI, V54, P612, DOI 10.1016/j.procs.2015.06.071
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Song W, 2015, UBIQUITOUS INT J INF, V6, P613
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C., 2016, FUTUR GENER COMPUT S
   Thirugnanam G., 2010, INT J SIGNAL IMAGE P, V1, p80 
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
NR 31
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22909
EP 22937
DI 10.1007/s11042-019-7542-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400033
DA 2024-07-18
ER

PT J
AU Cai, HL
   Yan, B
   Chen, N
   Pan, JS
   Yang, HM
AF Cai, Hui-Li
   Yan, Bin
   Chen, Na
   Pan, Jeng-Shyang
   Yang, Hong-Mei
TI Beautified QR code with high storage capacity using sequential module
   modulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Visual quality; Storage capacity; Parameter optimization;
   Module replacement
AB For the issue of beautification and capacity expansion of the Quick Response(QR) code, we proposed an algorithm based on sequential module modulation. First, the modules for the padding codewords are modulated by the module-based binarized background image. Then, to increase the storage capacity, low-pass textured patterns are designed for both the black modules and the white modules. The modules of the plain QR code are modulated by the second-level message. Finally, these modulated modules are further modulated by the L-channel of the background image in Lab color space. The module elimination parameter in the second modulation is optimized to maximize an objective function that accounts for both the visual quality and the decoding error. Experimental results demonstrate that, the proposed algorithm is superior to the reference method in terms of visual quality and capacity.
C1 [Cai, Hui-Li; Yan, Bin; Chen, Na] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Shandong, Peoples R China.
   [Pan, Jeng-Shyang; Yang, Hong-Mei] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Shandong, Peoples R China.
EM yanbinhit@hotmail.com
RI Yan, Bin/Y-7642-2019; Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025; Yan, Bin/0000-0003-2929-464X;
   Chen, Na/0000-0002-5541-8442
FU Shandong Provincial Natural Science Foundation [ZR2014JL044]; National
   Natural Science Foundation of China (NSFC) [61272432]; Qingdao
   Scientific Development Plan [KJZD-13-28-JCH]
FX This work is supported by Shandong Provincial Natural Science Foundation
   (No. ZR2014JL044), the National Natural Science Foundation of China
   (NSFC)(No. 61272432). The work of Hong-Mei Yang is also supported by
   Qingdao Scientific Development Plan (No. KJZD-13-28-JCH).
CR [Anonymous], 2000, 180042000 ISOIEC
   Bhardwaj S, 2016, 2016 INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL POWER AND INSTRUMENTATION (ICICPI), P47, DOI 10.1109/ICICPI.2016.7859671
   CHEN SK, 2017, 13TH INTERNATIONAL C, P290
   Chu HK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508408
   Garateguy GJ, 2014, IEEE T IMAGE PROCESS, V23, P2842, DOI 10.1109/TIP.2014.2321501
   Hou CT, 2013, BIOCATAL AGR BIOTECH, V2, P1, DOI 10.1016/j.bcab.2012.09.002
   Kan Tai-Wei, 2009, Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry, P253, DOI [10.1145/1670252.1670305, DOI 10.1145/1670252.1670305]
   Koschan A., 2008, DIGITAL COLOR IMAGE
   LAN X, 2018, P NIPS, P1
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lin SS, 2015, IEEE T MULTIMEDIA, V17, P1515, DOI 10.1109/TMM.2015.2437711
   Lin YS, 2013, COMPUT GRAPH FORUM, V32, P137, DOI 10.1111/cgf.12221
   Lin YH, 2013, IEEE T MULTIMEDIA, V15, P2198, DOI 10.1109/TMM.2013.2271745
   Liu S.-J., 2018, J INFORM HIDING MULT, V9, P515
   Liu S.-J., 2017, J INFORM HIDING MULT, V8, P1132
   Ono S, 2008, IEEE C EVOL COMPUTAT, P1068, DOI 10.1109/CEC.2008.4630929
   Querini M., 2011, Int. J. Comput. Sci. Appl., V8, P136
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 21
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22575
EP 22599
DI 10.1007/s11042-019-7504-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400018
DA 2024-07-18
ER

PT J
AU Lafkih, S
   Zaz, Y
AF Lafkih, Sara
   Zaz, Youssef
TI Solar panel monitoring: real-time system using video watermarking and
   Mosaicing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Solar plant; Solar panel; Video watermarking; Video indexing; Video
   mosaicing; Scale invariant features transform; Discrete cosine transform
AB In this paper, we propose a new approach to monitor a solar plant in real-time using an embedded vision system, comprised mainly of raspberry Pi3 card, GPS and thermometer sensors, and an HD camera module. This approach consists on using image processing techniques on solar energy fields. It is implemented on two steps, the first apply the digital watermarking technique based on discrete cosine transform (DCT) to indexing a captured video. We start by capturing all information from the solar plant (GPS coordinates, temperature, date, and time), then we embed on each video frame their related data. This method depends on transforming the video frames from the spatial to the frequency domain using DCT and embedding data in 8 x 8 block coefficients. The second step consists on applying a mosaicing techniques based on the scale invariant features transform (SIFT), in order to generate a panoramic image of the solar plant from video frames. Remotely, the supervisor can visualize the image of the whole, part, or panel of the solar plant, and exploits the embedded data to ensure an efficient real-time monitoring. The proposed method allows a high efficiency in terms of accuracy, data security, and retrieving data quickly, also it offers a high capacity, less imperceptibility and good robustness.
C1 [Lafkih, Sara; Zaz, Youssef] Abdelmalek Essaadi Univ, Fac Sci, BP 2121,MHannech 2, Tetouan 93030, Morocco.
C3 Abdelmalek Essaadi University of Tetouan
RP Lafkih, S (corresponding author), Abdelmalek Essaadi Univ, Fac Sci, BP 2121,MHannech 2, Tetouan 93030, Morocco.
EM lafkihsara@gmail.com; Youssef.zaz@gmail.com
RI Zaz, Youssef/ABB-8418-2020
OI ZAZ, Youssef/0009-0000-2172-2027
FU Mediterranean Space of Technology and Innovation (MSTI)
FX This research has been conducted with the support of the Mediterranean
   Space of Technology and Innovation (MSTI).
CR Al-Momen Saad M. A., 2010, J APPL COMPUTER SCI, P9
   [Anonymous], IJSAJ
   [Anonymous], 2014, SIPIJ, DOI [10.5121/sipij.2014.5502, DOI 10.5121/SIPIJ.2014.5502]
   Archana S, 2013, INT J SCI RES DEV, V1
   Devi R, 2016, INT J ENG RES, V4
   Forero N, 2006, ENERG CONVERS MANAGE, V47, P2329, DOI 10.1016/j.enconman.2005.11.012
   Ghannam S, 2013, INT J ADV COMPUT SC, V4, P94
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Gokay B, 2013, INT C REN EN RES APP
   Jyoti P, 2017, INT J ELECT ELECT EN, V9, P778
   Lafkih S., 2016, International Journal of Imaging and Robotics, V16, P137
   Lafkih S, 2018, 6 INT C MULT COMP SY
   Lafkih S, 2017, INT C INF COMP
   Lafkih S, 2016, 2016 INT REN SUST EN
   Lundqvist M, 1997, SOL ENERG MAT SOL C, V47, P289, DOI 10.1016/S0927-0248(97)00051-2
   Madeti SR, 2017, RENEW SUST ENERG REV, V67, P1180, DOI 10.1016/j.rser.2016.09.088
   Manoj K, 2015, INT J INNOV RES SCI, V1, P64
   Masukatsu K, 1999, P 1999 INT C IM PROC
   Mayamiko N, 2011, P ITU KAL 2011 FULL
   Mayuri E, 2017, P IEEE 2017 INT C CO
   Parikh P, 2006, IET INT C VIS INF EN
   Prabhishek S, 2013, INT J ENG INNOV TECH, V2
   Prachi VP, 2013, INT J RES ENG TECHNO, V2, P826, DOI [10.15623/ijret.2013.0205016, DOI 10.15623/IJRET.2013.0205016]
   Ranhotigamage C, 2011, IEEE SENS J, V11, P2583, DOI 10.1109/JSEN.2011.2150214
   Rashid A., 2016, INT J COMPUTER APPL, V5, P147, DOI DOI 10.7753/IJCATR0503.1006
   Reatti A, 2017, MEASUREMENT, V98, P384, DOI 10.1016/j.measurement.2015.06.022
   Rintu A, 2013, 3 INT C ADV COMP COM
   Sangeeta Y, 2015, INT J ADV RES COMPUT, V4, P429
   Shaohui L., 2015, INT J DISTRIB SENSOR, V11
   Shariff F, 2015, EXPERT SYST APPL, V42, P1730, DOI 10.1016/j.eswa.2014.10.007
   Shrihariprasath B, 2016, 2016 WORLD CONFERENCE ON FUTURISTIC TRENDS IN RESEARCH AND INNOVATION FOR SOCIAL WELFARE (STARTUP CONCLAVE)
   Shruti T, 2015, 2015 IEEE STUD C ENG
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Vatsa M, 2006, IEICE ELECTRON EXPR, V3, P23, DOI 10.1587/elex.3.23
NR 34
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22797
EP 22811
DI 10.1007/s11042-019-7497-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400028
DA 2024-07-18
ER

PT J
AU Lv, LT
   Yuan, QQ
   Li, ZX
AF Lv, LinTao
   Yuan, QinQin
   Li, ZhiXun
TI An algorithm of Iris feature-extracting based on 2D Log-Gabor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Feature extraction; 2D Log-Gabor filter; Odd symmetric
ID RECOGNITION
AB This paper proposes a new algorithm for iris feature extraction. The algorithm uses the odd symmetric 2D Log-Gabor filter to analyze the phase and amplitude of iris texture with respect to different frequencies and orientations, and uses feature fusion to eliminate redundant feature. It successfully solves such problems as the crescent-shaped spectrum and grid-like patterns which will appear when 2D Log-Gabor wavelet is used to extract iris features. The experimental results also show that the algorithm proposed has strong robustness against noise and interference, and has important theoretical value and practical significance.
C1 [Lv, LinTao; Yuan, QinQin] XiJing Univ, Dept Elect & Informat Engn, Xian 710123, Shaanxi, Peoples R China.
   [Li, ZhiXun] Xian Aerosp Prop Test Tech Inst, Xian, Shaanxi, Peoples R China.
C3 Xijing University
RP Lv, LT (corresponding author), XiJing Univ, Dept Elect & Informat Engn, Xian 710123, Shaanxi, Peoples R China.
EM lvlintao@xaut.edu.cn; 3165786088@qq.com; Zhixun15915@sohu.com
FU National Natural Science Foundations of China [61309008, 61309022,
   61273271]; industrial science and technology project of Shaanxi province
   of China [2016GY-141]; Foundation of Science and Technology on
   Information Assurance Laboratory [KJ-17-105]; science plan program of
   Xi'an City [201787CG/RC050 (XJCY001)]; Teaching Reform Project of
   Shaanxi of China [17BY118]; Teaching Reform Project of Xijing University
   of China [XJXGK201702]; Ministry of Education of China [201702109003,
   201702106003]
FX The authors would like to thank the anonymous reviewers and editors for
   their invaluable suggestions. Lecturer Wang Sheng and Professor Kong
   Weiwei have provided hard work for this paper. The work was supported in
   part by the National Natural Science Foundations of China under Grant
   61309008, 61309022 and 61273271, in part by the industrial science and
   technology project of Shaanxi province of China under Grant 2016GY-141,
   in part by the Foundation of Science and Technology on Information
   Assurance Laboratory under Grant KJ-17-105, in part by the science plan
   program of Xi'an City under Grant 201787CG/RC050 (XJCY001), in part by
   the Teaching Reform Project of Shaanxi of China under Grant 17BY118, in
   part by the Teaching Reform Project of Xijing University of China under
   Grant XJXGK201702, and the Ministry of Education of China cooperation in
   production and education under Grant 201702109003, 201702106003.
CR Alvarez-Betancourt Y, 2016, KNOWL-BASED SYST, V92, P169, DOI 10.1016/j.knosys.2015.10.024
   Bastos Carlos A. C. M., 2012, Intelligent Data Engineering and Automated Learning - IDEAL 2012. Proceedings 13th International Conference, P443, DOI 10.1007/978-3-642-32639-4_54
   Bastos CACM, 2010, PROC INT C TOOLS ART, P377, DOI 10.1109/ICTAI.2010.134
   Bhateja AK, 2016, PATTERN RECOGN LETT, V73, P13, DOI 10.1016/j.patrec.2015.12.009
   Boles W. W., 2012, 13th ASCE Aerospace Division Conference on Engineering, Science, Construction, and Operations in Challenging Environments. 5th NASA/ASCE Workshop on Granular Materials in Space Exploration. Earth and Space 2012. Proceedings., P111, DOI 10.1061/9780784412190.013
   Canguçú-Campinho AK, 2012, ADV CULT PSYCHOL CON, P443
   Daugman J, 2010, P SOC PHOTO-OPT INS, V7703, DOI 10.1117/12.855479
   Fancourt C, 2005, LECT NOTES COMPUT SC, V3546, P1
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Flom L, 1987, U S. Patent, P30, Patent No. 46413491
   Gao G, 2005, RES IRIS RECOGNITION
   [何家峰 He Jiafeng], 2003, [中国图象图形学报. A, Journal of image and graphics], V8, P387
   Kong AWK, 2004, LECT NOTES COMPUT SC, V3072, P761
   Leng L, 2014, INT C IM SIGN PROC
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Li N, 2009, IEICE T INF SYST, VE92D, P2275, DOI 10.1587/transinf.E92.D.2275
   Ling H, 2004, AIDS RES HUM RETROV, V20, P213, DOI 10.1089/088922204773004932
   Prasad MV, 2014, REC TRENDS COMP NETW, P202
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Yao P, 2017, J COMPUTER AIDED DES, V19, P574
   Yao P, 2017, J COMPUTER AIDED DES, V19, P563
   Zhao WJ, 2014, PROC SPIE, V9301, DOI 10.1117/12.2072856
NR 25
TC 4
Z9 5
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22643
EP 22666
DI 10.1007/s11042-019-7551-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400021
DA 2024-07-18
ER

PT J
AU Martin, M
   Nguyen, T
   Yousefi, S
   Li, B
AF Martin, Manu
   Thang Nguyen
   Yousefi, Shahrouz
   Li, Bo
TI Comprehensive features with randomized decision forests for hand
   segmentation from color images in uncontrolled indoor scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand segmentation; Randomized decision forests; Gesture recognition;
   Pixel classification
AB Hand segmentation is an integral part of many computer vision applications, especially gesture recognition. Training a classifier to classify pixels into hand or background using skin color as a feature is one of the most popular methods for this purpose. This approach has been highly restricted to simple hand segmentation scenarios since color feature alone provides very limited information for classification. Meanwhile there have been a rise of segmentation methods utilizing deep learning networks to exploit multi-layers of complex features learned from image data. Yet a deep neural network requires a large database for training and a powerful computational machine for operations due to its complexity in computations. In this work, the development of comprehensive features and optimized uses of these features with a randomized decision forest (RDF) classifier for the task of hand segmentation in uncontrolled indoor environments is investigated. Newly designed image features and new implementations are provided with evaluations of their hand segmentation performances. In total, seven image features which extract pixel or neighborhood related properties from color images are proposed and evaluated individually as well as in combination. The behaviours of feature and RDF parameters are also evaluated and optimum parameters for the scenario under consideration are identified. Additionally, a new dataset containing hand images in uncontrolled indoor scenarios was created during this work. It was observed from the research that a combination of features extracting color, texture, neighborhood histogram and neighborhood probability information outperforms existing methods for hand segmentation in restricted as well as unrestricted indoor environments using just a small training dataset. Computations required for the proposed features and the RDF classifier are light, hence the segmentation algorithm is suited for embedded devices equipped with limited power, memory, and computational capacities.
C1 [Martin, Manu; Thang Nguyen; Li, Bo] ManoMotion AB, Stockholm, Sweden.
   [Yousefi, Shahrouz] Linnaeus Univ, Dept Media Technol, Vaxjo, Sweden.
C3 Linnaeus University
RP Martin, M (corresponding author), ManoMotion AB, Stockholm, Sweden.
EM manu@manomotion.com
OI Martin, Manu/0000-0002-1056-0912
CR Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   [Anonymous], 3088 LEA
   [Anonymous], 2009, FRAMEWORK GESTURE BA
   [Anonymous], FINE HAND SEGMENTATI
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2008, PROCEDINGS BRIT MACH
   [Anonymous], P IEEE C CONS EL IEE
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615
   [Anonymous], 2003, PROC GRAPHICON
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2006, COMPUTER VISION PATT
   Breiman L., 2001, Mach. Learn., V45, P5
   Criminisi A., 2013, DECISION FORESTCOM, DOI DOI 10.1007/978-1-4471-4929-3
   Davies E. R., 2004, Machine vision: theory, algorithms, practicalities
   Garg P., 2009, P WORLD ACAD SCI ENG, V49, P972
   Goldin-Meadow S, 1999, TRENDS COGN SCI, V3, P419, DOI 10.1016/S1364-6613(99)01397-2
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Khan R, 2010, IEEE IMAGE PROC, P4613, DOI 10.1109/ICIP.2010.5651638
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Li C, 2013, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2013.458
   Nalepa J, 2014, COMM COM INF SC, V424, P364
   Oghaz MM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134828
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   RaySarkar A., 2013, INT J COMPUT APPL, V71, P25
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Serra G., 2013, Proceedings of the 3rd ACM international workshop on Interactive multimedia on mobile portable devices, P31, DOI DOI 10.1145/2505483.2505490
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang C, 2016, IEEE IJCNN, P1924, DOI 10.1109/IJCNN.2016.7727435
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Winn J., 2006, CVPR
   Zhu X., 2014, Asian Conference on Computer Vision, P64
   Zhu XL, 2015, COMPUT VIS IMAGE UND, V141, P95, DOI 10.1016/j.cviu.2015.07.008
NR 46
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20987
EP 21020
DI 10.1007/s11042-019-7445-3
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400020
DA 2024-07-18
ER

PT J
AU Moudgollya, R
   Midya, A
   Sunaniya, AK
   Chakraborty, J
AF Moudgollya, Rhittwikraj
   Midya, Abhishek
   Sunaniya, Arun Kumar
   Chakraborty, Jayasree
TI Dynamic background modeling using intensity and orientation distribution
   of video sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture feature; Dynamic background; Gray level co-occurrence matrix;
   Angle co-occurrence matrix; Background modeling
ID ROBUST; SUBTRACTION; IMAGE; TRANSFORM; TRACKING; FEATURES
AB Moving object detection in a video sequence is a challenging task in presence of dynamic background. In this paper, we propose a novel approach for background modeling by exploiting orientated patterns present in a video scene. Based on the observation that there exists a difference in directional edge patterns between foreground and background, we use the statistical measures of the orientation of texture via two angle co-occurrence matrices (ACMs). Orientation based features extracted from ACMs are then clubbed with intensity distribution-based features extracted from well-known gray level co-occurrence matrix (GLCM) to model the dynamic background. The model is then used to classify pixels within a video frame into background and foreground. Experimental results on a diverse set of video sequences have shown the effectiveness of the proposed method over competing schemes.
C1 [Moudgollya, Rhittwikraj; Sunaniya, Arun Kumar] Natl Inst Technol Silchar, Dept Elect & Instrumentat Engn, Silchar 788010, Assam, India.
   [Midya, Abhishek; Chakraborty, Jayasree] Mem Sloan Kettering Canc Ctr, Dept Surg, New York, NY 10022 USA.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; Memorial Sloan Kettering Cancer Center
RP Moudgollya, R (corresponding author), Natl Inst Technol Silchar, Dept Elect & Instrumentat Engn, Silchar 788010, Assam, India.
EM wrhittwik@gmail.com; midyaa@mskcc.org; arun.sunaniya@gmail.com;
   chakrabj@mskcc.org
RI Sunaniya, Arun/IQS-1884-2023; Chakraborty, Jayasree/Q-2424-2019; Midya,
   Abhishek/K-7603-2015
OI Chakraborty, Jayasree/0000-0003-4434-8861; Moudgollya,
   Rhittwikraj/0000-0003-3902-5451
CR [Anonymous], P INT C IM PROC COMP
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2000, Proc. of Image and Vision Computing
   Berjón D, 2013, IEEE T CONSUM ELECTR, V59, P361, DOI 10.1109/TCE.2013.6531118
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Butler D.E., 2005, EURASIP Journal on Advances in Signal Processing, V2005, P841
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chakraborty J, 2012, DETECTION ARCHITECTU
   Chakraborty J, 2018, EXPERT SYST APPL, V99, P168, DOI 10.1016/j.eswa.2018.01.010
   Chakraborty J, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033010
   Cheung SCS, 2005, EURASIP J ADV SIG PR, V2005, P261, DOI [10.1155/ASP.2005.23301097.68658, DOI 10.1155/ASP.2005.23301097.68658]
   Chiranjeevi P, 2012, IEEE SIGNAL PROC LET, V19, P603, DOI 10.1109/LSP.2012.2205380
   Chiranjeevi P, 2014, IEEE T CYBERNETICS, V44, P870, DOI 10.1109/TCYB.2013.2274330
   Chiranjeevi P, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3662910
   Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Farcas D, 2012, MACH VISION APPL, V23, P1083, DOI 10.1007/s00138-012-0421-9
   FEI MG, 2016, CAAI T INTELLIGENCE, V14
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hsia CH, 2014, SIGNAL PROCESS, V96, P138, DOI 10.1016/j.sigpro.2013.09.007
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Jalal AS, 2014, MULTIMED TOOLS APPL, V73, P779, DOI 10.1007/s11042-012-1326-3
   Jodoin PM, 2007, IEEE T CIRC SYST VID, V17, P1758, DOI 10.1109/TCSVT.2007.906935
   Jodoin PM, 2017, IEEE T IMAGE PROCESS, V26, P5244, DOI 10.1109/TIP.2017.2728181
   Karasulu B, 2013, PERFORMANCE EVALUATI, P7
   Karpagavalli P, 2017, MULTIMED TOOLS APPL, V76, P14129, DOI 10.1007/s11042-016-3777-4
   Kim H, 2007, LECT NOTES COMPUT SC, V4843, P758
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   Lee B., 2002, IMAGE VISION COMPUT, P315
   Lin HH, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P893, DOI 10.1109/ICIP.2002.1039116
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Luque R. M., 2008, 2008 8th International Conference on Hybrid Intelligent Systems (HIS), P613, DOI 10.1109/HIS.2008.130
   Midya A, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.1.011020
   Pak LM, 2018, J AM COLL SURG
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Seki M., 2003, P 2003 IEEE COMP SOC, VVolume 2, pII
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tavakkoli A, 2007, LECT NOTES COMPUT SC, V4842, P318
   Tezuka H, 2008, IEEE IMAGE PROC, P2732, DOI 10.1109/ICIP.2008.4712359
   Tian YL, 2012, MACH VISION APPL, V23, P967, DOI 10.1007/s00138-011-0377-1
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wren C.R., 2005, PERFORMANCE EVALUATI, P55
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xiao M., 2006, INFORM FUSION 9 INT, P1, DOI 10.1109/icif.2006.301727
   Yang L, 2018, IEEE T INTELL TRANSP, V19, P254, DOI 10.1109/TITS.2017.2754099
   Zhang R, 2007, IEEE T CONSUMER ELEC, V53
   Zhang SH, 2008, DNA SEQUENCE, V19, P1, DOI 10.1080/10425170500332314
   Zheng J, 2017, J AM COLL SURGEONS, V225, P778, DOI 10.1016/j.jamcollsurg.2017.09.003
   Zheng JY, 2006, TRANSPORT RES REC, P82
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 59
TC 6
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22537
EP 22554
DI 10.1007/s11042-019-7575-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400016
DA 2024-07-18
ER

PT J
AU Wu, TZ
   Hu, RM
   Wang, XC
   Ke, SF
AF Wu, Tingzhao
   Hu, Ruimin
   Wang, Xiaochen
   Ke, Shanfa
TI Audio object coding based on optimal parameter frequency resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object-based audio; SAOC; Aliasing distortion; Frequency resolution; SVD
ID INFORMED SOURCE SEPARATION; STANDARD; BLIND
AB Object-based audio content is becoming the main form of audio content, because it is more interactive and flexible than traditional channel-based audio content. The Spatial Audio Object Coding (SAOC) method is proposed to encode multiple audio objects at low bitrate. However, SAOC extracts only a few parameters for each frame signal, which leads to low parameter frequency resolution. So the decoded signals have serious aliasing distortion which will destroy the sound quality. In this paper, we present a novel audio object coding method. We are the first to analyze how the signal distortion varies with parameter frequency resolution, and determine the optimal resolution to reduce aliasing distortion. In addition, we also achieve low coding bitrate by the dimensional reduction algorithm. Both the objective and subjective experiments confirm that the proposed method can provide higher sound quality of output signals than the state-of-the-art methods at equivalent bitrate.
C1 [Wu, Tingzhao; Hu, Ruimin; Wang, Xiaochen; Ke, Shanfa] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Wu, Tingzhao; Wang, Xiaochen] Wuhan Univ Shenzhen, Res Inst, Shenzhen 518057, Peoples R China.
   [Wu, Tingzhao; Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan, Hubei, Peoples R China.
   [Ke, Shanfa] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.; Hu, RM (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan, Hubei, Peoples R China.
EM hrm@whu.edu.cn
FU National Key R&D Program of China [2017YFB1002803]; National Nature
   Science Foundation of China [U1736206]; Hubei Province Technological
   Innovation Major Project [2016AAA015]
FX This research is partially supported by the National Key R&D Program of
   China (No. 2017YFB1002803), National Nature Science Foundation of China
   (No. U1736206), Hubei Province Technological Innovation Major Project
   (No. 2016AAA015).
CR Ando A, 2011, IEEE T AUDIO SPEECH, V19, P1467, DOI 10.1109/TASL.2010.2092429
   [Anonymous], 2015, P INT TEL UN SWITZ
   [Anonymous], PRACTICAL APPROACH M
   Blauert Jens., 1974, Spatial Hearing
   Canadas-Quesada FJ, 2016, DIGIT SIGNAL PROCESS, V50, P240, DOI 10.1016/j.dsp.2016.01.004
   Elfitri I, 2014, INT C ADV COMP SCI I, P396, DOI 10.1109/ICACSIS.2014.7065868
   Emiya V, 2011, IEEE T AUDIO SPEECH, V19, P2046, DOI 10.1109/TASL.2011.2109381
   Fevotte C, 2005, 1706 IRISA
   Herre J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1894
   Herre J, 2015, IEEE J-STSP, V9, P770, DOI 10.1109/JSTSP.2015.2411578
   Herre J, 2012, J AUDIO ENG SOC, V60, P655
   Hou J, 2016, IEEE INT C MULT EXP, P1
   ISO/IEC, 2010, Standard 23003-2:2010
   ISO/IEC, 2014, 2300832014 ISOIEC
   Jia MS, 2015, IEEE-ACM T AUDIO SPE, V23, P1082, DOI 10.1109/TASLP.2015.2419980
   Kim K, 2011, IEEE T MULTIMEDIA, V13, P1208, DOI 10.1109/TMM.2011.2168197
   Kirbiz S, 2014, EUR SIGNAL PR CONF, P959
   Liutkus A, 2012, SIGNAL PROCESS, V92, P1937, DOI 10.1016/j.sigpro.2011.09.016
   Nikunen J, 2010, AUD ENG SOC CONV 128
   Ozerov A, 2013, IEEE T AUDIO SPEECH, V21, P1699, DOI 10.1109/TASL.2013.2260153
   Rodriguez-Serrano FJ, 2016, INT CONF ACOUST SPEE, P61, DOI 10.1109/ICASSP.2016.7471637
   Rohlfing C, 2017, INT CONF ACOUST SPEE, P741, DOI 10.1109/ICASSP.2017.7952254
   Rufai AM, 2014, DIGIT SIGNAL PROCESS, V24, P117, DOI 10.1016/j.dsp.2013.09.008
   Vincent E, 2007, SIGNAL PROCESS, V87, P1933, DOI 10.1016/j.sigpro.2007.01.016
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Vincent E, 2014, IEEE SIGNAL PROC MAG, V31, P107, DOI 10.1109/MSP.2013.2297440
   Wu TZ, 2017, CHINA COMMUN, V14, P32, DOI 10.1109/CC.2017.8068762
   Zhang SH, 2013, INT CONF ACOUST SPEE, P61, DOI 10.1109/ICASSP.2013.6637609
   Zheng XG, 2016, MULTIMED TOOLS APPL, V75, P5183, DOI 10.1007/s11042-015-2989-3
   Zheng XG, 2013, IEEE T AUDIO SPEECH, V21, P27, DOI 10.1109/TASL.2012.2211015
NR 30
TC 7
Z9 7
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20723
EP 20738
DI 10.1007/s11042-019-7409-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400008
DA 2024-07-18
ER

PT J
AU Atallah, DM
   Badawy, M
   El-Sayed, A
   Ghoneim, MA
AF Atallah, Dalia M.
   Badawy, Mohammed
   El-Sayed, Ayman
   Ghoneim, Mohamed A.
TI Predicting kidney transplantation outcome based on hybrid feature
   selection and KNN classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kidney transplantation; Feature selection; Information gain; Naive
   Bayes; K-nearest neighbor
ID GRAFT-SURVIVAL; LIVER-TRANSPLANTATION; NEURAL-NETWORKS; UNITED-STATES;
   RECIPIENTS; OPTIMIZATION; FAILURE; TIME
AB Kidney transplantation outcome prediction is very significant and doesn't require emphasis. This will grant the selection of the best available kidney donor and the best immunosuppressive treatment for patients. Survival prediction before treatment could simplify patient's decision making and boost survival by altering clinical practice. This paper proposes a new novel prediction method based on data mining techniques to predict five-year graft survival after transplantation. This new proposed prediction method composes of three stages: data preparation stage (DPS), feature selection stage (FSS), and prediction stage (PS). The new proposed prediction method merges information gain with naive Bayes and k-nearest neighbor. Initially, it uses information gain to select the essential features, uses naive Bayes to select the most essential features. These two methods are combined in a new hybrid feature selection method which chooses the minimum number of features that produce highest accuracy. Finally, it uses k-nearest neighbor for graft survival prediction classification. The proposed prediction method has been evaluated against recent techniques. Experimental results have proven that the proposed prediction method outperforms the recent techniques as it attains the maximum accuracy and F-measure with minimal errors. This prediction method can also be used in other transplant datasets.
C1 [Atallah, Dalia M.] Mansoura Univ, Urol & Nephrol Ctr, Mansoura, Egypt.
   [Badawy, Mohammed; El-Sayed, Ayman] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
   [Ghoneim, Mohamed A.] Mansoura Univ, Fac Med, Urol Dept, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge
   Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Mansoura
   University
RP Atallah, DM (corresponding author), Mansoura Univ, Urol & Nephrol Ctr, Mansoura, Egypt.
EM daliaat@hotmail.com
RI Badawy, Mohammed/AAY-6587-2021; EL-SAYED, Ayman E./AFM-8547-2022
OI Badawy, Mohammed/0000-0003-0833-9466; EL-SAYED, Ayman
   E./0000-0002-4437-259X
CR Akl A, 2008, EXP CLIN TRANSPLANT, V6, P30
   Akl A, 2008, TRANSPLANTATION, V86, P1401, DOI 10.1097/TP.0b013e31818b221f
   [Anonymous], 2010 2 INT C COMP RE
   [Anonymous], INT J ENG TECHNOL
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Ben-Bassat M., 1982, Handbook of statistics, V2, P773, DOI DOI 10.1016/S0169-7161(82)02038-0
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Breiman L., 2017, Classification and Regression Trees, DOI [10.1201/9781315139470-8, DOI 10.1201/9781315139470-8, DOI 10.1201/9781315139470]
   Brier ME, 2003, NEPHROL DIAL TRANSPL, V18, P2655, DOI 10.1093/ndt/gfg439
   Brown TS, 2012, AM J NEPHROL, V36, P561, DOI 10.1159/000345552
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Dag A, 2017, DECIS SUPPORT SYST, V94, P42, DOI 10.1016/j.dss.2016.10.005
   Dag A, 2016, DECIS SUPPORT SYST, V86, P1, DOI 10.1016/j.dss.2016.02.007
   Das S., 2001, P 18 INT C MACHINE L, P74, DOI DOI 10.5555/645530.658297
   Dash M., 1997, Intelligent Data Analysis, V1
   Doak J., 1992, EVALUATION FEATURE S
   DOYLE HR, 1994, ANN SURG, V219, P408, DOI 10.1097/00000658-199404000-00012
   Duch W, 2001, IEEE T NEURAL NETWOR, V12, P277, DOI 10.1109/72.914524
   Dy J.G., 2000, P 17 INT C MACHINE L, P247
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Ghoneim MA, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/912413
   Goldfarb-Rumyantzev AS, 2003, CLIN TRANSPLANT, V17, P485, DOI 10.1046/j.0902-0063.2003.00051.x
   Grinyó JM, 2013, CSH PERSPECT MED, V3, DOI 10.1101/cshperspect.a014985
   Han J, 2012, MOR KAUF D, P1
   Hariharan S, 2000, NEW ENGL J MED, V342, P605, DOI 10.1056/NEJM200003023420901
   Heldal K, 2010, NEPHROL DIAL TRANSPL, V25, P1680, DOI 10.1093/ndt/gfp681
   Hoot Nathan, 2005, AMIA Annu Symp Proc, P345
   Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7
   Kaplan B, 2009, NAT REV NEPHROL, V5, P190, DOI 10.1038/nrneph.2009.24
   Kohavi R., 1995, STUDY CROSS VALIDATI, DOI DOI 10.1067/MOD.2000.109031
   Krikov S, 2007, ASAIO J, V53, P592, DOI 10.1097/MAT.0b013e318145b9f7
   Kusiak A, 2005, COMPUT BIOL MED, V35, P311, DOI 10.1016/j.compbiomed.2004.02.004
   Lin RS, 2008, J BIOMED INFORM, V41, P944, DOI 10.1016/j.jbi.2008.03.005
   Liu H., 1998, Feature Extraction, Construction and Selection: A Data Mining Perspective, V241, P259
   Martín-Valdivia MT, 2008, INFORM PROCESS MANAG, V44, P1146, DOI 10.1016/j.ipm.2007.09.014
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Mukras R., 2007, P TEXTL WORKSH IJCAI, P16
   Nakayama N, 2012, J GASTROENTEROL, V47, P664, DOI 10.1007/s00535-012-0529-8
   Ojo AO, 2001, J AM SOC NEPHROL, V12, P589, DOI 10.1681/ASN.V123589
   Ojo AO, 1998, TRANSPLANTATION, V66, P1651, DOI 10.1097/00007890-199812270-00014
   Oztekin A, 2018, EUR J OPER RES, V266, P639, DOI 10.1016/j.ejor.2017.09.034
   Parmanto B, 2001, METHOD INFORM MED, V40, P386
   Poli F, 2000, Transpl Int, V13 Suppl 1, pS259, DOI 10.1111/j.1432-2277.2000.tb02032.x
   Port FK, 2002, TRANSPLANTATION, V74, P1281, DOI 10.1097/00007890-200211150-00014
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Raji CG, 2016, J COMPUT SCI-NETH, V16, P72, DOI 10.1016/j.jocs.2016.05.005
   Rana A, 2015, JAMA SURG, V150, P252, DOI 10.1001/jamasurg.2014.2038
   Refaeilzadeh P., 2009, ENCYCL DATABASE SYST, V5, P532, DOI DOI 10.1007/978-0-387-39940-9565
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   Shih DT, 2014, ANN OPER RES, V216, P287, DOI 10.1007/s10479-012-1129-y
   Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P197, DOI 10.1142/S0218001488000145
   Talavera L, 1999, MACHINE LEARNING, PROCEEDINGS, P389
   Tang HY, 2011, ASAIO J, V57, P206, DOI 10.1097/MAT.0b013e3182121bc5
   Topuz Kazim, 2018, Annals of Operations Research, V263, P479, DOI 10.1007/s10479-017-2489-0
   Topuz K, 2018, DECIS SUPPORT SYST, V106, P97, DOI 10.1016/j.dss.2017.12.004
   Tseng WT, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0241-3
   Webb G. I., 2010, Encyclopedia of Machine Learning, P713, DOI DOI 10.1007/978-0-387-30164-8_576
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wyse N., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P415
   Yang CH, 2010, J MED BIOL ENG, V30, P23
   YongSeog Kim, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P365
NR 61
TC 23
Z9 24
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20383
EP 20407
DI 10.1007/s11042-019-7370-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800065
OA Bronze
DA 2024-07-18
ER

PT J
AU Donati, L
   Cesano, S
   Prati, A
AF Donati, Luca
   Cesano, Simone
   Prati, Andrea
TI A complete hand-drawn sketch vectorization framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image vectorization; Line extraction; Unbiased thinning; Bezier curves;
   Sketch processing; Correlation coefficient
ID ALGORITHM
AB Vectorizing hand-drawn sketches is an important but challenging task. Many businesses rely on fashion, mechanical or structural designs which, sooner or later, need to be converted in vectorial form. For most, this is still a task done manually. This paper proposes a complete framework that automatically transforms noisy and complex hand-drawn sketches with different stroke types in a precise, reliable and highly-simplified vectorized model. The proposed framework includes a novel line extraction algorithm based on a multi-resolution application of Pearson's cross correlation and a new unbiased thinning algorithm that can get rid of scribbles and variable-width strokes to obtain clean 1-pixel lines. Other contributions include variants of pruning, merging and edge linking procedures to post-process the obtained paths. Finally, a modification of the original Schneider's vectorization algorithm is designed to obtain fewer control points in the resulting Bezier splines. All the steps presented in this framework have been extensively tested and compared with state-of-the-art algorithms, showing (both qualitatively and quantitatively) their outperformance. Moreover they exhibit fast real-time performance, making them suitable for integration in any computer graphics toolset.
C1 [Donati, Luca; Prati, Andrea] Univ Parma, Dept Engn & Architecture, Italy Parco Area Sci 181-A, I-43124 Parma, Italy.
   [Cesano, Simone] Adidas AG, Adi Dassler Str 1, D-91074 Herzogenaurach, Germany.
C3 University of Parma; Adidas Group
RP Donati, L (corresponding author), Univ Parma, Dept Engn & Architecture, Italy Parco Area Sci 181-A, I-43124 Parma, Italy.
EM luca.donati@unipr.it; simone.cesano@adidas.com; andrea.prati@unipr.it
RI Prati, Andrea/B-7440-2014
OI Prati, Andrea/0000-0002-1211-529X
FU Adidas AG
FX This work is funded by Adidas AG. We are really thankful to Adidas for
   this opportunity.
CR [Anonymous], 1760, Photometria sive de mensura et gradibus luminis, colorum et umbrae
   [Anonymous], 2013, SHREC' 13 track: large scale sketchbased 3D shape retrieval
   Bartolo A, 2007, SKETCH-BASED INTERFACES AND MODELING 2007, P123
   Bessmeltsev Mikhail, 2018, ARXIV180101922
   Bo PB, 2016, J COMPUT DES ENG, V3, P14, DOI 10.1016/j.jcde.2015.05.001
   Chen JZ, 2013, COMPUT GRAPH FORUM, V32, P98, DOI 10.1111/cgf.12164
   Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586
   González JD, 2007, RICYDE-REV INT CIENC, V3
   Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946
   Fiser J, 2016, COMPUT GRAPH-UK, V56, P46, DOI 10.1016/j.cag.2016.02.003
   Han JH, 2001, PATTERN RECOGN LETT, V22, P1133, DOI 10.1016/S0167-8655(01)00063-0
   Hilaire X, 2006, IEEE T PATTERN ANAL, V28, P890, DOI 10.1109/TPAMI.2006.127
   Igarashi T, 2006, ACM SIGGRAPH, P8
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Liu XT, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818067
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Noris G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421640
   Orbay G, 2011, IEEE T VIS COMPUT GR, V17, P694, DOI 10.1109/TVCG.2010.105
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Saeed K, 2010, INT J AP MAT COM-POL, V20, P317, DOI 10.2478/v10006-010-0024-4
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Schneider P.J., 1990, Graphics gems, V1, P612
   Simo-Serra E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132703
   Simo-Serra E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925972
   Song JQ, 2002, IEEE T PATTERN ANAL, V24, P1048, DOI 10.1109/TPAMI.2002.1023802
   Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2625, DOI 10.1016/S0167-8655(03)00106-5
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Yung-Sheng Chen, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P91, DOI 10.1109/ICPR.1996.546730
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 33
TC 15
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19083
EP 19113
DI 10.1007/s11042-019-7311-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gencoglu, MT
AF Gencoglu, Muharrem Tuncay
TI Embedded image coding using laplace transform for Turkish letters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Power series transform; Data encryption; Embedded image
ID STEGANOGRAPHY
AB In this paper, a different cryptographic method is introduced by using a Power series transform. A new algorithm for cryptography is produced. The extended Laplace transform of the exponential function is used to encode an explicit text. The key is generated by applying the modular arithmetic rules to the coefficients obtained in the transformation. Here, ASCII codes used to hide the mathematically generated keys to strengthen the encryption. Text steganography is used to make it difficult to break the password. The made encryption is reinforced by image steganography. To hide the presence of the cipher text, it is embedded in another open text with a stenography method. Later, this text is buried in an image. For decryption, it is seen that the inverse of the Power series transform can be used for decryption easily. Experimental results are obtained by making a simulation of the proposed method. As a result, it is stated that the proposed method can be used in crypto machines.
C1 [Gencoglu, Muharrem Tuncay] Firat Univ, Vocat Sch Tech Sci, TR-23119 Elazig, Turkey.
C3 Firat University
RP Gencoglu, MT (corresponding author), Firat Univ, Vocat Sch Tech Sci, TR-23119 Elazig, Turkey.
EM mt.gencoglu@firat.edu.tr
OI Gencoglu, Muharrem Tuncay/0000-0002-8784-9634
CR [Anonymous], 2010, Understanding Cryptography
   Aydn M, 1990, DIFERANSIYEL DENKLEM, P332
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Delfs H., 2007, Introduction to cryptography: principles and applications
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Gencoglu M.T., 2016, SCI ENG J FIRAT U, V28, P217
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Koc C.K., 2009, CRYPTOGRAPHIC ENG, P125
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Martin Keith, 2012, AUSTR MATH SOC, P560
   Tuncer T, 2018, MULTIMED TOOLS APPL, V77, P21463, DOI 10.1007/s11042-017-5569-x
   Usha S, 2011, INT C COMP SCI NETW
   Wu WC, 2016, J VIS COMMUN IMAGE R, V38, P18, DOI 10.1016/j.jvcir.2016.02.005
   Yalman Y, 2009, UNAK 2009 BILG CAG V
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
NR 15
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17521
EP 17534
DI 10.1007/s11042-018-7096-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200009
DA 2024-07-18
ER

PT J
AU Jaiswal, S
   Virmani, S
   Sethi, V
   De, K
   Roy, PP
AF Jaiswal, Saurabh
   Virmani, Shubham
   Sethi, Vishal
   De, Kanjar
   Roy, Partha Pratim
TI An intelligent recommendation system using gaze and emotion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-commerce recommendation system; Eye gaze; Emotion detection
AB Recently, recommendation system has become popular in many e-commerce websites. It helps users by suggesting products which they could buy. Existing work till now uses past feedback of user, similarity of other users' buying pattern, or a hybrid approach in which both type of information is used. But the pitfall of these approaches is that there is a need to collect and process huge amount of data for good recommendation. This paper is aimed at developing an efficient recommendation system by incorporating user's emotion and interest to provide good recommendations. The proposed system does not require any of aforementioned data and works without the continuous and interminable attention of the user. In this framework, we capture user's eye-gaze and facial expression while exploring websites through inexpensive, visible light "webcam". The eye-gaze detection method uses pupil-center extraction of both eyes and calculates the reference point through a joint probability. The facial expression uses landmark points of face and analyzes the emotion of the user. Both methods work in approximate real time and the proposed framework thus provides intelligent recommendations on-the-fly without requirement of feedback and buying patterns of users.
C1 [Jaiswal, Saurabh; Virmani, Shubham; Sethi, Vishal; De, Kanjar; Roy, Partha Pratim] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Roy, PP (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
EM proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/AAW-2994-2020; Roy, Partha Pratim/AAV-9061-2020; Roy,
   Partha Pratim/GPF-4253-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2017, Encyclopedia of Machine Learning and Data Mining, DOI DOI 10.1007/978-1-4899-7687-1964
   [Anonymous], NEURAL INFORM PROCES
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Chen H.H., 2015, ARXIV151102058
   Chen LJ, 2011, PROCEEDINGS OF 2011 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (7TH), VOL III, P231
   Felfernig A., 2007, PROC NATL CONF ARTIF, V22, P1692
   Guo Y, 2016, INT J AEROSPACE ENG, V2016, DOI 10.1155/2016/2942686
   Gupta Pankaj, 2013, P 22 INT C WORLD WID, P505, DOI DOI 10.1145/2488388.2488433
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Ishwar D, 2015, INT J EMERG RES MANA, V4, P144
   Jafarkarimi H., 2012, INT J INFORM ED TECH, V2, P216, DOI [10.7763/IJIET.2012.V2.113, DOI 10.7763/IJIET.2012.V2.113]
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Karray F, INT J SMART SENSING
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kermany NR, 2017, ELECTRON COMMER R A, V21, P50, DOI 10.1016/j.elerap.2016.12.005
   Liao CL, 2016, ELECTRON COMMER R A, V18, P1, DOI 10.1016/j.elerap.2016.05.001
   Liu Beilin, 2013, 2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering (ICIII), P337, DOI 10.1109/ICIII.2013.6703586
   Liu WF, 2018, PATTERN RECOGN LETT, V107, P123, DOI 10.1016/j.patrec.2017.06.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ma X, 2017, ELECTRON COMMER R A, V25, P29, DOI 10.1016/j.elerap.2017.06.005
   MASE K, 1991, IEICE TRANS COMMUN, V74, P3474
   Mooney R. J., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P195, DOI 10.1145/336597.336662
   Pourgholamali F, 2017, ELECTRON COMMER R A, V25, P70, DOI 10.1016/j.elerap.2017.08.001
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136
   Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414
   Yadava M, 2017, MULTIMED TOOLS APPL, V76, P19087, DOI 10.1007/s11042-017-4580-6
   Zhao WNX, 2016, IEEE T KNOWL DATA EN, V28, P1147, DOI 10.1109/TKDE.2015.2508816
   Zhao Z-L, ELECT COMMERCE RES A
NR 36
TC 20
Z9 20
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14231
EP 14250
DI 10.1007/s11042-018-6755-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700006
DA 2024-07-18
ER

PT J
AU Khan, MJ
   Mustafa, K
AF Khan, Mohd Javed
   Mustafa, Khurram
TI Modelling adaptive hypermedia instructional system: a framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive system; Hypermedia; Instructions; Ergonomics; Media
ID EDUCATIONAL-SYSTEM; LEARNING-SYSTEM; DESIGN; INFORMATION; PAPER
AB This research drill presents a perspective on modeling an Adaptive Hypermedia Instructional System (AHIS), by integrating investigational research findings on technology and education. In the past decade, a number of adaptive hypermedia learning systems have been developed. Most of these systems deliver instructions according to learner prior knowledge. Each learner, process and organize instruction in a different way. An effective and efficient instruction significantly affect student learning. Thus, researchers and practitioners are investigating ways to design and develop effective and efficient instructions. Proposed Adaptive Hypermedia Instructional System based on Component Display Theory (CDT) given by (Merrill, 1983) present guidelines to design effective and efficient instruction. Present study showed that an instruction is a balanced combination of - Graphic Aesthetic, Ergonomics, Hypermedia and Media building blocks. As a consequence, critical survey was conducted. Survey included 60 studies out which 30 studies were on adaptive systems (14 were peer reviewed journals). Survey revealed that little adaptation focus has been laid on Instructional Strategies and Components of Instruction. As a result, described framework (AHIS) assists in formulating efficient and effective instruction to achieve desired learning outcome. The design, development and improvement of learning instructions in AHIS are based on Media Worthiness, Ergonomics, Hypermedia, Attributes and Methods building blocks. Framework is at more abstract and coarse-grain level and calls for its evolution into Shell. Thus, we conceived the Modelling of Adaptive Hypermedia Instructional System (AHIS) by integrating the research findings of micro-studies on various aspects of Ergonomic, Hypermedia and Media. Effectiveness of instructions was evaluated by forty-four undergraduate students. Results indicate that instructions designed through Adaptive Hypermedia Instructional System were learner engaging and considerably affect learner performance. The implications of these results for the design of Adaptive Hypermedia Instructional System are discussed.
C1 [Khan, Mohd Javed; Mustafa, Khurram] Jamia Millia Islamia, Dept Comp Sci, New Delhi 110025, India.
C3 Jamia Millia Islamia
RP Khan, MJ (corresponding author), Jamia Millia Islamia, Dept Comp Sci, New Delhi 110025, India.
EM mohd.khanjk@gmail.com; kmustafa@jmi.ac.in
RI Khan, Mohd Javed/O-4429-2017
OI Khan, Mohd Javed/0000-0002-6742-3038
CR Altaboli A, 2011, ADV HUM-COMPUT INTER, V2011, DOI 10.1155/2011/659758
   ANDRE T, 1990, J EXP EDUC, V58, P77, DOI 10.1080/00220973.1990.10806525
   [Anonymous], INSTRUCTIONAL SYSTEM
   [Anonymous], ANN CONV ASS ED COMM
   [Anonymous], J ED TECHNOL
   [Anonymous], 7 IEEE INT C ADV LEA
   [Anonymous], USE COLOR COMPUTER I
   [Anonymous], INT J INTEGR TECHNOL
   [Anonymous], INT DES GUID US ALL
   [Anonymous], J ED TECHNOL
   [Anonymous], INT FORUM ED TECHNOL
   [Anonymous], P 6 INT C ADV LEARN
   [Anonymous], 2010 IEEE WORLD C CO
   [Anonymous], HDB RES ED COMMUNICA
   [Anonymous], INT COMP S
   [Anonymous], J ED PSYCHOL
   [Anonymous], USABILITY NEWS
   [Anonymous], 31 ASEE IEEE FRONT E
   [Anonymous], THEORIES LEARNING
   [Anonymous], READING ED MEDIA THE
   [Anonymous], 2001, P 10 INT C WORLD WID, DOI DOI 10.1145/371920.372074
   [Anonymous], 12 INT WORLD WID WEB
   [Anonymous], HDB RES EDUACTIONAL
   [Anonymous], USABILITY NEWS
   [Anonymous], [No title captured]
   Atkinson RK, 2002, J EDUC PSYCHOL, V94, P416, DOI 10.1037//0022-0663.94.2.416
   Bajraktarevic N., 2003, Workshop on Adaptive Hypermedia and Adaptive Web-Based Systems, Nottingham, UK: Eindhoven University, P41
   Bénabou R, 2003, REV ECON STUD, V70, P489, DOI 10.1111/1467-937X.00253
   Bodemer D, 2004, LEARN INSTR, V14, P325, DOI 10.1016/j.learninstruc.2004.06.006
   Carver CA, 1999, IEEE T EDUC, V42, P33, DOI 10.1109/13.746332
   Chanijani SSM, 2015, IEEE INT CONF MULTI
   Chiu CK, 2017, PERS UBIQUIT COMPUT, V21, P355, DOI 10.1007/s00779-016-0986-9
   Dias P, 1999, J EDUC COMPUT RES, V20, P93, DOI 10.2190/G8C5-342V-DJX3-Q53F
   Dyson MC, 2004, BEHAV INFORM TECHNOL, V23, P377, DOI 10.1080/01449290410001715714
   Gilbert J. E., 2002, Journal of Computing in Higher Education, V14, P113, DOI 10.1007/BF02940953
   Hartley J., 1996, HDB RES ED COMMUNICA, P795
   Hasan E.H. R., 2001, Instructional design and media selection: A study on the use of for teacher education (Publication No. C809436). [Doctoral dissertation
   Höffler TN, 2007, LEARN INSTR, V17, P722, DOI 10.1016/j.learninstruc.2007.09.013
   Jeong HY, 2016, MULTIMED TOOLS APPL, V75, P13193, DOI 10.1007/s11042-016-3292-7
   Keller J.M., 1979, J INSTRUCTIONAL DEV, V2, P26, DOI [10.1007/BF02904345, DOI 10.1007/BF02904345]
   KOZMA RB, 1991, REV EDUC RES, V61, P179, DOI 10.2307/1170534
   KRUK RS, 1984, HUM FACTORS, V26, P339, DOI 10.1177/001872088402600309
   Lin CF, 2014, COMPUT EDUC, V77, P50, DOI 10.1016/j.compedu.2014.04.007
   Mangen A, 2013, INT J EDUC RES, V58, P61, DOI 10.1016/j.ijer.2012.12.002
   Martinez M., 2001, Educational Technology & Society, V4
   Mayer G, 2017, EDUC TECHNOL SOC, V20, P15
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, V2nd, P31, DOI [https://doi.org/10.1017/CBO9781139547369.005, DOI 10.1017/CBO9780511816819.004, 10.1017/cbo9780511816819.004]
   Mayer RE, 2001, J EDUC PSYCHOL, V93, P187, DOI 10.1037//0022-0663.93.1.187
   Merrill M.D., 1983, Instructional-Design Theories and Models: An Overview of Their Current Status, V1, P282
   Morch AI, 2017, EDUC TECHNOL SOC, V20, P213
   Ngo DCL, 2000, DISPLAYS, V21, P3, DOI 10.1016/S0141-9382(00)00026-3
   Özyurt Ö, 2013, EXPERT SYST APPL, V40, P2914, DOI 10.1016/j.eswa.2012.12.008
   Papanikolaou KA, 2003, USER MODEL USER-ADAP, V13, P213, DOI 10.1023/A:1024746731130
   Park O., 2003, Handbook of Research for Educational Communications and Technology, V25, P651
   Peña CI, 2004, ITHET 2004: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY BASED HIGHER EDUCATION AND TRAINING, P167, DOI 10.1109/ITHET.2004.1358157
   Peter Sophie E., 2010, Campus-Wide Information Systems, V27, P91, DOI 10.1108/10650741011033062
   PEZDEK K, 1984, DEV PSYCHOL, V20, P212, DOI 10.1037/0012-1649.20.2.212
   Popescu E, 2010, J COMPUT ASSIST LEAR, V26, P243, DOI 10.1111/j.1365-2729.2010.00364.x
   Porion A, 2016, COMPUT HUM BEHAV, V54, P569, DOI 10.1016/j.chb.2015.08.002
   Ragan TJ., 2004, HDB RES ED COMMUNICA, P623
   Rakes T.A., 1982, Reading Horizons, P67
   Sancho P, 2005, J UNIVERS COMPUT SCI, V11, P1470
   Schiaffino S, 2008, COMPUT EDUC, V51, P1744, DOI 10.1016/j.compedu.2008.05.008
   TENNYSON RD, 1986, REV EDUC RES, V56, P40, DOI 10.3102/00346543056001040
   Triantafillou E, 2003, COMPUT EDUC, V41, P87, DOI 10.1016/S0360-1315(03)00031-9
   Williams Robin., 2004, NONDESIGNERS DESIGN
   Wolf C., 2007, Construction of an adaptive e-learning environment to address learning styles and an investigation of the effect of media choice
   Wu TT, 2017, EDUC TECHNOL SOC, V20, P265
   Young M.F., 2004, Handbook of Research for Educational Communications and Technology, P169
   Cabada RZ, 2011, EXPERT SYST APPL, V38, P9522, DOI 10.1016/j.eswa.2011.01.145
   Zengin Y, 2017, EDUC TECHNOL SOC, V20, P89
NR 71
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14397
EP 14424
DI 10.1007/s11042-018-6819-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700013
DA 2024-07-18
ER

PT J
AU Madhusudhan, R
   Nayak, CS
AF Madhusudhan, R.
   Nayak, Chaitanya S.
TI A robust authentication scheme for telecare medical information systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication; Password; Chaotic map; Hash functions; Mutual
   authentication; Security
ID PATIENT RECORD; SECURITY; PRIVACY; CRYPTANALYSIS; EFFICIENT
AB With the speedy progress in technology, the Internet has become a non-separable part of human life. It is obvious to use the Internet in all fields and medical field is no exception. The concept of establishing telecare medicine information systems(TMIS) for patients is gaining more popularity recently. To ensure the privacy of patients and to allow authorized access to remote medical servers, many authentication schemes have been proposed. Li et al., in 2016, proposed a secure dynamic identity and chaotic maps based user authentication and key agreement scheme. They claimed that the scheme is resistant to most of the known attacks. However, from thorough cryptanalysis, we have proved that their scheme is vulnerable to user impersonation attack, password guessing attack and server impersonation attack. We have also illustrated that their scheme does not provide user anonymity, convenient smart card revocation and security to session key. To overcome the aforementioned security weaknesses, we have proposed an enhanced authentication scheme using chaotic maps, which has been discussed in this paper along with its cryptanalysis. Cryptanalysis of the proposed scheme proves that the scheme is more robust and suitable for implementation.
C1 [Madhusudhan, R.; Nayak, Chaitanya S.] Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Madhusudhan, R (corresponding author), Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal, Karnataka, India.
EM madhu_nitks@yahoo.com; chaitanyasnayak19@gmail.com
CR Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0262-y
   Anderson JG, 2007, INT J MED INFORM, V76, P480, DOI 10.1016/j.ijmedinf.2006.09.016
   [Anonymous], 2018, ADV CONDENS MATTER P, DOI DOI 10.1109/ISCAS.2018.8351098
   [Anonymous], LIGHTWEIGHT METHOD D
   [Anonymous], 2017, INTERNET THINGS BIG
   [Anonymous], IEEE J BIOMED HLTH I
   [Anonymous], HLTH INF OVERVIEW
   Breaux TD, 2008, IEEE T SOFTWARE ENG, V34, P5, DOI 10.1109/TSE.2007.70746
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Cao TJ, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9912-5
   Chaturvedi Ankita, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P63, DOI 10.1007/978-3-642-45204-8_5
   Chen HM, 2012, J MED SYST, V36, P3907, DOI 10.1007/s10916-012-9862-y
   Chen TL, 2012, J MED SYST, V36, P1345, DOI 10.1007/s10916-010-9595-8
   Das AK, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0204-8
   Devaney R.L., 1993, Computers in Physics, V7, P416, DOI DOI 10.1063/1.4823195
   He DJ, 2011, IEEE T WIREL COMMUN, V10, P431, DOI 10.1109/TWC.2010.120610.101018
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Jiang Q, 2016, NONLINEAR DYNAM, V83, P2085, DOI 10.1007/s11071-015-2467-5
   Jiang Q, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9897-0
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Lee TF, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9985-9
   Lee TF, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9941-8
   Li CT, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0474-9
   Lovis C, 1998, COMPUT BIOL MED, V28, P567, DOI 10.1016/S0010-4825(98)00034-1
   Lu YR, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0229-z
   Madhusudhan R, 2012, J NETW COMPUT APPL, V35, P1235, DOI 10.1016/j.jnca.2012.01.007
   Masuda N, 2002, IEEE T CIRCUITS-I, V49, P28, DOI 10.1109/81.974872
   Meingast Marci, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5453
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mir O, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0265-8
   Mishra D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0154-6
   Mishra D, 2014, J MED SYST, V38, DOI [10.1007/s10916-014-0120-3, 10.1007/s10916-014-0024-2]
   Mishra D, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0041-1
   Moon J, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0422-0
   Nikooghadam M, 2012, J MED SYST, V36, P3839, DOI 10.1007/s10916-012-9857-8
   Rind D M, 1993, Proc Annu Symp Comput Appl Med Care, P74
   Safran C, 2000, INT J MED INFORM, V60, P77, DOI 10.1016/S1386-5056(00)00106-4
   Shen J, 2018, J NETW COMPUT APPL, V106, P117, DOI 10.1016/j.jnca.2018.01.003
   Steward M, 2005, J LEGAL MED, V26, P491, DOI 10.1080/019476405600364762
   Tang PC, 2006, J AM MED INFORM ASSN, V13, P121, DOI 10.1197/jamia.M2025
   Tsai SC., 2006, International Journal of Network Security, V2, P101
   Uslu AM, 2008, J BIOMED INFORM, V41, P675, DOI 10.1016/j.jbi.2008.02.001
   van Ginneken AM, 2002, INT J MED INFORM, V65, P97, DOI 10.1016/S1386-5056(02)00007-2
   Wang JC, 2018, COMPUT NETW, V143, P74, DOI 10.1016/j.comnet.2018.07.005
   Wei JH, 2012, J MED SYST, V36, P3597, DOI 10.1007/s10916-012-9835-1
   Wen FT, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0026-0
   Wen FT, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0042-0
   William S., 1999, CRYPTOGRAPHY NETWORK, P23
   Wu F, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9958-z
   Wu ZY, 2012, J MED SYST, V36, P1529, DOI 10.1007/s10916-010-9614-9
   Wu ZY, 2012, J MED SYST, V36, P631, DOI 10.1007/s10916-010-9527-7
   Xie Q, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9911-6
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhu ZA, 2012, J MED SYST, V36, P3833, DOI 10.1007/s10916-012-9856-9
NR 55
TC 34
Z9 34
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15255
EP 15273
DI 10.1007/s11042-018-6884-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700049
DA 2024-07-18
ER

PT J
AU Vinola, C
   Devi, KV
AF Vinola, C.
   Devi, Vimala K.
TI Smile intensity recognition in real time videos: fuzzy system approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smile intensity; Land Mark Points; Normalized Euclidean Distance
   Percentage; Fuzzy system
AB Facial emotion is a significant way of understanding or interpreting one's inner thoughts. Real time video at any instant exhibits the emotion which serves as the input to the emotion recognition system. Many literatures propose different strategies in identifying the emotions by working on different features in the facial components, including geometrical, appearance and motion features. This paper considers the geometrical features as a prime component in deciding the intensity of the smile expressed in the real time videos of the AM-FED (Affectiva-MIT Facial Expression Dataset). Geometrical features considered in the work are the normalized Euclidean distance between the contributing LandMarkPoints (LMPs) of the eyes and the lip portions of the face. Fuzzy logic is applied to the system to effectively classify the intensity of the emotion, i.e., happiness or smile as Maximum, Moderate, Less and neutral. Being a Land mark based assessment, evaluating the normalized values of the Euclidean distance between LMPs for each frame of the video and then mapping the values of all the frames in a range helps the fuzzy decision making stage to relate the mapped values to the smile intensity of each frame. The average recognition rate obtained is 86.54%. The system contributes a less complex but nearly accurate smile intensity recognition model when compared to other computation intensive decision making models, with a practical significance in the customer or client's mood/satisfactory identification in the online marketing and/or communication of the intensity of the smile of the conversing person to a visually challenged person.
C1 [Vinola, C.] Francis Xavier Engn Coll, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
   [Devi, Vimala K.] Velammal Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Velammal Engineering College
RP Vinola, C (corresponding author), Francis Xavier Engn Coll, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
EM selvivino@gmail.com; k.vimaladevi@gmail.com
RI C, Vinola/HNJ-2262-2023; K, VIMALA DEVI/AAW-7397-2020
OI C, Vinola/0000-0002-7031-4000; K, VIMALA DEVI/0000-0003-1681-8088
CR [Anonymous], 2001, FUZZY SET THEORY ITS, DOI [DOI 10.1007/978-94-010-0646-0, 10.1007/978-94-010-0646-0]
   Baltrusaitis T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P909, DOI 10.1109/FG.2011.5771372
   Chakraborty A, 2009, IEEE T SYST MAN CY A, V39, P726, DOI 10.1109/TSMCA.2009.2014645
   Chen JK, 2017, MACH VISION APPL, V28, P173, DOI 10.1007/s00138-016-0817-z
   Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014
   Dornaika F, 2013, ENG APPL ARTIF INTEL, V26, P467, DOI 10.1016/j.engappai.2012.09.002
   Ekman P, 1978, FACIAL ACTION CODING
   Esau N., 2007, P IEEE INT FUZZ SYST, P1, DOI [10.1109/FUZZY.2007.4295451, DOI 10.1109/FUZZY.2007.4295451]
   Freire-Obregón D, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415500068
   Guo GD, 2013, IEEE T AFFECT COMPUT, V4, P291, DOI 10.1109/T-AFFC.2013.13
   Hablani R., 2013, International Journal of Image Processing, V7, P163
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Kauser N, P INT C I SMAC IOT S, P445, DOI [10.1109/I-SMAC.2017.8058389, DOI 10.1109/I-SMAC.2017.8058389]
   Kudiri KM, INT C COMP INF SCI I, P351, DOI [10.1109/ICCOINS.2016.7783240, DOI 10.1109/ICCOINS.2016.7783240]
   Li P., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P581, DOI 10.1109/DICTA.2010.103
   Li ZS, 2009, IEEE SYS MAN CYBERN, P1353, DOI 10.1109/ICSMC.2009.5346254
   Liu Y, IEEE INT C REAL TIM, P368, DOI [10.1109/RCAR.2016.7784056, DOI 10.1109/RCAR.2016.7784056]
   Liu ZT, 2017, IEEE-CAA J AUTOMATIC, V4, P668, DOI 10.1109/JAS.2017.7510622
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Matlab, 2016, HELP DOC ALG NEUR NE
   McDuff D, 2013, 10 IEEE INT C WORKSH, DOI [10.1109/FG.2013.6553750, DOI 10.1109/FG.2013.6553750]
   Mcduff D., 2013, P IEEE C COMP VIS PA
   McDuff D, 2014, IMAGE VISION COMPUT, V32, P630, DOI 10.1016/j.imavis.2014.01.004
   Nicolle J., 2015, PROC 11 IEEE INT C W, V6, P1
   Patil J. V., 2016, 2016 INT C INV COMP, V2, P1, DOI [10.1109/inventive.2016.7824820, DOI 10.1109/INVENTIVE.2016.7824820, 10.1109/INVENTIVE.2016.7824820]
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Shimada K, PATTERN RECOGN LETT, P13, DOI [10.1016/j.patrec.2014.10.004, DOI 10.1016/J.PATREC.2014.10.004]
   Wang PH, 2017, J DIFFER EQUATIONS, V262, P5534, DOI 10.1016/j.jde.2017.02.010
   Wang PH, 2016, NONLINEAR ANAL-THEOR, V130, P1, DOI 10.1016/j.na.2015.09.021
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Yang Z, 2018, INTERMEDIATE DATA CA
   Yantao Qiao, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P230, DOI 10.1109/CCNC.2016.7444761
   Zhang KP, 2016, IEEE COMPUT SOC CONF, P739, DOI 10.1109/CVPRW.2016.97
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
NR 34
TC 3
Z9 3
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15033
EP 15052
DI 10.1007/s11042-018-6890-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700040
DA 2024-07-18
ER

PT J
AU Hu, H
   Shen, G
   Liu, YL
   Fu, ZX
   Yu, B
AF Hu, Hao
   Shen, Gang
   Liu, Yuling
   Fu, Zhengxin
   Yu, Bin
TI Improved schemes for visual secret sharing based on random grids
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Visual secret sharing; Visual cryptography; Random
   grid; General access structure; Meaningful share
ID GENERAL ACCESS STRUCTURES; CRYPTOGRAPHY
AB Random grid (RG) is an alternative approach to realize a visual secret sharing (VSS) scheme. RG-based VSS has merits such as no pixel expansion and no tailor-made matrix requirement. Recently, many investigations on RG-based VSS are made. However, they need further improvements. In this paper, we obtain some improvements on RG-based VSS. Actually, two improved schemes are proposed, namely RG-based VSS for general access structure (GAS) with improved contrast and extended RG-based VSS with improved access structure. The first scheme can achieve better contrast than previous schemes. The second scheme reduces the chance of suspicion on secret image encryption by generating meaningful shares instead of noise-like shares in the first scheme, and improves the access structure from (k, k) to GAS while maintaining the property that the contrast of the recovered image is traded with that of share images by setting a certain parameter from small to large. Finally, theoretical analyses and experimental results are provided to demonstrate the effectiveness and advantages of the proposed schemes.
C1 [Hu, Hao; Shen, Gang] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
   [Fu, Zhengxin; Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou 450001, Henan, Peoples R China.
   [Liu, Yuling] Chinese Acad Sci, Inst Software, Trusted Comp & Informat Assurance Lab, Beijing 100190, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Chinese Academy of Sciences; Institute of Software, CAS
RP Hu, H (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM wjjhh_908@163.com
RI Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942
FU Natural Science Foundation of China [61602513]; National Key Research
   and Development Program of China [2016YFF0204002, 2016YFF0204003];
   Equipment Pre-research Foundation During the 13th Five-Year Plan Period
   [6140002020115]; CCF-Venus "Hongyan" Scientific Research Plan Foundation
   [2017003]; Outstanding Youth Foundation of Zhengzhou Information Science
   and Technology Institute [2016611303]; Science and technology leading
   talent project of Zhengzhou [131PLJRC644]
FX The authors would like to thank the reviewers for their detailed reviews
   and constructive comments, which have helped improve the quality of this
   paper. This work was supported by the Natural Science Foundation of
   China (Grant No. 61602513), the National Key Research and Development
   Program of China (Grant No. 2016YFF0204002, 2016YFF0204003), the
   Equipment Pre-research Foundation During the 13th Five-Year Plan Period
   (Grant No. 6140002020115), the CCF-Venus "Hongyan" Scientific Research
   Plan Foundation (Grant No. 2017003), the Outstanding Youth Foundation of
   Zhengzhou Information Science and Technology Institute (Grant No.
   2016611303), and the Science and technology leading talent project of
   Zhengzhou (Grant No. 131PLJRC644).
CR [Anonymous], 2016, J REAL TIME IMAGE PR
   ATENIESE G, 2006, INFORM COMPUT, V129, P86
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chen YC, 2017, IEEE T INF FOREN SEC, V12, P1082, DOI 10.1109/TIFS.2016.2641378
   Cimato S., 2005, THE COMPUTER JOURNAL, V49, P97, DOI 10.1093/comjnl/bxh152
   D'Arco P, 2016, LECT NOTES COMPUT SC, V10015, P95, DOI 10.1007/978-3-319-49175-2_5
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   De Prisco R, 2013, THEOR COMPUT SCI, V510, P62, DOI 10.1016/j.tcs.2013.09.005
   Fu Z., 2013, P 12 INT WORKSH DIG, P109
   Fu ZX, 2014, MULTIMED TOOLS APPL, V73, P1177, DOI 10.1007/s11042-013-1625-3
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   HORNG G, 1936, CODES, V38, P219, DOI DOI 10.1007/S10623-005-6342-0
   Hu H, 2016, MULTIMED TOOLS APPL, V75, P13883, DOI 10.1007/s11042-016-3250-4
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M., 1995, LECT NOTES COMPUT SC, V950, P1
   Ren YW, 2017, IET INFORM SECUR, V11, P211, DOI 10.1049/iet-ifs.2016.0126
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   SHIVANI S, 2016, COMMUN, V12, P1, DOI DOI 10.1145/2935618
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2013, IEEE T CIRC SYST VID, V23, P414, DOI 10.1109/TCSVT.2012.2204940
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Wu X, 2014, IEEE T INF FOREN SEC, V8, P1541
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
   Yan X, 2017, IEEE INT C SIGN IM P, DOI DOI 10.1109/SIPR0CESS.2016.7888277
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
NR 37
TC 12
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12055
EP 12082
DI 10.1007/s11042-018-6738-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900044
DA 2024-07-18
ER

PT J
AU Liu, H
   Zhao, QJ
   Zhang, C
   Mbelwa, JT
   Tang, S
   Zhang, JW
AF Liu, Hao
   Zhao, Qingjie
   Zhang, Cong
   Mbelwa, Jimmy T.
   Tang, Song
   Zhang, Jianwei
TI Boosting VLAD with weighted fusion of local descriptors for image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VLAD; Saliency weighting; Image representation; Image retrieval
ID CLASSIFICATION; SEARCH
AB In the last decade, many efforts have been developed for discriminative image representations. Among these works, vector of locally aggregated descriptors (VLAD) has been demonstrated to be an effective one. However, most VLAD-based methods generally employ detected SIFT descriptors and contain limited content information, in which the representation ability is deteriorated. In this work, we propose a novel framework to boost VLAD with weighted fusion of local descriptors (WF-VLAD), which encodes more discriminative clues and maintains higher performance. Toward a preferable image representation that contains sufficient details, our approach fuses SIFT sampled densely (dense SIFT) and detected from the interest points (detected SIFT) in the aggregation. Furthermore, we assign each detected SIFT corresponding weight that measured by saliency analysis to make the salient descriptors with relatively high importance. The proposed method can include sufficient image content information and highlight the important image regions. Finally, experiments on publicly available datasets demonstrate that our approach shows competitive performance in retrieval tasks.
C1 [Liu, Hao; Zhao, Qingjie; Zhang, Cong; Mbelwa, Jimmy T.] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China.
   [Zhao, Qingjie; Tang, Song; Zhang, Jianwei] Univ Hamburg, Dept Informat, Hamburg, Germany.
C3 Beijing Institute of Technology; University of Hamburg
RP Liu, H (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China.
EM liuhao3721@gmail.com
RI zhang, jian/HPD-1712-2023; jin, li/IWU-4648-2023; zhan, y/ISA-2807-2023;
   Tang, Song/ITT-7528-2023
OI Tang, Song/0000-0003-2635-1872
FU China Scholarship Council [201706035021]; National Natural Science
   Foundation of China [61175096]; German Research Foundation in project
   Crossmodal Learning [TRR-169]; Chinese Government Scholarship under
   China Scholarship Council
FX This work was partly supported by the China Scholarship Council
   (201706035021), the National Natural Science Foundation of China
   (61175096), the German Research Foundation in project Crossmodal
   Learning (TRR-169) and Chinese Government Scholarship under China
   Scholarship Council.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Huang S, 2014, IEEE IMAGE PROC, P3087, DOI 10.1109/ICIP.2014.7025624
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kim TE, 2015, J VIS COMMUN IMAGE R, V31, P237, DOI 10.1016/j.jvcir.2015.07.005
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li J, 2017, NEUROCOMPUTING, V257, P47, DOI 10.1016/j.neucom.2016.10.074
   Li Y, 2015, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2015.7299108
   Liu H, 2017, MULTIMED TOOLS APPL, V76, P24435, DOI 10.1007/s11042-016-4176-6
   Liu Z, 2016, IEEE T CIRC SYST VID, V26, P375, DOI 10.1109/TCSVT.2015.2409693
   Liu ZQ, 2017, IEEE T IMAGE PROCESS, V26, P3128, DOI 10.1109/TIP.2017.2660244
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marszalek M, 2012, INT J COMPUT VISION, V97, P191, DOI 10.1007/s11263-011-0479-2
   Miller FP, 2010, REGION HESSIAN AFFIN
   Murata M, 2014, IEEE T MULTIMEDIA, V16, P1690, DOI 10.1109/TMM.2014.2323945
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Philbin J., 2008, P CVPR, P1
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   Tao R, 2015, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2015.7298613
   Wu Y, 2017, MULTIMED TOOLS APPL, P1
   XIE L, 2008, TIP, V23, P1994, DOI DOI 10.1109/TIP.2014.2310117
   Zhao WL, 2016, IEEE T MULTIMEDIA, V18, P1843, DOI 10.1109/TMM.2016.2585023
   Zheng L, 2015, IEEE T MULTIMEDIA, V17, P648, DOI 10.1109/TMM.2015.2408563
   Zhou QZ, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080311
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 44
TC 0
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11835
EP 11855
DI 10.1007/s11042-018-6712-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900034
DA 2024-07-18
ER

PT J
AU Liu, HH
   Lin, YC
   Lee, CM
AF Liu, Hsing-Han
   Lin, Yuh-Chi
   Lee, Chia-Ming
TI A digital data hiding scheme based on pixel-value differencing and side
   match method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Pixel-value differencing; Side-match; Human visual system
ID SIGNIFICANT-BIT SUBSTITUTION; STEGANOGRAPHIC METHOD
AB This paper proposes a new data-hiding scheme based on pixel-value differencing (PVD) in which 3-by-3 blocks are used to hide data within nine-pixel groups. The PVD scheme and the side match method are combined to ultimately produce eight groups of pixel-value differences, enabling maximum hiding capacity while maintaining an acceptable peak signal-to-noise ratio (PSNR). Experimental results demonstrate that the hiding capacity of this scheme can reach a maximum of 808,760 bits with a PSNR value of 32.0283dB, which is difficult to detect with human vision. The results of a performance comparison with those of PVD hiding schemes proposed by other researchers confirm that the proposed scheme has a higher capacity than the other methods while maintaining an acceptable PSNR, demonstrating the superiority of the proposed hiding scheme. Finally, to assess the suitability of the proposed method to databases with different patterns, a further 2260, 9074, and 10,000,512x512-pixel greyscale images were respectively selected from the NRCS, BOSS, and BOWS2 image databases as raw images. The proposed hiding scheme was used to hide data and generate steganographic images in these raw images. Experimental results show that the minimum PSNR mean value is 35.33dB, while the minimum mean value of the hiding capacity is 720,572 bits. These results confirm the suitability of the proposed hiding scheme for image database patterns.
C1 [Liu, Hsing-Han; Lee, Chia-Ming] Natl Def Univ, 70,Sec 2,Zhongyang N Rd, Taipei 11258, Taiwan.
   [Lin, Yuh-Chi] Chihlee Univ Technol, 313,Sec 1,Wenhua Rd, New Taipei 220, Taiwan.
C3 National Defense University - Taiwan
RP Liu, HH (corresponding author), Natl Def Univ, 70,Sec 2,Zhongyang N Rd, Taipei 11258, Taiwan.
EM liu.hansh@gmail.com
OI Liu, Hsing Han/0000-0002-8764-9501
CR Alturki F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958548
   [Anonymous], 1988, 461 NBA FIPS PUB NBS
   [Anonymous], 2010, Understanding Cryptography
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Hameed MA, 2018, MULTIMED TOOLS APPL, V77, P14705, DOI 10.1007/s11042-017-5056-4
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Joo JC, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/249826
   Joo S, 2002, ETRI J, V24, P401, DOI 10.4218/etrij.02.0202.0502
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Lee WB, 2002, J SYST SOFTWARE, V62, P195, DOI 10.1016/S0164-1212(01)00142-X
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   WESTFELD A, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu NI, 2010, J INTERNET TECHNOL, V11, P1071
   Yang CH, 2006, P INT COMP S
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Yang Sheng-Kai, 2012, J CHUNG CHENG I TECH, V41, P89
   Yang SK, 2011, J INFORM ELECT, V4, P43
NR 32
TC 21
Z9 22
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12157
EP 12181
DI 10.1007/s11042-018-6766-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900049
DA 2024-07-18
ER

PT J
AU Liu, L
   Zhang, JH
   Fu, XD
   Liu, LJ
   Huang, QS
AF Liu, Li
   Zhang, Jianhong
   Fu, Xiaodong
   Liu, Lijun
   Huang, Qingsong
TI Unsupervised segmentation and elm for fabric defect image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fabric defect detection; Image classification; Unsupervised
   segmentation; ELM classifier; Bayesian probability fusion
ID EXTREME LEARNING-MACHINE; TEXTILE FABRICS; GABOR FILTERS; INSPECTION;
   ILLUMINATION; SYSTEM
AB In order to solve the problem of low accuracy and efficiency for surface defects in common woven fabrics, a novel fabric defect classification method is proposed based on unsupervised segmentation and ELM. The classification method is divided into four steps including defect segmentation, feature extraction, ELM classifier training, and Bayesian probability fusion. Firstly, an unsupervised segmentation is presented for the Grayscale fabric defect image after preprocessing. Secondly, geometric and texture features were extracted by using the segmented image and the undivided Grayscale image. Then, features and labels in fabric defect images are considered as training sets to train the ELM classifier. Finally, the input fabric defect image is classified by the trained ELM classifier and the Bayesian probability fusion method. Experimental results show that the proposed method can classify the fabric defect image with high accuracy and efficiency that can better meet the requirements for practical applications.
C1 [Liu, Li; Zhang, Jianhong; Liu, Lijun; Huang, Qingsong] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Yunnan, Peoples R China.
   [Fu, Xiaodong] Kunming Univ Sci & Technol, Fac Aeronaut, Kunming 650500, Yunnan, Peoples R China.
   [Fu, Xiaodong] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology; Kunming University of Science & Technology
RP Liu, L (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Yunnan, Peoples R China.
EM kmust_mary@163.com
RI Huang, Qingsong/G-6657-2015; Liu, Lijun/AAN-3748-2020; Su,
   Zhuo/AAO-4506-2020; Liu, Li/JAC-5598-2023
OI Su, Zhuo/0000-0002-6090-0110; Liu, Li/0000-0001-9685-6599
FU National Natural Science Foundation of China [61862036, 61462051,
   61462056, 81560296]; Applied Fundamental Research Project of Yunnan
   Province [2017FB097]
FX The authors would like to thank the Associate Editor and the reviewers
   for their valuable comments and suggestions on this paper. This research
   is supported by the National Natural Science Foundation of China
   (61862036, 61462051, 61462056, 81560296), the Applied Fundamental
   Research Project of Yunnan Province (2017FB097).
CR Anitha S, 2013, EVALUATION DEFECT DE
   [Anonymous], 2017, IEEE T AUTOM SCI ENG
   [Anonymous], 2005, IEEE INT C IND TECHN
   [Anonymous], 2013, INT J COMPUTER TREND
   [Anonymous], 1996, TILDA TEXTILE TEXTUR
   Banumathi P, 2012, STUDIAINFORMATICA II, V47, P12
   Bissi L, 2013, J VIS COMMUN IMAGE R, V24, P838, DOI 10.1016/j.jvcir.2013.05.011
   Cao J., 2015, MULTIMEDIA TOOLS APP, V76, P1
   Çelik HI, 2014, J TEXT I, V105, P575, DOI 10.1080/00405000.2013.827393
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chetverikov D, 2002, PATTERN RECOGN, V35, P2165, DOI 10.1016/S0031-3203(01)00188-1
   Cho CS, 2005, IEEE T IND ELECTRON, V52, P1073, DOI 10.1109/TIE.2005.851648
   Sa JJD, 2016, PATTERN RECOGN, V51, P395, DOI 10.1016/j.patcog.2015.09.014
   Ding Shumin, 2011, 2011 International Conference on Multimedia Technology, P2903
   El-Tokhy MS, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0305-9
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   [高晓丁 GAO Xiaoding], 2006, [纺织学报, Journal of Textile Research], V27, P26
   Ghosh A, 2011, INT J CLOTH SCI TECH, V23, P142, DOI 10.1108/09556221111107333
   Guan SQ, 2014, TEXT RES J, V84, P1018, DOI 10.1177/0040517513517964
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Hanbay K, 2016, OPTIK, V127, P11960, DOI 10.1016/j.ijleo.2016.09.110
   Hu GH, 2015, APPL OPTICS, V54, P2963, DOI 10.1364/AO.54.002963
   Hu GH, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.093107
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jia L, 2017, NEUROCOMPUTING, V238, P84, DOI 10.1016/j.neucom.2017.01.039
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jian MW, 2013, COMPUT IND, V64, P1229, DOI 10.1016/j.compind.2013.06.011
   Jing JF, 2014, J IND TEXT, V44, P40, DOI 10.1177/1528083713490002
   Kim SC, 2007, PATTERN RECOGN, V40, P1207, DOI 10.1016/j.patcog.2006.09.012
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kuo CFJ, 2003, TEXT RES J, V73, P461, DOI 10.1177/004051750307300515
   Kuo CFJ, 2016, TEXT RES J, V86, P553, DOI 10.1177/0040517514553872
   Kuo CFJ, 2012, TEXT RES J, V82, P591, DOI 10.1177/0040517511426615
   Li P, 2019, MULTIMED TOOLS APPL, V78, P99, DOI 10.1007/s11042-017-5263-z
   Li WY, 2014, J TEXT I, V105, P163, DOI 10.1080/00405000.2013.833689
   Li YD, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2452-6
   Liu W, 2014, PROC CVPR IEEE, P3826, DOI 10.1109/CVPR.2014.483
   Lu B, 2014, INT CONF INFO SCI, P381, DOI 10.1109/ICIST.2014.6920407
   Mottalib MM, 2015, INT CONF ADV ELECTR, P137, DOI 10.1109/ICAEE.2015.7506815
   Ng MK, 2014, IEEE T AUTOM SCI ENG, V11, P943, DOI 10.1109/TASE.2014.2314240
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Rong HJ, 2008, IEEE IJCNN, P1709, DOI 10.1109/IJCNN.2008.4634028
   Sakhare K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P640, DOI 10.1109/IIC.2015.7150820
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Yildiz K, 2016, J IND TEXT, V45, P780, DOI 10.1177/1528083714555777
   Yu Zhang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P635
   Zhang DW, 2015, IEEE GEOSCI REMOTE S, V12, P701, DOI 10.1109/LGRS.2014.2358994
   Zhang Y, 2010, PATTERN RECOGN LETT, V31, P2033, DOI 10.1016/j.patrec.2010.05.030
   Zhao B, 2015, INTELLIGENT CONTROL, P2167
   Zhao L.-j., 2012, ADV NEURAL NETWORKS, P10
   Zhou J, 2016, J TEXT I, V107, P800, DOI 10.1080/00405000.2015.1131440
   Zhou J, 2014, J TEXT I, V105, P223, DOI 10.1080/00405000.2013.836784
   Zhou J, 2013, TEXT RES J, V83, P1846, DOI 10.1177/0040517513478451
   Zhou J, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P21, DOI 10.1109/ICMLA.2012.13
   Zhu B, 2015, TEXT RES J, V85, P1381, DOI 10.1177/0040517514555796
NR 61
TC 25
Z9 27
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12421
EP 12449
DI 10.1007/s11042-018-6786-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900060
DA 2024-07-18
ER

PT J
AU Chen, BJ
   Yu, M
   Su, QT
   Li, LD
AF Chen, Beijing
   Yu, Ming
   Su, Qingtang
   Li, Leida
TI Fractional quaternion cosine transform and its application in color
   image copy-move forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion; Color image; Fractional cosine transform; Image forgery
   detection
ID FOURIER-TRANSFORM; WATERMARKING; INFORMATION; MOMENTS
AB In this paper, fractional quaternion cosine transforms (FrQCT) is proposed to generalize the conventional fractional cosine transforms (FrCT) to quaternion signal processing in a holistic manner. Firstly, the new transform FrQCT is defined and the proof of its inverse transform is presented. An efficient discrete implementation method of FrQCT is then proposed, in which the relationship between FrQCT and FrCT of four components is used for a quaternion signal. Finally, a new color image copy-move forgery detection algorithm based on FrQCT and modified PatchMatch matching algorithm is proposed to evaluate the performance of the proposed FrQCT. Experimental results on two public datasets (FAU dataset and GRIP dataset) demonstrate that: (a) the proposed efficient implementation method takes only half the computational time of the direct method; (b) the proposed FrQCT-based forgery detection algorithm can achieve a better performance than some state-of-the-art algorithms, especially in the additional operation case.
C1 [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Chen, Beijing; Yu, Ming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Su, Qingtang] Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Peoples R China.
   [Li, Leida] China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Ludong University; China
   University of Mining & Technology
RP Chen, BJ (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.; Chen, BJ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM nbutimage@126.com
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022
FU NSFC [61572258, 61772281, 61771231, 61602253, 61672294]; Natural Science
   Foundation of Jiangsu Province of China [BK20151530, BK20150925]; PAPD
   fund; Qing Lan Project
FX This work was supported by the NSFC under Grants 61572258, 61772281,
   61771231, 61602253, and 61672294, the Natural Science Foundation of
   Jiangsu Province of China under Grants BK20151530, and BK20150925, the
   PAPD fund, sponsored by Qing Lan Project.
CR Amer YA, 2018, CMC-COMPUT MATER CON, V54, P161, DOI 10.3970/cmc.2018.054.161
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bi XL, 2017, INFORM SCIENCES, V418, P531, DOI 10.1016/j.ins.2017.08.044
   Bi XL, 2016, IEEE TRUST, P952, DOI [10.1109/TrustCom.2016.0161, 10.1109/TrustCom.2016.159]
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chen BJ, 2018, MULTIMED TOOLS APPL, V77, P20809, DOI 10.1007/s11042-017-5511-2
   Chen BJ, 2017, J VIS COMMUN IMAGE R, V49, P283, DOI 10.1016/j.jvcir.2017.08.011
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   CHEN BJ, 1994, TSP, V63, P5424, DOI DOI 10.1109/TSP.2015.2451107
   Choi JY, 2009, IEEE T SYST MAN CY B, V39, P1217, DOI 10.1109/TSMCB.2009.2014245
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   ELL TA, 1935, TIP, V16, P22, DOI DOI 10.1109/TIP.2006.884955
   Feng W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P252, DOI 10.1109/CISP.2008.61
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Guo LQ, 2012, OPT EXPRESS, V20, P18846, DOI 10.1364/OE.20.018846
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Li C, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P5, DOI 10.1145/3007669.3007689
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li YN, 2013, IEEE SIGNAL PROC LET, V20, P803, DOI 10.1109/LSP.2013.2267775
   Liu ZJ, 2005, OPT COMMUN, V255, P357, DOI 10.1016/j.optcom.2005.06.031
   Luo WQ, 2006, INT C PATT RECOG, P746
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Mendlovic D, 1997, APPL OPTICS, V36, P4801, DOI 10.1364/AO.36.004801
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P1198, DOI 10.1109/78.923302
   PEI SC, 1980, TSP, V50, P1661, DOI DOI 10.1109/TSP.2002.1011207
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang YQ, 2016, J APPL GEOPHYS, V129, P8, DOI 10.1016/j.jappgeo.2016.03.011
   Wei DY, 2013, OPTIK, V124, P6999, DOI 10.1016/j.ijleo.2013.05.163
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Xu GL, 2008, SIGNAL PROCESS, V88, P2511, DOI 10.1016/j.sigpro.2008.04.012
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
NR 47
TC 26
Z9 26
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8057
EP 8073
DI 10.1007/s11042-018-6595-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800010
DA 2024-07-18
ER

PT J
AU Fotouhi, M
   Hekmatian, H
   Kashani-Nezhad, MA
   Kasaei, S
AF Fotouhi, Mehran
   Hekmatian, Hamid
   Kashani-Nezhad, Mohammad Amin
   Kasaei, Shohreh
TI SC-RANSAC: Spatial consistency on RANSAC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust estimation; Outlier detection; RANSAC; PROSAC; SCRAMSAC
ID EPIPOLAR GEOMETRY; SAMPLE; CONSENSUS
AB The goal of robust parameter estimation is developing a model which can properly fit to data. Parameter estimation of a geometric model, in presence of noise and error, is an important step in many image processing and computer vision applications. As the random sample consensus (RANSAC) algorithm is one of the most well-known algorithms in this field, there have been several attempts to improve its performance. In this paper, after giving a short review on existing methods, a robust and efficient method that detects the gross outliers to increase the inlier to outlier ratio in a reduced set of corresponding image points is proposed. It has a new hypothesis and verification scheme which utilizes spatial relations between extracted corresponding points in two images. It can also be considered as a preprocessing step for RANSAC to improve the accuracy as well as the runtime of RANSAC in estimating the parameters of a geometric model (such as fundamental and homography matrices). Obviously, like almost all previous works for enhancing RANSAC's runtime, the proposed method does not use heavy and compilicated processes. Performance analysis is performed on a variety of standard challenging datasets for estimating the homography and fundamental matrix (as an applicable case used in the literature, especially in the state-of-the-art methods). The performance is also compared quantitatively to RANSAC, PROSAC, and SCRAMSAC robust estimators to demonstrate its superiority. Experimental results show that the proposed method removes about 50% of outliers in most cases and hence extremely reduces the required runtime of RANSAC, while improving its accuracy.
C1 [Fotouhi, Mehran; Hekmatian, Hamid; Kashani-Nezhad, Mohammad Amin; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM fotouhi@ce.sharif.edu; hekmatian@ce.sharif.edu; kashani@ce.sharif.edu;
   skasaei@sharif.edu
RI Kasaei, Shohreh/AAD-5618-2019
OI Kasaei, Shohreh/0000-0002-3831-0878
FU Iran national science foundation (INSF)
FX The authors would like to thank Mr. Afshin Bozorgpour, and Mrs. Sara
   Monji-azad for their valuable comments and suggestions to improve the
   work. Special thanks to Fabio Bellavia for providing us with the codes
   of PROSAC and SCRAMSAC. This work has been partly supported by a grant
   from Iran national science foundation (INSF).
CR [Anonymous], BMVC
   [Anonymous], 2019, BMVC 2009
   [Anonymous], 2006, CVPR
   Barcomb A., 2014, PATT REC REM SENS PR, P1
   Bellavia F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.98
   Chin TJ, 2012, IEEE T PATTERN ANAL, V34, P625, DOI 10.1109/TPAMI.2011.169
   Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150
   Chin TJ, 2010, LECT NOTES COMPUT SC, V6315, P533, DOI 10.1007/978-3-642-15555-0_39
   Choi J, 2009, PROC CVPR IEEE, P675, DOI 10.1109/CVPRW.2009.5206678
   Choi S., 1997, J COMPUT VIS, V24, P271, DOI [10.1023/A:1007927408552, DOI 10.1023/A:1007927408552]
   Chum O, 2005, PROC CVPR IEEE, P772
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Chum O., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P623
   Ciobanu L, 2011, MULTIMED TOOLS APPL, V55, P557, DOI 10.1007/s11042-010-0565-4
   Kang ZZ, 2014, IEEE GEOSCI REMOTE S, V11, P1096, DOI 10.1109/LGRS.2013.2286856
   Konouchine A., 2005, P GRAPH NOV RUSS JUN, P93
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2005, IEEE I CONF COMP VIS, P1727
   Meler A, 2010, BRIT MACH VIS C 2010
   Mittal S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2689, DOI 10.1109/CVPR.2011.5995514
   Monji-Azad S, 2014, IRAN CONF ELECTR ENG, P1064, DOI 10.1109/IranianCEE.2014.6999693
   Nasuto D, NAPSAC HIGH NOISE HI
   Ni K, 2009, IEEE I CONF COMP VIS, P2193, DOI 10.1109/ICCV.2009.5459241
   Otte S, 2014, INT C PATT RECOG, P3558, DOI 10.1109/ICPR.2014.612
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Rodehorst V., 2006, COMPUTER VISION PATT, P103, DOI DOI 10.1109/CVPRW.2006.88
   Sattler T, 2009, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2009.5459459
   Subbarao R, 2006, LECT NOTES COMPUT SC, V3951, P301
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087
   Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098
   TORR PHS, 1993, P SOC PHOTO-OPT INS, V2059, P432, DOI 10.1117/12.150246
   Trivedi P, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1380, DOI 10.1109/ICACCI.2013.6637380
   Tuytelaars Tinne, 2000, BMVC, V412
   Wang X. F., 2013, YANGTZE RIVER, V2013, P1, DOI DOI 10.1117/1.JRS.7.073519
   Yan W, CANONICAL CORRELATIO
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
   Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263
NR 42
TC 21
Z9 24
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9429
EP 9461
DI 10.1007/s11042-018-6475-6
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800080
DA 2024-07-18
ER

PT J
AU Liao, YW
   Chen, MJ
   Yeh, CH
   Lin, JR
   Chen, CW
AF Liao, Yi-Wen
   Chen, Mei-Juan
   Yeh, Chia-Hung
   Lin, Jie-Ru
   Chen, Chih-Wei
TI Efficient inter-prediction depth coding algorithm based on depth map
   segmentation for 3D-HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; Depth coding; Inter prediction; Automatic thresholding
ID PARALLEL FRAMEWORK; VIDEO; DECISION
AB The 3D extension of High Efficiency Video Coding (3D-HEVC) is the latest international 3D video coding standard, which enhances the compression efficiency of 3D videos with multi-view plus depth (MVD) format. However, it is at the cost of increasing coding complexity. Therefore, this paper proposes a fast inter-prediction algorithm based on depth segmentation for the depth coding of 3D-HEVC to reduce the coding complexity of the depth map. We aim to reduce the coding time by efficiently utilizing the properties of the depth map. First, the proposed algorithm divides a depth map into background, middle ground and foreground, based on automatic thresholding technique. Then, we adjust the search range according to the classification of the coding tree unit (CTU). In addition, an early termination decision by utilizing the correlation of spatial, temporal, and inter-view neighboring CTUs and a fast prediction unit mode decision are also proposed to reduce coding time. The experimental results show that the proposed algorithm can reduce the depth coding time and still maintain good video quality.
C1 [Liao, Yi-Wen; Chen, Mei-Juan; Lin, Jie-Ru; Chen, Chih-Wei] Natl Dong Hwa Univ, Dept Elect Engn, Hualien, Taiwan.
   [Yeh, Chia-Hung] Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.
   [Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 National Dong Hwa University; National Taiwan Normal University;
   National Sun Yat Sen University
RP Yeh, CH (corresponding author), Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.; Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
EM chyeh@ntnu.edu.tw
OI Chen, Mei-Juan/0000-0003-3382-8296
FU Ministry of Science and Technology, Taiwan, R.O.C. [MOST
   103-2221-E-259-009-MY3, MOST 107-2218-E-003-003-, MOST
   107-2218-E-110-004-, MOST 105-2221-E-110-094-MY3, MOST
   106-2221-E-110-083-MY2, MOST 105-2221-E-259-016-MY3]
FX The authors would like to thank the Ministry of Science and Technology,
   Taiwan, R.O.C. for financially supporting this research under contract
   NO. MOST 103-2221-E-259-009-MY3, MOST 107-2218-E-003-003-, MOST
   107-2218-E-110-004-, MOST 105-2221-E-110-094-MY3, MOST
   106-2221-E-110-083-MY2 and MOST 105-2221-E-259-016-MY3.
CR Bjontegaard G., 2008, VCEGAI11
   Bjotegaard G., 2001, VCEGM33
   Chen B, 2017, P 2017 IEEE 36 INT P
   Chen M, 2016, OPTIK, V127, P4758, DOI 10.1016/j.ijleo.2016.01.204
   Chen Y, 2015, JCT3V
   Chi GS, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P374, DOI 10.1109/VCIP.2014.7051584
   Cho H, 2014, LECT NOTES COMPUT SC, V8690, P189, DOI 10.1007/978-3-319-10605-2_13
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P2276, DOI 10.1109/TPAMI.2010.55
   Lin JL, 2013, IEEE J-STSP, V7, P957, DOI 10.1109/JSTSP.2013.2271975
   Merkle P, 2007, P 2007 IEEE INT C IM, V1, pI
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Samii A, 2011, CS281A STAT LEARNING, P1
   Shen LQ, 2014, MULTIMED TOOLS APPL, V72, P1639, DOI 10.1007/s11042-013-1455-3
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu YD, 2015, P 2015 NAT S TEL NST
   Yan C, 2018, IEEE Transactions on Multimedia
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang N, 2014, SIGNAL PROCESS-IMAGE, V29, P951, DOI 10.1016/j.image.2014.06.003
   Zhang Q, 2014, J DIABETES RES, V2014, DOI 10.1155/2014/862473
   Zhang XY, 2017, INT CONF ACOUST SPEE, P1957, DOI 10.1109/ICASSP.2017.7952498
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P1101, DOI 10.1007/s11042-015-3109-0
   Zheng YJ, 2013, IEEE T PATTERN ANAL, V35, P1480, DOI 10.1109/TPAMI.2012.210
NR 31
TC 9
Z9 12
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10181
EP 10205
DI 10.1007/s11042-018-6547-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400032
DA 2024-07-18
ER

PT J
AU Tan, L
   Liu, WQ
   Li, L
   Pan, ZK
AF Tan, Lu
   Liu, Wanquan
   Li, Ling
   Pan, Zhenkuan
TI A fast computational approach for illusory contour reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illusory contour capture; Variational level set formulation; Alternating
   direction method of multipliers (ADMM); Projection method; Fast Fourier
   transform (FFT)
ID PARALLEL FRAMEWORK
AB Illusory contour reconstruction can be modeled as a minimization problem with a tractable variational level set formulation, utilizing Euler's elastica to reconstruct the illusory boundaries. However, this kind of formulation is very difficult to solve numerically as it is hard to implement such optimization algorithms efficiently in practice. In this paper, we propose an equivalently reduced variational level set formulation by taking the level set functions as signed distance functions. Technically, an alternating direction method of multipliers (ADMM) is developed by introducing some auxiliary variables, Lagrange multipliers and applying an alternating optimization strategy. With the proposed ADMM method, the minimization problem can be transformed into a series of sub-problems, which can be solved easily via using the Gauss-Seidel iterations and Fast Fourier Transform (FFT). The corresponding level set functions are regarded as signed distance functions during computation process using a simple algebraic projection method, which avoids the traditional re-initialization process for conventional level set functions. Extensive experiments have been conducted on both synthetic and real images, which validated the proposed approach, and demonstrated the advantages of the proposed ADMM-Projection (ADMM-P) method over the existing algorithms based on traditional gradient descent method (GDM) in terms of computational efficiency.
C1 [Tan, Lu; Liu, Wanquan; Li, Ling] Curtin Univ, Dept Comp, Perth, WA, Australia.
   [Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Shandong, Peoples R China.
C3 Curtin University; Qingdao University
RP Tan, L (corresponding author), Curtin Univ, Dept Comp, Perth, WA, Australia.
EM lu.tan1@postgrad.curtin.edu.au; w.liu@curtin.edu.au; l.li@curtin.edu.au;
   zkpan@126.com
RI zhu, yujie/KBC-4009-2024; Zhao, YuHan/KIE-0813-2024; Huang,
   Liping/KIB-4430-2024
OI liu, wanquan/0000-0003-4910-353X; Li, Ling/0000-0001-9722-9503
FU National Natural Science Foundation of China [61602321, 61305045,
   61363066, 61303079]
FX The work has been partially supported by research funds from the
   National Natural Science Foundation of China with grant Nos.61602321,
   61305045, 61363066 and 61303079.
CR Amer MR, 2015, INT J COMPUT VISION, V112, P23, DOI 10.1007/s11263-014-0752-2
   [Anonymous], 1979, Organization in vision
   [Anonymous], 2015, ARXIV151106324
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2017, J VISUAL-JAPAN, DOI DOI 10.1167/17.10.569
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P161, DOI 10.1109/VLSM.2001.938895
   Chen K, 2005, 0526 UCLA CAM
   Fang Yang, 2018, Energy Minimization Methods in Computer Vision and Pattern Recognition. 11th International Conference, EMMCVPR 2017. Revised Selected Papers: LNCS 10746, P485, DOI 10.1007/978-3-319-78199-0_32
   Geiger D, 1998, PROC CVPR IEEE, P118, DOI 10.1109/CVPR.1998.698597
   Glowinski R, 2016, 1610 UCLA CAM
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P123, DOI 10.1007/s11042-015-3009-3
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   Jung YM, 2008, J VIS COMMUN IMAGE R, V19, P42, DOI 10.1016/j.jvcir.2007.07.001
   Kang SH, 2014, SIAM J IMAGING SCI, V7, P1907, DOI 10.1137/140959043
   KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D
   Li CM, 2005, PROC CVPR IEEE, P430
   Loreti P, 2000, EUR J APPL MATH, V11, P203, DOI 10.1017/S0956792599004131
   Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815
   MUMFORD D., 1994, ALGEBRAIC GEOMETRY I, P491, DOI DOI 10.1007/978-1-4612-2628-4_31
   MYLLYKOSKI M, 1925, SCIENCES, V8, P95, DOI DOI 10.1137/140962164
   Nitzberg M, 1990, P 3 IEEE INT C COMP, p[691, 138]
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Poscoliero T, 2017, ELECTROPHYSIOLOGICAL, P1
   Ringach DL, 1996, VISION RES, V36, P3037, DOI 10.1016/0042-6989(96)00062-4
   SAMSON C, 1999, MULTIPHASE EVOLUTION
   SARTI A, 2012, INT J COMPUT VISION, V46, P201
   SARTI A, 1963, PROC NATL ACAD SCI, V97, P6258
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Sussman M, 1999, SIAM J SCI COMPUT, V20, P1165, DOI 10.1137/S1064827596298245
   Tai XC, 2014, 1440 UCLA CAM
   Tai XC, 2011, SIAM J IMAGING SCI, V4, P313, DOI 10.1137/100803730
   Tan L, 2018, APPL MATH MODEL, V61, P280, DOI 10.1016/j.apm.2018.04.017
   Tan L, 2018, J MATH IMAGING VIS, V60, P1, DOI 10.1007/s10851-017-0735-3
   Xiaolei Jiang, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P190, DOI 10.1007/978-3-319-03731-8_18
   Yan C, 2018, IEEE Transactions on Multimedia
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   YANG F, 1984, SOFTWARE, V29, P274, DOI DOI 10.1080/10556788.2013.788650
   Yashtini M, 2015, ALTERNATING DIRECTIO, P690
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhao HK, 2005, MATH COMPUT, V74, P603
   Zhu W, 2007, J MATH IMAGING VIS, V27, P29, DOI 10.1007/s10851-006-9695-8
   Zhu W, 2006, SIAM J SCI COMPUT, V28, P1957, DOI 10.1137/050622213
   Zhu W, 2013, INVERSE PROBL IMAG, V7, P1409, DOI 10.3934/ipi.2013.7.1409
   Zhu W, 2013, J SCI COMPUT, V57, P414, DOI 10.1007/s10915-013-9710-3
   Zhu W, 2012, SIAM J IMAGING SCI, V5, P1, DOI 10.1137/110822268
NR 51
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10449
EP 10472
DI 10.1007/s11042-018-6546-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400041
DA 2024-07-18
ER

PT J
AU Wang, YQ
   Zhou, LK
   Wang, NB
AF Wang, Yingqi
   Zhou, Lianke
   Wang, Nianbin
TI Summarizing database schema based on graph partition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph partition; Relational database; Schema summarization; Spectral
   clustering
ID PARALLEL FRAMEWORK; SEMANTICS
AB As the underlying database schemas become larger and more complex, it is difficult for casual users to understand the schemas and contents of databases. Therefore, it has become an essential task to summarize the database schemas. However, most prior approaches pay little attention to the topological characteristics between tables, ignore the effect of the user feedback, and fail to accurately predict the number of clusters in the output. This seriously limits their accuracy of schema summarization. To deal with the problems, we propose a new schema summarization method based on a graph partition mechanism. First, we introduce a novel strategy to construct a similarity matrix between tables, which is based on the topology compactness, content similarity and query logs. Then we provide a calculation formula for table importance and a detection scheme of the most important nodes in local areas. Both are used for selecting the initial cluster centers and predicting the number of clusters in the graph partition mechanism. Finally, we evaluate the proposed method over the database TPC-E, and results demonstrate that it achieves high performance in summarizing accuracy.
C1 [Wang, Yingqi; Zhou, Lianke; Wang, Nianbin] Harbin Engn Univ, Coll Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Zhou, LK (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
EM zhoulianke@hrbeu.edu.cn
RI wang, yq/GWM-9918-2022
FU National Natural Science Foundation of China [61772152, 61502037]; Basic
   Research Project [JCKY2016206B001, JCKY2014206C002, JCKY2017604C010]
FX This work is sponsored by the National Natural Science Foundation of
   China under Grant No. 61772152 and 61502037, and the Basic Research
   Project (No. JCKY2016206B001, JCKY2014206C002 and JCKY2017604C010).
CR Alborzi F, 2015, LECT NOTES COMPUT SC, V9263, P3, DOI 10.1007/978-3-319-22729-0_1
   [Anonymous], P 32 INT C VER LARG
   [Anonymous], 2007, Proceedings of the 2007 ACM SIGMOD international conference on Management of data
   [Anonymous], 2009, P VLDB ENDOW, DOI DOI 10.14778/1687627.1687699
   Beneventano D, 2017, 2017 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P70, DOI 10.1109/HPCS.2017.21
   Bergamaschi S, 2016, J DATA SEMANT, V5, P211, DOI 10.1007/s13740-016-0063-6
   Bergamaschi Sonia., 2013, Bridging Between Information Retrieval and Databases - PROMISE Winter School 2013, Bressanone, Italy, February 4-8, P54
   Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X
   Dimitroff G, 2015, MACH LEARN, V98, P435, DOI 10.1007/s10994-014-5439-y
   Kahng M, 2016, PROC VLDB ENDOW, V9, P1017
   Kargar M, 2015, PROC INT CONF DATA, P411, DOI 10.1109/ICDE.2015.7113302
   Kruse S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2483, DOI 10.1145/3132847.3133180
   Liu DJ, 2017, INT J COMPUT SCI ENG, V14, P359, DOI 10.1504/IJCSE.2017.10005756
   Sampaio M, 2013, ADV INTELL SYST, V186, P217
   Taheriyan M, 2016, J WEB SEMANT, V37-38, P152, DOI 10.1016/j.websem.2015.12.003
   Troullinou G, 2015, LECT NOTES COMPUT SC, V9088, P119, DOI 10.1007/978-3-319-18818-8_8
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   van Gennip Y, 2013, SIAM J APPL MATH, V73, P67, DOI 10.1137/120882093
   Wang N, 2016, INT J SOFTW ENG KNOW, V26, P691, DOI 10.1142/S0218194016500224
   Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9
   Wang X, 2012, J COMPUT SCI TECH-CH, V27, P515, DOI 10.1007/s11390-012-1240-1
   Wang Z., 2014, International Journal of Hybrid Information Technology, V7, P1
   Wu W., 2008, SIGMOD, P1019
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan N, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1797, DOI 10.1145/2882903.2915221
   Yang XY, 2011, PROC VLDB ENDOW, V4, P899
   Yuan XJ, 2014, LECT NOTES COMPUT SC, V8709, P258, DOI 10.1007/978-3-319-11116-2_23
NR 30
TC 0
Z9 0
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10077
EP 10096
DI 10.1007/s11042-018-6543-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400027
DA 2024-07-18
ER

PT J
AU Engin, MA
   Cavusoglu, B
AF Engin, M. Alptekin
   Cavusoglu, Bulent
TI Rotation invariant curvelet based image retrieval & classification via
   Gaussian mixture model and co-occurrence features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Curvelet transform; Image retrieval; Image classification
ID TEXTURE; TRANSFORM
AB Demand for better retrieval methods continue to outstrip the capabilities of available technologies despite the rapid growth of new feature extraction techniques. Extracting discriminatory features that contain texture specific information are of crucial importance in image indexing. This paper presents a novel rotation invariant texture representation model based on the multi-resolution curvelet transform via co-occurrence and Gaussian mixture features for image retrieval and classification. To extract these features, curvelet transform is applied and the coefficients are obtained at each scale and orientation. The Gaussian mixture model (GMM) features are computed from each of the sub bands and co-occurrence features are computed for only specific sub band. Rotation invariance is provided by applying cycle-shift around the GMM features. The proposed method is evaluated on well-known databases such as Brodatz, Outex_TC_00010, Outex_TC_00012, Outex_TC_00012horizon, Outex_TC_00012tl84, Vistex and KTH-TIPS. When the feature vector is analyzed in terms of its size, it is observed that its dimension is smaller than that of the existing rotation-invariant variants and it has a very good performance. Simulation results show a good performance achieved by combining different techniques with the curvelet transform. Proposed method results in high degree of success rate in classification and in precision-recall value for retrieval.
C1 [Engin, M. Alptekin] Bayburt Univ, Fac Engn, Dept Elect & Elect Engn, TR-69000 Bayburt, Turkey.
   [Cavusoglu, Bulent] Ataturk Univ, Fac Engn, Dept Elect & Elect Engn, TR-25240 Erzurum, Turkey.
C3 Bayburt University; Ataturk University
RP Cavusoglu, B (corresponding author), Ataturk Univ, Fac Engn, Dept Elect & Elect Engn, TR-25240 Erzurum, Turkey.
EM maengin@bayburt.edu.tr; bulent.cavusoglu@gmail.com
RI Cavusoglu, Bulent/F-4832-2011
CR [Anonymous], 2006, P EUR C COMP VIS
   Arivazhagan S, 2006, INT C PATT RECOG, P938
   Bapat Malao S, 2013, INT J EMERG TRENDS T, V2
   Brilakis IK, 2006, ADV ENG INFORM, V20, P443, DOI 10.1016/j.aei.2006.03.001
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candes E. J., 2002, TECHNICAL REPORT
   Candes E.J., 1998, EJ RID THER AND APP
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P162, DOI 10.1016/j.acha.2005.02.003
   Candès EJ, 2005, APPL COMPUT HARMON A, V19, P198, DOI 10.1016/j.acha.2005.02.004
   Candès EJ, 1999, APPL COMPUT HARMON A, V6, P197, DOI 10.1006/acha.1998.0248
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cavusoglu B, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-22
   Chun J, 2013, APPL MECH MATER, V333-335, P822, DOI 10.4028/www.scientific.net/AMM.333-335.822
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Gasteratos A, 2004, LECT NOTES COMPUT SC, V3025, P63
   Gómez F, 2011, PATTERN RECOGN LETT, V32, P2178, DOI 10.1016/j.patrec.2011.09.029
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Iqbal K, 2012, J COMPUT SYST SCI, V78, P1258, DOI 10.1016/j.jcss.2011.10.013
   Kaushik M., 2012, INT J COMPUT APPL, V54, P11
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Li YC, 2010, EXPERT SYST APPL, V37, P3063, DOI 10.1016/j.eswa.2009.09.024
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   MIKOLAJCZYK K, 2003, P COMP VIS PATT REC
   Müller H, 2009, INT J MED INFORM, V78, P638, DOI 10.1016/j.ijmedinf.2009.05.001
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Rajlaxmi N, 2015, SSRG INT J ELECT COM, V2
   Shen LR, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P319
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   TAN TN, 1995, P SOC PHOTO-OPT INS, V2488, P475, DOI 10.1117/12.212001
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
NR 40
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6581
EP 6605
DI 10.1007/s11042-018-6368-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700008
DA 2024-07-18
ER

PT J
AU Singh, J
   Goyal, G
   Gupta, S
AF Singh, Jaiteg
   Goyal, Gaurav
   Gupta, Sahil
TI FADU-EV an automated framework for pre-release emotive analysis of
   theatrical trailers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dlib-ml; Emotive response; Social media; Machine learning; Movie trailer
   release; SVM
ID SOCIAL MEDIA; BUSINESS; KNOWLEDGE; EVENT
AB Release of a theatrical movie trailer is a major marketing practice and a considerable cost is associated with it. Evaluating the effectiveness of a theatrical movie trailer before its release could substantially contribute towards enriching its contents and economic value. The relationship between the emotional responses generated in response to a movie trailer cannot be effectively measured using traditional methods such as surveys and interviews. This paper proposes a framework to measure the effectiveness of movie trailers by measuring emotive response of viewers. A case study was conducted to study the impact of a movie trailer release on stock value of movie using virtual stock markets. Further, the case study investigated the impact of emotionally intense movie trailer over its stock price. Based on emotive content of trailers, few of the movie stocks experienced a surge of two hundred and 50 % while others experienced a marginal rise of five to 10 % only. The observed results indicated a direct relation between release of movie trailer, its emotive content and abnormal positive returns of a movie stock.
C1 [Singh, Jaiteg] Chitkara Univ, Inst Engn & Technol, Dept Comp Applicat, Rajpura, India.
   [Goyal, Gaurav] Chitkara Univ, Dept Comp Sci & Engn, Inst Engn & Technol, Rajpura, India.
   [Gupta, Sahil] Chitkara Univ, Chitkara Business Sch, Rajpura, India.
C3 Chitkara University, Punjab; Chitkara University, Punjab; Chitkara
   University, Punjab
RP Singh, J (corresponding author), Chitkara Univ, Inst Engn & Technol, Dept Comp Applicat, Rajpura, India.
EM jaitegkhaira@gmail.com
RI Khaira, Jaiteg Singh/AFD-9547-2022; Gupta, Sahil/AAW-6312-2021
OI Gupta, Sahil/0000-0003-3342-5382; Singh, Jaiteg/0000-0002-2370-9384
CR Adolphs Ralph, 2002, Behav Cogn Neurosci Rev, V1, P21, DOI 10.1177/1534582302001001003
   Agrawal M, 2006, INFORM MANAGE-AMSTER, V43, P861, DOI 10.1016/j.im.2006.08.002
   [Anonymous], 2012, J BUSINESS EC RES
   [Anonymous], J CONSUM RES INC
   [Anonymous], HSX COM HELP WHAT IS
   [Anonymous], INFORMS
   [Anonymous], J ADVERT RES
   [Anonymous], WHY MOVIES COST SO M
   [Anonymous], 2016 MED TECHN NAT C
   [Anonymous], 1977, HUMAN EMOTIONS
   Aurtenechea S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P901, DOI 10.1109/ISIE.2007.4374717
   Bakardjieva E, 2017, ETHICS BEHAV, V27, P179, DOI 10.1080/10508422.2016.1162719
   Bertero D., 2016, P 2016 C EMP METH NA, P1042, DOI DOI 10.18653/V1/D16-1110
   Bhargava HK, 2007, DECIS SUPPORT SYST, V43, P1083, DOI 10.1016/j.dss.2005.07.002
   Carlson N.R., 2010, Psychology the Science of Behaviour, P20
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen YL, 2017, DECIS SUPPORT SYST, V101, P40, DOI 10.1016/j.dss.2017.05.014
   Devlin MB, 2011, J BROADCAST ELECTRON, V55, P581, DOI 10.1080/08838151.2011.620668
   Drozdova N., 2014, Measuring Emotions in Marketing and Consumer Behavior: Is Face Reader an applicable tool?
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Elberse A, 2007, J MARKETING, V71, P102, DOI 10.1509/jmkg.71.4.102
   Elberse A, 2007, INF ECON POLICY, V19, P319, DOI 10.1016/j.infoecopol.2007.06.003
   FABER RJ, 1984, JOURNALISM QUART, V61, P371, DOI 10.1177/107769908406100219
   FAMA EF, 1991, J FINANC, V46, P1575, DOI 10.2307/2328565
   Gruca Thomas., 2000, J MARKET EDUC, V22, P5, DOI DOI 10.1177/0273475300221002
   Harrysson M., 2012, McKinsey Quarterly, P81
   Hazlett RL, 1999, J ADVERTISING RES, V39, P7
   Joshi AM, 2009, MARKET SCI, V28, P239, DOI 10.1287/mksc.1080.0392
   Karray S, 2017, INT J ADVERT, V36, P368, DOI 10.1080/02650487.2015.1090521
   Kearns GS, 2006, J MANAGE INFORM SYST, V23, P129, DOI 10.2753/MIS0742-1222230306
   Kernan L., 2004, COMING ATTRACTIONS R
   King DE, 2009, J MACH LEARN RES, V10, P1755
   MacKinlay AC, 1997, J ECON LIT, V35, P13
   McDuff D, 2017, IEEE T AFFECT COMPUT, V8, P148, DOI 10.1109/TAFFC.2016.2571284
   Mcduff D, 2013, INT CONF AFFECT, P369, DOI 10.1109/ACII.2013.67
   MEHRABIAN A, 1968, J CONSULT CLIN PSYCH, V32, P296, DOI 10.1037/h0025906
   Meredith R, 2011, J DECIS SYST, V20, P263, DOI 10.3166/jds.20.263-282
   Osgood CE, 1975, Cross-Cultural Universals of Affective Meaning
   Pham P, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P67, DOI 10.1145/3025171.3025186
   Poels K, 2006, J ADVERTISING RES, V46, P18, DOI 10.2501/S0021849906060041
   Power DJ, 2011, J DECIS SYST, V20, P249, DOI 10.3166/jds.20.249-261
   Ruth JA, 2002, J ACAD MARKET SCI, V30, P44, DOI 10.1177/03079459994317
   Schniederjans D, 2013, DECIS SUPPORT SYST, V55, P911, DOI 10.1016/j.dss.2012.12.027
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Solomon Robert.C., 2008, HDB EMOTIONS
   Spann M, 2003, MANAGE SCI, V49, P1310, DOI 10.1287/mnsc.49.10.1310.17314
   Stapleton C., 2005, Proceedings of 2005 International Conference on Human-Computer Interface Advances in Modeling and Simulation (SIMCHI'05), P23
   Tarvainen MP, 2001, IEEE T BIO-MED ENG, V48, P1071, DOI 10.1109/10.951509
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791
   Wiles MA, 2009, J MARKETING, V73, P44, DOI 10.1509/jmkg.73.4.44
   Wyer RS, 2002, ADV EXP SOC PSYCHOL, V34, P131, DOI 10.1016/S0065-2601(02)80005-3
NR 56
TC 5
Z9 6
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7207
EP 7224
DI 10.1007/s11042-018-6412-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700036
DA 2024-07-18
ER

PT J
AU Abdel-Basset, M
   Wang, GG
   Sangaiah, AK
   Rushdy, E
AF Abdel-Basset, Mohamed
   Wang, Gai-Ge
   Sangaiah, Arun Kumar
   Rushdy, Ehab
TI Krill herd algorithm based on cuckoo search for solving engineering
   optimization problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elitism scheme; Krill herd; Levy flight distribution; Engineering design
   problems
ID PARTICLE SWARM OPTIMIZATION; GLOBAL HARMONY SEARCH; DIFFERENTIAL
   EVOLUTION; DESIGN; SIMULATION; SELECTION; INTEGER; MOTION; MODEL
AB This paper presents a hybrid krill herd (CSKH) approach to solve structural optimization problems. CSKH improved the Krill herd algorithm (KH) by combining KU/KA operator originated from cuckoo search algorithm (CS) with KH. In CSKH, a greedy selection scheme is used and often overtakes the original KH and CS. In addition, in order to further enhance the assessment of CSKH, a fraction of the worst krill is thrown away and substituted with newly randomly generated ones by KA operator at the end of each generation. The CSKH is applied to five real engineering problems to verify its performance. The experimental results have proven that CSKH algorithm is well capable of solving constrained engineering design problems more efficiently and effectively than the basic CS and KH algorithm.
C1 [Abdel-Basset, Mohamed] Zagazig Univ, Dept Operat Res, Fac Comp & Informat, Zagazig, Egypt.
   [Wang, Gai-Ge] Jiangsu Normal Univ, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Rushdy, Ehab] Zagazig Univ, Dept Informat Technol, Fac Comp & Informat, Zagazig, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Jiangsu Normal
   University; Vellore Institute of Technology (VIT); VIT Vellore; Egyptian
   Knowledge Bank (EKB); Zagazig University
RP Abdel-Basset, M (corresponding author), Zagazig Univ, Dept Operat Res, Fac Comp & Informat, Zagazig, Egypt.
EM analyst_mohamed@yahoo.com; gaigewang@gmail.com; sarunkumar@vit.ac.in;
   ehab.rushdy@gmail.com
RI Wang, Gai-Ge/B-6060-2019; Sangaiah, Arun Kumar/U-6785-2019;
   Abdel-Basset, Mohamed/AAH-2833-2019
OI Wang, Gai-Ge/0000-0002-3295-8972; Sangaiah, Arun
   Kumar/0000-0002-0229-2460; Abdel-Basset, Mohamed/0000-0003-1102-1387
FU Natural Science Foundation of Jiangsu Province [BK20150239]; National
   Natural Science Foundation of China [61503165, 61673196, 61402207]; Open
   Research Fund of Sichuan Key Laboratory for Nature Gas and Geology
   [2015trqdz04]
FX This work was supported by the Natural Science Foundation of Jiangsu
   Province (No. BK20150239), National Natural Science Foundation of China
   (No. 61503165, No. 61673196, and No. 61402207), and The Open Research
   Fund of Sichuan Key Laboratory for Nature Gas and Geology (No.
   2015trqdz04).
CR Abdel-Baset M., 2015, Adv Eng Technol Appl, P27
   Abdel-Baset M., 2016, Int J Comput Appl, V140, P10, DOI DOI 10.5120/IJCA2016909119
   Abdel-Baset M., 2015, ASIAN J MATH COMPUTE, V3, P194
   Abdel-Baset M, 2016, INT J BIO-INSPIR COM, V8, P215, DOI 10.1504/IJBIC.2016.078662
   Abdel-Basset M, 2018, NEURAL COMPUT APPL, V29, P345, DOI 10.1007/s00521-016-2464-8
   Abdel-Raouf Osama, 2014, International Journal of Modern Education and Computer Science, V6, P18, DOI 10.5815/ijmecs.2014.08.03
   Abdel-Raouf Osama, 2014, International Journal of Modern Education and Computer Science, V6, P38, DOI 10.5815/ijmecs.2014.03.05
   ABDELBASET M, 2015, APPL MATH INFORM SCI, V3, P83
   Ahirwal MK, 2016, INT J BIO-INSPIR COM, V8, P170, DOI 10.1504/IJBIC.2016.076632
   Akay B, 2012, J INTELL MANUF, V23, P1001, DOI 10.1007/s10845-010-0393-4
   Akhtar S, 2002, ENG OPTIMIZ, V34, P341, DOI 10.1080/03052150212723
   [Anonymous], 2015, Fireworks Algorithm
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], ARXIV161101872
   [Anonymous], 2013, INT J COMPUT APPL
   [Anonymous], 1997, GENEAS ROBUST OPTIMA, DOI https://doi.org/10.1007/978-3-662-03423-1_27
   [Anonymous], 2012, J INFORM COMPUTATION
   [Anonymous], 1998, MACHINE LEARNING REA
   [Anonymous], 2016, Handbook of Research on Advanced Computational Techniques for Simulation-Based Engineering, DOI DOI 10.4018/978-1-4666-9479-8.CH019
   Atashpaz-Gargari E, 2007, IEEE C EVOL COMPUTAT, P4661, DOI 10.1109/CEC.2007.4425083
   Bolaji AL, 2016, APPL SOFT COMPUT, V49, P437, DOI 10.1016/j.asoc.2016.08.041
   CAGNINA LC, 1955, INFORMATICA, V32, P319
   Cai XJ, 2014, INT J BIO-INSPIR COM, V6, P166, DOI 10.1504/IJBIC.2014.062637
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Cheung NJ, 2017, IEEE T CYBERNETICS, V47, P391, DOI 10.1109/TCYB.2016.2517140
   Coelho LD, 2010, EXPERT SYST APPL, V37, P1676, DOI 10.1016/j.eswa.2009.06.044
   Coello CAC, 2002, ADV ENG INFORM, V16, P193, DOI 10.1016/S1474-0346(02)00011-3
   Coello CAC, 2000, COMPUT IND, V41, P113, DOI 10.1016/S0166-3615(99)00046-9
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Cui ZH, 2017, J PARALLEL DISTR COM, V103, P42, DOI 10.1016/j.jpdc.2016.10.011
   Deb K., 1996, Computer Science and informatics, V26, P30
   Dimopoulos GG, 2007, COMPUT METHOD APPL M, V196, P803, DOI 10.1016/j.cma.2006.06.010
   Djelloul H, 2015, INT J BIO-INSPIR COM, V7, P183, DOI 10.1504/IJBIC.2015.069554
   El-henawy Ibrahim, 2014, International Journal of Operational Research, V21, P252, DOI 10.1504/IJOR.2014.064551
   Feng YH, 2016, INT J COMPUT INT SYS, V9, P1174, DOI 10.1080/18756891.2016.1256577
   Feng Yanhong, 2014, Comput Intell Neurosci, V2014, P970456, DOI 10.1155/2014/970456
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Gandomi AH, 2014, ISA T, V53, P1168, DOI 10.1016/j.isatra.2014.03.018
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P17, DOI 10.1007/s00366-011-0241-y
   Gandomi AH, 2013, INT J BIO-INSPIR COM, V5, P281, DOI 10.1504/IJBIC.2013.057191
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Gandomi AH, 2011, COMPUT STRUCT, V89, P2325, DOI 10.1016/j.compstruc.2011.08.002
   Garg H, 2014, J IND MANAG OPTIM, V10, P777, DOI 10.3934/jimo.2014.10.777
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Ghosh B, 2015, 2015 INT C EN POW EN, P1
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Hafez AI, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P273, DOI 10.1109/ICENCO.2015.7416361
   He Q, 2007, ENG APPL ARTIF INTEL, V20, P89, DOI 10.1016/j.engappai.2006.03.003
   He S, 2004, ENG OPTIMIZ, V36, P585, DOI 10.1080/03052150410001704854
   Hedar AR, 2006, J GLOBAL OPTIM, V35, P521, DOI 10.1007/s10898-005-3693-z
   Hu YM, 2011, INT J ADV MANUF TECH, V56, P1125, DOI 10.1007/s00170-011-3244-3
   Jia B, 2016, NEUROCOMPUTING, V189, P106, DOI 10.1016/j.neucom.2015.12.066
   Jiang P, 2016, APPL MATH MODEL, V40, P9692, DOI 10.1016/j.apm.2016.05.030
   KANNAN BK, 1994, J MECH DESIGN, V116, P405, DOI 10.1115/1.2919393
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaveh A, 2010, ENG COMPUTATION, V27, P155, DOI 10.1108/02644401011008577
   Kaveh A., 2009, Asian Journal of Civil Engineering (Building and Housing), V10, P611
   Kavousi-Fard A, 2014, INT J BIO-INSPIR COM, V6, P416, DOI 10.1504/IJBIC.2014.066973
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Khatib W, 1998, LECT NOTES COMPUT SC, V1498, P683, DOI 10.1007/BFb0056910
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lee KS, 2005, COMPUT METHOD APPL M, V194, P3902, DOI 10.1016/j.cma.2004.09.007
   LI HL, 1985, J MECH TRANSM-T ASME, V107, P277, DOI 10.1115/1.3258721
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li XT, 2015, INFORM SCIENCES, V298, P80, DOI 10.1016/j.ins.2014.11.042
   Li XT, 2013, IEEE T NANOBIOSCI, V12, P343, DOI 10.1109/TNB.2013.2294716
   Li ZM, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/1423930
   LIU H, 2010, SOFT, V10, P629, DOI DOI 10.1016/J.ASOC.2009.08.031
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Long W, 2014, J CENT SOUTH UNIV, V21, P3197, DOI 10.1007/s11771-014-2291-y
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mehta VK, 2012, ENG OPTIMIZ, V44, P537, DOI 10.1080/0305215X.2011.598520
   Mezura-Montes E, 2007, ENG OPTIMIZ, V39, P567, DOI 10.1080/03052150701364022
   Mezura-Montes E, 2005, LECT NOTES ARTIF INT, V3789, P652
   Mezura-Montes E, 2003, PROC INT C TOOLS ART, P149, DOI 10.1109/TAI.2003.1250183
   Mezura-Montes E, 2008, INT J GEN SYST, V37, P443, DOI 10.1080/03081070701303470
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, NEURAL COMPUT APPL, V25, P1569, DOI 10.1007/s00521-014-1640-y
   Mirjalili S, 2014, INFORM SCIENCES, V269, P188, DOI 10.1016/j.ins.2014.01.038
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mukherjee A, 2015, CHAOS SOLITON FRACT, V78, P16, DOI 10.1016/j.chaos.2015.06.020
   Pan WT, 2012, KNOWL-BASED SYST, V26, P69, DOI 10.1016/j.knosys.2011.07.001
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Ray T, 2003, IEEE T EVOLUT COMPUT, V7, P386, DOI 10.1109/TEVC.2003.814902
   Ray T, 2001, ENG OPTIMIZ, V33, P735, DOI 10.1080/03052150108940941
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Rezoug A, 2016, INT J BIO-INSPIR COM, V8, P234, DOI 10.1504/IJBIC.2016.078641
   Rostami MA, 2015, IEEE T IND INFORM, V11, P388, DOI 10.1109/TII.2015.2395957
   Sadollah A, 2013, APPL SOFT COMPUT, V13, P2592, DOI 10.1016/j.asoc.2012.11.026
   SANDGREN E, 1990, J MECH DESIGN, V112, P223, DOI 10.1115/1.2912596
   Sekhar P, 2016, INT J ELEC POWER, V75, P303, DOI 10.1016/j.ijepes.2015.09.018
   Shah-Hosseini H, 2009, INT J BIO-INSPIR COM, V1, P71, DOI 10.1504/IJBIC.2009.022775
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   SHI YH, 2011, INT J SWARM INTELL R, V2, P35, DOI [DOI 10.4018/JSIR.2011100103, DOI 10.4018/IJSIR.2011100103]
   Shi YH, 2013, INT J SWARM INTELL R, V4, P1, DOI 10.4018/ijsir.2013070101
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun SC, 2016, APPL THERM ENG, V98, P1104, DOI 10.1016/j.applthermaleng.2016.01.017
   Tsai JF, 2005, ENG OPTIMIZ, V37, P399, DOI 10.1080/03052150500066737
   Wang G., 2014, Neural Computing and Applications, V24, P853, DOI [DOI 10.1007/S00521-012-1304-8, 10.1007/s00521-012-1304-8]
   Wang GG, 2014, NEURAL COMPUT APPL, V25, P297, DOI 10.1007/s00521-013-1485-9
   Wang GG, 2018, INT J BIO-INSPIR COM, V12, P1, DOI 10.1504/IJBIC.2015.10004283
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Wang GG, 2016, INT J BIO-INSPIR COM, V8, P394
   Wang GG, 2016, INT J BIO-INSPIR COM, V8, P286, DOI 10.1504/IJBIC.2016.10000414
   Wang GG, 2016, INT J ARTIF INTELL T, V25, DOI 10.1142/S021821301550030X
   Wang GG, 2016, NEUROCOMPUTING, V177, P147, DOI 10.1016/j.neucom.2015.11.018
   Wang GG, 2015, 2015 3RD INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI 2015), P39, DOI 10.1109/ISCBI.2015.14
   Wang GG, 2015, 2015 3RD INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI 2015), P1, DOI 10.1109/ISCBI.2015.8
   Wang GG, 2016, SOFT COMPUT, V20, P3349, DOI 10.1007/s00500-015-1726-1
   Wang GG, 2016, NEURAL COMPUT APPL, V27, P989, DOI 10.1007/s00521-015-1914-z
   Wang GG, 2016, SOFT COMPUT, V20, P273, DOI 10.1007/s00500-014-1502-7
   Wang GG, 2014, ENG COMPUTATION, V31, P1198, DOI 10.1108/EC-10-2012-0232
   Wang GG, 2014, INFORM SCIENCES, V274, P17, DOI 10.1016/j.ins.2014.02.123
   Wang GG, 2014, APPL MATH MODEL, V38, P2454, DOI 10.1016/j.apm.2013.10.052
   Wang GG, 2014, NEUROCOMPUTING, V128, P363, DOI 10.1016/j.neucom.2013.08.031
   Wang GG, 2013, KYBERNETES, V42, P962, DOI 10.1108/K-11-2012-0108
   Wang Gaige, 2012, ScientificWorldJournal, V2012, P583973, DOI [10.1100/2012/418946, 10.1100/2012/583973]
   [王改革 Wang Gaige], 2012, [电子学报, Acta Electronica Sinica], V40, P901
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xie SD, 2014, WIRELESS PERS COMMUN, V78, P231, DOI 10.1007/s11277-014-1748-5
   Yang X., 2010, STOCHASTIC TEST FUNC, DOI [10.1016/B978-0-12-416743-8.00005-1, DOI 10.1504/IJBIC.2010.032124]
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yi JH, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814015624832
   Zhang M, 2008, INFORM SCIENCES, V178, P3043, DOI 10.1016/j.ins.2008.02.014
   Zhou YQ, 2013, APPL MATH INFORM SCI, V7, P379, DOI 10.12785/amis/070147
   Zou DX, 2011, APPL SOFT COMPUT, V11, P1556, DOI 10.1016/j.asoc.2010.07.019
NR 131
TC 28
Z9 30
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 3861
EP 3884
DI 10.1007/s11042-017-4803-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200002
DA 2024-07-18
ER

PT J
AU Amami, A
   Ben Azouz, Z
   Alouane, MTH
AF Amami, Amal
   Ben Azouz, Zouhour
   Alouane, Monia Turki-Hadj
TI AdaSLIC: adaptive supervoxel generation for volumetric medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical images; Adaptive; Supervoxels; SLIC; Poisson-disk sampling; Big
   data
ID AUTOMATIC DETECTION; EDGE-DETECTION; SEGMENTATION; CLASSIFICATION;
   FORESTS
AB In the last decade, supervoxels have become a useful mid-level representation of volumetric medical images such as MRIs and CT scans. Several methods were suggested to produce uniform supervoxels, yet little has been done to generate content-sensitive over-segmentations. This is particularly beneficial to 3D medical image analysis, where sizes of anatomical structures vary largely. In this paper, we propose AdaSLIC as an adaptive supervoxel generation technique that applies to volumetric medical images. In small structures, it generates tiny supervoxels to capture the details of the image. Meanwhile, it partitions large structures into bigger supervoxels, hence leading to a sparse description. The proposed technique is an extension of the Simple Linear Iterative Clustering (SLIC) algorithm. Rather than using a regular sampling to initiate supervoxel centers, a content-sensitive initialization is performed using a Poisson-disk sampling algorithm (PDS). It relies on a map of distances to the main image contours. The size of each supervoxel depends on the distance of its center to the closest image contour. We compare our algorithm to the SLIC algorithm as well as to an extension of the DBSCAN algorithm (Density-Based Spatial Clustering of Applications with Noise). Two datasets are used for this purpose: knee MRIs and cardiovascular magnetic resonance (CMR) images. We use different metrics to assess the quality of the generated over-segmentations. Experimental results show that our algorithm achieves comparable or better boundary adherence than the state of the art algorithms while producing compact and adaptive supervoxels.
C1 [Amami, Amal; Ben Azouz, Zouhour; Alouane, Monia Turki-Hadj] Univ Tunis El Manar, Lab Signaux & Syst, Ecole Natl Ingn Tunis, Tunis, Tunisia.
   [Ben Azouz, Zouhour] Univ Tunis El Manar, Intitut Super Informat, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Tunis-El-Manar
RP Amami, A (corresponding author), Univ Tunis El Manar, Lab Signaux & Syst, Ecole Natl Ingn Tunis, Tunis, Tunisia.
EM amal.amami@enit.utm.tn
RI Turki-Hadj Alouane, Monia/HLV-7462-2023
OI Turki-Hadj Alouane, Monia/0000-0002-6375-0824; Amami,
   Amal/0000-0002-3459-0921
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Andres B, 2012, MED IMAGE ANAL, V16, P796, DOI 10.1016/j.media.2011.11.004
   [Anonymous], INTERACTIVE WHOLE HE
   [Anonymous], P 24 CAN C COMP GEOM
   [Anonymous], GSLIC REAL TIME IMPL
   [Anonymous], IEEE 14 INT S BIOM I
   Bi L, 2017, COMPUT MED IMAG GRAP, V60, P3, DOI 10.1016/j.compmedimag.2016.11.008
   Bridson R., 2007, Fast Poisson disk sampling in arbitrary dimensions, V10, P1, DOI DOI 10.1145/1278780.1278807
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen ZG, 2012, IEEE T VIS COMPUT GR, V18, P1784, DOI 10.1109/TVCG.2012.94
   Conze PH, 2017, INT J COMPUT ASS RAD, V12, P223, DOI 10.1007/s11548-016-1493-1
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Corsini M, 2012, IEEE T VIS COMPUT GR, V18, P914, DOI 10.1109/TVCG.2012.34
   Dang K, 2013, IEEE IMAGE PROC, P680, DOI 10.1109/ICIP.2013.6738140
   Dunbar D, 2006, ACM T GRAPHIC, V25, P503, DOI 10.1145/1141911.1141915
   Ebeida MS, 2012, COMPUT GRAPH FORUM, V31, P785, DOI 10.1111/j.1467-8659.2012.03059.x
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gentsos Christos, 2010, Proceedings of the 2010 17th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2010), P499, DOI 10.1109/ICECS.2010.5724558
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Heimann T, 2010, Proc. MICCAI Workshop on Medical Image Analysis for the Clinic, P207
   Heinrich MP, 2016, MED IMAGE ANAL, V27, P57, DOI 10.1016/j.media.2015.09.005
   Hesselink WH, 2008, IEEE T PATTERN ANAL, V30, P2204, DOI 10.1109/TPAMI.2008.21
   Irving B, 2016, MED IMAGE ANAL, V32, P69, DOI 10.1016/j.media.2016.03.002
   Kanavati F, 2017, LECT NOTES COMPUT SC, V10541, P79, DOI 10.1007/978-3-319-67389-9_10
   Kanavati F, 2017, PATTERN RECOGN, V63, P561, DOI 10.1016/j.patcog.2016.09.026
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu Y, 2016, PHYS MED BIOL, V61, P8440, DOI 10.1088/0031-9155/61/24/8440
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Lucchi A, 2012, IEEE T MED IMAGING, V31, P474, DOI 10.1109/TMI.2011.2171705
   Machairas V, 2015, IEEE T IMAGE PROCESS, V24, P3707, DOI 10.1109/TIP.2015.2451011
   Mahapatra D, 2013, IEEE T MED IMAGING, V32, P2332, DOI 10.1109/TMI.2013.2282124
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Moore AP, 2008, 2008 IEEE C COMPUTER, P1
   Ostromoukhov V, 2001, COMP GRAPH, P567, DOI 10.1145/383259.383326
   Pei YR, 2017, LECT NOTES COMPUT SC, V10541, P114, DOI 10.1007/978-3-319-67389-9_14
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Schick A, 2012, INT C PATT RECOG, P930
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Szmul A, 2016, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2016.80
   Tian ZQ, 2017, MED PHYS, V44, P558, DOI 10.1002/mp.12048
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6
   Wang YR, 2004, IEEE T SYST MAN CY B, V34, P517, DOI 10.1109/TSMCB.2003.817062
   Weikersdorfer D, 2012, INT C PATT RECOG, P2087
   White KB, 2007, RT07: IEEE/EG Symposium on Interactive Ray Tracing 2007, P129, DOI 10.1109/RT.2007.4342600
   Xu CL, 2016, INT J COMPUT VISION, V119, P272, DOI 10.1007/s11263-016-0906-5
   Xu CL, 2013, IEEE I CONF COMP VIS, P2240, DOI 10.1109/ICCV.2013.279
   Xu CL, 2012, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2012.6247802
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
NR 55
TC 6
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3723
EP 3745
DI 10.1007/s11042-017-5563-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600058
DA 2024-07-18
ER

PT J
AU Belkacem, I
   Nait-Bahloul, S
   Sauveron, D
AF Belkacem, Imad
   Nait-Bahloul, Safia
   Sauveron, Damien
TI Enhancing dependability through profiling in the collaborative internet
   of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; C-IoT; Collaboration; Dependability; Identification; Sensing; Data
   analysis
ID PERCENTAGE POINTS
AB The future of the Internet of Things (IoT) is the Collaborative Internet of Things (C-IoT) in which different IoT deployments collaborate to provide better services. For instance, in smart city scenarios, C-IoT will have the potential to provide immersive multimedia user-experiences based on content and context fusion, immersive multi-sensory environments, location-based and media internet technologies, and augmented reality. However, this future paradigm will only be possible if the right decisions can be made based on the analysis of huge volumes of collected data: i.e. if the dependability of C-IoT is ensured. To address this challenge, we studied a simplified view of a C-IoT architecture composed of devices using three different technologies that have enabled the existence of IoT (RFID, NFC and Beacons). However, our proposal could be extended to any other devices in the context of C-IoT. To enhance the dependability of C-IoT, we deploy statistical data analysis techniques to improve the quality of the data obtained from identification and sensing devices and to select the most reliable devices that provide trusted (i.e. non-faulty) data in order to support accurate decision-making.
C1 [Belkacem, Imad; Nait-Bahloul, Safia] Univ Oran1, LITIO Lab, BP 1524, El Mnaouer, Oran, Algeria.
   [Sauveron, Damien] Univ Limoges, UMR CNRS 7252, XLIM, 123 Ave Albert Thomas, F-87060 Limoges, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Limoges
RP Sauveron, D (corresponding author), Univ Limoges, UMR CNRS 7252, XLIM, 123 Ave Albert Thomas, F-87060 Limoges, France.
EM imad.belkacem@univ-mosta.dz; Nait-bahloul.safia@univ-oran.dz;
   damien.sauveron@unilim.fr
RI NAIT-BAHLOUL, Safia/ISV-5185-2023
OI NAIT-BAHLOUL, Safia/0009-0009-5695-4923
CR [Anonymous], APPL STAT DESIGNS RE
   [Anonymous], 2015, Collaborative Internet of Things (C-IoT): For Future Smart Connected Life and Business
   [Anonymous], 2009, RFID J
   [Anonymous], RELYONIT RES EXP DEP
   Beacon A, A SENSOR
   Beacon A, APR BEAC WEBS
   Belkacem I, 2014, INT J EMBEDDED REAL, V5, P1, DOI [10.4018/IJERTCS.2014070101, DOI 10.4018/IJERTCS.2014070101]
   Boano CA, 2015, IEEE IOT NEWSL, V13
   Neto JBB, 2015, SENSORS-BASEL, V15, P6607, DOI 10.3390/s150306607
   Chavira G, 2007, ENC 2007: EIGHTH MEXICAN INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER SCIENCE, PROCEEDINGS, P165, DOI 10.1109/ENC.2007.30
   Dar KS, 2016, PROCEEDINGS 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON INTERNET-OF-THINGS DESIGN AND IMPLEMENTATION IOTDI 2016, P106, DOI 10.1109/IoTDI.2015.38
   DEAN RB, 1951, ANAL CHEM, V23, P636, DOI 10.1021/ac60052a025
   Fritz G, METHODES STAT TEST L
   Fritz G., 2010, 2010 IEEE 16 INT MIX, P1
   GRUBBS FE, 1950, ANN MATH STAT, V21, P27, DOI 10.1214/aoms/1177729885
   GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761
   GRUBBS FE, 1972, TECHNOMETRICS, V14, P847, DOI 10.2307/1267134
   Hamdan D, 2013, THESIS
   Herrera Moises Manzano, 2008, Second International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies 2008, P144, DOI 10.1109/UBICOMM.2008.22
   Intel, GUID INT THINGS BILL
   Kajioka S, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P337, DOI 10.1109/GCCE.2014.7031308
   Kalia M, 2000, 2000 IEEE 51ST VEHICULAR TECHNOLOGY CONFERENCE, PROCEEDINGS, VOLS 1-3, P907, DOI 10.1109/VETECS.2000.851256
   Kendall MG, 1969, ADV THEORY STAT V2 I
   LAPRIE JC, 1995, GUIDE SURETE FONCTIO
   Macedo D, 2014, IEEE INT C NETW SENS, P417, DOI 10.1109/ICNSC.2014.6819662
   MARKOWSKI CA, 1990, AM STAT, V44, P322, DOI 10.2307/2684360
   Merrill R.M., 2012, Fundamentals of epidemiology and biostatistics: Combining the basics
   Mtita Collins, 2016, THESIS
   ROSNER B, 1983, TECHNOMETRICS, V25, P165, DOI 10.2307/1268549
   Schaffers H, 2011, LECT NOTES COMPUT SC, V6656, P431, DOI 10.1007/978-3-642-20898-0_31
   Stuart A., 1999, KENDALLS ADV THEORY, V2A
   Thornton F., 2011, CHEAT DEPLOYING SECU
   Zhao Y, 2015, IEEE INT CONF RFID, P174, DOI 10.1109/RFID.2015.7113089
NR 33
TC 5
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2983
EP 3007
DI 10.1007/s11042-017-5431-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600018
DA 2024-07-18
ER

PT J
AU Jiang, YJ
   Wang, JX
   Liang, YX
   Xia, JZ
AF Jiang, Yingjun
   Wang, Jianxin
   Liang, Yixiong
   Xia, Jiazhi
TI Combining static and dynamic features for real-time moving pedestrian
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Combined feature; Sparse optical flow
AB Pedestrian detecting and tracking are critical techniques in video monitoring. However, real-time pedestrian detection is still challenging in surveillance videos with complex background. In existing frameworks, feature extractions are usually time-consuming to achieve high detection accuracy. In this paper, we propose to combine sparse static and dynamic features to improve the feature extraction speed while keeping high detection accuracy. Firstly, the static sparse feature is extracted using a fast feature pyramid in each frame. Secondly, sparse optical flow is used to extract sparse dynamic feature among successive frames. Thirdly, we combine the two types of feature in the Adaboost classification. Experiments show that the average miss rate of our approach is 17%. The detection rate is up to 22 fps in a Matlab implementation. It shows that our approach achieves optimal detection accuracy compared to the state-of-the-art real-time pedestrian detection algorithms.
C1 [Jiang, Yingjun; Wang, Jianxin; Liang, Yixiong; Xia, Jiazhi] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Xia, JZ (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
EM xiajiazhi@csu.edu.cn
RI wang, jian/GVS-0711-2022; LIANG, YIXIONG/ABC-6068-2021; Wang,
   Jianxin/V-2800-2018; , Yixiong/AAQ-2023-2020
OI , Yixiong/0000-0002-2260-066X; Liang, Yixiong/0000-0003-0407-5838
FU National Nature Science Foundation of China [61309009]; Natural Science
   Foundation of Hunan Province, China [14JJ2008]
FX This research is partially supported by National Nature Science
   Foundation of China (61309009) and Natural Science Foundation of Hunan
   Province, China (14JJ2008).
CR Andriluka M, 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.141
   [Anonymous], AM MATH MONTH
   [Anonymous], 2010 5 IEEE INT C IN
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], J ZHEJIANG U IND VER
   [Anonymous], 2007, P NEURIPS
   Cao JL, 2016, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2016.147
   Costea AD, 2016, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2016.259
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Kang WX, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P824, DOI 10.1109/ICIS.2007.157
   Liang CW, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2459917
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Paisitkriangkrai S, 2016, IEEE T PATTERN ANAL, V38, P1243, DOI 10.1109/TPAMI.2015.2474388
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Yang YC, 2015, IEEE T PATTERN ANAL, V37, P1053, DOI 10.1109/TPAMI.2014.2360380
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
NR 26
TC 15
Z9 18
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3781
EP 3795
DI 10.1007/s11042-018-6057-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600061
DA 2024-07-18
ER

PT J
AU Kim, H
   Kim, DW
   Yi, O
   Kim, J
AF Kim, Hangi
   Kim, Do-won
   Yi, Okyeon
   Kim, Jongsung
TI Cryptanalysis of hash functions based on blockciphers suitable for IoT
   service platform security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT service platform security; Blockcipher-based hash functions;
   Related-key differential properties; Collision attacks; Second-preimage
   attacks
ID SECURITY/EFFICIENCY TRADEOFFS; 2ND-PREIMAGE ATTACKS; PREIMAGE;
   CONSTRUCTIONS; MODES; DM
AB It is well-known that blockcipher-based hash functions may be attacked when adopting blockciphers having related-key differential properties. However, all forms of related-key differentials are not always effective to attack them. In this paper we provide the general frameworks for collision and second-preimage attacks on hash functions by using related-key differential properties of instantiated blockciphers, and show their various applications. In the literature, there have been several provably secure blockcipher-based hash functions such as 12 PGV schemes, MDC-2, MJH, Abreast-DM, Tandem-DM, and HIROSE. However, their security cannot be guaranteed when they are instantiated with specific blockciphers. In this paper, we first observe related-key differential properties of some blockciphers such as Even-Mansour (EM), Single-key Even-Mansour (SEM), XPX with a fixed tweak (XPX1111), Chaskey cipher, and LOKI, which are suitable for IoT service platform security. We then present how these properties undermine the security of the aforementioned blockcipher-based hash functions. In our analysis, the collision and second-preimage attacks can be applied to several PGV schemes, MDC-2, MJH instantiated with SEM, XPX1111, Chaskey cipher, to PGV no.5, MJH, HIROSE, Abreast-DM, Tandem-DM instantiated with EM. Furthermore, LOKI-based MDC-2 is vulnerable to the collision attack. We also provide the necessary conditions for related-key differentials of blockciphers in order to attack each of the hash functions. To the best of our knowledge, this study is the first comprehensive analysis of hash functions based on blockciphers having related-key differential properties. Our cryptanalytic results support the well-known claim that blockcipher-based hash functions should avoid adopting blockciphers with related-key differential properties, such as the fixed point property in compression functions. We believe that this study provides a better understanding of the security of blockcipher-based hash functions.
C1 [Kim, Hangi; Yi, Okyeon; Kim, Jongsung] Kookmin Univ, Dept Financial Informat Secur, Seoul, South Korea.
   [Kim, Do-won] Korea Internet & Secur Agcy, Cryptog Technol Team, Naju, South Korea.
   [Yi, Okyeon; Kim, Jongsung] Kookmin Univ, Dept Informat Secur Cryptol & Math, Seoul, South Korea.
C3 Kookmin University; Kookmin University
RP Kim, J (corresponding author), Kookmin Univ, Dept Financial Informat Secur, Seoul, South Korea.; Kim, J (corresponding author), Kookmin Univ, Dept Informat Secur Cryptol & Math, Seoul, South Korea.
EM tiontta@kookmin.ac.kr; dowonkim@kisa.or.kr; oyyi@kookmin.ac.kr;
   jskim@kookmin.ac.kr
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government(MSIT) [2017-0-00520]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIT)
   (No. 2017-0-00520, Development of SCR-Friendly Symmetric Key
   Cryptosystem and Its Application Modes).
CR Andreeva E, 2016, J CRYPTOL, V29, P657, DOI 10.1007/s00145-015-9206-4
   Andreeva E, 2013, LECT NOTES COMPUT SC, V8042, P531, DOI 10.1007/978-3-642-40041-4_29
   Andreeva E, 2009, LECT NOTES COMPUT SC, V5867, P393, DOI 10.1007/978-3-642-05445-7_25
   Biham E., 1991, LECT NOTES COMPUTER, P156, DOI DOI 10.1007/3-540-46766-1_11
   Biryukov A, 2009, LECT NOTES COMPUT SC, V5677, P231, DOI 10.1007/978-3-642-03356-8_14
   Black J, 2005, LECT NOTES COMPUT SC, V3494, P526
   Black J, 2002, LECT NOTES COMPUT SC, V2442, P320
   BRACHTL BO, 1990, Patent No. 4908861
   BROWN L, 1990, LECT NOTES COMPUT SC, V453, P229, DOI 10.1007/BFb0030364
   Chien JG, 2016, IEICE T FUND ELECTR, VE99A, P14, DOI 10.1587/transfun.E99.A.14
   Dunkelman O, 2012, LECT NOTES COMPUT SC, V7237, P336, DOI 10.1007/978-3-642-29011-4_21
   Even Shimon, 1991, ASIACRYPT '91, V739, p210 224, DOI [10.1007/3-540-57332-1_17, DOI 10.1007/3-540-57332-1_17]
   Hirose S, 2006, LECT NOTES COMPUT SC, V4047, P210
   Hong D., 2012, IACR CRYPTOL EPRINT, V2012, P634
   Hong D, 2016, MULTIMED TOOLS APPL, V75, P14525, DOI 10.1007/s11042-015-2769-0
   Hong D, 2012, IEICE T FUND ELECTR, VE95A, P372, DOI 10.1587/transfun.E95.A.372
   Kelsey J, 2005, LECT NOTES COMPUT SC, V3494, P474
   Knudsen LR, 2007, LECT NOTES COMPUT SC, V4833, P315
   Knudsen LR, 2009, LECT NOTES COMPUT SC, V5479, P106, DOI 10.1007/978-3-642-01001-9_6
   Lai Xuejia, 1992, Lecture Notes in Computer Science, V658, P55
   Lee J, 2011, LECT NOTES COMPUT SC, V6841, P561, DOI 10.1007/978-3-642-22792-9_32
   Lee J, 2011, LECT NOTES COMPUT SC, V6558, P213, DOI 10.1007/978-3-642-19074-2_15
   Lee J, 2011, IEICE T FUND ELECTR, VE94A, P104, DOI 10.1587/transfun.E94.A.104
   Mennink B, 2016, LECT NOTES COMPUT SC, V9814, P64, DOI 10.1007/978-3-662-53018-4_3
   Mouha N, 2014, LECT NOTES COMPUT SC, V8781, P306, DOI 10.1007/978-3-319-13051-4_19
   Preneel B, 1993, LNCS, V773, P368
   Rivest R., 1992, MD5 MESSAGE DIGEST A
   Rogaway P, 2008, LECT NOTES COMPUT SC, V4965, P220
   Sasaki Y, 2011, LECT NOTES COMPUT SC, V6733, P378
   Secure Hash Standard (SHS), 2012, FIPS PUB, V1804
   Stam M, 2008, LECT NOTES COMPUT SC, V5157, P397, DOI 10.1007/978-3-540-85174-5_22
   STEIL M., 2005, 22 CHAOS COMM C
   Steinberger J, 2012, LECT NOTES COMPUT SC, V7417, P384
   Steinberger J, 2010, LECT NOTES COMPUT SC, V6110, P597
   Steinberger JP, 2007, LECT NOTES COMPUT SC, V4515, P34
   Wei L, 2012, LECT NOTES COMPUT SC, V7549, P163, DOI 10.1007/978-3-642-34047-5_10
   Winternitz R. S., 1984, Proceedings of the 1984 Symposium on Security and Privacy, P88
NR 37
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3107
EP 3130
DI 10.1007/s11042-018-5630-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600023
DA 2024-07-18
ER

PT J
AU Li, ZH
   Zhou, YAZ
   Wu, J
   Shu, YJ
   Han, P
AF Li, Zhenghao
   Zhou, Yangaizhu
   Wu, Jun
   Shu, Yuejie
   Han, Peng
TI Route tracking for self-propelled ship model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ship model test; Route tracking; Frame difference; Freeman chain-code
AB To ensure the safety of the navigation, self-propelled ship model test is widely used in navigable administer engineering to visually and really reflect navigable condition, offering reasonable suggestions for the design of route. This paper proposed a video analysis based route tracking approach for self-propelled ship model that sails in large scale river models, which can realize automatic measurement for ship model motion parameters. Firstly, the captured videos of the self-propelled ship model are transferred to the computer via wireless local area network (WLAN). Then, the camera lens distortion is eliminated by rectify and aerial view is reconstructed. Third, ORB and binary BoF classifier are used to detect ship model. At last, through frame difference and Freeman chain-code, the coordinates of ship model's markers can be obtained. Moreover, on visual interactive interface, the route of the ship model is plotted, and velocities and drift angles of ship model are also calculated. This approach was tested on the several river models, such as Jianzishan navigation junction, which is a medium-sized water conservancy project located in the middle reaches of the Minjiang River. The results from the experiments demonstrate the approach can not only realize accurate measurement of coordinates of ship model, but also can visually map out the route of the ship model that sailing in large scale river models.
C1 [Li, Zhenghao; Zhou, Yangaizhu] Chongqing Univ, Key Lab Optoelect Technol & Syst, Minist Educ, Coll Optoelect Engn, Chongqing 400044, Peoples R China.
   [Li, Zhenghao; Wu, Jun; Shu, Yuejie] Chongqing Jiaotong Univ, Minist Commun, Key Lab Inland Waterway Regulat Engn, Chongqing 400016, Peoples R China.
   [Han, Peng] Chongqing Acad Sci & Technol, Chongqing 401123, Peoples R China.
C3 Chongqing University; Chongqing Jiaotong University; Chongqing Academy
   of Science & Technology
RP Li, ZH (corresponding author), Chongqing Univ, Key Lab Optoelect Technol & Syst, Minist Educ, Coll Optoelect Engn, Chongqing 400044, Peoples R China.; Li, ZH (corresponding author), Chongqing Jiaotong Univ, Minist Commun, Key Lab Inland Waterway Regulat Engn, Chongqing 400016, Peoples R China.
EM lizhenghao@cqu.edu.cn
RI li, zhenghao/HNR-1871-2023
OI Li, Zhenghao/0000-0001-9898-8974
FU Key Research and Development Projects in Chongqing
   [cstc2017rgzn-zdyfX0025]; Chongqing Postdoctoral Science Foundation
   [Xm2015014]; Opening Fund of Key Laboratory of Inland Waterway
   Regulation Engineering (Chongqing Jiaotong University), Ministry of
   Communications [NHHD-201503]; Shandong Provincial Natural Science
   Foundation, China [ZR2016FQ25]; Visiting Scholar Foundation of Key
   Laboratory of Optoelectronic Technology & Systems (Chongqing
   University), Ministry of Education
FX This research was supported by the Key Research and Development Projects
   in Chongqing (cstc2017rgzn-zdyfX0025), the Chongqing Postdoctoral
   Science Foundation (Xm2015014), the Opening Fund of Key Laboratory of
   Inland Waterway Regulation Engineering (Chongqing Jiaotong University),
   Ministry of Communications (NHHD-201503), the Shandong Provincial
   Natural Science Foundation, China (ZR2016FQ25), and the Visiting Scholar
   Foundation of Key Laboratory of Optoelectronic Technology & Systems
   (Chongqing University), Ministry of Education.
CR Cai C, 2009, PORT ENG TECHNOLOGY, V46, P12
   Cai XY, 2017, PORT WATERWAY ENG, V2017, P77
   Cai XY, 2017, J CHONGQING JIAO TON, V36, P58
   Carsten S, 2008, MACHINE VISION ALGOR, P32
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Cheng-long Zhang, 2013, Journal of Henan University of Technology Natural Science Edition, V34, P27
   Choi BD, 2006, IEEE T CONSUM ELECTR, V52, P975, DOI 10.1109/TCE.2006.1706496
   Ciora Radu Adrian, 2014, Acta Universitatis Cibiniensis. Technical Series, V64, P17, DOI 10.2478/aucts-2014-0004
   Gao ZR, 2017, OPT LASER ENG, V98, P143, DOI 10.1016/j.optlaseng.2017.06.008
   Hou YX, 2013, IEEE INT C NETW INFR, P503
   Li J, 2011, ADV MATER RES-SWITZ, V317-319, P2490, DOI 10.4028/www.scientific.net/AMR.317-319.2490
   Li JK, 2008, ACTA HORTIC, P117, DOI 10.17660/ActaHortic.2008.768.13
   Li YB, 2004, J WATERW HARB, V25, P8
   LI Z, 2017, TKDE, V29, P2100, DOI DOI 10.1109/TKDE.2017.2728531
   Liu LC, 2014, INT C PATT RECOG, P2619, DOI 10.1109/ICPR.2014.452
   Muñoz-Salinas R, 2008, PATTERN RECOGN LETT, V29, P1504, DOI 10.1016/j.patrec.2008.03.004
   Ni SL, 2000, J SSSRI, V23, P91
   Onishi J, 2011, IEEE SYS MAN CYBERN, P1088, DOI 10.1109/ICSMC.2011.6083819
   Santana-Cedrés D, 2017, COMPUT VIS IMAGE UND, V161, P1, DOI 10.1016/j.cviu.2017.05.016
   SUN Q, 2016, ELECTRON OPTICS, V127, P4506, DOI DOI 10.1016/j.ijleo.2016.01.123
   Tsoi JKP, 2015, I CONF SENS TECHNOL, P665, DOI 10.1109/ICSensT.2015.7438481
   Wang SG, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1121, DOI 10.1109/ISKE.2008.4731098
   Wang YC, 2004, J SCI INSTRUMENT, V25, P993
   Xu GY, 1986, SHIP BUILDING CHINA, P82
   Yang F, 2012, IET IMAGE PROCESS, V6, P115, DOI 10.1049/iet-ipr.2010.0127
   Zeng F, 2017, PORT WATERWAY ENG, V2017, P71
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
   Zhan CH, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P519, DOI 10.1109/ICIG.2007.153
   Zhang T, 2016, FRONT MICROBIOL, V7, DOI 10.3389/fmicb.2016.00227
   [张婷 Zhang Ting], 2015, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V29, P531
NR 33
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4365
EP 4379
DI 10.1007/s11042-018-5751-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200024
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Dong, ZC
   Chen, XQ
   Jia, WJ
   Du, SD
   Muhammad, K
   Wang, SH
AF Zhang, Yu-Dong
   Dong, Zhengchao
   Chen, Xianqing
   Jia, Wenjuan
   Du, Sidan
   Muhammad, Khan
   Wang, Shui-Hua
TI Image based fruit category classification by 13-layer deep convolutional
   neural network and data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Fully connected layer; Softmax; Fruit
   category identification
ID ENTROPY
AB Fruit category identification is important in factories, supermarkets, and other fields. Current computer vision systems used handcrafted features, and did not get good results. In this study, our team designed a 13-layer convolutional neural network (CNN). Three types of data augmentation method was used: image rotation, Gamma correction, and noise injection. We also compared max pooling with average pooling. The stochastic gradient descent with momentum was used to train the CNN with minibatch size of 128. The overall accuracy of our method is 94.94%, at least 5 percentage points higher than state-of-the-art approaches. We validated this 13-layer is the optimal structure. The GPU can achieve a 177x acceleration on training data, and a 175x acceleration on test data. We observed using data augmentation can increase the overall accuracy. Our method is effective in image-based fruit classification.
C1 [Zhang, Yu-Dong; Wang, Shui-Hua] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Zhang, Yu-Dong] Jiangsu Key Lab Adv Mfg Technol, Huaiyin 223003, Jiangsu, Peoples R China.
   [Dong, Zhengchao] Columbia Univ, Translat Imaging Div, New York, NY 10032 USA.
   [Dong, Zhengchao] Columbia Univ, MRI Unit, New York, NY 10032 USA.
   [Dong, Zhengchao] New York State Psychiat Inst & Hosp, New York, NY 10032 USA.
   [Chen, Xianqing] Zhejiang Normal Univ, Dept Elect Engn, Coll Engn, Jinhua 321004, Zhejiang, Peoples R China.
   [Jia, Wenjuan] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Du, Sidan] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Jiangsu, Peoples R China.
   [Muhammad, Khan] Sejong Univ, Coll Software Convergence, Seoul, South Korea.
C3 Henan Polytechnic University; Columbia University; Columbia University;
   New York State Psychiatry Institute; Zhejiang Normal University; Nanjing
   Normal University; Nanjing University; Sejong University
RP Zhang, YD; Wang, SH (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Zhang, YD (corresponding author), Jiangsu Key Lab Adv Mfg Technol, Huaiyin 223003, Jiangsu, Peoples R China.; Muhammad, K (corresponding author), Sejong Univ, Coll Software Convergence, Seoul, South Korea.
EM yudongzhang@ieee.org; khan.muhammad@ieee.org; shuihuawang@ieee.org
RI xianqing, chen/C-7474-2012; Muhammad, Khan/L-9059-2016; Khan,
   Muhammad/IXN-8470-2023; Du, Sidan/JVN-2413-2024; Zhang,
   Yudong/I-7633-2013; Wang, shuihua/G-7326-2016
OI Muhammad, Khan/0000-0003-4055-7412; Du, Sidan/0000-0002-7079-0066;
   Muhammad, Khan/0000-0002-5302-1150; Zhang, Yudong/0000-0002-4870-1493;
   Wang, shuihua/0000-0003-4713-2791
FU Natural Science Foundation of China [61602250]; Natural Science
   Foundation of Jiangsu Province [BK20150983]; Open fund of Key Laboratory
   of Guangxi High Schools Complex System and Computational Intelligence
   [2016CSCI01]
FX This study was supported by Natural Science Foundation of China
   (61602250), Natural Science Foundation of Jiangsu Province (BK20150983),
   Open fund of Key Laboratory of Guangxi High Schools Complex System and
   Computational Intelligence (2016CSCI01).
CR Acquarelli J, 2017, ANAL CHIM ACTA, V954, P22, DOI 10.1016/j.aca.2016.12.010
   Adak MF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030304
   Ahmad J, 2017, J VIS COMMUN IMAGE R, V45, P62, DOI 10.1016/j.jvcir.2017.02.010
   [Anonymous], 2014, J FOOD ENG, DOI DOI 10.1016/j.jfoodeng.2014.07.001
   [Anonymous], 2016, IEEE ACM T NETWORK, DOI DOI 10.1109/TNET.2015.2425146
   [Anonymous], EXP SYST, DOI DOI 10.1111/EXSY.12146
   [Anonymous], 2016, BMC PLANT BIOL
   [Anonymous], 2017, ADV SOC SCI EDUC HUM
   [Anonymous], 2017, 5 INT C IND APPL ENG
   Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Cicero M, 2017, INVEST RADIOL, V52, P281, DOI 10.1097/RLI.0000000000000341
   Cintas C, 2017, IET BIOMETRICS, V6, P211, DOI 10.1049/iet-bmt.2016.0002
   Deliens T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165298
   Di Cagno R, 2017, J FUNCT FOODS, V31, P9, DOI 10.1016/j.jff.2017.01.033
   Tovar MF, 2016, AMAZON INVESTIG, V5, P45
   García F, 2016, IEEE LAT AM T, V14, P3434, DOI 10.1109/TLA.2016.7587652
   Getahun S, 2017, J FOOD ENG, V203, P58, DOI 10.1016/j.jfoodeng.2017.02.010
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Dai-Ton H, 2016, PATTERN RECOGN LETT, V80, P137, DOI 10.1016/j.patrec.2016.06.011
   Jiang YL, 2009, IEEE IJCNN, P2784
   Kim JH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051065
   Kooi T, 2017, MED PHYS, V44, P1017, DOI 10.1002/mp.12110
   Lee CH, 2016, INT CONF ACOUST SPEE, P2279, DOI 10.1109/ICASSP.2016.7472083
   Li SQ, 2017, COMPUT BIOL MED, V84, P156, DOI 10.1016/j.compbiomed.2017.03.017
   Miki Y, 2017, COMPUT BIOL MED, V80, P24, DOI 10.1016/j.compbiomed.2016.11.003
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Pardo-Mates N, 2017, FOOD CHEM, V221, P29, DOI 10.1016/j.foodchem.2016.10.033
   Qian RQ, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P578, DOI 10.1109/FSKD.2016.7603237
   Shao WH, 2017, ANAL BIOANAL CHEM, V409, P115, DOI 10.1007/s00216-016-9944-7
   Smirnov EA, 2014, AASRI PROC, V6, P89, DOI 10.1016/j.aasri.2014.05.013
   Sui XD, 2017, NEUROCOMPUTING, V237, P332, DOI 10.1016/j.neucom.2017.01.023
   Tabik S, 2017, INT J COMPUT INT SYS, V10, P555, DOI 10.2991/ijcis.2017.10.1.38
   Teh V, 2016, SCANNING, V38, P842, DOI 10.1002/sca.21334
   Thung KH, 2016, BRAIN STRUCT FUNCT, V221, P3979, DOI 10.1007/s00429-015-1140-6
   Thung KH, 2014, NEUROIMAGE, V91, P386, DOI 10.1016/j.neuroimage.2014.01.033
   Thung KH, 2012, PATTERN RECOGN, V45, P2193, DOI 10.1016/j.patcog.2011.12.001
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Yaghoubi S, 2015, EUR J OPER RES, V247, P879, DOI 10.1016/j.ejor.2015.06.038
   Zhang Y, 2016, IEEE T SERV COMPUT, V9, P786, DOI 10.1109/TSC.2016.2592520
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
   Zhu SG, 2014, J APPL MATH, DOI 10.1155/2014/828907
NR 43
TC 195
Z9 206
U1 7
U2 148
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3613
EP 3632
DI 10.1007/s11042-017-5243-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600053
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Bashir, R
   Junejo, R
   Qadri, NN
   Fleury, M
   Qadri, MY
AF Bashir, Rabia
   Junejo, Riaz
   Qadri, Nadia N.
   Fleury, Martin
   Qadri, Muhammad Yasir
TI SWT and PCA image fusion methods for multi-modal imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Multi-modal; PCA; SWT
ID FOCUS; IHS
AB Image fusion is the process of combining two or more related images to produce a single output image, containing more relevant information than any one of the input images. The image-fusion process depends upon: the application domain; the number of images undergoing fusion; and the type of imagery, such as whether it is multi-spectral or multi-modal. For clarity of presentation, this paper takes two important fusion methods, Stationary Wavelet Transform (SWT) and Principal Components Analysis (PCA), and applies them to a variety of imagery. Results show that in multi-modal image fusion, PCA appears to perform better for those input images that have different contrast/brightness levels. SWT appears to give better performance when the input images are multi-modal and multi-sensor. A feature of the paper are the number of objective functions employed to evaluate the SWT and PCA methods, allowing the utility of each to be judged. The reader will also find in this paper a concise guide to image fusion techniques with clear recommendations on how to evaluate them.
C1 [Bashir, Rabia; Qadri, Nadia N.] COMSATS Inst Informat Technol, Wah Campus, Wah Cantt, Pakistan.
   [Junejo, Riaz] COMSATS Inst Informat Technol, Dept Elect Engn, Wah Campus, Wah Cantt, Pakistan.
   [Fleury, Martin; Qadri, Muhammad Yasir] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI);
   University of Essex
RP Qadri, NN (corresponding author), COMSATS Inst Informat Technol, Wah Campus, Wah Cantt, Pakistan.
EM drnadia@ciitwah.edu.pk; fleum@essex.ac.uk; yasirqadri@acm.org
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Al-Azzawi N.A., 2011, IMAGE FUS APP, P93
   Al-Wassai F, 2011, INT J COMPUT SCI, V8, P113
   Al-Wassai F. A., 2011, INT J ARTIF INTELL K, V1, P5
   Alfanol B, 2007, LECT NOTES COMPUT SC, V4816, P117
   [Anonymous], 2011, Int. J. Eng. Sci. Technol.
   [Anonymous], 2013, INT J ADV RES ELECT
   [Anonymous], 2009, WORLD ACAD SCI ENG T
   Babu B, 2012, INT J COMPUT ENG MAN, V15, P15
   Bedi SS, 2013, INT J ADV RES COMPUT, V2, P1153
   Bharath B, 2017, INT CONF COMPUT POW, P43, DOI 10.1109/ICCPEIC.2017.8290336
   Bindu CH, 2012, INT J ADV COMPUT SC, V3, P54
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461
   Deshmukh M., 2010, Int. J. Image Process. (IJIP), V4, P484
   Divya R, 2014, INT J SCI TECHNOL, V1
   Divyaloshini V, 2014, INT J TECHNOL ENHANC, V2, P25
   Ehlers M, 2008, P SOC PHOTO-OPT INS, V71100, P1
   El Ejaily A, 2013, INT J COMPUT SCI ISS, V10
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Gupta AU, 2011, INT J ENG SCI TECHNO, V3, P1388
   Gupta C, 2015, INT J COMPUT APPS, V116, P26
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   Indhumadhi N., 2011, INT J SOFT COMPUTING, V1, P298
   Jolliffe I.T., 2008, PRINCIPAL COMPONENT
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Lin B, 2015, IEEE ACCESS, V14
   Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864
   Mahajan S., 2014, IPASJ INT J COMPUTER, V2, P8
   Mahajan S, 2014, IJECS, V3, P4030
   Mifdal J, 2017, INT GEOSCI REMOTE SE, P3373, DOI 10.1109/IGARSS.2017.8127721
   Mirajkar P. P., 2013, J INT J ADV ENG RES, V2, P99
   Morris C., 2014, INT J ADV RES COMPUT, V2, P249
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Nair S, 2013, INT J ADV COMPUT THE, V1, P106
   Nianyi Wang, 2012, Journal of Multimedia, V8, P270, DOI 10.4304/jmm.8.3.270-276
   Nisha G, 2014, INT J EMERGING RES M, V3, P54
   Núñez J, 1999, IEEE T GEOSCI REMOTE, V37, P1204, DOI 10.1109/36.763274
   Pardnya M, 2012, INT J ADV RES COMPUT, V2, P1
   Phadke G., 2014, INT J SCI ENG TECHNO, V3, P375
   Sadhasivam S. K., 2011, ELECT LETT COMPUT VI, V10, P1, DOI DOI 10.5565/REV/ELCVIA.353
   Sahu Akanksha, 2014, 2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom), P448, DOI 10.1109/MedCom.2014.7006050
   Sahu D., 2012, Int. J. Mod. Eng. Res. (IJMER), V2, P4298
   Sale D, 2012, INT J ENG RES APPL, V2, P686
   Savitha V, 2014, INT J RES ENG ADV TE, V1, P1
   Shabanzade F, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P178, DOI 10.1109/AISP.2017.8324077
   Siddiqui AB, 2011, INT J INNOV COMPUT I, V7, P3583
   Svab A, 2006, PHOTOGRAMM ENG REM S, V72, P565
   Tang MF, 2017, NEUROCOMPUTING, V225, P58, DOI 10.1016/j.neucom.2016.11.012
   Tank P., 2013, IOSR J VLSI SIGNAL P, V1, P32, DOI [10.9790/4200-0153236, DOI 10.9790/4200-0153236]
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Wakure S, 2013, IOSR J VLSI SIGNAL P, V1, P42
   Wan T, 2008, IEEE IMAGE PROC, P1308, DOI 10.1109/ICIP.2008.4712003
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Wilson T, 1995, OPT ENG, V34
   Yang W, 2013, MATH PROBL ENG, V10
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430
   Yuehao Wang, 2013, Journal of Convergence Information Technology, V8, P179, DOI 10.4156/jcit.vol8.issue8.22
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Z, 2009, COMPUT MATH APPL, V57, P1265, DOI 10.1016/j.camwa.2008.11.013
   Zheng Y, 2004, P SOC PHOTO-OPT INS, V5298, P177, DOI 10.1117/12.523966
   Zhou X., 2013, ADV MECH ENG, V1, P1
NR 70
TC 21
Z9 24
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1235
EP 1263
DI 10.1007/s11042-018-6229-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700002
DA 2024-07-18
ER

PT J
AU Shi, ZH
   Hao, H
   Zhao, MH
   Feng, YN
   He, LF
   Wang, YH
   Suzuki, K
AF Shi, Zhenghao
   Hao, Huan
   Zhao, Minghua
   Feng, Yaning
   He, Lifeng
   Wang, Yinghui
   Suzuki, Kenji
TI A deep CNN based transfer learning method for false positive reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE False positive reduction; Nodule detection; Deep convolutional network;
   Support vector machine
ID PULMONARY NODULE DETECTION; COMPUTER-AIDED DETECTION; CT IMAGES; LUNG
   NODULES
AB A low false positive (FP) rate is of great importance for the use of a Computer Aided Detection (CAD) system to detect pulmonary nodules in thoracic Computed Tomography (CT). However, due to the variations of nodules in appear and size, it is still a very challenging task to obtain a low FP rate. In this paper, we propose a deep Convolutional Neural Network (CNN) based transfer learning method for FP reduction in pulmonary nodule detection on CT slices. We utilized one of the state-of-the-art CNN models, VGG-16 [4], as a feature extractor to obtain nodule features, and used a support vector machine (SVM) for nodule classification. Firstly we transferred all the layers from a pre-trained VGG-16 model in ImageNet to our target networks. Then, we tuned the last fully connected layers to adjust the computer-vision-task-trained CNN model to pulmonary nodule classification task. The initial CNN filter weights were then optimized using the training data, i.e., the pulmonary nodule patch images and corresponding labels through back-propagation so that they better reflected the modalities in the pulmonary nodule image dataset. Finally, features learned in the fine-tuned CNN were used to train a SVM classifier. The output of the trained SVM was used for final classification. Experimental results show that the overall sensitivity of the proposed method was 87.2% with 0.39 FPs per scan, which is higher than 85.4% with 4 FPs per scan obtained by other state of art method.
C1 [Shi, Zhenghao; Hao, Huan; Zhao, Minghua; Feng, Yaning; Wang, Yinghui] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [He, Lifeng] Aichi Prefectural Univ, Sch Informat Sci & Technol, Nagakute, Aichi 4801198, Japan.
   [Suzuki, Kenji] IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
   [Suzuki, Kenji] Tokyo Inst Technol, Inst Innovat Res, World Res Hub Initiat, Yokohama, Kanagawa 2268503, Japan.
C3 Xi'an University of Technology; Illinois Institute of Technology; Tokyo
   Institute of Technology
RP Shi, ZH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.; He, LF (corresponding author), Aichi Prefectural Univ, Sch Informat Sci & Technol, Nagakute, Aichi 4801198, Japan.; Suzuki, K (corresponding author), IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.; Suzuki, K (corresponding author), Tokyo Inst Technol, Inst Innovat Res, World Res Hub Initiat, Yokohama, Kanagawa 2268503, Japan.
EM ylshi@xaut.edu.cn; helifeng@ist.aichi-pu.ac.jp; ksuzuki@iit.edu
RI wang, yinghui/GWV-7334-2022; Suzuki, Kenji/A-1284-2007
OI Suzuki, Kenji/0000-0002-3993-8309
FU National Natural Science Foundation of China [61202198, 61401355]; China
   Scholarship Council [201608610048]; Nature Science Foundation of Science
   Department of PeiLin count at Xi'an [GX1619]; Key Laboratory Foundation
   of Shaanxi Education Department, China [14JS072]
FX This work was supported in part by a grant from the National Natural
   Science Foundation of China (No. 61202198, No.61401355), a grant from
   the China Scholarship Council (No.201608610048) and the Nature Science
   Foundation of Science Department of PeiLin count at Xi'an(GX1619), the
   Key Laboratory Foundation of Shaanxi Education Department, China
   (No.14JS072). The authors gratefully acknowledge the helpful comments
   and suggestions of the reviewers.
CR [Anonymous], P MICCAI
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, Med Imaging Technol
   [Anonymous], INT J BIOMED IMAGING
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2013, J PATHOL INFORM
   [Anonymous], 2017, MEDICAL IMAGING INFO, DOI DOI 10.11318/MII.34.14
   [Anonymous], P SPIE MED IMAG
   [Anonymous], ABS14124564 CORR
   Camarlinghi N, 2013, EUR PHYS J PLUS, V128, DOI 10.1140/epjp/i2013-13110-5
   Dhara AK, 2012, IETE TECH REV, V29, P265, DOI 10.4103/0256-4602.101306
   Farag A, 2011, I S BIOMED IMAGING, P169, DOI 10.1109/ISBI.2011.5872380
   Gao M, 2015, 1 WORKSH DEEP LEARN
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Jiang HY, 2018, IEEE J BIOMED HEALTH, V22, P1227, DOI 10.1109/JBHI.2017.2725903
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Li F, 2005, RADIOLOGY, V237, P684, DOI 10.1148/radiol.2372041555
   Liang MZ, 2016, RADIOLOGY, V281, P279, DOI 10.1148/radiol.2016150063
   Liu JK, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0669-0
   Lu L, 2015, MED PHYS, V42, P5042, DOI 10.1118/1.4927573
   Margeta J, 2015, Comput Methods Biomech Biomed Eng, Imag Vis, P1
   Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Sivakumar S, 2013, INT J ENG TECHNOL, V5, P179
   Song Y, 2013, IEEE T MED IMAGING, V32, P797, DOI 10.1109/TMI.2013.2241448
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Suzuki K, 2013, IEICE T INF SYST, VE96D, P772, DOI 10.1587/transinf.E96.D.772
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Valente IRS, 2016, COMPUT METH PROG BIO, V124, P91, DOI 10.1016/j.cmpb.2015.10.006
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Ye J, 2018, FUTURE GENER COMP SY, V81, P433, DOI 10.1016/j.future.2017.09.030
   Zhang JP, 2018, IEEE J BIOMED HEALTH, V22, P1521, DOI 10.1109/JBHI.2017.2775662
   Zhang JJ, 2018, BIOMED SIGNAL PROCES, V43, P138, DOI 10.1016/j.bspc.2018.01.011
   Zheng YF, 2015, LECT NOTES COMPUT SC, V9349, P565, DOI 10.1007/978-3-319-24553-9_69
NR 41
TC 77
Z9 81
U1 0
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1017
EP 1033
DI 10.1007/s11042-018-6082-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500057
DA 2024-07-18
ER

PT J
AU Wang, HX
   Liu, PZ
   Du, YZ
   Liu, XF
AF Wang, Hongxiang
   Liu, Peizhong
   Du, Yongzhao
   Liu, Xiaofang
TI Online convolution network tracking via spatio-temporal context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Spatio-temporal context; Convolutional neural network
   (CNN); Particle filter
AB According to the lack of spatio-temporal information of convolution neural network abstraction, an online visual tracking algorithm based on convolution neural network is proposed, combining the spatio-temporal context model to the order filter of convolution neural network. Firstly, the initial target is preprocessed and the target spatial model is extracted, the spatio-temporal context model is obtained by the spatio-temporal information. The first layer adopts the spatio-temporal context model to convolve the input to obtain the simple layer feature. The second layer starts with skip the spatio-temporal context model to get a set of convolution filters, convolving with the simple features of the first layer to extract the target abstract features, and then the deep expression of the target can be obtained by superimposing the convolution results of the simple layer. Finally, the target tracking is realized by sparse updating method combining with particle filter tracking framework. Experiments show that deep abstract feature extracted by online convolution network structure combining with spatio-temporal context model, can preserve spatio-temporal information and improve the background clutters, illumination variation, low resolution, occlusion and scale variation and the tracking efficiency under complex background.
C1 [Wang, Hongxiang; Liu, Peizhong; Du, Yongzhao; Liu, Xiaofang] Huaqiao Univ, Coll Engn, Quanzhou, Fujian, Peoples R China.
C3 Huaqiao University
RP Du, YZ (corresponding author), Huaqiao Univ, Coll Engn, Quanzhou, Fujian, Peoples R China.
EM kakadadudu@163.com; pzliu@hqu.edu.cn; yongzhaodu@126.com;
   17750020683@163.com
FU Nature Science Foundation of China [61605048]; Fujian Provincial Natural
   Science Foundation [2016 J01300]
FX This work is supported by the Nature Science Foundation of China (Grant
   No. 61605048), and the Fujian Provincial Natural Science Foundation
   Projects Grant (No. 2016 J01300).The authors would like to thank the
   reviewers for their valuable suggestions and comments.
CR [Anonymous], 2012, CVPR
   [Anonymous], 2012, ECCV
   [Anonymous], 2015, ICCV
   [Anonymous], 2015, ICCV
   [Anonymous], 2015, IEEE T PATTERN ANAL
   [Anonymous], 2016, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46448-0_45
   [Anonymous], 2016, ECCV
   [Anonymous], 2014, CVPR
   [Anonymous], 2013, NIPS
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, IEEE
   [Anonymous], 2016, CVPR
   [Anonymous], 2012, ECCV
   Bao C., 2012, CVPR
   Bolme DS, 2010, ICCV
   Chi ZZ, 2017, TIP
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Kalal Z., 2012, IEEE T PATTERN ANAL
   Nam H., 2016, Modeling and propagating CNNs in a tree structure for visual tracking
   Wu Y., 2013, CVPR
   Zhang K., 2014, ECCV
   Zhang Kaihua, 2016, TIP
NR 26
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 257
EP 270
DI 10.1007/s11042-017-5533-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500014
DA 2024-07-18
ER

PT J
AU Zhou, HJ
   Li, ZC
AF Zhou, Huajun
   Li, Zechao
TI Deep networks with non-static activation function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Activation neuron; Convolution network; Feature
   learning
AB Deep neural networks typically with a fixed activation function at each neuron, have shown breakthrough performances. The fixed activation function is not the optimal choice for different data distributions. Toward this end, this work improves the deep neural networks by proposing a novel and efficient activation scheme called Mutual Activation (MAC). A non-static activation function is adaptively learned in the training phase of deep network. Furthermore, the proposed activation neuron cooperating with maxout is a potent higher-order function approximator, which can break through the convex curve limitation. Experimental results on object recognition benchmarks demonstrate the effectiveness of the proposed activation scheme.
C1 [Zhou, Huajun; Li, Zechao] Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Li, ZC (corresponding author), Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM mootheszhou@gmail.com; zechao.li@njust.edu.cn
OI Zhou, Huajun/0000-0002-1419-5422
FU 973 Program [2014CB347600]; National Natural Science Foundation of China
   [61772275, 61720106004, 61672285, 61672304]; Natural Science Foundation
   of Jiangsu Province [BK20170033]
FX This work was partially supported by the 973 Program (Project No.
   2014CB347600), the National Natural Science Foundation of China (Grant
   No. 61772275, 61720106004, 61672285 and 61672304) and the Natural
   Science Foundation of Jiangsu Province (BK20170033).
CR Agostinelli Forest., 2015, ICLR
   [Anonymous], 2016, ICML
   Chen YS, 2015, ARXIV151102583151025
   Clevert D., 2016, ARXIV151107289
   Glorot X, 2011, ASISTATS
   Glorot X, 2010, UNDERSTANDING DIFFIC
   Goodfellow IJ, 2013, ARXIV13024389
   Gulcehre C, 2014, ICML
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mishkin D., 2016, ICLR
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Romero A., 2015, ICLR, P1, DOI DOI 10.48550/ARXIV.1412.6550
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava RK, 2015, ARXIV150500387
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Q, 2017, IEEE T VEH TECHNOL, V66, P8001, DOI 10.1109/TVT.2017.2685526
NR 30
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 197
EP 211
DI 10.1007/s11042-018-5702-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500011
DA 2024-07-18
ER

PT J
AU Khokhlova, M
   Migniot, C
   Dipanda, A
AF Khokhlova, Margarita
   Migniot, Cyrille
   Dipanda, Albert
TI Advances in description of 3D human motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human motion description; 3D Motion; Action recognition; Gesture
   recognition; Gait assessment
ID GAIT RECOGNITION; GESTURE RECOGNITION; REAL-TIME; KINECT; IMAGE
AB This paper aims to provide a comprehensive reference source on depth-based human motion descriptors. Motion description is a challenging problem which became popular with recent advances in 3D computer vision. Our purpose is twofold. First, we introduce the main trends in human 3D motion descriptor design and evaluation. Second, we present a review of recent methods belonging to three different application categories: action recognition, gesture recognition and gait assessment. Selected categories have different specifics, which allow us to highlight aspects of a motion descriptor construction. A comparison of different methods by their main characteristics is provided. Finally, possible directions and recommendations for future research in 3D motion description are outlined.
C1 [Khokhlova, Margarita; Migniot, Cyrille; Dipanda, Albert] Univ Bourgogne Franche Comte, CNRS, FRE 2005, Le2i, Bourgogne, France.
C3 Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS); CNRS - Institute for Information Sciences & Technologies (INS2I)
RP Khokhlova, M (corresponding author), Univ Bourgogne Franche Comte, CNRS, FRE 2005, Le2i, Bourgogne, France.
EM margarita.khokhlova@u-bourgogne.fr; cyrille.migniot@u-bourgogne.fr;
   albert.dipanda@u-bourgogne.fr
RI Khokhlova, Margarita A/J-5314-2018
FU Region of Burgundy
FX Authors would like to acknowledge with much appreciation Briac Colobert
   from Proteor for his help and interest in this research. A special
   gratitude is given to the Region of Burgundy, who financed this
   research.
CR Alotaibi M., 2015, IEEE SYST APPL TECHN, P1
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2010, P WORKSH DEF REAL PE
   [Anonymous], 2006, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI DOI 10.1109/TPAMI.2006.38
   [Anonymous], 2014, PEOPLES DAILY O 0729
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   [Anonymous], 2009, THESIS
   Auvinet E, 2015, SENSORS-BASEL, V15, P4605, DOI 10.3390/s150304605
   Belghali M, 2017, GEROSCIENCE, V39, P305, DOI 10.1007/s11357-017-9977-7
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   Chenxia Wu, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4362, DOI 10.1109/CVPR.2015.7299065
   Cirujeda Pol, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P657, DOI 10.1109/3DV.2014.10
   Coates A., 2011, P 28 INT C MACH LEAR, V28, P921
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Ding WW, 2015, J VIS COMMUN IMAGE R, V26, P329, DOI 10.1016/j.jvcir.2014.10.009
   Drumond RR, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 1: GRAPP, P215, DOI 10.5220/0006585202150222
   Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654
   Filipe S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P476
   Fiterau Madalina, 2016, 29 C NEUR INF PROCES, V3
   Gao Z, 2017, J VISUAL COMMUNICATI
   Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5
   Gianaria E, 2013, IEEE INT WORKSH MULT, P440, DOI 10.1109/MMSP.2013.6659329
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Hadfield S, 2014, LECT NOTES COMPUT SC, V8690, P758, DOI 10.1007/978-3-319-10605-2_49
   Hadfield S, 2011, IEEE I CONF COMP VIS, P2290, DOI 10.1109/ICCV.2011.6126509
   He Q, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P47, DOI 10.1109/HUMO.2000.897370
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hofmann M., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P399, DOI 10.1109/BTAS.2012.6374606
   Hofmann M, 2014, J VIS COMMUN IMAGE R, V25, P195, DOI 10.1016/j.jvcir.2013.02.006
   Hu MD, 2013, IEEE T CYBERNETICS, V43, P77, DOI 10.1109/TSMCB.2012.2199310
   Jaimez M, 2015, IEEE INT CONF ROBOT, P98, DOI 10.1109/ICRA.2015.7138986
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kale A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P336, DOI 10.1109/AFGR.2002.1004176
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kolawole A, 2012, LECT NOTES COMPUT SC, V7432, P125, DOI 10.1007/978-3-642-33191-6_13
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Kwolek B, 2014, LECT NOTES ARTIF INT, V8398, P595, DOI 10.1007/978-3-319-05458-2_61
   Leightley D, 2015, ASIAPAC SIGN INFO PR, P1, DOI 10.1109/APSIPA.2015.7415438
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lim CD, 2015, IEEE INT CONF ROBOT, P5916, DOI 10.1109/ICRA.2015.7140028
   Litany O, 2017, DEFORMABLE SHAPE COM
   Liu L., 2013, 23 INT JOINT C ART I
   Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Milovanovic M, 2013, IEEE MULTIMEDIA, V20, P28, DOI 10.1109/MMUL.2013.16
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Munaro M, 2013, RSS WORKSH RGB D ADV
   Munaro M, 2013, BIOL INSPIR COGN ARC, V5, P42, DOI 10.1016/j.bica.2013.05.008
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Negin F, 2013, LECT NOTES COMPUT SC, V7950, P648, DOI 10.1007/978-3-642-39094-4_74
   Nordin M. J., 2016, RES J APPL SCI ENG T
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Ohn-Bar E, 2015, IEEE INT VEH SYM, P845, DOI 10.1109/IVS.2015.7225790
   Ohn-Bar E, 2014, IEEE T INTELL TRANSP, V15, P2368, DOI 10.1109/TITS.2014.2337331
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   PADILLALOPEZ JR, 2014, ARXIV14077390
   Paiement Adeline., 2014, British Machine Vision Conference, P153
   Papageorgiou XS, 2015, IEEE INT C INT ROBOT, P6342, DOI 10.1109/IROS.2015.7354283
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Saha PK, 2017, COMPUT VIS PATT REC, P3, DOI 10.1016/B978-0-08-101291-8.00002-X
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Sridhar S, 2016, REAL TIME JOINT TRAC
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sung J., 2011, C PLAN ACT INT REC, V64
   Suryanarayan Poonam, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3105, DOI 10.1109/ICPR.2010.760
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tang J, 2014, SENSORS-BASEL, V14, P6124, DOI 10.3390/s140406124
   Tombari F., 2013, CGLibs Conference in Pisa, P303
   Tosranon P., 2009, IEEE 6 INT C EL ENG, V2, P1124
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yu Kong, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163084
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zhang HL, 2017, NEUROCOMPUTING, V230, P417, DOI 10.1016/j.neucom.2016.12.041
   Zhang H, 2016, IEEE T CIRC SYST VID, V26, P541, DOI 10.1109/TCSVT.2014.2376139
   Zhang H, 2015, IEEE INT CONF ROBOT, P1991, DOI 10.1109/ICRA.2015.7139459
   Zhang JG, 2010, PATTERN RECOGN, V43, P197, DOI 10.1016/j.patcog.2009.05.015
   Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 105
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31665
EP 31691
DI 10.1007/s11042-018-6196-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000007
DA 2024-07-18
ER

PT J
AU Paramanandham, N
   Rajendiran, K
AF Paramanandham, Nirmala
   Rajendiran, Kishore
TI Swarm intelligence based image fusion for noisy images using consecutive
   pixel intensity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block separation; Consecutive pixel intensity similarity; Noise;
   Particle swarm optimization; Tsallis entropy; Mutual information
ID DISCRETE COSINE TRANSFORM; INFORMATION MEASURE
AB A novel image fusion technique is presented, aiming at resolving the fusion problem of noisy images. In this paper, a new activity level measurement based on consecutive pixel intensity similarity is proposed for detecting the noise free and noisy parts from the source images and also the fusion technique is optimized using particle swarm optimization for obtaining the optimized fused image. Experiments have been made on images affected by Gaussian noise, salt and pepper impulsive noise, speckle noise and Poisson noises for examining the efficiency of the proposed algorithm. The proposed framework is evaluated using quantitative metrics such as root mean square error, peak signal to noise ratio, mean absolute error, percentage fit error, structural similarity index and mutual information. The experimental results demonstrate the outperformance of the proposed algorithm over many other well known state-of-the-art fusion techniques reported in the literature.
C1 [Paramanandham, Nirmala; Rajendiran, Kishore] SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
C3 SSN College of Engineering
RP Paramanandham, N (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
EM nirmalap@ssn.edu.in; kishorer@ssn.edu.in
RI Rajendiran, Kishore/AGJ-8384-2022; Paramanandham, Nirmala/ABI-7089-2020
OI Rajendiran, Kishore/0000-0002-0779-6035; 
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Ajay K.B., 2015, Signal & Image Processing, V6, P63, DOI [DOI 10.5121/SIPIJ.2015.6206, 10.5121/sipij.2015.6206]
   [Anonymous], MULTIM TOOLS APPL
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Deepalaxmi R, 2013, IEEE T DIELECT EL IN, V20, P922, DOI 10.1109/TDEI.2013.6518961
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Indu CR, 2009, INT C ADV REC TECHN
   Kausar N, 2016, COMPUT ELECTR ENG, V54, P393, DOI 10.1016/j.compeleceng.2016.01.013
   Khan S., 2016, 6 INT C INN COMP TEC
   Li HF, 2013, J INF SCI ENG, V29, P227
   Li Xushuai, 2015, INT C EL SCI AUT CON
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Loza A, 2010, COMPUT VIS IMAGE UND, V114, P54, DOI 10.1016/j.cviu.2009.09.002
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Paramanandham N, 2018, INFRARED PHYS TECHN, V88, P13, DOI 10.1016/j.infrared.2017.11.006
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rahman SMM, 2010, IET IMAGE PROCESS, V4, P374, DOI 10.1049/iet-ipr.2009.0163
   Raol JitendraR., 2010, MULTISENSOR DATA FUS
   Srivastava R, 2015, IMAGING SCI J, V63, P408, DOI 10.1179/1743131X15Y.0000000025
   Srivastava R, 2013, INT CONF CONTEMP, P497, DOI 10.1109/IC3.2013.6612246
   Toet A, 2010, INFORM FUSION, V11, P95, DOI 10.1016/j.inffus.2009.06.008
   Wang Z., 2005, IEEE T GEOSCI REMOTE, V43
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
NR 26
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32133
EP 32151
DI 10.1007/s11042-018-6233-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000028
DA 2024-07-18
ER

PT J
AU Saravani, S
   Shad, R
   Ghaemi, M
AF Saravani, Shahram
   Shad, Rouzbeh
   Ghaemi, Marjan
TI Iterative adaptive Despeckling SAR image using anisotropic diffusion
   filter and Bayesian estimation denoising in wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic Aperture Radar (SAR); Speckle noise; Wavelet transform;
   Anisotropic diffusion filter; Bilateral filter; Bayesian estimate
ID SPECKLE NOISE-REDUCTION
AB In this paper, a new iterative algorithm has been presented by aggregating Stationary Wavelet Transform (SWT), Bilateral filtering, Bayesian estimation, and Anisotropic Diffusion (AD) filtering to reduce the speckle noise in SAR images. For this purpose, speckle images were first decomposed using two-dimensional stationary wavelet transform and then a suitable filtering method was used to filter respective coefficients of each sub-band of the speckled images. Generally, in wavelet transform-based noise reduction methods, filtering and thresholding techniques are usually applied to the coefficients of the detail sub-bands and the residual speckle noise is ignored in the approximate sub-band. In this paper, bilateral filtering has been applied to reduce the speckle noise in the approximate sub-band. We used Bayesian estimator to calculate the noise-free signal in the horizontal and vertical sub-bands with respect to that some parts of signal coefficients are eliminated in the traditional thresholding techniques. Moreover, we applied anisotropic diffusion filtering method to preserve the edges and structure of image along the diagonal subband which has more details (the entropy is maximum) than other directions in radar and optic images. Finally, both the proposed algorithm and other speckle noise reduction methods were applied on two synthetic speckled images and an actual SAR image in San Francisco. Their efficiencies were compared according to the Structural SIMilarity(SSIM), Peak Signal to Noise Ratio (PSNR), Equivalent Number of Looks (ENL), Speckle Suppression Index (SSI) and Speckle Suppression and Mean Preservation Index (SMPI). The experimental results indicate that the proposed algorithm efficiently reduces the speckle noise and preserves the edges and structure of image.
C1 [Saravani, Shahram; Shad, Rouzbeh; Ghaemi, Marjan] Ferdowsi Univ Mashhad, Fac Engn, Civil Dept, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Shad, R (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Civil Dept, Mashhad, Iran.
EM shahramsaravani1990@gmail.com; r.shad@um.ac.ir; mghaemi270@gmail.com
RI Shad, Rouzbeh/AAA-4026-2020
OI Shad, Rouzbeh/0000-0003-2078-8571
CR Aghababaee H, 2013, SCI IRAN, V20, P15, DOI 10.1016/j.scient.2012.11.006
   Bhateja V, 2015, MEASUREMENT, V74, P246, DOI 10.1016/j.measurement.2015.07.024
   Bianchi T, 2013, DIGIT SIGNAL PROCESS, V23, P1353, DOI 10.1016/j.dsp.2013.04.011
   Choi H, 2018, IEEE SENS J, V18, P3131, DOI 10.1109/JSEN.2018.2794550
   Dellepiane SG, 2014, IEEE J-STARS, V7, P691, DOI 10.1109/JSTARS.2013.2279501
   Finn S, 2011, IEEE T ULTRASON FERR, V58, P82, DOI 10.1109/TUFFC.2011.1776
   Gao Chao, 2010, Journal of Electronics, V27, P405, DOI 10.1007/s11767-010-0407-6
   Gao QW, 2008, APPL MATH COMPUT, V205, P517, DOI 10.1016/j.amc.2008.05.026
   Gove RP, 2012, J THEOR BIOL, V293, P1, DOI 10.1016/j.jtbi.2011.09.034
   Hedaoo P., 2011, IJNSA, V3, P16, DOI DOI 10.5121/IJNSA.2011.3402
   Henri M., 2008, Processing of synthetic aperture radar images
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   KUAN DT, 1987, IEEE T ACOUST SPEECH, V35, P373, DOI 10.1109/TASSP.1987.1165131
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   Mateo JL, 2009, EXPERT SYST APPL, V36, P7786, DOI 10.1016/j.eswa.2008.11.029
   Nason Guy P, 1995, Wavelets and Statistics, P281, DOI [DOI 10.1007/978-1-4612-2544-7_17, 10.1007/978-1-4612-2544-7_17]
   Oliver C, 1998, UNDERSTANDING SYNTHE, P451
   Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Poodanchi M, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P33, DOI 10.1109/IKT.2014.7030329
   Sarawale MR, 2013, INT J ADV RES COMPUT, V2, P2148
   Simsek A., 2011, 2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU 2011), P375, DOI 10.1109/SIU.2011.5929665
   Sveinsson JR, 2003, IEEE T GEOSCI REMOTE, V41, P2404, DOI 10.1109/TGRS.2003.817844
   Vidal-Pantaleoni A., 1999, IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293), P1325, DOI 10.1109/IGARSS.1999.774619
   Wang D, 2015, AEBMR ADV ECON, V3, P6
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wong A, 2010, OPT EXPRESS, V18, P8338, DOI 10.1364/OE.18.008338
   Xie H, 2002, IEEE T GEOSCI REMOTE, V40, P2196, DOI 10.1109/TGRS.2002.802473
   Zhang J, 1998, ICSP '98: 1998 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PROCEEDINGS, VOLS I AND II, P1469, DOI 10.1109/ICOSP.1998.770898
NR 29
TC 8
Z9 8
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31469
EP 31486
DI 10.1007/s11042-018-6153-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600059
DA 2024-07-18
ER

PT J
AU Xie, XL
   Xie, G
   Xu, XY
AF Xie, Xinlin
   Xie, Gang
   Xu, Xinying
TI High precision image segmentation algorithm using SLIC and neighborhood
   rough set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; SLIC; Neighborhood rough set; Superpixel;
   Neighborhood granule
AB A high precision image segmentation algorithm using SLIC and neighborhood rough set is proposed. The algorithm mainly includes two stages: the stage of superpixel generation and the mergence stage based on neighborhood rough set. In superpixel generation stage, based on L-channel color histogram and its peak, the scheme of initial superpixel number generation is proposed according to the complexity of the image itself. For inaccuracy segmentation edge of SLIC caused by isolated pixels, the compactness factor is appropriately increased before they are generated. After that, the scheme of reclassifying each isolated pixel is proposed just relying on the color space. In superpixel mergence stage based on neighborhood rough set, the texture information using the gray level co-occurrence matrix is introduced into the feature representation of superpixel. It can reduce the dependence of color feature and improve the accuracy of the mergence. By constructing the information table, the neighborhood granule of each superpixel is acquired under the neighborhood threshold. Finally, the superpixels within the neighborhood granule are merged on the basis of the spatial adjacency between superpixels. In Berkeley segmentation data set, compared with the SLIC algorithm, the schemes of initial superpixel number generation and the isolated pixels processing are proved to be effective. Furthermore, the experiments demonstrate that the proposed algorithm can produce high-quality and high-precision image segmentation results in comparison with the SLIC-based image segmentation algorithms on three standard metrics.
C1 [Xie, Xinlin; Xie, Gang; Xu, Xinying] Taiyuan Univ Technol, Coll Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
   [Xie, Gang] Taiyuan Univ Sci & Technol, Coll Elect Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Science &
   Technology
RP Xie, G (corresponding author), Taiyuan Univ Technol, Coll Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.; Xie, G (corresponding author), Taiyuan Univ Sci & Technol, Coll Elect Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
EM xiexinlin.tyut@qq.com; xiegang@tyut.edu.cn; xuxinying@tyut.edu.cn
RI Li, Zexi/KFA-6939-2024
OI Xie, Gang/0000-0001-5769-0565
CR Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ates HF, 2016, LECT NOTES COMPUT SC, V9730, P234, DOI 10.1007/978-3-319-41501-7_27
   Bai XD, 2014, OPTIK, V125, P4302, DOI 10.1016/j.ijleo.2014.03.035
   Chen HM, 2016, INFORM SCIENCES, V373, P351, DOI 10.1016/j.ins.2016.09.012
   Chen YM, 2017, SOFT COMPUT, V21, P6907, DOI 10.1007/s00500-016-2393-6
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Guoheng Huang, 2015, International Journal of Computer Theory and Engineering, V7, P489, DOI 10.7763/IJCTE.2015.V7.1007
   Hsu C. - Y., 2013, INTERNATIONAL CONFER, P1
   Hu QH, 2008, INFORM SCIENCES, V178, P3577, DOI 10.1016/j.ins.2008.05.024
   Li BY, 2018, ENERGIES, V11, DOI 10.3390/en11010185
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu B, 2013, IEEE T GEOSCI REMOTE, V51, P907, DOI 10.1109/TGRS.2012.2203358
   Liu FY, 2015, PATTERN RECOGN, V48, P2983, DOI 10.1016/j.patcog.2015.04.019
   Liu Y, 2017, CHEMOMETR INTELL LAB, V169, P35, DOI 10.1016/j.chemolab.2017.08.005
   Lucchi A, 2012, LECT NOTES COMPUT SC, V7573, P400, DOI 10.1007/978-3-642-33709-3_29
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Singla A, 2017, SIGNAL IMAGE VIDEO P, V11, P243, DOI 10.1007/s11760-016-0927-0
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Wang CZ, 2016, KNOWL-BASED SYST, V111, P173, DOI 10.1016/j.knosys.2016.08.009
   Wang MR, 2017, SIGNAL PROCESS-IMAGE, V56, P28, DOI 10.1016/j.image.2017.04.007
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang YX, 2017, IEEE T CIRC SYST VID, V27, P1502, DOI 10.1109/TCSVT.2016.2539839
NR 32
TC 9
Z9 10
U1 1
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31525
EP 31543
DI 10.1007/s11042-018-6150-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000001
DA 2024-07-18
ER

PT J
AU Han, B
   Wu, YQ
AF Han, Bin
   Wu, Yiquan
TI A hybrid active contour model driven by novel global and local fitting
   energies for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Active contour model; Weighted global fitted image;
   Cross entropy
ID INFORMATION
AB This paper proposes a hybrid active contour model driven by novel global and local fitting energies for image segmentation. First, the global fitting term is defined by minimizing the difference between the weighted global fitted image and the original image, which describes the global information more accurately. Second, the local fitting term is defined by the cross entropy to compute the local information, which improves the generality of the proposed model. Experiments are performed on synthetic and real images and the results demonstrate that compared with existing active contour models, the proposed model has advantages in terms of segmentation performance and robustness to initial contour and noise.
C1 [Han, Bin; Wu, Yiquan] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Jiang Jun Ave 29, Nanjing 211106, Jiangsu, Peoples R China.
   [Wu, Yiquan] Yellow Water Resources Commiss, Key Lab Yellow River Sediment, Minist Water Resources, Yellow River Inst Hydraul Res, Zhengzhou, Henan, Peoples R China.
   [Wu, Yiquan] Nanjing Hydraul Res Inst, Minist Transport, Key Lab Port Waterway & Sedimentat Engn, Nanjing, Jiangsu, Peoples R China.
   [Wu, Yiquan] Harbin Inst Technol, State Key Lab Urban Water Resources & Environm, Harbin, Heilongjiang, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Yangtze River Water
   Resources Protection Bureau; Nanjing Hydraulic Research Institute;
   Harbin Institute of Technology
RP Wu, YQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Jiang Jun Ave 29, Nanjing 211106, Jiangsu, Peoples R China.; Wu, YQ (corresponding author), Yellow Water Resources Commiss, Key Lab Yellow River Sediment, Minist Water Resources, Yellow River Inst Hydraul Res, Zhengzhou, Henan, Peoples R China.; Wu, YQ (corresponding author), Nanjing Hydraul Res Inst, Minist Transport, Key Lab Port Waterway & Sedimentat Engn, Nanjing, Jiangsu, Peoples R China.; Wu, YQ (corresponding author), Harbin Inst Technol, State Key Lab Urban Water Resources & Environm, Harbin, Heilongjiang, Peoples R China.
EM nuaaimagestrong@163.com
FU National Natural Science Fund of China [61573183]; Funding for
   Outstanding Doctoral Dissertation in NUAA [BCXJ18-04]; Key Laboratory of
   Yellow River Sediment of Ministry of Water Resources [2014006];
   Engineering Technology Research Center of Wuhan Intelligent Basin
   [CKWV2013225/KY]; State Key Laboratory of Urban Water Resources and
   Environment [LYPK201304]
FX This work is partially supported by the National Natural Science Fund of
   China under Grant 61573183, Funding for Outstanding Doctoral
   Dissertation in NUAA under Grant BCXJ18-04, Key Laboratory of Yellow
   River Sediment of Ministry of Water Resources under Grant 2014006,
   Engineering Technology Research Center of Wuhan Intelligent Basin under
   Grant CKWV2013225/KY, State Key Laboratory of Urban Water Resources and
   Environment under Grant LYPK201304.
CR Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Dong FF, 2013, IMAGE VISION COMPUT, V31, P809, DOI 10.1016/j.imavis.2013.08.003
   Han B, 2017, PATTERN RECOGN, V67, P396, DOI 10.1016/j.patcog.2017.02.022
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Jiang XL, 2015, OPTIK, V126, P5672, DOI 10.1016/j.ijleo.2015.09.021
   Jiang XL, 2014, OPTIK, V125, P6445, DOI 10.1016/j.ijleo.2014.06.152
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li Q, 2016, SIGNAL PROCESS, V120, P185, DOI 10.1016/j.sigpro.2015.08.020
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu WP, 2013, PATTERN RECOGN LETT, V34, P655, DOI 10.1016/j.patrec.2013.01.005
   Ma Z, 2010, MED ENG PHYS, V32, P766, DOI 10.1016/j.medengphy.2010.05.002
   Mondal A, 2016, APPL SOFT COMPUT, V47, P191, DOI 10.1016/j.asoc.2016.05.026
   Shi N, 2016, OPTIK, V127, P1037, DOI 10.1016/j.ijleo.2015.09.184
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang H, 2014, INFORM SCIENCES, V263, P43, DOI 10.1016/j.ins.2013.10.033
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wen WY, 2014, OPTIK, V125, P6995, DOI 10.1016/j.ijleo.2014.07.090
   Yu CY, 2013, COMPUT MATH APPL, V65, P1746, DOI 10.1016/j.camwa.2013.03.021
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhou SP, 2016, NEUROCOMPUTING, V186, P107, DOI 10.1016/j.neucom.2015.12.073
NR 24
TC 2
Z9 3
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29193
EP 29208
DI 10.1007/s11042-018-6127-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500060
DA 2024-07-18
ER

PT J
AU Hargood, C
   Millard, DE
   Weal, MJ
AF Hargood, Charlie
   Millard, David E.
   Weal, Mark J.
TI The thematic modelling of subtext
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Narrative; Term expansion; Thematics; Narrative cohesion; Semiotics;
   Multimedia mining
ID ONTOLOGY
AB Narratives form a key component of multimedia knowledge representation on the Web. However, many existing multimedia narrative systems either ignore the narrative qualities of any media, or focus on the literal depicted content ignoring any subtext. Ignoring narrative subtext can lead to erroneous search results, or automatically remixed content that lacks cohesion. We suggest that subtext can be computationally modeled in terms of Tomashevsky's hierarchy of themes and motifs. These elements can then be used in a semiotic term expansion algorithm, incorporating knowledge of subtext into search and subsequent narrative generation. We present two experimental applications of this technique. In the first, we use our thematic model in the automatic construction of photo montages from Flickr, comparing it to more traditional term expansion based on co-occurrence, and showing that this improves the perceived relevance of images within the montage. In the second, we use the thematic model in order to automatically identify Flickr images to illustrate short stories, where it dampened the perception of unwanted themes (an effect we describe as reducing thematic noise). Our work is among the first in this space, and shows that thematic subtext can be tackled computationally.
C1 [Hargood, Charlie] Bournemouth Univ, Poole BH12 5BB, Dorset, England.
   [Millard, David E.] Univ Southampton, Comp Sci, Elect & Comp Sci, Southampton, Hants, England.
   [Weal, Mark J.] Univ Southampton, Web & Internet Sci Grp, Elect & Comp Sci, Southampton, Hants, England.
C3 Bournemouth University; University of Southampton; University of
   Southampton
RP Hargood, C (corresponding author), Bournemouth Univ, Poole BH12 5BB, Dorset, England.
EM chargood@bournemouth.ac.uk; dem@ecs.soton.ac.uk; mjw@ecs.soton.ac.uk
OI Hargood, Charlie/0000-0002-5067-5941
CR Adams B, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P12, DOI 10.1145/2736277.2741137
   Agrawal Rakesh, 2009, P 2 ACM INT C WEB SE, P5, DOI DOI 10.1145/1498759.1498766
   Al-Khalifa H.S., 2006, IADIS-INT J COMPUT S, V7, P132
   Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556
   Bal Mieke., 1998, NARRATOLOGY INTRO TH
   BARTHES R, 1975, NEW LITERARY HIST, V6, P237, DOI 10.2307/468419
   Bischoff K, 2009, ACM-IEEE J CONF DIG, P285
   Booth W, 1974, THE RHETORIC OF FICT, P69
   BOWIE M., 1979, Structuralism and Since, From Levi-Strauss to Derrida
   BRUNER J, 1991, CRIT INQUIRY, V18, P1, DOI 10.1086/448619
   Buscaldi D, 2005, CLEF 2005 WORKING NO
   Fox Harrell D., 2005, Proceedings of the Sixth Digital Arts and Culture Conference, P133
   Friedland G, 2013, MULTIMED TOOLS APPL, V63, P387, DOI 10.1007/s11042-011-0877-z
   Fu GH, 2005, LECT NOTES COMPUT SC, V3761, P1466
   Gee K., 2001, ACMJ. Computer Documentation, V25, P3, DOI DOI 10.1145/383948.383950
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P193, DOI 10.3758/BF03195564
   Hargood C., 2010, HT 10 P 21 ACM C HYP, P19
   Hargood C, 2011, NARRATIVE AND HYPERT
   Hargood C, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P135
   Hargood C, 2010, NEW REV HYPERMEDIA M, V16, P71, DOI 10.1080/13614568.2010.499571
   JafariAsbagh M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0237-x
   Jewell M, 2005, MULTIMEDIA INFORMATI
   Jinxi Xu, 1996, SIGIR Forum, P4
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Jung JE, 2017, MULTIMED TOOLS APPL, V76, P10371, DOI 10.1007/s11042-016-3626-5
   Kaiser R, 2009, MULTIMED TOOLS APPL, V41, P437, DOI 10.1007/s11042-008-0242-z
   Kubek M, 2014, RECENT ADVAN INFORM, V265, P63
   Kuzey E, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P915, DOI 10.1145/2872427.2883055
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lombardo V, 2012, MULTIMED TOOLS APPL, V59, P407, DOI 10.1007/s11042-011-0813-2
   Lugmayr A, 2017, MULTIMED TOOLS APPL, V76, P15707, DOI 10.1007/s11042-016-3865-5
   Mandala R., 1999, COMBINING MULTIPLE E
   Matsuo Y, 2003, KEYWORD EXTRACTION F
   Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238
   McAdams DP, 2006, J CONSTR PSYCHOL, V19, P109, DOI 10.1080/10720530500508720
   McNamara D, 2002, TECH REP
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Musarra-Schroeder U, 1996, IL LABIRINTO E LA RE, V519
   Orellana-Rodriguez C., 2015, P 26 ACM C HYP SOC M, P185, DOI 10.1145/2700171.2791042
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Riedl MO, 2006, IEEE COMPUT GRAPH, V26, P23, DOI 10.1109/MCG.2006.56
   Saussure F., 1980, Course in general linguistics
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   TOMASHEVSKY B, 1965, RUSSIAN FORMALIST CR, P66
   Voorhees E. M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P61
   Weal MJ, 2007, INT J HUM-COMPUT ST, V65, P537, DOI 10.1016/j.ijhcs.2007.02.001
   Wolff A., 2013, P ACM HYP SOC MED NY, P79
   Zhou XS, 2002, IEEE MULTIMEDIA, V9, P23, DOI 10.1109/93.998050
NR 53
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28281
EP 28308
DI 10.1007/s11042-018-5972-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500022
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Shin, BS
   Sung, SK
AF Shin, Byeong-Seok
   Sung, Su-Kyung
TI Explosion simulation for viscoelastic objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle-based fluid simulations; Viscoelastic materials; Yield
   condition; Explosion simulation
ID ANIMATION; FLUIDS
AB In particle-based fluid simulations, viscoelastic materials, which exist in intermediate forms between fluids and perfect elastic bodies, require yield stress for material deformation. Existing studies on particle-based viscoelastic materials can represent the deformation of viscoelastic materials using the von Mises yield criterion, but not the explosion. In this study, we propose an ideal viscoelastic material yield criterion developed by modifying the Tresca yield criterion that can be easily approximated using the difference between the maximum principal stress and the minimum principal stress. This is different from the von Mises yield criterion in which the forces in numerous directions applied to an object are calculated. Unlike existing particle-based simulations that represent forces applied to an object as deformed lengths in order to easily approximate the von Mises yield criterion, the proposed ideal viscoelastic material yield criterion assumes the area of the object deformed owing to the forces applied to it as the principal stress. The moment at which the object is subjected to the largest force is approximated as the maximum principal stress, and the moment at which the object is subjected to the smallest force is approximated as the minimum principal stress. Using this method, we can realistically represent the process through which a viscoelastic material explodes because it cannot endure the critical stress when its interface decreases beyond the ideal yield criterion.
C1 [Shin, Byeong-Seok; Sung, Su-Kyung] Inha Univ, Dept Comp Engn, Incheon, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Engn, Incheon, South Korea.
EM bsshin@inha.ac.kr; rebirth87@naver.com
FU INHA UNIVERSITY Research Grant
FX This work was supported by the INHA UNIVERSITY Research Grant.
CR [Anonymous], 2003, P ACM SIGGRAPH EUR S
   [Anonymous], J CONVERG
   Bostanci E, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0040-3
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   Cazacu O, 2014, EUR J MECH A-SOLID, V47, P194, DOI 10.1016/j.euromechsol.2014.04.004
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Andrade LFD, 2015, COMPUT GRAPH-UK, V52, P106, DOI 10.1016/j.cag.2015.07.021
   Desbrun Mathieu, 1996, SMOOTHED PARTICLES N, P61
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Gerszewski D., 2009, SCA 09, P133, DOI DOI 10.1145/1599470.1599488
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Hirt C. W., 1970, Journal of Computational Physics, V5, P103, DOI 10.1016/0021-9991(70)90055-0
   Jeon J, 2016, J INF PROCESS SYST, V12, P612, DOI 10.3745/JIPS.02.0048
   Kavakli M, 2015, HUMAN CTR COMPUTING, V5, P1
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Peer A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766925
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Singh MM, 2017, J INF PROCESS SYST, V13, P559, DOI 10.3745/JIPS.04.0033
   Song W, 2017, HUMAN CTR COMPUTING, V7, P1
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Tonnesen DL, 1998, THESIS
NR 23
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30135
EP 30147
DI 10.1007/s11042-018-6438-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800055
DA 2024-07-18
ER

PT J
AU Bharti, SS
   Gupta, M
   Agarwal, S
AF Bharti, Shambhu Shankar
   Gupta, Manish
   Agarwal, Suneeta
TI A novel approach for verifiable (<i>n</i>, <i>n</i>) audio secret
   sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret share; Audio security; Internet telephony; Secret audio storage;
   Secret audio communication
AB Audio is a natural way of communication among persons. Nowadays, many cases of Phone-tapping, hacking of E-mail having some audio files have been reported. Hence, for sending a secret message in audio file over the internet, security and confidentiality must be assured. A secret message is commonly transmitted in encrypted form to assure confidentiality/security using a single key. This does not serve the purpose completely as knowing the key, the whole secret can be revealed. To enhance the security of the secret, sending it through multiple units is preferred. Here, a novel approach is proposed for the same. In the proposed approach an audio secret is divided into n audio shares such that information contained in any proper subset of share/shares (unit) is insignificant. With all the shares only secret can be revealed after performing some computation. Authenticity of the revealed secret can also be confirmed (if necessary) by checking the integrity of individual shares received. If any share is lost during transmission, the proposed scheme has the facility to determine the share number of the lost one, so that request may be sent for resending the same. The proposed scheme is suitable for real-time audio communication as the construction of shares is based upon the available bandwidth. Also, it does not need any cover audio to transmit the share. Experimentally, Mean Opinion Score (MOS) and correlation coefficient (r(S, S-r)) between input secret and revealed secret are found 5 and 0.99 respectively when there is no attack during the transmission. In case the total (either in one or more shares) attack is less than 50% of the size of a single share, MOS of the revealed secret lies between 3.8 to 4.
C1 [Bharti, Shambhu Shankar; Gupta, Manish] Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
   [Agarwal, Suneeta] Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; National Institute of Technology (NIT System);
   Motilal Nehru National Institute of Technology
RP Bharti, SS (corresponding author), Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM shambhu4u08@gmail.com; manishymca2007@gmail.com; suneeta@mnnit.ac.in
RI Bharti, Shambhu Shankar/GPW-9483-2022; gupta, manish/HIK-2539-2022;
   Gupta, Manish/KUF-1228-2024
OI bharti, shambhu shankar/0000-0003-3563-8226
CR Baby A., 2016, P COMM BAS BUILD LAN, P37
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Desmedt Y, 1998, LECT NOTES COMPUT SC, V1514, P392
   Ehdaie M, 2008, 2008 INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS, VOLS 1 AND 2, P13, DOI 10.1109/ISTEL.2008.4651264
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Lin CC, 2003, J INF SCI ENG, V19, P605
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mohammad E, 2008, INT C TEL ICT 08 JUN
   Nishimura R, 2005, LECT NOTES ARTIF INT, V3682, P1152
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Socek D., 2005, 2005 IEEE International Conference on Electro Information Technology (IEEE Cat. No. 05EX1098C)
   Vyavahare S., 2016, ANAL SECRET SHARING, V137, P39
   Wang JZ, 2015, INT CARN CONF SECU, P211, DOI 10.1109/CCST.2015.7389684
   Yang CN, 2002, J INF SCI ENG, V18, P381
NR 18
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25629
EP 25657
DI 10.1007/s11042-018-5810-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400045
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zhang, SH
   Ji, XM
AF Zhang, Yong
   Zhang, Suhua
   Ji, Xiaomin
TI EEG-based classification of emotions using empirical mode decomposition
   and autoregressive model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG signal; Emotion recognition; Empirical mode decomposition;
   Autoregressive model
ID RECOGNITION; ENTROPY; EMD
AB Emotion can be classified based on 2-dimensional valence-arousal model which includes four categories of emotional states, such as high arousal high valence, low arousal high valence, high arousal low valence, and low arousal low valence. In this paper, we present the attempt to investigate feature extraction of electroencephalogram (EEG) based emotional data by focusing on empirical mode decomposition (EMD) and autoregressive (AR) model, and construct an EEG-based emotion recognition method to classify these emotional states. We first employ EMD method to decompose EEG signals into several intrinsic mode functions (IMFs), and then the features are calculated from IMFs based on AR model using a sliding window, and finally we use these features to recognize emotions. The average recognition rate of our proposed method is 86.28% for 4 binary-class tasks on DEAP dataset. Experimental results show that our proposed method has a uniform and stable performance of emotion recognition, which are quite competitive with the results of methods of comparison.
C1 [Zhang, Yong; Zhang, Suhua; Ji, Xiaomin] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
   [Zhang, Yong] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Liaoning Normal University; Nanjing University
RP Zhang, Y (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.; Zhang, Y (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM zhyong@lnnu.edu.cn
FU National Natural Science Foundation of China [61772252, 61373127];
   Program for Liaoning Innovative Talents in University
FX This work is partly supported by National Natural Science Foundation of
   China (No. 61772252 and No. 61373127), and Program for Liaoning
   Innovative Talents in University.
CR Alarcao S. M., 2017, IEEE T AFFECT COMPUT, DOI [DOI 10.1109/TAFFC.2017.2714671, 10.1109/ TAFFC.2017.2714671, 10.1109/TAFFC.2017.2714671]
   Ali M, 2016, INT CONF UBIQ FUTUR, P946, DOI 10.1109/ICUFN.2016.7536936
   [Anonymous], 2013, T COMPUT SCI 23
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen J, 2015, APPL SOFT COMPUT, V30, P663, DOI 10.1016/j.asoc.2015.01.007
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Das AB, 2016, BIOMED SIGNAL PROCES, V29, P11, DOI 10.1016/j.bspc.2016.05.004
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Güntekin B, 2010, NEUROSCI LETT, V483, P173, DOI 10.1016/j.neulet.2010.08.002
   Guo YN, 2017, IEEE T SYST MAN CY-S, V47, P617, DOI 10.1109/TSMC.2016.2617465
   Hatamikia Sepideh, 2014, J Med Signals Sens, V4, P194
   HUANG NE, 1998, P ROY SOC LOND A MAT, V454, P903, DOI DOI 10.1098/RSPA.1998.0193
   Jie X, 2014, BIO-MED MATER ENG, V24, P1185, DOI 10.3233/BME-130919
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kroupi E, 2016, IEEE T AFFECT COMPUT, V7, P422, DOI 10.1109/TAFFC.2015.2496310
   Li MY, 2017, BIOMED SIGNAL PROCES, V34, P114, DOI 10.1016/j.bspc.2017.01.010
   Li SF, 2013, COMPUT BIOL MED, V43, P807, DOI 10.1016/j.compbiomed.2013.04.002
   Li X, 2016, IEEE INT C BIOINFORM, P352, DOI 10.1109/BIBM.2016.7822545
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Mohammadi Z, 2017, NEURAL COMPUT APPL, V28, P1985, DOI 10.1007/s00521-015-2149-8
   Murugappan Murugappan, 2010, Journal of Biomedical Science & Engineering, V3, P390, DOI 10.4236/jbise.2010.34054
   Nie D, 2011, I IEEE EMBS C NEUR E, P667, DOI 10.1109/NER.2011.5910636
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Petrantonakis PC, 2011, IEEE T INF TECHNOL B, V15, P737, DOI 10.1109/TITB.2011.2157933
   Priestley M., 1994, Spectral analysis and time series (Probability and mathematical statistics)
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Sanchez-Mendoza D, 2015, PATTERN RECOGN LETT, V67, P66, DOI 10.1016/j.patrec.2015.06.007
   Sebe N., 2015, P BRIT MACH VIS C 20
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Pham TD, 2015, LECT NOTES COMPUT SC, V9492, P95, DOI 10.1007/978-3-319-26561-2_12
   Vijayan A, 2015, P CICT, P587
   Vijayan AE, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P587, DOI 10.1109/CICT.2015.24
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Yoon HJ, 2013, COMPUT BIOL MED, V43, P2230, DOI 10.1016/j.compbiomed.2013.10.017
NR 41
TC 49
Z9 51
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26697
EP 26710
DI 10.1007/s11042-018-5885-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500022
DA 2024-07-18
ER

PT J
AU Zhong, FM
   Chen, ZK
   Min, GY
   Ning, ZL
   Zhong, H
   Hu, YM
AF Zhong, Fangming
   Chen, Zhikui
   Min, Geyong
   Ning, Zhaolong
   Zhong, Hua
   Hu, Yueming
TI Combinative hypergraph learning in subspace for cross-modal ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal ranking; Subspace learning; Hypergraph; Similarity
   preserving
ID CANONICAL CORRELATION-ANALYSIS; FACE
AB Recent years have witnessed a surge of interests in cross-modal ranking. To bridge the gap between heterogeneous modalities, many projection based methods have been studied to learn common subspace where the correlation across different modalities can be directly measured. However, these methods generally consider pair-wise relationship merely, while ignoring the high-order relationship. In this paper, a combinative hypergraph learning in subspace for cross-modal ranking (CHLS) is proposed to enhance the performance of cross-modal ranking by capturing high-order relationship. We formulate the cross-modal ranking as a hypergraph learning problem in latent subspace where the high-order relationship among ranking instances can be captured. Furthermore, we propose a combinative hypergraph based on fused similarity information to encode both the intra-similarity in each modality and the inter-similarity across different modalities into the compact subspace representation, which can further enhance the performance of cross-modal ranking. Experiments on three representative cross-modal datasets show the effectiveness of the proposed method for cross-modal ranking. Furthermore, the ranking results achieved by the proposed CHLS can recall 80% of the relevant cross-modal instances at a much earlier stage compared against state-of-the-art methods for both cross-modal ranking tasks, i.e. image query text and text query image.
C1 [Zhong, Fangming; Chen, Zhikui; Ning, Zhaolong; Zhong, Hua] Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
   [Min, Geyong] Univ Exeter, Coll Engn Comp & Math, Exeter, Devon, England.
   [Hu, Yueming] South China Agr Univ, Coll Nat Resources & Environm, Guangzhou, Guangdong, Peoples R China.
C3 Dalian University of Technology; University of Exeter; South China
   Agricultural University
RP Zhong, FM (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
EM fmzhong@mail.dlut.edu.cn; zkchen@dlut.edu.cn; g.min@exeter.ac.uk;
   zhaolongning@dlut.edu.cn; zhonghua@mail.dlut.edu.cn; ymhu163@163.com
RI Hu, Yueming/GLN-2642-2022; Ning, Zhaolong/ABI-3626-2022; zhong,
   hua/JRW-4786-2023
OI Ning, Zhaolong/0000-0002-7870-5524; 
FU Nature Science Foundation of China [61672123]; State Key Program of
   National Natural Science of China [U1301253]; Science and Technology
   Planning Key Project of Guangdong Province [2015B010110006]; National
   Key Research and Development Program of China [2016YFD0800300]; Chinese
   Scholarship Council
FX This work is jointly supported by the Nature Science Foundation of China
   under Grant 61672123, the State Key Program of National Natural Science
   of China under Grant U1301253, the Science and Technology Planning Key
   Project of Guangdong Province under Grant 2015B010110006, the National
   Key Research and Development Program of China under Grant
   2016YFD0800300, and the Chinese Scholarship Council.
CR [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   He R, 2015, IEEE T IMAGE PROCESS, V24, P5543, DOI 10.1109/TIP.2015.2466106
   He X., 2004, MULTIMEDIA '04, P2
   He XF, 2004, ADV NEUR IN, V16, P153
   He YH, 2016, IEEE T MULTIMEDIA, V18, P1363, DOI 10.1109/TMM.2016.2558463
   Irie G, 2015, IEEE I CONF COMP VIS, P1886, DOI 10.1109/ICCV.2015.219
   Jin Y., 2014, J EVIDENCE BASED COM, V2014, P1
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Kitanovski I, 2017, MULTIMED TOOLS APPL, V76, P2955, DOI 10.1007/s11042-016-3261-1
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lienhart R., 2009, Proceeding of the ACM International Conference on Image and Video Retrieval, P1, DOI DOI 10.1145/1646396.1646408
   Liu Hong, 2016, IJCAI, P1767, DOI DOI 10.1109/TIP.2016.2564638
   Liu YH, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P35, DOI 10.1145/3007669.3007716
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu XY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P985, DOI 10.1145/2647868.2655001
   Lu XY, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P433
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Shao J, 2016, NEUROCOMPUTING, V214, P618, DOI 10.1016/j.neucom.2016.06.047
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shixun W, 2013, 3 INT C MULT TECHN I
   Siddiquie B, 2014, P ACM INT C MULT RET, P1
   Simonyan K., 2014, 14091556 ARXIV
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang KY, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P236, DOI 10.1109/ACPR.2013.44
   Wang LQ, 2017, SIGNAL PROCESS, V131, P249, DOI 10.1016/j.sigpro.2016.08.012
   Wang S, 2014, INT C PATT RECOG, P1550, DOI 10.1109/ICPR.2014.275
   Wang SX, 2015, MULTIMED TOOLS APPL, V74, P2009, DOI 10.1007/s11042-013-1737-9
   Wang YQ, 2014, SIGNAL PROCESS, V105, P258, DOI 10.1016/j.sigpro.2014.05.032
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xie L, 2016, SIGNAL PROCESS, V124, P81, DOI 10.1016/j.sigpro.2015.10.010
   Xu JJ, 2012, INT CONF ACOUST SPEE, P2333, DOI 10.1109/ICASSP.2012.6288382
   Xu X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P847, DOI 10.1145/2733373.2806346
   Yao T, 2016, NEUROCOMPUTING, V193, P250, DOI 10.1016/j.neucom.2016.02.016
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhan YZ, 2015, MULTIMED TOOLS APPL, V74, P5513, DOI 10.1007/s11042-014-1866-9
   Zhuang Y., 2013, P 27 AAAI C ART INT, P1070
NR 54
TC 0
Z9 0
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25959
EP 25982
DI 10.1007/s11042-018-5830-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400058
DA 2024-07-18
ER

PT J
AU Zong, JX
   Meng, LL
   Tan, YY
   Zhang, J
   Ren, YW
   Zhang, HX
AF Zong, Jingxiu
   Meng, Lili
   Tan, Yanyan
   Zhang, Jia
   Ren, Yuwei
   Zhang, Huaxiang
TI Adaptive reconstruction based multiple description coding with randomly
   offset quantizations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description coding; Adaptive reconstruction; Prediction mode
ID REDUNDANCY ALLOCATION; CHANNEL; QUANTIZERS; TRANSFORM; SPEECH
AB In this paper, we propose a novel multiple description image coding (MDC) method,which can be called adaptive reconstruction based multiple description coding with randomly offset quantizations (ARMDROQ). In this scheme, two prediction modes are proposed, which are be defined as mode 1 and mode 2 respectively. Specifically, in the proposed ARMDROQ scheme, the input image is partitioned into M subsets and obtaining M descriptions. Then one subset of each description is encoded and decoded directly, while others are predicted encoded and decoded by using adaptive prediction modes. The experimental results show that the proposed scheme achieves better performance than other existing methods.
C1 [Zong, Jingxiu; Meng, Lili; Tan, Yanyan; Zhang, Jia; Ren, Yuwei; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zong, Jingxiu; Meng, Lili; Tan, Yanyan; Zhang, Jia; Ren, Yuwei; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Meng, LL (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Meng, LL (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM 18353116284@163.com; mengll_83@hotmail.com; yytan928@163.com;
   jiazhang@cs.niu.edu; ryw923@126.com; huaxzhang@163.com
RI meng, li/HTQ-7341-2023; meng, li/GVT-2063-2022
FU National Natural Science Foundation of China [61402268, 61401260,
   61373081, 61401408, 61572298, 61601269, 61602285, 61601268]; Technology
   and Development Project of Shandong [2013GGX10125]; Natural Science
   Foundation of Shandong China [BS2014DX006, ZR2014FM012, ZR2015PF006,
   ZR2016FB12]; Taishan Scholar Project of Shandong, China
FX The work is partially supported by the National Natural Science
   Foundation of China (No. 61402268, 61401260, 61373081, 61401408,
   61572298, 61601269, 61602285, 61601268), the Technology and Development
   Project of Shandong (No. 2013GGX10125), the Natural Science Foundation
   of Shandong China (No. BS2014DX006, ZR2014FM012, ZR2015PF006,
   ZR2016FB12) and the Taishan Scholar Project of Shandong, China.
CR Bai HH, 2007, IEEE T CIRC SYST VID, V17, P912, DOI 10.1109/TCSVT.2007.898646
   Bai HH, 2014, IEEE T CIRC SYST VID, V24, P1390, DOI 10.1109/TCSVT.2014.2315770
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   JAYANT NS, 1981, AT&T TECH J, V60, P501, DOI 10.1002/j.1538-7305.1981.tb03069.x
   JAYANT NS, 1981, IEEE T COMMUN, V29, P101, DOI 10.1109/TCOM.1981.1094975
   Jiang WQ, 1998, P SOC PHOTO-OPT INS, V3653, P998, DOI 10.1117/12.334752
   Kazemi M, 2017, IEEE T MULTIMEDIA, V19, P54, DOI 10.1109/TMM.2016.2607342
   Lin CY, 2015, IEEE T CIRC SYST VID, V25, P1016, DOI 10.1109/TCSVT.2014.2367391
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Meng LL, 2013, INT CONF ACOUST SPEE, P2026, DOI 10.1109/ICASSP.2013.6638009
   Meng LL, 2014, IEEE T IMAGE PROCESS, V23, P582, DOI 10.1109/TIP.2013.2288928
   Miguell A. C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P842, DOI 10.1109/ICIP.1999.817251
   Samarawickrama U, 2011, SIGNAL PROCESS, V91, P2277, DOI 10.1016/j.sigpro.2011.03.023
   Samarawickrama U, 2010, IEEE T CIRC SYST VID, V20, P933, DOI 10.1109/TCSVT.2010.2045820
   Sun GQ, 2009, IEEE T IMAGE PROCESS, V18, P1037, DOI 10.1109/TIP.2009.2013068
   Tian C, 2005, IEEE SIGNAL PROC LET, V12, P329, DOI 10.1109/LSP.2005.843764
   Tillo T, 2007, IEEE T IMAGE PROCESS, V16, P673, DOI 10.1109/TIP.2007.891152
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Wang Y, 2002, IEEE T SIGNAL PROCES, V50, P2843, DOI 10.1109/TSP.2002.804062
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Xiao JM, 2013, IEEE T CIRC SYST VID, V23, P1825, DOI 10.1109/TCSVT.2013.2248235
   Zong J., 2016, SIGNAL INFORM PROCES, P1
NR 22
TC 8
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26293
EP 26313
DI 10.1007/s11042-018-5857-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500006
DA 2024-07-18
ER

PT J
AU Bhuiyan, AI
   Hashemi, J
   Shamim, N
   Musa, SM
AF Bhuiyan, Ariful I.
   Hashemi, Javad
   Shamim, Nabila
   Musa, Sarhan M.
TI Tibial eminence: a new anatomical risk factor for anterior cruciate
   ligament injuries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anterior cruciate ligament (ACL); Tibial plateau; Tibial eminence; ACL
   injury; Risk factors
ID VIDEO ANALYSIS; ACL INJURIES; MECHANISMS; KNEE; BASKETBALL; ENTROPY;
   GENDER
AB Recently, the geometry of the tibial plateau has drawn a lot of attention as a source of possible risk factors for anterior cruciate ligament injury. The anterior cruciate ligament injuries may be linked to the intrinsic risk factors associated with the tibial plateau. Discovering this kind of risk factors may help in developing the anterior cruciate ligament (ACL) prevention strategies regardless of gender. In this paper, we hypothesize that subjects with smaller tibial eminence volume and height are more susceptible to ACL injury. We further hypothesize this factor remains significant even after adjusting for inter-subject size differences. The tibial eminence in 52 uninjured controls (32 women and 20 men) and 46 anterior cruciate ligament-injured cases (23 women and 23 men) were measured using magnetic resonance images. A t-test was performed to establish any existing differences between groups. The pooled injured population had less tibial eminence volume (p=0.0021) compared with the pooled uninjured population. We observed that small sized tibial eminence volume could be a major risk factor in anterior cruciate ligament injury.
C1 [Hashemi, Javad] Florida Atlantic Univ, Dept Ocean & Mech Engn, Boca Raton, FL 33431 USA.
   [Shamim, Nabila] Prairie View A&M Univ, Dept Chem Engn, Prairie View, TX USA.
   [Musa, Sarhan M.] Prairie View A&M Univ, Dept Engn Technol, Prairie View, TX USA.
C3 State University System of Florida; Florida Atlantic University; Texas
   A&M University System; Prairie View A&M University; Texas A&M University
   System; Prairie View A&M University
RP Hashemi, J (corresponding author), Florida Atlantic Univ, Dept Ocean & Mech Engn, Boca Raton, FL 33431 USA.
EM prince95me@gmail.com
RI hashemi, javad/V-9954-2019; Shamim, Nabila/AAL-3263-2021; Musa, Sarhan
   M./AGQ-8651-2022
OI Shamim, Nabila/0000-0002-8709-1464; 
FU National Institutes of Health [R01AR050421]
FX The authors gratefully acknowledge the support of Dr. Evelyne Fliszar,
   University of Vermont, for her patient assistance in collecting and
   evaluating the MRI scans. The support of the National Institutes of
   Health (R01AR050421; principal investigator, Bruce Beynnon) is also
   gratefully acknowledged.
CR Ageberg E, 2007, AUST J PHYSIOTHER, V53, P287, DOI 10.1016/S0004-9514(07)70013-2
   Beynnon BD, 2010, J ORTHOP RES, V29, P993
   Boden BP, 2009, AM J SPORT MED, V37, P252, DOI 10.1177/0363546508328107
   Boden BP, 2000, ORTHOPEDICS, V23, P573, DOI 10.3928/0147-7447-20000601-15
   Chaudhari AMW, 2009, AM J SPORT MED, V37, P1282, DOI 10.1177/0363546509332256
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   FINSTERBUSH A, 1990, AM J SPORT MED, V18, P475, DOI 10.1177/036354659001800505
   Garrett GE, 2004, 71 ANN M AM AC ORTH
   Griffin L Y, 2000, J Am Acad Orthop Surg, V8, P141
   Griffin LY, 2006, AM J SPORT MED, V34, P1512, DOI 10.1177/0363546506286866
   Harmon KG, 2000, CLIN SPORT MED, V19, P287, DOI 10.1016/S0278-5919(05)70204-0
   Hashemi J, 2010, AM J SPORT MED, V38, P54, DOI 10.1177/0363546509349055
   Hewett TE, 2006, AM J SPORT MED, V34, P299, DOI 10.1177/0363546505284183
   Ireland ML, 1997, J SPORT REHABIL, V6, P97, DOI 10.1123/jsr.6.2.97
   Ireland ML, 2002, ORTHOP CLIN N AM, V33, P637, DOI 10.1016/S0030-5898(02)00028-7
   Krosshaug T, 2007, AM J SPORT MED, V35, P359, DOI 10.1177/0363546506293899
   McLean SG, 2010, EXERC SPORT SCI REV, V38, P192, DOI 10.1097/JES.0b013e3181f450b4
   Nagano Y, 2009, KNEE, V16, P153, DOI 10.1016/j.knee.2008.10.012
   Renstrom P, 2008, BRIT J SPORT MED, V42, P394, DOI 10.1136/bjsm.2008.048934
   SHAMBAUGH JP, 1991, MED SCI SPORT EXER, V23, P522
   Simon RA, 2010, J BIOMECH, V43, P1702, DOI 10.1016/j.jbiomech.2010.02.033
   Stone KR, 2007, ARTHROSCOPY, V23, P503, DOI 10.1016/j.arthro.2006.12.025
   Uhorchak JM, 2003, AM J SPORT MED, V31, P831, DOI 10.1177/03635465030310061801
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P116, DOI 10.2174/1871527315666161111123638
   Wang SH, 2017, FUND INFORM, V151, P505, DOI 10.3233/FI-2017-1507
   Whiting W.C., 1998, BIOMECHANICS MUSCULO
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
NR 29
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22605
EP 22616
DI 10.1007/s11042-017-4874-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500045
DA 2024-07-18
ER

PT J
AU Kumar, M
   Chhabra, P
   Garg, NK
AF Kumar, Munish
   Chhabra, Payal
   Garg, Naresh Kumar
TI An efficient content based image retrieval system using BayesNet and
   K-NN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; SIFT; ORB; K-Means; LPP; BayesNet; K-NN
ID FEATURES; HEVC
AB In the progression of web and multi-media, substantial measure of pictures is created and appropriated, to viably store and offer such vast measure of bulky database is a big issue. In this way, Content Based Image Retrieval (CBIR) techniques are used to retrieve images from the massive database based on the desired information. In this proposed work, we are considering two local image feature extraction methods, namely, SIFT and ORB. Scale Invariant Feature Transform (SIFT) is used for detecting features and feature descriptor of an image. Oriented Fast Rotated and BRIEF (ORB) uses FAST (Features from Accelerated Segment Test) key point detector and binary BRIEF (Binary Robust Independent Elementary Features) descriptor of an image. K-Means clustering algorithm is also used in the present paper for analyzing the data, which generates number of clusters using the descriptor vector. Locality Preserving Projection (LPP) is employed to reduce the length of the feature vector to enhance the performance of image retrieval system. For classification, we have considered two classifiers, namely, BayesNet and K-Nearest Neighbours (K-NN). Wang image dataset has been used for experimentation work. We have accomplished the highest precision rate of 88.9% using proposed CBIR system.
C1 [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Dept Comp Applicat, Bathinda 151001, Punjab, India.
   [Chhabra, Payal; Garg, Naresh Kumar] Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Dept Comp Sci & Engn, Bathinda 151001, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Dept Comp Applicat, Bathinda 151001, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR ALHAIS Alexandra., 2017, CEDIS Working Papers no51, P1
   [Anonymous], 2016, 2016 INT C COMP TECH, DOI DOI 10.1109/ICCTIDE.2016.7725364
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Kumar TGS, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1193, DOI 10.1109/ICCSP.2016.7754341
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Montazer GA, 2015, OPTIK, V126, P1695, DOI 10.1016/j.ijleo.2015.05.002
   Nister David, 2006, CVPR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Srivastava P, 2016, 2016 IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS ENGINEERING (UPCON), P162, DOI 10.1109/UPCON.2016.7894645
   Vinay A, 2015, PROCEDIA COMPUT SCI, V58, P614, DOI 10.1016/j.procs.2015.08.080
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Zhuo L, 2014, NEUROCOMPUTING, V141, P202, DOI 10.1016/j.neucom.2014.03.014
   [No title captured]
NR 18
TC 56
Z9 56
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21557
EP 21570
DI 10.1007/s11042-017-5587-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300054
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Yang, L
   Li, LD
   Gu, K
   Tang, LJ
AF Zhou, Yu
   Yang, Liu
   Li, Leida
   Gu, Ke
   Tang, Lijuan
TI Reduced-reference quality assessment of DIBR-synthesized images based on
   multi-scale edge intensity similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality evaluation; DIBR; View synthesis; Down-sampling; Multi-scale;
   Edge detection
AB Depth-image-based-rendering (DIBR) plays an important role in view synthesis for free-viewpoint videos. The warping process in DIBR causes geometric displacement, which distributes intensively around edges, and the subsequent rendering process results in the impairment of edges. Traditional 2D image quality metrics are limited in the quality evaluation of DIBR-synthesized images. In this paper, we present a reduced-reference quality metric for DIBR-synthesized images by only extracting several feature values, namely multi-scale Edge Intensity Similarity (EIS). The original and synthesized images are first downsampled to generate images with different resolutions. Then an edge detection process is conducted on each scale and the edge intensity is calculated. The similarity of the edge intensity between each downsampled original image and the corresponding synthesized image is computed. Finally, the average similarity is calculated as the quality score of the DIBR-synthesized image. Experiments conducted on IRCCyN/IVC DIBR image and video databases demonstrate that the proposed method overall outperforms traditional 2D and existing DIBR-targeted quality metrics.
C1 [Zhou, Yu; Li, Leida; Tang, Lijuan] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Yang, Liu] Beijing Res Inst Telemetry, Beijing 100094, Peoples R China.
   [Gu, Ke] Beijing Univ Technol, BJUT Fac Informat Technol, Beijing 100124, Peoples R China.
   [Tang, Lijuan] Jiangsu Vocat Coll Business, Sch Informat & Elect Engn, Nantong 226011, Peoples R China.
C3 China University of Mining & Technology; Beijing University of
   Technology
RP Li, LD (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM lileida@cumt.edu.cn
RI Gu, Ke/AAJ-9684-2021; Li, Li/AEM-3636-2022; li, li/HII-4157-2022
FU Fundamental Research Funds for the Central Universities [2017XKQY084]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities under Grant No. 2017XKQY084.
CR [Anonymous], P SPIE INT SOC OPT E
   [Anonymous], PATTERN CLASSIFICATI
   [Anonymous], 2009, TEST PLAN EVALUATION
   [Anonymous], 2017, IEEE T NEUR NET LEAR
   [Anonymous], 2015, P IEEE TRUE VIS CAPT
   [Anonymous], 1999, SUBJ VID QUA ASS MET
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Bosc E, 2011, SPIE OPTICS PHOTONIC, V8135, P8135
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Fan YC, 2013, IEEE IMTC P, P835
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Gu K, 2014, IEEE IMAGE PROC, P506, DOI 10.1109/ICIP.2014.7025101
   Gu K, 2013, IEEE INT SYMP CIRC S, P1095, DOI 10.1109/ISCAS.2013.6572041
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Huszák A, 2017, MULTIMED TOOLS APPL, V76, P373, DOI 10.1007/s11042-015-3048-9
   Jain R., 1995, MACHINE VISION
   Jung YJ, 2016, IEEE T CIRC SYST VID, V26, P1201, DOI 10.1109/TCSVT.2015.2430632
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Kim HG, 2016, IEEE IMAGE PROC, P1027, DOI 10.1109/ICIP.2016.7532513
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P2811, DOI 10.1109/TIP.2015.2431441
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li LD, 2016, NEUROCOMPUTING, V177, P572, DOI 10.1016/j.neucom.2015.11.063
   Liang Y, 2017, IEEE T VIS COMPUT GR, V23, P1099, DOI 10.1109/TVCG.2016.2517641
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Narwaria M, 2012, IEEE T IMAGE PROCESS, V21, P3364, DOI 10.1109/TIP.2012.2197010
   Ndjiki-Nya P, 2010, IEEE INT CON MULTI, P424, DOI 10.1109/ICME.2010.5583559
   Purica A, 2017, IEEE INT WORKSH MULT
   Ren TW, 2010, IEEE IMAGE PROC, P1569, DOI 10.1109/ICIP.2010.5653559
   Roberts, 1965, MACHINE PERCEPTION 3
   Ryu S, 2014, IEEE IMAGE PROC, P585, DOI 10.1109/ICIP.2014.7025117
   Sandic-Stankovic D., 2015, P IEEE 7 INT WORKSH, P1
   Sandic-Stankovic D, 2016, J ELECTR ENG-SLOVAK, V67, P3, DOI 10.1515/jee-2016-0001
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang Y, 2016, MULTIMED TOOLS APPL, V75, P12499, DOI 10.1007/s11042-014-2321-7
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 55
TC 6
Z9 6
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21033
EP 21052
DI 10.1007/s11042-017-5543-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300032
DA 2024-07-18
ER

PT J
AU Liang, JZ
   Li, M
   Liao, CC
AF Liang, Jiuzhen
   Li, Min
   Liao, Cuicui
TI Efficient numerical schemes for Chan-Vese active contour models in image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chan-Vese; Variational integrators; Image segmentation; Level set
ID VARIATIONAL INTEGRATORS; ALGORITHMS; CONVERGENCE; GEOMETRY
AB In this paper, we introduce multi-symplectic Lagrangian variational integrators for solving Chan-Vese active contour models in image segmentation. Energy functionals are discretized firstly, and numerical schemes are derived from discrete Euler-Lagrange equations based on discrete variational principle. Lagrangian variational integrators preserve native differential structure-multi-symplecticity, that makes the numerical methods have a satisfied behavior. Experiments are performed on the benchmark images from literature. We further evaluated the methods in a segmentation database containing 1023 images. It shows that the proposed numerical schemes attain relatively faster convergence rates and better segmentation accuracy. Comparisons with the standard explicit Euler method of the original Chan-Vese model and other fast numerical optimization methods show that the proposed methods have better stability, higher accuracy, and are more robust when dealing with a large number of pictures. This study provides an example for further research to improve the performance of other existing image segmentation methods based on active contour models.
C1 [Liang, Jiuzhen] Changzhou Univ, 1 Gehu Rd, Changzhou 213164, Peoples R China.
   [Li, Min; Liao, Cuicui] Jiangnan Univ, 1800 Lihu Ave, Wuxi 214122, Peoples R China.
C3 Changzhou University; Jiangnan University
RP Liang, JZ (corresponding author), Changzhou Univ, 1 Gehu Rd, Changzhou 213164, Peoples R China.
EM jzliang@cczu.edu.cn
RI Liang, Jiuzhen/HJG-9384-2022
FU National Natural Science Foundation of China [61170121, 11401259]; Blue
   Project of Universities in Jiangsu Province Training Young Academic
   Leaders Object; Fundamental Research Funds for the Central Universities
   [JUSRR11407]
FX The authors would like to thank all the reviewers for their constructive
   comments. This research was supported by National Natural Science
   Foundation of China(Grant No. 61170121, No. 11401259), Blue Project of
   Universities in Jiangsu Province Training Young Academic Leaders Object,
   Fundamental Research Funds for the Central Universities(JUSRR11407).
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928
   Badshah N, 2009, IEEE T IMAGE PROCESS, V18, P1097, DOI 10.1109/TIP.2009.2014260
   Bar L, 2009, SIAM J IMAGING SCI, V2, P508, DOI 10.1137/080722436
   Boukerroui D, 2012, PATTERN RECOGN, V45, P626, DOI 10.1016/j.patcog.2011.07.007
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chartrand R., 2008, Proceedings of the 2008 International Conference on Image Processing, Computer Vision & Pattern Recognition. IPCV 2008, P212
   Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8
   Feddern C., 2003, PROC 2 IEEE WORKSHOP, P65
   Feng K, 2010, SYMPLECTIC GEOMETRIC ALGORITHMS FOR HAMILTONIAN SYSTEMS, P641
   Focardi M, 2009, DISCRETE CONT DYN-B, V11, P109, DOI 10.3934/dcdsb.2009.11.109
   Focardi M, 2008, INT J NUMER METH ENG, V75, P755, DOI 10.1002/nme.2271
   Forsyth D., 2011, Computer Vision: A Modern Approach
   Ge F, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762250
   Kobayashi T, 2012, LECT NOTES COMPUT SC, V7577, P371, DOI 10.1007/978-3-642-33783-3_27
   Lankton S., 2007, MED IMAGING INT SOC
   Lee S-M, 2005, IEEE INT C IM PROC, V3
   Li Z, FAST LEVEL SET ALGOR
   Marsden JE, 1998, COMMUN MATH PHYS, V199, P351, DOI 10.1007/s002200050505
   Mendi E., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P575
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pan YS, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P350, DOI 10.1109/MMSP.2006.285328
   Pereyra M, 2013, IEEE J-STSP, V7, P700, DOI 10.1109/JSTSP.2013.2258136
   Pi L, 2007, IMAGE VISION COMPUT, V25, P1414, DOI 10.1016/j.imavis.2006.12.013
   Ren DW, 2013, PATTERN RECOGN LETT, V34, P219, DOI 10.1016/j.patrec.2012.09.017
   Scheuermann B., 2013, LNCS, V7724, P745
   Scheuermann B, 2009, LECT NOTES COMPUT SC, V5876, P196, DOI 10.1007/978-3-642-10520-3_18
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi Y, 2005, INT CONF ACOUST SPEE, P97
   Sundaramoorthi G, 2007, INT J COMPUT VISION, V73, P345, DOI 10.1007/s11263-006-0635-2
   Sundaramoorthi G, 2009, INT J COMPUT VISION, V84, P113, DOI 10.1007/s11263-008-0133-9
   Sussman M, 1999, SIAM J SCI COMPUT, V20, P1165, DOI 10.1137/S1064827596298245
   Vankerschaver J, ARXIV11110280
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang ZZ, 2004, LECT NOTES COMPUT SC, V2034, P304
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 39
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16661
EP 16684
DI 10.1007/s11042-017-5232-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300030
DA 2024-07-18
ER

PT J
AU Sajedi, H
AF Sajedi, H.
TI Adaptive Image Steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive Steganography; adaptive Steganalysis; information forensics;
   information hiding
ID CLASSIFIERS
AB Image steganography is the process of sending messages secretly by hiding the message in AN image content. Although steganography hides information in any kinds of digital mediums, digital images are the most popular carrier because of the frequency of usage in the internet. Adaptive steganography methods do not embed a secret message uniformly in images. Steganalytic techniques are used to detect whether an image contains a hidden message by analyzing various image features extracted from stego images which contain hidden messages and cover images with no hidden messages. In this paper, an Adaptive Image Steganalysis (AIS) algorithm is proposed to breakdown adaptive steganography methods. In this method, a suspicieuse block of an image is selected intelligentlly. Afterward, a set of selected features is extracted from this chosen image block. As a result, a feature vector is generated which improves accuracy of steganalysis. Experimental results show that AIS algorithm outperforms other classic steganalysis approaches.
C1 [Sajedi, H.] Univ Tehran, Coll Sci, Dept Math Stat & Comp Sci, Tehran, Iran.
C3 University of Tehran
RP Sajedi, H (corresponding author), Univ Tehran, Coll Sci, Dept Math Stat & Comp Sci, Tehran, Iran.
EM hhsajedi@ut.ac.ir
RI Sajedi, Hedieh/Y-3803-2019
OI sajedi, hedieh/0000-0003-4782-9222
FU Iranian National Science Foundation (INSF) [87041894]
FX This work was supported by Iranian National Science Foundation (INSF
   with contract No. 87041894).
CR [Anonymous], P 11 ACM MULT SEC WO
   [Anonymous], 2009, INT J PATTERN RECOGN
   Avcibas I, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P645, DOI 10.1109/ICIP.2002.1039053
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Farid H, 2002, INT C IM PROC, V2
   Fazio Nelly, 2014, Topics in Cryptology - CT-RSA 2014. The Cryptographers Track at the RSA Conference 2014. Proceedings: LNCS 8366, P64, DOI 10.1007/978-3-319-04852-9_4
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Geetha S., 2010, INT J COMPUTER NETWO, V2, P161
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Hsiao J, 2011, IMAGE VISION COMPUT, V29, P55
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Koutanaei FN, 2015, J RETAIL CONSUM SERV, V27, P11, DOI 10.1016/j.jretconser.2015.07.003
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Rodriguez F, 2015, LECT NOTES COMPUT SC, V9423, P83, DOI 10.1007/978-3-319-25751-8_11
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Sajedi H, 2011, SECUR COMMUN NETW, V4, P1173, DOI 10.1002/sec.243
   Sajedi H, 2010, EXPERT SYST APPL, V37, P7703, DOI 10.1016/j.eswa.2010.04.071
   Sajedi H, 2010, J SIGNAL PROCESS SYS, V61, P367, DOI 10.1007/s11265-010-0460-2
   Sajedi H, 2009, INT J INF SECUR, V8, P433, DOI 10.1007/s10207-009-0089-y
   Sandoval O, 2016, 39 INT C TEL SIGN PR
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Sullivan K, 2006, IEEE T INF FOREN SEC, V1, P275, DOI 10.1109/TIFS.2006.873595
   Tang MW, 2015, AEU-INT J ELECTRON C, V69, P15, DOI 10.1016/j.aeue.2015.08.011
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Vojtech H, 2014, CONTENT ADAPTIVE STE
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang R, 2015, MULTIMED TOOLS APPL, V74, P5725, DOI 10.1007/s11042-014-1880-y
   Zhao SW, 2017, INT GEOL REV, V59, P1, DOI 10.1080/00206814.2016.1198994
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
NR 34
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17269
EP 17284
DI 10.1007/s11042-017-5295-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300057
DA 2024-07-18
ER

PT J
AU Su, X
   Liu, YM
   Geng, YZ
   Yang, YH
   Choi, DM
AF Su, Xin
   Liu, Yiming
   Geng, Yuanzhe
   Yang, Yihang
   Choi, Dongmin
TI Semantic-based role matching and dynamic inspection for smart access
   control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access control; Data security; Semantic approach; Role matching;
   Analytic hierarchy process; Transaction
ID ANALYTIC HIERARCHY PROCESS; CONTROL MODEL; SECURITY
AB In this paper, we propose a scheme of semantic-based role matching and dynamic inspection for smart access control. The basic roles are established first, and then they are allocated to each user via a semantic analysis so that each user obtains the role with the most appropriate access. Our scheme explains the process of basic role establishment. In the process of role matching, our scheme applies the analytic hierarchy process to match roles. The established roles matched to users should not be fixed after the first round matching process. In practice, the type of user often varies, and the role matched to the user requires updating accordingly. Our scheme proposes that the system inspect roles dynamically and adjust or apply re-matching after matching. Re-matching roles not only further guarantees system security but also can bring about a better user experience. In addition, user requests can be refused by the system during process operation. This will yield an incomplete operation or generate incorrect data. To ensure the consistency of user operation, we introduce the concept of a transaction. The proposed scheme ensures the rationality of access control and data security based on semantic approaches and the analytic hierarchy process (AHP).
C1 [Su, Xin; Liu, Yiming; Geng, Yuanzhe; Yang, Yihang] Hohai Univ, Coll IOT Engn, 200 North Jinling Rd, Changzhou 213022, Peoples R China.
   [Choi, Dongmin] Chosun Univ, Div Undeclared Majors, Gwangju 61452, South Korea.
C3 Hohai University; Chosun University
RP Choi, DM (corresponding author), Chosun Univ, Div Undeclared Majors, Gwangju 61452, South Korea.
EM leosu8622@163.com; 15995086362@163.com; 17305155556@163.com;
   yangyh660@163.com; jdmcc@chosun.ac.kr
RI Liu, Kai/IST-6808-2023; liu, chen/ISV-2093-2023; Liu, Yi/HTN-4916-2023;
   Liu, Yiming/ISU-3780-2023; Liu, Kun/JAX-5396-2023; Yan,
   Jun/IXD-7801-2023
FU Korea government (Ministry of Science, ICT & Future Planning)
   [NRF-2015R1C1A1A01053301]; Fundamental Research Funds for the Central
   Universities [2015B30614]; Natural Science Foundation of Jiangsu
   Province [BK20160287]
FX This work was supported in part by the Korea government (Ministry of
   Science, ICT & Future Planning), Grant/Award Number:
   NRF-2015R1C1A1A01053301. This work was also supported in part by the
   Fundamental Research Funds for the Central Universities under Grant
   2015B30614, and in part by the Natural Science Foundation of Jiangsu
   Province under Grant BK20160287.
CR Ahn G.-J., 2000, ACM Transactions on Information and Systems Security, V3, P207, DOI 10.1145/382912.382913
   [Anonymous], P IEEE INFOCOM
   Badii A., 2010, 2010 Third International Conference on Advances in Human-Oriented and Personalized Mechanisms, Technologies, and Services (CENTRIC 2010), P105, DOI 10.1109/CENTRIC.2010.29
   Bertino E., 2001, ACM Transactions on Information and Systems Security, V4, P191, DOI 10.1145/501978.501979
   Chang DY, 1996, EUR J OPER RES, V95, P649, DOI 10.1016/0377-2217(95)00300-2
   Chatterjee S, 2015, INT J SYST SCI, V46, P513, DOI 10.1080/00207721.2013.791001
   Chessa S, 2003, 2003 INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS, PROCEEDINGS, P207, DOI 10.1109/DSN.2003.1209931
   Choi C, 2014, J SUPERCOMPUT, V67, P711, DOI 10.1007/s11227-013-0980-1
   Foltz PW, 1996, BEHAV RES METH INSTR, V28, P197, DOI 10.3758/BF03204765
   Guan H, 2009, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY (ISCSCT 2009), P106
   Guo K, 2017, CHINA COMMUN, V14, P124, DOI 10.1109/CC.2017.8014353
   Halperin D, 2008, IEEE PERVAS COMPUT, V7, P30, DOI 10.1109/MPRV.2008.16
   Joshi JBD, 2005, IEEE T KNOWL DATA EN, V17, P4, DOI 10.1109/TKDE.2005.1
   Kalajainen T, 2007, THESIS
   Laham D., 1997, LATENT SEMANTIC ANAL
   LEE H, 1993, J SYST SOFTWARE, V21, P179, DOI 10.1016/0164-1212(93)90040-5
   Mehta V., 1982, POWER ENERGY MAGAZIN, V4, P46
   엄정호, 2008, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V18, P71
   Nair R., 2003, P 2 INT JOINT C AUTO, P552
   Ninghui Li, 2006, ACM Transactions on Information and Systems Security, V9, P391, DOI 10.1145/1187441.1187442
   Richardson R., 2008, COMPUTER SECURITY I, P1
   Sidagni M, 2014, US, Patent No. 8756698
   Tahir M N., 2007, Ubiquitous Computing and Communication Journal, V2, P67
   Taninaka Y, 2003, US, Patent No. 20030140250
   Zou DQ, 2009, J NETW COMPUT APPL, V32, P402, DOI 10.1016/j.jnca.2008.02.015
NR 25
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18545
EP 18562
DI 10.1007/s11042-017-5220-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900049
DA 2024-07-18
ER

PT J
AU Yao, H
   Cao, F
   Tang, ZJ
   Wang, JW
   Qiao, T
AF Yao, Heng
   Cao, Fang
   Tang, Zhenjun
   Wang, Jinwei
   Qiao, Tong
TI Expose noise level inconsistency incorporating the inhomogeneity scoring
   strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Splicing detection; Noise inconsistency; Inhomogeneity
   assessment; Noise estimation
AB Estimating variances in noise is of key importance in many image processing applications, such as filtering, enhancement, quality assessment, and detecting forgery. For the existing detection methods that are based on inconsistencies in noise, the conventional approach is to estimate the noise variance of each region first and then identify the regions with extremely higher or lower variance as splicing regions. However, due to the impossibility of completely separating image noise and inherent texture, inevitably, each estimate is overestimated, especially for regions that have more complex textures. In this paper, we consider the issue that the estimation of the noise of each region frequently is inaccurate due to the complexity of the texture of the region. Based on this consideration and motivated by the scoring strategy-based, object-proposal technique, an approach that incorporates the inhomogeneity scoring strategy is proposed to provide a more convincing result to expose image-splicing manipulations. Specifically, first, the image is segmented into small patches, and the noise variance of each patch is computed by using the kurtosis concentration-based pixel-level noise estimation method. Then, the inhomogeneity score is computed using the spectral residual-based saliency measurement method. After using a linear equation fitting based on the estimated sample of variance and the inhomogeneity score of each patch, the suspicious region can be identified by seeking the conjunct patches that are out of the linear constraint. The experimental results demonstrated the efficacy and robustness of the proposed method.
C1 [Yao, Heng] Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Yao, Heng] Univ Shanghai Sci & Technol, Minist Educ, Engn Res Ctr Opt Instrument & Syst, Shanghai 200093, Peoples R China.
   [Yao, Heng; Tang, Zhenjun] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Cao, Fang] Shanghai Maritime Univ, Coll Informat Engn, Shanghai 200135, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Qiao, Tong] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Zhejiang, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Guangxi Normal University; Shanghai Maritime
   University; Nanjing University of Information Science & Technology;
   Hangzhou Dianzi University
RP Yao, H (corresponding author), Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.; Yao, H (corresponding author), Univ Shanghai Sci & Technol, Minist Educ, Engn Res Ctr Opt Instrument & Syst, Shanghai 200093, Peoples R China.; Yao, H (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM hyao@usst.edu.cn
RI Yao, Heng/J-9457-2019
OI Yao, Heng/0000-0002-3784-4157
FU National Natural Science Foundation of China [61702332, 61672354,
   61562007]; Research Fund of Guangxi Key Lab of Multi-source Information
   Mining Security [MIMS16-03]; PAPD Fund; CICAEET Fund
FX We would like to thank Drs. Siwei Lyu and Hui Zeng for kindly sharing
   the codecs of their work. This work was supported in part by the
   National Natural Science Foundation of China (61702332, 61672354,
   61562007), Research Fund of Guangxi Key Lab of Multi-source Information
   Mining & Security (MIMS16-03), the PAPD Fund, and the CICAEET Fund.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chen BJ, 2015, IEEE T SIGNAL PROCES, V63, P5424, DOI 10.1109/TSP.2015.2451107
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Pan XY, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P15
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rakhshanfar M, 2016, IEEE T IMAGE PROCESS, V25, P4172, DOI 10.1109/TIP.2016.2588320
   Rota P, 2016, INT C PATT RECOG, P2503, DOI 10.1109/ICPR.2016.7900012
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Valsesia D, 2015, IEEE T INF FOREN SEC, V10, P1472, DOI 10.1109/TIFS.2015.2415461
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wei WM, 2010, IEEE T INF FOREN SEC, V5, P507, DOI 10.1109/TIFS.2010.2051254
   Wu CH, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0093-2
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 30
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18139
EP 18161
DI 10.1007/s11042-017-5206-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900031
DA 2024-07-18
ER

PT J
AU Lan, RS
   Zhong, S
   Liu, ZB
   Shi, Z
   Luo, XN
AF Lan, Rushi
   Zhong, Si
   Liu, Zhenbing
   Shi, Zhuo
   Luo, Xiaonan
TI A simple texture feature for retrieval of medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image retrieval; Texture feature; Gabor and Schimid filtering;
   BoW model
ID FEATURE DESCRIPTOR; PATTERNS; SYSTEM
AB Texture characteristic is an important attribute of medical images, and has been applied in many medical image applications. This paper proposes a simple approach to employ the texture features of medical images for retrieval. The developed approach first conducts image filtering to medical images using different Gabor and Schmid filters, and then uniformly partitions the filtered images into non-overlapping patches. These operations provide extensive local texture information of medical images. The bag-of-words model is finally used to obtain feature representations of the images. Compared with several existing features, the proposed one is more discriminative and efficient. Experiments on two benchmark medical CT image databases have demonstrated the effectiveness of the proposed approach.
C1 [Lan, Rushi; Zhong, Si; Liu, Zhenbing; Luo, Xiaonan] Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, Guilin 541004, Peoples R China.
   [Shi, Zhuo] Guilin Univ Elect Technol, Sch Art & Design, Guilin 541004, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology
RP Liu, ZB (corresponding author), Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, Guilin 541004, Peoples R China.
EM rslan2016@163.com; zhongsi@guet.edu.cn; zbliu@guet.edu.cn;
   shzh.cn@gmail.com; luoxn@guet.edu.cn
OI Lan, Rushi/0000-0002-9488-8236
FU National Natural Science Foundation of China [61702129, 61772149,
   61320106008]; Guangxi Colleges and Universities Key Laboratory of
   Intelligent Processing of Computer Images and Graphics [GIIP201703]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61702129, 61772149, and 61320106008), and by
   Guangxi Colleges and Universities Key Laboratory of Intelligent
   Processing of Computer Images and Graphics (No. GIIP201703).
CR Akakin HC, 2012, IEEE T INF TECHNOL B, V16, P758, DOI 10.1109/TITB.2012.2185829
   Antani S, 2003, PROC SPIE, V5021, P405, DOI 10.1117/12.476289
   Bruna J., 2013, THESIS ECOLE POLYTEC
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Felipe JC, 2003, COMP MED SY, P175
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Lan RS, 2017, IEEE J BIOMED HEALTH, V21, P1338, DOI 10.1109/JBHI.2016.2623840
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Lo P, 2012, IEEE T MED IMAGING, V31, P2093, DOI 10.1109/TMI.2012.2209674
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Mallat S, 2010, 18 EUR SING PROC C E
   Müller H, 2004, PRO BIOMED OPT IMAG, V5, P99
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quddus A, 2012, IEEE T INF TECHNOL B, V16, P348, DOI 10.1109/TITB.2012.2189439
   Schmid C., 2001, P IEEE C COMP VIS PA, V2, pII
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Traina AJM, 2003, COMP MED SY, P150
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Xu Y, 2016, IEEE ACCESS, V5, P6688
   Yoshino Y, 2017, INT J COMPUT ASS RAD, V12, P1789, DOI 10.1007/s11548-017-1598-1
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
NR 29
TC 26
Z9 26
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10853
EP 10866
DI 10.1007/s11042-017-5341-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900028
DA 2024-07-18
ER

PT J
AU López-Labraca, J
   Fernández-Torres, MA
   González-Díaz, I
   Díaz-de-María, F
   Pizarro, A
AF Lopez-Labraca, Javier
   Angel Fernandez-Torres, Miguel
   Gonzalez-Diaz, Ivan
   Diaz-de-Maria, Fernando
   Pizarro, Angel
TI Enriched dermoscopic-structure-based cad system for melanoma diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma diagnosis; Computer-aided diagnosis; Enriched diagnosis;
   Dermoscopic structures; Bayesian fusion
ID PIGMENTED SKIN-LESIONS; EPILUMINESCENCE MICROSCOPY; PATTERN-ANALYSIS;
   ABCD RULE; CLASSIFICATION; MODEL
AB Computer-Aided Diagnosis (CAD) systems for melanoma detection have received a lot of attention during the last decades because of the utmost importance of detecting this type of skin cancer in its early stages. However, despite of the many research efforts devoted to this matter, these systems are not used yet in everyday clinical practice. Very likely, this is due to two main reasons: 1) the accuracy of the systems is not high enough; and 2) they simply provide a parallel diagnosis that actually does not help to the doctors (as long as there is no way to interpret it). In this paper, we propose a novel approach that aims to provide the doctor with an enriched diagnosis. Specifically, we rely on a dermoscopic-structure-based soft segmentation to design a set of structure-specific classifiers. Each individual structure-specific classifier is trained to distinguish benign lesions from melanomas just paying attention to one type of dermoscopic structure. Then, the outputs of the individual classifiers are combined by a means of the Bayesian method that, besides the final diagnosis, provide the doctor with additional valuable information, such as the opinions of the individual structure-specific experts and the uncertainty of the diagnosis. The results in terms of the features selected for the structure-specific classifiers are consistent with the expert insights. Furthermore, regarding the automatic melanoma diagnosis problem, the proposed method has been assessed on two different datasets, and the experimental results revealed that the proposed system clearly outperforms other methods in two datasets and compares well with the official submissions of the ISBI 2016 challenge on melanoma detection. Moreover, the system performance is equivalent to that of a well-known dermoscopy expert and its combination with the human diagnosis surpasses the human performance.
C1 [Lopez-Labraca, Javier; Angel Fernandez-Torres, Miguel; Gonzalez-Diaz, Ivan; Diaz-de-Maria, Fernando] Univ Carlos III Madrid, Signal Theory & Commun Dept, Leganes 28911, Spain.
   [Pizarro, Angel] Clin Dermatol Int, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP López-Labraca, J (corresponding author), Univ Carlos III Madrid, Signal Theory & Commun Dept, Leganes 28911, Spain.
EM jlabraca@tsc.uc3m.es; matorres@tsc.uc3m.es; igonzalez@tsc.uc3m.es;
   fdiaz@tsc.uc3m.es; apizarro@ricardoruiz.es
RI de María, Fernando Díaz/E-8048-2011; Fernández-Torres,
   Miguel-Ángel/T-6507-2018; Díaz, Iván González/L-5103-2014
OI de María, Fernando Díaz/0000-0002-6437-914X; Fernández-Torres,
   Miguel-Ángel/0000-0002-0801-199X; Díaz, Iván
   González/0000-0003-4644-8479
FU Spanish Ministry of Economy and Competitiveness [TEC2014-53390-P]
FX This work has been partially supported by the National Grant
   TEC2014-53390-P of the Spanish Ministry of Economy and Competitiveness.
CR Abe S., 2005, Support vector machines for pattern classification, V2
   Abedini M, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2390017
   Abedini M., 2015, Dermoscopy Image Analysis, P293, DOI DOI 10.1201/B19107-11
   Aminikhanghahi S, 2017, MULTIMED TOOLS APPL, V76, P10191, DOI 10.1007/s11042-016-3605-x
   Andreassi L, 1999, ARCH DERMATOL, V135, P1459, DOI 10.1001/archderm.135.12.1459
   [Anonymous], EFFICIENT GABOR FILT
   [Anonymous], ARXIV160501397 CORR
   [Anonymous], INTRINSIC MELANIN HE
   [Anonymous], DIGITAL IMAGING COMP, DOI [10.1201/b19107-6, DOI 10.1201/B19107-6]
   Argenziano G, 1998, ARCH DERMATOL, V134, P1563, DOI 10.1001/archderm.134.12.1563
   Argenziano G., 2002, Interactive atlas of dermoscopy
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Barata C, 2014, IEEE IMAGE PROC, P3527, DOI 10.1109/ICIP.2014.7025716
   Ben Youssef B, 2014, MULTIMED TOOLS APPL, V73, P1795, DOI 10.1007/s11042-013-1657-8
   Benavente R, 2008, J OPT SOC AM A, V25, P2582, DOI 10.1364/JOSAA.25.002582
   Berger J. O., 1985, STAT DECISION THEORY, V2nd
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Di Leo G., 2010, 2010 IEEE International Instrumentation & Measurement Technology Conference - I2MTC 2010, P886, DOI 10.1109/IMTC.2010.5488165
   Fabbrocini G, 2014, SER BIOENG, P71, DOI 10.1007/978-3-642-39608-3_4
   Isasi AG, 2011, COMPUT BIOL MED, V41, P742, DOI 10.1016/j.compbiomed.2011.06.010
   González-Díaz I, 2013, PATTERN RECOGN, V46, P2437, DOI 10.1016/j.patcog.2013.01.034
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Martínez-Cortés T, 2014, IEEE IMAGE PROC, P2779, DOI 10.1109/ICIP.2014.7025562
   Menzies SW, 1996, ARCH DERMATOL, V132, P1178, DOI 10.1001/archderm.132.10.1178
   Mirzaalian H., 2012, 2012 IEEE Workshop on Mathematical Methods in Biomedical Image Analysis (MMBIA), P97, DOI 10.1109/MMBIA.2012.6164758
   Nachbar F., 2016, POSTGRAD MED, V30, P551, DOI [10.1016/S0190-9622(94)70061-3, DOI 10.1016/S0190-9622(94)70061-3]
   PEHAMBERGER H, 1987, J AM ACAD DERMATOL, V17, P571, DOI 10.1016/S0190-9622(87)70239-4
   Rubegni P, 2010, ARCH DERMATOL RES, V302, P551, DOI 10.1007/s00403-010-1051-6
   Sadeghi M, 2012, PROC SPIE, V8314, DOI 10.1117/12.911818
   Sáez A, 2014, IEEE T MED IMAGING, V33, P1137, DOI 10.1109/TMI.2014.2305769
   Serrano C, 2009, PATTERN RECOGN, V42, P1052, DOI 10.1016/j.patcog.2008.07.011
   Tanaka T, 2008, IEEJ T ELECTR ELECTR, V3, P143, DOI 10.1002/tee.20246
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Weinstock MA, 2006, DERMATOL THER, V19, P26, DOI 10.1111/j.1529-8019.2005.00053.x
   Zare H., 2015, DERMOSCOPY IMAGE ANA, P345
   Zhang H, 2016, FRONT ENV SCI ENG, V10, DOI 10.1007/s11783-016-0852-z
   Zortea M, 2014, ARTIF INTELL MED, V60, P13, DOI 10.1016/j.artmed.2013.11.006
NR 42
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12171
EP 12202
DI 10.1007/s11042-017-4879-3
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100026
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Paul, S
   Pandit, MK
AF Paul, Suman
   Pandit, Malay Kumar
TI A QoS-enhanced intelligent stochastic real-time packet scheduler for
   multimedia IP traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cache and deadline misses; Hidden Markov model; Packet loss rate (PLR);
   Quality of service (QoS); Scheduling algorithm
ID PERFORMANCE ANALYSIS; QUALITY; SERVICE; SYSTEMS; NETWORKS
AB A re-configurable, QoS-enhanced intelligent stochastic real-time optimal fair packet scheduler, QUEST, for IP routers is proposed and investigated. The objective is to maximize the system QoS subject to the constraint that the processor utilization is kept at 100%. All past work on router schedulers for multimedia traffic were of earlier generation, in that they focused on maximizing utilization whereas being QoS-aware but without explicitly maximizing the QoS. Keeping utilization fixed at nearly 100%, QoS is dynamically maximized, thus moving to the next generation. QUEST's other unique advantages are three-fold. First, it solves the challenging problem of starvation for low priority processes; second, it solves the major bottleneck of Earliest Deadline First scheduler's failure at heavy traffic loads. Finally, QUEST offers the benefit of arbitrarily pre-programming the process utilization ratio. Three classes of multimedia IP traffic, namely, VoIP, IPTV and HTTP have been considered. Two most important QoS metrics, namely, packet loss rate (PLR) and mean waiting time, are addressed. All claims are supported by discrete event and Monte Carlo simulations. The proposed scheduler outperforms benchmark schedulers and offers 37% improvement in packet loss rate and 23% improvement in mean waiting time over the best competing current scheduler Accuracy-aware EDF. The proposed scheduler was validated in a test-bed platform of a NetFPGAA (R) router and results were observed with PaesslerA (R) PRTG network monitor.
C1 [Paul, Suman; Pandit, Malay Kumar] Haldia Inst Technol, Dept Elect & Commun Engn, Haldia 721657, W Bengal, India.
   [Paul, Suman; Pandit, Malay Kumar] Maulana Abul Kalam Azad Univ Technol West Bengal, West Bengal Univ Technol, Kolkata 700064, India.
   [Paul, Suman] Maulana Abul Kalam Azad Univ Technol West Bengal, West Bengal Univ Technol, Sch Engn & Technol, Kolkata 700064, India.
C3 Haldia Institute of Technology; Maulana Abul Kalam Azad University of
   Technology; Maulana Abul Kalam Azad University of Technology
RP Paul, S (corresponding author), Haldia Inst Technol, Dept Elect & Commun Engn, Haldia 721657, W Bengal, India.; Paul, S (corresponding author), Maulana Abul Kalam Azad Univ Technol West Bengal, West Bengal Univ Technol, Kolkata 700064, India.; Paul, S (corresponding author), Maulana Abul Kalam Azad Univ Technol West Bengal, West Bengal Univ Technol, Sch Engn & Technol, Kolkata 700064, India.
EM paulsuman999@gmail.com; mkp10011@yahoo.com
OI PAUL, Dr. SUMAN/0000-0001-9648-9610
CR Abhaya VG, 2014, IEEE T PARALL DISTR, V25, P2149, DOI 10.1109/TPDS.2013.171
   AbouGhazaleh N., 2006, ACM Trans. Embed. Comput. Syst, V5, P82
   [Anonymous], DEVS SUIT DISCR EV S
   Bril RJ, 2007, EUROMICRO, P269, DOI 10.1109/ECRTS.2007.38
   Che-Fu Hsueh, 2016, CICTP 2016. Green and Multimodal Transportation and Logistics. Proceedings of the 16th COTA International Conference of Transportation Professionals, P1
   Chen SG, 1998, IEEE NETWORK, V12, P64, DOI 10.1109/65.752646
   Chen Y., 2004, Information.Knowledge.Systems Management, V4, P55
   CHIB S, 1995, AM STAT, V49, P327, DOI 10.2307/2684568
   De Cristofaro Nick, 2009, 2009 Canadian Conference on Electrical and Computer Engineering (CCECE 2009), P288, DOI 10.1109/CCECE.2009.5090139
   Doran G, 2014, MACH LEARN, V97, P79, DOI 10.1007/s10994-013-5429-5
   Elghazel H, 2015, MACH LEARN, V98, P157, DOI 10.1007/s10994-013-5337-8
   Ghaderi M, 2005, LECT NOTES COMPUT SC, V3462, P1309
   Ghazel C, 2015, PROCEDIA COMPUT SCI, V56, P225, DOI 10.1016/j.procs.2015.07.203
   Greco L, 2011, IEEE T AUTOMAT CONTR, V56, P571, DOI 10.1109/TAC.2010.2058497
   Jin XL, 2007, J COMPUT SYST SCI, V73, P1207, DOI 10.1016/j.jcss.2007.02.008
   Johnson J, 2010, MICROWAVE J, P12
   Kang KD, 2004, IEEE T KNOWL DATA EN, V16, P1200, DOI 10.1109/TKDE.2004.61
   Khan MA, 2012, HANDBOOK OF RESEARCH ON INDUSTRIAL INFORMATICS AND MANUFACTURING INTELLIGENCE: INNOVATIONS AND SOLUTIONS, P1, DOI 10.4018/978-1-4666-0294-6
   Kleinrock L, 1975, QUEUEING SYSTEMS THE, V1, P37
   Kooti H., 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P141, DOI 10.1109/ASPDAC.2011.5722174
   LIU CL, 1973, J ACM, V20, P46, DOI 10.1145/321738.321743
   Lyngso RB, 2001, LECT NOTES COMPUT SC, V2223, P416
   Nasri M, 2012, IEEE EMBED SYST LETT, V4, P61, DOI 10.1109/LES.2012.2195294
   Osojnik A, 2017, MACH LEARN, V106, P745, DOI 10.1007/s10994-016-5613-5
   Rikli NE, 2013, J KING SAUD UNIV-COM, V25, P89, DOI 10.1016/j.jksuci.2012.08.001
   Saleh Maen, 2010, 2010 International Conference on Networking, Sensing and Control (ICNSC 2010), P698, DOI 10.1109/ICNSC.2010.5461572
   Seth K., 2006, ACM Transactions on Embedded Computing Systems (TECS), V5, P200
   Szigeti T, 2005, END TO END QOS NETWO, P110
   THIEBAUT D, 1992, IEEE T COMPUT, V41, P388, DOI 10.1109/12.135552
   Toral-Cruz H, 2013, MATH COMPUT MODEL, V57, P2832, DOI 10.1016/j.mcm.2011.12.007
   Ullah S, 2017, MULTIMED TOOLS APPL, V76, P21519, DOI 10.1007/s11042-016-4008-8
   Wang G, 2010, IEEE T AERO ELEC SYS, V46, P1492, DOI 10.1109/TAES.2010.5545204
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang X, 2015, IEEE T AUTOM SCI ENG, V12, P258, DOI 10.1109/TASE.2014.2309479
   Williams JK, 2014, MACH LEARN, V95, P51, DOI 10.1007/s10994-013-5346-7
   Zhang Y, 2015, ADV SOC SCI EDUC HUM, V41, P1, DOI 10.1109/VCIP.2015.7457854
   Zhang YD, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/931256
   Zhou XB, 2007, J NETW COMPUT APPL, V30, P354, DOI 10.1016/j.jnca.2005.07.001
NR 38
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12725
EP 12748
DI 10.1007/s11042-017-4912-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100048
DA 2024-07-18
ER

PT J
AU Zhang, XS
   Tan, YA
   Zhang, CY
   Xue, Y
   Li, YZ
   Zheng, J
AF Zhang, Xiaosong
   Tan, Yu-an
   Zhang, Changyou
   Xue, Yuan
   Li, Yuanzhang
   Zheng, Jun
TI A code protection scheme by process memory relocation for android
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Code protection; Process memory relocation; Memory acquisition; Android;
   Anti-forensics
ID ANTI-FORENSICS
AB Android devices is emerging as a significant force for multimedia big data, which hold an enormous amount of information about the users. The security and privacy concerns have arisen as a salient area of inquiry since malicious attackers can use memory dump to extract privacy or sensitive data from these devices. This paper presents a code protection approach for Android devices which protects certain processes from memory acquisition by process memory relocation. The protected processes are relocated to the special memory area where the kernel is loaded, and thus these processes will be covered when android reboots and attackers can not recognize which protected programs have been performed on the devices. The experiment results show that the proposed approach disables forensics tools like FROST to obtain these processes and has little impact on the normal operation of the protected program. Compared with the similar methods, the proposed method can protect greater data quantity but it occupies no additional storage resources.
C1 [Zhang, Xiaosong; Tan, Yu-an; Xue, Yuan; Li, Yuanzhang; Zheng, Jun] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Zhang, Xiaosong] Tangshan Univ, Dept Comp Sci & Technol, Tangshan 063000, Peoples R China.
   [Tan, Yu-an; Zheng, Jun] Res Ctr Mass Language Informat Proc & Cloud Comp, Beijing 100081, Peoples R China.
   [Zhang, Changyou] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
C3 Beijing Institute of Technology; Tangshan University; Chinese Academy of
   Sciences; Institute of Software, CAS
RP Zheng, J (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.; Zheng, J (corresponding author), Res Ctr Mass Language Informat Proc & Cloud Comp, Beijing 100081, Peoples R China.
EM zxs0224@163.com; tan2008@bit.edu.cn; changyou@iscas.ac.cn;
   xueyuan_1007@163.com; popular@bit.edu.cn; zhengjun_bit@163.com
FU National Natural Science Foundation of China [U1636213]; Beijing
   Municipal Natural Science Foundation [4172053]
FX This research was supported by the National Natural Science Foundation
   of China (No. U1636213), Beijing Municipal Natural Science Foundation
   (No. 4172053).
CR Albano P., 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P380, DOI 10.1109/BWCCA.2011.62
   Anobah M, 2014, J DIGIT FORENSICS SE, V9, P221
   [Anonymous], 2013, INT C APPL CRYPT NET
   Azadegan S., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P5424, DOI 10.1109/HICSS.2012.452
   Berghel H, 2007, COMMUN ACM, V50, P15, DOI 10.1145/1278201.1278222
   Blunden Bill, 2009, BLACK HAT US 2009 C, P10
   Caloyannides MA, 2009, IEEE SECUR PRIV, V7, P18, DOI 10.1109/MSP.2009.37
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Conlan K, 2016, DIGIT INVEST, V18, pS66, DOI 10.1016/j.diin.2016.04.006
   Distefano A, 2010, DIGIT INVEST, V7, pS83, DOI 10.1016/j.diin.2010.05.011
   Garfinkel S, 2007, ICIW 2007: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INFORMATION WARFARE AND SECURITY, P77
   Geiger M, 2005, DFRWS
   Gotzfried Johannes, 2013, 2013 International Conference on Availability, Reliability and Security (ARES), P161, DOI 10.1109/ARES.2013.23
   Gupta BB, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017010101
   Gupta S, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017070101
   Harris R, 2006, DIGIT INVESTIG, pS44, DOI 10.1016/j.diin.2006.06.005
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jansen W., 2008, P 41 ANN HAW INT C S, P483
   Karlsson KJ, 2014, P ANN HICSS, P4828, DOI 10.1109/HICSS.2014.593
   Kessler Gary C., 2007, AUSTR DIG FOR C, P1
   Lee K, 2017, AEROSP CONF PROC
   Liu H, 2012, STUD COMPUT INTELL, V377, P145
   Liu V, 2006, BLEEDING EDGE ANTI F
   Muller Tilo, 2012, Applied Cryptography and Network Security. Proceedings 10th International Conference, ACNS 2012, P66, DOI 10.1007/978-3-642-31284-7_5
   Muller T., 2010, ACM P EUROSEC 10 PAR, P42
   Muller T., 2011, USENIX SEC S, V17
   Nilsson A, 2014, DIGIT INVEST, V11, pS63, DOI 10.1016/j.diin.2014.03.008
   Rastogi S., 2015, INT J SENS WIREL COM, V5, P47
   Rastogi S, 2016, PROCEDIA COMPUT SCI, V78, P26, DOI 10.1016/j.procs.2016.02.006
   Sharma K, 2016, PROCEDIA COMPUT SCI, V78, P19, DOI 10.1016/j.procs.2016.02.005
   Simmons P, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P73
   Sporea I., 2012, International Journal of Security, V6, P58
   Stuettgen J, 2013, DIGIT INVEST, V10, pS105, DOI 10.1016/j.diin.2013.06.012
   Sun Z, 2016, SHOCK VIB, V2016, DOI 10.1155/2016/8454567
   Sylve J, 2012, DIGIT INVEST, V8, P175, DOI 10.1016/j.diin.2011.10.003
   Thing VLL, 2010, DIGIT INVEST, V7, pS74, DOI 10.1016/j.diin.2010.05.010
   Wundram M, 2013, INT CONF IT SECUR, P83, DOI 10.1109/IMF.2013.17
   Xiao Y, 2017, MULTIMED TOOLS APPL, DOI [10.1007/s11042-017-4540-1, DOI 10.1007/S11042-017-4540-1]
   Xue Y, 2018, SOFT COMPUT, V22, P4445, DOI 10.1007/s00500-017-2651-2
   Yan F, 2016, CHINESE J ELECTRON, V25, P832, DOI 10.1049/cje.2016.06.021
   Zhang XS, 2017, CLUSTER COMPUT, V20, P2393, DOI 10.1007/s10586-016-0721-3
   Zhu HF, 2017, FUTURE GENER COMP SY, V73, P106, DOI 10.1016/j.future.2017.01.031
   Zhu R, 2017, INT J CRIT INFRASTRU, V16, P36
   Zhu RJ, 2016, DIGIT INVEST, V16, P19, DOI 10.1016/j.diin.2016.01.002
   Zkik K, 2017, INT J CLOUD APPL COM, V7, P62, DOI 10.4018/IJCAC.2017040105
NR 48
TC 14
Z9 14
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11137
EP 11157
DI 10.1007/s11042-017-5363-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900043
DA 2024-07-18
ER

PT J
AU Aishwarya, N
   Thangammal, CB
AF Aishwarya, N.
   Thangammal, C. Bennila
TI An image fusion framework using morphology and sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Supervised learning; Sparse representation; K-SVD; OMP;
   Euclidean norm
ID PERFORMANCE; TRANSFORM; ALGORITHM
AB Image fusion is the process which aims to integrate the relevant and complementary information from a set of images into a single comprehensive image. Sparse representation (SR) is a powerful technique used in a wide variety of applications like denoising, compression and fusion. Building a compact and informative dictionary is the principal challenge in these applications. Hence, we propose a supervised classification based learning technique for the fusion algorithm. As an initial step, each patch of the training data set is pre-classified based on their gradient dominant direction. Then, a dictionary is learned using K-SVD algorithm. With this universal dictionary, sparse coefficients are estimated using greedy OMP algorithm to represent the given set of source images in the dominant direction. Finally, the Euclidean norm is used as a distance measure to reconstruct the fused image. Experimental results on different types of source images demonstrate the effectiveness of the proposed algorithm with conventional methods in terms of visual and quantitative evaluations.
C1 [Aishwarya, N.; Thangammal, C. Bennila] Anna Univ, Dept ECE, RMD Engn Coll, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Aishwarya, N (corresponding author), Anna Univ, Dept ECE, RMD Engn Coll, Madras, Tamil Nadu, India.
EM aishwarya8914@gmail.com
RI Thangammal, C Bennila/A-9270-2018; N, Aishwarya/HGD-4106-2022; aish,
   N.AISHWARYA/AAG-5520-2019
OI Thangammal, C Bennila/0000-0002-2724-1678; N,
   Aishwarya/0000-0003-4054-6801; 
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aishwarya N, 2013, P IEEE INT C COMM SI, P686
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Dong LM, 2015, NEUROCOMPUTING, V159, P268, DOI 10.1016/j.neucom.2015.01.050
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   James AP, 2014, INFORM FUSION, V19, P14
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Ramabai M., 2010, INT J ENG SCI TECHNO, V2, P3832
   ShiHu Zhu, 2011, 2011 IEEE 2nd International Conference on Computing, Control and Industrial Engineering, P406, DOI 10.1109/CCIENG.2011.6008150
   Sollie P, 2003, MORPHOLOGICAL PRINCI
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   Yin HP, 2016, NEUROCOMPUTING, V216, P216, DOI 10.1016/j.neucom.2016.07.039
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
NR 32
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9719
EP 9736
DI 10.1007/s11042-017-5562-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200025
DA 2024-07-18
ER

PT J
AU Guo, YM
   Liu, Y
   Bakker, EM
   Guo, YH
   Lew, MS
AF Guo, Yanming
   Liu, Yu
   Bakker, Erwin M.
   Guo, Yuanhao
   Lew, Michael S.
TI CNN-RNN: a large-scale hierarchical image classification framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Recurrent neural network; Hierarchical
   image classification; Wider-Resnet
AB Objects are often organized in a semantic hierarchy of categories, where fine-level categories are grouped into coarse-level categories according to their semantic relations. While previous works usually only classify objects into the leaf categories, we argue that generating hierarchical labels can actually describe how the leaf categories evolved from higher level coarse-grained categories, thus can provide a better understanding of the objects. In this paper, we propose to utilize the CNN-RNN framework to address the hierarchical image classification task. CNN allows us to obtain discriminative features for the input images, and RNN enables us to jointly optimize the classification of coarse and fine labels. This framework can not only generate hierarchical labels for images, but also improve the traditional leaf-level classification performance due to incorporating the hierarchical information. Moreover, this framework can be built on top of any CNN architecture which is primarily designed for leaf-level classification. Accordingly, we build a high performance network based on the CNN-RNN paradigm which outperforms the original CNN (wider-ResNet) and also the current state-of-the-art. In addition, we investigate how to utilize the CNN-RNN framework to improve the fine category classification when a fraction of the training data is only annotated with coarse labels. Experimental results demonstrate that CNN-RNN can use the coarse-labeled training data to improve the classification of fine categories, and in some cases it even surpasses the performance achieved by fully annotated training data. This reveals that, CNN-RNN can alleviate the challenge of specialized and expensive annotation of fine labels.
C1 [Guo, Yanming; Liu, Yu; Bakker, Erwin M.; Guo, Yuanhao] Leiden Inst Adv Comp Sci, Leiden, Netherlands.
   [Lew, Michael S.] Leiden Inst Adv Comp Sci, Imagery & Media Res Cluster, Leiden, Netherlands.
   [Lew, Michael S.] Leiden Inst Adv Comp Sci, Media Lab, Leiden, Netherlands.
C3 Leiden University; Leiden University; Leiden University
RP Guo, YM (corresponding author), Leiden Inst Adv Comp Sci, Leiden, Netherlands.
EM y.guo@liacs.leidenuniv.nl; y.liu@liacs.leidenuniv.nl;
   e.m.bakker@liacs.leidenuniv.nl; y.guo.3@liacs.leidenuniv.nl;
   m.s.lew@liacs.leidenuniv.nl
RI Guo, Yuanhao/N-2763-2019
CR Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   [Anonymous], INT C LEARN REPR WOR
   [Anonymous], BRIT MACH VIS C
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C LEARN REPR WOR
   [Anonymous], DISTANCE BASED IMAGE
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2015, INT C LEARN REPR WOR
   [Anonymous], 2015, INT C LEARN REPR WOR
   [Anonymous], 2015, 3 INT C LEARNING REP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2016, P BRIT MACHINE VISIO
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Clevert D.-A., 2016, INT C LEARN REPR
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Larsson G., 2017, INT C LEARN REPR
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li H., 2016, INT C MACHINE LEARNI, P221
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu Y, 2017, LECT NOTES COMPUT SC, V10132, P277, DOI 10.1007/978-3-319-51811-4_23
   Liu Y, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P43, DOI 10.1145/2671188.2749300
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mishkin D., 2016, INT C LEARN REPR
   Murdock C, 2016, PROC CVPR IEEE, P2583, DOI 10.1109/CVPR.2016.283
   Ristin M, 2015, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2015.7298619
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov R, 2011, PROC CVPR IEEE, P1481, DOI 10.1109/CVPR.2011.5995720
   Shirahama K, 2016, MULTIMED TOOLS APPL, V75, P297, DOI 10.1007/s11042-014-2292-8
   Simonyan K, 2015, IEEE INT C ICLR
   Singh S, 2016, P ADV NEUR INF PROC, V29
   Snoek J, 2015, PR MACH LEARN RES, V37, P2171
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Visin F., 2015, CoRR
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhen Zuo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301268
NR 54
TC 61
Z9 67
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10251
EP 10271
DI 10.1007/s11042-017-5443-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200056
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Lv, ZH
   Li, XM
   Choo, KKR
AF Lv, Zhihan
   Li, Xiaoming
   Choo, Kim-Kwang Raymond
TI E-government multimedia big data platform for disaster management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Disaster management; E-government
ID ELECTRONIC GOVERNMENT; POLICY
AB By efficiently managing and utilizing the city's multimedia big data, 3D analysis and visualization of the city's multimedia information can be performed on the platform for disaster management, facilitating the provision of different disaster management services to policymakers and other relevant stakeholders in governments and industries (e.g. service providers such as traffic authorities, fire and other emergency authorities, as well as urban pipeline monitoring systems, financial monitoring systems, and ground subsidence monitoring systems).
C1 [Lv, Zhihan] Qingdao Univ, Qingdao 266, Peoples R China.
   [Li, Xiaoming] Shenzhen Res Ctr Digital City Engn, Shenzhen 518034, Peoples R China.
   [Li, Xiaoming] Minist Land & Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.
C3 Qingdao University; Ministry of Natural Resources of the People's
   Republic of China; University of Texas System; University of Texas at
   San Antonio (UTSA)
RP Lv, ZH (corresponding author), Qingdao Univ, Qingdao 266, Peoples R China.
EM lvzhihan@gmail.com
RI Lv, Zhihan/GLR-6000-2022; Choo, Kim-Kwang Raymond/A-3634-2009; Lyu,
   Zhihan/I-3187-2014; Li, Xiaoming/GSD-8174-2022
OI Lv, Zhihan/0000-0003-2525-3074; Choo, Kim-Kwang
   Raymond/0000-0001-9208-5336; Lyu, Zhihan/0000-0003-2525-3074; Li,
   Xiaoming/0000-0002-7804-368X
CR Beynon-Davies P, 2005, INT J INFORM MANAGE, V25, P3, DOI 10.1016/j.ijinfomgt.2004.08.002
   Chin CPY, 2015, J ORG COMP ELECT COM, V25, P289, DOI 10.1080/10919392.2015.1058118
   Christensen T, 1998, INT REV ADM SCI, V64, P457, DOI 10.1177/002085239806400308
   Chu PY, 2004, GOV INFORM Q, V21, P219, DOI 10.1016/j.giq.2004.01.005
   Cooper AndrewF., 2000, Global Society, V14, P361
   Jaeger PT, 2005, GOV INFORM Q, V22, P702, DOI 10.1016/j.giq.2006.01.012
   Janowski T, 2012, GOV INFORM Q, V29, pS1, DOI 10.1016/j.giq.2011.11.003
   Lv ZH, 2016, IEEE INTERNET THINGS, V3, P1015, DOI 10.1109/JIOT.2016.2546307
   Muir A, 2002, J INFORM SCI, V28, P173, DOI 10.1177/016555150202800301
   Xu Z, 2018, IEEE T BIG DATA, V4, P245, DOI 10.1109/TBDATA.2016.2599935
NR 10
TC 12
Z9 12
U1 6
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10077
EP 10089
DI 10.1007/s11042-017-5119-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200047
DA 2024-07-18
ER

PT J
AU Sun, BY
   Cao, CJ
AF Sun, Bangyong
   Cao, Congjun
TI Simulation of proposed eight-band camera for capturing multispectral
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multispectral image; Bilinear interpolation; Demosaicking
ID FILTER ARRAYS; GENERIC METHOD; RESOLUTION
AB Multispectral image contains much more information than regular RGB image so that it has wide applications in the field of physics, surveillance, environment monitoring or investigation of artworks. The traditional spectral imaging cameras are mainly based on broom/scanning or filter wheel imaging technologies, while those techniques share significant disadvantages of high cost and structural complexity. In this paper we proposed an eight-band multispectral camera prototype with only one CCD, which is cost-effective and high-speed for capturing the moving objects. A simulated experiment is designed to evaluate the proposed eight-band imaging system. The hyperspectral scene is firstly acquired and imaged on the CCD which generates the raw image, and then a demosaicking algorithm based on modified bilinear interpolation is employed to reconstruct the missing imaging values from the raw image, at last the demosaicked image is converted into spectral values with the conversion coefficient calculated from spectral camera characterization. In order to evaluate the proposed eight-band imaging system, the demosaicked image values and recovered spectral values are compared with the original data respectively in the form of PSNR and RRMS. In the experiment result, the eight-band multispectral camera captures spectral images successfully with high PSNR values and lower RRMS errors.
C1 [Sun, Bangyong; Cao, Congjun] Xian Univ Technol, Sch Printing & Packing, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Sun, BY (corresponding author), Xian Univ Technol, Sch Printing & Packing, Xian 710048, Shaanxi, Peoples R China.
EM sunbangyong@xaut.edu.cn
RI sun, booyoo/JXM-6252-2024
FU Key Laboratory of Shaanxi Province Foundation; Natural Science Basic
   Research Plan in Shaanxi Province of China [2017JM1028]; ShaanXi
   Postdoctoral Science Foundation [434016004]; XUT Science Foundation
   [2016CX031]
FX The authors would like to acknowledge the Key Laboratory of Shaanxi
   Province Foundation, Natural Science Basic Research Plan in Shaanxi
   Province of China (No.2017JM1028), ShaanXi Postdoctoral Science
   Foundation(No.434016004) and XUT Science Foundation(No.2016CX031) for
   their support, and also thank X. Wang for those helpful suggestions.
CR Aggarwal H. K., 2013, P 4 NAT C COMP VIS P, P1, DOI 10.1109/NCVPRTPG.2013.6776236
   Aggarwal HK, 2014, P 2 IEEE CHIN SUMM I, P9
   Akkaynak D, 2014, J OPT SOC AM A, V31, P312, DOI 10.1364/JOSAA.31.000312
   [Anonymous], 2000, BILLMEYER SALTZMANS
   [Anonymous], P SPIE
   BASIJI DA, 2001, Patent No. 6211955
   Bell AA, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P168
   Brauers J., 2006, 12 WORKSH FARBB ILM
   Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359
   FRENTRESS Z, 1964, APPL OPTICS, V3, P303, DOI 10.1364/AO.3.000303
   Grahn H., 2007, Techniques and Applications of Hyperspectral Image Analysis
   Heikkinen V, 2016, J OPT SOC AM A, V33, P1095, DOI 10.1364/JOSAA.33.001095
   Jackel BJ, 2014, GEOSCI INSTRUM METH, V3, P71, DOI 10.5194/gi-3-71-2014
   Jeon G, 2013, IEEE T IMAGE PROCESS, V22, P146, DOI 10.1109/TIP.2012.2214041
   Jolivot R, 2011, COMPUT MED IMAG GRAP, V35, P85, DOI 10.1016/j.compmedimag.2010.07.001
   Kwon JY, 2016, DIGIT SIGNAL PROCESS, V59, P115, DOI 10.1016/j.dsp.2016.08.009
   Lapray PJ, 2017, J EUR OPT SOC-RAPID, V13, DOI 10.1186/s41476-016-0031-7
   Lapray PJ, 2014, SENSORS-BASEL, V14, P21626, DOI 10.3390/s141121626
   Li QL, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.10.100901
   MARTINEZ K, 1993, P SOC PHOTO-OPT INS, V1901, P25, DOI 10.1117/12.144795
   Miao LD, 2004, IEEE IMAGE PROC, P3343
   Miao L, 2006, IEEE T IMAGE PROCESS, V15, P2780, DOI 10.1109/TIP.2006.877315
   Monno Y, 2015, IEEE T IMAGE PROCESS, V24, P3048, DOI 10.1109/TIP.2015.2436342
   MORRIS HR, 1994, APPL SPECTROSC, V48, P857, DOI 10.1366/0003702944029820
   Niruban R., 2014, Journal of Computer Science, V10, P1591, DOI 10.3844/jcssp.2014.1591.1599
   RAMANATH R, 2001, TECHNICAL REPORT
   Sadeghipoor Z, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6116339
   Shrestha R, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-57
   Sun BY, 2015, SPECTROSC LETT, V48, P660, DOI 10.1080/00387010.2014.958243
   Sun B, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/813150
   Thomas JB, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070993
   Wang J, 2017, IEEE SENS J, V17, P726, DOI 10.1109/JSEN.2016.2623422
   Wang SW, 2007, OPT LETT, V32, P632, DOI 10.1364/OL.32.000632
   Xie Hongbo, 2016, Journal of Applied Optics, V37, P172, DOI 10.5768/JAO201637.0201004
   Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811
   Zhang C, 2016, IEEE T IMAGE PROCESS, V25, P5173, DOI 10.1109/TIP.2016.2601266
NR 36
TC 5
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10157
EP 10169
DI 10.1007/s11042-017-5177-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200051
DA 2024-07-18
ER

PT J
AU Nguyen, XS
   Nguyen, TP
   Charpillet, F
   Vu, NS
AF Xuan Son Nguyen
   Thanh Phuong Nguyen
   Charpillet, Francois
   Ngoc-Son Vu
TI Local derivative pattern for action recognition in depth images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Local derivative pattern; Sparse coding; Fisher
   vector; Extreme learning machine
ID EXTREME LEARNING-MACHINE
AB This paper proposes a new local descriptor for action recognition in depth images using second-order directional Local Derivative Patterns (LDPs). LDP relies on local derivative direction variations to capture local patterns contained in an image region. Our proposed local descriptor combines different directional LDPs computed from three depth maps obtained by representing depth sequences in three orthogonal views and is able to jointly encode the shape and motion cues. Moreover, we suggest the use of Sparse Coding-based Fisher Vector (SCFVC) for encoding local descriptors into a global representation of depth sequences. SCFVC has been proven effective for object recognition but has not gained much attention for action recognition. We perform action recognition using Extreme Learning Machine (ELM). Experimental results on three public benchmark datasets show the effectiveness of the proposed approach.
C1 [Xuan Son Nguyen] Univ Caen Basse Normandie, CNRS, GREYC, UMR 6072, F-14000 Caen, France.
   [Thanh Phuong Nguyen] Aix Marseille Univ, CNRS, UMR 7296, ENSAM,LSIS, F-13397 Marseille, France.
   [Thanh Phuong Nguyen] Univ Toulon & Var, CNRS, LSIS, UMR 7296, F-83957 La Garde, France.
   [Charpillet, Francois] INRIA, Villers Les Nancy, France.
   [Charpillet, Francois] CNRS, UMR 7503, LORIA, Villers Les Nancy, France.
   [Ngoc-Son Vu] Univ Paris Seine, ETIS UMR 8051, UCP, ENSEA,CNRS, F-95000 Cergy, France.
   [Charpillet, Francois] Univ Lorraine, LORIA, UMR 7503, F-54600 Villers Les Nancy, France.
C3 Universite de Caen Normandie; Centre National de la Recherche
   Scientifique (CNRS); Aix-Marseille Universite; Centre National de la
   Recherche Scientifique (CNRS); Arts et Metiers Institute of Technology;
   Aix-Marseille Universite; Universite de Toulon; Centre National de la
   Recherche Scientifique (CNRS); Inria; Universite de Lorraine; Centre
   National de la Recherche Scientifique (CNRS); Centre National de la
   Recherche Scientifique (CNRS); Universite de Lorraine
RP Nguyen, XS (corresponding author), Univ Caen Basse Normandie, CNRS, GREYC, UMR 6072, F-14000 Caen, France.
EM xuan-son.nguyen@unicaen.fr; thanh-phuong.nguyen@univ-tln.fr;
   francois.charpillet@inria.fr; son.vu@ensea.fr
RI Nguyen, Thanh Phuong/AAA-2769-2019; Charpillet, Francois/S-3367-2018
OI Nguyen, Thanh Phuong/0000-0002-5646-8505; Charpillet,
   Francois/0000-0001-8260-1536
CR Chaaraoui AA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P91, DOI 10.1109/ICCVW.2013.19
   [Anonymous], 2014, Advances in Neural Information Processing Systems
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Boiman O., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587598
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liang CW, 2016, IEEE SIGNAL PROC LET, V23, P1241, DOI 10.1109/LSP.2016.2592419
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Mairal J., 2011, SPAMS SPARSE MODELIN, V2.1
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Muller M., 2007, Information retrieval for music and motion, P69, DOI [10.1007/978-3-540-74048-3_4, DOI 10.1007/978-3-540-74048-3_4]
   Murray R. M., 1994, MATH INTRO ROBOTIC M
   Ngo C. W., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P36, DOI 10.1109/CVPR.1999.786914
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Padilla-Lopez JR, 2014, ARXIV14077390 CORR
   Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Song Y, 2015, IEEE SIGNAL PROC LET, V22, P426, DOI 10.1109/LSP.2014.2361901
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 44
TC 13
Z9 13
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8531
EP 8549
DI 10.1007/s11042-017-4749-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800034
DA 2024-07-18
ER

PT J
AU Zheng, YZ
   Li, ZX
   Zhang, CL
AF Zheng, Yongzhe
   Li, Zhixin
   Zhang, Canlong
TI A hybrid architecture based on CNN for cross-modal semantic instance
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature learning; Semantic learning; Cross-modal semantic annotation;
   Convolutional neural networks
ID IMAGE RETRIEVAL
AB With the rapid growth of various media data, how to effectively manage and retrieve multimedia data has become an urgent problem to be solved. Due to semantic gap, overcoming the semantic gap has become a difficult problem for image semantic annotation. In this paper, a hybrid approach is proposed to learn automatically semantic concepts of images, which is called CNN-ECC. It's divided into two processes generative feature learning and discriminative semantic learning. In feature learning phase, the redesigned convolutional neural network (CNN) is utilized for feature learning, instead of traditional methods of feature learning. Besides the reconstructed CNN model has the ability to learn multi-instance feature, which can enhance the image features' representation when extracting features from images containing multiple instances. In semantic learning phase, the ensembles of classifier chains (ECC) are trained based on obtained visual feature for semantic learning. In addition, the ensembles of classifier chains can learn semantic association between different labels, which can effectively avoid generating redundant labels when resolving multi-label classification task. Furthermore, the experimental results confirm that proposed approach performs more effectively and accurately than state-of-the-art for image semantic annotation.
C1 [Zheng, Yongzhe; Li, Zhixin; Zhang, Canlong] Guangxi Normal Univ, Guangxi Key Lab Multi Source Informat Min & Secur, Guilin 541004, Peoples R China.
   [Zheng, Yongzhe; Li, Zhixin; Zhang, Canlong] Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multi Source Informat Min & Secur, Guilin 541004, Peoples R China.; Li, ZX (corresponding author), Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
EM zhengyzms@163.com; lizx@gxnu.edu.cn; clzhang@gxnu.edu.cn
RI Jeong, Yongwook/N-7413-2016; Li, Zhixin/ABI-9264-2022
OI Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [61663004, 61363035,
   61365009]; Guangxi Natural Science Foundation [2016GXNSFAA380146,
   2014GXNSFAA118368]; Guangxi Key Lab of Multi-source Information Mining
   and Security [16-A-03-02]; Guangxi "Bagui Scholar" Teams for Innovation
   and Research Project; Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61663004, 61363035, 61365009), the Guangxi Natural Science
   Foundation (Nos. 2016GXNSFAA380146, 2014GXNSFAA118368), the Director
   Fund of Guangxi Key Lab of Multi-source Information Mining and Security
   (16-A-03-02), the Guangxi "Bagui Scholar" Teams for Innovation and
   Research Project, Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing.
CR [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083
   Cusano C, 2004, PROC SPIE, V5304, P330
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong J, 2013, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2013.112
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwang SY, 2011, BIOTECH HISTOCHEM, V86, P181, DOI 10.3109/10520291003648367
   Escalante HJ, 2012, EXPERT SYST APPL, V39, P11011, DOI 10.1016/j.eswa.2012.03.023
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joachims T., 1998, Technical Report, V8, P499
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li ZX, 2013, ENG APPL ARTIF INTEL, V26, P2143, DOI 10.1016/j.engappai.2013.07.004
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paulin M, 2017, INT J COMPUT VISION, V121, P149, DOI 10.1007/s11263-016-0924-3
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Read J, 2009, LECT NOTES ARTIF INT, V5782, P254, DOI 10.1007/978-3-642-04174-7_17
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Zhang L, 2011, SOFT COMPUT, V15, P917, DOI 10.1007/s00500-010-0558-2
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
NR 33
TC 5
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8695
EP 8710
DI 10.1007/s11042-017-4764-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800041
DA 2024-07-18
ER

PT J
AU Hu, WC
   Chen, CH
   Su, YJ
   Chang, TH
AF Hu, Wu-Chih
   Chen, Chao-Ho
   Su, Yi-Jen
   Chang, Tzu-Hsing
TI Feature-based real-time video stabilization for vehicle video recorder
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stabilization; Moving camera; Optical flow; Feature point
ID VISUAL SURVEILLANCE; OBJECT DETECTION; MOTION; TRACKING
AB This paper presents a fast and effective method based on features to obtain real-time video stabilization for vehicle video recorder system. The corresponding feature points are first obtained from two consecutive frames and then optical flows are calculated based on these points. Next, the obtained optical flows are mapped to polar coordinates to obtain clusters and remove incorrect optical flows. These obtained clusters are used to evaluate the global motion and rotation angle. Finally, the obtained global motion and rotation angle are smoothed and then compensated to obtain the stabilized video. Experimental results show that the proposed method has good performance for video stabilization.
C1 [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Magong, Penghu, Taiwan.
   [Chen, Chao-Ho; Chang, Tzu-Hsing] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung, Taiwan.
   [Su, Yi-Jen] Shu Te Univ, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
C3 National Penghu University of Science & Technology; National Kaohsiung
   University of Science & Technology; Shu-Te University
RP Chen, CH (corresponding author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung, Taiwan.
EM wchu@npu.edu.tw; thouho@cc.kuas.edu.tw; iansu@stu.edu.tw;
   smallv2002@hotmail.com
FU Ministry of Science and Technology, Taiwan [MOST105-2221-E-346-009,
   MOST104-2221-E-151-008]
FX This work was partly supported by the Ministry of Science and
   Technology, Taiwan, under grants MOST105-2221-E-346-009 and
   MOST104-2221-E-151-008. The authors would like to thank Mr. Jhih-Bin Guo
   for his help with the experiments. The authors also gratefully
   acknowledge the helpful comments and suggestions of reviewers, which
   have improved the quality and presentation.
CR Aguilar WG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-46
   [Anonymous], 2014, ADV INTELLIGENT SYST
   Buehler C, 2001, PROC CVPR IEEE, P609
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Ghosh A, 2012, IEEE T CIRC SYST VID, V22, P1127, DOI 10.1109/TCSVT.2012.2190476
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Hu WC, 2011, J VIS COMMUN IMAGE R, V22, P543, DOI 10.1016/j.jvcir.2011.03.009
   Huang D. Y., 2012, J INFORM HIDING MULT, V3, P282
   Jia C, 2014, IEEE T SIGNAL PROCES, V62, P3293, DOI 10.1109/TSP.2014.2325795
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim SK, 2013, IEEE T CONSUM ELECTR, V59, P267, DOI 10.1109/TCE.2013.6490269
   Lee TH, 2014, J VIS COMMUN IMAGE R, V25, P943, DOI 10.1016/j.jvcir.2014.02.011
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Marcenaro L, 2001, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2001.959025
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Nicolescu M, 2005, IEEE T PATTERN ANAL, V27, P739, DOI 10.1109/TPAMI.2005.91
   Shen Y, 2009, IEEE T CONSUM ELECTR, V55, P1714, DOI 10.1109/TCE.2009.5278047
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Xu J, 2012, IEEE T CONSUM ELECTR, V58, P993, DOI 10.1109/TCE.2012.6311347
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
   Zhang GF, 2009, VISUAL COMPUT, V25, P997, DOI 10.1007/s00371-009-0310-z
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 29
TC 6
Z9 8
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5107
EP 5127
DI 10.1007/s11042-017-4369-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800001
DA 2024-07-18
ER

PT J
AU Khosravi, MH
   Hassanpour, H
   Ahmadifard, A
AF Khosravi, Mohammad Hossein
   Hassanpour, Hamid
   Ahmadifard, Alireza
TI A content recognizability measure for image quality assessment
   considering the high frequency attenuating distortions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Image content recognizability; High frequency
   attenuating distortions; Non-negative matrix factorization
ID NONNEGATIVE MATRIX FACTORIZATION; STRUCTURAL SIMILARITY; MODEL; BLUR
AB The existing image quality assessment (IQA) techniques try to estimate image distortions regardless of their destructive effects on image contents. Analyzing the subjective scores of image quality databases shows that the worst opinions belong to distortions which make the images non-recognizable. In this paper, we investigate the effects of image contents clarity on human perception of quality. We found that among the several image distortions, the high frequency attenuating (HFA) ones are noticeable distortions which influence the image content recognizability, and accordingly the image understandability. To evaluate the severity of HFA distortions, we employ the non-negative matrix factorization (NMF), which has the ability to part-based image decomposition. When this decomposition is applied on an image, the resulting factors provide the latent information regarding the image parts. We employ the statistical characteristics of NMF factors to quantify the influence of HFA distortions on image contents. Our experiments performed on popular image quality databases show that the accuracy of our proposed measure is promising.
C1 [Khosravi, Mohammad Hossein; Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn & Informat Technol, Shahrood, Iran.
   [Ahmadifard, Alireza] Shahrood Univ Technol, Fac Elect Engn & Robot, Shahrood, Iran.
C3 Shahrood University of Technology; Shahrood University of Technology
RP Khosravi, MH (corresponding author), Shahrood Univ Technol, Fac Comp Engn & Informat Technol, Shahrood, Iran.
EM mohokhosravi@shahroodut.ac.ir; h.hassanpour@shahroodut.ac.ir;
   ahmadyfard@shahroodut.ac.ir
RI Hassanpour, Hamid/AAL-7271-2020; Khosravi, Mohammad
   Hossein/AAQ-9988-2021
OI Hassanpour, Hamid/0000-0002-5513-9822; Khosravi, Mohammad
   Hossein/0000-0003-3595-1829
CR [Anonymous], IND C INDICON 2009 A
   [Anonymous], ELECT IMAGING
   [Anonymous], ELECT IMAGING
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], OPTIK INT J LIGHT EL
   [Anonymous], METRIX MUX VERSION 1
   [Anonymous], 2015, INFORM SCI
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], ELECT IMAGING
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Boutsidis C, 2008, PATTERN RECOGN, V41, P1350, DOI 10.1016/j.patcog.2007.09.010
   Carnec M, 2008, SIGNAL PROCESS-IMAGE, V23, P239, DOI 10.1016/j.image.2008.02.003
   Chandler DM, 2003, PROC SPIE, V5007, P73, DOI 10.1117/12.477772
   Donoho D, 2003, ADV NEURAL INFORM PR
   Flusser J, 2015, IEEE T PATTERN ANAL, V37, P786, DOI 10.1109/TPAMI.2014.2353644
   Gao WF, 2002, IEEE T CIRC SYST VID, V12, P1150, DOI 10.1109/TCSVT.2002.806817
   Gonzalez E., 2005, TR0502 RIC U DEP COM
   GOODMAN JS, 1979, IEEE T SYST MAN CYB, V9, P353
   Group VQE, 2003, FIN REP VID QUAL EXP
   Guo-Li Ji, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P791, DOI 10.1109/CSSE.2008.858
   Kamble V, 2015, OPTIK, V126, P1090, DOI 10.1016/j.ijleo.2015.02.093
   Khosravi MH, 2017, MULTIMED TOOLS APPL, V76, P2733, DOI 10.1007/s11042-015-3149-5
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Merigan WH, 1998, VISUAL NEUROSCI, V15, P359, DOI 10.1017/S0952523898152112
   Morrone MC, 1997, VISION RES, V37, P2609, DOI 10.1016/S0042-6989(97)00052-7
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   PAATERO P, 1991, J AEROSOL SCI, V22, pS273, DOI 10.1016/S0021-8502(05)80089-8
   Park CS, 2007, J MATH IMAGING VIS, V28, P279, DOI 10.1007/s10851-007-0019-4
   Pauca VP, 2006, LINEAR ALGEBRA APPL, V416, P29, DOI 10.1016/j.laa.2005.06.025
   Pollen DA, 1999, CEREB CORTEX, V9, P4, DOI 10.1093/cercor/9.1.4
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu JY, 2012, IEEE T IMAGE PROCESS, V21, P919, DOI 10.1109/TIP.2011.2169971
NR 53
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7357
EP 7382
DI 10.1007/s11042-017-4636-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700043
DA 2024-07-18
ER

PT J
AU Peng, YW
   Lan, H
   Yue, ML
   Xue, Y
AF Peng, Yuwei
   Lan, Hai
   Yue, Mingliang
   Xue, Yu
TI Multipurpose watermarking for vector map protection and authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multipurpose watermarking; Vector map; Protection; Authentication
ID FRAGILE WATERMARKING; ALGORITHM; SCHEME
AB The rapid flourishing of GIS applications has made the copyright protection and content authentication of vector maps two important issues in the digital world. In this paper, a multipurpose watermarking scheme is proposed for the scenarios when the two requirements are needed simultaneously. In the scheme, robust watermark and fragile watermarks are embedded into the host map simultaneously. To avoid the interference between the two kinds of watermarks, robust watermark is embedded into the feature points of the objects in the map, while fragile watermarks are embedded into the nonfeature points. Due to the independence of the feature points and non-feature points, the robust watermark and fragile watermarks can be detected independently. After watermark detection, the robust watermark can be used for copyright protection, and the fragile watermarks can be used for tamper localization and characterization. The fragility of the proposed scheme is analyzed theoretically, and both the robustness and the fragility are verified by a set comprehensive experiments.
C1 [Peng, Yuwei; Lan, Hai] Wuhan Univ, Comp Sch, Wuhan, Hubei, Peoples R China.
   [Yue, Mingliang] Chinese Acad Sci, Wuhan Lib, Wuhan, Hubei, Peoples R China.
   [Xue, Yu] Nanjing Univ Informat Sci & Technol, Coll Comp & Software, Nanjing, Jiangsu, Peoples R China.
C3 Wuhan University; Chinese Academy of Sciences; Nanjing University of
   Information Science & Technology
RP Peng, YW (corresponding author), Wuhan Univ, Comp Sch, Wuhan, Hubei, Peoples R China.
EM ywpeng@whu.edu.cn
RI XUE, YU/KIB-5975-2024
OI Yue, Mingliang/0000-0002-1138-6661; lan, hai/0009-0007-4433-9232
FU National Natural Science Foundations of China [71603252]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD); Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology (CICAEET)
FX This work is supported by the National Natural Science Foundations of
   China under grant (No. 71603252). This work is also partially supported
   by a project funded by the Priority Academic Program Development of
   Jiangsu Higher Education Institutions (PAPD) and Jiangsu Collaborative
   Innovation Center on Atmospheric Environment and Equipment Technology
   (CICAEET).
CR [Anonymous], 2007, INTELLIGENT MULTIMED
   [Anonymous], J NANOTECHNOL
   [Anonymous], 7541985 ANSIIEEE
   BELUSSI A, 2005, P 13 INT S ADV GIS, P220, DOI DOI 10.1145/1097064.1097096
   Brewer C.A., 2007, CARTOGR GEOGR INF SC, V34, P3, DOI [10.1559/152304007780279078, DOI 10.1559/152304007780279078]
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen N, 2008, J ZHEJIANG UNIV-SC A, V9, P517, DOI 10.1631/jzus.A071493
   Chih-Hung Lin, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P636, DOI 10.1109/IIH-MSP.2009.203
   Chuanjian Wang, 2012, Multimedia Tools and Applications, V57, P67, DOI 10.1007/s11042-010-0536-9
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gökgöz T, 2005, CARTOGR J, V42, P145, DOI 10.1179/000870405X61441
   Gou HM, 2005, IEEE T SIGNAL PROCES, V53, P3988, DOI 10.1109/TSP.2005.855411
   Guo HP, 2006, INFORM SCIENCES, V176, P1350, DOI 10.1016/j.ins.2005.06.003
   Huang M, 2007, LECT NOTES COMPUT SC, V4443, P1098
   Kang H, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P234, DOI 10.1109/ITCC.2001.918797
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Lafaye J, 2007, LECT NOTES COMPUT SC, V4605, P312
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Li J, 2012, EVID-BASED COMPL ALT, V2012, DOI 10.1155/2012/792820
   Li YY, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P424
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Madelaine J, 2007, ACM S INF COMP COMM, P265
   MINTZER F, 1999, ACOUST SPEECH SIG PR, P2067
   Mobasseri BG, 2000, IEEE IMAGE PROC, P458, DOI 10.1109/ICIP.2000.900994
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Ohbuchi R, ICME2002
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Solachidis V, 2000, INT CONF ACOUST SPEE, P1955, DOI 10.1109/ICASSP.2000.859213
   Varodayan D, 2008, INT CONF ACOUST SPEE, P225, DOI 10.1109/ICASSP.2008.4517587
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang ZF, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P461
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xu TT, 2009, LECT NOTES COMPUT SC, V5879, P1281
   Yan HW, 2012, APPL GEOMAT, V4, P225, DOI 10.1007/s12518-011-0064-y
   Yan HW, 2011, COMPUT ENVIRON URBAN, V35, P485, DOI 10.1016/j.compenvurbsys.2010.10.004
   Yu-Chi Pu, 2009, Information Technology Journal, V8, P982, DOI 10.3923/itj.2009.982.989
   Zhang HL, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P549, DOI 10.1109/MINES.2009.224
   Zheng L., 2009, 2009 INT C E BUS INF, P1, DOI [10.1109/EBISS.2009.5137869, DOI 10.1109/EBISS.2009.5137869]
   Zhu Congxu, 2006, Wuhan University Journal of Natural Sciences, V11, P1675, DOI 10.1007/BF02831848
NR 45
TC 19
Z9 22
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7239
EP 7259
DI 10.1007/s11042-017-4631-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700038
DA 2024-07-18
ER

PT J
AU Shivani, S
AF Shivani, Shivendra
TI Multi secret sharing with unexpanded meaningful shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Multi secret sharing; Meaningful share; Unexpanded
   share
ID VISUAL CRYPTOGRAPHY; IMAGE QUALITY
AB Traditional Visual Cryptography (VC) facilitates a technique to protect only one secret image using single set of shares. Recent researches enhance the capabilities of traditional VC by providing the feature of Multi Secret Sharing (MSS), where more than one secret image can be protected at a time. In MSS different secret images are revealed by the stacking of same set of shares at different angles. Most of the existing state of art researches on MSS have common problem of pixel expansion and random pattern of the shares. Due to pixel expansion, there is wastage of the storage space and transmission time, moreover random pattern of the shares increases the vulnerability for cryptanalysis. In this paper a novel Multi Secret Sharing scheme with unexpanded as well as meaningful shares has been proposed to protect two secret images at a time. In the proposed approach the recovery probability of black pixels of the secret images in the decoded images is always 1 while that of white pixels, it is 0.25. Therefore the contrast of the decoded images is obtained as 25 % which is same as in most of the earlier researches with pixel expansion & random shares. Experiments confirm that all meaningful shares fulfill the contrast and security conditions. Secret images can be easily decoded by only human visual system without any computation at receiver end.
C1 [Shivani, Shivendra] Thapar Univ, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Shivani, S (corresponding author), Thapar Univ, Patiala, Punjab, India.
EM shivendra.shivani@thapar.edu
RI Shivani, Shivendra/AFN-2368-2022
OI Shivani, Shivendra/0000-0002-5931-6603
CR [Anonymous], IEEE T NEURAL NETW L
   [Anonymous], 1998, THESIS
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Fu MS, 2004, P IEEE INT C MULT EX
   Haiping L, 2004, IEEE SIGNAL PROCESS, V11
   Hsu H-C, 2004, P IEEE INT C NETW SE
   Liao X, 2016, MULTIMED TOOLS APPL
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   MACPHERSON LA, 2002, THESIS
   Myodo E, 2006, P IEEE ICIP ATL
   Nakajima M, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P303
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Reddy L.S., 2015, 3 INT C ADV COMP NET, P249
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   ULICHNEY R, 1993, P SOC PHOTO-OPT INS, V1913, P332, DOI 10.1117/12.152707
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yan-Yan Ha, 2014, Applied Mechanics and Materials, V644-650, P2108, DOI 10.4028/www.scientific.net/AMM.644-650.2108
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Young DP, 2005, P 2 JOINT IEEE INT W
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 27
TC 19
Z9 19
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6287
EP 6310
DI 10.1007/s11042-017-4536-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800054
DA 2024-07-18
ER

PT J
AU Sun, LT
   Yamasaki, T
   Aizawa, K
AF Sun, Litian
   Yamasaki, Toshihiko
   Aizawa, Kiyoharu
TI Photo aesthetic quality estimation using visual complexity features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aesthetic estimation; Image feature; Photo quality assessment; Visual
   complexity
ID PREFERENCE; ARCHITECTURE
AB The amount of visual data available on the Web is growing explosively and it is becoming increasingly important to explore methods for automatically estimating the quality of this content in a manner that is consistent with the aesthetic perceptions of humans. The key to this challenging problem is to design an appropriate set of features to extract the aesthetic properties from content. Most previous studies designed a set of aesthetic features based on photographic criteria, which were unavoidably limited to specific examples and they lacked an interpretation based on the mechanism of human aesthetic perception. According to psychological theory, visual complexity is an important property of the stimuli, because it directly influences the viewer's arousal level, which is believed to be closely related to aesthetic perception. In this study, we propose an alternative set of features for aesthetic estimation based on a visual complexity principle. We extracted the visual complexity properties from an input image in terms of their composition, shape, and distribution. In addition, we demonstrated that the proposed features are consistent with human perception on the complexity in our visual complexity dataset. Next, we employed these features for photo-aesthetic quality estimation using a large-scale dataset. Various experiments were conducted under different conditions and comparisons with state-of-the-art methods shows that the proposed visual complexity feature outperforms photography rule-based features and even better than deep features.
C1 [Sun, Litian; Yamasaki, Toshihiko; Aizawa, Kiyoharu] Univ Tokyo, Fac Engn, Dept Informat & Commun Engn, Bunkyo Ku, Bldg 2,7-3-1 Hongo, Tokyo 1138656, Japan.
C3 University of Tokyo
RP Sun, LT (corresponding author), Univ Tokyo, Fac Engn, Dept Informat & Commun Engn, Bunkyo Ku, Bldg 2,7-3-1 Hongo, Tokyo 1138656, Japan.
EM sun1101@hal.t.u-tokyo.ac.jp; yamasaki@hal.t.u-tokyo.ac.jp;
   aizawa@hal.t.u-tokyo.ac.jp
CR Akalin A, 2009, J ENVIRON PSYCHOL, V29, P124, DOI 10.1016/j.jenvp.2008.05.005
   [Anonymous], 2011, ACM International Conference on Multimedia MM
   Martín JA, 2010, INFORM SCIENCES, V180, P846, DOI 10.1016/j.ins.2009.08.032
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Babin BJ, 2000, J BUS RES, V49, P91, DOI 10.1016/S0148-2963(99)00011-9
   Berlyne D.E., 1971, Aesthetics and Psychobiology
   Berlyne DavidE., 1974, STUDIES NEW EXPT AES, P1
   Bhattacharya S., 2010, P 18 ACM INT C MULTI, P271
   BIRKHOFF GEORGE DAVID, 1933, Aesthetic measure, DOI DOI 10.4159/HARVARD.9780674734470
   Campbell A, 2015, LECT NOTES COMPUT SC, V9027, P27, DOI 10.1007/978-3-319-16498-4_3
   CHIPMAN SF, 1977, J EXP PSYCHOL GEN, V106, P269, DOI 10.1037/0096-3445.106.3.269
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467
   Donderi DC, 2006, PSYCHOL BULL, V132, P73, DOI 10.1037/0033-2909.132.1.73
   Eysenck HJ, 1942, PSYCHOL REV, V49, P344, DOI 10.1037/h0057013
   Friedenberg J, 2015, EMPIR STUD ARTS, V33, P144, DOI 10.1177/0276237415594708
   GARCIA M, 1994, INTERACT COMPUT, V6, P191, DOI 10.1016/0953-5438(94)90024-8
   Guo XY, 2012, OPT REV, V19, P306, DOI 10.1007/s10043-012-0047-1
   He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377
   Heaps C, 1999, J EXP PSYCHOL HUMAN, V25, P299, DOI 10.1037/0096-1523.25.2.299
   Huhmann B., 2003, Visual Communication Quarterly, V10, P10
   ICHIKAWA S, 1985, PERCEPT PSYCHOPHYS, V38, P101, DOI 10.3758/BF03198846
   Imamoglu Ç, 2000, J ENVIRON PSYCHOL, V20, P5, DOI 10.1006/jevp.1999.0155
   Katz B. F., 2002, EMPIR STUD ARTS, V20, P1, DOI DOI 10.2190/Y66C-3RHH-8F4G-UE5T
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leder H, 2004, BRIT J PSYCHOL, V95, P489, DOI 10.1348/0007126042369811
   Li C, 2010, P ACM INT C MULT, P827, DOI DOI 10.1145/1873951.1874089
   Lihua G, 2015, ARXIV150505225
   Lo KY, 2012, INT C PATT RECOG, P2186
   Lu P, 2015, SIGNAL PROCESSING IM
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Mallon B, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00161
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   MUNSINGER H, 1964, PSYCHOL MONOGR, V78, P1
   MURRAY N, 2012, PROC CVPR IEEE, P2408, DOI DOI 10.1109/CVPR.2012.6247954
   Nadal M, 2008, P IAEA08, P137, DOI DOI 10.2190/EM.28.2.D
   Nadal Marcos., 2010, EMPIR STUD ARTS, V28, P173, DOI [https://doi.org/10.2190/EM.28.2.d, DOI 10.2190/EM.28.2.D, 10.2190/EM.28.2.d]
   Nasar J.L., 2002, EMPIRICAL STUDIES AR, V20, P83, DOI DOI 10.2190/286Y-5VLW-G05W-RAQG
   Nishiyama M, 2011, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2011.5995539
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Oliva A, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1041
   Palumbo L, 2016, EMPIR STUD ARTS, V34, P35, DOI 10.1177/0276237415621185
   Redies C, 2012, LECT NOTES COMPUT SC, V7583, P522, DOI 10.1007/978-3-642-33863-2_54
   Rigau J, 2008, IEEE COMPUT GRAPH, V28, P24, DOI 10.1109/MCG.2008.34
   Romero J, 2012, J MATH ARTS, V6, P125, DOI 10.1080/17513472.2012.679514
   SAKLOFSKE DH, 1975, PERCEPT MOTOR SKILL, V41, P813, DOI 10.2466/pms.1975.41.3.813
   Schenkman BN, 2000, BEHAV INFORM TECHNOL, V19, P367, DOI 10.1080/014492900750000063
   Simond F, 2015, IEEE P INT C IM PROC
   Sun L, 2014, COMP VIS ECCV 2014 W, P20
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Tuch AN, 2012, INT J HUM-COMPUT ST, V70, P794, DOI 10.1016/j.ijhcs.2012.06.003
   van der Helm PA, 2000, PSYCHOL BULL, V126, P770, DOI 10.1037//0033-2909.126.5.770
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Wakefield KL, 1998, J RETAILING, V74, P515, DOI 10.1016/S0022-4359(99)80106-7
   WANG L, 1990, PATTERN RECOGN, V23, P905, DOI 10.1016/0031-3203(90)90135-8
   Xu Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1183, DOI 10.1145/2702123.2702418
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang Q, 2014, ROLLING GUIDANCE FIL, P815
NR 64
TC 9
Z9 11
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5189
EP 5213
DI 10.1007/s11042-017-4424-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800005
DA 2024-07-18
ER

PT J
AU Teng, L
   Wang, XY
   Meng, J
AF Teng, Lin
   Wang, Xingyuan
   Meng, Juan
TI A chaotic color image encryption using integrated bit-level permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image; Chaos encryption; Integrated bit-level; Permutation
ID ALGORITHM
AB In this paper, a color image encryption algorithm based on chaos has been proposed. We convert the color image into three bit-level images (R, G, B components) and combine them to one bit-level image. Then, only use bit-level permutation architecture based on chaotic system to encrypt the integrated image. When diffuse the position of the integrated binary image, the value of the gray pixel is changed as well, so this architecture can achieve similar security to permutation-diffusion architecture. Besides, this architecture makes the three color components affect each other, it can reduce the correlations between three components. Simulation results show that the algorithm can encrypt the color image effectively and resist various typical attacks.
C1 [Teng, Lin; Meng, Juan] Dalian Ocean Univ, Coll Informat Engn, Dalian, Liaoning, Peoples R China.
   [Teng, Lin; Meng, Juan] Key Lab Marine Informat Technol Liaoning Prov, Dalian, Liaoning, Peoples R China.
   [Wang, Xingyuan] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Dalian Ocean University; Dalian University of Technology
RP Teng, L (corresponding author), Dalian Ocean Univ, Coll Informat Engn, Dalian, Liaoning, Peoples R China.; Teng, L (corresponding author), Key Lab Marine Informat Technol Liaoning Prov, Dalian, Liaoning, Peoples R China.
EM tenglin@mail.dlut.edu.cn
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61173183, 60973152,
   60573172]; Superior University Doctor Subject Special Scientific
   Research Foundation of China [20070141014]; Program for Liaoning
   Excellent Talents in University [LR2012003]; National Natural Science
   Foundation of Liaoning province [20082165]; Fundamental Research Funds
   for the Central Universities [DUT12JB06]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61173183, 60973152, and 60573172), the Superior University
   Doctor Subject Special Scientific Research Foundation of China (No:
   20070141014), Program for Liaoning Excellent Talents in University (No:
   LR2012003), the National Natural Science Foundation of Liaoning province
   (No: 20082165) and the Fundamental Research Funds for the Central
   Universities (No: DUT12JB06).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   [Anonymous], APPL MECH MAT
   [Anonymous], J EMERGING TECHNOLOG
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Faragallah OS, 2015, SIGNAL IMAGE VIDEO P, V9, P1917, DOI 10.1007/s11760-014-0683-y
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Mollaeefar M, 2015, MULTIMED TOOLS APPL, P1
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang XY, 2015, ENTROPY-SWITZ, V17, P3877, DOI 10.3390/e17063877
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 19
TC 85
Z9 87
U1 3
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6883
EP 6896
DI 10.1007/s11042-017-4605-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700020
DA 2024-07-18
ER

PT J
AU Zhang, H
   Huang, T
   Lv, ZH
   Liu, SY
   Zhou, ZL
AF Zhang, Hao
   Huang, Tao
   Lv, Zhihan
   Liu, SanYa
   Zhou, Zhili
TI MCRS: A course recommendation system for MOOCs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MOOC; Online course; Course recommendation; Apriori; Hadoop; Spark;
   Distributed computation
AB With the popularization development of MOOC platform, the number of online courses grows rapidly. Efficient and appropriate course recommendation can improve learning efficiency. Traditional recommendation system is applied to the closed educational environment in which the quantity of courses and users is relatively stable. Recommendation model and algorithm cannot directly be applied to MOOC platform efficiently. With the light of the characteristics of MOOC platform, MCRS proposed in this paper has made great improvement in the course recommendation model and recommendation algorithm. MCRS is based on distributed computation framework. The basic algorithm of MCRS is distributed association rules mining algorithm, which based on the improvement of Apriori algorithm. In addition, it is useful to mine the hidden courses rules in course enrollment data. Firstly, the data is pre-processed into a standard form by Hadoop. It aims to improve the efficiency of the basic algorithm. Then it mines association rules of the standard data by Spark. Consequently, course recommendation information is transferred into MySQL through Sqoop, which makes timely feedback and improves user's courses retrieval efficiency. Finally, to validate the efficiency of MCRS, a series of experiments are carried out on Hadoop and Spark, and the results shows that MCRS is more efficient than traditional Apriori algorithm and Apriori algorithm based on Hadoop, and the MCRS is suitable for current MOOC platform.
C1 [Zhang, Hao; Huang, Tao; Liu, SanYa] CCNU, Natl Engn Res Ctr E Learning, Room 419,Sci Hall,152 Luoyu Rd, Wuhan 430072, Hubei, Peoples R China.
   [Lv, Zhihan] UCL, Dept Comp Sci, London, England.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Central China Normal University; University of London; University
   College London; Nanjing University of Information Science & Technology
RP Lv, ZH (corresponding author), UCL, Dept Comp Sci, London, England.
EM lvzhihan@gmail.com
RI Lv, Zhihan/GLR-6000-2022; Lyu, Zhihan/I-3187-2014
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074; Liu,
   Sannyuya/0000-0002-4926-3720
FU National Programs for Science and Technology Development [2015BAK07B03];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology (CICAEET); CCNU from
   the colleges' basic research and operation of MOE [CCNU17QN0004]
FX This study was funded by the National Programs for Science and
   Technology Development (grant number 2015BAK07B03), the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD), Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology (CICAEET), and specific funding for
   education science research by self-determined research funds of CCNU
   from the colleges' basic research and operation of MOE ((grant number
   CCNU17QN0004)).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2382438.2382442
   Aher SB, 2013, KNOWL-BASED SYST, V51, P1, DOI 10.1016/j.knosys.2013.04.015
   [Anonymous], 2001, P WWW10 MAY 1 5 HONG
   Baker RS, 2014, IEEE INTELL SYST, V29, P78, DOI 10.1109/MIS.2014.42
   Dan Luo, 2015, 2015 INT S ED TECHN
   Dean BJ, 2010, OSDI
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Denley Tristan, 2013, EDUCAUSE REV
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gaikwad T, 2013, TECHN ED T4E 2013 IE
   García E, 2011, INTERNET HIGH EDUC, V14, P77, DOI 10.1016/j.iheduc.2010.07.006
   Hou Yifan, 2016, ARXIV161003147
   Li N, 2012, AC INT C SOFTW ENG A
   Lin M.Y., 2012, P 6 INT C UB INF MAN, P1
   Liu Q, 2016, SECUR COMMUN NETW, V9, P4002, DOI 10.1002/sec.1582
   Mirwais Tanai, 2010, DATA MINING ED DECIS, P260
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Romero C, 2010, IEEE T SYST MAN CY C, V40, P601, DOI 10.1109/TSMCC.2010.2053532
   Salehi M, 2013, IEEE T LEARN TECHNOL, V6, P350, DOI 10.1109/TLT.2013.28
   Wang YH, 2009, EXPERT SYST APPL, V36, P7681, DOI 10.1016/j.eswa.2008.09.008
   Wassan JT, 2015, PROCD SOC BEHV, V176, P642, DOI 10.1016/j.sbspro.2015.01.522
   Wen M, 2014, P 23 ACM INT C C INF
   West D.M., 2012, BIG DATA ED DATA MIN
   Yang XW, 2014, COMPUT COMMUN, V41, P1, DOI 10.1016/j.comcom.2013.06.009
   Yeqin Kang., 2014, Tsinghua Journal of Education, V35, P85
   [周庆 Zhou Qing], 2015, [软件学报, Journal of Software], V26, P3026
NR 27
TC 57
Z9 59
U1 1
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7051
EP 7069
DI 10.1007/s11042-017-4620-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700029
DA 2024-07-18
ER

PT J
AU Ahmad, J
   Sajjad, M
   Rho, S
   Kwon, SI
   Lee, MY
   Baik, SW
AF Ahmad, Jamil
   Sajjad, Muhammad
   Rho, Seungmin
   Kwon, Soon-il
   Lee, Mi Young
   Baik, Sung Wook
TI Determining speaker attributes from stress-affected speech in emergency
   situations with hybrid SVM-DNN architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker attributes; Stress-affected; Deep neural network; Emergency
   calls; Hybrid classifier
ID GENDER RECOGNITION; AGE; CLASSIFICATION; IDENTIFICATION
AB In the millions of emergency reporting calls made each year, about a quarter are non-emergencies. To avoid responding to such situations, forensic examination of the reported situation in the presence of speech as evidence has become an indispensable requirement for emergency response centers. Caller profile information like gender, age, emotional state, transcript, and contextual sounds determined from emergency calls, may be highly beneficial for their sophisticated forensic analysis. However, callers reporting emergency situations often express emotional stress which cause variations in speech production. Furthermore, low voice quality, and background noise make it very difficult to efficiently recognize caller attributes in such unconstrained environments. To overcome limitations of traditional classification systems in such situations, a hybrid two-stage classification scheme is proposed in this paper. Our framework consist of an ensemble of support vector machines (e-SVM) and deep neural networks (DNN) in a cascade. The first stage e-SVM consists of two models discriminatively trained on normal and stressful speech from emergency calls. Deep neural network forming the second stage of classification pipeline, is utilized only in case of ambiguous prediction results from the first stage. The adaptive nature of this two stage classification scheme helps achieve efficiency and high performance. Experiments conducted with a large dataset affirm the suitability of proposed architecture for efficient real-time speaker attribute recognition. The framework is evaluated for gender recognition from emergency calls in the presence of emotions and background noise. The framework yields significant performance improvements in comparison with other similar state-of-the-art gender recognition approaches.
C1 [Ahmad, Jamil; Kwon, Soon-il; Lee, Mi Young; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
   [Sajjad, Muhammad] Islamia Coll, Dept Comp Sci, Peshawar, Pakistan.
   [Rho, Seungmin] Sungkyul Univ, Deparment Multimedia, Anyang, South Korea.
C3 Sejong University; University of Peshawar; Sungkyul University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM sbaik@sejong.ac.kr
RI Rho, Seungmin/HTP-6683-2023; Sajjad, Muhammad/L-5269-2016; Baik, Sung
   Wook/AAR-8236-2020; Ahmad, Jamil/G-6931-2015
OI Sajjad, Muhammad/0000-0001-5646-0338; KWON, SOONIL/0000-0001-5451-8815;
   Ahmad, Jamil/0000-0001-8407-5971; Baik, Sung Wook/0000-0002-6678-7788
FU ICT R&D program of MSIP/IITP [R0126-15-1119]
FX This work was supported by the ICT R&D program of MSIP/IITP. (No.
   R0126-15-1119, Development of a solution for situation-awareness based
   on the analysis of speech and environmental sounds).
CR Ahmad Jamil, 2016, 2016 International Conference on Platform Technology and Service (PlatCon). Proceedings, P1, DOI 10.1109/PlatCon.2016.7456788
   Ahmad J, 2017, MULTIMED TOOLS APPL, V76, P4069, DOI 10.1007/s11042-016-3450-y
   [Anonymous], EENA OPERATIONS DOCU
   [Anonymous], 7 INT C MUS INF RETR
   [Anonymous], 2006, PROC 8 INT C SIGNAL, DOI DOI 10.1109/ICOSP.2006.345541
   [Anonymous], MULT EXP 2003 ICME 0
   [Anonymous], P 7 INT C LANG RES E
   [Anonymous], 1990, ICSLP 1990
   Baber C, 1996, SPEECH COMMUN, V20, P37, DOI 10.1016/S0167-6393(96)00043-X
   Bahari MH, 2014, ENG APPL ARTIF INTEL, V34, P99, DOI 10.1016/j.engappai.2014.05.003
   Barkana BD, 2015, APPL ACOUST, V98, P52, DOI 10.1016/j.apacoust.2015.04.013
   Campbell WilliamM., 2004, Advances in Neural Information Processing Systems, V16
   Campbell WM, 2006, COMPUT SPEECH LANG, V20, P210, DOI 10.1016/j.csl.2005.06.003
   Cummins N, 2013, INTERSPEECH, P857
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Fayek H., 2015, SIGNAL PROCESSING CO, P1
   Fujimura H, 2014, INTERSPEECH, P1139
   Germain FG, 2013, INTERSPEECH, P732
   Hansen John H. L., 2007, Speaker Classification I. Fundamentals, Features, and Methods. (Lecture Notes in Artificial Intelligence vol. 4343), P108, DOI 10.1007/978-3-540-74200-5_6
   Harb H, 2005, J INTELL INF SYST, V24, P179, DOI 10.1007/s10844-005-0322-8
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hu YK, 2012, SECUR COMMUN NETW, V5, P211, DOI 10.1002/sec.308
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kockmann M., 2010, Proc. of the Interspeech, P2822
   Li M, 2013, COMPUT SPEECH LANG, V27, P151, DOI 10.1016/j.csl.2012.01.008
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Martin A, 2001, INT CONF ACOUST SPEE, P237, DOI 10.1109/ICASSP.2001.940811
   Meinedo H., 2010, Proc. INTERSPEECH, P2818
   Metze F, 2007, INT CONF ACOUST SPEE, P1089
   Rao KS, 2014, SPRBRIEF ELECT, P13, DOI 10.1007/978-3-319-07130-5_2
   Sainath TN, 2013, IEEE T AUDIO SPEECH, V21, P2267, DOI 10.1109/TASL.2013.2284378
   Saul LK, 1996, J ARTIF INTELL RES, V4, P61, DOI 10.1613/jair.251
   Shahin I, 2013, ENG APPL ARTIF INTEL, V26, P1652, DOI 10.1016/j.engappai.2013.03.013
   Shriberg E, 2005, SPEECH COMMUN, V46, P455, DOI 10.1016/j.specom.2005.02.018
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wolters M, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1435
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
   Zhou GJ, 2001, IEEE T SPEECH AUDI P, V9, P201, DOI 10.1109/89.905995
NR 40
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4883
EP 4907
DI 10.1007/s11042-016-4041-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500045
DA 2024-07-18
ER

PT J
AU Thirumuru, R
   Gangashetty, SV
   Vuppala, AK
AF Thirumuru, Ramakrishna
   Gangashetty, Suryakanth V.
   Vuppala, Anil Kumar
TI Improved vowel region detection from a continuous speech using post
   processing of vowel onset points and vowel end-points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vowel onset point (VOP); Vowel end-point (VEP); Zero frequency
   filtering; Magnitude spectrum; Epoch intervals; Strength of the
   excitation
ID EXCITATION; SIGNALS
AB Vowels are produced with an open configuration of the vocal tract, without any audible friction. The acoustic signal is relatively loud with varying strength of impulse-like excitation. Vowels possess significant energy content in the low-frequency bands of the speech signal. Acoustic events such as vowel onset point (VOP) and vowel end-point (VEP) can be used as landmarks to detect vowel regions in a speech signal. In this paper, a two-stage algorithm is proposed to detect precise vowel regions. In the first level, the speech signal is processed using zero frequency filtering to emphasize energy content in low-frequency bands of speech. Zero frequency filtered signal predominantly contains low-frequency content of the speech signal as it is filtered around 0 Hz. This process is followed by the extraction of dominant spectral peaks from the magnitude spectrum around glottal closure regions of the speech signal. The vowel onset points and vowel end-points are obtained by convolving the enhanced spectral contour of zero frequency filtered signal with first order Gaussian differentiator. In the next level, a post-processing is carried out in the regions around VOP and VEP to remove spurious vowel regions based on uniformity of epoch intervals. In addition, the positions of VOPs and VEPs are also corrected using the strength of the excitation of the speech signal. The performance of the proposed vowel region detection method is compared with the existing state of art methods on TIMIT acoustic-phonetic speech corpus. It is reported that this method produced significant improvement in vowel region detection in clean and noisy environments.
C1 [Thirumuru, Ramakrishna; Gangashetty, Suryakanth V.; Vuppala, Anil Kumar] Int Inst Informat Technol Hyderabad, Language Technol Res Ctr, Hyderabad, Andhra Pradesh, India.
C3 International Institute of Information Technology Hyderabad
RP Thirumuru, R (corresponding author), Int Inst Informat Technol Hyderabad, Language Technol Res Ctr, Hyderabad, Andhra Pradesh, India.
EM ramakrishna.thirumuru@research.iiit.ac.in; svg@iiit.ac.in;
   anil.vuppala@iiit.ac.in
RI Gangashetty, Suryakanth/AAO-5590-2020; GANGASHETTY, SURYAKANTH
   V/AAX-9268-2021
OI Gangashetty, Suryakanth/0000-0001-6745-4363; 
CR [Anonymous], 1993, Discrete Time Processing of Speech Signals
   Gangamohan P, 2014, INTERSPEECH, P1253
   Glass JR, 2003, COMPUT SPEECH LANG, V17, P137, DOI 10.1016/S0885-2308(03)00006-8
   HERMES DJ, 1990, J ACOUST SOC AM, V87, P866, DOI 10.1121/1.398896
   Murty KSR, 2008, IEEE T AUDIO SPEECH, V16, P1602, DOI 10.1109/TASL.2008.2004526
   Prasanna S., 2001, SIGNIFICANCE VOWEL O, P81
   Prasanna SRM, 2009, IEEE T AUDIO SPEECH, V17, P556, DOI 10.1109/TASL.2008.2010884
   Prasanna SM, 2005, P INTERSPEECH, P1133
   Rao KS, 2013, SPEECH COMMUN, V55, P745, DOI 10.1016/j.specom.2013.03.002
   Rao KS, 2009, SPEECH COMMUN, V51, P1263, DOI 10.1016/j.specom.2009.06.004
   Schutte Ken., 2005, 9 EUROPEAN C SPEECH, P1005
   Stevens K.N., 2016, CIRC SYST SIGNAL PRO, V36, P1
   Vuppala AK, 2013, INT J SPEECH TECHNOL, V16, P229, DOI 10.1007/s10772-012-9179-8
   Vuppala AK, 2012, AEU-INT J ELECTRON C, V66, P697, DOI 10.1016/j.aeue.2011.12.013
   Vuppala AK, 2012, IEEE T AUDIO SPEECH, V20, P1894, DOI 10.1109/TASL.2012.2191284
   Vydana HK, 2015, P 2015 ANN IEEE IND, P1
   Yadav J, 2013, IEEE SIGNAL PROC LET, V20, P299, DOI 10.1109/LSP.2013.2245647
   Yegnanarayana B, 2011, INT CONF ACOUST SPEE, P5392
   Yegnanarayana B, 2009, IEEE T AUDIO SPEECH, V17, P614, DOI 10.1109/TASL.2008.2012194
NR 19
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4753
EP 4767
DI 10.1007/s11042-017-5044-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500038
DA 2024-07-18
ER

PT J
AU Yang, HH
   Qu, SR
   Zheng, ZX
AF Yang, Honghong
   Qu, Shiru
   Zheng, Zunxin
TI Visual tracking via online discriminative multiple instance metric
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Bag level metric learning; Multiple instance learning;
   Feature selection
ID OBJECT TRACKING; SELECTION
AB Motion object tracking is an important issue in computer vision. In this paper, a robust tracking algorithm based on multiple instance learning (MIL) is proposed. First, a coarse-to-fine search method is designed to reduce the computation load of cropping candidate samples for a new arriving frame. Then, a bag-level similarity metric is proposed to select the most correct positive instances to form the positive bag. The instance's importance to bag probability is determined by their Mahalanobis distance. Furthermore, an online discriminative classifier selection method, which exploits the average gradient and average weak classifiers strategy to optimize the margin function between positive and negative bags, is presented to solve the suboptimal problem in the process of selecting weak classifiers. Experimental results on challenging sequences show that the proposed method is superior to other compared methods in terms of both qualitative and quantitative assessments.
C1 [Yang, Honghong; Qu, Shiru] Northwestern Polytech Univ, Dept Automat, Xian, Shaanxi, Peoples R China.
   [Zheng, Zunxin] Shenzhen Univ, Coll Econ, Shenzhen, Guangdong, Peoples R China.
   [Zheng, Zunxin] Shenzhen Univ, Ctr Finance & Accounting Res, Shenzhen, Guangdong, Peoples R China.
C3 Northwestern Polytechnical University; Shenzhen University; Shenzhen
   University
RP Zheng, ZX (corresponding author), Shenzhen Univ, Coll Econ, Shenzhen, Guangdong, Peoples R China.; Zheng, ZX (corresponding author), Shenzhen Univ, Ctr Finance & Accounting Res, Shenzhen, Guangdong, Peoples R China.
EM zxzheng@szu.edu.cn
FU China Astronautic Science and Technology Innovation Foundation
   [CASC201104]; China Aviation Science Fund Project [2012ZC53043]; NSFC
   [71471119]
FX This work was supported by the China Astronautic Science and Technology
   Innovation Foundation under Grant No. CASC201104, China Aviation Science
   Fund Project under Grant No. 2012ZC53043 and NSFC under 71471119. The
   authors would like to thank the valuable comments from the reviewers and
   editors.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Elgammal A, 2003, PROC CVPR IEEE, P781
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Huang GH, 2016, MULTIMED TOOLS APPL, V75, P5473, DOI 10.1007/s11042-015-2516-6
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang N, 2011, PROC CVPR IEEE, P1161, DOI 10.1109/CVPR.2011.5995716
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Mei X., 2008, IJCV, V77, P125
   Qiu-Hong Zhou, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P545, DOI 10.1109/FG.2011.5771456
   Viola P, P IEEE COMP VIS PATT, P511
   Wang ZL, 2015, IMAGE VISION COMPUT, V38, P24, DOI 10.1016/j.imavis.2015.04.005
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu C, 2015, PATTERN RECOGN, V48, P3917, DOI 10.1016/j.patcog.2015.06.004
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhou T, 2015, ARXIV150104378V1, P1
NR 32
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4113
EP 4131
DI 10.1007/s11042-017-4498-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500003
DA 2024-07-18
ER

PT J
AU Chakraborty, D
   Roy, PP
   Saini, R
   Alvarez, JM
   Pal, U
AF Chakraborty, Dibyayan
   Roy, Partha Pratim
   Saini, Rajkumar
   Alvarez, Jose M.
   Pal, Umapada
TI Frame selection for OCR from video stream of book flipping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video OCR; OCR of flipping book; Video document image
ID TEXT DETECTION; SCENE; REPRESENTATION; SEGMENTATION
AB Optical Character Recognition (OCR) in video stream of flipping pages is a challenging task because flipping at random speed causes difficulties in identifying the frames that contain the open page image (OPI). Also, low resolution, blurring effect, shadow, etc., add significant noise in selection of proper frames for OCR. In this paper, we focus on identifying a set of representative frames from the video stream of flipping pages without using any explicit hardware and then perform OCR on these frames for recognition. Thus, an end-to-end solution is proposed for video stream of flipping pages. To select an OPI, we present an efficient algorithm that exploits cues from edge information during flipping event. These cues, extracted from the region of interest (ROI) of the frame, determine the flipping or open state of a page. The open state classification is performed by an SVM classifier following training of the edge cue information. After selecting a set of frames for each OPI, a representative frame from OPI set is chosen for OCR. Experiments are performed on videos captured using standard resolution camera. We have obtained 88.81 % accuracy on representative frame selection from the proposed method whereas when compared with GIST (Oliva and Torralba, Int J Comput Vis 42(3):145-175 (2001)), the accuracy was only 51.28 %. To the best of our knowledge this is the first work in this area. After frame selection, we have achieved 83.31 % character recognition accuracy and 78.11 % word recognition accuracy with traditional OCR in our dataset of flipping book.
C1 [Chakraborty, Dibyayan; Pal, Umapada] ISI Kolkata, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Roy, Partha Pratim; Saini, Rajkumar] IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Alvarez, Jose M.] Canberra Res Lab, Canberra, ACT, Australia.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Roy, PP (corresponding author), IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM dibyayancg@gmail.com; proy.fcs@iitr.ac.in; rajkr.dcs2014@iitr.ac.in;
   jose.alvarez@nicta.com.au; umapada@isical.ac.in
RI Serrano, Jose Manuel/J-6865-2016; Roy, Partha Pratim/AAW-2994-2020;
   Chakraborty, Dibyayan/AAM-1557-2021; Roy, Partha Pratim/GPF-4253-2022;
   Roy, Partha Pratim/AAV-9061-2020; Pal, Umapada/AAC-4930-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; Chakraborty,
   Dibyayan/0000-0003-0534-6417
CR [Anonymous], METHOD CAMERA BASED
   [Anonymous], INT J UBIQUITOUS MUL
   [Anonymous], IEEE INT WORKSH CONT
   [Anonymous], P DRR
   [Anonymous], 2012, PROC ASIAN C COMPUTE
   [Anonymous], 2013, ADV PATTERN RECOGNIT, DOI DOI 10.1007/3-540-44732-6-41
   [Anonymous], IMPROVING MULTIMEDIA
   [Anonymous], P ACM INT C DIG LIB
   [Anonymous], S US INT SOFTW TECHN
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bosamiya H, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P151, DOI 10.1109/ACPR.2015.7486484
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chakraborty D, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P130, DOI 10.1109/ACPR.2013.24
   Hearn D., 1994, Computer Graphics
   Iwamura Masakazu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P76, DOI 10.1109/ICDAR.2009.259
   Lee CW, 2003, PATTERN RECOGN LETT, V24, P2607, DOI 10.1016/S0167-8655(03)00105-3
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Micusik B, 2008, P COMPUTER VISION PA, P1
   Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Ngo CW, 2005, MULTIMEDIA SYST, V10, P261, DOI 10.1007/s00530-004-0157-0
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Roy S, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P288, DOI 10.1109/ACPR.2013.60
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381
   Shivakumara P, 2011, PROC INT CONF DOC, P126, DOI 10.1109/ICDAR.2011.34
   Singh M, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1250, DOI 10.1109/ICACCI.2015.7275784
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Vapnik V., 1999, NATURE STAT LEARNING
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yu Zhong, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P146, DOI 10.1109/ICDAR.1995.598963
   Zhang J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P5, DOI 10.1109/DAS.2008.49
NR 39
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 985
EP 1008
DI 10.1007/s11042-016-4292-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400042
DA 2024-07-18
ER

PT J
AU Dash, JK
   Mukhopadhyay, S
AF Dash, Jatindra Kumar
   Mukhopadhyay, Sudipta
TI Similarity learning for texture image retrieval using multiple
   classifier system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple classifier system; Content-based image retrieval; Classifier
   fusion; Similarity learning
ID SPEAKER VERIFICATION; FUSION; FEATURES; ROBUST; RULES
AB Multiple Classifier System has found its applications in many areas such as handwriting recognition, speaker recognition, medical diagnosis, fingerprint recognition, personal identification and others. However, there have been rare attempts to develop content-based image retrieval (CBIR) system that uses multiple classifiers to learn visual similarity. Texture as a primitive visual content is often used in many important applications (viz. Medical image analysis and medical CBIR system). In this paper, a texture image retrieval system is developed that learns the visual similarity in terms of class membership using multiple classifiers. The way proposed approach combines the decisions of multiple classifiers to obtain final class memberships of query for each of the output classes is also a novel concept. A modified distance that is weighted with the membership values obtained through similarity learning is used for ranking. Three different algorithms are proposed for the retrieval of images against a query image displaying the strength of multiple classifier approach, class membership score and their interplay to achieve the objective defined in terms of simplicity, retrieval effectiveness and speed. The proposed methods based on multiple classifiers achieve higher retrieval accuracy with lower standard deviation compared to all the competing methods irrespective of the texture database and feature set used. The multiple classifier retrieval schemes proposed here is tested for texture image retrieval. However, these can be used for any other challenging retrieval problems.
C1 [Dash, Jatindra Kumar] Indian Inst Technol, Kharagpur, W Bengal, India.
   [Dash, Jatindra Kumar] Natl Inst Sci & Technol, Dept Comp Sci & Engn, Berhampur, Orissa, India.
   [Mukhopadhyay, Sudipta] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; National Institute of Science & Technology
   (NIST); Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Kharagpur
RP Dash, JK (corresponding author), Indian Inst Technol, Kharagpur, W Bengal, India.; Dash, JK (corresponding author), Natl Inst Sci & Technol, Dept Comp Sci & Engn, Berhampur, Orissa, India.
EM jatinkdash@gmail.com; smukho@iitkgp.ac.in
RI Dash, Jatindra/JNT-5949-2023
OI Dash, Jatindra Kumar/0000-0001-9067-8517; Mukhopadhyay,
   Sudipta/0000-0002-4719-2578
FU Ministry of Communications and Information Technology, Department of
   Electronics and Information Technology, Govt. of India [1(3)2009-METMD,
   1(2)2013-METMD/ESDA]; Indian Institute of Technology Kharagpur
FX This work has been supported by Ministry of Communications and
   Information Technology, Department of Electronics and Information
   Technology, Govt. of India, Grant number 1(3)2009-ME&TMD and
   1(2)2013-ME&TMD/ESDA. Thanks to Indian Institute of Technology Kharagpur
   for funding our research. Authors are thankful to National Institute of
   Science and Technology, Berhampur, Odisha, India 761008 for extending
   its research facility. A special thanks to Dr. Ram Kulesh Thakur,
   Department of English, National Institute of Science and Technology,
   Berhampur, Odisha for his help.
CR [Anonymous], ROT TEXT
   [Anonymous], P 1997 IEEE WORKSH N
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], SPIE MED IMAGING
   [Anonymous], 2006, 1 COURSE FUZZY THEOR
   [Anonymous], SPIE MED IMAGING
   [Anonymous], 1963, Amer. Math. Soc. Transl.
   [Anonymous], 2006, International Journal of Hybrid Intelligent Systems, DOI DOI 10.3233/HIS-2006-3104
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Brodatz P., 1966, Textures: a photographic album for artists and designers, V66
   Carkacioglu A, 2002, IEEE IMAGE PROC, P405
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Dash JK, 2015, IET IMAGE PROCESS, V9, P836, DOI 10.1049/iet-ipr.2014.0299
   Dash JK, 2014, IEEE STUDENT TECHNOL, P264, DOI 10.1109/TechSym.2014.6808058
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   FARRELL KR, 1995, INT CONF ACOUST SPEE, P349, DOI 10.1109/ICASSP.1995.479545
   Felipe JC, 2003, COMP MED SY, P175
   Glatard T., 2004, P 6 INT WORKSHOP MUL, P135, DOI DOI 10.1145/1026711.1026734
   Guo GD, 2000, LECT NOTES COMPUT SC, V1842, P178
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Huenupán F, 2008, PATTERN RECOGN LETT, V29, P957, DOI 10.1016/j.patrec.2008.01.015
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lam L, 2000, LECT NOTES COMPUT SC, V1857, P77
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Mukhopadhyay S, 2013, PATTERN RECOGN LETT, V34, P646, DOI 10.1016/j.patrec.2013.01.001
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T., 2002, Proc. 2nd International Workshop on Texture Analysis and Synthesis, P99
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Qin C, 2012, INT J INNOV COMPUT I, V8, P6161
   Rashedi E, 2015, MULTIMED TOOLS APPL, V74, P3799, DOI 10.1007/s11042-013-1800-6
   Roli F, 2002, LECT NOTES COMPUT SC, V2364, P325
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   Santos LFD, 2015, IEEE INT SYM MULTIM, P357, DOI 10.1109/ISM.2015.115
   Sinha A, 2008, NEUROCOMPUTING, V71, P2650, DOI 10.1016/j.neucom.2007.06.016
   Traina AJM, 2011, BIOL MED PHYS BIOMED, P197, DOI 10.1007/978-3-542-15816-2_8
   Vasconcelos N, 2000, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2000.855822
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
   Xiang B, 2003, IEEE T SPEECH AUDI P, V11, P447, DOI 10.1109/TSA.2003.815822
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
NR 54
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 459
EP 483
DI 10.1007/s11042-016-4228-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400019
DA 2024-07-18
ER

PT J
AU Isaza, C
   Anaya, K
   de Paz, JZ
   Vasco-Leal, JF
   Hernandez-Rios, I
   Mosquera-Artamonov, JD
AF Isaza, Cesar
   Anaya, Karina
   Zavala de Paz, Jonny
   Vasco-Leal, Jose F.
   Hernandez-Rios, Ismael
   Mosquera-Artamonov, Jose D.
TI Image analysis and data mining techniques for classification of
   morphological and color features for seeds of the wild castor oil plant
   (<i>Ricinus communis L</i>.)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ricinus communis; Seed characterization; Image analysis; Classification
ID IDENTIFICATION; EXTRACTION; DIVERSITY; GENOTYPES
AB In this study, a castor seed (Ricinus communis L.) classification process was developed using a precise image analysis technique, and several data mining algorithms. Castor seed oil has an excellent demand in the pharmaceutical sector, and it has recently aroused the interest of the biodiesel production companies. However, there are few studies describing the physical characteristics of Ricinus communis; thus, any advance in this field contributes to the design of technology that may increase the production of this oil, up toindustrial levels. In fact, this work aims to contribute not only to understand the physical features of castor seed varieties, but also to unveil key information to develop better castor seed oil extraction machines. Additionally, a novel methodology to study accessions of castor seed gathered from several geographical locations is proposed. Particularly, an automatically accurate image analysis technique was implemented in order to extract color and morphological features from seeds. The data set of seeds was built considering fifty samples per accession. After that, several classification experiments were done using well known data mining algorithms in order to cluster all samples. Experimental results showed that it is possible to cluster studied seeds into ten similar classes with high accuracy (larger than 95 %). Moreover, image analysis and data mining techniques were efficient tools for the classification of seeds, and the color and morphological data gathered are really useful for the design of oil extraction equipment. In fact, the effectiveness in the correct classification instances was 100 %, with a computation time of 0.01 seconds.
C1 [Isaza, Cesar; Anaya, Karina; Zavala de Paz, Jonny] Univ Politecn Queretaro, El Rosario, Mexico.
   [Vasco-Leal, Jose F.] Univ Autonoma Queretaro, Santiago De Queretaro, Mexico.
   [Hernandez-Rios, Ismael] Colegio Postgrad SLP, Salinas De Hidalgo, Mexico.
   [Mosquera-Artamonov, Jose D.] Univ Autonoma Nuevo Leon, Fac Ingn Mecan & Elect, San Nicolas De Los Garza, Mexico.
C3 Universidad Autonoma de Queretaro; Universidad Autonoma de Nuevo Leon
RP Isaza, C (corresponding author), Univ Politecn Queretaro, El Rosario, Mexico.
EM cesar.isaza@upq.edu.mx; karina.anaya@upq.mx; jonny.zavala@upq.edu.mx;
   jose.vasco.leal@gmail.com; ismaelhr@colpos.mx; xoce15@ingenieros.com
RI Rivera, Karina Anaya/AAU-2929-2020; Isaza, Cesar/AGQ-5228-2022
OI Isaza, Cesar/0000-0002-0995-6231; Hernandez-Rios,
   Ismael/0000-0002-4284-7416; Vasco Leal, Jose
   Fernando/0000-0003-2503-1332; Mosquera-Artamonov, Jose
   Daniel/0000-0001-5419-6561
FU Mexican Council of Science and Technology (CONACYT, Mexico); CONACYT
FX Authors thank to the Mexican Council of Science and Technology (CONACYT,
   Mexico) for many years of support, and the Laboratory of Applied
   Technological Systems of the Telematic Engineering Department,
   Polytechnic University of Queretaro. Paticularly, J. D.
   Mosquera-Artamonov and J. F. Vasco-Leal thank CONACYT for their
   respective PhD. granted scholarships.
CR Amonsou E, 2011, LWT-FOOD SCI TECHNOL, V44, P42, DOI 10.1016/j.lwt.2010.06.021
   Ardebili MS, 2012, J AGR SCI TECH-IRAN, V14, P1219
   Armendáriz J, 2015, IND CROP PROD, V77, P484, DOI 10.1016/j.indcrop.2015.09.023
   Berman P, 2011, BIOMASS BIOENERG, V35, P2861, DOI 10.1016/j.biombioe.2011.03.024
   Bouguet J.-Y., 2004, CAMERA CALIBRATION T
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Campbell DN, 2014, IND CROP PROD, V53, P217, DOI 10.1016/j.indcrop.2013.12.035
   Carvalho Maria Laene Moreira de, 2010, Rev. bras. sementes, V32, P170, DOI 10.1590/S0101-31222010000100019
   Cervantes E, 2010, J PLANT PHYSL, V169, P1359
   Cervantes E, 2010, J PLANT PHYSIOL, V167, P408, DOI 10.1016/j.jplph.2009.09.013
   Chtioui Y, 1996, J SCI FOOD AGR, V71, P433, DOI [10.1002/(SICI)1097-0010(199608)71:4<433::AID-JSFA596>3.0.CO;2-B, 10.1002/(SICI)1097-0010(199608)71:4<433::AID-JSFA596>3.3.CO;2-2]
   Conceiçao MM, 2007, RENEW SUST ENERG REV, V11, P964, DOI 10.1016/j.rser.2005.10.001
   Dufaure C, 1999, J AM OIL CHEM SOC, V76, P1073, DOI 10.1007/s11746-999-0206-0
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Grillo O, 2010, SEED SCI TECHNOL, V38, P455, DOI 10.15258/sst.2010.38.2.19
   Gubitz GM, 1999, BIORESOURCE TECHNOL, V67, P73, DOI 10.1016/S0960-8524(99)00069-3
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hall M., 2008, FLAIRS Conference, P318
   Hernandez-Martinez MA, 1994, INTELL INF SYST, P357
   Hosmer D W., 2004, Applied Logistic Regression
   Isely D, 1947, INVESTIGATIONS SEED
   Jiang LX, 2016, INFORM SCIENCES, V329, P346, DOI 10.1016/j.ins.2015.09.037
   Kyari M, 2008, INT AGROPHYS
   Lati RN, 2013, AGRON J, V105, P191, DOI 10.2134/agronj2012.0305
   Liu S, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/290182
   Liu Zhao-yan, 2005, J Zhejiang Univ Sci B, V6, P1095, DOI 10.1631/jzus.2005.B1095
   Lorestani A. N., 2012, Quality Assurance and Safety of Crops & Foods, V4, pe29, DOI 10.1111/qas.12002
   Ma WY, 1996, MULTIMED TOOLS APPL, V2, P35
   Maïssa C, 2010, CONTACT LENS ANTERIO, V33, P76, DOI 10.1016/j.clae.2009.10.005
   Medina W, 2010, LWT-FOOD SCI TECHNOL, V43, P238, DOI 10.1016/j.lwt.2009.07.010
   Mitchell TM, 1997, MACHINE LEA IN PRESS
   Mohsenin N.N., 1970, PHYS PROPERTIES PLAN, V1
   Montes JM, 2013, IND CROP PROD, V51, P178, DOI 10.1016/j.indcrop.2013.08.046
   Ogunniyi DS, 2006, BIORESOURCE TECHNOL, V97, P1086, DOI 10.1016/j.biortech.2005.03.028
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Pecina-Quintero V, 2013, IND CROP PROD, V41, P134, DOI 10.1016/j.indcrop.2012.04.033
   Perdomo FA, 2013, BIOMASS BIOENERG, V48, P17, DOI 10.1016/j.biombioe.2012.10.020
   Perea-Flores MJ, 2011, IND CROP PROD, V34, P1057, DOI 10.1016/j.indcrop.2011.03.015
   Porebski A, 2014, MULTIMED TOOLS APPL, V70, P543, DOI 10.1007/s11042-013-1418-8
   Pourreza A, 2012, COMPUT ELECTRON AGR, V83, P102, DOI 10.1016/j.compag.2012.02.005
   Roscher R, 2014, COMPUT ELECTRON AGR, V100, P148, DOI 10.1016/j.compag.2013.11.008
   Sammut C., 2016, Encyclopedia of machine learning and data mining
   Sehgal P, 2010, FOOD CHEM TOXICOL, V48, P3171, DOI 10.1016/j.fct.2010.08.015
   Senger E, 2015, IND CROP PROD, V78, P9, DOI 10.1016/j.indcrop.2015.10.005
   Severino LS, 2015, IND CROP PROD, V75, P14, DOI 10.1016/j.indcrop.2015.06.043
   Severino LS, 2012, AGRON J, V104, P853, DOI 10.2134/agronj2011.0210
   Shahin M., 2003, CANADIAN BIOSYST ENG, V45, p3.5
   Sharma N., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P73
   Silva LOLA, 2013, COMPUT ELECTRON AGR, V97, P47, DOI 10.1016/j.compag.2013.07.001
   Wilcox D, 2003, IMAGE TOOL VERSION 3
   Zhao YH, 2008, ADV SPACE RES, V41, P1955, DOI 10.1016/j.asr.2007.07.020
NR 53
TC 11
Z9 16
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2593
EP 2610
DI 10.1007/s11042-017-4438-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400047
DA 2024-07-18
ER

PT J
AU Li, YH
   Lei, HP
   Lin, SJ
   Luo, GL
AF Li, Yuhua
   Lei, Haopeng
   Lin, Shujin
   Luo, Guoliang
TI A new sketch-based 3D model retrieval method by using composite features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Composite feature; Filter; Global feature; Local
   feature
ID SHAPE RETRIEVAL; CLASSIFICATION; HISTOGRAMS; SEARCH
AB With the rapid growth of available 3D models in various areas, effective methods to search 3D models are becoming increasingly important. In this paper, we propose a new method for sketch-based 3D model retrieval. Different from current methods that make use of either global or local features, the proposed method uses composite features combining global and local features extracted from representative 2D views of 3D models. The global features, shape strings, represent exterior boundary shape of the views and the local features, improved Pyramid of Histograms of Orientation Gradients (iPHOG), represent their interior details. Specifically, a global feature based filtering step is adopted to select more relevant candidate models to the query sketch and a local feature based process is used to refine chosen candidates. To evaluate the performance of the proposed method with that of other previous ones, we conducted a series of experiments on public standard 3D model databases. Experimental results are presented and indicate the effectiveness of the new approach for sketch-based 3D model retrieval.
C1 [Li, Yuhua] Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450001, Henan, Peoples R China.
   [Lei, Haopeng] Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
   [Lin, Shujin] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou 510006, Guangdong, Peoples R China.
   [Luo, Guoliang] Jiangxi Normal Univ, Sch Software, Nanchang 330022, Jiangxi, Peoples R China.
C3 Zhengzhou University of Light Industry; Jiangxi Normal University; Sun
   Yat Sen University; Jiangxi Normal University
RP Lei, HP (corresponding author), Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
EM leihaopeng@163.com
OI Li, Yuhua/0000-0002-1866-6607
FU National Natural Science Foundation of China [U1504608, 61602222,
   61572531]; Jiangxi Natural Science Foundation [20161BAB212043]
FX This research is jointly supported by the National Natural Science
   Foundation of China (U1504608, 61602222, 61572531), and the Jiangxi
   Natural Science Foundation (No. 20161BAB212043).
CR Amayeh G, 2005, LECT NOTES COMPUT SC, V3804, P462
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2013, P EUR WORKSH 3D OBJ, DOI DOI 10.2312/3DOR/3DOR13/049-056
   [Anonymous], 2003, 7 CENTR EUR SEM COMP
   [Anonymous], P ACM INT C MULT RET
   Barra V, 2014, VISUAL COMPUT, V30, P1247, DOI 10.1007/s00371-014-0926-5
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cole F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531334
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Furuya T, 2015, MULTIMED TOOLS APPL, V74, P10367, DOI 10.1007/s11042-014-2171-3
   Furuya T, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P274, DOI 10.1109/CW.2013.60
   Lavoué G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li B, 2013, 6 EUR WORKSH 3D OBJ, P89
   Li B., 2014, EUR WORKSH 3D OBJ RE, P121
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li B, 2013, MULTIMED TOOLS APPL, V65, P363, DOI 10.1007/s11042-012-1009-0
   Liu YJ, 2013, IEEE T AUTOM SCI ENG, V10, P783, DOI 10.1109/TASE.2012.2228481
   Löffler J, 2000, IEEE INFOR VIS, P82, DOI 10.1109/IV.2000.859741
   Nie W., 2015, ACM COMPUT SURV, V1, P1
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Petrou M. M., 2010, Image processing: the fundamentals
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Shao T, 2011, COMPUTER GRAPHICS FO, V30
   SHIH JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI DOI 10.1007/S11042-008-0256-6
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Veltkamp RC, 2001, ADV PTRN RECOGNIT, P87
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Zhao L., 2015, COMPUT MATH METHOD M, V2015, P1
NR 41
TC 16
Z9 19
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2921
EP 2944
DI 10.1007/s11042-017-4446-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400061
DA 2024-07-18
ER

PT J
AU Palacios-Luengas, L
   Delgado-Gutiérrez, G
   Díaz-Méndez, JA
   Vázquez-Medina, R
AF Palacios-Luengas, L.
   Delgado-Gutierrez, G.
   Diaz-Mendez, J. A.
   Vazquez-Medina, R.
TI Symmetric cryptosystem based on skew tent map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic skew tent map; Pseudorandom numbers generator; Hardware -
   software cryptography; Uniformly distributed sequences
ID IMAGE ENCRYPTION SCHEME; 2-DIMENSIONAL CHAOTIC MAP; CRYPTANALYSIS;
   ALGORITHM; DIFFUSION; STRATEGY; CIPHER; SYSTEM
AB This paper presents an efficient symmetric cryptosystem based on a non-scaled nor discretized skew tent map (STM); this system is implemented in a USB device interacting with a software module in a personal computer. The USB device uses a dedicated processor that contains a pseudorandom numbers generator (PRNG) to generate uniformly distributed chaotic sequences that satisfy the randomness tests defined in the NIST 800-22SP guide. The software module uses these sequences with substitution and rotation functions to produce cryptograms with confusion and diffusion properties, high level of security, high avalanche effect and high encryption and decryption speed. A variety of analysis and tests has been carried out to prove the security and the validity of the algorithm. Some of the evaluated characteristics are the statistical behavior, correlation, strength against differential attack, entropy, key space, key sensitivity, mutual information, encryption and decryption speed, and randomness test. Additionally, we analyze the structure of the proposed cryptosystem to find some security vulnerabilities; in this part, the analysis are based on known plaintext attack used in the literature on chaotic cryptosystems. In this way, the realized analysis shows that the performance of the proposed algorithm offers a high security level. Mutual information is calculated as evidence of this level of security.
C1 [Palacios-Luengas, L.] Tecnol Estudios Super Oriente Estado Mexico, La Paz 56400, Estado Mexico, Mexico.
   [Delgado-Gutierrez, G.; Vazquez-Medina, R.] Inst Politecn Nacl, ESIME Culhuacan, Mexico City 04430, DF, Mexico.
   [Diaz-Mendez, J. A.] Inst Nacl Astrofis, Opt & Elect, Puebla 72840, Mexico.
   [Vazquez-Medina, R.] Inst Politecn Nacl, CICATA Queretaro, Queretaro 76090, Mexico.
C3 Instituto Politecnico Nacional - Mexico; Instituto Nacional de
   Astrofisica, Optica y Electronica; Instituto Politecnico Nacional -
   Mexico
RP Vázquez-Medina, R (corresponding author), Inst Politecn Nacl, ESIME Culhuacan, Mexico City 04430, DF, Mexico.; Vázquez-Medina, R (corresponding author), Inst Politecn Nacl, CICATA Queretaro, Queretaro 76090, Mexico.
EM lpluengas@gmail.com; gdelgadog0902@alumno.ipn.mx; ajdiaz@inaoep.mx;
   ruvazquez345@gmail.com
RI VAZQUEZ-MEDINA, RUBEN/C-5081-2015
OI VAZQUEZ-MEDINA, RUBEN/0000-0002-6210-4097; Palacios-Luengas,
   Leonardo/0000-0002-5193-2014
FU CONACYT [CVU-372164];  [TecNM 393.15PD];  [SIP IPN 20160213]
FX The authors thank the financial support of the TecNM 393.15PD and SIP
   IPN 20160213 projects. G. Delgado-Gutierrez (CVU-372164) thanks for the
   scholarship provided by CONACYT. Technical and computational support
   from F. Rodriguez-Santos and J. L. Pichardo-Mendez (IPN) is gratefully
   acknowledged.
CR Al-Najjar HM, 2011, P COMPUTER SCI, P56
   Amin M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3360179
   [Anonymous], 2012, INT J COMPUT RES
   [Anonymous], 2011, IEEE INT C MICR ICM
   Barakat ML, 2014, IET IMAGE PROCESS, V8, P33, DOI 10.1049/iet-ipr.2012.0586
   Birkhoff GD, 1931, P NATL ACAD SCI USA, V17, P656, DOI 10.1073/pnas.17.12.656
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Chakraborty R, 2011, IJACSA EDITORIAL
   Chattopadhyay D., 2011, INDIAN J SCI TECHNOL, V4, P593, DOI 10.17485/ijst/2011/v4i5.27
   Chen HC, 2003, J SYST ARCHITECT, V49, P355, DOI 10.1016/S1383-7621(03)00087-0
   Devaney RL., 1989, An introduction to chaotic dynamical systems, V2
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fu C, 2014, ENTROPY-SWITZ, V16, P770, DOI 10.3390/e16020770
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Ghosal P, 2010, P 2010 INT C IND ENG
   He D, 2001, IEEE T CIRCUITS-I, V48, P900, DOI 10.1109/81.933333
   Janssens S, 2001, SIPS 2001: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: DESIGN AND IMPLEMENTATION, P209, DOI 10.1109/SIPS.2001.957349
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kartalopoulos S.V, 2008, 2008 NEW TECHNOLOGIE, p[1, 5]
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan MK, 2007, CHAOS SOLITON FRACT, V32, P1749, DOI 10.1016/j.chaos.2005.12.015
   Khan MK, 2011, TELECOMMUN SYST, V47, P227, DOI 10.1007/s11235-010-9314-2
   Lasota A., 2013, CHAOS FRACTALS NOISE, V97
   Li CQ, 2007, PHYS LETT A, V369, P23, DOI 10.1016/j.physleta.2007.04.023
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Liu SB, 2008, NCM 2008: 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 2, PROCEEDINGS, P191, DOI 10.1109/NCM.2008.11
   Ott E, 2002, CHAOS DYNAMICAL SYST
   Ou SC, 2006, MULTIMED TOOLS APPL, V28, P5, DOI 10.1007/s11042-006-5117-6
   Pande A., 2010, P INT C SIGN PROC CO, P1
   Pande A, 2013, TELECOMMUN SYST, V52, P551, DOI 10.1007/s11235-011-9460-1
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Ruisong Ye, 2013, International Journal of Computer Network and Information Security, V5, P21, DOI 10.5815/ijcnis.2013.07.03
   Rukhin A., 2010, NIST Special Publication, V800, P22
   Sakthidasan K., 2011, INT J NFO ED TECH, V1, P137, DOI DOI 10.7763/IJIET.2011.V1.23
   Scheicher K, 2016, J LOND MATH SOC
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Stoyanov B, 2015, ENTROPY-SWITZ, V17, P2117, DOI 10.3390/e17042117
   Sushko I, 2016, J DIFFER EQU APPL, V22, P1040, DOI 10.1080/10236198.2015.1113273
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Van Tilborg Henk C. A., 2014, Encyclopedia of cryptography and security
   Wei J, 2006, CHAOS SOLITON FRACT, V30, P1143, DOI 10.1016/j.chaos.2005.09.005
   Wen WY, 2016, MULTIMED TOOLS APPL, V75, P3553, DOI 10.1007/s11042-015-2464-1
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu XJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119660
   Yang DX, 2014, COMMUN NONLINEAR SCI, V19, P1229, DOI 10.1016/j.cnsns.2013.08.017
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Yavuz E, 2015, COMPUT ELECT ENG
   Ye R., 2013, J Emerg Trends Comput Inform Sci, V4, P800
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
NR 56
TC 12
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2739
EP 2770
DI 10.1007/s11042-017-4375-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400053
DA 2024-07-18
ER

PT J
AU Sarkis, M
   Concolato, C
   Dufourd, JC
AF Sarkis, Mira
   Concolato, Cyril
   Dufourd, Jean-Claude
TI A multi-screen refactoring system for video-centric web applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-screen applications; Web applications; Segmentation; Responsive
   web design; Application distribution; Synchronization
AB The ubiquity of web applications and the multiplication of personal devices are major factors for the increased demand for multi-screen applications. Multi-screen applications impose challenges on the application developer and designer especially if existing single-screen applications have to be transformed to the multi-screen environment. Challenges are related to the user interface division and distribution, layout adaptation, logic re-organization, runtime synchronization and adaptation to the underlying multi-screen platform. This paper faces these challenges and proposes an end-to-end refactoring system. The system allows the re-use of existing single-screen applications to automatically create multi-screen applications. The components of the multi-screen applications have their layout adapted to small and large devices and are ready to operate synchronously to provide a complementary usage experience. Our system is quantitatively evaluated on different sets of applications containing at least one video element and interactive content. Compared to a ground truth, our segmentation approach achieves an average recall of 78 %. Our layout refactoring approach reduces horizontal scrolling by 67 % on the tested applications. Finally, we evaluate the performance of the run-time behavior of one multi-screen application that is highly dynamic, in real physical environment. With a maximum total delay of 34 ms in a LAN, our solution is realistic.
C1 [Sarkis, Mira; Concolato, Cyril; Dufourd, Jean-Claude] Univ Paris Saclay, Telecom ParisTech, LTCI, F-75013 Paris, France.
C3 Universite Paris Saclay; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; Universite Paris Cite
RP Sarkis, M (corresponding author), Univ Paris Saclay, Telecom ParisTech, LTCI, F-75013 Paris, France.
EM gne.mirasarkis@gmail.com; cyril.concolato@telecom-paristech.fr;
   jean-claude.dufourd@telecom-paristech.fr
CR [Anonymous], 2011, MOZILLA SEMANTIC VID
   Bassbouss L, 2013, 2013 IEEE 37TH ANNUAL COMPUTER SOFTWARE AND APPLICATIONS CONFERENCE WORKSHOPS (COMPSACW), P528, DOI 10.1109/COMPSACW.2013.96
   Cai D., 2003, TECHNICAL REPORT
   Chen J., 2001, P WWW 2001 US, P587
   Cheng B, 2012, P WORKSH MULT APP MI
   Dufourd JC, 2013, 11 EUR INT TV C EURO
   Faraday P, 2000, SPRING COMP SCI, P155
   FRAIN B., 2012, Responsive Web Design with HTML5 and CSS3
   Ghiani G, 2013, J AMB INTEL HUM COMP, V6, P259
   Han R., 2000, P COMPUTER SUPPORTED, P221, DOI DOI 10.1145/358916.358993
   Hartmann Bjorn, 2013, P 2 ACM INT S PERV D, P43, DOI [10.1145/2491568.2491578, DOI 10.1145/2491568.2491578]
   Heinrich M, 2013, INT WORLD WID WEB C
   Kohlschtter C., 2008, PROCEEDING 17 ACM C, P1173, DOI DOI 10.1145/1458082.1458237
   Miller R., 1968, AFIPS Fall Joint Computer Conference, P267, DOI [10.1145/1476589.1476628, DOI 10.1145/1476589.1476628]
   Nebeling M, 2013, CROWDADAPT ENABLING, P23
   Pelli DG, 2009, COGN NEUROPSYCHOL, V26, P36, DOI 10.1080/13546800802550134
   Pnueli A., 2009, WEB PAGE LAYOUT VIA
   Sanoja Andres, 2014, 2014 International Conference on Multimedia Computing and Systems (ICMCS), P595, DOI 10.1109/ICMCS.2014.6911249
   Sarkis M, 2014, P 2014 ACM S DOC ENG, P139
   Sarkis M., 2015, P 2015 ACM S DOC ENG, P85
   Sun C., 2006, ACM Transactions on Computer-Human Interaction, V13, P531, DOI 10.1145/1188816.1188821
   Vadrevu S, 2005, LECT NOTES COMPUT SC, V3806, P107
   Weinstein R, 2013, MUTATION SUMMARY
   Yang JS, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2783
   Zorrilla M., 2015, BROADB MULT SYST BRO, P1
   Zorrilla M, 2015, PERS UBIQUIT COMPUT, V19, P803, DOI 10.1007/s00779-015-0864-x
NR 26
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1943
EP 1970
DI 10.1007/s11042-017-4357-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, WQ
   Luo, HZ
   Peng, JY
   Fan, JP
AF Zhao, Wanqing
   Luo, Hangzai
   Peng, Jinye
   Fan, Jianping
TI Locally linear spatial pyramid hash for large-scale image search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Large-scale image search; Semantic hashing; Locally linear coding;
   Spatial pyramid structure
AB Hash-based methods can achieve a fast similarity search by representing high-dimensional data with compact binary codes. However, the spatial structure in row images was always lost in most previous methods. In this paper, a novel Locally Linear Spatial Pyramid Hash(LLSPH) algorithm is developed for the task of fast image retrieval. Unlike the conventional approach, the spatial extent of image features is exploited in our method. The spatial pyramid structure is used both to construct binary hash codes and to increase the discriminability of the description. To generate interpretable binary codes, the proposed LLSPH method captures the spatial characteristics of the original SPM and generates a low-dimensional sparse representation using multi-dictionaries Locality-constrained Linear Coding(MD_LLC). LLSPH then converts the low-dimensional data into Hamming space by the TF-IDF binarization rule. Our experimental results show that our LLSPH method can outperform several state-of-the-art hashing algorithms on the Caltech256 and ImageNet-500 datasets.
C1 [Zhao, Wanqing; Luo, Hangzai; Peng, Jinye] Northwest Univ China, Sch Informat & Technol, Xian, Shaanxi, Peoples R China.
   [Fan, Jianping] UNC Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 Northwest University Xi'an; University of North Carolina; University of
   North Carolina Charlotte
RP Luo, HZ (corresponding author), Northwest Univ China, Sch Informat & Technol, Xian, Shaanxi, Peoples R China.
EM zhaowanqing@stumail.nwu.edu.cn; hzluo@nwu.edu.cn; pjy@nwu.edu.cn;
   jfan@nucc.edu
RI Zhao, Wanqing/ADL-9932-2022; Peng, Jin/HZH-6965-2023
OI Zhao, Wanqing/0000-0001-7622-0665
FU National Science Foundation of China [61272285]; National
   High-Technology Program of China (863 Program) [2014AA012301]; Program
   for Changjiang Scholars and Innovative Research Team in University
   [IRT13090]; Program of Shaanxi Province Innovative Research Team
   [2014KCT-17]
FX This research is partly supported by National Science Foundation of
   China under Grant 61272285, National High-Technology Program of China
   (863 Program, Grant No. 2014AA012301), Program for Changjiang Scholars
   and Innovative Research Team in University (No. IRT13090), and Program
   of Shaanxi Province Innovative Research Team (No. 2014KCT-17).
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2016, SURVEY LEARNING HASH
   [Anonymous], 2009, NEURIPS
   [Anonymous], IMAGE VISION COMPUTI
   [Anonymous], 2009, VISAPP
   [Anonymous], 2009, NEURIPS
   [Anonymous], CVPR
   Cherian A, 2012, IEEE IMAGE PROC, P2417, DOI 10.1109/ICIP.2012.6467385
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Chum O, 2012, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2012.6248039
   Drineas P, 2005, J MACH LEARN RES, V6, P2153
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Irie G, 2014, PROC CVPR IEEE, P2123, DOI 10.1109/CVPR.2014.272
   Jain P., 2008, COMPUTER VISION PATT
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Norouzi M., 2012, ADV NEURAL INFORM PR
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Turpin A., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P11, DOI 10.1145/1148170.1148176
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhou K, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1215, DOI 10.1145/2733373.2806320
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zou F, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/754562
NR 38
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 109
EP 123
DI 10.1007/s11042-016-4221-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400005
DA 2024-07-18
ER

PT J
AU Doshi, N
   Kumari, S
   Mishra, D
   Li, X
   Choo, KKR
   Sangaiah, AK
AF Doshi, Nishant
   Kumari, Saru
   Mishra, Dheerendra
   Li, Xiong
   Choo, Kim-Kwang Raymond
   Sangaiah, Arun Kumar
TI A password based authentication scheme for wireless multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Multimedia systems; Wireless mobile communications;
   Security threats
ID TICKET-BASED AUTHENTICATION; KEY AGREEMENT SCHEME; 2-FACTOR
   AUTHENTICATION; MUTUAL AUTHENTICATION; SENSOR NETWORKS; PROTOCOL;
   EFFICIENT; SECURITY; UNLINKABILITY; DESIGN
AB In this digital era, where Internet of Things (IoT) is increasing day by day, use of resource constrained devices is also increasing. Indeed, the features such as low cost, less maintenance, more adaptive to hostile environment, etc. make the wireless multimedia devices to be the best choice as the resource constrained devices. For the security, the end user device requires to establish the session key with the server before transferring the data. Mobile is one of the device having more and more usage as wireless multimedia device in recent years. In 2013, Li et al. proposed an efficient scheme for the wireless mobile communications and claimed it to be secure against various attacks. Recently, Shen et al. claimed that the scheme of Li et al. is still vulnerable to the privileged insider attack, the stolen verifier attack and finally proposed a scheme to withstand the mentioned and other attacks. However, in this paper we claim that the scheme of Shen et al. is still susceptible to the user anonymity, the session specific temporary information attack and the replay attack. In addition, Shen et al.'s scheme requires more time due to many operations. Further, we propose an efficient scheme that is secure against various known attacks and due to reduced time complexity our scheme is a preferred choice for the wireless mobile networks and hence for wireless multimedia systems.
C1 [Doshi, Nishant] Pandit Deendayal Petr Univ PDPU, Gandhinagar 382007, Gujarat, India.
   [Kumari, Saru] Ch Charan Singh Univ, Dept Math, Meerut 250005, Uttar Pradesh, India.
   [Mishra, Dheerendra] LNM Inst Informat Technol, Dept Math, Jaipur, Rajasthan, India.
   [Li, Xiong] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Pandit Deendayal Energy University; Chaudhary Charan Singh University;
   LNM Institute of Information Technology; Hunan University of Science &
   Technology; University of Texas System; University of Texas at San
   Antonio (UTSA); Vellore Institute of Technology (VIT); VIT Vellore
RP Kumari, S (corresponding author), Ch Charan Singh Univ, Dept Math, Meerut 250005, Uttar Pradesh, India.
EM nishant.doshi@sot.pdpu.ac.in; saryusiirohi@gmail.com;
   dheerendra.mishra@lnmiit.ac.in; lixiongzhq@163.com;
   raymond.choo@fulbrightmail.org; arunkumarsangaiah@gmail.com
RI Mishra, Dheerendra/C-4208-2017; Kumari, Saru/K-2038-2019; Doshi, Nishant
   P/E-9452-2015; Li, Xiong/K-7233-2012; Sangaiah, Arun Kumar/U-6785-2019;
   Choo, Kim-Kwang Raymond/A-3634-2009
OI Mishra, Dheerendra/0000-0001-8115-6397; Kumari,
   Saru/0000-0003-4929-5383; Doshi, Nishant P/0000-0003-3443-7561; Li,
   Xiong/0000-0001-6619-554X; Sangaiah, Arun Kumar/0000-0002-0229-2460;
   Choo, Kim-Kwang Raymond/0000-0001-9208-5336
FU Hunan Provincial Education Department [16B089]
FX This work is supported by the Scientific Research Fund of Hunan
   Provincial Education Department under Grant No. 16B089.
CR [Anonymous], 2004, AD HOC NETW, DOI DOI 10.1016/S1570-8705(03)00043-X
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Eisenbarth T, 2008, LECT NOTES COMPUT SC, V5157, P203, DOI 10.1007/978-3-540-85174-5_12
   Gu DQ, 2003, IEEE COMMUN MAG, V41, P120, DOI 10.1109/MCOM.2003.1204758
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   He DB, 2017, IEEE SYST J, V11, P2590, DOI 10.1109/JSYST.2016.2544805
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   He DB, 2015, INFORM SCIENCES, V321, P263, DOI 10.1016/j.ins.2015.02.010
   He DB, 2015, IEEE COMMUN MAG, V53, P71, DOI 10.1109/MCOM.2015.7010518
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   He DB, 2012, MATH COMPUT MODEL, V55, P1661, DOI 10.1016/j.mcm.2011.10.079
   Hwang MS, 2000, IEEE T CONSUM ELECTR, V46, P28, DOI 10.1109/30.826377
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   Jiang Q, 2016, J NETW COMPUT APPL, V76, P37, DOI 10.1016/j.jnca.2016.10.001
   Jiang Q, 2015, PEER PEER NETW APPL, V8, P1070, DOI 10.1007/s12083-014-0285-z
   Jiang Q, 2014, WIRELESS PERS COMMUN, V77, P1489, DOI 10.1007/s11277-013-1594-x
   Jiang Q, 2013, WIRELESS PERS COMMUN, V68, P1477, DOI 10.1007/s11277-012-0535-4
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Khan MK, 2007, COMPUT STAND INTER, V29, P82, DOI 10.1016/j.csi.2006.01.002
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kolbitz N., 1987, MATH COMPUT, V48, P203
   Kumari S, 2018, MULTIMED TOOLS APPL, V77, P2359, DOI 10.1007/s11042-017-4390-x
   Kumari S, 2017, FUTURE GENER COMP SY, V68, P320, DOI 10.1016/j.future.2016.10.004
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   Kumari S, 2015, AD HOC NETW, V27, P159, DOI 10.1016/j.adhoc.2014.11.018
   Kumari S, 2014, COMPUT ELECTR ENG, V40, P1997, DOI 10.1016/j.compeleceng.2014.05.007
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   LEE JK, 2001, IEE ELECT LETT, V38, P554
   Lee JH, 2013, INFORM SCIENCES, V230, P64, DOI 10.1016/j.ins.2012.11.006
   Li WM, 2012, COMPUT COMMUN, V35, P188, DOI 10.1016/j.comcom.2011.09.003
   Li XW, 2013, SECUR COMMUN NETW, V6, P711, DOI 10.1002/sec.605
   Li X, 2016, SECUR COMMUN NETW, V9, P2643, DOI 10.1002/sec.1214
   Li X, 2011, J NETW COMPUT APPL, V34, P73, DOI 10.1016/j.jnca.2010.09.003
   Li XL, 2013, INT J NETW MANAG, V23, P311, DOI 10.1002/nem.1827
   Lin CH, 2004, COMPUT STAND INTER, V27, P19, DOI 10.1016/j.csi.2004.03.003
   Lo JW, 2010, INT J INNOV COMPUT I, V6, P5249
   Lu RX, 2007, COMPUT STAND INTER, V29, P647, DOI 10.1016/j.csi.2007.04.002
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Niu JW, 2014, SECUR COMMUN NETW, V7, P1467, DOI 10.1002/sec.601
   Rhee HS, 2009, COMPUT STAND INTER, V31, P6, DOI 10.1016/j.csi.2007.11.017
   Shen H, 2016, J SUPERCOMPUT, V72, P3588, DOI 10.1007/s11227-015-1614-6
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   Sun HM, 2000, IEEE T CONSUM ELECTR, V46, P958, DOI 10.1109/30.920446
   Suzuki S, 1997, IEEE J SEL AREA COMM, V15, P1608, DOI 10.1109/49.634798
   Wang D, 2018, IEEE T DEPEND SECURE, V15, P708, DOI 10.1109/TDSC.2016.2605087
NR 47
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25893
EP 25918
DI 10.1007/s11042-017-4701-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500020
DA 2024-07-18
ER

PT J
AU Park, JK
   Park, HH
   Park, J
AF Park, Jeong-Keun
   Park, Ho-Hyun
   Park, Jaehwa
TI Distributed eigenfaces for massive face image data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eigenface; Face recognition; Parallel processing; Hadoop
ID PRINCIPAL COMPONENT ANALYSIS; RECOGNITION
AB The assumption that the number of training samples is less than the number of pixels in a face image is essential for conventional eigenface-based face recognition. But recently, it has become impractical for massive face image collections. A parallel processing method using distributed eigenfaces is presented. A massive face image set was divided into a bunch of small subsets that satisfied the assumption of conventional approaches. Eigenfaces were extracted from the subsets and stored in a cloud system. Face recognition was performed by parallel processing using the distributed eigenfaces in the cloud system. A face recognition system was implemented in the Hadoop system. Various experiments were performed to test the validity of the distributed eigenface-based approach. The experimental results show that, compared to conventional methods, the implemented distributed face recognition system worked well for large datasets without significant performance degradation.
C1 [Park, Jeong-Keun; Park, Jaehwa] Chung Ang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Park, Ho-Hyun] Chung Ang Univ, Dept Elect & Elect Engn, Seoul, South Korea.
C3 Chung Ang University; Chung Ang University
RP Park, J (corresponding author), Chung Ang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM pjk41018@gmail.com; hohyun@cau.ac.kr; jaehwa@cau.ac.kr
FU Chung-Ang University Excellent Student Scholarship; Basic Science
   Research Programs through the National Research Foundation of Korea(NRF)
   - Ministry of Education [NRF-2016R1D1A1B03936349,
   NRF-2016R1D1A1B03933895]
FX This research was supported by the Chung-Ang University Excellent
   Student Scholarship and by Basic Science Research Programs through the
   National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(NRF-2016R1D1A1B03936349 and NRF-2016R1D1A1B03933895).
CR Agarwal M, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P310, DOI 10.1109/ICSAP.2010.51
   [Anonymous], MESHES PARALLEL ALGO
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492
   Foster B, 2012, GPU BASED APPROXIMAT, P569
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Guodong Guo, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P196, DOI 10.1109/AFGR.2000.840634
   Halko N, 2011, SIAM J SCI COMPUT, V33, P2580, DOI 10.1137/100804139
   Hall P. M., 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P286
   Kawashima M, 2014, 2014 IEEE 5TH INTERNATIONAL CONFERENCE ON PHOTONICS (ICP), P1, DOI 10.1109/ICP.2014.7002292
   Seshadri G, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P44, DOI 10.1109/IADCC.2010.5423039
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Toygar Ö, 2004, PATTERN RECOGN LETT, V25, P1421, DOI 10.1016/j.patrec.2004.05.005
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Zhao HT, 2006, IEEE T SYST MAN CY B, V36, P873, DOI 10.1109/TSMCB.2006.870645
NR 18
TC 1
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25983
EP 26000
DI 10.1007/s11042-017-4823-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500023
DA 2024-07-18
ER

PT J
AU Qi, JW
   Huang, X
   Peng, YX
AF Qi, Jinwei
   Huang, Xin
   Peng, Yuxin
TI Cross-media similarity metric learning with unified deep networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Representation learning; Metric learning
ID REPRESENTATION
AB As a highlighting research topic in the multimedia area, cross-media retrieval aims to capture the complex correlations among multiple media types. Learning better shared representation and distance metric for multimedia data is important to boost the cross-media retrieval. Motivated by the strong ability of deep neural network in feature representation and comparison functions learning, we propose the Unified Network for Cross-media Similarity Metric (UNCSM) to associate cross-media shared representation learning with distance metric in a unified framework. First, we design a two-pathway deep network pretrained with contrastive loss, and employ double triplet similarity loss for fine-tuning to learn the shared representation for each media type by modeling the relative semantic similarity. Second, the metric network is designed for effectively calculating the cross-media similarity of the shared representation, by modeling the pairwise similar and dissimilar constraints. Compared to the existing methods which mostly ignore the dissimilar constraints and only use sample distance metric as Euclidean distance separately, our UNCSM approach unifies the representation learning and distance metric to preserve the relative similarity as well as embrace more complex similarity functions for further improving the cross-media retrieval accuracy. The experimental results show that our UNCSM approach outperforms 8 state-of-the-art methods on 4 widely-used cross-media datasets.
C1 [Qi, Jinwei; Huang, Xin; Peng, Yuxin] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Peng, Yuxin] Peking Univ, ICST, MIPL, Beijing, Peoples R China.
C3 Peking University; Peking University
RP Peng, YX (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM pengyuxin@pku.edu.cn
RI peng, yu/GXW-2071-2022; Peng, Yuxin/U-7376-2019
FU National Natural Science Foundation of China [61371128, 61532005];
   National Hi-Tech Research and Development Program of China (863 Program)
   [2014AA015102]
FX This work was supported by National Natural Science Foundation of China
   under Grants 61371128 and 61532005, and National Hi-Tech Research and
   Development Program of China (863 Program) under Grant 2014AA015102.
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], 2005, P INT C MUS INF RETR
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2006, IEEE T CIRC SYST VID, V16, P612, DOI 10.1109/TCSVT.2006.873157
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Salakhutdinov R, 1607, ADV NEURAL INFORM PR
   Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311
   Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49
   Srivastava Nitish, 2012, INT C MACH LEARN ICM
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yu J, 2008, IEEE T CIRC SYST VID, V18, P544, DOI 10.1109/TCSVT.2008.918763
   Zhai X., 2013, PROC 27 AAAI C ARTIF, P1198
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
NR 32
TC 3
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25109
EP 25127
DI 10.1007/s11042-017-4726-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Su, PH
AF Su, Pei-Hsuan
TI Case studies of applying electronic flexible material and technology to
   create the new media arts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual communications; New media arts; Innovative technology
AB The new media-arts revolution which combines art and design with innovative technology has made the shift of social and cultural texts into computer-mediated forms of production, distribution and communication. The invention of digital devices and contents has also revolutionized the quality of sound, image, and data, the way in which they are contemplated and served as the forms of art in relation to the convergence of multiple professions. Within this study, the social context and scenery are visualized and transcoded into design objects. The researcher delves further into the use of new electronic media-FleXpeaker (TM), which was invented by the Industrial Technology Research Institute, Taiwan. The researcher put specific images printed on both sides of the surface of FleXpeaker (TM), as well as with sound effects far-distance monitored by a Bluetooth receiver to call out one's imagination of the events, the time and the underlying environment encoded in the new media. Therefore, the devices viewed as design objects do help users to converge diverse elements in relation to artistic expression and cultural representation. As the result, this particular case of media convergence leads to a new hyper-real experience for the viewers and audience.
C1 [Su, Pei-Hsuan] Natl Taiwan Univ Arts, Dept Visual Commun Design, 59 Daquan Rd,Sect 1, New Taipei 22058, Taiwan.
C3 National Taiwan University of Arts
RP Su, PH (corresponding author), Natl Taiwan Univ Arts, Dept Visual Commun Design, 59 Daquan Rd,Sect 1, New Taipei 22058, Taiwan.
EM sherriesutaipei@gmail.com
FU Sun Yun-Suan Memorial Museum
FX The support of the 2014-2015 ITRI's curating team working with the Sun
   Yun-Suan Memorial Museum is gratefully acknowledged, in addition to all
   the assistances derived from the Department of Visual Communication
   Design, National Taiwan University of Arts.
CR Baudrillard Jean., 1981, Simulacra and Simulation
   Fischer G., 1994, User-Centred Requirements for Software Engineering Environment. Proceedings of the NATO Advanced Research Workshop, P297
   Gischer G., 2004, END USER DEVELOPMENT, P427
   Hall Stuart, 1997, REPRESENTATION CULTU, DOI DOI 10.1086/228311
   ITRI, 2016, FLEX EL PIL LAB
   ITRI, 2016, INN APPL SMART LIV S
   ITRI, 2012, 2012 ITRI FOR NEW TE
   Kelly Kevin, 2012, K KELL I WAS AM ITRI
   Manovich Lev, 2001, The Language of new media
   Plafke J., 2013, MOVE FLEXIBLE SCREEN
   Taipei Expo Foundation, 2016, TAIP EXP PARK PAV DR
   Tsao H. Y., 2007, HIST DIGITAL ARTS DE
   Yang EL, 1989, COMMON WEALTH MAGAZI
   Yang J, 2012, CARRY FLEXIBLE SPEAK
   Yeh JC, 2011, COMPOTECH CHINA, P39
NR 15
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25529
EP 25543
DI 10.1007/s11042-017-5155-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300052
DA 2024-07-18
ER

PT J
AU Chen, XY
   Lan, XG
   Liang, GQ
   Liu, JY
   Zheng, NN
AF Chen, Xingyu
   Lan, Xuguang
   Liang, Guoqiang
   Liu, Jianyi
   Zheng, Nanning
TI Pose-and-illumination-invariant face representation via a triplet-loss
   trained deep reconstruction model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose-and-illumination-invariant feature; Face reconstruction neural
   network; Triplet-loss training
AB Face recognition under variable pose and illumination is a challenging problem in computer vision tasks. In this paper, we solve this problem by proposing a new residual based deep face reconstruction neural network to extract discriminative pose-and-illumination-invariant (PII) features. Our deep model can change arbitrary pose and illumination face images to the frontal view with standard illumination. We propose a new triplet-loss training method instead of Euclidean loss to optimize our model, which has two advantages: a) The training triplets can be easily augmented by freely choosing combinations of labeled face images, in this way, overfitting can be avoided; b) The triplet-loss training makes the PII features more discriminative even when training samples have similar appearance. By using our PII features, we achieve 83.8% average recognition accuracy on MultiPIE face dataset which is competitive to the state-of-the-art face recognition methods.
C1 [Chen, Xingyu; Lan, Xuguang; Liang, Guoqiang; Liu, Jianyi; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Chen, XY; Lan, XG (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Shaanxi, Peoples R China.
EM chenxingyu_1990@163.com; xglan@mail.xjtu.edu.cn
RI Lan, Xuguang/N-8814-2019; Liang, Guoqiang/JUF-0287-2023
OI Lan, Xuguang/0000-0002-3422-944X; 
FU National Key Research and Development Program of China [2016YFB1000903];
   NSFC [61573268]
FX This work was supported in part by the National Key Research and
   Development Program of China under grant No.2016YFB1000903, and NSFC
   No.61573268.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2014, INT C MULT
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], 2015, PROC INT C MACH LEAR
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2014, C COMP VIS PATT REC
   [Anonymous], 2014, EUR C COMP VIS ECCV
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], INT C AUT FAC GEST R
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2015, BRIT MACHINE VISION
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, EUR C COMP VIS ECCV
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Simonyan K, 2015, IEEE INT C ICLR
   Simonyan K., 2014, 14091556 ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
NR 37
TC 10
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22043
EP 22058
DI 10.1007/s11042-017-4782-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200010
DA 2024-07-18
ER

PT J
AU Hagag, A
   Fan, XP
   Abd El-Samie, FE
AF Hagag, Ahmed
   Fan, Xiaopeng
   Abd El-Samie, Fathi E.
TI Hyperspectral image coding and transmission scheme based on wavelet
   transform and distributed source coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint source-channel code (JSCC); Wireless communication; Hyperspectral
   band ordering; AVIRIS; Wavelet transforms; DSC; LineCast; SoftCast
ID SCALAR DEADZONE QUANTIZATION; LOSSLESS COMPRESSION; PARALLEL FRAMEWORK;
   HEVC; SATELLITE; BROADCAST; DECISION; LOSSY
AB This paper presents a novel scheme for satellite hyperspectral images broadcasting over wireless channels. First, a simple pre-processing is performed. Then, a new hyperspectral band ordering algorithm that improves the compression performance is implemented. The ordered image data is also normalized. The discrete wavelet transform with three-level decomposition is used to divide each hyperspectral image band into ten wavelet sub-bands; nine of them are the details and the last LL-LL-LL is an approximation version of the band. Coset coding based on distributed source coding (DSC) is used for the LL-LL-LL sub-band to achieve high compression efficiency and low encoding complexity. Then, without syndrome coding, the transmission power is allocated directly to the band details and coset values according to their distributions and magnitudes without forward error correction (FEC). Finally, these data are transformed by the Hadamard matrix and transmitted over a dense constellation. Satellite hyperspectral images from an Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) satellite are used for the validation of the proposed scheme. Experimental results demonstrate that the proposed scheme improves the average image quality by 6.91, 3.00 and 7.68 dB over LineCast, SoftCast-3D, and Softcast-2D, respectively. It also achieves up to a 5.63 dB gain over JPEG2000 with FEC.
C1 [Hagag, Ahmed; Fan, Xiaopeng] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Hagag, Ahmed] Egyptian E Learning Univ, Fac Informat Technol, Dept Informat Technol, Giza 12611, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Hagag, A (corresponding author), Egyptian E Learning Univ, Fac Informat Technol, Dept Informat Technol, Giza 12611, Egypt.
EM ahagag88@gmail.com; fxp@hit.edu.cn; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Hagag, Ahmed/0000-0003-2631-1846
FU National Science Foundation of China (NSFC) [61472101, 61631017,
   61390513]; Major State Basic Research Development Program of China (973
   Program) [2015CB351804]; National High Technology Research and
   Development Program of China (863 Program) [2015AA015903]
FX This work was supported in part by the National Science Foundation of
   China (NSFC) under grants 61472101, 61631017 and 61390513, the Major
   State Basic Research Development Program of China (973 Program
   2015CB351804), and the National High Technology Research and Development
   Program of China (863 Program 2015AA015903). The authors would like to
   thank Prof. Dr. Michel Barret and Dr. Ibrahim Omara for their support in
   this work and also the anonymous reviewers for their valuable comments
   that greatly improved this paper.
CR Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Auli-Llinas F., 2014, BOI CODEC
   Aulí-Llinàs F, 2013, IEEE T IMAGE PROCESS, V22, P4678, DOI 10.1109/TIP.2013.2277801
   Barret M, 2011, IEEE T GEOSCI REMOTE, V49, P1557, DOI 10.1109/TGRS.2010.2083671
   Bartrina-Rapesta J, 2015, IEEE GEOSCI REMOTE S, V12, P1893, DOI 10.1109/LGRS.2015.2436438
   Beck RA, 2005, COMPUT NETW, V47, P765, DOI 10.1016/j.comnet.2004.08.010
   Bita IPA, 2010, SIGNAL PROCESS, V90, P759, DOI 10.1016/j.sigpro.2009.09.011
   Blanes I, 2014, IEEE GEOSC REM SEN M, V2, P8, DOI 10.1109/MGRS.2014.2352465
   Carvajal G, 2008, IEEE GEOSCI REMOTE S, V5, P593, DOI 10.1109/LGRS.2008.2000651
   Crowley MD, 2006, INT GEOSCI REMOTE SE, P907, DOI 10.1109/IGARSS.2006.233
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Evans B, 2005, IEEE WIREL COMMUN, V12, P72, DOI 10.1109/MWC.2005.1522108
   Fan XP, 2013, IEEE T CIRC SYST VID, V23, P1040, DOI 10.1109/TCSVT.2013.2249019
   Fan XP, 2012, IEEE DATA COMPR CONF, P199, DOI 10.1109/DCC.2012.27
   Fan Xiaopeng, 2011, P INT C MOB UB MULT, P226
   Ghandi MM, 2006, J VIS COMMUN IMAGE R, V17, P451, DOI 10.1016/j.jvcir.2005.05.005
   Hagag A, 2015, SIGNAL IMAGE VIDEO P, V9, P769, DOI 10.1007/s11760-013-0516-4
   Hagag A, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073511
   Herwitz SR, 2004, COMPUT ELECTRON AGR, V44, P49, DOI 10.1016/j.compag.2004.02.006
   Jakubczak S., 2011, PROC MOBICOM, P289
   Jakubczak S, 2010, ACM SIGCOMM COMP COM, V40, P449, DOI 10.1145/1851275.1851257
   Johnson M, 2004, COMPUT NETW, V46, P423, DOI 10.1016/j.comnet.2004.06.015
   Kratochvil T., 2009, LECT NOTES ELECT ENG, P333
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Liveris AD, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P53
   Penna B, 2006, IEEE GEOSCI REMOTE S, V3, P125, DOI 10.1109/LGRS.2005.859942
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   RAMCHANDRAN K, 1993, IEEE J SEL AREA COMM, V11, P6, DOI 10.1109/49.210540
   Reznic Z, 2011, uS Patent App, Patent No. [13/137,263, 13137263]
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shannon C. E., 1961, P 4 BERK S MATH STAT, V1, P611
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tate SR, 1997, IEEE T COMPUT, V46, P477, DOI 10.1109/12.588062
   Taubman D., 2012, JPEG2000 IMAGE COMPR, V642
   Toivanen P, 2005, IEEE GEOSCI REMOTE S, V2, P50, DOI 10.1109/LGRS.2004.838410
   Valsesia D, 2014, IEEE T GEOSCI REMOTE, V52, P6341, DOI 10.1109/TGRS.2013.2296329
   Wu F, 2014, IEEE T IMAGE PROCESS, V23, P1015, DOI 10.1109/TIP.2014.2298972
   Wu S, 2016, The Metallogenic Mechanism of Distal Contact Pb-Zn-ag Vines in Shizhuyuan Ore District, Hunan Province, China, V2016, P1
   Xu Q, 2007, IEEE J SEL AREA COMM, V25, P851, DOI 10.1109/JSAC.2007.070520
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 44
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23757
EP 23776
DI 10.1007/s11042-016-4158-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700030
DA 2024-07-18
ER

PT J
AU Lutovac, B
   Dakovic, M
   Stankovic, S
   Orovic, I
AF Lutovac, Budimir
   Dakovic, Milos
   Stankovic, Srdjan
   Orovic, Irena
TI An algorithm for robust image watermarking based on the DCT and Zernike
   moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Region clasification; Zernike moments; 2D DCT
   transform; Image quality
ID COMPUTATION; DOMAIN
AB An image watermarking scheme in the 2D DCT domain is proposed by exploring the advantages of using Zernike moments. Zernike transform has been used in image processing applications such as image recognition, authentication, protection, etc. Here, we propose to use the Zernike moments of the DCT transform to provide an efficient watermarking method. Particularly, the novelty of the proposed approach relies on the method for selection of features that will enable both preserving the image quality and robustness to attacks. Also, a criterion for selection of image blocks suitable for watermarking is given. It is based on the a"" (1)-norm of Zernike moments. The efficiency of the proposed watermarking algorithm is proved on several examples considering different types of attacks (compression, noise, filtering, geometrical attacks).
C1 [Lutovac, Budimir; Dakovic, Milos; Stankovic, Srdjan; Orovic, Irena] Univ Montenegro, Fac Elect Engn, Dz Vasingtona Bb, Podgorica 81000, Montenegro.
C3 University of Montenegro
RP Lutovac, B (corresponding author), Univ Montenegro, Fac Elect Engn, Dz Vasingtona Bb, Podgorica 81000, Montenegro.
EM budo@ac.me; milos@ac.me; srdjan@ac.me; irenao@ac.me
RI Stankovic, Srdjan/AAH-2804-2019; Lutovac, Budimir/AAH-5293-2019;
   Dakovic, Milos/C-1319-2010; Orovic, Irena/U-9175-2018
OI Stankovic, Srdjan/0000-0002-4795-494X; Lutovac,
   Budimir/0000-0003-4602-9733; Dakovic, Milos/0000-0002-3317-3632; Orovic,
   Irena/0000-0002-1752-9053
FU Montenegrin Ministry of Science; World Bank loan: CS-ICT "New ICT
   Compressive sensing based trends applied to: multimedia, biomedicine and
   communications"
FX This work is supported by the Montenegrin Ministry of Science, project
   grant funded by the World Bank loan: CS-ICT "New ICT Compressive sensing
   based trends applied to: multimedia, biomedicine and communications".
CR Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Chen Q., 2005, CAN C EL COMP ENG, P1340
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Foo SW, 2009, WORLD ACAD SCI ENG T, V3, P1968
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hwang SK, 2006, PATTERN RECOGN, V39, P2065, DOI 10.1016/j.patcog.2006.03.004
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kotoulas L, 2007, IEEE T IMAGE PROCESS, V16, P2028, DOI 10.1109/TIP.2007.899621
   Liu J., 2010, J COMPUTATIONAL INFO, V6, P1887
   Martin V, 2005, LECT NOTES COMPUT SC, V3727, P91
   MUHAREMAGIC E, 2006, MULTIMEDIA WATERMARK, P91
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Orovic I, 2014, MULTIMED TOOLS APPL, V70, P1503, DOI 10.1007/s11042-012-1182-1
   Papakostas GA, 2006, IMAGE VISION COMPUT, V24, P960, DOI 10.1016/j.imavis.2006.02.015
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Singhal N, 2009, J VIS COMMUN IMAGE R, V20, P408, DOI 10.1016/j.jvcir.2009.04.002
   Stankovic S., 2015, MULTIMEDIA SIGNALS S
   Stankovic S, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013014
   Stankovic S, 2010, MULTIMED TOOLS APPL, V49, P529, DOI 10.1007/s11042-009-0446-x
   Tahmasbi A, 2011, COMPUT BIOL MED, V41, P726, DOI 10.1016/j.compbiomed.2011.06.009
   Tsolis DK, 2010, MULTIMED TOOLS APPL, V47, P581, DOI 10.1007/s11042-009-0338-0
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 24
TC 18
Z9 18
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23333
EP 23352
DI 10.1007/s11042-016-4127-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700010
DA 2024-07-18
ER

PT J
AU Mühling, M
   Korfhage, N
   Müller, E
   Otto, C
   Springstein, M
   Langelage, T
   Veith, U
   Ewerth, R
   Freisleben, B
AF Muehling, Markus
   Korfhage, Nikolaus
   Mueller, Eric
   Otto, Christian
   Springstein, Matthias
   Langelage, Thomas
   Veith, Uli
   Ewerth, Ralph
   Freisleben, Bernd
TI Deep learning for content-based video retrieval in film and television
   production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media production; Deep learning; Image and video analysis; Visual
   concept detection; Similarity search; Face recognition
AB While digitization has changed the workflow of professional media production, the content-based labeling of image sequences and video footage, necessary for all subsequent stages of film and television production, archival or marketing is typically still performed manually and thus quite time-consuming. In this paper, we present deep learning approaches to support professional media production. In particular, novel algorithms for visual concept detection, similarity search, face detection, face recognition and face clustering are combined in a multimedia tool for effective video inspection and retrieval. The analysis algorithms for concept detection and similarity search are combined in a multi-task learning approach to share network weights, saving almost half of the computation time. Furthermore, a new visual concept lexicon tailored to fast video retrieval for media production and novel visualization components are introduced. Experimental results show the quality of the proposed approaches. For example, concept detection achieves a mean average precision of approximately 90% on the top-100 video shots, and face recognition clearly outperforms the baseline on the public Movie Trailers Face Dataset.
C1 [Muehling, Markus; Korfhage, Nikolaus; Mueller, Eric; Otto, Christian; Springstein, Matthias; Langelage, Thomas; Veith, Uli; Ewerth, Ralph; Freisleben, Bernd] Univ Marburg, Dept Math & Comp Sci, Hans Meerwein Str 6, D-35032 Marburg, Germany.
C3 Philipps University Marburg
RP Mühling, M (corresponding author), Univ Marburg, Dept Math & Comp Sci, Hans Meerwein Str 6, D-35032 Marburg, Germany.
EM muehling@informatik.uni-marburg.de; korfhage@informatik.uni-marburg.de;
   eric.mueller@tib.eu; christian.otto@tib.eu; matthias.springstein@tib.eu;
   thomas.langelage@taglichtmedia.de; uli.veith@taglichtmedia.de;
   ralph.ewerth@tib.eu; freisleb@informatik.uni-marburg.de
OI Otto, Christian/0000-0003-0226-3608; Muller-Budack,
   Eric/0000-0002-6802-1241; Freisleben, Bernd/0000-0002-7205-8389; Ewerth,
   Ralph/0000-0003-0918-6297; Korfhage, Nikolaus/0000-0002-0673-1379
FU German Federal Ministry for Economic Affairs and Energy (BMWi) in the
   ZIM Programme
FX This work is financially supported by the German Federal Ministry for
   Economic Affairs and Energy (BMWi) in the ZIM Programme.
CR [Anonymous], 23 INT C PATT REC IC
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], CNN SINGLE LABEL MUL
   [Anonymous], IGI GLOBAL
   [Anonymous], ARXIV160307057
   [Anonymous], P INT C ADV INT SYST
   [Anonymous], ARXIV160400989
   [Anonymous], FDDB BENCHMARK FACE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], UMCS2014003 U MASS
   [Anonymous], ARXIV160603473
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, MULTIMEDIA MODELING
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2013, ARXIV13124894
   [Anonymous], 2014, LEARNING FACE REPRES
   Blanco G, 2016, IEEE INT SYM MULTIM, P20, DOI [10.1109/ISM.2016.0014, 10.1109/ISM.2016.36]
   Breuel TM, 2013, PROC INT CONF DOC, P683, DOI 10.1109/ICDAR.2013.140
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Ewerth R., 2004, Proceedings of 11th International Workshop on Systems, Signals and Image Processing. Ambient Multimedia, P227
   Ewerth R, 2009, LECT NOTES COMPUT SC, V5807, P253
   Ewerth R, 2007, INT J SEMANT COMPUT, V1, P185, DOI 10.1142/S1793351X0700010X
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo Y, 2016, INT J AEROSPACE ENG, V2016, DOI 10.1155/2016/2942686
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Krizhevsky A., 2011, P ESANN, VVolume 1, P2
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Kumar V, 2014, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2014.61
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269, P543
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ortiz EG, 2013, PROC CVPR IEEE, P3531, DOI 10.1109/CVPR.2013.453
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Simonyan K., 2014, 14091556 ARXIV
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sun Y., 2015, Journal of Computational and Graphical Statistics
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou BL, 2014, ADV NEUR IN, V27
NR 52
TC 20
Z9 20
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22169
EP 22194
DI 10.1007/s11042-017-4962-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200016
DA 2024-07-18
ER

PT J
AU Seddati, O
   Dupont, S
   Mahmoudi, S
AF Seddati, Omar
   Dupont, Stephane
   Mahmoudi, Said
TI DeepSketch 3 Analyzing deep neural networks features for better sketch
   recognition and sketch-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch recognition; Sketch retrieval; Sketch-based image retrieval
AB Freehand sketches are a simple and powerful tool for communication. They are easily recognized across cultures and suitable for various applications. In this paper, we use deep convolutional neural networks (ConvNets), state-of-the-art in the field of sketch recognition, to address several applications of automatic sketch processing: complete and partial sketch recognition, sketch retrieval using query-by-example (QbE), and sketch-based image retrieval (SBIR) i.e the retrieval of images using a QbE paradigm but where the query is a sketch. We first focus on improving sketch recognition. For this purpose we compare different ConvNet architectures, training paradigms and data fusion schemes. This enabled us to outperform previous state-of-the-art in two large scale benchmarks for sketch classification. We achieved a mean average accuracy of 79.18% for the TU-Berlin sketch benchmark and 93.02% for the sketchy database. For partial sketch recognition, we were able to produce a system that achieves a mean average accuracy of 52.58% with only 40% of the strokes. We then conduct a comprehensive study of ConvNets features to enhance sketch retrieval and image retrieval, using a kNN similarity search paradigm in the ConvNet feature space. For the sketch retrieval tasks, we compare the performance obtained with features extracted from various depths (ConvNet layers) using one of the best performing model from the previous work. For the sketch-based image retrieval (SBIR), a sketch query is used to retrieve images of objects that belong to the same category, or even with a shape and pose close to the sketch query. The main challenge in the field of SBIR is to obtain efficient cross-domain features for sketch-image similarity measure. For this, besides comparing features extracted from different depth, we additionally compare different training approaches (some novel) for the ConvNets applied to sketches and images. Eventually, our best SBIR system achieves state-of-the-art results on the sketchy database (close to 40% recall at k = 1).
C1 [Seddati, Omar; Dupont, Stephane] Bd Dolez 31, B-7000 Mons, Belgium.
   [Mahmoudi, Said] Rue Houdain 9, B-7000 Mons, Belgium.
RP Seddati, O (corresponding author), Bd Dolez 31, B-7000 Mons, Belgium.
EM omar.seddati@umons.ac.be
RI Mahmoudi, Saïd/AAC-3834-2020
OI Mahmoudi, Saïd/0000-0001-8272-9425; seddati, omar/0000-0002-0573-8480;
   Dupont, Stephane/0000-0003-3674-6747
FU Chist-Era project IMOTION; Belgian Fonds de la Recherche Scientique
   (FNRS) [R.50.02.14.F]
FX This work was partly supported by the Chist-Era project IMOTION with
   contribution from the Belgian Fonds de la Recherche Scientique (FNRS),
   contract no. R.50.02.14.F.
CR [Anonymous], 2015, ARXIV150200254
   [Anonymous], 2011, P 16 INT C INT US IN
   Bozas K, 2012, LECT NOTES COMPUT SC, V7431, P210, DOI 10.1007/978-3-642-33179-4_21
   Bui T., 2016, ARXIV PREPRINT ARXIV
   Cao XC, 2013, IEEE I CONF COMP VIS, P313, DOI 10.1109/ICCV.2013.46
   Collobert R, 2011, BIGLEARN NIPS WORKSH, P1
   Das Bhattacharjee S, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1306, DOI 10.1145/2964284.2964317
   Deore A., 2016, ADV SKETCH BASED IMA
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2010, COMPUT GRAPH-UK, V34, P482, DOI 10.1016/j.cag.2010.07.002
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jin C, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P267, DOI 10.1145/2671188.2749302
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   LaViola J.J., 2007, ACM SIGGRAPH 2007 courses, P46
   Li Q, 2016, MULTIMED TOOLS APPL, V75, P2419, DOI 10.1007/s11042-015-2645-y
   Li Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.35
   Niu JW, 2017, LECT NOTES COMPUT SC, V10133, P257, DOI 10.1007/978-3-319-51814-5_22
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Seddati O, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P739, DOI 10.1145/2964284.2973828
   Seddati Omar, 2015, CONT BAS MULT IND CB, P1, DOI DOI 10.1109/CBMI.2015.7153606
   Seddati Omar, 2016, CBMI 2016, P1, DOI DOI 10.1109/CBMI.2016.7500261
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sutherland I.E., 1963, P MAY 21 23 1963 SPR, P329, DOI DOI 10.1145/1461551.1461591
   Szanto B., 2011, 2011 IEEE 9th International Symposium on Applied Machine Intelligence and Informatics (SAMI), P183, DOI 10.1109/SAMI.2011.5738872
   YANG Yongxin, 2015, ARXIV150107873
   Yesilbek Kemal Tugrul, 2015, P WORKSH SKETCH BAS, P117
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Yuxin Wang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1368, DOI 10.1109/CISP.2011.6100457
NR 31
TC 14
Z9 14
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22333
EP 22359
DI 10.1007/s11042-017-4799-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200025
DA 2024-07-18
ER

PT J
AU Stergiou, C
   Psannis, KE
AF Stergiou, Christos
   Psannis, Kostas E.
TI Efficient and secure BIG data delivery in Cloud Computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Algorithm; Big data; Cloud computing; Delivery; Security; Privacy,
   quality of services; Quality of experience
ID IMPACT
AB Big Data (BD) is a new technology which rapidly growing in the telecommunications sectors, especially in the contemporary field of wireless telecommunications. Another technology that grows rapidly in the field of wireless telecommunications is Cloud Computing (CC). CC concerns an infrastructure where data storage and processing take place outside of the user's device. Both of them face security and privacy issues in their function. In order to improve them and to optimize their privacy and security issues conducted the present survey. In this paper, we survey BD and CC technology and their basic characteristics, with a focus on the security and privacy issues of both technologies. Specifically, we try to combine the functionality of the two technologies (i.e BD and CC) with the aim to examine the frequent features, and also to discover the benefits related in security issues of their integration. Concluding, we present a new method of an algorithm that can be used for the purpose of improving Cloud Computing's security through the use of algorithms that can provide more privacy in the data related to Big Data technology. At the end, there is a survey about the challenges of the integration of BD and CC related to their security level.
C1 [Stergiou, Christos; Psannis, Kostas E.] Univ Macedonia, Sch Informat Sci, Dept Appl Informat, GR-54636 Thessaloniki, Greece.
C3 University of Macedonia
RP Psannis, KE (corresponding author), Univ Macedonia, Sch Informat Sci, Dept Appl Informat, GR-54636 Thessaloniki, Greece.
EM kpsannis@uom.edu.gr
RI Psannis, Konstantinos/C-8760-2017; Stergiou, Christos/S-7913-2017;
   Psannis, Kostas/AHA-8462-2022
OI Psannis, Konstantinos/0000-0003-0020-6394; Stergiou,
   Christos/0000-0002-7713-3667; Psannis, Kostas/0000-0003-0020-6394
CR Abdul Elminaam D. S., 2009, COMMUNICATIONS IBIMA, V8
   Ali M, 2015, INFORM SCIENCES, V305, P357, DOI 10.1016/j.ins.2015.01.025
   Andersson S, 2013, STUDY ADVANTAGES DI
   [Anonymous], 2011, BIG DATA ANAL
   [Anonymous], 2014, BLOG FOLL WHAT HAPP
   [Anonymous], IDC ANAL FUTURE
   [Anonymous], 2013, INT J SCI ENG RES
   [Anonymous], SECURE INTEGRATION I
   [Anonymous], SCI WORLD J
   [Anonymous], IJCSMS INT J COMPUT
   [Anonymous], 2011, IEEE COMSOC MULTIMED
   [Anonymous], CLOUD COMPUTING IS I
   [Anonymous], 2010, IEEE NETWORK, V24, P19
   [Anonymous], 2009, NIST definition of cloud computing
   Badve OP, 2016, HDB RES MODERN CRYPT
   Batalla JM, 2016, IEEE WIREL COMMUN, V23, P76, DOI 10.1109/MWC.2016.7721745
   Batalla JM, 2016, IEEE J SEL AREA COMM, V34, P2154, DOI 10.1109/JSAC.2016.2577360
   Bhavani S, 2015, INT J EMERG RES MANA, V5, P331
   Cloud News Daily, 2015, CLOUD NEWS DAIL 1212
   Dinh HT, 2013, WIREL COMMUN MOB COM, V13, P1587, DOI 10.1002/wcm.1203
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Fremdt S, 2013, P ANN HICSS, P1025, DOI 10.1109/HICSS.2013.182
   Garg SK, 2013, FUTURE GENER COMP SY, V29, P1012, DOI 10.1016/j.future.2012.06.006
   Goswami K, 2016, INFORM SCIENCES, V364, P72, DOI 10.1016/j.ins.2016.05.018
   Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970
   Iqbal R., 2016, INT J INFORM MANAGE, P1
   Kaur R., 2014, International Journal of Application or Innovation in Engineering and Management, V3, P171
   Kryftis Y, 2016, IEEE WIREL COMMUN, V23, P14, DOI 10.1109/MWC.2016.7422401
   Oludele A., 2016, INT J COMPUTER APPL, V133, P14, DOI [DOI 10.5120/ijca2016907861, 10.5120/ijca2016907861, DOI 10.5120/IJCA2016907861]
   Park CS, 2016, DISPLAYS, V44, P27, DOI 10.1016/j.displa.2016.06.003
   Pfarr F, 2014, P ANN HICSS, P5018, DOI 10.1109/HICSS.2014.616
   Rallapalli S, 2016, PROCEDIA COMPUT SCI, V85, P16, DOI 10.1016/j.procs.2016.05.171
   Sachdev A., 2013, INT J COMPUTER APPL, V67
   Sakr S, 2011, IEEE COMMUN SURV TUT, V13, P311, DOI 10.1109/SURV.2011.032211.00087
   Sathya S., 2015, RATH COLL NAT C ECH
   Shi E, 2011, LECT NOTES COMPUT SC, V6531, P99
   Skourletopoulos G, 2017, SOFT COMPUT, V21, P4523, DOI 10.1007/s00500-016-2083-4
   Stergiou C, 2017, INT J NETW MANAG, V27, DOI 10.1002/nem.1930
   Takabi H, 2010, IEEE SECUR PRIV, V8, P24, DOI 10.1109/MSP.2010.186
   The Economist, 2010, DAT DAT EV
   Vajjhala N.R., 2016, European Journal of Economics and Business Studies, V4, P129, DOI [10.26417/ejes.v4i1.p129-137, DOI 10.26417/EJES.V4I1.P129-137]
   Veluru S., 2014, IGI GLOBALS ADV INFO
   Zhou P, 2016, IEEE T MULTIMEDIA, V18, P1217, DOI 10.1109/TMM.2016.2537216
NR 43
TC 36
Z9 37
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22803
EP 22822
DI 10.1007/s11042-017-4590-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200047
DA 2024-07-18
ER

PT J
AU Tian, T
   Zhang, Y
   Dou, H
   Tong, HJ
AF Tian, Tian
   Zhang, Yun
   Dou, Hao
   Tong, Hengjian
TI Land-use classification with biologically inspired color descriptor and
   sparse coding spatial pyramid matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Land-use classification; Biologically inspired descriptor; Scale
   invariant feature transform (SIFT); Sparse coding spatial pyramid
   matching (ScSPM)
ID PERFORMANCE EVALUATION; SCENE; MODEL; REPRESENTATION; REGISTRATION
AB Land-use classification using remote sensing images plays a key role in many applications such as urban mapping and geospatial object detection. With the rapid development of satellite sensors, high-resolution images which exhibit more detailed textures now can be acquired. How to effectively represent these images and recognize the categories of land-use/land-cover scenes has become a challenging task. In this paper, we propose a novel biologically inspired descriptor combined with the sparse coding spatial pyramid matching (ScSPM) for land-use classification. A color processing pipeline is first presented to simulate the opponent responses of human visual system. By extending the scale invariant feature transform (SIFT) on processed color channels, a descriptor that is able to jointly extract color and shape information for land-use images is proposed. Then the ScSPM model is employed to incorporate the local descriptors of an image, followed by a linear kernel support vector machine (SVM) for image classification. Performance evaluation on the publicly available LULC data set demonstrates that the proposed method achieves better classification accuracy than other reference methods.
C1 [Tian, Tian; Tong, Hengjian] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Coll Comp Sci, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
   [Zhang, Yun] Beijing Electromech Engn Inst, Beijing 100074, Peoples R China.
   [Dou, Hao] Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences; Huazhong University of Science &
   Technology
RP Tong, HJ (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Coll Comp Sci, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
EM thj26@cug.edu.cn
RI Tian, Tian/AAO-6980-2021
FU Natural Foundation of Hubei Province [2016CFB278]; China Postdoctoral
   Science Foundation [2016M602390]; Open Research Project of the Hubei Key
   Laboratory of Intelligent Geo-Information Processing [KLIGIP1608];
   Fundamental Research Funds for the Central Universities, China
   University of Geosciences (Wuhan)
FX This work is supported by the Natural Foundation of Hubei Province under
   Grant 2016CFB278, China Postdoctoral Science Foundation under Grant
   2016M602390, Open Research Project of the Hubei Key Laboratory of
   Intelligent Geo-Information Processing under Grant KLIGIP1608, and the
   Fundamental Research Funds for the Central Universities, China
   University of Geosciences (Wuhan).
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2006, P IEEE C COMPUTER VI
   [Anonymous], 2009, P ADV NEUR INF PROC
   Avramovic A, 2016, SIGNAL IMAGE VIDEO P, V10, P75, DOI 10.1007/s11760-014-0704-x
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SZ, 2015, IEEE T GEOSCI REMOTE, V53, P1947, DOI 10.1109/TGRS.2014.2351395
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Conway BR, 2010, J NEUROSCI, V30, P14955, DOI 10.1523/JNEUROSCI.4348-10.2010
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao SB, 2015, IEEE T PATTERN ANAL, V37, P1973, DOI 10.1109/TPAMI.2015.2396053
   Gao SB, 2013, IEEE I CONF COMP VIS, P929, DOI 10.1109/ICCV.2013.119
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hurlbert AC, 1989, TECH REP
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LENNIE P, 1990, J NEUROSCI, V10, P649
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu P., 2016, SOFT COMPUTING
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Mekhalfi ML, 2015, IEEE GEOSCI REMOTE S, V12, P2155, DOI 10.1109/LGRS.2015.2453130
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shapley R, 2011, VISION RES, V51, P701, DOI 10.1016/j.visres.2011.02.012
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song YL, 2016, GENET MOL RES, V15, DOI 10.4238/gmr.15026298
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Wang LZ, 2018, FUTURE GENER COMP SY, V78, P353, DOI 10.1016/j.future.2016.06.009
   Wang LZ, 2016, CLUSTER COMPUT, V19, P793, DOI 10.1007/s10586-016-0569-6
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang KF, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425538
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Yang Y, 2011, IEEE I CONF COMP VIS, P1465, DOI 10.1109/ICCV.2011.6126403
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang J, 2012, LECT NOTES COMPUT SC, V7576, P312, DOI 10.1007/978-3-642-33715-4_23
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P6207, DOI 10.1109/TGRS.2015.2435801
NR 48
TC 6
Z9 6
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22943
EP 22958
DI 10.1007/s11042-016-4167-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200054
DA 2024-07-18
ER

PT J
AU Hu, ZP
   Xie, RL
   Wang, M
   Sun, Z
AF Hu, Zhengping
   Xie, Ronglu
   Wang, Meng
   Sun, Zhe
TI Midlevel cues mean shift visual tracking algorithm based on
   target-background saliency confidence map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Midlevel cues; Mean shift; Superpixel; Visual tracking
AB Because of the well-known merits of non-parametric estimation and fast mode matching, the mean shift tracking algorithm has been proposed with demonstrated success. But the traditional mean shift utilizes center-weighted color histogram as the reference model which is susceptible to interference of background pixels, and that can result in the compromised tracking robustness. In order to solve this problem, we propose a midlevel cues mean shift visual tracking algorithm based on target-background confidence map saliency-weighted model. A discriminative appearance model based on superpixels is introduced, thereby it can facilitate a tracker to distinguish between target and background by different weights. This improved mean shift tracker is formulated by computing a target-background saliency confidence map and mean shift iteration, and then we can obtain the position in next frame. Experimental results demonstrate that the improved mean shift tracker is able to handle occlusion and recover it from tracking drifts, furthermore, the improved algorithm facilitates foreground object segmentation during tracking.
C1 [Hu, Zhengping; Xie, Ronglu; Wang, Meng; Sun, Zhe] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Peoples R China.
   [Wang, Meng] Taishan Univ, Sch Phys & Elect Engn, Tai An 271021, Shandong, Peoples R China.
C3 Yanshan University; Taishan University
RP Hu, ZP (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Peoples R China.
EM hzp_ysu@163.com; xieronglu_ysu@163.com; wmshd2001@163.com;
   sunzhe_ysu@163.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   An X, 2014, IET COMPUT VIS, V8, P235, DOI 10.1049/iet-cvi.2013.0004
   [Anonymous], 2010, Technical Report
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Dulai A, 2014, IET SIGN PROCESS, V6, P534
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Leichter I, 2012, IEEE T PATTERN ANAL, V34, P695, DOI 10.1109/TPAMI.2011.167
   Liu HP, 2014, INT J FUZZY SYST, V16, P457
   Liu YM, 2014, IMAGING SCI J, V62, P206, DOI 10.1179/1743131X12Y.0000000042
   Lucena M, 2010, MULTIMED TOOLS APPL, V49, P371, DOI 10.1007/s11042-009-0376-7
   Wang LF, 2013, IEEE T INTELL TRANSP, V14, P1480, DOI 10.1109/TITS.2013.2263281
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yu WS, 2015, IET COMPUT VIS, V9, P110, DOI 10.1049/iet-cvi.2014.0077
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zheng SW, 2014, LECT NOTES COMPUT SC, V8834, P191, DOI 10.1007/978-3-319-12637-1_24
   Zhou ZP, 2015, MULTIMEDIA IN PRESS, V74
   Zhou ZY, 2012, J COMPUT INFORM SYST, V8, P1333
   Zhu GK, 2014, COMPUT VIS IMAGE UND, V118, P40, DOI 10.1016/j.cviu.2013.07.011
   Zuo JY, 2010, ACTA AUTOMAT SIN, V34, P736
NR 21
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21265
EP 21280
DI 10.1007/s11042-016-4068-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400043
DA 2024-07-18
ER

PT J
AU Pu, X
   Tian, XJ
   Zhang, J
   Liu, CY
   Yin, J
AF Pu, Xin
   Tian, Xiao-jian
   Zhang, Jing
   Liu, Chun-yan
   Yin, Jing
TI Chaotic multimedia stream cipher scheme based on true random sequence
   combined with tree parity machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE True random sequence; Tree parity machine; Erbium-doped fiber laser;
   Image encryption
ID HYPERCHAOTIC SYSTEM; ENCRYPTION; CIRCUIT
AB A new algorithm is presented in this paper by combining the true random sequences and the Tree Parity Machine (TPM), which is proven experimentally. Different from common method, true random sequences are proposed as dynamic inputs of TPM in this work compared to the pseudo-random sequences in the latest report. Therefore, several weaknesses of pseudo-random sequences can be overcome including finite precision effect, short cycle effect, and the dynamical property degradation. True random sequences are generated by artificial circuits, then, going through TPM neural networks. A series of key stream can be generated by the operation of XOR (exclusive OR) in the output of the TPMs. Randomness test shows that the final key stream can pass 15 tests proscribed by the National Institute of Standards and Technology (NIST). It was used in image encryption in the end, which demonstrates the improved randomness and gives a very promising prospect in secret communications.
C1 [Pu, Xin; Tian, Xiao-jian] Jilin Univ, Coll Elect Sci & Engn, Changchun, Jilin, Peoples R China.
   [Pu, Xin; Zhang, Jing; Liu, Chun-yan; Yin, Jing] Changchun Univ Sci & Technol, Coll Opt & Elect Informat, Elect Engn Dept, Changchun, Jilin, Peoples R China.
C3 Jilin University; Changchun University of Science & Technology
RP Tian, XJ (corresponding author), Jilin Univ, Coll Elect Sci & Engn, Changchun, Jilin, Peoples R China.
EM tianxj@jlu.edu.cn
CR Ai XX, 2014, ACTA PHYS SINICA, V63
   Amaki T, 2014, IEICE T FUND ELECTR, VE97A, P2393, DOI 10.1587/transfun.E97.A.2393
   [Anonymous], 2011, THESIS
   Azoug SE, 2016, OPT COMMUN, V359, P85, DOI 10.1016/j.optcom.2015.09.054
   Bao BC, 2008, CHINESE PHYS LETT, V25, P2396, DOI 10.1088/0256-307X/25/7/018
   Böhl E, 2014, IET COMPUT DIGIT TEC, V8, P239, DOI 10.1049/iet-cdt.2014.0029
   Chen TM, 2013, ACTA PHYS SIN-CH ED, V62, DOI 10.7498/aps.62.040301
   Chen XJ, 2011, ACTA PHYS SINICA, V60
   Kinzel W, 2002, ADV SOLID STATE PHYS, V42, P383, DOI 10.1007/3-540-45618-X_30
   Kocarev L., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P514, DOI 10.1109/ISCAS.1998.698968
   Li X, 2015, J AMB INTEL HUM COMP, V6, P563, DOI 10.1007/s12652-013-0217-4
   Liu YJ, 2010, J COMPUT APPL MATH, V234, P101, DOI 10.1016/j.cam.2009.12.008
   Luo LG, 1998, J OPT SOC AM B, V15, P972, DOI 10.1364/JOSAB.15.000972
   Moqadasi H, 2015, ANALOG INTEGR CIRC S, V82, P719, DOI 10.1007/s10470-015-0498-y
   Tuncer T, 2014, INFORM MIDEM, V44, P296
   Wang GY, 2008, CHINESE PHYS B, V17, P4014, DOI 10.1088/1674-1056/17/11/013
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Wu JJ, 2016, OPT COMMUN, V359, P38, DOI 10.1016/j.optcom.2015.09.039
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Yanchuk S, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.056235
   [尹汝明 YIN RuMing], 2011, [中国科学. 信息科学, Scientia Sinica Informationis], V41, P777
   Zhang HY, 2012, KEY ENG MATER, V500, P465, DOI 10.4028/www.scientific.net/KEM.500.465
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
NR 24
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19881
EP 19895
DI 10.1007/s11042-016-3728-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500033
DA 2024-07-18
ER

PT J
AU Kumar, I
   Bhadauria, HS
   Virmani, J
   Thakur, S
AF Kumar, Indrajeet
   Bhadauria, H. S.
   Virmani, Jitendra
   Thakur, Shruti
TI A hybrid hierarchical framework for classification of breast density
   using digitized film screen mammograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BIRADS breast density; Texture feature extraction; Principal component
   analysis; kNN classifier; PNN classifier; ANN classifier; NFC
   classifier; SVM classifier; Hierarchical classifier
ID FOCAL LIVER-LESIONS; PROBABILISTIC NEURAL-NETWORK; TEXTURAL FEATURES;
   IMAGE TEXTURE; PARENCHYMAL PATTERNS; DIAGNOSIS; TISSUE; FUZZY; RISK;
   CLASSIFIERS
AB In the present work, a hybrid hierarchical framework for classification of breast density using digitized film screen mammograms has been proposed. For designing of an efficient classification framework 480 MLO view digitized screen film mammographic images are taken from DDSM dataset. The ROIs of fixed size i.e. 128 x 128 pixels are cropped from the center area of the breast (i.e. the area where glandular ducts are prominent). A total of 292 texture features based on statistical methods, signal processing based methods and transform domain based methods are computed for each ROI. The computed feature vector is subjected to PCA for dimensionality reduction. The reduced feature space is fed to the classification module. In this work 4-class breast density classification has been conducted using hierarchical framework where the first classifier is used to classify an unknown test ROI into B-I/other class. If the test ROI is predicted as other class, it is inputted to second classifier for the classification into B-II/dense class. If the test ROI is predicted as belonging to dense class, it is inputted to classifier for the classification into B-III/B-IV class. In this work five hierarchical classifiers designs consisting of 3 PCA-kNN, 3 PCA-PNN, 3 PCA-ANN, 3 PCA-NFC and 3 PCA-SVM classifiers has been proposed. The obtained maximum OCA value is 80.4% using PCA-NFC in hierarchical approach. Further, the best performing individual classifiers are clubbed together in a hierarchical framework to design hybrid hierarchical framework for classification of breast density using digitized screen film mammograms. The proposed hybrid hierarchical framework yields the OCA value of 84.1%. The result achieved by the proposed hybrid hierarchical framework is quite promising and can be used in clinical environment for differentiation between different breast density patterns.
C1 [Kumar, Indrajeet; Bhadauria, H. S.] Govind Ballabh Pant Engn Coll, CSE, Pauri 246001, Uttarakhand, India.
   [Virmani, Jitendra] CSIR Cent Sci Instruments Org, Chandigarh, India.
   [Thakur, Shruti] Indira Gandhi Med Coll, Dept Radiol, Shimla, Himachal Prades, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Scientific Instruments Organisation (CSIO); Indira Gandhi
   Medical College & Hospital Shimla
RP Kumar, I (corresponding author), Govind Ballabh Pant Engn Coll, CSE, Pauri 246001, Uttarakhand, India.
EM erindrajeet@gmail.com; hsb76iitr@gmail.com; jitendra.virmani@gmail.com;
   tshruti878@yahoo.in
RI Kumar, Indrajeet/AAX-8915-2021; Kumar, Indrajeet/AAV-7936-2021
OI Kumar, Indrajeet/0000-0003-2814-2900; Kumar,
   Indrajeet/0000-0003-2814-2900; Virmani, Jitendra/0000-0002-6458-0484
CR Acharya UR, 2016, KNOWL-BASED SYST, V107, P235, DOI 10.1016/j.knosys.2016.06.010
   Agrawal RK, 2008, PATTERN RECOGN, V41, P1452, DOI 10.1016/j.patcog.2007.10.002
   Ahmed S. S., 2016, MED BIOL ENG COMPUT, P1
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   Amendolia SR, 2003, CHEMOMETR INTELL LAB, V69, P13, DOI 10.1016/S0169-7439(03)00094-7
   André TCSS, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2178271
   [Anonymous], P BMVC 91
   [Anonymous], P IEEE INT C SYST MA
   [Anonymous], P 6 LAST INT C SIGN
   [Anonymous], INT J ENG INVENTIONS
   [Anonymous], INT J SCI RES PUBL
   [Anonymous], BIOCYBERNETICS BIOME
   [Anonymous], 2011, PROCEEDINGS OF IEEE, DOI DOI 10.1109/DESE.2011.56
   [Anonymous], 2014, INT J COMPUTING, DOI DOI 10.47839/IJC.3.3.300
   [Anonymous], P IEEE REG 10 9 ANN
   [Anonymous], 2000, P 5 INT WORKSH DIG M
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], BREAST CANC EARL DET
   Azar AT, 2014, NEURAL COMPUT APPL, V24, P1163, DOI 10.1007/s00521-012-1324-4
   Bosch Anna., 2006, COMPUTER VISION PATT, V2, P1552, DOI DOI 10.1109/CVPR.2006.188
   Bovis K., 2002, Proceedings of the 4th Int Workshop on Digital Mammography, P177
   Buciu I, 2011, BIOMED SIGNAL PROCES, V6, P370, DOI 10.1016/j.bspc.2010.10.003
   Buciu I, 2009, 2009 2ND INTERNATIONAL SYMPOSIUM ON APPLIED SCIENCES IN BIOMEDICAL AND COMMUNICATION TECHNOLOGIES (ISABEL 2009), P8
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   Cetisli B, 2010, SOFT COMPUT, V14, P365, DOI 10.1007/s00500-009-0410-8
   Chen Z., 2011, INT C BIOM ENG INF 4, V4, P351
   Choi JY, 2015, BIOMED ENG LETT, V5, P251, DOI 10.1007/s13534-015-0191-1
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   DAPONTE JS, 1991, COMPUT MED IMAG GRAP, V15, P3, DOI 10.1016/0895-6111(91)90100-A
   DASARATHY BV, 1991, PATTERN RECOGN LETT, V12, P497, DOI 10.1016/0167-8655(91)80014-2
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Do QuangHung., 2013, Computational intelligence and neuroscience, V2013, P6
   Du C, 2008, GEODERMA, V143, P85, DOI 10.1016/j.geoderma.2007.10.012
   Enderwick CY, 1997, P ANN INT IEEE EMBS, V19, P810, DOI 10.1109/IEMBS.1997.757772
   Ferrari RJ, 2004, IEEE T MED IMAGING, V23, P232, DOI 10.1109/TMI.2003.823062
   Fuller Robert., 1995, Neural Fuzzy Systems
   Gletsos M, 2003, IEEE T INF TECHNOL B, V7, P153, DOI 10.1109/TITB.2003.813793
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He WD, 2016, LECT NOTES COMPUT SC, V9699, P359, DOI 10.1007/978-3-319-41546-8_45
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jamal N, 2007, IFMBE PROC, V14, P1405
   Kadir Abdul., 2012, International Journal of Advanced Science and Technology, V44, P113
   Kar S, 2014, APPL SOFT COMPUT, V15, P243, DOI 10.1016/j.asoc.2013.10.014
   Karssemeijer N, 1998, PHYS MED BIOL, V43, P365, DOI 10.1088/0031-9155/43/2/011
   Khalifa S., 2012, Australian Journal of Crop Science, V6, P183
   Kher Rahul, 2015, Journal of Medical Engineering & Technology, V39, P138, DOI 10.3109/03091902.2014.998372
   Khuzi AM, 2008, IFMBE PROC, V21, P629
   Kim JK, 1999, IEEE T MED IMAGING, V18, P231, DOI 10.1109/42.764896
   Kumar I, 2015, PROCEDIA COMPUT SCI, V70, P76, DOI 10.1016/j.procs.2015.10.042
   Kumar I, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1960
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Li H, 2004, INT CONGR SER, V1268, P878, DOI 10.1016/j.ics.2004.03.212
   Li H, 2004, MED PHYS, V31, P549, DOI 10.1118/1.1644514
   Mao KZ, 2000, IEEE T NEURAL NETWOR, V11, P1009, DOI 10.1109/72.857781
   Masmoudi AD, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-19
   Mougiakakou SG, 2007, ARTIF INTELL MED, V41, P25, DOI 10.1016/j.artmed.2007.05.002
   Mudigonda NR, 2001, IEEE T MED IMAGING, V20, P1215, DOI 10.1109/42.974917
   Mudigonda NR, 2000, IEEE T MED IMAGING, V19, P1032, DOI 10.1109/42.887618
   Mustra M, 2012, AUTOMATIKA-UK, V53, P362, DOI 10.7305/automatika.53-4.281
   Neagoe Victor -Emil, 2003, AMIA Annu Symp Proc, P494
   Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514
   Owjimehr M, 2017, ULTRASONIC IMAGING, V39, P79, DOI 10.1177/0161734616649153
   Qu YP, 2011, INT J FUZZY SYST, V13, P282
   Rangayyan R. M., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P170, DOI 10.1109/SIBGRA.2000.883910
   Sachdeva J, 2012, INT J NUMER METH BIO, V28, P1107, DOI 10.1002/cnm.2481
   Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937
   Sahiner B, 2001, MED PHYS, V28, P1455, DOI 10.1118/1.1381548
   Shan YC, 2002, ANAL CHIM ACTA, V471, P77, DOI 10.1016/S0003-2670(02)00924-8
   Sharma M, 2001, ANZIIS 2001: PROCEEDINGS OF THE SEVENTH AUSTRALIAN AND NEW ZEALAND INTELLIGENT INFORMATION SYSTEMS CONFERENCE, P117
   Sharma V, 2014, MED BIOL ENG COMPUT, V52, P521, DOI 10.1007/s11517-014-1158-6
   Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
   Sood M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1925
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Stepnowski A, 2003, ACOUST PHYS+, V49, P193, DOI 10.1134/1.1560382
   Sudarshan VK, 2016, COMPUT BIOL MED, V69, P97, DOI 10.1016/j.compbiomed.2015.12.006
   Sujana H, 1996, ULTRASOUND MED BIOL, V22, P1177, DOI 10.1016/S0301-5629(96)00144-5
   SUN CT, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P94, DOI 10.1109/FUZZY.1993.327457
   Tourassi GD, 1999, RADIOLOGY, V213, P317, DOI 10.1148/radiology.213.2.r99nv49317
   Vasantha M., 2010, International Journal of Engineering Science and Technology Medical Image Feature, Extraction, Selection and Classification, V2, P2071
   Virmani J, 2014, J DIGIT IMAGING, V27, P520, DOI 10.1007/s10278-014-9685-0
   Wen-Li Lee, 2004, Biomedical Engineering, Applications Basis Communications, V16, P59
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   WOLFE JN, 1976, CANCER-AM CANCER SOC, V37, P2486, DOI 10.1002/1097-0142(197605)37:5<2486::AID-CNCR2820370542>3.0.CO;2-8
   WOLFE JN, 1976, AM J ROENTGENOL, V126, P1130, DOI 10.2214/ajr.126.6.1130
   WU YZ, 1993, RADIOLOGY, V187, P81, DOI 10.1148/radiology.187.1.8451441
   Zhang G., 2011, ACM S RES APPL COMPU, P232
   Zhang XJ, 2009, RADIOL PHYS TECHNOL, V2, P175, DOI 10.1007/s12194-009-0062-5
   Zheng YF, 2010, ALGORITHMS, V3, P44, DOI 10.3390/a3010044
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
NR 90
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18789
EP 18813
DI 10.1007/s11042-016-4340-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800031
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Cai, YG
   Cheng, DF
AF Zhao, Yang
   Cai, Yanguang
   Cheng, Defu
TI A novel local exploitation scheme for conditionally breeding real-coded
   genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Conditionally breeding; Continuous optimization
ID SET
AB Conditionally breeding real-coded genetic algorithm (CGAR) is effective approach for continue domain problems, in which crossover and mutation behaviors are performed by difference-degree between individuals instead of given probability. In this paper we present a novel exploitation scheme for CGAR to balance between two contradictory aspects of its performance: exploration and exploitation, which is aimed at improving its ability to converge to the near-optimal solutions. The proposed algorithms are evaluated on a number of benchmark functions and the simulation results show that the proposed algorithm performs quite well and outperforms other algorithms.
C1 [Zhao, Yang; Cai, Yanguang] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Guangdong, Peoples R China.
   [Cheng, Defu] Jilin Univ, Coll Instrumentat & Elect Engn, Changchun 130000, Jilin, Peoples R China.
C3 Guangdong University of Technology; Jilin University
RP Cheng, DF (corresponding author), Jilin Univ, Coll Instrumentat & Elect Engn, Changchun 130000, Jilin, Peoples R China.
EM zhaoyang19781023@gmail.com; caiyg99@163.com; chengdefu@jlu.edu.cn
CR Ackley D.H., 1987, GENETIC ALGORITHMS S, P170
   Akimoto Y., 2007, SICE S DEC AUT SYST, V19, P341
   Bilchev G., 1995, Evolutionary Computing. AISB Workshop. Selected Papers, P25
   Boumkheld N, 2015, J INF PROCESS SYST, V11, P116, DOI 10.3745/JIPS.03.0022
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Chen ZQ, 2011, INT J INNOV COMPUT I, V7, P4871
   Chen ZQ, 2011, COMMUN COMPUT SCI E, V94, P417
   Deb K, 2002, EVOL COMPUT, V10, P371, DOI 10.1162/106365602760972767
   Deep K, 2007, APPL MATH COMPUT, V188, P895, DOI 10.1016/j.amc.2006.10.047
   Eshelman LJ, 1998, FOUND GENET ALGORITH, V1, P265
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Gupta GP, 2015, J INF PROCESS SYST, V11, P148, DOI 10.3745/JIPS.03.0018
   Juan C, 2013, HUM-CENT COMPUT INFO, V3, P12
   Jyoti A, 2015, HUM-CENT COMPUT INFO, V5, P3
   Kobayashi Shigenobu, 2009, Journal of Japanese Society for Artificial Intelligence, V24, P128
   Kumar KPK, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0014-x
   Lee HG, 2015, J INF PROCESS SYST, V11, P248, DOI 10.3745/JIPS.04.0008
   Li C, 2015, MECH SYST SIGNAL PR, V64-65, P132, DOI 10.1016/j.ymssp.2015.04.004
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Michalewicz Z., 1996, GENETIC ALGORITHMS D, DOI [DOI 10.1007/978-3-662-03315-9, 10.1007/978-3-662-03315-9]
   Monmarché N, 2000, FUTURE GENER COMP SY, V16, P937, DOI 10.1016/S0167-739X(00)00047-9
   Ono I., 1997, P 7 INT C GENETIC AL, P246
   Price Kenneth, 2006, NAT COMP SER, DOI 10.1007/3-540-31306-0
   Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706
   ROSENBROCK HH, 1960, COMPUT J, V3, P175, DOI 10.1093/comjnl/3.3.175
   Satoh H., 1996, Methodologies for the Conception, Design, and Application of Intelligent Systems. Proceedings of the 4th International Conference on Soft Computing, P494
   Wang RL, 2004, NEUROCOMPUTING, V57, P463, DOI 10.1016/j.neucom.2003.12.003
   Wang RL, 2007, SOFT COMPUT, V11, P687, DOI [10.1007/s00500-006-0131-1, 10.1007/S00500-006-0131-1]
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Zheng Z., 2015, Applied Mathematics Information Sciences, P3169, DOI DOI 10.12785/AMIS/090646
   Zhihan L, 2013, PLOS ONE, V8
NR 35
TC 8
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17955
EP 17969
DI 10.1007/s11042-016-3493-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800021
DA 2024-07-18
ER

PT J
AU Laleye, FAA
   Ezin, EC
   Motamed, C
AF Laleye, Frejus A. A.
   Ezin, Eugene C.
   Motamed, Cina
TI Automatic boundary detection based on entropy measures for
   text-independent syllable segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Syllable segmentation; Nonlinear speech analysis; Singularity exponents;
   Renyi entropy; Tsallis entropy; Shannon entropy
ID RECOGNITION; IMAGES
AB In this paper, we study the boundary detection in syllable segmentation field. We describe an algorithm proposed for text-independent syllable segmentation. This algorithm provides a performance comparison between the entropies of Shannon, Tsallis and Renyi in an effective detection of beginning-ending points of syllable in a speech signal. The Shannon generalizations (Tsallis and Renyi) quantify the degree of signal organization and offer the relevant information such as the voicing degree on the first syllable segment that we obtained from the temporal dynamics of singularity exponents. The method we propose is focused on an aggregation measure based on entropies to enhance the syllable boundaries detection. It has been also demonstrated in this paper that the best suited entropy for efficient boundary detection is Renyi entropy. Once evaluated, our algorithm produced better performance with efficient results on two languages, i.e., the Fongbe (an African tonal language spoken especially in Benin, Togo, and Nigeria) and an American English. The overall accuracy of syllable boundaries was obtained on Fongbe dataset and validated subsequently on TIMIT dataset with a margin of error < 5ms.
C1 [Laleye, Frejus A. A.; Motamed, Cina] Univ Littoral Cote dOpale, Lab Informat Signal & Image Cote Opale, 50 Rue F Buisson,BP 719, F-62228 Calais, France.
   [Ezin, Eugene C.] Univ Abomey Calavi, Inst Math & Sci Phys, BP 613, Porto Novo, Benin.
C3 Universite du Littoral-Cote-d'Opale; University of Abomey Calavi;
   Institute of Mathematical Sciences & Physics IMPS
RP Laleye, FAA (corresponding author), Univ Littoral Cote dOpale, Lab Informat Signal & Image Cote Opale, 50 Rue F Buisson,BP 719, F-62228 Calais, France.
EM laleye@lisic.univ-littoral.fr; eugene.ezin@imsp-uac.org;
   motamed@lisic.univ-littoral.fr
RI Laleye, Fréjus/AAX-5865-2021
OI Laleye, Frejus A. A./0000-0003-0744-642X
CR [Anonymous], 2014, 2014 INT C POW SIGN
   [Anonymous], 2009, INTERSPEECH 2009
   Baraniuk RG, 2001, IEEE T INFORM THEORY, V47, P1391, DOI 10.1109/18.923723
   Boashash B., TIME FREQUENCY SIGNA, P2003
   Chen X.C., 2015, C EMP METH NAT LANG, P1197
   Chou CH, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P745, DOI 10.1109/APSCC.2008.6
   Demeechai T, 2001, SPEECH COMMUN, V33, P241, DOI 10.1016/S0167-6393(00)00017-0
   Fantinato PC, 2008, IEEE INT SYM MULTIM, P551, DOI 10.1109/ISM.2008.123
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Haque MA, 2013, MULTIMED TOOLS APPL, V63, P485, DOI 10.1007/s11042-011-0921-z
   Howitt A, 2002, J ACOUST SOC AM, V112, P2279, DOI [10.1121/1.4779139, DOI 10.1121/1.4779139]
   Hsieh CT, 1999, J INF SCI ENG, V15, P615
   Jittiwarangkul N, AS PAC C CIRC SYST
   Khanagha V, 2014, DIGIT SIGNAL PROCESS, V35, P86, DOI 10.1016/j.dsp.2014.08.002
   Khanagha V, 2011, INT CONF ACOUST SPEE, P4484
   Kinsner W, 2008, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P351, DOI 10.1109/COGINF.2008.4639188
   Landsiedel C, 2011, INT CONF ACOUST SPEE, P5256
   Makashay M., 2000, P 6 C SPOK LANG PROC
   MERMELSTEIN P, 1975, J ACOUST SOC AM, V58, P880, DOI 10.1121/1.380738
   Obin N, 2013, INT CONF ACOUST SPEE, P6699, DOI 10.1109/ICASSP.2013.6638958
   Origlia A, 2014, SPEECH COMMUN, V57, P155, DOI 10.1016/j.specom.2013.09.012
   Pan Feng, 2010, Proceedings of the 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P433, DOI 10.1109/ICMTMA.2010.587
   Petrillo M., 2003, P 8 EUR C SPEECH COM
   Pfitzinger HR, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1261, DOI 10.1109/ICSLP.1996.607838
   Pikrakis A, 2008, STUD COMPUT INTELL, V120, P81
   Pont O, 2011, LECT NOTES COMPUT SC, V6636, P346, DOI 10.1007/978-3-642-21073-0_31
   Prasad VK, 2004, SPEECH COMMUN, V42, P429, DOI 10.1016/j.specom.2003.12.002
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shastri L., 1999, PROC 14 INT C PHONET, P1721
   Sheikhi G., 2011, 2011 18th Iranian Conference of Biomedical Engineering (ICBME), P195, DOI 10.1109/ICBME.2011.6168554
   Shen HJE, 1998, 5 INT C SPOK LANG PR
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Turiel A, 2000, NEURAL COMPUT, V12, P763, DOI 10.1162/089976600300015583
   Turiel A, 2006, J COMPUT PHYS, V216, P362, DOI 10.1016/j.jcp.2005.12.004
   Villing R., 2004, Irish Signals and Systems Conference 2004, P41, DOI 10.1049/cp:20040515
   Vuuren VZ, ICPRAM 2015, V1
   Wu SL, 1997, INT CONF ACOUST SPEE, P987, DOI 10.1109/ICASSP.1997.596105
   Yahia H, 2010, PATTERN RECOGN, V43, P3591, DOI 10.1016/j.patcog.2010.04.011
   Zhao XF, 2008, CAN CON EL COMP EN, P139
NR 41
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16347
EP 16368
DI 10.1007/s11042-016-3911-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100013
DA 2024-07-18
ER

PT J
AU Pan, Z
   Liu, S
   Fu, WN
AF Pan, Zheng
   Liu, Shuai
   Fu, Weina
TI A review of visual moving target tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computer vision; Visual tracking; Meanshift; Particle filter; Active
   Contour; Scale-invariant
ID ROBUST OBJECT TRACKING; REAL-TIME TRACKING; MEAN-SHIFT; CONTOUR
   TRACKING; PARTICLE FILTER; COMPUTER VISION; HISTOGRAMS; GRADIENT; MODELS
AB Recently, computer vision and multimedia understanding become important research domains in computer science. Meanwhile, visual tracking of moving target, one of most important application in computer vision, becomes a highlight today. So, this paper reviews research and technology in this domain. First, background and application of visual tracking is introduced. Then, visual tracking methods are classified by different thinking and technologies. Their positiveness, negativeness and improvement are analyzed deeply. Finally, difficulty in this domain is summarized and future prospect of related fields is presented.
C1 [Pan, Zheng; Liu, Shuai; Fu, Weina] Inner Mongolia Univ, Coll Comp Sci, Hohhot 130012, Peoples R China.
   [Fu, Weina] Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 130012, Peoples R China.
C3 Inner Mongolia University; Inner Mongolia Agricultural University
RP Liu, S (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Hohhot 130012, Peoples R China.
EM cs_liushuai@imu.edu.cn
RI Liu, Shuai/AAX-1239-2021; Liu, Shuai/AAB-1960-2019; Fu,
   Weina/AAF-5699-2020; Liu, Shuai/P-3939-2017
OI Liu, Shuai/0000-0001-9909-0664; Liu, Shuai/0000-0001-9909-0664
FU National Natural Science Foundation of China [61502254]; National
   Natural Science Foundation of Inner Mongolia [2014BS0606]
FX This research is supported by following grants:r National Natural
   Science Foundation of China [61502254] and National Natural Science
   Foundation of Inner Mongolia [2014BS0606].
CR Allili MS, 2008, NEUROCOMPUTING, V71, P2001, DOI 10.1016/j.neucom.2007.10.019
   [Anonymous], 2015, COMPUT SCI
   [Anonymous], 2005, OPEN SOURCE TRACKING
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], APPL MATH SCI
   [Anonymous], SYSTEMATIC SAMPLING
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2007, ACM T MULTIMEDIA COM
   [Anonymous], P 2012 ACM RES APPL
   [Anonymous], P 6 IEEE INT WORK PE
   [Anonymous], P IEEE CVPR
   [Anonymous], P IEEE ECCV HER
   [Anonymous], 2015, CHINESE J COMPUTERS
   [Anonymous], B SNAKES IMPLEMENTAT
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Brox T, 2010, IMAGE VISION COMPUT, V28, P376, DOI 10.1016/j.imavis.2009.06.009
   Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919
   Chen Z., 2003, Statistics, V182, P1, DOI [10.1080/02331888.2012.708030, DOI 10.1080/02331880309257]
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chiverton J, 2012, IEEE T IMAGE PROCESS, V21, P1231, DOI 10.1109/TIP.2011.2167343
   Choi JW, 2015, MULTIMED TOOLS APPL, V74, P199, DOI 10.1007/s11042-013-1756-6
   Chong Xia, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P173, DOI 10.1007/978-3-319-13168-9_18
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fen Xu, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1503, DOI 10.1109/CISP.2010.5646273
   Fu WN, 2016, MULTIMED TOOLS APPL, V75, P13001, DOI 10.1007/s11042-014-2391-6
   Fu WN, 2016, MULTIMED TOOLS APPL, V75, P15553, DOI 10.1007/s11042-015-2519-3
   Fu WN, 2016, J SUPERCOMPUT, V72, P2502, DOI 10.1007/s11227-015-1499-4
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gress O, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P374, DOI 10.1109/ISBI.2012.6235562
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hong SH, 2013, CIRC SYST SIGNAL PR, V32, P825, DOI 10.1007/s00034-012-9506-y
   HORN BKP, 1981, P SOC PHOTO-OPT INST, V281, P319
   Hou Zhi-Qiang, 2006, Acta Automatica Sinica, V32, P603
   Huang YL, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/693484
   Hwang SS, 2011, IEEE T CONTR SYST T, V19, P1384, DOI 10.1109/TCST.2010.2091415
   Jatoth Ravi Kumar, 2015, International Journal of Image, Graphics and Signal Processing, V7, P24, DOI 10.5815/ijigsp.2015.03.04
   Jeyakar J, 2008, COMPUT VIS IMAGE UND, V112, P296, DOI 10.1016/j.cviu.2008.05.005
   Jia DP, 2015, INT J SECUR APPL, V9, P21, DOI 10.14257/ijsia.2015.9.2.03
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2592, DOI 10.1109/TSP.2003.816758
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kwok C, 2004, P IEEE, V92, P469, DOI 10.1109/JPROC.2003.823144
   Kwon J, 2009, PROC CVPR IEEE, P991, DOI 10.1109/CVPRW.2009.5206501
   Leichter I, 2012, IEEE T PATTERN ANAL, V34, P695, DOI 10.1109/TPAMI.2011.167
   Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577
   Li SX, 2014, COMPUT VIS IMAGE UND, V125, P1, DOI 10.1016/j.cviu.2013.10.001
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Xiang-Ru, 2005, Journal of Software, V16, P365, DOI 10.1360/jos160365
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mondal A, 2016, SOFT COMPUT, V20, P785, DOI 10.1007/s00500-014-1543-y
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Nieto M, 2016, J REAL-TIME IMAGE PR, V11, P179, DOI 10.1007/s11554-012-0315-0
   Ning JF, 2013, IEEE T CIRC SYST VID, V23, P1589, DOI 10.1109/TCSVT.2013.2254931
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Pai CJ, 2004, PATTERN RECOGN, V37, P1025, DOI 10.1016/j.patcog.2003.10.005
   Peng Ning-Song, 2005, Journal of Software, V16, P1542, DOI 10.1360/jos161542
   Rosenfeld A, 2001, COMPUT VIS IMAGE UND, V84, P298, DOI 10.1006/cviu.2001.0953
   Shuqiang Guo, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P451, DOI 10.1007/978-981-10-0557-2_45
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sun SF, 2013, INT CONF ACOUST SPEE, P2297, DOI 10.1109/ICASSP.2013.6638064
   Sun X, 2015, IEEE T IMAGE PROCESS, V24, P3386, DOI 10.1109/TIP.2015.2447213
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   [王欢 WANG Huan], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P489
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie ZH, 2015, IET COMPUT VIS, V9, P831, DOI 10.1049/iet-cvi.2014.0403
   Yan HX, 2015, IEEE T GEOSCI REMOTE, V53, P6134, DOI 10.1109/TGRS.2015.2432067
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yi SY, 2015, SIGNAL PROCESS, V110, P178, DOI 10.1016/j.sigpro.2014.09.020
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou Z, 2016, MULTIMED TOOLS APPL, P1
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 97
TC 87
Z9 96
U1 11
U2 204
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 16989
EP 17018
DI 10.1007/s11042-016-3647-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500007
DA 2024-07-18
ER

PT J
AU Park, JW
AF Park, Jae Wan
TI <i>Hybrid Monopoly</i>: A Multimedia Board Game that Supports
   Bidirectional Communication between a Mobile Device and a Physical Game
   Set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid monopoly; Multimedia board game; Physical game set; Bidirectional
   communication
AB This paper presents an associated and integrated cyber-physical multimedia board game that supports bidirectional communication between a mobile device and a physical game set. The objective of this research is to assist, enhance, and expand the scope of hybrid board games based on today's media culture. By investigating and analyzing existing hybrid board game systems, we propose in this paper a new direction for the development of such board games. According to the new direction, we developed a new Monopoly-based hybrid board game, Hybrid Monopoly, which provides intelligent content through the utilization of a digital interface for mobile devices and a physical game set that is linked to the digital interface, and proposed several technologies that can support bidirectional communication. In order to prove its validity, the hybrid board game was tested and evaluated. Our hybrid board game exemplifies a new possibility for multimedia systems that provides a new experience for users.
C1 [Park, Jae Wan] Soongsil Univ, Global Sch Media, 369 Sangdo Ro, Seoul 06978, South Korea.
C3 Soongsil University
RP Park, JW (corresponding author), Soongsil Univ, Global Sch Media, 369 Sangdo Ro, Seoul 06978, South Korea.
EM jaewan.park@ssu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2013R1A1A1061628]
FX "This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (No. NRF-2013R1A1A1061628)."
CR [Anonymous], 2000, Multiagent Systems: AModern Approach to DistributedArtificial Intelligence
   Bakker S., 2007, ACM International Conference Proceeding Series, V203, P163, DOI [DOI 10.1145/1255047.1255081, 10.1145/1255047.1255081]
   Bakker S., 2007, P 1 INT C TANGIBLE E, P151
   Baldwin CY, 2006, UND COM SYS, P175
   Bieszczad Andrzej, 1998, IEEE Communications Surveys & Tutorials, V1, P2, DOI 10.1109/COMST.1998.5340400
   Björk S, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P423
   Bodker S., 1995, CONTEXT CONSCIOUSNES, P147
   Booth Paul., 2014, Convergence, V22, P647
   Butler A, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P201, DOI 10.1145/1449715.1449746
   Dietz P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P219, DOI 10.1145/502348.502389
   Felsen M, 2007, COMPLEX POPULATIONS, V11, P166
   Feng A, 2012, IET INFORM SECUR, V6, P111, DOI 10.1049/iet-ifs.2010.0073
   Goyal Diksha, 2013, INT J EMERGING TECHN, V4, P15
   Haartsen J, 1998, ERICSSON REV, V75, P110
   Jorda Sergi., 2010, CHI 2010: Media Showcase Session 1, P2989, DOI [10.1145/1753846.1753903, DOI 10.1145/1753846.1753903]
   Magerkurth C, 2004, PROC GRAPH INTERF, P73
   Magerkurth C., 2005, Computer in Entertainment (CIE), V3, P4
   Magerkurth Carsten, 2003, P VID TRACK UB COMP
   Mandryk R.L., 2002, CHI 02 EXTENDED ABST, P640, DOI 10.1145/506443.506523
   Rogers Y, 2003, KIS CO SUP COOP WORK, V2, P45
   Roudaut A., 2008, P WORKING C ADV VISU, P146, DOI DOI 10.1145/1385569.1385594
   Woo Kim Min, 2013, [Design Convergence Study, 디자인융복합연구(구.인포디자인이슈)], V12, P273
NR 22
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17385
EP 17401
DI 10.1007/s11042-017-4589-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500028
DA 2024-07-18
ER

PT J
AU Rohit, U
   Rahiman, VA
   George, SN
AF Rohit, U.
   Rahiman, Abdu, V
   George, Sudhish N.
TI A robust face hallucination technique based on adaptive learning method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Hallucination; Sparse representation; Position-patch;
   Regularization
ID SUPERRESOLUTION; SPARSE; REPRESENTATIONS
AB Position-patch based approaches have been proposed for single-image face hallucination. This paper models the face hallucination problem as a coefficient recovery problem with respect to an adaptive training set for improved noise robustness. The image-adaptive training set is constructed by corrupting a local training set of position-patches by adding specific amounts of noise depending on the input image noise level. In this proposed method, image denoising and super-resolution are simultaneously carried out to obtain superior results. Though the principle is general and can be extended to most super-resolution algorithms, we discuss this in context of existing locality-constrained representation (LcR) approach in order to compare their performances. It can be demonstrated that the proposed approach can quantitatively and qualitatively yield better results in high noisy environments.
C1 [Rohit, U.; Rahiman, Abdu, V] Natl Inst Technol Calicut, Calicut, Kerala, India.
   [George, Sudhish N.] Natl Inst Technol Calicut, Dept Elect & Commun, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut; National Institute of Technology (NIT System);
   National Institute of Technology Calicut
RP Rohit, U (corresponding author), Natl Inst Technol Calicut, Calicut, Kerala, India.
EM rohitu17@gmail.com; vkarahim@gmail.com; sudhish@nitc.ac.in
RI George, Sudhish/U-3625-2019; V, Abdu Rahiman/AAD-9927-2022
CR Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jin YG, 2015, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR.2015.7299162
   Junjun Jiang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P212, DOI 10.1109/ICME.2012.152
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364
   Thomaz C. E., 2012, FEI face database
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2014, IEEE T CIRC SYST VID, V24, P802, DOI 10.1109/TCSVT.2013.2290574
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang Y, 2013, J OPER RES SOC CHINA, V1, P79, DOI 10.1007/s40305-013-0010-2
NR 27
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16809
EP 16829
DI 10.1007/s11042-016-3953-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100035
DA 2024-07-18
ER

PT J
AU Hou, YH
   Ye, YL
   Lei, JJ
   Xiang, W
   Guo, Y
   Cui, B
AF Hou, Yonghong
   Ye, Yilin
   Lei, Jianjun
   Xiang, Wei
   Guo, Yao
   Cui, Bo
TI Rate control for HEVC based on spatio-temporal context and motion
   complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; R - lambda model; Spatio-temporal context; Motion
   complexity
ID DISTORTION MODELS; BIT ALLOCATION; VIDEO; STANDARD; QUALITY
AB Rate control plays a crucial role in video coding. Existing rate control methods for high efficiency video coding standard (HEVC) hardly take advantage of spatio-temporal context information when updating model parameters, resulting in inaccurate computation of the Lagrange multiplier and quantization parameter (QP). Meanwhile, these methods fail to consider the motion complexity of a basic unit (BU). Therefore, a large mismatch may exist between the allocated bits and actually encoded bits. In this paper, we propose an effective rate control scheme for HEVC at the BU layer to exploit both the spatio-temporal context and motion complexity. Firstly, the actually used Lagrange multiplier and generated bits of the highly correlated coded BUs in the spatio-temporal context are carefully weighted to update the model parameters. Secondly, the allocated bits for a BU are adjusted based on its motion complexity. Thus, an improved Lagrange multiplier is more accurate in minimizing the difference between the target bits and actually generated bits. Experimental results show that our proposed method outperforms the current scheme in HM with negligible complexity increase.
C1 [Hou, Yonghong; Ye, Yilin; Lei, Jianjun; Guo, Yao; Cui, Bo] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Xiang, Wei] Univ Southern Queensland, Sch Mech & Elect Engn, Toowoomba, Qld 4350, Australia.
C3 Tianjin University; University of Southern Queensland
RP Lei, JJ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM yeyilin@tju.edu.cn; jjlei@tju.edu.cn
RI hou, yonghong/N-9255-2013; Xiang, Wei/AAF-9780-2019; Lei,
   Jianjun/P-2539-2018
OI Xiang, Wei/0000-0002-0608-065X; 
CR Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Bossen F, 2012, 10 JCTVC M STOCKH SW
   Bross B, 2013, 12 JCTVC M GEN SWITZ
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Corbera J, 1997, DOCUMENTS
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   Jiang MQ, 2005, IEEE T CONSUM ELECTR, V51, P281, DOI 10.1109/TCE.2005.1405733
   Kamaci N, 2005, IEEE T CIRC SYST VID, V15, P994, DOI 10.1109/TCSVT.2005.852400
   Katto J., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P555, DOI 10.1109/ICIP.1995.537539
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Li B, 2013, 13 JCTVC M SHANGH AP
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   LI ZG, 2003, 7 M PATT THAIL
   Li ZG, 2003, 7 JVT M JVT G012 RL
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   MULLER F, 1993, ELECTRON LETT, V29, P1935, DOI 10.1049/el:19931288
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Seo CW, 2013, IEEE T IMAGE PROCESS, V22, P2442, DOI 10.1109/TIP.2013.2251647
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan W, 2005, 15 M BUS KOR APR 200
   Yuan Y, 2012, IEEE T CIRC SYST VID, V22, P1707, DOI 10.1109/TCSVT.2012.2223037
NR 29
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14035
EP 14053
DI 10.1007/s11042-016-3784-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800017
DA 2024-07-18
ER

PT J
AU Oszust, M
AF Oszust, Mariusz
TI Image quality assessment with lasso regression and pairwise score
   differences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Full-reference; Lasso regression; Evaluation
ID STRUCTURAL SIMILARITY; FUSION; DEGRADATION; INFORMATION; INDEX
AB The reception of multimedia applications often depends on the quality of processed and displayed visual content. This is the main reason for the development of automatic image quality assessment (IQA) techniques which try to mimic properties of human visual system and produce objective scores for evaluated images. Most of them require a training step in which subjective scores, obtained in tests with human subjects, are used for parameters tuning. In this paper, it is shown that pairwise score differences (PSD) can be successfully used for training a full-reference hybrid IQA measure based on the least absolute shrinkage and selection operator (lasso) regression. The results of extensive experimental evaluation on four largest IQA benchmarks show that the proposed IQA technique is statistically better than its version trained using raw scores, and both approaches are statistically better than state-of-the-art full-reference IQA measures. They are also better than other hybrid approaches. In the paper, the evaluation protocol is extended with tests using PSD.
C1 [Oszust, Mariusz] Rzeszow Univ Technol, Dept Comp & Control Engn, W Pola 2, PL-35959 Rzeszow, Poland.
C3 Rzeszow University of Technology
RP Oszust, M (corresponding author), Rzeszow Univ Technol, Dept Comp & Control Engn, W Pola 2, PL-35959 Rzeszow, Poland.
EM marosz@kia.prz.edu.pl
RI Oszust, Mariusz/AAC-3224-2022
OI Oszust, Mariusz/0000-0002-5482-6313
CR [Anonymous], CIT
   [Anonymous], 2015, APPL INFORM
   [Anonymous], VISUAL COMMUNICATION
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], P IEEE INT C IM PROC, DOI [10.1109/icip.2010.5649275, DOI 10.1109/ICIP.2010.5649275]
   [Anonymous], 2015, INT J ANTENNAS PROPA, DOI DOI 10.1155/2015/216983
   [Anonymous], CORRABS14125488
   Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Barri A, 2014, IEEE T IMAGE PROCESS, V23, P2446, DOI 10.1109/TIP.2014.2316379
   Bhandari AK, 2017, MULTIDIM SYST SIGN P, V28, P495, DOI 10.1007/s11045-015-0353-4
   Chandra A, 2016, MULTIMED TOOLS APPL, V75, P1079, DOI 10.1007/s11042-014-2358-7
   Chang HW, 2015, NEUROCOMPUTING, V151, P1142, DOI 10.1016/j.neucom.2014.04.081
   Chang HW, 2013, IEEE T IMAGE PROCESS, V22, P4007, DOI 10.1109/TIP.2013.2266579
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Group VQE, 2003, FIN REP VID QUAL EXP
   Jin LN, 2012, INT CONF ACOUST SPEE, P1145, DOI 10.1109/ICASSP.2012.6288089
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu MN, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P10, DOI 10.1109/FSKD.2008.469
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Lukin VV, 2015, PROC SPIE, V9394, DOI 10.1117/12.2085465
   Okarma K, 2013, ELEKTRON ELEKTROTECH, V19, P129, DOI 10.5755/j01.eee.19.10.5908
   Okarma K, 2010, LECT NOTES ARTIF INT, V6113, P539, DOI 10.1007/978-3-642-13208-7_67
   Oszust M, 2016, IEEE SIGNAL PROC LET, V23, P65, DOI 10.1109/LSP.2015.2500819
   Pei SC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440172
   Peng P, 2012, IEEE SYS MAN CYBERN, P2127, DOI 10.1109/ICSMC.2012.6378054
   Peng P, 2012, LECT NOTES COMPUT SC, V7324, P123, DOI 10.1007/978-3-642-31295-3_15
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rehman A, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-16
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sharif M, 2015, MULTIMED TOOLS APPL, V74, P5533, DOI 10.1007/s11042-014-1867-8
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Wang FL, 2015, IEEE SIGNAL PROC LET, V22, P1534, DOI 10.1109/LSP.2015.2413891
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2014, IEEE SIGNAL PROC LET, V21, P437, DOI 10.1109/LSP.2014.2304714
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2010, INT J IMAG SYST TECH, V20, P301, DOI 10.1002/ima.20246
   Yuan Y, 2015, NEUROCOMPUTING, V159, P227, DOI 10.1016/j.neucom.2015.01.066
   Zhang H, 2012, P IEEE INT C E-SCI
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XD, 2013, IEEE SIGNAL PROC LET, V20, P319, DOI 10.1109/LSP.2013.2244081
   Zhou F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116312
NR 54
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13255
EP 13270
DI 10.1007/s11042-016-3755-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900015
OA hybrid
DA 2024-07-18
ER

PT J
AU Savino, HJ
   de Lima, EB
AF Savino, Heitor Judiss
   de Lima Filho, Eddie Batista
TI Program clock reference correction in transport stream processors with
   rate adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PCR correction; MPEG-2; Transport stream; Semaphore; Jitter
ID MPEG-2 SYSTEMS
AB The program clock reference (PCR), which is carried by MPEG-2 transport streams, is commonly used for synchronizing different media types, in receivers. In summary, it is a snapshot of the transmitter's 27 MHz counter and is employed to adapt the local clock. However, the PCR may present inaccuracies on its time base information, known as jitter, given that the processing chain between transmitter and receiver often modifies relative distances among time stamps. In order to correct such a behavior, some authors have suggested PCR-jitter control schemes, which are able to compensate for new PCR positions, in streams. Nevertheless, as none of them takes into account the asynchronism among all elements involved in this procedure, there is often an increase in jitter. The present paper addresses this problem and introduces a methodology for joint rate adaptation and PCR correction, which has the potential to reduce the output jitter, when it is caused by stream modifications due to a rate adaptation module. Simulation results show that the proposed method is effective and outperforms traditional and more recent schemes presented in the literature, by keeping the output jitter level as close as possible to the one at the input and, consequently, avoiding large clock deviations.
C1 [Savino, Heitor Judiss; de Lima Filho, Eddie Batista] Fed Univ Amazonas UFAM, BR-69077000 Manaus, Amazonas, Brazil.
   [de Lima Filho, Eddie Batista] FPF Tech, BR-69075351 Manaus, Amazonas, Brazil.
C3 Universidade Federal de Amazonas
RP de Lima, EB (corresponding author), Fed Univ Amazonas UFAM, BR-69077000 Manaus, Amazonas, Brazil.; de Lima, EB (corresponding author), FPF Tech, BR-69075351 Manaus, Amazonas, Brazil.
EM heitor_savino@ufam.edu.br; eddie_batista@yahoo.com.br
RI Savino, Heitor/K-6542-2019
OI Savino, Heitor/0000-0001-6975-0270; de Lima Filho, Eddie
   Batista/0000-0002-2758-4638
FU CT-PIM; UNISOL
FX The authors would like to thank CT-PIM and UNISOL, for the support
   provided for this work.
CR [Anonymous], 2000, 101154 ETSI TR, V1.4.1
   [Anonymous], 2001, 101290 ETSI TR, V1.2.1
   [Anonymous], 2007, 138181 ISO IEC
   [Anonymous], 1998, 500839 ETSI EN
   Chen YP, 2009, 2009 10TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS, AND NETWORKS (ISPAN 2009), P722, DOI 10.1109/I-SPAN.2009.18
   Diniz P., 2010, DIGIT SIGNAL PROCESS
   Fischer W, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-642-11612-4
   He Y.P., 2005, P IEEE WORKSH MULT S, V71, P1, DOI DOI 10.1109/MMSP.2005.248571
   Lee GS, 2004, ETRI J, V26, P653, DOI 10.4218/etrij.04.0204.0018
   Lee SI, 1997, IEEE T CONSUM ELECTR, V43, P324, DOI 10.1109/30.628620
   Liang LF, 2002, IEEE T BROADCAST, V48, P348, DOI 10.1109/TBC.2002.806799
   Machmerth Markus, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P863, DOI 10.1109/ISCE.2009.5156867
   Machmerth M, 2008, P CAR C DEV CIRC SYS, P1, DOI [10.1109/ICCDCS.2008.4542612, DOI 10.1109/ICCDCS.2008.4542612]
   Noro R, 1999, TELECOMMUN SYST, V11, P3, DOI 10.1023/A:1019124713179
   Peng X, 2007, I C WIREL COMM NETW, P2940, DOI 10.1109/WICOM.2007.730
   Roll T., 2010, P INT C CONS EL LAS, P405, DOI DOI 10.1109/ICCE.2010.5418919
   Savino H. J., 2013, 31 S BRAS TEL SBRT F, P1
   Savino HJ, 2012, P INT C SOFTW TEL CO, P1
   Tryfonas C, 1999, IEEE T MULTIMEDIA, V1, P251, DOI 10.1109/6046.784464
   Uehara M, 2006, P IEEE, V94, P261, DOI 10.1109/JPROC.2005.859695
   Wang XD, 2002, IEEE T CONSUM ELECTR, V48, P329, DOI 10.1109/TCE.2002.1010139
NR 21
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14107
EP 14128
DI 10.1007/s11042-016-3814-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800021
DA 2024-07-18
ER

PT J
AU Dong, XS
   He, B
   Dong, XH
   Dong, JY
AF Dong, Xingshuai
   He, Bo
   Dong, Xinghui
   Dong, Junyu
TI Monocular visual-IMU odometry using multi-channel image patch exemplars
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual-IMU odometry; Odometry; Navigation; Multi-channel image features;
   Local features
AB In this paper, we propose three sets of multi-channel image patch features for monocular visual-IMU (Inertial Measurement Unit) odometry. The proposed feature sets extract image patch exemplars from multiple feature maps of an image. We also modify an existing visual-IMU odometry framework by using different salient point detectors and feature sets and replacing the inlier selection approach with a self-adaptive scheme. The modified framework is used to examine the proposed feature sets. In addition to the Root Mean Square Error (RMSE) metric, we use the Hausdorff distance to measure the inconsistency between the estimated and ground-truth trajectories. Compared to the point-wise comparison used by RMSE, the Hausdorff distance takes the shape inconsistency of two trajectories into account and is hence more perceptually consistent. Experimental results show that the multi-channel feature sets outperform, or perform comparably to, the single gray level channel feature sets examined in this study. Particularly, the multi-channel feature set that uses integral channels, i.e., ICIMGP (Integral Channel Image Patches), outperforms two state-of-the-art feature sets: SIFT (Scale Invariant Feature Transform) and SURF (Speed Up Robust Features). Besides, ICIMGP performs better than the two multi-channel feature sets that are designed based on derivative channels and gradient channels respectively. These promising results are attributed to the fact that the multi-channel features encode richer image characteristics than their single gray level channel counterparts.
C1 [Dong, Xingshuai; He, Bo] Ocean Univ China, Dept Elect Engn, Qingdao 266071, Peoples R China.
   [Dong, Xinghui] Univ Manchester, Ctr Imaging Sci, Manchester M13 9PT, Lancs, England.
   [Dong, Junyu] Ocean Univ China, Dept Comp Sci, Qingdao, Peoples R China.
C3 Ocean University of China; University of Manchester; Ocean University of
   China
RP He, B (corresponding author), Ocean Univ China, Dept Elect Engn, Qingdao 266071, Peoples R China.; Dong, XH (corresponding author), Univ Manchester, Ctr Imaging Sci, Manchester M13 9PT, Lancs, England.
EM bhe@ouc.edu.cn; xinghui.dong@manchester.ac.uk
FU Natural Science Foundation of China [41176076]; High Technology Research
   and Development Program of China [2014AA093410]
FX This work is partially supported by the Natural Science Foundation of
   China (41176076) and the High Technology Research and Development
   Program of China (2014AA093410).
CR [Anonymous], 2009, P BRIT MACH VIS C
   Barros Pablo, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P403, DOI 10.1007/978-3-319-11179-7_51
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cartwright J. H., 1992, International Journal of Bifurcation and Chaos, V2, P427
   Cheng Y, 2006, IEEE ROBOT AUTOM MAG, V13, P54, DOI 10.1109/MRA.2006.1638016
   Corke P, 2007, INT J ROBOT RES, V26, P519, DOI 10.1177/0278364907079279
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dong XH, 2015, ASIAPAC SIGN INFO PR, P663, DOI 10.1109/APSIPA.2015.7415353
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hu JS, 2014, IEEE INT CONF ROBOT, P3963, DOI 10.1109/ICRA.2014.6907434
   Kitt B, 2010, IEEE INT VEH SYM, P486, DOI 10.1109/IVS.2010.5548123
   Li MY, 2012, IEEE INT CONF ROBOT, P828, DOI 10.1109/ICRA.2012.6225229
   Liu BB, 2005, IEEE INT CONF ROBOT, P4703
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Nistér D, 2004, PROC CVPR IEEE, P652
   Piniés P, 2007, IEEE INT CONF ROBOT, P2797, DOI 10.1109/ROBOT.2007.363895
   Rodriguez D., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P156, DOI 10.1109/MFI.2012.6343049
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233
   Shen SJ, 2015, IEEE INT CONF ROBOT, P5303, DOI 10.1109/ICRA.2015.7139939
   Sirtkaya S, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P219
   Sobel  I., 1968, STANF ART INT PROJ
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
NR 35
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11975
EP 12003
DI 10.1007/s11042-016-3927-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000046
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Huang, TC
   Huang, YM
AF Huang, Tien-Chi
   Huang, Yong-Ming
TI Where are my cooperative learning companions: designing an intelligent
   recommendation mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer supported cooperative learning; Learning companion;
   Recommendation mechanism; Genetic algorithm
ID ENHANCED GENETIC APPROACH; SYSTEM; WEB
AB Computer supported cooperative learning (CSCL) has attained considerable attention in recent years, but most CSCL systems do not consider ways of supporting learners in finding appropriate learning companions. In this study, we propose an intelligent learning companion recommendation mechanism (ILCRM) to deal with this problem. Specifically, ILCRM comprises three agents: (i) a candidate retrieval agent (CRA), (ii) a candidate evaluation agent (CEA), and (iii) a GA-based learning companion composition agent (GLCCA). The CRA and CEA are used to search a series of learning companion candidates based on two criteria (expertise level and participation level), and the GLCCA is employed to compose an appropriate cooperative group in which group members could be able to help learners solve the problems they face. The experimental results show that the proposed approach obtains a near optimal learning companion recommendation, has a significantly low computational cost, and satisfies the specified demands.
C1 [Huang, Tien-Chi] Natl Taichung Inst Technol, Dept Informat Management, Taichung, Taiwan.
   [Huang, Yong-Ming] Chia Nan Univ Pharm & Sci, Dept Appl Informat & Multimedia, Tainan, Taiwan.
C3 Chia Nan University of Pharmacy & Science
RP Huang, YM (corresponding author), Chia Nan Univ Pharm & Sci, Dept Appl Informat & Multimedia, Tainan, Taiwan.
EM ym.huang.tw@gmail.com
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [MOST 103-2511-S-025-001-MY3, 103-2511-S-041-002-MY3]
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China, Taiwan, for financially supporting this
   research under Contract No. MOST 103-2511-S-025-001-MY3 and
   103-2511-S-041-002-MY3.
CR Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   Baker M, 1997, J COMPUT ASSIST LEAR, V13, P175, DOI 10.1046/j.1365-2729.1997.00019.x
   Chang TY, 2009, EXPERT SYST APPL, V36, P8342, DOI 10.1016/j.eswa.2008.10.050
   Chen CC, 2015, MULTIMEDIA SYST, V21, P61, DOI [10.1007/978-3-642-36620-8_1, 10.1007/s00530-013-0348-7]
   Chen CC, 2012, COMPUT EDUC, V59, P873, DOI 10.1016/j.compedu.2012.04.003
   Chen HC, 2012, 2012 IEEE FOURTH INTERNATIONAL CONFERENCE ON TECHNOLOGY FOR EDUCATION (T4E), P160, DOI 10.1109/T4E.2012.36
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   English S, 1999, J COMPUT ASSIST LEAR, V15, P2, DOI 10.1046/j.1365-2729.1999.151071.x
   Falkenauer E., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P776, DOI 10.1109/CEC.1999.782011
   Gao L, 2008, P 4 INT C WIR COMM N, P2
   HELLER P, 1992, AM J PHYS, V60, P637, DOI 10.1119/1.17118
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Hsu S, 2004, TEACH TEACH EDUC, V20, P681, DOI 10.1016/j.tate.2004.07.001
   Huang CJ, 2008, EDUC TECHNOL SOC, V11, P139
   Huang TC, 2008, EXPERT SYST APPL, V35, P2113, DOI 10.1016/j.eswa.2007.09.039
   Huang TC, 2013, EDUC TECHNOL SOC, V16, P79
   Huang YM, 2012, EDUC TECHNOL SOC, V15, P150
   Huang YM, 2015, BRIT J EDUC TECHNOL, V46, P864, DOI 10.1111/bjet.12182
   Huang YM, 2015, BRIT J EDUC TECHNOL, V46, P437, DOI 10.1111/bjet.12147
   Hwang GJ, 2008, EDUC TECHNOL SOC, V11, P148
   Hwang GJ, 2008, COMPUT EDUC, V51, P337, DOI 10.1016/j.compedu.2007.05.014
   Hwang JP, 2012, J INTERNET TECHNOL, V13, P817
   Johnson D.W., 1991, Cooperation in the classroom
   Johnson DW, 1999, THEOR PRACT, V38, P67, DOI 10.1080/00405849909543834
   Jonassen D., 2000, COMPUTERS MINDTOOLS, V2nd
   Kim KJ, 2008, EXPERT SYST APPL, V34, P1200, DOI 10.1016/j.eswa.2006.12.025
   Liang TH, 2014, EDUC TECHNOL SOC, V17, P218
   Lin KC, 2013, LIBR HI TECH, V31, P294, DOI 10.1108/07378831311329068
   MILLER BL, 1995, 95006 ILLIGAL U ILL
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sheremetov L, 2002, COMPUT EDUC, V39, P161, DOI 10.1016/S0360-1315(02)00030-1
   Singh B, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-13
   Sun CT, 1996, IEEE T EDUC, V39, P357, DOI 10.1109/13.538759
   SYSWERDA G, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P2
   Thalemann S, 2004, P 26 ANN M COGN SCI
NR 36
TC 2
Z9 2
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11547
EP 11565
DI 10.1007/s11042-015-2678-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000025
DA 2024-07-18
ER

PT J
AU Otani, M
   Nakashima, Y
   Sato, T
   Yokoya, N
AF Otani, Mayu
   Nakashima, Yuta
   Sato, Tomokazu
   Yokoya, Naokazu
TI Video summarization using textual descriptions for authoring video blogs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-based video summarization; Video skimming; User study
ID SALIENCY
AB Authoring video blogs requires a video editing process, which is cumbersome for ordinary users. Video summarization can automate this process by extracting important segments from original videos. Because bloggers typically have certain stories for their blog posts, video summaries of a blog post should take the author's intentions into account. However, most prior works address video summarization by mining patterns from the original videos without considering the blog author's intentions. To generate a video summary that reflects the blog author's intention, we focus on supporting texts in video blog posts and present a text-based method, in which the supporting text serves as a prior to the video summary. Given video and text that describe scenes of interest, our method segments videos and assigns to each video segment its priority in the summary based on its relevance to the input text. Our method then selects a subset of segments with content that is similar to the input text. Accordingly, our method produces different video summaries from the same set of videos, depending on the input text. We evaluated summaries generated from both blog viewers' and authors' perspectives in a user study. Experimental results demonstrate the advantages to the proposed text-based method for video blog authoring.
C1 [Otani, Mayu; Nakashima, Yuta; Sato, Tomokazu; Yokoya, Naokazu] Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Otani, M (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara 6300192, Japan.
EM otani.mayu.ob9@is.naist.jp
RI Nakashima, Yuta/Y-6218-2019
OI Nakashima, Yuta/0000-0001-8000-3567; Otani, Mayu/0000-0001-9923-2669
FU Japan Society for the Promotion of Science (JSPS) [25730115, 25540086,
   16K16086]; Grants-in-Aid for Scientific Research [25540086, 16K16086,
   25730115] Funding Source: KAKEN
FX This work was partially supported by Grants-in-Aid for Scientific
   Research No. 25730115, No. 25540086 and Young Scientists (B) No.
   16K16086 from the Japan Society for the Promotion of Science (JSPS).
CR Aizawa K, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P398, DOI 10.1109/ICIP.2001.958135
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2011, ACM T MULTIM COMPUT, DOI DOI 10.1145/2043612.2043613
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2010, P 18 ACM INT C MULTI
   [Anonymous], 2014, ADV NEURAL INFORM PR
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Girshick R., 2014, P IEEE CVPR
   Gong BQ, 2014, ADV NEUR IN, V27
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Hu YT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1107, DOI 10.1145/2733373.2806293
   Huang CR, 2008, IEEE T MULTIMEDIA, V10, P1097, DOI 10.1109/TMM.2008.2001374
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Laganiere R, 2008, P ACM TRECVID VID SU, P144
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li YS, 2010, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE 2010, VOL 1: CODES AND STANDARDS, P851, DOI 10.1145/1873951.1874095
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   McDonald R, 2007, LECT NOTES COMPUT SC, V4425, P557
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Nakashima Y, 2013, IEEE IMAGE PROC, P191, DOI 10.1109/ICIP.2013.6738040
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Nguyen C., 2012, SIGCHI C HUMAN FACTO, V19, P3
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Takamura Hiroya., 2009, Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, P781
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
NR 42
TC 11
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12097
EP 12115
DI 10.1007/s11042-016-4061-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000053
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, H
   Wang, HX
   Sun, XM
   Qian, Q
AF Wang, Huan
   Wang, Hong-Xia
   Sun, Xing-Ming
   Qian, Qing
TI A passive authentication scheme for copy-move forgery based on package
   clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Passive authentication; Feature extraction; Package
   clustering
AB Copy-move forgery as one of popular methods is widely used to tamper digital images. Passive authentication is extensively used to detect the copy-move forgery images. This paper proposes a passive authentication scheme for copy-move forgery based on the discrete cosine transform (DCT) and the package clustering algorithm. The copy regions and paste regions can be automatically detected in doctored digital images. This scheme works by first applying the DCT to small fixed image blocks to obtain their features and the size of feature vectors are reduced. Moreover, the package clustering algorithm is applied to replace the general lexicographic order technologies to improve the detection precision. The similar blocks can be found by comparing the feature vectors in each package. The experimental results represent that the proposed scheme can locate irregular and meaningful tampered regions and multiply duplicated regions in a suspicious image. The duplicated regions can also be located in digital images that are distorted by adding white Gaussian noise, Gaussian blurring and their mixed operations.
C1 [Wang, Huan; Wang, Hong-Xia; Qian, Qing] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Sun, Xing-Ming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Southwest Jiaotong University; Nanjing University of Information Science
   & Technology
RP Wang, HX (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM hxwang@home.swjtu.edu.cn; ideahuan@163.com; sunnudt@163.com;
   qianqing_swjtu@163.com
RI Sun, Xingming/AAD-1866-2019; Wang, Hongxia/AAE-2135-2022
FU National Natural Science Foundation of China (NSFC) [U1536110, 61373180]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under the grant Nos. U1536110, 61373180.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], TR2003515 DARTM COLL
   Beste U, 2015, INFORM SCI SYSTEMS, V363, P127
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Chang, 2004, TECH REP
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li Kang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2419, DOI 10.1109/CISP.2010.5648249
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Manu VT, 2016, ADV INTELL SYST COMP, V425, P645, DOI 10.1007/978-3-319-28658-7_55
   Mishra A., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252363
   Oommen RS, 2016, ADV INTELL SYST COMP, V425, P559, DOI 10.1007/978-3-319-28658-7_47
   Sebe N, 2007, BLIND PASSIVE MADIA, V4577, P57
   Shabnam MS, 2015, J FORENSIC SCI
   Sunil K., 2014, Ict and critical infrastructure: Proceedings of the 48th annual convention of computer society of india-vol, Vii, P577, DOI DOI 10.1007/978-3-319-03095-1_62
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Yu J, 2015, INTERNATIONAL CONFERENCE ON COMPUTER NETWORKS AND INFORMATION SECURITY (CNIS 2015), P73
   Zhou L, 2007, P 1 KES INT S AG MUL
   Zimba M., 2011, International Journal of Digital Content Technology and its Applications, V5, P251
NR 23
TC 10
Z9 10
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12627
EP 12644
DI 10.1007/s11042-016-3687-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200020
DA 2024-07-18
ER

PT J
AU Alkawaz, MH
   Basori, AH
   Hashim, SZM
AF Alkawaz, Mohammed Hazim
   Basori, Ahmad Hoirul
   Hashim, Siti Zaiton Mohd
TI Oxygenation absorption and light scattering driven facial animation of
   natural virtual human
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Realistic facial skin color; Oxygenation; Shadowing; Unity 3D; Epidermis
   and dermis
ID HUMAN SKIN; MELANIN CONTENT; PIGMENTATION
AB The color of skin is one of the key indicators of bodily change that affect facial expressions. The skin colour tenacity is majorly determined by the light effect and concentration from the chromophores inside skin and haemoglobin oxygenation in the blood. We did an extension work of previous researcher: Donner and Jensen approach to develop a realistic textured 3D facial animation model. Both surface and subsurface effect of light with the skin is considered. Six model parameters are used to control the amount of oxygenation, de-oxygenation, hemoglobin, melanin, oil and blend factor for different types of melanin in the skin in creating a perfect match. Pulse Oximetry and 3D skin analyzer are used to determine the correlation between blood oxygenation and basic natural emotional expressions. The multi-pole method for layered materials is applied to calculate the spectral diffusion profiles of two-layered skin in simulating the subsurface scattering. Torrance-Sparrow bidirectional reflectance distribution function (BRDF) is employed to simulate the light interaction with an oily skin surface stratum. Unity3D is exploited for shading programming to implement advanced real-time rendering. Five basic natural human facial emotive appearance such as angry, happy, neutral, sad and fear are simulated for Asian, European and Middle East male and female. It is suggested that our tailored approach may be helpful for the development of virtual reality and serious games application.
C1 [Alkawaz, Mohammed Hazim] Management & Sci Univ, Fac Informat Sci & Engn, B9,Seksyen 13, Shah Alam 40100, Selangor, Malaysia.
   [Basori, Ahmad Hoirul] King Abdulaziz Univ, Fac Comp & Informat Technol Rabigh, Dept Informat Technol, Jeddah, Saudi Arabia.
   [Alkawaz, Mohammed Hazim; Hashim, Siti Zaiton Mohd] Univ Teknol Malaysia, UTM Big Data Ctr, Johor Baharu 81310, Johor, Malaysia.
C3 Management Science University; King Abdulaziz University; Universiti
   Teknologi Malaysia
RP Alkawaz, MH (corresponding author), Management & Sci Univ, Fac Informat Sci & Engn, B9,Seksyen 13, Shah Alam 40100, Selangor, Malaysia.; Alkawaz, MH (corresponding author), Univ Teknol Malaysia, UTM Big Data Ctr, Johor Baharu 81310, Johor, Malaysia.
EM mohammed.alkawaz@yahoo.com
RI Basori, Ahmad Hoirul/F-5778-2011; Hashim, Siti Zaiton
   Mohd/AAE-5401-2020; Alkawaz, Mohammed Hazim/KOC-6843-2024
OI Basori, Ahmad Hoirul/0000-0001-9684-490X; Alkawaz, Mohammed
   Hazim/0000-0001-9715-8477
CR Alaluf S, 2002, PIGM CELL RES, V15, P112, DOI 10.1034/j.1600-0749.2002.1o071.x
   Alaluf S, 2001, PIGM CELL RES, V14, P337, DOI 10.1034/j.1600-0749.2001.140505.x
   Alkawaz MH, 2014, SCI WORLD J, V2014, P9
   Anderson R, 1981, J INVESTIGAT DERMATO, V77
   Apostolakis KC, 2015, LECT NOTES COMPUT SC, V9254, P371, DOI 10.1007/978-3-319-22888-4_27
   Bashkatov AN, 2005, J PHYS D APPL PHYS, V38, P2543, DOI 10.1088/0022-3727/38/15/004
   Bhat VS, 2013, FACE DETECTION SYSTE
   Chen TF, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2701416
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Decaudin P., 2006, Computer Graphics Forum
   Donald E, 1999, EGANS FUNDAMENTALS R
   Donner C, 2008, ACM T GRAPH TOG
   Donner C, 2005, ACM T GRAPH TOG
   Donner C., 2006, P 17 EUROGRAPHICS C, P409
   Faraway JJ, 2004, STAT COMPUT, V14, P357, DOI 10.1023/B:STCO.0000039485.52129.ed
   Fiske S. T., 2013, Social cognition: From brains to culture, DOI DOI 10.1016/B978-012088566-4/50012-X
   Ghosh A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409092
   Hanrahan P., 1993, P 20 ANN C COMP GRAP
   Hansen MF, 2010, COMPUT VIS IMAGE UND, V114, P942, DOI 10.1016/j.cviu.2010.03.001
   Hery C, 2003, SIGGRAPH 2005 DIGITA, V14
   Hudson DM, 2006, TOP SHELF
   Igarashi T., 2005, APPEARANCE HUMAN SKI
   Igarashi T, 2007, FOUND TRENDS COMPUT, V3, P1, DOI 10.1561/0600000013
   Iglesias-Guitian JA, 2015, COMPUTER GRAPHICS FO
   Ito S, 2003, PIGM CELL RES, V16, P523, DOI 10.1034/j.1600-0749.2003.00072.x
   Jacques S. L., 1996, OSA Trends in Optics and Photonics on Advances in Optical Imaging and Photon Migration. Vol.2 From the Topical Meeting, P364
   Jacques S.L., 1998, OREGON MED LASER CTR, V1, P1
   JACQUES SL, 1991, PHOTOCHEM PHOTOBIOL, V53, P769, DOI 10.1111/j.1751-1097.1991.tb09891.x
   Jensen HW, 2001, P 28 ANN C COMP GRAP
   Jensen HW, 2002, ACM T GRAPH TOG
   Jimenez J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866167
   Johns DPPR, 2003, MCGRAW HILLS POCKET
   Jue T., 2013, Application of near infrared spectroscopy in biomedicine
   KELLEHER JF, 1989, J CLIN MONITOR, V5, P37, DOI 10.1007/BF01618369
   Klehm O., 2015, COMPUTER GRAPHICS FO
   Krishnaswamy Aravind., 2004, Computer Graphics Forum
   Lauterbach C, 2010, COMPUT GRAPH FORUM
   Li CC, 2014, MAT CHEM A
   Litscher G, 2013, EVIDENCE BASED COMPL
   Ma TY, 2014, ANGEW CHEM INT EDIT, V53, P7281, DOI 10.1002/anie.201403946
   Magnenat-Thalmann N, 2015, CONTEXT AWARE HUMAN, V2015
   Marschner SR, 1999, SPRING EUROGRAP, P131
   Martin L., 1999, ALL YOU REALLY NEED, V2nd
   Meglinski IV, 2002, PHYSIOL MEAS, V23, P741, DOI 10.1088/0967-3334/23/4/312
   PAYNE JP, 1986, PULSE OXIMETRY
   Rabalais NN, 2010, BIOGEOSCIENCES, V7, P585, DOI 10.5194/bg-7-585-2010
   Ramirez G, 2014, P IEEE C COMP VIS PA
   Rowat AM, 2006, CEREBROVASC DIS, V21, P166, DOI 10.1159/000090528
   SAIDI IS, 1995, APPL OPTICS, V34, P7410, DOI 10.1364/AO.34.007410
   Saneiro M, 2014, SCI WORLD J, DOI 10.1155/2014/484873
   Sarna T., 1998, The Pigmentary System: Physiology and Pathophysiology, VSecond, P311
   Spott T, 1998, BIOS EUR 97 INT SOC, V97
   Stam J, 2001, SPRING EUROGRAP, P39
   Stamatas GN, 2004, PIGM CELL RES, V17, P618, DOI 10.1111/j.1600-0749.2004.00204.x
   Stephen ID, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005083
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tayal Y, 2012, INT J SCI RES PUBL, V2
   Tsumura N, 1999, J OPT SOC AM A, V16, P2169, DOI 10.1364/JOSAA.16.002169
   Tuchin Valerii Viktorovich., 2007, Tissue optics: light scattering methods and instruments for medical diagnosis, V642
   Wakamatsu K, 2006, PIGM CELL RES, V19, P154, DOI 10.1111/j.1600-0749.2006.00293.x
   Weyrich T, 2006, ACM T GRAPH TOG
   Zhang J, 2010, BIOGEOSCIENCES, V7, P1443, DOI 10.5194/bg-7-1443-2010
   Zhou Z, 2016, J OROFACIAL ORTHOPED, V1-8
NR 63
TC 5
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9587
EP 9623
DI 10.1007/s11042-016-3564-2
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300022
DA 2024-07-18
ER

PT J
AU Chu, WT
   Chou, YC
AF Chu, Wei-Ta
   Chou, Yung-Chieh
TI On broadcasted game video analysis: event detection, highlight
   detection, and highlight forecast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broadcasted computer game video; Event detection; Highlight detection;
   Highlight forecast; Genetic algorithm; Linear exponential smoothing
ID CONSUMER VIDEOS
AB Efficient access to broadcasted computer game videos is urgently demanded due to the emergence of live streaming platforms. The popularity of game video streaming builds a big market showing commercial potentials and arising many technical challenges. In this work we facilitate efficient access from two aspects: event detection and highlight detection. By recognizing designated text displayed on screen when important events occur, we associate game events with time stamps, and accordingly develop an interface to facilitate direct access. For highlight detection, we jointly consider visual features, event features, and viewer's behavior to construct two highlight models based on the psychophysiological approach and the data-driven approach, respectively. The concatenated highlights then enable compact game video presentation. To facilitate adaptive live streaming, a novel highlight forecast model is built to predict whether there will be a highlight in the next seconds, so that the streaming system can allocate more resource for more important segments on the fly. Comprehensive experiments based on various experimental settings demonstrate effectiveness of the proposed methods. We believe that this work is one of the early attempts on analyzing broadcasted computer game videos from the perspective of multimedia content analysis.
C1 [Chu, Wei-Ta] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
   [Chou, Yung-Chieh] Natl Chung Cheng Univ, Chiayi, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM wtchu@cs.ccu.edu.tw
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
CR Brown R.G., 1956, Exponential Smoothing for Predicting Demand
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CM, 2014, IEEE IMAGE PROC, P961, DOI 10.1109/ICIP.2014.7025193
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Chiu CY, 2012, IEEE T CIRC SYST VID, V22, P999, DOI 10.1109/TCSVT.2012.2189478
   Chu WT, 2005, MULTIMEDIA SYST, V10, P570, DOI 10.1007/s00530-005-0183-6
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dang CT, 2014, IEEE T IMAGE PROCESS, V23, P2704, DOI 10.1109/TIP.2014.2320814
   Douglass J, 2009, P WROKSH MED ARTS SC
   Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fan-Chiang T-Y, 2015, P INT WORKSH NETW SY, P1
   Hamilton WA, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1315, DOI 10.1145/2556288.2557048
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373
   Kaytoue M., 2012, Proceedings of the 21st International Conference Companion on World Wide Web-WWW'12 Companion, P1181, DOI [DOI 10.1145/2187980.2188259, 10.1145/2187980.2188259]
   Kirsh David., 2011, Proceedings of the 33rd Annual Conference of the Cognitive Science Society, P687
   Lienhart R, 1998, PROC SPIE, V3656, P290, DOI 10.1117/12.333848
   Lu T, 2014, INT C PATT RECOG, P756, DOI 10.1109/ICPR.2014.140
   Nguyen N, 2014, IEEE INT WORKSH MULT
   Pires K, 2014, DASH TWITCH ADAPTIVE, P13
   Pires K., 2015, P 6 ACM MULT SYST C, P225, DOI DOI 10.1145/2713168.2713195
   Riegler Michael, 2014, P ACMM INT C MULT RE, V534, P534, DOI [10.1145/2578726.2582621, DOI 10.1145/2578726.2582621]
   Rioult F, 2014, AASRI PROC, V8, P82, DOI 10.1016/j.aasri.2014.08.014
   Stensland HK, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2541011
   Sulser Fabio., 2014, Proceedings of the 2014 international ACM workshop on crowd-sourcing for multimedia, P63, DOI DOI 10.1145/2660114
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P330, DOI 10.1109/TMM.2010.2046364
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhang C., 2015, ACM Workshop on Network and Operating Systems Support for Digital Audio and Video, P55, DOI DOI 10.1145/2736084.2736091
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
NR 34
TC 12
Z9 13
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9735
EP 9758
DI 10.1007/s11042-016-3577-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300028
DA 2024-07-18
ER

PT J
AU Hsu, CH
   Wu, YL
   Cheng, WH
   Chen, YJ
   Hua, KL
AF Hsu, Che-Hao
   Wu, Yi-Leh
   Cheng, Weng-Huang
   Chen, Yu-Jen
   Hua, Kai-Lung
TI HoloTube: a low-cost portable 360-degree interactive autostereoscopic
   display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cylindrical display 360-degree display; Omnidirectional autostereoscopic
   display; Thick barrier sheet
AB This paper proposes a novel, low cost, and portable 360-degree cylindrical interactive autostereoscopic 3D display system. The proposed system consists of three parts: the optical architecture (for back-projecting image correctly on the cylindrical screen), the projection image transformation workflow (for image rectifying and generating multi-view images), and the 360-degree motion detection module (for identifying viewers' locations and providing the corresponding views). Based on the proposed design, only one commercial micro projector is employed for the proposed cylindrical screen. The proposed display offers great depth perception (stereoacuity) with a special designed thick barrier sheet attached to the screen. The viewers are not required to wear special glasses and within appropriate range (< 5m) the viewers can view the screen at any distance and angle. The user study verified that the proposed display offers satisfactory depth perception (binocular parallax, shading distribution, and linear perspective) for various viewing distances and angles without noticeable discomfort. The production cost of the current prototype is about USD$ 300. With mass production, the unit cost is expected to decline to within USD$60. The proposed display system has the advantages of ease of use, low production cost, high portability and mobility. The proposed system is suitable for application such as museum virtual exhibition, remote meeting, multi-user online game, etc. We believe that the proposed system is very promising for the market of low-cost portable 360-degree interactive autosereoscopic displays.
C1 [Hsu, Che-Hao; Wu, Yi-Leh; Hua, Kai-Lung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
   [Cheng, Weng-Huang] Acad Sinica, Res Ctr Informat Technol Innovat CITI, Taipei, Taiwan.
   [Chen, Yu-Jen] MacKay Mem Hosp, Dept Radiat Oncol, Ctr Biomed Dev, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; Academia Sinica -
   Taiwan; Mackay Memorial Hospital
RP Hua, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM hua@mail.ntust.edu.tw
RI Cheng, Wen-Huang/AAK-2774-2020
OI Hua, Kai-Lung/0000-0002-7735-243X
FU NTUST-MMH Joint Research Program [NTUST-MMH-No 103-02]; Ministry of
   Science and Technology [104-2221-E-011-091-MY2, 103-2622-E-011-020-CC3]
FX This work was supported in part by the NTUST-MMH Joint Research Program
   (NTUST-MMH-No 103-02) and the Ministry of Science and Technology
   (104-2221-E-011-091-MY2, 103-2622-E-011-020-CC3).
CR [Anonymous], 2014, QUBE LED 3D LED MATR
   [Anonymous], 2014, BARCO RP 360 360 DEG
   [Anonymous], 2014, DICOLOR CYLINDRICAL
   Bahr D, 1997, P SOC PHOTO-OPT INS, V3101, P202, DOI 10.1117/12.281281
   Benko H, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P77, DOI 10.1145/1449715.1449729
   Beyer G, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1021
   Butler A., 2011, UIST '11 Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology, P569
   Cheng YS, 2010, OPT EXPRESS, V18, P14012, DOI 10.1364/OE.18.014012
   Erdenebat M-U, 2011, P SOC PHOTO-OPT INS, V7863
   Erdenebat MU, 2014, OPT LETT, V39, P2326, DOI 10.1364/OL.39.002326
   Favalora GE, 2002, P SOC PHOTO-OPT INS, V4712, P300, DOI 10.1117/12.480930
   Ito K, 2010, ACM SIGGRAPH EMERGIN
   Jones A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276427
   Jung K, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.2.027402
   Kawanishi T, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P85
   Kim KS, 2015, SPIE OPTO
   Kimura H, 2006, ACM SIGGRAPH EMERGIN
   Kimura H, 2011, ACM SIGGRAPH EMERGIN
   Langhans K, 2009, P SOC PHOTO-OPT INS, V7237
   LEWIS JD, 1971, IEEE T ELECTRON DEV, VED18, P724, DOI 10.1109/T-ED.1971.17273
   Lin J., 2009, Proc. MM, P253, DOI DOI 10.1145/1631272.1631309
   Liu SM, 2011, IEEE T CONSUM ELECTR, V57, P289, DOI 10.1109/TCE.2011.5955158
   Miyazaki D, 2012, P SOC PHOTO-OPT INS, V8288
   Otsuka R, 2006, IEEE T VIS COMPUT GR, V12, P178, DOI 10.1109/TVCG.2006.38
   Otsuka R, 2007, ACM SIGGRAPH
   Park G, 2012, P SOC PHOTO-OPT INS, V8280
   Reichelt S, 2010, P SOC PHOTO-OPT INS, V7690
   Shih PY, 2014, MULTIMED TOOLS APPL, V73, P417, DOI 10.1007/s11042-013-1609-3
   Soltan P, 1997, P SOC PHOTO-OPT INS, V3091, P96, DOI 10.1117/12.271781
   Tanaka K, 2004, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VR.2004.1310056
   Tsai HC, 2014, MULTIMED TOOLS APPL, V73, P291, DOI 10.1007/s11042-013-1606-6
   Xing Jianfang., 2010, 2010 Symposium on Photonics and Optoelectronics, P1
   Yabu H, 2015, IS T SPIE ELECT IMAG
   Yagi A, 2011, SIGGRAPH ASIA 2011 E
   Yamaguchi T, 2007, DIGITAL HOLOGRAPHY 3
   Yan CJ, 2011, OPT ENG, V50, DOI 10.1117/1.3552664
   Yendo T, 2010, J VIS COMMUN IMAGE R, V21, P586, DOI 10.1016/j.jvcir.2009.10.004
   Yoshida S., 2011, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video (3DTV-CON), 2011, P1
   Zhao D, 2015, OPT EXPRESS, V23, P9812, DOI 10.1364/OE.23.009812
NR 39
TC 5
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9099
EP 9132
DI 10.1007/s11042-016-3502-3
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300001
DA 2024-07-18
ER

PT J
AU Pigeau, A
AF Pigeau, Antoine
TI Life Gallery: event detection in a personal media collection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection algorithm; Personal multimedia collection; Mobile
   application; Benchmark
AB Usage of camera-equipped mobile devices raises the need for automatically organizing large personal media collections. Event detection algorithms have been proposed in the literature to tackle this problem but a shortcoming of these studies resides in the lack of comparison of the different solutions. The goal of this work is then to provide a set of tools for the assessment of an event detection method. Our first contribution is our prototype Life Gallery, which aims to retrieve metadata of a personal media collection in order to facilitate the building of a benchmark. Our second contribution is an event detection algorithm based on successive refinements of an initial temporal partition. Our solution uses a simple algorithm that regroups consecutive similar media or split groups with dissimilar media. The choice to provide a basic solution is to compare in a future work our results with more complex solutions, in order to really assess the benefit of these latter. Finally, our third contribution is a benchmark of 6 different users' collections obtained thanks to our Life Gallery application.
C1 [Pigeau, Antoine] CNRS, UMR 6241, LINA, DUKe Res Grp, 2 Rue Houssiniere, F-44322 Nantes 03, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Pigeau, A (corresponding author), CNRS, UMR 6241, LINA, DUKe Res Grp, 2 Rue Houssiniere, F-44322 Nantes 03, France.
EM antoine.pigeau@univ-nantes.fr
CR [Anonymous], MSRTR200217
   [Anonymous], P ACM MM
   [Anonymous], 2000, WORKSHOP ARTIFICIAL
   Barla A, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P566, DOI 10.1109/ICIAP.2003.1234110
   Carvalho RF, 2009, MULTIMED TOOLS APPL, V42, P73, DOI 10.1007/s11042-008-0249-5
   Chen CF, 2006, LECT NOTES COMPUT SC, V3936, P362
   Chen CF, 2008, INT WORK CONTENT MUL, P518
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Das M, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P116, DOI 10.1109/ICSC.2009.36
   Ferre S, 2007, CAMELIS ORG BROWSING, V331
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Huang A., 2008, NZCSRSC 2008
   Jaffe Alexander., 2006, P INT C WORLD WIDE W, P853
   Lacerda YA, 2008, IEEE INT SYM MULTIM, P258, DOI 10.1109/ISM.2008.81
   Lowe DG, 1999, OBJEC RECOGNITION LO, V2
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   Naaman M., 2004, P 12 ANN ACM INT C M, P196
   Naaman M, 2008, IEEE MULTIMEDIA, V15, P34, DOI 10.1109/MMUL.2008.69
   Pigeau A., 2005, 13th Annual ACM International Conference on Multimedia, P141, DOI 10.1145/1101149.1101170
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Vega-Pons S, 2011, INT J PATTERN RECOGN, V25, P337, DOI 10.1142/S0218001411008683
   Viana W, 2007, LECT NOTES COMPUT SC, V4857, P187
NR 23
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9713
EP 9734
DI 10.1007/s11042-016-3576-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300027
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, S
   Zhang, Y
   Su, WC
   Zhang, MY
   Tan, GZ
   Zhang, Q
   Zhou, DS
   Wei, XP
AF Yang, Xin
   Li, Shuai
   Zhang, Yong
   Su, Wanchao
   Zhang, Mingyue
   Tan, Guozhen
   Zhang, Qiang
   Zhou, Dongsheng
   Wei, Xiaopeng
TI Interactive traffic simulation model with learned local parameters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic simulation; Genetic algorithm; Real-virtual interaction
AB In this paper, we present a parameter learning method to reflect the rapidly changing behaviors in the traffic flow simulation process, in which we insert virtual vehicles into the real trajectory data. We come up with a real-virtual interaction model and then we use genetic algorithm to learn some parameters in the model with the purpose to get some specific driving characteristics. Then we propose a real-virtual interaction system to vividly simulate the various interaction behaviors between the real vehicles and the virtual ones. Our results are compared to the existing methods to prove the effectiveness of our presented method.
C1 [Yang, Xin] Dalian Univ Technol, Dept Comp Sci, Dalian, Peoples R China.
   [Li, Shuai; Zhang, Yong; Su, Wanchao; Zhang, Mingyue; Tan, Guozhen; Wei, Xiaopeng] Dalian Univ Technol, Dalian, Peoples R China.
   [Zhang, Qiang] Dalian Univ, Ctr Adv Design Technol, Dalian, Peoples R China.
   [Zhou, Dongsheng] Dalian Univ, Minist Educ, Key Lab Adv Design & Intelligent Comp, Dalian, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University; Dalian University
RP Yang, X (corresponding author), Dalian Univ Technol, Dept Comp Sci, Dalian, Peoples R China.
EM xinyang@zju.edu.cn
RI zhang, qiang/HZJ-9551-2023; jiang, lei/IWE-1124-2023; wei,
   xiao/ISB-6027-2023; Zhang, Qiang/A-3698-2010
FU NSFC [61300084, 61370141, 61300015, 91546123, 11372067, 61425002];
   National High-tech R&D Program of China [2015AA7046207]; Open Project
   Program of the State Key Lab of CADCG [A1511]; Zhejiang University, and
   the Fundamental Research Funds for the Central Universities [DUT15QY41]
FX The authors wish to acknowledge the support of NSFC grant 61300084,
   61370141, 61300015, 91546123, 11372067, and 61425002, National High-tech
   R&D Program of China (Grant No. 2015AA7046207), the Open Project Program
   of the State Key Lab of CAD&CG (Grant No. A1511), Zhejiang University,
   and the Fundamental Research Funds for the Central Universities (Grant
   No. DUT15QY41).
CR [Anonymous], 2008, NGSIM NEXT GEN SIM P
   Aw A, 2000, SIAM J APPL MATH, V60, P916, DOI 10.1137/S0036139997332099
   BANDO M, 1995, PHYS REV E, V51, P1035, DOI 10.1103/PhysRevE.51.1035
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Cheu RL, 1998, J TRANSP ENG-ASCE, V124, P526, DOI 10.1061/(ASCE)0733-947X(1998)124:6(526)
   GAZIS DC, 1961, OPER RES, V9, P545, DOI 10.1287/opre.9.4.545
   Gerlough D.L., 1955, Simulation of Freeway Traffic on a General-purpose Discrete Variable Computer
   Hourdakis J, 2003, TRANSPORT RES REC, P130
   Kesting A., 2009, ARXIV09123613
   Kesting A, 2008, TRAFFIC GRANULAR FLO, V07, P117
   Kesting A, 2008, TRANSPORT RES REC, P148, DOI 10.3141/2088-16
   Lighthill MJ, 1955, ATHEORY TRAFFIC FLOW
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   Paris S, 2007, PEDESTRIAN REACTIVE
   Redmill K A., 1999, VATSIM VEHICLE TRAFF
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Treiber M., 2001, Automatisierungstechnik, V49, P478, DOI 10.1524/auto.2001.49.11.478
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
NR 21
TC 1
Z9 1
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9503
EP 9516
DI 10.1007/s11042-016-3560-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300018
DA 2024-07-18
ER

PT J
AU Lei, JJ
   Zhang, CC
   Wu, M
   You, L
   Fan, KF
   Hou, CP
AF Lei, Jianjun
   Zhang, Cuicui
   Wu, Min
   You, Lei
   Fan, Kefeng
   Hou, Chunping
TI A divide-and-conquer hole-filling method for handling disocclusion in
   single-view rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-view rendering; Disocclusion handling; Hole-filling; Depth map;
   3D; Stereoscopic image processing
ID FREE-VIEWPOINT; VIDEO; DIBR
AB Large holes are unavoidably generated in depth image based rendering (DIBR) using a single color image and its associated depth map. Such holes are mainly caused by disocclusion, which occurs around the sharp depth discontinuities in the depth map. We propose a divide-and-conquer hole-filling method which refines the background depth pixels around the sharp depth discontinuities to address the disocclusion problem. Firstly, the disocclusion region is detected according to the degree of depth discontinuity, and the target area is marked as a binary mask. Then, the depth pixels located in the target area are modified by a linear interpolation process, whose pixel values decrease from the foreground depth value to the background depth value. Finally, in order to remove the isolated depth pixels, median filtering is adopted to refine the depth map. In these ways, disocclusion regions in the synthesized view are divided into several small holes after DIBR, and are easily filled by image inpainting. Experimental results demonstrate that the proposed method can effectively improve the quality of the synthesized view subjectively and objectively.
C1 [Lei, Jianjun; Zhang, Cuicui; Wu, Min; You, Lei; Hou, Chunping] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Fan, Kefeng] China Elect Standardizat Inst, Beijing, Peoples R China.
C3 Tianjin University
RP Wu, M (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM wumin_tju@tju.edu.cn
RI Fan, K/GXH-3734-2022; Lei, Jianjun/P-2539-2018; Wu, Min/HNI-5320-2023
OI Wu, Min/0000-0002-3956-0107
FU Natural Science Foundation of China [61271324, 61520106002, 61471262,
   91320201, 61471260]
FX This research was partially supported by the Natural Science Foundation
   of China (Nos. 61271324, 61520106002, 61471262, 91320201, and 61471260).
CR [Anonymous], P IEEE VIS COMM IM P
   [Anonymous], SIGN INF PROC ASS AN
   [Anonymous], P IEEE C IM PROC ICI
   [Anonymous], 2005, JTC1SC29WG11 ISOIEC
   [Anonymous], COMMON TEST CONDITIO
   [Anonymous], JTC1SC29WG11 ISOIEC
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Chen KH, 2015, CIRC SYST SIGNAL PR, V34, P579, DOI 10.1007/s00034-014-9870-x
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Feng YM, 2009, IEEE T CONSUM ELECTR, V55, P2349, DOI 10.1109/TCE.2009.5373809
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Jung SW, 2013, IEEE T IMAGE PROCESS, V22, P3892, DOI 10.1109/TIP.2013.2263150
   Kellnhofer P, 2013, COMPUT GRAPH FORUM, V32, P143, DOI 10.1111/cgf.12160
   Kim HG, 2017, IEEE T CIRC SYST VID, V27, P1435, DOI 10.1109/TCSVT.2016.2515360
   Lee PJ, 2011, IEEE T MULTIMEDIA, V13, P246, DOI 10.1109/TMM.2010.2100372
   Lei JJ, 2015, IEEE T MULTIMEDIA, V17, P457, DOI 10.1109/TMM.2015.2400823
   Loghman M, 2015, MULTIMED TOOLS APPL, V74, P1611, DOI 10.1007/s11042-013-1747-7
   Lu S., 2013, Proceedings of the International Conference on Image Processing, Computer Vision, and Pattern Recognition (IPCV). The Steering Committee of The World Congress in Computer Science, P1
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Oh KJ, 2010, INT J IMAG SYST TECH, V20, P378, DOI 10.1002/ima.20253
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D, 2007, P IEEE INT C COMPUTE, P1
   Solh M, 2012, IEEE J-STSP, V6, P495, DOI 10.1109/JSTSP.2012.2204723
   Tanimoto M., 2008, JTC1SC29WG11 ISOIEC
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang LH, 2015, MULTIMED TOOLS APPL, V74, P9529, DOI 10.1007/s11042-014-2133-9
   Xu XY, 2013, SIGNAL PROCESS-IMAGE, V28, P1023, DOI 10.1016/j.image.2013.04.003
   Xu XY, 2012, INT CONF ACOUST SPEE, P805, DOI 10.1109/ICASSP.2012.6288006
   Yao C, 2014, IEEE T BROADCAST, V60, P394, DOI 10.1109/TBC.2014.2321671
   Zhao Y, 2011, IEEE T BROADCAST, V57, P510, DOI 10.1109/TBC.2011.2120730
NR 32
TC 14
Z9 17
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7661
EP 7676
DI 10.1007/s11042-016-3413-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800004
OA hybrid
DA 2024-07-18
ER

PT J
AU Rosa, REVD
   de Lucena, VF
AF Rosa, Ricardo Erikson V. de S.
   de Lucena, Vicente Ferreira, Jr.
TI Contextualizing and capturing individual user interactions in shared iTV
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Individual user interactions; Contextualized interactions; Interactive
   TV; Second screen; User-media interaction
ID DIGITAL TV; TELEVISION; API; FRAMEWORK; SERVICES; DEVICES; SYSTEM
AB Advances in Interactive TV (iTV) technology have enabled users to actively interact with the TV instead of just passively watching it. Associating the individual user interactions with contextual data (e.g., date, time, current channel, and people around) may reveal important information about user interests regarding the iTV content. However, capturing individual data is a difficult task since it lacks a proper mechanism to identify viewers while using the iTV. In a typical TV environment, a viewer has only a conventional remote control (RC) device being shared by other viewers, which makes it difficult to distinguish the events performed by each user. This paper presents a novel approach that facilitates the capture of contextualized and individualized data while users interact with the iTV content by using mobile devices as second screen interfaces. In contrast with conventional RCs, mobile devices are personal and typically present advanced computing and communication capabilities that makes it possible to distinguish each viewer and allows the capture of individual and contextualized interactions. The data generated in those interactions may be interpreted by specific algorithms becoming useful information for TV service providers (TSPs) enhancing TV-based services, e.g., advertising and personalization. An experimental prototype was developed as a proof of concept for the mechanism proposed in this paper. The prototype consists of an application that allows to capture and contextualize interactions of three iTV related events: channel change, sound volume change, and content evaluation.
C1 [Rosa, Ricardo Erikson V. de S.] Univ Fed Minas Gerais, Grad Program Elect Engn, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
   [de Lucena, Vicente Ferreira, Jr.] Univ Fed Amazonas, PPGEE, PPGI, Manaus, Amazonas, Brazil.
   [de Lucena, Vicente Ferreira, Jr.] Univ Fed Amazonas, CETELI, Manaus, Amazonas, Brazil.
   [de Lucena, Vicente Ferreira, Jr.] UFMG, PPGEE, Manaus, Amazonas, Brazil.
C3 Universidade Federal de Minas Gerais; Universidade Federal de Amazonas;
   Universidade Federal de Amazonas; Universidade Federal de Minas Gerais
RP Rosa, REVD (corresponding author), Univ Fed Minas Gerais, Grad Program Elect Engn, Ave Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
EM ricardoerikson@ufmg.br; vicente@ufam.edu.br
RI Lucena, Vicente/B-4784-2008; de Sena Rosa, Ricardo Erikson
   Veras/ABC-5671-2020
OI Lucena, Vicente/0000-0001-9864-2850; de Sena Rosa, Ricardo Erikson
   Veras/0000-0003-2750-4148
FU Fundacao de Amparo a Pesquisa do Estado do Amazonas (FAPEAM);
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES);
   Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq)
FX This work was developed at Electronics and Information Technology R&D
   Center (CETELI) at the Federal University of Amazonas (UFAM). The
   authors would like to thank the following Brazilian agencies: Fundacao
   de Amparo a Pesquisa do Estado do Amazonas (FAPEAM), Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES), and Conselho
   Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq) for their
   financial support.
CR ABNT, 2007, 1560332007 ABNT NBR
   ABNT, 2008, 1560712008 ABNT NBR
   Abreu Jorge., 2014, Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video, P63, DOI [10.1145/2602299.2602313, DOI 10.1145/2602299.2602313]
   Abreu Jorge., 2013, PROCS 11 EUROPEAN C, P5, DOI DOI 10.1145/2465958.2465970
   Aina T, 2014, 2014 IEEE INT S BROA, P1, DOI [10.1109/BMSB.2014.6873536, DOI 10.1109/BMSB.2014.6873536]
   Alvarez F, 2009, IEEE T BROADCAST, V55, P502, DOI 10.1109/TBC.2008.2012040
   [Anonymous], ACT FIG 2 SCREENS AR
   Cabarcos PA, 2011, IEEE T CONSUM ELECTR, V57, P6, DOI 10.1109/TCE.2011.5735473
   Bambini R, 2012, MULTIMEDIA COMPUT CO, P277
   Basilio SDCA, 2013, P 11 EUR C INT TV VI, P23, DOI [10.1145/2465958.2465977, DOI 10.1145/2465958.2465977]
   Buschmann F., 2007, PATTERN ORIENTED SOF, V4
   Carmona CJ, 2012, EXPERT SYST APPL, V39, P11243, DOI 10.1016/j.eswa.2012.03.046
   Cesar P., 2011, 2011 IEEE Consumer Communications and Networking Conference (CCNC 2011), P347, DOI 10.1109/CCNC.2011.5766487
   Cesar P., 2008, Computers in Entertainment, V6, DOI [10.1145/1350843.1350847, DOI 10.1145/1350843.1350847]
   Courtois C., 2012, P 10 EUR C INT VID E, V11, P153
   Dai LL, 2012, IEEE COMMUN MAG, V50, P150, DOI 10.1109/MCOM.2012.6211500
   de Lucena VF, 2012, IEEE T CONSUM ELECTR, V58, P1077, DOI 10.1109/TCE.2012.6311359
   de Lucena VF, 2009, IEEE T CONSUM ELECTR, V55, P1254, DOI 10.1109/TCE.2009.5277985
   Hellman E., 2013, Android programming: Pushing the limits
   Hwang MC, 2007, IEEE T CONSUM ELECTR, V53, P218, DOI 10.1109/TCE.2007.339528
   Kazienko P, 2007, INFORM SCIENCES, V177, P2269, DOI 10.1016/j.ins.2007.01.002
   Kim J, 2013, MULTIMED TOOLS APPL, V64, P517, DOI 10.1007/s11042-011-0965-0
   Kulesza R, 2012, IEEE INT CONF MULTI, P266, DOI 10.1109/ICMEW.2012.52
   Lai CF, 2011, FUTURE GENER COMP SY, V27, P823, DOI 10.1016/j.future.2010.10.002
   Lee BH, 2012, IEEE T CONSUM ELECTR, V58, P978, DOI 10.1109/TCE.2012.6311345
   Lee S, 2010, IEEE T CONSUM ELECTR, V56, P1034, DOI 10.1109/TCE.2010.5506036
   Lim C, 2014, MULTIMED TOOLS APPL, V73, P1757, DOI 10.1007/s11042-013-1658-7
   Lukic N, 2013, IEEE T CONSUM ELECTR, V59, P875, DOI 10.1109/TCE.2013.6689702
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   Morris S., 2005, Interactive TV Standards: A Guide to MHP, OCAP
   Pijetlovic S, 2014, IEEE I C CONS ELECT, P384, DOI 10.1109/ICCE-Berlin.2014.7034253
   Rao KR, 2006, INTRODUCTION TO MULTIMEDIA COMMUNICATIONS: APPLICATIONS, MIDDLEWARE, NETWORKING, P1
   ROBERTSON S, 1996, P SIGCHI C HUM FACT, P79, DOI DOI 10.1145/238386.238408
   Romero C, 2013, COMPUT APPL ENG EDUC, V21, P135, DOI 10.1002/cae.20456
   Sadalage PJ, 2012, NOSQL DISTILLED BRIE
   Sanchez F, 2013, MULTIMEDIA SYST, V19, P493, DOI 10.1007/s00530-013-0312-6
   Senkul P, 2012, KNOWL INF SYST, V30, P527, DOI 10.1007/s10115-011-0386-4
   Soares LFG, 2009, MULTIPLE EXHIBITION
   Srivastava H, 2001, INTERACTIVE TV TECHN
   Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12, DOI DOI 10.1145/846183.846188
   Teixeira CAC, 2010, MULTIMED TOOLS APPL, V50, P587, DOI 10.1007/s11042-010-0481-7
   Tsekleves E, 2011, ENTERTAIN COMPUT, V2, P151, DOI 10.1016/j.entcom.2011.02.002
   Wang B, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501648
   Wheeler W, 2013, SPRING IN PRACTICE
   Witten IH, 2011, MOR KAUF D, P1
NR 45
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8573
EP 8595
DI 10.1007/s11042-016-3489-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800042
DA 2024-07-18
ER

PT J
AU Wang, XF
   Han, X
   Xi, JH
   Wang, SP
AF Wang, Xiaofeng
   Han, Xiao
   Xi, Jianghuan
   Wang, Shangping
TI Reversible data hiding in encrypted image with separable data extraction
   from image decryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Reversible data hiding; Reserve room before
   encryption; Bicubic interpolation; Histogram shifting
ID DIFFERENCE EXPANSION; WATERMARKING; PREDICTION; TRANSFORM; PROTOCOL
AB We propose a method of reversible data hiding in encrypted image. Proposed method achieves reserving room before encryption, and separates data extraction from image decryption. Our method is an improvement of Ma's method [IEEE Trans Inf Forensic Secur 8(3): 554-558, 2013]. Our improvements mainly focus on two aspects. (1) We improved the interpolation error estimate method via using Bicubic interpolation instead of pixel estimation that calculates the weighted sum of four surrounding pixels. Thus more sharp interpolation error histogram is obtained to increase the hidden information capacity. (2) We use partitioned local histogram shift instead of traditional histogram shift to reduce the amount of shifted pixels. This directly results in a higher quality of stego image in the same embedding capacity. The experimental results indicate that the improved method offers better performance. It is superior to Ma's work in both embedding rate and the PSNR values of stego images.
C1 [Wang, Xiaofeng; Han, Xiao; Xi, Jianghuan; Wang, Shangping] Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
   [Wang, Xiaofeng; Wang, Shangping] Xian Univ Technol, Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Xi'an University of Technology
RP Wang, XF (corresponding author), Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.; Wang, XF (corresponding author), Xian Univ Technol, Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Shaanxi, Peoples R China.
EM xfwang66@sina.com.cn
RI li, ye/GWN-2672-2022; Li, Ye/JBS-2949-2023; Hu, Shaolin/N-1791-2018
OI Wang, Shangping/0000-0002-8964-5328
FU National High Technology Development 973 Program of China
   [2012CB316400]; National Natural Science Foundation of China [61075007];
   Natural Science Foundation of Shaanxi Province of China [2015JM6262]
FX This work was supported by the National High Technology Development 973
   Program of China under Grant No. 2012CB316400; the National Natural
   Science Foundation of China under Grant No. 61075007; The Natural
   Science Foundation of Shaanxi Province of China under Grant No.
   2015JM6262.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2008, IET INFORM SECUR, V2, P35, DOI 10.1049/iet-ifs:20070004
   Feng J.B., 2006, IJ Network Security, V2, P161
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kuribayashi M, 2005, IEEE T IMAGE PROCESS, V14, P2129, DOI 10.1109/TIP.2005.859383
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P813, DOI 10.1109/83.923277
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Zeng W., 1998, PROC INT C INF SYST, V3, P223
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   ZHANG XP, 2011, SIGNAL PROCESSING LE, V18, P255, DOI DOI 10.1109/LSP.2011.2114651
NR 28
TC 4
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6127
EP 6142
DI 10.1007/s11042-016-3288-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400002
DA 2024-07-18
ER

PT J
AU Cheng, PH
   Chang, KC
   Liu, CL
AF Cheng, Po-Hsin
   Chang, Ko-Chin
   Liu, Chiang-Lung
TI A reversible data hiding scheme for VQ indices using histogram shifting
   of prediction errors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Vector quantization; Histogramshifting;
   Prediction errors
ID DIFFERENCE EXPANSION; COMPRESSED IMAGES; WATERMARKING; ALGORITHM;
   MECHANISM; TABLE
AB Concomitant with the rapid advancements in information technology, the issue of secure data transmission through the Internet has become increasingly important. Hiding data in images is an important technique in digital media; it facilitates confidential data transfer to receivers and renders the data virtually undetectable by third parties. In this paper, a novel reversible data hiding scheme based on vector quantization (VQ) is proposed. First, codebook sorting is employed to enhance the correlation of neighbor indices and then a prediction error technique is used to generate a high peak histogram. The secret data are then embedded via histogram shifting of prediction errors. Our proposed scheme utilizes only one codebook, unlike other similar methods, and the stego carrier (index table after embedding) can be decompressed without secret data extraction to avoid detection by third parties. Experimental results indicate that the proposed scheme has better visual image quality and greater embedding capacity than recently proposed schemes of a similar nature.
C1 [Cheng, Po-Hsin] Natl Def Univ, Chung Cheng Inst Technol, Sch Def Sci, Taoyuan, Taiwan.
   [Chang, Ko-Chin; Liu, Chiang-Lung] Natl Def Univ, Dept Elect & Elect Engn, Taoyuan, Taiwan.
C3 National Defense University - Taiwan; National Defense University -
   Taiwan
RP Cheng, PH (corresponding author), Natl Def Univ, Chung Cheng Inst Technol, Sch Def Sci, Taoyuan, Taiwan.
EM phc212@gmail.com; deeran44@gmail.com; chianglung.liu@gmail.com
RI Liu, Chiang-Lung/IZE-3553-2023
CR Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   [Anonymous], T IEEE PATTERN ANAL
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Chang YT, 2015, MULTIMED TOOLS APPL, V74, P1645, DOI 10.1007/s11042-014-2019-x
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lou DC, 2002, COMPUT SECUR, V21, P449, DOI 10.1016/S0167-4048(02)00515-1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai CL, 2005, PATTERN RECOGN, V38, P1993, DOI 10.1016/j.patcog.2005.03.001
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Wang WJ, 2011, IEEE SYST J, V5, P528, DOI 10.1109/JSYST.2011.2165603
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Xuan GXG, 2004, 2004 I E INT S CIRC, DOI [10.1109/ISCAS.2004.1329200, DOI 10.1109/ISCAS.2004.1329200]
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
NR 30
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6031
EP 6050
DI 10.1007/s11042-015-3142-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500063
DA 2024-07-18
ER

PT J
AU Deng, HP
   Wu, J
   Zhu, L
   Yan, ZQ
   Yu, L
AF Deng, Huiping
   Wu, Jin
   Zhu, Lei
   Yan, Zengqiang
   Yu, Li
TI Texture edge-guided depth recovery for structured light-based depth
   sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; RGB-D data; Depthmaprecovery; Edge detection; Depthedge
   alignment
ID 3-D OBJECT RETRIEVAL; COLOR; RECOGNITION
AB The emergence of depth sensor facilitates the real-time and low-cost depth capture. However, the quality of its depth map is still inadequate for further applications due to holes, noises and artifacts existing within its depth information. In this paper, we propose an iterative depth boundary refinement framework to recover Kinect depth map. We extract depth edges and detect the incorrect regions, and then re-fill the incorrect regions until the depth edges are consistent with color edges. In the incorrect region detection procedure, we propose a RGB-D data edge detection method inspired by the recently developed deep learning. In the depth in-painting procedure, we propose a priority-determined fill order in which the high confidence pixels and strong edges are assigned to high priority. The actual depth values are computed by using a weighted cost filter, in which color, spatial similarity measures and Gaussian error model are considered. Experimental results demonstrate that the proposed method provides sharp and clear edges for the Kinect depth, and depth edges are aligned with the color edges.
C1 [Deng, Huiping; Wu, Jin; Zhu, Lei] Wuhan Univ Sci & Technol, Sch Inf Sci & Engn, Wuhan 430081, Peoples R China.
   [Yan, Zengqiang; Yu, Li] Huazhong Univ Sci & Technol, Sch Elec Inf & Comm, Wuhan 430074, Peoples R China.
C3 Wuhan University of Science & Technology; Huazhong University of Science
   & Technology
RP Deng, HP (corresponding author), Wuhan Univ Sci & Technol, Sch Inf Sci & Engn, Wuhan 430081, Peoples R China.
EM pingp1223@163.com
RI Li, Mengqi/AAG-6804-2021; Zhu, Lei/KUD-1330-2024
CR [Anonymous], 2015, PAMI
   [Anonymous], P VIS COMM IM PROC
   [Anonymous], 2013, ICCV
   [Anonymous], 2001, ICCV
   [Anonymous], ICCV WORKSH 3D REPR
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Chen L, 2012, INT C PATT RECOG, P3070
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Miao D, 2012, IEEE INT SYMP CIRC S, P604, DOI 10.1109/ISCAS.2012.6272103
   Milani S, 2012, INT CONF ACOUST SPEE, P797, DOI 10.1109/ICASSP.2012.6288004
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033
   Qingxiong Yang, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P69, DOI 10.1109/MMSP.2010.5661996
   Shen J, 2013, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2013.157
   Xiang S, 2015, SIGNAL PROCESS-IMAGE, V31, P34, DOI 10.1016/j.image.2014.11.004
   Xu YT, 2014, INT CONF DIGIT SIG, P327, DOI 10.1109/ICDSP.2014.6900681
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang Q., 2007, PROC IEEE COMPUT VIS, P1
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 28
TC 4
Z9 4
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4211
EP 4226
DI 10.1007/s11042-016-3340-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200050
DA 2024-07-18
ER

PT J
AU Di Mascio, T
   Gennari, R
   Tarantino, L
   Vittorini, P
AF Di Mascio, Tania
   Gennari, Rosella
   Tarantino, Laura
   Vittorini, Pierpaolo
TI Designing visualizations of temporal relations for children: action
   research meets HCI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Children-oriented design; Temporal relations; Visualization; Action
   research; Games
ID COMPREHENSION; PRINCIPLES; FRONTIERS
AB The diffusion of ICT products in everyday life is bringing into the realm of technological artifacts new users and their demands, which translate into novel design/research issues, like in the case of children-oriented Technology Enhanced Learning (TEL) systems. In this paper we report our experience within the framework of the EU project TERENCE, which developed an adaptive learning system supporting 7-11 years old children characterized by "poor text comprehension", a cognitive disability related to reading activities. In particular we discuss how our design approach allowed us to overcome the inadequacy of existing consolidated techniques for visualization of temporal relations and data gathering, which turned out not to comply with constraints typical of children-oriented TEL systems. We show how the definition of a novel children-oriented data gathering technique allowed us to carry out a study on the children mental model of time and, based on it, to design a children-oriented integrated "read-n-play" visual environment able to force the acquisition of the capability of reasoning about temporal events within a story. Since the aim of the stimulation is to drive children towards a mature mental model of time, the challenge was to overcome the drawbacks of adult-oriented techniques by building on concepts already possessed by children, while at the same time retaining some basic features of adult-oriented temporal visualization to favor the transition.
C1 [Di Mascio, Tania; Tarantino, Laura] Univ Studi Aquila, Dipartimento Ingn & Sci Informaz Matemat, Via Vetoio 1, I-67100 Laquila, Italy.
   [Gennari, Rosella] Free Univ Bozen Bolzano, Fac Comp Sci, Piazza Domenicani 3, I-39100 Bolzano, Italy.
   [Vittorini, Pierpaolo] Univ Studi Aquila, Dipartimento Med Clin Sanita Pubbl Sci Vita & Amb, Piazzale S Tommasi 1, I-67100 Laquila, Italy.
C3 University of L'Aquila; Free University of Bozen-Bolzano; University of
   L'Aquila
RP Di Mascio, T (corresponding author), Univ Studi Aquila, Dipartimento Ingn & Sci Informaz Matemat, Via Vetoio 1, I-67100 Laquila, Italy.
EM tania.dimascio@univaq.it
RI VITTORINI, Pierpaolo/HJP-5306-2023; Gennari, Rosella/AAX-1802-2021;
   Gennari, Rosella/HIR-3964-2022; Di Mascio, Tania/M-9725-2016
OI VITTORINI, Pierpaolo/0000-0002-6975-8958; Gennari,
   Rosella/0000-0003-0063-0996; Di Mascio, Tania/0000-0002-8069-1168
CR Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Arfe B., 2014, METHODOLOGIES INTELL, P165
   Baskerville R., 1999, ACCOUNTING MANAGEMEN, V9, P1, DOI 10.1016/S0959-8022(98)00017-4
   Baskerville R. L., 1999, Communications of the association for information systems, V2, P2, DOI [https://doi.org/10.17705/1CAIS.00219, DOI 10.17705/1CAIS.00219]
   Baskerville RL, 1996, J INFORM TECHNOL, V11, P235, DOI 10.1080/026839696345289
   Bekker M, 2003, INTERACT COMPUT, V15, P187, DOI 10.1016/S0953-5438(03)00007-9
   Bruckman A., 2002, The human-computer interaction handbook: Fundamentals, evolving technologies, and emerging applications, P428
   Brusilovsky P., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P263
   Cain K, 2003, J CHILD LANG, V30, P681, DOI 10.1017/S0305000903005713
   Cain K., 2009, Perspectives on Language and Literacy, V35, P11
   Cain K, 2007, COMPREHENSION PROBLE, DOI Guildford Press
   Cecilia MR, 2014, INTERACT DES ARCHIT, P50
   Chi E. H., 1998, Proceedings of the SIGCHI conference on Human factors in computing systems, P400
   Chittaro L, 2001, EIGHTH INTERNATIONAL SYMPOSIUM ON TEMPORAL REPRESENTATION AND REASONING, PROCEEDINGS, P13, DOI 10.1109/TIME.2001.930692
   Collalto A, 2009, THESIS
   Davison R, 2004, INFORM SYST J, V14, P65, DOI 10.1111/j.1365-2575.2004.00162.x
   de la Prieta F, 2014, INT J TECHNOL ENHANC, V6, P212, DOI 10.1504/IJTEL.2014.068350
   Di Mascio T, 2012, P ITAIS 2012
   Di Mascio T, 2015, P 11 BIANN C IT SIGC, P1
   Di Mascio T, J DISTANCE IN PRESS
   Di Mascio T, 2015, ADV INTELL SYST, V374, P81, DOI 10.1007/978-3-319-19632-9_11
   Dina D, 2016, COMPUT HUM BEHAV, V55, P1125, DOI 10.1016/j.chb.2014.09.053
   Dix A, 2012, ACTION RES HCI
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/014492901101008659, 10.1080/01449290110108659]
   Druin A., 1999, The design of children's technology, P51
   Fails JA, 2006, IEEE CONF VIS ANAL, P167
   Gay L.R., 2000, Educational research: Competencies for analysis and application, V6th
   Geva E, 2013, J LEARN DISABIL-US, V46, P387, DOI 10.1177/0022219412466651
   Gough P., 1986, Remedial Special Education, V7, P6, DOI DOI 10.1177/074193258600700104
   Gulliksen J, 2003, BEHAV INFORM TECHNOL, V22, P397, DOI 10.1080/01449290310001624329
   Hajnicz E, 1996, LNCS
   Hayes GR, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1993060.1993065
   Hibino S, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P99, DOI 10.1145/266180.266342
   Hourcade Juan Pablo, 2007, Foundations and Trends in Human-Computer Interaction, V1, P277, DOI 10.1561/1100000006
   Jensen JanneJ., 2005, PROCEEDING 2005 C IN, P80
   Kock N, 2014, ENCY HUMAN COMPUTER
   Kumar V., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P126, DOI 10.1145/276675.276689
   Lewin K, 1947, HUM RELAT, V1, P143, DOI 10.1177/001872674700100201
   Mackinlay J. D., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P173, DOI 10.1145/108844.108870
   McColgan KL, 2008, CHILD DEV, V79, P1477, DOI 10.1111/j.1467-8624.2008.01200.x
   McKay J., 2001, Information Technology & People, V14, P46, DOI 10.1108/09593840110384771
   Nation K, 2005, BL HBK DEV PSYCHOL, P248, DOI 10.1002/9780470757642.ch14
   Nesset V, 2004, LIBR INFORM SCI RES, V26, P140, DOI 10.1016/j.lisr.2003.12.002
   NIELSEN J, 1994, BEHAV INFORM TECHNOL, V13, P3, DOI 10.1080/01449299408914577
   Oakhill JV, 2003, LANG COGNITIVE PROC, V18, P443, DOI 10.1080/01690960344000008
   Oosterholt R., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P450, DOI 10.1145/238386.238603
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295
   Plaisant C, 1996, P SIGCHI C HUM FACT, V1996, P221, DOI [DOI 10.1145/257089.2573912, DOI 10.1145/238386.238493.2, DOI 10.1145/238386.238493]
   Prensky M., 2003, Computers in Entertainment (CIE), V1, P21, DOI DOI 10.1145/950566.950596
   Przybylski AK, 2010, REV GEN PSYCHOL, V14, P154, DOI 10.1037/a0019440
   Read J.C., 2013, INT J CHILD COMPUTER, V1, P2, DOI DOI 10.1016/J.IJCCI.2012.09.001
   Redish J.G., 2002, CHI '02 extended abstracts on Human factors in computing systems, P885
   Rekimoto Jun., 1999, Proceedings of ACM CHI'99 Extended Abstracts, P180
   Siang-Ting Siew, 2013, Human-Computer Interaction. Human-Centred Design Approaches, Methods, Tools, and Environments. 15th International Conference, HCI International 2013. Proceedings. LNCS 8004, P470, DOI 10.1007/978-3-642-39232-0_51
   Silva SF, 2000, PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING, VOL I, P310, DOI 10.1109/WISE.2000.882407
   Slegers K, 2011, STATE ART METHODS US
   Snowling MargaretJean., 2008, The Science of Reading: A Handbook
   Spector, 2013, RESHAPING LEARNING N, DOI [https://doi.org/10.1007/978-3-642-32301-0_13, DOI 10.1007/978-3-642-32301-0_13]
   SUSMAN GI, 1978, ADMIN SCI QUART, V23, P582, DOI 10.2307/2392581
   Trist EL, 1951, HUM RELAT, V4, P3, DOI 10.1177/001872675100400101
   Vaajakallio K., 2009, P 8 INT C INTERACTIO, P246, DOI [DOI 10.1145/1551788.1551843, 10.1145/1551788.1551843]
   Valeriani A, 1986, ERMENEUTICA RETORICA
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Verhagen M, 2005, LNCS, P10
NR 65
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4855
EP 4893
DI 10.1007/s11042-016-3609-6
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500011
DA 2024-07-18
ER

PT J
AU Gennari, R
   Melonio, A
   Torello, S
AF Gennari, Rosella
   Melonio, Alessandra
   Torello, Santina
TI Gamified probes for cooperative learning: a case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gamification; Self determination theory; Technology probes; Gamified
   tangibles; User experience; Cooperative learning
ID GAMIFICATION
AB This paper advances the idea of tangible gamified probes for cooperative learning processes, which require synchronous in-presence and in-situ interactions. The paper focuses on gamified probes for promoting a sense of progression and control, as well as social relations in a cooperative learning process in classroom. It reports a case study in a primary school. The study employed gamified probes as early-design solutions: each probe had limited ad-hoc functionalities, tested in the field, and was flexible enough to enable different usages so as to inspire designers. Probes were also endowed with embedded micro-electronic components for enhancing their interaction with children and human-to-human interaction, besides for storing relevant interaction data. After reporting the study results, the paper discusses them, and it concludes reflecting on the design of future gamified probes for enhancing cooperative learning in classroom.
C1 [Gennari, Rosella; Melonio, Alessandra; Torello, Santina] Free Univ Bozen Bolzano, Fac Comp Sci, Piazza Domenicani 3, I-39100 Bolzano, Italy.
C3 Free University of Bozen-Bolzano
RP Gennari, R; Melonio, A (corresponding author), Free Univ Bozen Bolzano, Fac Comp Sci, Piazza Domenicani 3, I-39100 Bolzano, Italy.
EM gennari@inf.unibz.it; alessandra.melonio@unibz.it
RI Gennari, Rosella/AAX-1802-2021; Gennari, Rosella/HIR-3964-2022
OI Gennari, Rosella/0000-0003-0063-0996; Melonio,
   Alessandra/0000-0001-6655-1946
CR Adams Ernest, 2013, Fundamentals of Game Design, V3rd
   Andres J., 2015, CHI PLAY 2015-Proceedings of the 2015 Annual Symposium on Computer-Human Interaction in Play, P445, DOI [https://doi.org/10.1145/2793107.2810295, DOI 10.1145/2793107.2810295]
   [Anonymous], P HICSS 2014
   [Anonymous], 2011, C HUM FACT COMP SYST, DOI DOI 10.1145/1979742.1979575
   Brondino M, 2015, ADV INTELL SYST, V374, P1, DOI 10.1007/978-3-319-19632-9_1
   Casas I, 2010, PROCD SOC BEHV, V2, P2685, DOI 10.1016/j.sbspro.2010.03.396
   Challis B, 2015, ENCY HUMAN COMPUTER
   Collazos C. A., 2004, International Journal of Computer Applications in Technology, V19, P151, DOI 10.1504/IJCAT.2004.004044
   Deci EL, 2000, PSYCHOL INQ, V11, P227, DOI 10.1207/S15327965PLI1104_01
   Deterding S, 2011, WORKSH GAM US GAM DE
   DiMicco JM, 2007, HUM-COMPUT INTERACT, V22, P47
   Dodero G., 2014, CHI 14 EXTENDED ABST, P707
   Dodero G., 2015, P 11 BIANN C IT SIGC, V28, P10, DOI [10.1145/2808435.2808436, DOI 10.1145/2808435.2808436]
   Dodero Gabriella, 2014, P 1 ACM SIGCHI ANN S, P77, DOI [10.1145/2658537.2658688, DOI 10.1145/2658537.2658688]
   Dourish P., 1997, P CHI 97 WORKSH AW C
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/014492901101008659, 10.1080/01449290110108659]
   Gaver B., 1999, Interactions, V6, P21, DOI DOI 10.1145/291224.291235
   Glover I., 2013, P WORLD C ED MULTIME
   GRAVES T, 1991, EDUC LEADERSHIP, V48, P77
   Greenbaum J, 1992, DESIGN ATWORK COOPER
   Guerrero LA, 2009, INT C COMP SUPP COOP, P516, DOI 10.1109/CSCWD.2009.4968111
   Hanus MD, 2015, COMPUT EDUC, V80, P152, DOI 10.1016/j.compedu.2014.08.019
   Horn MS, 2012, PERS UBIQUIT COMPUT, V16, P379, DOI 10.1007/s00779-011-0404-2
   Huang K, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2541, DOI 10.1145/2556288.2557416
   Huang W.H-Y., 2013, RES REPORT SERIES BE
   Hutchinson H., 2003, P ACM C HUMAN FACTOR, P17, DOI DOI 10.1145/642611.642616
   Johnson D, 2002, CREATIVITY COLLABORA
   KAGAN S, 1990, EDUC LEADERSHIP, V47, P12
   Kapp K.M., 2013, GAMIFICATION LEARNIN
   Lidwell William, 2010, Universal Principles of Design, Revised and Updated: 125 Ways to Enhance Usability, Influence Perception, Increase Appeal, Make Better Design Decisions, and Teach through Design
   Lindsay S., 2012, P SIGCHI C HUMAN FAC, P1199, DOI DOI 10.1145/2207676.2208570
   Lynch PJ, 2015, WEB STYLE GUIDE ONLI
   Rogers Yvonne, 2015, P 2015 ANN S COMP HU, P127
   Rubegni E., 2014, IDC 2014, P165, DOI [10.1145/2593968.2593979, DOI 10.1145/2593968.2593979]
   Ryan R. M., 1985, INTRINSIC MOTIVATION
   Sanders E., 2008, CoDesign, V4, P5, DOI DOI 10.1080/15710880701875068
   Schuler D., 1993, Participatory Design: Principles and Practices
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Shkirando E, 2014, THESIS
   Simoes J, 2013, COMPUT HUM BEHAV, V29, P345, DOI 10.1016/j.chb.2012.06.007
   Slavin R.E., 1991, STUDENT TEAM LEARNIN
   STEVENS RJ, 1995, AM EDUC RES J, V32, P321, DOI 10.2307/1163434
   Thomas Tullis WilliamAlbert., 2013, Measuring the user experience: collecting, analyzing, and presenting usability metrics
   Zuckerman O, 2013, INT J HUM-COMPUT ST, V71, P803, DOI 10.1016/j.ijhcs.2013.04.003
NR 44
TC 13
Z9 14
U1 2
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4925
EP 4949
DI 10.1007/s11042-016-3543-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500013
DA 2024-07-18
ER

PT J
AU He, Q
   Huang, LH
AF He, Qian
   Huang, Lihong
TI Bayesian image reconstruction for positron emission tomography based on
   anisotropic median-diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Positron emission tomography; Partial differential equation; Median root
   prior; Anisotropic diffusion
ID ROOT PRIOR; ALGORITHM
AB For improving the quality of positron emission tomography (PET) images, the partial differential equation median (PDEmedian) algorithm which incorporates an anisotropic diffusion (AD) filter into the median root prior (MRP) algorithm was proposed. However, due to the shortcomings of the AD filter, the PDEmedian algorithm is difficult to realize. This work aims to solve this problem by introducing a new diffusion model into the PDEmedian. The proposed algorithm shows its positive effects on image reconstruction and denoising. Experimental results present that the new algorithm can preserve sharp edges while reducing noise at the same time. Furthermore, in comparison to other similar reconstruction algorithms, the proposed method is less sensitive to the value of the gradient threshold and the adjustment of the diffusion number.
C1 [He, Qian; Huang, Lihong] Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
   [He, Qian] Hunan City Univ, Coll Informat Sci & Engn, Yiyang 413000, Peoples R China.
   [Huang, Lihong] Hunan Womens Univ, Dept Informat & Technol, Changsha 410004, Hunan, Peoples R China.
C3 Hunan University; Hunan City University
RP He, Q (corresponding author), Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
EM heqian0808@163.com
RI Huang, Li/IUQ-0909-2023
FU Science and Technology Department of Hunan Province [2014FJ6068]; Hunan
   Provincial Education Department [14C0211, 13C112]; Yiyang Municipal
   Science and Technology Bureau [2014JZ36]
FX The authors would like to thank anonymous reviewers for their helpful
   work of this paper. This work was supported by: 1. Science and
   Technology Department of Hunan Province no. 2014FJ6068; 2. Fund Project
   of Hunan Provincial Education Department no. 14C0211; 3. Fund Project of
   Hunan Provincial Education Department no. 13C112; 4. Yiyang Municipal
   Science and Technology Bureau no. 2014JZ36.
CR Alenius S, 2002, IEEE T MED IMAGING, V21, P1413, DOI 10.1109/TMI.2002.806415
   Alenius S, 1997, EUR J NUCL MED, V24, P258, DOI 10.1007/BF01728761
   [Anonymous], MACH INTELL
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Ferrari RJ, 2013, MED BIOL ENG COMPUT, V51, P71, DOI 10.1007/s11517-012-0971-z
   Gaitanis A, 2010, COMPUT MED IMAG GRAP, V34, P131, DOI 10.1016/j.compmedimag.2009.07.006
   GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985
   Grega M, 2014, MULTIMED TOOLS APPL, V68, P95, DOI 10.1007/s11042-012-1164-3
   Gui ZG, 2012, OPTIK, V123, P507, DOI 10.1016/j.ijleo.2011.05.016
   Gui ZG, 2012, IEEE T NUCL SCI, V59, P1984, DOI 10.1109/TNS.2012.2198495
   He Q, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/491239
   Hsiao IT, 2003, IEEE T MED IMAGING, V22, P580, DOI 10.1109/TMI.2003.812249
   Kazantsev D, 2012, PHYS MED BIOL, V57, P3793, DOI 10.1088/0031-9155/57/12/3793
   Koch A, 2012, MULTIMED TOOLS APPL, V57, P565, DOI 10.1007/s11042-010-0657-1
   Krissian K, 2009, IEEE T IMAGE PROCESS, V18, P2265, DOI 10.1109/TIP.2009.2025553
   Ling J, 2002, IEEE T MED IMAGING, V21, P377, DOI 10.1109/TMI.2002.1000261
   Nadernejad E., 2008, Appl. Math. Sci, V2, P1507
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Shepp L A, 1982, IEEE Trans Med Imaging, V1, P113, DOI 10.1109/TMI.1982.4307558
   Szwoch G, 2016, MULTIMED TOOLS APPL, V75, P761, DOI 10.1007/s11042-014-2324-4
   TorkamaniAzar F, 1996, IEEE T IMAGE PROCESS, V5, P1573, DOI 10.1109/83.541427
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   WU Y, 2013, SIGNAL PROCESSING LE, V20, P411, DOI DOI 10.1109/LSP.2013.2247755
   Yan JH, 2007, J OPT SOC AM A, V24, P1026, DOI 10.1364/JOSAA.24.001026
   Zhou J, 2006, DIGIT SIGNAL PROCESS, V16, P735, DOI 10.1016/j.dsp.2006.08.006
NR 25
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5803
EP 5816
DI 10.1007/s11042-015-2493-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500049
DA 2024-07-18
ER

PT J
AU Hong, W
   Ma, YB
   Wu, HC
   Chen, TS
AF Hong, Wien
   Ma, Yuan-Bo
   Wu, Hung-Che
   Chen, Tung-Shou
TI An efficient reversible data hiding method for AMBTC compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; AMBTC; Prediction; Low computing cost
ID STEGANOGRAPHY; SEGMENTATION; PREDICTION; TABLE
AB Analyzing multimedia data in mobile devices is often constrained by limited computing capacity and power storage. Therefore, more and more studies are trying to investigate methods with algorithm efficiency. Sun et al. proposed a low computing cost reversible data hiding method for absolute moment block truncation coding (AMBTC) images with excellent embedding performance. Their method predicts quantization values and uses encrypted data bits, division information, and prediction errors to construct the stego codes. This method successfully embeds data while providing a comparable bit-rate; however, it does not fully exploit the correlation of neighboring pixels and division of prediction error for better embedment. Therefore, the payload and bit-rate are penalized because the embedding performance directly depends on the prediction accuracy and division efficiency. In this paper, we use median edge detection predictor to better predict the quantization values. We also employ an alternative prediction technique to increase the prediction accuracy by narrowing the range of prediction values. Besides, an efficient centralized error diversion technique is proposed to further decrease the bit-rate. The experimental results show that the proposed method offers 8 % higher payload with 5 % lower bit-rate on average if compared to Sun et al.'s method and has better embedding performance than prior related works.
C1 [Hong, Wien] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Hong, Wien; Ma, Yuan-Bo] Sun Yat Sen Univ, Nanfang Coll, Dept Elect Commun & Software Engn, Guangzhou, Guangdong, Peoples R China.
   [Wu, Hung-Che] Sun Yat Sen Univ, Nanfang Coll, Dept Business Adm, Guangzhou, Guangdong, Peoples R China.
   [Chen, Tung-Shou] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Nanjing University of Information Science & Technology; Nanfang College,
   Guangzhou; Sun Yat Sen University; Sun Yat Sen University; Nanfang
   College, Guangzhou; National Taichung University of Science & Technology
RP Ma, YB (corresponding author), Sun Yat Sen Univ, Nanfang Coll, Dept Elect Commun & Software Engn, Guangzhou, Guangdong, Peoples R China.
EM mayb1314@foxmail.com
RI Wu, Hung-Che/H-4859-2019
OI Wu, Hung-Che/0000-0001-5282-8473
CR Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hong W, 2011, APPL MECH MATER, V65, P182, DOI 10.4028/www.scientific.net/AMM.65.182
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P6159, DOI 10.1007/s11042-015-3208-y
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Malik A, 2016, HIGH PAYLOAD DATA HI, DOI [10.1007/s11042-016-3815-2, DOI 10.1007/S11042-016-3815-2]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 33
TC 41
Z9 42
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5441
EP 5460
DI 10.1007/s11042-016-4032-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500034
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Li, XX
   Liu, AA
   Su, YT
AF Nie, Weizhi
   Li, Xixi
   Liu, Anan
   Su, Yuting
TI 3D object retrieval based on Spatial plus LDA model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; LDA; Topic model; Similarity measure; Topic
   extraction
ID SEARCH ENGINE; 2-D
AB Latent Dirichlet Allocation (LDA) is one popular topic extraction method, which has been applied in many applications such as textual retrieval, user recommendation system and video cluster. In this paper, we apply LDA model for visual topics extraction and utilized the topic distribution visual feature of image to handle 3D object retrieval problem. Different from the traditional LDA model, we add the spatial information of visual feature for document generation. First, we extract SIFT features from each 2D image extracted from 3D object. Then, we structure the visual documents according to the spatial information of 3D model. Finally, LDA model is used to extract the topic model for handling the retrieval problem. We further propose a multi-topic model to improve retrieval performance. Extensive comparison experiments were on the popular ETH, NTU and MV-RED 3D model datasets. The results demonstrate the superiority of the proposed method.
C1 [Nie, Weizhi; Li, Xixi; Liu, Anan; Su, Yuting] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM anan0422@gmail.com
RI Nie, Weizhi/ABF-5316-2021
FU National Natural Science Foundation of China [61472275, 61170239,
   61303208]; Tianjin Research Program of Application Foundation and
   Advanced Technology [15JCYBJC16200]; Tianjin University [2014XRG-0046]
FX This work was supported in part by the National Natural Science
   Foundation of China (61472275, 61170239, 61303208), the Tianjin Research
   Program of Application Foundation and Advanced Technology
   (15JCYBJC16200), and the grant of Elite Scholar Program of Tianjin
   University (2014XRG-0046).
CR [Anonymous], 2003, INT J IMAGE GRAPH
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   Hu D. J., 2013, LATENT DIRICHLET ALL
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Leibe B, 2003, PROC CVPR IEEE, P409
   Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3
   Leng BA, 2009, CHINESE J ELECTRON, V18, P291
   Li WJ, 2008, IEEE T IMAGE PROCESS, V17, P2236, DOI 10.1109/TIP.2008.2003404
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Wang F, 2008, ELECT IMAGING 2008 I
   Wong HS, 2007, IEEE T MULTIMEDIA, V9, P1026, DOI 10.1109/TMM.2007.898915
   Yeh JS, 2005, BIOINFORMATICS, V21, P3056, DOI 10.1093/bioinformatics/bti458
   Zeng J., 2014, MULTIMED TOOLS APPL, P1, DOI [10.1007/s1104201420298, DOI 10.1007/S1104201420298]
NR 33
TC 5
Z9 5
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4091
EP 4104
DI 10.1007/s11042-015-2840-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200043
DA 2024-07-18
ER

PT J
AU Peng, F
   Gong, XQ
   Long, M
   Sun, XM
AF Peng, Fei
   Gong, Xiao-qing
   Long, Min
   Sun, Xing-ming
TI A selective encryption scheme for protecting H.264/AVC video in
   multimedia social network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Selective encryption; H.264/AVC; multimedia social
   network
AB Aiming to protect H. 264/AVC video in multimedia social network, a selective encryption scheme is put forward. In the scheme, after analyzing the impact of quantization parameter (QP) on the encryption of the sign of T1 s and the impact of encrypting intermacroblock non-zero coefficients, the sign of intra-macroblock non-zero DCT coefficients, the sign of trailing ones (T1 s), the intra prediction modes (IPMs) and the sign of motion vector difference (MVD) are encrypted to protect the texture and motion information of H. 264/AVC. Experimental results and analysis show that the computation cost is low and the bitrate increment is negligible, and it can achieve good performance in resisting brute-force attacks, histogram-based attacks and replacement attacks. Based on the encryption scheme, a framework of its implementation in multimedia social network is put forward. It has great potential to be implemented for the video data protection in multimedia social network.
C1 [Peng, Fei; Gong, Xiao-qing] Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410014, Hunan, Peoples R China.
   [Sun, Xing-ming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology; Nanjing
   University of Information Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM eepengf@gmail.com
RI Sun, Xingming/AAD-1866-2019; Long, Min/AGW-6059-2022; Peng,
   Fei/H-6951-2017
OI Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [61370225, 61572182]; Hunan
   Provincial Natural Science Foundation of China [15JJ2007]; Scientific
   Research Plan of Hunan Provincial Science and Technology Department of
   China [2014FJ4161]; Project of the Priority Academic Program Development
   of Jiangsu Higher Education Institutions; Jiangsu Collaborative
   Innovation Center on Atmospheric Environment and Equipment Technology
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant No. 61370225, 61572182), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No. 15JJ2007), supported by the Scientific Research Plan of Hunan
   Provincial Science and Technology Department of China (2014FJ4161),
   supported by Project of the Priority Academic Program Development of
   Jiangsu Higher Education Institutions, and supported by Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology.
CR Ahn J, 2004, LECT NOTES COMPUT SC, V3333, P386
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2011, JM REFERENCE SOFTWAR
   [Anonymous], TENCON 2008 2008 IEE
   Friedman WilliamF., 1987, The Index of Coincidence and Its Applications in Cryptanalysis
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Furht B, 2005, INTERNET COMMUN SER, P95
   Goldreich O, 2009, FDN CRYPTOGRAPHY, P373
   Hong GM, 2006, LECT NOTES COMPUT SC, V4261, P510
   Jiang Jian-guo, 2007, Acta Electronica Sinica, V35, P1724
   Jiang JG, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P478, DOI 10.1109/MINES.2009.26
   Kwon SG, 2005, LECT NOTES COMPUT SC, V3656, P207, DOI 10.1007/11559573_26
   Li Xiao-ju, 2009, Computer Engineering and Applications, V45, P114, DOI 10.3778/j.issn.1002-8331.2009.34.035
   Lian SG, 2008, MULTIMED TOOLS APPL, V38, P75, DOI 10.1007/s11042-007-0150-7
   [廉士国 Lian Shiguo], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P483
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   Liu Y, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P583, DOI 10.1109/ICACT.2007.358423
   Liu Z, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P64
   Martina Podesser A U., 2002, 5th Nordic Signal Processing Symposium, V10, P4
   Peng F, 2013, IEEE T INF FOREN SEC, V8, P1688, DOI 10.1109/TIFS.2013.2259819
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Shahid Z., 2009, Proceedings of the Singaporean-French IPAL Symposium 2009 - SinFra'09, P11, DOI 10.1142/9789814277563_0002
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Wang YJ, 2007, CIS: 2007 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PROCEEDINGS, P883, DOI 10.1109/CIS.2007.99
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yeung SKA, 2009, IEEE SIGNAL PROC LET, V16, P893, DOI 10.1109/LSP.2009.2026109
   Zhang Z., 2011, INT J DIGIT CONTENT, V5, P255, DOI DOI 10.4156/JDCTA.VOL5.ISSUE3.26
   Zhang Z. Y., 2012, INT J DIGIT CONTENT, V6, P245, DOI DOI 10.4156/JDCTA.V0L6.ISSUE9.31
NR 33
TC 23
Z9 24
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3235
EP 3253
DI 10.1007/s11042-016-3710-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200005
DA 2024-07-18
ER

PT J
AU Youn, JM
   Cho, D
AF Youn, Jonghee M.
   Cho, Doosan
TI Improving memory system performance for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Memory system; Energy consumption; Compiler optimization; Restructuring;
   burst mode
AB The cost and performance of embedded systems heavily depends on the performance of memories it utilizes. Latency of a memory access is one of the major bottlenecks in the system performance. In software compilation, it is known that there are high variations in memory access latency depending on the ways of storing/retrieving variables in code to/from memories. To improve the latency, it needs a technique to maximize the use of memory bandwidth. A burst transfer is well known technique to maximally utilize memory bandwidth. The burst transfer capability offers an average access time reduction of more than 65 % for an eight-word sequential transfer. However, the problem of utilizing such burst transfers has not been generally addressed, and unfortunately, it is not tractable. In this work, we present a new technique that both identifies sequences of single load and store instructions for combining into burst transfers. The proposed technique provides an optimal data placement of nonarray variables to achieve the maximum utilization of burst data transfers. The major contributions of our work are, 1) we prove that the problem is NP-hard and 2) we propose an exact formulation of the problem and an efficient data placement algorithm. From experiments with a set of multimedia benchmarks, we confirm that our proposed technique uses on average 7 times more burst accesses than generated codes from ARM commercial compiler.
C1 [Youn, Jonghee M.] Yeungnam Univ, Dept Comp Engn, Gyongsan, South Korea.
   [Cho, Doosan] Sunchon Natl Univ, Dept Elect & Elect Engn, Chungnam, Suncheon, South Korea.
C3 Yeungnam University; Sunchon National University
RP Cho, D (corresponding author), Sunchon Natl Univ, Dept Elect & Elect Engn, Chungnam, Suncheon, South Korea.
EM mew26@snu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2010-0024529]; KOFAC(Korea
   Foundation for the Advancement of Science Creativity); Yeungnam
   University Research Grant.
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2010-0024529), KOFAC (Korea Foundation for the
   Advancement of Science & Creativity), and the 2015 Yeungnam University
   Research Grant.
CR Ayukawa K, 1998, IEEE J SOLID-ST CIRC, V33, P800, DOI 10.1109/4.668996
   Chaitin GJ, 1982, P ACM SIGPLAN 1982 S, P201
   Chame J, 2000, P 27 ANN INT S COMP
   Dutt ND, 1997, P INT C VLSI COMP AI
   Grun P, 2000, DES AUT CON, P316
   Grun P, 2000, P INT S SYST SYNTH, P25
   Hettiaratchi S, 2002, IEEE/ACM INTERNATIONAL CONFERENCE ON CAD-02, DIGEST OF TECHNICAL PAPERS, P577, DOI 10.1109/ICCAD.2002.1167590
   Johnson N, 2003, LECT NOTES COMPUT SC, V2622, P1
   Khare A., 1998, WORKSH SYNTH SYST IN
   McKee SA, 2000, IEEE T COMPUT, V49, P1255, DOI 10.1109/12.895941
   Panda P. R., 1997, ACM Transactions on Design Automation of Electronic Systems, V2, P384, DOI 10.1145/268424.268464
   Panda PR, 1997, 1997 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN - DIGEST OF TECHNICAL PAPERS, P333, DOI 10.1109/ICCAD.1997.643539
   SHIN J, 2002, P 4 WORKSH MED STREA
   Zivojnovic Vojin, 1994, P INT C SIGN PROC AP
NR 14
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5951
EP 5963
DI 10.1007/s11042-015-2807-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500058
DA 2024-07-18
ER

PT J
AU Chen, WS
   Ding, GG
   Lin, ZJ
   Pei, JS
AF Chen, Wenshuo
   Ding, Guiguang
   Lin, Zijia
   Pei, Jisheng
TI Accelerated Manhattan hashing via bit-remapping with location
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accelerated Manhattan hashing; Bit-remapping; Multiple-bit quantization;
   Manhattan distance
AB Hashing is a binary-code encoding method which tries to preserve the neighborhood structures in the original feature space, in order to realize efficient approximate nearest neighbor search in large-scale databases. Existing hashing methods usually adopt a two-stage strategy (projection stage and quantization stage) to encode data points, and threshold-based single-bit quantization (SBQ) is used to binarize each projected dimension into 0 or 1. Data similarity between hash codes is measured by their Hamming distance. However, SBQ may destroy the original neighborhood structures by quantizing neighboring points near threshold into different binary values. Double-bit quantization (DBQ) and its derivative, Manhattan hashing, have been proposed to fix this problem. Experimental results showed that Manhattan hashing outperformed state-of-the-art methods in terms of effectiveness, but lost the advantage of efficiency because it used decimal arithmetic instead of fast bitwise operations for similarity measurement between hash codes. In this paper, we propose an accelerated strategy of Manhattan hashing by making full use of bitwise operations. Our main contributions are: 1) a new encoding method which assigns location information to each binary digit is proposed to avoid the time-consuming decimal arithmetic; 2) a novel hash code distance measurement that accelerates the calculation of Manhattan distance is proposed to improve query efficiency. Extensive experiments on three benchmark datasets show that our approach improves the speed of data querying on 2-bit, 3-bit and 4-bit quantized hash codes by at least one order of magnitude on average, without any precision loss.
C1 [Chen, Wenshuo; Ding, Guiguang] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Lin, Zijia; Pei, Jisheng] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Ding, GG (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM cws13@mails.tsinghua.edu.cn; dinggg@tsinghua.edu.cn;
   linzijia07@tsinghua.org.cn; pjs07@mails.tsinghua.edu.cn
RI Ding, Guiguang/KIL-3528-2024
FU National Natural Science Foundation of China [61271394, 61571269]
FX This research was supported by the National Natural Science Foundation
   of China (Grant No. 61271394 and 61571269). The authors would like to
   thank the anonymous reviewers for their valuable comments.
CR Andoni A, 2008, COMMUNICATIONS ACM 5, V51
   [Anonymous], EUR C COMP VIS
   [Anonymous], P 28 INT C MACH LEAR
   [Anonymous], 2012, MATH PROBL ENG, DOI DOI 10.1155/2012/829451
   [Anonymous], 1984, R TREES DYNAMIC INDE
   [Anonymous], CHEMOM INTELL LAB SY
   [Anonymous], 2010, COMPUTER VISION PATT
   [Anonymous], ADV NEURAL INFORM PR
   Baluja S, 2008, DATA MIN KNOWL DISC, V17, P402, DOI 10.1007/s10618-008-0096-z
   Cheng W, 2014, KNOWL DATA ENG, V26
   Ding G, 2014, COMPUTER VISION PATT
   Friedman JH, 1977, ACM T MATH SOFTW, V3
   Gionis A, 1999, VERY LARGE DATA BASE, V99
   Gong Y, 2011, COMPUTER VISION PATT
   Indyk P., 1998, P 13 ANN ACM S THEOR
   Jegou H, 2011, PATTERN ANAL MACHINE, V33
   Jegou H., 2010, INT J COMPUT VIS, V87
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kong W, 2012, ACM SPECIAL INTEREST
   Kong W, 2012, ASS ADV ARTIFICIAL I
   Lee Y, 2014, COMPUT VIS IMAGE UND, P125
   Lin Z, 2014, MULTIMEDIA TOOLS APP
   Lin Z., 2015, COMPUTER VISION PATT
   Moran S, 2013, ASS COMPUTATIONAL LI
   Moran S, 2013, P 36 INT ACM SIGIR C
   Mu Y., 2010, COMPUTER VISION PATT
   Norouzi M, 2011, INT C MACH LEARN
   Song J, 2011, P 19 ACM INT C MULT
   Uhlmann JK, 1991, INF PROCESS LETT, V40
   Weiss Yair., 2009, NIPS
   Yu Z, 2014, P 37 INT ACM SIGIR C
   Zhou J., 2014, P 37 INT ACM SIGIR C
   Zhu X, 2014, IMAGE PROCESSING, V23
   Zhu X., 2013, P ACM MULT C BARC SP
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
NR 35
TC 3
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2441
EP 2466
DI 10.1007/s11042-015-3217-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000037
DA 2024-07-18
ER

PT J
AU Cui, C
   Wang, S
   Niu, XM
AF Cui, Chen
   Wang, Shen
   Niu, Xiamu
TI A novel watermarking for DIBR 3D images with geometric rectification
   based on feature points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth-image-based rendering (DIBR); 3D image watermarking; Scale
   invariant feature transform (SIFT); Geometric rectification
ID ROBUST
AB Depth-image-based rendering (DIBR) has become an important technology in 3D displaying with its great advantages. As a result, more and more 3D products copyright problems turn out. Since either the center view with depth image or the synthesized virtual views could be illegally distributed, we need to protect not only the center views but also the synthesized virtual views. In this paper, a robust watermarking method for DIBR 3D images is proposed. After applying three-level DWT to the center image, we utilize spread spectrum technology to embed the watermark into suitable coefficients of the sub-blocks of the center image, by this way we make our method robust to typical signal distortions, such as JPEG compression, noise addition and median filter. Meanwhile, in order to make the proposed method robust to some common geometric distortion attacks, SIFT-based feature points are used for geometric rectification to eliminate the effect caused by geometric distortion attacks. As the experimental results shown, the proposed method is much more robust to the common signal distortion attacks with lower BER (bit error rate) compared with existing methods. With geometric rectification, our method also performs good robustness to some simple affine transformations. In addition, the proposed watermarking method also has good robustness to the common operations of DIBR processing system.
C1 [Cui, Chen; Wang, Shen; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Da Zhi St, Harbin, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, S (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Da Zhi St, Harbin, Peoples R China.
EM 394874486@qq.com; shen.wang@hit.edu.cn; xiamu.niu@hit.edu.cn
OI cui, chen/0000-0003-1221-4877
CR Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   [Anonymous], STIRMARK BENCHMARK 4
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], INNOV COMPUT INFORM
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Chan SC, 2007, IEEE SIGNAL PROC MAG, V24, P22, DOI 10.1109/MSP.2007.905702
   Deng Cheng, 2009, Acta Photonica Sinica, V38, P1005
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Dugelay JL, 2006, IEEE T IMAGE PROCESS, V15, P2831, DOI 10.1109/TIP.2006.877311
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Fujii T, 2002, PROC SPIE, V4864, P175, DOI 10.1117/12.454905
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   Hwang DC, 2004, PROC SPIE, V5208, P196, DOI 10.1117/12.506616
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Lee HY, 2006, OPT ENG, V45, DOI 10.1117/1.2181887
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Min-Jeong Lee, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P81, DOI 10.1109/IIHMSP.2011.83
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D., 2007, IEEE C COMPUT VIS PA, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 29
TC 13
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 649
EP 677
DI 10.1007/s11042-015-3028-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000029
DA 2024-07-18
ER

PT J
AU Guo, ZZ
   Zhou, QX
   Liu, ZQ
AF Guo, Zhizhi
   Zhou, Qianxiang
   Liu, Zhongqi
TI Appearance-based gaze estimation under slight head motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze estimation; Feature extraction; Compensation equation; Blink
   recognition
ID ADAPTIVE LINEAR-REGRESSION; REAL-TIME; TRACKING TECHNIQUES; EYE;
   MINIMIZATION; CAMERA; SPARSE; ROBUST
AB At present a lot of gaze estimation methods can get accurate result under ideal conditions, but some practical issues are still the biggest challenges affect the accuracy such as head motion and eye blinking. Improving the accuracy of gaze estimation and the tolerance of head motion are common tasks in the field of gaze estimation. Therefore, this paper aims to propose an accurate gaze estimation method without fixed head pose. The core problem is how to build the mapping relationship between image features and gaze position, and how to resist the head motion through the training samples. To this end, at first, a new input feature, which can well reflect the change of eye image features with different gaze positions, is proposed and it is based on appearance feature and distance feature. So the number of training samples in the process of calibration is significantly reduced. Then a"" (1)-optimization is used to select an optimal set, which represents the mapping relationship between input feature and gaze position. At last, a linear equation is fitted to correct the initial estimation bias which is brought by head motion. In this paper, the experimental results demonstrate that our system achieves accurate result with one camera and a small number of calibration points. The accuracy of final gaze estimation is improved by 22 % through compensation equation. In addition, our system is robustness to eye blink and distance change.
C1 [Guo, Zhizhi; Zhou, Qianxiang; Liu, Zhongqi] Beihang Univ, Sch Biol Sci & Med Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Guo, ZZ (corresponding author), Beihang Univ, Sch Biol Sci & Med Engn, Beijing 100191, Peoples R China.
EM 1016759797@qq.com
RI Zhou, Qian/JMB-8448-2023; zhou, qian/HSG-2858-2023; qian,
   zhou/JGM-3505-2023
CR Alnajar F, 2013, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2013.24
   Beymer D, 2003, PROC CVPR IEEE, P451
   Cheung YM, 2015, IEEE T HUM-MACH SYST, V45, P419, DOI 10.1109/THMS.2015.2400442
   Coutinho FL, 2012, INT J COMPUT VISION, P1
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Drori I, 2006, AC SPEECH SIGN PROC, V3, pIII
   Grauman K, 2001, PROC CVPR IEEE, P1010
   Guestrin ED, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P267, DOI 10.1145/1344471.1344531
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   Jafari R, 2015, EXPERT SYST APPL, V42, P510, DOI 10.1016/j.eswa.2014.08.003
   Lee WO, 2010, J NEUROSCI METH, V193, P356, DOI 10.1016/j.jneumeth.2010.08.034
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Lu F, 2014, IMAGE VISION COMPUT, V32, P169, DOI 10.1016/j.imavis.2014.01.005
   Lu F, 2011, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2011.6126237
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Martinez F, 2012, IEEE IMAGE PROC, P1961, DOI 10.1109/ICIP.2012.6467271
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Nagamatsu T, 2012, IEICE T INF SYST, VE95D, P1656, DOI 10.1587/transinf.E95.D.1656
   Sesma-Sanchez L, 2012, IEEE T BIO-MED ENG, V59, P2235, DOI 10.1109/TBME.2012.2201716
   Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101
   Sun L, 2015, INFORM SCIENCES, V320, P346, DOI 10.1016/j.ins.2015.02.004
   Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Villanueva A., 2007, EURASIP Journal on Image and Video Processing, V2007, P1
   Villanueva A, 2008, IEEE T SYST MAN CY B, V38, P1123, DOI 10.1109/TSMCB.2008.926606
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wright J.D., 2008, 2008 SPE SHAL GAS PR, P1
   Xu Li-Qun, 1998, BMVC, P1
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhu ZW, 2007, IEEE T BIO-MED ENG, V54, P2246, DOI 10.1109/TBME.2007.895750
NR 35
TC 11
Z9 11
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2203
EP 2222
DI 10.1007/s11042-015-3182-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000027
DA 2024-07-18
ER

PT J
AU Himeur, Y
   Boukabou, A
AF Himeur, Yassine
   Boukabou, Abdelkrim
TI Robust image transmission over powerline channel with impulse noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Powerline communication (PLC); OFDM; Impulse noise; Image compression;
   Turbo codes; Adaptive noise clipping; Neighboring coefficients
ID LINE COMMUNICATION-SYSTEMS; BIVARIATE SHRINKAGE; BAND; PERFORMANCE;
   ALGORITHMS; REMOVAL; MODELS
AB This paper addresses the robust image transmission over powerline communication (PLC) channel in the presence of impulse noise. Under this framework, an adaptive noise clipping-based hybrid progressive median filter (ANC-HPMF), which is a combination of hybrid progressive median filter, noise clipping technique, image compression algorithm and coded OFDM modulation is designed to ensure image transmission over the PLC channel. For this purpose, image compression and turbo codes algorithms are inserted before image transmission in order to reduce the size of the transmitted data, and, therefore, save a significant amount of the PLC channel for forward error correction. The adaptive noise clipping method using neighboring coefficients is designed at the receiver side as a first stage. It is based on an improved estimation of noise threshold from the standard deviation of the noise and the peak value of the received noisy image. To enhance the performance of the proposed system, a new form of median filter is applied to the received image as a second stage of impulse noise reduction. By combining the noise clipping and the new median filtering, the proposed technique showed high robustness for the reduction of impulse noise even under high impulse level conditions while maintaining good visual quality of the images by preserving the edges. The performances of the proposed technique were compared with other well-known methods dedicated for impulse noise reduction, and showed much superior performance against the impulse noise generated over the PLC channel.
C1 [Himeur, Yassine; Boukabou, Abdelkrim] Jijel Univ, Dept Elect, BP 98, Jijel 18000, Algeria.
   [Himeur, Yassine] Ctr Dev Adv Technol CDTA, Telecom Div, Algiers 16303, Algeria.
C3 Universite de Jijel
RP Himeur, Y (corresponding author), Jijel Univ, Dept Elect, BP 98, Jijel 18000, Algeria.; Himeur, Y (corresponding author), Ctr Dev Adv Technol CDTA, Telecom Div, Algiers 16303, Algeria.
EM him.yassine@gmail.com; aboukabou@univ-jijel.dz
RI Himeur, Yassine/AAK-7814-2021
OI Himeur, Yassine/0000-0001-8904-5587; Boukabou,
   Abdelkrim/0000-0002-9427-9190
FU DGRSDT (Direction Generale de la Recherche Scientifique et du
   Developpement Technologique) of Algeria [PNR 13/u18/4368]
FX The authors would like to thank the editor and the anonymous referees
   who kindly reviewed this paper and provided valuable suggestions and
   comments. This project was financially supported by the DGRSDT
   (Direction Generale de la Recherche Scientifique et du Developpement
   Technologique) of Algeria (PNR 13/u18/4368).
CR Balbuena-Campuzano CA, 2014, SIGNAL IMAGE VIDEO P, V8, P615, DOI 10.1007/s11760-013-0567-6
   Alsusa E, 2013, IEEE T POWER DELIVER, V28, P2201, DOI 10.1109/TPWRD.2013.2272766
   Amirshahi P, 2006, IEEE T POWER DELIVER, V21, P1927, DOI 10.1109/TPWRD.2006.877073
   Anatory J, 2010, BROADBAND POWER-LINE COMMUNICATION SYSTEMS: THEORY AND APPLICATIONS, P1
   Andreadou N, 2010, IEEE T POWER DELIVER, V25, P1440, DOI 10.1109/TPWRD.2010.2041370
   Andreadou N, 2010, IEEE T POWER DELIVER, V25, P150, DOI 10.1109/TPWRD.2009.2035295
   Andreadou N, 2009, IEEE T POWER DELIVER, V24, P585, DOI 10.1109/TPWRD.2008.2002958
   [Anonymous], 2009, INF COMM SIGN PROC 2
   [Anonymous], 2008, 2008 IEEE 19 INT S P
   Cortés JA, 2010, IEEE T ELECTROMAGN C, V52, P849, DOI 10.1109/TEMC.2010.2052463
   Berrou C., 1993, Near shannon limit error-correcting coding and decoding, P1064, DOI 10.1109/ICC.1993.397441
   Brahimi T, 2009, DIGIT SIGNAL PROCESS, V19, P220, DOI 10.1016/j.dsp.2008.07.012
   Cañete FJ, 2011, IEEE COMMUN MAG, V49, P166, DOI 10.1109/MCOM.2011.6094022
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Degardin V, 2002, IEEE T CONSUM ELECTR, V48, P913, DOI 10.1109/TCE.2003.1196420
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Ferreira H.C., 2010, Power Line Communications: Theory and Applications for Narrowband and Broadband Communications over Power Lines, V1
   Guerrieri L, 2007, PERFORMANCE TURBO CO, P138, DOI DOI 10.1109/ISPLC.2007.371112
   Güzel T, 2011, IEEE T POWER DELIVER, V26, P2735, DOI 10.1109/TPWRD.2011.2164814
   Himeur Y, 2015, INT J ELECT COMMUNIC, DOI [10.1016/j.aeue.2015.08.008, DOI 10.1016/J.AEUE.2015.08.008]
   Himeur Y., 2014, 11 INT C SIGN PROC M, V11, P5
   Himeur Y, 2016, TELECOMMUN SYST, V62, P481, DOI 10.1007/s11235-015-0087-5
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jiang J, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2894, DOI 10.1109/WCICA.2010.5554856
   Katayama M, 2006, IEEE J SEL AREA COMM, V24, P1267, DOI 10.1109/JSAC.2006.874408
   MacKay DJC, 2003, ELECT NOTES THEOR CO, V71, P97
   MIDDLETON D, 1977, IEEE T ELECTROMAGN C, V19, P106, DOI 10.1109/TEMC.1977.303527
   Nassar M, 2012, IEEE SIGNAL PROC MAG, V29, P116, DOI 10.1109/MSP.2012.2187038
   Nikolova Z, 2010, SIGNAL IMAGE VIDEO P, V4, P197, DOI 10.1007/s11760-009-0111-x
   Pighi, 2006, 2006 IEEE INT S POWE, P277
   Pinchas M, 2010, SIGNAL IMAGE VIDEO P, V4, P187, DOI 10.1007/s11760-009-0110-y
   Robertson P, 1997, EUR T TELECOMMUN, V8, P119, DOI 10.1002/ett.4460080202
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Shebl S, 2013, DIGIT SIGNAL PROCESS, V23, P1933, DOI 10.1016/j.dsp.2013.08.001
   Song D, 2008, J VIS COMMUN IMAGE R, V19, P311, DOI 10.1016/j.jvcir.2008.03.003
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Sripimanwat K., 2005, Turbo Code Applications: A Journey from a Paper to Realization", V4a
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Woodard JP, 2000, IEEE T VEH TECHNOL, V49, P2208, DOI 10.1109/25.901892
   Yang Y, 2012, CIRC SYST SIGNAL PR, V31, P827, DOI 10.1007/s00034-011-9346-1
   Yin SF, 2011, SIGNAL PROCESS, V91, P2078, DOI 10.1016/j.sigpro.2011.03.016
   Zhidkov SV, 2008, IEEE T COMMUN, V56, P5, DOI 10.1109/TCOMM.2008.050391
NR 44
TC 9
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2813
EP 2835
DI 10.1007/s11042-015-3216-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000054
DA 2024-07-18
ER

PT J
AU Hwang, I
   Lee, SH
   Park, JS
   Cho, NI
AF Hwang, Insung
   Lee, Sang Hwa
   Park, Jae Sung
   Cho, Nam Ik
TI Saliency detection based on seed propagation in a multilayer graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency; Seed propagation; Multilayer; Contrast prior; Boundary prior;
   Semi-supervised learning
ID REGION DETECTION
AB This paper presents a saliency detection algorithm based on the seed propagation in graph representation of image. First, the image is divided into over-segmented regions and a graph of the connected regions (nodes) with color similarity (edge weight) is constructed. Second, saliency seeds and background seeds are extracted based on contrast and boundary prior respectively. The contrast prior is used to select the regions to be used as saliency seeds, because salient regions usually have high contrast. Meanwhile, the regions for the background seeds are extracted from image boundaries, based on the observation that salient objects are seldom located on the image boundaries. Finally, using a semi-supervised learning framework, both saliency and background seeds are propagated to the entire nodes and the saliency of each node is calculated from the propagated results. In addition, we introduce a multilayer graph to further improve the performance, which makes the saliency values within an object more uniform. Comparison with the state-of-the-art methods shows that our algorithm yields comparable or better results on several datasets in terms of precision-recall curve, ROC curve, F-measure and area under ROC curve, and also show visually plausible results.
C1 [Hwang, Insung; Lee, Sang Hwa; Park, Jae Sung; Cho, Nam Ik] Seoul Natl Univ, Dept Elect & Comp Engn, INMC, Seoul 151742, South Korea.
   [Park, Jae Sung] SAMSUNG Elect Co Ltd, Visual Display Div, Suwon 443742, South Korea.
C3 Seoul National University (SNU); Samsung; Samsung Electronics
RP Cho, NI (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, INMC, Seoul 151742, South Korea.
EM nicho@snu.ac.kr
RI Cho, Nam Ik/I-5029-2014
OI cho, nam ik/0000-0001-5297-4649
FU Projects for Research and Development of Police science and Technology
   under Center for Research and Development of Police science and
   Technology; Korean National Police Agency - Ministry of Science, ICT and
   Future Planning [PA-C000001]
FX This research was supported by Projects for Research and Development of
   Police science and Technology under Center for Research and Development
   of Police science and Technology and Korean National Police Agency
   funded by the Ministry of Science, ICT and Future Planning (PA-C000001).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], TRENDS TOPICS COMPUT
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hu G, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P177
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   ZHOU D, 2004, IN ADVANCES IN NEURA, P321
   Zhou L, 2013, IEEE J SEL AREA COMM, V31, P981, DOI 10.1109/JSAC.2013.130516
NR 29
TC 16
Z9 19
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2111
EP 2129
DI 10.1007/s11042-015-3171-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000024
DA 2024-07-18
ER

PT J
AU Ruiz, D
   Fernández-Escribano, G
   Adzic, V
   Kalva, H
   Martínez, JL
   Cuenca, P
AF Ruiz, Damian
   Fernandez-Escribano, Gerardo
   Adzic, Velibor
   Kalva, Hari
   Luis Martinez, Jose
   Cuenca, Pedro
TI Fast CU partitioning algorithm for HEVC intra coding using data mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Rate distortion optimization; Intra-prediction; Machine learning;
   Coding tree block
ID MODE DECISION ALGORITHM; EFFICIENCY; COMPLEXITY; PREDICTION; MPEG-2
AB The international standard of High Efficiency Video Coding (HEVC) improves the compression ratio by over 50 % compared to H.264/AVC, for the same perceptual quality. HEVC adopts flexible coding unit (CU) partitioning by applying recursive CU splitting into four sub-CUs, up to four depth levels, which causes a significant complexity increase. Intra-prediction coding in HEVC achieves high coding performance through the exhaustive evaluation of all available CU sizes, with up to 35 prediction modes for each CU, selecting the one with the lower rate distortion cost. This work presents a novel CU size classifier comprising an offline-trained decision tree with three hierarchical nodes. The decision rules computed in each node are based on the content texture properties of CUs as well as the inter-sub-CUs statistics of the same depth level. Our approach can reduce the number of CU sizes to be checked by the Rough Mode Decision and Rate Distortion Optimization stages of intra-prediction coding. The experimental results show that the proposed algorithm can achieve over 50 % coding time reduction, with no quality penalty in terms of the Peak Signal to Noise Ratio, and just a low bit rate increase (2 %) compared to the HEVC reference model. A performance comparison with state-of-the-art proposals shows that this algorithm surpasses the best proposal in terms of time reduction, for the same coding performance penalty.
C1 [Ruiz, Damian; Fernandez-Escribano, Gerardo; Luis Martinez, Jose; Cuenca, Pedro] Univ Castilla La Mancha, Inst Invest Informat Albacete, Ave Espana S-N, Albacete 02071, Spain.
   [Adzic, Velibor; Kalva, Hari] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, 777 Glades Rd, Boca Raton, FL 33431 USA.
C3 Universidad de Castilla-La Mancha; State University System of Florida;
   Florida Atlantic University
RP Ruiz, D (corresponding author), Univ Castilla La Mancha, Inst Invest Informat Albacete, Ave Espana S-N, Albacete 02071, Spain.
EM damian.ruiz.coll@gmail.com; gerardo.fernandez@uclm.es; vadzic@fau.edu;
   hkalva@fau.edu; joseluis.martinez@uclm.es; pedro.cuenca@uclm.es
RI Cuenca, Pedro/P-7960-2019; Coll, Damian Ruiz/G-8991-2011; Martinez, Jose
   Luis/ABA-2535-2021; Fernández-Escribano, Gerardo/I-1167-2015
OI Cuenca, Pedro/0000-0002-2791-0165; Coll, Damian
   Ruiz/0000-0002-5538-0608; Martinez, Jose Luis/0000-0001-5119-2418;
   Fernández-Escribano, Gerardo/0000-0002-0037-2061
FU MINECO; European Commission (FEDER funds) [TIN2012-38341-C04-04]
FX This work has been jointly supported by the MINECO and European
   Commission (FEDER funds) under the project TIN2012-38341-C04-04.
CR [Anonymous], C207 JCTVC
   [Anonymous], 2012, JCTVCH0012 ITUTISOIE
   [Anonymous], D250 JCTVC
   [Anonymous], ISOIECJTC1SC29WG11 N
   [Anonymous], ELECTRONIC JOURNAL O, DOI DOI 10.1109/VCIP.2011.6115979
   [Anonymous], 2300823013 ISOIEC
   [Anonymous], ITU T ISO IEC JOINT
   [Anonymous], SG16QC ITUT
   [Anonymous], B100 JCTVC
   [Anonymous], P VPQM 10 SCOTTSD JA
   [Anonymous], VID ENC TRANSC US MA
   [Anonymous], P AAAI 2000 WORKSH L
   Carrillo Paula, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P461, DOI 10.1109/ICCE.2010.5418749
   Chen LS, 2013, I C SERV SYST SERV M, P680, DOI 10.1109/ICSSSM.2013.6602538
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   da Silva TL, 2012, EUR SIGNAL PR CONF, P1214
   Dufaux F, 2009, IEEE SIGNAL PROC MAG, V26, P195, DOI 10.1109/MSP.2009.934187
   Fernández-Escribano G, 2010, IEEE T CIRC SYST VID, V20, P763, DOI 10.1109/TCSVT.2010.2045914
   Fernández-Escribano G, 2008, IEEE T CIRC SYST VID, V18, P172, DOI 10.1109/TCSVT.2008.918115
   Gaoxing Chen, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P514, DOI 10.1109/ChinaSIP.2013.6625393
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Han WJ, 2010, IEEE T CIRC SYST VID, V20, P1709, DOI 10.1109/TCSVT.2010.2092612
   Hanhart P, 2012, PROC SPIE, V8499, DOI 10.1117/12.946036
   Huang HT, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/927873
   Jillani R, 2009, IEEE T CONSUM ELECTR, V55, P277, DOI 10.1109/TCE.2009.4814446
   Kim Y, 2013, ETRI J, V35, P270, DOI 10.4218/etrij.13.0112.0223
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li X, 2011, IEEE T CIRC SYST VID, V21, P957, DOI 10.1109/TCSVT.2011.2133750
   Martinez JL, 2008, IEEE IMAGE PROC, P1140, DOI 10.1109/ICIP.2008.4711961
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian GF, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P405, DOI 10.1109/PCS.2012.6213317
   Nguyen T, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P233, DOI 10.1109/PCS.2012.6213335
   Van Hulse J., 2007, P 24 INT C MACH LEAR, DOI [DOI 10.1145/1273496.1273614, 10.1145/1273496.1273614]
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Yao YB, 2016, MULTIMED TOOLS APPL, V75, P1963, DOI 10.1007/s11042-014-2382-7
   Yu HH, 2013, INT WORK QUAL MULTIM, P12, DOI 10.1109/QoMEX.2013.6603194
NR 44
TC 23
Z9 24
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 861
EP 894
DI 10.1007/s11042-015-3014-6
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000037
DA 2024-07-18
ER

PT J
AU Harakawa, R
   Ogawa, T
   Haseyama, M
AF Harakawa, Ryosuke
   Ogawa, Takahiro
   Haseyama, Miki
TI A Web video retrieval method using hierarchical structure of Web video
   groups
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web video retrieval; Web video group; Hierarchical structure; Strongly
   connected component; Edge betweenness; Modularity
ID DATABASE
AB In this paper, we propose a Web video retrieval method that uses hierarchical structure of Web video groups. Existing retrieval systems require users to input suitable queries that identify the desired contents in order to accurately retrieve Web videos; however, the proposed method enables retrieval of the desired Web videos even if users cannot input the suitable queries. Specifically, we first select representative Web videos from a target video dataset by using link relationships between Web videos obtained via metadata "related videos" and heterogeneous video features. Furthermore, by using the representative Web videos, we construct a network whose nodes and edges respectively correspond to Web videos and links between these Web videos. Then Web video groups, i.e., Web video sets with similar topics are hierarchically extracted based on strongly connected components, edge betweenness and modularity. By exhibiting the obtained hierarchical structure of Web video groups, users can easily grasp the overview of many Web videos. Consequently, even if users cannot write suitable queries that identify the desired contents, it becomes feasible to accurately retrieve the desired Web videos by selecting Web video groups according to the hierarchical structure. Experimental results on actual Web videos verify the effectiveness of our method.
C1 [Harakawa, Ryosuke; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Hokkaido University
RP Harakawa, R (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
EM harakawa@lmd.ist.hokudai.ac.jp; ogawa@lmd.ist.hokudai.ac.jp;
   miki@ist.hokudai.ac.jp
RI Haseyama, Miki/A-6163-2012
OI Ogawa, Takahiro/0000-0001-5332-8112
FU Japan Society for the Promotion of Science (JSPS) [25280036]; MEXT
   [24120002]; Grants-in-Aid for Scientific Research [24120002, 25280036]
   Funding Source: KAKEN
FX This work was partly supported by Grant-in-Aid for Scientific Research
   (B) 25280036, Japan Society for the Promotion of Science (JSPS), and
   Grant-in-Aid for Scientific Research on Innovative Areas 24120002 from
   the MEXT.
CR Allaire G., 2008, Numerical linear algebra
   [Anonymous], 2012, DIGITAL UNIVERSE 202
   [Anonymous], P INT TECH C CIRC SY
   [Anonymous], 2012, P 27 ANN ACM S APPL
   [Anonymous], 2010, P ACM INT C IMAGE VI, DOI [DOI 10.1145/1816041.1816094, 10.1145/1816041, DOI 10.1145/1816041, 10.1145/1816041.1816094]
   [Anonymous], 1991, P VDB
   Arenas A, 2007, NEW J PHYS, V9, DOI 10.1088/1367-2630/9/6/176
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Botafogo R. A., 1991, Third ACM Conference on Hypertext Proceedings, P63, DOI 10.1145/122974.122981
   BRACHMAN RJ, 1983, COMPUTER, V16, P30, DOI 10.1109/MC.1983.1654194
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Fan JP, 2004, IEEE T MULTIMEDIA, V6, P70, DOI 10.1109/TMM.2003.819583
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gargi U., 2011, PROC 5 INT C WEBLOGS, P486
   Harakawa R, 2013, IEEE IMAGE PROC, P4397, DOI 10.1109/ICIP.2013.6738906
   Haseyama M, 2013, ITE TRANS MEDIA TECH, V1, P2, DOI 10.3169/mta.1.2
   Haseyama M, 2013, INT J HUM-COMPUT INT, V29, P96, DOI 10.1080/10447318.2012.692316
   Hatakeyama Y, 2009, IEICE T FUND ELECTR, VE92A, P1961, DOI 10.1587/transfun.E92.A.1961
   Hindle A, 2011, WORLD WIDE WEB, V14, P53, DOI 10.1007/s11280-010-0097-x
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133
   Ngo CW, 2002, IEEE T MULTIMEDIA, V4, P446, DOI 10.1109/TMM.2002.802022
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Nitanda N, 2007, IEICE T FUND ELECTR, VE90A, P1542, DOI 10.1093/ietfec/e90-a.8.1542
   Papadopoulos S, 2012, DATA MIN KNOWL DISC, V24, P515, DOI 10.1007/s10618-011-0224-z
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sang JT, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037687
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Taskiran C, 2004, IEEE T MULTIMEDIA, V6, P103, DOI 10.1109/TMM.2003.819783
   Wang Y., 2012, P ACM INT C MULT, P941, DOI [10.1145/2393347.23963525, DOI 10.1145/2393347.23963525, 10.1145/2393347.2396352, DOI 10.1145/2393347.2396352]
NR 31
TC 5
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17059
EP 17079
DI 10.1007/s11042-015-2976-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, F
   Bharanitharan, K
   Chang, CC
   Mao, Q
AF Li, Fan
   Bharanitharan, K.
   Chang, Chin-Chen
   Mao, Qian
TI Bi-stretch reversible data hiding algorithm for absolute moment block
   truncation coding compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Absolute moment block truncation coding; Hiding
   capacity; Tiny distortion
ID HISTOGRAM-MODIFICATION; DIFFERENCE EXPANSION; TRANSFORM
AB Steganography is one of the most important approaches for secure transmission by concealing secret data into a host image imperceptibly. To achieve a good tradeoff between the hiding capacity and image quality, more work needs to be further researched. In this paper, to obtain satisfactory results, a Bi-Stretch Hiding (BSH) algorithm for absolute moment block truncation coding (AMBTC)-compressed image is proposed. In the scheme, the AMBTC-compressed image is divided into non-overlapped blocks first, after that, four feasible cases are employed to embed secret data, which takes advantage of the characteristics of the coefficients of the AMBTC-compressed image and lead tiny distortion of the AMBTC-compressed image. The experimental results demonstrate that the proposed BSH scheme outperforms the other state-of-the-art compression data hiding methods.
C1 [Li, Fan; Mao, Qian] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
   [Bharanitharan, K.] Hanyang Univ, Dept Elect Engn, 222 Wangsimni Ro, Seoul, South Korea.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Chang, Chin-Chen; Mao, Qian] Asia Univ, Dept Comp Sci & Informat Engn, 500 Lioufeng Rd, Taichung 41354, Taiwan.
C3 University of Shanghai for Science & Technology; Hanyang University;
   Feng Chia University; Asia University Taiwan
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.; Chang, CC (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, 500 Lioufeng Rd, Taichung 41354, Taiwan.
EM lifansunshine@gmail.com; dharan@ieee.org; alan3c@gmail.com;
   maoqiansh@gmail.com
RI Li, Fan/GRX-7461-2022; Li, Fan/JRY-4017-2023; Chang,
   Ching-Chun/JAN-6210-2023
OI Brown, Darren K/0000-0003-1246-1974
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Bhatnagar G, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542207
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Golle P, 2008, ACM T INFORM SYST SE, V12, DOI 10.1145/1455518.1455521
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2012, DIGIT SIGNAL PROCESS, V22, P776, DOI 10.1016/j.dsp.2012.04.004
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI DOI 10.1145/2568224
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Sun HM, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2423636.2423639
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wang XF, 2010, ACM T INFORM SYST SE, V13, DOI 10.1145/1698750.1698758
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
NR 26
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16153
EP 16171
DI 10.1007/s11042-015-2924-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700058
DA 2024-07-18
ER

PT J
AU Mármol, E
   Sevillano, X
AF Marmol, Elena
   Sevillano, Xavier
TI QuickSpot: a video analytics solution for on-street vacant parking spot
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart parking; Computer vision; Vacant parking spot detection
ID FRAMEWORK
AB Vehicles searching for a vacant parking spot on the street can amount to as much as 40 % of the traffic in certain city areas, thus largely affecting mobility in urban environments. For this reason, it would be desirable to create integrated smart traffic management systems capable of providing real-time information to drivers about the location of available vacant parking spots. A scalable solution would consist in exploiting the existing and widely-deployed video surveillance camera networks, which requires the development of computer vision algorithms for detecting vacant parking spots. Following this idea, this work introduces QuickSpot, a car-driven video analytics solution for on-street vacant parking spot detection designed as a motion detection, object tracking and visual recognition pipeline. One of the main features of QuickSpot is its simplified setup, as it can be trained on external databases to learn the appearances of the objects it is capable of recognizing (pedestrians and vehicles). To test its performance under different daytime lighting conditions, we have recorded, edited, annotated and made available to the research community the QuickSpotDB video database for the vacant parking spot detection problem. In the conducted experiments, we have evaluated the trade-off between the accuracy and the computational complexity of QuickSpot with an eye to its practical applicability. The results show that QuickSpot detects parking spot status with an average accuracy close to 99 % at a 1-second rate regardless of the illumination conditions, outperforming in an indirect comparison the other car-driven approaches reported in the literature.
C1 [Marmol, Elena; Sevillano, Xavier] La Salle Univ Ramon Llull, GTM Grp Recerca Tecnol Media, Quatre Camins 30, Barcelona 08022, Spain.
C3 Universitat Ramon Llull
RP Sevillano, X (corresponding author), La Salle Univ Ramon Llull, GTM Grp Recerca Tecnol Media, Quatre Camins 30, Barcelona 08022, Spain.
EM emarmol@salleurl.edu; xavis@salleurl.edu
RI Sevillano, Xavier/ABF-5507-2020
OI Sevillano, Xavier/0000-0002-6209-3033
CR Albiol A, 2011, IEEE T INTELL TRANSP, V12, P1277, DOI 10.1109/TITS.2011.2156791
   Almeida P, 2013, IEEE SYS MAN CYBERN, P3603, DOI 10.1109/SMC.2013.614
   [Anonymous], ECE201101 BOST U
   [Anonymous], P CVPR
   [Anonymous], ECE200506 BOST U DEP
   [Anonymous], P S SIGN PROC IM COM
   [Anonymous], 2015, P IEEE INT C ADV VID
   [Anonymous], MACH LEARN FAL
   [Anonymous], P INT C INF FUS
   [Anonymous], P FUZZ
   [Anonymous], P WSCG
   [Anonymous], IET COMPUT VIS
   [Anonymous], P AVBS
   [Anonymous], 2007, VACANT PARKING SPACE
   [Anonymous], P INT C SOUND VIBR
   [Anonymous], CURB CARS SHOPP PARK
   [Anonymous], 2011, Eur. Transp. Res. Rev.
   [Anonymous], P ASCE INT WORKSH CO
   [Anonymous], P IEEE C INT TRANSP
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bong D. B. L., 2008, IAENG International Journal of Computer Science, V35, P7
   Ching-Chun Huang, 2012, 2012 12th International Conference on ITS Telecommunications (ITST 2012), P284, DOI 10.1109/ITST.2012.6425183
   Choeychuen K., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P12, DOI 10.1109/JCSSE.2012.6261917
   de Almeida PRL, 2015, EXPERT SYST APPL, V42, P4937, DOI 10.1016/j.eswa.2015.02.009
   Fabián T, 2008, SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER INFORMATION SYSTEMS AND INDUSTRIAL MANAGEMENT APPLICATIONS, PROCEEDINGS, P165, DOI 10.1109/CISIM.2008.53
   Fabian T, 2013, ADV INTELL SYST COMP, V226, P733, DOI 10.1007/978-3-319-00969-8_72
   Fan QF, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P223, DOI 10.1109/AVSS.2014.6918672
   Funck S, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P325
   del Postigo CG, 2015, IET INTELL TRANSP SY, V9, P835, DOI 10.1049/iet-its.2014.0090
   Huang CC, 2008, INT CONF ACOUST SPEE, P2097
   Huang CC, 2013, IEEE T CIRC SYST VID, V23, P1598, DOI 10.1109/TCSVT.2013.2254961
   Huang CC, 2010, IEEE T CIRC SYST VID, V20, P1770, DOI 10.1109/TCSVT.2010.2087510
   Ichihashi H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P127, DOI 10.1109/FUZZY.2009.5277099
   Idris M. Y. I., 2009, Information Technology Journal, V8, P101, DOI 10.3923/itj.2009.101.113
   Jermsurawong Jermsak, 2014, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V14, P33
   Jermsurawong J, 2012, 10TH INTERNATIONAL CONFERENCE ON FRONTIERS OF INFORMATION TECHNOLOGY (FIT 2012), P84, DOI 10.1109/FIT.2012.24
   Kim J, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P283, DOI 10.1109/AVSS.2014.6918682
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Li YD, 2016, MULTIMED TOOLS APPL, V75, P11683, DOI 10.1007/s11042-015-2676-4
   Li-Chih Chen, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P631, DOI 10.1109/IIHMSP.2010.160
   Lin NL, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CIRCUITS AND SYSTEMS (ICCAS), P137, DOI 10.1109/ICCircuitsAndSystems.2012.6408305
   Liu JZ, 2013, IEEE I C ELECT CIRC, P933, DOI 10.1109/ICECS.2013.6815565
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Martchouk M, 2011, J TRANSP ENG, V137, P697, DOI 10.1061/(ASCE)TE.1943-5436.0000253
   Ortego D, 2015, IEEE SIGNAL PROC LET, V22, P2368, DOI 10.1109/LSP.2015.2482598
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Sastre RJL, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1675, DOI 10.1109/ISIE.2007.4374856
   Sevillano Xavier, 2014, 2014 17th International Conference on Information Fusion (FUSION 2014)
   Sevillano X, 2016, NOISE MAPP, V3, P172, DOI 10.1515/noise-2016-0013
   Lin SF, 2006, IEEE SYS MAN CYBERN, P2897, DOI 10.1109/ICSMC.2006.385314
   Shi XM, 2016, MULTIMED TOOLS APPL, V75, P12547, DOI 10.1007/s11042-014-2343-1
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Wang YP, 2015, AER ADV ENG RES, V27, P516
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Wolff J., 2006, 2006 IEEE Intelligent Transportation Systems Conference, P1275
   Wu Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P659
   Yao YJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P45, DOI 10.1109/SOLI.2013.6611379
   Zhong C, 2014, COMPUT ENVIRON URBAN, V48, P124, DOI 10.1016/j.compenvurbsys.2014.07.004
   Zou YX, 2011, MULTIMED TOOLS APPL, V52, P133, DOI 10.1007/s11042-010-0466-6
NR 59
TC 22
Z9 25
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17711
EP 17743
DI 10.1007/s11042-016-3773-8
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600045
DA 2024-07-18
ER

PT J
AU De Meester, B
   Verborgh, R
   Pauwels, P
   De Neve, W
   Mannens, E
   Van de Walle, R
AF De Meester, Ben
   Verborgh, Ruben
   Pauwels, Pieter
   De Neve, Wesley
   Mannens, Erik
   Van de Walle, Rik
TI Towards robust and reliable multimedia analysis through semantic
   integration of services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia analysis; Reasoning cycle; Semantic reasoning; Web services
ID WEB SERVICES; RECOGNITION
AB Thanks to ubiquitous Web connectivity and portable multimedia devices, it has never been so easy to produce and distribute new multimedia resources such as videos, photos, and audio. This ever-increasing production leads to an information overload for consumers, which calls for efficient multimedia retrieval techniques. Multimedia resources can be efficiently retrieved using their metadata, but the multimedia analysis methods that can automatically generate this metadata are currently not reliable enough for highly diverse multimedia content. A reliable and automatic method for analyzing general multimedia content is needed. We introduce a domain-agnostic framework that annotates multimedia resources using currently available multimedia analysis methods. By using a three-step reasoning cycle, this framework can assess and improve the quality of multimedia analysis results, by consecutively (1) combining analysis results effectively, (2) predicting which results might need improvement, and (3) invoking compatible analysis methods to retrieve new results. By using semantic descriptions for the Web services that wrap the multimedia analysis methods, compatible services can be automatically selected. By using additional semantic reasoning on these semantic descriptions, the different services can be repurposed across different use cases. We evaluated this problem-agnostic framework in the context of video face detection, and showed that it is capable of providing the best analysis results regardless of the input video. The proposed methodology can serve as a basis to build a generic multimedia annotation platform, which returns reliable results for diverse multimedia analysis problems. This allows for better metadata generation, and improves the efficient retrieval of multimedia resources.
C1 [De Meester, Ben; Verborgh, Ruben; De Neve, Wesley; Mannens, Erik; Van de Walle, Rik] Univ Ghent, iMinds, Multimedia Lab, Gaston Crommenlaan 8 Bus 201, B-9050 Ledeberg Ghent, Belgium.
   [Pauwels, Pieter] Univ Ghent, Dept Architecture & Urban Planning, Jozef Plateaustr 22, B-9000 Ghent, Belgium.
   [De Neve, Wesley] Korea Adv Inst Sci & Technol, Image & Video Syst Lab, 335 Ghawak Ro 373-1 Guseong Dong, Daejeon 305701, South Korea.
C3 Ghent University; IMEC; Ghent University; Korea Advanced Institute of
   Science & Technology (KAIST)
RP De Meester, B (corresponding author), Univ Ghent, iMinds, Multimedia Lab, Gaston Crommenlaan 8 Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM ben.demeester@ugent.be; ruben.verborgh@ugent.be;
   pipauwel.pauwels@ugent.be; wesley.deneve@ugent.be;
   erik.mannens@ugent.be; rik.vandewalle@ugent.be
RI De Meester, Ben/AAR-4511-2020; De Neve, Wesley Marcel/C-6480-2008;
   Pauwels, Pieter/I-8256-2015; Verborgh, Ruben/P-6571-2014
OI De Meester, Ben/0000-0003-0248-0987; De Neve, Wesley
   Marcel/0000-0002-8190-3839; Pauwels, Pieter/0000-0001-8020-4609;
   Mannens, Erik/0000-0001-7946-4884; Verborgh, Ruben/0000-0002-8596-222X
FU Ghent University; iMinds; Institute for the Promotion of Innovation by
   Science and Technology in Flanders (IWT); Fund for Scientific Research
   Flanders (FWO Flanders); European Union
FX The described research activities were funded by Ghent University,
   iMinds, the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research Flanders
   (FWO Flanders), and the European Union.
CR [Anonymous], 2004, W3C recommendation
   [Anonymous], J CONVERGENCE
   [Anonymous], 2014, WORLD TEL ICT IND DA
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   De Roo J, 2013, EULER YET ANOTHER PR
   Drummond N, 2006, ESI WORKSH CLOS WORL
   Erdmann M., 2000, Proceedings of the COLING-2000Workshop on Semantic Annotation and Intelligent Content, P79
   Fensel D, 2002, LECT NOTES ARTIF INT, V2479, P319
   Hanani U, 2001, USER MODEL USER-ADAP, V11, P203, DOI 10.1023/A:1011196000674
   Hauptmann AG, 2005, LECT NOTES COMPUT SC, V3568, P1
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Huang Y-P, 2012, J CONVERG, V3, P1
   Jaeger MC, 2004, EIGHTH IEEE INTERNATIONAL ENTERPRISE DISTRIBUTED OBJECT COMPUTING CONFERENCE, PROCEEDINGS, P149, DOI 10.1109/EDOC.2004.1342512
   Lanthaler M, 2013, P WWW2013 WORKSH LIN, V6
   Ma M, 2012, J INF PROCESS SYST, V8, P653, DOI 10.3745/JIPS.2012.8.4.653
   Menascé DA, 2004, IEEE INTERNET COMPUT, V8, P88, DOI 10.1109/MIC.2004.57
   Ohkawara T, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-11
   Pauwels P, 2013, LIT LINGUIST COMPUT, V28, P452, DOI 10.1093/llc/fqs056
   Sarkar K, 2012, J INF PROCESS SYST, V8, P693
   Satone MP, 2012, J INF PROCESS SYST, V8, P483
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Silas S, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-5
   Smith A, 2013, SMARTPHONE OWNERSHIP, P12
   SMITH DR, 1985, SCI COMPUT PROGRAM, V5, P37, DOI 10.1016/0167-6423(85)90003-6
   Smith JR, 2006, IEEE MULTIMEDIA, V13, P84, DOI 10.1109/MMUL.2006.34
   Verborgh R, 2013, MULTIMED TOOLS APPL, V64, P365, DOI 10.1007/s11042-012-1004-5
   Verborgh R, 2012, MULTIMED TOOLS APPL, V61, P105, DOI 10.1007/s11042-010-0709-6
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wolfgang Pree., 1994, DESIGN PATTERNS OBJE
   Yen N. Y., 2012, J CONVERGENCE, V3, P37
   ZADEH LA, 1988, COMPUTER, V21, P83, DOI 10.1109/2.53
   Zeng LZ, 2004, IEEE T SOFTWARE ENG, V30, P311, DOI 10.1109/TSE.2004.11
   Zhu YH, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-15
NR 34
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14019
EP 14038
DI 10.1007/s11042-014-2445-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500002
DA 2024-07-18
ER

PT J
AU An, Y
   Lee, J
   Park, J
AF An, Youngeun
   Lee, Jimin
   Park, Jongan
TI Image retrieval technique using the clustering based on rearranged radon
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radon transform; Clustering; Rearranged; Shape based image retrieval
AB This study proposed a new image retrieval technique in which the existing radon transform that was used for image retrieval is reinforced with noise invariance. For this, a radon transform was performed on an inquiry image which had been preprocessed to extract vector values and then the vector values were arranged depending on size to extract a second feature vector. After clustering and normalizing the levels of vector values based on the second feature vector, the feature vector was created. For a simulation on the image retrieval technique using the clustering based on rearranged radon transform, diverse images were used in this experiment. For performance analysis, the system proposed was compared with the retrieval system using a rearrangement hough transform based on voting number. As a result, the proposed image retrieval technique was more robust to geometric transforms such as rotated and scaled in the retrieval technique using the general radon transform and standard hough transform, and it had recall enhanced to 0.05 and precision enhanced to 0.04 in comparison with the rearrangement hough transform based on voting number.
C1 [An, Youngeun] Chosun Univ, Coll Gen Educ, 309 Pilmun Daero, Gwangju, South Korea.
   [Lee, Jimin] A Joo Commun Inc, Res Inst, 219 Pungseojwa Ro, Gwangju, South Korea.
   [Park, Jongan] Chosun Univ, Coll Elect & Informat Engn, 309 Pilmun Daero, Gwangju, South Korea.
C3 Chosun University; Chosun University
RP Park, J (corresponding author), Chosun Univ, Coll Elect & Informat Engn, 309 Pilmun Daero, Gwangju, South Korea.
EM yean@chosun.ac.kr; histhing@naver.com; japark@chosun.ac.kr
FU Chosun University
FX study was supported by research funds from Chosun University, 2014.
CR Aggarwal N, 2006, IEEE T IMAGE PROCESS, V15, P582, DOI 10.1109/TIP.2005.863021
   [Anonymous], THESIS
   Bo-Ho Cho, 2008, Journal of KISS: Computing Practices, V14, P291
   Brown RG, 2010, INT J COMPUT APPL T, V39, P72, DOI 10.1504/IJCAT.2010.034733
   Capi Genci, 2010, International Journal of Intelligent Systems Technologies and Applications, V9, P97, DOI 10.1504/IJISTA.2010.034315
   Chatterjee A, 2011, EXPERT SYST APPL, V38, P8266, DOI 10.1016/j.eswa.2011.01.007
   Dorado Adrian, 2015, Journal of Information and Communication Convergence Engineering, V13, P132, DOI 10.6109/jicce.2015.13.2.132
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fishbain B, 2010, J REAL-TIME IMAGE PR, V5, P213, DOI 10.1007/s11554-010-0180-7
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gonzalez RC, 1992, WOODS DIGITAL IMAGE
   Hart PE, 2009, IEEE SIGNAL PROC MAG, V26, P18, DOI 10.1109/MSP.2009.934181
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Hough PVC., 1959, P INT C HIGH EN ACC, V590914, P554
   Kim J, 2000, DEV MPEG 7 TECHNOLOG, P37
   Li WC, 2011, IEEE T IND INFORM, V7, P136, DOI 10.1109/TII.2009.2034844
   Luengo Hendriks CL, 2005, PATTERN RECOGN, V38, P2494, DOI 10.1016/j.patcog.2005.04.018
   Martiney JA, 2003, FCRAR, V2003, P1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park SJ, 2004, LECT NOTES COMPUT SC, V3046, P948
   Patel M, 2010, INT J ELECTRON TELEC, V56, P457, DOI 10.2478/v10177-010-0062-8
   Press WH, 2006, P NATL ACAD SCI USA, V103, P19249, DOI 10.1073/pnas.0609228103
   Radon J., 1986, IEEE Transactions on Medical Imaging, VMI-5, P170, DOI 10.1109/TMI.1986.4307775
   ROSENFELD A, 1969, PICTURE PROCESSING C
   Thuc ND, 2004, INT C EL INF COMM, P274
   Won J, 1998, J KOREAN SOC REMOTE, V14, P17
NR 26
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12983
EP 12997
DI 10.1007/s11042-016-3527-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700040
DA 2024-07-18
ER

PT J
AU Mademlis, I
   Iosifidis, A
   Tefas, A
   Nikolaidis, N
   Pitas, I
AF Mademlis, Ioannis
   Iosifidis, Alexandros
   Tefas, Anastasios
   Nikolaidis, Nikos
   Pitas, Ioannis
TI Exploiting stereoscopic disparity for augmenting human activity
   recognition performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Stereoscopic video description; Bag of
   features; Disparity zones
AB This work investigates several ways to exploit scene depth information, implicitly available through the modality of stereoscopic disparity in 3D videos, with the purpose of augmenting performance in the problem of recognizing complex human activities in natural settings. The standard state-of-the-art activity recognition algorithmic pipeline consists in the consecutive stages of video description, video representation and video classification. Multimodal, depth-aware modifications to standard methods are being proposed and studied, both for video description and for video representation, that indirectly incorporate scene geometry information derived from stereo disparity. At the description level, this is made possible by suitably manipulating video interest points based on disparity data. At the representation level, the followed approach represents each video by multiple vectors corresponding to different disparity zones, resulting in multiple activity descriptions defined by disparity characteristics. In both cases, a scene segmentation is thus implicitly implemented, based on the distance of each imaged object from the camera during video acquisition. The investigated approaches are flexible and able to cooperate with any monocular low-level feature descriptor. They are evaluated using a publicly available activity recognition dataset of unconstrained stereoscopic 3D videos, consisting in extracts from Hollywood movies, and compared both against competing depth-aware approaches and a state-of-the-art monocular algorithm. Quantitative evaluation reveals that some of the examined approaches achieve state-of-the-art performance.
C1 [Mademlis, Ioannis; Tefas, Anastasios; Nikolaidis, Nikos; Pitas, Ioannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
   [Iosifidis, Alexandros] Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki; Aristotle University of
   Thessaloniki
RP Mademlis, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
EM imademlis@aiia.csd.auth.gr; aiosif@aiia.csd.auth.gr;
   tefas@aiia.csd.auth.gr; nikolaid@aiia.csd.auth.gr;
   pitas@aiia.csd.auth.gr
RI Nikolaidis, Nikos/F-1819-2010; Mademlis, Ioannis/K-3673-2019; Tefas,
   Anastasios/ABA-2328-2020; Tefas, Anastasios/F-1899-2010; Iosifidis,
   Alexandros/G-2433-2013
OI Nikolaidis, Nikos/0000-0003-1515-7986; Mademlis,
   Ioannis/0000-0001-5479-0632; Tefas, Anastasios/0000-0003-1288-3667;
   Iosifidis, Alexandros/0000-0003-4807-1345
FU European Union Seventh Framework Programme (FP7) [287674 (3DTVS)]
FX The research leading to these results has received funding from the
   European Union Seventh Framework Programme (FP7/2007-2013) under grant
   agreement number 287674 (3DTVS). This publication reflects only the
   author's views. The European Union is not liable for any use that may be
   made of the information contained therein.
CR [Anonymous], ARXIV13123429V2
   [Anonymous], 2004, ECCV WORKSHOPS
   Biswas K. K., 2011, IEEE P INT C AUT ROB
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Hadfield S., 2013, IEEE P C COMP VIS PA
   Iosifidis A., 2012, EUR SIGN PROC C EUSI
   Iosifidis A., 2012, IEEE INT C AC SPEECH
   Iosifidis A, 2014, PATTERN RECOGN LETT, V49, P185, DOI 10.1016/j.patrec.2014.07.011
   Iosifidis A, 2014, NEUROCOMPUTING, V145, P250, DOI 10.1016/j.neucom.2014.05.036
   Iosifidis A, 2013, IEEE T CIRC SYST VID, V23, P1968, DOI 10.1109/TCSVT.2013.2269774
   Iosifidis A, 2013, PATTERN RECOGN LETT, V34, P1890, DOI 10.1016/j.patrec.2012.10.019
   Iosifidis A, 2013, SIGNAL PROCESS, V93, P1445, DOI 10.1016/j.sigpro.2012.08.015
   Iosifidis A, 2012, IEEE T NEUR NET LEAR, V23, P412, DOI 10.1109/TNNLS.2011.2181865
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I., 2008, IEEE P C COMP VIS PA
   Le QV, 2011, PROC CVPR IEEE
   Marszalek M., 2009, IEEE P C COMP VIS PA
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Riechert C., 2011, P EUR C VIS MED PROD
   Sanchez-Riera J., 2012, EUR C COMP VIS
   Sanchez-Riera J., 2012, P ECCV WORKSH, V7583
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sigalas P, 2009, P INT C INT ROB SYST
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 28
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11641
EP 11660
DI 10.1007/s11042-015-2719-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200004
DA 2024-07-18
ER

PT J
AU Xu, Z
   Hu, CP
   Mei, L
AF Xu, Zheng
   Hu, Chuanping
   Mei, Lin
TI Video structured description technology based intelligence analysis of
   surveillance videos for public security applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video structured description; Surveillance videos; Public security
AB Video surveillance is an integrated system with strong prevention capabilities and widely used in military, customs, police, fire fighting, airports, railways, urban transport and many other public places. It's an important part of security system because of its visualized, accurate, timely and rich information content. Video surveillance has become the main tool due to its rich, intuitive and accurate information. However, with the large-scale construction of video surveillance systems all over the world, problems such as "useful information and clues cannot be found immediately with video big data" decrease detecting efficiency during crime prediction and public security governance. The increasing need of video based applications issues the importance of parsing and organizing the content in videos. However, the accurate understanding and managing video contents at the semantic level is still insufficient. The semantic gap between low level features and high level semantics cannot be bridged by manual or semi-automatic methods. In this paper, a semantic based model named video structural description (VSD) for representing and organizing the content in videos is introduced firstly. Video structural description aims at parsing video content into the text information, which uses spatiotemporal segmentation, feature selection, object recognition, and semantic web technology. The applications of VSD technology on public security from surveillance videos are given. The intelligent analysis of person and vehicle from surveillance video based on VSD is presented. The cloud enhanced platform managing surveillance videos is also given. At last, applications using VSD are introduced.
C1 [Xu, Zheng; Hu, Chuanping; Mei, Lin] Minist Publ Secur, Res Inst 3, Shanghai 201142, Peoples R China.
C3 Ministry of Public Security (China)
RP Mei, L (corresponding author), Minist Publ Secur, Res Inst 3, Shanghai 201142, Peoples R China.
EM xuzheng@shu.edu.cn; l_mei72@hotmail.com
FU National Science and Technology Major Project [2013ZX01033002-003];
   National High Technology Research and Development Program of China (863
   Program) [2013AA014601]; National Science Foundation of China
   [61300202]; China Postdoctoral Science Foundation [2014 M560085];
   Science Foundation of Shanghai [13ZR1452900]
FX This work was supported in part by the National Science and Technology
   Major Project under Grant 2013ZX01033002-003, in part by the National
   High Technology Research and Development Program of China (863 Program)
   under Grant 2013AA014601, in part by the National Science Foundation of
   China under Grant 61300202, in part by the China Postdoctoral Science
   Foundation under Grant 2014 M560085, and in part by the Science
   Foundation of Shanghai under Grant 13ZR1452900,
CR Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Cheng HT, 2012, PROC CVPR IEEE, P741, DOI 10.1109/CVPR.2012.6247744
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Felzenszwalb P. F., 2009, PAMI, V32, P1627, DOI [DOI 10.1109/TPAMI.2009.167, 10.1109/TPAMI.2009.167]
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Javed K, 2012, IEEE T KNOWL DATA EN, V24, P465, DOI 10.1109/TKDE.2010.263
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu YH, 2011, IEEE T PARALL DISTR, V22, P2100, DOI 10.1109/TPDS.2011.113
   Liu YH, 2010, IEEE T PARALL DISTR, V21, P405, DOI 10.1109/TPDS.2009.57
   Luo XF, 2011, IEEE T AUTOM SCI ENG, V8, P482, DOI 10.1109/TASE.2010.2094608
   Ma Y, 2013, CONCURR COMP-PRACT E, V25, P1784, DOI 10.1002/cpe.2965
   Plebani P, 2009, IEEE T KNOWL DATA EN, V21, P1629, DOI 10.1109/TKDE.2009.35
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang LZ, 2013, FUTURE GENER COMP SY, V29, P739, DOI 10.1016/j.future.2012.09.001
   Wigan MR, 2013, COMPUTER, V46, P46, DOI 10.1109/MC.2013.195
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Xu Z, 2011, COMPUT SYST SCI ENG, V26, P153
   Zhuge H, 2009, IEEE T KNOWL DATA EN, V21, P785, DOI 10.1109/TKDE.2008.141
NR 21
TC 48
Z9 48
U1 1
U2 73
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12155
EP 12172
DI 10.1007/s11042-015-3112-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200032
DA 2024-07-18
ER

PT J
AU Yu, J
   Luo, CW
   Yu, LY
   Li, LY
   Wang, ZF
AF Yu, Jun
   Luo, Changwei
   Yu, Lingyun
   Li, Lingyan
   Wang, Zengfu
TI Facial video coding/decoding at ultra-low bit-rate: a 2D/3D model-based
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding/decoding; Facial motion tracking; Facial animation; Hair
   analysis and modeling
ID EXPRESSION RECOGNITION; VISUAL TRACKING; MOTION; HAIR
AB A real-time facial video coding/decoding system was proposed based on the establishment of 2D/3D mixed coding/decoding scheme. It has better rate/distortion performance at ultra-low bit-rate. Multi-measurements and online appearance models were applied to track the 3D facial motion from video by the improved particle filtering. 3D facial animation was produced by combining the parameterized model and muscular model. 3D hair was synthesized based on the hair detection result in video. 3D coding/decoding result of foreground and 2D coding/decoding result of background were stitched seamlessly. At ultra-low bit-rate, the objective experiment confirmed the comprehensive advantage between coding efficiency and decoding quality of this system, and the subjective experiment indicated the suitability of subjective face identification by it.
C1 [Yu, Jun; Luo, Changwei; Yu, Lingyun; Li, Lingyan; Wang, Zengfu] Univ Sci & Technol China, Dept Automat, Hefei, Peoples R China.
   [Wang, Zengfu] Chinese Acad Sci, Inst Intelligent Machines, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Hefei Institutes of Physical
   Science, CAS
RP Yu, J (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei, Peoples R China.
EM harryjun@ustc.edu.cn
RI zhan, xiao/JEZ-3810-2023
CR Ahlberg J., 2002, THESIS
   [Anonymous], 2001, TECHNICAL REPORT
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1976, DOI 10.1016/j.patrec.2006.05.008
   Balci Koray., 2007, MULTIMEDIA'07: Proceedings of the 15th international conference on Multimedia, P1013
   Black MJ, 1997, INT J COMPUT VISION, V13, P1491
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   CHOWDHURY MF, 1994, IEEE T CIRC SYST VID, V4, P216, DOI 10.1109/76.305867
   Dornaika F, 2005, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2005.225
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   Eisert P, 2000, IEEE T CIRC SYST VID, V10, P344, DOI 10.1109/76.836279
   Gao M. C., 2015, METALL MATER TRANS A, V47, P3322, DOI DOI 10.1007/S11661-015-3091-1
   Gokturk SB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P701, DOI 10.1109/ICCV.2001.937695
   Grassberger P, 1997, PHYS REV E, V56, P3682, DOI 10.1103/PhysRevE.56.3682
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Hu YK, 2006, INT C PATT RECOG, P1147
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Juang CF, 2011, IEEE T FUZZY SYST, V19, P717, DOI 10.1109/TFUZZ.2011.2140326
   Kampmann M, 2002, IEEE T CIRC SYST VID, V12, P172, DOI 10.1109/76.993438
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Levin A., 2007, COMPUTER VISION PATT, P1
   Liao WK, 2007, LECT NOTES COMPUT SC, V4778, P109
   Liao Wei-keng., 2008, High Performance Computing, Networking, Storage and Analysis, P1, DOI DOI 10.1061/40988(323)169
   Lui YM, 2010, IEEE T SYST MAN CY A, V40, P437, DOI 10.1109/TSMCA.2010.2041655
   Marcos S, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3810, DOI 10.1109/IROS.2008.4650814
   Marcos S, 2010, INTERACT COMPUT, V22, P176, DOI 10.1016/j.intcom.2009.12.002
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Schwalb M, 2009, IEEE T MULTIMEDIA, V11, P1, DOI 10.1109/TMM.2008.2008873
   Strom J, 2002, THESIS
   Sung J, 2008, INT J COMPUT VIS, V80
   Wang WM, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P521, DOI 10.1109/ICIG.2009.26
   Ward K, 2007, IEEE T VIS COMPUT GR, V13, P213, DOI 10.1109/TVCG.2007.30
   Waters FIPK, 1996, COMPUTER FACIAL ANIM
   Waters K., 1987, COMPUTER GRAPHICS, V22, P17
   Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646
   Yacoob Y, 2005, IEEE I CONF COMP VIS, P741
   Yu J, 2015, IEEE T CYBERNETICS, V45, P977, DOI 10.1109/TCYB.2014.2341737
   Yuankui H, 2005, IEEE INT WORKSH VIS, P46
   Zhang W, 2008, LECT NOTES COMPUT SC, V5303, P720, DOI 10.1007/978-3-540-88688-4_53
   Zhou S, 2004, IEEE T IMAGE PROCESS, V76, P257
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 41
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12021
EP 12041
DI 10.1007/s11042-016-3368-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200025
DA 2024-07-18
ER

PT J
AU Bagchi, P
   Bhattacharjee, D
   Nasipuri, M
AF Bagchi, Parama
   Bhattacharjee, Debotosh
   Nasipuri, Mita
TI A robust analysis, detection and recognition of facial features in 2.5D
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2,5D image; Range image; 3D Harris corner detector; Facial landmarks
ID FACE RECOGNITION
AB A robust technique for recognition of 3D faces which performs well with face images with various poses, expressions and occlusions. In this method, the face images represented in 3D mesh format are smoothed using trilinear interpolation and then converted to 2.5D image or range images. Nose-tip which is the most prominent feature on human face is detected first on the corner points selected by 3D Harris corner and curvedness at those corner points. K-Means clustering is applied to group those corner points in 2 groups. The cluster of points with larger curvedness values represents the possible locations of nose-tip. Nose-tip is finally localized using Mean-Gaussian curvature values of the prospective corner points in that cluster. Using the nose-tip location, other facial landmarks namely corners of the eyes and mouth are located and a facial graph is generated. The dimensionality of 2.5D feature space is that, depth values are stored at each (x, y) grid of the 2.5D image, so a 3D face image uses some function to map the depth value at any pixel position to the intensity with which that pixel will be displayed. Here finally extracted features for each subject is of dimensionality [1x21], taking into account the Euclidean distances in three dimensional form between each feature points detected automatically. Taking Euclidean distances between all pairs of landmark points as features, face images are classified using Multilayer Perceptron (MLP), as well as Support Vector Machines (SVM). Maximum recognition rates of 75 and 87.5 % have been obtained in case of Bosphorus Databases, 62.5 and 87.5 % in case of GavabDB databases, 75 and 87.5 % in case of Frav3D Databases by Multilayer Perceptron and Support Vector Machines respectively.
C1 [Bagchi, Parama] RCC Inst Informat Technol, Dept Comp Sci & Engn, Kolkata, India.
   [Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 RCC Institute of Information Technology (RCCIIT); Jadavpur University
RP Bagchi, P (corresponding author), RCC Inst Informat Technol, Dept Comp Sci & Engn, Kolkata, India.
EM paramabagchi@gmail.com; debotosh@ieee.org; mitanasipuri@gmail.com
RI Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee, Debotosh/Q-4065-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413
FU DeiTY, MCIT, Govt. of India, at the Department of Computer Science and
   Engineering, Jadavpur University, India
FX Authors are thankful for a project entitled "Development of 3D Face
   Recognition Techniques Based on Range Images," supported by DeiTY, MCIT,
   Govt. of India, at the Department of Computer Science and Engineering,
   Jadavpur University, India for providing the necessary infrastructure to
   conduct experiments relating to this work.
CR Alyuz N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P111, DOI 10.1109/ICB.2012.6199767
   Amberg B, 2008, 8 INT C AUTOMATIC FA, P1
   [Anonymous], SOFT COMPUT
   [Anonymous], INT C INT SOC PHOT R
   [Anonymous], INT C IM PROC COMP V
   [Anonymous], 3RDINTERNATIONAL C B
   [Anonymous], 2NDINTERNATIONAL C S
   [Anonymous], ADV DEPTH IMAGE ANAL
   [Anonymous], 1THINTERNATIONAL C C
   [Anonymous], ACM TOMS
   [Anonymous], 2011, VISUAL COMPUT, DOI DOI 10.1007/s00371-011-0610-y
   Cantzler H, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P285, DOI 10.1109/IM.2001.924458
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   GORDON GG, 1991, P SOC PHOTO-OPT INS, V1570, P234, DOI 10.1117/12.48428
   Hajati F, 2012, PATTERN RECOGN, V45, P969, DOI 10.1016/j.patcog.2011.08.025
   Inan T, 2012, IEEE T INF FOREN SEC, V7, P577, DOI 10.1109/TIFS.2012.2186293
   Li XX, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P21, DOI 10.1109/SMI.2007.4
   Liu XA, 2015, MULTIMED TOOLS APPL, V74, P2803, DOI 10.1007/s11042-013-1698-z
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784
   Mahoor MH, 2009, PATTERN RECOGN, V42, P445, DOI 10.1016/j.patcog.2008.08.012
   MORENO A, 2003, IR MACH VIS IM PROC
   Moreno AB, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P185, DOI 10.1109/ISPA.2005.195407
   MORENO AB, 2003, P IR MACH VIS IM PRO
   Mousavi MH, 2008, 7TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE IN CONJUNCTION WITH 2ND IEEE/ACIS INTERNATIONAL WORKSHOP ON E-ACTIVITY, PROCEEDINGS, P208, DOI 10.1109/ICIS.2008.77
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Perakis P., 2010, Tech. Rep. TP-2010-01
   Perakis P, 2013, IEEE T PATTERN ANAL, V35, P1552, DOI 10.1109/TPAMI.2012.247
   Salahshoor Sadegh, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P253, DOI 10.1007/978-3-642-31254-0_29
   Wang XW., 2014, Biomed Res Int, V2014, P198697, DOI [DOI 10.1155/2014/198697, 10.1155/2014/198697]
NR 31
TC 9
Z9 19
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11059
EP 11096
DI 10.1007/s11042-015-2835-7
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900012
DA 2024-07-18
ER

PT J
AU Mstafa, RJ
   Elleithy, KM
AF Mstafa, Ramadhan J.
   Elleithy, Khaled M.
TI A video steganography algorithm based on Kanade-Lucas-Tomasi tracking
   algorithm and error correcting codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Smart video transmission; Hamming codes; Face
   detection; Smart video tracking; KLT tracking; ROI
ID WATERMARKING
AB Due to the significant growth of video data over the Internet, video steganography has become a popular choice. The effectiveness of any steganographic algorithm depends on the embedding efficiency, embedding payload, and robustness against attackers. The lack of the preprocessing stage, less security, and low quality of stego videos are the major issues of many existing steganographic methods. The preprocessing stage includes the procedure of manipulating both secret data and cover videos prior to the embedding stage. In this paper, we address these problems by proposing a novel video steganographic method based on Kanade-Lucas-Tomasi (KLT) tracking using Hamming codes (15, 11). The proposed method consists of four main stages: a) the secret message is preprocessed using Hamming codes (15, 11), producing an encoded message, b) face detection and tracking are performed on the cover videos, determining the region of interest (ROI), defined as facial regions, c) the encoded secret message is embedded using an adaptive LSB substitution method in the ROIs of video frames. In each facial pixel 1 LSB, 2 LSBs, 3 LSBs, and 4 LSBs are utilized to embed 3, 6, 9, and 12 bits of the secret message, respectively, and d) the process of extracting the secret message from the RGB color components of the facial regions of stego video is executed. Experimental results demonstrate that the proposed method achieves higher embedding capacity as well as better visual quality of stego videos. Furthermore, the two preprocessing steps increase the security and robustness of the proposed algorithm as compared to state-of-the-art methods.
C1 [Mstafa, Ramadhan J.; Elleithy, Khaled M.] Univ Bridgeport, Dept Comp Sci & Engn, Bridgeport, CT 06604 USA.
C3 University of Bridgeport
RP Mstafa, RJ (corresponding author), Univ Bridgeport, Dept Comp Sci & Engn, Bridgeport, CT 06604 USA.
EM rmstafa@my.bridgeport.edu; elleithy@bridgeport.edu
RI Mstafa, Ramadhan J./G-4533-2015
OI Mstafa, Ramadhan J./0000-0002-6122-234X; Elleithy,
   Khaled/0000-0001-9239-5035
CR Alavianmehr M. A., 2012, 2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE 2012), P194, DOI 10.1109/ICCKE.2012.6395377
   [Anonymous], INF SEC INT CONTR IS
   [Anonymous], 1991, CMUCS91132
   [Anonymous], REALTIME KLT FEATURE
   Bhole AT, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P189
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheddad A, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P905, DOI 10.1109/ICME.2008.4607582
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2324, DOI 10.1016/j.sigpro.2009.02.001
   Egiazarian K, 2006, P 2 INT WORKSHOP VID
   Farschi SMR, 2012, NONLINEAR DYNAM, V69, P1525, DOI 10.1007/s11071-012-0367-5
   Fontaine C, 2007, LECT NOTES COMPUT SC, V4567, P130
   Guangjie Liu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P642, DOI 10.1109/MINES.2011.138
   Hasnaoui M, 2014, SIGNAL PROCESS-IMAGE, V29, P107, DOI 10.1016/j.image.2013.07.007
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Isukapalli R, 2005, LECT NOTES COMPUT SC, V3723, P70
   Kelash HM, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P353, DOI 10.1109/ICTC.2013.6675372
   Khupse S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P811, DOI 10.1109/ICICICT.2014.6781384
   Lan TH, 2006, IEEE T IMAGE PROCESS, V15, P2431, DOI 10.1109/TIP.2006.875238
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Liu GJ, 2012, INT C MULTIMED INFO, P323, DOI 10.1109/MINES.2012.55
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Moon SK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P660, DOI 10.1109/ICIIP.2013.6707677
   Mstafa R.J., 2015, IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI 10.1109/LISAT.2015.7160192
   Mstafa R.J., 2015, Wireless Telecommunications Symposium (WTS), P1
   Mustafa RJ., 2014, SYST APPL TECHN C LI, V2014, P2014, DOI [10.1109/LISAT.2014.6845191, DOI 10.1109/LISAT.2014.6845191]
   Paul R., 2013, Confluence 2013: The Next Generation Information Technology Summit (4th International Conference), P337, DOI DOI 10.1049/CP.2013.2338
   Ponomarenko N., 2007, INT WORKSH VID PROC
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Rupa C., 2013, Journal of the Institution of Engineers (India) Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V94, P147, DOI 10.1007/s40031-013-0054-z
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sarkar A, 2010, IEEE T INF FOREN SEC, V5, P225, DOI 10.1109/TIFS.2010.2046218
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Torres-Pereira E, 2014, LECT NOTES COMPUT SC, V8827, P810, DOI 10.1007/978-3-319-12568-8_98
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Zhang RY, 2009, LECT NOTES COMPUT SC, V5806, P48, DOI 10.1007/978-3-642-04431-1_4
NR 45
TC 51
Z9 53
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10311
EP 10333
DI 10.1007/s11042-015-3060-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800011
DA 2024-07-18
ER

PT J
AU Poignant, J
   Fortier, G
   Besacier, L
   Quénot, G
AF Poignant, Johann
   Fortier, Guillaume
   Besacier, Laurent
   Quenot, Georges
TI Naming multi-modal clusters to identify persons in TV broadcast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal fusion; VideoOCR; Face and speaker identification; TV
   broadcast
ID FACES
AB Persons' identification in TV broadcast is one of the main tools to index this type of videos. The classical way is to use biometric face and speaker models, but, to cover a decent number of persons, costly annotations are needed. Over the recent years, several works have proposed to use other sources of names for identifying people, such as pronounced names and written names. The main idea is to form face/speaker clusters based on their similarities and to propagate these names onto clusters. In this paper, we propose a method to take advantage of written names during the diarization process, in order to both name clusters and prevent the fusion of two clusters named differently. First, we extract written names with the LOOV tool (Poignant et al. 2012); these names are associated to their co-occurring speaker turns / face tracks. Simultaneously, we build a multi-modal matrix of distances between speaker turns and face tracks. Then agglomerative clustering is performed on this matrix with the constraint to avoid merging clusters associated to different names. We also integrate the prediction of few biometric models (anchors, some journalists) to directly identify speaker turns / face tracks before the clustering process. Our approach was evaluated on the REPERE corpus and reached an F-measure of 68.2% for speaker identification and 60.2 % for face identification. Adding few biometric models improves results and leads to 82.4 % and 65.6 % for speaker and face identity respectively. By comparison, a mono-modal, supervised person identification system with 706 speaker models trained on matching development data and additional TV and radio data provides 67.8 % F-measure, while 908 face models provide only 30.5 % F-measure.
C1 [Poignant, Johann; Fortier, Guillaume; Besacier, Laurent; Quenot, Georges] Univ Grenoble Alpes, LIG, F-38000 Grenoble, France.
   [Poignant, Johann; Fortier, Guillaume; Besacier, Laurent; Quenot, Georges] CNRS, LIG, F-38000 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes;
   Institut National Polytechnique de Grenoble; Universite Grenoble Alpes
   (UGA); Centre National de la Recherche Scientifique (CNRS)
RP Poignant, J (corresponding author), Univ Grenoble Alpes, LIG, F-38000 Grenoble, France.; Poignant, J (corresponding author), CNRS, LIG, F-38000 Grenoble, France.
EM Johann.Poignant@imag.fr
FU OSEO (French State agency for innovation); ANR (French national research
   agency)
FX This work was partly realized as part of the Quaero Program and the
   QCompere project, respectively funded by OSEO (French State agency for
   innovation) and ANR (French national research agency
CR [Anonymous], 1998, P DARPA BROADC NEWS
   Barras C, 2006, IEEE T AUDIO SPEECH, V14, P1505, DOI 10.1109/TASL.2006.878261
   Bauml Martin, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P441, DOI 10.1109/AVSS.2010.42
   Bechet F, 2014, INTERSPEECH, P135
   Bendris M, 2013, INT WORK CONTENT MUL, P243, DOI 10.1109/CBMI.2013.6576591
   Bredin H, 2013, 1 WORKSH SPEECH LANG
   Bredin H, 2014, INT J MULTIMEDIA INF
   Bredin H, 2013, INTERSPEECH, P1466
   Bredin H, 2012, LECT NOTES COMPUT SC, V7585, P385, DOI 10.1007/978-3-642-33885-4_39
   Canseco L, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P415
   Canseco-Rodriguez L, 2004, 5 ANN C INT SPEECH C
   Esteve Y., 2007, 8 ANN C INT SPEECH C, P2601
   Favre B, 2013, 1 WORKSH SPEECH LANG
   Gay P, 2014, 12 INT WORKSH CONT B
   Giraudel A, 2012, 8 INT C LANG RES EV
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Houghton R, 1999, IEEE INTELL SYST APP, V14, P45, DOI 10.1109/5254.796089
   Jousse V, 2009, AUTOMATIC NAMED IDEN
   Kahne J., 2012, Political Psychology, V34, P1
   Khoury E, 2012, MULTIMEDIA TOOLS APP
   Le VB, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P146
   Mauclair J, 2006, IEEE OD 2006 SPEAK L
   Petitrenand S, 2010, COMM COM INF SC, V80, P179
   Pham PT, 2010, IEEE INT C MULT EXP
   Pham PT, 2011, IEEE MULTIMEDIA, V18, P44, DOI 10.1109/MMUL.2011.22
   Poignant J., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P854, DOI 10.1109/ICME.2012.119
   Poignant J, 2013, 10 C RECH INF APPL C
   Poignant J, 2013, 14 ANN C INT SPEECH
   Poignant J, 2013, 1 WORKSH SPEECH LANG
   Poignant J, 2014, DOCUMENTS NUMRIQUES, P37
   Poignant J, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2649
   Rouvier M, 2014, 12 INT WORKSH CONT B
   Rouvier M, 2012, OD SPEAK LANG REC WO
   Sato T, 1999, ACM MULTIMEDIA SYSTE
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Tranter SE, 2006, INT CONF ACOUST SPEE, P1013
   Uricar Michal, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P547
   Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28
   Yang J., 2004, NAMING EVERY INDIVID
NR 39
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8999
EP 9023
DI 10.1007/s11042-015-2723-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500011
DA 2024-07-18
ER

PT J
AU Tamaazousti, M
   Naudet-Collette, S
   Gay-Bellile, V
   Bourgeois, S
   Besbes, B
   Dhome, M
AF Tamaazousti, M.
   Naudet-Collette, S.
   Gay-Bellile, V.
   Bourgeois, S.
   Besbes, B.
   Dhome, M.
TI The constrained SLAM framework for non-instrumented augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Tracking; Constrained SLAM; Optical see-through; Head
   mounted display; Hand-based interaction
ID VISUAL TRACKING; POSE ESTIMATION; RECOGNITION
AB This paper addresses the challenging issue of marker less tracking for Augmented Reality. It proposes a real-time camera localization in a partially known environment, i.e. for which a geometric 3D model of one static object in the scene is available. We propose to take benefit from this geometric model to improve the localization of keyframe-based SLAM by constraining the local bundle adjustment process with this additional information. We demonstrate the advantages of this solution, called contrained SLAM, on both synthetic and real data and present very convincing augmentation of 3D objects in real-time. Using this tracker, we also propose an interactive augmented reality system for training application. This system, based on a Optical See-Through Head Mounted Display, allows to augment the users vision field with virtual information accurately co-registered with the real world. To keep greatly benefit of the potential of this hand free device, the system combines the tracker module with a simple user-interaction vision-based module to provide overlaid information in response to user requests.
C1 [Tamaazousti, M.; Naudet-Collette, S.; Bourgeois, S.; Besbes, B.] CEA, LIST, Vis & Content Engn Lab, F-91191 Gif Sur Yvette, France.
   Univ Blaise Pascal, Pascal Inst, UMR 660, F-63000 Clermont Ferrand, France.
C3 Universite Paris Saclay; CEA; Centre National de la Recherche
   Scientifique (CNRS); Universite Clermont Auvergne (UCA)
RP Naudet-Collette, S (corresponding author), CEA, LIST, Vis & Content Engn Lab, F-91191 Gif Sur Yvette, France.
EM sylvie.naudet@cea.fr; dhome@lasmea.univ-bpclermont.fr
CR [Anonymous], 2011, P 24 ANN ACM S US IN, DOI DOI 10.1145/2047196.2047255
   [Anonymous], 2006, PHOTOGRAMMETRIC COMP
   [Anonymous], 2007, INT S MIX AUGM REAL
   Bartoli A, 2003, INT J COMPUT VISION, V52, P45, DOI 10.1023/A:1022318524906
   Benhimane S, 2006, INT C INT ROB SYST
   Bleser G, 2006, INT SYM MIX AUGMENT, P223
   Caron G, 2014, IMAGE VISION COMPUT, V32, P54, DOI 10.1016/j.imavis.2013.10.007
   Chun W. H., 2013, P 2013 INT C INT US, P307, DOI [DOI 10.1145/2449396.2449435, 10.1145/2449396.2449435]
   COMPORT AI, 2003, INT S MIX AUGM REAL
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Farenzena M, 2008, EUR C COMP VIS ECCV
   Gay-Bellile V, 2010, INT C COMP VIS THEOR
   Gay-Bellile V, 2010, INT S MIX AUGM REAL
   Harris C., 1992, Tracking with Rigid Objects
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kempter T, 2012, COMP VIS WINT WORKSH
   Klein Georg., 2008, ECCV
   Kurz D, 2007, P 2007 6 IEEE ACM IN, P1
   Kurz D, 2014, INT SYM MIX AUGMENT, P9, DOI 10.1109/ISMAR.2014.6948403
   Kyrki V, 2011, MACH VISION APPL, V22, P323, DOI 10.1007/s00138-009-0214-y
   LADIKOS A, 2007, INT C COMP VIS THEOR
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Lothe P, 2010, COMPUTER VISION PATT
   Lothe P., 2009, COMPUTER VISION PATT
   Lourakis MIA, 2005, INT C COMP VIS ICCV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marchand E, 1999, INT C COMP VIS ICCV
   Marchand T, 2002, COMPUT GRAPH FORUM, V21, P289, DOI 10.1111/1467-8659.t01-1-00588
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Mouragnon E, 2006, C COMP VIS PATT REC
   Newcombe R. A., 2011, INT C COMP VIS ICCV
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nister David, 2004, COMPUTER VISION PATT
   Petit A, 2012, INT C INT ROB SYST I
   Platonov J, 2006, INT SYM MIX AUGMENT, P149
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Royer E., 2005, IEEE C COMP VIS PATT
   Simon G, 2002, IEEE COMPUT GRAPH, V22, P46, DOI 10.1109/MCG.2002.1046628
   Simon G, 2011, INT SYM MIX AUGMENT
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Sourimant G, 2007, COMP GRAPH INT C CGI
   Strasdat H, 2010, INT C ROB AUT ICRA
   Sturm P, 2000, PROC CVPR IEEE, P706, DOI 10.1109/CVPR.2000.855889
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tamaazousti M, 2011, COMPUTER VISION PATT
   Tamaazousti M, 2011, INT WORKSH AR MR REG
   Triggs B, 2000, INT WORKSH VIS ALG T
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Vacchetti L., 2004, INT S MIX AUGM REAL
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Whelan T., 2013, INT C ROB AUT ICRA
   Whelan T., 2012, Proceedings of the RSS Workshop on RGB-D: Advanced Reasoning with Depth Cameras
   Wuest H, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P62
   Wuest H., 2007, J VIRTUAL REAL BROAD, V4
   Wuest H., 2007, COMPUTER ANAL IMAGES
NR 58
TC 7
Z9 7
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9511
EP 9547
DI 10.1007/s11042-015-2968-8
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500002
DA 2024-07-18
ER

PT J
AU Zhang, H
   Zhang, WP
   Liu, WH
   Xu, X
   Fan, HH
AF Zhang, Hong
   Zhang, Wenping
   Liu, Wenhe
   Xu, Xin
   Fan, Hehe
TI Multiple kernel visual-auditory representation learning for retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple kernel learning; Visual-auditory data representation;
   Cross-media retrieval
ID INFORMATION-RETRIEVAL; CANONICAL CORRELATION; FEATURE-SELECTION
AB Cross-media data representation, which focuses on semantics understanding of multimedia data in different modalities, is a rising hot topic in web media data analysis. The most challenging issues for cross-media data representation include: how to find underlying content-level data correlations and how to use such correlations in the representation model. Most traditional web media data analysis works are based on single modality data sources, such as Flickr images or YouTube videos, leaving cross-media data representation and semantics understanding wide open. In this paper, we propose a multiple kernel visual-auditory representation learning approach, which learns cross-media correlations from visual and auditory feature spaces with multiple kernel strategies. Besides, we give cross-media distance measure for image-audio retrieval in the mutual subspace of co-occurrence. Experiment results on the collected image-audio database are encouraging, and show that the performance of our approach is effective from multiple perspectives.
C1 [Zhang, Hong; Zhang, Wenping; Xu, Xin] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.
   [Zhang, Hong] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
   [Liu, Wenhe] Univ Technol Sydney UTS, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW, Australia.
   [Fan, Hehe] Baidu, Beijing, Peoples R China.
C3 Wuhan University of Science & Technology; University of Technology
   Sydney; Baidu
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.; Zhang, H (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
EM zhanghong_wust@163.com
RI Xu, Xin/JRW-5800-2023
FU National Natural Science Foundation of China [61003127, 61373109,
   61440016]; China Scholarship Council [201508420248]
FX This research is supported by the National Natural Science Foundation of
   China (No.61003127, No. 61373109, No.61440016) and the China Scholarship
   Council (201508420248).
CR [Anonymous], P ACM SIGKDD C KNOWL
   [Anonymous], INT C MACH LEARN ICM
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Chang Xiaojun, 2015, SEARCHING PERSUASIVE
   Gao DD, 2000, LINEAR ALGEBRA APPL, V321, P47, DOI 10.1016/S0024-3795(99)00085-3
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Jain P, 2012, J MACH LEARN RES, V13, P519
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu Gaowen., 2014, ICMR
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu Y, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P91, DOI 10.1145/1459359.1459372
   Ma Q, 2006, INFORM SYST, V31, P659, DOI 10.1016/j.is.2005.12.004
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Shen HQ, 2015, MULTIMED TOOLS APPL, V74, P523, DOI 10.1007/s11042-014-1936-z
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Thomas M, 2003, PATTERN RECOGN, V27, P1
   Tolias G, 2015, COMPUT VIS IMAGE UND, V140, P9, DOI 10.1016/j.cviu.2015.06.007
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Vapnik V, 1997, IEEE T NEURAL NETW, V8
   Varma M., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P1065, DOI DOI 10.1145/1553374.1553510
   Vishwanathan S., 2010, Proc. of Neural Information Processing Systems, P2361
   Wang DY, 2014, IEEE T PATTERN ANAL, V36, P550, DOI 10.1109/TPAMI.2013.145
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Xia H., 2012, IEEE T PATTERN ANAL, V1, P1
   Yan Y, IEEE T PATT IN PRESS
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563
   Zhang H, 2014, ACM INT C MULT
   Zhang H, 2016, NEUROCOMPUTING, V173, P93, DOI 10.1016/j.neucom.2015.07.104
   Zhang H, 2013, NEUROCOMPUTING, V119, P10, DOI 10.1016/j.neucom.2012.03.033
   Zhang H, 2012, NEUROCOMPUTING, V93, P100, DOI 10.1016/j.neucom.2012.03.007
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 39
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9169
EP 9184
DI 10.1007/s11042-016-3294-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500019
DA 2024-07-18
ER

PT J
AU Li, XJ
   Zhao, HL
   Huang, H
   Hu, ZY
   Xiao, L
AF Li, Xujie
   Zhao, Hanli
   Huang, Hui
   Hu, Zhongyi
   Xiao, Lei
TI Interactive image recoloring by combining global and local optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recoloring; Global optimization; Local optimization; Color
   propagation
AB We propose a novel interactive image recoloring method by combining global and local optimization. Our approach assumes that each pixel is a linear transform of its neighbors which can be in spatial or feature space. Corresponding, a new framework for combining global and local energy optimization is designed and derived. By taking advantage of global and local color propagation, our approach requires only a few user scribbles to produce the high-quality results. We show various experimental results and comparisons on image recoloring. Compared with the state-of-the-art methods, our approach produces higher-quality results with only a small amount of user interaction than those only consider local propagation or global propagation approaches.
C1 [Li, Xujie; Zhao, Hanli; Huang, Hui; Hu, Zhongyi; Xiao, Lei] Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Peoples R China.
C3 Wenzhou University
RP Li, XJ (corresponding author), Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Peoples R China.
EM lixujie@aliyun.com; hanlizhao@gmail.com; huanghui@wzu.edu.cn;
   hujunyi@163.com; xiaolei@wzu.edu.cn
FU National Natural Science Foundation of China [61100146]; Zhejiang
   Provincial Natural Science Foundation of China [LQ14F020006, LQ12F02010,
   LY12F02015, LY12F02014]; Science and Technology Plan Program of Wenzhou,
   China [G20130017, S20100053]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61100146), the Zhejiang Provincial Natural Science
   Foundation of China (Grant Nos. LQ14F020006, LQ12F02010, LY12F02015 and
   LY12F02014), and the Science and Technology Plan Program of Wenzhou,
   China (Grant Nos. G20130017 and No. S20100053).
CR An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   Beigpour S, 2011, IEEE I CONF COMP VIS, P327, DOI 10.1109/ICCV.2011.6126259
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Chen XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366151
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Criminisi A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857910
   Farbman Z, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866171
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hsu E, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1399504.1360669, 10.1145/1360612.1360669]
   Huang H., 2014, J NANOMATER, V2014, P1, DOI DOI 10.1371/J0URNAL.P0NE.0091570
   Krishnan D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024211
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Lin S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461988
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Musialski P, 2013, VISUAL COMPUT, V29, P1173, DOI 10.1007/s00371-012-0761-5
   Olonetsky I, 2012, LECT NOTES COMPUT SC, V7575, P602, DOI 10.1007/978-3-642-33765-9_43
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Seo S, 2013, MULTIMED TOOLS APPL, V64, P293, DOI 10.1007/s11042-012-1024-1
   Sheng B, 2014, IEEE T CIRC SYST VID, V24, P407, DOI 10.1109/TCSVT.2013.2276702
   Sheng B, 2011, IEEE COMPUT GRAPH, V31, P24, DOI 10.1109/MCG.2011.18
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 27
TC 10
Z9 11
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6431
EP 6443
DI 10.1007/s11042-015-2579-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700018
DA 2024-07-18
ER

PT J
AU Nuricumbo, JR
   Ali, H
   Márton, ZC
   Grzegorzek, M
AF Nuricumbo, Jorge Rene
   Ali, Haider
   Marton, Zoltan-Csaba
   Grzegorzek, Marcin
TI Improving object classification robustness in RGB-D using adaptive SVMs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive SVM; aSVM; RGB-D; Kinect
ID DOMAIN ADAPTATION; RECOGNITION
AB Nowadays object recognition is a fundamental capability for an autonomous robot in interaction with the physical world. Taking advantage of new sensing technologies providing RGB-D data, the object recognition capabilities increase dramatically. Object recognition has been well studied, however, known object classifiers usually feature poor generality and, therefore, limited adaptivity to different application domains. Although some domain adaptation approaches have been presented for RGB data, little work has been done on understanding the effects of applying object classification algorithms using RGB-D for different domains. Addressing this problem, we propose and comprehensively investigate an approach for object recognition in RGB-D data that uses adaptive Support Vector Machines (aSVM) and, in this way, achieves an impressive robustness in cross-domain adaptivity. For evaluation, two datasets from different application domains were used. Moreover, a study of state-of-the-art RGB-D feature extraction techniques and object classification methods was performed to identify which combinations (object representation - classification algorithm) remain less affected in terms of performance while switching between different application domains.
C1 [Nuricumbo, Jorge Rene; Grzegorzek, Marcin] Univ Siegen, Pattern Recognit Grp, Hoelderlinstr 3, D-57076 Siegen, Germany.
   [Ali, Haider; Marton, Zoltan-Csaba] DLR German Aerosp Ctr, Inst Robot & Mechatron RM, Muenchner Str 20, D-82234 Oberpfaffenhofen, Germany.
C3 Universitat Siegen; Helmholtz Association; German Aerospace Centre (DLR)
RP Grzegorzek, M (corresponding author), Univ Siegen, Pattern Recognit Grp, Hoelderlinstr 3, D-57076 Siegen, Germany.
EM jorge.nmorales@student.uni-siegen.de; haider.ali@dlr.de;
   zoltan.marton@dlr.de; marcin.grzegorzek@uni-siegen.de
RI Grzegorzek, Marcin/AAF-1647-2021
OI Grzegorzek, Marcin/0000-0003-4877-8287
CR Aldoma A, 2012, IEEE ROBOT AUTOM MAG, V19, P80, DOI 10.1109/MRA.2012.2206675
   [Anonymous], ROBOTICS SCI SYSTEMS
   [Anonymous], 2007, ACL
   [Anonymous], 2012, WORKSH COL DEPTH CAM
   [Anonymous], ACL
   [Anonymous], 2008, P 21 IEEE RSJ INT C
   [Anonymous], 2008, CVPR
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Chang C.-C., ACM T INTELLIGENT SY, V2
   Daumé H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Grzegorzek M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P553
   Grzegorzek M, 2010, PATTERN ANAL APPL, V13, P333, DOI 10.1007/s10044-009-0163-0
   Grzegorzek M, 2010, IEEE MULTIMEDIA, V17, P56, DOI 10.1109/MMUL.2010.16
   Hoffman J, 2012, LECT NOTES COMPUT SC, V7573, P702, DOI 10.1007/978-3-642-33709-3_50
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu L., 2013, 23 INT JOINT C ART I
   Madry M, 2011, EUR ROB FOR 2011 RGB
   Marton ZC, 2012, ENSEMBLES STRONG LEA
   Richtsfeld A, 2014, J VIS COMMUN IMAGE R, V25, P64, DOI 10.1016/j.jvcir.2013.04.006
   Roark B., 2003, PROC 2003 C N AM CHA, P126
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shirahama K., 2014, MULTIMEDIA TOOLS APP
   Spinello L, 2012, IEEE INT CONF ROBOT, P4469, DOI 10.1109/ICRA.2012.6225137
   Wahl Eric, 2003, 3D DIGITAL IMAGING M
   Yang J., 2007, P 15 ACM INT C MULT, P188
NR 30
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6829
EP 6847
DI 10.1007/s11042-015-2612-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400007
DA 2024-07-18
ER

PT J
AU Suditu, N
   Fleuret, F
AF Suditu, Nicolae
   Fleuret, Francois
TI Adaptive relevance feedback for large-scale image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Query-free; Large-scale; Interactive
   relevance feedback; Adaptive exploration/exploitation trade-off;
   Log-based similarity learning; Multi-modal indexing features; User-based
   evaluation
ID ANNOTATION; FRAMEWORK
AB Content-based image retrieval aims at substituting traditional indexing based on manual annotation by using automatically-extracted visual indexing features. Novel techniques are needed however to efficiently deal with the semantic gap (i.e. the partial match between the low-level features and the visual content). Here, we investigate a query-free retrieval approach first proposed by Ferecatu and Geman. This approach relies solely on an iterative relevance feedback mechanism that drives a heuristic sampling of the collection, and aims to take explicitly into account the semantic gap. Our contributions are related to three complementary aspects. First, we formalize a large-scale approach based on a hierarchical tree-like organization of the images computed off-line. Second, we propose a versatile modulation of the exploration/exploitation trade-off based on the consistency of the system internal states between successive iterations. Third, we elaborate a long-term optimization of the similarity metric based on the user searching session logs accumulated off-line. We implemented a web-application that integrates all our contributions, and distribute it under the AGPL Version 3 free software license. We organized user-based evaluation campaigns using ImageNet dataset, and show empirically that our contributions significantly improve the retrieval performance of the original framework, that they are complementary to each other, and that their overall integration is consistently beneficial.
C1 [Suditu, Nicolae; Fleuret, Francois] Idiap Res Inst, Rue Marconi 19, CH-1920 Martigny, Switzerland.
RP Suditu, N (corresponding author), Idiap Res Inst, Rue Marconi 19, CH-1920 Martigny, Switzerland.
EM nicolae.suditu@gmail.com; francois.fleuret@idiap.ch
OI Fleuret, Francois/0000-0001-9457-7393
FU Hasler Foundation; European Community [247022 - MASH]
FX Nicolae Suditu was supported by the Hasler Foundation through the EMMA
   project. Francois Fleuret was supported in part by the European
   Community's Seventh Framework Programme FP7 - Challenge 2 - Cognitive
   Systems, Interaction, Robotics - under grant agreement No 247022 - MASH.
   The authors would like to express their thanks to Prof.Dr. Donald Geman
   and Dr. Marin Ferecatu for their constructive feedback and fruitful
   discussions that served as inspiration.
CR Abello J, 2004, LECT NOTES COMPUT SC, V3383, P431
   [Anonymous], 2007, International Conference on Computer Vision (ICCV)
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Buchsbaum AL, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P566
   Campbell I, 1996, COLIS 2 - SECOND INTERNATIONAL CONFERENCE ON CONCEPTIONS OF LIBRARY AND INFORMATION SCIENCE: INTEGRATION IN PERSPECTIVE, PROCEEDINGS, P251
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   CHANG E, 2001, P ACM MULT OCT, P611
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Emre Celebi M, 2005, P ART INT RES SOC C, P245
   Fang YC, 2005, LECT NOTES COMPUT SC, V3546, P637
   Ferecatu M, 2009, IEEE T PATTERN ANAL, V31, P1087, DOI 10.1109/TPAMI.2008.259
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Han JW, 2005, IEEE T IMAGE PROCESS, V14, P511, DOI 10.1109/TIP.2004.841205
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Hoi SCH, 2006, IEEE T KNOWL DATA EN, V18, P509, DOI 10.1109/TKDE.2006.1599389
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Suditu N, 2012, P 21 ACM INT C INF K, P1323, DOI DOI 10.1145/2396761.2398435
   Suditu N, 2011, IEEE I CONF COMP VIS, P2118, DOI 10.1109/ICCV.2011.6126487
   Urban J, 2006, MULTIMED TOOLS APPL, V31, P1, DOI 10.1007/s11042-006-0035-1
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 30
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6777
EP 6807
DI 10.1007/s11042-015-2610-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400005
DA 2024-07-18
ER

PT J
AU Almadani, B
   Alsaeedi, M
   Al-Roubaiey, A
AF Almadani, Basem
   Alsaeedi, Mohammed
   Al-Roubaiey, Anas
TI QoS-aware scalable video streaming using data distribution service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-Time video streaming; DDS; RTPS; H.264/AVC; H.264/SVC; Scalable
   video streaming
ID REAL-TIME VIDEO; FRIENDLY RATE CONTROL; TRANSMISSION; ALLOCATION;
   EFFICIENT; SVC
AB Enabling Real-Time video streaming over wireless networks is a challenging task due to the time-varying channel conditions and the limited network resources. The instability of wireless networks leads to problems such as limited and time-varying bandwidth, and unexpected traffic congestion when transmitting a burst of video streams. In Real-Time video streaming, each frame must be delivered and decoded by its playback time. Recently, layer coding (LC) has enabled Real-Time and scalable video streaming to clients of heterogeneous capabilities by dropping upper enhancement layers without the need of re-encoding and with much less bit rate. However, layer coding still facing unfair layer protection problem in which packets from the base or lower layers might be dropped while there is a chance to drop packets from the upper enhancement layers. Losing packets from the base layer can significantly affect the delivered video quality and sometimes lead to an interruption especially in error-prone networks as wireless networks. Architectural solutions at the middleware level introduce higher flexibility, more efficiency in development time and more QoS control. This work investigates the behavior of video streaming over Real-Time publish-subscribe based middleware. We propose and develop an unequal layer protection mechanism for Real-Time video streaming based on the Data Distribution Service (DDS) middleware. A combination of video quality of service (QoS) is proposed to adapt the video transmission to the time-varying network changes. The performance of Real-Time video streaming is measured over IEEE 802.11 g WLAN network. The results show a graceful degradation of video quality while maintaining a robust video streaming free of visible error or interruptions. This is due to the intentionally dropping of some enhancement video stream layers in order to protect lower layers, and therefore maintain a continuous video flow of acceptable quality. Numerical results indicate that the proposed scheme is able to achieve higher throughput and improve the average received video quality especially in a large number of video subscribers.
C1 [Almadani, Basem; Alsaeedi, Mohammed; Al-Roubaiey, Anas] King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran, Eastern Provinc, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Al-Roubaiey, A (corresponding author), King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran, Eastern Provinc, Saudi Arabia.
EM Mbasem@kfupm.edu.sa; Malsaeedi@kfupm.edu.sa; roubaiey@kfupm.edu.sa
RI Almadani, Basem M.S./F-1634-2015; Alsaeedi, Mohammed/KPY-0878-2024
OI Almadani, Basem/0000-0002-8768-7655; Alsaeedi,
   Mohammed/0000-0003-4508-9187
CR [Anonymous], MED 07 MED C CONTR A
   [Anonymous], ICARCV 06 9 INT C CO
   [Anonymous], ICME 04 2004 IEEE IN
   [Anonymous], DAT DISTR SERV DDS 1
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], DISTRIBUTED PROGRAMM
   [Anonymous], GLOB TEL C 2009 GLOB
   [Anonymous], P IEEE INT C COMM IC
   [Anonymous], JVTY202 ISOIEC MPEG
   [Anonymous], COR LIB UT US MAN RE
   [Anonymous], IEEE INT C WIR MOB C
   [Anonymous], MUE 07 INT C MULT UB
   Atzori L, 2012, IEEE ICC, P2021, DOI 10.1109/ICC.2012.6364029
   Chen CM, 2007, J VIS COMMUN IMAGE R, V18, P191, DOI 10.1016/j.jvcir.2007.02.001
   Chen MH, 2005, IEEE WIREL COMMUN, V12, P32, DOI 10.1109/MWC.2005.1497856
   Chen MH, 2004, IEEE INFOCOM SER, P1181
   Clavijo JA, 2001, CONTROL ENG PRACT, V9, P459, DOI 10.1016/S0967-0661(00)00124-6
   Detti Andrea., 2010, WORLD WIRELESS MOBIL, P1
   Fallah YP, 2008, IEEE T CIRC SYST VID, V18, P875, DOI 10.1109/TCSVT.2008.920745
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Garcia-Valls M., 2010, 2010 8th IEEE International Conference on Industrial Informatics (INDIN 2010), P130, DOI 10.1109/INDIN.2010.5549450
   Hong YS, 2008, MUE: 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P537, DOI 10.1109/MUE.2008.21
   Hsing-Lung Chen, 2008, Fourth International Conference on Wireless and Mobile Communications. ICWMC 2008, P241, DOI 10.1109/ICWMC.2008.35
   Huang HC, 2007, IEEE COMMUN MAG, V45, P68, DOI 10.1109/MCOM.2007.284540
   Huang YS, 2009, IEEE T MULTIMEDIA, V11, P1072, DOI 10.1109/TMM.2009.2026085
   Jae-Young Pyun, 2008, ICC Workshops 2008 - IEEE International Conference on Communications Workshops, P47
   Jiang TG, 2012, IEEE J SEL AREA COMM, V30, P1215, DOI 10.1109/JSAC.2012.120807
   Joshi R., 2006, REAL TIME INNOVATION
   Karimi O., 2010, COMPUTERS ELECT ENG, Vi, P160
   Karr DA, 2001, DOA'01: 3RD INTERNATIONAL SYMPOSIUM ON DISTRIBUTED OBJECTS & APPLICATIONS, PROCEEDINGS, P299, DOI 10.1109/DOA.2001.954095
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Le TienAnh., 2010, CONSUMER ELECT ISCE, P1, DOI DOI 10.1109/ISCE.2010.5523712
   Lee C, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1454, DOI 10.1109/APCCAS.2008.4746305
   Lei ZJ, 2005, J SYST SOFTWARE, V75, P253, DOI 10.1016/j.jss.2003.09.029
   Li MD, 2011, J VIS COMMUN IMAGE R, V22, P284, DOI 10.1016/j.jvcir.2011.01.002
   Luo HY, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.969
   Luo HY, 2010, J VIS COMMUN IMAGE R, V21, P98, DOI 10.1016/j.jvcir.2009.06.006
   Ma XL, 2012, J SYST SOFTWARE, V85, P300, DOI 10.1016/j.jss.2011.08.016
   Maione G, 2012, CONTROL ENG PRACT, V20, P1366, DOI 10.1016/j.conengprac.2012.08.003
   Mansour H, 2009, IEEE T MULTIMEDIA, V11, P1478, DOI 10.1109/TMM.2009.2032682
   Mastouri MA, 2007, INT J COMPUT SCI NET, V7, P313
   Oh S, 2010, FUTURE GENER COMP SY, V26, P318, DOI 10.1016/j.future.2009.09.001
   Radakovic D, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P213
   Schierl T, 2007, IEEE INT SYMP CIRC S, P3455, DOI 10.1109/ISCAS.2007.378370
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Song D, 2008, J VIS COMMUN IMAGE R, V19, P520, DOI 10.1016/j.jvcir.2008.06.008
   Wang CH, 2003, GLOB TELECOMM CONF, P3361, DOI 10.1109/GLOCOM.2003.1258858
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y, 2010, IEEE T BROADCAST, V56, P288, DOI 10.1109/TBC.2010.2050629
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiaolin Tong, 2004, Proceedings. Third International Conference on Image and Graphics, P369
   Yu HB, 2004, SIGNAL PROCESS-IMAGE, V19, P369, DOI 10.1016/j.image.2004.01.002
   Zhang HH, 2010, IEEE J SEL AREA COMM, V28, P344, DOI 10.1109/JSAC.2010.100406
   Zhang XC, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND INFORMATION SYSTEMS, P286, DOI 10.1109/WNIS.2009.39
   Zhou LA, 2011, IEEE T VEH TECHNOL, V60, P1161, DOI 10.1109/TVT.2011.2104420
   Zhou LA, 2011, IEEE T VEH TECHNOL, V60, P692, DOI 10.1109/TVT.2010.2102782
NR 58
TC 9
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5841
EP 5870
DI 10.1007/s11042-015-2551-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600023
DA 2024-07-18
ER

PT J
AU Montagner, C
   Jesus, R
   Correia, N
   Vilarigues, M
   Macedo, R
   Melo, MJ
AF Montagner, Cristina
   Jesus, Rui
   Correia, Nuno
   Vilarigues, Marcia
   Macedo, Rita
   Melo, Maria Joao
TI Features combination for art authentication studies: brushstroke and
   materials analysis of Amadeo de Souza-Cardoso
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Painting analysis; Gabor; SIFT; Hyperspectral imaging; Authentication
ID COMPUTER VISION; IMAGE-ANALYSIS; MASTER ART; PAINTINGS; IDENTIFICATION;
   SPECTROSCOPY; RETRIEVAL
AB This work presents a tool to support authentication studies of paintings attributed to the modernist Portuguese artist Amadeo de Souza-Cardoso (1887-1918). The strategy adopted was to quantify and combine the information extracted from the analysis of the brushstroke with information on the pigments present in the paintings. The brushstroke analysis was performed combining Gabor filter and Scale Invariant Feature Transform. Hyperspectral imaging and elemental analysis were used to compare the materials in the painting with those present in a database of oil paint tubes used by the artist. The outputs of the tool are a quantitative indicator for authenticity, and a mapping image that indicates the areas where materials not coherent with Amadeo's palette were detected, if any. This output is a simple and effective way of assessing the results of the system. The method was tested in twelve paintings obtaining promising results.
C1 [Montagner, Cristina; Melo, Maria Joao] Univ Nova Lisboa, LAQV, Requimte, P-2829516 Monte De Caparica, Portugal.
   [Montagner, Cristina; Vilarigues, Marcia; Macedo, Rita; Melo, Maria Joao] Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Conservacao & Restauro, P-2829516 Monte De Caparica, Portugal.
   [Vilarigues, Marcia] Univ Nova Lisboa, VICARTE, P-2829516 Monte De Caparica, Portugal.
   [Macedo, Rita] Univ Nova Lisboa, IHA, P-2829516 Monte De Caparica, Portugal.
   [Jesus, Rui] Inst Super Engn Lisboa, Multimedia & Machine Learning Grp, Rua Conselheiro Emidio Navarro 1, Lisbon, Portugal.
   [Correia, Nuno] Univ Nova Lisboa, NOVA LINCS, Dept Informat, Fac Ciencias & Tecnol, P-1200 Lisbon, Portugal.
C3 Universidade Nova de Lisboa; Universidade Nova de Lisboa; Universidade
   Nova de Lisboa; Universidade Nova de Lisboa; Polytechnic Institute of
   Lisbon; Universidade Nova de Lisboa
RP Montagner, C (corresponding author), Univ Nova Lisboa, LAQV, Requimte, P-2829516 Monte De Caparica, Portugal.; Montagner, C (corresponding author), Univ Nova Lisboa, Fac Ciencias & Tecnol, Dept Conservacao & Restauro, P-2829516 Monte De Caparica, Portugal.
EM moncri@campus.fct.unl.pt
RI Macedo, Rita/AAE-4648-2019; Jesus, Rui/JZT-7448-2024; Jesus,
   Rui/G-9199-2011; Vilarigues, Marcia/K-8709-2015; Montagner,
   Cristina/W-8644-2019; Correia, Natália T. T./D-6699-2013; Melo, Maria
   J./C-8594-2011; Correia, Nuno/D-2298-2010
OI Macedo, Rita/0000-0002-6320-3214; Vilarigues,
   Marcia/0000-0003-4134-2819; Montagner, Cristina/0000-0003-4381-1244;
   Melo, Maria J./0000-0001-7393-6801; Jesus, Rui/0000-0003-1869-6491;
   Correia, Nuno/0000-0002-8704-6698
FU national funds through FCT-Fundacao para a Ciencia e a Tecnologia
   (Portuguese Foundation for Science and Technology)
   [PTDC/EAT-EAT/113612/2009]; REQUIMTE [PEst-C/EQB/LA0006/2011]; 
   [SFRH/BD/66488/2009]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/66488/2009, PTDC/EAT-EAT/113612/2009] Funding Source: FCT
FX This work has been supported by national funds through FCT-Fundacao para
   a Ciencia e a Tecnologia (Portuguese Foundation for Science and
   Technology) under project PTDC/EAT-EAT/113612/2009 and grant of Cristina
   Montagner SFRH/BD/66488/2009 as well as REQUIMTE supporting project
   PEst-C/EQB/LA0006/2011. The authors are grateful to all team members of
   CAM - Centro de Arte Moderna da Fundacao Gulbenkian for the fruitful
   collaboration, in particular to director Isabel Carlos and curator Ana
   Vasconcelos e Melo. Thanks also to Professor Sergio Nascimento, Joao
   M.M. Linhares, Osamu Masuda and Helder Tiago Correia for the spectral
   imaging analysis.
CR Al-Ayyoub M, 2011, PROC SPIE, V7869, DOI 10.1117/12.873142
   Alfaro C, 2008, CRITERIOS METODOLOGI, V2
   Almeida P., 2013, SIGN PROC C EUSIPCO, P1
   Almeida P F.M., 2012, Analise e identificacao de obras de arte
   [Anonymous], 2011, P 28 INT C MACH LEAR
   [Anonymous], GEOSC REM SENS S IGA
   Barni M, 2005, IEEE SIGNAL PROC MAG, V22, P141, DOI 10.1109/MSP.2005.1511835
   Baronti S, 1997, CHEMOMETR INTELL LAB, V39, P103, DOI 10.1016/S0169-7439(97)00047-6
   Berezhnoy IE, 2005, Humanities, Computers and Cultural Heritage, P28
   Berezhnoy IE, 2009, MACH VISION APPL, V20, P1, DOI 10.1007/s00138-007-0098-7
   Boselli L., 2011, Practical handbook on diagnosis of paintings on movable support
   Browne MW, 2000, J MATH PSYCHOL, V44, P108, DOI 10.1006/jmps.1999.1279
   Cesaratto A, 2013, APPL SPECTROSC, V67, P1234, DOI 10.1366/13-07032
   Comelis B, 2009, INT C SAMPL THEOR AP
   Comelli D, 2011, J CULT HERIT, V12, P11, DOI 10.1016/j.culher.2010.06.003
   Deborah H, 2014, ICIP
   Delaney JK, 2014, STUD CONSERV, V59, P91, DOI 10.1179/2047058412Y.0000000078
   Delaney JK, 2010, APPL SPECTROSC, V64, P584, DOI 10.1366/000370210791414443
   Doulamis AD, 2011, 5 C EM TECHN NOND TE
   Elgammal Arora Ahmed, 2014, MULTIMED TOOLS APPL, P1
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Feller R.J., 2004, Color science in the examination of museum objects: non-destructive procedures
   Franca J.A., 1956, Amadeo de Souza-Cardoso
   Freitas H, 2008, CATALOGO RAISONNE V
   Freitas H, 2006, DIALOGO VANGUARDAS A
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Hendriks E, 2006, FACULTY HUMANITIES
   Hendriks E., 2009, Art, conservation and authenticities: material, concept, context International conference, P143
   Jesus R, 2009, U NOVA LISBOA FACULD
   Jesus R., 2010, MULTIMED TOOLS APPL, V1380, P1
   Johnson CR, 2008, IEEE SIGNAL PROC MAG, V25, P37, DOI 10.1109/MSP.2008.923513
   Keshava N, 2004, IEEE T GEOSCI REMOTE, V42, P1552, DOI 10.1109/TGRS.2004.830549
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2012, IEEE T PATTERN ANAL, V34, P1159, DOI 10.1109/TPAMI.2011.203
   Liang H, 2012, APPL PHYS A-MATER, V106, P309, DOI 10.1007/s00339-011-6689-1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maarten van der L, 2008, AAAI C ART INT
   Linhares JMM, 2008, J OPT SOC AM A, V25, P2918, DOI 10.1364/JOSAA.25.002918
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Melo MJ, 2008, CATALOGO RAISONNE V
   Montagner C., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P201
   Montagner C, 2015, DEP CONSERVATION RES
   Montagner C, 2013, 12 INT AIC C, P359
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Pelagotti A, 2008, IEEE SIGNAL PROC MAG, V25, P27, DOI 10.1109/MSP2008-923095
   Pinto PD, 2008, J OPT SOC AM A, V25, P623, DOI 10.1364/JOSAA.25.000623
   Poggio T., 2003, NOTICES AMS, V50, P537
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Shen JL, 2009, PATTERN RECOGN, V42, P293, DOI 10.1016/j.patcog.2008.04.016
   Stork DG, 2006, IEEE MULTIMEDIA, V13, P12, DOI 10.1109/MMUL.2006.78
   Stork DG, 2006, IEEE MULTIMEDIA, V13, P16, DOI 10.1109/MMUL.2006.50
   Stork DG, 2006, COMPUTER VISION IM 3, V14, P14
   Taylor RP, 1999, NATURE, V399, P422, DOI 10.1038/20833
   Zhao Y., 2008, Image segmentation and pigment mapping of cultural heritage based on spectral imaging
NR 57
TC 5
Z9 5
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 4039
EP 4063
DI 10.1007/s11042-015-3197-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200023
DA 2024-07-18
ER

PT J
AU Cao, JW
   Chen, T
   Fan, JY
AF Cao, Jiuwen
   Chen, Tao
   Fan, Jiayuan
TI Landmark recognition with compact BoW histogram and ensemble ELM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Landmark recognition; Compact BoW histogram; Extreme learning machine;
   Ensemble method; ELM kernel; Support vector machine
ID EXTREME LEARNING-MACHINE; IMAGES; SCENE; WEB
AB Along with the rapid development of mobile terminal devices, landmark recognition applications based on mobile devices have been widely researched in recent years. Due to the fast response time requirement of mobile users, an accurate and efficient landmark recognition system is thus urgent for mobile applications. In this paper, we propose a landmark recognition framework by employing a novel discriminative feature selection method and the improved extreme learning machine (ELM) algorithm. The scalable vocabulary tree (SVT) is first used to generate a set of preliminary codewords for landmark images. An efficient codebook learning algorithm derived from the word mutual information and Visual Rank technique is proposed to filter out those unimportant codewords. Then, the selected visual words, as the codebook for image encoding, are used to produce a compact Bag-of-Words (BoW) histogram. The fast ELM algorithm and the ensemble approach using the ELM classifier are utilized for landmark recognition. Experiments on the Nanyang Technological University campus's landmark database and the Fifteen Scene database are conducted to illustrate the advantages of the proposed framework.
C1 [Cao, Jiuwen] Hangzhou Dianzi Univ, Key Lab IOT & Informat Fus Technol Zhejiang, Hangzhou 310018, Zhejiang, Peoples R China.
   [Chen, Tao; Fan, Jiayuan] ASTAR, Inst Infocomm Res I2R, Singapore 138632, Singapore.
C3 Hangzhou Dianzi University; Agency for Science Technology & Research
   (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Cao, JW (corresponding author), Hangzhou Dianzi Univ, Key Lab IOT & Informat Fus Technol Zhejiang, Hangzhou 310018, Zhejiang, Peoples R China.
EM jwcao@hdu.edu.cn; chent@i2r.a-star.edu.sg; fanj@i2r.a-star.edu.sg
RI cao, jiuwen/C-9547-2009
FU National Natural Science Major Foundation of Research Instrumentation of
   P. R. China [61427808]; Key Foundation of P. R. China [61333009];
   National Key Basic Research Program of P. R. China [2012CB821204]
FX This work was supported by the National Natural Science Major Foundation
   of Research Instrumentation of P. R. China under Grants 61427808, the
   Key Foundation of P. R. China under Grants 61333009, and in part by the
   National Key Basic Research Program of P. R. China under Grants
   2012CB821204. We would like to thank the reviewers and the Editor for
   their constructive comments and suggestions on improving our paper.
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P MULT
   [Anonymous], P INT WORKSH STAT LE
   [Anonymous], INTELLIGENT COMPUTER, DOI DOI 10.1007/978-3-642-31745-3_13
   Arai Kohei, 2007, Reports of the Faculty of Science and Engineering, Saga University, V36, P25
   Bobek S, 2016, MULTIMED TOOLS APPL, V75, P10595, DOI 10.1007/s11042-014-2060-9
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Cao JW, 2014, C IND ELECT APPL, P1163, DOI 10.1109/ICIEA.2014.6931341
   Cao JW, 2013, IEEE INT SYMP CIRC S, P2327, DOI 10.1109/ISCAS.2013.6572344
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Cao JW, 2010, NEUROCOMPUTING, V73, P1405, DOI 10.1016/j.neucom.2009.12.007
   Chen T, 2014, IEEE T CYBERNETICS, V44, P695, DOI 10.1109/TCYB.2013.2267015
   Chen T, 2011, IEEE T CIRC SYST VID, V21, P1476, DOI 10.1109/TCSVT.2011.2161413
   Chen T, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P625, DOI 10.1109/MDM.2009.107
   Cheng C, 2008, IEEE INT CONF ROBOT, P557, DOI 10.1109/ROBOT.2008.4543265
   Chin T, 2008, P COMP VIS PATT REC
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2003, PROC CVPR IEEE, P264
   Fritz G., 2006, P 4 IEEE INT C COMPU, P30
   Han JW, 2014, MULTIMED TOOLS APPL, V72, P2275, DOI 10.1007/s11042-013-1509-6
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Lan Y, 2009, NEUROCOMPUTING, V72, P3391, DOI 10.1016/j.neucom.2009.02.013
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P8821, DOI 10.1007/s11042-013-1565-y
   Li YQ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1493, DOI 10.1109/ICME.2008.4607729
   Lim JH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P100
   Lin SB, 2014, ARXIV14016240V1CSLG
   Linde O, 2004, P IEEE C IM PROC PAT
   Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HJ, 2014, NEUROCOMPUTING, V128, P22, DOI 10.1016/j.neucom.2013.02.052
   Lu L, 2005, PROC CVPR IEEE, P688
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Parikh D, 2008, LECT NOTES COMPUT SC, V5303, P446, DOI 10.1007/978-3-540-88688-4_33
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Pronobis A., 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2394, DOI 10.1109/IROS.2007.4399493
   Pronobis A, 2006, P IEEE C INT ROB SYS
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Yap KH, 2010, IEEE INTELL SYST, V25, P48, DOI 10.1109/MIS.2010.12
   Yeh T, 2004, PROC CVPR IEEE, P76
   Yin C, 2014, AUTOMATICA, V50, P3173, DOI 10.1016/j.automatica.2014.10.027
   Yin C, 2013, APPL MATH MODEL, V37, P2469, DOI 10.1016/j.apm.2012.06.002
   Yin C, 2012, COMMUN NONLINEAR SCI, V17, P356, DOI 10.1016/j.cnsns.2011.04.024
   Yinghui Ge, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P838, DOI 10.1109/ICCIS.2008.4670816
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 55
TC 106
Z9 107
U1 0
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2839
EP 2857
DI 10.1007/s11042-014-2424-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000027
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Courtois, C
   Vanhecke, K
   Van Damme, K
   Martens, L
   De Marez, L
AF De Pessemier, Toon
   Courtois, Cedric
   Vanhecke, Kris
   Van Damme, Kristin
   Martens, Luc
   De Marez, Lieven
TI A user-centric evaluation of context-aware recommendations for a mobile
   news service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; News recommendation; User evaluation; Context-aware;
   Algorithm-based news
ID SPARSITY PROBLEM; SYSTEMS; INFORMATION
AB Traditional recommender systems provide personal suggestions based on the user's preferences, without taking into account any additional contextual information, such as time or device type. The added value of contextual information for the recommendation process is highly dependent on the application domain, the type of contextual information, and variations in users' usage behavior in different contextual situations. This paper investigates whether users utilize a mobile news service in different contextual situations and whether the context has an influence on their consumption behavior. Furthermore, the importance of context for the recommendation process is investigated by comparing the user satisfaction with recommendations based on an explicit static profile, content-based recommendations using the actual user behavior but ignoring the context, and context-aware content-based recommendations incorporating user behavior as well as context. Considering the recommendations based on the static profile as a reference condition, the results indicate a significant improvement for recommendations that are based on the actual user behavior. This improvement is due to the discrepancy between explicitly stated preferences (initial profile) and the actual consumption behavior of the user. The context-aware content-based recommendations did not significantly outperform the content-based recommendations in our user study. Context-aware content-based recommendations may induce a higher user satisfaction after a longer period of service operation, enabling the recommender to overcome the cold-start problem and distinguish user preferences in various contextual situations.
C1 [De Pessemier, Toon; Vanhecke, Kris; Martens, Luc] Univ Ghent, Dept Informat Technol, WiCa, iMinds, G Crommenlaan 8 box 201, B-9050 Ghent, Belgium.
   [Courtois, Cedric; Van Damme, Kristin; De Marez, Lieven] Univ Ghent, Dept Commun Sci, MICT, iMinds, Korte Meer 7-9-11, B-9000 Ghent, Belgium.
C3 Ghent University; IMEC; IMEC; Ghent University
RP De Pessemier, T (corresponding author), Univ Ghent, Dept Informat Technol, WiCa, iMinds, G Crommenlaan 8 box 201, B-9050 Ghent, Belgium.
EM toon.depessemier@ugent.be; cedric.courtois@ugent.be;
   kris.vanhecke@ugent.be; kristin.vandamme@ugent.be;
   luc1.martens@ugent.be; lieven.demarez@ugent.be
OI Courtois, Cedric/0000-0002-2942-2114; De Marez,
   Lieven/0000-0001-7716-4079
FU iMinds (Interdisciplinary institute for Technology) a research
   institute; IWT
FX This research was performed in the context of the iMinds-MIX Stream
   Store project. Stream Store is a project cofunded by iMinds
   (Interdisciplinary institute for Technology) a research institute
   founded by the Flemish Government. Companies and organizations involved
   in the project are De Persgroep, Roularta Media Group nv, iMinds-iLab.o,
   VMMA, and Limecraft with project support of IWT.
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   [Anonymous], CHI SQUARED TESTS
   [Anonymous], CHI SQUARED TEST
   [Anonymous], ACM RECSYS WORKSH CO
   [Anonymous], P 2 ACM C REC SYST R
   Baltrunas L., 2009, Proceedings of the Third ACM Conference on Recommender Systems, RecSys'09, P245, DOI [DOI 10.1145/1639714.1639759, 10.1145/1639714.1639759]
   Bazire M, 2005, LECT NOTES ARTIF INT, V3554, P29
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Brown PJ, 1997, IEEE PERS COMMUN, V4, P58, DOI 10.1109/98.626984
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Cantador I, 2008, LECT NOTES COMPUT SC, V5149, P279, DOI 10.1007/978-3-540-70987-9_34
   De Pessemier T, 2008, IEEE T CONSUM ELECTR, V54, P709, DOI 10.1109/TCE.2008.4560151
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2497, DOI 10.1007/s11042-013-1563-0
   De Pessemier T, 2012, MULTIMED TOOLS APPL, V58, P167, DOI 10.1007/s11042-010-0715-8
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   FISHER RJ, 1993, J CONSUM RES, V20, P303, DOI 10.1086/209351
   Folstad A., 2008, Electr. J. Organ. Virtual., V10, P99
   Gavalas D, 2014, J NETW COMPUT APPL, V39, P319, DOI 10.1016/j.jnca.2013.04.006
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Kabassi Katerina, 2010, Telematics and Informatics, V27, P51, DOI 10.1016/j.tele.2009.05.003
   Kam Fung Yeung, 2010, Proceedings of the Third International Conference on Developments in eSystems Engineering (DESE 2010), P207, DOI 10.1109/DeSE.2010.40
   Kenteris M., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P840, DOI 10.1109/ISCC.2010.5546758
   Kutner M.H., 2005, Applied linear statistical models, V5th
   Panniello U, 2014, USER MODEL USER-ADAP, V24, P35, DOI 10.1007/s11257-012-9135-y
   Papagelis M, 2005, LECT NOTES COMPUT SC, V3477, P224
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Ricci F., 2010, Information Technology and Tourism, V12, P205, DOI 10.3727/109830511X12978702284390
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   SCHILIT BN, 1994, IEEE NETWORK, V8, P22, DOI 10.1109/65.313011
   Shani G, 2013, AI COMMUN, V26, P225, DOI 10.3233/AIC-130551
   Yu ZW, 2006, IEEE PERVAS COMPUT, V5, P68, DOI 10.1109/MPRV.2006.61
NR 37
TC 21
Z9 22
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3323
EP 3351
DI 10.1007/s11042-014-2437-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600019
DA 2024-07-18
ER

PT J
AU Gaggi, O
   Ciman, M
AF Gaggi, Ombretta
   Ciman, Matteo
TI The use of games to help children eyes testing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Game-based diagnosis; Assistive technologies; Multimedia
   applications; Mobile devices; Natural human Interaction
ID OUTCOMES
AB A doctor cannot perform a good diagnosis without the patient collaboration. One of the major problem for ophthalmologists with children is to capture and maintain their attention while performing their tests. Sometimes children give wrong answers, or not accurate, since they are no longer interested in the task. In this paper we use the serious game paradigm to help children eyes testing. We ask the children to perform a vision acuity and a daltonism test using our game PlayWithEyes. Children have to recognize symbols projected on a wall and point them in a touch interface which displays all the possible answers. Tests performed in a kindergarten with 65 children have shown that the use of our game helps to obtain children cooperation because they have fun, so their attention may last longer, thus improving the possibility to perform a correct diagnosis especially for very young children. This is particular important for some sight defects like amblyopia (lazy eye). Moreover, the system allows us to identify visual acuity reduction in two children. Tests also highlight some limitations of the tool which have been promptly fixed.
C1 [Gaggi, Ombretta; Ciman, Matteo] Univ Padua, Dept Math, Via Trieste 63, I-35121 Padua, Italy.
C3 University of Padua
RP Gaggi, O (corresponding author), Univ Padua, Dept Math, Via Trieste 63, I-35121 Padua, Italy.
EM gaggi@math.unipd.it; mciman@math.unipd.it
FU University of Padua
FX Partial financial support for this work is provided by the University of
   Padua through its research funding program. The authors would like to
   thank Alberto De Bortoli and Alberto Maragno for the implementation of
   the game, Luisa Pinello for her helpful suggestions and contribution to
   the work and teachers, children and parents of the kindergarten "G.
   Rodari" in Mogliano Veneto for participating to the test phase.
CR [Anonymous], 2014, GARTN SAYS ANN SMART
   [Anonymous], 2013, P 1 INT WORKSH INT D
   Audenaeren L, 2013, GAMES HEALTH J, P257, DOI DOI 10.1007/978-3-658-02897-8_20
   Baranowski T, 2008, AM J PREV MED, V34, P74, DOI 10.1016/j.amepre.2007.09.027
   Burke JW, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P103, DOI 10.1109/VS-GAMES.2009.17
   Chou R, 2011, PEDIATRICS, V127, pE442, DOI 10.1542/peds.2010-0462
   Ciman Matteo, 2013, WEBIST 2013. 9th International Conference on Web Information Systems and Technologies. Proceedings, P257
   Colenbrander A., 2008, Visual Impairment Research, V10, P57
   Cooper J, 2010, TECHNICAL REPORT
   De Bortoli A, 2011, P IEEE INT C SER GAM, P190
   Forlines C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P647
   Gaggi O, 2014, ACM COMPUTERS ENTERT
   Kanis M, 2013, INT CONF PER COMP, P97, DOI 10.4108/icst.pervasivehealth.2013.252060
   Kato PM, 2008, PEDIATRICS, V122, pE305, DOI 10.1542/peds.2007-3134
   Lane ND, 2011, P 5 INT C PERV COMP
   Pittarello F, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P250
   Qin J, 2010, IEEE COMPUT GRAPH, V30, P45, DOI 10.1109/MCG.2009.83
   Williams C, 2002, BMJ-BRIT MED J, V324, P1549, DOI 10.1136/bmj.324.7353.1549
   Wong B, 2011, NAT METH, V6
   Zapusek M., 2011, 2011 Proceedings of 34th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO 20111), P1056
NR 20
TC 19
Z9 19
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3453
EP 3478
DI 10.1007/s11042-014-2444-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600025
DA 2024-07-18
ER

PT J
AU Teng, Z
   Liu, F
   Zhang, BP
AF Teng, Zhu
   Liu, Feng
   Zhang, Baopeng
TI Visual railway detection by superpixel based intracellular decisions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Railway detection; Superpixel; Intracellular decision scheme
AB Safety is one of the most concerned issues in traffic and transportation, among which railway detection is a fundamental and necessary research. In this paper, we propose a visual railway detection method based on superpixels rather than pixels. An SVM classifier is learned based on features, on which a TF-IDF like transform is applied, and it greatly improves the performance of the classification. The intracellular decision scheme is proposed to make decisions on a superpixel by using predictions of features within the superpixel. All the superpixels that are predicted as positive constitute the railway to be detected. The proposed railway detection method is evaluated on a number of challenging images and experiments demonstrate that the proposed method is an effective and detailed solution to railway detection, and is superior to other railway detection methods.
C1 [Teng, Zhu; Zhang, Baopeng] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Liu, Feng] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Network Management Res Ctr, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Teng, Z (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM zteng@bjtu.edu.cn; fliu@bjtu.edu.cn; bpzhang@bjtu.edu.cn
OI zhang, baopeng/0000-0003-2592-2354
FU Fundamental Research Funds for the Central Universities [2014JBM040]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities with grant number 2014JBM040.
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   Akgul Y. S., 2009, P 12 INT IEEE C INT, P1
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Ruvo P, 2008, OPEN CYBERN SYST J, V2, P57, DOI DOI 10.2174/1874110X00802010057
   Esveld C., 2001, MODERN RAILWAY TRACK, VSecond
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   Garcia J, 2005, DEDICATED SMART IR B
   Jaakkola T., 1998, Advances in Neural Information Processing Systems, V11
   Kang DJ, 2003, PATTERN RECOGN LETT, V24, P3177, DOI 10.1016/j.patrec.2003.08.003
   Kato T, 2002, IEEE T INTELL TRANSP, V3, P182, DOI 10.1109/TITS.2002.802932
   Kobayashi T, 2014, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2014.413
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Li YD, 2013, IEEE T INF FOREN SEC, V8, P1384, DOI 10.1109/TIFS.2013.2271425
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Maire F, 2010, I C CONT AUTOMAT ROB, P2172, DOI 10.1109/ICARCV.2010.5707923
   Möckel S, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P42, DOI 10.1109/IVS.2003.1212880
   Nassu BT, 2011, IEEE INT VEH S 4 BAD
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Passarella Rossi, 2011, IJRRAS, V9
   Qi ZQ, 2013, NEURAL COMPUT APPL, V23, P245, DOI 10.1007/s00521-012-0846-0
   Reisert M, 2008, IEEE T IMAGE PROCESS, V17, P190, DOI 10.1109/TIP.2007.914218
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Rüder M, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P180, DOI 10.1109/IVS.2003.1212905
   Singh Maneesha, 2006, IEEE INT C COMP INT
   Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Vedaldi A, 2008, ACM INT C MULT
   Wang T, 2012, COMPUT VIS IMAGE UND, V116, P1168, DOI 10.1016/j.cviu.2012.08.002
   Wohlfeil J, 2011, IEEE INT VEH S 4 BAD
   Wu J, 2013, PATTERN RECOGN, V46, P2927, DOI 10.1016/j.patcog.2013.04.008
   Zhang Zhongfei, 1994, TR9420 COMPSI
NR 33
TC 22
Z9 27
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2473
EP 2486
DI 10.1007/s11042-015-2654-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000005
DA 2024-07-18
ER

PT J
AU Wang, DD
   Song, HB
   Tie, ZH
   Zhang, WY
   He, DJ
AF Wang, Dandan
   Song, Huaibo
   Tie, Zhihui
   Zhang, Weiyuan
   He, Dongjian
TI Recognition and localization of occluded apples using K-means clustering
   algorithm and convex hull theory: a comparison
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Occluded apple; Localization; Recognition; K-means clustering algorithm;
   Convex hull
AB For apple harvesting robot, it is difficult to acquire the coordinates of occluded apples accurately in natural scenes, which is important in implementing picking tasks. In this paper, a method on automatic recognition and localization of occluded apples was proposed. Firstly, an apple recognition algorithm based on K-means clustering theory was described. Secondly, convex hull information which was obtained by following the contours of extracted apple regions was used to extract the real apple edges. Finally, three points from these real edges were selected to estimate the centers and radius of apples. This algorithm was tested and compared with traditional Hough transform method (HT method) and contour curvature method (CC method) and 125 apple images were used to test the effectiveness of these methods. Four parameters including Segmentation Error (SE), False Positive Rate (FPR), False Negative Rate (FNR) and Overlap Index (OI) were used to evaluate the performance of these methods. Experimental results showed that SE of the presented method was decreased by 14.399 and 30.782 % when compared to CC method and HT method respectively, FPR by 7.234 and 11.728 % and OI was increased by 18.644 and 30.938 %. FNR of the proposed method was 0.912 % lower than CC method, while it was 5.869 % higher than HT method. The experimental results indicated that the proposed method could get much better localization rate than Hough transform method and contour curvature method, thus it could be concluded that the algorithm is an efficient means for the recognition and localization of occluded apples.
C1 [Wang, Dandan; Song, Huaibo; Tie, Zhihui; Zhang, Weiyuan; He, Dongjian] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China
RP Song, HB (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
EM songhuaibo@nwsuaf.edu.cn
RI SONG, Huaibo/GXM-9402-2022
FU National High Technology Research and Development Program of China (863
   Program) [2013AA10230402]; "National Natural Science Foundation" of
   China [31000670]; "Fundamental Research Funds for the Central
   Universities" of China [QN2011031]
FX This work is supported by the National High Technology Research and
   Development Program of China (863 Program) (No. 2013AA10230402),
   "National Natural Science Foundation" of China (No. 31000670), and the
   "Fundamental Research Funds for the Central Universities" of China (No.
   QN2011031). The authors would like to thank Shaojin Wang (Ph.D, College
   of Mechanical and Electronic Engineering, Northwest A&F University),
   Xiuli Yu (graduate student, College of Mechanical and Electronic
   Engineering, Northwest A&F University) and Weifeng Qu graduate student,
   College of Mechanical and Electronic Engineering, Northwest A&F
   University) for their useful advices.
CR [Anonymous], [No title captured]
   [Anonymous], 2004, T CHIN SOC AGR MACH
   Bulanon DM, 2002, BIOSYST ENG, V83, P405, DOI 10.1006/bioe.2002.0132
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Fang C, 2009, BIOMEDICAL ENG INFOR, P1
   Feng J, 2012, IFIP ADV INF COMM TE, V368, P258
   Gonzalez RafaelC., 2009, Digital image processing using MATLAB, V2
   Huang HC, 2001, J INF SCI ENG, V17, P753
   Huang HC, 2001, SIGNAL PROCESS, V81, P1513, DOI 10.1016/S0165-1684(01)00048-2
   Muscato G, 2005, IND ROBOT, V32, P128, DOI 10.1108/01439910510582255
   Plebe A, 2001, MACH VISION APPL, V13, P70, DOI 10.1007/PL00013271
   Rekik A, 2006, 2006 1ST IEEE INTERNATIONAL CONFERENCE ON E-LEARNING IN INDUSTRIAL ELECTRONICS, P11, DOI 10.1109/ICELIE.2006.347204
   SARIG Y, 1993, J AGR ENG RES, V54, P265, DOI 10.1006/jaer.1993.1020
   SCHWARZ MW, 1987, ACM T GRAPHIC, V6, P123, DOI 10.1145/31336.31338
   Song HuaiBo Song HuaiBo, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P135
   Song HuaiBo Song HuaiBo, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P174
   Stajnko Denis, 2005, Agriculturae Conspectus Scientificus, V70, P59
   Sun J., 2014, J INFORM HIDING MULT, V5, P567
   Wang X.-X., 2014, J INF HIDING MULTIME, V5, P508
   Xu H, 2005, T CSAE, V5
   Xun Y, 2008, J JIANGSU U NAT SCI, V28, P461
   Yao H, 2013, MATH COMPUT MODEL, V58, P784, DOI 10.1016/j.mcm.2012.12.025
   Yawena P, 2012, COMPUT ENG, V14
   Yin HP, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P557, DOI 10.1109/SoCPaR.2009.111
   Zhao J., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P263
   Zhao J W., 2004, T CSAM, V35, P135
   Zhou Qihai, 2008, 2008 Workshop on Knowledge Discovery and Data Mining (WKDD '08), P630, DOI 10.1109/WKDD.2008.40
NR 27
TC 23
Z9 26
U1 1
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3177
EP 3198
DI 10.1007/s11042-014-2429-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600012
DA 2024-07-18
ER

PT J
AU Park, J
   Lee, H
AF Park, Jiro
   Lee, Haeyoung
TI A hierarchical framework for large 3D mesh streaming on mobile systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile 3D; 3D mesh streaming; Vertex clustering; Out-of-core mesh
   partitioning
ID COMPRESSION
AB Large 3D meshes are emerging as the new media for various applications but are still hard to use in mobile applications, due to the limited resources of mobile systems. This paper introduces a large 3D mesh streaming framework which flexibly deals with the limited resources of mobile systems and also provides a user with interactive controls and random accessibilities. To reduce resource usage, our framework presents a uniform mesh partitioning algorithm, in which each partition of a large mesh has the same number of vertices. Our uniform partitioning is based on a k-d tree clustering and extended for out-of-core meshes. A median search with heaps in the main memory is designed for faster external sorting. Large 3D meshes are transformed into a set of partitioned and simplified meshes in the server. For interactive 3D browsing, on mobile devices, our framework presents a mobile 3D viewer which is hierarchically designed with intuitive interfaces. A user can experience rapid 3D searches with 3D previews of simplified meshes. Multi touch inputs can control zooming and the level of detail in meshes automatically. Double tap touches enable a user to randomly select a region of a large mesh, and a set of partitions for the selected region will be streamed and displayed on a mobile client. As a result, our framework enables a user to browse large 3D meshes on a mobile system interactively, while optimizing system resource usage and protecting the original data in the server.
C1 [Lee, Haeyoung] Hongik Univ, Dept Comp Engn, 72-1 Sangsu Dong, Seoul 121791, South Korea.
   [Park, Jiro] Wemade Entertainment, Seoul, South Korea.
C3 Hongik University
RP Lee, H (corresponding author), Hongik Univ, Dept Comp Engn, 72-1 Sangsu Dong, Seoul 121791, South Korea.
EM qkrwlfh@gmail.com; leeh@hongik.ac.kr
FU Hongik University Research Fund
FX This work was supported by the 2013 Hongik University Research Fund. The
   authors would like to thank Prof. Marc Levoy at Stanford University for
   his out-of-core meshes; Prof. Seungyong Lee at Postech and Junho Kim at
   Kookmin University for their simplified meshes; Dr. Sungyul Choe at
   Samsung Electronics and Dr. Daeyoung Kim at 3D Systems for their
   assistance implementing k-d tree clustering.
CR Alliez P, 2005, MATH VIS, P3, DOI 10.1007/3-540-26808-1_1
   Bribiesca E, 2008, PATTERN RECOGN, V41, P543, DOI 10.1016/j.patcog.2007.06.029
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   CHENG W, 2008, P 16 ACM INT C MULT, P1047
   Choe S, 2009, IEEE T VIS COMPUT GR, V15, P160, DOI 10.1109/TVCG.2008.64
   Cignoni P, 2003, IEEE T VIS COMPUT GR, V9, P525, DOI 10.1109/TVCG.2003.1260746
   Daiber Florian, 2013, P ITS, P483
   Devillard N., 1998, FAST MEDIAN SEARCH A
   Doellner J, 2012, WEB3D 2012, P97
   Doran A., 2009, Proceeding of ACM international conference on Multimedia, P955
   Duguet F, 2004, IEEE COMPUT GRAPH, V24, P57, DOI 10.1109/MCG.2004.5
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Kim D, 2012, P ICAS 2012 8 INT C, V8, P38
   Kim D, 2008, IEEE T CONSUM ELECTR, V54, P1398, DOI 10.1109/TCE.2008.4637633
   Lamberti F, 2007, IEEE T VIS COMPUT GR, V13, P247, DOI 10.1109/TVCG.2007.29
   Lee H, 2003, ACM T GRAPHIC, V22, P471, DOI 10.1145/882262.882294
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Rekik Y, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P201, DOI 10.1145/2598153.2598167
   Rodríguez MB, 2014, WEB3D 2014, P7
   Sander P. V., 2003, Symposium on Geometry Processing, P146
   SCHAEFER S, 2003, SIAM GEOMETRIC DESIG
   Tang Z, 2011, P 19 ACM INT C MULT, P1009
   Tang ZY, 2011, MULTIMED TOOLS APPL, V51, P779, DOI 10.1007/s11042-010-0634-8
   Zhao SH, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2537854
NR 25
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1983
EP 2004
DI 10.1007/s11042-014-2383-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000012
OA hybrid
DA 2024-07-18
ER

PT J
AU Jiang, W
AF Jiang, Wei
TI Rate-distortion optimized image compression based on image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Rate-distortion; Image compression; Perceptual quality
ID SIMULTANEOUS CARTOON; QUALITY ASSESSMENT; COMPLETION
AB Inspired by recent advancements in image inpainting techniques, an image coding framework is proposed in this paper. In the framework, an original image is analyzed at the encoder side such that a number of the regions are skipped intentionally. A drop map is extracted and compressed into the generated bit stream to indicate the skipped regions. The image is recovered through the inpainting process by taking advantage of the available portion of the decoded image and the drop map at the decoder. Furthermore, the rate-distortion optimization is introduced to select the blocks to be removed for the better performance. Only the blocks containing certain visual features and satisfying rate-distortion criterion are dropped. A practical system is constructed to verify the effectiveness of the compression approach. Evaluations have been made in comparison with baseline JPEG and H.264/AVC. Compared to the baseline JPEG, the proposed algorithm obtains obvious visual quality improvements, as well as PSNR gains. Moreover, the proposed algorithm outperforms H.264/AVC intra coding under the low bit rates.
C1 [Jiang, Wei] Shanghai Univ Elect Power, Sch Comp & Informat Engn, Shanghai 200090, Peoples R China.
C3 Shanghai University of Electric Power
RP Jiang, W (corresponding author), 702,35,Gaoqing Rd 2878, Shanghai 200123, Peoples R China.
EM shiepdouma@163.com
FU National Natural Science Foundation of China (NSFC) [61401269, 61371125,
   61205081]; Natural Science Foundation of Shanghai [14ZR147400]; Shanghai
   Technology Innovation Project [10110502200, 11510500900]; Innovation
   Program of Shanghai Municipal Education Commission [12ZZ176, 13YZ105];
   Science and Technology Commission of Shanghai Municipality
   [10PJ1404500]; Leading Academic Discipline Project of Shanghai Municipal
   Education Commission [J51303]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC, 61401269, 61371125, 61205081), the Natural Science
   Foundation of Shanghai (14ZR147400), Shanghai Technology Innovation
   Project (10110502200, 11510500900), Innovation Program of Shanghai
   Municipal Education Commission (12ZZ176, 13YZ105), Project of Science
   and Technology Commission of Shanghai Municipality (10PJ1404500),
   Leading Academic Discipline Project of Shanghai Municipal Education
   Commission (J51303)
CR Bastani V, 2010, J ZHEJIANG U-SCI C, V11, P92, DOI 10.1631/jzus.C0910182
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bertozzi AL, 2007, IEEE T IMAGE PROCESS, V16, P285, DOI 10.1109/TIP.2006.887728
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Cai JF, 2008, APPL COMPUT HARMON A, V24, P131, DOI 10.1016/j.acha.2007.10.002
   Cai JF, 2010, INVERSE PROBL IMAG, V4, P379, DOI 10.3934/ipi.2010.4.379
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan TF, 2006, J MATH IMAGING VIS, V25, P107, DOI 10.1007/s10851-006-5257-3
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dobrosotskaya JA, 2008, IEEE T IMAGE PROCESS, V17, P657, DOI 10.1109/TIP.2008.919367
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   Grossauer H, 2004, LECT NOTES COMPUT SC, V3022, P214
   Jiang Wei, 2009, Journal of Donghua University, V26, P259
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Li YR, 2013, IEEE T IMAGE PROCESS, V22, P752, DOI 10.1109/TIP.2012.2222896
   Liu D, 2009, P INT C MULT EXP, P1443
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815
   Ramchandran K, 1993, IEEE T IMAGE PROCESS, V2, P160, DOI 10.1109/83.217221
   Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264
   Reid MM, 1997, ACM COMPUT SURV, V29, P3, DOI 10.1145/248621.248622
   Wang C, 2006, IEEE INT SYMP CIRC S, P1816
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P106, DOI 10.1109/TIP.2011.2159983
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wu F., 2007, 2007 IEEE INT C IMAG, V2, P369, DOI [10.1109/ICIP.2007.4379169, DOI 10.1109/ICIP.2007.4379169]
   Wu YD, 2009, INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL SCIENCES AND OPTIMIZATION, VOL 1, PROCEEDINGS, P816, DOI 10.1109/CSO.2009.470
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P1651, DOI 10.1109/TIP.2010.2044960
NR 32
TC 1
Z9 1
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 919
EP 933
DI 10.1007/s11042-014-2332-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700011
DA 2024-07-18
ER

PT J
AU Kumar, R
   Chand, S
AF Kumar, Rajeev
   Chand, Satish
TI A reversible high capacity data hiding scheme using pixel value
   adjusting feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Adjusting feature; Concealable pixel
ID DIFFERENCE EXPANSION; HISTOGRAM-MODIFICATION; COMPANDING TECHNIQUE;
   WATERMARKING
AB In this paper, we propose a new reversible data hiding scheme that uses pixel value adjusting feature. It has two phases. In first phase, It scans the image diagonally from left to right and hides the some of the secret data into the odd valued pixels. In second phase, it also scans the image diagonally but in right to left order and hides the secret data into the even valued pixels. In the second phase, some of the pixels used for hiding in the first phase are again used to hide the secret data but this time their values are positively changed. In other words, if a pixel value is decremented in the first phase; this time, it is incremented so that more secret data can be embedded and the quality of the stego-image is also maintained. Though, our scheme has some overhead in hiding the secret data, yet it is able to provide good quality with high capacity. The scheme is very simple because at the time of hiding it doesn't perform much computation; rather it simply increases or decreases the pixel value. Thus, it has very low computational complexity. The experimental results show that our proposed scheme is superior to many existing schemes.
C1 [Kumar, Rajeev; Chand, Satish] Netaji Subhas Inst Technol, Div Comp Engn, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Kumar, R (corresponding author), Netaji Subhas Inst Technol, Div Comp Engn, New Delhi, India.
EM rajivgarg@outlook.com; schand20@gmail.com
RI Kumar, Rajeev/IUP-5006-2023
OI Kumar, Rajeev/0000-0002-5000-7644
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2013, J INF HIDING MULTIM
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Carpenter B, 2002, COMP VIA ARITHMETIC
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Chung KL, 2012, APPL MATH COMPUT, V218, P5819, DOI 10.1016/j.amc.2011.10.056
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Horng G, 2014, J INFORM HIDING MULT, V5, P152
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hsu FH, 2012, MULTIMED TOOLS APPL, P1
   Huang HC, 2009, IEEE INT SYMP CIRC S, P1661, DOI 10.1109/ISCAS.2009.5118092
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Lu TC, 2008, IMAGE VISION COMPUT, V26, P632, DOI 10.1016/j.imavis.2007.07.011
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2008, IMAGE VISION COMPUT, V26, P1148, DOI 10.1016/j.imavis.2007.12.005
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Weng SW, 2008, CIRC SYST SIGNAL PR, V27, P229, DOI 10.1007/s00034-008-9021-3
   Weng SW, 2008, INT J INNOV COMPUT I, V4, P351
   Weng SW, 2007, IEICE T FUND ELECTR, VE90A, P1717, DOI 10.1093/ietfec/e90-a.8.1717
   Yang B, 2005, PROC SPIE, V5681, P218, DOI 10.1117/12.588147
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 41
TC 27
Z9 27
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 241
EP 259
DI 10.1007/s11042-014-2289-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500013
DA 2024-07-18
ER

PT J
AU Tang, J
   Kim, S
AF Tang, Jiamei
   Kim, Sangwook
TI A Service-oriented device selection solution based on user satisfaction
   and device performance in a ubiquitous environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Service-oriented; User satisfaction; Device selection; Ubiquitous
   environment
ID SINGULAR VALUE DECOMPOSITION; DISCOVERY
AB Ubiquitous computing provides the vision of a smart space filled with various smart devices and services where users can navigate with seamless interaction. To achieve such an intelligent scene, service providers attempt to fulfill the functional requirements of users as well as their non-functional demands, such as user satisfaction. Such non-functional demands depend on required services as well as the devices that execute them. For instance, different devices may provide different user satisfaction for an identical service. Currently, selecting a desired device for a requested service is generally completed manually. However, it is a challenge to match a desired device to a service in the aforementioned smart environment because a service is an abstract concept associated with user intention and experience, whereas a device is a concrete item associated with physical functionalities. Therefore, an automatic mechanism is imperative to balance the benefits and drawbacks of selecting a specific device to instantiate a particular service for a certain consumer. The objective of the current paper is to propose a solution that automatically selects one device among multiple devices with overlapping or identical functionalities for a specific given service to achieve maximum user satisfaction. To achieve this, the device selection procedure in a ubiquitous environment is decomposed into four tasks: 1) filtering to obtain candidate devices that are functionally available for the given service, 2) predicting user satisfaction with these candidate devices considering historic usage, 3) estimating device performance based on available device resources, and 4) selecting the top-ranked device to achieve maximum user satisfaction. This study constructs a quantitative metric for selecting a device for a certain service by quantitating service-oriented device performance based on available device resources and predicting user satisfaction considering historic usage. This method is validated through a comparison to another quantitative solution that considers user preference and a method that simply considers device capabilities. Using an example scenario, the overall hit rate of this proposed method exceeds those of the other two methods, and the experimental results indicate that the proposed method is helpful for automatically selecting a user-desired device for a specific service.
C1 [Tang, Jiamei; Kim, Sangwook] Kyungpook Natl Univ, Sch Comp Sci & Engn, Coll IT Engn, Taegu 702701, South Korea.
C3 Kyungpook National University
RP Tang, J (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Coll IT Engn, 80 Daehak Ro, Taegu 702701, South Korea.
EM tangjiamei618@gmail.com; kimsw@knu.ac.kr
FU Next-Generation Information Computing Development Program through
   National Research Foundation of Korea (NRF) - Ministry of Science, ICT &
   Future Planning [2012M3C4A7032185]
FX This research was supported by the Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF), funded by the Ministry of Science, ICT & Future Planning (No.
   2012M3C4A7032185).
CR Badr Youakim, 2008, 2008 4th International Conference on Next Generation Web Services Practices, P60, DOI 10.1109/NWeSP.2008.39
   Bronsted J., 2007, Proc. UbiComp Workshop, P87
   Demers Louise., 2002, TECHNOL DISABIL, V14, P101, DOI [10.3233/TAD-2002-14304, DOI 10.3233/TAD-2002-14304]
   Doll WJ, 1988, MIS Q, V12
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Elting C., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P55
   Friday A, 2004, WIREL NETW, V10, P631, DOI 10.1023/B:WINE.0000044024.54833.cb
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Helal S, 2003, IEEE WCNC, P2107
   Huhns MN, 2005, IEEE INTERNET COMPUT, V9, P75, DOI 10.1109/MIC.2005.21
   Kaowthumrong K, 2002, WORKSH UBICOMP 20022
   Kim MK, 2004, TELECOMMUN POLICY, V28, P145, DOI 10.1016/j.telpol.2003.12.003
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Lin N, 2008, SEMANTIC WEB RES APP, P29
   Mukhtar H, 2009, ICNS: 2009 FIFTH INTERNATIONAL CONFERENCE ON NETWORKING AND SERVICES, P43, DOI 10.1109/ICNS.2009.56
   Oviatt S., 2003, HUM FAC ER, P286
   Pan G, 2011, IEEE INTELL SYST, V26, P50, DOI 10.1109/MIS.2010.32
   Papazoglou MP, 2008, INT J COOP INF SYST, V17, P223, DOI 10.1142/S0218843008001816
   Papazoglou MP, 2003, FOURTH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING, PROCEEDINGS, P3
   Park JH, 2009, 2009 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS 2009), P175, DOI 10.1109/INCOS.2009.36
   Park Y, 2007, IND MANAGE DATA SYST, V107, P1349, DOI 10.1108/02635570710834009
   Rowley J, 2006, INTERNET RES, V16, P339, DOI 10.1108/10662240610673736
   Sohrabi S, 2006, LECT NOTES COMPUT SC, V4273, P597
   Svensson D, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES, P301
   Ter Beek M., 2006, 2006TR15
   Venkatasubramanian N, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P371, DOI 10.1145/266180.266389
   Wang X, 2006, SCI SCI TECHNOLOGY M, P90
   Yu T., 2005, Information Systems and Ebusiness Management, V3, P103, DOI DOI 10.1007/S10257-005-0052-Z
   Zeng LZ, 2004, IEEE T SOFTWARE ENG, V30, P311, DOI 10.1109/TSE.2004.11
NR 29
TC 3
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10761
EP 10783
DI 10.1007/s11042-014-2205-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700028
DA 2024-07-18
ER

PT J
AU Wang, XY
   Liu, YC
   Zhang, N
   Wu, CJ
   Yang, HY
AF Wang, Xiang-Yang
   Liu, Yang-Cheng
   Zhang, Na
   Wu, Chang-Jian
   Yang, Hong-Ying
TI An edge-preserving adaptive image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Nonsubsampled shearlet transform; Fuzzy support vector
   machines; Adaptive Bayesian threshold
ID WAVELET SHRINKAGE; ALGORITHM; REPRESENTATIONS; REMOVAL; NOISE
AB Based on nonsubsampled shearlet transform (NSST) and fuzzy support vector machines (FSVMs), we present a new denoising approach that can effectively suppress noise from an image while keeping its features intact. The noisy image is firstly decomposed into different subbands of frequency and orientation responses using NSST. The NSST detail coefficients are then divided into edge/texture-related coefficients and noise-related ones by FSVMs classifier. And finally the detail subbands of NSST coefficients are denoised by using the adaptive Bayesian threshold. Extensive experimental results demonstrate that our approach is competitive relative to many state-of-the-art denoising techniques. Especially, the proposed method can preserve edges very well while removing noise.
C1 [Wang, Xiang-Yang; Liu, Yang-Cheng; Zhang, Na; Wu, Chang-Jian; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-Yang] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou 215006, Peoples R China.
C3 Liaoning Normal University; Soochow University - China
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61472171, 61272416]; Open
   Project Program of Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) [30920130122006]; Open Foundation of Zhejiang Key Laboratory
   for Signal Processing [ZJKL_4_SP-OP2013-01]; Open Foundation of
   Provincial Key Laboratory for Computer Information Processing Technology
   (Soochow University) [KJS1325]; Open Project Program of the State Key
   Lab of CAD&CG, Zhejiang University [A1425]; Liaoning Research Project
   for Institutions of Higher Education of China [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472171 & 61272416, the Open Project Program of
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety (Nanjing University of Science and Technology) under Grant No.
   30920130122006, the Open Foundation of Zhejiang Key Laboratory for
   Signal Processing under Grant No. ZJKL_4_SP-OP2013-01, the Open
   Foundation of Provincial Key Laboratory for Computer Information
   Processing Technology (Soochow University) under Grant No. KJS1325, the
   Open Project Program of the State Key Lab of CAD&CG (Grant No. A1425),
   Zhejiang University, and Liaoning Research Project for Institutions of
   Higher Education of China under Grant No. L2013407.
CR Ashkezari AD, 2013, IEEE T DIELECT EL IN, V20, P965, DOI 10.1109/TDEI.2013.6518966
   Balster EJ, 2006, IEEE T CIRC SYST VID, V16, P220, DOI 10.1109/TCSVT.2005.857816
   Balster EJ, 2005, IEEE T IMAGE PROCESS, V14, P2024, DOI 10.1109/TIP.2005.859385
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bhujle H, 2014, IEEE T IMAGE PROCESS, V23, P356, DOI 10.1109/TIP.2013.2290871
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai Wei, 2007, Acta Electronica Sinica, V35, P1939
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fabbrini L, 2014, IEEE GEOSCI REMOTE S, V11, P99, DOI 10.1109/LGRS.2013.2247377
   Hashemi M, 2014, IEEE T SIGNAL PROCES, V62, P1147, DOI 10.1109/TSP.2013.2296272
   Hou B, 2012, IEEE J-STARS, V5, P809, DOI 10.1109/JSTARS.2012.2196680
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kazerouni A, 2013, IEEE SIGNAL PROC LET, V20, P249, DOI 10.1109/LSP.2013.2242061
   Krissian K, 2009, IEEE T IMAGE PROCESS, V18, P2265, DOI 10.1109/TIP.2009.2025553
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Peleg T, 2012, IEEE T SIGNAL PROCES, V60, P2286, DOI 10.1109/TSP.2012.2188520
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rabbani H, 2010, IET IMAGE PROCESS, V4, P413, DOI 10.1049/iet-ipr.2009.0048
   Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   Wang XY, 2010, EXPERT SYST APPL, V37, P7040, DOI 10.1016/j.eswa.2010.03.014
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   Zhang K, 2012, IEEE T IMAGE PROCESS, V21, P4309, DOI 10.1109/TIP.2012.2198220
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
   Zhu X, 2013, IEEE T PATTERN ANAL, V35, P157, DOI 10.1109/TPAMI.2012.82
NR 32
TC 8
Z9 8
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11703
EP 11720
DI 10.1007/s11042-014-2258-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600032
DA 2024-07-18
ER

PT J
AU Yang, K
   Park, T
AF Yang, Kisun
   Park, Taejung
TI K-motion: visualizing election information for live television
   broadcasts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual studio; Live television broadcast; Depth sensor; Interactive
   gesture recognition; Election information; Ballot opening
AB We present an interactive information visualization system for live television broadcasts of the ballot opening process. Our proposed system satisfies the general requirements for ballot opening processes in modern democratic political systems, in which a great deal of complex information floods in, but the time frame for gathering and processing information for live broadcasting is very limited. Traditional virtual studio techniques cannot properly handle such urgent situations, because the final presenter must wait for the visual content to be determined by the directors or engineers behind the scenes. As a solution, we implement a gesture-based interactive system based on commercial depth sensors that utilize the infra-red (IR) spectrum. Because commercial depth sensors experience interference and do not work properly under common studio lights that emit IR spectrum, we apply filters and compensation algorithms to implement a robust and stable visualization system for live television broadcasts. We also address usability and information visualization with our system, providing unique features for both the presenter and the television audience. Our system has been named "K-Motion," and it was used to broadcast on 11-12 April 2012 by the Korea Broadcasting System, one of the largest television networks in South Korea, and achieved the highest peak viewing record.
C1 [Yang, Kisun] Korea Broadcasting Syst, Seoul, South Korea.
   [Park, Taejung] Duksung Womens Univ, Seoul, South Korea.
C3 Duksung Women's University
RP Park, T (corresponding author), Duksung Womens Univ, Seoul, South Korea.
EM tjpark@duksung.ac.kr
RI Park, Taejung/GYU-9638-2022
OI Park, Taejung/0000-0001-5118-3271
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [NRF-2013R1A1A2064147]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2013R1A1A2064147).
CR [Anonymous], 2011, ACM transactions on graphics (TOG), DOI DOI 10.1145/1964921.1964972
   Bederson B.B., 2003, Human Factors in Computing Systems: Proceedings of CHI 2003, P145, DOI [10.1145/642611.642638, DOI 10.1145/642611.642638]
   BEEBE SA, 1974, SPEECH TEACH, V23, P21
   Byrne MD, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P171
   DAVIDHIZAR R, 1992, INFECT CONT HOSP EP, V13, P222
   Dokania A, BUSINESS TRANSFORMAT
   Everett SP, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P883
   Gallo L, 2011, COMP MED SY, DOI 10.1109/CBMS.2011.5999138
   Gorawara-Bhat R, 2011, PATIENT EDUC COUNS, V82, P442, DOI 10.1016/j.pec.2010.12.002
   Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Ryden F, 2011, P ROB SCI SYST RSS W
   Stowers J., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics (ICM), P358, DOI 10.1109/ICMECH.2011.5971311
NR 13
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11631
EP 11651
DI 10.1007/s11042-014-2253-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600029
DA 2024-07-18
ER

PT J
AU Benmohamed, A
   Neji, M
   Ramdani, M
   Wali, A
   Alimi, AM
AF Benmohamed, Abderrahim
   Neji, Mohamed
   Ramdani, Messaoud
   Wali, Ali
   Alimi, Adel M.
TI Feast: face and emotion analysis system for smart tablets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Smart tablet; Face detection; Emotion recognition
AB Face and emotion recognition is still an open and very challenging problem. This paper presents a system FEAST which is an intelligent control system of Smart Tablets. It involves manipulating user sessions to adapt the working environment to his emotional state. First, a face detection followed by face and emotion recognition is performed, then a profile change is made basing on the obtained results. The face detection is based on skin color and geometric moments and face recognition is done by merging two features spaces, namely, Zernike moments and EAR-LBP. A feature selection technique reducing the parameter space size is applied. The same parameters are used for the emotion recognition.
C1 [Neji, Mohamed; Wali, Ali; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax 3038, Tunisia.
   [Ramdani, Messaoud] Badji Mokhtar Annaba Univ, Fac Engn, Dept Elect, Annaba 23000, Algeria.
   [Benmohamed, Abderrahim] Mohamed Cherif Messaadia Univ Souk Ahras, Dept Informat, Fac Sci & Tech, Souk Ahras 41000, Algeria.
   [Benmohamed, Abderrahim] Badji Mokhtar Annaba Univ, Fac Engn, Dept Informat, Annaba 23000, Algeria.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite Badji Mokhtar - Annaba; Universite Badji Mokhtar - Annaba
RP Wali, A (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM benmohamed.abderrahim@gmail.com; ali.wali@ieee.org
RI Wali, Ali/J-7961-2012; Alimi, Adel M./A-5697-2012; Néji,
   Mohamed/A-1135-2013; Ramdani, Messaoud/R-8746-2019; Neji,
   Mohamed/P-5532-2019; Wali, Ali/R-4243-2019
OI Wali, Ali/0000-0002-8423-7923; Alimi, Adel M./0000-0002-0642-3384;
   Ramdani, Messaoud/0000-0002-6726-1155; Wali, Ali/0000-0002-8423-7923
CR Alastair JG, 2008, P CHI FLOR IT
   Amine A, 2008, LECT NOTES COMPUT SC, V5099, P321, DOI 10.1007/978-3-540-69905-7_37
   Bac LH, 2005, LECT NOTES ARTIF INT, V3518, P226
   BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915
   Burgoon JK, 2005, INT AN C MCCLEAN
   Camurri A, 2003, INT J HUM-COMPUT ST, V59, P213, DOI 10.1016/S1071-5819(03)00050-8
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carlo S, 2008, SAC 08
   Cristian XR, 2012, MULTIMED TOOLS APPL
   Crowley Katie, 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P276, DOI 10.1109/ICALT.2010.81
   Ekman P, 1978, FACIAL ACTION CODING
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Erik H, 2001, SURV COMPUT VISION I, V83, P236, DOI DOI 10.1006/CVIU.2001.0921
   Gunes H, 2006, INT C PATT RECOG, P1148
   Gyu-Tae P, 2000, PATTERN RECOGN LETT, V21, P93105
   Haapalainen E, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P301
   Haddadnia J, 2003, INT J PATTERN RECOGN, V17, P41, DOI 10.1142/S0218001403002265
   Han CC, 1997, LECT NOTES COMPUTER, V1311
   Hong P, 2011, LNCS 2, V6692, P228
   Hua Y, 2012, MUTIMED TOOLS APPL
   Huang XM, 2015, MULTIMED TOOLS APPL, V74, P8293, DOI 10.1007/s11042-013-1783-3
   James J, 2012, P FISITA
   Jen-Da S, 2007, APPL INTELL, V28, P69
   Jingru WM, 1999, PATTERN RECOGN ARTIF, V12
   Kapur A, 2005, ACII
   Karin S, 1997, INT WORK AUD VID BIO
   Kawulok M, 2010, MULTIMED TOOLS APPL, V49, P463, DOI 10.1007/s11042-009-0444-z
   Kim JK, 2012, COMM COM INF SC, V353, P141
   Lai JH, 2001, PATTERN RECOGN, V34, P95, DOI 10.1016/S0031-3203(99)00200-9
   LANITIS A, 1995, IMAGE VISION COMPUT, V13, P393, DOI 10.1016/0262-8856(95)99726-H
   Le HT, 2011, INT J MACH LEARN COM, V1
   Leonardis A, 2000, COMPUT VISION IMAGE, V78, P99118
   Lin YT, 2013, MULTIMED TOOLS APPL, V65, P543, DOI 10.1007/s11042-012-1202-1
   Mase K, 1991, IEICE T, V74
   Nefian AV, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P141, DOI 10.1109/ICIP.1998.723445
   New T, 2003, SPEECH COMMUN, V41
   Niemann H., 1990, PATTERN ANAL UNDERST
   Nikolaidis A, 2000, PATTERN RECOGN, V33, P1783, DOI 10.1016/S0031-3203(99)00176-4
   Nina Z, 2009, LECT NOTES COMPUT SC, V5507, P551, DOI 10.1007/978-3-642-03040-6_67
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Pei-zhi C, 2010, NEW FACE RECOGNITION
   Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Ryu YS, 2001, PATTERN RECOGN, V34, P2459, DOI 10.1016/S0031-3203(00)00173-4
   Satyanadh G, 2007, SIGNALS COMM TECHNOL, P109
   Schneiderman H, 1998, P IEEE C COMP VIS PA, P4551
   Shenghua B, 2012, IEEE T KNOWLEDGE DAT, V24
   Shi ZP, 2012, MULTIMED TOOLS APPL, V61, P263, DOI 10.1007/s11042-011-0836-8
   Shih FY, 2004, INFORM SCIENCES, V158, P117, DOI 10.1016/j.ins.2003.03.002
   Shizhi C, 2011, COMP VIS PATT REC WO
   SUNG KK, 1996, THESIS MIT
   Taskeed J Md, 2010, ETRI J, V32
   Tefas A, 2001, IEEE T PATTERN ANAL, V23, P735, DOI 10.1109/34.935847
   Tsekeridou S., 1998, Proceedings of the IX European Signal Processing Conference, V1, P315
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Venugopal KR, 2012, CCIS, V292, P244
   Wan-zeng K, 2007, J ZHEJIANG UNIV-SC A, V8, P7278
   YACOOB Y, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P70, DOI 10.1109/CVPR.1994.323812
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yazhou L, 2005, LECT NOTES COMPUT SC, V3768, P946
   Yilmaz A, 2001, PATTERN RECOGN, V34, P181, DOI 10.1016/S0031-3203(00)00031-5
   Ying-li Tian, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P484, DOI 10.1109/AFGR.2000.840678
NR 64
TC 7
Z9 7
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9297
EP 9322
DI 10.1007/s11042-014-2082-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200011
DA 2024-07-18
ER

PT J
AU dos Santos, AM
   Bianchini, D
AF dos Santos, Alan Menk
   Bianchini, David
TI Smart marketing in Brazilian digital TV system through a recommendation
   ads
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital TV; Interactivity; Recommendation systems; Personalization;
   Smart marketing
AB With the implementation of the Brazilian Digital TV System (SBTVD), starts a range of new opportunities and possibilities both for viewer as for TV stations. For the viewers, they will have an immense amount of channels, programs and interactive advertisements. For TV stations, it increases the possibility of advertising in new media. Within this framework, the opportunity arises for a recommendation system for applications and interactivity portals. This dissertation presents a proposal of advertising personalization into applications and portals of digital TV environment in order to bring a better experience to the viewer, a new form of income for the broadcasters and also a greater acceptance of specialized products for use. This work develops an application for interactive Digital TV called Smart Marketing, capable of capturing viewer navigation data through both implicit and explicit means by performing customized advertising from the process of knowledge discovery. Developed from AstroTV middleware, compatible with the Brazilian specification, its application was evaluated by means of experiment that used varied user profiles, applying into the generated database the process of knowledge discovery, which used tasks of classification and grouping. The results indicated the quality of the recommendation generated by Smart Marketing.
C1 [dos Santos, Alan Menk; Bianchini, David] Pontificia Univ Catolica Campinas, Campinas, SP, Brazil.
C3 Pontificia Universidade Catolica de Campinas
RP dos Santos, AM (corresponding author), Pontificia Univ Catolica Campinas, Rodovia Dom Pedro I,Km 136 Parque Univ, Campinas, SP, Brazil.
EM alanmenk@hotmail.com; davidb@puc-campinas.edu.br
CR [Anonymous], P ACM RECSYS 2010 WO
   Aranha F, 2000, ANAL REDES PROCEDIME
   Burrowes P, 2012, COMMUNICACAO MEDIA C, V2, P205
   Camacho K, 2012, VOLKS APOSTA NOVO GO
   CPQD, 2012, REC US SEG
   Craide S, 2012, TV DIGITAL INTERATIV
   DATOS, 2011, DIR MARK LIST CLASS
   ERABAKI, 2012, PLATF IND TEXT MIN E
   Hanson W., 1999, PRINCIPLES INTERNET
   IBGE, 2012, INST BRAS GEOGR EST
   KNIME, 2012, KONST INF MIN
   KXEN, 2012, PRED AN LEAD
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Meira WJ, 2002, SISTEMAS COMERCIO EL
   SAS, 2012, MOD DEV DEPL
   WEBMOTORS, 2012, SAIB QUAIS SAO DEZ C
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
NR 17
TC 1
Z9 1
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8343
EP 8364
DI 10.1007/s11042-013-1697-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600007
DA 2024-07-18
ER

PT J
AU Koch, A
   Bourgeois-République, C
   Dipanda, A
AF Koch, Alain
   Bourgeois-Republique, Claire
   Dipanda, Albert
TI Evolutionary algorithms for a mixed stereovision uncalibrated 3D
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Evolutionary algorithm; Uncalibrated system;
   Correspondence problem; Encoding
ID GENETIC ALGORITHM; CALIBRATION
AB This paper proposes an original 3D shape reconstruction which is a mixture of the passive and active stereovision systems. Similarly to the passive stereovision systems, two cameras are used to acquire the images. As for the active stereovision methods, the detection of the points of interest (POIs) and the matching problem are solved by using a structured-light pattern projected onto the analysed object. An encoding is proposed to ease the matching procedure. Then, Evolutionary Algorithms (EAs) are designed to calculate the depth of the detected POIs. Numerous experiments are conducted to validate the different steps of the proposed method.
C1 [Koch, Alain; Bourgeois-Republique, Claire; Dipanda, Albert] Univ Bourgogne, Fac Sci, LE2I, CNRS UMR 6306, F-21000 Dijon, France.
C3 Universite de Bourgogne
RP Bourgeois-République, C (corresponding author), Univ Bourgogne, Fac Sci, LE2I, CNRS UMR 6306, 9 Ave Alain Savary,BP 47870, F-21000 Dijon, France.
EM claire.bourgeois-republique@u-bourgogne.fr; adipanda@u-bourgogne.fr
CR Batenburg KJ, 2005, DISCRETE APPL MATH, V151, P36, DOI 10.1016/j.dam.2005.02.021
   Ben-Hamadou A, 2013, COMPUT VIS IMAGE UND, V117, P1468, DOI 10.1016/j.cviu.2013.06.002
   Bensrhair A, 1996, PATTERN RECOGN LETT, V17, P457, DOI 10.1016/0167-8655(96)00004-9
   Bleyer M, 2007, SIGNAL PROCESS-IMAGE, V22, P127, DOI 10.1016/j.image.2006.11.012
   Brunetti A, 2000, COMPUT PHYS COMMUN, V124, P204, DOI 10.1016/S0010-4655(99)00454-3
   Chou HL, 2004, PATTERN RECOGN LETT, V25, P1399, DOI 10.1016/j.patrec.2004.05.018
   Cootes TF, 1996, IMAGE VISION COMPUT, V14, P581, DOI 10.1016/0262-8856(96)01099-2
   Derrac J, 2014, INFORM SCIENCES, V289, P41, DOI 10.1016/j.ins.2014.06.009
   Dipanda A, 2005, PATTERN RECOGN, V38, P1632, DOI 10.1016/j.patcog.2005.01.006
   Dipanda A, 2003, PATTERN RECOGN, V36, P2143, DOI 10.1016/S0031-3203(03)00049-9
   Du GL, 2014, ROBOT CIM-INT MANUF, V30, P150, DOI 10.1016/j.rcim.2013.09.003
   FAUGERAS OD, 1987, P INT WORKSH MACH VI
   Gao Wei, 2008, Acta Automatica Sinica, V34, P1358, DOI 10.3724/SP.J.1004.2008.01358
   Goldberg DavidE., 2007, Genetic Algorithms in Search, Optimization Machine Learning
   Han KP, 2001, PATTERN RECOGN, V34, P1729, DOI 10.1016/S0031-3203(00)00114-X
   Heikkilä J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788
   Ibañez R, 2014, ADV ENG SOFTW, V76, P171, DOI 10.1016/j.advengsoft.2014.07.005
   Jang W, 2013, OPT LASER ENG, V51, P1255, DOI 10.1016/j.optlaseng.2013.05.001
   Koch A, 2012, MULTIMED TOOLS APPL, V57, P565, DOI 10.1007/s11042-010-0657-1
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   Shi FH, 2004, PATTERN RECOGN LETT, V25, P1155, DOI 10.1016/j.patrec.2004.03.010
   Wang Y, 2013, OPT LASER TECHNOL, V49, P28, DOI 10.1016/j.optlastec.2012.12.008
   Zhang J, 2008, IMAGE VISION COMPUT, V26, P201, DOI 10.1016/j.imavis.2007.04.003
   Zhang XY, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P26, DOI 10.1109/IAI.2002.999883
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao Y, 2012, APPL OPTICS, V51, P3338, DOI 10.1364/AO.51.003338
NR 26
TC 5
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8703
EP 8721
DI 10.1007/s11042-014-2354-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600029
DA 2024-07-18
ER

PT J
AU Yang, HS
AF Yang, Hwan-Seok
TI A study on attack information collection using virtualization technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtualization; Computer security; Honeypot; Honeynet
AB Internet is used in all sectors of society by rapid changes in computing technology and expanded internet prevalence. But due to opposite effect of this, malicious code and damage of hacking is growing rapidly and the technique is becoming various. Attacker's attack patterns and information should be collected in order to reduce the damage and cope more aggressively to attack. In this paper, we propose a system which build honeypot farm using created virtual machine dynamically by utilizing honeypot to collect attack information and virtualization technology. The created virtual machines are managed by VMSC and protocol-based intrusion detection system which shows stable performance in mass traffic to attacker's intrusion detection is applied. Measurement of attack attempt and attack detection rate was measured to confirm the performance of the proposed system in this paper and the result of good performance through experiment was confirmed.
C1 Joongbu Univ, Dept Informat Secur Engn, Chubu Myeon, Chungnam, South Korea.
C3 Joongbu University
RP Yang, HS (corresponding author), Joongbu Univ, Dept Informat Secur Engn, 101 Majeon Ri, Chubu Myeon, Chungnam, South Korea.
EM yanghs@joongbu.ac.kr
CR Baumann R, WHITE PAPER HONEYPOT
   Costa DG, 2011, MULTIMED TOOLS APPL, V55
   Ikinci A., 2008, Sicherheit, V8, P407
   Koachev D, 2012, MULTIMED TOOLS APPL, V58, P1
   Kreibich Christian., 2011, Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference, P397, DOI DOI 10.1145/2068816.2068854
   Lee DH, 2010, MULTIMED TOOLS APPL, V50
   Leita C, 2005, P 21 ANN COMP SEC AP, P203
   Marchette D., 2001, Computer Intrusion Detection and Network Monitoring: A Statistical Viewpoint
   Nance K, 2008, IEEE SECUR PRIV, V6, P32, DOI 10.1109/MSP.2008.134
   NING P, 2003, 10 ACM C COMP COMM S, V1, P200, DOI DOI 10.1145/948109.948137.HTTP://D0I.ACM.0RG.EZPR0XY1.LIB.ASU.EDU/10.1145/948109.948137
   Park WH, 2012, MULTIMED TOOLS APPL, V60, P1
   Provos N, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P1
   Spitzner L., 2002, Honeypots, "Tracking Hackers,"
NR 13
TC 9
Z9 11
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8791
EP 8799
DI 10.1007/s11042-013-1487-8
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600006
DA 2024-07-18
ER

PT J
AU Agarwal, H
   Raman, B
   Venkat, I
AF Agarwal, Himanshu
   Raman, Balasubramanian
   Venkat, Ibrahim
TI Blind reliable invisible watermarking method in wavelet domain for face
   image watermark
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Redundant discrete wavelet transform (RDWT); Discrete wavelet transform
   (DWT); Biometrics; Watermarking; Peak signal to noise ratio (PSNR);
   Normalized correlation coefficient (NC)
ID ROBUST WATERMARKING; DIGITAL WATERMARKING; ENHANCING SECURITY; BIOMETRIC
   DATA; SYSTEM
AB In this paper, we have combined watermarking and biometrics for possible improvement in owner identification/verification technology. We have proposed and compared wavelet based four blind invisible watermarking methods that have used face image as watermark. Two watermarking methods are based on the discrete wavelet transform (DWT) and rest two watermarking methods are based on the redundant discrete wavelet transform (RDWT). One watermarking method in each transform incorporates weighted binary coding to achieve improved reliability of extracted watermark. Other watermarking methods replace original image coefficients with face image coefficients. We have observed that DWT based watermarking methods outperform RDWT based watermarking methods. We have compared the robustness of the proposed watermarking methods against various common image processing attacks/operations. We have observed that DWT based watermarking method coupled with weighted binary coding has the best performance without attacks; peak signal to noise ratio value of watermarked image is greater than 50 dB and normalized correlation coefficient value of extracted watermark is 1 at the watermark embedding strength of 1. Moreover, the same watermarking method has the best robustness against most of the attacks.
C1 [Agarwal, Himanshu] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
   [Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
   [Venkat, Ibrahim] Univ Sains Malaysia, Sch Comp Sci, George Town, Malaysia.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee; Universiti
   Sains Malaysia
RP Agarwal, H (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM him11dma@iitr.ac.in; balarfma@iitr.ac.in; ibrahim@cs.usm.my
RI Agarwal, Himanshu/D-2825-2017
OI Agarwal, Himanshu/0000-0002-9950-7447
FU University Grants Commission (UGC), of New Delhi, India
FX One of the authors, Himanshu Agarwal, acknowledges the University Grants
   Commission (UGC), of New Delhi, India for granting him a scholarship
   under the JRF scheme for his research.
CR [Anonymous], IEEE INT C IMAG PROC
   [Anonymous], 2009, GAZ CONS UN ID AUTH
   [Anonymous], ACOUST SPEECH SIG PR
   [Anonymous], STUDY IRIS FEATURE W
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V52, P621, DOI 10.1007/s11042-009-0433-2
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Cao JG, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P277, DOI 10.1109/ICIP.2001.958478
   Cheddad A, 2008, FIFTEENTH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P159, DOI 10.1109/ECBS.2008.11
   Chung YW, 2005, LECT NOTES ARTIF INT, V3683, P1049
   Dugad R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P419, DOI 10.1109/ICIP.1998.723406
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Fouad M., 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P25, DOI 10.1109/ISSPA.2010.5605564
   Fridrich J, 2000, PROC SPIE, V3971, P286, DOI 10.1117/12.384982
   Ghouti L, 2006, IEEE T SIGNAL PROCES, V54, P1519, DOI 10.1109/TSP.2006.870624
   Gunsel B, 2002, PATTERN RECOGN, V35, P2739, DOI 10.1016/S0031-3203(01)00250-3
   Hassanien A. E., 2006, Pattern Recognition and Image Analysis, V16, P637, DOI 10.1134/S1054661806040092
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hong I, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P1946, DOI 10.1109/ISIE.2001.932010
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Hsu CT, 1998, IEEE T CIRCUITS-II, V45, P1097, DOI 10.1109/82.718818
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2012, COMPUTER, V45, P87, DOI 10.1109/MC.2012.364
   Jong Ryul Kim, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P226, DOI 10.1109/ICIP.1999.822889
   Keyvanpour MR, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.040
   Khan MK, 2007, LECT NOTES COMPUT SC, V4642, P702
   Khan MK, 2007, CHAOS SOLITON FRACT, V32, P1749, DOI 10.1016/j.chaos.2005.12.015
   Kim T, 2006, LECT NOTES COMPUT SC, V3919, P217
   Kim WG, 2009, SIGNAL PROCESS, V89, P2385, DOI 10.1016/j.sigpro.2009.04.014
   Korus P, 2014, MULTIMED TOOLS APPL, V68, P59, DOI 10.1007/s11042-011-0986-8
   Kougianos E, 2009, COMPUT ELECTR ENG, V35, P339, DOI 10.1016/j.compeleceng.2008.06.002
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li CL, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P95, DOI 10.1109/MINES.2009.70
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Liu JL, 2006, COMPUT STAND INTER, V28, P356, DOI 10.1016/j.csi.2005.07.001
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Mohanty SP, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413865
   Mohanty SP, 2009, J SYST ARCHITECT, V55, P468, DOI 10.1016/j.sysarc.2009.09.005
   Morimoto N., 1999, Informing Science, V2, P107
   Noore A, 2007, FORENSIC SCI INT, V169, P188, DOI 10.1016/j.forsciint.2006.08.019
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Qi M, 2010, J NETW COMPUT APPL, V33, P247, DOI 10.1016/j.jnca.2009.12.004
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   Ratha N.K., 2000, P ACM MULTIMEDIA, P127
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Reddy AA, 2005, PATTERN RECOGN LETT, V26, P1019, DOI 10.1016/j.patrec.2004.09.047
   Roy SD, 2013, IEEE T CIRC SYST VID, V23, P300, DOI 10.1109/TCSVT.2012.2203738
   Shejul AA, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA STORAGE AND DATA ENGINEERING (DSDE 2010), P39, DOI 10.1109/DSDE.2010.10
   Shumin Ding, 2010, Proceedings of the 2010 WASE International Conference on Information Engineering (ICIE 2010), P105, DOI 10.1109/ICIE.2010.120
   Soheili MR, 2008, I C COMP SYST APPLIC, P591, DOI 10.1109/AICCSA.2008.4493591
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Tay P, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P258
   Vatsa M., 2004, P WORKSHOP BIOMETRIC, P5
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
   Zebbiche K, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/918601
   Zebbiche K, 2006, AHS 2006: FIRST NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P451
   Zhang XD, 2003, J VIS COMMUN IMAGE R, V14, P474, DOI 10.1016/S1047-3203(03)00047-6
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 69
TC 15
Z9 15
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6897
EP 6935
DI 10.1007/s11042-014-1934-1
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800015
DA 2024-07-18
ER

PT J
AU Essmaeel, K
   Gallo, L
   Damiani, E
   De Pietro, G
   Dipanda, A
AF Essmaeel, Kyis
   Gallo, Luigi
   Damiani, Ernesto
   De Pietro, Giuseppe
   Dipanda, Albert
TI Comparative evaluation of methods for filtering Kinect depth data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Comparative evaluation; Kinect; Depth data; Depth instability; Temporal
   denoising; Median filter; Bilateral filter
ID ENHANCEMENT
AB The release of the Kinect has fostered the design of novel methods and techniques in several application domains. It has been tested in different contexts, which span from home entertainment to surgical environments. Nonetheless, to promote its adoption to solve real-world problems, the Kinect should be evaluated in terms of precision and accuracy. Up to now, some filtering approaches have been proposed to enhance the precision and accuracy of the Kinect sensor, and preliminary studies have shown promising results. In this work, we discuss the results of a study in which we have compared the most commonly used filtering approaches for Kinect depth data, in both static and dynamic contexts, by using novel metrics. The experimental results show that each approach can be profitably used to enhance the precision and/or accuracy of Kinect depth data in a specific context, whereas the temporal filtering approach is able to reduce noise in different experimental conditions.
C1 [Essmaeel, Kyis; Dipanda, Albert] Univ Bourgogne, Lab LE2I, Aile Sci Ingenieur, Dijon, France.
   [Essmaeel, Kyis; Gallo, Luigi; De Pietro, Giuseppe] ICAR CNR, Naples, Italy.
   [Essmaeel, Kyis; Damiani, Ernesto] Univ Milan, Dept Comp Technol, Milan, Italy.
C3 Universite de Bourgogne; Consiglio Nazionale delle Ricerche (CNR);
   Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR); University of
   Milan
RP Essmaeel, K (corresponding author), Univ Bourgogne, Lab LE2I, Aile Sci Ingenieur, 9 Ave Alain Savary, Dijon, France.
EM kyis.essmaeel@na.icar.cnr.it; luigi.gallo@na.icar.cnr.it;
   ernesto.damiani@unimi.it; giuseppe.depietro@na.icar.cnr.it;
   adipanda@u-bourgogne.fr
RI de pietro, giuseppe/L-6139-2019; damiani, ernesto/AAI-5709-2020; Gallo,
   Luigi/A-2924-2012; De Pietro, Giuseppe/AAZ-1151-2020
OI de pietro, giuseppe/0000-0002-4675-5957; damiani,
   ernesto/0000-0002-9557-6496; Gallo, Luigi/0000-0002-1281-404X; 
CR Andersen M.R., 2012, KINECT DEPTH SENSOR
   [Anonymous], 8 INT C METH TECHN B
   [Anonymous], 2011, MICROSOFT KINECT X B
   Berger Kai, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P257, DOI 10.1007/978-3-642-44964-2_12
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Camplani M, 2012, EFFICIENT SPATIOTEMP, P82
   Cerveri P, 2003, HUM MOVEMENT SCI, V22, P377, DOI 10.1016/S0167-9457(03)00004-6
   Chan D., 2008, ECCV WORKSH MULT MUL
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   Dutta T, 2012, APPL ERGON, V43, P645, DOI 10.1016/j.apergo.2011.09.011
   Essmaeel K, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P47, DOI 10.1109/SITIS.2012.18
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Fu JJ, 2012, IEEE INT SYMP CIRC S, P512, DOI 10.1109/ISCAS.2012.6272078
   Gallo L, 2012, INT J HUM-COMPUT ST, V70, P287, DOI 10.1016/j.ijhcs.2011.12.001
   Gallo L, 2011, COMP MED SY, DOI 10.1109/CBMS.2011.5999138
   Gallo L, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS (CISIS 2010), P712, DOI 10.1109/CISIS.2010.76
   Hartley JL, 2012, METHODS MOL BIOL, V801, P1, DOI 10.1007/978-1-61779-352-3_1
   Huhle Benjamin, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563158
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Maimone A, 2012, COMPUT GRAPH-UK, V36, P791, DOI 10.1016/j.cag.2012.04.011
   Matyunin S., 2011, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, P1
   Merrell P, 2007, IEEE I CONF COMP VIS, P3012, DOI 10.1109/iccv.2007.4408984
   Monnich H., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P449, DOI 10.1109/ROBIO.2011.6181327
   Nguyen CV, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P524, DOI 10.1109/3DIMPVT.2012.84
   Parra-Dominguez GS, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P97, DOI 10.1109/3DIMPVT.2012.34
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Stoyanov T., 2011, P EUR C MOB ROB ECMR
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
NR 33
TC 15
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7331
EP 7354
DI 10.1007/s11042-014-1982-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800033
DA 2024-07-18
ER

PT J
AU Rana, S
   Sahu, N
   Sur, A
AF Rana, Shuvendu
   Sahu, Nilkanta
   Sur, Arijit
TI Robust watermarking for resolution and quality scalable video sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Watermarking; H.264; SVC; Scale invariant; Block DCT; MCDCT-TF;
   Scalable watermarking; Blind watermarking; Spatial scalability
AB Due to the increasing heterogeneity among the end using devices for playing multimedia content, scalable video communication attracts significant attention in recent days. As a consequence, content authentication or ownership authentication using watermarking for scalable video stream is becoming emerging research topic. In this paper, a watermarking scheme for scalable video is proposed which is robust against spatial and quality scalability. In the proposed scheme, a DC frame is generated by accumulating DC values of non-overlapping blocks for every frame in the input video sequence. DC frame sequence is up-sampled and subtracted from the original video sequence to generate residual frame sequence. Then Discrete Cosine Transform (DCT) based temporal filtering is applied on DC as well as residual frame sequence. Watermark is embedded in low pass frames of DC frames and up sampled watermark is embedded in the low pass residual frames to achieve the graceful improvement of watermark signal in successive enhancement layer. A comprehensive set of experiments are done to justify the superiority of the proposed scheme over existing literature with respect to spatial and quality adaptation attacks as well as visual quality.
C1 [Rana, Shuvendu; Sahu, Nilkanta; Sur, Arijit] IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Sahu, N (corresponding author), IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM shuvendu@iitg.ac.in; nilkanta@iitg.ac.in; arijit@iitg.ac.in
RI Rana, Shuvendu/J-5190-2019; Sur, Arijit/AAB-4216-2020; Rana,
   Shuvendu/ACC-7002-2022
OI Rana, Shuvendu/0000-0002-8372-5669; Rana, Shuvendu/0000-0002-8372-5669;
   Sur, Arijit/0000-0002-9038-8138
CR [Anonymous], 2000, DCT BASED VIDEO QUAL
   Atta R, 2006, IEEE T CIRC SYST VID, V16, P43, DOI 10.1109/TCSVT.2005.858743
   Bhattacharya S, 2006, I SYMP CONSUM ELECTR, P616
   BHOWMIK D, 2010, P 12 ACM WORKSH MULT, P127, DOI DOI 10.1145/1.854229.1854254
   Chang FC, 2005, IEEE INT SYMP CIRC S, P4983
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Essaouabi A, 2009, NDT: 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKED DIGITAL TECHNOLOGIES, P429, DOI 10.1109/NDT.2009.5272116
   Fan X., 2002, JVTE070 ISOIEC MPEG
   Grois D, 2012, RECENT ADV WATERMARK
   Hmmerle-Uhl J, 2011, WATERMARKING MEANS E, V6958, P238
   Jung HS, 2004, EURASIP J APPL SIG P, V2004, P2113, DOI 10.1155/S1110865704405046
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lin WS, 2006, IEEE IMAGE PROC, P2293, DOI 10.1109/ICIP.2006.312833
   Lu WM, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2338
   Meerwald Peter, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P82, DOI 10.1109/IIHMSP.2010.28
   Meerwald P, 2008, P SPIE, V6819
   Noorkami M, 2008, IEEE T INF FOREN SEC, V3, P441, DOI 10.1109/TIFS.2008.923825
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Piper A, 2004, LECT NOTES COMPUT SC, V2939, P235
   PIPER A, 2005, P 7 WORKSH MULT SEC, P79, DOI DOI 10.1145/1073170.1073186
   Seo J, 2005, Fourth Annual ACIS International Conference on Computer and Information Science, Proceedings, P376
   Shi F, 2010, LECT NOTES COMPUT SC, V6297, P697
   Vatolin D., 2001, MSU VIDEO QUALITY ME
   Vinod P., 2006, IEE Proceedings-Information Security, V153, P61, DOI 10.1049/ip-ifs:20055088
   Wang CC, 2006, DIGITAL AUTHENTICATI, P16
   Wang C, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1457, DOI 10.1109/ICME.2006.262816
   Wang Y, 2006, IEE P-VIS IMAGE SIGN, V153, P581, DOI 10.1049/ip-vis:20045094
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xing Chang, 2011, 2011 Seventh International Conference on Natural Computation (ICNC 2011), P61, DOI 10.1109/ICNC.2011.6022111
   Yan Liu, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P443, DOI 10.1049/cp:20080354
   Zhuang HY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1727, DOI 10.1109/ICME.2004.1394587
NR 31
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7773
EP 7802
DI 10.1007/s11042-014-2023-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200017
DA 2024-07-18
ER

PT J
AU Walha, A
   Wali, A
   Alimi, AM
AF Walha, Ahlem
   Wali, Ali
   Alimi, Adel M.
TI Video stabilization with moving object detecting and tracking for aerial
   video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Aerial surveillance; Scale invariant feature
   transform (SIFT); Digital video stabilization
ID DIGITAL IMAGE STABILIZATION
AB Aerial surveillance system provides a large amount of data compared with traditional surveillance system. But, it usually suffers from undesired motion of cameras, which presents new challenges. These challenges must be overcome before such video can be widely used. In this paper, we present a novel video stabilization and moving object detection system based on camera motion estimation. We use local feature extraction and matching to estimate global motion and we demonstrate that Scale Invariant Feature Transform (SIFT) keypoints are suitable for the stabilization task. After estimating the global camera motion parameters using affine transformation, we detect moving object by Kalman filtering. For motion smoothing, we use a median filter to retain the desired motion. Finally, motion compensation is carried out to obtain a stabilized video sequence. A number of aerial video examples demonstrate the effectiveness of our proposed system. We use the software Virtual Dub with the Deshaker-Plugin for test purposes. For objective evaluation, we use Interframe Transformation Fidelity for video stabilization tasks and Detection Ratio for moving object detection task.
C1 [Walha, Ahlem; Wali, Ali; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Walha, A (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM walha.ahlem@ieee.org; ali.wali@ieee.org; adel.alimi@ieee.org
RI Wali, Ali/R-4243-2019; Walha, Ahlem/AAM-9724-2020; Wali,
   Ali/J-7961-2012; Alimi, Adel M./A-5697-2012
OI Wali, Ali/0000-0002-8423-7923; Walha, Ahlem/0000-0003-2779-5328; Wali,
   Ali/0000-0002-8423-7923; Alimi, Adel M./0000-0002-0642-3384
CR Ali S, 2006, PROC SPIE, V6209, DOI 10.1117/12.667266
   [Anonymous], 2008, IEEE AEROSP C PROC, DOI [DOI 10.1109/AERO.2008.4526558, DOI 10.1109/AERO.2008.4526559]
   [Anonymous], 2012, ROTATION INVARIANT F, V8499, DOI [10.1117/12.945968, DOI 10.1117/12.945968]
   Battiato S, CATANIA SSD SIFT FEA
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Censi A., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P665, DOI 10.1109/ICIAP.1999.797671
   Chung-Ching Lin, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P460, DOI 10.1109/ICPR.2010.121
   Clark D, 2006, PROC SPIE, V6235, DOI 10.1117/12.663522
   Cuntoor Naresh P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3640, DOI 10.1109/ICPR.2010.888
   Daum F. E., 1996, IEEE AERO EL SYS MAG, V11, P41, DOI DOI 10.1109/MAES.1996.484305
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Ertürk S, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P266, DOI 10.1109/ISPA.2001.938639
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Freudenberg J.S., 2007, Proc. 46th IEEE Conf. Decision Contr, P3958
   Huang CH, 2010, LECT NOTES COMPUT SC, V6297, P357, DOI 10.1007/978-3-642-15702-8_33
   Li XM, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P411, DOI 10.1109/CISP.2012.6470015
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miller A, 2008, LECT NOTES COMPUT SC, V4625, P215
   Roujol S, 2012, IEEE T MED IMAGING, V31, P533, DOI 10.1109/TMI.2011.2171772
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shen Y, 2009, IEEE T CONSUM ELECTR, V55, P1714, DOI 10.1109/TCE.2009.5278047
   Yang SH, 2006, IEEE SYS MAN CYBERN, P1968, DOI 10.1109/ICSMC.2006.385019
   Teutsch M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2012.36
   Walha A, 2013, AASRI PROC, V4, P72, DOI 10.1016/j.aasri.2013.10.012
   Walha A, 2013, LECT NOTES COMPUT SC, V8192, P310, DOI 10.1007/978-3-319-02895-8_28
   Wali Ali, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P555, DOI 10.1109/AVSS.2010.54
   Wang YF, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P446, DOI 10.1109/ICMLA.2012.206
   Xu LD, 2006, IEEE T CONSUM ELECTR, V52, P566, DOI 10.1109/TCE.2006.1649681
   Yalcin H, 2005, FLOW BASED APPROACH
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
NR 31
TC 27
Z9 29
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6745
EP 6767
DI 10.1007/s11042-014-1928-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800009
DA 2024-07-18
ER

PT J
AU Park, P
   Yoo, S
   Ryu, H
   Park, J
   Kim, CH
   Choi, SI
   Ryou, J
AF Park, PyungKoo
   Yoo, SeongMin
   Ryu, HoYong
   Park, Jaehyung
   Kim, Cheol Hong
   Choi, Su-il
   Ryou, JaeCheol
TI A Service-oriented DDoS detection mechanism using pseudo state in a flow
   router
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed denial-of-service; Flow Router; Pseudo states
AB As distributed denial-of-service (DDoS) attacks have caused serious economic and social problems, there have been numerous researches to defend against them. The current DDoS defense system relies on a dedicated security device, which is located in front of the server it is required to protect. To detect DDoS attacks, this security device compares incoming traffic to known attack patterns. Since such a defense mechanism cannot prevent an influx of attack traffic into the network, and every packet must be compared against the known attack patterns, the mechanism often degrades the service. In this paper, we propose the Service-oriented DDoS Detection Mechanism using a Pseudo State (SDM-P), which runs on network devices to defend against DDoS attacks without sacrificing performance in terms of data forwarding. The SDM-P mechanism is suitable for both low- and high-rate attacks. In addition, we verified the performance of the SDM-P mechanism by evaluating its performance using a DDoS attack similar to the one that occurred in Korea and the USA on July 7th, 2009.
C1 [Park, PyungKoo; Ryu, HoYong] Elect & Telecommun Res Inst, Commun Internet Res Lab, Network Software Res Sect, Taejon, South Korea.
   [Yoo, SeongMin; Ryou, JaeCheol] Chungnam Natl Univ, Dept Comp Engn, Informat Secur Lab, Taejon, South Korea.
   [Park, Jaehyung; Kim, Cheol Hong; Choi, Su-il] Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Chungnam National University; Chonnam National University
RP Park, P (corresponding author), Elect & Telecommun Res Inst, Commun Internet Res Lab, Network Software Res Sect, Taejon, South Korea.
EM parkpk@etri.re.kr; mingoon@home.cnu.ac.kr; hyryu@etri.re.kr;
   hyeoung@chonnam.ac.kr; chkim22@chonnam.ac.kr; sichoi@chonnam.ac.kr;
   jcryou@home.cnu.ac.kr
OI Ryou, Jaecheol/0000-0002-2374-995X
FU R&D program of MSIP (Ministry of Science, ICT and Future Planning)
   [10043380]; ITRC (Information Technology Research Center) support
   program [NIPA-2013-H0301-13-1003]; Basic Science Research Program
   through the National Research Foundation of Korea (NRF) - Ministry of
   Education, Science, and Technology [2012R1A1A4A01004195]
FX This research was partly supported by the R&D program of MSIP (Ministry
   of Science, ICT and Future Planning) [Project No. 10043380], the ITRC
   (Information Technology Research Center) support program
   [NIPA-2013-H0301-13-1003] supervised by the NIPA (National IT Industry
   Promotion Agency) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education, Science, and Technology [Grant No. 2012R1A1A4A01004195].
CR [Anonymous], P ACM C COMP COMM SE
   [Anonymous], 2009, BBC NEWS
   BELLOVIN S, 2000, ICMP TRACEB IN PRESS
   Binstock A., 1996, Dr. Dobb's Journal, V4
   Black Jr JR, 1998, P 2 WORKSH ALG ENG W
   Broder A, 2001, P 20 ANN JOINT C IEE
   Charette C, 2011, IEEE SPECTRUM
   Gong C, 2008, IEEE T PARALL DISTR, V19, P1310, DOI 10.1109/TPDS.2007.70817
   Hillier F.S., 2001, INTRO OPERATIONS RES
   Ioannidis J., 2002, P NDSS 2002
   Jin C. G., 2003, ACM CCS
   Kuzmanovic A, 2001, IEEE ACM T IMPR IP L
   Lau F, 2000, 2000 IEEE INT C SYST
   Litwin W., 1980, P VLDB
   Paxson V, 2006, IEEE ACM T NETWORK, P601
   Shon T., 2005, 6 ANN IEEE SMC
   Waldvogel M., 1997, SCALABLE HIGH SPEED
   Wang HI, 2002, IEEE INFOCOM SER, P1530, DOI 10.1109/INFCOM.2002.1019404
NR 18
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6341
EP 6363
DI 10.1007/s11042-014-2100-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700015
DA 2024-07-18
ER

PT J
AU Zhang, ZY
   Wang, Z
   Niu, DM
AF Zhang, Zhiyong
   Wang, Zhen
   Niu, Danmei
TI A novel approach to rights sharing-enabling digital rights management
   for mobile multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Security; Digital Rights Management; Smart Mobile; Rights
   Sharing
AB Aiming at protecting the copyrights of audio, video and multimedia in mobile consumer electronics, a novel digital rights management (DRM) approach based on mobile Android terminal was proposed. Firstly, the solution adopted AES encryption and decryption algorithm to package multimedia contents, and meanwhile bound digital license to the hardware of the terminal device, as achieved the usage control and secure playback for mobile multimedia contents. Secondly, the license was written with Extensible Markup Language (XML), and especially a digital rights sharing between terminal devices was supported in the scheme. Thirdly, the times of reading and writing were reduced in the process of encrypting and decrypting multimedia contents by the way of introducing the appropriate size of the buffer, which effectively improved the encryption and decryption speed, and shortened the response time of the system. Finally, a prototype indicated that the solution has significant features of high security and faster cryptographic computation speed meeting the practical requirements for digital rights management and sharing by Android platforms.
C1 [Zhang, Zhiyong; Wang, Zhen; Niu, Danmei] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
   [Niu, Danmei] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
C3 Henan University of Science & Technology; Beijing University of Posts &
   Telecommunications
RP Zhang, ZY (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
EM xidianzzy@126.com
RI ZHANG, Zhiyong/AAG-3281-2021
OI ZHANG, Zhiyong/0000-0003-3061-7768
FU National Natural Science Foundation of China [61370220]; Plan for
   Scientific Innovation Talent of Henan Province [134100510006]; Program
   for Science & Technology Innovation Talents in Universities of Henan
   Province [2011HASTIT015]; Key Program for Basic Research of The
   Education Department of Henan Province [13A520240, 14A520048]
FX The work was sponsored by National Natural Science Foundation of China
   (Grant No. 61370220), Plan for Scientific Innovation Talent of Henan
   Province (Grant No. 134100510006), Program for Science & Technology
   Innovation Talents in Universities of Henan Province (Grant No.
   2011HASTIT015), and Key Program for Basic Research of The Education
   Department of Henan Province (Grant No. 13A520240, No. 14A520048). We
   give thanks to the reviewers and editors for their valuable comments,
   questions, and suggestions.
CR Barhoush M, 2010, TELECOMMUN SYST, V45, P3, DOI 10.1007/s11235-009-9231-4
   Bhatt S, 2009, COMPUT SECUR, V28, P327, DOI 10.1016/j.cose.2009.03.001
   Chuang C.H., 2010, Proceedings of the Annual Hawaii International Conference on System Sciences, P1, DOI DOI 10.1109/HICSS.2010.449
   Díaz-Sánchez D, 2011, IEEE T CONSUM ELECTR, V57, P970, DOI 10.1109/TCE.2011.5955247
   Fan YC, 2009, IEEE T INSTRUM MEAS, V58, P2026, DOI 10.1109/TIM.2008.2006722
   Feng X. Z., 2009, P INT C IM SIGN PROC, P1
   Guojun Ma, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P248, DOI 10.1109/IIHMSP.2011.26
   JungSoo Lee, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P64, DOI 10.1109/ISCE.2009.5156835
   Koushanfar F, 2012, IEEE T INF FOREN SEC, V7, P51, DOI 10.1109/TIFS.2011.2163307
   Lee S, 2012, J SYST SOFTWARE, V85, P1058, DOI 10.1016/j.jss.2011.12.008
   Lee S, 2009, INT J INF SECUR, V8, P263, DOI 10.1007/s10207-009-0082-5
   Lian SG, 2012, MULTIMED TOOLS APPL, V57, P49, DOI 10.1007/s11042-010-0521-3
   Lian SG, 2010, COMPUT COMMUN, V33, P1664, DOI 10.1016/j.comcom.2010.03.015
   Open Mobile Alliance, 2008, OMA DRM REQ CAND VER
   Thomas T, 2009, IEEE T INF FOREN SEC, V4, P758, DOI 10.1109/TIFS.2009.2033229
   Toma C, 2009, J MOB EMBED DISTRIB, V1, P32
   Win LL, 2012, MULTIMED TOOLS APPL, V60, P97, DOI 10.1007/s11042-011-0802-5
   Wu CC, 2010, EXPERT SYST APPL, V37, P6787, DOI 10.1016/j.eswa.2010.03.047
   Yan Xi-xi, 2012, Journal on Communications, V33, P12
   Ye C., 2012, P 20 ACM INT C MULT, P1117
   Zhang Z., 2011, INT J DIGIT CONTENT, V5, P255, DOI DOI 10.4156/JDCTA.VOL5.ISSUE3.26
   Zhang ZY, 2012, SECURITY TRUST RISK
   [No title captured]
NR 23
TC 42
Z9 47
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6255
EP 6271
DI 10.1007/s11042-014-2135-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700009
DA 2024-07-18
ER

PT J
AU Pouladzadeh, P
   Shirmohammadi, S
   Bakirov, A
   Bulut, A
   Yassine, A
AF Pouladzadeh, Parisa
   Shirmohammadi, Shervin
   Bakirov, Aslan
   Bulut, Ahmet
   Yassine, Abdulsalam
TI Cloud-based SVM for food categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Calorie measurement; Food image processing; Cloud computing
AB As people across the globe are becoming more interested in watching their weight, eating more healthily, and avoiding obesity, a system that can measure calories and nutrition in everyday meals can be very useful. Recently, due to ubiquity of mobile devices such as smart phones, the health monitoring applications are accessible by the patients practically all the time. We have created a semi-automatic food calorie and nutrition measurement system via mobile that can help patients and dietitians to measure and manage daily food intake. While segmentation and recognition are the two main steps of a food calorie measurement system, in this paper we have focused on the recognition part and mainly the training phase of the classification algorithm. This paper presents a cloud-based Support Vector Machine (SVM) method for classifying objects in cluster. We propose a method for food recognition application that is referred to as the Cloud SVM training mechanism in a cloud computing environment with Map Reduce technique for distributed machine learning. The results show that by using cloud computing system in classification phase and updating the database periodically, the accuracy of the recognition step has increased in single food portion, non-mixed and mixed plate of food compared to LIBSVM.
C1 [Pouladzadeh, Parisa; Shirmohammadi, Shervin; Yassine, Abdulsalam] Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
   [Pouladzadeh, Parisa; Shirmohammadi, Shervin; Bakirov, Aslan; Bulut, Ahmet] Istanbul Sehir Univ, Coll Engn, Istanbul, Turkey.
   [Pouladzadeh, Parisa; Shirmohammadi, Shervin; Bakirov, Aslan; Bulut, Ahmet] Istanbul Sehir Univ, Coll Nat Sci, Istanbul, Turkey.
C3 University of Ottawa; Istanbul Sehir University; Istanbul Sehir
   University
RP Pouladzadeh, P (corresponding author), Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
EM ppouladzadeh@discover.uottawa.ca; shervin@discover.uottawa.ca;
   aslanbakirov@sehir.edu.tr; ahmetbulut@sehir.edu.tr;
   ayassine@discover.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012; Abdulsalam, Yassine/ABA-9425-2020;
   Pouladzadeh, Parisa/JAX-7657-2023
OI Shirmohammadi, Shervin/0000-0002-3973-4445; Yassine,
   Abdulsalam/0000-0003-3539-0945
CR Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Deng Y, 2009, IMAGE PROCESS PHOTON, DOI [10.1117/12.836650, DOI 10.1117/12.836650]
   Du CJ, 2005, J FOOD ENG, V66, P137, DOI 10.1016/j.jfoodeng.2004.03.011
   Grzegorz, 2010, P 2010 ACM SIGMOD IN
   Harnack L, 2004, J AM DIET ASSOC, V104, P804, DOI 10.1016/j.jada.2004.02.026
   Johnson RK, 1998, J AM DIET ASSOC, V98, P1136, DOI 10.1016/S0002-8223(98)00263-6
   Kruizinga P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P142, DOI 10.1109/ICIAP.1999.797585
   Liu NA, 1999, P 5 ACM SIGKDD INT C
   Madival SA, 2012, INT J ENG RES TECHNO, V1
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Ogden CL, 2010, JAMA-J AM MED ASSOC, V303, P242, DOI 10.1001/jama.2009.2012
   Pouladzadeh P, 2014, IEEE T INSTRUM MEAS, V63, P1947, DOI 10.1109/TIM.2014.2303533
   Pouladzadeh P, 2012, IEEE INT CONF MULTI, P495, DOI 10.1109/ICMEW.2012.92
   Probst YC, 2005, J NUTR EDUC BEHAV, V37, P20, DOI 10.1016/S1499-4046(06)60255-8
   Rebro SM, 1998, J AM DIET ASSOC, V98, P1163, DOI 10.1016/S0002-8223(98)00269-7
   Sathya S., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P892, DOI 10.1109/ICETECT.2011.5760245
   Talwalkar A, 2013, C INN DAT SYST RES 2
   Trabulsi J, 2001, AM J PHYSIOL-ENDOC M, V281, pE891, DOI 10.1152/ajpendo.2001.281.5.E891
   Villalobos G., 2011, Proceedings of the 2011 International ACM Workshop on Ubiquitous Meta User Interfaces, New York, NY, USA, P17, DOI 10.1145/2072652.2072657
   Wang DH, 2006, J AM DIET ASSOC, V106, P1588, DOI 10.1016/j.jada.2006.07.004
   Young LR, 2002, AM J PUBLIC HEALTH, V92, P246, DOI 10.2105/AJPH.92.2.246
   Yucheng, 2012, PROC VLDB ENDOW, V5, P716
   Zhu FQ, 2010, IEEE J-STSP, V4, P756, DOI 10.1109/JSTSP.2010.2051471
NR 25
TC 34
Z9 39
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5243
EP 5260
DI 10.1007/s11042-014-2116-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900017
DA 2024-07-18
ER

PT J
AU Glowacz, A
   Kmiec, M
   Dziech, A
AF Glowacz, Andrzej
   Kmiec, Marcin
   Dziech, Andrzej
TI Visual detection of knives in security applications using Active
   Appearance Models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active Appearance Models; Knife-detection; Computerised video
   surveillance; Harris interest-point detector
AB In this paper, a novel application of Active Appearance Models to detecting knives in images is presented. In contrast to its popular applications in face segmentation and medical image analysis, we not only use this computer vision algorithm to locate an object that is known to exist in an analysed image, but-using an interest point typical of knives-also try to identify whether or not a knife exists in the image in question. We propose an entire detection scheme and examine its performance on a sample test set. The work presented in this paper aims to create a robust visual knife-detector to be used in security applications.
C1 [Glowacz, Andrzej; Kmiec, Marcin; Dziech, Andrzej] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Kmiec, M (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM kmiec@agh.edu.pl
RI Dziech, Andrzej/M-4483-2016
FU European Regional Development Fund under the Innovative Economy
   Operational Programme, INSIGMA project [POIG.01.01.02-00-062/09]
FX This work has been co-financed by the European Regional Development Fund
   under the Innovative Economy Operational Programme, INSIGMA project no.
   POIG.01.01.02-00-062/09.
CR [Anonymous], TECHNICAL REPORT
   [Anonymous], STAT MODELS APPEARAN
   Beichel R, 2005, IEEE T MED IMAGING, V24, P1151, DOI 10.1109/TMI.2005.853237
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Bradski Rost G, 2008, LEARNING OPENCV
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P375, DOI 10.1109/AFGR.2004.1301561
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Derpanis K.G., 2004, HARRIS CORNER DETECT
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Jiang YF, 2004, INT C PATT RECOG, P802, DOI 10.1109/ICPR.2004.1334650
   Kim DJ, 2006, IEEE IMAGE PROC, P2833, DOI 10.1109/ICIP.2006.312998
   Lavee G, 2007, MULTIMED TOOLS APPL, V35, P109, DOI 10.1007/s11042-007-0117-8
   Leung KYE, 2010, P ULTR S IUS, P197
   Liang YY, 2011, NAT MATER, V10, P780, DOI [10.1038/NMAT3087, 10.1038/nmat3087]
   Maalouf A, 2012, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-17012-17126817-9
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mitchell SC, 2000, PROC SPIE, V3979, P224, DOI 10.1117/12.387684
   Nam Y, 2012, MULTIMED TOOLS APPL, V57, P315, DOI 10.1007/s11042-010-0677-x
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Tadeusiewicz R, 2011, STUDIES COMPUTATIONA, V339
   TICKNER AH, 1973, ERGONOMICS, V16, P381, DOI 10.1080/00140137308924529
   van Ginneken B., 2004, MED IMAGE ANAL
   Viola P., 2001, P IEEE COMP SOC C CO, P1
   Wilamowski BM, 2011, IND ELECT HDB INTELL
NR 25
TC 22
Z9 23
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4253
EP 4267
DI 10.1007/s11042-013-1537-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600005
OA hybrid
DA 2024-07-18
ER

PT J
AU Jin, BW
   Geng, WD
AF Jin, Bingwen
   Geng, Weidong
TI Correspondence specification learned from master frames for automatic
   inbetweening
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial cartoon animation; Inbetweening; Keyframe; Correspondence
   specification
AB We present a new approach to automatically specify the correspondences between hand-drawn keyframes for automatic inbetweening in 2D facial cartoon animation. Recent techniques are not robust to occlusion as they mainly rely on the information provided by the keyframes, which are 2D drawings lacking 3D information. Our approach creates a hybrid face model to learn the prior knowledge about the approximate 3D geometry and multi-view appearances of an individual character's face from master frames to overcome the lack of information. Based on the hybrid model, we combine our example-based stroke annotating method with our example-based viewpoint recognition method to automatically specify accurate stroke correspondences, even when there is occlusion. Our approach facilitates auto-inbetweening much.
C1 [Jin, Bingwen; Geng, Weidong] Zhejiang Univ, Coll Comp Sci & Technol, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Jin, BW (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM vole1987@gmail.com; gengwd@zju.edu.cn
FU National Program on Key Basic Research Project of China (973 Program)
   [2013CB329504]; National High Technology Research and Development
   Program of China (863 Program) [2013AA013705]; National Natural Science
   Foundation of China [61379067]; National Key Technology R&D Program of
   the Ministry of Science and Technology [2012BAH03F03]
FX This work was supported by a grant from National Program on Key Basic
   Research Project of China (973 Program, 2013CB329504), National High
   Technology Research and Development Program of China (863 Program,
   2013AA013705), National Natural Science Foundation of China (No.
   61379067), and National Key Technology R&D Program of the Ministry of
   Science and Technology (2012BAH03F03).
CR [Anonymous], INTELLIGENT USER INT
   Baxter WV, 2009, IEEE T VIS COMPUT GR, V15, P867, DOI 10.1109/TVCG.2009.38
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Catmull E., 1978, The Problems of Computer-Assisted Animation", V12, P348
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang CW, 1997, J VISUAL COMP ANIMAT, V8, P165, DOI 10.1002/(SICI)1099-1778(199707)8:3<165::AID-VIS157>3.0.CO;2-2
   Huang J, 1998, INT C PATT RECOG, P154, DOI 10.1109/ICPR.1998.711102
   Isenberg T, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1210862
   Knerr S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P41
   Kort A., 2002, NPAR 02, P125, DOI DOI 10.1145/508530.508552
   Li SZ, 2001, P 8 IEEE INT C COMP, V2
   Li XA, 2010, COMPUT ANIMAT VIRT W, V21, P193, DOI 10.1002/cav.344
   Liu DQ, 2011, COMPUT GRAPH FORUM, V30, P2194, DOI 10.1111/j.1467-8659.2011.01969.x
   Ma BP, 2006, INT C PATT RECOG, P512
   Madeira JS, 1996, VISUAL COMPUT, V12, P1
   Mao XY, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P142
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qiu J, 2005, COMPUT ANIMAT VIRT W, V16, P463, DOI 10.1002/cav.86
   Qiu J, 2005, VISUAL COMPUT, V21, P928, DOI 10.1007/s00371-005-0307-1
   Qiu J, 2003, PG 03, P17
   Qiu J, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/135398
   Rivers A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778796
   Seah HS, 2000, VISUAL COMPUT, V16, P289, DOI 10.1007/s003719900068
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Song Z, 2013, NEUROCOMPUTING
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   Sykora D., 2011, Proceedings of International Symposium on Non-Photorealistic Animation and Rendering, P75
   Sykora Daniel, 2009, P 7 INT S NONPHOTORE, P25, DOI DOI 10.1145/1572614.1572619.3,7
   Whited B, 2010, COMPUT GRAPH FORUM, V29, P605, DOI 10.1111/j.1467-8659.2009.01630.x
   Yu J, 2012, NEUROCOMPUTING, V79, P105, DOI 10.1016/j.neucom.2011.10.003
   Zhou X-D, ICDAR, V1, P377
NR 31
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4873
EP 4889
DI 10.1007/s11042-013-1847-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400020
DA 2024-07-18
ER

PT J
AU Uddin, MZ
   Hassan, MM
AF Uddin, Md. Zia
   Hassan, Mohammad Mehedi
TI A depth video-based facial expression recognition system using radon
   transform, generalized discriminant analysis, and hidden Markov model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Depth video; Radon transformation
ID INDEPENDENT COMPONENT ANALYSIS; FACE-RECOGNITION; SEQUENCES
AB In this paper, a depth camera-based novel method is proposed to recognize several facial expressions from depth video. At first, Radon Transformation (RT) is done to extract features from the time-sequential depth faces that are further improved by Generalized Discriminant Analysis (GDA) to generate more robust features and then, Hidden Markov Models (HMMs) are applied to train and recognize different facial expressions successfully. Performance of the proposed facial expression recognition shows the superiority over conventional RGB camera-based approaches.
C1 [Uddin, Md. Zia] Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
   [Hassan, Mohammad Mehedi] King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh, Saudi Arabia.
C3 Sungkyunkwan University (SKKU); King Saud University
RP Hassan, MM (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh, Saudi Arabia.
EM ziauddin@skku.edu; mmhassan@ksu.edu.sa
RI Hassan, Mohammad/KDM-9524-2024; Uddin, Zia/AAC-1309-2020; Hassan,
   Mohammad Mehedi/D-4946-2016; Hassan, Mohammad/GZA-7507-2022
OI Uddin, Zia/0000-0002-5215-1834; Hassan, Mohammad/0000-0002-1712-0004
FU Deanship of Scientific Research at King Saud University [RGP-VPP-281]
FX The authors would like to extend their sincere appreciation to the
   Deanship of Scientific Research at King Saud University for its funding
   of this research through the Research Group Project no RGP-VPP-281.
CR Aleksic PS, 2006, IEEE T INF FOREN SEC, V1, P3, DOI 10.1109/TIFS.2005.863510
   [Anonymous], 1983, The Radon Transform and Some of Its Applications
   Bartlett Marian Stewart, 1999, P 6 JOINT S NEUR COM, P8
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Boulgouris NV, 2007, IEEE T IMAGE PROCESS, V16, P731, DOI 10.1109/TIP.2007.891157
   Buciu I, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P855
   Calder AJ, 2000, J EXP PSYCHOL HUMAN, V26, P527, DOI 10.1037/0096-1523.26.2.527
   Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5
   Chen F, 2008, IEICE T INF SYST, VE91D, P341, DOI 10.1093/ietisy/e91-d.2.341
   Chen L, 2009, LECT NOTES COMPUT SC, V5754, P92, DOI 10.1007/978-3-642-04070-2_11
   Chuang CF, 2006, PATTERN RECOGN, V39, P1795, DOI 10.1016/j.patcog.2006.03.017
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Dubuisson S, 2002, SIGNAL PROCESS-IMAGE, V17, P657, DOI 10.1016/S0923-5965(02)00076-0
   Ekman P, 1978, FACIAL ACTION CODING
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913
   Karklin Y, 2003, NETWORK-COMP NEURAL, V14, P483, DOI 10.1088/0954-898X/14/3/306
   Kim DS, 2006, IEEE T CONSUM ELECTR, V52, P726, DOI 10.1109/TCE.2006.1706463
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Meulders M, 2005, J ROY STAT SOC C-APP, V54, P781, DOI 10.1111/j.1467-9876.2005.00515.x
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Otsuka T, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P546, DOI 10.1109/ICIP.1997.638829
   Padgett C, 1997, ADV NEUR IN, V9, P894
   Pengfei Yu, 2010, 2010 International Conference on Information, Networking and Automation (ICINA 2010), P148, DOI 10.1109/ICINA.2010.5636417
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rahman MT, 2008, IEEE T CONSUM ELECTR, V54, P1506, DOI 10.1109/TCE.2008.4711194
   Shen L, 2007, IMAGE VISION COMPUT, V25, P553, DOI 10.1016/j.imavis.2006.05.002
   Singh M., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1091
   Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhu Y, 2002, PATTERN RECOGN LETT, V23, P83, DOI 10.1016/S0167-8655(01)00108-8
NR 35
TC 15
Z9 15
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3675
EP 3690
DI 10.1007/s11042-013-1793-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800004
DA 2024-07-18
ER

PT J
AU Hu, T
   Zheng, MH
   Li, J
   Zhu, L
   Hu, J
AF Hu, Tao
   Zheng, Minghui
   Li, Jun
   Zhu, Li
   Hu, Jia
TI A scene-adaptive motion detection model based on machine learning and
   data clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion detection; Clustering; Machine learning; Scene-adaptive
ID TRACKING
AB Due to its wide applications and importance in computer vision, motion detection has been receiving considerable attention from industry and academy. However, previous motion detection algorithms fail to achieve the flexibility and accuracy simultaneously for good detection results. In the present work, a scene-adaptive motion detection model based on machine learning and clustering technology is proposed. This model begins with training to the system by a group of testing images, in terms of various accurate parameters of one certain scene. Significant modifications have been reserved in the same area during motion detection, which are considered as a change clustering. Then, the model takes advantage of clustering technology to generate a minimum spanning tree (MST), which is one kind of average linkage clustering. The average shortest distance of the minimum spanning tree serves as a benchmark to identify the change in images. Finally the training parameters and detection algorithm are combined to monitor the scene. The clustering is introduced to this model during sample training, in order to obtain factors of higher quality followed by more accurate detection results. Finally, the experiment confirms the excellent adaptability and precision of the proposed motion detection model.
C1 [Hu, Tao; Zheng, Minghui; Li, Jun; Zhu, Li] Hubei Univ Nationalities, Sch Informat Engn, Enshi, Hubei, Peoples R China.
   [Hu, Jia] Liverpool Hope Univ, Dept Math & Comp Sci, Liverpool L16 9JD, Merseyside, England.
C3 Hubei Minzu University; Liverpool Hope University
RP Zheng, MH (corresponding author), Hubei Univ Nationalities, Sch Informat Engn, Enshi, Hubei, Peoples R China.
EM mhzheng3@gmail.com
RI Hu, Jia/U-8626-2019
OI hu, tao/0009-0002-6661-2723
FU Education Commission of Hubei Province, China [Q20131904]; National
   Natural Science Foundation of China [61261016]; National Culture
   Promotion Project of China [201307]; Program of Ethnic and Religious
   Affairs Commission of Hubei Province, China [HBMW2012006]
FX This work was financially supported by the Program of Education
   Commission of Hubei Province, China (Grant No.Q20131904), the National
   Natural Science Foundation of China (Grant No. 61261016), the National
   Culture Promotion Project of China (Grant No.201307) and the Program of
   Ethnic and Religious Affairs Commission of Hubei Province, China (Grant
   No.HBMW2012006). Moreover, during the research, many valuable
   suggestions have been provided by Professor May Huang and Dr. Eric Chen,
   International Technological University, USA.
CR [Anonymous], 2004, INTRO MACHINE LEARNI
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chan P.K., 2003, MACHINE LEARNING APP
   Chaudhary A., 2011, Int J Comput Sci Eng Survey, V2, P122, DOI DOI 10.5121/IJCSES.2011.2109
   Chen DT, 2007, IEEE T PATTERN ANAL, V29, P2157, DOI 10.1109/TPAMI.2007.1134
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cutler R, 1998, INT C PATT RECOG, P495, DOI 10.1109/ICPR.1998.711189
   Dixon K. R., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P604
   Dong HW, 2012, PROCEDIA ENGINEER, V41, P749, DOI 10.1016/j.proeng.2012.07.239
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Fablet R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P939, DOI 10.1109/ICIP.1999.823036
   Fung G., 2001, Tech. Rep.
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Guanglong H, 2012, CAAI T INTELL SYST, V7, P61
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Hu T, 2010, P INT C COMP COMM TE, P83
   Jain R., 1995, MACHINE VISION
   OLSON CF, 1995, PARALLEL COMPUT, V21, P1313, DOI 10.1016/0167-8191(95)00017-I
   Piciarelli C, 2011, IEEE INTELL SYST, V26, P32, DOI 10.1109/MIS.2010.38
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Scott DW, 2015, WILEY SER PROBAB ST, P1
   Shafe AA, 2009, WORLD ACAD SCI ENG T, V32, P559
   Stenger B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P294, DOI 10.1109/ICCV.2001.937532
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Witten I., 2002, ACM Sigmod Rec., V31, P76, DOI [10.1145/507338.507355, DOI 10.1145/507338.507355]
   Zhong Zhou, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P57, DOI 10.1109/ISM.2010.18
NR 28
TC 3
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2821
EP 2839
DI 10.1007/s11042-013-1741-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300014
DA 2024-07-18
ER

PT J
AU Zhang, ZT
   Zheng, YP
   Xu, H
   Li, HJ
AF Zhang, Zutao
   Zheng, Yipeng
   Xu, Hong
   Li, Hengjian
TI A novel elevator group control algorithm based on binocular-cameras
   corridor passenger detection and tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elevator group control system; Binocular-cameras; Haar-like features;
   Unscented Kalman Filter (UKF)
ID SYSTEMS
AB The conventional elevator arrives at the floor in response to the user request and where is to dispatch an elevator car. There is one big problem that when system dispatches the elevator to the button responding floor, but corridor passenger is no there. In this paper, we present a novel elevator group control algorithm based on binocular-cameras corridor passenger detection and tracking, aiming to overcome the difficulty in the conventional elevator group control system. In the above proposed system, the corridor passengers are detected using Haar-like features based on binocular-cameras, and Unscented Kalman Filter (UKF) is introduced to improve robustness and accuracy of corridor passenger motion tracking. A new elevator group control strategy based on corridor passenger detection and tracking is proposed to improve the performance and transport efficiency of the elevator service. Compared with the traditional elevator group control system, the proposed system has potential advantages in minimizing passengers' waiting time and saving electronic energy. The final experimental results show the validity of our method under simulation and realistic condition.
C1 [Zhang, Zutao; Zheng, Yipeng] Southwest Jiaotong Univ, Sch Mech Engn, Chengdu 610031, Peoples R China.
   [Zhang, Zutao] Iowa State Univ, Automat & Robot Lab, Ames, IA 50011 USA.
   [Xu, Hong] Southwest Jiaotong Univ, Sch Informat Sci & Tech, Chengdu 610031, Peoples R China.
   [Li, Hengjian] Shandong Comp Sci Ctr, Shandong Prov Key Lab Comp Network, Jinan 250014, Peoples R China.
C3 Southwest Jiaotong University; Iowa State University; Southwest Jiaotong
   University; Qilu University of Technology
RP Zhang, ZT (corresponding author), Southwest Jiaotong Univ, Sch Mech Engn, Chengdu 610031, Peoples R China.
EM zzt@swjtu.edu.cn
RI Zhang, yuxuan/JXM-9935-2024
OI Hong, Xu/0000-0002-1273-7937
FU National Natural Science Foundation of China [51175443]; Science and
   Technology Projects of Chengdu [11DXYB085JH-27]; Science and Technology
   Projects of Sichuan [2013GZX0150, 13ZC1072, 2013GZX0154]
FX The work is supported by the National Natural Science Foundation of
   China (Grant No. 51175443), by the Science and Technology Projects of
   Chengdu under Grant No. 11DXYB085JH-27 and by the Science and Technology
   Projects of Sichuan under 2013GZX0150, 13ZC1072 and 2013GZX0154.
CR Barney G.C., 2003, Elevator traffic handbook: Theory and practice
   Curio C, 2000, IEEE T INTELL TRANSP, V1, P155, DOI 10.1109/6979.892152
   Fujino A, 1997, IEEE T IND ELECTRON, V44, P546, DOI 10.1109/41.605632
   Gavrila DM, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P13
   Guoqing Xu, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P384, DOI 10.1109/ICINFA.2011.5949022
   JULIER SJ, 1995, PROCEEDINGS OF THE 1995 AMERICAN CONTROL CONFERENCE, VOLS 1-6, P1628
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141
   Julier SJ, 1996, IEEE T AUTOMAT CONTR, V45, P477, DOI DOI 10.1109/9.847726
   Jung HK, 2001, IEEE T IND ELECTRON, V48, P377
   KIM CB, 1995, IEEE T SYST MAN CYB, V25, P985, DOI 10.1109/21.384263
   Kim CB, 1998, IEEE T SYST MAN CY A, V28, P277, DOI 10.1109/3468.668960
   Li J, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL III, P811, DOI 10.1109/ICMTMA.2009.95
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liting Cao, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.246
   Liu H, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1202, DOI 10.1109/ICMLC.2008.4620586
   Muñoz DM, 2008, ENG APPL ARTIF INTEL, V21, P1309, DOI 10.1016/j.engappai.2008.04.014
   Overett G, 2008, IEEE INT VEH SYM, P1038
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Pepyne DL, 1997, IEEE T CONTR SYST T, V5, P629, DOI 10.1109/87.641406
   Rashid M. M., 2011, Proceedings 2011 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2011), P63, DOI 10.1109/ISIEA.2011.6108794
   Rashid MM, 2011, P INT C MECH ICMA, P2386
   Senevirathna TKW, 2007, P C ANN SESS SRILANK, P55
   SIIKONEN M, 1997, A67 HELS U TECHN
   Siikonen ML., 1991, Proceedings of the fourth world congress of the international fuzzy systems association, V1, P195
   Uysal A, 2009, APPLIED ELECTRONICS, P253
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhang YN, 2010, P INT S INF SCI ENG, P512
   Zhu DW, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT PROCESSING SYSTEMS, VOLS 1 & 2, P528, DOI 10.1109/ICIPS.1997.672839
NR 28
TC 0
Z9 0
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1761
EP 1775
DI 10.1007/s11042-013-1716-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500003
DA 2024-07-18
ER

PT J
AU Li, Z
   Wang, WQ
   Liu, XQ
   Lu, K
AF Li, Zhong
   Wang, Weiqiang
   Liu, Xiaoqian
   Lu, Ke
TI An efficient multi-threshold AdaBoost approach to detecting faces in
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Cascade AdaBoost; Multi-threshold weak classifier
ID DETECTION ALGORITHM
AB During the past decade, the cascade AdaBoost approach based on Haar features has been one of the-state-of-art techniques for face detection, due to its good combination of accuracy and efficiency. Nevertheless recent study shows that more than 90 % of Haar features are non-discriminative under the single-threshold weak classifiers. In this paper, we present a new cascade AdaBoost face detection approach based on multi-threshold weak classifiers, called multi-threshold AdaBoost (MTAdaBoost). Compared with the existing multi-threshold approaches, the proposed approach is capable of intelligently choosing multiple thresholds, by computing the solutions of two optimal problems. Furthermore, its computational complexity is O(N), i.e. linear with respect to the number of examples, which is of the same scale as that of the single-threshold weak classifiers. This is made possible by exploiting the Kadane algorithm. The experimental results show that the usage of the proposed multi-threshold weak classifier leads to an effective face detector with much less features and at the same time maintaining the same or even better performance, when comparing to the conventional single-threshold weak classifier. In particular, less features give rise to simpler structure, which amounts to significant reduction of training time as well as faster detection speed. As a result, empirically our method processes an image with only half of the time consumed by the single-threshold weak classifiers.
C1 [Li, Zhong; Wang, Weiqiang; Liu, Xiaoqian; Lu, Ke] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Weiqiang] Inst Comp Technol, CAS, Key Lab Intell Info Proc, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Wang, WQ (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM zli@jdl.ac.cn; wqwang@ict.ac.cn; xqliu@jdl.ac.cn; luk@ucas.ac.cn
FU National Natural Science Foundation of China [61232013, 61271434,
   61175115]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61232013, No. 61271434, No. 61175115. The authors
   appreciate the valuable suggestions of the reviewers.
CR Amjad A, 2012, IET IMAGE PROCESS, V6, P1093, DOI 10.1049/iet-ipr.2012.0167
   [Anonymous], 2007, Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'07)
   Bentley J., 1984, Communications of the ACM, V27, P865, DOI 10.1145/358234.381162
   Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1
   Castrillón M, 2011, MACH VISION APPL, V22, P481, DOI 10.1007/s00138-010-0250-7
   Cevikalp H., 2013, Proceedings of the 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, P1
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Huang C, 2005, IEEE I CONF COMP VIS, P446
   Huang C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P401
   Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317
   Kawulok M, 2012, IET IMAGE PROCESS, V6, P95, DOI 10.1049/iet-ipr.2010.0495
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Liu C, 2003, PROC CVPR IEEE, P587
   Overett G, 2007, IEEE INT CONF ROBOT, P3799, DOI 10.1109/ROBOT.2007.364061
   Rasolzadeh B, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P348
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   SCHAPIRE RE, 1999, P 16 INT JOINT C ART
   Tsao WK, 2010, PATTERN RECOGN, V43, P1039, DOI 10.1016/j.patcog.2009.09.005
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2002, ADV NEUR IN, V14, P1311
   Wan C, 2011, LECT NOTES COMPUT SC, V6676, P356, DOI 10.1007/978-3-642-21090-7_42
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
   Wu JX, 2008, IEEE T PATTERN ANAL, V30, P369, DOI 10.1109/TPAMI.2007.1181
   Xiao R., 2007, IEEE 11 INT C COMPUT, P1
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 29
TC 5
Z9 6
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 885
EP 901
DI 10.1007/s11042-013-1703-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400011
DA 2024-07-18
ER

PT J
AU Penet, C
   Demarty, CH
   Gravier, G
   Gros, P
AF Penet, Cedric
   Demarty, Claire-Helene
   Gravier, Guillaume
   Gros, Patrick
TI Variability modelling for audio events detection in movies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bayesian network; Audio words; Movies; Factor Analysis; Audio events
   detection
ID TEMPORAL INTEGRATION; CLASSIFICATION
AB Detecting audio events in Hollywood movies is a complex task due to the presence of variability between the soundtracks of the movies. This inter-movies variability is shown to impair the audio events detection results in a realistic framework. In this article, we propose to model the variability using a factor analysis technique, which we then use to compensate the audio features. The factor analysis compensation is validated using the state-of-the-art system based on multiple audio words sequences and contextual Bayesian networks which we previously developed in Penet et al. (2013). Results obtained on the same publicly available dataset for the detection of gunshots and explosions show an improvement in the handling of the variability, while keeping the robustness capabilities of the previous system. Furthermore, the system is applied to the detection of screams and proves its ability to generalise to other types of events. The obtained results also emphasise the fact that, in addition to modelling variability, adding concepts in the system may also be beneficial for the precision rates.
C1 [Penet, Cedric; Demarty, Claire-Helene] ZAC Champs Blancs, F-35576 Cesson, Sevign, France.
   [Gravier, Guillaume] IRISA Campus Beaulieu, CNRS, F-35042 Rennes, France.
   [Gros, Patrick] INRIA Campus Beaulieu, F-35042 Rennes, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS)
RP Penet, C (corresponding author), ZAC Champs Blancs, 975 Ave Champs Blancs, F-35576 Cesson, Sevign, France.
EM penetcedric@gmail.com; claire-helene.demarty@technicolor.com;
   guig@irisa.fr; patrick.gros@inria.fr
FU OSEO, French State agency for innovation
FX This work was partly achieved as part of the Quaero Program, funded by
   OSEO, French State agency for innovation. We would like to acknowledge
   the MediaEval Multimedia Benchmark http://www.multimediaeval.org/ and in
   particular the Affect Task 2011/2012 for providing the data used in this
   research.
CR ANDREOBRECHT R, 1988, IEEE T ACOUST SPEECH, V36, P29, DOI 10.1109/29.1486
   [Anonymous], P 2007 INT
   [Anonymous], P 2006 IEEE OD SPEAK
   [Anonymous], 2006, 2006 IEEE INT C AC S
   [Anonymous], 2012, MEDIAEVAL
   [Anonymous], EUSIPCO
   [Anonymous], INTERSPEECH
   [Anonymous], INTERSPEECH
   [Anonymous], ADV BAYESIAN NETWORK
   [Anonymous], 2013, P 3 ACM C INT C MULT, DOI DOI 10.1145/2461466.2461502
   [Anonymous], INTERSPEECH
   [Anonymous], IEEE P OD SPEAK LANG
   Bello JP, 2004, IEEE SIGNAL PROC LET, V11, P553, DOI 10.1109/LSP.2004.827951
   Burred JJ, 2012, INT CONF ACOUST SPEE, P361, DOI 10.1109/ICASSP.2012.6287891
   Chin ML, 2012, INT CONF ACOUST SPEE, P1953, DOI 10.1109/ICASSP.2012.6288288
   Giannakopoulos T, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P90, DOI 10.1109/MMSP.2007.4412825
   Gravier G, 2012, MULTIMEDIA SOOLS APP, P1
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Joder C, 2009, IEEE T AUDIO SPEECH, V17, P174, DOI 10.1109/TASL.2008.2007613
   Kenny P., 2006, JOINT FACTOR ANAL SP
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Matrouf D, 2011, COMPUT SPEECH LANG, V25, P481, DOI 10.1016/j.csl.2010.11.001
   McKinney M.F., 2003, Proc. ISMIR, V3, P151
   Ono N., 2008, ISMIR, P139
   Penet C, 2013, INT WORK CONTENT MUL, P17, DOI 10.1109/CBMI.2013.6576546
   Penet C, 2012, INT CONF ACOUST SPEE, P2393, DOI 10.1109/ICASSP.2012.6288397
   Ramona Mathieu, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P20
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Trancoso I, 2009, IEEE INT CON MULTI, P630, DOI 10.1109/ICME.2009.5202575
   Vogt R, 2008, COMPUT SPEECH LANG, V22, P17, DOI 10.1016/j.csl.2007.05.003
NR 30
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1143
EP 1173
DI 10.1007/s11042-014-2038-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300002
DA 2024-07-18
ER

PT J
AU Jun, S
   Rho, S
   Hwang, E
AF Jun, Sanghoon
   Rho, Seungmin
   Hwang, Eenjun
TI Music structure analysis using self-similarity matrix and two-stage
   categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music structure; Music segmentation; Signal processing; Self-similarity
   matrix
AB Music tends to have a distinct structure consisting of repetition and variation of components such as verse and chorus. Understanding such a music structure and its pattern has become increasingly important for music information retrieval (MIR). Thus far, many different methods for music segmentation and structure analysis have been proposed; however, each method has its advantages and disadvantages. By considering the significant variations in timbre, articulation and tempo of music, this is still a challenging task. In this paper, we propose a novel method for music segmentation and its structure analysis. For this, we first extract the timbre feature from the acoustic music signal and construct a self-similarity matrix that shows the similarities among the features within the music clip. Further, we determine the candidate boundaries for music segmentation by tracking the standard deviation in the matrix. Furthermore, we perform two-stage categorization: (i) categorization of the segments in a music clip on the basis of the timbre feature and (ii) categorization of segments in the same category on the basis of the successive chromagram features. In this way, each music clip is represented by a sequence of states where each state represents a certain category defined by two-stage categorization. We show the performance of our proposed method through experiments.
C1 [Jun, Sanghoon; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul 136713, South Korea.
   [Rho, Seungmin] Mevlana Univ, Dept Comp Engn, Konya, Turkey.
C3 Korea University; Mevlana University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul 136713, South Korea.
EM ysbhjun@korea.ac.kr; korea.smrho@gmail.com; ehwang04@korea.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU National Research Foundation of Korea(NRF) - Ministry of Education
   [NRF-2013R1A1A2012627]; MSIP(Ministry of Science, ICT&Future Planning),
   Korea, under the C-ITRC(Convergence Information Technology Research
   Center) [NIPA-2013-H0301-13-3006]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (NRF-2013R1A1A2012627) and the MSIP(Ministry of Science,
   ICT&Future Planning), Korea, under the C-ITRC(Convergence Information
   Technology Research Center) support program (NIPA-2013-H0301-13-3006)
   supervised by the NIPA(National IT Industry Promotion Agency).
CR Cooper M, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P127, DOI 10.1109/ASPAA.2003.1285836
   Cooper M., 2002, P 3 INT S MUSIC INFO, P81
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   Foote J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P77, DOI 10.1145/319463.319472
   Fujishima T., 1999, P INT COMP MUS C, P464
   Jun S, 2010, INT J SEMANT WEB INF, V6, P1, DOI 10.4018/jswis.2010040101
   Jun Sanghoon., 2013, Proceedings of the 7th international conference on ubiquitous information management and communication, V82, P1
   Kaiser F., 2010, ISMIR, P429
   Klapuri A, 1999, INT CONF ACOUST SPEE, P3089, DOI 10.1109/ICASSP.1999.757494
   LOGAN B, 2000, P INT C MUS INF RETR
   Lu L., 2004, PROC ACM MULTIMEDIA, P275
   MADDAGE NC, 2004, P 12 ANN ACM INT C M, P112, DOI DOI 10.1145/1027527.1027549
   Paulus J, 2009, IEEE T AUDIO SPEECH, V17, P1159, DOI 10.1109/TASL.2009.2020533
   Peeters G, 2004, LECT NOTES COMPUT SC, V2771, P143
   Peeters Geoffroy., 2007, Proceedings of the International Symposium on Music Information Retrieval, P35
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Serra J., 2012, Proc. of the 26th AAAI Conference on Artificial Intelligence, P1613
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang MY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2019, DOI 10.1109/ICME.2004.1394660
NR 19
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 287
EP 302
DI 10.1007/s11042-013-1761-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300019
DA 2024-07-18
ER

PT J
AU Kang, D
   Kong, P
   Yoon, K
   Seo, S
AF Kang, Dongwann
   Kong, Phutphalla
   Yoon, KyungHyun
   Seo, SangHyun
TI Directional texture transfer for video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture transfer; Temporal coherence; Example-based rendering; Video
   processing
ID IMAGE
AB Texture transfer is a method that copies the texture of a reference image to a target image. This technique has an advantage in that various styles can be expressed according to the reference image, in a single framework. However, in this technique, it is not easy to control the effect of each style. In addition, when this technique is extended to processing video images, maintaining temporal coherence is very difficult. In this paper, we propose an algorithm that transfers the texture of a reference image to a target video while retaining the directionality of the target video. The algorithm maintains the temporal coherency of the transferred texture, and controls the style of the texture transfer.
C1 [Kang, Dongwann; Kong, Phutphalla] Chung Ang Univ, Seoul, South Korea.
   [Yoon, KyungHyun] Chung Ang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Seo, SangHyun] ETRI, Taejon, South Korea.
C3 Chung Ang University; Chung Ang University; Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Seo, S (corresponding author), ETRI, Taejon, South Korea.
EM dongwann@cglab.cau.ac.kr; kong@cglab.cau.ac.kr; khyoon@cau.ac.kr;
   shseo@etri.re.kr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Business for Cooperative R & D between Industry, Academy, and Research
   Institute [C0004960]
FX This work (Grants No. C0004960) was supported by Business for
   Cooperative R & D between Industry, Academy, and Research Institute
   funded Korea Small and Medium Business Administration in 2013.
CR Ashikhmin M, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1210863
   Bousseau A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276507
   De Benet J. S., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P361, DOI 10.1145/258734.258882
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Eisenacher C., 2008, P EUR C
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Haeberli P., 1990, P SIGGRAPH, P207
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A., 2000, NPAR, P7
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Lee H, 2009, COMPUT GRAPH FORUM, V28, P1207, DOI 10.1111/j.1467-8659.2009.01498.x
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6
   Wang B, 2004, IEEE T VIS COMPUT GR, V10, P266, DOI 10.1109/TVCG.2004.1272726
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Ye N, 2010, IEEE IMAGE PROC, P3993, DOI 10.1109/ICIP.2010.5650592
NR 25
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 245
EP 258
DI 10.1007/s11042-013-1759-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300016
DA 2024-07-18
ER

PT J
AU Liu, Y
   Li, ZC
   Liu, J
   Lu, HQ
AF Liu, Yang
   Li, Zechao
   Liu, Jing
   Lu, Hanqing
TI Boosted MIML method for weakly-supervised image semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MIML; Weakly-supervised; Semantic segmentation; Objectness
AB Weakly-supervised image semantic segmentation aims to segment images into semantically consistent regions with only image-level labels are available, and is of great significance for fine-grained image analysis, retrieval and other possible applications. In this paper, we propose a Boosted Multi-Instance Multi-Label (BMIML) learning method to address this problem, the approach is built upon the following principles. We formulate the image semantic segmentation task as a MIML problem under the boosting framework, where the goal is to simultaneously split the superpixels obtained from over-segmented images into groups and train one classifier for each group. In the method, a loss function which uses the image-level labels as weakly-supervised constraints, is employed to suitable semantic labels to these classifiers. At the same time a contextual loss term is also combined to reduce the ambiguities existing in the training data. In each boosting round, we introduce an "objectness" measure to jointly reweigh the instances, in order to overcome the disturbance from highly frequent background superpixels. We demonstrate that BMIML outperforms the state-of-the-arts for weakly-supervised semantic segmentation on two widely used datasets, i.e., MSRC and LabelMe.
C1 [Liu, Yang; Liu, Jing; Lu, Hanqing] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing, Peoples R China.
   [Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci, Nanjing, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Nanjing
   University of Science & Technology
RP Li, ZC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci, Nanjing, Jiangsu, Peoples R China.
EM liuyang6@nlpr.ia.ac.cn; zechao.li@gmail.com; jliu@nlpr.ia.ac.cn;
   luhq@nlpr.ia.ac.cn
FU 973 Program [2010CB327905]; National Natural Science Foundation of China
   [61272329, 61070104, 61202325]; Open Projects Program of National
   Laboratory of Pattern Recognition
FX This work was supported by 973 Program (2010CB327905), National Natural
   Science Foundation of China (61272329, 61070104, 61202325) and Open
   Projects Program of National Laboratory of Pattern Recognition.
CR Achanta R., 2012, IEEE TPAMI, V22, P888
   [Anonymous], 2007, ICCV
   [Anonymous], 2009, ICCV
   [Anonymous], 2012, CVPR
   [Anonymous], 2012, CVPR
   [Anonymous], 2010, ECCV
   [Anonymous], 2010, CVPR
   [Anonymous], 2012, CVPR
   [Anonymous], ICCV
   [Anonymous], 2011, CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], 2005, NIPS
   [Anonymous], ACM MM
   Babenko B, 2008, ECCV WORKSH
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Han Y., 2012, CVPR
   jia Li L, 2009, CVPR
   LIU X, 2010, CVPR
   Liu X., 2009, ACM MM
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mason L., 1999, NIPS
   Russell C., 2009, ICCV
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Zha Z., 2008, CVPR
   Zhang ML, 2008, ICDM
   Zhou z, 2006, MULTIINSTANCE MULTIL
NR 26
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 543
EP 559
DI 10.1007/s11042-014-1967-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300013
DA 2024-07-18
ER

PT J
AU Hsiao, CC
   Lo, MJ
   Chu, SL
AF Hsiao, Chih-Chieh
   Lo, Min-Jen
   Chu, Slo-Li
TI Demand look-ahead memory access scheduling for 3D graphics processing
   units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Demand look-ahead; GPU; Graphics rendering; Memory access scheduling
AB With the rapid growing complexity of 3D applications, the memory subsystem has become the most bandwidth-exhausting bottleneck in a Graphics Processing Unit (GPU). To produce realistic images, tens to hundreds of thousands of primitives are used. Furthermore, each primitive generates thousands of pixels, and these pixels are computed by shaders with special effects, even to blend multiple texture pixels from external memory to obtain a final color. To hide the long latency texture operations, the shaders are usually highly multithreaded to increase its throughput. However, conventional memory scheduling mechanisms are unaware of the producer consumer relationship between primitives and pixels. The conventional scheduling mechanisms neither assume that all initiators are independent nor that they use a fixed priority scheme. This paper proposes Demand Look-Ahead (DLA) memory access scheduling based on the statuses of each unit in the GPU, and dynamically generates priority for the memory request scheduler. By considering the producer-consumer relationship, the proposed mechanism reschedules most urgent requests to be serviced first. Experimental results show that the proposed DLA improves 1.47 % and 1.44% in FPS and IPC, respectively, than First-Ready First-Come-First-Serve (FR-FCFS). By integrating DLA with Bank-level Parallelism Awareness (BPA), DLA-BPA improves FPS and IPC by 7.28 % and 6.55 %, respectively. Furthermore, shader thread performance is improved by 22.06 % and increases the attainable bandwidth by 5.91 % with DLA-BPA.
C1 [Hsiao, Chih-Chieh; Lo, Min-Jen; Chu, Slo-Li] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Chungli 32023, Taiwan.
C3 Chung Yuan Christian University
RP Hsiao, CC (corresponding author), Chung Yuan Christian Univ, Dept Informat & Comp Engn, 200 Chung Pei Rd, Chungli 32023, Taiwan.
EM g9802603@cycu.edu.tw; g9477031@cycu.edu.tw; slchu@cycu.edu.tw
FU National Science Council of Republic of China, Taiwan [NSC
   101-2221-E-033-049]
FX This work is supported in part by the National Science Council of
   Republic of China, Taiwan under Grant NSC 101-2221-E-033-049.
CR Ausavarungnirun R, 2012, CONF PROC INT SYMP C, P416, DOI 10.1109/ISCA.2012.6237036
   Ebrahimi E, 2011, INT SYMP MICROARCH, P362
   Hong SI, 1999, FIFTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE, PROCEEDINGS, P80, DOI 10.1109/HPCA.1999.744337
   Hongzhong Zheng, 2008, 2008 37th International Conference on Parallel Processing (ICPP), P406, DOI 10.1109/ICPP.2008.53
   Hynix, 2006, 512M 16MX32 GDDR3 SD
   Jaekyu Lee, 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P213, DOI 10.1109/MICRO.2010.44
   Jeong MK, 2012, DES AUT CON, P850
   Joao JA, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P223
   Juffa N, 2011, US Patent, Patent No. [7,925,860 B1, 7925860]
   Kim Y. H., 2010, 2010 IEEE 37th International Conference on Plasma Sciences (ICOPS 2010), DOI 10.1109/PLASMA.2010.5534009
   Mantor M, 2007, HOT CHIPS 19, V19
   Mizuyabu C, 2003, US Patent, Patent No. [6,297,832 B1, 6297832]
   Del Barrio VM, 2006, INT SYM PERFORM ANAL, P231
   Mutlu O, 2008, CONF PROC INT SYMP C, P63, DOI 10.1109/ISCA.2008.7
   Mutlu O, 2007, INT SYMP MICROARCH, P146
   Nesbit KJ, 2006, INT SYMP MICROARCH, P208
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Rafique  N., 2007, P 16 INT C PAR ARCH, P245
   Rixner S, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P128, DOI [10.1145/342001.339668, 10.1109/ISCA.2000.854384]
   Shao J, 2007, INT S HIGH PERF COMP, P285
   Therdsteerasukdi K, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086730
   Van Hook T, 2001, US Patent, Patent No. [6,564,304 B1, 6564304]
   Wu CC, 1998, 1998 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, PROCEEDINGS, P504, DOI 10.1109/ICPADS.1998.741124
   Yoongu Kim, 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P65, DOI 10.1109/MICRO.2010.51
   Yuan George L., 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P34, DOI 10.1145/1669112.1669119
   Zuravleff W. K., 1997, U.S. Patent, Patent No. 5,630,096
NR 26
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1391
EP 1416
DI 10.1007/s11042-013-1639-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200014
DA 2024-07-18
ER

PT J
AU Martín, R
   Martínez, JM
AF Martin, Rafael
   Martinez, Jose M.
TI A semi-supervised system for players detection and tracking in
   multi-camera soccer videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports videos; Multi-camera systems; Object detection; Object tracking;
   Fusion; Homography
AB This paper presents a complete, general and modular system which after a simple previous configuration is able to detect and track each player on the court or field. The presented multi-camera system is based on a mono-camera object detection and tracking system originally designed for video surveillance applications. Target sports of the developed system are team sports (e. g., basketball, soccer). The main objective of this paper is to present a semi-supervised system able to detect and track the players in multi-camera sports videos, focusing on the fusion of different tracks of detected blobs in order to match tracks across cameras. The proposed system is simpler than other systems from the state of the art, can operate in real time and has margin to be improved and to reduce supervision adding additional complexity. In addition to the detection and tracking system, an evaluation system has been designed to obtain quantitative results of the system performance.
C1 [Martin, Rafael; Martinez, Jose M.] EPS Univ Autonoma Madrid, VPULab, Madrid, Spain.
RP Martín, R (corresponding author), EPS Univ Autonoma Madrid, VPULab, Madrid, Spain.
EM rafael.martinn@estudiante.uam.es; josem.martinez@uam.es
RI Martinez, Jose M./A-1185-2008
FU Spanish Government [TEC2011-25995]
FX This work has been partially supported by the Spanish Government
   (TEC2011-25995).
CR Anjum N, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P201, DOI 10.1109/AVSS.2009.65
   Bebie T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P898, DOI 10.1109/ICIP.1998.723665
   D'Orazio T, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P559, DOI 10.1109/AVSS.2009.69
   de Meneses YL, 2005, ELECT LETT COMPUTER, V5, P148
   Du W, 2006, WORKSH COMP VIS BAS, P2
   Figueroa P, 2004, INT C PATT RECOG, P787, DOI 10.1109/ICPR.2004.1333890
   Figueroa PJ, 2006, COMPUT VIS IMAGE UND, V101, P122, DOI 10.1016/j.cviu.2005.07.006
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Huang Y, 2007, LECT NOTES COMPUT SC, V4577, P416
   Junejo Imran N., 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Kang J, 2004, P ACCV
   Kayumbi G., 2008, INT C DISTRIBUTED SM, P1
   Kayumbi G, 2008, P CIVR
   Martin R, 2013, P AMMDS AVS IN PRESS
   Misu T, 2004, P INT C CENTR EUR CO, P285
   Nummiaro K, 2003, LECT NOTES COMPUT SC, V2781, P591
   Poppe C., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P26, DOI 10.1109/AVSS.2010.64
   Sachiko I, 2004, P ICPR
   SanMiguel JC, 2012, COMPUT VIS IMAGE UND, V116, P937, DOI 10.1016/j.cviu.2012.04.005
   Sheikh YA, 2008, IEEE T PATTERN ANAL, V30, P361, DOI 10.1109/TPAMI.2007.70750
   Taj M, 2009, P ICDSC
   Tong XF, 2004, INT C PATT RECOG, P795, DOI 10.1109/ICPR.2004.1333892
   Xinguo Y, 2005, P ICME
   Xu M, 2004, IEEE IMAGE PROC, P2909
   Yongduek Seo, 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P196
NR 25
TC 17
Z9 20
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1617
EP 1642
DI 10.1007/s11042-013-1659-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200023
DA 2024-07-18
ER

PT J
AU Tsai, MJ
   Yin, JS
   Yuadi, I
   Liu, J
AF Tsai, Min-Jen
   Yin, Jin-Shen
   Yuadi, Imam
   Liu, Jung
TI Digital forensics of printed source identification for Chinese
   characters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Graylevel co-occurrence Matrix (GLCM); Discrete
   Wavelet Transform (DWT); Feature Selection
ID FEATURE-SELECTION; SECURITY; FEATURES
AB Recently, digital forensics, which involves the collection and analysis of the origin digital device, has become an important issue. Digital content can play a crucial role in identifying the source device, such as serve as evidence in court. To achieve this goal, we use different texture feature extraction methods such as graylevel co-occurrence matrix (GLCM) and discrete wavelet transform (DWT), to analyze the Chinese printed source in order to find the impact of different output devices. Furthermore, we also explore the optimum feature subset by using feature selection techniques and use support vector machine (SVM) to identify the source model of the documents. The average experimental results attain a 98.64 % identification rate which is significantly superior to the existing known method of GLCM by 1.27 %. The superior testing performance demonstrates that the proposed identification method is very useful for source laser printer identification.
C1 [Tsai, Min-Jen; Yin, Jin-Shen; Yuadi, Imam] Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
RI Yuadi/V-3570-2018
OI Liu, Jung/0009-0009-7109-823X
FU National Science Council in Taiwan, Republic of China
   [NSC99-2410-H-009-053-MY2, NSC101-2410-H-009-006-MY2]
FX This work was supported by the National Science Council in Taiwan,
   Republic of China, under Grant NSC99-2410-H-009-053-MY2 and
   NSC101-2410-H-009-006-MY2.
CR Bulan O, 2009, INT CONF ACOUST SPEE, P1401, DOI 10.1109/ICASSP.2009.4959855
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan CS, 2012, J INF HIDING MULTIME, V3, P340
   Chiclana F, 1998, FUZZY SET SYST, V97, P33, DOI 10.1016/S0165-0114(96)00339-9
   Choi JH, 2009, IEEE IMAGE PROC, P1505, DOI 10.1109/ICIP.2009.5414614
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Khanna N, 2006, DIGIT INVEST, pS17, DOI 10.1016/j.diin.2006.06.014
   Kundur D, 2004, P IEEE, V92, P879, DOI 10.1109/JPROC.2004.827336
   Mikkilineni AK, 2005, PROC SPIE, V5681, P430, DOI 10.1117/12.593796
   Mikkilineni AK, 2004, PROC SPIE, V5306, P455, DOI 10.1117/12.531944
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Ritchey PhilipC., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P212
   Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P71
   Talbot V, 2006, NIP 22: 22ND INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P427
   Tsai MJ, 2012, COMPUT STAND INTER, V34, P292, DOI 10.1016/j.csi.2011.10.006
   Tsai MJ, 2011, IEEE INT SYMP CIRC S, P2633
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   VILLASENOR JD, 1995, IEEE T IMAGE PROCESS, V4, P1053, DOI 10.1109/83.403412
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Zhu B, 2003, CCS 03 WASH
NR 26
TC 27
Z9 28
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2129
EP 2155
DI 10.1007/s11042-013-1642-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200046
DA 2024-07-18
ER

PT J
AU Jia, J
   Wu, ZY
   Zhang, S
   Meng, HM
   Cai, LH
AF Jia, Jia
   Wu, Zhiyong
   Zhang, Shen
   Meng, Helen M.
   Cai, Lianhong
TI Head and facial gestures synthesis using PAD model for an expressive
   talking avatar
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-visual-speech; Head motion; Facial expression; Talking avatar
ID SPEECH SYNTHESIS; ANIMATION; DRIVEN; MOVEMENT; EMOTION; PROSODY; MOTION
AB This paper proposes to synthesize expressive head and facial gestures on talking avatar using the three dimensional pleasure-displeasure, arousal-nonarousal and dominance-submissiveness (PAD) descriptors of semantic expressivity. The PAD model is adopted to bridge the gap between text semantics and visual motion features with three dimensions of pleasure-displeasure, arousal-nonarousal, and dominance-submissiveness. Based on the correlation analysis between PAD annotations and motion patterns derived from the head and facial motion database, we propose to build an explicit mapping from PAD descriptors to facial animation parameters with linear regression and neural networks for head motion and facial expression respectively. A PAD-driven talking avatar in text-to-visual-speech system is implemented by generating expressive head motions at the prosodic word level based on the (P, A) descriptors of lexical appraisal, and facial expressions at the sentence level according to the PAD descriptors of emotional information. A series of PAD reverse evaluation and comparative perceptual experiments shows that the head and facial gestures synthesized based on PAD model can significantly enhance the visual expressivity of talking avatar.
C1 [Jia, Jia; Zhang, Shen; Cai, Lianhong] Tsinghua Univ, Minist Educ China, Key Lab Pervas Comp, Beijing 100084, Peoples R China.
   [Jia, Jia; Zhang, Shen; Cai, Lianhong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Wu, Zhiyong; Meng, Helen M.] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
   [Wu, Zhiyong; Meng, Helen M.] Tsinghua Univ, Grad Sch Shenzhen, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518055, Peoples R China.
C3 Tsinghua University; Tsinghua University; Chinese University of Hong
   Kong; Tsinghua University; Tsinghua Shenzhen International Graduate
   School
RP Wu, ZY (corresponding author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
EM jjia@tsinghua.edu.cn; zywu@se.cuhk.edu.hk; hmmeng@se.cuhk.edu.hk;
   clh-dcs@tsinghua.edu.cn
RI jia, jia/JKJ-5720-2023; Meng, Helen M/F-6043-2011
OI Meng, Helen M/0000-0002-4427-3532
FU National Basic Research Program of China [2011CB302201]; 973 program
   [2012CB316401]; Hong Kong SAR Government's Research Grants Council
   [N-CUHK414/09, N-CUHK417/04]; National Natural Science Foundation of
   China [60805008]; Microsoft Research Asia-Tsinghua Univertity Joint
   Laboratory
FX This work is supported by the National Basic Research Program of China
   (2011CB302201). This work is also partially supported by 973 program
   (2012CB316401), the research funds from the Hong Kong SAR Government's
   Research Grants Council (N-CUHK414/09, N-CUHK417/04), the National
   Natural Science Foundation of China (60805008).; The basic idea of this
   paper appeared in our conference versions [43, 44]. In this version, we
   extend our approach to be combined with both head and facial gesture,
   carry out detailed analysis, and present more performance results. The
   authors would like to thank Professor Haizhou Ai for providing the face
   alignment toolkit [41], and the Microsoft Research Asia-Tsinghua
   Univertity Joint Laboratory for its funding.
CR Albrecht I., 2005, J VIRTUAL REALITY, V8, P201, DOI DOI 10.1007/S10055-005-0153-5
   [Anonymous], 2002, FACS INVESTIGATORS G
   [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Boukricha H, 2009, 3 INT C AFF COMP INT, P21
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Busso C, 2005, COMPUT ANIMAT VIRT W, V16, P283, DOI 10.1002/cav.80
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P2331, DOI 10.1109/TASL.2007.905145
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   Cosatto E, 2003, P IEEE, V91, P1406, DOI 10.1109/JPROC.2003.817141
   Deng Z., 2006, Proc. of ACM SIGGGRAPH/Eurographics Symposium on Computer Animation, P251
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ekman P, 1978, FACIAL ACTION CODING
   Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186
   Granström B, 2005, SPEECH COMMUN, V46, P473, DOI 10.1016/j.specom.2005.02.017
   Hofer G, 2007, INT 2007 ANTW BELG
   Hong Kong Tourism Board, 2006, DISC HONG KONG
   Hong PY, 2002, IEEE T NEURAL NETWOR, V13, P916, DOI 10.1109/TNN.2002.1021892
   Horprasert T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P242, DOI 10.1109/AFGR.1996.557271
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Lance B, 2007, LECT NOTES ARTIF INT, V4722, P72
   Li XM, 2005, LECT NOTES COMPUT SC, V3784, P513
   Lipori G, 2005, MANUAL ANNOTATIONS F
   Mana N., 2006, P 8 INT C MULTIMODAL, P380
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Mehrabian A., 1972, Nonverbal communication
   Motion Pictures Expert G, 1999, 144962 ISOIEC
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Sargin ME, 2008, IEEE T PATTERN ANAL, V30, P1330, DOI 10.1109/TPAMI.2007.70797
   Schröder M, 2006, IEEE T AUDIO SPEECH, V14, P1128, DOI 10.1109/TASL.2006.876118
   Stoiber N, 2010, COMPUT ANIMAT VIRT W, V21, P39, DOI 10.1002/cav.331
   Tang H, 2008, IEEE T MULTIMEDIA, V10, P969, DOI 10.1109/TMM.2008.2001355
   Wu ZY, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1802
   Wu ZY, 2009, IEEE T AUDIO SPEECH, V17, P1567, DOI 10.1109/TASL.2009.2023161
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Zhang L., 2005, Proc. IEEE Int'l Conf. Image Processing, P354
   Zhang S, 2007, LECT NOTES COMPUT SC, V4738, P24
   Zhang S, 2007, INT CONF ACOUST SPEE, P837
   Zhang YM, 2008, IEEE T CIRC SYST VID, V18, P1383, DOI 10.1109/TCSVT.2008.928887
   Zhou C, 2005, PATTERN RECOGN LETT, V26, P2611, DOI 10.1016/j.patrec.2005.06.007
NR 43
TC 20
Z9 24
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 439
EP 461
DI 10.1007/s11042-013-1604-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ryu, DS
   Cho, HG
AF Ryu, Dong-Sung
   Cho, Hwan-Gue
TI A summarized photo visualization system with maximal clique finding
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo management; Photo clustering; Photo visualization; Nearly
   identical photo
ID IMAGE; CLASSIFICATION
AB The affordability of digital cameras, storage, processors and the advances made in these areas are encouraging people to continuously take hundreds of photos. However, managing the large number of photographs involves arduous tasks such as selecting good quality photos and classifying and labeling each photo. Generally, users put their photos into certain user-designated folders on their local PCs without considering any classified information. One of the main problems related to this management method is that users do not systematically create their photo folders because they are careless and apathetic. This practice results in confusion when the users want to find their photos. One method to overcome this problem is to construct a central photo management system that can manage many photos on the user's local PC. This paper proposes an integrated photo management system coupled with a database on the web, which provides users with an automated photo clustering and visualization function that allows photo overlaps. The proposed system provides spatial clustering for Nearly Identical Photos, and it places photos with overlaps to improve space efficiency for the user. This system also provides users with a CUDA version of Depth of Field evaluation and blur estimation functions. In order to evaluate our system, we conducted two quantitative experiments relating to space efficiency and clustering correctness. First, we investigate the placed photo areas of ACDSee (grid layout) and our system to evaluate how much screen space is saved by nearly identical photos overlapping. Second, we also calculate the precision and recall of our system and Cooper's with regard to user-classified photo sets.
C1 [Ryu, Dong-Sung; Cho, Hwan-Gue] Pusan Natl Univ, Dept Comp Sci & Engn, Pusan, South Korea.
C3 Pusan National University
RP Cho, HG (corresponding author), Pusan Natl Univ, Dept Comp Sci & Engn, Pusan, South Korea.
EM bluesky4383@gmail.com; hgcho@pusan.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MEST)
   [2011-0015359]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (No. 2011-0015359).
CR [Anonymous], 2008, PROC CVPR IEEE
   Bartolini I, 2006, MULTIMED TOOLS APPL, V31, P269, DOI 10.1007/s11042-006-0044-0
   Chen JY, 1999, P INT C STOR RETR IM, P144
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Girgensohn A., 2009, Proceedings of the 14th International Conference on Intelligent User Interfaces, P419, DOI DOI 10.1145/1502650.1502711
   Gomi A., 2011, P 2011 ACM S APPL CO, P1245
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   GUPTA UI, 1982, NETWORKS, V12, P459, DOI 10.1002/net.3230120410
   Jang C, 2010, MULTIMED TOOLS APPL, V50, P441, DOI 10.1007/s11042-010-0485-3
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   PARDALOS PM, 1994, J GLOBAL OPTIM, V4, P301, DOI 10.1007/BF01098364
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Ryu D.-S., 2011, P ACM SAC, P1229
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Schaefer G, 2010, MULTIMED TOOLS APPL, V47, P105, DOI 10.1007/s11042-009-0409-2
NR 17
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 1011
EP 1027
DI 10.1007/s11042-012-1160-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700024
DA 2024-07-18
ER

PT J
AU Huang, YG
   Zhang, J
   Huang, HY
   Wang, DF
AF Huang, Yonggang
   Zhang, Jun
   Huang, Heyan
   Wang, Daifa
TI Medical image retrieval based on unclean image bags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Retrieval scheme; Image bag; Similarity aggregation
ID SUPPORT VECTOR MACHINE; RELEVANCE FEEDBACK; FRAMEWORK; FUSION; SYSTEM
AB Traditional content-based image retrieval (CBIR) scheme with assumption of independent individual images in large-scale collections suffers from poor retrieval performance. In medical applications, images usually exist in the form of image bags and each bag includes multiple relevant images of the same perceptual meaning. In this paper, based on these natural image bags, we explore a new scheme to improve the performance of medical image retrieval. It is feasible and efficient to search the bag-based medical image collection by providing a query bag. However, there is a critical problem of noisy images which may present in image bags and severely affect the retrieval performance. A new three-stage solution is proposed to perform the retrieval and handle the noisy images. In stage 1, in order to alleviate the influence of noisy images, we associate each image in the image bags with a relevance degree. In stage 2, a novel similarity aggregation method is proposed to incorporate image relevance and feature importance into the similarity computation process. In stage 3, we obtain the final image relevance in an adaptive way which can consider both image bag similarity and individual image similarity. The experiments demonstrate that the proposed approach can improve the image retrieval performance significantly.
C1 [Huang, Yonggang; Huang, Heyan] Beijing Inst Technol, Beijing Engn Res Ctr High Volume Language Informa, Beijing 100081, Peoples R China.
   [Huang, Yonggang; Huang, Heyan] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Zhang, Jun] Deakin Univ, Sch Informat Technol, Geelong, Vic 3217, Australia.
   [Wang, Daifa] Beihang Univ, Sch Biol Sci & Med Engn, Beijing 100191, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology; Deakin
   University; Beihang University
RP Huang, YG (corresponding author), Beijing Inst Technol, Beijing Engn Res Ctr High Volume Language Informa, Beijing 100081, Peoples R China.
EM yonggang.h@gmail.com; jun.zhang@deakin.edu.au; daifa.wang@buaa.edu.cn
RI Zhang, Jun/AAJ-6927-2020; huang, yonggang/O-6236-2019
OI Zhang, Jun/0000-0002-2189-7801; 
FU National Natural Science Foundation of China [61108084]; Research Fund
   for the Doctoral Program of Higher Education of China; Basic Research
   Foundation of Beijing Institute of Technology [20120742009]
FX The authors thank courtesy of TM Deserno, Dep. of Medical Informatics,
   RWTH Aachen, Germany, for providing IRMA dataset. This work is supported
   by the National Natural Science Foundation of China (Multilingual
   Translation and Integration Using Visual Information for Cross-Language
   Image Retrieval), the National Natural Science Foundation of China (No.
   61108084), the Research Fund for the Doctoral Program of Higher
   Education of China (Query and Annotation Translation Using Visual
   Information for Cross-Language Image Retrieval), and the Basic Research
   Foundation of Beijing Institute of Technology (No. 20120742009).
CR [Anonymous], 2012, LIBSVM LIB SUPPORT V
   Arevalillo-Herráez M, 2010, PATTERN RECOGN, V43, P619, DOI 10.1016/j.patcog.2009.08.010
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191
   [黄云美 Huang Yunmei], 2010, [扬州大学学报. 自然科学版, Journal of Yangzhou University], V13, P13
   Iakovidis DK, 2009, IEEE T INF TECHNOL B, V13, P442, DOI 10.1109/TITB.2008.923144
   Kong J, 2008, J NEUROSCI, V28, P13354, DOI 10.1523/JNEUROSCI.2944-08.2008
   Kushki A, 2004, IEEE T IMAGE PROCESS, V13, P277, DOI 10.1109/TIP.2003.821350
   Lehmann TM, 2012, IMAGE RETRIEVAL MED
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Machado CJ, 2008, NEUROIMAGE, V39, P832, DOI 10.1016/j.neuroimage.2007.09.029
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Mildenberger P, 2002, EUR RADIOL, V12, P920, DOI 10.1007/s003300101100
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Qin T, 2008, PATTERN RECOGN LETT, V29, P637, DOI 10.1016/j.patrec.2007.11.015
   Rahman MM, 2008, COMPUT MED IMAG GRAP, V32, P95, DOI 10.1016/j.compmedimag.2007.10.001
   Rahman MM, 2007, IEEE T INF TECHNOL B, V11, P58, DOI 10.1109/TITB.2006.884364
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Rahman MM, 2011, I S BIOMED IMAGING, P1905, DOI 10.1109/ISBI.2011.5872781
   [茹立云 Ru Liyun], 2005, [计算机研究与发展, Journal of Computer Research and Development], V42, P1640, DOI 10.1360/crad20050928
   Scott G, 2007, IEEE T INF TECHNOL B, V11, P320, DOI 10.1109/TITB.2006.880551
   Shao H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT SYSTEMS AND SIGNAL PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P731
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Zhang J, 2009, IEEE IMAGE PROC, P1865, DOI 10.1109/ICIP.2009.5413602
   Zhang J, 2009, IEEE T IMAGE PROCESS, V18, P2370, DOI 10.1109/TIP.2009.2026669
   Zhang J, 2009, SIGNAL PROCESS, V89, P2291, DOI 10.1016/j.sigpro.2009.04.034
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 34
TC 6
Z9 6
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2977
EP 2999
DI 10.1007/s11042-013-1589-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300038
DA 2024-07-18
ER

PT J
AU Nam, Y
AF Nam, Yunyoung
TI Crowd flux analysis and abnormal event detection in unstructured and
   structured scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormality; Moving objects; Spatio-temporal; Entropy; Crowded scene
ID REPRESENTATION; RECOGNITION
AB This paper presents a spatio-temporal grid-based framework to deal with the complexity of structured and unstructured motion flows that can effectively group optical flows in the field of view into crowds. This approach utilizes motion flows of the features based on a grid in a scene. In order to detect abnormal events in crowded scenes, the proposed method measures motion features including the speed and direction of moving objects based on a spatio-temporal grid-based approach for flow representation. Experiments have been conducted on several different videos in three domains that are crosswalks, escalators, and highways. To evaluate and compare the performance of our method to other methods, ROC curves are plotted which take into consideration both detection rate and false alarm rate for multiple threshold values.
C1 Worcester Polytech Inst, Dept Biomed Engn, Worcester, MA 01607 USA.
C3 Worcester Polytechnic Institute
RP Nam, Y (corresponding author), Worcester Polytech Inst, Dept Biomed Engn, Worcester, MA 01607 USA.
EM ynam@wpi.edu
RI Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394
CR Ali S, 2007, PROC CVPR IEEE, P65
   Andrade EL, 2006, INT C PATT RECOG, P460
   [Anonymous], 2012, PARENTING ADOLESCENT
   [Anonymous], TRECVID 2008 WORKSH
   [Anonymous], BMVC 08
   [Anonymous], TRECVID 08
   [Anonymous], 11 INT C COMP INF TE
   Cho SH, 2011, KSII T INTERNET INF, V5, P1166, DOI 10.3837/tiis.2011.06.005
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492
   Ihaddadene N, 2008, INT C PATT RECOG, P217
   Lin L, 2012, IEEE T IMAGE PROCESS, V21, P4844, DOI 10.1109/TIP.2012.2211373
   Lin L, 2009, PATTERN RECOGN LETT, V30, P180, DOI 10.1016/j.patrec.2008.02.023
   Liu XB, 2011, IEEE T CIRC SYST VID, V21, P393, DOI 10.1109/TCSVT.2010.2087570
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nam Y, 2013, MULTIMED TOOLS APPL, V67, P289, DOI 10.1007/s11042-012-0997-0
   Ozturk Ovgu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3533, DOI 10.1109/ICPR.2010.862
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Xiang T, 2005, IEEE I CONF COMP VIS, P1238
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Zhang D, 2005, PROC CVPR IEEE, P611
NR 21
TC 9
Z9 11
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 3001
EP 3029
DI 10.1007/s11042-013-1593-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300039
DA 2024-07-18
ER

PT J
AU Zhong, Y
   Liu, C
AF Zhong, Ying
   Liu, Chang
TI A domain-oriented end-user design environment for generating interactive
   3D virtual chemistry experiments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional virtual worlds; Educational virtual environments;
   Three-dimensional virtual chemistry experiments; Domain-oriented design;
   End-user design environment
ID SOPHISTICATED SIMULATION; CHEMLAB PROJECT; LABORATORIES; USABILITY
AB Three-dimensional virtual worlds are potentially feasible for building virtual educational environments. However, educators face technical challenges to apply these technologies because creating virtual educational environments based on virtual worlds demands 3D modeling and programming skills. This paper proposes a method to lower the technical barriers through domain-oriented interfaces with languages and environments that are familiar to educators. A domain-oriented end-user design environment, iVirtualWorld, is designed and developed to implement the proposed method in a specific educational domain, namely introductory chemistry experiments. This web-based environment provides end-users with domain-oriented building blocks, which can be assembled to create 3D virtual chemistry experiments. A usability evaluation and a comparative case study are designed to evaluate the system among chemistry educators, who are the target audience. The usability evaluation contains a task requiring participants to create a 3D virtual chemistry experiment and a voluntary semi-structured interview. The case study compares a virtual experiment generated using iVirtualWorld with an experiment in a commercial virtual chemistry laboratory system. The results show that 1) the domain-oriented end-user design environment enables participants to generate the 3D virtual chemistry experiment within 30 min; 2) participants gain confidence on creating 3D virtual experiments by themselves using iVirtualWorld; 3) participants confirm the usefulness of applying the system in introductory chemistry education; and 4) iVirtualWorld is considered more intuitive and straightforward for students to focus on finishing the experiment without being distracted than the commercial virtual chemistry laboratory system. Areas that can benefit from the system most and areas where the system is less effective are identified by participants. The responses also reveal the limitations of the current system and suggest directions for future improvement.
C1 [Zhong, Ying; Liu, Chang] Ohio Univ, Sch EECS, Athens, OH 45701 USA.
C3 University System of Ohio; Ohio University
RP Liu, C (corresponding author), Ohio Univ, Sch EECS, Athens, OH 45701 USA.
EM liuc@ohio.edu
FU Direct For Education and Human Resources; Division Of Graduate Education
   [0947813] Funding Source: National Science Foundation
CR Bell J.T., 2004, P SPEC INT GROUP COM
   Bell J.T., 2003, P AM SOC ENG ED ANN
   Chen X, 2010, VIRTUAL REMOTE LAB D, P368
   Chou C.C., 2010, Proceedings of the 2010 World Conference on Educational Multimedia, Hypermedia and Telecommunications, P2659
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dalgarno B, 2009, COMPUT EDUC, V53, P853, DOI 10.1016/j.compedu.2009.05.005
   Domingues L, 2010, EDUC CHEM ENG, V5, pE22, DOI 10.1016/j.ece.2010.02.001
   Dorn B, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P703
   Drozdz B., 2010, Loading 3d models at runtime in Unity3d
   Ertugrul N, 2000, INT J ENG EDUC, V16, P171
   Evans E., 2003, Domain-Driven Design
   Holloway R., 1991, Computer Graphics. Computer Animation, Virtual Reality, Visualisation, P181
   Hornbæk K, 2006, INT J HUM-COMPUT ST, V64, P79, DOI 10.1016/j.ijhcs.2005.06.002
   Indraprastha A, 2009, J ICT RES APPL, V3, P1
   Jensen N, 2004, ED-MEDIA 2004: World Conference on Educational Multimedia, Hypermedia & Telecommunications, Vols. 1-7, P2148
   Konstantinidis A, 2009, MULTIMED TOOLS APPL, V44, P279, DOI 10.1007/s11042-009-0289-5
   LAGOWSKI JJ, 1989, J CHEM EDUC, V66, P12, DOI 10.1021/ed066p12
   Lieberman H, 2006, HUM COM INT, V9, P1
   Liu C, 2013, INT J VIRTU IN PRESS
   Ma J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132960.1132961
   Martínez-Jiménez P, 2003, J CHEM EDUC, V80, P346
   Mikropoulos T.A., 2006, VIRTUAL REAL-LONDON, V10, P197, DOI DOI 10.1007/S10055-006-0039-1
   Nyasulu F, 2011, CHEM 121 150 LAB MAN
   Pansa I, 2010, SERVICE COMPUTATION 2010: THE SECOND INTERNATIONAL CONFERENCES ON ADVANCED SERVICE COMPUTING, P132
   Trescak T, 2010, VISUAL COMPUT, V26, P521, DOI 10.1007/s00371-010-0473-7
   Trindade J, 2002, BRIT J EDUC TECHNOL, V33, P471, DOI 10.1111/1467-8535.00283
   VIRZI RA, 1992, HUM FACTORS, V34, P457, DOI 10.1177/001872089203400407
   Wiedenbeck S, 2005, 2005 IEEE SYMPOSIUM ON VISUAL LANGUAGE AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P215, DOI 10.1109/VLHCC.2005.36
   Woodfield BF, 2005, J CHEM EDUC, V82, P1728, DOI 10.1021/ed082p1728
   Woodfield BF, 2004, J CHEM EDUC, V81, P1672, DOI 10.1021/ed081p1672
   Ying Zhong, 2012, Proceedings 2012 First International Workshop on User Evaluation for Software Engineering Researchers (USER 2012), P5, DOI 10.1109/USER.2012.6226585
NR 31
TC 10
Z9 11
U1 2
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2895
EP 2924
DI 10.1007/s11042-013-1554-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300035
DA 2024-07-18
ER

PT J
AU Mai, HT
   Kim, MH
AF Hai Thanh Mai
   Kim, Myoung Ho
TI Utilizing similarity relationships among existing data for high accuracy
   processing of content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image database; Content-based retrieval; Similarity relationship;
   Bag-of-words; Ranking improvement
ID REPRESENTATION; GEOMETRY
AB Retrieving similar images based on its visual content is an important yet difficult problem. We propose in this paper a new method to improve the accuracy of content-based image retrieval systems. Typically, given a query image, existing retrieval methods return a ranked list based on the similarity scores between the query and individual images in the database. Our method goes further by relying on an analysis of the underlying connections among individual images in the database to improve this list. Initially, we consider each image in the database as a query and use an existing baseline method to search for its likely similar images. Then, the database is modeled as a graph where images are nodes and connections among possibly similar images are edges. Next, we introduce an algorithm to split this graph into stronger subgraphs, based on our notion of graph's strength, so that images in each subgraph are expected to be truly similar to each other. We create for each subgraph a structure called integrated image which contains the visual features of all images in the subgraph. At query time, we compute the similarity scores not only between the query and individual database images but also between the query and the integrated images. The final similarity score of a database image is computed based on both its individual score and the score of the integrated image that it belongs to. This leads effectively to a re-ranking of the retrieved images. We evaluate our method on a common image retrieval benchmark and demonstrate a significant improvement over the traditional bag-of-words retrieval model.
C1 [Hai Thanh Mai; Kim, Myoung Ho] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Mai, HT (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, 291 Daehak Ro, Taejon 305701, South Korea.
EM mhthanh@dbserver.kaist.ac.kr; mhkim@dbserver.kaist.ac.kr
RI Kim, Myoung Ho/C-1997-2011
FU Brain Korea 21 Project; Department of Computer Science, KAIST; National
   Research Foundation of Korea (NRF) - Korea government (MEST)
   [2012R1A2A2A01046694]
FX This work was supported by the Brain Korea 21 Project, the Department of
   Computer Science, KAIST in 2012 and the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MEST) (No.
   2012R1A2A2A01046694). The authors also thank anonymous reviewers for
   valuable comments to improve this work.
CR [Anonymous], 2007, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2007.382970
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Chi M, 2009, P 18 INT C WORLD WID, P1189
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   El Sayad I, 2012, MULTIMED TOOLS APPL, V60, P455, DOI 10.1007/s11042-010-0596-x
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hai Thanh Mai, 2012, Proceedings of the 2012 8th International Conference on Computing Technology and Information Management (NCM and ICNIT), P410
   Hayter A.J., 2007, PROBABILITY STAT ENG, Vthird
   Hsiao JH, 2009, P 18 ACM C INF KNOWL, P157
   Huang YG, 2012, IEICE T INF SYST, VE95D, P694, DOI 10.1587/transinf.E95.D.694
   Jain P, 2008, PROC CVPR IEEE, P3879
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, IEEE I CONF COMP VIS, P2357, DOI 10.1109/ICCV.2009.5459419
   Jiyi Li, 2012, Web Technologies and Applications. Proceedings of the 14th Asia-Pacific Web Conference, APWeb 2012, P399, DOI 10.1007/978-3-642-29253-8_34
   Kilinç D, 2011, EXPERT SYST APPL, V38, P13121, DOI 10.1016/j.eswa.2011.04.118
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lin WH, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P242
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu H, 2006, IEEE T KNOWL DATA EN, V18, P1544, DOI 10.1109/TKDE.2006.174
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Park G, 2005, INFORM PROCESS MANAG, V41, P177, DOI 10.1016/j.ipm.2003.08.002
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Rahman MM, 2009, CIVR
   Ramaswamy S, 2011, IEEE T KNOWL DATA EN, V23, P815, DOI 10.1109/TKDE.2010.59
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Weiss A., 2008, NIPS, P1753
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
NR 36
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 331
EP 360
DI 10.1007/s11042-013-1360-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800016
DA 2024-07-18
ER

PT J
AU Lu, TC
   Chang, CC
   Huang, YH
AF Lu, Tzu-Chuen
   Chang, Chin-Chen
   Huang, Ying-Hsuan
TI High capacity reversible hiding scheme based on interpolation,
   difference expansion, and histogram shifting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible hiding; Difference expansion; Histogram shifting;
   Interpolation
AB Difference expansion and histogram shifting methods are two popular hiding strategies that have been widely used in many researches. For example, Hong and Chen developed a reversible hiding method based on interpolation and histogram shifting. The image quality of their scheme is exceptional; however, their scheme needs to keep and transmit two peak points for secret data extraction and pixel recovering. Moreover, the reference pixels in their scheme cannot be used to embed secret data that will decrease the hiding capacity. Therefore, this paper shall propose a reversible hiding method to enhance their scheme. The proposed method applies the difference expansion, histogram shifting and interpolation strategies to conceal secret data in the reference pixels for increasing the hiding payload. Experimental results indicate that the proposed method performs better in terms of hiding capacity than recently developed methods.
C1 [Lu, Tzu-Chuen] Chaoyang Univ Technol, Dept Informat Management, Taichung 41349, Taiwan.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Huang, Ying-Hsuan] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
C3 Chaoyang University of Technology; Feng Chia University; Asia University
   Taiwan; National Chung Hsing University
RP Chang, CC (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
EM tclu@cyut.edu.tw; alan3c@gmail.com; phd9807@cs.nchu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Awranjeb M, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1877523
   Berson T. A., 1993, Advances in Cryptology - EUROCRYPT '92. Workshop on the Theory and Applications of Cryptographic Techniques. Proceedings, P71
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2012, AEU-INT J ELECTRON C, V66, P758, DOI 10.1016/j.aeue.2012.01.008
   Chu YH, 1999, ELECTRON LETT, V35, P974, DOI 10.1049/el:19990693
   Highland HJ, 1997, COMPUT SECUR, V16, P369, DOI 10.1016/S0167-4048(97)82243-2
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin CC, 2011, COMPUT STAND INTER, V33, P477, DOI 10.1016/j.csi.2011.02.003
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qin C, 2012, MULTIMED TOOLS APPL, V56, P469, DOI 10.1007/s11042-010-0601-4
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Yang CY, 2011, ETRI J, V33, P580, DOI 10.4218/etrij.11.0110.0534
   Yang HW, 2009, JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING, P823, DOI 10.1109/JCPC.2009.5420071
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 31
TC 42
Z9 46
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 417
EP 435
DI 10.1007/s11042-013-1369-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800019
DA 2024-07-18
ER

PT J
AU Wang, SH
   Lin, T
AF Wang, Shuhui
   Lin, Tao
TI United coding method for compound image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compound image and video; United coding; Hybrid coding; Lossless coding;
   Dictionary-entropy coding
ID MATCHING IMAGE; VIDEO
AB This paper proposes a compound image coding method named united coding (UC). In UC, several lossless coding tools such as dictionary-entropy coders, run-length encoding (RLE), Hextile, and a few filters used in portable network graphics (PNG) format are united into H.264 like intraframe hybrid video coding. The basic coding unit (BCU) has a size typically between 16 x 16 pixels to 64 x 64 pixels. All coders in UC are used to code each BCU. Then, the lossless coder that generates minimum bit-rate (R) is chosen as the optimal lossless coder. Finally, the final optimal coder is chosen from the lossy intraframe hybrid coder and the optimal lossless coder using R-D cost based optimization criterion. Moreover, the data coded by one lossless coder can be used as the dictionary of other lossless coders. Experimental results demonstrate that compared with H.264, UC achieves up to 20 dB PSNR improvement and better visual picture quality for compound images with mixed text, graphics and natural picture. Compared with lossless coders such as gzip and PNG, UC can achieve 2-5 times higher compression ratio with just a minor loss and keep partial-lossless picture quality. The partial-lossless nature of UC is indispensable for some typical applications, such as cloud computing and rendering, cloudlet-screen computing and remote desktop, where lossless coding of partial image regions is demanded. On the other hand, the implementation complexity and cost increment of UC is moderate, typically less than 25 % of a traditional hybrid coder such as H.264.
C1 [Wang, Shuhui; Lin, Tao] Tongji Univ, VLSI Lab, Shanghai 200092, Peoples R China.
C3 Tongji University
RP Wang, SH (corresponding author), Tongji Univ, VLSI Lab, Shanghai 200092, Peoples R China.
EM wangshuhui_cn@yahoo.com.cn; lintao@tongji.edu.cn
FU NSFC [61201226, 61271096]; Natural Science Foundation of Shanghai
   [12ZR1433800]; Fundamental Research Funds for the Central Universities
   of China [2810219002, 2810219003]
FX This work was supported in part by NSFC under Grant No. 61201226 and
   Grant No. 61271096, the Natural Science Foundation of Shanghai under
   Grant No. 12ZR1433800 and the Fundamental Research Funds for the Central
   Universities of China under Grant No. 2810219002 and Grant No.
   2810219003.
CR Alzina M, 2002, IEEE T IMAGE PROCESS, V11, P318, DOI 10.1109/83.988964
   [Anonymous], 2004, 15948 ISOIEC
   [Anonymous], 2011, JCTVCE145
   [Anonymous], 2009, DEP ELECT ENG COMPUT
   Atallah M, 1999, IEEE T PATTERN ANAL, V21, P614, DOI 10.1109/34.777372
   Bottou L, 1998, J ELECTRON IMAGING, V7, P410, DOI 10.1117/1.482609
   Chen JM, 1999, IEE P-CIRC DEV SYST, V146, P268, DOI 10.1049/ip-cds:19990535
   Francisco NC, 2010, IEEE T IMAGE PROCESS, V19, P2712, DOI 10.1109/TIP.2010.2049181
   Huttenlocher D., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P219, DOI 10.1109/ICIP.1999.821601
   Konstantinides K, 2000, IEEE T IMAGE PROCESS, V9, P1282, DOI 10.1109/83.847840
   Kountchev Roumen, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P133, DOI 10.1109/IWSSIP.2007.4381171
   Lakhani G, 2006, IEEE IMAGE PROC, P2273, DOI 10.1109/ICIP.2006.312816
   Lan CL, 2010, IEEE T IMAGE PROCESS, V19, P946, DOI 10.1109/TIP.2009.2038636
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Lin T, 2005, P IEEE INT C IM PROC, P561
   Lin T, 2009, IEEE SIGNAL PROC LET, V16, P323, DOI 10.1109/LSP.2009.2014285
   Ma SW, 2007, PROC SPIE, V6508, DOI 10.1117/12.707582
   Mixed Raster Content (MRC) ITU-T, 1998, MIX RAST CONT MRC IT
   Mogi T., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P777, DOI 10.1109/ICIP.1999.817222
   Mukherjee D, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P73, DOI 10.1109/ICIP.2002.1038906
   Said A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P229, DOI 10.1109/ICIP.1999.821603
   Said A, 2004, PROC SPIE, V5308, P69, DOI 10.1117/12.532433
   Selvakumar RK, 2008, P IEEE INT C COMP CO, P1
   Shuhui Wang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P566, DOI 10.1109/CISP.2010.5647270
   Tao Lin, 2009, Proceedings 2009 IEEE International Conference on Multimedia and Expo (ICME), P1805, DOI 10.1109/ICME.2009.5202873
   Wenpeng Ding, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P337
   Zaghetto A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P679, DOI 10.1109/ICVGIP.2008.14
   Zaghetto A, 2007, IEEE T IMAGE PROCESS, V16, P1755, DOI 10.1109/TIP.2007.899036
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 29
TC 12
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1263
EP 1282
DI 10.1007/s11042-012-1274-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000014
DA 2024-07-18
ER

PT J
AU Huo, X
   Tan, JQ
   He, L
   Hu, M
AF Huo, Xing
   Tan, Jieqing
   He, Lei
   Hu, Min
TI An automatic video scratch removal based on Thiele type continued
   fraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video inpainting; Scratch detection; Continued fraction; Non-linear
   interpolation
ID RECONSTRUCTION
AB Old age, repeat play and improper preservation always deteriorate the film, and dust and mechanical operations produce artifacts like scratches and blotches. Many researches carried out to repair the damaged digital videos and video inpainting gradually becomes an important topic in digital image process ing. Challenges in scratched video inpainting are automatic detection of scratches and restoration of damaged part. This paper presents an automatic scratch detec tion method as well as a novel scratch removal approach. Stationary wavelet transform (SWT) which shows excellent performance in keeping translation-invariant is introduced to automatically detect the scratches, this strategy makes the scratches' detection more accurate. At the heart of our method is a new nonlinear interpolation method based on continued fraction in which Thiele-type continued fraction is used to interpolate surrounding known pixels for repairing the damaged part. Algorithm presented in this paper also utilizes both spatial and temporal information of the scratched video during the restoration stage. Experimental results show that our scheme not only obtains more accurate detection of scratches, but also gives better video quality.
C1 [Huo, Xing; Tan, Jieqing; He, Lei] Hefei Univ Technol, Sch Comp & Informat, Sch Math, Hefei, Anhui, Peoples R China.
   [Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Huo, X (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Sch Math, Hefei, Anhui, Peoples R China.
EM phenixhuo@yahoo.com.cn; humin@163.com
RI Tan, Jie/IVV-5250-2023; Hu, Min/HLH-2112-2023
FU National Natural Science Foundation of China
FX The authors would like to thank Prelinger Archives
   (http://www.archive.org) for archive film material. We sincerely
   appreciate the financial support of National Natural Science Foundation
   of China and we are also grateful to editor and reviewers for their
   constructive comments and suggestions.
CR Bao P, 2003, IEEE T MED IMAGING, V22, P1089, DOI 10.1109/TMI.2003.816958
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Dubey N, 2009, GEN WAVELET EXPANSIO
   Graves-Morris P.R., 1981, LECT NOTES MATH, V888, P28, DOI DOI 10.1007/BFB0095575
   He SQ, 2011, MULTIMED TOOLS APPL, V52, P19, DOI 10.1007/s11042-009-0450-1
   Joyeux L, 2002, MACH VISION APPL, V13, P119, DOI 10.1007/s001380100067
   Joyeux L, 2001, IMAGE VISION COMPUT, V19, P503, DOI 10.1016/S0262-8856(00)00091-3
   Joyeux L., 1999, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), P548, DOI DOI 10.1109/CVPR.1999.786991
   Milukova O., 2010, Pattern Recognition and Image Analysis, V20, P179, DOI 10.1134/S1054661810020094
   Nie Shiliang, 2010, 2010 2nd International Conference on Industrial and Information Systems (IIS 2010), P257, DOI 10.1109/INDUSIS.2010.5565861
   Qian XM, 2014, MULTIMED TOOLS APPL, V70, P1487, DOI 10.1007/s11042-012-1168-z
   Qin C, 2012, MULTIMED TOOLS APPL, V56, P469, DOI 10.1007/s11042-010-0601-4
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Solbo S, 2008, IEEE T GEOSCI REMOTE, V46, P1219, DOI 10.1109/TGRS.2007.912718
   Tan JQ, 2000, NUMER ALGORITHMS, V24, P141, DOI 10.1023/A:1019193210259
   Tegolo D, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P507, DOI 10.1109/ICIAP.2001.957060
   Güllü MK, 2006, IEEE INT SYMP CIRC S, P4591
   Vijaykumar VR, 2010, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2010.5651915
   Xiang YJ, 2011, MULTIMED TOOLS APPL, V52, P91, DOI 10.1007/s11042-009-0457-7
NR 22
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 451
EP 467
DI 10.1007/s11042-013-1523-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400005
DA 2024-07-18
ER

PT J
AU Huang, XD
   Ma, HD
   Ling, CX
   Gao, GY
AF Huang, Xiaodong
   Ma, Huadong
   Ling, Charles X.
   Gao, Guangyu
TI Detecting both superimposed and scene text with multiple languages and
   multiple alignments in video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superimposed text; Scene text; Text detection; Motion field
ID LOCALIZATION; EXTRACTION; ALGORITHM
AB Video text often contains highly useful semantic information that can contribute significantly to video retrieval and understanding. Video text can be classified into scene text and superimposed text. Most of the previous methods detect superimposed or scene text separately due to different text alignments. Moreover, because different language characters have different edge and texture features, it is very difficult to detect the multilingual text. In this paper, we first perform a detailed analysis of motion patterns of video text, and show that the superimposed and scene text exhibit different motion patterns on consecutive frames, which is insensitive to multiple language characters and multiple text alignments. Based on our analysis, we define Motion Perception Field (MPF) to represent the text motion patterns. Finally, we propose a text detection algorithms using MPF for both superimposed and scene text with multiple languages and multiple alignments. Experimental results on diverse videos demonstrate that our algorithms are robust, and outperform previous methods for detecting both superimposed and scene texts with multiple languages and multiple alignments.
C1 [Huang, Xiaodong; Ma, Huadong; Ling, Charles X.; Gao, Guangyu] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
   [Huang, Xiaodong] Capital Normal Univ, Beijing 100048, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Capital Normal
   University
RP Ma, HD (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM mhd@bupt.edu.cn
RI Chen, John/GPW-8839-2022
FU National Natural Science Foundation [60925010]; National Natural Science
   Foundation of China [60833009]; Beijing Committee of Education; Funds
   for Creative Research Groups of China [61121001]; Program for Changjiang
   Scholars and Innovative Research Team in University [IRT1049]
FX The authors would like to thank the reviewers for their thorough
   comments and suggestions that helped to improve this paper. This work is
   supported by the National Natural Science Foundation for Distinguished
   Young Scholars under Grant No. 60925010; the National Natural Science
   Foundation of China under Grant No. 60833009; the Cosponsored Project of
   Beijing Committee of Education, the Funds for Creative Research Groups
   of China under Grant No. 61121001, and the Program for Changjiang
   Scholars and Innovative Research Team in University under Grant No.
   IRT1049.
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Boreczky JS, 1998, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.1998.679697
   Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Gao J, 2001, PROC CVPR IEEE, P84
   Goto H, 2008, INT J DOC ANAL RECOG, V11, P1, DOI 10.1007/s10032-008-0061-9
   Harris C., 1988, ALVEY VISION C, P147151
   Horn B, 1986, ROBOT VISION
   Hua X.-S., 2001, P 2001 ACM WORKSH MU, P24
   Hua XS, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P397
   Huang XD, 2008, LECT NOTES COMPUT SC, V5353, P525, DOI 10.1007/978-3-540-89796-5_54
   Kim KC, 2004, INT C PATT RECOG, P679, DOI 10.1109/ICPR.2004.1334350
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Li HP, 2000, INT C PATT RECOG, P223, DOI 10.1109/ICPR.2000.906053
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Mariano VY, 2000, INT C PATT RECOG, P539, DOI 10.1109/ICPR.2000.902976
   Miao GY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P569, DOI 10.1109/ICME.2008.4607498
   SATO T, 1998, VIDEO OCR INDEXING D
   Shivakumara Palaiahnakote, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P156, DOI 10.1109/ICDAR.2009.85
   Sin BK, 2002, INT C PATT RECOG, P489, DOI 10.1109/ICPR.2002.1047983
   SINGH A., 1992, Optic Flow Computation
   Soffer A, 1997, PROC INT CONF DOC, P233, DOI 10.1109/ICDAR.1997.619847
   Wang RR, 2004, INT C PATT RECOG, P449
   Wang YK, 2006, INT C PATT RECOG, P754
   Winger LL, 2000, INT J PATTERN RECOGN, V14, P113, DOI 10.1142/S0218001400000106
   Ye QX, 2004, LECT NOTES COMPUT SC, V3332, P858
   Yi J., 2007, MULTIMEDIA 07, P847, DOI DOI 10.1145/1291233.1291426
NR 28
TC 3
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1703
EP 1727
DI 10.1007/s11042-012-1201-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500016
DA 2024-07-18
ER

PT J
AU Kim, DH
   Kim, JD
AF Kim, Dong Hyun
   Kim, Jong Deok
TI A collision avoidance scheme for the synchronized broadcast packets in a
   multi-AP Wi-Fi broadcasting system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IEEE 802.11; Broadcasting system; Multi AP; Collision Avoidance
AB A Wi-Fi broadcasting system is a kind of Mobile-TV system that transmits multimedia content over Wi-Fi networks. The specialty of the system is that it takes advantage of broadcast packets for streaming to be scalable to the number of users. However, the loss rate of broadcast packets is much higher than that of unicast ones because MAC layer retransmission is not applied on broadcast packets. To recover lost packets, a packet level Forward Error Correction (FEC) scheme is usually used in Wi-Fi broadcasting systems. But it introduces additional transmission overhead, which is usually proportional to the packet loss rate. So it is important to reduce the packet loss rate to build an efficient and reliable Wi-Fi broadcasting system. While past studies have considered only single-AP systems, our study focuses on a multi-AP system which is designed to cover a much larger area. We found a specific packet collision problem that increases packet loss rate significantly in a multi-AP system. It is caused by the simultaneous arrival and transmission of a broadcast packet at and by APs. We identify two scenarios of the collision that depend on the channel state at the time of packet arrival. We propose two collision avoidance methods to handle these scenarios: Broadcast Packet Scheduling Method (BPSM) and Adaptive Contention Window-Sizing Method(ACWSM). We implement both methods in our multi-AP Wi-Fi broadcasting system and verify their effectiveness through experiments.
C1 [Kim, Jong Deok] Telcoware, Seoul, South Korea.
RP Kim, JD (corresponding author), Pusan Natl Univ, Pusan, South Korea.
EM dhkim1106@mobile.re.kr; kimjd@pusan.ac.kr
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2012-0001578]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2012-0001578)
CR [Anonymous], 80211 IEEE
   *ANSI IEEE, 1999, 80211 ANSIIEEE
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Chilamkurti N, 2010, MULTIMED TOOLS APPL, V47, P189, DOI 10.1007/s11042-009-0413-6
   Choi Jaehyuk, 2012, QOS PROVISI IN PRESS
   Convertino G., 2006, MOBIMEDIA 06, P1
   Dujovne D., ACM MSWIM 06
   Kim J, 2007, IEEE T CONSUM ELECTR, V53, P120, DOI 10.1109/TCE.2007.339512
   Lin CH, 2008, IEEE T BROADCAST, V54, P517, DOI 10.1109/TBC.2008.2001713
   Ma X., 2007, IEEE COMMUNICATION L, V11
   Makharia S., 2008, EXPT STUDY WIRELESS, P1
   Munaretto D., 2009, COMP COMM 2009 ISCC, P30
   Park KH, 1998, IEEE IC COMP COM NET, P196, DOI 10.1109/ICCCN.1998.998777
   Takahata K, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P594
   van der Schaar M, 2006, IEEE T MOBILE COMPUT, V5, P755, DOI 10.1109/TMC.2006.81
NR 15
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 643
EP 659
DI 10.1007/s11042-012-1113-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300005
DA 2024-07-18
ER

PT J
AU Gkonela, C
   Chorianopoulos, K
AF Gkonela, Chrysoula
   Chorianopoulos, Konstantinos
TI VideoSkip: event detection in social web videos with an implicit user
   heuristic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Event detection; Semantics; Web; User-based; Experiment
ID NAVIGATION
AB In this paper, we present a user-based event detection method for social web videos. Previous research in event detection has focused on content-based techniques, such as pattern recognition algorithms that attempt to understand the contents of a video. There are few user-centric approaches that have considered either search keywords, or external data such as comments, tags, and annotations. Moreover, some of the user-centric approaches imposed an extra effort to the users in order to capture required information. In this research, we are describing a method for the analysis of implicit users' interactions with a web video player, such as pause, play, and thirty-seconds skip or rewind. The results of our experiments indicated that even the simple user heuristic of local maxima might effectively detect the same video-events, as indicated manually. Notably, the proposed technique was more accurate in the detection of events that have a short duration, because those events motivated increased user interaction in video hot-spots. The findings of this research provide evidence that we might be able to infer semantics about a piece of unstructured data just from the way people actually use it.
C1 [Gkonela, Chrysoula; Chorianopoulos, Konstantinos] Ionian Univ, Dept Informat, Corfu, Greece.
C3 Ionian University
RP Chorianopoulos, K (corresponding author), Ionian Univ, Dept Informat, Corfu, Greece.
EM choko@ionio.gr
RI Chorianopoulos, Konstantinos/N-4943-2019; Chorianopoulos,
   Konstantinos/I-7289-2013
OI Chorianopoulos, Konstantinos/0000-0002-5999-9387; 
CR [Anonymous], 2011, Proceedings of the 3rd ACM SIGMM international workshop on Social media, DOI [10.1145/2072609.2072614, DOI 10.1145/2072609.2072614]
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Chen L, 2008, INTERACT COMPUT, V20, P17, DOI 10.1016/j.intcom.2007.06.003
   Crockford C, 2006, INT J HUM-COMPUT ST, V64, P340, DOI 10.1016/j.ijhcs.2005.08.012
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P757, DOI 10.1109/TCSVT.2004.828348
   Doulamis DA, 2010, ACM MULTIMEDIA, V2010, P1749
   Drucker S. M., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P219, DOI 10.1145/503376.503416
   Girgensohn A, 2001, COMPUTER, V34, P61, DOI 10.1109/2.947093
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Hjelsvold R., 2001, P 10 INT C WORLD WID, P129, DOI [https://doi.org/10.1145/371920.371969, DOI 10.1145/371920.371969]
   Kelly Diane, 2009, Foundations and Trends in Information Retrieval, V3, P1, DOI 10.1561/1500000012
   Kim J, 2006, INTERACT COMPUT, V18, P723, DOI 10.1016/j.intcom.2005.11.011
   Leftheriotis I, 2010, P 2 INT C US CENTR M
   Li F. C., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P169, DOI 10.1145/332040.332425
   Ma YF, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P94
   Mitra S, 2011, ACM T WEB, V5, DOI 10.1145/1961659.1961662
   Ntalianis KS, 2010, MULTIMED TOOLS APPL, V50, P199, DOI 10.1007/s11042-009-0369-6
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Shamma DA., 2007, P INT WORKSHOP WORKS, P275, DOI [10.1145/1290082.1290120, DOI 10.1145/1290082.1290120]
   Shen Xuehua, 2005, CIKM '05, P824, DOI DOI 10.1145/1099554.1099747
   Syeda-Mahmood T, 2001, P 9 ACM INT C MULT M, P119
   Takahashi Y., 2005, P 13 ANN ACM INT C M, P820
   Yu B, 2003, P 11 ACM INT C MULT, P382
   Zhang DQ, 2011, COMPUTER, V44, P21, DOI 10.1109/MC.2011.65
NR 24
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 383
EP 396
DI 10.1007/s11042-012-1016-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400008
DA 2024-07-18
ER

PT J
AU Mohamed, H
   Marchand-Maillet, S
AF Mohamed, Hisham
   Marchand-Maillet, Stephane
TI Distributed media indexing based on MPI and MapReduce
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed multimedia indexing; MPI; MapReduce; Distributed inverted
   indexing; Permutation-based indexes; Distributed approximate similarity
   search
AB Web-scale digital assets comprise millions or billions of documents. Due to such increase, sequential algorithms cannot cope with this data, and parallel and distributed computing become the solution of choice. MapReduce is a programming model proposed by Google for scalable data processing. MapReduce is mainly applicable for data intensive algorithms. In contrast, the message passing interface (MPI) is suitable for high performance algorithms. This paper proposes an adapted structure of the MapReduce programming model using MPI for multimedia indexing. Experimental results are done on various multimedia applications to validate our model. The experiments indicate that our proposed model achieves good speedup compared to the original sequential versions, Hadoop and the earlier versions of MapReduce using MPI.
C1 [Mohamed, Hisham; Marchand-Maillet, Stephane] Univ Geneva, Viper Grp, Comp Vis & Multimedia Lab, Geneva, Switzerland.
C3 University of Geneva
RP Mohamed, H (corresponding author), Univ Geneva, Viper Grp, Comp Vis & Multimedia Lab, 7 Route Drize, Geneva, Switzerland.
EM hisham.mohamed@unige.ch; stephane.marchand-maillet@unige.ch
FU Swiss National Science Foundation (SNSF) via the Swiss National Center
   of Competence in Research (NCCR) on Interactive Multimodal Information
   Management (IM2); European COST Action on Multilingual and Multifaceted
   Interactive Information Access (MUMIA) via the Swiss State Secretariat
   for Education and Research (SER)
FX This work is jointly supported by the Swiss National Science Foundation
   (SNSF) via the Swiss National Center of Competence in Research (NCCR) on
   Interactive Multimodal Information Management (IM2) and the European
   COST Action on Multilingual and Multifaceted Interactive Information
   Access (MUMIA) via the Swiss State Secretariat for Education and
   Research (SER).
CR Ahmad F, 2007, TECHNICAL REPORT
   Amato G, 2008, P 3 INT C SCAL INF S, P28
   [Anonymous], 2009, CVPR 09
   [Anonymous], 2010, P 19 ACM INT S HIGH, DOI DOI 10.1145/1851476.1851593
   [Anonymous], 2009, Hadoop: The definitive guide
   Bruno Eric, 2009, Journal of Multimedia, V4, P321, DOI 10.4304/jmm.4.5.321-329
   Chavez E, 2008, IEEE T PATTERN ANAL, V30, P1647, DOI 10.1109/TPAMI.2007.70815
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dean Jeffrey, 2004, OSDI 04, P10
   Gabriel E, 2004, LECT NOTES COMPUT SC, V3241, P97
   Gillick Dan., 2006, MAPREDUCE DISTRIBUTE
   Gropp W., 1994, USING MPI
   Hoefler T, 2009, LECT NOTES COMPUT SC, V5759, P240, DOI 10.1007/978-3-642-03770-2_30
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jagadish H. V., 1995, Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1995, P36, DOI 10.1145/212433.212444
   Kumar V., 2002, Introduction to parallel computing
   McCreadie R, 2012, INFORM PROCESS MANAG, V48, P873, DOI 10.1016/j.ipm.2010.12.003
   Patella M, 2009, J DISCRET ALGORITHMS, V7, P36, DOI 10.1016/j.jda.2008.09.014
   Plimpton SJ, 2011, PARALLEL COMPUT, V37, P610, DOI 10.1016/j.parco.2011.02.004
   Rajasekaran R, 2007, HDB PARALLEL COMPUTI
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Stanfill C., 1990, P 13 ANN INT ACM SIG, P413, DOI DOI 10.1145/96749.98247
   von Wyl M, 2011, P 1 ACM INT C MULT R, P73
   Witten I.H., 1999, Managing Gigabytes: Compressing and Indexing Documents and Images
   Xiaoyi Lu, 2011, Proceedings of the 2011 International Conference on Parallel Processing Workshops (ICPPW 2011), P371, DOI 10.1109/ICPPW.2011.56
   Zezula P., 2006, ADV IND CON, V32
NR 26
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 513
EP 537
DI 10.1007/s11042-012-1283-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Voulodimos, AS
   Kosmopoulos, DI
   Doulamis, ND
   Varvarigou, TA
AF Voulodimos, Athanasios S.
   Kosmopoulos, Dimitrios I.
   Doulamis, Nikolaos D.
   Varvarigou, Theodora A.
TI A top-down event-driven approach for concurrent activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concurrent activity recognition; Event detection; Top-down; Region of
   interest (ROI); Workflow
ID HIDDEN MARKOV MODEL; BEHAVIOR RECOGNITION; MOTION
AB In this paper a framework for automatic online workflow recognition in industrial environments where the issue of concurrent activities rises, is presented. The framework consists of three main parts: The first part is devoted to detecting activity in specific Regions of Interest (ROIs) of the video sequence. This is effected by separating each frame into ROIs and representing the resulting subimages through feature vectors. By observing these vectors we can determine when there is action in a particular ROI. The second part of the framework lies in examining whether the detected activity corresponds to a workflow related event. This is accomplished by HMM modeling. Finally, the third part employs a string matching based technique to confirm the validity of the observed sequence of events or correct any detection or classification errors. This last step also addresses a top down approach by informing lower system levels (such as image representation or object tracking) about the errors committed. The performance of the proposed approach is thoroughly evaluated under real-life complex visual workflow understanding scenarios, in an industrial plant. The obtained results are compared and discussed.
C1 [Voulodimos, Athanasios S.; Doulamis, Nikolaos D.; Varvarigou, Theodora A.] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
   [Kosmopoulos, Dimitrios I.] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
C3 National Technical University of Athens; University of Texas System;
   University of Texas Arlington
RP Voulodimos, AS (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
EM thanosv@mail.ntua.gr; dkosmo@ieee.org; ndoulam@cs.ntua.gr;
   dora@telecom.ntua.gr
RI Voulodimos, Athanasios/ABC-1836-2021; Doulamis,
   Anastasios/AAL-5972-2021; Kosmopoulos, Dimitrios/P-4325-2015
OI Kosmopoulos, Dimitrios/0000-0003-3325-1247
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], 1966, SOVIET PHYS DOKL
   [Anonymous], 2007, P IEEE INT C COMP VI, DOI DOI 10.1109/ICCV.2007.4408894
   [Anonymous], ACM MULT ARTEMIS WOR
   Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892
   Chatzis SP, 2009, IEEE T PATTERN ANAL, V31, P1657, DOI 10.1109/TPAMI.2008.215
   Doulamis A, 2012, FUTURE GENER COMP SY, V28, P605, DOI 10.1016/j.future.2011.02.008
   Doulamis A, 2010, MULTIMED TOOLS APPL, V50, P49, DOI 10.1007/s11042-009-0368-7
   Eickeler S, 1998, INT C PATT RECOG, P1206, DOI 10.1109/ICPR.1998.711914
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hung MH, 2008, IEEE T CIRC SYST VID, V18, P1713, DOI 10.1109/TCSVT.2008.2004934
   Kosmopoulos Dimitrios I., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3575, DOI 10.1109/ICPR.2010.872
   Kosmopoulos D, 2010, IEEE SIGNAL PROC MAG, V27, P34, DOI 10.1109/MSP.2010.937392
   Kosmopoulos DI, 2012, COMPUT VIS IMAGE UND, V116, P422, DOI 10.1016/j.cviu.2011.09.006
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004
   Padoy N., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P585, DOI 10.1109/ICCVW.2009.5457648
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Qiong Hu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1521, DOI 10.1109/ICPR.2010.376
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   Voulodimos A, 2011, IEEE IMAGE PROC
   Voulodimos AS, 2012, APPL ARTIF INTELL, V26, P97, DOI 10.1080/08839514.2012.629540
   Wada T, 2000, IEEE T PATTERN ANAL, V22, P873, DOI 10.1109/34.868687
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Xiang T, 2008, COMPUT VIS IMAGE UND, V112, P310, DOI 10.1016/j.cviu.2008.05.011
   Yang MH, 1998, PROC CVPR IEEE, P892, DOI 10.1109/CVPR.1998.698710
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Zeng ZH, 2008, IEEE T MULTIMEDIA, V10, P570, DOI 10.1109/TMM.2008.921737
NR 34
TC 19
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 293
EP 311
DI 10.1007/s11042-012-0993-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400004
DA 2024-07-18
ER

PT J
AU Han, ZC
   Su, TM
   Ou, ZY
   Xu, WJ
AF Han, Zhaocui
   Su, Tieming
   Ou, Zongying
   Xu, Wenji
TI Precise localization of eye centers with multiple cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye detection; Eye center localization; Multiple cues
ID FACE RECOGNITION; FEATURES
AB Automatic detection and precise localization of human eye centers are the essential processes in photo related multimedia applications. Since eye center points are used as reference base points for further intelligent processing, precise eye center localization is very important. In face recognition the accuracy of localization of eye centers directly influences the identification accuracy. A multiple stage approach with multiple cues for detection and precise localization of eye centers is presented in this paper. Multiple scopes searching strategy is used for correctly extracting eye patch images from the background. Dedicated gradient based features and curvelet based features are constructed and used for comprehensively revealing the intensity distribution characteristics and the edge based texture around eye centers. A rebuilt score calculation mechanism is proposed and the rebuilt scores are used as a specific measurement index reflecting the matching accuracy. The final localizations of eye centers are determined with integrating the gradient based scores and curvelet based scores. The experiment results testing on public face datasets show that the localization accuracy of proposed approach outperforms the accuracy with other state of the art methods.
C1 [Han, Zhaocui; Su, Tieming; Ou, Zongying; Xu, Wenji] Dalian Univ Technol, Sch Mech Engn, Dalian, Peoples R China.
C3 Dalian University of Technology
RP Ou, ZY (corresponding author), Dalian Univ Technol, Sch Mech Engn, Dalian, Peoples R China.
EM ouzyg@dlut.edu.cn
FU Dalian University of Technology; Shenyang Institute of Automation,
   Chinese Academy of Science; National Hi-Tech Program; ISVISION Tech. Co.
   Ltd.
FX The research work is supported by the joint research funds of Dalian
   University of Technology and Shenyang Institute of Automation, Chinese
   Academy of Science. The authors would like to thank to those who provide
   public datasets which we used for training and testing, including the
   BioID Inc. for providing the BioID face dataset; Miyuki Kamachi, Michael
   Lyons and Jiro Gyoba for providing the JAFFE face dataset; the Face
   Recognition Group of JDL, ICT, CAS for providing the CAS-PEAL face
   dataset under the sponsors of National Hi-Tech Program and ISVISION
   Tech. Co. Ltd.
CR Asteriadis S, 2006, INT S CONTR COMM SIG
   Bai L, 2006, INT C PATT RECOG, P511
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Campadelli P., 2006, BRIT MACHINE VISION, P187
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   [车昊 CHE Hao], 2008, [中国图象图形学报, Journal of Image and Graphics], V13, P472
   Cristinacce D., 2004, BMVC, P231
   Gao Wen., 2004, The cas-peal large-scale chinese face database and evaluation protocols
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Jain M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P152
   Jesorsky O., 1992, Audio and Video Biom. Pers. Auth, P90
   Monzo D, 2011, MACH VISION APPL, V22, P471, DOI 10.1007/s00138-010-0273-0
   Turkan M., 2007, INT C COMP VIS THEOR
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P., 2005, 2005 IEEE COMP SOC C, P164
NR 18
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 931
EP 945
DI 10.1007/s11042-012-1090-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000020
DA 2024-07-18
ER

PT J
AU Lee, JY
   Park, HM
   Lee, SH
   Shin, SH
   Kim, TE
   Choi, JS
AF Lee, Jae-Young
   Park, Hyung-Min
   Lee, Seok-Han
   Shin, Soon-Ho
   Kim, Tae-Eun
   Choi, Jong-Soo
TI Design and implementation of an augmented reality system using gaze
   interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Annotation system; Wearable system; Gaze interaction
AB In this paper, we discuss an interactive optical see-through head-mounted device (HMD) which makes use of a user's gaze for an augmented reality (AR) interface. In particular, we propose a method to employ a user's half-blink information for more efficient interaction. Since the interaction is achieved using a user's gaze and half-blinks, the proposed system can create a more efficient computing environment. In addition, the proposed system can be quite helpful to those who have difficulties in using their hands for conventional interaction methods. The experimental results present the robustness and efficiency of the proposed system.
C1 [Lee, Jae-Young; Lee, Seok-Han; Choi, Jong-Soo] Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Seoul 156756, South Korea.
   [Park, Hyung-Min] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Taejon 305701, South Korea.
   [Shin, Soon-Ho] Calif State Univ, Long Beach, CA USA.
   [Kim, Tae-Eun] Namseoul Univ, Cheonan, South Korea.
C3 Chung Ang University; Korea Advanced Institute of Science & Technology
   (KAIST); California State University System; California State University
   Long Beach; Namseoul University
RP Lee, JY (corresponding author), Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Seoul 156756, South Korea.
EM evs0@imagelab.cau.ac.kr; elt3470@naver.com; ichthus@imagelab.cau.ac.kr;
   winshin2@naver.com; tekim@nsu.ac.kr; jschoi@cau.ac.kr
RI Lee, jaeyoung/KHD-6423-2024
FU Korean Research Foundation
FX This work was supported by Korean Research Foundation under BK21
   project.
CR Agustin JS, 2008, P COGAIN 2008 PRAG C, P6
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Bichlmeier C., 2007, INT S MIX AUGM REAL, P129, DOI DOI 10.1109/ISMAR.2007.4538837
   Feiner S, 1997, PERS UBIQUIT COMPUT, V1, P1617
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Höllerer TH, 2004, TELEGEOINFORMATICS: LOCATION-BASED COMPUTING AND SERVICES, P221
   Looser J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P203
   Nilsson S., 2007, P WORKSHOP COMMUNICA, P53
   Park HM, 2008, INT SYM MIX AUGMENT, P175, DOI 10.1109/ISMAR.2008.4637353
   Tuceryan M, 2002, PRESENCE-TELEOP VIRT, V11, P259, DOI 10.1162/105474602317473213
NR 11
TC 12
Z9 13
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 265
EP 280
DI 10.1007/s11042-011-0944-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400005
DA 2024-07-18
ER

PT J
AU Ryu, ES
   Han, SW
AF Ryu, Eun-Seok
   Han, Sung Won
TI Priority-based selective H.264 SVC streaming over erroneous converged
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264 SVC; Video streaming; Channel prediction; Converged network; FMO
ID AWARE
AB This paper provides a detailed description and discussion of new optimal H.264 scalable video coding (SVC) transmission method over multi-path networks that have variable packet loss rates (PLR). The proposed method has three steps: (1) using flexible macroblock ordering (FMO), it prioritizes SVC layers and slice groups (SG) according to their affect on video quality; (2) it measures current channel status and predicts future bandwidths (BW); and (3) it allocates SVC layers and SGs to the prioritized channels by PLR. Experiments show that the proposed selective streaming method can improve video quality as much as 3.4 dB in peak signal-to-noise ratio (PSNR), and has better error resilience than traditional streaming methods.
C1 [Ryu, Eun-Seok] InterDigital, San Diego, CA 92121 USA.
   [Han, Sung Won] Univ Penn, Dept Biostat & Epidemiol, Philadelphia, PA 19104 USA.
C3 InterDigital; University of Pennsylvania
RP Han, SW (corresponding author), Univ Penn, Dept Biostat & Epidemiol, Philadelphia, PA 19104 USA.
EM esryu@gatech.edu; hansungw@mail.med.upenn.edu
RI Ryu, Eun-Seok/AAA-3536-2021
CR [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 9 INT C ADV COMM TEC
   [Anonymous], IEEE COMSOC MMTC E L
   [Anonymous], SVC AVC PACKET LOSS
   [Anonymous], SLICE GROUP MAP GENE
   [Anonymous], JOINT SCAL VID MOD J
   Apostolopoulos JG, 2004, IEEE COMMUN MAG, V42, P80, DOI 10.1109/MCOM.2004.1321395
   Begen AC, 2005, SIGNAL PROCESS-IMAGE, V20, P39, DOI 10.1016/j.image.2004.09.002
   Chakareski J, 2007, IEEE COMMUN MAG, V45, P77, DOI 10.1109/MCOM.2007.284541
   Chen H, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P868, DOI 10.1109/ICALIP.2008.4589969
   Chen JC, 2004, IEEE J SEL AREA COMM, V22, P1920, DOI 10.1109/JSAC.2004.836000
   Chen Ying, 2006, Journal of Zhejiang University (Science), V7, P677, DOI 10.1631/jzus.2006.A0677
   Han SW, 2010, QUAL RELIAB ENG INT, V26, P279, DOI 10.1002/qre.1056
   Hellge C, 2008, IEEE IMAGE PROC, P2304, DOI 10.1109/ICIP.2008.4712252
   Huang HC, 2007, IEEE COMMUN MAG, V45, P68, DOI 10.1109/MCOM.2007.284540
   Lambert P, 2009, J REAL-TIME IMAGE PR, V4, P79, DOI 10.1007/s11554-008-0104-y
   Mansour H, 2005, IEEE INT SYMP CIRC S, P4042, DOI 10.1109/ISCAS.2005.1465518
   Martini MG, 2007, IEEE COMMUN MAG, V45, P84, DOI 10.1109/MCOM.2007.284542
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Roberts SW, 2000, TECHNOMETRICS, V42, P97, DOI 10.2307/1271439
   Ryu ES, 2011, IEEE T CONSUM ELECTR, V57, P1652, DOI 10.1109/TCE.2011.6131138
   Wenger S., 2002, ERROR PATTERNS INTER
   Zhu XQ, 2011, IEEE T MULTIMEDIA, V13, P720, DOI 10.1109/TMM.2011.2115996
NR 23
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 337
EP 353
DI 10.1007/s11042-012-1121-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400010
DA 2024-07-18
ER

PT J
AU Tsai, CW
   Liao, MY
   Yang, CS
   Chiang, MC
AF Tsai, Chun-Wei
   Liao, Ming-Yi
   Yang, Chu-Sing
   Chiang, Ming-Chao
TI Classification algorithms for interactive multimedia services: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Interactive multimedia service; Clustering; Classification
ID RELEVANCE FEEDBACK; VIDEO SEGMENTATION; FACE RECOGNITION; TABU SEARCH;
   SYSTEM; IMAGE; OPTIMIZATION; RETRIEVAL; ARCHITECTURE; COLONY
AB Interactive multimedia services, which integrate and unify techniques from a variety of disciplines, have been an active research topic for many years. However, two major challenges need to be overcome to provide a better service: The first is that interactive multimedia systems have to provide the contents a user needs at the right time no matter where the user is located and what device the user is using; the second is that the performance of such systems needs to be improved. Apparently, classification and clustering (also called unsupervised classification) algorithms play an indispensable role in these respects. Thus, this paper contains a review of the classification algorithms for interactive multimedia systems. Also discussed in this paper are several important issues, open questions, and trends.
C1 [Tsai, Chun-Wei] Chia Nan Univ Pharm & Sci, Dept Appl Geoinformat, Tainan, Taiwan.
   [Liao, Ming-Yi; Yang, Chu-Sing] Natl Cheng Kung Univ, Dept Elect Engn, Inst Comp & Commun Engn, Tainan 70101, Taiwan.
   [Chiang, Ming-Chao] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
C3 Chia Nan University of Pharmacy & Science; National Cheng Kung
   University; National Sun Yat Sen University
RP Chiang, MC (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
EM cwtsai0807@gmail.com; q3897130@mail.ncku.edu.tw; csyang@ee.ncku.edu.tw;
   mcchiang@cse.nsysu.edu.tw
RI Tsai, Chun-Wei/R-6389-2019
FU National Science Council of Taiwan, R.O.C. [NSC100-2218-E-041-001-MY2,
   NSC99-2219-E-006-002, NSC99-2221-E-110-052]
FX This work was supported in part by the National Science Council of
   Taiwan, R.O.C., under Grants NSC100-2218-E-041-001-MY2,
   NSC99-2219-E-006-002, and NSC99-2221-E-110-052.
CR Ahanger G, 1996, J VIS COMMUN IMAGE R, V7, P28, DOI 10.1006/jvci.1996.0004
   Almeroth KC, 1998, COMPUT NETWORKS ISDN, V30, P431, DOI 10.1016/S0169-7552(98)00119-6
   [Anonymous], P ACM S DOC ENG
   [Anonymous], 1991, SIMULATION ADAPTIVE
   [Anonymous], 1996, SIGMOD REC ACM SPEC, DOI DOI 10.1145/235968.233324
   [Anonymous], P INT WORKSH IM AN M
   [Anonymous], P ACM INT C MULT
   [Anonymous], P GEN EV COMP C
   [Anonymous], PERSONAL UBIQUITOUS
   [Anonymous], P BRAZ S MULT WEB
   [Anonymous], P ACM SIGGRAPH 2006
   [Anonymous], P IEEE ANN FRONT ED
   [Anonymous], P HUM FACT COMP SYST
   [Anonymous], P SIGN PROC SYST
   [Anonymous], DATA MINING MULTIMED
   [Anonymous], P U MAR
   [Anonymous], PRINCIPLES ARTIFICIA
   [Anonymous], PATTERN RECOGNIT SUP
   [Anonymous], P INT C MOB MULT COM
   [Anonymous], P ACM INT C MULT
   [Anonymous], TABU SEARCH
   [Anonymous], P INT C MULT COMP SY
   [Anonymous], HLTH ED BEHAV
   [Anonymous], DATA MINING KNOWLEDG
   [Anonymous], 2009, 2009 DIGEST TECHNICA, DOI DOI 10.1109/ICCE.2009.5012309
   [Anonymous], P IEEE INT PAR DISTR
   [Anonymous], 1996, ARTIFICIAL INTELLIGE
   [Anonymous], IEEE COMMUN SURV TUT
   [Anonymous], P PAC RIM S ADV IM V
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], P ACM S APPL COMP
   [Anonymous], P INT S UB MULT COMP
   [Anonymous], AM J DISTANCE ED
   [Anonymous], DATA MINING CONCEPTS
   [Anonymous], P GEOM MOD IM NEW TR
   Arandjelovic O, 2005, PROC CVPR IEEE, P860
   Arevalillo-Herráez M, 2008, SIGNAL PROCESS-IMAGE, V23, P490, DOI 10.1016/j.image.2008.04.016
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Back T., 1997, Handbook of evolutionary computation, V1st
   Barhoumi W, 2009, STUD COMP INTELL, V226, P177
   Barua S, 2001, IEEE T EDUC, V44, P41, DOI 10.1109/13.912709
   Berrani SA, 2008, SIGNAL PROCESS-IMAGE, V23, P525, DOI 10.1016/j.image.2008.04.018
   Blum C, 2003, ACM COMPUT SURV, V35, P268, DOI 10.1145/937503.937505
   Broilo M., 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P666, DOI 10.1109/MMSP.2008.4665159
   Broilo M, 2010, IEEE T MULTIMEDIA, V12, P267, DOI 10.1109/TMM.2010.2046269
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Calarco G, 2003, LECT NOTES COMPUT SC, V2720, P146
   Campbell C, 2002, NEUROCOMPUTING, V48, P63, DOI 10.1016/S0925-2312(01)00643-9
   CARLSON HL, 1991, ETR&D-EDUC TECH RES, V39, P41, DOI 10.1007/BF02296437
   Castagno R, 1998, IEEE T CIRC SYST VID, V8, P562, DOI 10.1109/76.718503
   Cattelan RG, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412201
   Cavaco S, 2010, LECT NOTES COMPUT SC, V6134, P307, DOI 10.1007/978-3-642-13681-8_36
   Chalechale A, 2008, IRAN J SCI TECHNOL B, V32, P279
   Chandramouli K, 2011, STUD COMPUT INTELL, V346, P81
   Chen HN, 2011, J NETW COMPUT APPL, V34, P888, DOI 10.1016/j.jnca.2010.04.004
   Chen M, 2010, IEEE INTELL SYST, V25, P12, DOI 10.1109/MIS.2010.44
   Cheng HN, 2008, ACS SYM SER, V999, P1
   Cho SB, 2004, P IEEE, V92, P702, DOI 10.1109/JPROC.2004.825900
   Chrysostomou K, 2009, INTERACT LEARN ENVIR, V17, P151, DOI 10.1080/10494820801988315
   Chrysostomou KA, 2006, IEEE SYS MAN CYBERN, P2849, DOI 10.1109/ICSMC.2006.385306
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   de Silva GC, 2007, COMPUTER, V40, P52, DOI 10.1109/MC.2007.155
   Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, P53, DOI 10.1109/4235.585892
   Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436
   Dote Y, 2001, P IEEE, V89, P1243, DOI 10.1109/5.949483
   Dotu I, 2011, J HEURISTICS, V17, P415, DOI 10.1007/s10732-010-9140-4
   Dotu I, 2009, LECT NOTES COMPUT SC, V5732, P21, DOI 10.1007/978-3-642-04244-7_5
   Doulamis ND, 2000, IEEE T CIRC SYST VID, V10, P501, DOI 10.1109/76.844996
   Doulamis ND, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P575, DOI 10.1109/ICDSP.2002.1028155
   Draman NA, 2011, COMM COM INF SC, V180, P724
   Duval E, 2008, IEEE T LEARN TECHNOL, V1, P229, DOI 10.1109/TLT.2009.6
   Edwards G. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P486, DOI 10.1109/CVPR.1999.786982
   Ehrmantraut M., 1996, Proceedings of the 1996 ACM CIKM. International Conference on Information and Knowledge Management, P243, DOI 10.1145/238355.238505
   Ellwart D, 2010, SMART INNOV SYST TEC, V6, P33
   Endres C, 2005, MOB INF SYST, V1, P41, DOI 10.1155/2005/654215
   Engelbrecht A.P., 2006, Fundamentals of computational swarm intelligence
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fan JP, 2004, ACM-IEEE J CONF DIG, P192, DOI 10.1145/996350.996395
   Fan JP, 2004, IEEE T IMAGE PROCESS, V13, P974, DOI 10.1109/TIP.2004.827232
   Fan JP, 2002, SIGNAL PROCESS-IMAGE, V17, P145, DOI 10.1016/S0923-5965(01)00012-1
   FOX EA, 1989, COMMUN ACM, V32, P794, DOI 10.1145/65445.65446
   FOX EA, 1991, COMPUTER, V24, P9, DOI 10.1109/2.97247
   Frear V, 1999, BRIT J EDUC TECHNOL, V30, P323, DOI 10.1111/1467-8535.00122
   Gao T, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL IV, PROCEEDINGS, P534, DOI 10.1109/AICI.2009.316
   Gharehchopogh F.S., 2010, Application of Information and Communication Technologies (AICT), P1, DOI [10.1109/ICAICT.2010.5611792, DOI 10.1109/ICAICT.2010.5611792]
   Grangeiro F, 2009, INT CONF ACOUST SPEE, P1945, DOI 10.1109/ICASSP.2009.4959991
   Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387
   Harless W. G., 1999, CALICO Journal, V16, P313
   HIRZALLA N, 1995, IEEE MULTIMEDIA, V2, P24, DOI 10.1109/93.410508
   Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593
   Holland I.H., 1975, ADAPTATION NATURAL A
   Hu GH, 2003, IEEE SYS MAN CYBERN, P268
   Huang C, 2005, COMPUT MED IMAG GRAP, V29, P223, DOI 10.1016/j.compmedimag.2004.09.017
   Huang CM, 1998, MULTIMEDIA SYST, V6, P316, DOI 10.1007/s005300050096
   Irvine AB, 2004, HEALTH EDUC RES, V19, P290, DOI 10.1093/her/cyg027
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kenteris M., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P840, DOI 10.1109/ISCC.2010.5546758
   Kim EY, 2006, PATTERN RECOGN LETT, V27, P1252, DOI 10.1016/j.patrec.2005.07.023
   Kim EY, 2002, PATTERN RECOGN LETT, V23, P843, DOI 10.1016/S0167-8655(01)00160-X
   Kinoshita Y, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P630, DOI 10.1109/ICME.2005.1521502
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Laha A, 2004, IEEE T IMAGE PROCESS, V13, P1291, DOI 10.1109/TIP.2004.833107
   Lai CF, 2011, COMPUT COMMUN, V34, P184, DOI 10.1016/j.comcom.2010.03.034
   Laskaris NA, 2004, NEUROCOMPUTING, V61, P421, DOI 10.1016/j.neucom.2004.03.013
   Lee PM, 1996, IEEE T EDUC, V39, P430, DOI 10.1109/13.538769
   Li N, 2006, LECT NOTES CONTR INF, V344, P945
   Lin P, 2009, WIREL NETW, V15, P163, DOI 10.1007/s11276-007-0019-8
   Liu B., 2007, Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data
   Liu F, 2009, P INT C MANAGEMENT S, P1
   LOEB S, 1992, IEEE COMMUN MAG, V30, P52, DOI 10.1109/35.137479
   Losquadro G, 1997, EUR T TELECOMMUN, V8, P379, DOI 10.1002/ett.4460080411
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Márquez JM, 2008, IEEE IJCNN, P3834, DOI 10.1109/IJCNN.2008.4634349
   Meng Y, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P1671, DOI 10.1109/ICMLC.2009.5212297
   Meyer S., 2003, C RES PRACTICE INFOR, V21, P159, DOI 10.5555/827987.828005
   Modritscher F., 2004, Proceedings of the World Conference on E-Learning in Corporate, Government, Healthcare, Higher Education, P2499
   Nahrstedt K, 2011, MULTIMED TOOLS APPL, V51, P99, DOI 10.1007/s11042-010-0627-7
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   NUSSBAUMER JP, 1995, IEEE J SEL AREA COMM, V13, P779, DOI 10.1109/49.391753
   Omran MG, 2005, INFORM-J COMPUT INFO, V29, P261
   Ordonez C, 2004, IEEE T KNOWL DATA EN, V16, P909, DOI 10.1109/TKDE.2004.25
   Palafox L, 2010, C HUM SYST INTERACT, P369, DOI 10.1109/HSI.2010.5514542
   Palaniappan K, 2000, INT GEOSCI REMOTE SE, P688, DOI 10.1109/IGARSS.2000.861672
   Papadopoulos G, 2008, P INT C SEMANTICS DI, P1
   Patras I, 2003, SIGNAL PROCESS-IMAGE, V18, P51, DOI 10.1016/S0923-5965(02)00092-9
   Pfister T, 2010, LECT NOTES COMPUT SC, V6219, P151, DOI 10.1007/978-3-642-14715-9_15
   Piatrik T, 2009, INT WORK CONTENT MUL, P107, DOI 10.1109/CBMI.2009.50
   Pimentel MDC, 2008, LECT NOTES COMPUT SC, V5066, P72, DOI 10.1007/978-3-540-69478-6_8
   Ramanathan S., 1994, IEEE Multimedia, V1, P37, DOI 10.1109/93.295266
   Regan M., 1996, Journal of Engineering Education, V85, P123, DOI 10.1002/j.2168-9830.1996.tb00221.x
   Romero C, 2007, EXPERT SYST APPL, V33, P135, DOI 10.1016/j.eswa.2006.04.005
   Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788
   Rubio-García R, 2007, COMPUT EDUC, V49, P615, DOI 10.1016/j.compedu.2005.11.005
   Sadeghi B, 2003, WIREL NETW, V9, P7, DOI 10.1023/A:1020820922326
   Sanxing Cao, 2008, 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Workshops, P591, DOI 10.1109/WIIAT.2008.399
   Schmidt A, 2001, IEEE PERS COMMUN, V8, P66, DOI 10.1109/98.944006
   Shin Y, 2010, P INT C INFORM SCI A, P1
   Shute V, 2003, EDUC PSYCHOL-US, V38, P105, DOI 10.1207/S15326985EP3802_5
   Strecher V J, 1999, J Natl Cancer Inst Monogr, P134
   Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485
   Terzi E, 2004, J SYST SOFTWARE, V73, P467, DOI 10.1016/j.jss.2003.09.020
   Tsai CW, 2009, PATTERN RECOGN LETT, V30, P653, DOI 10.1016/j.patrec.2009.02.003
   Tseng JCR, 2008, COMPUT EDUC, V51, P776, DOI 10.1016/j.compedu.2007.08.002
   Tsihrintzis G.A., 2008, New directions in intelligent interactive multimedia
   Vazirgiannis M, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P244, DOI 10.1109/MMCS.1997.609599
   Velusamy S, 2008, MULTIMEDIA SYST, V14, P73, DOI 10.1007/s00530-008-0117-1
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Weis G, 2008, IEEE C EVOL COMPUTAT, P1708, DOI 10.1109/CEC.2008.4631020
   Witten I.H., 1999, MOR KAUF D
   Wu YM, 2004, MULTIMEDIA SYST, V10, P41, DOI 10.1007/s00530-004-0136-5
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yan XH, 2010, COMPUT NETW, V54, P1848, DOI 10.1016/j.comnet.2010.02.006
   Yoo HW, 2007, MULTIMED TOOLS APPL, V34, P317, DOI 10.1007/s11042-007-0109-8
   Yu ZD, 2010, PATTERN RECOGN, V43, P1889, DOI 10.1016/j.patcog.2009.11.015
   Zaiane O.R., 1998, Proceedings of the 1998 conference of the Centre for Advanced Studies on Collaborative research, CASCON '98, P24
   Zappi P, 2009, ENTERTAIN COMPUT, V1, P75, DOI 10.1016/j.entcom.2009.09.005
   Zhang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1333
   Zhang Y, 2011, EXPERT SYST APPL, V38, P9036, DOI 10.1016/j.eswa.2011.01.041
   Zhao GS, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 2, P338, DOI 10.1109/ISISE.2008.94
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zheng YH, 2008, IEEE C EVOL COMPUTAT, P405, DOI 10.1109/CEC.2008.4630829
   Zhuo JC, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P781
   Zoric G, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1367
NR 164
TC 3
Z9 3
U1 0
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 137
EP 165
DI 10.1007/s11042-011-0957-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800008
DA 2024-07-18
ER

PT J
AU Indyk, W
   Kajdanowicz, T
   Kazienko, P
AF Indyk, Wojciech
   Kajdanowicz, Tomasz
   Kazienko, Przemyslaw
TI Relational large scale multi-label classification method for video
   categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-label classification; Relational learning; MapReduce;
   Classification in networks; Automated video categorization; Automated
   video tagging; Cloud computing; Parallel computing
AB The problem of automated video categorization in large datasets is considered in the paper. A new Iterative Multi-label Propagation (IMP) algorithm for relational learning in multi-label data is proposed. Based on the information of the already categorized videos and their relations to other videos, the system assigns suitable categories-multiple labels to the unknown videos. The MapReduce approach to the IMP algorithm described in the paper enables processing of large datasets in parallel computing. The experiments carried out on 5-million videos dataset revealed the good efficiency of the multi-label classification for videos categorization. They have additionally shown that classification of all unknown videos required only several parallel iterations.
C1 [Indyk, Wojciech; Kajdanowicz, Tomasz; Kazienko, Przemyslaw] Wroclaw Univ Technol, PL-50370 Wroclaw, Poland.
C3 Wroclaw University of Science & Technology
RP Kazienko, P (corresponding author), Wroclaw Univ Technol, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM wojciech.indyk@pwr.wroc.pl; tomasz.kajdanowicz@pwr.wroc.pl;
   kazienko@pwr.wroc.pl
RI Kajdanowicz, Tomasz/B-6269-2013; Kazienko, Przemysław/F-1849-2014;
   Kajdanowicz, Tomasz/ADC-6299-2022
OI Kazienko, Przemysław/0000-0001-5868-356X; Kajdanowicz,
   Tomasz/0000-0002-8417-1012
FU Polish National Center of Science; European Union within The European
   Social Fund; Wroclaw Networking and Supercomputing Center
   [POIG.02.03.00-00-028/08]
FX This work was partially supported by The Polish National Center of
   Science the research project 2011-2012, 2011-2014 and Fellowship
   co-financed by The European Union within The European Social Fund.; The
   authors are grateful to Wroclaw Networking and Supercomputing Center for
   granting access to the computing infrastructure built in the project No.
   POIG.02.03.00-00-028/08 "PLATON-Science Services Platform".
CR [Anonymous], 2000, Proc. AAAI-2000 Workshop on Learning Statistical Models from Relational Data
   [Anonymous], 1998, ACM SIGMOD RECORD, DOI DOI 10.1145/276305.276332
   [Anonymous], 1999, AAAI WORKSH TEXT LEA
   [Anonymous], 2005, Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM'05, DOI [DOI 10.1145/1099554.1099591, 10.1145/1099554.1099591]
   Azran A., 2007, P 24 INT C MACHINE L, P49
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Clare A, 2001, LNCS LNAI, P42, DOI [DOI 10.1007/3-540-44794-6_4, 10.1007/3-540-44794-6_4, DOI 10.1007/3-540-44794-6]
   Dean Jeffrey, 2004, OSDI 04, P10
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Fürnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605
   Indyk W, 2012, LECT NOTES ARTIF INT, V7267, P656, DOI 10.1007/978-3-642-29347-4_76
   Jung JJ, 2012, INFORM SCIENCES, V182, P30, DOI 10.1016/j.ins.2010.08.042
   Kajdanowicz T, 2012, INT J APPL IN PRESS
   Kazienko P, 2012, NEUROCOMPUTING, V75, P199, DOI 10.1016/j.neucom.2011.04.047
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Lin J, 1994, P 1994 IEEE S COMP B, P207
   Peters S, 2012, SOC NETW ANAL MIN, V2, P17, DOI 10.1007/s13278-011-0034-8
   Rao D., 2009, Proc. Workshop Graph-Based Methods Natural Language Process, P58
   Read J, 2008, P 2008 NZ COMP SCI R, V143150, P41
   Slattery S., 2000, PROC ICML00, P895
   Szummer M, 2001, P NEUR INF PROC SYST, V14
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Tsoumakas G, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P667, DOI 10.1007/978-0-387-09823-4_34
   Zhang ML, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, VOLS 1 AND 2, P718
NR 25
TC 13
Z9 14
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 63
EP 74
DI 10.1007/s11042-012-1149-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800005
OA hybrid
DA 2024-07-18
ER

PT J
AU Ekenel, HK
   Semela, T
AF Ekenel, Hazim Kemal
   Semela, Tomas
TI Multimodal genre classification of TV programs and YouTube videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genre classification; Content-based descriptors; Tag descriptors; TV
   programs; YouTube videos
AB This paper presents an automatic video genre classification system, which utilizes several low level audio-visual features as well as cognitive and structural information, and in case of web videos tag-based features, to classify the types of TV programs and YouTube videos. Classification is performed using an ensemble of support vector machines. The visual descriptors consist of color and texture-based features, which are often used to represent the concepts appearing in a video. The audio descriptors are signal energy, zero crossing rate, fundamental frequency, and mel-frequency cepstral coefficients representing a wide range of perceptual cues available in the audio signal. Cognitive descriptors correspond to the information derived from a face detector, whereas structural descriptors are related to shot editing of the video. Tag descriptor is used additionally for the genre classification of YouTube videos and it is based on term frequency-inverse document frequency measure. For each feature and type of genre a separate support vector machine classifier is trained following the one-vs-all scheme. The outputs of the classifiers are then combined to yield the final classification result. The proposed system is extensively evaluated using complete TV programs from Italian RAI TV channel, from a French TV channel, and videos from YouTube on which using only the audio-visual cues as well as cognitive and structural information, 99.2, 94.5 and 87.3% correct classification rates are attained, respectively. These results show that the developed system can reliably determine TV programs' genre. Incorporating tag feature to the content-based features increases the YouTube genre classification performance from 87.3 to 89.7%. Further experiments indicate that the quality of videos does not influence the results significantly. It is found that the performance drop in classifying genres of YouTube videos is mainly due to the large variety of content contained in these videos. In summary, this study shows that the proposed low level visual feature set, which we have used to represent the concepts appearing in a video, also provides robust cues for genre classification. In addition, obtained genre information is expected to provide additional cues which can be used to improve the concept detection system's performance. It has also been shown that ensemble of support vector machine classifiers outperforms neural network based classification proposed in the previous state-of-the-art genre classification systems (Montagnuolo and Messina, AIIA, LNAI 4733:730-741, 2007, Multimed Tools Appl 41(1):125-159, 2009). Besides the improvement in the employed feature set and classification scheme, the experimental framework of the study is exemplary with the extensive tests conducted on different domains ranging from TV programs from different countries to web videos.
C1 [Ekenel, Hazim Kemal; Semela, Tomas] KIT, Inst Anthropomat, Karlsruhe, Germany.
   [Ekenel, Hazim Kemal] KIT, Young Investigator Grp Facial Image Proc & Anal, Dept Comp Sci, Karlsruhe, Germany.
   [Semela, Tomas] KIT, Dept Comp Sci, Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology; Helmholtz
   Association; Karlsruhe Institute of Technology; Helmholtz Association;
   Karlsruhe Institute of Technology
RP Ekenel, HK (corresponding author), KIT, Inst Anthropomat, Karlsruhe, Germany.
EM ekenel@kit.edu; tomas.semela@student.kit.edu
RI EKENEL, HAZIM KEMAL/A-5293-2016
OI EKENEL, HAZIM KEMAL/0000-0003-3697-8548
FU OSEO, French State agency for innovation
FX The authors would like to thank Alberto Messina and Maurizio Montagnuolo
   from RAI Centre for Research and Technological Innovation for their
   contributions to the study and for providing the TV program data. The
   authors would also like to thank INA (French National Audiovisual
   Institute) for providing the corpus used in Quaero evaluations. This
   study is funded by OSEO, French State agency for innovation, as part of
   the Quaero Programme.
CR [Anonymous], P 17 ACM INT C MULT
   Borth D., 2009, P ACM MULT, P1111
   Campbell M, 2006, P NIST TRECVID WORKS
   Cao J, 2009, TECHNICAL REPORT
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Ekenel HK, 2007, P NIST TRECVID WORKS
   Ekenel HK, 2008, P NIST TRECVID WORKS
   Fischer Stephan., 1995, ACM MULTIMEDIA, V95, P295, DOI DOI 10.1145/217279.215283
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Messina A, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P117, DOI 10.1109/ICME.2008.4607385
   Montagnuolo M, 2007, LECT NOTES COMPUT SC, V4733, P730
   Montagnuolo M, 2009, MULTIMED TOOLS APPL, V41, P125, DOI 10.1007/s11042-008-0222-3
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Song Y, 2010, PROC CVPR IEEE, P871, DOI 10.1109/CVPR.2010.5540124
   Song Y, 2009, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INNOVATION AND MANAGEMENT, VOLS I AND II, P1113, DOI 10.1145/1631272.1631524
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Talkin D., 1995, Speech coding and synthesis, V495, P518
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JJ, 2006, INT C PATT RECOG, P778
   Wang ZS, 2010, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2010.5540125
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   YANG L., 2007, MIR, P265
NR 26
TC 19
Z9 19
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 547
EP 567
DI 10.1007/s11042-011-0923-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200012
DA 2024-07-18
ER

PT J
AU Van Lancker, W
   Van Deursen, D
   Verborgh, R
   Van de Walle, R
AF Van Lancker, Wim
   Van Deursen, Davy
   Verborgh, Ruben
   Van de Walle, Rik
TI Semantic media decision taking using N3logic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decision taking; Media selection; N3Logic; RDF; Rules
ID ADAPTATION; FRAMEWORK
AB In this paper, we introduce a media decision taking engine (MDTE), enabling the automatic selection and/or rating of multimedia content versions, based on the available context information. The presented approach is fully semantic-driven, which means that we not only semantically model the context information, but also the decision algorithms themselve, which are represented in N3 Rules, a rule language that extends RDF. The decision rules are based on a rating function, supporting the specification of weights and affinity parameters for each environment property. Finally, we show how the MDTE is integrated in a media delivery platform, using the provisions of the existing Web infrastructure.
C1 [Van Lancker, Wim; Van Deursen, Davy; Verborgh, Ruben; Van de Walle, Rik] Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Van Deursen, D (corresponding author), Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, Gaston Crommenlaan 8-201, B-9050 Ledeberg Ghent, Belgium.
EM davy.vandeursen@ugent.be
RI Verborgh, Ruben/P-6571-2014
OI Verborgh, Ruben/0000-0002-8596-222X
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), and the European Union.
CR Bamasak Omaima, 2011, International Journal of Information Technology, Communications and Convergence, V1, P173, DOI 10.1504/IJITCC.2011.039284
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Berners-Lee T, 2008, THEOR PRACT LOG PROG, V8, P249, DOI 10.1017/S1471068407003213
   De Roo J, 2012, EULER PROOF MECH
   De Roo J, 2010, EYE DEEP TAXONOMY BE
   Fielding R., 1999, RFC 2616, DOI DOI 10.17487/RFC2616
   Gearon P, 2011, SPARQL 1 1 IN PRESS
   Herranz L, 2007, MULTIMEDIA SYST, V13, P103, DOI 10.1007/s00530-007-0090-0
   Hutter A, 2005, P IEEE INT C IM PROC
   *ISO IEC, 2004, 2100072004 ISOIEC
   Klyne G, 2004, Resource description framework (RDF): Concepts and abstract syntax
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Köhncke B, 2007, MULTIMEDIA SYST, V13, P119, DOI 10.1007/s00530-007-0089-6
   Lee W, 2011, ONTOLOGY ME IN PRESS
   Liang W. Y., 2010, J CONVERGENCE, V1, P93
   López F, 2011, MULTIMED TOOLS APPL, V53, P181, DOI 10.1007/s11042-010-0507-1
   McGuinness D. L., 2004, OWL WEB ONTOLOGY LAN, DOI DOI 10.2004-03
   Mukherjee D, 2005, IEEE T MULTIMEDIA, V7, P454, DOI 10.1109/TMM.2005.846798
   Osmun T, 2010, EULER EYE INSTALLATI
   Prangl M, 2007, IEEE T CIRC SYST VID, V17, P719, DOI 10.1109/TCSVT.2007.896650
   Szwabe A., 2006, Journal of Zhejiang University (Science), V7, P63, DOI 10.1631/jzus.2006.AS0063
   Troncy R., 2011, MEDIA FRAGM IN PRESS
   Van Deursen D, 2010, IEEE INT CON MULTI, P1028, DOI 10.1109/ICME.2010.5582620
   Van Deursen D, 2010, MULTIMEDIA SYST, V16, P85, DOI 10.1007/s00530-009-0178-9
   Van Deursen D, 2010, MULTIMED TOOLS APPL, V46, P371, DOI 10.1007/s11042-009-0354-0
   Van Lancker W, 2011, P 2011 WORKSH MULT W
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P16, DOI 10.1109/MSP.2003.1184335
   Wai Yip Lum, 2002, IEEE Pervasive Computing, V1, P41, DOI 10.1109/MPRV.2002.1037721
   Wireless Application Protocol Forum, 2001, UAPROF US AG PROF SP
NR 29
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 7
EP 26
DI 10.1007/s11042-012-1032-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400002
DA 2024-07-18
ER

PT J
AU Ji, XH
   Zhang, CM
   Zhang, XF
AF Ji, Xiuhua
   Zhang, Caiming
   Zhang, Xuefen
TI An efficient joint implementation of three stages for fast computation
   of color space conversation in image coding/decoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint Implementation; Color space conversion; Quantization; DCT;
   Transform coding
ID TRANSFORM ALGORITHM; DCT
AB This paper proposes an efficient joint implementation algorithm for computing color space conversion, quantization and discrete cosine transform (DCT) in an image coder/decoder. By combining the three stages, the proposed algorithm reduces the operation amount of computing color space conversion considerably. In the case of color sampling 4:4:4, the proposed algorithm reduces the multiplication amount by 40% and the addition amount by 42% for the conversion from RGB to YCbCr in an image coder, and reduces the multiplication amount by 60% and the addition amount by 42% for the conversion from YCbCr to RGB in an image decoder. In the cases of down-sampling 4:2:2 and 4:1:1, there are the similar results. The existing fast methods in the literatures can still be applied together with this proposed algorithm into the implementation of the international image coding standards which use the transform coding technology, such as JPEG, MPEG and H.26X, and raises the image coding/decoding speed efficiently.
C1 [Ji, Xiuhua; Zhang, Caiming; Zhang, Xuefen] Shandong Econ Univ, Shandong Prov Key Lab Digital Media Technol, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
C3 Shandong University of Finance & Economics
RP Ji, XH (corresponding author), Shandong Econ Univ, Shandong Prov Key Lab Digital Media Technol, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
EM jane@sdu.edu.cn
RI Zhang, Caiming/AHD-6558-2022
OI Zhang, Caiming/0000-0002-6365-6221
FU national natural science foundation of China [60933008, 61073162];
   Shandong natural science foundation of China [ZR2009GL013]
FX This research is supported by the national natural science foundation of
   China (Key Program No. 60933008 and No. 61073162) and the Shandong
   natural science foundation of China (No. ZR2009GL013).
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2010, P 2010 INT S INFORM
   Arai Y., 1988, Transactions of the Institute of Electronics, Information and Communication Engineers E, VE71, P1095
   Bartkowiak M, 2001, EURASIP C DIG SIGN P
   Bensaali F, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P265
   Bensaali F., 2004, ICGST INT J GRAPHICS, V5, P37
   Bhaskaran V, 2003, IMAGE VIDEO COMPRESS
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Docef A, 2002, IEEE T IMAGE PROCESS, V11, P177, DOI 10.1109/83.988952
   Fan CP, 2006, IEEE T CIRCUITS-II, V53, P174, DOI 10.1109/TCSII.2005.858748
   FEIG E, 1992, IEEE T SIGNAL PROCES, V40, P2174, DOI 10.1109/78.157218
   Ji XH, 2009, INT J INNOV COMPUT I, V5, P689
   Ji XH, 2009, SCI CHINA SER F, V52, P215, DOI 10.1007/s11432-009-0038-4
   Latha P, 2005, XAPP283 XIL
   LEE BG, 1984, IEEE T ACOUST SPEECH, V32, P1243
   Lengwehasatit K, 2004, IEEE T CIRC SYST VID, V14, P1236, DOI 10.1109/TCSVT.2004.835151
   Leoffler C, 1989, P IEEE ICASSP, V2, P988, DOI 10.1109/ICASSP.1989.266596
   Liang J, 2001, IEEE T SIGNAL PROCES, V49, P3032, DOI 10.1109/78.969511
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Mihai S, 2002, P WORKSH CIRC SYST S, P465
   Mitchell J.L., 1997, MPEG VIDEO COMPRESSI
   Nguyen-Phi K, 1999, INT CONF ACOUST SPEE, P3197, DOI 10.1109/ICASSP.1999.757521
   Sima M, 2003, IEEE INT CONF ASAP, P250, DOI 10.1109/ASAP.2003.1212848
   Xiang Xiaoxuan, 2010, Proceedings 2010 3rd International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2010), P76, DOI 10.1109/ICINIS.2010.28
   Xue YL, 2002, ACTA ELECT SINICA, V32, P153
   Yang Y, 2007, IEEE T CONSUM ELECTR, V53, P1490, DOI 10.1109/TCE.2007.4429242
NR 26
TC 0
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 879
EP 893
DI 10.1007/s11042-011-0881-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500015
DA 2024-07-18
ER

PT J
AU Todorov, K
   James, N
   Hudelot, C
AF Todorov, Konstantin
   James, Nicolas
   Hudelot, Celine
TI Multimedia ontology matching by using visual and textual modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia search and retrieval; Ontology matching; Semantic gap;
   Semantic image annotation; Extensional and conceptual heterogeneity
ID IMAGE; DATABASE
AB Ontologies have been intensively applied for improving multimedia search and retrieval by providing explicit meaning to visual content. Several multimedia ontologies have been recently proposed as knowledge models suitable for narrowing the well known semantic gap and for enabling the semantic interpretation of images. Since these ontologies have been created in different application contexts, establishing links between them, a task known as ontology matching, promises to fully unlock their potential in support of multimedia search and retrieval. This paper proposes and compares empirically two extensional ontology matching techniques applied to an important semantic image retrieval issue: automatically associating common-sense knowledge to multimedia concepts. First, we extend a previously introduced textual concept matching approach to use both textual and visual representation of images. In addition, a novel matching technique based on a multi-modal graph is proposed. We argue that the textual and visual modalities have to be seen as complementary rather than as exclusive sources of extensional information in order to improve the efficiency of the application of an ontology matching approach in the multimedia domain. An experimental evaluation is included in the paper.
C1 [Todorov, Konstantin; James, Nicolas; Hudelot, Celine] Ecole Cent Paris, MAS Lab, F-92295 Chatenay Malabry, France.
C3 Universite Paris Saclay
RP Todorov, K (corresponding author), Ecole Cent Paris, MAS Lab, F-92295 Chatenay Malabry, France.
EM konstantin.get@gmail.com; nicolas.james@ecp.fr; celine.hudelot@ecp.fr
RI HUDELOT, CELINE/IRZ-2920-2023
OI HUDELOT, CELINE/0000-0003-3849-4133; Todorov,
   Konstantin/0000-0002-9116-6692
CR [Anonymous], 2004, COLING 2004 P 20 INT, DOI DOI 10.3115/1220355.1220517
   [Anonymous], P IEEE INT C IM VID
   [Anonymous], 2001, IJCAI
   [Anonymous], P CVPR
   Athanasiadis T, 2005, SEMANNOT 05
   Dasiopoulou S, 2008, LECT NOTES COMPUT SC, V5392, P31, DOI 10.1007/978-3-540-92235-3_5
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P1
   Doan A, 2002, P 11 INT C WORLD WID, P662, DOI [10.1145/511446.511532, DOI 10.1145/511446.511532]
   Euzenat J., 2007, ONTOLOGY MATCHING, DOI 10.1007/978-3-540-49612-0
   Fan J, 2009, ACM CIVR 09, P1
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   Hudelot C, 2005, SKCV WORKSH ICCV
   Hudelot C, 2008, FUZZY SET SYST, V159, P1929, DOI 10.1016/j.fss.2008.02.011
   Inoue M., 2004, P ACM SIGIR WORKSHOP, P44
   James N, 2010, IEEE INT CONF FUZZY
   Lacher M. S., 2001, Proceedings of the Fourteenth International Florida Artificial Intelligence Research Society Conference, P305
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Pan J, 2004, P 10 ACM SIGKDD INT, P658
   Peraldi ISE, 2009, DESCRIPTION LOGICS
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Tansley R, 1998, THESIS
   Todorov K, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS (CISIS 2010), P962, DOI 10.1109/CISIS.2010.59
   Tong HH, 2006, IEEE DATA MINING, P613
   Wang C, 2006, ACM MULTIMEDIA, P650
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Yang Y., 1997, ICML, V97, P412
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
NR 32
TC 2
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 401
EP 425
DI 10.1007/s11042-011-0912-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shi, ZP
   Liu, X
   Li, QY
   He, Q
   Shi, ZZ
AF Shi, Zhiping
   Liu, Xi
   Li, Qingyong
   He, Qing
   Shi, Zhongzhi
TI Extracting discriminative features for CBIR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2-class LDA; Image retrieval; Image classification; Discriminative
   features; LBP
ID LOCAL BINARY PATTERNS; RECOGNITION; RETRIEVAL; FRAMEWORK; LDA;
   CLASSIFICATION
AB Developing low-dimensional discriminative features is crucial for content-based image retrieval (CBIR). In this paper, we present a square symmetrical local binary pattern (SSLBP) texture descriptor, which is a compact symmetrical-invariant variation of local binary pattern (LBP), then we propose a merging 2-class linear discriminant analysis (M2CLDA) method to capture low-dimensional optimal discriminative features in the projection space. M2CLDA calculates discriminant vectors with respect to each class in the one-vs.-all classification scenario and then merges all the discriminant vectors to form a projection matrix. The dimensionality of the M2CLDA space fits in with the number of classes involved. Our experiments show that the SSLBP feature is an effective variation of LBP, and the M2CLDA approach improves the performance of image retrieval and image classification observably as compared with the existed LDA approaches and takes less computation complexity than the kernel discriminant analysis (KDA) methods.
C1 [Shi, Zhiping] Capital Normal Univ, Coll Informat Engn, Beijing Engn Res Ctr High Reliable Embedded Syst, Beijing 100048, Peoples R China.
   [Liu, Xi; He, Qing; Shi, Zhongzhi] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Li, Qingyong] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
C3 Capital Normal University; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Beijing Jiaotong University
RP Shi, ZP (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing Engn Res Ctr High Reliable Embedded Syst, Beijing 100048, Peoples R China.
EM shizhiping@gmail.com
RI shi, zhiping/J-9594-2012; He, Qing/C-1249-2013; Li,
   Qingyong/P-5250-2015; Li, Qingyong/GPK-0945-2022
OI Li, Qingyong/0000-0002-3860-4809; Shi, Zhiping/0000-0002-6401-5506; Shi,
   Zhiping/0000-0002-3562-8602
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], 1995, Applied Combinatorics
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BOUJEMAA N, 1999, 10 DELOS WORKSH AUD
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Ekenel H., 2007, Computer Vision and Pattern Recognition, 2007, P1
   Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jing F, 2005, IEEE T IMAGE PROCESS, V14, P979, DOI 10.1109/TIP.2005.847289
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li ZX, 2010, J VIS COMMUN IMAGE R, V21, P798, DOI 10.1016/j.jvcir.2010.06.004
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu Xi, 2010, ACM MM 10 OCT 25 29
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2004, PATTERN RECOGN, V37, P313, DOI 10.1016/S0031-3203(03)00231-0
   Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825
   Shi Zhi-Ping, 2005, Journal of Software, V16, P1039, DOI 10.1360/jos161039
   Shi ZP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P260, DOI 10.1109/ICICISYS.2009.5357682
   Shi ZP, 2009, MULTIMED TOOLS APPL, V42, P207, DOI 10.1007/s11042-008-0235-y
   SHI ZP, 2008, IEEE C IM SIGN PROC, P825, DOI DOI 10.1109/CISP.2008.258
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   You D, 2010, IEEE T PATTERN ANAL
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 34
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 263
EP 279
DI 10.1007/s11042-011-0836-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600001
DA 2024-07-18
ER

PT J
AU Li, Z
   Mao, X
AF Li, Zheng
   Mao, Xia
TI EEMML: the emotional eye movement animation toolkit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal interaction; Eye movement synthesis; Markup language; Virtual
   agents
AB Eye movement plays an important role in face to face communication in that it conveys nonverbal information and emotional intent beyond speech. Being "a window to the mind", the eye and its behavior are tightly coupled with human cognitive processes. In this paper, we proposed an Emotional Eye Movement Markup Language (EEMML) which is an emotional eye movement animation scripting tool that enables authors to describe and generate emotional eye movement in virtual agents. The language can describe eye movement parameters we derived from facial expression database as well as real-time eye movement data (pupil size, blink rate and saccade). EEMML provides the input for our eye movement generator system with one or more eye movement actions in sequence. The language is extensible, so that new rules can be quickly added. It is designed to plug into larger human-agent or agent-agent interaction systems. We present an evaluation in which subjects evaluated the EEMML and gave their feedback. The results indicate the validity of our approach.
C1 [Li, Zheng; Mao, Xia] Beihang Univ, Sch Elect & Informat Engn, Beijing, Peoples R China.
C3 Beihang University
RP Li, Z (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Beijing, Peoples R China.
EM buaa_david@yahoo.com.cn; moukyoucn@yahoo.com.cn
FU National Nature Science Foundation of China [60873269]; International
   Science and Technology Cooperation Program of China [2010DFA11990];
   Innovation Foundation of BUAA
FX This work is supported by the National Nature Science Foundation of
   China (No. 60873269), International Science and Technology Cooperation
   Program of China (No. 2010DFA11990) and Innovation Foundation of BUAA
   for PhD Graduates.
CR Balci Koray., 2004, AVI'04: Proceedings of the working conference on Advanced visual interfaces, P399
   BEARD S, 2002, P HF 02 WORKSH VIRT
   Bradley M.M., 1999, INT AFFECTIVE DIGITI
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184
   Damasio A., 1994, DESCARTESS ERROR EMO
   Faigin Gary, 1990, ARTISTS COMPLETE GUI
   GU E, 2007, P INT C INT VIRT AG, P193, DOI DOI 10.1007/11821830
   Ishizuka M, 2006, NEW GENERAT COMPUT, V24, P97, DOI 10.1007/BF03037295
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Kopp S, 2006, P IVA2006
   Lance B. J., 2008, AAMAS
   Lance Brent., 2007, 7th Int'l Conference on Intelligent Virtual Agemts (IVA), P72, DOI DOI 10.1007/978-3-540-74997
   Lang P. J., 1997, Technical Report A-8
   Li Z., 2009, Proceeding of ICMI-MLMI2009, P241, DOI [10.1145/1647314.1647367, DOI 10.1145/1647314.1647367]
   Mao X, 2008, P IVA2008, P289
   Mao X, 2010, STUD COMPUT INTELL, V289, P323
   MARRIOTT A, 2002, P AAMAS 02 WORKSH EC
   MPEG4, 2005, 14496 MPEG4 ISO IEC
   Ortony A., 1988, COGNITIVE STRUCTURE
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Raouzaiou A, 2002, EURASIP J APPL SIG P, V2002, P1021, DOI 10.1155/S1110865702206149
   Stamper R.K., 1996, Signs of Work
   Ullrich S, 2008, LECT NOTES COMPUT SC, V5208, P281
   Whissel C. M., 1989, EMOTION THEORY RES E
NR 26
TC 3
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 181
EP 201
DI 10.1007/s11042-011-0816-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500009
DA 2024-07-18
ER

PT J
AU Pham, TT
   Mulhem, P
   Maisonnasse, L
   Gaussier, E
   Lim, JH
AF Trong-Ton Pham
   Mulhem, Philippe
   Maisonnasse, Loic
   Gaussier, Eric
   Lim, Joo-Hwee
TI Visual graph modeling for scene recognition and mobile robot
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph theory; Information retrieval; Language model; Scene Recognition;
   Robot localization
ID SPATIAL RELATIONS
AB Image retrieval and categorization may need to consider several types of visual features and spatial information between them (e.g., different point of views of an image). This paper presents a novel approach that exploits an extension of the language modeling approach from information retrieval to the problem of graph-based image retrieval and categorization. Such versatile graph model is needed to represent the multiple points of views of images. A language model is defined on such graphs to handle a fast graph matching. We present the experiments achieved with several instances of the proposed model on two collections of images: one composed of 3,849 touristic images and another composed of 3,633 images captured by a mobile robot. Experimental results show that using visual graph model (VGM) improves the accuracies of the results of the standard language model (LM) and outperforms the Support Vector Machine (SVM) method.
C1 [Trong-Ton Pham] Grenoble Inst Technol, LIG, F-38400 Grenoble, France.
   [Maisonnasse, Loic] TecKnowMetrix, R&D Dept, Voiron, France.
   [Lim, Joo-Hwee] Comp Vis & Image Understanding Inst Infocomm Res, Connexis 138632, Singapore.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS); Agency for Science Technology & Research
   (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Pham, TT (corresponding author), Grenoble Inst Technol, LIG, 385 Av Bibliotheque, F-38400 Grenoble, France.
EM ttpham@imag.fr; mulhem@imag.fr; lm@tkm.fr; eric@imag.fr;
   joohwee@i2r.a-star.edu.sg
FU French National Agency of Research [ANR-06-MDCA-002]; French Embassy in
   Singapore
FX This work was supported by the French National Agency of Research
   (ANR-06-MDCA-002). Pham Trong-Ton would like to thank Merlion programme
   of the French Embassy in Singapore for their supports during his Ph.D
   study.
CR [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], 2007, P INT WORKSHOP WORKS
   [Anonymous], INTRO INFORM RETRIEV
   Boutell MR, 2007, IEEE T MULTIMEDIA, V9, P136, DOI 10.1109/TMM.2006.886372
   Chang YI, 2000, PATTERN RECOGN, V33, P1263, DOI 10.1016/S0031-3203(99)00115-6
   Chengxiang Zhai, 2001, SIGIR Forum, P334
   Chua TS, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P362, DOI 10.1109/MMCS.1997.609637
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Egenhofer M., 1991, A Framework for Definition of Topological Relationships and an Algebraic Approach to Spatial Reasoning within this Framework, NCGIA Technical Report 91-7
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gao S, 2006, P ICASSP TOUL FRANC, P377
   Han DF, 2008, MULTIMED TOOLS APPL, V39, P169, DOI 10.1007/s11042-008-0203-6
   Hironobu Y.M., 1999, Proceedings of First International Workshop on Multimedia Intelligent Storage and Retrieval Management, P405
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lim J, 2007, ICME 07
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maisonnasse L, 2007, SIGIR 07
   Maisonnasse L, 2009, LECT NOTES COMPUT SC, V5478, P240, DOI 10.1007/978-3-642-00958-7_23
   Mulhem P, 2006, INT J INF TECHNOL, V12, P74
   Ounis I., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P266, DOI 10.1145/290941.291007
   Papadopoulos GT, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/45842
   Pham TV, 2006, PATTERN RECOGN LETT, V27, P1673, DOI 10.1016/j.patrec.2006.03.016
   Pham TT, 2010, ACM SIGIR 10 GEN SWI
   Pham TT, 2009, CLEF WORKING NOTES 2
   Pham TT, 2010, 8 IEEE INT WORKSH CO
   Ponte J. M., 1998, SIGIR 98
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Song F, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P316, DOI 10.1145/319950.320022
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
NR 32
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 419
EP 441
DI 10.1007/s11042-010-0598-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400010
DA 2024-07-18
ER

PT J
AU Yu, H
   Qin, SF
   Sun, GM
   Wright, DK
AF Yu, Hui
   Qin, Shengfeng
   Sun, Guangmin
   Wright, David K.
TI On generating realistic avatars: dress in your own style
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D avatar; Avatar customization; Virtual dressing; Virtual world
ID INTERFACE
AB The use of 3D avatars is becoming more frequent with the development of computer technology and the internet. To meet users' requirements, some software or programs have allowed users to customize the avatar. However, users are only able to customize the avatar using the pre-defined accessories such as hair, clothing and so on. That is, users have limited chance to customize the avatar according to their own styles. It will be of interest to users if they are able to change the appearance of the avatar by their own design, such as creating garments for avatars themselves. This paper provides an easy solution to dressing realistic 3D avatars for non-professional users based on a sketch interface. After a user drawing a 2D garment profile around the avatar, the prototype system can generate an elaborate 3D geometric garment surface dressed on the avatar. The construction of the garment surface is constrained by key body features. And the garment shape is then optimized to remove artefacts. The proposed method can generate a uniform mesh for processing such as mesh refinement, 3D decoration and so on.
C1 [Yu, Hui; Qin, Shengfeng; Wright, David K.] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
   [Sun, Guangmin] Beijing Univ Technol, Sch Elect Informat & Control Engn, Beijing 830022, Peoples R China.
C3 Brunel University; Beijing University of Technology
RP Yu, H (corresponding author), Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
EM hui.yu@brunel.ac.uk; sheng.feng.qin@brunel.ac.uk; gmsun@bjut.edu.cn;
   david.wright@brunel.ac.uk
RI Yu, Hui/G-1115-2018
OI Yu, Hui/0000-0002-7655-9228; Qin, Shengfeng/0000-0001-8538-8136
FU Engineering and Physical Sciences Research Council, UK [EP/p501245];
   Beijing Municipal Commission of Education [KM200710005009,
   PXM2009_014204_09_000154]
FX This work is supported by Engineering and Physical Sciences Research
   Council, UK (EP/p501245) and partly supported by Projects of Beijing
   Municipal Commission of Education (KM200710005009 and
   PXM2009_014204_09_000154). The authors would like to thank all anonymous
   reviewers for their valuable comments. Thanks to Dr. Oliver G. B. Garrod
   for suggestions.
CR [Anonymous], KIN
   [Anonymous], GRAND THEFT AUT SAN
   [Anonymous], 2002, J ED TECHNOL SOC
   Bajaj CL, 1996, GRAPH MODEL IM PROC, V58, P524, DOI 10.1006/gmip.1996.0044
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bourguignon D, 2002, COMPUT GRAPH FORUM, V20, P114
   Breen D. E., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P365, DOI 10.1145/192161.192259
   Chen M, 2010, VISUAL COMPUT, V26, P853, DOI 10.1007/s00371-010-0467-5
   DiPaola S, 1999, SIGGR 99
   DiPaola S, 2002, P W COMP GRAPH S
   Fernando ONN, 2006, IEICE T INF SYST, VE89D, P73, DOI 10.1093/ietisy/e89-d.1.73
   Fuhrmann A, 2003, COMPUT GRAPH-UK, V27, P71, DOI 10.1016/S0097-8493(02)00245-5
   Half-Life Sierra Entertainment Inc, HALF LIF
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Igarashi T., 2002, PROC ACM S USER INTE, P91
   Igarashi T, 2010, COMMUN ACM, V53, P71, DOI 10.1145/1785414.1785436
   Kirkpatrick EM, 1983, CHAMBERS 20 CENTURY, P84
   Lawson CL, 1977, SOFTWARE, P161
   Linden Lab. Second Life, 2 LIF
   Loop C, 1987, THESIS U UTAH
   MEYERS D, 1992, ACM T GRAPHIC, V11, P228, DOI 10.1145/130881.131213
   Mullineux G, 2007, COMPUT AIDED DESIGN, V39, P27, DOI 10.1016/j.cad.2006.09.002
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PROVOT X, 1995, GRAPH INTER, P147
   RUPPERT J, 1995, J ALGORITHM, V18, P548, DOI 10.1006/jagm.1995.1021
   Sakaguchi Y., 1991, Transactions of Society of Electronics, Information and Communications, P25
   Salomon D., 1999, COMPUTER GRAPHICS GE, V1st
   Shewchuk J. R., 1996, LECT NOTES COMPUTER, P203, DOI DOI 10.1007/BFB0014497
   Shewchuk JR, 2002, COMP GEOM-THEOR APPL, V22, P21, DOI 10.1016/S0925-7721(01)00047-5
   Sorkine O, 2004, P EUR ACM SIGGRAPH S, V71
   Turquin E., 2004, PROC 1 EUROGRAPHICS, P175
   Turquin E, 2007, IEEE COMPUT GRAPH, V27, P72, DOI 10.1109/MCG.2007.1
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Volino P, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P109, DOI 10.1109/VSMM.1997.622337
   Vollmer J, 1999, COMPUT GRAPH FORUM, V18, pC131, DOI 10.1111/1467-8659.00334
   Wang CCL, 2003, COMPUT AIDED DESIGN, V35, P659, DOI 10.1016/S0010-4485(02)00091-X
   Yu H, 2008, IND INF 2008 INDIN 2, P1426
   Zorin D., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P189, DOI 10.1145/237170.237254
NR 38
TC 4
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 973
EP 990
DI 10.1007/s11042-011-0781-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900011
DA 2024-07-18
ER

PT J
AU Fang, MY
   Kuan, YH
   Kuo, CM
   Hsieh, CH
AF Fang, Min-Yuan
   Kuan, Yu-Hsin
   Kuo, Chung-Ming
   Hsieh, Chaur-Heh
TI Effective image retrieval techniques based on novel salient region
   segmentation and relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region-based image retrieval; Salient region segmentation; Relevance
   feedback; Quick-match algorithm
ID TOOL
AB This paper proposes an effective region-based image retrieval technique based on novel salient region segmentation and relevance feedback. With a good and fast segmentation technique, our system achieves an on-the-fly segmentation capability, which enables users to select particular regions for matching and feedbacks without waiting for image segmentation. Therefore, we adopt a relatively simple feedback schemes to derive the intent of the user. The experimental results show that the system performance is greatly improved with this capability. Furthermore, a Quick-match algorithm is also presented in this paper. The mechanism of the Quick-match algorithm is to exclude from distance computation regions that are of low possibility to be the top-Mmatches. This algorithm excludes most of regions from distance computation and therefore greatly cuts down the turnaround time of the retrieval with slightly degradation of precision.
C1 [Fang, Min-Yuan; Kuan, Yu-Hsin; Kuo, Chung-Ming] I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
   [Hsieh, Chaur-Heh] Ming Chung Univ, Dept Comp & Commun Engn, Tao Yuan 333, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
FU National Science Counsel of Republic of China [NSC. 97-2221-E-214-053-]
FX The authors would like to express their sincere thanks to the anonymous
   reviewers for their invaluable comments and suggestions. This work was
   supported by the National Science Counsel of Republic of China Granted
   NSC. 97-2221-E-214-053-
CR Brunelli R, 2000, IEEE T MULTIMEDIA, V2, P164, DOI 10.1109/6046.865481
   Carson C., 1999, 3 INT C VIS INF SYST
   Chiang CC, 2009, J VIS COMMUN IMAGE R, V20, P167, DOI 10.1016/j.jvcir.2009.01.001
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Dimai A., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P686, DOI 10.1109/ICIAP.1999.797674
   Hsu CT, 2005, IEEE T IMAGE PROCESS, V14, P1617, DOI 10.1109/TIP.2005.852202
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Jing F, 2004, IEEE T CIRC SYST VID, V14, P672, DOI 10.1109/TCSVT.2004.826775
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Ko B, 2005, IEEE T MULTIMEDIA, V7, P105, DOI 10.1109/TMM.2004.840603
   Kuan YH, 2008, IEEE T MULTIMEDIA, V10, P832, DOI 10.1109/TMM.2008.922853
   Kurita T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P547, DOI 10.1109/ICDAR.1993.395676
   Li CY, 2008, IEEE T MULTIMEDIA, V10, P447, DOI 10.1109/TMM.2008.917421
   Li F, 2008, IEEE T MULTIMEDIA, V10, P1592, DOI 10.1109/TMM.2008.2004914
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Mills Timothy J., SHOEBOX DIGITAL PHOT
   Niblack C.W., 1993, STORAGE RETRIEVAL IM
   O'Callaghan RJ, 2005, IEEE T IMAGE PROCESS, V14, P49, DOI 10.1109/TIP.2004.838695
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Pauwels EJ, 1999, COMPUT VIS IMAGE UND, V75, P73, DOI 10.1006/cviu.1999.0763
   Picard RW, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P777, DOI 10.1109/ICIP.1996.561018
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Smith JR, 1996, P 4 ACM INT C MULT A
   Torres JM, 2007, LECT NOTES COMPUT SC, V4398, P192
   Wang JZ, 1997, IEEE INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGY ADVANCES IN DIGITAL LIBRARIES - ADL'97 - PROCEEDINGS, P13, DOI 10.1109/ADL.1997.601196
   WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131
   Weng S-K, 2007, IEICE T INFORM SYSTE
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
NR 30
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 501
EP 525
DI 10.1007/s11042-010-0655-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900003
DA 2024-07-18
ER

PT J
AU Koch, A
   Dipanda, A
   Republique, CB
AF Koch, Alain
   Dipanda, Albert
   Republique, Claire Bourgeois
TI Evolutionary-based 3D reconstruction using an uncalibrated stereovision
   system: application of building a panoramic object view
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panoramic 3D reconstruction; Evolutionary algorithm; Uncalibrated system
ID FUNDAMENTAL MATRIX; GENETIC ALGORITHM; SCENE
AB In this paper, we propose an original evolutionary-based method for 3D panoramic reconstruction from an uncalibrated stereovision system (USS). The USS is composed of five cameras located on an arc of a circle around the object to be analyzed. The main originality of this work concerns the process of the calculation of the 3D information. Actually, with our method, 3D coordinates are directly obtained without any prior estimation of the fundamental matrix. The method operates in two steps. Firstly, points of interest are detected in pairs of images acquired by two consecutive cameras of the USS are matched. And secondly, using evolutionary algorithms, we jointly compute the transformed matrix between the two images and the respective depth of the points of interest. The accuracy of the proposed method is validated through a comparison with the depth values obtained using a traditional method. In order to perform 3D panoramic object reconstruction, the process is repeated for all the pairs of consecutive cameras. The 3D points thus obtained throughout the successive steps of the process which correspond to the different points of interest, are combined in order to obtain a set of 3D points all around the analyzed object.
C1 [Koch, Alain; Dipanda, Albert; Republique, Claire Bourgeois] Univ Bourgogne, Fac Sci, LE2I, F-21000 Dijon, France.
C3 Universite de Bourgogne
RP Republique, CB (corresponding author), Univ Bourgogne, Fac Sci, LE2I, Aile Ingenieur 9,Ave Alain Savary,BP 47870, F-21000 Dijon, France.
EM alain.koch@u-bourgogne.fr; adipanda@u-bourgogne.fr;
   claire.bourgeois-republique@u-bourgogne.fr
CR Alvarez L, 1997, INT J COMPUT VISION, V25, P95, DOI 10.1023/A:1007959616598
   [Anonymous], IEEE INT C ROB AUT
   [Anonymous], P 9 SCAND C ART INT
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Baker J.E., P INT C GEN ALG THEI, P101
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Bunschoten R, 2002, ROBOT AUTON SYST, V41, P111, DOI 10.1016/S0921-8890(02)00257-9
   Cantu-Paz E., 1992, Calc. Paralleles, V10, P141
   Dai ST, 2001, IEEE INT CONF ROBOT, P2165, DOI 10.1109/ROBOT.2001.932944
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   Dipanda A, 2003, PATTERN RECOGN, V36, P2143, DOI 10.1016/S0031-3203(03)00049-9
   FAUGERAS OD, 1987, P INT WORKSH MACH VI
   Fiala M, 2005, COMPUT VIS IMAGE UND, V98, P363, DOI 10.1016/j.cviu.2004.07.015
   Fleming PJ, 2002, CONTROL ENG PRACT, V10, P1223, DOI 10.1016/S0967-0661(02)00081-3
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Grossmann E, 2000, IMAGE VISION COMPUT, V18, P685, DOI 10.1016/S0262-8856(99)00072-4
   Harris C., 1988, ALVEY VISION C, P147151
   Hespanha JP, 1999, INT J COMPUT VISION, V35, P65, DOI 10.1023/A:1008111128520
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   Hua M, 2008, PATTERN RECOGN, V41, P575, DOI 10.1016/j.patcog.2007.06.016
   Jankó Z, 2006, ENG APPL ARTIF INTEL, V19, P269, DOI 10.1016/j.engappai.2005.10.002
   Knoll P, 2003, J PARALLEL DISTR COM, V63, P356, DOI 10.1016/S0743-7315(03)00019-4
   Koza JR, 1995, WESCON 95 - CONFERENCE RECORD, P589, DOI 10.1109/WESCON.1995.485447
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Mendonca P. R. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P500, DOI 10.1109/CVPR.1999.786984
   Menegatti E, 2010, ROBOT AUTON SYST, V58, P745, DOI 10.1016/j.robot.2010.02.006
   Meng Y, 2007, ROBOT CIM-INT MANUF, V23, P436, DOI 10.1016/j.rcim.2006.05.002
   STEFANO LD, 2002, IAPR CIPRS INT C VIS
   Wang ZG, 2005, PARALLEL COMPUT, V31, P839, DOI 10.1016/j.parco.2005.03.006
   Yang F., 2006, J MULTIMED, V1, P14
   Yin XM, 2003, PATTERN RECOGN, V36, P567, DOI 10.1016/S0031-3203(02)00072-9
   Zhang J, 2008, IMAGE VISION COMPUT, V26, P201, DOI 10.1016/j.imavis.2007.04.003
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 33
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 565
EP 586
DI 10.1007/s11042-010-0657-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900006
OA hybrid
DA 2024-07-18
ER

PT J
AU Debevc, M
   Kosec, P
   Holzinger, A
AF Debevc, Matjaz
   Kosec, Primoz
   Holzinger, Andreas
TI Improving multimodal web accessibility for deaf people: sign language
   interpreter module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Usability; Accessibility; Deaf and hard of
   hearing; Sign language; Video; Transparent video
ID USABILITY; CHILDREN
AB The World Wide Web is becoming increasingly necessary for everybody regardless of age, gender, culture, health and individual disabilities. Unfortunately, there are evidently still problems for some deaf and hard of hearing people trying to use certain web pages. These people require the translation of existing written information into their first language, which can be one of many sign languages. In previous technological solutions, the video window dominates the screen, interfering with the presentation and thereby distracting the general public, who have no need of a bilingual web site. One solution to this problem is the development of transparent sign language videos which appear on the screen on request. Therefore, we have designed and developed a system to enable the embedding of selective interactive elements into the original text in appropriate locations, which act as triggers for the video translation into sign language. When the short video clip terminates, the video window is automatically closed and the original web page is shown. In this way, the system significantly simplifies the expansion and availability of additional accessibility functions to web developers, as it preserves the original web page with the addition of a web layer of sign language video. Quantitative and qualitative evaluation has demonstrated that information presented through a transparent sign language video increases the users' interest in the content of the material by interpreting terms, phrases or sentences, and therefore facilitates the understanding of the material and increases its usefulness for deaf people.
C1 [Debevc, Matjaz; Kosec, Primoz] Univ Maribor, Fac Elect Engn & Comp Sci, SI-2000 Maribor, Slovenia.
   [Holzinger, Andreas] Med Univ Graz, Inst Med Informat, Res Unit HCI4MED, A-8036 Graz, Austria.
   [Holzinger, Andreas] Graz Univ Technol, Inst Informat Syst & Comp Media, A-8010 Graz, Austria.
C3 University of Maribor; Medical University of Graz; Graz University of
   Technology
RP Debevc, M (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova Ulica 17, SI-2000 Maribor, Slovenia.
EM matjaz.debevc@uni-mb.si
RI Holzinger, Andreas/E-9530-2010; Debevc, Matjaž/AAY-3715-2021
OI Holzinger, Andreas/0000-0002-6786-5194; Debevc,
   Matjaž/0000-0003-4638-7864
FU European Commission [DEAFVOC 2]; Slovenian Research Agency
FX The project is partially supported by the European Commission within the
   framework of the Lifelong Learning Programme, project DEAFVOC 2. It is
   also partially supported by the Slovenian Research Agency in the
   framework of the Science to Youth program which provides financial
   support to young researchers. Special thanks go to Petra Rezar from the
   Ljubljana School for the Deaf for her comments and suggestions while
   using the first prototype of the application, to the Association of the
   Deaf and Hard-Of- Hearing People of Podravje for their help in the
   evaluation of the application, as well as to Milan Rotovnik from
   University of Maribor for his work on transparency.
CR [Anonymous], 2007, HDB PARLIAMENTARIANS
   [Anonymous], P 8 ERCIM WORKSH US
   BANGHAM J, 2000, P IEE SEM SPEECH LAN
   Beskow J., 2008, TECHNOL DISABIL, V20, P97
   Brophy P, 2007, LIBR TRENDS, V55, P950
   CALDWELL B, WEB CONTENT ACCESSSI
   Cavender A, 2008, DISABIL REHABIL-ASSI, V3, P93, DOI 10.1080/17483100701343475
   CHISHOLM W, WEB CONTENT ACCESSSI
   Davis C.D., 1999, Career Development for Exceptional Individuals, V22, P267
   Debevc M, 2004, DISABIL REHABIL, V26, P1048, DOI 10.1080/09638280410001702441
   DEBEVC M, 2007, LNCS, V4556, P549
   *EBU, I442004 EBU
   ELLIOTT R, 2004, UNIVERSAL ACCESS INF, V6, P375
   Fajardo I, 2006, BEHAV INFORM TECHNOL, V25, P455, DOI 10.1080/01449290500331180
   FARWELL RM, 1976, AM ANN DEAF, V121, P19
   Fels DI, 2006, AM ANN DEAF, V151, P423, DOI 10.1353/aad.2006.0045
   Hanson VL, 2009, HUM FACTORS ERGON, P125
   HELLSTROM G, 1997, P 16 INT S HUM FACT
   Hermans D, 2008, J DEAF STUD DEAF EDU, V13, P518, DOI 10.1093/deafed/enn009
   Hilzensauer M, 2006, STUD COMP INTELL, V19, P183
   Holley MC, 2005, DRUG DISCOV TODAY, V10, P1269, DOI 10.1016/S1359-6446(05)03595-6
   HOLT JA, 1995, AM ANN DEAF, V140, P23, DOI 10.1353/aad.2012.0286
   Holzinger A, 2005, COMMUN ACM, V48, P71, DOI 10.1145/1039539.1039541
   Holzinger A, 2007, LECT NOTES COMPUT SC, V4554, P923
   Huenerfauth Matt, 2008, Universal Access in the Information Society, V6, P419, DOI 10.1007/s10209-007-0095-7
   Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114
   Kennaway JR, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1279700.1279705
   KRONREIF G, 2000, P 7 INT C COMP HELP
   Marschark M, 2000, J CHILD PSYCHOL PSYC, V41, P1067, DOI 10.1017/S0021963099006496
   Martini A, 1999, INT J PEDIATR OTORHI, V49, pS155
   Muir LJ, 2005, J DEAF STUD DEAF EDU, V10, P390, DOI 10.1093/deafed/eni037
   NIGAY L, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P172
   OLIVRIN GJL, 2007, P W3C VID WEB WORKSH
   Roberts VL, 2006, INT J HUM-COMPUT ST, V64, P489, DOI 10.1016/j.ijhcs.2005.11.001
   SHIEL B, 2006, REPORT HEAR IT
   SMITH C, 1995, TELEMATICS APPL ED T
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Stewart D., 1998, SIGN LANGUAGE INTERP
   *UN, 2006, GLOB AUD WEB ACC
   USKOV V, 2006, INT J ADV TECHNOLOGY, V3, P1
   VANDERHEIDEN GC, 1992, P RESNA INT C TOR
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   World Federation of the Deaf (WFD), 2003, Technical Report
NR 43
TC 37
Z9 44
U1 1
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 181
EP 199
DI 10.1007/s11042-010-0529-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100010
DA 2024-07-18
ER

PT J
AU Lee, S
   Son, S
   Kim, J
AF Lee, Seokhee
   Son, Seokho
   Kim, JongWon
TI Cost-effective haptic-based networked virtual environments with
   high-resolution tiled display
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic rendering; Graphic rendering; Networked virtual environment;
   Networked tiled display; Resource management; Stability
ID SYSTEM
AB In this paper, a haptic-based NVE (networked virtual environment) supporting high-resolution tiled display is proposed with a resource management scheme for future home applications such as a haptic-based networked game. Although NVEs with haptic interaction and immersive display have been developed in previous studies, they usually require expensive system configurations. In order to implement a cost-effective system, our proposed design includes a tiled display supporting high-resolution with several low-cost LCDs. The display nodes of the tiled display also have low processing and storage resource requirements because they only need to handle display-ready pixels received from the application node. The proposed resource management scheme, called as an object-based display scheme, reduces the resource requirements of the application node that would otherwise require significant resources to manage all the display nodes and to provide a user with haptic feedback. The proposed scheme segments graphic scenes into several pixelated virtual objects and assigns different frame rates to each object according to the interest of user. Experimental results confirm that the proposed scheme reduces the required network bandwidth and appropriately assigns the limited processing resources to graphic and haptic renderings for a high-level visual and haptic quality.
C1 [Lee, Seokhee; Kim, JongWon] GIST, Dept Informat & Commun, Networked Media Lab, Sch Informat & Mechatron, Kwangju, South Korea.
   [Son, Seokho] GIST, Dept Informat & Commun, Multiagent Syst Lab, Sch Informat & Mechatron, Kwangju, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Gwangju Institute of
   Science & Technology (GIST)
RP Kim, J (corresponding author), GIST, Dept Informat & Commun, Networked Media Lab, Sch Informat & Mechatron, Kwangju, South Korea.
EM shlee@nm.gist.ac.kr; shson@gist.ac.kr; jongwon@nm.gist.ac.kr
RI Son, Seokho/AAQ-6511-2020
OI Son, Seokho/0000-0002-9405-6878
FU MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center) [NIPA-2010-(C1090-1011-0004)]
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   support program supervised by the NIPA (National IT Industry Promotion
   Agency) NIPA-2010-(C1090-1011-0004)).
CR Allard J, 2002, P IEEE VIRT REAL ANN, P273, DOI 10.1109/VR.2002.996534
   ANDREWS S, 2006, FUTUREPLAY 06
   [Anonymous], IEEE WORLD HAPT
   Bailenson JN, 2008, MULTIMED TOOLS APPL, V37, P5, DOI 10.1007/s11042-007-0171-2
   Buck I., 2000, P ACM SIGGRAPH EUROG, P87, DOI DOI 10.1145/346876.348233
   Carson M, 2003, ACM SIGCOMM COMP COM, V33, P111, DOI 10.1145/956993.957007
   Cha J, 2006, IEEE T CONSUM ELECTR, V52, P477, DOI 10.1109/TCE.2006.1649668
   Chen H, 2001, COMPUT GRAPH-UK, V25, P811, DOI 10.1016/S0097-8493(01)00123-6
   Choi S, 2007, PRESENCE-TELEOP VIRT, V16, P263, DOI 10.1162/pres.16.3.263
   COLGATE JE, 1994, PROCEEDINGS OF THE 1994 AMERICAN CONTROL CONFERENCE, VOLS 1-3, P3236
   de Haan G, 2001, IEEE T CONSUM ELECTR, V47, P326, DOI 10.1109/30.964117
   Grant B, 1998, P IEEE VIRT REAL ANN, P81, DOI 10.1109/VRAIS.1998.658427
   Hashimoto N, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P361, DOI 10.1109/CW.2004.37
   Iwata H., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P16, DOI 10.1109/VRAIS.1993.378268
   Kahol K, 2008, MULTIMED TOOLS APPL, V37, P15, DOI 10.1007/s11042-007-0167-y
   Kim JP, 2010, INT J ROBOT RES, V29, P666, DOI 10.1177/0278364909338770
   KIM JY, 2005, P SPIE ITCOM 05 MULT, V8
   Lee KC, 2007, IEEE GLOBE WORK, P1
   LEE S, 2009, P ACM NETGAMES 09
   Lee S, 2009, COMPUT COMMUN, V32, P992, DOI 10.1016/j.comcom.2008.12.028
   Lee S, 2009, MULTIMEDIA SYST, V15, P355, DOI 10.1007/s00530-009-0170-4
   Lee Y, 2007, IEEE T CONSUM ELECTR, V53, P424, DOI 10.1109/TCE.2007.381711
   Lu X, 2008, COMPUT GRAPH-UK, V32, P561, DOI 10.1016/j.cag.2008.07.001
   NAM S, 2010, P ACM MULT SYST 10
   Navrátil PA, 2009, LECT NOTES COMPUT SC, V5876, P970, DOI 10.1007/978-3-642-10520-3_93
   NI T, 2006, P IEEE C VIRT REAL 0
   Niederauer C, 2003, ACM T GRAPHIC, V22, P700, DOI 10.1145/882262.882331
   Orozco M, 2008, MULTIMED TOOLS APPL, V37, P73, DOI 10.1007/s11042-007-0169-9
   OUHYOUNG M, 1995, IEEE T CONSUM ELECTR, V41, P787, DOI 10.1109/30.468083
   RAMANATHAN S, 1992, IEEE T CONSUM ELECTR, V38, P70, DOI 10.1109/30.142861
   RENAMBOT L, 2000, FUTURE GENER COMPUT, V25, P161
   RENAMBOT L, 2004, P WORKSH ADV COLL EN
   Singhal S., 1999, Networked Virtual Environments
   Wen K, 2008, MULTIMED TOOLS APPL, V37, P39, DOI 10.1007/s11042-007-0172-1
NR 34
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 365
EP 384
DI 10.1007/s11042-010-0535-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700008
DA 2024-07-18
ER

PT J
AU Anantrasirichai, N
   Canagarajah, NC
   Redmill, DW
   Akbari, AS
   Bull, DR
AF Anantrasirichai, Nantheera
   Canagarajah, Nishan C.
   Redmill, David W.
   Akbari, Akbar Sheikh
   Bull, David R.
TI Colour volumetric compression for realistic view synthesis applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view image; Volumetric representation; View synthesis; Residual
   coding
AB Colour volumetric data, which is constructed from a set of multi-view images, is capable of providing realistic immersive experience. However it is not widely applicable due to its manifold increase in bandwidth. This paper presents a novel framework to achieve scalable volumetric compression. Based on wavelet transformation, data rearrangement algorithm is proposed to compact volumetric data leading to high efficiency of transformation. The colour data is rearranged using the characteristics of human visual system. A pre-processing scheme for adaptive resolution is also proposed in this paper. The low resolution overcomes the limitation of the data transmission at low bitrates, whilst the fine resolution improves the quality of the synthesised images. Results show significant improvement of the compression performance over the traditional 3D coding. Finally, effect of using residual coding is investigated in order to show a trade off between the compression and view synthesis performance.
C1 [Anantrasirichai, Nantheera; Canagarajah, Nishan C.; Redmill, David W.; Akbari, Akbar Sheikh; Bull, David R.] Univ Bristol, Bristol BS8 1UB, Avon, England.
C3 University of Bristol
RP Anantrasirichai, N (corresponding author), Univ Bristol, Woodland Rd, Bristol BS8 1UB, Avon, England.
EM N.Anantrasirichai@bristol.ac.uk
RI Sheikh-Akbari, Akbar/AAA-7302-2022
OI Sheikh-Akbari, Akbar/0000-0003-0677-7083
CR ABOUSLEMAN GP, 1995, IEEE T GEOSCI REMOTE, V33, P26, DOI 10.1109/36.368225
   Ahn JH, 2006, IEEE T CIRC SYST VID, V16, P291, DOI 10.1109/TCSVT.2005.861945
   ANANTRASIRICHAI N, 2006, INT CONF ACOUST SPEE, pA269
   ANANTRASIRICHAI N, 2006, IEEE P ICASSP 06, V2, P269
   ANANTRASIRICHAI N, 2007, THESIS U BRISTOL
   BEARDSLEY P, 1996, EUR C COMP VIS, P683
   Deering M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P13, DOI 10.1145/218380.218391
   Eisert P, 2000, IEEE T CIRC SYST VID, V10, P261, DOI 10.1109/76.825726
   GAO Y, 2005, IEEE P ICIP, V2, P257
   Gargallo P, 2005, PROC CVPR IEEE, P885
   *ISO IEC, 2000, 154441 ISOIEC JTC1SC
   *ISO IEC, 2004, 154442 ISOIEC JTC1SC
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Kim CS, 2002, IEEE T IMAGE PROCESS, V11, P932, DOI 10.1109/TIP.2002.800891
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Magnor M, 2003, IEEE T CIRC SYST VID, V13, P1092, DOI 10.1109/TCSVT.2003.817630
   RODLER FF, 1999, IEEE P 7 PAC C COMP, P108
   Schelkens P, 2003, IEEE T MED IMAGING, V22, P441, DOI 10.1109/TMI.2003.809582
   Schelkens P, 2006, IEEE INT SYMP CIRC S, P3874, DOI 10.1109/ISCAS.2006.1693474
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TZANNES A, 2003, JPEG 2000 2
   Xiong ZX, 2003, IEEE T MED IMAGING, V22, P459, DOI 10.1109/TMI.2003.809585
   Xu JZ, 2001, APPL COMPUT HARMON A, V10, P290, DOI 10.1006/acha.2000.0345
NR 23
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 25
EP 51
DI 10.1007/s11042-010-0484-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700002
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Tsai, MJ
AF Tsai, Min-Jen
TI Wavelet tree based digital image watermarking by adopting the chaotic
   system for security enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Wavelet-tree quantization
ID DIFFERENTIAL ENERGY WATERMARKING; CRYPTANALYSIS; QUANTIZATION; TRANSFORM
AB Wavelet tree based watermarking algorithms are generally using the wavelet coefficient energy difference for copyright protection and ownership verification. Since there are cryptanalysis-based methods addressed for successfully attacking wavelet tree based watermarking algorithm of wavelet tree quantization (WTQ), it is the motivation in this research to devise a scheme to improve WTQ's robustness. Furthermore, the combination of wavelet tree based watermarking techniques, chaotic system for block based scrambling techniques have not been seen or few discussed in the literatures. The study in this paper has presented such research findings and contribution for the academic and industry fields. Therefore, a chaotic system is adopted for WTQ to counteract the attacks in this paper. The digital image is first split into many blocks and the chaotic system is applied to scramble the image before the implementation of WTQ. The experimental results demonstrate the effectiveness of using chaotic system to enhance the security of WTQ, especially, to resist cryptanalysis attack. In addition, such mechanism also works for other advanced wavelet tree based algorithms like wavelet tree group modulation (WTGM) and dynamic energy enabled differentiation (called DEED) watermarking techniques.
C1 Natl Chiao Tung Univ, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Hsinchu, Taiwan.
EM mjtsai@cc.nctu.edu.tw
FU National Science Council in Taiwan, Republic of China
   [NSC96-2416-H009-015, NSC97-2410-H009-034, 99-2918-1-009-008]
FX The author would like to thank the anonymous reviewers with their
   valuable comments to improve the quality of this manuscript. This work
   is partially supported by the National Science Council in Taiwan,
   Republic of China, under Grant NSC96-2416-H009-015, NSC97-2410-H009-034
   and 99-2918-1-009-008.
CR [Anonymous], 1883, Journal des sciences militaires
   [Anonymous], USC SIPI IM DAT
   [Anonymous], Stirmark
   BATTISTI F, 2007, INT WORKSH NONL SIGN, P15
   Cox IJ, 1998, IEEE J SEL AREA COMM, V16, P587, DOI 10.1109/49.668980
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das TK, 2004, LECT NOTES COMPUT SC, V3326, P219
   Das TK, 2005, IEEE T SIGNAL PROCES, V53, P768, DOI 10.1109/TSP.2004.839930
   He ZH, 2007, IEEE T IMAGE PROCESS, V16, P1741, DOI 10.1109/TIP.2007.896599
   Kalker T, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P201, DOI 10.1109/MMSP.2001.962734
   Kok CW, 1998, IEEE T SIGNAL PROCES, V46, P2041, DOI 10.1109/78.700978
   KUNDUR D, 1998, P IEEE ICASSP, V5, P2869
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Rao S, 1996, IEEE T INFORM THEORY, V42, P1160, DOI 10.1109/18.508839
   Saha S, 2000, IEEE SIGNAL PROC LET, V7, P104, DOI 10.1109/97.841153
   SAHA S, 1999, P IEEE IECON 99, V2, P559
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Tsai MJ, 2008, IEICE T FUND ELECTR, VE91A, P1961, DOI 10.1093/ietfec/e91-a.8.1961
   Tsai MJ, 2007, INT CONF ACOUST SPEE, P173
   Tsai MJ, 2000, IEEE T CONSUM ELECTR, V46, P241
   TSAI MJ, 2009, MULTIMEDIA IN PRESS
   Voyatzis G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P237, DOI 10.1109/ICIP.1996.560753
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   ZOU J, 2004, ACOUSTICS SPEECH SIG, V3, P385
NR 25
TC 6
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 347
EP 367
DI 10.1007/s11042-010-0475-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000007
DA 2024-07-18
ER

PT J
AU Kalva, H
   Colic, A
   Garcia, A
   Furht, B
AF Kalva, Hari
   Colic, Aleksandar
   Garcia, Adriana
   Furht, Borko
TI Parallel programming for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel programming; OpenMP; CUDA; SIMD; Multimedia programming
ID EXTENSION
AB Computing capabilities are continuing to increase with the availability of multi core and many core processors. The wide availability of multi core processors has made parallel programming possible for end user applications running on desktops, workstations, and mobile devices. While parallel hardware has become common, software that exploits parallel capabilities is just beginning to take hold. Multimedia applications, with their data parallel nature and large computing requirements will benefit significantly from parallel programming. In this paper an overview of parallel programming is presented and languages and tools for parallel programming such as OpenMP and CUDA are introduced within the scope of multimedia applications.
C1 [Kalva, Hari; Colic, Aleksandar; Garcia, Adriana; Furht, Borko] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Kalva, H (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM hari@cse.fau.edu
OI Kalva, Hari/0000-0002-7165-5499
CR [Anonymous], 2008, IRPTR0805
   [Anonymous], 2004, P OSDI 04 6 S OP SYS
   [Anonymous], 2007, NY TIMES
   [Anonymous], 2007, Using OpenMP: Portable Shared Memory Parallel Programming
   [Anonymous], CUSTOMIZING INPUT FI
   Asanovic K, 2009, COMMUN ACM, V52, P56, DOI 10.1145/1562764.1562783
   Borkar S, 2007, DES AUT CON, P746, DOI 10.1109/DAC.2007.375263
   Bulic P, 2003, INT J PARALLEL PROG, V31, P107, DOI 10.1023/A:1022617308483
   Chantry D., 2009, Mapping applications to the cloud
   Colic Aleksandar., 2010, Proceedings of the first annual ACM SIGMM conference on Multimedia systems, MMSys'10, pages, P13
   CONTE G, 2000, P 5 IEEE INT WORKSH, P249
   Diefendorff K, 2000, IEEE MICRO, V20, P85, DOI 10.1109/40.848475
   Ferretti M, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P249, DOI 10.1109/CAMP.2000.875984
   GARCIA A, 2010, P WORKSH MOB CLOUD M
   *HP LABS, VID TOON
   Hwu W.-m, 2016, Programming Massively Parallel Processors: A Hands-On Approach
   Krall A, 2000, INT J PARALLEL PROG, V28, P347, DOI 10.1023/A:1007507005174
   LEE JB, 2009, VC I H 264 VIDEO COM
   Lee RB, 1996, IEEE MICRO, V16, P51, DOI 10.1109/40.526925
   LEUPERS R, 1999, BUSINESS WORK INFORM
   Luebke David., 2004, GRAPH 04, P33, DOI [10.1145/ 1103900.1103933, DOI 10.1145/1103900.1103933]
   Peleg A, 1996, IEEE MICRO, V16, P42, DOI 10.1109/40.526924
   TREASE H, USING T BASED PARALL
   Tremblay M, 1996, IEEE MICRO, V16, P10, DOI 10.1109/40.526921
   MAP REDUCE TUTORIAL
NR 25
TC 9
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 801
EP 818
DI 10.1007/s11042-010-0656-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300016
DA 2024-07-18
ER

PT J
AU Dasiopoulou, S
   Kompatsiaris, I
   Strintzis, MG
AF Dasiopoulou, Stamatia
   Kompatsiaris, Ioannis
   Strintzis, Michael G.
TI Investigating fuzzy DLs-based reasoning in semantic image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy reasoning; Semantic image analysis; Semantic integration; Fuzzy
   DLs; Inconsistency handling
ID KNOWLEDGE REPRESENTATION; ANNOTATION; RETRIEVAL
AB Recent advances in semantic image analysis have brought forth generic methodologies to support concept learning at large scale. The attained performance however is highly variable, reflecting effects related to similarities and variations in the visual manifestations of semantically distinct concepts, much as to the limitations issuing from considering semantics solely in the form of perceptual representations. Aiming to enhance performance and improve robustness, we investigate a fuzzy DLs-based reasoning framework, which enables the integration of scene and object classifications into a semantically consistent interpretation by capturing and utilising the underlying semantic associations. Evaluation with two sets of input classifiers, configured so as to vary with respect to the wealth of concepts' interrelations, outlines the potential of the proposed approach in the presence of semantically rich associations, while delineating the issues and challenges involved.
C1 [Dasiopoulou, Stamatia; Kompatsiaris, Ioannis; Strintzis, Michael G.] Ctr Res & Technol Hellas, Informat & Telemat Inst, Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas
RP Dasiopoulou, S (corresponding author), Ctr Res & Technol Hellas, Informat & Telemat Inst, Thessaloniki, Greece.
EM dasiop@iti.gr; ikom@iti.gr; strintzis@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Dasiopoulou,
   Stamatia/0000-0003-2831-7459
FU European Commission [FP6-001765, FP6-507482, FP7-215453]
FX This work was partially supported by the European Commission under
   contracts FP6-001765 aceMedia, FP6-507482 KnowledgeWeb and FP7-215453
   WeKnowIt.
CR [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P IEEE INT C SEM COM
   [Anonymous], RC23612W0505104 IBM
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060
   Baader F., 2003, DESCRIPTION LOGIC HD
   Bechhofer S., 2004, W3C recommendation
   Bell D, 2007, LECT NOTES COMPUT SC, V4806, P1303
   Bobillo F, 2008, IEEE INT CONF FUZZY, P923, DOI 10.1109/FUZZY.2008.4630480
   Brickley D., 2004, RDF VOCABULARY DESCR
   Crevier D, 1997, COMPUT VIS IMAGE UND, V67, P161, DOI 10.1006/cviu.1996.0520
   Dubois D, 2001, ANN MATH ARTIF INTEL, V32, P35, DOI 10.1023/A:1016740830286
   ELFERS C, 2008, LOGIC B PROBABILTY S
   ESPINOSA S, 2007, P INT WORKSH DESCR L
   Haase P, 2005, LECT NOTES COMPUT SC, V3729, P353, DOI 10.1007/11574620_27
   Haase Peter, 2007, INT WORKSH ONT DYN, P97
   Hanjalic A, 2008, P IEEE, V96, P541, DOI 10.1109/JPROC.2008.916338
   Hauptmann Alexander., 2007, CIVR 07, P627
   Hunter J, 2004, IEEE INTELL SYST, V19, P40, DOI 10.1109/MIS.2004.1265884
   KALYANPUR A, 2006, P 3 EUR SEM WEB C ES, P170
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Lam JSC, 2008, LECT NOTES COMPUT SC, V4900, P62
   Le Borgne H, 2007, IEEE T CIRC SYST VID, V17, P286, DOI 10.1109/TCSVT.2007.890635
   LITTLE S, 2004, INT SEM WEB C ISWC H, P534
   Moller R., 1999, Proceedings Integration of Speech and Image Understanding, P101, DOI 10.1109/ISIU.1999.824868
   MOOSMANN F, 2006, NEURAL INFORM PROCES
   MYLONAS P, 2007, KNOWL ACQ MULT CONT
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Naphade MR, 2002, IEEE T NEURAL NETWOR, V13, P793, DOI 10.1109/TNN.2002.1021881
   NATSEV A, 2008, P TREC VID RETR WORK
   NEUMANN B, 2008, DAGSTUHL SEMINAR P
   NEUMANN B, 2004, FBIB25704
   Neumann B, 2008, IMAGE VISION COMPUT, V26, P82, DOI 10.1016/j.imavis.2007.08.013
   NIEMANN H, 1990, IEEE T PATTERN ANAL, V12, P883, DOI 10.1109/34.57683
   Papadopoulos GT, 2006, INT J SEMANT WEB INF, V2, P17, DOI 10.4018/jswis.2006070102
   Petridis K, 2006, IEE P-VIS IMAGE SIGN, V153, P255, DOI 10.1049/ip-vis:20050059
   RAO AR, 1988, IEEE EXPERT, V3, P64, DOI 10.1109/64.2096
   REITER R, 1989, ARTIF INTELL, V41, P125, DOI 10.1016/0004-3702(89)90008-8
   Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1
   SCHOBER JP, 2004, P KI 2004 WORKSH APP
   SIMOU N, 2007, 2 INT WORKSH SEM MED
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SNOEK C, 2008, THEMEDIAMILL TRECVID
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   STOILOS G, 2005, INT WORKSH UNC REAS
   Stoilos G., 2006, P INT WORKSH DESCR L
   Stoilos G, 2007, J ARTIF INTELL RES, V30, P273, DOI 10.1613/jair.2279
   Straccia U, 2004, LECT NOTES COMPUT SC, V3229, P385, DOI 10.1007/978-3-540-30227-8_33
   Straccia U, 2001, J ARTIF INTELL RES, V14, P137, DOI 10.1613/jair.813
   Straccia U., 2006, FUZZY LOGIC SEMANTIC, P73, DOI 10.1016/S1574-9576(06)80006-7
   TOWN C, 2003, INT C COMP VIS SYST, P54
   UMBERTO S, 2007, P INT WORKSH DESCR L
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 53
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 167
EP 194
DI 10.1007/s11042-009-0393-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600009
DA 2024-07-18
ER

PT J
AU Yuan, HD
   Ma, HD
   Huang, XD
AF Yuan, Haidong
   Ma, Huadong
   Huang, Xiaodong
TI Automatic detection and restoration of frame pixel-shift in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel-shift; Defect detection and restoration; Content management
AB Defect detection and restoration of degraded videos is an important topic in media content management systems. Frame pixel-shift is a common form of severe defect in videos caused by loss of consecutive pixels by the video transmission system. Pixel-shift refers to the large amount of pixel shifts one by one due to a small quantity of image data loss. The damaged region in the affected frame is usually quite large, causing serious degradation of visual quality. This paper addresses the issue of how to automatically detect and restore frame pixel-shift in videos. Pixel-shift frame detection relies on spatio-temporal information and motion estimation. Accurate measurement of pixels shift is achieved based on the analysis of temporal frequency information and restoration is accomplished by reversing the pixels shift and spatio-temporal interpolation. Performance evaluation using real video sequences demonstrate the good performance of our algorithm.
C1 [Yuan, Haidong; Ma, Huadong; Huang, Xiaodong] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
   [Yuan, Haidong] Univ Informat Engn, Inst Elect Technol, Zhengzhou 450004, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ma, HD (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM authoryhd@msn.com; mhd@bupt.edu.cn
RI Chen, John/GPW-8839-2022
FU National Natural Science Foundation of China [60833009]; National High
   Technology Research and Development Program of China [2009AA01Z305];
   Cosponsored Project of Beijing Committee of Education [SYS100130422];
   111 Project [B08004]
FX The authors would like to thank the reviewers for their thorough
   comments and suggestions that helped to improve this paper. The work
   reported in this paper is supported by the National Natural Science
   Foundation of China under Grant No. 60833009, the National High
   Technology Research and Development Program of China under Grant No.
   2009AA01Z305, the Cosponsored Project of Beijing Committee of Education
   under Grant No. SYS100130422 and the 111 Project under Grant No. B08004.
CR BERNARD C, 1999, R1415 CTR MATH APPL
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bruni V, 2004, IEEE T IMAGE PROCESS, V13, P44, DOI 10.1109/TIP.2003.817231
   Corrigan D, 2004, INT C PATT RECOG, P779, DOI 10.1109/ICPR.2004.1333888
   CORRIGAN D, 2004, 2004 IEEE INT C IM P, V3, P1823, DOI DOI 10.1109/ICIP.2004.1421430
   Corrigan D, 2007, IEEE IMAGE PROC, P557, DOI 10.1109/ICIP.2007.4379015
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Kokaram AC, 2004, IEEE T IMAGE PROCESS, V13, P395, DOI 10.1109/TIP.2004.823815
   Kokaram AC, 2002, IEEE T SIGNAL PROCES, V50, P189, DOI 10.1109/78.978375
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1509, DOI 10.1109/83.469932
   KOMATSU T, 1999, 1999 IEEE INT C IM P, V3, P479, DOI DOI 10.1109/ICIP.1999.817160
   MATSUSHITA Y, 2005, 2005 IEEE INT C COMP, V1, P50, DOI DOI 10.1109/CVPR.2005.166
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   PETER K, 2003, AUSTR PATT REC SOC C, P309
   Schallauer P, 2006, IEEE IMAGE PROC, P413, DOI 10.1109/ICIP.2006.312481
   Shih TK, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P477, DOI 10.1109/ICME.2006.262576
   Tenze L, 2002, IEEE SIGNAL PROC LET, V9, P309, DOI 10.1109/LSP.2002.803410
   Vlachos T, 2004, IEEE T CIRC SYST VID, V14, P508, DOI 10.1109/TCSVT.2004.825559
NR 19
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2010
VL 47
IS 2
BP 307
EP 323
DI 10.1007/s11042-009-0324-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 576IY
UT WOS:000276139000005
DA 2024-07-18
ER

PT J
AU Burlamaqui, AMF
   Azevedo, SO
   Dantas, RR
   Schneider, CA
   Xavier, JS
   Melo, JCP
   Gonçalves, LMG
   Filho, GLS
   de Oliveira, JC
AF Burlamaqui, Aquiles M. F.
   Azevedo, Samuel O.
   Dantas, Rummenigge Rudson
   Schneider, Claudio A.
   Xavier, Josivan S.
   Melo, Julio C. P.
   Goncalves, Luiz M. G.
   Filho, Guido L. S.
   de Oliveira, Jauvane C.
TI The H-N2N framework: towards providing interperception in massive
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Massive interaction; Multi-user gaming; Accessibility; Interperception
AB We propose a framework with a flexible architecture that have been designed and implemented for collaborative interaction of users, to be applied in massive applications through the Web. We introduce the concept of interperception and use technologies as massive virtual environments and teleoperation for the creation of environments (mixing virtual and real ones) in order to promote accessibility and transparency in the interaction between people, and between people and animate devices (such as robots) through the Web. Experiments with massive games, with interactive applications in digital television, with users and robots interacting in virtual and real versions of museums and cultural centers are presented to validate our proposal.
C1 [Burlamaqui, Aquiles M. F.; Azevedo, Samuel O.; Dantas, Rummenigge Rudson; Schneider, Claudio A.; Xavier, Josivan S.; Melo, Julio C. P.; Goncalves, Luiz M. G.] Univ Fed Rio Grande do Norte, ECT UFRN, BR-59072970 Natal, RN, Brazil.
   [Filho, Guido L. S.] Univ Fed Paraiba, LAVID DI UFPB, BR-58059900 Joao Pessoa, Paraiba, Brazil.
   [de Oliveira, Jauvane C.] Natl Lab Sci Comp, LNCC CCC, BR-25651075 Rio De Janeiro, Brazil.
C3 Universidade Federal do Rio Grande do Norte; Universidade Federal da
   Paraiba; Laboratorio Nacional de Computacao Cientifica (LNCC)
RP Burlamaqui, AMF (corresponding author), Univ Fed Rio Grande do Norte, ECT UFRN, Campus Univ, BR-59072970 Natal, RN, Brazil.
EM aquilesburlamaqui@gmail.com
RI Gonçalves, Luiz Marcos Garcia/C-3786-2009; de Oliveira, Jauvane
   C./Q-8242-2019; Macc, Inct/K-3440-2013; de Souza Filho, Guido
   Lemos/AAD-1048-2019
OI Gonçalves, Luiz Marcos Garcia/0000-0002-7735-5630; de Oliveira, Jauvane
   C./0000-0002-7522-7846; de Souza Filho, Guido Lemos/0000-0001-5834-5237;
   Burlamaqui, Aquiles/0000-0001-6754-8335; Dantas,
   Rummenigge/0000-0001-9486-6574
FU CNPq; FAPERJ; Brazilian Research Sponsoring Agencies; RNP; National
   Research Network, Brazil; GT-MV
FX We acknowledge financial support from CNPq and FAPERJ, Brazilian
   Research Sponsoring Agencies, and from RNP, the National Research
   Network, sponsor of the GT-MV Project.
CR Agrawal D, 2005, SIXTH IEEE INTERNATIONAL WORKSHOP ON POLICIES FOR DISTRIBUTED SYSTEMS AND NETWORKS, PROCEEDINGS, P223, DOI 10.1109/POLICY.2005.25
   [Anonymous], VLNET NETWORKED VIRT
   [Anonymous], 1996, FORCE TOUCH FEEDBACK
   [Anonymous], PROFESSIONAL COMPUTI
   [Anonymous], 1995, ACM Transactions on Computer-Human Interaction (TOCHI), DOI DOI 10.1145/210079.210088
   AZEVEDO S, 2006, IEEE INT C VIRT ENV
   BURLAMAQUI A, 2008, P IEEE INT C VIRT EN
   BURLAMAQUI A, 2002, SBMIDIA
   CAPIN T, 1999, AVATARS NETWORKED VI, P15
   CARLSSON C, 1993, COMPUT GRAPH, V17, P663, DOI 10.1016/0097-8493(93)90115-P
   DONGSEOK R, 2004, P IEEE RSJ INT C INT, V1, P168
   Dragone A, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P24
   IBA S, 2002, ROB AUT 2002 P ICRA, V1, P161
   KUNERT T, 2006, P 4 EUR C INT TEL 20, P242
   MACEDNIA M, 1994, PRESENCE-TELEOP VIRT, V3
   Macedonia MR, 1997, IEEE MULTIMEDIA, V4, P48, DOI 10.1109/93.580395
   MILGRAM P, 1994, P SPIE, V2351
   MINJANG S, 2008, ETRI J, V30, P618
   Morillo P., 2003, LECT NOTES COMPUT SC, V2970, P182
   Oliveira J.C., 2003, Presence, V12, P555
   OLIVEIRA MAM, 1999, 10 INT WORKSH DAT EX, P279
   SAITO H, 2002, SICE 2002, V5, P2721
   Schrempf OC, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P555
   SHAW C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P463, DOI 10.1109/VRAIS.1993.380743
   SINGH G, 1995, P IEEE VIRT REAL ANN
   SOUZA F, 2004, FRAMEWORKS MIDDLEWAR
   Tavares D, 2003, PROC ANNU SIMUL SYMP, P351, DOI 10.1109/SIMSYM.2003.1192833
   TAVARES T, 2004, 2004 IEEE INT C MULT
   TAVARES TA, 2001, SPRINGER VERLAG LECT, V2252
   2006, RTP TRANSPORT PROTOC
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 215
EP 245
DI 10.1007/s11042-009-0305-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900010
OA Green Published
DA 2024-07-18
ER

PT J
AU Frank, J
   Lidy, T
   Peiszer, E
   Genswaider, R
   Rauber, A
AF Frank, Jakob
   Lidy, Thomas
   Peiszer, Ewald
   Genswaider, Ronald
   Rauber, Andreas
TI Creating ambient music spaces in real and virtual worlds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Semantic Ambient Media Experience
CY OCT 31, 2008
CL Vancouver, CANADA
SP ACM
DE Music information retrieval; Virtual worlds; Mobile computing; User
   interfaces
ID ORGANIZATION
AB Sound and, specifically, music is a medium that is used for a wide range of purposes in different situations in very different ways. Ways for music selection and consumption range from completely passive, almost unnoticed perception of background sound environments to the very specific selection of a particular recording of a piece of music with a specific orchestra and conductor at a certain event. Different systems and interfaces exist for the broad range of needs in music consumption. Locating a particular recording is well supported by traditional search interfaces via metadata. Other interfaces support the automatic creation of playlists via artist or album selection, up to more artistic installations of sound environments that users can navigate through. In this paper we present a set of systems that support the creation of as well as the navigation in musical spaces, both in the real world as well as in virtual environments. We show common principles and point out further directions for a more direct coupling of the various spaces and interaction methods, creating ambient sound environments and providing organic interaction with music for different purposes.
C1 [Frank, Jakob; Lidy, Thomas; Peiszer, Ewald; Genswaider, Ronald; Rauber, Andreas] Vienna Univ Technol, Inst Software Technol & Interact Syst, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Frank, J (corresponding author), Vienna Univ Technol, Inst Software Technol & Interact Syst, Favoritenstr 9-11-188, A-1040 Vienna, Austria.
EM frank@ifs.tuwien.ac.at; lidy@ifs.tuwien.ac.at; mail@ewald-peiszer.net;
   r.genswaider@gmx.at; rauber@ifs.tuwien.ac.at
CR [Anonymous], SPRINGER SERIES INFO
   BAUM D, 2006, P 9 INT C AS DIG LIB
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   FEITEN B, 1994, COMPUT MUSIC J, V18, P53, DOI 10.2307/3681185
   Frank J., 2008, P INT WORKSH SEM AMB, P9
   Fruhwirth M., 2001, SPRINGER LECT NOTES
   Genswaider R, 2008, STUD COMPUT INTELL, V96, P79
   Ghias A., 1995, PROC ACM MULTIMEDIA, P231
   Hitchner S., 2007, P 8 INT C MUS INF RE, P175
   *ISO, 2002, 1593842002 ISO IEC
   Knees P., 2006, MULTIMEDIA 06 P 14 A, P17, DOI 10.1145/1180639.1180652
   Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729
   Kohonen T., 2001, SPRINGER SERIES INFO, V30, P1
   LAAKSONEN J., 1999, P INT JOINT C NEUR N
   Leitich S., 2007, P ISMIR, P167
   LEITICH S, 2007, P AUD MOSTL 2007 ILM
   LIDY T, 2005, P 6 INT C MUS INF RE, P34
   Lidy T., 2007, Proceedings of the International Conference on Music Information Retrieval, P61
   Lidy T, 2008, COGN TECHNOL, P249, DOI 10.1007/978-3-540-75171-7_11
   Lubbers D., 2005, Proceedings of the International Conference on Music Information Retrieval, P590
   MAYER R, 2006, P INT C MUS INF RETR
   Mayer R, 2007, LECT NOTES COMPUT SC, V4669, P359
   McNab R. J., 1996, Proceedings of the 1st ACM International Conference on Digital Libraries, P11, DOI 10.1145/226931.226934
   Neuman HB, 2007, ANN SURG ONCOL, V14, P9
   Neumayer R., 2005, QUEEN MARY, P618
   NEUMAYER R, 2007, P INT JOINT C NEUR N
   Ong TH, 2005, DECIS SUPPORT SYST, V39, P583, DOI 10.1016/j.dss.2004.03.008
   Orio Nicola, 2006, Foundations and Trends in Information Retrieval, V1, P1, DOI 10.1561/1500000002
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Rauber A, 2003, J NEW MUSIC RES, V32, P193, DOI 10.1076/jnmr.32.2.193.16745
   RAUBER A, 1999, P 4 ACM C DIG LIB DL, P240
   Rauber A., 2002, PROC INT S MUSIC INF, P71
   TORRENS M, 2004, P 5 INT C MUS INF RE
   Tzanetakis G, 2004, J AM SOC INF SCI TEC, V55, P1077, DOI 10.1002/asi.20060
   TZANETAKIS G, 2001, P INT C AUD DISPL
   Ultsch A, 2005, ST CLASS DAT ANAL, P91, DOI 10.1007/3-540-26981-9_12
   ULTSCH A, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P305
   Ultsch A., 2004, U MATRIX TOOL VISUAL
NR 38
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 3
BP 449
EP 468
DI 10.1007/s11042-009-0275-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 474WB
UT WOS:000268313900007
DA 2024-07-18
ER

PT J
AU Palazzi, CE
   Ferretti, S
   Roccetti, M
AF Palazzi, Claudio E.
   Ferretti, Stefano
   Roccetti, Marco
TI Communities on the road: fast triggering of interactive multimedia
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Live video triggering; Social network communities; V2V communication;
   V2V multimedia applications; Vehicular communities
AB Social network communities are involving millions of users, representing one of the main reasons why people log on the Internet from their home computers. Part of this success is certainly due to the possibility for end users to reverse the traditional publisher/consumer model, achieving control over service consumption, and gaining the opportunity to produce multimedia contents instantaneously available worldwide. Social network communities are not destined to be confined in traditional wired networks. Indeed, mobile users could greatly benefit from applications that combine social networks and location-based multimedia services. It is hence of particular interest to consider the next frontier in wireless networking, i.e., vehicular networks, and imagine how community-based services could be provided in this highly variable context, enabling the sprouting of communities on the road. To this aim, we address here one of the specific challenges in this scenario, i.e., the fast delivery of service triggering messages generated by a user to a certain area where another user can provide the requested multimedia service (e.g., live video streaming, traffic updates, friends finder, status messages of social network applications). We discuss the state-of-art for this technical challenge and compare it against our solution, which is able to dynamically adapt to different transmission conditions as those featuring a vehicular network. In essence, the main innovation of our contribution amounts to a transmission range estimator that enables vehicles to know their current transmission range, independently from changes in the vehicular network topology, and use it to maximize the efficiency in transmitting service-triggering messages.
C1 [Ferretti, Stefano; Roccetti, Marco] Univ Bologna, Dipartimento Sci Informaz, I-40127 Bologna, Italy.
   [Palazzi, Claudio E.] Univ Padua, Dipartimento Matemat Pura & Applicata, I-35131 Padua, Italy.
C3 University of Bologna; University of Padua
RP Roccetti, M (corresponding author), Univ Bologna, Dipartimento Sci Informaz, Via Mura Anteo Zamboni 7, I-40127 Bologna, Italy.
EM cpalazzi@math.unipd.it; sferrett@cs.unibo.it; roccetti@cs.unibo.it
OI ROCCETTI, MARCO/0000-0003-1264-8595; PALAZZI, Claudio
   Enrico/0000-0002-8877-0848
CR [Anonymous], 2006, P 3 INT WORKSH VEH A, DOI DOI 10.1145/1161064.1161070
   [Anonymous], P IEEE INT C WIR PER
   *ASTM INT, 2003, E221303 ASTM INT
   Biswas S, 2006, IEEE COMMUN MAG, V44, P74, DOI 10.1109/MCOM.2006.1580935
   BURAK A, 2004, P 3 INT C MOB UB MUL, P93, DOI DOI 10.1145/1052380.1052394
   CACCIAGUERRA S, 2006, P 2 IEEE INT WORKSH, P1214
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   FASOLO E, 2005, P WPMC 05 AALB DENM
   FURINI M, 2008, ACM COMPUT ENTERTAIN, V6, P19
   FUSSLER H, 2003, ELSEVIERS AD HOC NET, V1, P351, DOI DOI 10.1016/S1570-8705(03)00038-6
   Gallagher B, 2006, IEEE VEH TECHNOL MAG, V1, P4, DOI 10.1109/MVT.2006.343641
   *GLOB INF INC, 2008, MOB SOC NETW US GEN
   *GSL, 2009, GNU SCI LIB
   Guo M, 2005, Third IEEE International Conference on Pervasive Computing and Communications, Proceedings, P171
   HEITMANN M, 2004, P 37 ANN HAW INT C S
   *IEEE, 80211G IEEE 11
   Karp B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P243, DOI 10.1145/345910.345953
   KORKMAX G, 2004, P ACM VANET 04 PHIL, P75
   Kortuem G., 2001, Proceedings of the First International Conference on Peer-to-Peer Computing, P75, DOI DOI 10.1109/P2P.2001.990429
   LEIMEISTER JM, 2003, P 36 ANN HAW INT C S, P8
   Lim G, 2002, INT CONF PARA PROC, P116, DOI 10.1109/ICPPW.2002.1039720
   PALAZZI CE, 2005, COMPUTERS ENTERTAINM, V3, DOI DOI 10.1145/1063723.1063730
   Peng J, 2007, IEEE T MOBILE COMPUT, V6, P1357, DOI [10.1109/TMC.2007.1073, 10.1109/TMC.2007.1073.]
   Preece J., 2000, Online communities. Designing usability, DOI DOI 10.1108/IMDS.2000.100.9.459.3
   Roccetti M, 2007, IEEE IPCCC, P556, DOI 10.1109/PCCC.2007.358940
   Rybicki J, 2007, MOBICOM'07: PROCEEDINGS OF THE THIRTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P215
   SATCHELL C, 2005, P 11 INT C HUM COMP
   WAN PJ, 2002, P IEEE C COMP COMM I, P141
   Yang X, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P114
   Yin J., 2004, P 1 ACM INT WORKSHOP, P1
   Zhao W., 2004, Proceedings of the 5th ACM International Symposium On Mobile Ad Hoc Networking And Computing (MobiHoc), P187
NR 31
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 229
EP 247
DI 10.1007/s11042-009-0292-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100004
DA 2024-07-18
ER

PT J
AU Rönnau, S
   Borghoff, UM
AF Roennau, Sebastian
   Borghoff, Uwe M.
TI Versioning XML-based office documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE XML diff; XML patch; Fingerprint; Office applications; Version control;
   Document merging
AB The ability to reliably merge independent updates of a document is a crucial prerequisite to efficient collaboration in office work. However, merge support for common office document standards like OpenDocument or OfficeOpenXML is still in its infancy. In this paper, we present a consistent versioning model for XML documents in general including merge support. This is achieved by using context-aware fingerprints that identify edit operations and allow for a conflict detection. We show how to extract tracked changes from office documents and map them on our delta model. Experimental results indicate that our fingerprinting technique is efficient and reliable.
C1 [Roennau, Sebastian; Borghoff, Uwe M.] Univ Bundeswehr Munchen, Neubiberg, Germany.
C3 Bundeswehr University Munich
RP Rönnau, S (corresponding author), Univ Bundeswehr Munchen, Neubiberg, Germany.
EM Sebastian.Roennau@unibw.de
RI Borghoff, Uwe M./HIZ-8009-2022
OI Borghoff, Uwe M./0000-0002-7688-2367
CR BALASUBRAMANIAM S, 1998, 4 ANN ACM IEEE INT C
   Boyer J, 2001, CANONICAL XML VERSIO
   Boyer JM, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P8
   BRAUER M, 2007, OPENDOCUMENT V1 1 SP
   Chamberlin D D., 2008, XQuery Update Facility 1.0
   Chawathe S. S., 1997, SIGMOD Record, V26, P26, DOI 10.1145/253262.253266
   Clark J., 1999, XML Path Language (XPath) Version 1.0
   Cobéna G, 2002, PROC INT CONF DATA, P41, DOI 10.1109/ICDE.2002.994696
   Fayzullin M, 2004, MULTIMED TOOLS APPL, V24, P273, DOI 10.1023/B:MTAP.0000039422.87260.52
   FONTAINE RL, 2002, P XML EUR 2002 BARC
   *FSF, 2002, COMP MERG FIL
   Ignat CL, 2006, LECT NOTES COMPUT SC, V4101, P267
   KHANNA S, 2007, FDN SOFTWARE TECHNOL
   Lam F., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P153, DOI 10.1145/584792.584820
   LINDHOLM T, 2004, DOCENG 04, P1
   LINDHOLM T, 2006, DOCENG 06, P75
   Marian A., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P581
   MARUYAMA H, 2000, DIGEST VALUES DOM DO
   Mens T, 2002, IEEE T SOFTWARE ENG, V28, P449, DOI 10.1109/TSE.2002.1000449
   Neuwirth C. M., 1992, CSCW '92. Sharing Perspectives. Proceedings of the Conference on Computer-Supported Cooperative Work, P147, DOI 10.1145/143457.143473
   Paoli J., 2006, ECMA-376 Office Open XML File Formats"
   RONNAU S, 2005, DOCENG 05, DOI DOI 10.1145/1096601.1096606
   Ronnau S, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P52
   Rosado LJA, 2007, LECT NOTES COMPUT SC, V4704, P107
   Tatarinov I., 2001, SIGMOD, P413, DOI DOI 10.1145/375663.375720
   [No title captured]
NR 26
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 253
EP 274
DI 10.1007/s11042-009-0271-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800004
DA 2024-07-18
ER

PT J
AU Kaiser, R
   Hausenblas, M
   Umgeher, M
AF Kaiser, Rene
   Hausenblas, Michael
   Umgeher, Martin
TI Metadata-driven interactive web video assembly
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-linear video; Interactive video; Dynamic video assembly;
   Metadata-based video assembly
ID ABSTRACTION; HIGHLIGHTS
AB The recent expansion of broadband Internet access led to an exponential increase of potential consumers of video on the Web. The huge success of video upload websites shows that the online world, with its virtually unlimited possibilities of active user participation, is an ideal complement to traditional consumption-only media like TV and DVD. It is evident that users are willing to interact with content-providing systems in order to get the content they desire. In parallel to these developments, innovative tools for producing interactive, non-linear audio-visual content are being created. They support the authoring process alongside management of media and metadata, enabling on-demand assembly of videos based on the consumer's wishes. The quality of such a dynamic video remixing system mainly depends on the expressiveness of associated metadata. Eliminating the need for manual input as far as possible, we aim at designing a system which is able to automatically enrich its own media and metadata repositories continuously. Currently, video content remixing is available on the Web mostly in very basic forms. Most platforms offer upload and simple modification of content. Although several implementations exist, to the best of our knowledge no solution uses metadata to its full extent to dynamically render a video stream based on consumers' wishes. With the research presented in this paper, we propose a novel concept to interactive video assembly on the Web. In this approach, consumers may describe the desired content using a set of domain-specific parameters. Based on the metadata the video clips are annotated with, the system chooses clips fitting the user criteria. They are aligned in an aesthetically pleasing manner while the user furthermore is able to interactively influence content selection during playback at any time. We use a practical example to clarify the concept and further outline what it takes to implement a suchlike system.
C1 [Kaiser, Rene; Hausenblas, Michael] Joanneum Res Forschungsgesellschaft mbH, Inst Informat Syst & Informat Management, Graz, Austria.
   [Umgeher, Martin] Graz Univ Technol, Inst Software Technol, A-8010 Graz, Austria.
C3 Graz University of Technology
RP Kaiser, R (corresponding author), Joanneum Res Forschungsgesellschaft mbH, Inst Informat Syst & Informat Management, Graz, Austria.
EM rene.kaiser@joanneum.at; michael.hausenblas@joanneum.at;
   mumgeher@ist.tugraz.at
OI Kaiser, Rene/0000-0001-7775-4554; Hausenblas,
   Michael/0000-0003-0967-5998
CR Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   BABAGUCHI N, 2001, IEEE INT C MULT EXP, P158
   Bailer W, 2005, PROC SPIE, V5682, P284, DOI 10.1117/12.586884
   Bhagavathy S, 2004, LECT NOTES COMPUT SC, V3332, P256
   Bocconi S., 2006, THESIS TU EINDHOVEN
   EKIN A, 2003, THESIS ROCHESTER I T
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   HARE JS, 2006, 3 EUR SEM WEB C BUDV
   HAUSENBLAS M, 2007, 1 INT C NEW MED TECH
   HAUSENBLAS M, 2007, MULTIMEDIA SEMANTICS
   Hausenblas M, 2007, IEEE MULTIMEDIA, V14, P1, DOI 10.1109/MMUL.2007.37
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Liu S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/32135
   *MPEG 7, 2001, 15938 ISOIEC MPEG7
   Murray J.H., 1997, Hamlet on the Holodeck
   NATSEV A, 2004, KDD 04 P 10 ACM SIGK, P641
   NEPAL S, 2001, MULTIMEDIA 01, P261
   *OWL, 2004, WEB ONT LANG REF W3C
   Riedl MO, 2006, IEEE COMPUT GRAPH, V26, P23, DOI 10.1109/MCG.2006.56
   SHAW R, 2006, HCM 06
   Takahashi Y, 2004, LECT NOTES COMPUT SC, V3332, P272
   Tien M.-C., 2007, P IEEE INT C AC SPEE
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   TJONDRONEGORO DW, 2006, ACSC 06
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   URSU M, 2005, D5 3 LANGUAGES REPRE
   Ursu MF, 2007, LECT NOTES COMPUT SC, V4471, P96
   von Ahn L, 2006, COMPUTER, V39, P92, DOI 10.1109/MC.2006.196
   Wang JJ, 2008, MULTIMEDIA SYST, V14, P179, DOI 10.1007/s00530-008-0112-6
   WILLIAMS D, 2006, 2 IET MULT C 29 30 N
   Wu LF, 2006, INT C PATT RECOG, P319
   YOUNG M, 1999, AAAI FALL S NARR INT, P164
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 34
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2009
VL 41
IS 3
SI SI
BP 437
EP 467
DI 10.1007/s11042-008-0242-z
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 395EL
UT WOS:000262506300005
DA 2024-07-18
ER

PT J
AU Luo, HL
   Shyu, ML
   Chen, SC
AF Luo, Hongli
   Shyu, Mei-Ling
   Chen, Shu-Ching
TI Video streaming over the internet with optimal bandwidth resource
   allocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video streaming; quality of service; optimal bandwidth allocation;
   congestion control
ID CONGESTION CONTROL; MECHANISM
AB In this paper, an adaptive framework for video streaming over the Internet is presented. The framework is a joint design of packet scheduling and rate control with optimal bandwidth resource allocation. The transmission rate is dynamically adjusted to obtain maximal utilization of the client buffer and minimal allocation of the bandwidth. Under the constraint of the transmission rate, a prioritized packet scheduling is designed to provide a better visual quality of video frames. The packet scheduling is a refined bandwidth allocation which takes into account of varying importance of the different packets in a compressed video stream. Moreover, the proposed approach is scalable with increasing multimedia flows in the distributed Internet environment. Comparisons are made with the most current streaming approaches to evaluate the performance of the framework using the H.264 video codec. The extensive simulation results show that the average Peak Signal to Noise Ratio (PSNR) increases in our proposed approach. It provides a better quality of the decoded frames, and the quality of the decoded frames changes more smoothly. The achieved video quality among different users also has a lower fluctuation, which indicates a fair sharing of network resources.
C1 [Luo, Hongli] Indiana Univ Purdue Univ, Dept Elect & Comp Engn Technol, Ft Wayne, IN 46805 USA.
   [Shyu, Mei-Ling] Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
   [Chen, Shu-Ching] Florida Int Univ, Distributed Multimedia Informat Syst Lab, Sch Comp & Informat Sci, Miami, FL 33199 USA.
C3 Purdue University System; Indiana University Purdue University Fort
   Wayne; University of Miami; State University System of Florida; Florida
   International University
RP Luo, HL (corresponding author), Indiana Univ Purdue Univ, Dept Elect & Comp Engn Technol, Ft Wayne, IN 46805 USA.
EM luoh@ipfw.edu; shyu@miami.edu; chens@cs.fiu.edu
CR BAJIC IV, 2003, IEEE ICIP 03 BARC SE, P257
   Balk A, 2004, COMPUT NETW, V44, P415, DOI 10.1016/j.comnet.2003.12.002
   Bansal D, 2001, IEEE INFOCOM SER, P631, DOI 10.1109/INFCOM.2001.916251
   BOURAS C, 2004, J MULTIMEDIA TOOLS A, V25, P85
   Cai L, 2005, IEEE T MULTIMEDIA, V7, P339, DOI 10.1109/TMM.2005.843360
   Chen IR, 2005, MULTIMED TOOLS APPL, V25, P167, DOI 10.1007/s11042-005-5604-1
   Chen SC, 2005, J SYST SOFTWARE, V75, P271, DOI 10.1016/j.jss.2003.10.031
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   CUETOS P, 2003, P 3 ACM MULT C, P55
   Dong JY, 2005, MULTIMED TOOLS APPL, V25, P187, DOI 10.1007/s11042-005-5605-0
   Floyd JM, 2000, AUSTRALAS I MIN MET, V2000, P43
   Jin SD, 2003, IEEE ACM T NETWORK, V11, P341, DOI 10.1109/TNET.2003.813046
   Joint Video Team of ISO/IEC MPEG and ITU-T VCEG, 2002, JOINT MOD NUMB 1 REV
   KANG SH, 2003, P ICIP BARC SEPT 200, P633
   Kim YG, 2004, IEEE T CIRC SYST VID, V14, P256, DOI 10.1109/TCSVT.2003.819186
   KRASIC C, 2003, NETWORK OPERATING SY, P112
   Kusmierek E, 2005, J SYST SOFTWARE, V75, P237, DOI 10.1016/j.jss.2003.12.034
   LUO H, 2005, P IEEE INT C MULT EX, P1218
   Luo HL, 2006, COMPUT NETW, V50, P921, DOI 10.1016/j.comnet.2005.06.005
   Mielke M, 2002, IEEE T MULTIMEDIA, V4, P561, DOI 10.1109/TMM.2002.806537
   Rejaie R, 1999, IEEE INFOCOM SER, P1337, DOI 10.1109/INFCOM.1999.752152
   RHEE I, 2005, P ACM SIGCOMM PHIL P, P49
   Tunali ET, 2005, MULTIMED TOOLS APPL, V27, P431, DOI 10.1007/s11042-005-4090-9
   Viéron J, 2004, IEEE T MULTIMEDIA, V6, P634, DOI [10.1109/TMM.2004.830805, 10.1109/tmm.2004.830805]
   WANG B, 2004, ACM MULTIMEDIA, P908
   Widmer J, 2001, IEEE NETWORK, V15, P28, DOI 10.1109/65.923938
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Zhang Q, 2001, IEEE T MULTIMEDIA, V3, P339, DOI 10.1109/6046.944477
   Zhu P, 2007, IEEE T MULTIMEDIA, V9, P366, DOI 10.1109/TMM.2006.886284
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 30
TC 8
Z9 9
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2008
VL 40
IS 1
BP 111
EP 134
DI 10.1007/s11042-007-0187-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 339KO
UT WOS:000258576700006
DA 2024-07-18
ER

PT J
AU Zhang, M
   Wong, J
   Tavanapong, W
   de Groen, JOP
AF Zhang, Mu
   Wong, Johnny
   Tavanapong, Wallapak
   de Groen, JungHwan Oh Piet
TI Deadline-constrained media uploading systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE file upload; hard real-time systems; emergency control for storage
   overflow; scheduling algorithms
ID SCALE
AB This paper presents the design, implementation, and performance evaluation of a novel file uploading system. The system automatically uploads multimedia files to a centralized server given a client machine's hard deadline-the time when a client machine will exhaust its available storage space due to on-going recording of media files. If existing files have not been uploaded and removed from the client machine's hard disk by the deadlines, existing files may be overwritten or new files may not get created. Our uploading system was designed to provide a practical solution for emerging business needs. For instance, our system can be used in medical practice to gather videos generated from medical devices located in various procedure rooms for post-procedure analysis, and in law enforcement to collect video recordings from police cars during routine patrolling. Here we investigate two upload scheduling algorithms that determine which client machine should upload its file(s) first. We introduce two emergency control algorithms to handle situations when a client machine is about to exhaust its hard disk space. We evaluate the proposed algorithms via simulations and analysis. Our performance studies show that the upload scheduling algorithms and the emergency control algorithms have a significant impact on overall system performance.
C1 [Zhang, Mu; Wong, Johnny; Tavanapong, Wallapak] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
   [Wong, Johnny] Univ N Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
   [de Groen, JungHwan Oh Piet] Mayo Clin & Mayo Fdn, Dept Comp Sci & Engn, Rochester, MN 55905 USA.
C3 Iowa State University; University of North Texas System; University of
   North Texas Denton; Mayo Clinic
RP Tavanapong, W (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM tavanapo@cs.iastate.edu
CR [Anonymous], 1949, Human behaviour and the principle of least-effort
   BHATTACHARJEE B, 2001, PERFORM EVALUATION, V28, P29
   Cox LandonP., 2003, ACM S OPERATING SYST, P120
   FU K, 2004, VIDEO DATA MANAGEMEN
   HOWARD JH, 1988, ACM T COMPUT SYST, V6, P51, DOI 10.1145/35037.35059
   Hua KA, 2004, P IEEE, V92, P1439, DOI 10.1109/JPROC.2004.832954
   HWANG S, 2005, P 13 ANN ACM INT C M, P912
   *IBM, 2003, IBM BOLST POL FLEET
   *KAZAA, 2006, KAZAA FIL SHAR NETW
   Krauter K, 2002, SOFTWARE PRACT EXPER, V32, P135, DOI 10.1002/spe.432
   Lillibridge M, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK, P29
   LIU CL, 1973, J ACM, V20, P46, DOI 10.1145/321738.321743
   Rangaswami R, 2003, IEEE T MULTIMEDIA, V5, P558, DOI [10.1109/TMM.2003.814722, 10.1109/TTM.2003.814722]
   *SUN MICR, 1989, RFC1094 SUN MICR
   *US NAT SCI FDN, 2006, FASTL
   Zhang M, 2004, Proceedings of the Eighth IASTED International Conference on Internet and Multimedia Systems and Applications, P305
   ZHANG M, 2005, TR0510 IOW STAT U DE
NR 17
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 51
EP 74
DI 10.1007/s11042-007-0149-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000003
DA 2024-07-18
ER

PT J
AU Dai, H
   Chan, E
AF Dai, Han
   Chan, Edward
TI Quick patching: an overlay multicast scheme for supporting video on
   demand in wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video on demand; wireless networks; application layer multicast; video
   streaming
AB Many overlay multicast schemes have been proposed recently at the application level to support video-on-demand service over the Internet. With the proliferation of mobile devices and the increasing coverage of high speed wireless networks, such services are likely to be extended to support clients connected to the Internet through a wireless last hop. However, existing application level multicast schemes are not designed to handle the characteristics of the noisy wireless links. In this paper we propose an overlay multicast scheme called Quick Patching which arranges additional patch streams to clients under poor link conditions to improve their clients' viewing quality. We demonstrate through extensive simulation experiments that Quick Patching is not only scalable, but can also sustain the required viewing quality under different network conditions including fluctuating error conditions as well as heterogeneous user viewing quality requirements.
C1 [Dai, Han; Chan, Edward] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Chan, E (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM csedchan@cityu.edu.hk
CR ABOUZEID A, 2000, P IEEE INF TEL AV 26
   BANERJEE S, 2002, P ACM SIGCOMM PITTSB
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   DEERING S, 1989, RFC1122
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Fitzek FHP, 2001, IEEE J SEL AREA COMM, V19, P2015, DOI 10.1109/49.957315
   FOULIRAS P, 2004, P ACM S APPL COMP SA
   FRITCHMAN BD, 1967, IEEE T INFORM THEORY, V13, P221, DOI 10.1109/TIT.1967.1053975
   GAO L, 1998, P INT WORKSH NETW OP
   GUO Y, 2003, P 12 INT C WORLD WID
   GUO Y, 2002, P INT PACK VID WORKS
   HU A, 2001, P IEEE INFOCOM ANCH
   HUA K, 1998, P ACM MULT BRIST 12
   HUA KA, 2003, P ACM S APPL COMP ME
   Liu J., 2003, P MOD OPT MOB AD HOC, P1
   SHENOY P, 2003, P MULT COMP NETW SAN
   SHEU S, 1997, P 1997 INT C MULT CO
   TRAN, 2004, P MOB DAT MAN BERK 1
   Zorzi M, 1997, IEEE T COMMUN, V45, P660, DOI 10.1109/26.592604
   Zorzi M, 1999, IEEE T COMMUN, V47, P1537, DOI 10.1109/26.795822
NR 21
TC 8
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 221
EP 242
DI 10.1007/s11042-007-0143-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600003
DA 2024-07-18
ER

PT J
AU Bialkowski, J
   Barkowsky, M
   Kaup, A
AF Bialkowski, Jens
   Barkowsky, Marcus
   Kaup, Andre
TI Fast video transcoding from h.263 to H.264/MPEG-4 AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video transcoding; low complexity coding; H.263; H.264/MPEG-4 AVC
AB In the past 10 years detailed works on different video transcoders have been published. However, the new ITU-T Recommendation H.264-also adapted as ISO/IEC MPEG-4 Part 10 (AVC)-provides many new encoding options for the prediction processes that lead to difficulties for low complexity transcoding. In this work we present very fast transcoding techniques to convert H.263 bitstreams into H.264/AVC bitstreams. We will give reasoning, why the proposed pixel domain approach is advantageous in this scenario instead of using a DCT domain transcoder. Our approach results in less than 9% higher data rate at equivalent PSNR quality compared to a full-search approach. But this rate loss allows the reduction of the search complexity by a factor of over 200 for inter frames and still a reduction of over 70% for intra frames. A comparison to a fast search algorithm is given. We also provide simulation results that our algorithm works for transcoding MPEG-2 to H.264/AVC in the aimed scenario.
C1 Univ Erlangen Nurnberg, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Bialkowski, J (corresponding author), Univ Erlangen Nurnberg, Cauerstr 7, D-91058 Erlangen, Germany.
EM bialkowski@lnt.de; barkowsky@lnt.de; kaup@lnt.de
OI Kaup, Andre/0000-0002-0929-5074
CR Assunçao PAA, 1998, IEEE T CIRC SYST VID, V8, P953, DOI 10.1109/76.736724
   BARKOWSKY M, 2006, P 2 INT WORKSH VID P
   BELLARD F, 2005, FFMEG MULTIMEDIA SYS
   Bialkowski J, 2004, IEEE IMAGE PROC, P2785
   BIALKOWSKI J, 2004, P PICT COD S PCS SAN
   BIALKOWSKI J, 2005, P MULT SIG P WORKS M
   Chen G, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P321, DOI 10.1109/ICME.2006.262463
   FEAMSTER N, 1999, P SPEL INT S VOIC VI
   *ISO IEC JTC, 2000, 138182 ISO IEC
   *JVT, 2003, JVTF100
   *JVT, 2002, H264 ITUT REC
   KEESMAN G, 1996, IMAGE COMMUN, V8, P481
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   PURI A, 2004, IMAGE COMMUNICATION, V19, P793
   Shen B, 2004, IEEE IMAGE PROC, P115
   SU Y, 2005, P IEEE INT S CIRC SY, V2, P1234
   SULLIVAN G, 1998, ITU T RECOMMENDATION
   *U BRIT COL, 1998, SG11 ITUT
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   *VQEG, 2000, COM 980E FIN REP VID
   XIAOQUAN Y, 2005, 16 M JOINT VID TEAM
   XIN J, 2004, PAC C MULT PCM, P939
NR 22
TC 5
Z9 12
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2007
VL 35
IS 2
BP 127
EP 146
DI 10.1007/s11042-007-0126-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 212XA
UT WOS:000249629100002
DA 2024-07-18
ER

PT J
AU Hartanto, F
   Kangasharju, J
   Reisslein, M
   Ross, K
AF Hartanto, Felix
   Kangasharju, Jussi
   Reisslein, Martin
   Ross, Keith
TI Caching video objects: layers vs versions?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE proxy caching; streaming video; layered video; multi-version video
AB Because Internet access rates are highly heterogeneous, many video content providers today make available different versions of the videos, with each version encoded at a different rate. Multiple video versions, however, require more server storage and may also dramatically impact cache performance in a traditional cache or in a CDN server. An alternative to versions is layered encoding, which can also provide multiple quality levels. Layered encoding requires less server storage capacity and may be more suitable for caching; but it typically increases transmission bandwidth due to encoding overhead. In this paper we compare video streaming of multiple versions with that of multiple layers in a caching environment. We examine caching and distribution strategies that use both versions and layers. We consider two cases: the request distribution for the videos is known a priori; and adaptive caching, for which the request distribution is unknown. Our analytical and simulation results indicate that mixed distribution/caching strategies provide the best overall performance.
C1 Arizona State Univ, Dept Elect Engn, WINTech Ctr, Goldwater Ctr, Tempe, AZ 85287 USA.
   Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.
   Polytech Univ, Brooklyn, NY 11201 USA.
C3 Arizona State University; Arizona State University-Tempe; Chinese
   University of Hong Kong; Technical University of Darmstadt; New York
   University
RP Reisslein, M (corresponding author), Arizona State Univ, Dept Elect Engn, WINTech Ctr, Goldwater Ctr, MC 5706, Tempe, AZ 85287 USA.
EM hartanto@cse.cuhk.edu.hk; jussi@tk.informatik.tu-darmstadt.de;
   reisslein@asu.edu; ross@poly.edu
RI Kangasharju, Jussi/E-8922-2012; Reisslein, Martin/B-3278-2014
OI Kangasharju, Jussi/0000-0001-6119-1638; Reisslein,
   Martin/0000-0003-1606-233X
CR ABDELZAHER T, 1999, P INT WORKSH OOS LON
   Chandra K, 1999, IEEE ACM T NETWORK, V7, P398, DOI 10.1109/90.779209
   Crovella M, 1998, IEEE INFOCOM SER, P1232, DOI 10.1109/INFCOM.1998.662937
   DECUETOS P, 2001, P INT PACK VID WORKS
   FOX A, 1996, P 5 WWW C PAR FRANC
   Hartanto F, 1996, COMPUT ELECTR ENG, V22, P367, DOI 10.1016/S0045-7906(96)00015-8
   Kangasharju J, 2002, IEEE T COMPUT, V51, P622, DOI 10.1109/TC.2002.1009148
   KIM T, 2001, P NOSSDAV 2001 PORT
   KIMURA J, 1999, SPIE INT S VOIC VID
   MA W, 2000, P MMCN 2000 SAN JOS
   ORTEGA A, 1997, P MMSP PRINC NEW JER
   Ross K., 1995, MULTISERVICE LOSS MO
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
NR 13
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2006
VL 31
IS 2
BP 221
EP 245
DI 10.1007/s11042-006-0037-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 103MP
UT WOS:000241890500005
DA 2024-07-18
ER

PT J
AU Theodorakopoulos, V
   Woodward, ME
AF Theodorakopoulos, Vasileios
   Woodward, Michael E.
TI Comparative analysis of a twin-class <i>M</i>-QAM transmission system
   for wireless video applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE twin-class transmission system; wireless video communication; video
   partitioning; M-QAM
ID BER COMPUTATION; MODULATION
AB This paper presents a unique set of techniques to Support reliable and efficient video transmission over mobile channels. The transmission system is comprised of an M level Quadrature Amplitude Modulation (QAM) technique. A twin class uniform and non-Uniform partitioned M-QAM system is used to transport a compressed video bitstream which is partitioned to match the bit-error sensitivity of the transmitted symbol in terms of mapping in the constellation diagram and picture quality. Video partitioning based on a separation of the Variable Length Coded (VLC) Discrete Cosine Transforms (DCT) coefficients within each block is considered for constant bitrate transmission (CBR). Various scenarios for splitting the bitstream are investigated and their results are compared and analysed thoroughly. The performance of the transmission system is evaluated under Additive White Gaussian Noise (AWGN) conditions. The Simulation results showed that the video partition strategy results in a significantly higher quality of the reconstructed video data.
C1 Univ Bradford, Sch Informat, Dept Comp, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford
RP Theodorakopoulos, V (corresponding author), Univ Bradford, Sch Informat, Dept Comp, Bradford BD7 1DP, W Yorkshire, England.
EM V.Theodorakopoulos@Bradford.ac.uk; M.E.Woodward@Bradford.ac.uk
CR Assunçao PAA, 2000, IEEE T CIRC SYST VID, V10, P83, DOI 10.1109/76.825863
   BARMADA B, 2005, IN PRESS IEEE SIGNAL
   COVER TM, 1972, IEEE T INFORM THEORY, V18, P2, DOI 10.1109/TIT.1972.1054727
   *DVBT, 1999, 300744 DVBT ETS DIG
   GHANDI MM, 2005, IN PRESS J VISUAL CO
   Gharavi H, 2002, IEEE T CIRC SYST VID, V12, P77, DOI 10.1109/76.988655
   Gharavi H, 2001, J RES NATL INST STAN, V106, P455, DOI 10.6028/jres.106.020
   Hanzo L, 1998, P IEEE, V86, P1342, DOI 10.1109/5.681368
   Hanzo L, 2004, Quadrature amplitude modulation: From basics to adaptive trellis-coded, turbo-equalised and space-time coded OFDM, CDMA and MC-CDMA systems
   Khan E, 2004, IEEE T CIRC SYST VID, V14, P1294, DOI 10.1109/TCSVT.2004.837018
   KOLOTOS MK, 2000, IEEE 51 VTC 2000, V3, P1732
   KOLOTOS MK, 1999, IEEE MILCOM 1999, V2, P1236
   Kozintsev I, 1998, IEEE T SIGNAL PROCES, V46, P1012, DOI 10.1109/78.668553
   Mirabbasi S, 2000, IEEE COMMUN MAG, V38, P140, DOI 10.1109/35.883503
   MORIMOTO M, 1994, IEICE T COMMUN, VE77B, P1495
   Pursley MB, 1999, IEEE J SEL AREA COMM, V17, P774, DOI 10.1109/49.768194
   Theodorakopoulos V., 2005, Proceedings. DFMA 05. First International Conference on Distributed Frameworks for Multimedia Applications, P218
   Tong L, 2004, IEEE SIGNAL PROC MAG, V21, P12
   Vitthaladevuni PK, 2003, IEEE T INFORM THEORY, V49, P297, DOI 10.1109/TIT.2002.806159
   Vitthaladevuni PK, 2001, IEEE T BROADCAST, V47, P228, DOI 10.1109/11.969372
   Yang LL, 2000, IEEE COMMUN LETT, V4, P304, DOI 10.1109/4234.880816
NR 21
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 125
EP 139
DI 10.1007/s11042-006-6138-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600002
DA 2024-07-18
ER

PT J
AU Westermann, U
   Klas, W
AF Westermann, U
   Klas, W
TI A typed DOM for the management of MPEG-7 media descriptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE metadata; MPEG-7; XML databases; DOM
AB MPEG-7 is a very promising standard for the description of multimedia content. Certainly, means for the adequate management of large amounts of MPEG-7 media descriptions are needed in the near future. Essentially, MPEG-7 media descriptions are XML documents following media description schemes and descriptors defined with an extension of XML Schema named MPEG-7 DDL. However, XML database solutions available today are not suitable for the management of MPEG-7 media descriptions. They typically neglect type information available with the definitions of description schemes and descriptors and represent the basic contents of media descriptions as text. But storing non-textual multimedia data typically contained in media descriptions such as melody contours and object shapes textually and forcing applications to access and process such data as text is neither adequate nor efficient. In this paper, we therefore propose the Typed Document Object Model (TDOM), a data model for XML documents that can benefit from available schema definitions and represent the basic contents of a document in a typed fashion. Through these typed representations, applications can access and work with multimedia data contained in MPEG-7 media descriptions in way that is appropriate to the particular type of the data. Thereby, TDOM constitutes a solid foundation for an XML database solution enabling the adequate management of MPEG-7 media descriptions.
C1 Univ Vienna, Fac Comp Sci, Dept Distributed & Multimedia Syst, A-1010 Vienna, Austria.
C3 University of Vienna
RP Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92717 USA.
EM gerd-utz.westermann@univie.ac.at; wolfgang.klas@univie.ac.at
CR *AN DES PLATF TASK, 2001, UN MOD LANG UML
   [Anonymous], 2001, XML SCHEMA 1
   BOAG S, 2002, IN PRESS XQUERY 1 0
   CHANG B, 2002, DOCUMENT OBJECT MODE
   CHIDLOVSKII B, 2000, P IEEE ADV DIG LIB 2
   Clark J., 1999, XML Path Language (XPath) Version 1.0
   Clark James, 1999, Xsl transformations (xslt)
   COWAN R, 2001, XML INFORMATION SET
   DCMI, 1999, DUBL COR MET EL SET
   DEUTSCH A, 1999, P ACM SIGMOD INT C M
   *EXCELON CORP, 2001, MAN DXE SYST DOC REL
   FERNANDEZ MF, 2002, IN PRESS XQUERY 1 0
   Florescu Daniela., 1999, IEEE DATA ENG B, V22
   FRANKSTON C, 1998, UNPUB XML DATA REDUC
   Fuchs Matthew, 1999, SCHEMA OBJECT ORIENT
   GARDARIN G, 1999, P 18 INT C CONC MOD
   GOLDMAN R, 1999, P ACM SIGMOD WORKSH
   HIGGINS S, 2001, ORACLE 9I APPL DEV G
   HUCK G, 1999, P WORKSH JAV DAT PER
   *IBM CORP, 2000, IBM DB2 UN DAT XML E
   *IEEE P1484 12 LEA, 2002, P14841212002 IEEE LT
   *INF GMBH, 2002, INF DB US MAN PROGR
   *ISO IEC, 2001, 1593832001 ISOIEC JT
   *ISO IEC, 2001, 1593822001 ISOIEC JT
   *ISO IEC, 2001, 1593812001 ISO IEC J
   *ISO IEC, 1999, 1SC29WG11 ISOIEC JTC
   *ISO IEC, 2001, 1593852001 ISOIEC JT
   *ISO IEC, 2001, 1593842001 ISOIEC JT
   *IXIASOFT INC, 2001, CREAT CLIENT APPL TE
   JAGADISH H, 1999, P IEEE WORKSH KNOWL
   KANNE C, 1999, 899 U MANNH
   Le Hors Arnaud., 2000, Document object model level 2 core
   LEHORS A, 2002, DOCUMENT OBJECT MODE
   Malhotra Ashok, 2001, XML SCHEM 2
   *MICR CORP, 2000, MICR SQL SERV 2000 S
   MURATA M, 1999, IN PRESS HEDGE AUTOM
   NACK F, 1999, IEEE MULTIMEDIA, V6
   SALMINEN A, 2001, P ACM S DOC ENG 2001
   SCHMIDT A, 2000, P 3 INT WORKSH WEB D
   SHANMUGASUNDARA.J, 1999, P 25 INT C VER LARG
   SHIMURA T, 1999, P DAT EXP SYST APPL
   *SOFTW AG, 2001, US GUID SYST DOC VER
   STAKEN K, 2002, XINDICE DEV GUIDE 0
   STAKEN K, 2001, DBXML DEV GUIDE 0 5
   TIAN F, 2002, ACM SIGMOD RECORD, V31
   *VRA DAT STAND COM, 2002, VRA COR CAT VRA STAN
   WESTERMAN U, 2006, IN PRESS SOFTWARE PR
   WESTERMANN U, 2003, ACM COMPUTING SURVEY, V35
   *X HIV CORP, 2002, X HIV DB 2 0 MAN SYS
   *XCBL ORG INC, 2001, XML COMM BUS LIB XCB
   *XML GLOB TECHN IN, 2001, GOXML DB ADM HELP SY
NR 51
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 291
EP 322
DI 10.1007/s11042-005-3810-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300001
DA 2024-07-18
ER

PT J
AU Ziviani, A
   Wolfinger, B
   De Rezende, JF
   Duarte, OCMB
   Fdida, S
AF Ziviani, A
   Wolfinger, B
   De Rezende, JF
   Duarte, OCMB
   Fdida, S
TI Joint adoption of QoS schemes for MPEG streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of Service; video communications; MPEG; differentiated services;
   forward error correction
ID PACKET VIDEO; QUALITY; ALLOCATION
AB Indiscriminated packet discards strongly degrade the quality perceived by end users of MPEG video transmissions. This paper investigates different Quality of Service (QoS) schemes and the tradeoffs of jointly adopting such schemes to improve the delivery quality of an MPEG stream. From an analytical model, we evaluate the impact of frame losses on the quality of MPEG streams and on the waste of network resources. Our assessment considers issues such as the use of redundancy by applying a Forward Error Correction (FEC) scheme to tolerate losses, the changing of the compression factor in MPEG encoding, the unequal protection of MPEG frames in a Differentiated Services environment, and how to evaluate the impact of network losses onto application quality. Results provide predicted bounds on the quality to be expected by end users as well as guidelines on how to take the best advantage from the joint adoption of the investigated QoS schemes.
C1 LNCC, Petropolis, Brazil.
   Univ Hamburg, TKRN, CS Dept, Hamburg, Germany.
   Univ Fed Rio de Janeiro, Poli, COPPE, GTA, BR-21941 Rio De Janeiro, Brazil.
   Univ Paris 06, LIP6, F-75252 Paris, France.
C3 Laboratorio Nacional de Computacao Cientifica (LNCC); University of
   Hamburg; Universidade Federal do Rio de Janeiro; Sorbonne Universite
RP LNCC, Petropolis, Brazil.
EM ziviani@lncc.br; wolfinger@informatik.uni-hamburg.de;
   rezende@gta.ufrj.br; otto@gta.ufrj.br; Serge.Fdida@lip6.fr
RI Duarte, Otto Carlos M B/C-5828-2013; de Rezende, Jose
   Ferreira/C-3166-2013; Ziviani, Artur/A-6426-2009
OI de Rezende, Jose Ferreira/0000-0002-5660-6488; Ziviani,
   Artur/0000-0001-9326-8214
CR Alam MF, 2000, COMPUT COMMUN, V23, P1336, DOI 10.1016/S0140-3664(00)00180-8
   Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   [Anonymous], 1998, 2386 RFC
   [Anonymous], 1998, An Architecture for Differentiated Services, RFC 2475 Informational
   [Anonymous], NS MANUAL
   ASHMAWI W, 2001, P ACM SIGCOMM 2001 S
   BOYCE JM, 1998, P ACM MULT 98 BRIST
   Clark DD, 1998, IEEE ACM T NETWORK, V6, P362, DOI 10.1109/90.720870
   Costa LHMK, 2002, COMPUT NETW, V39, P713, DOI 10.1016/S1389-1286(02)00228-1
   CROOKS R, 1998, ANAL MPEG ENCODING T
   de Amorim MD, 2004, COMPUT COMMUN, V27, P197, DOI 10.1016/j.comcom.2003.10.003
   de Amorim MD, 2003, MULTIMEDIA SYST, V9, P94, DOI 10.1007/s00530-002-0081-0
   DIOT C, 1995, P HIGH PERF COMP SYS
   FARIN D, 2001, P SPIE VISUAL COMMUN
   Fitzek FHP, 2001, IEEE NETWORK, V15, P40, DOI 10.1109/65.967596
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Frossard P, 2001, IEEE T IMAGE PROCESS, V10, P1815, DOI 10.1109/83.974566
   GONCALVES PAS, 2002, IFIP NETWORKING 2002
   HEIDTMANN K, 2001, P KIVS 2001
   HEINANEN J, 1999, 2597 RFC
   HEMY M, 1999, P 9 PACK VID WORKSH
   Koenen R, 1999, IEEE SPECTRUM, V36, P26, DOI 10.1109/6.744873
   Krunz M, 1999, IEEE COMMUN MAG, V37, P40, DOI 10.1109/35.739277
   KRUNZ M, 1997, P ACM SIGMETRICS 97
   Mathy L, 2000, IEEE NETWORK, V14, P46, DOI 10.1109/65.855479
   Shin J, 2001, IEEE T MULTIMEDIA, V3, P219, DOI 10.1109/6046.923821
   SHIN J, 2001, P IEEE INT C COMM IC
   SHIN J, 2000, P 10 PACK VID WORKSH
   STORN R, 1995, TR95018 INT COMP SCI
   TURAGA DS, 2001, P 11 PACK VID WORKSH
   Verscheure O, 1998, IEEE NETWORK, V12, P12, DOI 10.1109/65.752641
   WOLFINGER BE, 1997, P ACM S PRINC DISTR
   WOLFINGER BE, 2001, P INT C NETW ICN 200
   Xiao XP, 1999, IEEE NETWORK, V13, P8, DOI 10.1109/65.768484
   Ziviani A, 2002, INT J COMMUN SYST, V15, P799, DOI 10.1002/dac.564
   Ziviani A, 2002, ECUMN'2002: 2ND EUROPEAN CONFERENCE ON UNIVERSAL MULTISERVICE NETWORKS, CONFERENCE PROCEEDINGS, P107, DOI 10.1109/ECUMN.2002.1002095
   ZIVIANI A, 2002, P INT S PERF EV COMP, P25
   ZIVIANI A, 2001, P 17 INT TEL C ITC17, P907
NR 38
TC 57
Z9 61
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2005
VL 26
IS 1
BP 59
EP 80
DI 10.1007/s11042-005-6849-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 915EU
UT WOS:000228281600003
DA 2024-07-18
ER

PT J
AU Mohanna, F
   Mokhtarian, F
AF Mohanna, F
   Mokhtarian, F
TI An efficient active contour model through curvature scale space
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE active contour; dynamic programming; curvature; energy-minimising;
   curvature scale space; edge detector
ID GRADIENT VECTOR FLOW; OBJECT TRACKING; NATURAL SCENES; ALGORITHM; SNAKE;
   EXTRACTION; SEQUENCES
AB Active contour models can be successfully used in multimedia database retrieval systems if they have good accuracy and high speed. The majority of existing active contour models do not lock on to interest objects very accurately and quickly especially in complex images. The behavior of the active contour is generally controlled by its internal and external energies. Internal energy is composed of two parts; the first part acts to shorten the active contour as it iterates towards the interest object, while the second part is the curvature of the active contour and forces smoothness of active contour during its movement towards interest object. In this paper, first a reformulated internal energy is proposed to improve the computation of curvature at point vi by making use of the three points v(i-1), v(i) and v(i+1). Second, an accurate and high speed active contour model, SAC is proposed based on reformulating internal energy by removing the curvature part and using Gaussian filtering with low scale of smoothing. The SAC model has only one parameter that affects the internal energy of active contour and as a result of using the Curvature Scale Space (CSS)(1) technique for smoothing, the SAC model is more independent of model parameter setting and the initial snake.
C1 Univ Surrey, Dept Elect & Elect Engn, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Mohanna, F (corresponding author), Univ Surrey, Dept Elect & Elect Engn, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM F.Mohanna@ee.surrey.ac.uk; F.Mokhtarian@ee.surrey.ac.uk
RI Mohanna, Farahnaz/AEQ-4401-2022
OI Mohanna, Farahnaz/0000-0002-8689-6201
CR AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   AMINI AA, 1988, P 2 INT C COMP VIS, P95
   Caselles V., 1995, INT C COMP VIS ICCV
   Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810
   Davatzikos C, 1999, IMAGE VISION COMPUT, V17, P27, DOI 10.1016/S0262-8856(98)00087-0
   DELANGES P, 1995, PATTERN RECOGN LETT, V16, P171, DOI 10.1016/0167-8655(94)00086-I
   EVIATAR H, 1998, J PATTERN RECOGNITIO, V1, P18
   GIRALDI GA, 2000, IEEE COMP SOC C COMP, V1, P44
   GRZESZUK RP, 1995, IEEE T PATTERN ANAL
   Ip HHS, 1998, IMAGE VISION COMPUT, V16, P135, DOI 10.1016/S0262-8856(97)00051-6
   JI L, 1999, P IEEE INT C IM PROC, V3, P193
   Kang DJ, 1999, ELECTRON LETT, V35, P1070, DOI 10.1049/el:19990716
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KIM W, 1999, IEEE INT C INT ROB S, V1, P216
   Lam CL, 1998, PATTERN RECOGN LETT, V19, P491, DOI 10.1016/S0167-8655(98)00015-4
   LUO H, 2000, P IEEE COMP SOC C CO, V1, P452
   Marques JS, 1998, SIGNAL PROCESS, V67, P271, DOI 10.1016/S0165-1684(98)00044-9
   MOHANNA F, 2001, INT C IM PROC THESS, V2, P781
   NAYAR SK, 1996, P ARPA IM UND WORKSH
   Ngoi KP, 1996, PATTERN RECOGN LETT, V17, P1271, DOI 10.1016/0167-8655(96)00076-1
   Ngoi KP, 1999, IMAGE VISION COMPUT, V17, P955, DOI 10.1016/S0262-8856(98)00169-3
   Peterfreund N, 1999, COMPUT VIS IMAGE UND, V73, P346, DOI 10.1006/cviu.1998.0732
   Ravi D, 2000, MATH METHOD APPL SCI, V23, P709, DOI 10.1002/(SICI)1099-1476(20000525)23:8<709::AID-MMA127>3.0.CO;2-F
   Wang M, 1996, IEEE T IMAGE PROCESS, V5, P1586, DOI 10.1109/83.541430
   WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Yoshida M, 2000, GONDWANA RES, V3, P253, DOI 10.1016/S1342-937X(05)70102-7
   Yuen PC, 1999, PATTERN RECOGN LETT, V20, P141, DOI 10.1016/S0167-8655(98)00117-2
NR 29
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2003
VL 21
IS 3
BP 225
EP 242
DI 10.1023/A:1025718816384
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 721VY
UT WOS:000185340200002
DA 2024-07-18
ER

PT J
AU Shaik, A
   Saxena, S
   Gupta, M
   Parveen, N
AF Shaik, Amjan
   Saxena, Surabhi
   Gupta, Manisha
   Parveen, Nikhat
TI Heterogeneous data-based information retrieval using a fine-tuned
   pre-trained BERT language model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Information retrieval; Fine-tuned BERT; Syntax BERT; Paragraph
   extraction; Topical attention; Self-attention; Syntax mask
AB Automatic information retrieval from written documents is made possible through natural language processing (NLP). Due to the uncertainty and diversity of real languages, the application of information retrieval is challenging. However, with the development of NLP methods based on deep learning, the issues have been alleviated through information learning criteria. Deep learning-based information retrieval technique provides the answers to their queries as a single piece of specialized information rather than a whole document. Therefore, in the proposed framework, a novel and hybrid BERT model is developed to perform the NLP based information retrieval process. Query input uses information retrieval from the entire document through two different stages of paragraph extraction and information retrieval. Here, the paragraph extraction is employed using the syntax Bidirectional encoder representations from transformers (BERT), and the information retrieval is employed through the fine-tuned BERT. The loss function of the fine-tuned BERT is optimized using the proposed Adaptive Improved Arithmetic Optimization (AIAO) algorithm for enhancing retrieval accuracy by minimizing information loss during the learning phase. The proposed AIAO-FT information retrieval method is analyzed based on various assessment measures like Precision, Recall, F1-Score, Bleu_Score, and RIBES_score and accomplished the values of 0.700, 0.767, 0.732, 0.721, and 0.776 respectively.
C1 [Shaik, Amjan] St Peters Engn Coll, Dept CSE, Hyderabad, TS, India.
   [Saxena, Surabhi] Poornima Univ, Fac Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Gupta, Manisha] Univ Technol & Appl Sci, Dept Informat Technol, Sect Math, Muscat, Oman.
   [Parveen, Nikhat] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
C3 St. Peter's Institute of Higher Education & Research; Koneru Lakshmaiah
   Education Foundation (K L Deemed to be University)
RP Parveen, N (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM saxenasurabhi1987@gmail.com; manisha.gupta@utas.edu.om;
   nikhat0891@gmail.com
RI Parveen, Nikhat/IUM-8961-2023
OI Parveen, Nikhat/0000-0003-2939-0025; Saxena, Surabhi/0000-0002-4518-059X
CR Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Agboola B, 2019, Library Philosophy and Practice, P1
   Alnaied A, 2020, EGYPT INFORM J, V21, P209, DOI 10.1016/j.eij.2020.02.004
   Azzopardi L, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1321, DOI 10.1145/3331184.3331398
   Balaneshinkordan S, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103238
   Barbosa A, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295977
   Cabanac G, 2021, InACM SIGIR Forum, V54, P1
   Chouni Y, 2019, PROCEDIA COMPUT SCI, V151, P1108, DOI 10.1016/j.procs.2019.04.157
   Chu XT, 2023, Arxiv, DOI arXiv:2301.12700
   Deo A, 2018, Intl J Adv Res Comput Sci, V9
   Gudivada A, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P250, DOI 10.1109/SSCI.2018.8628846
   Gudivada V.N. R., 2018, Handbook of statistics, V38, P331, DOI [DOI 10.1016/BS.HOST.2018.07.009, 10.1016/bs.host.2018.07.009]
   Huibers T, 2021, InACM SIGIR Forum, V53, P76
   Husain M.S., 2020, Natural Language Processing in Artificial Intelligence, P29, DOI [10.1201/9780367808495-2, DOI 10.1201/9780367808495-2]
   Ibrihich S., 2022, PROCEDIA COMPUTER SC, V201, P777, DOI [10.1016/j.procs.2022.03.106, DOI 10.1016/J.PROCS.2022.03.106]
   Kim Y, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104061
   Kocián M, 2022, AAAI CONF ARTIF INTE, P12369
   Kong J, 2022, KNOWL-BASED SYST, V238, DOI 10.1016/j.knosys.2021.107872
   Kowsher M, 2019, International Journal on Natural Language Computing (IJNLC), V8
   Mahalakshmi P, 2021, Webology, V18
   Marcos-Pablos S, 2020, SOFT COMPUT, V24, P5551, DOI 10.1007/s00500-018-3568-0
   Mitra B, 2018, FOUND TRENDS INF RET, V13, P1, DOI 10.1561/1500000061
   Mothe J, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10122135
   Munir Kamran, 2018, Applied Computing and Informatics, V14, P116, DOI 10.1016/j.aci.2017.07.003
   Pang L, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P499, DOI 10.1145/3397271.3401104
   Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341
   Rondeau MA, 2018, MACHINE READING FOR QUESTION ANSWERING, P12
   Sansone C, 2022, INFORM SYST, V106, DOI 10.1016/j.is.2021.101967
   Selvalakshmi B, 2019, CLUSTER COMPUT, V22, P12871, DOI 10.1007/s10586-018-1789-8
   Sharma DK, 2022, MEASUREMENT, V198, DOI 10.1016/j.measurement.2022.111300
   Thakur N, 2021, Arxiv, DOI arXiv:2104.08663
   Wiggers G., 2018, Proceedings of the 17th Dutch-Belgian Information Retrieval Workshop, P5
   Zhang P, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102747
NR 33
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17868-4
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500002
DA 2024-07-18
ER

PT J
AU Singh, MK
   Chand, S
AF Singh, Manoj Kumar
   Chand, Satish
TI Hybrid sigmoid activation function and transfer learning assisted breast
   cancer classification on histopathological images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Neural network; Histopathological images; Cancer
   detection; Transfer learning; Activation function
AB Breast cancer is the most widespread form of cancer diseases among women. Such oncoviral cancer starts in the epithelial lining of the lobules or ducts in the breast gland tissue. Identifying and classifying breast cancer presents a significant challenge for researchers and scientists. Neural networks have emerged as a powerful tool for classifying cancer data through feature extraction. This paper addresses the challenge of accurately classifying breast cancer using a novel approach that combines a hybrid sigmoid activation function (HSAF) with transfer learning, utilizing the pre-trained EfficientNetB6 model. The HSAF is specifically designed to capture complex patterns within histopathological images, while transfer learning leverages prior knowledge from the pre-trained model. In our experimental approach, we employ a breast histopathological image dataset, dividing it into three segments: 60% for training, 20% for validation, and 20% for testing. Furthermore, data augmentation techniques are performed to increase the size of training data. The experimental results of this research indicate an impressive precision, recall, and F1 score of 91%. Furthermore, our proposed model is compared to existing methods, demonstrating its efficiency. We also conduct a comparative study of activation functions (AFs), highlighting the classification performance of HSAF for breast cancer. This research not only advances our ability to classify breast cancer more accurately but also serves as a catalyst for raising awareness and alleviating concerns related to breast cancer. By integrating advanced technology and innovative techniques, this paper aims to make a meaningful contribution to the early detection and effective treatment of this widespread and life-affecting disease.
C1 [Singh, Manoj Kumar; Chand, Satish] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Singh, MK (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM mkniranjan.ittech@gmail.com; schand@mail.jnu.ac.in
RI Singh, Manoj Kumar/AAA-9369-2020
OI Singh, Manoj Kumar/0000-0002-9098-6189; Singh, Manoj
   Kumar/0009-0007-5666-0963
CR Abunasser BS, 2022, Int J Adv Comput Sci Appl, V13, P7
   Ahmad HM, 2019, INT BHURBAN C APPL S, P328, DOI 10.1109/ibcast.2019.8667221
   Ahmad N, 2022, VISUAL COMPUT, V38, P2751, DOI 10.1007/s00371-021-02153-y
   Alghodhaifi H, 2019, PROC NAECON IEEE NAT, P374, DOI [10.1109/naecon46414.2019.9057822, 10.1109/NAECON46414.2019.9057822]
   Allugunti VR., 2022, INT J ENG COMPUT SCI, V4, P49, DOI DOI 10.33545/26633582.2022.V4.I1A.68
   Alruwaili M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030876
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   American Cancer Society, 2022, About us
   [Anonymous], 2014, WHO POSITION PAPER M
   Nguyen CP, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P366, DOI [10.1109/iscit.2019.8905196, 10.1109/ISCIT.2019.8905196]
   Deepa BG, 2022, MULTIMED TOOLS APPL, V81, P8575, DOI 10.1007/s11042-022-12114-9
   Fathy WE, 2019, INT J ADV COMPUT SC, V10, P175
   Gupta I, 2022, MULTIMED TOOLS APPL, V81, P36309, DOI 10.1007/s11042-021-11853-5
   Hassan SA, 2020, MULTIMED TOOLS APPL, V79, P30735, DOI 10.1007/s11042-020-09518-w
   Jannesari M, 2018, IEEE INT C BIOINFORM, P2405, DOI 10.1109/BIBM.2018.8621307
   Kaur P., 2019, Informatics in Medicine Unlocked, V16, DOI [DOI 10.1016/J.IMU.2019.01.001, 10.1016/j.imu.2019.01.001]
   Maan J, 2022, Int J Comput Sci Trends Appl, V2202
   Mobark N, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147080
   Mooney Paul, 2018, about us
   Nawaz M, 2018, INT J ADV COMPUT SC, V9, P316
   Rabiei Reza, 2022, J Biomed Phys Eng, V12, P297, DOI 10.31661/jbpe.v0i0.2109-1403
   Rachapudi V, 2021, EVOL INTELL, V14, P1337, DOI 10.1007/s12065-020-00367-y
   Reshma VK, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/8363850
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Sharma S, 2022, ICT EXPRESS, V8, P101, DOI 10.1016/j.icte.2021.11.010
   Sharma S, 2020, VISUAL COMPUT, V36, P1755, DOI 10.1007/s00371-019-01768-6
   Singh R, 2021, IEEE ACM T COMPUT BI, V18, P83, DOI 10.1109/TCBB.2020.2980831
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P5849, DOI 10.1007/s11042-021-11775-2
   The American Cancer Society, 2021, about us
   Turkki R, 2019, BREAST CANCER RES TR, V177, P41, DOI 10.1007/s10549-019-05281-1
   Wang XM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172767
   Wei BZ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P348, DOI 10.1109/ICCCBDA.2017.7951937
   WHO, 2023, Global breast cancer initiative implementation framework: assessing, strengthening and scaling up of services for the early detection and management of breast cancer
   WHO, 2021, about us
   Yadavendra, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01094-1
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 26
PY 2023
DI 10.1007/s11042-023-17808-2
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB6Q4
UT WOS:001129615800002
DA 2024-07-18
ER

PT J
AU Raghavan, K
   Sivaselvan, B
   Kamakoti, 
AF Raghavan, Kaushik
   Sivaselvan, B.
   Kamakoti, V
TI Attention guided grad-CAM : an improved explainable artificial
   intelligence model for infrared breast cancer detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Explainable AI; Clinical thermography; Bio-medical image analysis;
   Ensemble pre-trained networks
ID BLACK-BOX; FEATURES; NETWORKS
AB Explainable artificial intelligence (XAI) can help build trust between AI models and healthcare professionals in the context of medical image classification. XAI can help explain the reasoning behind predictions, which can help healthcare professionals understand and trust the AI model. This paper presents a novel, 'attention-guided Grad-CAM,' a class of explainability algorithms that will visually reveal the reasons for prediction in image classification. To implement the proposed methods, we used infrared breast images from the" Database of Mastology Research" First; we built a classifier for detecting breast cancer using an ensemble of three pre-trained networks. Then we implemented an attention-guided Grad-CAM using channel and spatial attention to visualize the critical regions of infrared breast image that will explain the reasons for the predictions. The proposed ensemble of the pre-trained network was able to classify the breast thermograms (Healthy / Tumour) with an accuracy of 98.04% (Precision: 97.22%, Specificity: 97.77%, Sensitivity: 98.21%, F1-Score: 97.49, AUC: 0.97). The proposed Attention guided Grad-CAM method was able distinctively show the hottest regions of the thermograms (tumor regions). The ablation study also showed an average drop in the model's 42.5% when the explanation maps were used instead of the original image. The activation score also increased by 25.35%. The proposed ensemble of pre-trained networks was able to classify the breast thermograms accurately, and the attention-guided Grad-CAM was able to visually explain the AI model's prediction using a heat map. The proposed model will aid in the adoption of AI techniques by healthcare professionals with trust.
C1 [Raghavan, Kaushik; Sivaselvan, B.] Indian Inst Informat Technol Design & Mfg, Kancheepuram, India.
   [Kamakoti, V] Indian Inst Technol Madras, Chennai, Tamil Nadu, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Madras
RP Raghavan, K (corresponding author), Indian Inst Informat Technol Design & Mfg, Kancheepuram, India.
EM kaushik.gr@gmail.com; sivaselvanb@iiitdm.ac.in; kama@cse.iitm.ac.in
OI Raghavan, Kaushik/0000-0003-4710-8994
CR Abhishek A, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104722
   Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Afify HM, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104704
   Ahamed MKU, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030551
   Aidossov Nurduman, 2023, SN Comput Sci, V4, P184, DOI 10.1007/s42979-022-01536-9
   Altini N, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9090475
   Marmolejo-Saucedo JA, 2022, MOBILE NETW APPL, DOI 10.1007/s11036-022-02021-6
   Bezerra LA, 2020, INT J HEAT MASS TRAN, V149, DOI 10.1016/j.ijheatmasstransfer.2019.119215
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Chebbah NK, 2023, QUANT INFR THERM J, V20, P62, DOI 10.1080/17686733.2021.2025018
   Daanouni Othmane, 2021, Advances on Smart and Soft Computing. Proceedings of ICACIn 2020. Advances in Intelligent Systems and Computing (AISC 1188), P15, DOI 10.1007/978-981-15-6048-4_2
   de Vos BD, 2019, IEEE T MED IMAGING, V38, P2127, DOI 10.1109/TMI.2019.2899534
   Deepika P, 2022, 2022 IEEE-EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS (BHI) JOINTLY ORGANISED WITH THE IEEE-EMBS INTERNATIONAL CONFERENCE ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS (BSN'22), DOI 10.1109/BHI56158.2022.9926782
   Demner-Fushman D, 2019, P CLEF C LABS EV FOR
   Dey S, 2022, MULTIMED TOOLS APPL, V81, P9331, DOI 10.1007/s11042-021-11477-9
   Fu J, 2022, SPIE, V12342, P317
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Itoh H, 2020, PROC SPIE, V11314, DOI 10.1117/12.2549532
   Jahmunah V, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105550
   Jia X, 2020, MED PHYS, V47, P1, DOI 10.1002/mp.13891
   Jiang HY, 2019, IEEE ENG MED BIO, P2045, DOI [10.1109/embc.2019.8857160, 10.1109/EMBC.2019.8857160]
   Jiao J, 2020, Laplacian Denoising Autoencoder
   Karim MM, 2022, TRANSPORT RES REC, V2676, P743, DOI 10.1177/03611981221076121
   Kim JK, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103408
   Kubach J, 2020, EPILEPSIA, V61, P421, DOI 10.1111/epi.16447
   Lee JH, 2020, EUR RADIOL, V30, P3066, DOI 10.1007/s00330-019-06652-4
   Li YC, 2019, NEUROCOMPUTING, V323, P363, DOI 10.1016/j.neucom.2018.10.014
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Mahoro E, 2022, Quantitative InfraRed Thermograph J, P1
   Meng YD, 2023, J CLIN MED, V12, DOI 10.3390/jcm12041284
   Mengying Xiao, 2021, 2021 International Conference on Electronic Information Engineering and Computer Science (EIECS), P242, DOI 10.1109/EIECS53707.2021.9587953
   Mohamed EA, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262349
   Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116
   Nunnari F, 2021, LECT NOTES COMPUT SC, V12844, P241, DOI 10.1007/978-3-030-84060-0_16
   Obikane S., 2020, Pattern Recognition, P127, DOI 10.1007/978-981-15-3651-9_12
   Olah C., 2017, Feature visualization. Distill, V2, P7
   Ornek AH, 2023, Quantitative InfraRed Thermograph J, P1
   Özbay E, 2023, ARTIF INTELL REV, V56, P3291, DOI 10.1007/s10462-022-10231-3
   Papandrianos NI, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157592
   Qjidaa M, 2022, MULTIMED TOOLS APPL, V81, P13115, DOI 10.1007/s11042-022-12030-y
   Rai A, 2020, J ACAD MARKET SCI, V48, P137, DOI 10.1007/s11747-019-00710-5
   Seerala PK., 2021, Advances in Signal Processing and Intelligent Recognition Systems, P161
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Siegel RL, 2023, CA-CANCER J CLIN, V73, P17, DOI 10.3322/caac.21763
   Silva LF, 2014, J MED IMAG HEALTH IN, V4, P92, DOI 10.1166/jmihi.2014.1226
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060052
   Sobahi N, 2022, BIOCYBERN BIOMED ENG, V42, P1066, DOI 10.1016/j.bbe.2022.08.005
   Tan MX, 2019, PR MACH LEARN RES, V97
   Torres-Galván JC, 2022, QUANT INFR THERM J, V19, P283, DOI 10.1080/17686733.2021.1918514
   Umair M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175813
   Vardhan J, 2023, Arxiv, DOI arXiv:2305.14389
   Vila-Blanco N, 2020, IEEE T MED IMAGING, V39, P2374, DOI 10.1109/TMI.2020.2968765
   von Schacky CE, 2020, RADIOLOGY, V295, P136, DOI 10.1148/radiol.2020190925
   Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020
   Windisch P, 2020, NEURORADIOLOGY, V62, P1515, DOI 10.1007/s00234-020-02465-1
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016
   Zhang YY, 2021, J NEUROSCI METH, V353, DOI 10.1016/j.jneumeth.2021.109098
NR 60
TC 2
Z9 2
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17776-7
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5L8
UT WOS:001129325100002
DA 2024-07-18
ER

PT J
AU Attar, H
   Ahmed, T
   Rabie, R
   Amer, A
   Khosravi, MR
   Solyman, A
   Deif, MA
AF Attar, Hani
   Ahmed, Tasneem
   Rabie, Rahma
   Amer, Ayman
   Khosravi, Mohammad R.
   Solyman, Ahmed
   Deif, Mohanad. A.
TI Modeling and computational fluid dynamics simulation of blood flow
   behavior based on MRI and CT for Atherosclerosis in Carotid Artery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Atherosclerosis; Carotid artery; Ansys; Heart attack; And Blood vessels
ID WALL SHEAR-STRESS; IN-VITRO; MECHANICAL-PROPERTIES;
   NUMERICAL-SIMULATION; PULSATILE FLOW; CORONARY; PLAQUE; CFD;
   HEMODYNAMICS; RECOGNITION
AB Carotid atherosclerosis is one of the main cardiovascular diseases, widely considered as the main reason for death. Atherosclerosis forms a plaque that impedes blood vessels, and if ruptured, it causes a stroke or heart attack. The treatment protocol for atherosclerosis depends heavily on plaque type, structure, and composition, affecting plaque behavior (stable/unstable) or vulnerability. The fluid-structure interaction between the blood vessels and the blood flow must be examined to study the plaque's behavior. Consequently, this paper aims to reconstruct patient-specific three-dimensional models of the blood vessels for simulation and three-dimensional (3D) Printing, particularly for the carotid artery. In addition, Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) datasets of atherosclerotic vessels are used to reconstruct the 3D model fed into a simulation program to measure the stress, strain, pressure, and velocity to assess the plaque. Five analyses studies were conducted on the constructed blood vessels; Non-pathological Flow in a cylindrical artery, Pathological Flow in a cylindrical artery, Non-pathological Flow in a 2D bifurcating carotid artery, Blood flow analysis in a normal carotid artery, and Blood flow analysis in a stenosed carotid artery. Two validation studies were performed for normal and atherosclerotic arteries. The results agreed with previous well-published work, considering that a 3D realistic model was printed for the vessel. Based on the above, our work provides a simulation environment for predicting atherosclerotic plaque behavior that helps medical specialists choose the proper treatment and preventive medical plans.
C1 [Attar, Hani; Amer, Ayman] Zarqa Univ, Dept Energy Engn, Zarqa, Jordan.
   [Ahmed, Tasneem; Rabie, Rahma] Modern Univ Technol & Informat MTI Univ, Dept Bioelect, Cairo, Egypt.
   [Khosravi, Mohammad R.] Weifang Univ Sci & Technol, Shandong Prov Univ Lab Protected Hort, Weifang 262799, Shandong, Peoples R China.
   [Solyman, Ahmed] Gelisim Univ, Dept Elect & Elect Engn, Istanbul, Turkiye.
   [Deif, Mohanad. A.] Misr Univ Sci & Technol MUST Univ, Dept Artificial Intelligence Technol, Giza, Egypt.
C3 Zarqa University; Istanbul Gelisim University
RP Khosravi, MR (corresponding author), Weifang Univ Sci & Technol, Shandong Prov Univ Lab Protected Hort, Weifang 262799, Shandong, Peoples R China.
EM Hattar@zu.edu.jo; Tasneim.22706@eng.mti.edu.eg;
   Raham.19664@eng.mti.edu.eg; Aamer@zu.edu.jo; mohammadkhosravi@acm.org;
   aaasahmed@gelisim.edu.tr; Mohanad.Deif@gmail.com
RI Khosravi, Mohamadreza (Mohammad Reza)/KOD-0343-2024; Attar,
   Hani/ACM-2908-2022
FU Fawzi from Mechanical Engineering Dept., Cairo University; National
   Institute of Health (NIH)
FX The authors would like to thank Waleed, Mohammed Salem and Fawzi from
   Mechanical Engineering Dept., Cairo University. Also, Dr. Khaled Zakaria
   of the National Institute of Health (NIH) for providing the MRI dataset,
   and Dr. Mohammed Donya of the cardiovascular department, Nile Scan for
   CT data.
CR Abazari MA, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95315-w
   Adewopo V, 2022, Arxiv, DOI [arXiv:2208.09588, 10.48550/arXiv.2208.09588, DOI 10.48550/ARXIV.2208.09588]
   Andelovic K, 2021, BIOMEDICINES, V9, DOI 10.3390/biomedicines9020185
   Attia RM, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P72, DOI [10.1109/itce48509.2020.9047796, 10.1109/ITCE48509.2020.9047796]
   Badimon L, 2014, J INTERN MED, V276, P618, DOI 10.1111/joim.12296
   Bento D, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11040344
   Carpenter HJ, 2020, INT J ENG SCI, V147, DOI 10.1016/j.ijengsci.2019.103201
   Carvalho V, 2020, Open Biomed. Eng. J, P87, DOI [10.2174/1874120702014010087, DOI 10.2174/1874120702014010087]
   Carvalho V, 2021, FLUIDS, V6, DOI 10.3390/fluids6080284
   Carvalho V, 2021, COMPUT METHOD BIOMEC, V24, P623, DOI 10.1080/10255842.2020.1842377
   Carvalho V, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11060549
   Chaichana T, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/504367
   Chaichana T, 2013, ACTA BIOENG BIOMECH, V15, P107, DOI 10.5277/abb130313
   Chayer B, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab1145
   Chen CX, 2012, ANZIAM J, V53, P278, DOI 10.1017/S1446181112000168
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen JW, 2022, IEEE WINT CONF APPL, P786, DOI 10.1109/WACV51458.2022.00086
   Chen YW, 2022, FUND RES-CHINA, V2, P329, DOI 10.1016/j.fmre.2021.09.019
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Dabagh M, 2013, J APPL MATH, DOI 10.1155/2013/715407
   Das Srijan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P72, DOI 10.1007/978-3-030-58545-7_5
   Das S, 2019, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2019.00092
   De Boissiere AM, 2020, IEEE ACCESS, V8, P168297, DOI 10.1109/ACCESS.2020.3023599
   Diskin Y, 2013, 2013 IEEE APPL IMAGE, P1
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Doutel E, 2018, EUR J MECH B-FLUID, V67, P341, DOI 10.1016/j.euromechflu.2017.09.009
   Elhanafy A, 2020, J MOL LIQ, V313, DOI 10.1016/j.molliq.2020.113550
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Formaggia L, 2009, MS A MOD SIMUL, V1, P1, DOI 10.1007/978-88-470-1152-6
   Friedman MH, 2005, ANN BIOMED ENG, V33, P1710, DOI 10.1007/s10439-005-8773-1
   Fröhlich E, 2014, INT J MOL SCI, V15, P4795, DOI 10.3390/ijms15034795
   Gamage PT, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104962
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Goudot G, 2021, ULTRASCHALL MED, V42, P297, DOI 10.1055/a-1060-0529
   Han D, 2016, J AM HEART ASSOC, V5, DOI 10.1161/JAHA.116.004186
   Hewlin RL, 2018, CARDIOVASC ENG TECHN, V9, P1, DOI 10.1007/s13239-017-0332-z
   Hossain SS, 2021, BIOMECH MODEL MECHAN, V20, P2071, DOI 10.1007/s10237-021-01495-9
   Hoving AM, 2020, CARDIOVASC ENG TECHN, V11, P111, DOI 10.1007/s13239-019-00448-9
   Hu JF, 2018, LECT NOTES COMPUT SC, V11211, P346, DOI 10.1007/978-3-030-01234-2_21
   Islam MM, 2020, IEEE INT C INT ROBOT, P10285, DOI 10.1109/IROS45743.2020.9340987
   Kabiriejadian F, 2014, MED ENG PHYS, V36, P1233, DOI 10.1016/j.medengphy.2014.06.024
   Kadem M, 2023, IEEE REV BIOMED ENG, V16, P403, DOI 10.1109/RBME.2022.3142058
   Kamangar S, 2019, BIO-MED MATER ENG, V30, P463, DOI 10.3233/BME-191067
   Karimi A, 2014, BIOMED ENG-APP BAS C, V26, DOI 10.4015/S1016237214500136
   Karimi A, 2013, MAT SCI ENG C-MATER, V33, P2550, DOI 10.1016/j.msec.2013.02.016
   Kashyap V, 2020, APPL ENG SCI, V4, DOI 10.1016/j.apples.2020.100027
   Kim HJ, 2010, ANN BIOMED ENG, V38, P3195, DOI 10.1007/s10439-010-0083-6
   Ku DN, 1997, ANNU REV FLUID MECH, V29, P399, DOI 10.1146/annurev.fluid.29.1.399
   LaDisa JF, 2006, BIOMED ENG ONLINE, V5, DOI 10.1186/1475-925X-5-40
   Lee J, 2012, ANN BIOMED ENG, V40, P2399, DOI 10.1007/s10439-012-0583-7
   Li JN, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107356
   Libby P, 2019, NAT REV DIS PRIMERS, V5, DOI [10.1038/s41572-019-0106-z, 10.1038/s41572-019-0116-x]
   Lieber BB, 2005, ANN BIOMED ENG, V33, P1695, DOI 10.1007/s10439-005-8760-6
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Lin WY, 2008, IEEE INT SYMP CIRC S, P2737, DOI 10.1109/ISCAS.2008.4542023
   Liu GY, 2019, IEEE INT C INT ROBOT, P258, DOI [10.1109/IROS40897.2019.8967570, 10.1109/iros40897.2019.8967570]
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu TS, 2019, IEEE SENS J, V19, P1862, DOI 10.1109/JSEN.2018.2884443
   Lopes D, 2020, J BIOMECH, V111, DOI 10.1016/j.jbiomech.2020.110019
   Lopes D, 2019, INT J MECH SCI, V160, P209, DOI 10.1016/j.ijmecsci.2019.06.029
   Lusis AJ, 2000, NATURE, V407, P233, DOI 10.1038/35025203
   Mehta S, 2021, Arxiv, DOI arXiv:2008.00623
   Mulani S.S., 2015, Int. Eng. Res. J, V41, P2319
   Nannini G., 2021, Comput Biol Med, V104581, P135, DOI [10.1016/j.compbiomed.2021.10458, DOI 10.1016/J.COMPBIOMED.2021.10458]
   Nannini G, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104581
   Othman NA, 2021, TRAIT SIGNAL, V38, P1403, DOI 10.18280/ts.380515
   Pandey R, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105661
   Pandey R, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105243
   Papathanasopoulou P, 2003, J MAGN RESON IMAGING, V17, P153, DOI 10.1002/jmri.10243
   Park SM, 2010, J MECH MED BIOL, V10, P695, DOI 10.1142/S0219519410003812
   Parmar N, 2018, Arxiv, DOI arXiv:1802.05751
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Qiu HL, 2022, Arxiv, DOI arXiv:2201.02849
   Razavi A, 2011, J BIOMECH, V44, P2021, DOI 10.1016/j.jbiomech.2011.04.023
   Rezvan A, 2011, ANTIOXID REDOX SIGN, V15, P1433, DOI 10.1089/ars.2010.3365
   Rodrigues RO, 2020, SMALL, V16, DOI 10.1002/smll.202003517
   Samady H, 2011, CIRCULATION, V124, P779, DOI 10.1161/CIRCULATIONAHA.111.021824
   Sandra S, 2017, IEEE T ULTRASON FERR, V64, P11, DOI 10.1109/TUFFC.2016.2597246
   SANTAMORE WP, 1980, AM HEART J, V100, P852, DOI 10.1016/0002-8703(80)90066-6
   Settecase Fabio, 2021, Handb Clin Neurol, V176, P81, DOI 10.1016/B978-0-444-64034-5.00016-X
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shanmugavelayudam SK, 2010, J BIOMECH ENG-T ASME, V132, DOI 10.1115/1.4001033
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Siasos G, 2018, J AM COLL CARDIOL, V71, P2092, DOI 10.1016/j.jacc.2018.02.073
   Simonyan K, 2014, ADV NEUR IN, V27
   Smith KA, 2021, ANN BIOMED ENG, V49, P3255, DOI 10.1007/s10439-021-02851-7
   Song SJ, 2018, IEEE INT CON MULTI
   Soulis JV, 2014, HIPPOKRATIA, V18, P12
   Souza A, 2020, MECH RES COMMUN, V107, DOI 10.1016/j.mechrescom.2020.103535
   Sriyab S, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/479152
   Starodumov IO, 2022, PHILOS T R SOC A, V380, DOI 10.1098/rsta.2020.0303
   Stepniak K, 2019, BIOMED PHYS ENG EXPR, V5, DOI 10.1088/2057-1976/ab2696
   Su L, 2021, Arxiv, DOI arXiv:2012.07175
   Sun Y., 2018, Front. Lab. Med, V2, P68, DOI DOI 10.1016/J.FLM.2018.07.002
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tzeng E., 2020, arXiv, DOI DOI 10.48550/ARXIV.2012.09958
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma P, 2020, MULTIMEDIA SYST, V26, P671, DOI 10.1007/s00530-020-00677-2
   Versteeg H.K., 2007, An Introduction to Computational Fluid Dynamics: The Finite Volume Method, Vsecond, DOI DOI 10.2514/1.22547
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Warey A, 2021, ENERGY AI, V5, DOI 10.1016/j.egyai.2021.100080
   Xu W, 2021, IEEE SENS J, V21, P19157, DOI 10.1109/JSEN.2021.3089705
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yanhong Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P528, DOI 10.1007/978-3-030-58517-4_31
   Yazdi SG, 2018, ANN BIOMED ENG, V46, P1697, DOI 10.1007/s10439-018-2085-8
   Yilmaz F, 2008, KOREA-AUST RHEOL J, V20, P197
   Yu Q., 2021, arXiv
   Yu QH, 2022, PROC CVPR IEEE, P2550, DOI 10.1109/CVPR52688.2022.00259
   Zaromytidou M, 2016, HELL J CARDIOL, V57, P389, DOI 10.1016/j.hjc.2016.11.019
   Zhang JM, 2014, INT J NUMER METH BIO, V30, P659, DOI 10.1002/cnm.2625
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
   Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316
   Zuo Y, 2020, SCI TRANSL MED, V12, DOI 10.1126/scitranslmed.abd3876
NR 119
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17765-w
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800003
DA 2024-07-18
ER

PT J
AU An, K
   Lu, ZM
   Sun, XC
   Wang, ZH
AF An, Kai
   Lu, Zhe-Ming
   Sun, Xue-Cheng
   Wang, Zong-Hui
TI Multipurpose video watermarking algorithm for copyright protection and
   tamper detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video watermarking; Multipurpose watermarking; Tamper detection;
   Geometric attacks
ID IMAGE WATERMARKING; ROBUST; DOMAIN
AB With the rise of short video and the development of self-media, video has become a type of frequently used data, thus the protection of video data is particularly important. Digital watermarking is a very effective digital authentication and copyright protection technology that hides a piece of data called watermark into digital multimedia content. However, most existing video watermark algorithms fail to deal with the videos under geometric distortions, and they only focus on copyright protection, ignoring the task of tamper detection. This paper proposes a multipurpose video watermarking algorithm that is resistant to rotation and scaling attacks while providing both copyright protection and tamper detection. We design a DFT template embedding method to make the watermarking algorithm resistant to rotation and scaling attacks efficiently. This method can detect the rotation and scaling that the video has undergone during the watermark extraction process, and then extract the copyright watermark information based on geometric correction. In addition, we propose a robust watermark embedding method with tamper detection function, which embeds copyright watermark information with validation bits in the DCT coefficients of I frames. By embedding the copyright watermark block by block, the algorithm can not only improve the robustness, but also enable the system to detect tampering. Experiments show that the proposed algorithm has good robustness to various attacks such as compression, filtering, rotation, scaling, frame rate changing and other inter-frame operations, and it outperforms previous geometrically robust algorithm by an average of 12.8% under geometric attacks on the normalized correlation values. Also, we show that our algorithm is effective in tamper detection by localizing the distorted areas in the video frames.
C1 [An, Kai; Lu, Zhe-Ming; Sun, Xue-Cheng] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.
   [Wang, Zong-Hui] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.; Wang, ZH (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM zheminglu@zju.edu.cn; zhwang@zju.edu.cn
FU National Key Research and Development Program of China [2020AAA0140004];
   Public Good Research Project of Science and Technology Program of
   Zhejiang Province [LGG21F020005]
FX This work is supported in part by the National Key Research and
   Development Program of China under Grant No.2020AAA0140004 and the
   Public Good Research Project of Science and Technology Program of
   Zhejiang Province under Grant No.LGG21F020005.
CR Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Chemak C, 2007, P 2007 SUMM COMP SIM, P1201
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Clark R.J., 1985, TRANSFORM CODING IMA
   Das Soumik, 2017, International Journal of Image, Graphics and Signal Processing, V9, P40, DOI 10.5815/ijigsp.2017.09.05
   Deb K., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P458, DOI 10.1109/ICECE.2012.6471586
   Gupta BB., 2020, Handbook of Research on Multimedia Cyber Security, P90, DOI [10.4018/978-1-7998-2701-6.ch005, DOI 10.4018/978-1-7998-2701-6.CH005]
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lei BY, 2019, MULTIMED TOOLS APPL, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2005, IEEE Int Conf Image Process, V2005, pII
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Sharkas M, 2005, PROC WRLD ACAD SCI E, V5, P136
   Shi H, 2016, MULTIMED TOOLS APPL, V75, P465, DOI 10.1007/s11042-014-2301-y
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Sun XC, 2021, MULTIMED TOOLS APPL, V80, P13491, DOI 10.1007/s11042-020-10392-9
   Wang YG, 2018, IEEE ACCESS, V6, P15816, DOI 10.1109/ACCESS.2018.2802928
   Wu KX, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P668
   Xiph.Org Foundation, 2020, Xiph.org Video Test Media
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
NR 25
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17558-1
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900010
DA 2024-07-18
ER

PT J
AU Srinivasan, P
   Doraipandiyan, M
   Lakshmi, KD
   Panchada, V
   Krithivasan, K
AF Srinivasan, Palanivel
   Doraipandiyan, Manivannan
   Lakshmi, K. Divya
   Panchada, Vamsi
   Krithivasan, Kannan
TI Grid sampling based hypergraph matching technique for multiple objects
   tracking in video frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object matching; Hypergraph; Grid sampling; KAZE; SIFT; Optimization
ID RARE-EVENT DETECTION
AB Multiple Object Tracking (MOT), which is a vibrant research area in computer vision, has many multi-disciplinary applications. The evolution of Machine Learning (ML) techniques has brought out a wide variety of data analytics schemes especially in video processing for IOT implementations. Recently graph powered ML techniques with its added topological capabilities have gained much importance due to their applicability in computer vision applications. Yet complexity issues remain unresolved as several graph based techniques reduce the computational complexity at the cost of accuracy. Hypergraphs (HG) with its topological and geometric features add values to the existing features which increase the accuracy with reduced complexity and also pave a way to track multiple objects simultaneously. This paper presents one such novel HG matching algorithm (objects described by modified KAZE key-points) and a feature extraction technique to process video frames with multiple objects. For ascertaining independency of HG based KAZE features Chi - square test has been conducted with its value (1.0845), observed to be much less than the tabular value (7.962) to accept the null hypothesis at 5% level of significance. Among the 8 pre-processing schemes KAZE has been found to be an apt model to suit grid sampling-based HG representation and it has been proved by computational experiments that it produces new matches between frames. The evaluation of the proposed technique is done in terms of matching accuracy, score, and processing time. Grid sampling with HG, exhibited an average better tracking performance of 81.51% (of all consecutive pairs of frames with multiple objects) than the recently reported one of 73.88% accuracy (with single object image matching) with same reduced tensor size. Moreover, the matching accuracy between every pair of consecutive video frames is observed to be consistent and lying between 77.78 and 81.51%. Results obtained from this investigation clearly indicate the superiority of the proposed algorithm over recently reported ones in the literature in terms of consistency, accuracy and matching scores and its applicability in quick abnormal event detection in surveillance videos.
C1 [Srinivasan, Palanivel; Doraipandiyan, Manivannan; Panchada, Vamsi; Krithivasan, Kannan] Sastra Deemed Univ, Thanjavur, Tamil Nadu, India.
   [Lakshmi, K. Divya] VIT Univ, Vellore, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA); Vellore
   Institute of Technology (VIT); VIT Vellore
RP Doraipandiyan, M (corresponding author), Sastra Deemed Univ, Thanjavur, Tamil Nadu, India.
EM dmv@cse.sastra.edu
FU The authors are grateful to express their sincere thanks to SASTRA
   Deemed to be University, Thanjavur for extending 'computing center'
   support to carry out this research work. One of the authors of the paper
   wishes to acknowledge Department of Science and; SASTRA
   [DST/CRG/2023/006090]; Department of Science and Technology, Government
   of India [BIRAC/CCAMP0949/BIG-14/19]; BIRAC-BIG Grant; CCamp (Centre for
   Cellular and Molecular Platforms)
FX The authors are grateful to express their sincere thanks to SASTRA
   Deemed to be University, Thanjavur for extending 'computing center'
   support to carry out this research work. One of the authors of the paper
   wishes to acknowledge Department of Science and Technology, Government
   of India for their financial support to carry out this project (Grant
   No. DST/CRG/2023/006090) and BIRAC-BIG Grant
   (BIRAC/CCAMP0949/BIG-14/19), CCamp (Centre for Cellular and Molecular
   Platforms) for their financial support.
CR Acar E, 2017, MULTIMED TOOLS APPL, V76, P11809, DOI 10.1007/s11042-016-3618-5
   Ahuja U, 2023, MULTIMED TOOLS APPL, V82, P7553, DOI 10.1007/s11042-022-13718-x
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bloisi DD, 2017, IEEE T INTELL TRANSP, V18, P824, DOI 10.1109/TITS.2016.2591321
   Bretto A., 2001, Electron Notes Theoretic Comput Sci, V46, P181, DOI [DOI 10.1016/S1571-0661(04)80985-X, 10.1016/S1571-0661(04)80985-X]
   Caetano T S, 2009, IEEE Trans Pattern Anal Mach Intell., DOI [10.48550/arXiv.0806.2890, DOI 10.48550/ARXIV.0806.2890]
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chen XJ, 2016, PROCEEDINGS 2016 IEEE SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING SOSE 2016, P225, DOI 10.1109/SOSE.2016.33
   Chen XJ, 2016, MULTIMED TOOLS APPL, V75, P15079, DOI 10.1007/s11042-015-2514-8
   Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11
   Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701
   Dharmarajan R., 2016, Studies in Hypergraphs with a few applications in Image Processing (Doctoral dissertation)
   Doran MM, 2010, ATTEN PERCEPT PSYCHO, V72, P33, DOI 10.3758/APP.72.1.33
   Du D, 2016, IEEE Trans Cybern., DOI [10.48550/arXiv.1603.05930, DOI 10.48550/ARXIV.1603.05930]
   Chau DP, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P569
   Fan YX, 2018, Arxiv, DOI [arXiv:1805.11223, 10.1016/j.cviu.2020.102920, DOI 10.48550/ARXIV.1805.11223]
   Fiscante N, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040662
   Fu SC, 2019, NEUROCOMPUTING, V362, P166, DOI 10.1016/j.neucom.2019.06.068
   Gao Y, 2022, IEEE T PATTERN ANAL, V44, P2548, DOI 10.1109/TPAMI.2020.3039374
   Guha P, 2011, P INT C IMAGE PROCES, P1
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hou J., 2021, IEEE Intern Conf Multimed Expo (ICME), DOI [10.1109/ICME51207.2021.9428156, DOI 10.1109/ICME51207.2021.9428156]
   Janjua ZH, 2019, ENG APPL ARTIF INTEL, V84, P41, DOI 10.1016/j.engappai.2019.05.011
   Ji Z, 2018, SIGNAL PROCESS, V148, P114, DOI 10.1016/j.sigpro.2018.01.028
   Kannan K, 2010, IMAGE VISION COMPUT, V28, P1329, DOI 10.1016/j.imavis.2010.01.013
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kwon J, 2012, IEEE Access, P266, DOI [10.1109/CVPR.2012.6247810, DOI 10.1109/CVPR.2012.6247810]
   Kwon J, 2015, IEEE T PATTERN ANAL, V37, P1737, DOI 10.1109/TPAMI.2014.2385695
   Lakshmi KD, 2019, MULTIMED TOOLS APPL, V78, P14657, DOI 10.1007/s11042-018-6852-1
   Lee J., 2011, CVPR, DOI [10.1109/CVPR.2011.5995387, DOI 10.1109/CVPR.2011.5995387]
   Li W., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.06398
   Lombardi E, 2015, Comput Vis Pattern Recognit, DOI [10.48550/arXiv.1505.0058, DOI 10.48550/ARXIV.1505.0058]
   Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Moon S, 2017, INT CONF ADV COMMUN, P883, DOI 10.23919/ICACT.2017.7890221
   Munjal B, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103932
   Park S, 2004, IEEE Access, P66, DOI [10.1109/CVPR.2004.434, DOI 10.1109/CVPR.2004.434]
   Park Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192406
   Poulding S, 2015, J SYST SOFTWARE, V103, P296, DOI 10.1016/j.jss.2014.11.042
   Nguyen Q, 2017, IEEE T PATTERN ANAL, V39, P1054, DOI 10.1109/TPAMI.2016.2574706
   Rajesh Khanna B., 2012, Development of hypergraph-based techniques for selected image engineering applications
   Ryoo M., 2006, 2006 IEEE COMP SOC C, V2, P1709, DOI DOI 10.1109/CVPR.2006.242
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shokri M, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102769
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Smal I, 2008, MED IMAGE ANAL, V12, P764, DOI 10.1016/j.media.2008.03.004
   Smal I, 2008, Med Image Anal, DOI [10.1007/978-3-540-73273-0_10, DOI 10.1007/978-3-540-73273-0_10]
   Somu N, 2017, FUTURE GENER COMP SY, V68, P14, DOI 10.1016/j.future.2016.08.014
   Srinivasan P, 2020, J INTELL FUZZY SYST, V39, P8463, DOI 10.3233/JIFS-189164
   Sukumaran V, 2016, S. Patent, Patent No. [9,246,924, 9246924]
   Te GS, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102720
   Walia S, 2023, MULTIMED TOOLS APPL, V82, P4517, DOI 10.1007/s11042-022-13610-8
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang RZ, 2022, IEEE T PATTERN ANAL, V44, P5261, DOI 10.1109/TPAMI.2021.3078053
   Wen LY, 2016, IEEE T PATTERN ANAL, V38, P1983, DOI 10.1109/TPAMI.2015.2509979
   Yadav Piyush, 2019, 2019 First International Conference on Graph Computing (GC), P13, DOI 10.1109/GC46384.2019.00011
   Yan YC, 2021, Arxiv, DOI [arXiv:2104.14913, 10.48550/arXiv.2104.14913, DOI 10.48550/ARXIV.2104.14913]
   Zaidenberg S., 2011, Sophia Antipolis, France, DOI [10.1109/ICME.2008.4607367, DOI 10.1109/ICME.2008.4607367]
   Zass R, 2008, PROC CVPR IEEE, P1221
   Zhang H, 2015, INT WORKSHOP GRAPH B, DOI [10.1007/978-3-319-18224-7_11, DOI 10.1007/978-3-319-18224-7_11]
NR 64
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17486-0
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100002
DA 2024-07-18
ER

PT J
AU Kaur, N
   Devendran, V
AF Kaur, Navneet
   Devendran, V.
TI A novel framework for semi-automated system for grape leaf disease
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Grape leaf disease detection; Law's texture features; Ensemble
   classification
ID CLASSIFICATION
AB Plants play a significant role in our lives. They are the primary source of food. But when these are diagnosed with diseases, productivity reduces. Grape is an important fruit, which is rich in potassium and hence is advantageous in balancing fluids in our body. Manually recognizing disease symptoms in plants is difficult due to several factors, involving time consumption and cost. A semi-automated system is proposed for grape lead disease detection. In existing systems, less accuracy has been observed and optimization of the segmentation process, hybridized feature extraction and ensemble classification has been ignored for detecting the leaf diseases. So, we have stressed on hybridization of different feature extraction algorithms and machine learning classifiers for the accurate prediction of diseases. Hence, a very novel approach is proposed that focuses on all the important stages in computerized leaf disease detection - segmentation, feature extraction and classification. To segment the diseased regions in mages, we have utilized K means clustering which is optimized using Grey Wolf Optimization (GWO). For the extraction of features, a hybrid of different algorithms has been utilized. Here, we have utilized Law's mask, which involves a convolution process for extracting features and is an acknowledged feature extraction algorithm in machine learning. Grey Level Co-occurrence Matrix, Local Binary Pattern and Gabor features have been conjunct to create a hybrid approach for robust results. Later, a newly introduced powerful ensemble classifier is applied to classify the correct diseases. A total of four categories of grape diseases have been used for the research from the "PlantVillage" dataset - Leaf Blight, Black measles, Black rot and healthy. We have compared our approach to existing approaches for detecting diseases in grape leaves. Our approach has proved to be robust as compared to existing approaches and has revealed an accuracy of 95.69%.
C1 [Kaur, Navneet; Devendran, V.] Lovely Profess Univ, Sch Comp Sci & Engn, Jalandhar, Punjab, India.
C3 Lovely Professional University
RP Kaur, N (corresponding author), Lovely Profess Univ, Sch Comp Sci & Engn, Jalandhar, Punjab, India.
EM navneetphul@gmail.com; devendran.22735@lpu.co.in
OI kaur, navneet/0000-0002-8789-4013
FU The authors thank the anonymous reviewers for helpful and constructive
   comments that greatly contributed to improving this article.
FX The authors thank the anonymous reviewers for helpful and constructive
   comments that greatly contributed to improving this article.
CR Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Afifi A.J., 2012, Int. Sch. Res. Not, V2012, DOI [10.5402/2012/248285, DOI 10.5402/2012/248285]
   Agrawal N, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P238, DOI 10.1109/RISE.2017.8378160
   Ahmed AA, 2021, AGRIENGINEERING, V3, P478, DOI 10.3390/agriengineering3030032
   Ahmed KT, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P162, DOI 10.1109/iccisci.2019.8716437
   Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Ali A, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/3114525
   Alkan A, 2021, TURK J AGRIC FOR, V45, P717, DOI 10.3906/tar-2007-105
   Andrushia AD, 2020, EVOL SYST-GER, V11, P105, DOI 10.1007/s12530-019-09289-2
   Ayu HR, 2021, Deep learning for detection cassava leaf disease, DOI [10.1088/1742-6596/1751/1/012072, DOI 10.1088/1742-6596/1751/1/012072]
   Beura S, 2015, NEUROCOMPUTING, V154, P1, DOI 10.1016/j.neucom.2014.12.032
   Bhusri S, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P56, DOI 10.1109/PDGC.2016.7913115
   Chauhan MD., 2021, Turk. J. Comput. Math. Educ., V12, P715
   Chen YP, 2023, PRECIS AGRIC, V24, P235, DOI 10.1007/s11119-022-09941-z
   Dcruz M., 2017, Int J Eng Res, V7, P61, DOI [10.9790/9622-0708066163, DOI 10.9790/9622-0708066163]
   De Certaines JD, 2015, EPJ NONLINEAR BIOMED, V3, DOI 10.1140/epjnbp/s40366-015-0017-1
   de Luna RG, 2018, TENCON IEEE REGION, P1414, DOI 10.1109/TENCON.2018.8650088
   Dhingra G, 2019, MEASUREMENT, V135, P782, DOI 10.1016/j.measurement.2018.12.027
   Fayyad M S., 2008, Artic. J. Artif. Intell, V1, P79, DOI DOI 10.3923/JAI.2008.78.85
   Francis J, 2016, 2016 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P161
   Hariharan GT., 2016, Int J Latest Trends Eng Technol (IJLTET), V6, P225
   Hum Yan Chai, 2011, WSEAS Transactions on Systems, V10, P7
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Islam MT, 2021, Lect Notes Netw Syst, V238, DOI DOI 10.1007/978-981-16-2641-8_20
   Jhuria M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P521, DOI 10.1109/ICIIP.2013.6707647
   kaggle.com, About us
   Kamal K, 2017, ADV ENG INFORM, V34, P125, DOI 10.1016/j.aei.2017.09.007
   Kamarainen JK, 2012, INT CONF IMAG PROC, P13, DOI 10.1109/IPTA.2012.6469502
   Kaur N, 2020, Mater Today Proc., DOI [10.1016/j.matpr.2020.10.901, DOI 10.1016/J.MATPR.2020.10.901]
   Kaur N., 2021, 2021 9 INT C RELIABI, P1, DOI DOI 10.1109/ICRITO51393.2021.9596070
   Kaur N., 2021, P 2021 9 INT C REL I, DOI [10.1109/icrito51393.2021.9596456, DOI 10.1109/ICRITO51393.2021.9596456]
   Kaur N, 2021, ALG COMP MATH C 19 2
   Kaur N., 2019, Feature Extraction and Ensemble Classif, V4, P121
   Kaur N., 2019, J Comput Theor Nanosci, V16, P3728, DOI [10.1166/jctn.2019.8241, DOI 10.1166/JCTN.2019.8241]
   Kaur NJ., 2021, Turkish J. Comput. Math. Educ., V12, P2339
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Kumari CU, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P1095, DOI [10.1109/iccmc.2019.8819750, 10.1109/ICCMC.2019.8819750]
   Kurmi Y, 2021, SIGNAL IMAGE VIDEO P, V15, P589, DOI 10.1007/s11760-020-01780-7
   Lin JW, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12060887
   Miaomiao J, 2022, Northeast Agric Univ, DOI [10.21203/rs.3.rs-2234059/v1, DOI 10.21203/RS.3.RS-2234059/V1]
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mittal S. C., 2001, Fertiliser News, V46, P83
   Mustafa MS, 2020, NEURAL COMPUT APPL, V32, P11419, DOI 10.1007/s00521-019-04634-7
   Nagi R, 2022, 2022 2 INT C ART INT, P2, DOI [10.1109/AISP53593.2022.9760547, DOI 10.1109/AISP53593.2022.9760547]
   Ouhami M, 2022, 2022 E HLTH BIOENG C, DOI [10.1109/EHB55594.2022.9991443, DOI 10.1109/EHB55594.2022.9991443]
   Pantazi XE, 2016, IFIP ADV INF COMM TE, V475, P319, DOI 10.1007/978-3-319-44944-9_27
   Prasad S, 2016, SIGNAL IMAGE VIDEO P, V10, P379, DOI 10.1007/s11760-015-0751-y
   Prasad S, 2012, LECT NOTES COMPUT SC, V7677, P372, DOI 10.1007/978-3-642-35380-2_44
   Pujari JD, 2016, INT J INTERACT MULTI, V3, P6, DOI 10.9781/ijimai.2016.371
   Rachidi M, 2008, I S BIOMED IMAGING, P1191, DOI 10.1109/ISBI.2008.4541215
   Ramamoorthy R., 2023, SN COMPUT SCI, V4, P158, DOI [10.1007/s42979-022-01589-w, DOI 10.1007/S42979-022-01589-W]
   Sainis JK, 2004, Applicationsof image processing in biology and agriculture
   Samatha E., 2020, Int J Adv Sci Technol, V29, P194
   Setiawan AS, 2015, PROCEDIA COMPUT SCI, V59, P92, DOI 10.1016/j.procs.2015.07.341
   Shenbagavalli R., 2011, Bonfring Int J Adv Image Process, V1, P15, DOI [10.9756/BIJAIP.1004, DOI 10.9756/BIJAIP.1004]
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Silva Diogo M., 2022, Procedia Computer Science, P125, DOI 10.1016/j.procs.2021.11.081
   Singh V, 2019, ARTIF INTELL AGR, V3, P62, DOI 10.1016/j.aiia.2019.09.002
   Sivagami S., 2021, International Journal of Agricultural Technology, V17, P1135
   Suresha M, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P663, DOI 10.1109/I2CT.2017.8226213
   Sutha P., 2021, ANN ROMANIAN SOC CEL, V25, P9430
   Szilagyi T, 2015, Semantic Scholar
   Tyagi V., 2012, INT J PHYS SOCIAL SC, V2, P116
   Varga D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062209
   Varga D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010101
   Xiong YH, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105712
NR 66
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17629-3
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600010
DA 2024-07-18
ER

PT J
AU Wu, Y
   Wang, YG
   Lou, XL
   Zhang, MW
AF Wu, Ying
   Wang, Yigang
   Lou, Xiaolong
   Zhang, Mingwei
TI An empirical practice of design and evaluation of freehand interaction
   gestures in virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Freehand interaction; Hand gestures; Virtual reality; Motion-sensing
   interaction; Human-computer interaction evaluation
ID MENU
AB Nowadays, virtual reality (VR) technologies are increasingly used in various domains. Thus, there is an urgent need to sufficiently explore a natural approach to human-computer interaction that can be customized to various situations across different user groups. In this study, we explored hand gesture types that are more effective and natural for manipulating three-dimensional (3D) objects for application in freehand interaction within a VR environment. More specifically, gestures for 3D manipulation including directional navigation, rotation, scaling, and teleportation were tracked and recognized through a Leap Motion sensor equipped in front of a head-mounted VR device and on top of 3D glasses, respectively. To systematically validate the efficiency, usability, and reliability of the hand gestures, we designed a series of representative tasks in a specifically designed VR application and then recruited 40 participants to complete all required interaction tasks using the newly designed gestures and baseline hand controller. The results showed that the gestural interaction method was sufficiently effective for accomplishing most of the interactive tasks, indicating that this method could be a viable alternative to the conventional hand controller interaction method. Moreover, users preferred the new gestural interaction method more than the conventional one in terms of user experience and immersion. Based on these results, guidelines and strategies were discussed for developing freehand interaction techniques in general VR applications.
C1 [Wu, Ying; Wang, Yigang; Lou, Xiaolong; Zhang, Mingwei] Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wu, Ying] Jiaxing Nanhu Univ, Jiaxing 314001, Zhejiang, Peoples R China.
   [Lou, Xiaolong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Hangzhou Dianzi University; Jiaxing Nanhu University; Beihang University
RP Wang, YG (corresponding author), Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou 310018, Zhejiang, Peoples R China.
EM yigang.wang@hdu.edu.cn
RI Lou, Xiaolong/AAD-9278-2022; zhang, mingwei/AAK-1077-2020
OI Lou, Xiaolong/0000-0001-9790-3780; 
FU We thank all reviewers for their insightful comments on this work. This
   research was supported by the National Natural Science Foundation of
   China under the grant number of "61902097"; the PRC Industry-University
   Collaborative Education Program under the g [61902097]; National Natural
   Science Foundation of China [CES/Kingfar202209RYJG15]; PRC
   Industry-University Collaborative Education Program [LQ19F020010];
   Natural Science Foundation of Zhejiang Province" [19NDQN301YB]; Zhejiang
   Provincial Philosophy and Social Science Planning Project
FX We thank all reviewers for their insightful comments on this work. This
   research was supported by the National Natural Science Foundation of
   China under the grant number of "61902097"; the PRC Industry-University
   Collaborative Education Program under the grant number of
   "CES/Kingfar202209RYJG15"; the "Natural Science Foundation of Zhejiang
   Province" under the grant number of "LQ19F020010"; and the Zhejiang
   Provincial Philosophy and Social Science Planning Project under the
   grant number of "19NDQN301YB".
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Adkins A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486582
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Allgaier M, 2022, INT J COMPUT ASS RAD, V17, P449, DOI 10.1007/s11548-021-02538-3
   [Anonymous], 1998, ISO I. 9241--11
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   BORG GAV, 1982, MED SCI SPORT EXER, V14, P377, DOI 10.1249/00005768-198205000-00012
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Caggianese G, 2020, INT J HUM-COMPUT INT, V36, P1734, DOI 10.1080/10447318.2020.1785151
   Chaudhary A., 2011, Int J Comput Sci Eng Survey, V2, P122, DOI DOI 10.5121/IJCSES.2011.2109
   developer oculus, About us
   Du MH, 2023, IEEE T VIS COMPUT GR, V29, P1415, DOI 10.1109/TVCG.2021.3115901
   Facebook, Oculus Quest 2
   Feng A, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085045
   Fh A., 2021, Comput Graph, V98, P210, DOI [10.1016/j.cag.2021.05.014, DOI 10.1016/J.CAG.2021.05.014]
   Frokjaer E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P345, DOI 10.1145/332040.332455
   Gerber D, 2005, P IEEE VIRT REAL ANN, P271
   Guerra-Segura E, 2017, MEASUREMENT, V105, P87, DOI 10.1016/j.measurement.2017.04.016
   HART S G, 1988, P139
   Ismail AW, 2015, 8TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION (VINCI 2015), P75, DOI 10.1145/2801040.2801058
   Jacob Habgood M. P., 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P371, DOI 10.1109/VR.2018.8446130
   Lee M, 2020, INT J IND ERGONOM, V75, DOI 10.1016/j.ergon.2019.102878
   Li B, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S021800141955005X
   Li ZP, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3534590
   Lou ZH., 2018, Softw Guide, V17, P19
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.00-32, 10.1109/VR46266.2020.1581086151885]
   Lu W, 2016, IEEE SIGNAL PROC LET, V23, P1188, DOI 10.1109/LSP.2016.2590470
   Masurovsky A, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040091
   Medeiros D, 2020, IEEE T VIS COMPUT GR, V26, P2793, DOI 10.1109/TVCG.2019.2905200
   Mendes D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P261, DOI 10.1145/2993369.2993396
   Ni T, 2011, INT J HUM-COMPUT ST, V69, P551, DOI 10.1016/j.ijhcs.2011.05.001
   Ogdon DC, 2019, J MED LIBR ASSOC, V107, P118, DOI 10.5195/jmla.2019.602
   Paulo SF, 2022, VIRTUAL REAL-LONDON, V26, P1079, DOI 10.1007/s10055-021-00620-4
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Ramadoss P, 2022, Arxiv, DOI arXiv:2205.07835
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Schäfer A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P729, DOI 10.1109/VRW55335.2022.00220
   Sreenath S, 2021, 2021 IEEE 9 REG 10 H, P1, DOI [10.1109/R10-HTC53172.2021.9641542, DOI 10.1109/R10-HTC53172.2021.9641542]
   Su GE, 2020, INT J HUM-COMPUT ST, V141, DOI 10.1016/j.ijhcs.2020.102433
   Tran TQ, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139149
   Tian F, 2017, INT J HUM-COMPUT INT, V33, P565, DOI 10.1080/10447318.2016.1265782
   Venkatakrishnan R, 2023, IEEE T VIS COMPUT GR, V29, P2258, DOI 10.1109/TVCG.2023.3247041
   Venkatakrishnan R, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560817
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Wu HY, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0204-7
   Wu HY, 2019, INT J HUM-COMPUT INT, V35, P1102, DOI 10.1080/10447318.2018.1510607
   Xia Z, 2022, P 2022 ACM S SPATIAL, P1, DOI [10.1145/3565970.3568189, DOI 10.1145/3565970.3568189]
   Zhang F, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P539
NR 50
TC 0
Z9 0
U1 9
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17640-8
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600003
DA 2024-07-18
ER

PT J
AU Farahani, MG
   Torkestani, JA
   Rahmani, M
AF Farahani, Mansoureh Ghiasabadi
   Torkestani, Javad Akbari
   Rahmani, Mohsen
TI Dynamic user profile for adaptive personalized recommender system using
   learning automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Change of user interest; Adaptive user's profile; Clustering;
   Personalization; Learning automata; Recommender system
AB The personalized recommender systems provide favorite services based on user preferences and interests. Due to the user's interests changing over time; hence the recommender system must be tracking these changes automatically; to overcome the research gap and col start problem in the current study, we suggest a framework to create an adaptive user profiling for a personalized recommender system using learning automata. We clustered items based on their features. In this technique, the learning automaton adjusts the amount of user interest in each cluster based on user feedback; then recommends the best items to the user based on demographic information of user and user's preferences. Several experiments are conducted on three movie datasets to show the performance of the proposed algorithm. The obtained results demonstrate that the proposed algorithm outperforms several existing approaches in terms of precision, recall, MAE, and RMSE.
C1 [Farahani, Mansoureh Ghiasabadi; Torkestani, Javad Akbari] Islamic Azad Univ, Dept Comp Engn, Arak Branch, Arak, Iran.
   [Rahmani, Mohsen] Arak Univ, Fac Engn, Dept Comp Engn, Arak, Iran.
C3 Islamic Azad University; Arak University
RP Farahani, MG (corresponding author), Islamic Azad Univ, Dept Comp Engn, Arak Branch, Arak, Iran.
EM Mansoureh.ghias@iau.ac.ir; j-akbari@iau-arak.ac.ir;
   M-rahmani@araku.ac.ir
RI Farahani, Mansoureh Ghiasbadi/ABF-5193-2021
OI Farahani, Mansoureh Ghiasbadi/0000-0002-0312-301X; rahmani,
   mohsen/0000-0001-6890-192X
CR Bhowmick P. K., 2010, IJCSA, V7, P1
   Billard E, 1999, IEEE T SYST MAN CY B, V29, P329, DOI 10.1109/3477.764864
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R, 2012, INT J HUM-COMPUT INT, V28, P72, DOI 10.1080/10447318.2012.632301
   Chen JR, 2020, IEEE SYST J, V14, P244, DOI 10.1109/JSYST.2019.2900325
   Chen JR, 2018, SWARM EVOL COMPUT, V38, P35, DOI 10.1016/j.swevo.2017.05.008
   Chen YC, 2021, J SUPERCOMPUT, V77, P244, DOI 10.1007/s11227-020-03266-2
   Cremonesi Paolo., 2011, Proceedings of the Second International Workshop on Information Heterogeneity and Fusion in Recommender Systems, HetRec'11, P33, DOI DOI 10.1145/2039320.2039325
   Cufoglu A., 2014, International Journal of Computer Applications, V108, P1, DOI [10.5120/18888-0179, DOI 10.5120/18888-0179]
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Frémal S, 2017, EXPERT SYST APPL, V77, P105, DOI 10.1016/j.eswa.2017.01.031
   GraphLab J, 2012, The smallnetflix recommender systems dataset
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Hwang TG, 2016, MULTIMED TOOLS APPL, V75, P12843, DOI 10.1007/s11042-016-3526-8
   Jadhav Saudagar L., 2016, International Journal of Information Technology and Computer Science, V8, P72, DOI 10.5815/ijitcs.2016.07.10
   Jawaheer G, 2014, ACM T INTERACT INTEL, V4, DOI 10.1145/2512208
   Kassak O, 2015, ACTA POLYTECH HUNG, V12, P27
   LAKSHMIVARAHAN S, 1976, IEEE T SYST MAN CYB, V6, P756
   Li J, 2018, J COMPUT SCI-NETH, V26, P128, DOI 10.1016/j.jocs.2018.03.009
   Liang H., 2010, Proceedings of the 19th ACM International Conference on Information and Knowledge Management, P1641, DOI DOI 10.1145/1871437.1871693
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773
   NARENDRA KS, 1974, IEEE T SYST MAN CYB, VSMC4, P323, DOI 10.1109/TSMC.1974.5408453
   OConnor M, 1999, P ACM SIGIR WORKSH R
   Papadakis H, 2017, EXPERT SYST APPL, V79, P8, DOI 10.1016/j.eswa.2017.02.025
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Reddy Srs, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P391, DOI 10.1007/978-981-13-1927-3_42
   Singh PK, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107272
   Staab Steffen, 2009, Handbook on Ontologies, DOI DOI 10.1007/978-3-540-92673-3
   van den Berg R, 2017, Arxiv, DOI arXiv:1706.02263
   Van Meteren Robin, 2000, P MACH LEARN NEW INF, P47
   Wit J., 2008, Evaluating recommender systems: an evaluation framework to predict user satisfaction for recommender systems in an electronic programme guide context
   Zhang C, 2015, AAAI
NR 34
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17339-w
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200008
DA 2024-07-18
ER

PT J
AU Dasu, MV
   Reddy, PVN
   Reddy, SCM
AF Dasu, Marri Venkata
   Reddy, P. Veera Narayana
   Reddy, S. Chandra Mohan
TI Deep concatenated features with improved heuristic-based recurrent
   neural network for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral Image Classification; Deep Concatenated Features; Enhanced
   Convolutional Neural Network; Modified Recurrent Neural Network;
   Modified Velocity-based Colliding Bodies Optimization
ID EXTRACTION
AB Hyperspectral remote sensing is one of the important approaches in the area of remote sensing owing to the latest enhancements in the Hyper Spectral Imaging (HSI) technology. The classification represents a direct approach in the HSI field that provides every pixel a particular semantic label based on its behavior automatically. Nowadays, deep learning-oriented techniques have gained wide attention in the area of HSI classification. Although Convolutional Neural Network (CNN)-oriented techniques are subjected to the HSI classification, their performances are not up to the expectation. This is because; the majority of the traditional techniques cannot utilize the intrinsic behavior of distinct pixels in HSI efficiently. The inherent relationships are ignored between distinct category dependencies, distinct spectral bands, and distinct spatial pixels. Moreover, deep learning methods are required to build a huge and complicated network, and hence the training process tends to be time-consuming. Hence, these work tactics to design and implement a novel HSI classification method using deep structured architectures. The major stages of the offered method are feature extraction, and classification. Initially, the HSI from RIT-18 benchmark sources is collected. Before processing it for feature extraction, the images are split into 'n' number of patches, where the length of every patch is 16 x 16. Then the feature extraction begins, in which the spatial and spectral features, as well as the Enhanced CNN, are utilized for acquiring the deep features from the entire patches. In the CNN, the architecture is enhanced by the "Modified Velocity-based Colliding Bodies Optimization (MV-CBO)". Then, the entire features acquired from all the patches are concatenated. Finally, the utilization of deep structured architectures termed modified Recurrent Neural Network (RNN) is utilized in the classification phase, which classifies the images into different categories as per the dataset. The RNN architecture is also modified by the MV-CBO to attain high classification accuracy. From the simulation results, the accuracy rate of the MV-CBO-M-RNN at a 75% learning rate is correspondingly secured at 3.16%, 4.26%, 1.03%, and 2.08% more advanced than DNN, RNN, CNN, and NN. The validation of the recommended technique on challenging public datasets, and the experimental evaluation over baseline approaches validates the efficiency and robustness of the suggested model.
C1 [Dasu, Marri Venkata] Annamacharya Inst Technol & Sci, Dept Elect & Commun Engn, Rajampet, Andhra Pradesh, India.
   [Reddy, P. Veera Narayana] RSR Engn Coll, Kavali, Andhra Pradesh, India.
   [Reddy, S. Chandra Mohan] JNTU Coll Engn, Ananthapuramu, Andhra Pradesh, India.
C3 JNTUA College of Engineering Anantapur; Jawaharlal Nehru Technological
   University - Anantapur
RP Dasu, MV (corresponding author), Annamacharya Inst Technol & Sci, Dept Elect & Commun Engn, Rajampet, Andhra Pradesh, India.
EM dassmarri@gmail.com; principal.rsrec@gmail.com; email2cmr@gmail.com
RI Dasu, Venkata/GQQ-1698-2022
OI Dasu, Venkata/0000-0002-8870-4410
CR Bhosle K, 2019, J INDIAN SOC REMOTE, V47, P1949, DOI 10.1007/s12524-019-01041-2
   Cai YM, 2021, NEUROCOMPUTING, V434, P21, DOI 10.1016/j.neucom.2020.12.064
   Ding HY, 2020, ARAB J GEOSCI, V13, DOI 10.1007/s12517-020-05487-4
   Fang B, 2020, ISPRS J PHOTOGRAMM, V161, P164, DOI 10.1016/j.isprsjprs.2020.01.015
   Fang J, 2020, NEUROCOMPUTING, V410, P211, DOI 10.1016/j.neucom.2020.05.034
   Fu AY, 2018, INT GEOSCI REMOTE SE, P2643, DOI 10.1109/IGARSS.2018.8518045
   Gu YF, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3084-1
   Hang RL, 2019, IEEE T GEOSCI REMOTE, V57, P5384, DOI 10.1109/TGRS.2019.2899129
   Hu YB, 2019, ACTA OCEANOL SIN, V38, P142, DOI 10.1007/s13131-019-1445-z
   Ibrahem Wasseem Nahy, Lecture, V6
   Jayapriya K, 2020, EARTH SCI INFORM, V13, P1093, DOI 10.1007/s12145-020-00485-2
   Jiang XH, 2018, WIRELESS PERS COMMUN, V102, P3529, DOI 10.1007/s11277-018-5389-y
   Kaveh A, 2014, COMPUT STRUCT, V139, P18, DOI 10.1016/j.compstruc.2014.04.005
   Kong Y, 2018, IEEE J-STARS, V11, P4128, DOI 10.1109/JSTARS.2018.2869210
   Kutluk S, 2021, DIGIT SIGNAL PROCESS, V113, DOI 10.1016/j.dsp.2021.103016
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Li YM, 2018, APPL INTELL, V48, P4128, DOI 10.1007/s10489-018-1200-8
   Li ZX, 2017, INT GEOSCI REMOTE SE, P1812, DOI 10.1109/IGARSS.2017.8127328
   Liu BX, 2019, J INDIAN SOC REMOTE, V47, P1989, DOI 10.1007/s12524-019-01045-y
   Lv Q, 2016, IEEE GEOSCI REMOTE S, V13, P434, DOI 10.1109/LGRS.2016.2517178
   Ma L, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0023-8
   Ma XR, 2016, ISPRS J PHOTOGRAMM, V120, P99, DOI 10.1016/j.isprsjprs.2016.09.001
   Ma XR, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0071-8
   Nagasubramanian K, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0479-8
   Namatevs Ivars, 2017, Ind Technol Manag Sci, V20, P40, DOI DOI 10.1515/ITMS-2017-0007
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Qasem Abu Al-Haija, 2019, J Comput Sci, V15, P499, DOI [10.3844/jcssp.2019.499.510, DOI 10.3844/JCSSP.2019.499.510]
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Shen Y, 2019, IEEE ACCESS, V7, P132240, DOI 10.1109/ACCESS.2019.2940697
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Singh TI., 2016, 2016 IEEE Int Conf Comput Intell Comput Res (ICCIC), V2016, P1
   Venkatesan R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1347-9
   Venkatesh C, 2022, WIRELESS PERS COMMUN, V125, P2621, DOI 10.1007/s11277-022-09676-0
   Wang LZ, 2017, SOFT COMPUT, V21, P213, DOI 10.1007/s00500-016-2246-3
   Yan L, 2019, OPT REV, V26, P597, DOI 10.1007/s10043-019-00528-0
   Yilmaz S, 2020, NEURAL COMPUT APPL, V32, P11543, DOI 10.1007/s00521-019-04641-8
   Yu XJ, 2018, FOOD ANAL METHOD, V11, P768, DOI 10.1007/s12161-017-1050-8
   Zhang CC, 2020, INT GEOSCI REMOTE SE, P509, DOI 10.1109/IGARSS39084.2020.9324463
   Zhang J, 2021, FOOD ANAL METHOD, V14, P389, DOI 10.1007/s12161-020-01871-8
   Zhu XF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060734
NR 41
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17351-0
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500006
DA 2024-07-18
ER

PT J
AU Abdulrahman, AO
   Rawf, KMH
   Mohammed, AA
AF Abdulrahman, Ayub Othman
   Hama Rawf, Karwan Mahdi
   Mohammed, Aree Ali
TI Improved ECG heartbeat classification based on 1-D convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ECG signal; MIT-BIH; Classification; Arrhythmia; 1-D convolution neural
   network
ID MYOCARDIAL-INFARCTION; HEALTH
AB ECG (Electrocardiogram) waves have a significant role in identifying the nature of heart diseases and monitoring the heart situation of patients who suffer from different cardiovascular diseases. In this research, a model that implements a binary classification in the light of the 1D-CNN algorithm is proposed for the ECG signal environment. The main objective of this study is to detect and separate regular and irregular heartbeat signals. The model has been trained and tested on the MIT-BIH dataset and classifies the signal into "normal" and "abnormal" samples using various activation functions for different epochs. Test results indicated that, according to the confusion matrix, an improvement of 99.8%, 99.9%, and 99.7% was achieved for accuracy, sensitivity, and specificity, respectively. These results are better than other related works that have been recently published for the classification of ECG signals.
C1 [Abdulrahman, Ayub Othman; Hama Rawf, Karwan Mahdi; Mohammed, Aree Ali] Univ Halabja, Coll Sci, Comp Sci Dept, Halabja, Krg, Iraq.
   [Mohammed, Aree Ali] Univ Sulaimani, Coll Sci, Comp Sci Dept, Sulaimani, Krg, Iraq.
C3 University of Sulimanyah
RP Abdulrahman, AO (corresponding author), Univ Halabja, Coll Sci, Comp Sci Dept, Halabja, Krg, Iraq.
EM ayub.abdulrahman@uoh.edu.iq
RI Abdulrahman, Ayub Othman/HKD-9647-2023
OI Abdulrahman, Ayub Othman/0000-0003-3508-1093
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   [Anonymous], 2019, Epidemic of Cardiovascular Disease and Diabetes: Explaining the Phenomenon in South Asians Worldwide
   [Anonymous], 2019, SYST ICACCS COIMB IN, P365
   [Anonymous], 2018, Int J Intell Eng Syst
   Anwar SM, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/1380348
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Avanzato R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060951
   Brownlee J., 2020, Machine Learning Mastery
   CDC website, 2020, Heart Disease Facts.
   Chamley RR, 2019, EUR HEART J, V40, P2663, DOI 10.1093/eurheartj/ehz559
   Chen JM, 2019, IEEE ACCESS, V7, P120831, DOI 10.1109/ACCESS.2019.2937875
   Gope P, 2016, IEEE SENS J, V16, P1368, DOI 10.1109/JSEN.2015.2502401
   Hsieh CH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072136
   Kannathal N, 2003, Exp Clin Cardiol, V8, P206
   Khan MA, 2020, IEEE ACCESS, V8, P34717, DOI 10.1109/ACCESS.2020.2974687
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Li J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7354081
   Li ZJ, 2019, IEEE ACCESS, V7, P77849, DOI 10.1109/ACCESS.2019.2920900
   Mechanic OJ, 2021, StatPearls
   Mehta LS, 2016, CIRCULATION, V133, P916, DOI 10.1161/CIR.0000000000000351
   Murray CJL, 1997, LANCET, V349, P1436, DOI 10.1016/S0140-6736(96)07495-8
   Mustaqeem A, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/7310496
   Mustaqeem A, 2017, INT J MED INFORM, V108, P134, DOI 10.1016/j.ijmedinf.2017.10.008
   Mustaqeem A, 2017, IEEE ENG MED BIO, P3656, DOI 10.1109/EMBC.2017.8037650
   Nannavecchia A, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020026
   Nashif Shadman, 2018, World Journal of Engineering and Technology, V6, P854
   National Institute of Neurological Disorders and Stroke, 2020, Sudden Unexplained Death in Epliepsy, online available at The Epilepsies and Seizures: Hope Through Research |National Institute of Neurological Disorders and Stroke
   Perrier E., 2015, Positive Disruption: Healthcare, Ageing and Participation in the Age of Technology
   Prasad BVP, 2018, BIOTECHNOL BIOTEC EQ, V32, P183, DOI 10.1080/13102818.2017.1389303
   Priyadharsan DJ., 2019, Int Res J Eng Technol, V06, P03
   Rajkumar A, 2019, INT CONF ADVAN COMPU, P365, DOI [10.1109/ICACCS.2019.8728362, 10.1109/icaccs.2019.8728362]
   Ranjan R, 2018, PATTERN RECOGN LETT, V115, P74, DOI 10.1016/j.patrec.2018.01.001
   Rehman SU., 2016, IEEE Int Conf Online Anal Comput Sci, V2016, P139, DOI [10.1109/ICOACS.2016.7563066, DOI 10.1109/ICOACS.2016.7563066]
   Rohmantri R, 2020, INT J ADV COMPUT SC, V11, P201
   Sanchez F. A. Rivera, 2019, Journal of Physics: Conference Series, V1221, DOI 10.1088/1742-6596/1221/1/012062
   Singh Shraddha, 2018, Procedia Computer Science, V132, P1290, DOI 10.1016/j.procs.2018.05.045
   Tu SS, 2020, IET COMPUT VIS, V14, P259, DOI 10.1049/iet-cvi.2019.0506
   Ullah A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030951
   Ullah A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101685
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Zhang DY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224968
   Zhu N, 2015, IEEE INTELL SYST, V30, P39, DOI 10.1109/MIS.2015.57
   Zubair M, 2016, INT CONF IT CONVERGE, P335
NR 43
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17619-5
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500013
DA 2024-07-18
ER

PT J
AU Mattins, RF
   Sarobin, MVR
   Aziz, AA
   Srivarshan, S
AF Mattins, R. Faerie
   Sarobin, M. Vergin Raja
   Aziz, Azrina Abd
   Srivarshan, S.
TI Object detection and classification of butterflies using efficient CNN
   and pre-trained deep convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional Neural Network; Object detection; Image Classification;
   Transfer Learning; Performance Analysis
ID IDENTIFICATION
AB With over 18,000 species, butterflies account for nearly one-quarter of all identified species on the planet. The images of different butterfly species can be utilized to train Deep Convolutional Neural Networks (CNNs) for the automatic detection and classification of butterflies. This work proposes an end-to-end system for automatically detecting butterflies in given images and predicting their respective species. To achieve butterfly detection, we utilized the YOLOv3 object detection model, which was trained on the Beautiful Butterflies dataset. This dataset comprises 832 photos of butterflies from 10 different species, captured from various angles. For species classification, we designed a deep convolutional neural network-based architecture named Efficient Convolutional Neural Network (Effi-CNN), employing multiple CNN layers and trained on the custom dataset. To benchmark the performance of Effi-CNN, we compared three versions: Effi-CNN-1, Effi-CNN-2, and Effi-CNN-3, with five other transfer learning CNN models, including VGG16, VGG19, ResNet50, MobileNetV2, and Inception-v3 models. Evaluation of the models was conducted using a separate test dataset. The YOLOv3 object detection model exhibited a promising result, achieving a mean Average Precision (mAP) of 0.98. Among the classification models, Effi-CNN-3 demonstrated the highest accuracy, reaching 98.20%.
C1 [Mattins, R. Faerie; Sarobin, M. Vergin Raja; Srivarshan, S.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
   [Aziz, Azrina Abd] Univ Teknol PETRONAS, Perak, Malaysia.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Universiti Teknologi
   Petronas
RP Sarobin, MVR (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
EM verginraja.m@vit.ac.in
CR Almryad AS, 2020, ENG SCI TECHNOL, V23, P189, DOI 10.1016/j.jestch.2020.01.006
   Andrian R., 2020, Scientific Journals of Information System Technology, V6, P11
   Arzar NNK, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P221, DOI [10.1109/I2CACIS.2019.8825031, 10.1109/i2cacis.2019.8825031]
   Bohan Liang, 2020, Genetic and Evolutionary Computing. Proceedings of the Thirteenth International Conference on Genetic and Evolutionary Computing. Advances in Intelligent Systems and Computing (AISC 1107), P500, DOI 10.1007/978-981-15-3308-2_55
   Chazhoor A, 2022, MULTIMED TOOLS APPL, V81, P29383, DOI 10.1007/s11042-022-12916-x
   Chen X, 2021, INT C PATT RECOG, P5798, DOI 10.1109/ICPR48806.2021.9412080
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong SJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071651
   Josiah W, 2009, 20 BRIT MACH VIS C
   Kaya Y, 2013, 21 SIGN PROC COMM AP, P1, DOI [10.1109/SIU.2013.6531283, DOI 10.1109/SIU.2013.6531283]
   Kaya Y, 2014, J EXP THEOR ARTIF IN, V26, P267, DOI 10.1080/0952813X.2013.861875
   Mishra DP, 2018, 2018 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN ELECTRICAL, ELECTRONICS & COMMUNICATION ENGINEERING (ICRIEECE 2018), P200, DOI 10.1109/ICRIEECE44171.2018.9008419
   Nam N., 2018, P 2018 INT C CONTR C, P33
   Rajeena PPF, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11132016
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma G, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033881
   Silva A, 2020, SIBGRAPI, P295, DOI 10.1109/SIBGRAPI51738.2020.00047
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan AJ, 2020, IEEE ACCESS, V8, P124722, DOI 10.1109/ACCESS.2020.3007745
   Theivaprakasham H, 2021, J ASIA-PAC ENTOMOL, V24, P329, DOI 10.1016/j.aspen.2020.11.015
   [谢娟英 Xie Juanying], 2021, [计算机研究与发展, Journal of Computer Research and Development], V58, P1686
   Xin DJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051681
   Yasashvini R, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091932
   Zhao RY, 2019, J PHYS CONF SER, V1176, DOI 10.1088/1742-6596/1176/3/032048
   Zhu LL, 2019, IEEE GLOB CONF SIG, DOI 10.1109/globalsip45357.2019.8969441
NR 28
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17563-4
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900007
DA 2024-07-18
ER

PT J
AU Chu, CQ
   Xiao, QK
   Shen, JN
   Chang, LR
   Zhang, N
   Du, Y
   Gao, H
AF Chu, Chaoqin
   Xiao, Qinkun
   Shen, Jianing
   Chang, Leran
   Zhang, Na
   Du, Yu
   Gao, Hui
TI A novel approach of decoding four-class motor imagery tasks via wavelet
   transform and 1DCNN-BiLSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BCI; EEG decoding; 1DCNN; BiLSTM; RAM; WT
ID CONVOLUTIONAL NEURAL-NETWORKS; EEG
AB Electroencephalogram (EEG)-based human-computer interaction (HCI) has become a major research direction in the field of brain-computer interface (BCI). Although EEG research has made progress, motor imagery (MI) EEG decoding remains a challenge due to a lack of sample data, a lower signal noise ratio (SNR), and individual differences. Recently, many deep learning methods have been widely used in EEG classification tasks. Our work presents a novel approach to decoding four-class MI tasks by utilizing one-dimensional convolutional neural network (1DCNN). We use 1D multiscale CNN (1DMCNN) block, residual attention mechanism (RAM) block and bidirectional long-short-term memory (BiLSTM) networks for EEG decoding. We named it the 1DMRCNN-BiLSTM model, which can achieve good accuracy in decoding human intentions. The highlights include: (1) Based on the wavelet transform (WT), we use 1D wavelet denoising and 1D wavelet reconstruction methods not only to improve the SNR of EEG signals but also to enhance the number of EEG samples. (2) We fused the 1DMCNN block and the RAM block with dropout layers to design a new 1DMRCNN model for EEG feature extraction. (3) Based on the 1DMRCNN-BiLSTM structure, an effective end-to-end framework for MI classification is built. We trained and tested our proposed method on the BCI competition IV datasets 2a (BCICID-2a) and PhysioNet. The experimental results show that the method demonstrates excellent ability in EEG decoding.
C1 [Chu, Chaoqin; Xiao, Qinkun] Xian Technol Univ, Dept Mech & Elect Engn, Xian 710021, Shaanxi, Peoples R China.
   [Xiao, Qinkun; Shen, Jianing; Chang, Leran; Zhang, Na; Du, Yu; Gao, Hui] Xian Technol Univ, Dept Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
C3 Xi'an Technological University; Xi'an Technological University
RP Xiao, QK (corresponding author), Xian Technol Univ, Dept Mech & Elect Engn, Xian 710021, Shaanxi, Peoples R China.; Xiao, QK; Gao, H (corresponding author), Xian Technol Univ, Dept Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
EM xiaoqinkun10000@163.com; gaohui@xatu.edu.cn
OI Xiao, Qinkun/0000-0002-2651-1218
FU This work was supported by the Nature Science Foundation of China (Nos.
   61671362 and 62071366). [61671362, 62071366]; Nature Science Foundation
   of China
FX This work was supported by the Nature Science Foundation of China (Nos.
   61671362 and 62071366).
CR Aggarwal S, 2019, ARRAY-NY, V1-2, DOI 10.1016/j.array.2019.100003
   Alzahrani SI, 2023, IEEE ACCESS
   Ang KK, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00039
   Bang JS, 2022, IEEE T NEUR NET LEAR, V33, P3038, DOI 10.1109/TNNLS.2020.3048385
   Boubchir L, 2013, IEEE T SIGNAL PROCES, V61, P1880, DOI 10.1109/TSP.2013.2245657
   Chu CQ, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422500367
   Feng JK, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8068357
   Grobbelaar M, 2022, SIGNALS-BASEL, V3, P577, DOI 10.3390/signals3030035
   Hou YM, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab4af6
   Ivaylov Ivaylo, 2020, 2020 28th National Conference with International Participation (TELECOM), P53, DOI 10.1109/TELECOM50385.2020.9299532
   Jeong JH, 2020, IEEE T NEUR SYS REH, V28, P1226, DOI 10.1109/TNSRE.2020.2981659
   Jiao ZC, 2018, PATTERN RECOGN, V76, P582, DOI 10.1016/j.patcog.2017.12.002
   Khademi S, 2022, Artificial IntelligenceBased Brain-Computer Interface, P23, DOI DOI 10.1016/B978-0-323-91197-9.00004-7
   Khademi Z, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105288
   Li HL, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103342
   Li X, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3524499
   Lopez KL, 2022, NEUROIMAGE, V260, DOI 10.1016/j.neuroimage.2022.119390
   Lun XM, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00338
   Ma WF, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103718
   Ma WF, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103582
   Mammone N, 2023, IEEE J BIOMED HEALTH
   Noureddin B, 2012, IEEE T BIO-MED ENG, V59, P2103, DOI 10.1109/TBME.2011.2108295
   Padfield N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061423
   Pillette L, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102603
   Qu W, 2020, IEEE J BIOMED HEALTH, V24, P2833, DOI 10.1109/JBHI.2020.2978004
   Saibene A, 2023, SENSORS-BASEL, V23, P221
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Swain CMK, 2023, COMPUTATIONAL INTELL, P169
   Tang XL, 2023, IEEE T NEUR SYS REH, V31, P1208, DOI 10.1109/TNSRE.2023.3242280
   Tuncer T, 2021, MULTIMED TOOLS APPL, V80, P25197, DOI 10.1007/s11042-021-10882-4
   Velasco-Alvarez F, 2022, NEUROCOMPUTING, V509, P121, DOI 10.1016/j.neucom.2022.08.068
   Wang JL, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104627
   Wang K, 2022, IEEE T NEUR NET LEAR, V33, P2159, DOI 10.1109/TNNLS.2021.3135696
   Wang XS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020219
   Wu Y., 2023, HIGHLIGHTS SCI ENG T, V39, P809, DOI [10.54097/hset.v39i.6648, DOI 10.54097/HSET.V39I.6648]
   Xie LX, 2019, IEEE T CYBERNETICS, V49, P2200, DOI 10.1109/TCYB.2018.2821764
   Xu GW, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.578126
   Zhang R, 2016, IEEE T NEUR SYS REH, V24, P128, DOI 10.1109/TNSRE.2015.2439298
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhao XF, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103338
   Zhuang JY, 2021, IEEE T SYST MAN CY-S, V51, P5392, DOI 10.1109/TSMC.2019.2955478
NR 41
TC 0
Z9 0
U1 14
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45789
EP 45809
DI 10.1007/s11042-023-17396-1
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001090305500007
DA 2024-07-18
ER

PT J
AU Valentine, NH
   Akaerue, EI
   Etido, MG
   Davies-Ekpo, CS
AF Valentine, Ndianabasi H.
   Akaerue, Emmanuel I.
   Etido, Mfon G.
   Davies-Ekpo, Christopher S.
TI A 3-factor authentication access control system using RFID, fingerprint,
   token and code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fingerprint; Token; GSM; RFID and Module
AB The 3-factor authentication control system is aim at providing maximum security in company's stores, special utilities and premises where valuables are stored. A developed security system with automatic sensing was introduced using the integration of Radio Frequency Identification (RFID) card tagging system, fingerprint sensing biometric security system and Global System for Mobile communication (GSM) to send token generated by the system to the authorized user's access cell-phone. The accuracy of the system was measured virtually in a simulation screen. Results and performance evaluation test shows over 98% accuracy in access granted to access denial, for both right and wrong RFID card and correct to incorrect fingerprint scanning respectively. This consequently, shows satisfaction in the performance of the system test, which proves the validity and efficiency of the system by ensuring full integrity of the door lock in any premises as the case may be.
C1 [Valentine, Ndianabasi H.; Akaerue, Emmanuel I.] Univ Calabar, Dept Phys, PMB 1115, Calabar, Cross River Sta, Nigeria.
   [Etido, Mfon G.] Coll Sci & Technol, Dept Phys, Ikono, Akwa Ibom State, Nigeria.
   [Davies-Ekpo, Christopher S.] Univ Calabar, Dept Sci Lab Technol, Calabar, Nigeria.
C3 University of Calabar; University of Calabar
RP Akaerue, EI (corresponding author), Univ Calabar, Dept Phys, PMB 1115, Calabar, Cross River Sta, Nigeria.
EM emmanuelakaerue@unical.edu.ng
OI Akaerue, Emmanuel/0000-0002-7675-4672
CR Addy D, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1995, DOI 10.1109/ICACCI.2016.7732344
   Adeoye TO, 2014, J World Comput Sci Inf Technol, V4, P76
   Belguechi R, 2013, COMPUT SECUR, V39, P325, DOI 10.1016/j.cose.2013.08.009
   Etinosa NO., 2017, Design and implementation of an iris biometric door access control system
   Jain Anil K., 2011, Introduction to Biometrics, DOI [DOI 10.1007/978-0-387-77326-1, 10.1007/978-0-387-77326-1_1]
   Kawale A, 2013, Int J Sci Eng Res, V4
   Komol M., 2020, Int J Adv Mechatronic Syst, V8, P36, DOI [10.1504/IJAMECHS.2020.10032097, DOI 10.1504/IJAMECHS.2020.10032097]
   Komol M., 2019, Int J Wirel Microw Technol (IJWMT), V9, P22
   Okokpujie K., 2015, J Electr Electron Eng, V12, P68
   Patrick PK, 2010, C MACH LEARN CYB QIN, ppp675, DOI [10.1109/ICMLC.2010.5580558, DOI 10.1109/ICMLC.2010.5580558]
   Peter A., 2016, Am J Eng Res (AJER), V5, P236
   Podio FL, 2002, 2002 IEEE 4TH INTERNATIONAL WORKSHOP ON NETWORKED APPLIANCES, PROCEEDINGS, P57, DOI 10.1109/IWNA.2001.980804
   Pollak R, 2019, INT J BIOMETRICS, V11, P101
   Ramalatha M., 2014, Elysium J Eng Res Manag, V1, P51
   Ren K, 2006, IEEE T VEH TECHNOL, V55, P1373, DOI 10.1109/TVT.2006.877704
   Saraswat C, 2010, Int J Comput Sci Eng, V2, P264
   Shepard S., 2005, RFID RADIO FREQUENCY
   Ting SL, 2011, INT J ENG BUS MANAG, V3, P9
   Umar F., 2004, Int J Eng Technol, V6, P309
   Valentine NH, 2021, JORDAN J PHYS, V14, P117, DOI 10.47011/14.2.3
   vikipedia, U6VJ6
   Wang M., 2014, Sensors Transducers (1726-5479), V176, P196
NR 22
TC 1
Z9 1
U1 16
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17325-2
EA OCT 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600018
DA 2024-07-18
ER

PT J
AU Yang, WC
   Jiang, JJ
   Mao, AS
   Su, KA
   Chen, CH
AF Yang, Wen-Chao
   Jiang, Jiajun
   Mao, Austin
   Su, Kai-An
   Chen, Chung-Hao
TI The study on the estimation of vehicles speed using a dashboard camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Photogrammetry; Cross-ratio; Video understanding; Vehicle speed
   estimation
ID CROSS-RATIO; VELOCITY
AB Mobile and handheld electronic products such as smartphones and dashboard cameras are frequently used to record occurrences of traffic accidents nowadays. Most existing studies require at least one entire lane marking as a reference to calculate a certain amount of driving distances and are not adapted to a targeted vehicle with a rapidly changing speed in a short time. Therefore, existing approaches cannot provide the desired accuracy of speed estimation in real-life scenarios. In this study, we obtain dynamic time and space data from recorded footage using dashboard cameras and then apply photogrammetry and cross-ratio methods to estimate the vehicle speed. In addition, the proposed method is applied to other cars' speed estimation and ego-speed estimation even though both cars are moving. The experimental results show that given the frame rate on the recorded footage, our proposed method only needs one object in each frame to estimate the vehicle speed even at a rapidly changing speed. Our proposed method shows that the difference between the estimated speed and the reference speed by the Global Positioning System (GPS) is smaller than 1 km/h when only one car is on the move, and smaller than 3 km/h when both cars are on the move. Nevertheless, the difference between the estimated speed and the reference speed is between 1.46 km/h and 5.28 km/h when one car moves by AUPD method. To our knowledge, there is no existing method that estimated the front vehicle speed when both cars are on the move using dashboard cameras.
C1 [Yang, Wen-Chao] Natl Cent Police Univ, Dept Forens Sci, Taoyuan, Taiwan.
   [Jiang, Jiajun; Chen, Chung-Hao] Old Dominion Univ, Elect & Comp Engn Dept, Norfolk, VA USA.
   [Mao, Austin] Ocean Lakes High Sch, Virginia Beach, VA USA.
   [Su, Kai-An] New Taipei City Police Dept, Forens Sci Ctr, Taipei, Taiwan.
C3 Old Dominion University
RP Yang, WC (corresponding author), Natl Cent Police Univ, Dept Forens Sci, Taoyuan, Taiwan.
EM una135@mail.cpu.edu.tw
RI Jiang, Jiajun/AAA-5636-2020
OI Jiang, Jiajun/0000-0003-0250-8249
FU This work on this paper was supported by the Ministry of the Interior,
   Republic of China (Taiwan). (Project No. 112-0805-02-28-01).
   [112-0805-02-28-01]; Ministry of the Interior, Republic of China
   (Taiwan)
FX This work on this paper was supported by the Ministry of the Interior,
   Republic of China (Taiwan). (Project No. 112-0805-02-28-01).
CR Adnan MA, 2013, INSTRUMENTATION IEEE, DOI [10.1109/BEIAC.2013.6560214, DOI 10.1109/BEIAC.2013.6560214]
   Brannan David., 2011, GEOMETRY
   El Bouziady A., 2018, 2018 International Conference on Intelligent Systems and Computer Vision ISCV, P1
   Epstein B, 2019, J FORENSIC SCI, V64, P1523, DOI 10.1111/1556-4029.14053
   Farid A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053059
   Han I, 2016, FORENSIC SCI INT, V269, P89, DOI 10.1016/j.forsciint.2016.11.014
   Hoogeboom B, 2010, J FORENSIC SCI, V55, P1347, DOI 10.1111/j.1556-4029.2010.01412.x
   Jenkins FA, 2001, Fundamentals of optics, V4th, P171
   Kim JH, 2018, FORENSIC SCI INT, V287, P195, DOI 10.1016/j.forsciint.2018.04.002
   Klein L.A., 2006, Traffic Detector Handbook: Third Edition - Volume I, VI
   Krishnan R, 2008, Travel time estimation and forecasting on urban roads, DOI [10.1080/23249935.2016.1151964, DOI 10.1080/23249935.2016.1151964]
   Kumar A, 2018, IEEE COMPUT SOC CONF, P137, DOI 10.1109/CVPRW.2018.00026
   Lin CJ, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/1577614
   Liu SX, 2017, J FORENSIC SCI, V62, P1071, DOI 10.1111/1556-4029.13381
   Milne JJ, 2015, scholar's choice, P10
   Modenov PS., 2014, Projective Transformations: Geometric Transformations
   Park SJ, 2003, IEEE MTT-S, P607, DOI 10.1109/MWSYM.2003.1211012
   Prajwal, 2022, IC3-2022: Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing, P258, DOI 10.1145/3549206.3549254
   Rais AH, 2021, 2021 8 INT C ADV INF, DOI [10.1109/ICAICTA53211.2021.9640272, DOI 10.1109/ICAICTA53211.2021.9640272]
   Shim KS, 2021, IEEE ACCESS, V9, P132862, DOI 10.1109/ACCESS.2021.3115500
   Su KA., 2021, The study on evaluating vehicle speed with digital images
   SWGDE, 2022, SWGDE Technical Notes on FFmpeg
   SWGIT, 2022, Guidelines for Image Processing
   Weber N, 2002, IEEE MTT S INT MICR, P2233, DOI 10.1109/MWSYM.2002.1012317
   Wong TW, 2014, FORENSIC SCI INT, V235, P19, DOI 10.1016/j.forsciint.2013.11.012
   Yang L, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23070910
   Yang L, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23070866
   Zou J, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P613, DOI 10.1109/ICASI.2018.8394329
NR 28
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17171-2
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000012
DA 2024-07-18
ER

PT J
AU Wu, J
   Liu, X
   Dong, JM
AF Wu, Jun
   Liu, Xin
   Dong, Jiaming
TI Strategies for inserting attention in computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention; Yolov5s; Object Detection; Inserting Strategies; Yolov3-tiny
AB Attention is increasingly used in computer vision, where both channel attention and spatial attention have proven their effectiveness in classification tasks. So how do we add the appropriate attention module to make it work effectively? In this paper, we train the model by inserting the SE attention module and CA attention module at different positions of YOLOv5s, thus exploring the optimal insertion positions of the channel attention module and spatial attention module in the object detection network. The experimental results found that the attention module is not effective for all object detection models. The spatial attention module should be used to obtain the best performance when the feature map size is large. And the channel attention module is added to the layer with the highest number of channels to obtain the best performance. The CA attention modules do not perform better with more insertions. Only one attention module needs to be inserted at a critical position to get the best performance. The validity of this conclusion is also verified in this experiment on a lightweight network like YOLOv3-tiny.
C1 [Wu, Jun; Liu, Xin; Dong, Jiaming] Hubei Univ Technol, Inst Comp Sci, Wuhan, Peoples R China.
C3 Hubei University of Technology
RP Dong, JM (corresponding author), Hubei Univ Technol, Inst Comp Sci, Wuhan, Peoples R China.
EM wujun@whut.edu.cn; 201910756@hbut.edu.cn; a15707239166@gmail.com
FU National Natural Science Foundation of China [61602161,61772180];
   National Natural Science Foundation of China [:2020BAB012]; Hubei
   Province Science and Technology Support Project [HBUT:
   2021046,21060,21066]; Fundamental Research Funds for the Research Fund
   of Hubei University of Technology
FX This research was funded by National Natural Science Foundation of China
   (Grant No. 61602161,61772180), Hubei Province Science and Technology
   Support Project (Grant No:2020BAB012), and The Fundamental Research
   Funds for the Research Fund of Hubei University of Technology (HBUT:
   2021046,21060,21066).
CR Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Cores D, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104179
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu ZY, 2020, COMPUT GRAPH-UK, V90, P126, DOI 10.1016/j.cag.2020.06.001
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jaderberg M, 2015, ADV NEUR IN, V28
   Joseph K. J., 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P5826, DOI 10.1109/CVPR46437.2021.00577
   Li C, 2020, COMPUT GRAPH-UK, V90, P11, DOI 10.1016/j.cag.2020.05.003
   Li Y, 2023, MULTIMED TOOLS APPL, V82, P7567, DOI 10.1007/s11042-022-13251-x
   Mai J, 2020, Intelligent Automation & Soft Computing, V26
   Mnih V, 2014, ADV NEUR IN, V27
   Othmani M, 2022, MULTIMED TOOLS APPL, V81, P28347, DOI 10.1007/s11042-022-12715-4
   Pang SR, 2022, MULTIMED TOOLS APPL, V81, P4797, DOI 10.1007/s11042-021-11138-x
   Shi JT, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11223735
   Tanveer M, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3344998
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031746
   Wu J, 2023, CONNECT SCI, V35, DOI 10.1080/09540091.2022.2155614
   Yang L, 2023, IEEE T INTELL TRANSP, V24, P7717, DOI 10.1109/TITS.2022.3193909
   Yao JL, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218577
   Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zhenget Z., 2022, P IEEE CVF C COMP VI, P9407
   Zhou K, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104120
NR 30
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17373-8
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6A2
UT WOS:001155212900001
DA 2024-07-18
ER

PT J
AU Kondekar, VH
   Bodhe, SK
AF Kondekar, V. H.
   Bodhe, S. K.
TI Automation in plant pathology: Optimized Attentional Capsule_BiLSTM
   optimized with chaotic sparrow algorithm for colour feature-based plant
   disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant disease detection; Pre-processing; Colour feature extraction;
   Segmentation; ANN; Optimization
AB Agriculture is considered as the backbone of Indian economy. However, the growth of agricultural production is affected by varied types of plant diseases. Such diseases are a primary threat to food security and hence early identification is highly necessary to enhance the production of agricultural goods. In order to detect the plant diseases, several existing studies have attempted to develop an effective mechanism. But, there performance are limited due to reduced learning ability, complex training, increased overfitting problem and complicated training issues. Thus, an innovative hybrid optimal deep learning framework is developed in this work for detecting plant diseases. Initially, the noises presented in the input images are removed in the pre-processing stage with the help of adaptive bilateral filtering. Then for enhancing the detection accuracy, the disease affected regions are gets segmented using a new adaptive density-based fuzzy C-means clustering approach. From the segmented portions, the most significant features like color, texture and shape are extracted to reduce the complexity issues. Here, the color features are extracted through kurtosis, standard deviation, skewness, mean, HSI colour histogram, HSV Colour histogram feature and Colour co-occurrence matrix. Then, the texture features are extracted by hybrid wavelet-Walsh transform, and the shape features are extracted by elliptic Fourier analysis. Finally, a novel Optimized Attentional Capsule_BiLSTM (OACB) model is proposed to detect an exact plant diseases from the given samples. Whereas, the efficiency of proposed classifier is improvised by fine-tuning the hyperparameters using a new Chaotic Sparrow Search Optimization (CSSO) algorithm. For simulation, the proposed study used MATLAB tool and Plant Village Dataset is employed for experimental analysis. The simulation results shows that the proposed study attains higher detection accuracy value of 97.06% as compared with other existing methods.
C1 [Kondekar, V. H.; Bodhe, S. K.] SVERIs Coll Engn, Pandharpur 413304, Maharashtra, India.
   [Kondekar, V. H.] Walchand Inst Technol, Solapur 413006, Maharashtra, India.
C3 SVERI'S College of Engineering
RP Kondekar, VH (corresponding author), SVERIs Coll Engn, Pandharpur 413304, Maharashtra, India.; Kondekar, VH (corresponding author), Walchand Inst Technol, Solapur 413006, Maharashtra, India.
EM vipulkondekar@gmail.com
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Ale L, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024439
   Amara J., 2017, DATENBANKSYSTEME BUS
   Ashwinkumar S, 2022, MATER TODAY-PROC, V51, P480, DOI 10.1016/j.matpr.2021.05.584
   Bedi P, 2021, ARTIF INTELL AGR, V5, P90, DOI 10.1016/j.aiia.2021.05.002
   Chohan M., 2020, Int. J. Recent Technol. Eng, V9, P909
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Daniya T, 2022, COMPUT J, V65, P1812, DOI 10.1093/comjnl/bxab022
   Fang Y, 2015, BIOSENSORS-BASEL, V5, P537, DOI 10.3390/bios5030537
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Golhani Kamlesh, 2018, Information Processing in Agriculture, V5, P354, DOI 10.1016/j.inpa.2018.05.002
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Kobayashi K, 2018, IEEE SYS MAN CYBERN, P2206, DOI 10.1109/SMC.2018.00379
   Kondekar V, 2010, P INT C WORKSH EM TR
   Kondekar VH., 2018, INT J COMPUT APPL, V180, P19
   Mahlein A.-K., 2017, Advances in Animal Biosciences, V8, P238, DOI [10.1017/s2040470017001248, DOI 10.1017/S2040470017001248, 10.1017/S2040470017001248]
   Mahlein AK, 2016, PLANT DIS, V100, P241, DOI 10.1094/PDIS-03-15-0340-FE
   Martinelli F, 2015, AGRON SUSTAIN DEV, V35, P1, DOI 10.1007/s13593-014-0246-1
   Mohameth F., 2020, Journal of Computer and Communications, V8, P10, DOI DOI 10.4236/JCC.2020.86002
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Ning X, 2020, IEEE ACCESS, V8, P59059, DOI 10.1109/ACCESS.2020.2982782
   Pandian JA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12146982
   Pourazar H, 2019, EUR J REMOTE SENS, V52, P17, DOI 10.1080/22797254.2019.1642143
   Prashanthi V., 2020, Int J Adv Trends Comput Sci Eng, V9, P2632, DOI [10.30534/ijatcse/2020/21932020, DOI 10.30534/IJATCSE/2020/21932020]
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sandhu Gurleen Kaur, 2019, 2019 International Conference on Automation, Computational and Technology Management (ICACTM). Proceedings, P34, DOI 10.1109/ICACTM.2019.8776827
   Shruthi U, 2019, INT CONF ADVAN COMPU, P281, DOI [10.1109/icaccs.2019.8728415, 10.1109/ICACCS.2019.8728415]
   Singh D, 2020, ACM INT CONF PR SER, P249, DOI 10.1145/3371158.3371196
   Tete TN, 2017, RICE, P103, DOI DOI 10.15439/2017R24
   Toda Y, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/9237136
   Yadhav S. Yegneshwar, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P564, DOI 10.1109/ICESC48915.2020.9155815
NR 35
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-16925-2
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500014
DA 2024-07-18
ER

PT J
AU Liu, J
   Tian, SW
   Yu, L
   Shi, XW
   Wang, F
AF Liu, Jing
   Tian, Shengwei
   Yu, Long
   Shi, Xianwei
   Wang, Fan
TI Image-text fusion transformer network for sarcasm detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal; Sarcasm detection; Transformer; BERT; ResNet-101
AB Sarcasm is a sophisticated method to convey ideas. Usually, the literal meaning of a sarcasm message is the opposite of its true intent. The development of social platforms has enriched the way users express their thoughts. User-posted information now incorporates not only text but also images. Traditional Sarcasm detection methods rely solely on textual data, failing to leverage the valuable information provided by images. This limitation leads to incomplete information for sarcasm detection, thereby compromising the accuracy of detection results. To address this, the paper proposes a new image-text fusion Transformer network (ITFT-Net) for sarcasm detection. This model uses the Bidirectional Encoder Representations from Transformers (BERT) model to extract text features. Additionally, it introduces the ResNet-101 model with a Transformer Encoder block to extract image features. Due to the lack of adaptive correlation in multimodal feature fusion, a multimodal fusion Transformer Encoder (MFTE) module is designed to enhance the fusion of the image and text features. Finally, the fusion features, processed by the Transformer Encoder module, is utilized for prediction. Experimental results on public datasets have demonstrated that the proposed model outperforms the baseline model in terms of accuracy and F1 value by 0.75% and 0.69% respectively.
C1 [Liu, Jing; Tian, Shengwei; Wang, Fan] Xinjiang Univ, Sch Software, Urumqi, Xinjiang, Peoples R China.
   [Liu, Jing; Yu, Long] Xinjiang Univ, Network & Informat Technol Ctr, Urumqi, Xinjiang, Peoples R China.
   [Shi, Xianwei] Xinjiang Uygur Autonomous Reg Party Comm Polit & L, Urumqi, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Tian, SW (corresponding author), Xinjiang Univ, Sch Software, Urumqi, Xinjiang, Peoples R China.
EM tianshengwei@163.com
OI Tian, Shengwei/0000-0003-3525-5102
FU This work was supported by the National Natural Science Foundation of
   China (grant numbers 61962057); Key project of National Natural Science
   Foundation of China (grant numbers U2003208); Xinjiang Key R amp; D
   Project (grant number 2021B01002). [61962057]; National Natural Science
   Foundation of China [U2003208]; Key project of National Natural Science
   Foundation of China [2021B01002]; Xinjiang Key R amp; D Project
FX This work was supported by the National Natural Science Foundation of
   China (grant numbers 61962057); Key project of National Natural Science
   Foundation of China (grant numbers U2003208); Xinjiang Key R & D Project
   (grant number 2021B01002).
CR Avvaru A, 2020, FIGURATIVE LANGUAGE PROCESSING, P98
   Cai YT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2506
   Castro S, 2019, Arxiv, DOI arXiv:1906.01815
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding N, 2022, MULTIMED TOOLS APPL, V81, P8597, DOI 10.1007/s11042-022-12122-9
   Du YP, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2021.108107
   Du Y, 2022, COGN COMPUT, V14, P78, DOI 10.1007/s12559-021-09832-x
   Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3454
   Govindan V, 2022, J KING SAUD UNIV-COM, V34, P5110, DOI 10.1016/j.jksuci.2022.01.008
   Hao T, IEEE Trans Multimed, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jaiswal N, 2020, FIGURATIVE LANGUAGE PROCESSING, P77
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Kamal A, 2022, COGN COMPUT, V14, P91, DOI 10.1007/s12559-021-09821-0
   Kumar A, 2020, INT CONF ACOUST SPEE, P4477, DOI 10.1109/ICASSP40776.2020.9053012
   Li Z, 2022, Arxiv, DOI arXiv:2204.05515
   Nayak DK, 2022, SMART INNOV SYST TEC, V269, P371, DOI 10.1007/978-981-16-7996-4_26
   Qi QF, 2022, IEEE ACCESS, V10, P28750, DOI 10.1109/ACCESS.2022.3157712
   Salur MU, 2022, NEURAL COMPUT APPL, V34, P18391, DOI 10.1007/s00521-022-07451-7
   Savini E, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10050844
   Schifanella R., 2016, P 24 ACM INT C MULT, P1136
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang R, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2172, DOI 10.1145/3477495.3531825
   Wu Y, 2021, IEEE MULTIMEDIA, V28, P86, DOI 10.1109/MMUL.2021.3069097
   Xu N, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3777
   Yadav A, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3517139
   Yang KC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P521, DOI 10.1145/3394171.3413690
   Yu JF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5408
   Yuan ZQ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4400, DOI 10.1145/3474085.3475585
   Zhang YZ, 2021, IEEE T FUZZY SYST, V29, P3696, DOI 10.1109/TFUZZ.2021.3072492
   Zhu T, 2022, IEEE Trans Multimed, P1
NR 32
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17252-2
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900004
DA 2024-07-18
ER

PT J
AU Taimori, A
   Zayyani, H
   Marvasti, F
AF Taimori, Ali
   Zayyani, Hadi
   Marvasti, Farokh
TI Forensic discrimination between traditional and compressive imaging by
   blurring kernel investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Compressive sensing; Convolutional neural network; Data compression;
   Deconvolution; Image forensics; Imaging; Systems modeling
AB Image forensics encompasses a set of scientific tests to investigation of a suspected event via intrinsic clues of imaging pipeline. Traditional image sensing at the Nyquist-Shannon rate as well as the new modality of compressive imaging below the rate are two main types of sensing in photography and imaging applications. Hence, for forensic investigators, it would importantly necessitate the ability to discriminate among images captured by them. However, due to the complex nonlinear nature of imaging processes, investigating imagers' traces is a difficult task. To this intent, we first systematically model the imaging pipelines as an encoder-decoder pair. For exploring distinguishable traces, we mathematically simplify and linearize the pair for compressive imaging and two main forms of traditional image sensing with or without compression. Our theoretical analyses on the approximate linear models reveal blurring kernels of different imagers have discriminability. To validate it in real-world scenarios, we considered the whole imaging process as an inverse problem and estimated the blurring kernel based on a deconvolution approach, where the discriminability is also justified by information visualization. Then, we designed a pipeline classification system, where a deep convolutional neural network is trained by the estimated blurring kernels to be able to classify the three imaging systems. Our results in compressive imaging identification show an accuracy improvement about 3.7 % in comparison to the best result among compared methods. Implementation codes are available for research and development.
C1 [Taimori, Ali; Marvasti, Farokh] Sharif Univ Technol, Dept Elect Engn, Tehran 1458889694, Iran.
   [Zayyani, Hadi] Qom Univ Technol QUT, Qom, Iran.
C3 Sharif University of Technology
RP Taimori, A (corresponding author), Sharif Univ Technol, Dept Elect Engn, Tehran 1458889694, Iran.
EM alitaimori@yahoo.com; zayyani@qut.ac.ir; marvasti@sharif.edu
RI zayyani, Hadi/ABD-6756-2020
OI Taimori, Ali/0000-0001-9550-7434
FU This research was jointly sponsored by Iran National Science Foundation
   and ACRI of Sharif University of Technology under agreement numbers
   95/SAD/47585 and 7000/6642, respectively. The authors also thank Prof A.
   Amini and other researchers in Multimedia a; Iran National Science
   Foundation [95/SAD/47585, 7000/6642]; ACRI of Sharif University of
   Technology
FX This research was jointly sponsored by Iran National Science Foundation
   and ACRI of Sharif University of Technology under agreement numbers
   95/SAD/47585 and 7000/6642, respectively. The authors also thank Prof A.
   Amini and other researchers in Multimedia and Signal Processing Lab for
   their valuable comments.
NR 0
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16535-y
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200007
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, S
   Singh, B
AF Singh, Sudhir
   Singh, Buddha
TI An efficient patient data hiding scheme using cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE - Reversible data hiding; Cellular automata; Electronic patient data;
   Paillier cryptosystem
AB Recently, Bhardwaj has discussed a technique for hiding the patient data in a cover image. Though it is an efficient technique, yet it some limitations: i) it does not provide any mechanism to have the size of the embedded data if it is less than the maximum embedding capacity, ii) If the intermediate pixel values are not updated in the cover image, it will not function properly, and iii) its embedding capacity has possibly not properly estimated. In this paper, we address these problems and also find the embedding capacity analytically that helps to compute the embedding capacity for an image of any given size.
C1 [Singh, Sudhir; Singh, Buddha] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Singh, S (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi, India.
EM sidsingh73@gmail.com
CR Bhardwaj R, 2022, MULTIMED TOOLS APPL, V81, P44363, DOI 10.1007/s11042-022-12501-2
   Bhardwaj R, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102276
   Bhardwaj R, 2021, J AMB INTEL HUM COMP, V12, P2915, DOI 10.1007/s12652-020-02449-2
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Kier LB., 2005, Modeling chemical systems using cellular automata, p9781402036576, DOI [10.1007/1-4020-3690-6, DOI 10.1007/1-4020-3690-6]
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lu TC., 2017, Signal Process, V115, P195, DOI [10.1016/j.sigpro.2015.03.017, DOI 10.1016/J.SIGPRO.2015.03.017]
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ni ZC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2199, DOI 10.1109/ICME.2004.1394706
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   USC-SIPI Image Database Website, About us
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Xuan G, 2004, IEEE INT WORKSH MULT, DOI [10.1109/ICME.2005.1521722, DOI 10.1109/ICME.2005.1521722]
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17106-x
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600030
DA 2024-07-18
ER

PT J
AU Benbakreti, S
   Benouis, M
   Roumane, A
   Benbakreti, S
AF Benbakreti, Samir
   Benouis, Mohamed
   Roumane, Ahmed
   Benbakreti, Soumia
TI Impact of the data augmentation on the detection of brain tumor from MRI
   images based on CNN and pretrained models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Image classification; Brain tumor; MRI images; CNN;
   Pretrained models
AB Deep Learning has significantly push forward the research on cancer magnetic resonance imaging (MRI) images. These images are widely used to diagnose the presence of a deformed tissue within the brain in which the cells replicate indefinitely without control, i.e. a brain tumor. Radiologist have to deeply examine a set of MRI images for each patient in order to decide whether the tumor is benign (noncancerous) or malignant (cancerous). The latest have very severe consequences and have a very high mortality rate, but this could be significantly reduced if the cancer is diagnosed at an earlier stage. The classification task is very complicated due to neurological and radiological similarities of different tumors. In order to assist the radiologists, our objective in this paper is to achieve a correct classification of the MRI images. The studied deep classification models have been trained over three types of tumors: meningioma, glioma and pituitary tumor, on sagittal, coronal and axial views in addition to MRI of normal patients. The proposed model consists of combining a set of several classifiers that uses the features extracted by a convolutional neural network (CNN). We will, also, explore the impact of data augmentation and image resolution on the classification performance with the goal of obtaining the best possible accuracy. We used a CNN architecture and several pre-trained models. The model ResNet 18 gave the highest accuracy of 95.7%.
C1 [Benbakreti, Samir; Roumane, Ahmed] Ecole Natl Super Telecommun & Technol Informat & C, Dept Special, St Senia, Oran 31000, Algeria.
   [Benouis, Mohamed] Univ Augsburg, Chair Human Ctr Artificial Intelligence, Augsburg, Germany.
   [Benbakreti, Soumia] Univ Djillali Liabes Sidi Bel Abbes, Lab Matematic, Sidi Bel Abbes 22000, Algeria.
C3 University of Augsburg; University Djillali Liabes Sidi Bel Abbes
RP Benbakreti, S (corresponding author), Ecole Natl Super Telecommun & Technol Informat & C, Dept Special, St Senia, Oran 31000, Algeria.
EM Samir.benbakreti@ensttic.dz; Mohamed.benouis@uni-a.de;
   Ahmed.roumane@ensttic.dz; souben2223@gmail.com
OI Samir, Benbakreti/0000-0001-6587-6626
CR Abdelaziz M, 2021, INT J IMAG SYST TECH, V31, P2226, DOI 10.1002/ima.22594
   Addeh A., 2021, ENG Transactions, V2, P1
   Akagi Y, 2018, BRAIN TUMOR PATHOL, V35, P81, DOI 10.1007/s10014-018-0313-4
   Alshayeji MH, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103141
   [Anonymous], 2014, Computer Vision-ECCV, P740
   Asano K, 2018, BRAIN TUMOR PATHOL, V35, P131, DOI 10.1007/s10014-018-0320-5
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Buckner JC, 2007, MAYO CLIN PROC, V82, P1271, DOI 10.4065/82.10.1271
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144479
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Cruz DPF, 2016, NEUROCOMPUTING, V172, P427, DOI 10.1016/j.neucom.2015.03.106
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jarnalo COM, 2021, CLIN RADIOL, V76, P838, DOI 10.1016/j.crad.2021.07.012
   Jerban S, 2020, MAGN RESON IMAGING, V65, P27, DOI 10.1016/j.mri.2019.09.007
   Jungblut L, 2022, INVEST RADIOL, V57, P108, DOI 10.1097/RLI.0000000000000814
   Kleesiek J., 2014, P MICCAI BRATS BRAIN, P12
   Komori T, 2020, BRAIN TUMOR PATHOL, V37, P1, DOI 10.1007/s10014-020-00358-y
   Koriyama S, 2018, BRAIN TUMOR PATHOL, V35, P159, DOI 10.1007/s10014-018-0324-1
   Kuwahara K, 2019, BRAIN TUMOR PATHOL, V36, P135, DOI 10.1007/s10014-019-00348-9
   Noone AM., 2015, SEER Cancer Statistics Review
   Ohgaki H, 2005, ACTA NEUROPATHOL, V109, P93, DOI 10.1007/s00401-005-0991-y
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Samanta AK, 2018, ADV INTELL SYST COMP, V723, P343, DOI 10.1007/978-3-319-74690-6_34
   Saygili A, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107323
   Shaojuan Li, 2021, Journal of Physics: Conference Series, V1813, DOI 10.1088/1742-6596/1813/1/012051
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2021, VISUAL COMPUT, V37, P2157, DOI 10.1007/s00371-020-01977-4
   Spadaccini M, 2021, LANCET GASTROENTEROL, V6, P793, DOI 10.1016/S2468-1253(21)00215-6
   Spatharou A, 2020, Transforming healthcare with AI: The impact on the workforce and organizations, V10
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thangudu S, 2020, POLYMERS-BASEL, V12, DOI 10.3390/polym12123055
NR 41
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17092-0
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100009
DA 2024-07-18
ER

PT J
AU Zhang, XB
AF Zhang, Xuebo
TI An efficient method for the simulation of multireceiver SAS raw signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multireceiver; Synthetic aperture sonar; Raw signal; Simulation;
   Efficiency
ID CLASSIFICATION
AB The raw echoed signal considered to be an input of signal processors of multireceiver synthetic aperture sonar (SAS) system plays an important role in multireceiver SAS imaging algorithms and system design. Traditional echo simulation methods such as time-domain algorithm are characterized by time-consuming. To improve the simulation efficiency of SAS echoed signal, this paper proposes a novel method to simulate the SAS raw echo. The presented method firstly calculates the time delay corresponding to each target. Based on the spectrum of transmitted signal in the Fourier domain, the spectrum of echoed signal can be accurately obtained by the complex multiplication between the spectrum of transmitted signal and the phase shifting related to the time delay. This operation is repeatedly conducted for each target, and the final echo can be obtained by the inverse Fourier transformation. Compared to traditional echo simulation algorithms, the presented method can significantly improve the simulation efficiency of echoed signal without loss of performance. At last, the simulations well demonstrate that the presented method is highly efficient compared to traditional methods.
C1 [Zhang, Xuebo] Whale Wave Technol Inc, Kunming 650200, Peoples R China.
RP Zhang, XB (corresponding author), Whale Wave Technol Inc, Kunming 650200, Peoples R China.
EM xuebo_zhang@sina.cn
RI Zhang, Xuebo/ABI-2669-2020
OI Zhang, Xuebo/0000-0001-5164-754X
FU National Key Laboratory Foundation [9140C290401150C29132]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The work
   described in this article was partially supported by the National Key
   Laboratory Foundation under Grant 9140C290401150C29132
CR Brandes TS, 2019, IEEE T GEOSCI REMOTE, V57, P1278, DOI 10.1109/TGRS.2018.2865606
   Chen M, 2009, INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL SCIENCES AND OPTIMIZATION, VOL 1, PROCEEDINGS, P367, DOI 10.1109/CSO.2009.442
   Cumming I. G., 2005, ARTECH REM
   Dillon J, 2019, 2019 MTS IEEE OC C S, P1
   Hall JJ, 2019, IEEE J OCEANIC ENG, V44, P739, DOI 10.1109/JOE.2018.2835538
   Huang P, 2022, FRONT MAR SCI, V9, DOI 10.3389/fmars.2022.1049761
   Huang P, 2021, 2021 14TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2021), DOI 10.1109/CISP-BMEI53629.2021.9624422
   Huang P, 2022, ELECTRON LETT, V58, P1009, DOI 10.1049/ell2.12472
   Huang Pan, 2019, Geomatics and Information Science of Wuhan University, V44, P601, DOI 10.13203/j.whugis20170167
   Huang Pan, 2017, Journal of Naval University of Engineering, V29, P25, DOI 10.7495/j.issn.1009-3486.2017.05.006
   Hunter A.J., 2006, Underwater Acoustic Modelling for Synthetic Aperture Sonar
   Kaur S, 2022, INT J INTERACT MULTI, V7, P48, DOI 10.9781/ijimai.2022.01.004
   Kerstens R, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2019.2951061
   Kim SW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3138396
   Köhntopp D, 2019, IEEE J OCEANIC ENG, V44, P767, DOI 10.1109/JOE.2018.2835218
   Li YF, 2021, INT J INTERACT MULTI, V7, P34, DOI 10.9781/ijimai.2021.06.002
   Sahu LP, 2022, INT J INTERACT MULTI, V7, P56, DOI 10.9781/ijimai.2022.10.003
   Wang M, 2023, IEEE ACCESS, V11, P75112, DOI 10.1109/ACCESS.2023.3297138
   Xu H, 2023, DATA TECHNOL APPL, V57, P643, DOI 10.1108/DTA-09-2021-0236
   Xue AK, 2023, J ELECTRON INF TECHN, V45, P2528, DOI 10.11999/JEIT220710
   Yang J., 2019, Ship Electron Eng, V39, P187
   Yang PX, 2022, I C COMM SOFTW NET, P109, DOI 10.1109/ICCSN55126.2022.9817582
   Zhang XB, 2023, ELECTRON LETT, V59, DOI 10.1049/ell2.12859
   Zhang XB, 2023, IEEE GEOSCI REMOTE S, V20, DOI 10.1109/LGRS.2023.3286180
   [张学波 Zhang Xuebo], 2022, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V47, P133
NR 25
TC 11
Z9 11
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16992-5
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300002
DA 2024-07-18
ER

PT J
AU Liansheng, S
   Zhi, P
   Ying, C
   Zhaolin, X
   Ailing, T
AF Liansheng, Sui
   Zhi, Pang
   Ying, Cheng
   Zhaolin, Xiao
   Ailing, Tian
TI Reversible data hiding in encrypted images using multiple Huffman coding
   based on optimal block allocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data hiding; Image encryption; Multiple Huffman coding;
   Optimal block allocation
ID WATERMARKING; PROTECTION
AB As a booming technique in the field of information security, reversible data hiding in encrypted images has attracted great concern because secret data can be recorded in the encryption domain without knowing the related encryption key and the content of original images. In this paper, a fully reversible data hiding method with high embedding capacity is proposed based on optimal block allocation with full consideration of distinct pixel characteristics. The occurrence frequency of most significant bits in smooth blocks is used to obtain embeddable space. For fluctuant blocks, a cascaded two Huffman coding is innovatively designed to compress most significant bits of each pixel to generate more spare rooms. To enhance the security, not only the original image is encrypted based on sequences generated with the high-dimension chaotic system, but also the encrypted image containing secret data is further scrambled. Compared with some state-of-the-art methods, the experimental results and analysis demonstrate that the proposed method has larger embedding capacity using different test images and image databases.
C1 [Liansheng, Sui; Zhi, Pang; Zhaolin, Xiao] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
   [Liansheng, Sui] Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Peoples R China.
   [Ying, Cheng] Xian Univ Technol, Students Affairs Div, Xian 710048, Peoples R China.
   [Ailing, Tian] Xian Technol Univ, Shaanxi Prov Key Lab Thin Film Technol & Opt Test, Xian 710048, Peoples R China.
C3 Xi'an University of Technology; Xi'an University of Technology; Xi'an
   Technological University
RP Liansheng, S (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.; Liansheng, S (corresponding author), Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Peoples R China.
EM liudua2010@gmail.com
FU National Natural Science Foundation of China (NSFC): 62031023.
   [62031023]; National Natural Science Foundation of China (NSFC)
FX National Natural Science Foundation of China (NSFC): 62031023.
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2017, Image database of BOWS-2
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   De Vleeschouwer C, 2002, P IEEE, V90, P64, DOI 10.1109/5.982406
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Li X, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2372473
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Pang Z, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15020524
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Puteaux P, 2018, IEEE INT WORKS INFOR
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Ren HL, 2019, SIGNAL PROCESS, V165, P268, DOI 10.1016/j.sigpro.2019.07.020
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh P, 2018, INFORM SCIENCES, V422, P77, DOI 10.1016/j.ins.2017.08.077
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2021, IEEE T MULTIMEDIA, V23, P2286, DOI 10.1109/TMM.2020.3009492
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Xu N, 2022, COGN COMPUT, V14, P1172, DOI 10.1007/s12559-021-09919-5
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 40
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16966-7
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200011
DA 2024-07-18
ER

PT J
AU Shaik, A
   Devi, BA
   Baskaran, R
   Bojjawar, S
   Vidyullatha, P
   Balaji, P
AF Shaik, Amjan
   Devi, B. Aruna
   Baskaran, R.
   Bojjawar, Satish
   Vidyullatha, P.
   Balaji, Prasanalakshmi
TI Recurrent neural network with emperor penguin-based Salp swarm (RNN-
   EPS<SUP>2</SUP>) algorithm for emoji based sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE RNN; Salp; Swarm; Emoji; Sentiment analysis; Reviews; Polarities;
   Emperor penguin
AB The opinions of the users are analyzed by the sentiment analysis process. Sometimes, the users reviewed their opinions using emojis and it is necessary to analyze them to find the classes (positive, negative, or neutral). However, the existing works lack the ability of emoji analysis in large databases, which induces computational complexity and reduces performance. To tackle those issues, we propose a novel Recurrent Neural network (RNN) with an Emperor Penguin-based Salp Swarm algorithm (EPS2) approach. The optimization algorithm can be used to choose the parameters of the RNN and provide better results. The experiments are conducted by taking the data from four social media platforms known as Reddit, Twitter, IMDB movie review, and Yelp dataset. The performance is analyzed by different metrics and compared the outcomes with other state-of-art works. From the results, it is found that our proposed approach effectively analyses the emojis from the social media platform and provides better results.
C1 [Shaik, Amjan] St Peters Engn Coll, Hyderabad, Telangana, India.
   [Devi, B. Aruna] Dr NGP Inst Technol, Dept Elect & Commun Enginnering, Coimbatore 641048, Tamil Nadu, India.
   [Baskaran, R.] Agni Coll Technol, Ctr Res & Dev, Chennai 600130, Tamil Nadu, India.
   [Bojjawar, Satish] CVR Coll Engn, Dept Elect & Instrumentat Engn, Hyderabad 501510, Telangana, India.
   [Vidyullatha, P.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
   [Balaji, Prasanalakshmi] King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
C3 St. Peter's Institute of Higher Education & Research; Koneru Lakshmaiah
   Education Foundation (K L Deemed to be University); King Khalid
   University
RP Shaik, A (corresponding author), St Peters Engn Coll, Hyderabad, Telangana, India.
EM shaikammjann@gmail.com
RI vidyullatha, p/ADP-4147-2022
OI vidyullatha, p/0000-0001-7609-7791
CR Ahanin Z, 2022, COMPUT SPEECH LANG, V73, DOI 10.1016/j.csl.2021.101330
   Alharbi ASM, 2019, COGN SYST RES, V54, P50, DOI 10.1016/j.cogsys.2018.10.001
   Alhumoud SO, 2022, ARTIF INTELL REV, V55, P707, DOI 10.1007/s10462-021-09989-9
   Aljedaani W, 2022, KNOWL-BASED SYST, V255, DOI 10.1016/j.knosys.2022.109780
   Babu Nirmal Varghese, 2022, SN Comput Sci, V3, P74, DOI 10.1007/s42979-021-00958-1
   Behera RK, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102435
   Chenane JL, 2022, J CRIM JUSTICE EDUC, V33, P509, DOI 10.1080/10511253.2021.1991411
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Fernández-Gavilanes M, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115279
   Fernández-Gavilanes M, 2018, EXPERT SYST APPL, V103, P74, DOI 10.1016/j.eswa.2018.02.043
   Grover Vandita, 2022, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V103, P259, DOI 10.1007/s40031-021-00620-7
   Hakami SAA, 2022, 2022 14 INT C COMP I
   Janjanam L, 2022, 2022 IEEE 6 C INF CO
   Khalid OW, 2022, Alex Eng J
   Kumar TP, 2022, 2022 INT C EDG COMP
   Li D, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102290
   Li XY, 2023, ENTERP INF SYST-UK, V17, DOI 10.1080/17517575.2022.2037160
   Neelakandan S, 2024, J EXP THEOR ARTIF IN, V36, P415, DOI 10.1080/0952813X.2022.2093405
   Nistor SC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072266
   Onan A, 2022, J KING SAUD UNIV-COM, V34, P2098, DOI 10.1016/j.jksuci.2022.02.025
   Patil RS., 2022, "building Marathi SentiWordNet." international conference on recent trends in image processing and pattern recognition
   Rasool A, 2020, IEEE ACCESS, V8, P191850, DOI 10.1109/ACCESS.2020.3030642
   Reddy R, 2022, 2022 INT C APPL ART
   Sakode H, 2023, 2023 INT C INV COMP
   Saxena Akrati, 2022, Principles of Social Networking: The New Horizon and Emerging Challenges. Smart Innovation, Systems and Technologies (246), P279, DOI 10.1007/978-981-16-3398-0_13
   Si TN, 2022, 2022 IEEE ACIS 7 INT
   Singh A., 2022, 2022 3 INT C INT ENG
   Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1
   Xu J, 2019, APPL SOFT COMPUT, V80, P387, DOI 10.1016/j.asoc.2019.04.010
   Yuan X, 2022, 2022 26 INT C PATT R
NR 30
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16808-6
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200004
DA 2024-07-18
ER

PT J
AU Diwedi, HK
   Misra, A
   Tiwari, AK
AF Diwedi, Himanshu Kumar
   Misra, Anuradha
   Tiwari, Amod Kumar
TI CNN-based medicinal plant identification and classification using
   optimized SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Support vector machine; ResNet50; Transfer
   learning; Indian medicinal plants; Classification; IMPLAD
ID VISION
AB The exact and unfailing categorization of medicinal plants exceeds the capabilities of the average individual because it necessitates in-depth subject expertise and physical detection is cumbersome and imprecise owing to human mistakes. There have been multiple efforts to automate the recognition of medicinal plants using images of plant parts like flowers, leaves, and bark. The most trustworthy data source, according to research, is Leaf. An Enhanced Convolutional Neural Network architecture (using modified ResNet50) with Progressive Transfer Learning (ECNN-PTL) has been proposed in this paper. The suggested method uses an improved ReNet50 framework for feature extraction along with PTL. Classification has been done using an Optimized Support Vector Machine (OSVM). The classical SVM hyperparameters are tuned further by the Adam optimizer to achieve a better performance model. During the first stage of training, the initial levels of the pre-trained ResNet50 architecture have been frozen while the recently introduced levels have been taught using a differentiated learning rate. In the second step, the refined model from the first stage is loaded and trained by restructuring. This technique has been replicated so that in these two learning steps, the image size is allowed to gradually rise from 64, 128, and 150 to 256 pixels. The proposed ResNet-50 effectively max-pools the activation from the previous fully connected layer to the subsequent convolution layer. In the trials, the maximum and average activations from the previous convolution are kept, giving the model knowledge of both the approaches and enhancing performance. The Indian Medicinal Plants Database (IMPLAD) has been used to compile the list of online medicinal plant species.The improved ResNet50 modelOSVM classifier in the ECNN-PTLapproach has been compared with baseline models like VGG16, VGG19 and ResNet50 in terms of accuracy, precision, recall, error rate and execution time. The modified ResNet50 + OSVM model achieve a testing phase accuracy of 96.8% and a training phase accuracy of 98.5%.
C1 [Diwedi, Himanshu Kumar; Misra, Anuradha] Amity Univ, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Lucknow Campus, Lucknow, India.
   [Tiwari, Amod Kumar] Rajkiya Engn Coll, Dept Comp Sci & Engn, Sonbhadra, Uttar Pradesh, India.
RP Diwedi, HK (corresponding author), Amity Univ, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Lucknow Campus, Lucknow, India.
EM himanshudiwedi01@gmail.com; amisra@lko.amity.edu;
   amod.tiwari@recsonbhadra.ac.in
CR Armi L., 2019, ARXIV
   Austen GE, 2016, SCI REP-UK, V6, DOI 10.1038/srep33634
   B R Pushpa, 2022, 2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS), P238, DOI 10.1109/ICAISS55157.2022.10011101
   Bodhwani Vinit, 2019, Procedia Computer Science, V152, P186, DOI 10.1016/j.procs.2019.05.042
   Chen D, 2022, COMPUT ELECTRON AGR, V198, DOI 10.1016/j.compag.2022.107091
   Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Goyal N, 2022, MULTIMED TOOLS APPL, V81, P32243, DOI 10.1007/s11042-022-12825-z
   Hu J, 2018, IEEE SIGNAL PROC LET, V25, P853, DOI 10.1109/LSP.2018.2809688
   Huang ML, 2022, SUSTAIN COMPUT-INFOR, V33, DOI 10.1016/j.suscom.2021.100646
   Kanda PS, 2021, IEEE ACCESS, V9, P162590, DOI 10.1109/ACCESS.2021.3131726
   Kaur S., 2019, Journal of Multimedia Information System, V6, P49, DOI [10.33851/JMIS.2019.6.2.49, DOI 10.33851/JMIS.2019.6.2.49]
   Kaya Y, 2023, ECOL INFORM, V75, DOI 10.1016/j.ecoinf.2023.101998
   Keceli AS, 2022, ECOL INFORM, V69, DOI 10.1016/j.ecoinf.2022.101679
   Kheirkhah FM, 2019, IET COMPUT VIS, V13, P369, DOI 10.1049/iet-cvi.2018.5028
   Kurmi Y, 2022, MULTIMED TOOLS APPL, V81, P8155, DOI 10.1007/s11042-022-11910-7
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   Li ZB, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105672
   Mathe A., 2022, Medicinal and Aromatic Plants of India, V1, P1
   Mohtashamian M, 2021, IJST-T ELECTR ENG, V45, P1051, DOI 10.1007/s40998-020-00398-2
   Naeem S, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11020263
   Nazarenko DV, 2016, CHEMOMETR INTELL LAB, V156, P174, DOI 10.1016/j.chemolab.2016.06.003
   Roopashree S, 2021, IEEE ACCESS, V9, P135927, DOI 10.1109/ACCESS.2021.3116207
   Rull V, 2022, EMBO REP, V23, DOI 10.15252/embr.202154193
   Sachar S., 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012086
   Shaheen S, 2019, ADULTERATION IN HERBAL DRUGS: A BURNING ISSUE, P35, DOI 10.1007/978-3-030-28034-5_4
   Taheri-Garavand A, 2021, PLANTS-BASEL, V10, DOI 10.3390/plants10071406
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Turkoglu M, 2019, APPL MATH COMPUT, V352, P1, DOI 10.1016/j.amc.2019.01.054
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Venugopalan Nair SN, 2020, CONSERVATION UTILIZA, P63, DOI DOI 10.1007/978-3-030-39793-7_3
   Wang AC, 2019, COMPUT ELECTRON AGR, V158, P226, DOI 10.1016/j.compag.2019.02.005
   Willis CG, 2017, TRENDS ECOL EVOL, V32, P531, DOI 10.1016/j.tree.2017.03.015
   Yang CZ, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107809
   Zhang CM, 2021, J IND INF INTEGR, V23, DOI 10.1016/j.jii.2021.100224
NR 35
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33823
EP 33853
DI 10.1007/s11042-023-16733-8
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400021
DA 2024-07-18
ER

PT J
AU He, QL
   Gao, PZ
   Zhang, F
   Bian, GQ
   Li, Z
   Wang, Z
AF He, Qinlu
   Gao, Pengze
   Zhang, Fan
   Bian, Genqing
   Li, Zhen
   Wang, Zan
TI Healthcare entity recognition based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical Named Entity Recognition; BiLSTM; IDCNN
ID STAIN NORMALIZATION; CLASSIFICATION; ENSEMBLE; CONTEXT; IMAGES
AB China has entered a stage of high-quality development, and people have higher demand and expectations for the existing medical field. MNER(Medical Named Entity Recognition) is the task of identifying the correct entity boundary and classifying medical entities from a piece of medical text information. The effect of MNER would directly affect the performance of downstream relationship extraction and intelligent question answering, which has important research significance and value. In this paper, aiming at the named entity recognition of discontinuous medical entities in Chinese medical text information, this paper expands the research based on BiLSTM-CRF, introduces the IDCNN layer after the input layer of the model to capture the local context information in the medical text, and then uses the output of IDCNN as the input of BiLSTM-CRF for subsequent training, to construct an IDCNN-BiLSTM-CRF network model for discontinuous medical text. Based on BERT, the weight is assigned to the 12-layer transformer in BERT, and the results are weighted and averaged, and a WfBERT-Att-D-BiLSTM-CRF model based on the weight output of different layers of BERT is proposed. During the experiment, the hidden layer, the number of iterations, and the batch data size are continuously experimented with, and finally, the optimal parameter settings are obtained. In this paper, repeated experiments are carried out on different datasets, the final actual recognition effect is also tested, and the correctness of the proposed model is verified from different perspectives.
C1 [He, Qinlu; Gao, Pengze; Zhang, Fan; Bian, Genqing] Xian Univ Architecture & Technol, Sch Informat & Control Engn, Xian 710054, Peoples R China.
   [Li, Zhen] Shaan Xi Inst Metrol Sci, Xian 710043, Peoples R China.
   [Wang, Zan] Shanghai Today Informat Technol Co Ltd, Shanghai 200080, Peoples R China.
C3 Xi'an University of Architecture & Technology
RP He, QL (corresponding author), Xian Univ Architecture & Technol, Sch Informat & Control Engn, Xian 710054, Peoples R China.; Li, Z (corresponding author), Shaan Xi Inst Metrol Sci, Xian 710043, Peoples R China.
EM luluhe8848@Hotmail.com; billywin1982@126.com
OI he, qinlu/0000-0003-4051-3137
FU National Natural Science Foundation of China
FX This work is supported by the National Natural Science Foundation of
   China (61872284); Industrial field of general projects of science and
   Technology Department of Shaanxi Province(2023-YBGY-203, 2023-YBGY-021);
   Industrialization Project of Shaanxi Provincial Department of Education
   (21JC017); "Thirteenth Five-Year" National Key R&D Program Project
   (Project Number: 2019YFD1100901). Natural Science Foundation of Shannxi
   Province, China(2021JLM-16).
CR Bhatia S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P262
   Cui SM, 2023, NEURAL COMPUT APPL, V35, P2561, DOI 10.1007/s00521-022-07747-8
   Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365
   Hssayni El Houssaine, 2023, Journal of Ambient Intelligence and Humanized Computing, P13715, DOI 10.1007/s12652-022-04025-2
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Huang L, 2019, 2019 8 INT C
   Jin YC, 2023, J AM MED INFORM ASSN, V30, P438, DOI 10.1093/jamia/ocac230
   Landolsi Mohamed Yassine, 2022, Procedia Computer Science, P674, DOI 10.1016/j.procs.2022.09.122
   Landolsi MY, 2023, KNOWL INF SYST, V65, P463, DOI 10.1007/s10115-022-01779-1
   Lee LH, 2021, IEEE J BIOMED HEALTH, V25, P2801, DOI 10.1109/JBHI.2020.3048700
   Li LQ, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0933-6
   Li Xiaoqing, 2023, Tenth International Conference on Applications and Techniques in Cyber Intelligence (ICATCI 2022). Lecture Notes on Data Engineering and Communications Technologies (169), P229, DOI 10.1007/978-3-031-28893-7_28
   Li XY, 2020, J BIOMED INFORM, V107, DOI 10.1016/j.jbi.2020.103422
   Li YB, 2020, JMIR MED INF, V8, DOI 10.2196/19848
   Li Z, P EV TASKS CHIN C KN
   Liu MF, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3387634
   Méndez M, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.106041
   Morales-Burton V, 2022, LSE Research Online Documents on Economics
   Quimbaya AP, 2016, PROCEDIA COMPUT SCI, V100, P55, DOI 10.1016/j.procs.2016.09.123
   Pomares-Quimbaya A, 2018, Int J Reliab Qual E-Healthc(IJRQEH), V7
   Ramachandran R, 2021, SSRN Electron J, DOI [10.2139/ssrn.3769845, DOI 10.2139/SSRN.3769845]
   Rebecka W, 2014, P WORKSH 28 AAAI C A, P46
   Sui Y, 2022, Trigger-GNN: A trigger-based graph neural network for nested named entity recognition, DOI [10.1109/IJCNN55064.2022.9892555, DOI 10.1109/IJCNN55064.2022.9892555]
   Tay Y, 2018, Arxiv, DOI [arXiv:1806.00778, 10.48550/arXiv.1806.00778, DOI 10.48550/ARXIV.1806.00778]
   Wang Q, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103133
   Wang Xiaoyan, 2008, AMIA Annu Symp Proc, P783
   Wei Q, 2020, 2020 IEEE INT C HEAL
   Wen GH, 2020, J BIOMED INFORM, V112, DOI 10.1016/j.jbi.2020.103608
   Xia Y, 2017, CEUR WORKSHOP P, P43
   Xishuang Dong, 2017, 2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom), P1, DOI 10.1109/HealthCom.2017.8210840
   Xue K, 2019, IEEE INT C BIOINFORM, P892, DOI 10.1109/BIBM47256.2019.8983370
   Yang BS, 2019, Arxiv, DOI [arXiv:1902.09091, 10.48550/arXiv.1902.09091]
   Yang YS, 2018, Arxiv, DOI [arXiv:1801.05147, 10.48550/arXiv.1801.05147, DOI 10.48550/ARXIV.1801.05147]
   Yao L., 2022, Softw Eng, V25, P30, DOI [10.19644/j.cnki.issn2096-1472.2022.012.007, DOI 10.19644/J.CNKI.ISSN2096-1472.2022.012.007]
   Yin R., 2016, P 2016 C EMP METH NA, P981, DOI DOI 10.18653/V1/D16-1100
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhang XM, 2023, INT J SOFTW ENG KNOW, V33, P109, DOI 10.1142/S0218194022500681
   Zhang Y, 2018, Arxiv, DOI arXiv:1805.02023
NR 39
TC 0
Z9 0
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32739
EP 32763
DI 10.1007/s11042-023-16900-x
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100010
DA 2024-07-18
ER

PT J
AU Meswal, H
   Kumar, D
   Gupta, A
   Roy, S
AF Meswal, Himanshi
   Kumar, Deepika
   Gupta, Aryan
   Roy, Sudipta
TI A weighted ensemble transfer learning approach for melanoma
   classification from skin lesion images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble; Skin cancer; Transfer learning; Classification; Weighted; Deep
   learning
ID SECRET SHARING SCHEME; VISUAL CRYPTOGRAPHY; XOR; QUALITY
AB Cancer is the foremost cause of mortality among humans, as per statistics and accurate classification of the lesion is critical for treating skin cancer at an early stage. Identification of the disease via computer-aided tools can help in accurate diagnosis. This study's primary goal is to suggest an effective strategy for more accurately classifying skin lesions. The binary classification of skin lesions has been proposed using the weighted average ensemble approach. The predictions from various models are combined via the weighted sum ensemble, where the weights of each model are determined by how well it performs. Weights for each learner in the weighted ensemble are scientifically determined based on their average accuracy on the testing dataset. The proposed weighted ensemble classifier uses an ensemble of seven deep-learning neural networks to perform binary classification, including InceptionV3, VGG16, Xception, ResNet50, and others. The International Skin Imaging Collaboration (ISIC) dataset has been used for experimentation, which is binary classified into Melanoma and Nevus. The proposed ensemble method provides the highest level of accuracy, precision, recall, f1-score, sensitivity, and specificity of 93.36%, 93%, 93%, 93%, 97%, and 97% respectively on the first ISIC dataset. The proposed methodology's efficiency has also been compared and evaluated with another ISIC dataset. On the other ISIC dataset, the proposed weighted ensemble classifier had an accuracy of 85.54%. Additionally, the proposed methodology has been compared with state-of-art techniques. a weighted ensemble method where the final result decision is made based on the weighted total of the anticipated outputs from the classifiers. Each model is given a specific weight, which is then multiplied by the value it predicted and used to get the sum or average forecast. The suggested classification model concluded about the expected probabilities for each class and selected the class with the highest probability.
C1 [Meswal, Himanshi] Amity Univ, AIAS, Noida 201303, Uttar Pradesh, India.
   [Kumar, Deepika; Gupta, Aryan] Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, New Delhi 110063, India.
   [Roy, Sudipta] Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai 410206, India.
C3 Amity University Noida
RP Roy, S (corresponding author), Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai 410206, India.
EM meswal.himanshi1234@gmail.com; deepika.kumar@bharatividyapeeth.edu;
   aryan.sgs@gmail.com; sudipta1.roy@jioinstitute.edu.in
RI Roy, Sudipta/T-5231-2019
OI Roy, Sudipta/0000-0001-5161-9311
CR Abdelhalim ISA, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113922
   Alfi IA, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030726
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Milton MAA, 2019, Arxiv, DOI [arXiv:1901.10802, 10.48550/arXiv.1901.10802]
   Banasode Praveen, 2021, IOP Conference Series: Materials Science and Engineering, V1065, DOI 10.1088/1757-899X/1065/1/012039
   Basak H, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108673
   Bisla D, 2019, IEEE COMPUT SOC CONF, P2720, DOI 10.1109/CVPRW.2019.00330
   Brinker TJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218713
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   DeVries T, 2017, Arxiv, DOI arXiv:1703.01402
   Farooq MA, 2016, IEEE INT C BIOINF BI, P301, DOI 10.1109/BIBE.2016.53
   Fekri-Ershad S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040686
   Imran A, 2022, IEEE ACCESS, V10, P118198, DOI 10.1109/ACCESS.2022.3220329
   Jain S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21238142
   Jaleel JA, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P1137, DOI 10.1109/ICCPCT.2013.6528879
   Jana E, 2017, 2017 IEEE INT C COMP, P1, DOI DOI 10.1109/ICCIC.2017.8524554
   Jin QG, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106881
   Kassem MA, 2020, IEEE ACCESS, V8, P114822, DOI 10.1109/ACCESS.2020.3003890
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Liao HF, 2016, INT C PATT RECOG, P355, DOI 10.1109/ICPR.2016.7899659
   Meena T, 2023, Infor Reuse and Inte, P309, DOI 10.1109/IRI58017.2023.00061
   Nijhawan R, 2022, 2022 5 INT C COMP IN, P1
   Nugroho AA, 2019, AIP CONF PROC, V2202, DOI 10.1063/1.5141652
   Pal D, 2023, Infor Reuse and Inte, P261, DOI 10.1109/IRI58017.2023.00052
   Rashid H, 2019, IEEE ENG MED BIO, P916, DOI [10.1109/EMBC.2019.8857905, 10.1109/embc.2019.8857905]
   Rezvantalab A, 2018, Arxiv, DOI arXiv:1810.10348
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Roy S, 2019, LECT NOTES COMPUT SC, V11663, P159, DOI 10.1007/978-3-030-27272-2_14
   Roy S, 2017, COMPUT METH PROG BIO, V140, P307, DOI 10.1016/j.cmpb.2017.01.003
   Mahecha MSS, 2018, LECT NOTES COMPUT SC, V11195, P605, DOI 10.1007/978-3-030-02131-3_53
   Shahsavari A, 2023, MULTIMED TOOLS APPL, V82, P10575, DOI 10.1007/s11042-022-13666-6
   Singh V, 2018, IEEE SYS MAN CYBERN, P4035, DOI 10.1109/SMC.2018.00684
   Srinivasu PN, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12123067
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Srivastava V, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108259
   Suganya R, 2016, INT CONF RECENT
   Tembhurne JV, 2023, MULTIMED TOOLS APPL, V82, P27501, DOI 10.1007/s11042-023-14697-3
   Togaçar M, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110714
   Dang T, 2021, IEEE C EVOL COMPUTAT, P744, DOI 10.1109/CEC45853.2021.9504929
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
NR 41
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33615
EP 33637
DI 10.1007/s11042-023-16783-y
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100003
DA 2024-07-18
ER

PT J
AU Zhang, ES
   Wang, SB
AF Zhang, Enshuo
   Wang, Shubin
TI A new universal object detection solution based on point-cloud
   projection with viewport feature calibration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object illation; Feature-points calibration (FPC); Point-cloud
   projection (PCP); Equivalent-radius (ER)
AB The existing object detection algorithms are divided into neural network and non-neural network based methods. Both of them require sufficient training data samples and the consistent environment with the training data to work stably and efficiently. However, they are not able to work if i) there is no object image sample, and/or ii) the working viewports are different from those of the object sampling. To address the above problems, we propose a new method, which includes point-cloud projection (PCP), and equivalent-radius (ER), and the feature-points calibration (FPC) algorithms based on the optical imaging principle. The new PCP algorithm provides a general method to project the point cloud of the object to different viewports for detection. The new ER algorithm uses the output of the PCP algorithm to detect objects. The new FPC algorithm uses markers of a known size to calibrate the viewport parameters of any visual system for the PCP algorithm. Different from the conventional object detection methods and the rendering methods in computer graphics, the new method does not need training samples and thus has less computation. Moreover, it has better generality since it is independent of the viewport locations and angles. Simulation results show that the proposed method works effectively and its object detection accuracy on a standard dataset is above 99.7%, demonstrating that the new method works well without training data, and has a high accuracy even if the working viewports are different from those for object sampling.
C1 [Zhang, Enshuo] Inner Mongolia Univ, Coll Comp Sci, Coll Software, Hohhot 010021, Peoples R China.
   [Wang, Shubin] Inner Mongolia Univ, Sch Elect Informat Engn, Hohhot 010021, Peoples R China.
C3 Inner Mongolia University; Inner Mongolia University
RP Wang, SB (corresponding author), Inner Mongolia Univ, Sch Elect Informat Engn, Hohhot 010021, Peoples R China.
EM wangshubin@imu.edu.cn
FU This work was supported by the National Natural Science Foundation of
   China under Grant 62361048. [62361048]; National Natural Science
   Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62361048.
CR Chen XY, 2022, IEEE T MULTIMEDIA, V24, P1558, DOI 10.1109/TMM.2021.3067439
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Heckbert PS, 2013, GRAPHICS GEMS, V4
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu S, 2022, IEEE T MULTIMEDIA, V24, P2058, DOI 10.1109/TMM.2021.3075323
   Xie J, 2023, IEEE T MULTIMEDIA, V25, P2153, DOI 10.1109/TMM.2022.3143707
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou Y, 2018, IEEE CONF COMPUT
NR 20
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 34031
EP 34054
DI 10.1007/s11042-023-16912-7
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100011
DA 2024-07-18
ER

PT J
AU Rejeb, A
   Rejeb, K
   Appolloni, A
   Treiblmaier, H
AF Rejeb, Abderahman
   Rejeb, Karim
   Appolloni, Andrea
   Treiblmaier, Horst
TI Foundations and knowledge clusters in TikTok (Douyin) research: evidence
   from bibliometric and topic modelling analyses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TikTok; Public health; Body image; Bibliometrics; Topic modeling
ID SOCIAL MEDIA; COVID-19 INFORMATION; SHORT VIDEO; MANAGEMENT; DOMAIN;
   VISUALIZATION; OPPORTUNITIES; ENGAGEMENT; BUSINESS; SCIENCE
AB The goal of this study is to comprehensively analyze the dynamics and structure of TikTok research since its initial development. The scholarly composition of articles dealing with TikTok was dissected via a bibliometric study based on a corpus of 542 journal articles from the Scopus database. The results show that TikTok research has flourished in recent years and also demonstrate that the authors' collaboration networks are disjointed, indicating a lack of cooperation among TikTok researchers. Furthermore, the analysis reveals that research collaboration among academic institutions reflects the North-South divide, also highlighting a limited research collaboration between institutions in developed and developing countries. Based on the keyword co-occurrence network and topic modeling, TikTok research revolves mainly around five thematic areas, including public health, health communication and education, platform governance, body image, and its impact on children and students. Based on these findings, numerous suggestions for further research are offered. As far as the authors are aware, this is the first application of bibliometrics and topic modeling to assess the growth of TikTok research and reveal the intellectual base of this knowledge domain.
C1 [Rejeb, Abderahman] Univ Roma Tor Vergata, Fac Econ, Dept Management & Law, Via Columbia 2, I-00133 Rome, Italy.
   [Rejeb, Karim] Univ Carthage, Fac Sci Bizerte, Zarzouna 7021, Bizerte, Tunisia.
   [Appolloni, Andrea] Univ Roma Tor Vergata, Fac Econ, Dept Management & Law, Via Columbia 2, I-00133 Rome, Italy.
   [Treiblmaier, Horst] Modul Univ Vienna, Sch Int Management, Kahlenberg 1, A-1190 Vienna, Austria.
C3 University of Rome Tor Vergata; Universite de Carthage; University of
   Rome Tor Vergata
RP Treiblmaier, H (corresponding author), Modul Univ Vienna, Sch Int Management, Kahlenberg 1, A-1190 Vienna, Austria.
EM horst.treiblmaier@modul.ac.at
FU MODUL University Vienna GmbH
FX No Statement Available
CR Abdollahi A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132112011
   AI-Maroof R., 2021, International Journal of Data and Network Scie nce, V5, P197, DOI [10.5267/j.ijdns.2021.6.013, DOI 10.5267/J.IJDNS.2021.6.013]
   AJIFERUKE I, 1988, SCIENTOMETRICS, V14, P421, DOI 10.1007/BF02017100
   Alalwan AA, 2017, TELEMAT INFORM, V34, P1177, DOI 10.1016/j.tele.2017.05.008
   Anderson K.E., 2020, Library Hi Tech News, V37, P7, DOI DOI 10.1108/LHTN-01-2020-0001
   [Anonymous], 2021, MEDICINA LITHUANIA, DOI DOI 10.3390/MEDICINA57070648
   Arora SD, 2022, TECHNOL FORECAST SOC, V183, DOI 10.1016/j.techfore.2022.121942
   Arroyo-Machado W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228713
   Aryadoust V, 2021, COMPUT ASSIST LANG L, V34, P898, DOI 10.1080/09588221.2019.1647251
   Ashta A, 2021, STRATEG CHANG, V30, P211, DOI 10.1002/jsc.2404
   Avdeeff MK, 2021, CONTEMP MUSIC REV, V40, P78, DOI 10.1080/07494467.2021.1945225
   Bai GC, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.924748
   Bandy Jack, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449148
   Barta S, 2023, J RETAIL CONSUM SERV, V70, DOI 10.1016/j.jretconser.2022.103149
   Basch CH, 2021, JMIR PEDIATR PARENT, V4, DOI 10.2196/30681
   Basch CH, 2021, JMIR PUBLIC HLTH SUR, V7, DOI 10.2196/26392
   Basch Corey H, 2022, Int J Adolesc Med Health, V34, P367, DOI 10.1515/ijamh-2020-0111
   Bassell K, 2010, TEACH LEARN NURS, V5, P143, DOI 10.1016/j.teln.2010.07.007
   Bolton RN, 2013, J SERV MANAGE, V24, P245, DOI 10.1108/09564231311326987
   Bozzola E, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19169960
   Bradford S. C., 1985, Engineering, V137, P176, DOI [DOI 10.1177/016555158501000407, 10.1177/016555158501000, DOI 10.1177/016555158501000]
   Brooks R, 2022, BMJ GLOB HEALTH, V7, DOI 10.1136/bmjgh-2022-009112
   Brown Y, 2024, J SOCIOL, V60, P121, DOI 10.1177/14407833221110267
   Bossen CB, 2020, YOUNG CONSUM, V21, P463, DOI 10.1108/YC-07-2020-1186
   BURRELL QL, 1989, J DOC, V45, P302, DOI 10.1108/eb026847
   Caputo A, 2023, INT J CONFL MANAGE, V34, P1, DOI 10.1108/IJCMA-07-2021-0117
   Chai XN, 2022, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.774675
   Chang CY, 2021, NURS EDUC TODAY, V96, DOI 10.1016/j.nedt.2020.104645
   Chen XL, 2022, COGN COMPUT, V14, P24, DOI 10.1007/s12559-021-09861-6
   Chobanyan K., 2021, J RUSSIAN MEDIA JOUR, V3, DOI DOI 10.30547/WORLDOFMEDIA.3.2021.3
   Cleofas JV, 2022, ARCH PSYCHIAT NURS, V40, P97, DOI 10.1016/j.apnu.2022.06.003
   Cobo MJ, 2011, J AM SOC INF SCI TEC, V62, P1382, DOI 10.1002/asi.21525
   Colicchia C, 2019, SUPPLY CHAIN MANAG, V24, P5, DOI 10.1108/SCM-01-2018-0003
   Colicchia C, 2012, SUPPLY CHAIN MANAG, V17, P403, DOI 10.1108/13598541211246558
   Cooper BR, 2022, CURR DERMATOL REP, V11, P103, DOI 10.1007/s13671-022-00359-4
   Cuccurullo C, 2016, SCIENTOMETRICS, V108, P595, DOI 10.1007/s11192-016-1948-8
   Dabic M, 2020, SMALL BUS ECON, V55, P705, DOI 10.1007/s11187-019-00181-6
   De La Garza H, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18095002
   De Leyn T, 2022, J YOUTH STUD, V25, P1108, DOI 10.1080/13676261.2021.1939286
   De Veirman M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02685
   Della Corte V, 2018, BRIT FOOD J, V120, P2270, DOI 10.1108/BFJ-09-2017-0538
   Demiroz F, 2019, LOCAL GOV STUD, V45, P308, DOI 10.1080/03003930.2018.1541796
   Deng DS, 2022, J HOSP TOUR TECHNOL, V13, P683, DOI 10.1108/JHTT-05-2021-0143
   Dias P, 2022, J Digital Social Media Market, V10, P95
   Ding Y, 2011, J INFORMETR, V5, P187, DOI 10.1016/j.joi.2010.10.008
   Dinic BM, 2021, CURR PSYCHOL, V40, P3206, DOI 10.1007/s12144-019-00250-9
   Doyle B, 2023, TikTok Statistics
   Dwivedi Y. K., 2015, The Marketing Review, V15, P289, DOI [DOI 10.1362/146934715X14441363377999, 10.1362/146934715X14441363377999]
   Eghtesadi M, 2020, CAN J PUBLIC HEALTH, V111, P389, DOI 10.17269/s41997-020-00343-0
   Escamilla-Fajardo P, 2021, J HOSP LEIS SPORT TO, V28, DOI 10.1016/j.jhlste.2021.100302
   ESFAHANI H J., 2019, Int J Data Netw Sci, V3, P145, DOI [DOI 10.5267/J.IJDNS.2019.2.007, 10.5267/j.ijdns.2019.2.007]
   Fahimnia B, 2015, INT J PROD ECON, V162, P101, DOI 10.1016/j.ijpe.2015.01.003
   Fraticelli L, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182413260
   Gamir-Ríos J, 2022, COMMUN SOC-SPAIN, V35, P37, DOI 10.15581/003.35.2.37-52
   Gao LQ, 2022, FRONT PHYS-LAUSANNE, V9, DOI 10.3389/fphy.2021.787185
   Garrido-Cardenas JA, 2020, TUBERCULOSIS, V121, DOI 10.1016/j.tube.2020.101917
   Gillespie T, 2014, INSIDE TECHNOL, P1
   Glänzel W, 2005, SCIENTOMETRICS, V65, P323, DOI 10.1007/s11192-005-0277-0
   González-Teruel A, 2015, SCIENTOMETRICS, V103, P687, DOI 10.1007/s11192-015-1548-z
   Gray JE, 2021, INTERNET POLICY REV, V10, DOI 10.14763/2021.2.1557
   Greene Derek, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P498, DOI 10.1007/978-3-662-44848-9_32
   Guarda Teresa, 2021, Marketing and Smart Technologies. Proceedings of ICMarkTech 2020. Smart Innovation, Systems and Technologies (SIST 205), P35, DOI 10.1007/978-981-33-4183-8_4
   He M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12189136
   Helbach J, 2021, J SPORT SCI MED, V20, P642, DOI 10.52082/jssm.2021.642
   Hermida A, 2012, JOURNALISM STUD, V13, P815, DOI 10.1080/1461670X.2012.664430
   Herrick SSC, 2021, INT J EAT DISORDER, V54, P516, DOI 10.1002/eat.23463
   Holland G, 2016, BODY IMAGE, V17, P100, DOI 10.1016/j.bodyim.2016.02.008
   Hopfer S, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.819228
   Jain J, 2022, MANAG REV Q, V72, P823, DOI 10.1007/s11301-021-00215-y
   Janmaijaya M, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104280
   Kajikawa Y, 2022, TECHNOL FORECAST SOC, V182, DOI 10.1016/j.techfore.2022.121877
   Karizat Nadia, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3476046
   Kaye D.B. V., 2022, TikTok: Creativity and culture in short video
   Keim Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182972
   Khan GF, 2016, COMMUN ASSOC INF SYS, V39, P367, DOI 10.17705/1CAIS.03918
   Khan Y, 2022, ADV ARCHAEOL PRACT, V10, P452, DOI 10.1017/aap.2022.28
   KINNUCAN MT, 1990, INFORM PROCESS MANAG, V26, P777, DOI 10.1016/0306-4573(90)90051-3
   Knani M, 2022, INT J HOSP MANAG, V107, DOI 10.1016/j.ijhm.2022.103317
   Kozlowski D, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245393
   LAW J, 1988, SCIENTOMETRICS, V14, P251, DOI 10.1007/BF02020078
   Li M, 2022, CHEMOSPHERE, V304, DOI 10.1016/j.chemosphere.2022.135337
   Li Y, 2021, Front Econ Manag, V2, P176, DOI [10.6981/FEM.202102_2(2).0022, DOI 10.6981/FEM.202102_2(2).0022]
   Li YC, 2021, HEALTH EDUC RES, V36, P261, DOI 10.1093/her/cyab010
   Liang J, 2022, J MED INTERNET RES, V24, DOI 10.2196/39360
   Liu ZY, 2023, TECHNOL FORECAST SOC, V187, DOI 10.1016/j.techfore.2022.122253
   Ma YL, 2021, MANAGE ORGAN REV, V17, P382, DOI 10.1017/mor.2020.69
   MacKinnon KR, 2021, J MED INTERNET RES, V23, DOI 10.2196/30315
   Manago A.M., 2015, FRIENDSHIP HAPPINESS, P187, DOI DOI 10.1007/978-94-017-9603-3_11
   McCashin D, 2023, CLIN CHILD PSYCHOL P, V28, P279, DOI 10.1177/13591045221106608
   Meng KS, 2021, TELECOMMUN POLICY, V45, DOI 10.1016/j.telpol.2021.102172
   Mhalla M, 2020, INT J INNOV TECHNOL, V17, DOI 10.1142/S0219877020500509
   Miao WS, 2023, MEDIA INT AUST, V186, P97, DOI 10.1177/1329878X211013919
   Mobin MA, 2021, EURASIAN ECON REV, DOI 10.1007/s40822-021-00193-2
   Morales M, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031820
   Mostafa MM, 2020, TRENDS FOOD SCI TECH, V99, P660, DOI 10.1016/j.tifs.2020.03.022
   Muhl DD, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e09369
   Nekmahmud M, 2022, TECHNOL FORECAST SOC, V185, DOI 10.1016/j.techfore.2022.122067
   Olvera C, 2021, MOV DISORD CLIN PRAC, V8, P1200, DOI 10.1002/mdc3.13316
   Omar Bahiyah, 2020, International Journal of Interactive Mobile Technologies, V14, P121, DOI 10.3991/ijim.v14i04.12429
   Ostrovsky AM, 2020, J ADOLESCENT HEALTH, V67, P730, DOI 10.1016/j.jadohealth.2020.07.039
   Pan WJ, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.846390
   Patra SK, 2006, SCIENTOMETRICS, V67, P477, DOI 10.1556/Scient.67.2006.3.9
   Pop LM, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19095064
   Price DJDS., 1963, Little science, big science, DOI DOI 10.7312/PRIC91844
   Prieto-Gutirrez J. J., 2019, The Serials Librarian, V77, P38, DOI [10.1080/0361526X.2019.1637387, DOI 10.1080/0361526X.2019.1637387]
   Purushothaman V, 2022, J MED INTERNET RES, V24, DOI 10.2196/34050
   Qin Y, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.932805
   Radin AGB, 2022, J MICROBIOL BIOL EDU, V23, DOI 10.1128/jmbe.00236-21
   Ramos-Rodríguez AR, 2004, STRATEGIC MANAGE J, V25, P981, DOI 10.1002/smj.397
   Rand JR, 2021, SCHOLE: A J Leisure Stud Recreat Educ, DOI [10.1080/1937156X.2021.1962219, DOI 10.1080/1937156X.2021.1962219]
   Rejeb A, 2022, TELEMAT INFORM, V73, DOI 10.1016/j.tele.2022.101876
   Reuter K, 2021, JMIR PUBLIC HLTH SUR, V7, DOI 10.2196/24429
   Rosas SR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017428
   Ruparel N, 2023, J BUS RES, V156, DOI 10.1016/j.jbusres.2022.113482
   Rutherford BN, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031141
   SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974
   Sari E. F. N., 2022, International Journal of Human Movement and Sports Sciences, V10, P187, DOI [10.13189/saj.2022.100208, DOI 10.13189/SAJ.2022.100208]
   Schellewald A, 2021, INT J COMMUN, V15, P0
   Scherr S, 2021, COMPUT HUM BEHAV, V124, DOI 10.1016/j.chb.2021.106893
   Song SJ, 2021, INTERNET RES, V31, P2120, DOI 10.1108/INTR-10-2020-0593
   Southerton C, 2021, J Commun, V15, P0
   Southwick L, 2021, J ADOLESCENT HEALTH, V69, P234, DOI 10.1016/j.jadohealth.2021.05.010
   Su HN, 2010, SCIENTOMETRICS, V85, P65, DOI 10.1007/s11192-010-0259-8
   Su YR, 2020, INT J SPORT COMMUN, V13, P436, DOI 10.1123/ijsc.2020-0238
   Sun TZ, 2023, TOB CONTROL, V32, P251, DOI 10.1136/tobaccocontrol-2021-056619
   Szeto MD, 2021, CURR DERMATOL REP, V10, P97, DOI 10.1007/s13671-021-00343-4
   Tang KY, 2023, INTERACT LEARN ENVIR, V31, P2134, DOI 10.1080/10494820.2021.1875001
   Umar IM, 2022, J ACCOUNT EMERG ECON, V12, P741, DOI 10.1108/JAEE-01-2021-0011
   Van Eck N.J., 2014, Measuring Scholarly Impact: Methods and Practice, P285, DOI [10.1007/978-3-319-10377-8_13(InEng.), 10.1007/978-3-319-10377-8_13, DOI 10.1007/978-3-319-10377-813]
   Vanni T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093376
   Vázquez-Herrero J, 2022, JOURNALISM, V23, P1717, DOI 10.1177/1464884920969092
   Wakefield R., 2008, Br Account Rev, V40, P228, DOI [DOI 10.1016/J.BAR.2008.03.001, 10.1016/j.bar.2008.03.001]
   Wamba SF, 2017, BUS PROCESS MANAG J, V23, P477, DOI 10.1108/BPMJ-02-2017-0047
   Wang SS, 2022, SEXUALITIES, DOI 10.1177/13634607221106912
   Wang YW, 2020, COMPUT HUM BEHAV, V110, DOI 10.1016/j.chb.2020.106373
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Weimann G, 2023, STUD CONFL TERROR, V46, P752, DOI 10.1080/1057610X.2020.1780027
   Wengel Y, 2022, J OUTDOOR REC TOUR, V37, DOI 10.1016/j.jort.2021.100458
   Whiting A, 2013, QUAL MARK RES, V16, P362, DOI 10.1108/QMR-06-2013-0041
   Wu JX, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19127064
   Xi JN, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106672
   Xi JN, 2022, NEUROCOMPUTING, V468, P60, DOI 10.1016/j.neucom.2021.10.013
   Xue J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239441
   Yan RT, 2022, INT J MACH LEARN CYB, V13, P839, DOI 10.1007/s13042-021-01356-y
   Yang Y., 2021, J Interact Advertising, V21, P297, DOI DOI 10.1080/15252019.2021.1995544
   Yeung AWK, 2018, CHEMOSENS PERCEPT, V11, P42, DOI 10.1007/s12078-018-9243-0
   Yuan CX, 2022, J INTELL MANUF, V33, P425, DOI 10.1007/s10845-021-01885-x
   Yuan L, 2022, IND MANAGE DATA SYST, V122, P1956, DOI 10.1108/IMDS-12-2021-0754
   Zeng J, 2022, POLICY INTERNET, V14, P79, DOI 10.1002/poi3.287
   Zheng DX, 2021, PEDIATR DERMATOL, V38, P336, DOI 10.1111/pde.14471
   Zhu R, 2023, CURR ISSUES TOUR, V26, P2762, DOI 10.1080/13683500.2022.2097058
   Zong QJ, 2013, SCIENTOMETRICS, V94, P781, DOI 10.1007/s11192-012-0799-1
   Zou HB, 2015, J MANAG ANAL, V2, P295, DOI 10.1080/23270012.2015.1100969
   Zou X, 2018, ACCIDENT ANAL PREV, V118, P131, DOI 10.1016/j.aap.2018.06.010
   Zulli D, 2022, NEW MEDIA SOC, V24, P1872, DOI 10.1177/1461444820983603
NR 155
TC 1
Z9 1
U1 15
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32213
EP 32243
DI 10.1007/s11042-023-16768-x
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Mishra, A
   Reddy, US
   Reddy, AV
AF Mishra, Abinash
   Reddy, U. Srinivasulu
   Reddy, A. Venkataswamy
TI A customized cost penalized boosting approach for the selection of wart
   treatment methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immunotherapy; Cryotherapy; Cost penalize; Class distribution; Extreme
   gradient boosting
ID IMAGE; FORGERIES; NETWORK
AB Warts are benign tumors infected by the Human Papillomavirus. Physicians and medical practitioners are endeavoring to identify the best wart treatment method. The present study finds the response of well-known wart treatment methods, namely immunotherapy and cryotherapy, towards the removal of predominant wart types such as plantar and common warts. The present study utilized the optimal feature space generated by the measure of Fisher score, information gain, and univariate statistical test. In addition, the proposed method finds the customized cost in terms of class weighted and non-class weighted to reduce the miss-classified instances for the positive class sample. The class-weighted and non-class-weighted approaches explicitly incorporated with the well-known classification algorithm extreme gradient boosting approach, which provides a maximum measure of true positive rate, true negative rate, positive predicted value, F-measure, and area under receiver operating characteristic curve of 100.00, 100.00, 100.00, 80.00, and 82.00% respectively on immunotherapy dataset, 100.00, 100.00, 100.00, 100.00, 92.00% respectively on cryotherapy dataset. While validating the performance on the benchmark dataset with the state-of-the-art approach, the proposed model gives an improvement of 6.40% to a maximum of 43.00% in terms of specificity on the immunotherapy dataset. However, the proposed model improves 3.33 - 30%, 5.70 -30%, and 0 - 31% in terms of accuracy, sensitivity, and specificity, respectively on cryotherapy dataset. Also, the proposed framework achieved a maximum sensitivity of 91.30%, which dominates the existing state-of-the-art approaches by a margin of 1.87% and 10.82%, respectively on the merged dataset.
C1 [Mishra, Abinash] Natl Forens Sci Univ, Sch Cyber Secur & Digital Forens, Cyber Secur Lab, Delhi Campus, Delhi 382007, India.
   [Reddy, U. Srinivasulu] Natl Inst Technol, Dept Comp Applicat, Machine Learning & Data Analyt Lab, Tiruchirappalli 620015, Tamil Nadu, India.
   [Reddy, A. Venkataswamy] Natl Inst Technol, Dept Comp Applicat, Big Data Analyt Lab, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli
RP Reddy, US (corresponding author), Natl Inst Technol, Dept Comp Applicat, Machine Learning & Data Analyt Lab, Tiruchirappalli 620015, Tamil Nadu, India.
EM abinash.mishra_dc@nfsu.ac.in; usreddy@nitt.edu; reddy@nitt.edu
FU Abinash Mishra would like to thank the Ministry of Human Resource
   Development (MHRD) for providing the financial support (Grant number
   405117002). Also, we would like to thank the Machine Learning and Data
   Analytics Lab, Department of Computer Applications [405117002]; Ministry
   of Human Resource Development (MHRD); National Forensic Sciences
   University Gandhinagar; Ministry of Home Affairs
FX Abinash Mishra would like to thank the Ministry of Human Resource
   Development (MHRD) for providing the financial support (Grant number
   405117002). Also, we would like to thank the Machine Learning and Data
   Analytics Lab, Department of Computer Applications, National Institute
   of Technology, Tiruchirappalli; National Forensic Sciences University
   Gandhinagar and Ministry of Home Affairs for the infrastructure support.
CR Abdar M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1343-0
   Akben SB, 2018, BIOCYBERN BIOMED ENG, V38, P819, DOI 10.1016/j.bbe.2018.06.007
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Ghiasi MM, 2019, COMPUT BIOL MED, V108, P400, DOI 10.1016/j.compbiomed.2019.04.001
   Jia WJ, 2019, MATH FDN COMPUT, V2, P73, DOI 10.3934/mfc.2019006
   Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521
   Keel S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22612-2
   Khozeimeh Fahime, 2018, UCI Machine Learning Repository
   Khozeimeh Fahime, 2018, UCI Machine Learning Repository
   Khozeimeh F, 2017, COMPUT BIOL MED, V81, P167, DOI 10.1016/j.compbiomed.2017.01.001
   lazypredict.readthedocs, Lazy Predict Documentation
   Mazlin TT, 2019, IOP Conference Series: Materials Science and Engineering, V551
   Mishra A, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-00246-7
   Nugroho HW, 2018, Int J Adv Sci Eng Inf Technol, V8, P1858, DOI DOI 10.18517/IJASEIT.8.5.6504
   Pandey SK, 2019, NEURAL PROCESS LETT, V50, P1907, DOI 10.1007/s11063-018-09976-2
   Praveen SP, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25089-2
   Rahman M, 2020, Int. J. Intell. Syst., V12, P1
   SIZONENKO PC, 1978, AM J DIS CHILD, V132, P704, DOI 10.1001/archpedi.1978.02120320064015
   skinsight, Plantar wart Child
   skinsight, Common wart Child
   Thurnhofer-Hemsi K, 2021, NEURAL PROCESS LETT, V53, P3073, DOI 10.1007/s11063-020-10364-y
   Vivaldi N, 2021, IEEE Transactions on Biomedical Engineering
NR 22
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33393
EP 33419
DI 10.1007/s11042-023-16621-1
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900010
DA 2024-07-18
ER

PT J
AU Phukan, A
   Gupta, D
AF Phukan, Arpan
   Gupta, Deepak
TI Deep feature extraction from EEG signals using xception model for
   emotion classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Emotion Classification; Xception; Wavelet Transform; Support Vector
   Machine; Random Forest
ID RECOGNITION
AB Throughout the years, major advancements have been made in the field of EEG-based emotion classification. Implementing deep architectures for supervised and unsupervised learning from data has come a long way. This study aims to capitalize on these advancements to classify emotions from EEG signals accurately. It still is, however, a challenging task. The fact that the data we are reliant on changes from person to person calls for an elaborate machine-learning solution that can achieve high degrees of abstraction without sacrificing accuracy and legibility. In this study, the Xception model from Keras API was utilized, as well as wavelet transform for feature extraction, which was then used for classification using different classifiers. These features were classified into three distinct categories: NEGATIVE, POSITIVE and NEUTRAL. To examine the effectiveness of the Xception deep neural net, we compare the results of different classifiers like Support Vector Machine, Random Forest, AdaBoostM1, LogitBoost, Naive Bayes Updateable and Non-Nested Generalization Exemplars. The random forest ensemble achieved the best results from all the classifiers implemented in this study. It had higher accuracy scores than existing models without compromising on areas like precision, F1 score, and recall value.
C1 [Phukan, Arpan] Natl Inst Technol, Dept Comp Sci & Engn, Jote 791113, Arunachal Prade, India.
   [Gupta, Deepak] Motilal Nehru Natl Inst Technol, Dept Comp Sci & Engn, Allahabad 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh; National Institute of Technology (NIT
   System); Motilal Nehru National Institute of Technology
RP Gupta, D (corresponding author), Motilal Nehru Natl Inst Technol, Dept Comp Sci & Engn, Allahabad 211004, Uttar Pradesh, India.
EM arpanphukan@gmail.com; deepakg@mnnit.ac.in
CR Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Ashraf A, 2021, MULTIMED TOOLS APPL, V80, P30117, DOI 10.1007/s11042-020-10331-8
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Bird J.J., 2019, Proceedings of theInternational Conference on Digital Image and Signal Processing (DISP'19), DOI DOI 10.1109/IS.2018.8710576
   Bird JJ, 2019, INT C DIG IM SIGN PR
   Bird JJ, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P795, DOI 10.1109/IS.2018.8710576
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chao H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092212
   Chen Yu-Jou, 2023, MMAsia '23: Proceedings of the 5th ACM International Conference on Multimedia in Asia, DOI 10.1145/3595916.3626370
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Das A, 2002, COMPLEXITY INT, V9, P1
   Dash DP, 2022, MULTIMED TOOLS APPL, V81, P42057, DOI 10.1007/s11042-021-11487-7
   De Carolis B, 2017, MULTIMED TOOLS APPL, V76, P5073, DOI 10.1007/s11042-016-3797-0
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donos C, 2015, INT J NEURAL SYST, V25, DOI 10.1142/S0129065715500239
   Fernandez-Fraga SM, 2018, DISCRETE DYN NAT SOC, V2018, DOI 10.1155/2018/2143873
   Fraga S., 2018, INT J ADV RES, V6, P1718, DOI 10.21474/ijar01/6612
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Garg A, 2022, MULTIMED TOOLS APPL, V81, P5137, DOI 10.1007/s11042-021-11650-0
   Garima, 2023, MULTIMED TOOLS APPL, V82, P28547, DOI 10.1007/s11042-023-14671-z
   Gini C., 1912, Variabilita e mutuabilita. Contributo allo studio delle distribuzioni e delle relazioni statistiche
   Gupta S, 2023, MULTIMED TOOLS APPL, V82, P11365, DOI 10.1007/s11042-022-13558-9
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Haputhanthri D, 2020, INT J AUTOM COMPUT, V17, P837, DOI 10.1007/s11633-020-1231-6
   Hatamikia S, 2014, 2014 21th Iranian Conference on Biomedical Engineering (ICBME), P333, DOI 10.1109/ICBME.2014.7043946
   Hosseinifard B, 2013, COMPUT METH PROG BIO, V109, P339, DOI 10.1016/j.cmpb.2012.10.008
   Husain SS, 2022, MULTIMED TOOLS APPL, V81, P20425, DOI 10.1007/s11042-022-12433-x
   Jadhav N, 2017, ADV INTELL SYST, V459, P335, DOI 10.1007/978-981-10-2104-6_30
   Jinsakul N, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7121170
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Kamble A, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2022.3216673
   Kamble K, 2023, MULTIMED TOOLS APPL, V82, P27269, DOI 10.1007/s11042-023-14489-9
   Kamble KS, 2022, IEEE SENS J, V22, P2496, DOI 10.1109/JSEN.2021.3135953
   Kapoor S, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120882
   Khare SK, 2021, IEEE T NEUR NET LEAR, V32, P2901, DOI 10.1109/TNNLS.2020.3008938
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon YH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051383
   LeCun Y., 1995, NEURAL NETW STAT MEC, V261, P276
   Lee JS, 2007, CLIN NEUROPHYSIOL, V118, P2489, DOI 10.1016/j.clinph.2007.08.001
   Lee M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103501
   Li JP, 2020, IEEE T CYBERNETICS, V50, P3281, DOI [10.1109/TPAMI.2019.2929036, 10.1109/TCYB.2019.2904052]
   Martínez-Rodrigo A, 2017, LECT NOTES COMPUT SC, V10586, P766, DOI 10.1007/978-3-319-67585-5_74
   Menon V, 1997, NEUROREPORT, V8, P3029, DOI 10.1097/00001756-199709290-00007
   Minhas AA, 2022, MULTIMED TOOLS APPL, V81, P26969, DOI 10.1007/s11042-022-13193-4
   Mumtaz W, 2016, KNOWL-BASED SYST, V105, P48, DOI 10.1016/j.knosys.2016.04.026
   Murugappan Murugappan, 2010, Journal of Biomedical Science & Engineering, V3, P390, DOI 10.4236/jbise.2010.34054
   Narmada A, 2023, MULTIMED TOOLS APPL, V82, P40403, DOI 10.1007/s11042-023-14949-2
   Noachtar S, 2009, EPILEPSY BEHAV, V15, P22, DOI 10.1016/j.yebeh.2009.02.035
   Nobler MS, 2000, J ECT, V16, P211, DOI 10.1097/00124509-200009000-00002
   Pane ES, 2019, COGN PROCESS, V20, P405, DOI 10.1007/s10339-019-00924-z
   Phukan Arpan, 2022, Mobile Radio Communications and 5G Networks: Proceedings of Second MRCN 2021. Lecture Notes in Networks and Systems (339), P95, DOI 10.1007/978-981-16-7018-3_7
   Piatek L., 2018, DIGIT MED, V4, P84, DOI [10.4103/digm.digm_41_17, DOI 10.4103/DIGM.DIGM_41_17]
   Qing CM, 2019, IEEE ACCESS, V7, P94160, DOI 10.1109/ACCESS.2019.2928691
   Raghu S, 2020, NEURAL NETWORKS, V124, P202, DOI 10.1016/j.neunet.2020.01.017
   Rana M, 2023, MULTIMED TOOLS APPL, V82, P26731, DOI 10.1007/s11042-022-14305-w
   Richhariya B, 2019, APPL SOFT COMPUT, V76, P53, DOI 10.1016/j.asoc.2018.11.046
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Mandeep., 2013, International Journal of Information Technology Knowledge Management, V7, P6
   Spüler M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051077
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   Sun SL, 2007, PATTERN RECOGN LETT, V28, P2157, DOI 10.1016/j.patrec.2007.06.018
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tyagi A, 2023, MULTIMED TOOLS APPL, V82, P20343, DOI 10.1007/s11042-022-13809-9
   Ullah H, 2019, IEEE ACCESS, V7, P40144, DOI 10.1109/ACCESS.2019.2904400
   Xing XF, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00037
   Zaman K, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040687
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang YQ, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.622759
   Zheng W.-L., 2014, In 2014 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI [DOI 10.1109/ICME.2014.6890166, 10.1109/ICME.2014.6890166]
   Zhuang N, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/8317357
   Zubair M, 2018, LECT NOTES ELECTR EN, V450, P21, DOI 10.1007/978-981-10-6454-8_3
NR 74
TC 2
Z9 2
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33445
EP 33463
DI 10.1007/s11042-023-16941-2
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900012
DA 2024-07-18
ER

PT J
AU Xiong, LZ
   Zhang, MT
   Yang, CN
   Kim, C
AF Xiong, Lizhi
   Zhang, Mengtao
   Yang, Ching-Nung
   Kim, Cheonshik
TI An enhanced AMBTC for color image compression using color palette
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AMBTC; K-means; Color Palette; Color difference; Huffman coding
ID CLASSIFICATION; EEG
AB Digital image has been used in various fields as an essential carrier. Many color images have been constantly produced since their more realistic description, which takes up much storage space and network bandwidth. Thus, color image compression has become an essential key technology. Absolute Moment Block Truncation Coding (AMBTC) has been widely studied as one of the classical image compression methods. However, in the existing methods, the visual quality of the reconstructed images and the compression rate are all relatively low. Therefore, this paper proposes an enhanced AMBTC for color image compression using a color palette. In the proposed method, the K-means clustering algorithm is utilized for training the image's palette pattern. The color palette obtained by K-mean will be more suitable for reconstructing this image than the standard color palette, and the visual quality will be higher. The six clustered central pixels are matched with the palette through a color difference formula, and the obtained index values are used as the quantization levels. Huffman coding is used to build a bitmap to achieve a higher compression rate, that is, a lower bit rate. At last, a block of a color image can be represented by six index values and a bitmap. Experimental results and theoretical analysis demonstrate that the proposed method has better visual quality and bit rate than similar schemes.
C1 [Xiong, Lizhi; Zhang, Mengtao] Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing, Peoples R China.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
   [Kim, Cheonshik] Sejong Univ, Dept Comp Engn, Seoul, South Korea.
C3 Nanjing University of Information Science & Technology; National Dong
   Hwa University; Sejong University
RP Xiong, LZ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing, Peoples R China.; Yang, CN (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
EM lzxiong16@163.com; cnyang@gms.ndhu.edu.tw
RI zhang, hao/KEJ-2291-2024; ren, jun/KHG-7717-2024; liu, qi/KFA-4047-2024;
   Xiong, Lizhi/KCK-1464-2024; li, jing/KHC-8303-2024; liu,
   qi/KHC-7509-2024; Zhang, Lu/KHE-5879-2024; li, cheng/KCZ-0615-2024;
   zhang, yan/KHC-3163-2024; guo, yi/KHC-4669-2024; zhu, hao/KHW-3813-2024;
   Liu, Yu/KFS-0769-2024; Yang, Ching-Nung/HKV-1639-2023; su,
   lin/KHC-5034-2024
CR Bhardwaj R, 2021, MULTIMED TOOLS APPL, V80, P26161, DOI 10.1007/s11042-021-10722-5
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Cheng HH, 2019, IEEE INT C ELECTR TA, DOI 10.1109/icce-tw46550.2019.8992037
   Chuang JC, 2020, MULTIMED TOOLS APPL, V79, P28189, DOI 10.1007/s11042-020-09325-3
   Datta K, 2024, MULTIMED TOOLS APPL, V83, P8591, DOI 10.1007/s11042-023-15727-w
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2007, PATTERN RECOGN, V40, P2408, DOI 10.1016/j.patcog.2006.12.022
   Hassanpour S, 2021, IEEE T COMMUN, V69, P6633, DOI 10.1109/TCOMM.2021.3097142
   Hu YC, 2022, MULTIMED TOOLS APPL, V81, P17937, DOI 10.1007/s11042-022-12680-y
   Hu YC, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS), P196, DOI 10.1109/CCOMS.2018.8463236
   Hu YC, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.093104
   Hu YC, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762241
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Ikotun AM, 2023, INFORM SCIENCES, V622, P178, DOI 10.1016/j.ins.2022.11.139
   Kumar R, 2022, MULTIMED TOOLS APPL, V81, P20817, DOI 10.1007/s11042-022-12634-4
   Kumar R, 2020, MULTIDIM SYST SIGN P, V31, P1145, DOI 10.1007/s11045-020-00701-8
   Lamsrichan P, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427615
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Mathews J, 2015, COMPUT ELECTR ENG, V43, P169, DOI 10.1016/j.compeleceng.2015.01.001
   Nayak D, 2023, MULTIMED TOOLS APPL, V82, P47367, DOI 10.1007/s11042-023-15694-2
   Pang JX, 2022, IEEE T IND INFORM, V18, P8786, DOI 10.1109/TII.2022.3145834
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Su GD, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15486-8
   Swain Monalisa, 2022, Integration, The VLSI Journal, P12, DOI 10.1016/j.vlsi.2021.11.004
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wu XT, 2020, MULTIMED TOOLS APPL, V79, P25657, DOI 10.1007/s11042-020-09253-2
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   WU YY, 1992, IEEE J SEL AREA COMM, V10, P952, DOI 10.1109/49.139000
   Xiang ZY, 2019, MULTIMED TOOLS APPL, V78, P7895, DOI 10.1007/s11042-018-6030-5
   Yang CN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207340
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Yin WB, 2020, IEEE T MULTIMEDIA, V22, P1917, DOI 10.1109/TMM.2019.2949393
   Zhang YM, 2021, IEEE T MULTIMEDIA, V23, P1069, DOI 10.1109/TMM.2020.2992940
   Zhu SY, 2018, IEEE T MULTIMEDIA, V20, P525, DOI 10.1109/TMM.2017.2749162
   Zhu SYY, 2019, IEEE T CIRC SYST VID, V29, P1474, DOI 10.1109/TCSVT.2018.2841642
NR 35
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31783
EP 31803
DI 10.1007/s11042-023-16734-7
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900018
DA 2024-07-18
ER

PT J
AU Ma, B
   Lai, E
   Yan, WQ
   Wu, JS
AF Ma, Bo
   Lai, Edmund
   Yan, Wei Qi
   Wu, Jinsong
TI A privacy-preserving word embedding text classification model based on
   privacy boundary constructed by deep belief network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy-preserving; Support vector machine(SVM); Independence
   degree(ID); Word embedding; Deep belief network(DBN); Privacy
   boundary(PB)
ID SUPPORT VECTOR MACHINE
AB To effectively extract and classify the information from reports or documents and protect the privacy of the extracted results, we propose a privacy classification named Word Embedding Combination Privacy-preserving Support Vector Machine (WECPPSVM) model to classify the text. In addition, this paper also proposes the Privacy-preserving Distribution and Independent Frequent Subsequence Extraction Algorithm (PPDIFSEA), which calculates the degree of independence of the training data input to the classification model by training the Deep Belief Network(DBN) in PPDIFSEA, then obtains the Privacy Boundary(PB). PB is an indispensable condition for both data sampling and privacy noise generation. And this model can protect privacy by injecting the privacy noise into the classification result, this method can interfere with the background knowledge-based privacy attack. Our quantitative analysis shows that the WECPPSVM proposed in this paper can approach mainstream text classification algorithms in terms of text classification accuracy while preserving privacy without increasing computational complexity. In addition, the fusion study and privacy threat evaluation also verify that the proposed PPDIFSEA method combined with WECPPSVM achieves an acceptable level of classification accuracy and privacy protection.
C1 [Ma, Bo; Lai, Edmund; Yan, Wei Qi] Auckland Univ Technol, Sch Engn Comp & Math Sci, 55 Wellesley St East, Auckland 1010, New Zealand.
   [Wu, Jinsong] Univ Chile, Dept Comp Sci, Ave Libertador Bernardo OHiggins, Santiago 1058, Region Metropol, Chile.
C3 Auckland University of Technology; Universidad de Chile
RP Ma, B (corresponding author), Auckland Univ Technol, Sch Engn Comp & Math Sci, 55 Wellesley St East, Auckland 1010, New Zealand.
EM rcn4743@aut.ac.nz
OI Ma, Bo/0000-0003-1076-3290
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. The authors did not receive support from any organization
   for the submitted work. The authors have no financial or non-financial
   or proprietary interests in any material discussed in this article.
CR Abdalla M, 2020, J MED INTERNET RES, V22, DOI 10.2196/18055
   Abe N, 2006, PATTERN ANAL APPL, V9, P127, DOI 10.1007/s10044-006-0030-1
   Ambrosio L, 2010, J FUNCT ANAL, V258, P785, DOI 10.1016/j.jfa.2009.09.008
   [Anonymous], 2020, KAGGL COVID 19 OP RE
   Bartunov S, 2016, JMLR WORKSH CONF PRO, V51, P130
   Chang YK., 2011, ADV DIFFER EQU-NY, V1, P1
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Devlin J., 2018, BERT PRE TRAINING DE
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Fellbaum C, 2010, THEORY AND APPLICATIONS OF ONTOLOGY: COMPUTER APPLICATIONS, P231, DOI 10.1007/978-90-481-8847-5_10
   Fernandes M., 2019, P 8 INT C PRINC SEC, P123
   Geng CX, 2021, IEEE T PATTERN ANAL, V43, P3614, DOI 10.1109/TPAMI.2020.2981604
   Ghosh S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P24, DOI 10.1109/iss1.2019.8908018
   Gupta D, 2021, ARTIF INTELL
   Hirsch C, 2010, P IEEE ACM INT C AUT, P13
   Huang CR, 2003, LANG SCI, V25, P353, DOI 10.1016/S0388-0001(02)00021-9
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kurnia R., 2020, Int. J. Adv. Trends Comput. Sci. Eng, V9, P643, DOI 10.30534/ijatcse/2020/90912020
   Lai SW, 2016, IEEE INTELL SYST, V31, P5, DOI 10.1109/MIS.2016.45
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Leskovec J., 2007, ACM T KNOWL DISCOV D, V1, P2, DOI [DOI 10.1145/1217299.1217301, 10.1145/1217299.1217301]
   Li WM, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P369, DOI 10.1109/ICDM.2001.989541
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu D, 2017, SCI REP-UK, V7, DOI 10.1038/srep43330
   Melis L, 2019, P IEEE S SECUR PRIV, P691, DOI 10.1109/SP.2019.00029
   Mironov I, 2017, P IEEE CSFW, P263, DOI 10.1109/CSF.2017.11
   Mitra V, 2007, APPL SOFT COMPUT, V7, P908, DOI 10.1016/j.asoc.2006.04.002
   Mnih A., 2013, Advances in Neural Information Processing Systems, V26, P2265
   Osswald H, 2003, ADV MATH, V176, P1, DOI 10.1016/S0001-8708(02)00033-6
   Rahulamathavan Y, 2014, IEEE T DEPEND SECURE, V11, P467, DOI 10.1109/TDSC.2013.51
   Ramanathan V, 2013, COMPUT SECUR, V34, P123, DOI 10.1016/j.cose.2012.12.002
   Shen DH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P440
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Thomas A, 2020, LECT NOTES ARTIF INT, V12284, P273, DOI 10.1007/978-3-030-58323-1_30
   Treves F., 1966, LINEAR PARTIAL DIFFE
   Wang M, 2018, IEEE ACCESS, V6, P35206, DOI 10.1109/ACCESS.2018.2848298
   Wang Q, 2017, IEEE IJCNN, P2851, DOI 10.1109/IJCNN.2017.7966208
   Yi K, 2009, J INF SCI, V35, P67, DOI 10.1177/0165551508092257
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
NR 42
TC 1
Z9 1
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30181
EP 30206
DI 10.1007/s11042-023-15623-3
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066067700004
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhao, DX
   Wang, W
   Xiao, ZT
   Zhang, F
AF Zhao, Dongxu
   Wang, Wen
   Xiao, Zhitao
   Zhang, Fang
TI Super-resolution reconstruction of medical images based on deep residual
   attention network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; Medical image; Deep learning; Residual structure;
   Attention mechanism
ID CONVOLUTIONAL NETWORK; RESOLUTION; MRI; CT
AB Medical images are commonly used to determine the location, size, and shape of organs, as well as the scope and physical properties of lesions, which are important bases for intelligent medical diagnosis. Low-quality medical images have serious spots, noise, and weak boundaries between similar tissues, which might affect the clarity of human organs and lesions in the image. This problem seriously hinders doctors' diagnoses and the accuracy of computer-aided detection. Therefore, enhancing the internal texture details of medical images, strengthening tissue boundary information, and suppressing noise are of great significance for experts to diagnose diseases. We propose a medical image super-resolution reconstruction method based on residual attention networks. The method combines channel attention and spatial attention modules to enhance weak boundaries of the tissues and suppress noise. In addition, we introduce the skip connection structure to prevent network feature extraction from causing the loss of shallow feature information. We built three medical image datasets (lung CT images, brain MR images, and transrectal ultrasound (TRUS) images) to evaluate the performance of the proposed method. The results reveal that the proposed method outperforms other methods of medical image reconstruction. Moreover, it accurately reconstructs the internal texture and edge information of medical images while effectively suppressing noise.
C1 [Zhao, Dongxu; Wang, Wen; Xiao, Zhitao; Zhang, Fang] Tiangong Univ, Sch Life Sci, Tianjin 300387, Peoples R China.
   [Zhao, Dongxu; Wang, Wen; Xiao, Zhitao; Zhang, Fang] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Zhang, F (corresponding author), Tiangong Univ, Sch Life Sci, Tianjin 300387, Peoples R China.; Zhang, F (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin 300387, Peoples R China.
EM hhzhangfang@126.com
FU Special Foundation~for Beijing Tianjin Hebei Basic Research Cooperation
   [J210008, 21JCZXJC00170, H2021202008]
FX This work was supported by the Special Foundation~for Beijing Tianjin
   Hebei Basic Research Cooperation (J210008, 21JCZXJC00170, H2021202008).
CR Armato SG, 2007, ACAD RADIOL, V14, P1455, DOI 10.1016/j.acra.2007.08.006
   Bao LJ, 2019, J MAGN RESON, V305, P232, DOI 10.1016/j.jmr.2019.07.020
   Carmi E, 2006, MAGN RESON IMAGING, V24, P133, DOI 10.1016/j.mri.2005.09.011
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen R, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108349
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Cong WY, 2022, PROC CVPR IEEE, P18449, DOI 10.1109/CVPR52688.2022.01792
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Du JL, 2020, NEUROCOMPUTING, V392, P209, DOI 10.1016/j.neucom.2018.10.102
   Feng Chun-Mei, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12906), P307, DOI 10.1007/978-3-030-87231-1_30
   Feng CM, 2021, LECT NOTES COMPUT SC, V12906, P140, DOI 10.1007/978-3-030-87231-1_14
   Georgescu MI, 2020, IEEE ACCESS, V8, P49112, DOI 10.1109/ACCESS.2020.2980266
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Hatvani J, 2019, IEEE T RADIAT PLASMA, V3, P120, DOI 10.1109/TRPMS.2018.2827239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2020, IEEE T CIRC SYST VID, V30, P3911, DOI 10.1109/TCSVT.2019.2915238
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang YW, 2017, PROC CVPR IEEE, P5787, DOI 10.1109/CVPR.2017.613
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kong X., 2022, P IEEECVF C COMPUTER, P6002
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li B, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071372
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin Z., 2022, ARXIV
   Liu C, 2016, INT C CLOUD COMP BIG, P275, DOI [10.1109/CCBD.2016.061, 10.1109/CCBD.2016.77]
   Liu YB, 2023, IEEE T MED IMAGING, V42, P557, DOI 10.1109/TMI.2022.3226575
   LiW Lu X, 2021, EFFICIENT TRANSFORME
   Mahapatra D, 2019, COMPUT MED IMAG GRAP, V71, P30, DOI 10.1016/j.compmedimag.2018.10.005
   Mehri A, 2021, IEEE WINT CONF APPL, P2703, DOI 10.1109/WACV48630.2021.00275
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Muqeet Abdul, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P103, DOI 10.1007/978-3-030-67070-2_6
   Niu B., 2020, EUR C COMP VIS, P191, DOI [10.1007/978-3-030-58610-2_47, DOI 10.1007/978-3-030-58610-2_12]
   Park K., 2021, IEEE Trans Multimed, V10, P54599
   Plenge E, 2012, MAGN RESON MED, V68, P1983, DOI 10.1002/mrm.24187
   Prashanth H. S., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P859, DOI 10.1109/ACT.2009.218
   Ruder S., 2016, ARXIV
   Sert E, 2019, MED HYPOTHESES, V133, DOI 10.1016/j.mehy.2019.109413
   Shakeel PM, 2019, MEASUREMENT, V145, P702, DOI 10.1016/j.measurement.2019.05.027
   Shamshad F, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.09873
   Shi J, 2019, IEEE J BIOMED HEALTH, V23, P1129, DOI 10.1109/JBHI.2018.2843819
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang L, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108206
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia B, 2022, AAAI CONF ARTIF INTE, P2759
   Xue XT, 2020, IEEE J BIOMED HEALTH, V24, P377, DOI 10.1109/JBHI.2019.2945373
   You CY, 2020, IEEE T MED IMAGING, V39, P188, DOI 10.1109/TMI.2019.2922960
   Yue ZS, 2022, PROC CVPR IEEE, P2118, DOI 10.1109/CVPR52688.2022.00217
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang WL, 2019, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2019.00319
   Zhang YL, 2021, PROC CVPR IEEE, P13420, DOI 10.1109/CVPR46437.2021.01322
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao XL, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2921882
   Zhou S., 2020, P ADV NEUR INF PROC, V33, P3499
NR 68
TC 0
Z9 0
U1 14
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27259
EP 27281
DI 10.1007/s11042-023-16478-4
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300012
DA 2024-07-18
ER

PT J
AU Kakani, V
   Jin, CB
   Kim, H
AF Kakani, Vijay
   Jin, Cheng-Bin
   Kim, Hakil
TI Segmentation-based ID preserving iris synthesis using generative
   adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; Biometric database generation; Iris
   identification; ID preserving
AB This study proposes a method for generating ID preserving synthetic iris database. The proposed method can be applied in the generation of a synthetic iris database for various iris recognition tasks. This work successfully combines the main idea of generative adversarial learning, segmentation, and identification to solve real-world problems. The method produces synthetic iris images from the segmentation masks given ID information. The segmentation mask, iris pose, is devised from the input image by using a segmentation network. By doing this, the ID-preserving iris synthesis method generates an unlimited number of synthetic iris images by processing the provided input images. The accuracy of the generated iris images is validated by measuring top-1, top-5, and Area under the Curve (AUC). The SegNet and IDNet performance was evaluated using class accuracy in terms of precision, recall, and F1-score alongside the computation model complexity. This study exhibits ease of use, compatibility, and accuracy in preserving ID information for the generated synthetic images compared to the other baseline methods. Evaluation results prove the efficacy of this work by comparing the randomly generated iris images using the current study alongside existing methods.
C1 [Kakani, Vijay] Inha Univ, Dept Integrated Syst Engn, 100 Inha Ro, Incheon 22212, South Korea.
   [Jin, Cheng-Bin] HUYA Inc, 280 Hanxi Rd, Guangzhou 511446, Peoples R China.
   [Kim, Hakil] Inha Univ, Dept Elect & Comp Engn, 100 Inha Ro, Incheon 22212, South Korea.
C3 Inha University; Inha University
RP Kim, H (corresponding author), Inha Univ, Dept Elect & Comp Engn, 100 Inha Ro, Incheon 22212, South Korea.
EM vjkakani@inha.ac.kr; sbkim0407@gmail.com; hikim@inha.ac.kr
RI Kim, Hakil/AAH-9861-2019
OI Kim, Hakil/0000-0003-4232-3804
FU INHA UNIVERSITY Research Grant
FX This work was supported by INHA UNIVERSITY Research Grant.
CR Abdigapporov S, 2023, IEEE ACCESS
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Boutros F, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104007
   Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586
   Cheng Z, 2023, ARXIV
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Choudhary M, 2022, IEEE T CYBERNETICS, V52, P2370, DOI 10.1109/TCYB.2020.3005089
   Cui JL, 2004, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2004.1333804
   Dabouei A, 2018, INT CONF BIOMETR, P1, DOI 10.1109/ICB2018.2018.00012
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Garbin SJ, 2019, ARXIV
   Ghimire A, 2023, IEEE ACCESS, V11, P51930, DOI 10.1109/ACCESS.2023.3278974
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jayanthi J, 2021, J AMB INTEL HUM COMP, V12, P3271, DOI 10.1007/s12652-020-02172-y
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Juraev S, 2022, IEEE ACCESS, V10, P94249, DOI 10.1109/ACCESS.2022.3203174
   Kakani V., 2022, 2022 IEEE REG 10 S T, P1
   Kakani V, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051920
   Kansal P, 2019, IEEE INT CONF COMP V, P3688, DOI 10.1109/ICCVW.2019.00456
   Keskar NS, 2017, ARXIV
   Ketchum Karyl E., 2009, Women's Studies Quarterly, V37, P183, DOI [DOI 10.1353/WSQ.0.0150, 10.1353/WSQ.0.0150]
   Kim T, 2017, PR MACH LEARN RES, V70
   Kohli N, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P674, DOI 10.1109/BTAS.2017.8272756
   Lee H, 2021, INFORM SCIENCES, V575, P399, DOI 10.1016/j.ins.2021.06.042
   Lefohn A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1242384
   Li Y, 2023, MULTIMEDIA SYST, V29, P211, DOI 10.1007/s00530-022-00982-y
   Liao X, 2021, INFORM SCIENCES, V575, P231, DOI 10.1016/j.ins.2021.06.045
   Liu YY, 2021, INFORM SCIENCES, V578, P195, DOI 10.1016/j.ins.2021.07.034
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Makthal Sarvesh, 2005, 2005 13th European Signal Processing Conference, P1
   Minaee S., 2018, ARXIV
   Miraliev S, 2024, IEEE T INTELL VEHICL, V9, P247, DOI 10.1109/TIV.2023.3270878
   Morampudi MK, 2020, MULTIMED TOOLS APPL, V79, P19215, DOI 10.1007/s11042-020-08680-5
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Ning X, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5792
   Orlans NM, 2004, IC-AI '04 & MLMTA'04 , VOL 1 AND 2, PROCEEDINGS, P499
   Orlans NM, 2003, P 2003 ACM SIGMM WOR, P58
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tapia JE, 2022, IEEE T INF FOREN SEC, V17, P42, DOI 10.1109/TIFS.2021.3132582
   Ulyanov Dmitry, 2016, arXiv
   Vijaykumar V, 2021, DES ENG-LONDON, P10921
   Wang W., 2022, ARXIV
   Wei H., 2022, ARXIV
   Wei ZS, 2008, INT C PATT RECOG, P1344, DOI 10.1109/ICPR.2008.4761674
   Wu GQ, 2023, IET COMPUT VIS, V17, P537, DOI 10.1049/cvi2.12138
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Yadav S, 2021, IEEE WINT CONF APPL, P2411, DOI 10.1109/WACV48630.2021.00246
   Yadav S, 2019, IEEE COMPUT SOC CONF, P2422, DOI 10.1109/CVPRW.2019.00297
   Zhang H, 2011, INT JOINT C BIOM, V1
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou H, 2018, INT C PATT RECOG, P3561, DOI 10.1109/ICPR.2018.8546154
   Zuo JY, 2007, IEEE T INF FOREN SEC, V2, P77, DOI 10.1109/TIFS.2006.890305
NR 64
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27589
EP 27617
DI 10.1007/s11042-023-16508-1
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100001
DA 2024-07-18
ER

PT J
AU Verma, M
   Singh, D
AF Verma, Mayank
   Singh, Durgesh
TI Survey on image copy-move forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Copy-Move forgery detection; Image tampering detection; Passive forgery;
   Image forensics; Block based CMFD techniques; Keypoint based CMFD
   techniques; Image forgery detection
ID REGION DUPLICATION DETECTION; WATERMARKING SCHEME; FORENSIC TECHNIQUE;
   ROBUST; AUTHENTICATION; SIFT; DCT; EFFICIENT; ZERNIKE; MODEL
AB In this digital era, a huge amount of images are flooding the internet, which is extensively used for digital communications, and are also regarded as a significant source of information in many fields. However, the images can be easily altered without leaving any traces due to the availability of digital image editing softwares. Hence, it becomes essential to validate the integrity of the images. One of the most serious and popular tampering procedures is Copy Move Forgery (CMF), wherein some portion of an image is copied and pasted to another region in the same image. This paper reviews recent state-of-the-art copy-move forgery detection (CMFD) schemes along with their pros, and cons with the help of tables for better readability. In addition, this paper enlists the performance evaluation criteria and different image datasets used for CMFD, along with their merits and demerits. At last, this review addresses the various issues, challenges, and future directions in the field of CMFD. This survey paper aims to provide researchers with a broad perspective on the various aspects of advancements in CMFD techniques.
C1 [Verma, Mayank; Singh, Durgesh] PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Singh, D (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
EM durgesh@iiitdmj.ac.in
RI Singh, Durgesh/AAZ-2801-2020
OI Singh, Durgesh/0000-0002-6078-1502
FU Faculty Initiation Grant of PDPM Indian Institute of Information
   Technology Design and Manufacturing Jabalpur, India
FX This work was supported by Faculty Initiation Grant of PDPM Indian
   Institute of Information Technology Design and Manufacturing Jabalpur,
   India
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Agarwal V, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P84, DOI 10.1109/ICRCICN.2016.7813636
   Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Alhussein M, 2016, UKSIM INT CONF COMP, P196, DOI 10.1109/UKSim.2016.39
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Amerini I, 2010, INT CONF ACOUST SPEE, P1702, DOI 10.1109/ICASSP.2010.5495485
   Anand V, 2014, LECT NOTES COMPUT SC, V8397, P530, DOI 10.1007/978-3-319-05476-6_54
   [Anonymous], 2006, Multimedia Security Technologies for Digital Rights, chapter Passive-Blind Image Forensics
   [Anonymous], 2003, Techniques and Applications of Digital Watermarking and Content Protection
   [Anonymous], 2011, 2011 18 INT C SYST S
   [Anonymous], 2016, INT J APPL ENG RES
   [Anonymous], 2015, J INFORM HIDING MULT
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Ardizzone E, 2010, IEEE IMAGE PROC, P2117, DOI 10.1109/ICIP.2010.5652490
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Badr A., 2020, 2020 8 INT S DIG FOR, P1
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barni M, 2021, IEEE T INF FOREN SEC, V16, P1825, DOI 10.1109/TIFS.2020.3045903
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bhanu MPB, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P224, DOI 10.1109/ISCO.2017.7855986
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Cao GC, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P599, DOI 10.1109/CISP.2015.7407949
   Chauhan D, 2016, PROCEDIA COMPUT SCI, V85, P206, DOI 10.1016/j.procs.2016.05.213
   Chen BJ, 2021, IEEE T MULTIMEDIA, V23, P3506, DOI 10.1109/TMM.2020.3026868
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   Doegar A, 2019, INT J COMPUTATIONAL, V2
   El Biach FZ, 2022, MULTIMED TOOLS APPL, V81, P22611, DOI 10.1007/s11042-020-10158-3
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fadl SM, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P253, DOI 10.1109/VCIP.2014.7051552
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   Hegazi Aya, 2020, International Journal of Sociotechnology and Knowledge Development, V12, P1, DOI 10.4018/IJSKD.2020010101
   Hosny KM, 2022, IEEE ACCESS, V10, P48622, DOI 10.1109/ACCESS.2022.3172273
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Huang DY, 2017, MULTIMED TOOLS APPL, V76, P1509, DOI 10.1007/s11042-015-3152-x
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hussain M, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P197, DOI 10.1109/INISTA.2014.6873618
   Hussain M, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P395, DOI 10.1109/SITIS.2012.64
   Imamoglu MB, 2013, 2013 8TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P311
   Isaac MM, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P394, DOI 10.1145/2791405.2791453
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Jwaid MF, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kalsi DK, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P284, DOI 10.1109/RISE.2017.8378168
   Karsh RK, 2016, 2016 1 IND INT C INF, P1, DOI [10.1109/IICIP.2016.7975329, DOI 10.1109/IICIP.2016.7975329]
   Kashyap A, 2017, INT J ENG TECHNOLOGY, V7, DOI [10.14419/ijet.v7i2.13.11604, DOI 10.14419/IJET.V7I2.13.11604]
   Ketenci S, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P813, DOI 10.1109/TSP.2013.6614051
   Khayeat ARH, 2015, PSIVT
   Kirchner M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2082789
   Kotsiantis SB, 2007, FRONT ARTIF INTEL AP, V160, P3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2016, Arxiv, DOI arXiv:1612.03989
   Kumari R, 2023, IMAGE COPY MOVE FORG, P515, DOI [10.1109/AISC56616.2023.10085429, DOI 10.1109/AISC56616.2023.10085429]
   Kushol R, 2016, 2016 INT C DIG IM CO, P1, DOI [10.1109/DICTA.2016.7797027, DOI 10.1109/DICTA.2016.7797027]
   Le-Tien T., 2016, LUONG THKLPCHATHM
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li LD, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P1061, DOI 10.1109/WICT.2012.6409232
   Li WH, 2010, IEEE IMAGE PROC, P2113, DOI 10.1109/ICIP.2010.5652519
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P20739, DOI 10.1007/s11042-019-7342-9
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Liu L, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P626, DOI 10.1109/IIH-MSP.2014.162
   Liu YQ, 2022, IEEE T IMAGE PROCESS, V31, P541, DOI 10.1109/TIP.2021.3132828
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mahmood T, 2020, MULTIMED TOOLS APPL, V79, P31759, DOI 10.1007/s11042-020-09655-2
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Mahmoud K., 2016, Int. J. Comput. Sci. Inf. Secur, V14, P28
   Mahmoud K, 2016, INT ARAB J INF TECHN, V13, P930
   Malviya AV, 2016, PROCEDIA COMPUT SCI, V79, P383, DOI 10.1016/j.procs.2016.03.050
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Meena KB, 2019, MULTIMED TOOLS APPL, P1
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   Mohebbian Elham, 2015, 2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI). Proceedings, P436, DOI 10.1109/KBEI.2015.7436084
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Muzaffer G, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741657
   Muzaffer G, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P595, DOI 10.1109/TSP.2017.8076056
   NathalieDiane WN, 2014, SCI WORLD J, V2014
   Ouyang JL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Ouyang JL, 2019, MULTIMED TOOLS APPL, V78, P10207, DOI 10.1007/s11042-018-6605-1
   Pandey Ramesh Chand, 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036519
   Pandey RC, 2015, ADV INTELL SYST, V327, P659, DOI 10.1007/978-3-319-11933-5_74
   Panzade PP, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P264, DOI 10.1109/PDGC.2016.7913156
   Park CS, 2016, MULTIMED TOOLS APPL, V75, P16577, DOI 10.1007/s11042-016-3575-z
   Park JY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040492
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Popescu AC, 2004, DIGITAL FORGERIES DE
   Prakash CS, 2017, INT J MULTIMED DATA, V8, P1, DOI 10.4018/IJMDEM.2017040101
   Prasad S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P706, DOI 10.1109/RTEICT.2016.7807915
   Pugar FH, 2019, INT CONF ELECT ENG, P63, DOI [10.1109/ICEEI47359.2019.8988905, 10.1109/iceei47359.2019.8988905]
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Qiao M, 2011, NOVEL APPROACH DETEC
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sadu C, 2022, DETECTION METHOD COP, P1, DOI [10.1109/TENCON55691.2022.9977490, DOI 10.1109/TENCON55691.2022.9977490]
   Samir S, 2020, INFORMATION, V11, DOI 10.3390/info11050275
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Shahroudnejad A, 2016, 2016 2ND INTERNATIONAL CONFERENCE OF SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P149, DOI 10.1109/ICSPIS.2016.7869896
   Sharma S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P795, DOI 10.1109/CICT.2015.88
   Shelke NA, 2022, MULTIMEDIA SYST, V28, P267, DOI 10.1007/s00530-021-00837-y
   Shelke NA, 2022, MULTIMED TOOLS APPL, V81, P22731, DOI 10.1007/s11042-021-10989-8
   Shi WC, 2016, CHINA COMMUN, V13, P139, DOI 10.1109/CC.2016.7405711
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Singh D., 2013, Intelligent Interactive Technologies and Multimedia, P111, DOI [10.1007/978-3-642-37463-010, DOI 10.1007/978-3-642-37463-010]
   Singh D, 2023, MULTIMED TOOLS APPL, V82, P1045, DOI 10.1007/s11042-022-13270-8
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P., 2013, SURVEY DIGITAL WATER
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Tralic D, 2014, INT CONF SYST SIGNAL, P167
   Tyagi V., 2018, UNDERSTANDING DIGITA
   Uliyan DM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8070062
   Uliyan DM, 2015, IEEE CONF OPEN SYST, P7, DOI 10.1109/ICOS.2015.7377269
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Wang H, 2017, MULTIMED TOOLS APPL, V76, P12627, DOI 10.1007/s11042-016-3687-5
   Wang S, 2007, IEEE T CIRC SYST VID, V17, P98, DOI 10.1109/TCSVT.2006.887086
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang XF, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550089
   Wang YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102536
   Wang Y, 2017, IEEE INT SYM MULTIM, P553, DOI 10.1109/ISM.2017.108
   Warbhe AD, 2016, PROCEDIA COMPUT SCI, V78, P61, DOI 10.1016/j.procs.2016.02.011
   Warbhe AD, 2016, PROCEDIA COMPUT SCI, V79, P458, DOI 10.1016/j.procs.2016.03.059
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang B, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.063016
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang P, 2016, LECT NOTES COMPUT SC, V10040, P404, DOI 10.1007/978-3-319-48674-1_36
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Yuan Y, 2017, ARAB J SCI ENG, V42, P559, DOI 10.1007/s13369-016-2268-2
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
   Zhao F, 2016, LECT NOTES COMPUT SC, V10066, P478, DOI 10.1007/978-3-319-49148-6_39
   Zhao J, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/619564
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhen-Long Du, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P17, DOI 10.1109/ICMLC.2012.6358879
   Zhi-ping Zhou, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P242, DOI 10.1109/ICETC.2010.5529692
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
   Zhong JL, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540052
   Zhong JL, 2016, NONLINEAR DYNAM, V84, P189, DOI 10.1007/s11071-015-2374-9
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 172
TC 2
Z9 2
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16455-x
EA AUG 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YW0
UT WOS:001050046600001
DA 2024-07-18
ER

PT J
AU Ye, Q
   Sun, YX
AF Ye, Qing
   Sun, Yaxin
TI Diversity subspace generation based on feature selection for speech
   emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speech emotion recognition; Feature selection; Diversity subspace
   generation; Ensemble learning; Pattern recognition
AB Automatic emotion recognition from speech signals is an important research area. Many speech emotion recognition (SER) methods have been proposed, among which ensemble learning is an effective way to recognize speech emotion. However, the ability and diversity of the base classifier are not carefully considered in the case of limited available speech emotion samples. To overcome the above problem, this paper proposes a new diversity subspace generation based on feature selection (DSGFS) for SER. In DSGFS, a constrained problem is cleverly designed, which can iteratively select many diversity and strong subspaces, so the classification ability and the diversity of the corresponding base classifiers can be ensured. As a result, more features can be extracted from the data, an ensemble classifier framework with strong base classifiers can be automatically generated, and the number of base classifiers can be smaller. The proposed models offered SER weighted average recall of 87.24%, 64.58%, 69.10%, 53.50% on the EmoDB, SAVEE, RAVDESS, CASIA datasets with speaker independent, respectively, which validate the proposed approach in terms of the performance of speech emotion recognition.
C1 [Ye, Qing; Sun, Yaxin] Wenzhou Univ Technol, Wenzhou 325000, Peoples R China.
   [Sun, Yaxin] Zhejiang Aerosp Hengjia Data Technol Co Ltd, Jiaxing 314000, Peoples R China.
   [Sun, Yaxin] Zhejiang Normal Univ, Jinhua 321000, Peoples R China.
C3 Wenzhou University of Technology; Zhejiang Normal University
RP Sun, YX (corresponding author), Wenzhou Univ Technol, Wenzhou 325000, Peoples R China.; Sun, YX (corresponding author), Zhejiang Aerosp Hengjia Data Technol Co Ltd, Jiaxing 314000, Peoples R China.; Sun, YX (corresponding author), Zhejiang Normal Univ, Jinhua 321000, Peoples R China.
EM yeqing0713@163.com; sunyaxin2005@163.com
RI YE, QING/KIG-8170-2024
FU Zhejiang Provincial Natural Science Foundation; Wenzhou Natural Science
   Foundation [2021G0170]
FX AcknowledgmentThis work was supported by Zhejiang Provincial Natural
   Science Foundation (No.LQ18F020006), Wenzhou Natural Science Foundation
   (No.2021G0170).
CR Anagnostopoulos Theodoros, 2014, Journal of Systems and Information Technology, V16, P222, DOI 10.1108/JSIT-01-2014-0009
   [Anonymous], 2009, INTERSPEECH
   [Anonymous], 2013, P IET INT SIGN PROC
   Anuragi A, 2022, INFORM SCIENCES, V610, P508, DOI 10.1016/j.ins.2022.07.121
   Badshah A.M., 2016, INT INT C CONC CONV, P1
   Bandela SR, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107645
   Bastanfard A, 2023, ALIREZA ABBASIAN SPE
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Cai D., 2010, KDD, P333
   Chen LF, 2020, INFORM SCIENCES, V509, P150, DOI 10.1016/j.ins.2019.09.005
   Chen ZZ, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.118943
   Daneshfar F, 2023, NEURAL NETWORKS, V163, P108, DOI 10.1016/j.neunet.2023.03.026
   Darekar RV, 2023, ADV ENG SOFTW, V180, DOI 10.1016/j.advengsoft.2023.103412
   datatang, SEL SPEECH EM DAT I
   Demilie WB, 2022, J BIG DATA, P1
   Eyben F, 2018, IEEE INT C AC SPEECH, P1
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Hacine-Gharbi A, 2021, J KING SAUD UNIV-COM, V33, P1074, DOI 10.1016/j.jksuci.2019.07.008
   Haq S., 2009, INT C AUDITORY VISUA, P53
   Hou MX, 2022, IEEE-ACM T AUDIO SPE, V30, P218, DOI 10.1109/TASLP.2021.3133196
   Huang DY, 2014, COMPUT SPEECH LANG, V28, P392, DOI 10.1016/j.csl.2013.06.002
   Ilyas O., 2021, BIOM SIGNAL PROCESS, V66, P80
   Jha Tulika, 2022, International Journal of Speech Technology, V25, P707, DOI 10.1007/s10772-022-09985-6
   Jin Y, 2018, IEEE INT C ACOUSTICS, P4808
   Krajewski Jarek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3716, DOI 10.1109/ICPR.2010.905
   Langari S., 2020, INFORM MED UNLOCKED, V20, DOI [10.1016/j.imu.2020.100424, DOI 10.1016/J.IMU.2020.100424]
   Lei JJ, 2022, NEURAL NETWORKS, V156, P67, DOI 10.1016/j.neunet.2022.09.022
   Li DD, 2021, NEURAL PROCESS LETT, V53, P4097, DOI 10.1007/s11063-021-10581-z
   Li DD, 2021, INFORM SCIENCES, V548, P328, DOI 10.1016/j.ins.2020.09.047
   Liu XW, 2014, IEEE T NEUR NET LEAR, V25, P1083, DOI 10.1109/TNNLS.2013.2287275
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Mannepalli K, 2022, J KING SAUD UNIV-COM, V34, P384, DOI 10.1016/j.jksuci.2018.11.012
   Manohar K, 2022, KNOWL-BASED SYST, V246, DOI 10.1016/j.knosys.2022.108659
   Mao S., 2022, SPEECH LANGUAGE PROC, V30, P23
   Mencattini A, 2017, IEEE T AFFECT COMPUT, V8, P314, DOI 10.1109/TAFFC.2016.2531664
   Milton A, 2014, COMPUT SPEECH LANG, V28, P727, DOI 10.1016/j.csl.2013.08.004
   Mustaqeem, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114177
   Mutlag Wamidh K., 2020, Journal of Physics: Conference Series, V1591, DOI 10.1088/1742-6596/1591/1/012028
   Noroozi F, 2017, INT J SPEECH TECHNOL, V20, P239, DOI 10.1007/s10772-017-9396-2
   Pandey SK, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103173
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qian Y, 2013, P IEEE C ANTH, P1
   Sala-Vila A, 2022, ADV NUTR, V13, P1584, DOI 10.1093/advances/nmac016
   Schuller B, 2013, INTERSPEECH, P148
   Schuller B, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3208
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
   Schuller Bjorn., 2012, INTERSPEECH 2012 Speaker Trait Challenge
   Shahin I, 2023, APPL ACOUST, V205, DOI 10.1016/j.apacoust.2023.109279
   Shilandari A, 2022, SIGNAL IMAGE VIDEO P, V16, P1955, DOI 10.1007/s11760-022-02156-9
   Singh P, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107316
   Singh P, 2023, SPEECH COMMUN, V146, P53, DOI 10.1016/j.specom.2022.11.005
   Singh P, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103712
   Singh YB, 2023, J. Chem. Phys.
   Song P, 2020, IEEE T AFFECT COMPUT, V11, P373, DOI 10.1109/TAFFC.2018.2800046
   Sun YX, 2017, MULTIMED TOOLS APPL, V76, P8305, DOI 10.1007/s11042-016-3487-y
   Sun YX, 2015, BIOMED SIGNAL PROCES, V18, P80, DOI 10.1016/j.bspc.2014.10.008
   Tanko D, 2022, APPL ACOUST, V190, DOI 10.1016/j.apacoust.2022.108637
   Thakur A., 2022, INT J SPEECH TECHNOL, V14, P3691
   Thirumuru R, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103293
   Tuncer T., 2021, KNOWL-BASED SYST, V211, P216
   van der Wal CN, 2013, APPL INTELL, V39, P675, DOI 10.1007/s10489-013-0449-1
   Vasuki P., 2015, Res J Appl Sci Eng Technol, V9, P1105, DOI DOI 10.19026/RJASET.9.2604
   Wen GH, 2022, KNOWL-BASED SYST, V254, DOI 10.1016/j.knosys.2022.109589
   Ye Q, 2018, SOFT COMPUT, V22, P7255, DOI 10.1007/s00500-017-2727-z
   Yildirim S, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107721
   Yuanlu Kuang, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P795, DOI 10.1109/ICSESS.2013.6615425
   Zhang SQ, 2021, SPEECH COMMUN, V127, P73, DOI 10.1016/j.specom.2020.12.009
   Zhang ZC, 2021, ALEX ENG J, V60, P1499, DOI 10.1016/j.aej.2020.11.004
   Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou N, 2016, PATTERN RECOGN, V53, P87, DOI 10.1016/j.patcog.2015.12.008
   Zhou Y, 2022, IEEE-ACM T AUDIO SPE, V30, P695, DOI 10.1109/TASLP.2022.3145287
NR 72
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16465-9
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600005
DA 2024-07-18
ER

PT J
AU Guan, RW
   Man, KL
   Chen, FF
   Yao, SL
   Hu, RS
   Zhu, XH
   Smith, J
   Lim, EG
   Yue, YT
AF Guan, Runwei
   Man, Ka Lok
   Chen, Feifan
   Yao, Shanliang
   Hu, Rongsheng
   Zhu, Xiaohui
   Smith, Jeremy
   Lim, Eng Gee
   Yue, Yutao
TI FindVehicle and VehicleFinder: a NER dataset for natural language-based
   vehicle retrieval and a keyword-based cross-modal vehicle retrieval
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross modal learning; Named entity recognition; Intelligent traffic
   system; Vehicle retrieval; Human-computer interaction; Object detection
AB Natural language (NL) based vehicle retrieval is a task aiming to retrieve a vehicle that is most consistent with a given NL query from among all candidate vehicles. Because NL query can be easily obtained, such a task has a promising prospect in building an interactive intelligent traffic system (ITS). Current solutions mainly focus on extracting both text and image features and mapping them to the same latent space to compare the similarity. However, existing methods usually use dependency analysis or semantic role-labelling techniques to find keywords related to vehicle attributes. These techniques may require a lot of pre-processing and post-processing work, and also suffer from extracting the wrong keyword when the NL query is complex. To tackle these problems and simplify, we borrow the idea from named entity recognition (NER) and construct FindVehicle, a NER dataset in the traffic domain. It has 42.3k labelled NL descriptions of vehicle tracks, containing information such as the location, orientation, type and colour of the vehicle. FindVehicle also adopts both overlapping entities and fine-grained entities to meet further requirements. To verify its effectiveness, we propose a baseline NL-based vehicle retrieval model called VehicleFinder. Our experiment shows that by using text encoders pre-trained by FindVehicle, VehicleFinder achieves 87.7% precision and 89.4% recall when retrieving a target vehicle by text command on our homemade dataset based on UA-DETRAC [1]. From loading the command into VehicleFinder to identifying whether the target vehicle is consistent with the command, the time cost is 279.35 ms on one ARM v8.2 CPU and 93.72 ms on one RTX A4000 GPU, which is much faster than the Transformer-based system. The dataset is open-source via the link , and the implementation can be found via the link .
C1 [Guan, Runwei; Yao, Shanliang; Smith, Jeremy] Univ Liverpool, Dept Elect Engn & Elect, Liverpool, England.
   [Guan, Runwei; Man, Ka Lok; Chen, Feifan; Yao, Shanliang; Zhu, Xiaohui; Lim, Eng Gee] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Peoples R China.
   [Guan, Runwei; Yao, Shanliang; Yue, Yutao] Xian Jiaotong Liverpool Univ, XJTLU JITRI Acad Technol, Suzhou 215123, Peoples R China.
   [Guan, Runwei; Yao, Shanliang; Yue, Yutao] JITRI, Inst Deep Percept Technol, Wuxi 214000, Peoples R China.
   [Hu, Rongsheng] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Peoples R China.
   [Yue, Yutao] Univ Liverpool, Dept Math Sci, Liverpool L69 7ZX, England.
C3 University of Liverpool; Xi'an Jiaotong-Liverpool University; Xi'an
   Jiaotong-Liverpool University; Kunming University of Science &
   Technology; University of Liverpool
RP Yue, YT (corresponding author), Xian Jiaotong Liverpool Univ, XJTLU JITRI Acad Technol, Suzhou 215123, Peoples R China.; Yue, YT (corresponding author), JITRI, Inst Deep Percept Technol, Wuxi 214000, Peoples R China.; Yue, YT (corresponding author), Univ Liverpool, Dept Math Sci, Liverpool L69 7ZX, England.
EM Runwei.Guan@liverpool.ac.uk; Ka.Man@xjtlu.edu.cn;
   sgfchen5@liverpool.ac.uk; shanliang.yao@liverpool.ac.uk;
   1033170432@stu.jiangnan.edu.cn; Xiaohui.Zhu@xjtlu.edu.cn;
   J.S.Smith@liverpool.ac.uk; enggee.lim@xjtlu.edu.cn; yueyutao@idpt.org
RI Yao, Shanliang/KBB-2115-2024; Man, Ka Lok/K-7013-2013; Guan,
   Runwei/GYQ-7280-2022; lim, eng GEE/JMC-6208-2023
OI Yao, Shanliang/0000-0001-7596-3598; Guan, Runwei/0000-0003-4013-2107;
   lim, eng GEE/0000-0003-0199-7386
FU Xi'an Jiaotong-Liverpool University (XJTLU) AI University Research
   Centre, Jiangsu (Provincial) Data Science and Cognitive Computational
   Engineering Research Centre at XJTLU [XJTLU-REF-21-01-002]
FX AcknowledgementsThe authors acknowledge XJTLU-JITRI Academy of
   Industrial Technology for giving valuable support to the joint project.
   This work is also partially supported by the Xi'an Jiaotong-Liverpool
   University (XJTLU) AI University Research Centre, Jiangsu (Provincial)
   Data Science and Cognitive Computational Engineering Research Centre at
   XJTLU (funding: XJTLU-REF-21-01-002). The authors sincerely acknowledge
   Sihao Dai, Zhou Yuan, Wenjie Zhou for their help in the project.
CR Adaimi G, 2021, TRANSPORT RES C-EMER, V126, DOI 10.1016/j.trc.2021.103067
   Agarap AF, 2018, arXiv, DOI 10.48550/arXiv.1803.08375
   Bai S., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P4034
   Balasuriya Dominic, 2009, P 2009 WORKSH PEOPL, P10
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Chien CF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164559
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Derczynski Leon, 2017, P 3 WORKSHOP NOISY U, P140
   Deruyttere T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2088
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3198
   El Hamdani S, 2020, TRANSPORT RES C-EMER, V121, DOI 10.1016/j.trc.2020.102856
   Feng Q., 2021, ARXIV
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Ganin AA, 2019, TRANSPORT RES C-EMER, V100, P318, DOI 10.1016/j.trc.2019.01.014
   Goel S, 2022, Arxiv, DOI arXiv:2205.14459
   Gui T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4982
   Huang ZH, 2015, Arxiv, DOI arXiv:1508.01991
   Khorramshahi Pirazh, 2021, P IEEECVF C COMPUTER, P4183
   Kong FY, 2020, MULTIMED TOOLS APPL, V79, P35195, DOI 10.1007/s11042-019-7614-4
   Le H.D.-A., 2022, P IEEE CVF C COMP VI, P3300
   Li Jingye., 2021, arXiv
   Li XA, 2020, Arxiv, DOI arXiv:2004.11795
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XC, 2016, IEEE INT CON MULTI
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Morwal S., 2012, International Journal on Natural Language Computing (IJNLC), V1
   Park Eun-Ju, 2021, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) Workshops, P4220
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Phung Trang T. T., 2021, ICMLSC'21: 2021 The 5th International Conference on Machine Learning and Soft Computing, P18, DOI 10.1145/3453800.3453804
   Radford A, 2021, PR MACH LEARN RES, V139
   RangiLyu, 2021, NanoDet-Plus: Super fast and high accuracy lightweight anchor-free object detection model
   Rao YM, 2022, PROC CVPR IEEE, P18061, DOI 10.1109/CVPR52688.2022.01755
   Schweter S, 2021, Arxiv, DOI [arXiv:2011.06993, 10.48550/arXiv.2011.06993]
   Scribano Carmelo, 2021, P IEEECVF C COMPUTER, P4253
   Sharma P, 2022, MULTIMED TOOLS APPL, V81, P34893, DOI 10.1007/s11042-020-10366-x
   Souza F, 2020, Arxiv, DOI [arXiv:1909.10649, DOI 10.48550/ARXIV.1909.10649]
   Stubbs A, 2015, J BIOMED INFORM, V58, pS20, DOI 10.1016/j.jbi.2015.07.020
   Sui Y, 2022, Arxiv, DOI arXiv:2204.05518
   Sun Z., 2021, PROC IEEECVF C COMPU, P4061
   Nguyen TM, 2021, IEEE COMPUT SOC CONF, P4240, DOI 10.1109/CVPRW53098.2021.00480
   Tjong KSE, 2003, P 7 C NAT LANG LEARN, P142, DOI DOI 10.3115/1119176.1119195
   VILCEK A., 2018, TRANSFORMER BASED DE
   Weischedel R., 2013, Ontonotes Release 5.0 ldc2013t19, V23, P23
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Xu B., 2022, P IEEE CVF C COMP VI, P3142
   Xu Z., 2008, P 6 SIGHAN WORKSHOP
   Zhang J., 2022, MULTIGRANULARITY RET
   Zhao C., 2022, SYMMETRIC NETWORK SP
NR 52
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16373-y
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900004
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Soualmi, A
   Ducottet, C
   Patural, H
   Giraud, A
   Alata, O
AF Soualmi, Ameur
   Ducottet, Christophe
   Patural, Hugues
   Giraud, Antoine
   Alata, Olivier
TI A 3D pose estimation framework for preterm infants hospitalized in the
   Neonatal Unit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Infant pose estimation; 3D pose; Stereoscopic vision; General movements
   assessment; Premature infants; Preterm birth; Video analysis
ID MOVEMENT ANALYSIS; COMPUTER VISION; QUANTIFICATION
AB Infant pose estimation is crucial in different clinical applications, including preterm automatic general movements assessment. Recent infant pose estimation methods are limited by a lack of real clinical data and are mainly focused on 2D detection. We introduce a stereoscopic system for infants' 3D pose estimation, based on fine-tuning state-of-the-art 2D human pose estimation networks on a large, real, and manually annotated dataset of infants' images. Our dataset contains over 88k images, collected from 175 videos from 53 premature infants born <33 weeks of gestational age (GA), acquired within the Neonatology department of the Centre Hospitalier Universitaire de Saint Etienne, France, between 32 and 41 weeks of GA. This framework significantly reduced the pose estimation error compared to existing 2D infant pose estimation networks. It achieved a mean error of 1.72 cm on 18000 stereoscopic images in the 3D pose estimation task. This framework is the first 3D pose estimation tool dedicated to preterm infants hospitalized in the Neonatal Unit that does not depend on any visual markers or infrared cameras.
C1 [Soualmi, Ameur; Ducottet, Christophe; Alata, Olivier] Univ Jean Monnet, Lab Hubert Curien, CNRS, IOGS,UMR 5516, St Etienne, France.
   [Soualmi, Ameur; Patural, Hugues; Giraud, Antoine] Univ Jean Monnet, INSERM, U1059, SAINBIOSE, St Etienne, France.
   [Patural, Hugues; Giraud, Antoine] CHU St Etienne, Serv Neonatal, St Etienne, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS); Universite Jean Monnet;
   Institut National de la Sante et de la Recherche Medicale (Inserm); CHU
   de St Etienne
RP Soualmi, A (corresponding author), Univ Jean Monnet, Lab Hubert Curien, CNRS, IOGS,UMR 5516, St Etienne, France.; Soualmi, A (corresponding author), Univ Jean Monnet, INSERM, U1059, SAINBIOSE, St Etienne, France.
EM ameur.soualmi@univ-st-etienne.fr; ducottet@univ-st-etienne.fr;
   hugues.patural@chu-st-etienne.fr; antoine.giraud@univ-st-etienne.fr;
   olivier.alata@univ-st-etienne.fr
OI SOUALMI, Ameur/0000-0003-1395-2687; PATURAL, Hugues/0000-0002-5359-6544
FU Contrat Doctoral de l'Ecole Doctorale 488 SIS
FX & nbsp;AS was funded by a Contrat Doctoral de l'Ecole Doctorale 488 SIS.
CR Adde L, 2009, EARLY HUM DEV, V85, P541, DOI 10.1016/j.earlhumdev.2009.05.003
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Baccinelli W, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10040203
   Berthouze L, 2011, J BIOMECH, V44, P1212, DOI 10.1016/j.jbiomech.2011.01.016
   Cabon S., 2021, 2021 COMP CARD CINC, V48, P1
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chambers C, 2020, IEEE T NEUR SYS REH, V28, P2431, DOI 10.1109/TNSRE.2020.3029121
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Cioni G., 2008, PRECHTLS METHOD QUAL
   cocodataset, CO COKEYPOINT EVALUA
   Doroniewicz I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20215986
   Fan MM, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P411
   Gravem D, 2012, J MED DEVICES, V6, DOI 10.1115/1.4006129
   Groos D, 2021, APPL INTELL, V51, P2518, DOI 10.1007/s10489-020-01918-7
   Hesse N, 2019, LECT NOTES COMPUT SC, V11134, P32, DOI 10.1007/978-3-030-11024-6_3
   Huang X., 2021, 2021 16 IEEE INT C A, P1
   Karch D, 2010, METHOD INFORM MED, V49, P526, DOI 10.3414/ME09-02-0034
   Karch D, 2008, J BIOMECH, V41, P2860, DOI 10.1016/j.jbiomech.2008.06.033
   Li M, 2021, IEEE SENS J, V21, P6904, DOI 10.1109/JSEN.2020.3037121
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   McCay KD, 2022, IEEE T NEUR SYS REH, V30, P8, DOI 10.1109/TNSRE.2021.3138185
   McCay KD, 2020, IEEE ACCESS, V8, P51582, DOI 10.1109/ACCESS.2020.2980269
   Meinecke L, 2006, HUM MOVEMENT SCI, V25, P125, DOI 10.1016/j.humov.2005.09.012
   Moccia S, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY - CIBCB 2019, P1, DOI 10.1109/cibcb.2019.8791242
   Olsen JE, 2020, EARLY HUM DEV, V148, DOI 10.1016/j.earlhumdev.2020.105115
   Orlandi S, 2018, IEEE ENG MED BIO, P3598, DOI 10.1109/EMBC.2018.8513078
   Pavel AM, 2020, LANCET CHILD ADOLESC, V4, P740, DOI 10.1016/S2352-4642(20)30239-X
   Pierrat V, 2021, BMJ-BRIT MED J, V373, DOI 10.1136/bmj.n741
   Raghuram K, 2019, J PERINATOL, V39, P1362, DOI 10.1038/s41372-019-0464-0
   Rahmati H, 2014, IEEE ENG MED BIO, P3779, DOI 10.1109/EMBC.2014.6944446
   Reich S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89347-5
   Sakkos D, 2021, IEEE ACCESS, P1
   Sciortino G, 2017, LECT NOTES COMPUT SC, V10485, P410, DOI 10.1007/978-3-319-68548-9_38
   Shivakumar SS, 2017, INT C REHAB ROBOT, P841, DOI 10.1109/ICORR.2017.8009353
   Singh M, 2010, IEEE INT SYM WRBL CO
   Spittle A, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005495.pub4
   Stahl A, 2012, IEEE T NEUR SYS REH, V20, P605, DOI 10.1109/TNSRE.2012.2195030
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Wu Q., 2021, IMMUNOL INVEST, VPP, P1, DOI [10.1109/ACCESS.2021.3051505, DOI 10.1080/08820139.2020.1869254]
   Wu QQ, 2020, IEEE ENG MED BIO, P5802, DOI 10.1109/EMBC44109.2020.9176407
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
NR 41
TC 0
Z9 0
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16333-6
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900003
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Vellaidurai, A
   Rathinam, M
AF Vellaidurai, Arthi
   Rathinam, Murugeswari
TI A novel OYOLOV5 model for vehicle detection and classification in
   adverse weather conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous vehicle; Residual Network-50; Feature pyramid network; Fuzzy
   C-means; Intersection over Union; Detection in adverse weather nature
AB An autonomous vehicle must accurately detect its surrounding environment to operate reliably. Adverse weather conditions (ADWC) are snow, rain, sand, and haze, badly affect the quality of vehicle detection (VD) in an autonomous environment. Most existing techniques focused on VD under various weather effects such as signal control, travel pattern, traffic volume variations and collision risk. Only a limited number of works of literature were focused on VD under ADWC at different automation scales. In this paper, a novel deep learning (DL) model, Optimized You Look Only Once Version 5 (OYOLOV5), is proposed for autonomous VD (AVD) in ADWC. The proposed model consists of three phases: data collection, data preprocessing, feature extraction and classification. Initially, the data is collected from the DAWN and COCO dataset to perform VD, which is openly available. The augmentation of the data is carried out on the collected input data by including hue, saturation, blur, brightness, and noise, which helps to get a clear view of vehicles. After data augmentation, feature extraction and classification of the preprocessed images are done using the OYOLOV5 framework, which uses Resnet-50 as the backbone network and Feature Pyramid Network (FPN) for detecting the vehicles at multi-scales. Experiments are conducted, and the outcomes demonstrated the proposed OYOLOV5 model achieves better performance with the state-of-art methods in terms of precision (PRC), recall (RC), f-measure (FMS), accuracy (ACU), average IoU (AI), processing speed (PS), and training time (TTI). Also, the system attains good mean average precision (mAP) than the conventional methods.
C1 [Vellaidurai, Arthi; Rathinam, Murugeswari] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil, India.
C3 Kalasalingam Academy of Research & Education
RP Rathinam, M (corresponding author), Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil, India.
EM arthidurai.1297@gmail.com; murugesananth@gmail.com
OI Vellaidurai, Arthi/0000-0002-7435-267X
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Corovic A, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P731
   Dai XR, 2019, SIGNAL PROCESS-IMAGE, V70, P79, DOI 10.1016/j.image.2018.09.002
   Dasgupta K, 2022, Arxiv, DOI arXiv:2105.12713
   Ennajar A, 2021, 18 INT MULT SYST SIG
   Feng D, 2020, Arxiv, DOI arXiv:1902.07830
   Ghosh R, 2021, MULTIMED TOOLS APPL, V80, P25985, DOI 10.1007/s11042-021-10954-5
   Gupta A, 2021, ARRAY-NY, V10, DOI 10.1016/j.array.2021.100057
   Haris M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161932
   Hassaballah M, 2021, IEEE T INTELL TRANSP, V22, P4230, DOI 10.1109/TITS.2020.3014013
   Hnewa M, 2021, IEEE SIGNAL PROC MAG, V38, P53, DOI 10.1109/MSP.2020.2984801
   Humayun M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172748
   Ibrahim MR, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8120549
   Khosravian A, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115417
   Kim SW, 2021, IEEE NETWORK, V35, P177, DOI 10.1109/MNET.011.2000248
   Kopelias P., 2020, SCI TOTAL ENVIRON, V172, P1
   Kuutti S, 2019, ARXIV
   Masmoudi M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE OF VEHICULAR ELECTRONICS AND SAFETY (ICVES 19), DOI 10.1109/icves.2019.8906437
   Mehra A, 2021, IEEE T INTELL TRANSP, V22, P4256, DOI 10.1109/TITS.2020.3013099
   Meng Q., 2019, HINDAWI COMPLEXITY, V2019, P1
   Nabati R, 2019, IEEE IMAGE PROC, P3093, DOI [10.1109/ICIP.2019.8803392, 10.1109/icip.2019.8803392]
   Rjoub Gaith, 2021, Mobile Web and Intelligent Information Systems: 17th International Conference, MobiWIS 2021, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12814), P121, DOI 10.1007/978-3-030-83164-6_10
   Sarda Abhishek, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P1370, DOI 10.1109/ICICV50876.2021.9388577
   Sharma T, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040563
   Walambe R, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5278820
   Wang G, 2019, IEEE ACCESS, V7, P18840, DOI 10.1109/ACCESS.2019.2897283
   Yahya MA, 2020, INT CONF SYST ENG, P207, DOI [10.1109/icset51301.2020.9265358, 10.1109/ICSET51301.2020.9265358]
   Yu J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010076
   Zhao P, 2021, 58 ACM IEEE DES AUT
NR 29
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16450-2
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900005
DA 2024-07-18
ER

PT J
AU Nguyen, D
   Nguyen, DT
   Sridharan, S
   Abdelrazek, M
   Denman, S
   Tran, SN
   Zeng, R
   Fookes, C
AF Nguyen, Dung
   Nguyen, Duc Thanh
   Sridharan, Sridha
   Abdelrazek, Mohamed
   Denman, Simon
   Tran, Son N.
   Zeng, Rui
   Fookes, Clinton
TI Deep cross-domain transfer for emotion recognition via joint learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotional knowledge transfer; Emotion recognition; Cross-domain
   transfer; Joint leaning
ID NETWORK; FUSION
AB Deep learning has been applied to achieve significant progress in emotion recognition from multimedia data. Despite such substantial progress, existing approaches are hindered by insufficient training data, leading to weak generalisation under mismatched conditions. To address these challenges, we propose a learning strategy which jointly transfers emotional knowledge learnt from rich datasets to source-poor datasets. Our method is also able to learn cross-domain features, leading to improved recognition performance. To demonstrate the robustness of the proposed learning strategy, we conducted extensive experiments on several benchmark datasets including eNTERFACE, SAVEE, EMODB, and RAVDESS. Experimental results show that the proposed method surpassed existing transfer learning schemes by a significant margin.
C1 [Nguyen, Dung; Nguyen, Duc Thanh; Abdelrazek, Mohamed] Deakin Univ, Sch Informat Technol, Burwood, Vic, Australia.
   [Nguyen, Dung] Monash Univ, Fac Informat Technol, Clayton, Vic, Australia.
   [Sridharan, Sridha; Denman, Simon; Zeng, Rui; Fookes, Clinton] Queensland Univ Technol, Speech Audio Image & Video Technol SAIVT Lab, Brisbane, Qld, Australia.
   [Tran, Son N.] Univ Tasmania, Informat & Commun Technol, Hobart, Australia.
C3 Deakin University; Monash University; Queensland University of
   Technology (QUT); University of Tasmania
RP Nguyen, DT (corresponding author), Deakin Univ, Sch Informat Technol, Burwood, Vic, Australia.
EM duc.nguyen@deakin.edu.au
RI Fookes, Clinton/I-9786-2012
OI Abdelrazek, Mohamed/0000-0003-3812-9785; Sridharan,
   Sridha/0000-0003-4316-9001
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   [Anonymous], 2013, P ICML
   Bozorgtabar B, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107111
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Nguyen D, 2018, COMPUT VIS IMAGE UND, V174, P33, DOI 10.1016/j.cviu.2018.06.005
   Nguyen D, 2018, INT C PATT RECOG, P3543, DOI 10.1109/ICPR.2018.8545411
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   Haq S., 2009, INT C AUD VIS SPEECH, P53
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Hu GS, 2018, LECT NOTES COMPUT SC, V11216, P106, DOI 10.1007/978-3-030-01258-8_7
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Jiabei Zeng, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11217), P227, DOI 10.1007/978-3-030-01261-8_14
   Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Nagrani A, 2018, LECT NOTES COMPUT SC, V11217, P73, DOI 10.1007/978-3-030-01261-8_5
   Nagrani A, 2018, PROC CVPR IEEE, P8427, DOI 10.1109/CVPR.2018.00879
   Nguyen D, 2023, NEURAL COMPUT APPL, V35, P10535, DOI 10.1007/s00521-023-08248-y
   Nguyen D, 2022, IEEE T MULTIMEDIA, V24, P1313, DOI 10.1109/TMM.2021.3063612
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Peng ZX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3020, DOI 10.1109/ICASSP39728.2021.9414286
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Wu F, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107335
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Yoon S, 2019, INT CONF ACOUST SPEE, P2822, DOI 10.1109/ICASSP.2019.8683483
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang XY, 2018, INT CONF SIGN PROCES, P1194, DOI 10.1109/ICSP.2018.8652371
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
   Zhu WJ, 2022, INT CONF ACOUST SPEE, P6437, DOI 10.1109/ICASSP43922.2022.9747517
   Zou HQ, 2022, INT CONF ACOUST SPEE, P7367, DOI 10.1109/ICASSP43922.2022.9747095
NR 41
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-15441-7
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700008
OA hybrid
DA 2024-07-18
ER

PT J
AU Bida, I
   Aouat, S
AF Bida, Ikram
   Aouat, Saliha
TI Efficient bat-inspired block matching algorithm with novel motion energy
   directional histograms for dynamic texture fast recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bat algorithm; Block matching algorithms; Dynamic texture recognition;
   Feature extraction; Motion estimation; PCA
ID 3-STEP SEARCH ALGORITHM
AB Motion estimation is a crucial step in Dynamic Texture (DT) Motion-based recognition systems, as it directly affects the system's overall accuracy and computational proficiency. Whereas efficient motion estimation methods are pixel-based prioritizing recognition quality over computational complexity, this trade-off may not be acceptable in time-sensitive applications. Therefore, Block Matching algorithms (BMA) stand as potential alternative candidates, however, classic BMA often falls into local optimums ambushes resulting suboptimal solutions, particularly for complex motion videos such DT. In this paper, we propose a novel bat-inspired block matching approach for motion estimation to overcome the issue of falling into local optima. Our approach is inspired from the powerful search capacity of the bat algorithm seeking the best block within a search space; aiming accuracy improvement and a faster convergence. Afterwards, we extract motion features from the matched blocks fields to characterize the different DT videos. Two comprehensive sets of experiments were performed to validate the proposed approaches, Firstly the bat-inspired block motion estimation performance was compared against common algorithms on various standard video sequences. Moreover, the effectiveness of the introduced Dynamic Texture Recognition (DTR) system was demonstrated using well-known DT datasets, where comparative studies with state-of-art methods were presented. The results achieved a balance on computational speed and accuracy on multiple datasets.
C1 [Bida, Ikram; Aouat, Saliha] Univ Sci & Technol Houari Boumediene USTHB, Dept Comp Sci, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Bida, I (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Dept Comp Sci, Algiers 16111, Algeria.
EM ibida@usthb.dz; saouat@usthb.dz
CR Ahn TG, 2004, IEEE T CIRC SYST VID, V14, P1265, DOI 10.1109/TCSVT.2004.835146
   Andrearczyk V, 2015, IRISH MACHINE VISION, V2015
   Andrearczyk V, 2018, PATTERN RECOGN, V76, P36, DOI 10.1016/j.patcog.2017.10.030
   Bansal R, 2017, TENCON IEEE REGION, P2609, DOI 10.1109/TENCON.2017.8228302
   Bida Ikram, 2019, Information Systems and Technologies to Support Learning. Proceedings of EMENA-ISTL 2018. Smart Innovation, Systems and Technologies (SIST 111), P631, DOI 10.1007/978-3-030-03577-8_69
   Bida I, 2022, SIVIP, P1
   Bida I, 2018, SMART INNOVATION SYS, V111
   Bida I, 2019, LECT NOTE NETW SYST, V50, P182, DOI 10.1007/978-3-319-98352-3_20
   Bull DR, 2014, COMMUNICATING PICTURES: A COURSE IN IMAGE AND VIDEO CODING, P99
   Couto Leandro N., 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P351, DOI 10.1007/978-3-030-13469-3_41
   Dimitropoulos K, 2015, IEEE T CIRC SYST VID, V25, P339, DOI 10.1109/TCSVT.2014.2339592
   Du GY, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5038
   Dubois S, 2012, IEEE T CIRC SYST VID, V22, P188, DOI 10.1109/TCSVT.2011.2159430
   Fablet R., 1999, MOTION BASED FEATUR, P221
   Fazekas S, 2007, 6 C HUNGARIAN ASS IM, P157
   Fazekas S, 2007, INT WORK CONTENT MUL, P25, DOI 10.1109/CBMI.2007.385388
   Fekri-Ershad Shervan, 2022, COMPUT INTEL NEUROSC, V2022
   Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223
   Gupta D., 2020, Nature-Inspired Computation and Swarm Intelligence, P179, DOI DOI 10.1016/B978-0-12-819714-1.00022-1
   Kim JN, 1998, IEEE T CONSUM ELECTR, V44, P638, DOI 10.1109/30.713175
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lizarraga-Morales Rocio A., 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P38, DOI 10.1007/978-3-642-37410-4_4
   Lu JH, 1997, IEEE T CIRC SYST VID, V7, P429, DOI 10.1109/76.564122
   Lu Z., 2005, P WORKSHOP MOTION, P241
   Menassel Rafik, 2020, International Journal of Computers and Applications, V42, P697, DOI 10.1080/1206212X.2019.1638631
   NELSON RC, 1992, CVGIP-IMAG UNDERSTAN, V56, P78, DOI 10.1016/1049-9660(92)90087-J
   Nguyen TT, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116394
   Nguyen TT, 2020, IET COMPUT VIS, V14, P162, DOI 10.1049/iet-cvi.2019.0455
   Paygude Shilpa, 2019, International Journal of Reasoning-based Intelligent Systems, V11, P170
   Peh CH, 2002, IEEE T IMAGE PROCESS, V11, P1179, DOI 10.1109/TIP.2002.804265
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Péteri R, 2005, LECT NOTES COMPUT SC, V3523, P223
   Péteri R, 2006, COMPUT IMAGING VIS, V32, P33, DOI 10.1007/1-4020-4179-9_6
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Quan YH, 2017, COMPUT VIS IMAGE UND, V165, P85, DOI 10.1016/j.cviu.2017.10.008
   Ravichandran A, 2011, IEEE T PATTERN ANAL, V33, P158, DOI 10.1109/TPAMI.2010.61
   Ren R, 2006, ARXIV
   Ribas LC, 2019, LECT NOTES COMPUT SC, V11751, P82, DOI 10.1007/978-3-030-30642-7_8
   Ribas LC, 2019, DIGIT SIGNAL PROCESS, V92, P109, DOI 10.1016/j.dsp.2019.03.017
   Saisan P, 2001, PROC CVPR IEEE, P58
   Nguyen TT, 2021, IEEE T MULTIMEDIA, V23, P1367, DOI 10.1109/TMM.2020.2997202
   Nguyen TT, 2019, LECT NOTES COMPUT SC, V11678, P155, DOI 10.1007/978-3-030-29888-3_13
   Thanh Tuan Nguyen, 2020, Advanced Concepts for Intelligent Vision Systems. 20th International Conference, ACIVS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12002), P277, DOI 10.1007/978-3-030-40605-9_24
   Nguyen TT, 2018, LECT NOTES COMPUT SC, V11182, P74, DOI 10.1007/978-3-030-01449-0_7
   Xu Y, 2015, PATTERN RECOGN, V48, P3239, DOI 10.1016/j.patcog.2015.04.015
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yazdani Azita, 2022, Comput Intell Neurosci, V2022, P1658615, DOI 10.1155/2022/1658615
   Zhang P, 2010, P IEEE INFOCOM, P1
   Zhang P, 2011, INT J DIGIT CONTENT, V5
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21633
EP 21653
DI 10.1007/s11042-023-16295-9
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500009
DA 2024-07-18
ER

PT J
AU Yang, L
   Li, XY
   Liu, YH
AF Yang, Lei
   Li, Xingyu
   Liu, Yanhong
TI A novel vision-based defect detection method for hot-rolled steel strips
   via multi-branch network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surface defects; Deep learning; Image segmentation; Residual path;
   Multi-branch network
ID FUSION; MODEL
AB Defects of hot-rolled steel strips will bring a certain effect to the produce appearance and structural strength, even may bring the lose of economy. Accurate defect detection of hot-rolled steel strips could provide an effective support for precise maintenance decision and quality control. However, the defects of hot-rolled steel strips are always against with some challenging factors, such as weak texture, poor contrast, different signal-to-noise (SNR) ratios among different types of defects, etc., which will bring a great effect to accurate pixel-level defect detection. Recently, deep learning has shown a promising performance on image segmentation, especially, U-Net and its variant networks. However, there are also some shortcomings to affect the detection precision, such as the information loss issue caused by multiple pooling operations, insufficient processing of local feature maps, etc. Especially, the information loss issue caused by multiple pooling operations will greatly effect the detection performance on micro defects. To address the above issues, a deep multi-branch defect segmentation network is proposed in this paper for accurate and automatic pixel-level defect location of hot-rolled steel strips. Aimed at the insufficient processing of local feature maps by skip connections, a residual path is proposed to optimize the simple skip connections to acquire the effective context features, and it also could well reduce the effect of semantic gap issue. Meanwhile, to realize feature enhancement of local feature maps, a multi-scale context fusion (MCF) block is proposed to embed into the bottleneck layer to extract multi-scale attention context features. More importantly, to address the information loss issue caused by multiple pooling operations and improve the detection precision on micro defects, a multi-branch network with shared network weights is proposed for accurate multi-scale defect detection. Experiments show that proposed network could acquire a promising segmentation performance compared with other advanced segmentation models.
C1 [Yang, Lei; Li, Xingyu; Liu, Yanhong] Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou 450001, Henan, Peoples R China.
   [Yang, Lei; Li, Xingyu; Liu, Yanhong] Robot Percept & Control Engn Lab, Zhengzhou 450001, Henan, Peoples R China.
C3 Zhengzhou University
RP Yang, L (corresponding author), Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou 450001, Henan, Peoples R China.; Yang, L (corresponding author), Robot Percept & Control Engn Lab, Zhengzhou 450001, Henan, Peoples R China.
EM leiyang2019@zzu.edu.cn
RI Li, Xingyu/AHE-0001-2022; Yang, Lei/K-8424-2018
OI Li, Xingyu/0000-0002-5547-9894; Yang, Lei/0000-0003-1212-9445
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cao JG, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3033726
   Cao JJ, 2017, MULTIMED TOOLS APPL, V76, P4141, DOI 10.1007/s11042-015-3041-3
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen TY, 2020, J IND INF INTEGR, V18, DOI 10.1016/j.jii.2020.100144
   Choi W, 2020, IEEE T IND ELECTRON, V67, P8016, DOI 10.1109/TIE.2019.2945265
   Choudhary A, 2021, IEEE SENS J, V21, P1727, DOI 10.1109/JSEN.2020.3015868
   Fan X, 2021, 2021 IEEE 6 INT C SI, P189, DOI DOI 10.1109/ICSIP52628.2021.9688782
   Gan JR, 2017, IEEE SENS J, V17, P7935, DOI 10.1109/JSEN.2017.2761858
   Gibert X, 2017, IEEE T INTELL TRANSP, V18, P153, DOI 10.1109/TITS.2016.2568758
   Guo RY, 2021, IEEE SENS J, V21, P10844, DOI 10.1109/JSEN.2021.3059860
   Hsieh YA, 2021, IEEE INT C INTELL TR, P2251, DOI 10.1109/ITSC48978.2021.9564806
   Hu BZ, 2021, IEEE T IMAGE PROCESS, V30, P472, DOI 10.1109/TIP.2020.3036770
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Z, 2021, MATER LETT, V301, DOI 10.1016/j.matlet.2021.130271
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Kheradmandi N, 2022, CONSTR BUILD MATER, V321, DOI 10.1016/j.conbuildmat.2021.126162
   Lau SLH, 2020, ARXIV
   Li C, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1822585
   Li CL, 2019, MULTIMED TOOLS APPL, V78, P7321, DOI 10.1007/s11042-018-6483-6
   Li MK, 2021, IEEE SENS J, V21, P23390, DOI 10.1109/JSEN.2021.3106057
   Lian J, 2020, IEEE T IND INFORM, V16, P1343, DOI 10.1109/TII.2019.2945403
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Q, 2019, NDT&E INT, V108, DOI 10.1016/j.ndteint.2019.102164
   Luo QW, 2020, IEEE T INSTRUM MEAS, V69, P626, DOI 10.1109/TIM.2019.2963555
   Miao HH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3033457
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qu Z, 2022, IEEE T INTELL TRANSP, V23, P11710, DOI 10.1109/TITS.2021.3106647
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Song GR, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.106000
   Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002
   Taghibakhsh F, 2009, IEEE SENS J, V9, P51, DOI 10.1109/JSEN.2008.2008409
   [汤勃 Tang Bo], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P1640
   Tsai DM, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3087826
   Wang JZ, 2020, IEEE T IND INFORM, V16, P141, DOI 10.1109/TII.2019.2917522
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xi DJ, 2023, J INTELL MANUF, V34, P1585, DOI 10.1007/s10845-021-01876-y
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xu L, 2020, IEEE T INSTRUM MEAS, V69, P1191, DOI 10.1109/TIM.2019.2912237
   Yahyatabar M, 2020, IEEE ENG MED BIO, P1242, DOI [10.1109/EMBC44109.2020.9176033, 10.1109/embc44109.2020.9176033]
   Yang H, 2021, IEEE T IND INFORM, V17, P2220, DOI 10.1109/TII.2020.3015765
   Yang L, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108338
   Yang L, 2021, NDT&E INT, V120, DOI 10.1016/j.ndteint.2021.102435
   Yang L, 2018, INT J ADV MANUF TECH, V94, P1209, DOI 10.1007/s00170-017-0991-9
   Yu F., 2015, ARXIV
   Yu HM, 2019, IEEE T INSTRUM MEAS, V68, P656, DOI 10.1109/TIM.2018.2853958
   Yu ZY, 2017, LECT NOTES COMPUT SC, V10528, P417, DOI 10.1007/978-3-319-68345-4_37
   Zhang YX, 2019, IEEE SENS J, V19, P9364, DOI 10.1109/JSEN.2019.2927268
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao S, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103934
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 56
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21655
EP 21676
DI 10.1007/s11042-023-15753-8
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500010
DA 2024-07-18
ER

PT J
AU Ghaffari, A
AF Ghaffari, Aboozar
TI Image encryption-compression method via encryption based sparse
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression-encryption scheme; chaotic system; sparse
   decomposition; measurement matrix; Half Quadratic Splitting; image
   denoising
ID CHAOTIC SYSTEM; REPRESENTATIONS
AB This paper proposes an image compression and encryption scheme based on sparse decomposition and chaotic system. The proposed approach contains three steps. In the first step, the original image is encrypted and converted to a meaningless image via the perturbation of the image phase in the Fourier transform and chaotic scrambling. This step improves the accuracy of image reconstruction based on sparse decomposition. In the second step, the encrypted image is compressed with a measurement matrix generated from a chaotic system. Then the compressed image is mapped and quantized. Finally, DNA XOR operation and chaotic scrambling are used to increase security. This step reduces the correlation among pixels and maximizes the entropy of the encrypted image. The two first steps present a problem of encryption-based sparse decomposition (ESD). The ESD problem is solved via the Half Quadratic Splitting approach in the decryption process. The proposed image reconstruction approach is based on sequential encryption, image denoising, and projection on the feasible set. The convergence of the ESD solver is investigated analytically. The simulation results show that the proposed method improves image reconstruction performance. The Peak Signal to Noise Ratios of the proposed approach are approximately in the range of 29 to 40 dB for compression ratios higher than 0.25. The ESD approach outperforms some other reconstruction approaches. The Security analysis based on different measures, such as obtaining near-zero correlation among adjacent pixels and maximum entropy of nearly 8, indicates the effectiveness of the proposed approach.
C1 [Ghaffari, Aboozar] Iran Univ Sci & Technol, Dept Elect Engn, Tehran, Iran.
C3 Iran University Science & Technology
RP Ghaffari, A (corresponding author), Iran Univ Sci & Technol, Dept Elect Engn, Tehran, Iran.
EM aboozar_ghaffari@iust.ac.ir
RI ghaffari, aboozar/T-8772-2019
OI ghaffari, aboozar/0000-0001-8813-3462
CR Abuturab MR, 2022, OPT LASER TECHNOL, V151, DOI 10.1016/j.optlastec.2022.108071
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Suhail KMA, 2020, IRAN J SCI TECHNOL A, V44, P1091, DOI 10.1007/s40995-020-00905-4
   [Anonymous], 2007, MODERN APPROACHES MA, V2, P507
   Arthi G, 2022, MULTIMED TOOLS APPL, V81, P15859, DOI 10.1007/s11042-022-12598-5
   Bao WJ, 2022, MULTIMED TOOLS APPL, V81, P15977, DOI 10.1007/s11042-022-12623-7
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Bengio Y., 2017, DEEP LEARNING
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2022, NONLINEAR DYNAM, V108, P2671, DOI 10.1007/s11071-022-07328-3
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chen TG, 2016, OPT LASER TECHNOL, V84, P118, DOI 10.1016/j.optlastec.2016.05.012
   Chuman T, 2019, IEEE T INF FOREN SEC, V14, P1515, DOI 10.1109/TIFS.2018.2881677
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Ding Y, 2021, IEEE T NEUR NET LEAR
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Dou YQ, 2020, IEEE ACCESS, V8, P220646, DOI 10.1109/ACCESS.2020.3043240
   Duan XT, 2019, J REAL-TIME IMAGE PR, V16, P765, DOI 10.1007/s11554-018-0826-4
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fan JH, 2019, OPT APPL, V49, P461, DOI 10.5277/oa190308
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   Ghaffari A, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107723
   Ghaffari A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79747-4
   Ghaffari A, 2014, IET IMAGE PROCESS, V8, P728, DOI 10.1049/iet-ipr.2013.0575
   Ghaffari A, 2009, INT CONF ACOUST SPEE, P3157, DOI 10.1109/ICASSP.2009.4960294
   Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031
   Hao J, 2021, IEEE ACCESS, V9, P52364, DOI 10.1109/ACCESS.2021.3069977
   Hu F., 2016, arXiv
   Hu HY, 2021, IEEE ACCESS, V9, P22141, DOI 10.1109/ACCESS.2021.3054842
   Hu WW, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02641-5
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Kaige Zhu, 2020, MATEC Web of Conferences, V309, DOI 10.1051/matecconf/202030903017
   Kaur M., 2021, Math. Probl. Eng., V2021
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Li J, 2015, SCI REP-UK, V5, DOI 10.1038/srep10374
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu JL, 2022, MULTIMEDIA SYST, V28, P595, DOI 10.1007/s00530-021-00859-6
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Liu XB, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02739-w
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Maniyath SR, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103134
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Molaie M, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413501885
   Ni RJ, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3076480
   Patel S, 2021, NEURAL COMPUT APPL, V33, P14533, DOI 10.1007/s00521-021-06096-2
   Paul LSJ, 2022, MULTIMED TOOLS APPL, V81, P37873, DOI 10.1007/s11042-022-13095-5
   Ponuma R, 2019, MULTIDIM SYST SIGN P, V30, P1895, DOI 10.1007/s11045-019-00634-x
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Shao GQ, 2014, IEEE T IMAGE PROCESS, V23, P489, DOI 10.1109/TIP.2013.2287996
   Sharma M, 2010, IMAGE ENCRYPTION TEC
   Song W, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116628
   Sridevi A, 2022, MULTIMED TOOLS APPL, V81, P16987, DOI 10.1007/s11042-022-12471-5
   Sun CY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030291
   Wang H, 2021, MATH PROBL ENG
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang XY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75562-z
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei D, 2021, OPTIK
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Yang FF, 2020, MULTIMED TOOLS APPL, V79, P19963, DOI 10.1007/s11042-020-08821-w
   Yang YG, 2015, SCI REP-UK, V5, DOI 10.1038/srep07784
   Zhang XQ, 2012, OPT COMMUN, V285, P1736, DOI 10.1016/j.optcom.2011.12.023
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhu LY, 2019, IEEE ACCESS, V7, P22161, DOI 10.1109/ACCESS.2019.2897721
NR 82
TC 2
Z9 2
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19129
EP 19160
DI 10.1007/s11042-023-16163-6
EA JUL 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043237000001
DA 2024-07-18
ER

PT J
AU Sriharsha, KV
   Alphonse, PJA
AF Sriharsha, K., V
   Alphonse, P. J. A.
TI A computational geometric learning approach for person axial and
   slanting depth prediction using single RGB camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-focus; Axial line; Slanting distance; Focal length; Infinite focus;
   Curve estimation regression
ID ALGORITHM
AB The paper proposes a non triangulation method for estimating the depth of a person in slanting position relative to camera lens center. The influence of three parameters, namely lens aperture radius, focal length, and object size on person depth along the axial line, is well investigated while recording the in-focused portions of the person at various distances on the axial line. This investigation is taken as a basis for estimating the depth of the person on the axial line for different combination of aforementioned parameters using machine learning framework. Further to estimate the slanting depth, a geometrical relation is obtained from the predicted axial depth, deviation taken by the person to the left/right of the axial line. Considering the ground truth depth data taken within 3 to 6mts range using Nikon D5300, the model is validated and is inferred that the camera to object distance (or depth) anticipated along axial line is 99.06% correlated with actual camera to object distance at a confidence level of 95% with RMSE of 17.36
C1 [Sriharsha, K., V; Alphonse, P. J. A.] NIT Tiruchirappalli, Dept Comp Applicat, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Sriharsha, KV (corresponding author), NIT Tiruchirappalli, Dept Comp Applicat, Tiruchirappalli 620015, Tamil Nadu, India.
EM sriharsha.phd@gmail.com; alphonse@nitt.edu
FU Viswesvaraya Ph.D scheme for Electronics amp; IT, a division of the
   Ministry of Electronics amp; IT, Govt of India [PhD-MLA/4(16)/2014]
FX This work is supported under Viswesvaraya Ph.D scheme for Electronics &
   IT [Order No: PhD-MLA/4(16)/2014], a division of the Ministry of
   Electronics & IT, Govt of India. The writers also gratefully acknowledge
   the association of Sica Southern Indian Cinematographers, Chennai, for
   creating the dataset to validate the proposed theory. The author would
   also like to thank the Student society ,Department of Computer
   Applications who have been with us and supported us in Dataset creation.
   The Author is also grateful to the Incharge Faculty and Lab, Sensors &
   Security Lab for offering experimental validation facilities.
CR Achar S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073686
   Alphonse PJA, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04212-4
   Alphonse PJA, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107349
   Alphonse PJA, 2020, TRAIT SIGNAL, V37, P333, DOI 10.18280/ts.370220
   ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   Benjamin J M Jr, 1974, Bull Prosthet Res, P443
   Bhatti A., 2012, Current Advancements in Stereo Vision
   Cabezas I, 2011, LECT NOTES COMPUT SC, V7042, P223, DOI 10.1007/978-3-642-25085-9_26
   Chaudhuri S., 2012, Depth From Defocus: A Real Aperture Imaging Approach
   Chen Shan-shan, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P403, DOI 10.1109/ICCSN.2011.6014298
   Chen YJ, 2016, OPTIK, V127, P763, DOI 10.1016/j.ijleo.2015.10.171
   Fekri-Ershad S, 2018, INT ARAB J INF TECHN, V15, P1024
   Fuchs Stefan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3583, DOI 10.1109/ICPR.2010.874
   Hannah M. J., 1974, Computer Matching of Areas in Stereo Images
   Hansard M., 2012, Time-of-Flight Cameras: Principles, Methods and Applications
   Langmann B, 2014, WIDE AREA 2D3D IMAGI, P5
   Lefloch Damien, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P3, DOI 10.1007/978-3-642-44964-2_1
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li L., 2014, Time-of-Flight Camera - An Introduction
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]
   Monteiro NB, 2018, COMPUT VIS IMAGE UND, V168, P104, DOI 10.1016/j.cviu.2018.01.010
   Munro P, 2009, STEREO VISION COMPUT
   Mure-Dubois J, 2007, P ICVS WORKSH CAM CA
   Niwa H, 2007, IEEE INT CONF ROBOT, P423, DOI 10.1109/ROBOT.2007.363823
   Pertuz S, 2018, ISPRS J PHOTOGRAMM, V144, P38, DOI 10.1016/j.isprsjprs.2018.06.020
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Reynolds M, 2011, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2011.5995550
   Sarbolandi H, 2015, COMPUT VIS IMAGE UND, V139, P1, DOI 10.1016/j.cviu.2015.05.006
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D, 1998, INT J COMPUT VISION, V28, P7
   Scharstein D., 1999, View Synthesis Using Stereo Vision
   Wahab M. N. A., 2011, 2011 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology, P36, DOI 10.1109/STUDENT.2011.6089321
   Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Zhang L, 2010, PROC CVPR IEEE, P522, DOI 10.1109/CVPR.2010.5540171
NR 35
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14133
EP 14149
DI 10.1007/s11042-023-15970-1
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200005
DA 2024-07-18
ER

PT J
AU Guidi, B
   Michienzi, A
AF Guidi, Barbara
   Michienzi, Andrea
TI Delving NFT vulnerabilities, a sleepminting prevention system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NFT; Blockchain; Scams; Sleepminting
ID BLOCKCHAIN APPLICATIONS
AB The rise of Non-Fungible Tokens (NFTs) is beginning to revolutionize the digital world thanks to the unique property of these tokens. Indeed, they can represent the ownership of physical or digital assets. They are implemented using smart contracts, therefore if the code of the smart contract contains bugs, an attacker can exploit its vulnerabilities to perform an attack called sleepminting. Sleepminting consists of transferring NFTs owned by an address, without the owner's consent. In this paper, we provide a detailed analysis of the sleepminting attack and, thanks to the insights gained, we propose a prevention system to reduce the number of sleepminting attacks. Our prevention system is based on analysing the transactions included in new blocks, detecting those that are related to sleepminting attacks and keeping track of the addresses that are involved in these transactions. A dictionary-like data structure can be used to keep track of the addresses involved, where the key is the address and the value acts as a counter for the number of times the address is involved in sleepminting. With this information, block-creating nodes can add another verification step before adding a transaction to a block, which consists of blocking transactions when the addresses involved appear in sleepminting attacks a number of times greater than a threshold. The evaluation shows that sleepminting is a relevant phenomenon, and now it involves NFT transfers rather than NFT minting. Our proposed prevention system is able to block up to 87% of attacks.
C1 [Guidi, Barbara; Michienzi, Andrea] Univ Pisa, Dept Comp Sci, Pisa, Italy.
C3 University of Pisa
RP Michienzi, A (corresponding author), Univ Pisa, Dept Comp Sci, Pisa, Italy.
EM guidi@di.unipi.it; andrea.michienzi@unipi.it
RI Michienzi, Andrea/JDD-8184-2023
OI Michienzi, Andrea/0000-0001-8005-8701
FU Universita~di Pisa within the CRUI-CARE Agreement
FX Open access funding provided by Universita & nbsp;di Pisa within the
   CRUI-CARE Agreement
CR Abou Jaoude J, 2019, IEEE ACCESS, V7, P45360, DOI 10.1109/ACCESS.2019.2902501
   Bellagarda J, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10213934
   Brighente, 2022, ARXIV
   Chen C, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040887
   Daian P., 2019, ARXIV
   Dannen Chris, 2017, Introducing Ethereum and solidity, V1
   Das Dipanjan, 2021, arXiv
   di Angelo M, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON DECENTRALIZED APPLICATIONS AND INFRASTRUCTURES (DAPPS 2020), P1, DOI 10.1109/DAPPS49028.2020.00001
   Dimitrov DV, 2019, HEALTHC INFORM RES, V25, P51, DOI 10.4258/hir.2019.25.1.51
   Dingman W, 2019, 2019 IEEE/ACIS 17TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P116, DOI [10.1109/sera.2019.8886793, 10.1109/SERA.2019.8886793]
   Erturk Emre, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P699, DOI 10.1109/UBMK52708.2021.9559006
   Gervais A., 2016, P 2016 ACMSIGSAC C C, P3
   Guidi Barbara, 2022, DICG '22: Proceedings of the 3rd International Workshop on Distributed Infrastructure for the Common Good, P13, DOI 10.1145/3565383.3566108
   Guidi Barbara, 2022, GoodIT 2022: Conference on Information Technology for Social Good, P75, DOI 10.1145/3524458.3547239
   Guidi B., 2022, ACM SIGWEB Newsletter, P1
   Guidi B, 2022, IEEE INT CON DIS, P199, DOI 10.1109/ICDCSW56584.2022.00045
   Guidi B, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369473
   Guidi B, 2020, PERVASIVE MOB COMPUT, V62, DOI 10.1016/j.pmcj.2020.101131
   Helliar CV, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102136
   I Storj Labs, 2018, STORJ DEC CLOUD STOR
   Jung Y, 2022, MICROGRID SYSTEM COM, P1
   McConaghy T., 2016, BigchainDB
   Mofokeng N., 2018, African Journal of Hospitality, Tourism and Leisure, V7, P1
   Nakamoto S., 2008, DECENTRAL BUS REV
   Popescu A.-D., 2021, P 5 INT C INN BUS EC, P26
   Regner F., 2019, 40 INT C INF SYST IC
   Saleh F, 2021, REV FINANC STUD, V34, P1156, DOI 10.1093/rfs/hhaa075
   Salimitari M, 2018, ARXIV
   Scharfman J, 2023, CRYPTOCURRENCY DIGIT, P1
   Valeonti F, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11219931
   Vorick D., 2014, Sia: Simple decentralized storage
   Wang Q., 2021, ARXIV
NR 32
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46065
EP 46084
DI 10.1007/s11042-023-16087-1
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001023992100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Ramesh, M
   Edla, DR
AF Ramesh, M.
   Edla, Damodar Reddy
TI EEG Signal Classification for Concealed Information Test using Spider
   Monkey Candidate Rule Miner
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalographic; SMO; Optimal Rule Set; EEG Channels; Candidate
   Rule Miner; CIT
ID COMPONENT ANALYSIS; MODEL
AB Controlling continuous data, such as Electroencephalographic (EEG) data, is challenging. The EEG data is recorded during the Concealed Information Test (CIT), performed with a 16-channel electrode. Some of the meta-heuristic algorithms that are already in use need to be improved so that they can handle the balance between the exploration and exploitation stages, deal with the problem of local optimums, and take continuous data. The Spider Monkey Optimization (SMO) algorithm is utilized as a candidate rule miner known as the SM-Candidate Rule Miner (SM-CRM) for categorizing EEG data into two groups, like guilty or innocent. These problems are solved by making an exhaustive optimal rule set that balances the SM-CRM's sensitivity, accuracy, and specificity. These rules are applied to the entire EEG dataset, and ten cross-folder validations are performed to get the individual confusion matrix. The SM-CRM method was better than other well-known algorithms regarding average sensitivity, specificity, and classification accuracy. It achieved a decent mean rule length and mean rule set size. Compared to meta-heuristic algorithms like the genetic and bat, the proposed framework achieved a maximum accuracy of 97.66%.
C1 [Ramesh, M.; Edla, Damodar Reddy] Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda 403401, Goa, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa
RP Edla, DR (corresponding author), Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda 403401, Goa, India.
EM m.ramesh@nitgoa.ac.in; dr.reddy@nitgoa.ac.in
CR Abootalebi V, 2006, INT J PSYCHOPHYSIOL, V62, P309, DOI 10.1016/j.ijpsycho.2006.05.009
   Abootalebi V, 2009, COMPUT METH PROG BIO, V94, P48, DOI 10.1016/j.cmpb.2008.10.001
   Akhavan A, 2017, COMPUT METH PROG BIO, V143, P25, DOI 10.1016/j.cmpb.2017.02.007
   Arasteh A, 2016, IEEE T INF FOREN SEC, V11, P2584, DOI 10.1109/TIFS.2016.2590938
   Bablani A, 2019, IEEE T INF FOREN SEC, V14, P3057, DOI 10.1109/TIFS.2019.2913798
   Bablani A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3297713
   Bablani A, 2019, MACH VISION APPL, V30, P813, DOI 10.1007/s00138-018-0950-y
   Bansal JC, 2014, MEMET COMPUT, V6, P31, DOI 10.1007/s12293-013-0128-0
   Dodia S, 2020, COMPUT INTELL-US, V36, P637, DOI 10.1111/coin.12256
   Dodia S, 2019, J NEUROSCI METH, V314, P31, DOI 10.1016/j.jneumeth.2019.01.007
   Farahani Ehsan Darestani, 2017, Informatics in Medicine Unlocked, V9, P58, DOI 10.1016/j.imu.2017.05.004
   FARWELL LA, 1991, PSYCHOPHYSIOLOGY, V28, P531, DOI 10.1111/j.1469-8986.1991.tb01990.x
   Gao JF, 2012, CLIN EEG NEUROSCI, V43, P54, DOI 10.1177/1550059411428715
   Hayashi Yoichi, 2016, Informatics in Medicine Unlocked, V2, P92, DOI 10.1016/j.imu.2016.02.001
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Kiziloluk S, 2015, ADV ELECTR COMPUT EN, V15, P17, DOI 10.4316/AECE.2015.04003
   Meixner JB, 2011, PSYCHOPHYSIOLOGY, V48, P149, DOI 10.1111/j.1469-8986.2010.01050.x
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P702, DOI 10.1016/j.dsp.2006.09.005
   Pourpanah F, 2016, EXPERT SYST APPL, V49, P74, DOI 10.1016/j.eswa.2015.11.009
   Ramadan RA, 2017, NEUROCOMPUTING, V223, P26, DOI 10.1016/j.neucom.2016.10.024
   Rosenfeld JP, 2008, PSYCHOPHYSIOLOGY, V45, P906, DOI 10.1111/j.1469-8986.2008.00708.x
   Rosenfeld JP, 2004, PSYCHOPHYSIOLOGY, V41, P205, DOI 10.1111/j.1469-8986.2004.00158.x
   Saini N, 2022, INTELLIGENT APPROACH, P1
   Shankaracharya, 2010, Rev Diabet Stud, V7, P252, DOI 10.1900/RDS.2010.7.252
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Shi XJ, 2008, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT, INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL 1, P175, DOI 10.1109/ICIII.2008.289
   Svojanovsky, BRAIN PROD
   Wang D, 2013, IEEE T INF FOREN SEC, V8, P520, DOI 10.1109/TIFS.2013.2244884
NR 28
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14477
EP 14501
DI 10.1007/s11042-023-16042-0
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700005
DA 2024-07-18
ER

PT J
AU Dowerah, R
   Patel, S
AF Dowerah, Rituporna
   Patel, Sanjeev
TI Comparative analysis of color histogram and LBP in CBIR systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Image retrieval; Color histogram; LBP; Microservices architecture
ID LOCAL BINARY PATTERNS; FEATURE DESCRIPTOR
AB In the current trend, the image retrieval (IR) system has also been shifted from traditional text-based to content-based with the advancement in technology. Many issues have been resolved by content-based IR. In a particular case of information retrieval/image retrieval (IR) systems, the number of images on the web and the usage of images are growing exponentially. Therefore, IR system needs to be scalable, flexible, modularizable and promotes reusability so that it becomes easy to deploy, develop and maintain the system. In this paper, we have presented a CBIR model using Color Histogram and Local Binary Pattern (LBP) where both are built with Microservices architecture using docker platform. The framework used in this model is logic independent therefore any CBIR system can be run using this framework. The CBIR using Color Histogram uses chi-squared distance as a similarity measure while CBIR model using LBP is implemented using Linear Support Vector Machines for image classification. In our experiments, we have achieved the average recall, precision, and F-measure using Color Histogram 22.25%, 63.12%, and 32.67%, respectively. Though, we have achieved the average recall, precision, and F-measure using LBP 77.15%, 79.90%, and 76.17%, respectively. It has been observed that LBP model is more accurate than Color Histogram for detecting different weather conditions. It has also been found that the use of Microservices architecture leads to improve the non-functional qualities of a CBIR system as compared to traditional architecture styles by a great margin.
C1 [Dowerah, Rituporna; Patel, Sanjeev] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Orissa, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Patel, S (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Orissa, India.
EM pornaritudowerah@gmail.com; patels@nitrkl.ac.in
CR Aderaldo Carlos M., 2017, 2017 IEEE/ACM 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering (ECASE). Proceedings, P8, DOI 10.1109/ECASE.2017.4
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ali WK., 2020, J CRIT REV, V7, P4207
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Boudra S, 2021, MULTIMED TOOLS APPL, V80, P22373, DOI 10.1007/s11042-020-08874-x
   Degaonkar VN, 2020, 2020 4 INT C EL COMM, P896
   Ghahremani M, 2021, MULTIMED TOOLS APPL, V80, P28245, DOI 10.1007/s11042-021-10895-z
   Grycuk R, 2019, IEEE INT CONF SERV, P119, DOI 10.1109/SOCA.2019.00025
   Jaramillo D, 2016, IEEE SOUTHEASTCON
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Kashyap N, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P799, DOI 10.1109/I2CT.2017.8226238
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Khan A, 2021, IEEE ACCESS, V9, P135608, DOI 10.1109/ACCESS.2021.3116225
   Komazec T, 2020, 2020 28TH TELECOMMUNICATIONS FORUM (TELFOR), P272
   Kumar A. Ramesh., 2013, International Journal of Computer Science and Information Technologies, V4, P242
   Lehmann TM, 2004, METHOD INFORM MED, V43, P354
   Maree R, 2010, P INT C MULT INF RET, P91
   Meena M, 2016, PROCEDIA COMPUT SCI, V79, P569, DOI 10.1016/j.procs.2016.03.072
   Moustakas J, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1279
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rosebrock A, 2014, COMPLETE GUIDE BUILD
   Shi DM, 2021, MULTIMED TOOLS APPL, V80, P23899, DOI 10.1007/s11042-021-10825-z
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Trojacanec K, 2009, EUROCON 2009: INTERNATIONAL IEEE CONFERENCE DEVOTED TO THE 150 ANNIVERSARY OF ALEXANDER S. POPOV, VOLS 1- 4, PROCEEDINGS, P118, DOI 10.1109/EURCON.2009.5167614
   Yuan Y, 2021, IEEE T IMAGE PROCESS, V30, P7702, DOI 10.1109/TIP.2021.3108403
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 27
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12467
EP 12486
DI 10.1007/s11042-023-15955-0
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800006
DA 2024-07-18
ER

PT J
AU Lu, Y
   Tao, XP
   Jiang, F
   Du, JJ
   Li, GF
   Liu, YR
AF Lu, Yang
   Tao, Xianpeng
   Jiang, Feng
   Du, Jiaojiao
   Li, Gongfa
   Liu, Yurong
TI Image recognition of rice leaf diseases using atrous convolutional
   neural network and improved transfer learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rice leaf diseases; Atrous convolutional neural network; Transfer
   learning; Deep learning
AB Rice diseases pose a great threat to abundant yield, stable harvest, and high-quality production of rice in China. Among them, the four diseases causing the most significant yield loss are sheath blight, rice blast, false smut, and ear rot. Accelerating the diagnosis and accurate identification of rice diseases is very important for the future development of rice production. To enhance the diagnostic accuracy of traditional CNNs in small-sample rice disease image sets, this paper proposes an ACNN-TL model based on CNN structure combined with Atrous convolution and transfer learning. Compared with standard convolution, Atrous convolution can increase the size of the receptive field in feature extraction and enrich the extracted feature details. Transfer learning can use knowledge in the original model to enhance capability in the target task. The experimental results show that the accuracy of ResNet-34, VGG-16, and AlexNet combining Atrous convolution and Transfer learning is 98.4%, 97.9%, and 95.9%, which increased 8.7%, 9.4%, and 16.7%, respectively, compared to with the original model. It can be seen that the combination of Atrous convolution and Transfer learning can effectively improve the diagnostic accuracy of CNN for small sample rice diseases, and the best model is Atrous ResNet-34 with Transfer learning.
C1 [Lu, Yang; Tao, Xianpeng; Jiang, Feng; Du, Jiaojiao] Heilongjiang Bayi Agr Univ, Coll Informat & Elect Engn, Daqing 163319, Heilongjiang, Peoples R China.
   [Li, Gongfa] Wuhan Univ Sci & Technol, Key Lab Met Equipment, Control Minist Educ, Whhan 430081, Hubei, Peoples R China.
   [Liu, Yurong] Yangzhou Univ, Dept Math, Yangzhou 225009, Jiangsu, Peoples R China.
C3 Heilongjiang Bayi Agricultural University; Wuhan University of Science &
   Technology; Yangzhou University
RP Lu, Y (corresponding author), Heilongjiang Bayi Agr Univ, Coll Informat & Elect Engn, Daqing 163319, Heilongjiang, Peoples R China.
EM luyanga@sina.com; taoxianpeng@gmail.com; 1213902894@qq.com;
   duyuanyuan37@gmail.com; ligongfa@wust.edu.cn; liuyurong@gmail.com
RI Lu, Yang/B-3068-2016
OI Lu, Yang/0000-0001-9887-7078
FU National Natural Science Foundation of China [61873058, 61933007]; Key
   Projects of Heilongjiang Natural Science Foundation [ZD2019F001];
   Heilongjiang Natural Science Foundation [LH2020F042]; China Postdoctoral
   Science Foundation [2016M591560]; Heilongjiang Postdoctoral Financial
   Assistance [LBH-Z15185]; Scientific Research Starting Foundation for
   Post Doctor from Heilongjiang [LBH-Q17134]; Heilongjiang Bayi
   Agricultural University Innovative Research Team Foundation
   [TDJH201807]; Open Fund of the Key Laboratory for Metallurgical
   Equipment and Control of Ministry of Education in Wuhan University of
   Science and Technology [2018A02, MECOF2019B02]
FX & nbsp;This work was supported in part by the National Natural Science
   Foundation of China under Grants 61873058 and 61933007, the Key Projects
   of Heilongjiang Natural Science Foundation under Grant ZD2019F001,
   Heilongjiang Natural Science Foundation under Grant LH2020F042, China
   Postdoctoral Science Foundation under Grant 2016M591560, Heilongjiang
   Postdoctoral Financial Assistance under Grant LBH-Z15185, the Scientific
   Research Starting Foundation for Post Doctor from Heilongjiang under
   Grant LBH-Q17134, Heilongjiang Bayi Agricultural University Innovative
   Research Team Foundation under Grant TDJH201807 and the Open Fund of the
   Key Laboratory for Metallurgical Equipment and Control of Ministry of
   Education in Wuhan University of Science and Technology under Grants
   2018A02 and MECOF2019B02.
CR Bengio Y, 2021, COMMUN ACM, V64, P58, DOI 10.1145/3448250
   Ding L, 2020, RES APPL IMAGE RECOG, DOI [10.27005/d.cnki.gdzku.2020.001172, DOI 10.27005/D.CNKI.GDZKU.2020.001172]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai ZY, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01779-5
   Lie WL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43171-0
   [林景栋 Lin Jingdong], 2020, [自动化学报, Acta Automatica Sinica], V46, P24
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Minu E.P., 2020, 2020 4 INT C COMPUTI, P670, DOI [DOI 10.1109/ICCMC48092.2020.ICCMC-00080, 10.1109/ICCMC48092.2020.ICCMC-00080]
   Mohameth F., 2020, Journal of Computer and Communications, V8, P10, DOI DOI 10.4236/JCC.2020.86002
   Mohanty SP, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1604.03169
   Nanehkaran YA, 2021, J SUPERCOMPUT, V77, P3193, DOI 10.1007/s11227-020-03388-7
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Shah NA, 2021, INT C COMPUTER VISIO, P451, DOI [DOI 10.1007/978-981-16-1086-8_40, 10.1007/978-981-16-1086-8_40]
   Shan X, 2022, SEED TECHNOL, P103, DOI [10.19904/j.cnki.cn14-1160/s.2022.20.035, DOI 10.19904/J.CNKI.CN14-1160/S.2022.20.035]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang ZN, 2023, INT J ADV MANUF TECH, V124, P4183, DOI 10.1007/s00170-022-09367-x
   Xu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142867
   Xu R, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2109.05687,2109.05687
   Yan Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123535
   Yu F., 2016, 4 INT C LEARN REPR I, DOI [10.48550/arXiv.1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yuan Y, 2018, UNDERSTANDING CONVOL, P1451, DOI [10.48550/arXiv.1702.08502, DOI 10.48550/ARXIV.1702.08502]
   Zhang L, 2020, MED PHYS, V47, P6270, DOI 10.1002/mp.14512
   Zhang ShanWen Zhang ShanWen, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P167
   Zhuang-Zhuang() Yan, 2020, Acta Agronomica Sinica, V46, P1771, DOI 10.3724/SP.J.1006.2020.94187
   Ziegler T, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1903.07992
NR 31
TC 4
Z9 4
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12799
EP 12817
DI 10.1007/s11042-023-16047-9
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200002
DA 2024-07-18
ER

PT J
AU Abayomi-Alli, OO
   Damasevicius, R
   Misra, S
   Abayomi-Alli, A
AF Abayomi-Alli, Olusola O. O.
   Damasevicius, Robertas
   Misra, Sanjay
   Abayomi-Alli, Adebayo
TI FruitQ: a new dataset of multiple fruit images for freshness evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE fruit freshness evaluation; fruit decay detection; precision
   agriculture; image processing; computer vision
ID COMPUTER VISION; QUALITY
AB Application of artificial intelligence methods in agriculture is gaining research attention with focus on improving planting, harvesting, post-harvesting, etc. Fruit quality recognition is crucial for farmers during harvesting and sorting, for food retailers for quality monitoring, and for consumers for freshness evaluation, etc. However, there is a lack of multi-fruit datasets to support real-time fruit quality evaluation. To address this gap, we present a new dataset of fruit images aimed at evaluating fruit freshness, which addresses the lack of multi-fruit datasets for real-time fruit quality evaluation. The dataset contains images of 11 fruits categorized into three freshness classes, and five well-known deep learning models (ShuffleNet, SqueezeNet, EfficientNet, ResNet18, and MobileNet-V2) were adopted as baseline models for fruit quality recognition using the dataset. The study provides a benchmark dataset for the classification task, which could improve research endeavors in the field of fruit quality recognition. The dataset is systematically organized and annotated, making it suitable for testing the performance of state-of-the-art methods and new learning classifiers. The research community in the fields of computer vision, machine learning, and pattern recognition could benefit from this dataset by applying it to various research tasks such as fruit classification and fruit quality recognition. The study achieved impressive results with the best classifier being ResNet-18 with an overall best performance of 99.8% for accuracy. The study also identified limitations, such as the small size of the dataset, and proposed future work to improve deep learning techniques for fruit quality classification tasks.
C1 [Abayomi-Alli, Olusola O. O.; Damasevicius, Robertas] Kaunas Univ Technol, Dept Software Engn, LT-44249 Kaunas, Lithuania.
   [Misra, Sanjay] Inst Energy Technol, Dept Appl Data Sci, N-1777 Halden, Norway.
   [Abayomi-Alli, Adebayo] Fed Univ Agr, Dept Comp Sci, Abeokuta 110124, Nigeria.
C3 Kaunas University of Technology; Institute for Energy Technology (IFE);
   University of Agriculture, Abeokuta
RP Damasevicius, R (corresponding author), Kaunas Univ Technol, Dept Software Engn, LT-44249 Kaunas, Lithuania.
EM olusola.abayomi-alli@ktu.edu; robertas.damasevicius@ktu.lt;
   sanjay.misra@ife.no; abayomiallia@funaab.edu.ng
RI Damaševičius, Robertas/E-1387-2017; Misra, Sanjay/K-2203-2014
OI Damaševičius, Robertas/0000-0001-9990-1084; Misra,
   Sanjay/0000-0002-3556-9331
CR Abayomi-Alli OO, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12746
   Almadhor A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113830
   Anowar F, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100378
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Bird JJ, 2022, SCI HORTIC-AMSTERDAM, V293, DOI 10.1016/j.scienta.2021.110684
   Cárdenas-Pérez S, 2017, BIOSYST ENG, V159, P46, DOI 10.1016/j.biosystemseng.2017.04.009
   Cavallo DP, 2019, COMPUT ELECTRON AGR, V156, P558, DOI 10.1016/j.compag.2018.12.019
   Chauhan C, 2021, J CLEAN PROD, V295, DOI 10.1016/j.jclepro.2021.126438
   Chen LY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13224712
   Cho WH, 2021, CMC-COMPUT MATER CON, V69, P4003, DOI 10.32604/cmc.2021.018758
   Civille GV, 2012, PHYSIOL BEHAV, V107, P598, DOI 10.1016/j.physbeh.2012.04.015
   Das S, 2018, PATTERN RECOGN, V81, P674, DOI 10.1016/j.patcog.2018.03.008
   Elbir Z., 2022, ARTIF INTELL, P29, DOI [10.4018/978-1-6684-5141-0.ch003, DOI 10.4018/978-1-6684-5141-0.CH003]
   Fahad LG, 2022, CMC-COMPUT MATER CON, V71, P5083, DOI 10.32604/cmc.2022.023357
   Fenu G, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11112107
   Fu Y., 2022, SCIENCE, V3, p10.1007/s42979
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hughes D., 2015, ABS151108060 CORR
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ismail N, 2022, INFORM PROCESS AGR, V9, P24, DOI 10.1016/j.inpa.2021.01.005
   Javaid M., 2021, Sens. Int, V2, P100121, DOI [DOI 10.1016/J.SINTL.2021.100121, 10.1016/j.sintl.2021.100121]
   Kang J, 2022, MULTIMED TOOLS APPL, V81, P22355, DOI 10.1007/s11042-021-11282-4
   Kaur P, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105210
   Kazi A, 2022, MULTIMED TOOLS APPL, V81, P7611, DOI 10.1007/s11042-022-12150-5
   Komorowski M., 2016, Secondary Analysis of Electronic Health Records [Internet], DOI [10.1007/978-3-319-43742-2_1, DOI 10.1007/978-3-319-43742-2_15]
   Ma J, 2016, CRIT REV FOOD SCI, V56, P113, DOI 10.1080/10408398.2013.873885
   Mavani NR, 2022, FOOD ENG REV, V14, P134, DOI 10.1007/s12393-021-09290-z
   Medhi E, 2022, DATA BRIEF, V43, DOI 10.1016/j.dib.2022.108427
   Melki P, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14040996
   Meshram V., 2020, Fruitsgb: top Indian fruits with quality
   Meshram V, 2022, DATA BRIEF, V40, DOI 10.1016/j.dib.2021.107686
   Nemade SB, 2020, J KING SAUD UNIV-COM
   Ni JG, 2020, IEEE ACCESS, V8, P228369, DOI 10.1109/ACCESS.2020.3045394
   Rajbongshi A, 2022, DATA BRIEF, V42, DOI 10.1016/j.dib.2022.108174
   Rauf HT, 2019, DATA BRIEF, V26, DOI 10.1016/j.dib.2019.104340
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma A, 2021, IEEE ACCESS, V9, P4843, DOI 10.1109/ACCESS.2020.3048415
   Sherafati A, 2022, COMPUT ELECTRON AGR, V200, DOI 10.1016/j.compag.2022.107214
   Sonwani E, 2022, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.816226
   Strong DM, 1997, COMMUN ACM, V40, P103, DOI 10.1145/253769.253804
   Suryawanshi Y, 2022, DATA BRIEF, V45, DOI 10.1016/j.dib.2022.108657
   Tan M., 2020, arXiv
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wieme J, 2022, BIOSYST ENG, V222, P156, DOI 10.1016/j.biosystemseng.2022.07.013
   Xu HL, 2016, SCI PROGRAMMING-NETH, V2016, DOI 10.1155/2016/8048246
   Yang J, 2022, FOOD CONTROL, V140, DOI 10.1016/j.foodcont.2022.109108
   Zarnaq Mohammad Hosseinpour, 2022, Agricultural Engineering International: CIGR Journal, V24, P282
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhu R, 2020, PATTERN RECOGN LETT, V133, P217, DOI 10.1016/j.patrec.2020.03.004
NR 50
TC 5
Z9 5
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11433
EP 11460
DI 10.1007/s11042-023-16058-6
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900004
DA 2024-07-18
ER

PT J
AU Deepak, NA
AF Deepak, N. A. N.
TI Change detection-siamese based framework to detect changes over the
   earth's surface (CD-CSNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Change detection; Divide and conquer; Features; Neural network;
   Sub-images
AB Recognizing the change over the earth's surface in the context of remote sensing identities needs to find the differences between the images. The manual execution of this task will be erroneous and incompetent to scale. To automate this process, we propose a novel framework that uses a customized Siamese-based neural network pipeline (CSNN) to detect the changes over the earth's surface. Based on the spatiotemporal analysis, the proposed work leverage's the ancient divide and conquers strategy. The image is divided into sub-image, and the feature maps are extracted using convolution layers that detect the fine-grained changes which occur at the sub-image level. The proposed methodology uses the LEVIR-CD dataset, which has 637 images. The performance of the proposed change detection method increases, as the input image size gets reduced, this is experimentally proved by decreasing the original image size into sub-images of size 2 x 2. The best performance achieved at 2 x 2 sized sub-image is 94.15%, 87.0%, 92.0%, 89.40% for accuracy, precision, recall, and F1-score respectively, which outperforms the results of the baseline algorithm. Further, the proposed framework performs well on different terrains, with varying amounts and types of changes in the satellite image.
C1 [Deepak, N. A. N.] RV Inst Technol & Management, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
RP Deepak, NA (corresponding author), RV Inst Technol & Management, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
EM deepakna.rvitm@rvei.edu.in
CR Abbas HK, 2020, AIP C P, P2290
   Aqeel Aslam Muhammad, 2020, J PHYS C SERIES, P20
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Bai T, 2023, GEO-SPAT INF SCI, V26, P262, DOI 10.1080/10095020.2022.2085633
   Benhur S, 2020, FRIENDLY INTRO SIAME
   Bontempi G, 2013, LECT NOTES BUS INF P, V138, P62
   Campbell JB, 2011, INTRO REMOTE SENSING
   Chen H, 2020, LEVIR CD DATASET
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2016, ISPRS J PHOTOGRAMM, V115, P3, DOI 10.1016/j.isprsjprs.2015.09.008
   Deilami BR, 2015, REV CHANGE DETECTION
   Devi TG, 2020, 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN INFORMATION TECHNOLOGY (ICITIIT), DOI 10.1109/icitiit49094.2020.9071556
   Dhruv B, 2017, 2017 RECENT DEVELOPMENTS IN CONTROL, AUTOMATION AND POWER ENGINEERING (RDCAPE), P410, DOI 10.1109/RDCAPE.2017.8358306
   Ghouaiel N, 2016, GEO-SPAT INF SCI, V19, P222, DOI 10.1080/10095020.2016.1244998
   Goel S, 2020, CHANGE DETECTION USI
   Gupta R.K., 2011, Inst. Town Planners India J., V8, P88
   Hendrycks D., 2016, ARXIV160608415
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Liang Y, 2022, IEEE T INFORM THEORY, DOI [10.48550/arXiv.2108.11348, DOI 10.48550/ARXIV.2108.11348]
   Liu ZT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3125055
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Moustafa MS, 2021, J APPL REMOTE SENS, V15, DOI [10.1117/1.JRS.15.028505, 10.1117/IIRS.15.028505]
   Mozgovoy D., 2018, ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VIV -3, P167, DOI DOI 10.5194/ISPRS-ANNALS-IV-3-167-2018
   Nielsen A., 2019, Practical Time Series Analysis: Prediction with Statistics and Machine Learning
   Oh KY, 2012, KOREAN J REMOTE SENS, V28, P39, DOI 10.7780/kjrs.2012.28.1.039
   Olofsson P, 2016, ENVIRON RES LETT, V11, DOI 10.1088/1748-9326/11/6/064002
   Polykretis C., 2020, EGU GEN ASSEMBLY, V2020, P8
   Public Health CUMS, 2020, SPAT AN
   Qin D, 2018, EXPERT SYST APPL, V97, P372, DOI 10.1016/j.eswa.2017.12.038
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Sharma V, 2019, 4 INT C INT THINGS S, P1, DOI [10.1109/IoT-SIU.2019.8777623, DOI 10.1109/IOT-SIU.2019.8777623]
   Shi W, 2010, REMOTE SENS-BASEL, V12
   Song L, 2021, INT J APPL EARTH OBS, V105, DOI 10.1016/j.jag.2021.102597
   Suribabu CR, 2012, J INDIAN SOC REMOTE, V40, P699, DOI 10.1007/s12524-011-0196-x
   Tomowski D., 2011, 2011 Proceedings of Joint Urban Remote Sensing Event (JURSE 2011), P329, DOI 10.1109/JURSE.2011.5764786
   TURNER MG, 1990, LANDSCAPE ECOL, V4, P21, DOI 10.1007/BF02573948
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang QM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108540
   Willhauck G., 2000, INT ARCH PHOTOGRAMME, V33, P214, DOI DOI 10.1016/S0022-3913(12)00047-9
   Yin CT, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-015-5397-4
   Zhou ST, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122874
   Zhou XL, 2011, LANDSCAPE URBAN PLAN, V100, P268, DOI 10.1016/j.landurbplan.2010.12.013
NR 45
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11387
EP 11409
DI 10.1007/s11042-023-15562-z
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900005
DA 2024-07-18
ER

PT J
AU Dang, C
   Xia, ZQ
   Dai, J
   Gao, J
   Li, L
   Feng, XY
AF Dang, Chen
   Xia, Zhaoqiang
   Dai, Jing
   Gao, Jie
   Li, Lei
   Feng, Xiaoyi
TI SCPAD: An approach to explore optical characteristics for robust static
   presentation attack detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Presentation attack detection(PAD); Interpretability; Frequency domain
   analysis; Optical characteristics; Color space; Adversarial robustness
AB Presentation attack detection approaches have achieved great progress on various attack types while adversarial learning technology has become a new threat to these approaches. Now few works are devoted to developing a robust detection method for both physical spoofing faces and digital adversarial faces. In this paper, we find that fake face images from printed photos and replayed videos have a different optical characteristic from the real ones, and the adversarial samples generated by various attacking methods retain this characteristic. By exploring this characteristic, we propose the Spectral Characteristic Presentation Attack Detection (SCPAD), a new approach that detects presentation attacks by reconstructing the color space of input images, which also performs well on adversarial samples. More specifically, a new HSCbb color space is manually constructed by studying the difference in albedo intensity between real faces and fake faces. Then the difference between real and spoofing faces can be effectively magnified and modeled by color texture features with the shallow convolutional network. The experimental results show that our proposed method consistently outperforms the state-of-the-art methods on adversarial faces and also achieves competitive performance on fake faces.
C1 [Dang, Chen; Xia, Zhaoqiang; Gao, Jie] Northwestern Polytech Univ, Sch Elect & Informat, 127 Youyi West Rd, Xian 710072, Shaanxi, Peoples R China.
   [Dai, Jing] China Acad Launch Vehicle Technol, 1 Nandahongmen Rd, Beijing 100076, Peoples R China.
   [Li, Lei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, 7366 Erhuan West Rd, Jinan 250014, Shandong, Peoples R China.
   [Feng, Xiaoyi] Northwestern Polytech Univ Shenzhen, Res & Dev Inst, 45 Gaoxinnanjiu Rd, Shenzhen 518057, Guangdong, Peoples R China.
C3 Northwestern Polytechnical University; Shandong University of Finance &
   Economics; Northwestern Polytechnical University
RP Xia, ZQ (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, 127 Youyi West Rd, Xian 710072, Shaanxi, Peoples R China.; Feng, XY (corresponding author), Northwestern Polytech Univ Shenzhen, Res & Dev Inst, 45 Gaoxinnanjiu Rd, Shenzhen 518057, Guangdong, Peoples R China.
EM cdang@mail.nwpu.edu.cn; zxia@nwpu.edu.cn; buaadaij@126.com;
   jie_gao@mail.nwpu.edu.cn; lilei@sdufe.edu.cn; fengxiao@nwpu.edu.cn
RI Xia, Zhaoqiang/AAC-4021-2019
OI Xia, Zhaoqiang/0000-0003-0630-3339
FU National Natural Science Foundation of China [62002199]; Natural Science
   Foundation of Shandong Province [ZR2020QF109]; Key Research and
   Development Program of Shaanxi [2021ZDLGY15-01, 2021ZDLGY09-04,
   2021GY-004]; Shenzhen Science and Techonlogy Program
   [GJHZ20200731095204013]
FX This work was supported by the National Natural Science Foundation of
   China (No. No.62002199), the Natural Science Foundation of Shandong
   Province (No.ZR2020QF109), the Key Research and Development Program of
   Shaanxi (Nos. 2021ZDLGY15-01, 2021ZDLGY09-04, and 2021GY-004), and
   Shenzhen Science and Techonlogy Program (No. GJHZ20200731095204013)
CR Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Arora G., 2019, SELFIE BIOMETRICS, P197, DOI [10.1007/978-3-030-26972-2_9, DOI 10.1007/978-3-030-26972-2_9]
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bisogni C, 2021, PATTERN RECOGN LETT, V147, P55, DOI 10.1016/j.patrec.2021.04.004
   Bobbia S, 2019, PATTERN RECOGN LETT, V124, P82, DOI 10.1016/j.patrec.2017.10.017
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Cai GR, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4641
   Chen D, 2019, COMM COM INF SC, V1143, P286, DOI 10.1007/978-3-030-36802-9_31
   Chingovska I., 2012, IEEE INT C BIOM SPEC
   Fang ML, 2022, IEEE WINT CONF APPL, P1131, DOI 10.1109/WACV51458.2022.00120
   Feng H, 2020, ARXIV
   George A, 2021, PROC CVPR IEEE, P7878, DOI 10.1109/CVPR46437.2021.00779
   Goodfellow I. J., 2014, ARXIV
   Hernandez-Ortega J., 2019, Handbook of Biometric Anti-Spoofing, P187
   Hernandez-Ortega Javier., 2018, P IEEE C COMP VIS PA, P544
   HINO K, 2020, IEEE C EVOL COMPUTAT, pNI177, DOI DOI 10.1109/cec48606.2020.9185634
   Inoue S., 2012, Jpn. Tappi J, V66, P879, DOI [10.2524/jtappij.66.879, DOI 10.2524/JTAPPIJ.66.879]
   Kurakin Alexey, 2017, INT C LEARN REPR
   Li L., 2018, arXiv
   Li L, 2020, NEUROCOMPUTING, V409, P191, DOI 10.1016/j.neucom.2020.05.017
   Lin B., 2019, P 2019 3 INT C BIOM, P61
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Luo Z, 2015, OPT PHOTONICS NEWS, V26, P19
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Mygdalis V, 2022, PATTERN RECOGN, V125, DOI 10.1016/j.patcog.2022.108527
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Perdana RN, 2021, IJITEE, V1
   Quan RJ, 2021, IEEE T IMAGE PROCESS, V30, P3946, DOI 10.1109/TIP.2021.3066912
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   SVAASAND LO, 1995, LASER MED SCI, V10, P55, DOI 10.1007/BF02133165
   Wang CY, 2022, PROC CVPR IEEE, P20249, DOI 10.1109/CVPR52688.2022.01964
   Wang SY, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120305
   Wang YH, 2021, IEEE T INF FOREN SEC, V16, P4280, DOI 10.1109/TIFS.2021.3102448
   Wang Z, 2018, ARXIV
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Xiong ZB, 2021, IEEE T VEH TECHNOL, V70, P2822, DOI 10.1109/TVT.2021.3061065
   Yu H, 2008, IEEE IMAGE PROC, P3140, DOI 10.1109/ICIP.2008.4712461
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Zeng XH, 2019, PROC CVPR IEEE, P4297, DOI 10.1109/CVPR.2019.00443
   ZHANG P, 2019, P IEEE CVF C COMP VI
   Zhang X, 2019, P 2019 3 INT C BIOM, P48
NR 45
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14503
EP 14520
DI 10.1007/s11042-023-15870-4
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001021028900002
DA 2024-07-18
ER

PT J
AU Singh, K
   Pandey, A
   Agarwal, A
   Agarwal, MK
   Shankar, A
   Parihar, AS
AF Singh, Kavinder
   Pandey, Ashutosh
   Agarwal, Akshat
   Agarwal, Mohit Kumar
   Shankar, Aditya
   Parihar, Anil Singh
TI FRN: Fusion and recalibration network for low-light image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light (LOL) image enhancement (LLIE); Deep learning-based network;
   Multi-exposure fusion; Multi-level feature extraction; Convolutional
   neural networks
ID MODEL
AB This paper proposes a Fusion and Recalibration Network (FRN) for low-light image enhancement. Firstly, The proposed method generates multi-exposure images from a single image to enhance low-light images. The proposed Feature Extraction Module (FEM) extracts multi-level features from an image. The proposed method uses Feature Augmentation Module (FAM), a U-net-like structure, to encode the multi-level features and assist in the reconstruction. The proposed Feature Fusion and Re-calibration Module (FFRM) re-calibrates and merges the features to provide an enhanced output image. The advantage of dynamically selecting features from extremely bright regions of the artificially darkened images and darker regions of the artificially brightened image results in a balanced output image. The proposed model was evaluated on various datasets and significantly outperformed most state-of-the-art techniques. Additionally, the experimental assessment shows that the proposed FRN model outperforms other quantitative and qualitative assessment approaches.
C1 [Singh, Kavinder; Pandey, Ashutosh; Agarwal, Akshat; Agarwal, Mohit Kumar; Shankar, Aditya; Parihar, Anil Singh] Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
C3 Delhi Technological University
RP Parihar, AS (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
EM parihar.anil@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bellamkonda S, 2023, COGN NEURODYNAMICS, V17, P985, DOI 10.1007/s11571-022-09879-y
   Bellamkonda S, 2020, INT J AMBIENT COMPUT, V11, P48, DOI 10.4018/IJACI.2020010103
   Bhat N., 2020, P 5 INT C COMM EL SY, P1390
   Bhowmik A, 2021, MULTIMED TOOLS APPL, V80, P28015, DOI 10.1007/s11042-021-10964-3
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P20547, DOI 10.1007/s11042-021-10753-y
   Chakraborty S, 2018, MULTIMED TOOLS APPL, V77, P20269, DOI 10.1007/s11042-018-5612-6
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Dehshibi MM., 2010, LPT EYE FEATURES LOC, P347
   Dehshibi MM, 2010, P IPCV, P270
   Goodfellow I. J., 2014, ARXIV
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   Hebbache L, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15051218
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jain G, 2022, IEEE T COGN DEV SYST, V14, P136, DOI 10.1109/TCDS.2020.3023055
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   KAUR J, 2022, MULTIMEDIA TOOLS, P1
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee S, 2018, IEEE ACCESS, V6, P49913, DOI 10.1109/ACCESS.2018.2868246
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P5805, DOI 10.1109/TIP.2020.2987133
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F., 2018, P BMVC, V220, P4
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   MirMashhouri A, 2022, MULTIMED TOOLS APPL, V81, P18935, DOI 10.1007/s11042-022-11966-5
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Moran Sean, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12823, DOI 10.1109/CVPR42600.2020.01284
   Pandey NN, 2022, MULTIMED TOOLS APPL, V81, P38175, DOI 10.1007/s11042-022-13150-1
   Parihar AS, 2022, VISUAL COMPUT, V38, P295, DOI 10.1007/s00371-020-02016-y
   Parihar AS, 2021, IET IMAGE PROCESS, V15, P1410, DOI 10.1049/ipr2.12114
   Parihar AS, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P823, DOI [10.1109/ICICCS48265.2020.9120999, 10.1109/iciccs48265.2020.9120999]
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Parihar AS, 2022, 2022 2 INT C INTELLI, P1, DOI [10.1109/CONIT55038.2022.9847710, DOI 10.1109/CONIT55038.2022.9847710]
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   Rohith G, 2021, VISUAL COMPUT, V37, P1965, DOI 10.1007/s00371-020-01957-8
   Sen Gupta S, 2021, IEEE T CONSUM ELECTR, V67, P119, DOI 10.1109/TCE.2021.3066431
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Kavinder, 2022, 2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N), P870, DOI 10.1109/ICAC3N56670.2022.10074393
   Singh Kavinder, 2022, 2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS), P1565, DOI 10.1109/ICICCS53718.2022.9788377
   Singh K, 2023, J VIS COMMUN IMAGE R
   Singh K, 2024, VISUAL COMPUT, V40, P121, DOI 10.1007/s00371-023-02770-9
   Singh K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103241
   Singh N, 2022, MULTIMED TOOLS APPL, V81, P38887, DOI 10.1007/s11042-022-13160-z
   Sivaiah B, 2023, SIGNAL IMAGE VIDEO P, V17, P1705, DOI 10.1007/s11760-022-02381-2
   Ulucan O, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107791
   Vaidwan N., 2021, 2021 INT C INT TECHN, P1, DOI [10.1109/CONIT51480.2021.9498550, DOI 10.1109/C0NIT51480.2021.9498550]
   Vishwakarma DK, 2019, VISUAL COMPUT, V35, P1595, DOI 10.1007/s00371-018-1560-4
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang Y., 2021, arXiv
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, ARXIV
   Xu H, 2021, IEEE T MULTIMEDIA
   Zhang Q, 2021, IEEE T MULTIMEDIA, V23, P189, DOI 10.1109/TMM.2020.2982045
   Zheng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4419, DOI 10.1109/ICCV48922.2021.00440
NR 66
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12235
EP 12252
DI 10.1007/s11042-023-15908-7
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000008
DA 2024-07-18
ER

PT J
AU Fu, JR
   Yan, LY
   Peng, YL
   Zheng, KP
   Gao, R
   Ling, HF
AF Fu, Jiarun
   Yan, Lingyu
   Peng, Yulin
   Zheng, KunPeng
   Gao, Rong
   Ling, HeFei
TI Low-light image enhancement base on brightness attention mechanism
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; Low-light image enhancement; Attention
   mechanism
AB With the development of the field of deep learning, image recognition, enhancement and other technologies have been widely used.However, dark lighting environments in reality, such as insufficient light at night, cause or block photographic images in low brightness, severe noise, and a large number of details are lost, resulting in a huge loss of image content and information, which hinders further analysis and use. Such problems not only exist in the traditional deep learning field, but also exist in criminal investigation, scientific photography and other fields, such as the accuracy of low-light image. However, in the current research results, there is no perfect means to deal with the above problems. Therefore, the study of low-light image enhancement has important theoretical significance and practical application value for the development of smart cities. In order to improve the quality of low-light enhanced images, this paper tries to introduce the luminance attention mechanism to improve the enhancement efficiency. The main contents of this paper are summarized as follows: using the attention mechanism, we proposed a method of low-light image enhancement based on the brightness attention mechanism and generative adversarial networks . This method uses brightness attention mechanism to predict the illumination distribution of low-light image and guides the enhancement network to enhance the image adaptiveness in different luminance regions. At the same time, u-NET network is designed and constructed to improve the modeling process of low-light image. We verified the performance of the algorithm on the synthetic data set and compared it with traditional image enhancement methods (HE, SRIE) and deep learning methods (DSLR). The experimental results show that our proposed network model has relatively good enhancement quality for low-light images, and improves the overall robustness, which has practical significance for solving the problem of low-light image enhancement.
C1 [Fu, Jiarun; Yan, Lingyu; Zheng, KunPeng; Gao, Rong] Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
   [Peng, Yulin] Hunan Prov Maternal & Child Hlth Care Hosp, Changsha, Peoples R China.
   [Ling, HeFei] Huazhong Univ Sci & Technol, Sch Comp Sci, Wuhan, Peoples R China.
C3 Hubei University of Technology; Huazhong University of Science &
   Technology
RP Yan, LY (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
EM yanlingyu@hbut.edu.cn
OI Peng, Yulin/0000-0002-1574-7241
FU National Natural Science Foundation [61502155, 61772180]
FX & nbsp;Project supported by the National Natural Science Foundation
   (61502155, 61772180);
CR Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Denton E, 2015, ADV NEUR IN, V28
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kumar A, 2015, PROCEDIA COMPUT SCI, V57, P1015, DOI 10.1016/j.procs.2015.07.512
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Li Huafeng, 2018, PATTERN RECOGN
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Yan L, 2021, MULTIMED TOOLS APPL, V1
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, 2019, RES POPULATION COUNT
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhang Z, 2017, STUDY WEATHER CLASSI
   Zhou Z, 2018, NEURAL COMPUT APPL
NR 23
TC 1
Z9 1
U1 9
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10341
EP 10365
DI 10.1007/s11042-023-15815-x
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600003
DA 2024-07-18
ER

PT J
AU Abd El-Nabi, S
   El-Shafai, W
   El-Rabaie, EM
   Ramadan, KF
   Abd El-Samie, FE
   Mohsen, S
AF Abd El-Nabi, Samy
   El-Shafai, Walid
   El-Rabaie, El-Sayed M.
   Ramadan, Khalil F.
   Abd El-Samie, Fathi E.
   Mohsen, Saeed
TI Machine learning and deep learning techniques for driver fatigue and
   drowsiness detection: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Drowsiness; Fatigue; Deep learning; Vehicle accidents; Yawning; Eye
   closure; Head movements; Facial expressions; Machine learning
ID MONITORING-SYSTEM; EEG; SLEEPINESS; PERFORMANCE; EXTRACTION; ALGORITHM;
   KNOWLEDGE; ALGEBRA; SCHEME; WHEEL
AB There are several factors for vehicle accidents during driving such as drivers' negligence, drowsiness, and fatigue. These accidents can be avoided, if drivers are warned in time. Moreover, recent developments in computer vision and artificial intelligence (AI) have helped to monitor drivers and alert them in case they are not concentrating on driving. The AI techniques can extract relevant features from expressions of driver's face, such as eye closure, yawning, and head movements to infer the level of sleepiness. In addition, they can acquire biological signals from the driver's body, and indications from the vehicle behavior. This paper provides a comprehensive review of the detection techniques of drowsiness and fatigue of drivers using machine learning (ML) and deep learning (DL). The current techniques for this application are classified into four categories: image- or video-based analysis during the driving, biological signal analysis for drivers, vehicle movement analysis, and hybrid techniques. A review of supervised techniques is presented for detecting fatigue and drowsiness on different datasets, with a comparison of the various techniques in terms of pros and cons. Results are presented in terms of accuracy of detection for each technique. The results are discussed according to the recent problems and challenges in this field. The paper also highlights the applicability and reliability of the different techniques. Furthermore, some suggestions are presented for the future work in the field of driver drowsiness detection (DDD).
C1 [Abd El-Nabi, Samy; El-Shafai, Walid; El-Rabaie, El-Sayed M.; Ramadan, Khalil F.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Abd El-Nabi, Samy; Mohsen, Saeed] King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, El Tor 46511, S Sinai, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
   [Mohsen, Saeed] Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; King Salman
   International University; Prince Sultan University; Princess Nourah bint
   Abdulrahman University
RP Abd El-Nabi, S (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.; Abd El-Nabi, S (corresponding author), King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, El Tor 46511, S Sinai, Egypt.
EM Sami.abdelnabi@ksiu.edu.eg
RI El-Shafai, Walid/AAG-4796-2021; Arjmandmanesh, Saba/AGA-7907-2022;
   Mohsen, Saeed/GQH-2016-2022
OI El-Shafai, Walid/0000-0001-7509-2120; Mohsen, Saeed/0000-0003-2863-0074
CR Abbas Q, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010056
   Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Adebisi OA, 2022, INTELL HEALTHCARE, P19, DOI DOI 10.1007/978-981-16-8150-9_2
   Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe S. A., 2022, ININTELLIGENTHEALTHC, P299, DOI [10.1007/978-981-16-8150-9_14, DOI 10.1007/978-981-16-8150-914, DOI 10.1007/978-981-16-8150-9_14]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Albadawi Y, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22052069
   Alharbey R, 2022, IEEE ACCESS, V10, P79403, DOI 10.1109/ACCESS.2022.3185251
   Alioua N, 2011, LECT NOTES COMPUT SC, V6855, P397, DOI 10.1007/978-3-642-23678-5_47
   Altameem A, 2021, IEEE ACCESS, V9, P162805, DOI 10.1109/ACCESS.2021.3131601
   [Anonymous], 2013, International Journal on Recent and Innovation Trends in Computing and Communication
   [Anonymous], 2019, VIDEO IMAGE DATABASE
   Anund A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064782
   Arachchige SNKK, 2022, THEOR ISS ERGON SCI, V23, P374, DOI 10.1080/1463922X.2021.1965670
   Arakawa T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237921
   Arefnezhad S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040943
   Awais M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17091991
   Baiasu Ana-Maria, 2021, International Journal of Circuits, Systems and Signal Processing, V15, P1, DOI 10.46300/9106.2021.15.1
   Bajaj Jaspreet Singh, 2022, ECS Transactions, V107, P4651, DOI 10.1149/10701.4651ecst
   Bajaj S., 2023, ICT ANAL APPL, P639, DOI [10.1007/978-981-19-5224-1_64, DOI 10.1007/978-981-19-5224-1_64]
   Balam VP, 2021, IET INTELL TRANSP SY, V15, P514, DOI 10.1049/itr2.12041
   Bamidele AA, 2019, INT J ADV COMPUT SC, V10, P549
   bankrate, US
   Barua S, 2019, EXPERT SYST APPL, V115, P121, DOI 10.1016/j.eswa.2018.07.054
   Beirness DJ, 2005, ROAD SAFETY MONITOR
   Bhatti Uzair Aslam, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P75, DOI 10.1007/978-981-16-7618-5_7
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Budak U, 2019, IEEE SENS J, V19, P7624, DOI 10.1109/JSEN.2019.2917850
   Castaneda Denisse, 2018, Int J Biosens Bioelectron, V4, P195, DOI 10.15406/ijbsbe.2018.04.00125
   Celecia A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154093
   Chaabene S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051734
   Chacon-Murguia MI, 2015, IEEE CONSUM ELECTR M, V4, P107, DOI 10.1109/MCE.2015.2463373
   Chai M, 2019, TRANSPORT RES D-TR E, V66, P95, DOI 10.1016/j.trd.2018.07.007
   Chang WJ, 2018, IEEE T CONSUM ELECTR, V64, P461, DOI 10.1109/TCE.2018.2872162
   Chaudhuri A, 2020, IEEE T INTELL TRANSP, V21, P185, DOI 10.1109/TITS.2018.2890332
   Chen JC, 2019, NEUROPSYCHOLOGIA, V129, P200, DOI 10.1016/j.neuropsychologia.2019.04.004
   Chi Yu Mike, 2010, IEEE Rev Biomed Eng, V3, P106, DOI 10.1109/RBME.2010.2084078
   Choi HS, 2019, IEEE ACCESS, V7, P146390, DOI 10.1109/ACCESS.2019.2946053
   Chowdhury RH, 2013, SENSORS-BASEL, V13, P12431, DOI 10.3390/s130912431
   Dasgupta A, 2019, IEEE T INTELL TRANSP, V20, P4045, DOI 10.1109/TITS.2018.2879609
   Medeiros PAD, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116073
   de Naurois CJ, 2019, ACCIDENT ANAL PREV, V126, P95, DOI 10.1016/j.aap.2017.11.038
   Deepa A., 2023, P INT C COGN INT COM, P679, DOI [10.1007/978-981-19-2358-6_61, DOI 10.1007/978-981-19-2358-6_61]
   Deng WH, 2019, IEEE ACCESS, V7, P118727, DOI 10.1109/ACCESS.2019.2936663
   Dong N, 2019, IEEE ACCESS, V7, P124702, DOI 10.1109/ACCESS.2019.2937914
   Dong YC, 2011, IEEE T INTELL TRANSP, V12, P596, DOI 10.1109/TITS.2010.2092770
   Dua M, 2021, NEURAL COMPUT APPL, V33, P3155, DOI 10.1007/s00521-020-05209-7
   Ed-Doughmi Y, 2020, J IMAGING, V6, DOI 10.3390/jimaging6030008
   El-Shafai W, 2022, CMC-COMPUT MATER CON, V70, P6107, DOI 10.32604/cmc.2022.020698
   Fors C, 2018, J TRANSP SAF SECUR, V10, P72, DOI 10.1080/19439962.2016.1228092
   Fouad IA, 2023, AIN SHAMS ENG J, V14, DOI 10.1016/j.asej.2022.101895
   Fu RR, 2014, INT J NEURAL SYST, V24, DOI 10.1142/S0129065714500063
   Fujiwara K, 2019, IEEE T BIO-MED ENG, V66, P1769, DOI 10.1109/TBME.2018.2879346
   Fusek R, 2018, LECT NOTES COMPUT SC, V11241, P433, DOI 10.1007/978-3-030-03801-4_38
   Ghoddoosian R, 2019, IEEE COMPUT SOC CONF, P178, DOI 10.1109/CVPRW.2019.00027
   github, DATA ARE AVAILABLE A
   Guede-Fernández F, 2019, IEEE ACCESS, V7, P81826, DOI 10.1109/ACCESS.2019.2924481
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   Gwak J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082890
   Hashemi M., 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00306-9
   Ichimaru Y, 1999, PSYCHIAT CLIN NEUROS, V53, P175, DOI 10.1046/j.1440-1819.1999.00527.x
   Islam M, 2022, MECH HYDROGELS, P1
   Jasim SS., 2022, J AL QADISIYAH COMPU, V14, P119
   Kaida K, 2006, CLIN NEUROPHYSIOL, V117, P1574, DOI 10.1016/j.clinph.2006.03.011
   Kashevnik A, 2020, IEEE SENS J, V20, P6701, DOI 10.1109/JSEN.2020.2975382
   Kemp B, 2000, IEEE T BIO-MED ENG, V47, P1185, DOI 10.1109/10.867928
   Kemp B, 2013, MCH WESTEINDE HOSP D
   Kemp B, Sleep-EDF database expanded
   Khan MT, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/2036818
   Khare SK, 2021, IEEE SENS J, V21, P6421, DOI 10.1109/JSEN.2020.3038440
   Khorovets A, 1999, INT J ADV NURS PRACT, V4
   Khunpisuth O, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P661, DOI 10.1109/SITIS.2016.110
   Khushaba RN, 2011, IEEE T BIO-MED ENG, V58, P121, DOI 10.1109/TBME.2010.2077291
   Kiashari SEH, 2020, MULTIMED TOOLS APPL, V79, P17793, DOI 10.1007/s11042-020-08696-x
   Knapik M, 2019, NEUROCOMPUTING, V338, P274, DOI 10.1016/j.neucom.2019.02.014
   Koh S, 2017, INT C CONTROL DECISI, P383, DOI 10.1109/CoDIT.2017.8102622
   Krishna GS, 2022, ARXIV
   Kumar JS, 2012, PROCEDIA ENGINEER, V38, P2525, DOI 10.1016/j.proeng.2012.06.298
   Kundinger T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041029
   Lee Boon Leng, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370355
   Lee BG, 2012, SENSORS-BASEL, V12, P17536, DOI 10.3390/s121217536
   Lee H, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020192
   Lee YH, 2019, INTELL AUTOM SOFT CO, V25, P205
   Lemkaddem A., 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P9, DOI 10.1109/BHI.2018.8333357
   Li G, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031100
   Li G, 2015, IEEE SENS J, V15, P7169, DOI 10.1109/JSEN.2015.2473679
   Li YG, 2020, CMC-COMPUT MATER CON, V63, P1575, DOI 10.32604/cmc.2020.07451
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030495
   Lin ShengTong., 2012, J. Vision, V12, P546, DOI DOI 10.1167/12.9.546
   Liu WH, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11050115
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lopez-Gordo MA, 2014, SENSORS-BASEL, V14, P12847, DOI 10.3390/s140712847
   Ma JQ, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P411, DOI 10.1109/SSCI.2015.68
   Magán E, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031145
   Manchanda TS., 2021, 2021 9 INT C RELIABI, P1
   Mårtensson H, 2019, IEEE T INTELL TRANSP, V20, P421, DOI 10.1109/TITS.2018.2814207
   Massoz Q., 2016, Applications of Computer Vision (WACV), P1
   McDonald AD., 2012, Sage Publications, V56, P2201, DOI [DOI 10.1177/1071181312561464, 10.1177/1071181312561464]
   Mehreen A, 2019, IEEE SENS J, V19, P5119, DOI 10.1109/JSEN.2019.2904222
   Mejía-Mejía E, 2020, FRONT PHYSIOL, V11, DOI 10.3389/fphys.2020.00779
   Min JL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188756
   Minhas AA, 2022, MULTIMED TOOLS APPL, V81, P26969, DOI 10.1007/s11042-022-13193-4
   Mittal A, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P903, DOI 10.1109/ICETECH.2016.7569378
   Miyaji Masahiro, 2014, International Journal of Information and Electronics Engineering, V4, P264, DOI 10.7763/IJIEE.2014.V4.445
   Mohsen S, 2022, SMART INNOV SYST TEC, V262, P304, DOI 10.1007/978-981-16-6128-0_29
   Mohsen S, 2021, IEEE ACCESS, V9, P150508, DOI 10.1109/ACCESS.2021.3125733
   Moujahid A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114334
   National Highway Traffic Safety Administration, DROWS DRIV
   National Sleep Foundation, DROWS DRIV
   Nordbakke S, 2007, TRANSPORT RES F-TRAF, V10, P1, DOI 10.1016/j.trf.2006.03.003
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Otmani S, 2005, PHYSIOL BEHAV, V84, P715, DOI 10.1016/j.physbeh.2005.02.021
   Ouabida E, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164102
   Pandey NN, 2022, MULTIMED TOOLS APPL, V81, P38175, DOI 10.1007/s11042-022-13150-1
   Pandey R., 2023, EMERGING TECHNOLOGIE, P25, DOI [10.1007/978-981-19-4193-1_3, DOI 10.1007/978-981-19-4193-1_3]
   Phanikrishna BV, 2021, J NEUROSCI METH, V347, DOI 10.1016/j.jneumeth.2020.108927
   Popieul JC, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P616, DOI 10.1109/IVS.2003.1212983
   Pratama BG, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON SCIENCE AND TECHNOLOGY - COMPUTER (ICST), P70, DOI 10.1109/ICSTC.2017.8011855
   pyimagesearch, ROSEBROCK EYEBLINK D
   Ramzan M, 2019, IEEE ACCESS, V7, P61904, DOI 10.1109/ACCESS.2019.2914373
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sahayadhas A, 2015, EXPERT SYST APPL, V42, P8669, DOI 10.1016/j.eswa.2015.07.021
   Saito Y, 2016, IEEE T HUM-MACH SYST, V46, P660, DOI 10.1109/THMS.2016.2549032
   Salvati L, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23020135
   Samiee S, 2014, SENSORS-BASEL, V14, P17832, DOI 10.3390/s140917832
   Saurav S, 2022, J REAL-TIME IMAGE PR, V19, P607, DOI 10.1007/s11554-022-01211-5
   Savas BK, 2021, DEEP LEARNING APPROA
   Shahid A., 2012, STOP, THAT and one hundred other sleep scales electronic resource
   Sikander G, 2019, IEEE T INTELL TRANSP, V20, P2339, DOI 10.1109/TITS.2018.2868499
   Singh PK, 2023, J MOBIL MULTIMED, P567
   Song FY, 2014, PATTERN RECOGN, V47, P2825, DOI 10.1016/j.patcog.2014.03.024
   Maior CBS, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113505
   Nguyen T, 2017, SCI REP-UK, V7, DOI 10.1038/srep43933
   Thomas FD., 2022, 813233 DOT HS NAT HI
   Wang J., 2011, Effectiveness of stability control systems for truck tractors
   Wang XS, 2016, ACCIDENT ANAL PREV, V95, P350, DOI 10.1016/j.aap.2015.09.002
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Wijnands JS, 2020, NEURAL COMPUT APPL, V32, P9731, DOI 10.1007/s00521-019-04506-0
   You F, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/8851485
   Yu J, 2019, IEEE T INTELL TRANSP, V20, P4206, DOI 10.1109/TITS.2018.2883823
   Zandi AS, 2019, TRANSPORT RES REC, V2673, P247, DOI 10.1177/0361198119847985
   Zhang C, 2019, IEEE ACCESS, V7, P11829, DOI 10.1109/ACCESS.2019.2891971
   Zhao HX, 2020, IEEE ACCESS, V8, P168087, DOI 10.1109/ACCESS.2020.3024070
   Zhao Z., 2020, COMPUT INTEL NEUROSC, V2020
   Zheng WL, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa5a98
   Zhou KY, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012051
NR 150
TC 5
Z9 5
U1 40
U2 96
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9441
EP 9477
DI 10.1007/s11042-023-15054-0
EA JUN 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000005
DA 2024-07-18
ER

PT J
AU He, YC
   Liang, ZX
   He, SC
   Wang, YH
   Yin, M
AF He, Yicheng
   Liang, Zixi
   He, Shaocong
   Wang, Yonghua
   Yin, Ming
TI Viewpoint guided multi-stream neural network for skeleton action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Skeletal data; Neural network; Virtual viewpoint;
   Multi-stream
ID DESCRIPTOR; FEATURES; LATENCY; POSE
AB Skeleton-based human action recognition has attracted considerable attention and succeeded in computer vision. However, one of the main challenges for skeleton action recognition is the complex viewpoint variations. Moreover, existing methods may be prone to develop the complicated networks with large model size. To this end, in this paper, we introduce a novel viewpoint-guided feature by adaptively selecting the optimal observation point to deal with the viewpoint variation problem. Furthermore, we present a novel multi-stream neural network for skeleton action recognition, namely Viewpoint Guided Multi-stream Neural Network (VGMNet). In particular, by incorporating four streams from spatial and temporal information, the proposed VGMNet can effectively learn the discriminative features of the skeleton sequence.We validate our method on three famous datasets, i.e., SHREC, NTU RGB+D, and Florence 3D. On SHREC, our proposed method has achieved better performance in terms of accuracy and efficiency against the state-of-the-art approaches. Furthermore, the highest scores on Florence 3D and NTU RGB+D show that our method is suitable for real application scenario with edge computing, and compatible to the case of multi-person action recognition.
C1 [He, Yicheng; Liang, Zixi; He, Shaocong; Yin, Ming] South China Normal Univ, Sch Semicond Sci & Technol, Foshan 528225, Peoples R China.
   [Wang, Yonghua; Yin, Ming] Guangdong Univ Technol, Sch Automation, Guangzhou 510006, Peoples R China.
C3 South China Normal University; Guangdong University of Technology
RP Yin, M (corresponding author), South China Normal Univ, Sch Semicond Sci & Technol, Foshan 528225, Peoples R China.; Yin, M (corresponding author), Guangdong Univ Technol, Sch Automation, Guangzhou 510006, Peoples R China.
EM yiming@gdut.edu.cn
RI Wang, Yonghua/F-7906-2017
OI Yin, Ming/0000-0002-7037-1048; He, Yicheng/0000-0003-3213-9907
FU National Natural Science Foundation of China [61876042]; Guangdong Basic
   and Applied Basic Research Foundation [2020A1515011493]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China Grant 61876042, and the Guangdong Basic and
   Applied Basic Research Foundation (No. 2020A1515011493).
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Ahad MAR, 2021, PATTERN RECOGN LETT, V145, P216, DOI 10.1016/j.patrec.2021.02.013
   Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934
   Caputo F.M., 2017, STAG, P9
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen XH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020239
   Cho S, 2020, IEEE WINT CONF APPL, P624, DOI [10.1109/wacv45572.2020.9093639, 10.1109/WACV45572.2020.9093639]
   De Smedt Q., 2017, 3DOR 10 EUR WORKSH 3, P1, DOI DOI 10.2312/3DOR.20171049
   De Smedt Q, 2016, IEEE COMPUT SOC CONF, P1206, DOI 10.1109/CVPRW.2016.153
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Devineau G, 2018, REC FORM IM APPR PER
   Ding YK, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P458, DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00095
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Feng JG, 2015, FRONT INFORM TECH EL, V16, P917, DOI 10.1631/FITEE.1500080
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Hinton G. E., 2012, 12070580 ARXIV
   Hou B, 2018, LECT NOTES COMPUT SC, V11070, P756, DOI 10.1007/978-3-030-00928-1_85
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Huang G, 2020, IEEE ACCESS, V8, P211869, DOI 10.1109/ACCESS.2020.3037238
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Kingma D. P., 2014, arXiv
   Li C.T., 2018, ARXIV
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li L, 2018, ARXIVHTTPARXIVORGABS, V1, P3
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Nakamura S., 2019, P ACM MULT AS, DOI [10.1145/3338533.3366569, DOI 10.1145/3338533.3366569]
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Pandey P, 2021, ENG SCI TECHNOL, V24, P1478, DOI 10.1016/j.jestch.2021.03.014
   Paoletti G, 2021, INT C PATT RECOG, P6035, DOI 10.1109/ICPR48806.2021.9412060
   Peng Wang, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings: LNCS 8645, P1, DOI 10.1007/978-3-319-10085-2_1
   Rao C, 2001, P 2001 IEEE COMP SOC
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shao ZP, 2013, IEEE INT CONF ROBOT, P4749, DOI 10.1109/ICRA.2013.6631253
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Singh I, 2020, IEEE IMAGE PROC, P1781, DOI [10.1109/icip40778.2020.9191034, 10.1109/ICIP40778.2020.9191034]
   Sun N, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104141
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xu B., 2015, ARXIV
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Zabrovskiy A, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P316, DOI 10.1109/BigMM50055.2020.00056
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhu GM, 2020, PATTERN RECOGN LETT, V135, P286, DOI 10.1016/j.patrec.2020.05.005
NR 54
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6783
EP 6802
DI 10.1007/s11042-023-15676-4
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700007
DA 2024-07-18
ER

PT J
AU Choudhary, V
   Tanwar, S
   Choudhury, T
AF Choudhary, Vandana
   Tanwar, Sarvesh
   Choudhury, Tanupriya
TI Evaluation of contemporary intrusion detection systems for internet of
   things environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intrusion Detection System (IDS); Internet of Things (IoT); Bibliometric
   Analysis; Convolutional Neural Network (CNN); Aquila Optimization (AO)
ID IOT; ANALYTICS
AB Internet of Things (IoT) involves wide-ranging devices connected through the Internet with an aim to enable coherent communication amongst them without human intervention to realize profuse smart applications which inherently makes our life a lot easier and furthermore productive. These connected devices continuously sense and gather information from surroundings, thereby producing an immense amount of data that cater for big data analytics. In the current era, number of smart devices are increasing rapidly due to the magnificent features they offer. Moreover, public access to the Internet makes the system even more vulnerable to intrusions. Catastrophically, this has fascinated numerous cybercriminals who have turned the IoT ecosystem into a hotbed of illicit activities. Thereupon, implication of Intrusion Detection System (IDS) in IoT is apparent. The literature suggests a number of IDS to address intrusions/attacks in the discipline of IoT. In the current paper, besides Systematic Literature Review of the IDS for IoT environment, a deep learning model with aquila optimization is proposed to predict anomaly using IoTID20, UNSW-NB15-1 and UNSW_2018_IoT_Botnet_Full5pc_4 datasets. The hybrid model that we have developed, uses a combined network structure of convolutional neural network and aquila optimization algorithm. In all of the studies that were carried out, the swarm intelligence-driven deep learning strategy outperformed other, comparable approaches. Based on current findings, it is reasonable to draw the conclusion that the suggested technique offers an efficient method for early anomaly detection and contributes to viable control of anomaly in the IoT environment.
C1 [Choudhary, Vandana; Tanwar, Sarvesh] Amity Univ, Amity Inst Informat Technol, Noida 201301, Uttar Pradesh, India.
   [Choudhury, Tanupriya] Univ Petr & Energy Studies, Sch Comp Sci, Informat Cluster, Dehra Dun 248007, Uttarakhand, India.
C3 Amity University Noida; University of Petroleum & Energy Studies (UPES)
RP Choudhary, V; Tanwar, S (corresponding author), Amity Univ, Amity Inst Informat Technol, Noida 201301, Uttar Pradesh, India.
EM vandana.choudhary@s.amity.edu; s.tanwar1521@gmail.com;
   tanupriya1986@gmail.com
OI Choudhury, Tanupriya/0000-0002-9826-2759; Tanwar,
   Sarvesh/0000-0003-0136-0182
CR Abu Al-Haija Q, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040556
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Abualigah L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113827
   Albawi S, 2017, I C ENG TECHNOL
   Ali MH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030494
   Alkahtani H, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5579851
   Alsulami AA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312336
   Amin SO, 2009, 2009 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT - WORKSHOPS, P269, DOI 10.1109/INMW.2009.5195973
   Anitha AA, 2021, INT J ADV COMPUT SC, V12, P499
   Benkhelifa E, 2018, IEEE COMMUN SURV TUT, V20, P3496, DOI 10.1109/COMST.2018.2844742
   Bhor Harsh Namdev, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P939, DOI 10.1109/ICOSEC49089.2020.9215365
   Bostani H, 2017, COMPUT COMMUN, V98, P52, DOI 10.1016/j.comcom.2016.12.001
   Chaabouni N, 2019, IEEE COMMUN SURV TUT, V21, P2671, DOI 10.1109/COMST.2019.2896380
   Creech G, 2014, IEEE T COMPUT, V63, P807, DOI 10.1109/TC.2013.13
   Disha RA, 2022, CYBERSECURITY, V5, DOI 10.1186/s42400-021-00103-8
   Fenanir S, 2020, ING NIERIE SYST MES, V25, P569, DOI DOI 10.18280/ISI.250503
   Gassais R, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00206-6
   Gyamfi E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103744
   Hajiheidari S, 2019, COMPUT NETW, V160, P165, DOI 10.1016/j.comnet.2019.05.014
   Hindy H, 2020, IEEE ACCESS, V8, P104650, DOI 10.1109/ACCESS.2020.3000179
   Javed SH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050742
   Khraisat A, 2021, CYBERSECURITY, V4, DOI 10.1186/s42400-021-00077-7
   Khraisat A, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111210
   Koroniotis N, 2020, ARXIV
   Koroniotis N., 2020, Designing an Effective Network Forensic Framework for the Investigation of Botnets in the Internet of Things
   Koroniotis N, 2020, IEEE ACCESS, V8, P209802, DOI 10.1109/ACCESS.2020.3036728
   Koroniotis N, 2020, FUTURE GENER COMP SY, V110, P91, DOI 10.1016/j.future.2020.03.042
   Koroniotis N, 2019, FUTURE GENER COMP SY, V100, P779, DOI 10.1016/j.future.2019.05.041
   Koroniotis N, 2018, L N INST COMP SCI SO, V235, P30, DOI 10.1007/978-3-319-90775-8_3
   Krishna E., 2021, Int. J. Intell. Eng. Syst, V14, P66
   Le A, 2016, INFORMATION, V7, DOI 10.3390/info7020025
   Le KH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040524
   Maciá-Pérez F, 2011, IEEE T IND ELECTRON, V58, P722, DOI 10.1109/TIE.2010.2052533
   Min EX, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4943509
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Moustafa N, 2019, IEEE T BIG DATA, V5, P481, DOI 10.1109/TBDATA.2017.2715166
   Moustafa N, 2017, DATA ANALYTIC, P127, DOI 10.1007/978-3-319-59439-2_5
   Moustafa N, 2016, INF SECUR J, V25, P18, DOI 10.1080/19393555.2015.1125974
   Nguyen DT, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/9173291
   Qaddoura R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092987
   Ramadan RA., 2020, ANN EMERGING TECHNOL, V4, P61, DOI DOI 10.33166/AETIC.2020.05.004
   Ribera EG, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11234041
   Saghezchi FB, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040602
   Saheed YK, 2022, ALEX ENG J, V61, P9395, DOI 10.1016/j.aej.2022.02.063
   Salcedo-Sanz S, 2016, PHYS REP, V655, P1, DOI 10.1016/j.physrep.2016.08.001
   Sandhya E., 2021, INT J INTELL ENG SYS, V14, P30
   Sarhan Mohanad, 2021, Big Data Technologies and Applications. 10th EAI International Conference, BDTA 2020, and 13th EAI International Conference on Wireless Internet, WiCON 2020. Virtual Event. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 371), P117, DOI 10.1007/978-3-030-72802-1_9
   Sedjelimaci H, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510811
   Sekar R., 2002, P 9 ACM C COMPUTER C, P265
   Sicato JCS, 2020, J INF PROCESS SYST, V16, P975
   Song Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134294
   Spadaccino P, 2020, ARXIV
   Syamsuddin I, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050737
   Tharewal S, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/9023719
   Ullah Imtiaz, 2020, Advances in Artificial Intelligence. 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12109), P508, DOI 10.1007/978-3-030-47358-7_52
   Ullah I, 2020, ADV ARTIFICIAL INTEL, P08
   Wang JP, 2015, PERS UBIQUIT COMPUT, V19, P1021, DOI 10.1007/s00779-015-0874-8
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Zarpelao BB, 2017, J NETW COMPUT APPL, V84, P25, DOI 10.1016/j.jnca.2017.02.009
NR 59
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7541
EP 7581
DI 10.1007/s11042-023-15918-5
EA JUN 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001005496300002
DA 2024-07-18
ER

PT J
AU Khunsongkiet, P
   Bootkrajang, J
   Techawut, C
AF Khunsongkiet, Piyavach
   Bootkrajang, Jakramate
   Techawut, Churee
TI Low-level feature image retrieval using representative images from
   minimum spanning tree clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image retrieval; Image clustering and merging; Representative image
   retrieval; Low-level visual feature; Patch arrangement vision; Region
   covariance matrix; Patch Relational Covariance Descriptor
AB Typical content-based image retrieval systems retrieve images based on comparison of low-level features such as images color, texture, and shapes of objects in the images. Further, the image covariance descriptor (CD) and the image Patch Relational Covariance Descriptor (PRCD) can be used to summarize low-level features and the visual arrangement to improve the precision of the retrieval. Nonetheless, comparing images based on those two descriptors is computationally expensive. Therefore, this research proposes a clustering method that dynamically groups database images using the Minimum Spanning Tree Clustering algorithm (MSTC). The technique is named Representative Images from Minimum Spanning Tree Clustering (RIMSTC). In the proposed technique, only the representative images selected from each cluster are compared with the input image . Experimental results demonstrated that the proposed representative images by COV and PRCD combined with RIMSTC helps to improve the retrieval time while maintaining comparable retrieval performance to existing methods.
C1 [Khunsongkiet, Piyavach; Bootkrajang, Jakramate; Techawut, Churee] Chiang Mai Univ, Dept Comp Sci, Chiang Mai 50200, Thailand.
C3 Chiang Mai University
RP Khunsongkiet, P (corresponding author), Chiang Mai Univ, Dept Comp Sci, Chiang Mai 50200, Thailand.
EM Piyavach_k@cmu.ac.th; churee.t@cmu.ac.th
OI Khunsongkiet, Piyavach/0000-0003-1270-3486
CR Anju J, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116070
   Bank D, 2020, AUTOENCODERS MACHINE
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cao Z, 2021, PATTERN RECOGN LETT, V142, P58, DOI 10.1016/j.patrec.2020.12.009
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen T, 2021, IEEE J BIOMED HLTH I
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Dokmanic I, 2015, IEEE SIGNAL PROC MAG, V32, P12, DOI 10.1109/MSP.2015.2398954
   Dupret G, 2013, J DISCRET ALGORITHMS, V18, P49, DOI 10.1016/j.jda.2012.10.002
   Faulkner H, 2015, STUDY REGION COVARIA
   Feng RW, 2021, IEEE J BIOMED HEALTH, V25, P3700, DOI 10.1109/JBHI.2020.3040269
   GRAHAM RL, 1985, ANN HIST COMPUT, V7, P43
   Kanagala HK, 2016, INT CONF COMP COMMUN
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Khunsongkiet P, 2020, PATCH RELATIONAL COV
   Kouchehbagh SM, 2012, COMM COM INF SC, V295, P262
   Krizaj J, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062388
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lindeberg T., 2012, SCHOLARPEDIA, V7, P10491, DOI [10.4249/scholarpedia.10491, DOI 10.4249/SCHOLARPEDIA.10491]
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2008, WHAT ARE HIGH LEVEL
   Nguyen-Quoc H, 2021, J SENSORS, V2021, DOI 10.1155/2021/6296505
   Pachghare Vinod, 2016, J INFORM TECHNOLOGY, V2, P13
   Panda S., 2019, International Journal of Computer Sciences and Engineering, V7, P538
   Patwary MJ A., 2015, Int. J. Comput. Appl, V132, P17, DOI [10.5120/ijca2015907704, DOI 10.5120/IJCA2015907704]
   PETERS G, 1970, SIAM J NUMER ANAL, V7, P479, DOI 10.1137/0707039
   PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x
   Rajinikanth V, 2021, INT J INTERACT MULTI, V7, P163, DOI 10.9781/ijimai.2021.11.008
   Rakesh C, 2015, DOCUMENT CLUSTERING
   Russakovsky O, 2015, Arxiv, DOI [arXiv:1409.0575, DOI 10.48550/ARXIV.1409.0575]
   Shikha B, 2020, INT J INTERACT MULTI, V6, P15, DOI 10.9781/ijimai.2020.01.002
   Sulic V., 2010, P 19 INT EL COMP SCI, P229
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Ulutagay G, 2008, FN DBSCAN NOVEL DENS
   Wu HL, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4992874
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Yang X, 2021, IEEE T CYBERNETICS, V51, P5773, DOI 10.1109/TCYB.2019.2959261
NR 40
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 7
PY 2023
DI 10.1007/s11042-023-15605-5
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I6WB4
UT WOS:001004157400004
DA 2024-07-18
ER

PT J
AU Parashar, S
   Mittal, N
   Mehta, P
AF Parashar, Sakshi
   Mittal, Namita
   Mehta, Parth
TI CASRank: A ranking algorithm for legal statute retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Legal information retrieval; Statute retrieval
ID INFORMATION-RETRIEVAL; RELEVANCE
AB Unlike the courts in western countries, legal documents of the Indian judiciary are unstructured, verbose, and noisy. In the justice system, statutes are written laws referred to by judges in support of judicial decisions. Retrieving relevant statutes for a given legal problem can be helpful to lawyers as well as the common man. Moreover, the dearth of publicly available annotated datasets of Indian legal documents limits the scope of legal analytics research. In this paper, we propose a ranking algorithm called CASRank to identify relevant statutes for a legal case query. We also develop a new dataset consisting of 858 Central Acts enacted by the Indian Parliament. Each Central Act is annotated with several attributes, like the act title, enactment date, act definition, chapters, sections, schedules, and footnotes. The first part of the experiment determines the best retrieval model suited for CASRank. The second set of experiments aims to identify the extent to which the attributes of the proposed Central Act dataset contribute towards the retrieval effectiveness of statutes. Experimental results show that the proposed approach obtains a MAP score of 0.0776 with a Precision@10 of 0.0420, showing a considerable increase in retrieval efficiency.
C1 [Parashar, Sakshi; Mittal, Namita] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Mehta, Parth] Parmonic AI, Atlanta, GA USA.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Parashar, S (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM parasharsakshi687@gmail.com; nmittal.cse@mnit.ac.in;
   parth.mehta126@gmail.com
RI Mittal, Namita/AAL-3336-2020; PARASHAR, NISHTHA/KRQ-7492-2024
OI Mittal, Namita/0000-0001-6886-9974; PARASHAR,
   NISHTHA/0000-0002-5689-1987; Parashar, Sakshi/0000-0003-1675-2103
CR Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416
   BELKIN NJ, 1995, INFORM PROCESS MANAG, V31, P431, DOI 10.1016/0306-4573(94)00057-A
   Bhattacharya P, 2019, ARXIV
   Bhattacharya P, 2019, FIRE CEUR, P1
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Das A, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3015467
   Farzindar A, 2004, 17 ANN C LEGAL KNOWL, P11
   Galgani Filippo, 2012, PRICAI 2012 TRENDS A, P40
   Géry M, 2012, KNOWL INF SYST, V32, P217, DOI 10.1007/s10115-011-0426-0
   Hachey B, 2006, ARTIF INTELL LAW, V14, P305, DOI 10.1007/s10506-007-9039-z
   Hliaoutakis A, 2006, INT J SEMANT WEB INF, V2, P55, DOI 10.4018/jswis.2006070104
   Jain D, 2020, ACM INT CONF PR SER, P41, DOI 10.1145/3441501.3441502
   Jain R, 2020, CEUR WORKSHOP P, V2826, P66
   Kanapala A, 2019, ARTIF INTELL REV, V51, P371, DOI 10.1007/s10462-017-9566-2
   Kim M.-Y., 2019, P 17 INT C ART INT L, P283
   Kim W, 2016, P 18 ANN INT C EL CO
   Lefoane M., 2019, CEUR Workshop Proceedings, P52
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Liu C-L, 2019, P 17 INT C ART INT L, P73, DOI [10.1145/3322640.3326715, DOI 10.1145/3322640.3326715]
   Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101
   Liu YH, 2015, INFORM PROCESS MANAG, V51, P194, DOI 10.1016/j.ipm.2014.07.003
   Lloret E, 2012, ARTIF INTELL REV, V37, P1, DOI 10.1007/s10462-011-9216-z
   LOVINS JB, 1968, MECH TRANSL, V11, P22
   Mandal A, 2017, CEUR WORKSHOP P, V2036, P63
   Merchant K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1803, DOI 10.1109/ICACCI.2018.8554831
   Moens M-F, 2005, P 10 INT C ARTIFICIA, P141
   More R., 2019, P CEUR WORKSH P DEC, P13
   Oard DW, 2010, ARTIF INTELL LAW, V18, P347, DOI 10.1007/s10506-010-9093-9
   Parashar Sakshi, 2021, Zenodo, DOI 10.5281/ZENODO.5088102
   Parikh V., 2021, arXiv
   Polsley Seth, 2016, P COLING SYST DEM, P258
   Rabelo J, 2020, LECT NOTES ARTIF INT, V12331, P34, DOI 10.1007/978-3-030-58790-1_3
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Saravanan M, 2006, FRONT ARTIF INTEL AP, V152, P51
   Shao Y, 2019, CEUR WORKSHOP P, V2517, P46
   Teufel S, 2002, COMPUT LINGUIST, V28, P409, DOI 10.1162/089120102762671936
   Thenmozhi D., 2017, FIRE (working notes), P90
   Trappey CV, 2020, WORLD PAT INF, V62, DOI 10.1016/j.wpi.2020.101980
   Turtle H., 1995, Artificial Intelligence and Law, V3, P5, DOI 10.1007/BF00877694
   van Opijnen M, 2017, ARTIF INTELL LAW, V25, P65, DOI 10.1007/s10506-017-9195-8
   Wang T, 2016, APPL INTELL, V45, P127, DOI 10.1007/s10489-015-0747-x
   Wu HC, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361686
   Yu Zhang, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166999
   Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066
   Zhao Zicheng, 2019, Working Notes of FIRE 2019, V2517, P40
NR 46
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 2
PY 2023
DI 10.1007/s11042-023-15464-0
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0KI8
UT WOS:000999746300001
DA 2024-07-18
ER

PT J
AU Elbedwehy, S
   Medhat, T
   Hamza, T
   Alrahmawy, MF
AF Elbedwehy, Samar
   Medhat, T.
   Hamza, Taher
   Alrahmawy, Mohammed F.
TI Enhanced descriptive captioning model for histopathological patches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image captioning; Medical-images; Word-embedding; Concatenation;
   Transformer
ID IMAGE; NETWORK
AB The interpretation of medical images into a natural language is a developing field of artificial intelligence (AI) called image captioning. This field integrates two branches of artificial intelligence which are computer vision and natural language processing. This is a challenging topic that goes beyond object recognition, segmentation, and classification since it demands an understanding of the relationships between various components in an image and how these objects function as visual representations. The content-based image retrieval (CBIR) uses an image captioning model to generate captions for the user query image. The common architecture of medical image captioning systems consists mainly of an image feature extractor subsystem followed by a caption generation lingual subsystem. We aim in this paper to build an optimized model for histopathological captions of stomach adenocarcinoma endoscopic biopsy specimens. For the image feature extraction subsystem, we did two evaluations; first, we tested 5 different vision models (VGG, ResNet, PVT, SWIN-Large, and ConvNEXT-Large) using (LSTM, RNN, and bidirectional-RNN) and then compare the vision models with (LSTM-without augmentation, LSTM-with augmentation and BioLinkBERT-Large as an embedding layer-with augmentation) to find the accurate one. Second, we tested 3 different concatenations of pairs of vision models (SWIN-Large, PVT_v2_b5, and ConvNEXT-Large) to get among them the most expressive extracted feature vector of the image. For the caption generation lingual subsystem, we tested a pre-trained language embedding model which is BioLinkBERT-Large compared to LSTM in both evaluations, to select from them the most accurate model. Our experiments showed that building a captioning system that uses a concatenation of the two models ConvNEXT-Large and PVT_v2_b5 as an image feature extractor, combined with the BioLinkBERT-Large language embedding model produces the best results among the other combinations.
C1 [Elbedwehy, Samar] Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Data Sci, Kafr Al Sheikh, Egypt.
   [Elbedwehy, Samar; Hamza, Taher; Alrahmawy, Mohammed F.] Mansoura Univ, Fac Comp & Informat Sci, Dept Comp Sci, Mansoura, Egypt.
   [Medhat, T.] Kafrelsheikh Univ, Fac Engn, Dept Elect Engn, Kafr Al Sheikh, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge Bank
   (EKB); Kafrelsheikh University
RP Elbedwehy, S (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Data Sci, Kafr Al Sheikh, Egypt.; Elbedwehy, S (corresponding author), Mansoura Univ, Fac Comp & Informat Sci, Dept Comp Sci, Mansoura, Egypt.
EM samarelbedwehy@ai.kfs.edu.eg
RI Medhat, Tamer/E-1516-2013
OI Medhat, Tamer/0000-0002-2468-3438; Elbedwehy, Samar/0000-0002-2187-0174
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR [Anonymous], NETR VIS NEUR NETW D
   Atliha V, 2021, 2021 IEEE OP C EL EL, P1
   Chen B., 2022, CVPR, P4815
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova Polina, 2012, Association for Computational Linguistics
   Lin M, 2014, 2 INT C LEARN REPRES, P1
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Ma Edward, 2019, NLP Augmentation
   Mao JH, 2015, Arxiv, DOI arXiv:1412.6632
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Saad W, 2022, J AMB INTEL HUM COMP, V13, P2025, DOI 10.1007/s12652-021-02967-7
   Shah Ashita, 2022, Soft Computing and Signal Processing: Proceedings of 3rd ICSCSP 2020. Advances in Intelligent Systems and Computing, P553, DOI 10.1007/978-981-16-1249-7_52
   Shin HC, 2016, J MACH LEARN RES, V17
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Song JQ, 2021, OPT EXPRESS, V29, P22732, DOI 10.1364/OE.430508
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tarjan Balazs, 2019, Statistical Language and Speech Processing. 7th International Conference, SLSP 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11816), P223, DOI 10.1007/978-3-030-31372-2_19
   Tsuneki M, 2022, Arxiv, DOI arXiv:2202.03432
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang SW, 2019, IEEE ACCESS, V7, P66680, DOI 10.1109/ACCESS.2019.2917979
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wu LH, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P515, DOI 10.1109/SPAC.2017.8304332
   Xiao XY, 2019, IEEE T MULTIMEDIA, V21, P2942, DOI 10.1109/TMM.2019.2915033
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yasunaga Michihiro, 2022, arXiv
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu FX, 2021, Arxiv, DOI arXiv:1911.07158
   Yuan ZH, 2020, IEEE ACCESS, V8, P2608, DOI 10.1109/ACCESS.2019.2962195
   Zakraoui J, 2019, IEEE ACCESS, V7, P18772, DOI 10.1109/ACCESS.2019.2896713
NR 39
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15884-y
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, T
   Sinha, A
   Singh, S
   Vyas, OP
   Kumar, M
AF Singh, Tinku
   Sinha, Ayush
   Singh, Satakshi
   Vyas, O. P.
   Kumar, Manish
TI Distributed hyperparameter optimization based multivariate time series
   forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recurrent neural network; Information retrieval; LSTM; HMM;
   Hyperparameter optimization
ID ELECTRICITY PRICE; NEURAL-NETWORKS; ALGORITHM
AB Various domains generate continuous data in the form of multivariate time series (MTS), including electricity and stock trading. It is difficult to maintain a low variance in forecasting error while forecasting multi-step MTS. Deep learning models can forecast large and complex multivariate time series with high accuracy, but simulating the hyperparameters for a model to achieve high accuracy is time-consuming. Figuring out the appropriate hyperparameters becomes increasingly stagnant and resource-intensive as the dataset size increases. In this study, we propose a distributed random parameter optimization model to deal with short-term multivariate time series forecasting problems. It utilizes the deep neural network for forecasting in synchronization with the hyperparameter tuning optimization in a distributed manner to exploit the resources and speed up the computation. The proposed model has been validated against a real-world multivariate dataset of electricity consumption and weather conditions for the Canadian province of Ontario from 2010 to 2019. Extensive experiments on the Ontario region demonstrate that the proposed model is scalable and outperforms traditional models such as vector autoregression(VAR), Multilayer Perceptron(MLP), Hidden Markov Model (HMM), and Long Short Term Memory (LSTM). Furthermore, the model outperformed all others in terms of accuracy on a benchmark Spanish electricity dataset.
C1 [Singh, Tinku; Sinha, Ayush; Vyas, O. P.; Kumar, Manish] Indian Inst Informat Technol Allahabad, Dept IT, Prayagraj, Uttar Pradesh, India.
   [Singh, Satakshi] SHAUTS, Dept Maths, Prayagraj, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Singh, T (corresponding author), Indian Inst Informat Technol Allahabad, Dept IT, Prayagraj, Uttar Pradesh, India.
EM tinkuinbox@gmail.com; pro.ayush@iiita.ac.in; satakshi@shiats.edu.in;
   opvyas@iiita.ac.in; manish@iiita.ac.in
OI Singh, Tinku/0000-0002-9146-8682
CR Bakir Houda, 2018, International Journal of Machine Learning and Computing, V8, P169, DOI 10.18178/ijmlc.2018.8.2.682
   BAKIRTZIS AG, 1995, IEEE T POWER SYST, V10, P1518, DOI 10.1109/59.466494
   Bellman RE., 2015, ADAPTIVE CONTROL PRO, P2045
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Box G. E. P., 1970, Time series analysis, forecasting and control
   Chang ZH, 2018, INT CONF SOFTW ENG, P245, DOI 10.1109/ICSESS.2018.8663710
   Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679
   Chen Z., 2016, 2016 IEEE 24 INT C N, P1
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571
   Choi HyeongKyu., 2018, Stock price correlation coefficient prediction with arima-lstm hybrid model
   Ky DX, 2018, INT J APPL MATH STAT, V57, P1
   Deleforge A, 2015, INT J NEURAL SYST, V25, DOI 10.1142/S0129065714400036
   Donnarumma F, 2015, INT J NEURAL SYST, V25, DOI 10.1142/S0129065715500173
   Dore MHI, 2003, NAT HAZARDS, V28, P249, DOI 10.1023/A:1022978024522
   Durrett R., 2019, Cambridge Series in Statistical and Probabilistic Mathematics, DOI DOI 10.1017/9781108591034
   Hahmann M., 2019, DATENBANK SPEKTRUM, V19, P17, DOI [10.1007/s13222-018-00304-5, DOI 10.1007/S13222-018-00304-5]
   HEINEMANN GT, 1966, IEEE T POWER AP SYST, VPA85, P1144, DOI 10.1109/TPAS.1966.291535
   Hippert HS, 2001, IEEE T POWER SYST, V16, P44, DOI 10.1109/59.910780
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jahan I., 2018, MIDW INSTR COMP S 20
   Kandil MS, 2002, IEEE T POWER SYST, V17, P491, DOI 10.1109/TPWRS.2002.1007923
   Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329, DOI 10.1109/72.548162
   Liu T., 2010, Mod. Appl. Sci, V4, P162, DOI [10.5539/mas.v4n5p162, DOI 10.5539/MAS.V4N5P162]
   Livingstone DJ, 1997, J COMPUT AID MOL DES, V11, P135, DOI 10.1023/A:1008074223811
   Lutkepohl H., 2013, Introduction to multiple time series analysis
   Mandal P, 2010, INT J ENERG RES, V34, P507, DOI 10.1002/er.1569
   Nieto FH, 2016, STAT SINICA, V26, P1389, DOI 10.5705/ss.2014.184t
   official website of the Government of Canada T, 2020, HIST CLIM DAT
   OMIE T.n.e.m.o, 2020, DAY AHEAD MARK HOURL
   Operator IES, 2020, HOURL ONT EN PRIC HO
   Selvin S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1643, DOI 10.1109/ICACCI.2017.8126078
   Shahidehpour M., 2002, MARKET OPERATIONS EL
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shi SH, 2016, INT C CLOUD COMP BIG, P99, DOI [10.1109/CCBD.2016.029, 10.1109/CCBD.2016.33]
   Talavera-Llames R, 2019, NEUROCOMPUTING, V353, P56, DOI 10.1016/j.neucom.2018.07.092
   Weron R, 2014, INT J FORECASTING, V30, P1030, DOI 10.1016/j.ijforecast.2014.08.008
   Xiao H, 2020, RES SOC ADMIN PHARM, V16, P1095, DOI 10.1016/j.sapharm.2019.11.009
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zaharia Matei, 2012, Proceedings of the 9th USENIX Conference on Networked Systems Design and Implementation, NSDI'12, P1, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Zeinali Y, 2017, INTEGR COMPUT-AID E, V24, P105, DOI 10.3233/ICA-170540
   Zheng J, 2017, 2017 51ST ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)
NR 41
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15456-0
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700007
DA 2024-07-18
ER

PT J
AU Meriem, F
   Messaoud, B
   Bahia, YZ
AF Meriem, Fedila
   Messaoud, Bengherabi
   Bahia, Yahya-zoubir
TI Texture analysis of edge mapped audio spectrogram for spoofing attack
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anti-spoofing; Spectrogram; Edge mapped spectrogram; Texture
   descriptors; Automatic speaker verification
ID SPEAKER VERIFICATION; CEPSTRAL COEFFICIENTS; COUNTERMEASURES;
   RECOGNITION; PHASE
AB The vulnerability of the Automatic Speaker verification technology to different presentation attacks has drawn much interest to design anti-spoofing countermeasures. Following their success in face anti-spoofing, some techniques based on texture analysis were cross-pollinated recently to the voice anti-spoofing domain with very promising results. In this same research direction and motivated by the fact that the spectrogram image local gradient amplitude is sensitive to image distortions presented by spoof attacks, a novel voice anti-spoofing countermeasure based on texture analysis of spectrogram image is devised in this paper. The main novelty of the proposed approach resides in the use of edge detection techniques applied to the spectrogram image. The recorded speech was initially converted to a 2-D image. Then, the spectrogram is mapped by the use of the edge detection method. Finally, different texture descriptors are used to extract the visual features from the original and the mapped spectrograms combination. Experimental results on the ASVspoof 2017 v2.0 dataset show that the proposed countermeasure clearly outperforms some well-known techniques, providing an Equal-Error Rate (EER) as low as 3.52% and 22.86% for the development and evaluation sets, respectively. For the ASVspoof 2019 dataset, in turn, the proposed method achieves up to 27.62% and 29.15% relative EER improvement over the baseline CQCC feature in the Logical and Physical Access scenarios, respectively. In addition, the results show that the proposed hand-crafted features-based approach with an SVM classifier can deliver superior performance than more sophisticated solutions that rely upon the complex neural network architecture.
C1 [Meriem, Fedila; Messaoud, Bengherabi; Bahia, Yahya-zoubir] Ctr Dev Technol Avancees CDTA, POB 17 Baba Hassen, Algiers 16303, Algeria.
C3 Centre for the Development of Advanced Technologies (CDTA)
RP Meriem, F (corresponding author), Ctr Dev Technol Avancees CDTA, POB 17 Baba Hassen, Algiers 16303, Algeria.
EM mfedila@cdta.dz; mbengherabi@cdta.dz; byahyazoubir@cdta.dz
OI bengherabi, messaoud/0000-0001-8679-2093
FU DGRSDT (Direction Generale de la Recherche Scientifique et du
   Developpement Technologique); CDTA (Centre de Developpement des
   Technologies Avancees) Algeria [N004-1/BIOSMC/DTELECOM/CDTA/PT 19-21]
FX This work is financially supported by the DGRSDT (Direction Generale de
   la Recherche Scientifique et du Developpement Technologique) and CDTA
   (Centre de Developpement des Technologies Avancees) Algeria, as part of
   the CDTA's triennial research protocol 2019-2021. (Project code:
   N004-1/BIOSMC/DTELECOM/CDTA/PT 19-21)
CR Adiban M, 2020, COMPUT SPEECH LANG, V64, DOI 10.1016/j.csl.2020.101105
   Al-karawi KA, 2021, MULTIMED TOOLS APPL, V80, P22231, DOI 10.1007/s11042-021-10767-6
   Alegre F, 2013, INTERSPEECH 2013 14, P5
   Alegre F, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Alzantot M, 2019, ARXIV
   Avila AR, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101163
   Bakar B, 2018, IEEE W SP LANG TECH, P132, DOI 10.1109/SLT.2018.8639511
   Bhargav KVJ, 2023, MATER MANUF PROCESS, V38, P271, DOI 10.1080/10426914.2022.2072879
   Biagio MS, 2013, IEEE I CONF COMP VIS, P809, DOI 10.1109/ICCV.2013.105
   Boashash B, 2003, TIME FREQUENCY SIGNAL ANALYSIS AND PROCESSING: A COMPREHENSIVE REFERENCE, P627
   BROWN JC, 1991, J ACOUST SOC AM, V89, P425, DOI 10.1121/1.400476
   BROWN JC, 1992, J ACOUST SOC AM, V92, P2698, DOI 10.1121/1.404385
   Brown J, 2017, IEEE INT CON INF VIS, P29, DOI 10.1109/iV.2017.52
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Burger W., 2009, Principles of Digital Image Processing, V111
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SY, 2019, INTERSPEECH, P1063, DOI 10.21437/Interspeech.2019-2014
   Chen ZX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2052, DOI 10.1109/ICASSP.2018.8462644
   Cheng XL, 2019, ASIAPAC SIGN INFO PR, P540, DOI [10.1109/apsipaasc47483.2019.9023158, 10.1109/APSIPAASC47483.2019.9023158]
   Chettri B, 2018, ARXIV
   Chettri B, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101092
   DEHAK N, 2010, ODYSSEY, P15
   Delgado H, 2018, OD 2018 SPEAK LANG R
   Evans N, 2013, INTERSPEECH, P925
   Fedila M, 2018, MULTIMED TOOLS APPL, V77, P16721, DOI 10.1007/s11042-017-5237-1
   Fedila M., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P1034, DOI 10.1109/ISSPA.2012.6310441
   Fedila M, 2012, 2012 24 INT C MICR I, P1
   Fitzgerald D., 2010, Proc. of the International Conference on Digital Audio Effects, P10
   Gonzalez-Soler L J, 2020, 2020 IEEE INT WORKSH, P1
   Gupta P, 2022, COMPUT SPEECH LANG
   Hanilçi C, 2018, DIGIT SIGNAL PROCESS, V72, P171, DOI 10.1016/j.dsp.2017.10.010
   Jung J, 2019, ARXIV
   Kamble MR, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101140
   Kanagasundaram A, 2014, COMPUT SPEECH LANG, V28, P121, DOI 10.1016/j.csl.2013.04.002
   Kannala J, 2012, INT C PATT RECOG, P1363
   Khoury E, 2014, INT CONF ACOUST SPEE
   Kinnunen T, 2018, ARXIV
   Kinnunen T, 2017, INT CONF ACOUST SPEE, P5395, DOI 10.1109/ICASSP.2017.7953187
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Krobba A, 2020, MULTIMED TOOLS APPL, V79, P18679, DOI 10.1007/s11042-020-08748-2
   Lai CH, 2019, ARXIV
   Lai CI, 2019, INT CONF ACOUST SPEE, P6316, DOI 10.1109/ICASSP.2019.8682640
   Lavrentyeva G, 2017, INTERSPEECH, P82, DOI 10.21437/Interspeech.2017-360
   Li JL, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103256
   Li RJ, 2019, INTERSPEECH, P1048, DOI 10.21437/Interspeech.2019-1698
   Liu M, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101161
   Liu Yuzong, 2015, 16 ANN C INT SPEECH
   Maini R., 2009, Int J Image Process, V3, P1
   Martin A., 1997, Eurospeech
   Monteiro J, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101096
   Nagarsheth P, 2017, INTERSPEECH, P97, DOI 10.21437/Interspeech.2017-1377
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Patel TB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2062
   Patil AT, 2022, COMPUT SPEECH LANG, V72, DOI 10.1016/j.csl.2021.101281
   Patil AT, 2019, INTERSPEECH, P2898, DOI 10.21437/Interspeech.2019-2742
   Rahmeni R, 2022, MULTIMED TOOLS APPL, V81, P31443, DOI 10.1007/s11042-022-12606-8
   Rakotomamonjy A, 2015, IEEE-ACM T AUDIO SPE, V23, P142, DOI 10.1109/TASLP.2014.2375575
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Rose P, 2006, COMPUT SPEECH LANG, V20, P159, DOI 10.1016/j.csl.2005.07.003
   Schlüter R, 2007, INT CONF ACOUST SPEE, P649
   Schorkhuber C, 2014, AUD ENG SOC C 53 INT
   Singh M, 2019, AEU-INT J ELECTRON C, V110, DOI 10.1016/j.aeue.2019.152837
   Snyder David, 2018, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5329, DOI 10.1109/ICASSP.2018.8461375
   Solomon C., 2011, Fundamentals of Digital Image Processing: A Practical Approach with Examples in MATLAB, V1st ed.
   Spoofing A S V, 2019, COUNT CHALL EV PLAN
   Sriskandaraja K, 2018, INTERSPEECH, P671, DOI 10.21437/Interspeech.2018-1819
   Standard I, 2017, INFORM TECHNOLOGY BI
   Tapkir PA, 2018, ASIAPAC SIGN INFO PR, P1019, DOI 10.23919/APSIPA.2018.8659582
   Todisco M., 2016, P SPEAK LANG REC WOR, V25, P249, DOI DOI 10.21437/ODYSSEY.2016-41
   Todisco M., 2019, ARXIV
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wang XL, 2017, INTERSPEECH, P32, DOI 10.21437/Interspeech.2017-304
   Wang X, 2020, COMPUT SPEECH LANG, V64, DOI [10.1016/j.csl.2020.101114, 10.1016/j.csi.2020.101114]
   Wei LQ, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020274
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2037
   Wu ZZ, 2016, MULTIMED TOOLS APPL, V75, P5311, DOI 10.1007/s11042-015-3080-9
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Yang JC, 2020, DIGIT SIGNAL PROCESS, V97, DOI 10.1016/j.dsp.2019.102622
   Yang JC, 2019, IEEE-ACM T AUDIO SPE, V27, P2373, DOI 10.1109/TASLP.2019.2946897
   Yang JC, 2019, DIGIT SIGNAL PROCESS, V89, P30, DOI 10.1016/j.dsp.2019.02.018
   Zhang CL, 2017, IEEE J-STSP, V11, P684, DOI 10.1109/JSTSP.2016.2647199
   Zhang CL, 2016, INT CONF ACOUST SPEE, P5035, DOI 10.1109/ICASSP.2016.7472636
   Zhao YJ, 2020, COMPUT SPEECH LANG, V64, DOI 10.1016/j.csl.2020.101115
NR 85
TC 3
Z9 3
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15915
EP 15937
DI 10.1007/s11042-023-15329-6
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:000995280400006
DA 2024-07-18
ER

PT J
AU Fawzy, S
   Moustafa, HE
   AbdelHay, EH
   Ata, MM
AF Fawzy, Shimaa
   Moustafa, Hossam El-Din
   AbdelHay, Ehab H. H.
   Ata, Mohamed Maher
TI Proposed optimized active contour based approach for accurately skin
   lesion segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Benign; Active contour; Malignant; Segmentation; Optimization;
   Dermoscopy image
ID IMAGE SEGMENTATION; FEATURE-EXTRACTION; RECOGNITION
AB The presented work suggests a robust approach for skin lesion segmentation in the state of the art of optimized active contours and level sets according to the estimation of both restriction and energy forces. The proposed system would separate accurately the interest region by defining the appropriate contour or curvature. Accordingly, the following optimizers have been utilized and tested; particle swarm optimization (PSO), genetic algorithm (GA), grey wolf optimization (GWO), whale optimization algorithm (WOA), bee colony optimization (BCO), and interior-point optimization (IPO) for optimizing the suggested trigonometric regularization functions. Experimental findings have recommended the use of the proposed Sine-IPO algorithm which targeting the best-segmentation of different types of skin lesions in dermoscopy images. In addition, different performance metrics have been utilized; true positive (TP), true negative (TN), false positive (FP), and false-negative (FN) in order to guarantee the appropriate segmentation accuracy. The results depicted the superiority of using IPO based Sine function with accuracy (about 96.23%), sensitivity (about 66.48%), specificity (about 99.45%), dice coefficient (DC) (about 67.43%), and Jaccard coefficient (JAC) (about 53.63%).
C1 [Fawzy, Shimaa; Moustafa, Hossam El-Din; AbdelHay, Ehab H. H.] Mansoura Univ, Fac Engn, Dept Elect & Commun Engn, Mansoura 35516, Egypt.
   [Ata, Mohamed Maher] MISR Higher Inst Engn & Technol, Dept Commun & Elect Engn, Mansoura 35516, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University
RP Ata, MM (corresponding author), MISR Higher Inst Engn & Technol, Dept Commun & Elect Engn, Mansoura 35516, Egypt.
EM mmaher844@yahoo.com
RI Moustafa, Hossam El-Din/AAK-8256-2020; Ata, Mohamed/J-6403-2017
OI Moustafa, Hossam El-Din/0000-0002-8242-942X; Ata,
   Mohamed/0000-0003-4151-9717
CR Abbes W, 2017, PROCEDIA COMPUT SCI, V112, P2096, DOI 10.1016/j.procs.2017.08.226
   Abdullah AS, 2020, MED BIOL ENG COMPUT, V58, P25, DOI 10.1007/s11517-019-02032-8
   Afza F, 2019, MICROSC RES TECHNIQ, V82, P1471, DOI 10.1002/jemt.23301
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Albahli S, 2020, IEEE ACCESS, V8, P198403, DOI 10.1109/ACCESS.2020.3035345
   Arora G, 2022, NEURAL COMPUT APPL, V34, P8385, DOI 10.1007/s00521-020-05212-y
   Astorino A, 2020, INTERDISCIP SCI, V12, P24, DOI 10.1007/s12539-019-00341-y
   Bansal N., 2020, Int J Appl Eng Res, V15, P1116, DOI DOI 10.37622/IJAER/15.12.2020.1116-1121
   Bayraktar M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2625-8
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Eelbode T, 2020, IEEE T MED IMAGING, V39, P3679, DOI 10.1109/TMI.2020.3002417
   El-Khatib H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061753
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Fang LL, 2022, SIGNAL IMAGE VIDEO P, V16, P193, DOI 10.1007/s11760-021-01979-2
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Garg G, 2021, MULTIMED TOOLS APPL, V80, P30557, DOI 10.1007/s11042-021-11133-2
   Garg S, 2021, MULTIMED TOOLS APPL, V80, P7397, DOI 10.1007/s11042-020-10064-8
   Geng N, 2021, COMPLEX INTELL SYST, V7, P873, DOI 10.1007/s40747-020-00252-2
   Goyal M, 2020, IEEE ACCESS, V8, P4171, DOI 10.1109/ACCESS.2019.2960504
   Hosseinzadeh H, 2020, EVOL SYST-GER, V11, P589, DOI 10.1007/s12530-018-9258-4
   Hou YX, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103810
   Javed R., 2019, BIOMED RES, V30, P1, DOI DOI 10.1016/J.MICRON.2018.09.015
   Jiang D, 2021, J AMB INTEL HUM COMP, V12, P10809, DOI 10.1007/s12652-020-02843-w
   Kaveh M, 2020, APPL GEOMAT, V12, P291, DOI 10.1007/s12518-020-00297-5
   Khan MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050811
   Khan US, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113845
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Liu LN, 2021, J IMAGING, V7, DOI 10.3390/jimaging7040067
   Liu YZ, 2022, PROCESSES, V10, DOI 10.3390/pr10071238
   Mahbod A, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105725
   Majumder S, 2019, PATTERN RECOGN IMAGE, V29, P503, DOI 10.1134/S1054661819030131
   Manzoor K, 2022, CMC-COMPUT MATER CON, V70, P1617, DOI 10.32604/cmc.2022.018621
   Marka A., 2019, BMC MED IMAGING, V19.1, P1
   Meskini E, 2018, J Biomed Phys Eng, V8, P117
   Mishra NK, 2019, SKIN RES TECHNOL, V25, P544, DOI 10.1111/srt.12685
   Mostafa A, 2017, MULTIMED TOOLS APPL, V76, P24931, DOI 10.1007/s11042-017-4638-5
   Pathan S, 2018, MED BIOL ENG COMPUT, V56, P2051, DOI 10.1007/s11517-018-1837-9
   Rana N, 2020, NEURAL COMPUT APPL, V32, P16245, DOI 10.1007/s00521-020-04849-z
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Riaz F, 2019, IEEE J BIOMED HEALTH, V23, P489, DOI 10.1109/JBHI.2018.2832455
   Rimskaya EN, 2019, OPT SPECTROSC+, V126, P503, DOI 10.1134/S0030400X19050230
   Salih O, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081224
   Saman S, 2021, MULTIMED TOOLS APPL, V80, P21925, DOI 10.1007/s11042-021-10738-x
   Sengupta S, 2019, SKIN RES TECHNOL, V25, P846, DOI 10.1111/srt.12744
   Sreelatha T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1334-1
   Sun Q, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-0662-0
   Thada V., 2013, Int. J. Innov. Eng. Technol, V2, P202
   Thanh DNH, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ICEEE 2019), P116, DOI 10.1109/ICEEE2019.2019.00030
   Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072
   Wu YF, 2019, MULTIMED TOOLS APPL, V78, P33633, DOI 10.1007/s11042-019-08098-8
   Yang TJ, 2019, SIGNAL IMAGE VIDEO P, V13, P813, DOI 10.1007/s11760-019-01417-4
   Yang Y., 2021, MULTIMED TOOLS APPL, V80, P1, DOI [10.1007/s11042-019-07896-4, DOI 10.1007/S11042-019-07896-4]
   Yao LP, 2021, MULTIMED TOOLS APPL, V80, P3425, DOI 10.1007/s11042-020-09812-7
   Yousif BB, 2020, IEEE ACCESS, V8, P49285, DOI 10.1109/ACCESS.2020.2979185
NR 56
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15436-4
EA MAY 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H1DL6
UT WOS:000993432500005
DA 2024-07-18
ER

PT J
AU Ren, F
   Tang, C
   Tong, AY
   Wang, WJ
AF Ren, Fang
   Tang, Chao
   Tong, Anyang
   Wang, Wenjian
TI Skeleton-based human action recognition by fusing attention based
   three-stream convolutional neural network and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skeleton-based human action recognition; Convolutional neural network;
   Attention mechanism; Support vector machine; Spatial-temporal feature
ID RECOMMENDATION SYSTEM; VISION
AB This work proposes a method, aiming the 3D skeleton sequence, for the human action recognition by fusing the attention-based three-stream convolutional neural network and support vector machine. The traditional action recognition methods primarily employ RGB video as input. However, RGB video has issues with respect to large data volume, low semanticity, and ease of making the model interfered by irrelevant information such as the background. The efficient and advanced human action information contained in the 3D skeleton sequence facilitates human behavior recognition. First, the information of 3D coordinates, temporal-difference information, and spatial-difference information of joints are extracted from the raw skeleton data, and the above information is input into the respective convolutional neural networks for pre-training. Then, the pre-trained network model extracts the feature containing the spatial-temporal information. Finally, the mixed feature vectors are input into the support vector machine for training and classification. Under the X-View and X-Sub benchmarks, the accuracy on the open dataset NTU RGB+D is 92.6% and 86.7% respectively, demonstrating that the method proposed for incorporating multistream feature learning, feature fusing, and hybrid model can improve the recognition accuracy.
C1 [Ren, Fang; Tang, Chao; Tong, Anyang] Hefei Univ, Sch Artificial Intelligence & Big Data, Hefei, Peoples R China.
   [Wang, Wenjian] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Peoples R China.
C3 Hefei University; Shanxi University
RP Tang, C (corresponding author), Hefei Univ, Sch Artificial Intelligence & Big Data, Hefei, Peoples R China.
EM tangchao@hfuu.edu.cn
OI Tong, Anyang/0000-0003-0960-1497; tang, chao/0000-0002-8934-9537; Ren,
   Fang/0000-0002-5349-6500
FU National Natural Science Foundation [62076154, U21A20513]; Anhui
   Provincial Natural Science Foundation [2008085MF202]; University Natural
   Sciences Research Project of Anhui Province [KJ2020A0660]; Open Project
   of Anhui Provincial Key Laboratory of Multimodal Cognitive Computation,
   Anhui University [MMC202003]; Scientific Research Projects for Graduate
   Students in Anhui Universities [YJS20210564]; Anhui Province Student
   Innovation Training Project [S202111059266, S202111059016]
FX This work was supported in part by the National Natural Science
   Foundation (62076154, U21A20513), the Anhui Provincial Natural Science
   Foundation (2008085MF202), the University Natural Sciences Research
   Project of Anhui Province (KJ2020A0660), and the Open Project of Anhui
   Provincial Key Laboratory of Multimodal Cognitive Computation, Anhui
   University (MMC202003), Scientific Research Projects for Graduate
   Students in Anhui Universities (YJS20210564), Anhui Province Student
   Innovation Training Project (S202111059266, S202111059016).
CR Al-Faris M, 2020, PATTERN ANAL APPL, V23, P1587, DOI 10.1007/s10044-020-00886-5
   Bhatti UA, 2022, SCIENCE, V377, P585, DOI 10.1126/science.add9065
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Caetano C, 2019, SIBGRAPI, P16, DOI 10.1109/SIBGRAPI.2019.00011
   Chen JW, 2022, IEEE WINT CONF APPL, P786, DOI 10.1109/WACV51458.2022.00086
   Dan Yi, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P101, DOI 10.1007/978-981-16-3013-2_9
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Ding WW, 2021, IEEE ACCESS, V9, P54078, DOI 10.1109/ACCESS.2021.3059650
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Feng D, 2021, IEEE ACCESS, V9, P58256, DOI 10.1109/ACCESS.2021.3073107
   Feng LQ, 2022, ARTIF INTELL REV, V55, P4275, DOI 10.1007/s10462-021-10107-y
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Ruiz AH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1087, DOI 10.1145/3123266.3123299
   Huawei Pan, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P2218, DOI 10.1109/HPCC/SmartCity/DSS.2019.00308
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kennedy-Metz LR, 2021, IEEE T MED ROBOT BIO, V3, P2, DOI [10.1109/tmrb.2020.3040002, 10.1109/TMRB.2020.3040002]
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li C, 2017, IEEE INT CONF MULTI
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li Y, 2022, INT C ART INT SEC, P386
   Liang D, 2019, IEEE CVF C COMP VIS
   Lin ZY, 2020, IEEE INT CONF AUTOMA, P532, DOI 10.1109/FG47880.2020.00066
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Wenyi, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1588), P350, DOI 10.1007/978-3-031-06764-8_28
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Mazzia V, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108487
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shao Z, 2023, TEXTUAL CONTEXT AWAR, P1, DOI DOI 10.1109/TMM.2023.3241517
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Shen XP, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103386
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Singla M, 2020, INT J MACH LEARN CYB, V11, P1359, DOI 10.1007/s13042-019-01044-y
   Su BY, 2019, IEEE ACCESS, V7, P52532, DOI 10.1109/ACCESS.2019.2911705
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tong AY, 2023, IEEE T CIRC SYST VID, V33, P1305, DOI 10.1109/TCSVT.2022.3210271
   Nguyen VT, 2021, MULTIMED TOOLS APPL, V80, P27757, DOI 10.1007/s11042-021-10866-4
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HB, 2022, IEEE T CIRC SYST VID, V32, P1250, DOI [10.1109/TAI.2021.3092698, 10.1109/TCSVT.2021.3077512]
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xiliang Xiao, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P75, DOI 10.1007/978-981-16-3013-2_7
   Xu WY, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107236
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yangxiu F, 2021, NOVEL ROBUST WATERMA, DOI [10.1007/978-981-16-3013-2_6, DOI 10.1007/978-981-16-3013-2_6]
   Yu L, 2022, APPL INTELL
   Yue RJ, 2022, NEUROCOMPUTING, V512, P287, DOI 10.1016/j.neucom.2022.09.071
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang JD, 2022, IEEE INTERNET THINGS, V9, P3443, DOI 10.1109/JIOT.2021.3099164
   Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648
   Zheng ZX, 2019, NEUROCOMPUTING, V358, P446, DOI 10.1016/j.neucom.2019.05.058
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
   Zhuang QB, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107096
NR 68
TC 0
Z9 0
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15334-9
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H1DL6
UT WOS:000993432500003
DA 2024-07-18
ER

PT J
AU Veena, A
   Gowrishankar, S
AF Veena, A.
   Gowrishankar, S.
TI An automated pre-term prediction system using EHG signal with the aid of
   deep learning technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pre-processing; Optimization; Spiking neural network; Seagull
   optimization algorithm; Deep learning
AB Prematurity is the leading cause of infant morbidity and mortality around the world. Surface uterine electromyogram (sEMG) is a non-invasive uterine electromyogram. One of most hopeful biophysical tests is the electro hysterogram (EHG). As a result, EHG prove to be a biomarker for detecting preterm birth may allow us to detect a preterm birth before labour begins. The goal of this article is to use a deep learning technique called Spiking Neural Network with Seagull Optimization Technique to predict preterm labour using EHG signals (SNN-SOA). This work pre-processes the EHG signal and extracts metrics such as sample frequency peak, median frequency, RMSE, and entropy. In this study, signal is pre-processed with filter Wiener for improving the quality of signal. The features stripped from the pre-processed signal is to define the separate-class. Furthermore, Ant Lion Optimization based on opposition is utilised to choose the training methods and multi-kernel-support-vector-machine as forecasting preterm delivery. The suggested method is tested for classification accuracy using MATLAB software. As per the experimental study results, the research framework enhanced accuracy of classification by 3-19percent when matched to earlier task.
C1 [Veena, A.; Gowrishankar, S.] Dr Ambedkar Inst Technol, Dept Comp Sci & Engn, Bengaluru 560056, Karnataka, India.
RP Veena, A (corresponding author), Dr Ambedkar Inst Technol, Dept Comp Sci & Engn, Bengaluru 560056, Karnataka, India.
EM veenaa1@acm.org; gowrishankarnath@acm.org
RI A, Veena/AAF-5946-2021; S, Gowrishankar/AAI-5635-2020
OI S, Gowrishankar/0000-0002-9718-4365
CR Acharya UR, 2017, COMPUT BIOL MED, V85, P33, DOI 10.1016/j.compbiomed.2017.04.013
   Allahem Hisham, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2021.100771
   Beiranvand M, 2017, SIG P ALGO ARCH ARR, P269, DOI 10.23919/SPA.2017.8166877
   Degbedzui DK, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103677
   Diab A, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104308
   El Beltagy NS., 2016, ARCH NURS PRACT CARE, V2, P045, DOI [10.17352/2581-4265.000013, DOI 10.17352/2581-4265.000013]
   Fergus P, 2016, NEUROCOMPUTING, V188, P42, DOI 10.1016/j.neucom.2015.01.107
   Fry KE, 2019, IEEE ACCESS, V7, P51357, DOI 10.1109/ACCESS.2019.2911450
   Hamdi MA, 2019, NEUROPHYSIOLOGY+, V51, P272, DOI 10.1007/s11062-019-09821-9
   Hong S, 2020, REPROD SCI, V27, P1187, DOI 10.1007/s43032-019-00114-4
   Kaleem AM, 2021, J AMB INTEL HUM COMP, V12, P3689, DOI 10.1007/s12652-019-01648-w
   Lee Y, 2020, IEEE T NEUR SYS REH, V28, P2627, DOI 10.1109/TNSRE.2020.3032742
   Moccia S, 2020, IEEE T BIO-MED ENG, V67, P2370, DOI 10.1109/TBME.2019.2961448
   Rawashdeh H, 2020, COMPUT BIOL CHEM, V85, DOI 10.1016/j.compbiolchem.2020.107233
   Rittenhouse KJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0198919
   Sadi-Ahmed N, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0847-8
   Saleem S, 2020, BIOCYBERN BIOMED ENG, V40, P454, DOI 10.1016/j.bbe.2020.01.007
   Semenova O, 2019, COMPUT METH PROG BIO, V180, DOI 10.1016/j.cmpb.2019.104996
   Shahrdad M, 2018, BIOMED SIGNAL PROCES, V45, P109, DOI 10.1016/j.bspc.2018.05.044
   Vinothini S, 2021, BIOCYBERN BIOMED ENG, V41, P293, DOI 10.1016/j.bbe.2021.01.004
   Vogel JP, 2018, BEST PRACT RES CL OB, V52, P3, DOI 10.1016/j.bpobgyn.2018.04.003
   Xu JS, 2020, Arxiv, DOI [arXiv:2007.01447, 10.48550/arXiv.2007.01447]
   Xu JS, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104644
   Zhang MX, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152421
NR 24
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 22
PY 2023
DI 10.1007/s11042-023-15665-7
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9PW0
UT WOS:000992398700003
DA 2024-07-18
ER

PT J
AU Chen, JS
   Yi, JZ
   Chen, AB
   Yang, K
   Jin, Z
AF Chen, Junsong
   Yi, Jizheng
   Chen, Aibin
   Yang, Ke
   Jin, Ze
TI SMFE-Net: a saliency multi-feature extraction framework for VHR remote
   sensing image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Very-high resolution (VHR) remote sensing image; Saliency multi-feature
   extraction; Attention mechanism; Remote sensing scene classification
ID SCENE CLASSIFICATION; NETWORK; ATTENTION; FUSION; MODEL; LSTM
AB Scene classification of very-high resolution (VHR) remote sensing images is a challenging research hotspot. It is difficult to extract salient features because of the characteristics of remote sensing images, such as large spatial range changes and complex scenes. In addition, the effective combination of high-level semantic information and low-level contour information is also a major difficulty at present. In order to solve these problems, we proposed a new end-to-end saliency multi-feature extraction network (SMFE-Net) based on VGG16 and long short-term memory (LSTM) to extract salient features and effectively integrate high-level features with low-level features. Firstly, we design an adaptive memory network (AMN) based on the rectangular combination of LSTMs to capture rich features of high and low levels. The AMN not only provides supplementary information but also focuses on key areas, thus discarding non-critical information. Secondly, in order to realize adaptive feature extraction, the sequential connection of channel attention (CA) and spatial attention (SA) is placed in the high-level feature extraction subnetwork, whose outputs are multiplied by the weights of the last feature map layer of VGG16. Finally, the outputs of AMN and the attention-weighted features are concatenated and inputted to the fully connected layer for the scene classification of the VHR remote sensing image. To verify the validity of the proposed SMFE-Net, the UC Merced (UCM) land-use dataset, the Aerial Image Dataset (AID), and the OPTIMAL-31 (OPTL) dataset are selected as the experimental materials. Experimental results have demonstrated that the proposed SMFE-Net is superior to several most advanced methods.
C1 [Chen, Junsong; Yi, Jizheng; Chen, Aibin; Yang, Ke] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410000, Peoples R China.
   [Chen, Junsong; Yi, Jizheng; Chen, Aibin; Yang, Ke] Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Changsha 410000, Peoples R China.
   [Yi, Jizheng; Chen, Aibin] Hunan Key Lab Intelligent Logist Technol, Changsha 410000, Peoples R China.
   [Jin, Ze] Informat & Artificial Intelligence Res Int Hub Grp, Suzuki Lab, Tokyo 2268503, Japan.
   [Jin, Ze] Tokyo Inst Technol, Inst Innovat Res, Lab Future Interdisciplinary Res Sci & Technol, Tokyo 2268503, Japan.
C3 Central South University of Forestry & Technology; Central South
   University of Forestry & Technology; Tokyo Institute of Technology
RP Yi, JZ (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410000, Peoples R China.; Yi, JZ (corresponding author), Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Changsha 410000, Peoples R China.; Yi, JZ (corresponding author), Hunan Key Lab Intelligent Logist Technol, Changsha 410000, Peoples R China.
EM kingkong148@163.com
FU Hunan Provincial Natural Science Foundation of China [2022JJ31022];
   Undergraduate Education Reform Project of Hunan Province
   [HNJG-2021-0532]; National Natural Science Foundation of China
   [61602528]
FX AcknowledgementsThe authors would like to thank all editors and the
   anonymous reviewers for their valuable support and suggestion. This work
   was supported in part by the Hunan Provincial Natural Science Foundation
   of China (Grant no. 2022JJ31022), the Undergraduate Education Reform
   Project of Hunan Province (Grant no. HNJG-2021-0532), the National
   Natural Science Foundation of China (Grant no. 61602528).
CR Bhagavathy S, 2006, IEEE T GEOSCI REMOTE, V44, P3706, DOI 10.1109/TGRS.2006.881741
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Chen J, 2023, IEEE T GEOSCI REMOTE, V61, DOI [10.5414/CP204156, 10.1109/TGRS.2023.3262576]
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P1803, DOI 10.1109/TGRS.2017.2768479
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gehring J, 2017, PR MACH LEARN RES, V70
   Guo DE, 2020, IEEE ACCESS, V8, P6344, DOI 10.1109/ACCESS.2019.2963769
   Guo YY, 2021, MULTIMED TOOLS APPL, V80, P23009, DOI 10.1007/s11042-020-08713-z
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He NJ, 2020, IEEE T NEUR NET LEAR, V31, P1461, DOI 10.1109/TNNLS.2019.2920374
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hua YS, 2020, IEEE T GEOSCI REMOTE, V58, P4558, DOI 10.1109/TGRS.2019.2963364
   Huang W, 2019, INT GEOSCI REMOTE SE, P3017, DOI [10.1109/igarss.2019.8898875, 10.1109/IGARSS.2019.8898875]
   Jetley S, 2018, Arxiv, DOI [arXiv:1804.02391, DOI 10.48550/ARXIV.1804.02391, 10.48550/arXiv.1804.02391]
   Krizhevsky A., 2012, NEURIPS, V25, p1097
   Larochelle H., 2010, ADV NEURAL INFORM PR, V23, P1243
   Li B., 2021, IEEE T GEOSCI ELECT
   Li J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091366
   Li ST, 2016, IEEE T GEOSCI REMOTE, V54, P7416, DOI 10.1109/TGRS.2016.2603190
   Li ZL, 2020, IEEE T GEOSCI REMOTE, V58, P3685, DOI 10.1109/TGRS.2019.2960889
   Liang ZY, 2021, IEEE ACCESS, V9, P112637, DOI 10.1109/ACCESS.2021.3103669
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu MY, 2021, IEEE IMAGE PROC, P644, DOI 10.1109/ICIP42928.2021.9506410
   Liu Q., 2016, arXiv
   Liu YF, 2018, IEEE T GEOSCI REMOTE, V56, P7109, DOI 10.1109/TGRS.2018.2848473
   Lu XQ, 2019, IEEE T GEOSCI REMOTE, V57, P7894, DOI 10.1109/TGRS.2019.2917161
   Lu XQ, 2019, NEUROCOMPUTING, V328, P135, DOI 10.1016/j.neucom.2018.03.076
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Mnih V, 2014, ADV NEUR IN, V27
   Santos JAD, 2010, VISAPP 2010 P 5 INT, VDBLP
   Shaikh S, 2021, IEEE ACCESS, V9, P117887, DOI 10.1109/ACCESS.2021.3106443
   Shen JE, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092042
   Shin Y, 2020, IEEE-ACM T AUDIO SPE, V28, P105, DOI 10.1109/TASLP.2019.2948773
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P82, DOI 10.1109/TGRS.2019.2931801
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang X, 2021, IEEE T GEOSCI REMOTE, V59, P7918, DOI 10.1109/TGRS.2020.3044655
   Wu P, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107792
   Wu ZZ, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107885
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3057689
   Yang K, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104916
   Yang K, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3093101
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050494
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao B, 2017, IEEE GEOSCI REMOTE S, V14, P1436, DOI 10.1109/LGRS.2017.2691013
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhong P, 2014, IEEE T NEUR NET LEAR, V25, P1319, DOI 10.1109/TNNLS.2013.2293061
NR 56
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15759-2
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0BI9
UT WOS:000992700500002
DA 2024-07-18
ER

PT J
AU Liu, DL
   Yao, HX
   Lu, XS
AF Liu, Dilin
   Yao, Hongxun
   Lu, Xiusheng
TI Artistic image synthesis from unsupervised segmentation maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artistic image synthesis; Image translation; Texture synthesis
ID TRANSLATION
AB We present a framework for artwork image synthesis from unsupervised segmentation maps input and style images. The output has style consistency with style images and the semantic structure from the corresponding segmentation label. Existing methods of transferring semantic labels to painting images require large amounts of manual segmentation pairs for training. To address the issue, we use unsupervised segmentation maps to build on training pairs and learn the generator with the proposed spatially adaptive instance normalization block. Our method exploits the style consistency and semantic consistency loss functions to reduce the artifact in synthetic images. Extensive experiments in several image translation tasks show the effectiveness of our method in generating an image with both structures of segmentation and style of exemplar image.
C1 [Liu, Dilin; Yao, Hongxun; Lu, Xiusheng] Harbin Inst Technol, Sch Comp Sci & Technol, Dazhi St West 92, Harbin 150006, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Liu, DL (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Dazhi St West 92, Harbin 150006, Heilongjiang, Peoples R China.
EM liudilin@hit.edu.cn; h.yao@hit.edu.cn; xiusheng.lu.cs@gmail.com
OI Liu, Dilin/0000-0003-1462-3674
FU National Key R&D Program of China [2021ZD0110901]
FX AcknowledgmentsThis work is supported by the National Key R&D Program of
   China (No. 2021ZD0110901).
CR Aberman K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201332
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Choy C B, 2018, US Patent, Patent No. [10,115,032, 10115032]
   Cohen N, 2022, COMPUT GRAPH FORUM, V41, P261, DOI 10.1111/cgf.14473
   Dong H, 2017, IEEE I CONF COMP VIS, pCP1, DOI 10.1109/ICCV.2017.608
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Hwang S, 2022, MULTIMED TOOLS APPL, V81, P40269, DOI 10.1007/s11042-022-12934-9
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kim S., 2017, CVPR, P6560
   Kingma D. P., 2014, arXiv
   Kolkin N, 2019, PROC CVPR IEEE, P10043, DOI 10.1109/CVPR.2019.01029
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Liao J, 2017, Arxiv, DOI arXiv:1705.01088
   Liu T., 2017, P INT C ADV NEUR INF, V30, P700, DOI DOI 10.48550/ARXIV.1703.00848
   Liu YF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3133956
   Liu Yun, 2022, P IEEE CVF C COMP VI, P640
   Long J.L., 2014, Advances in neural information processing systems, V27, P1601
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mechrez R, 2018, LECT NOTES COMPUT SC, V11218, P800, DOI 10.1007/978-3-030-01264-9_47
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Park Taesung, 2020, EUR C COMP VIS, P319, DOI [DOI 10.1007/978-3-030-58545-719, DOI 10.1007/978-3-030-58545-7_19]
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Pirrone R, 2009, INT CONF INTELL SYST, P913, DOI 10.1109/ISDA.2009.219
   Chen TQ, 2016, Arxiv, DOI arXiv:1612.04337
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tu H, 2023, MOD INTELLECT HIST, V20, P323, DOI 10.1017/S1479244322000063
   Wang M, 2019, Arxiv, DOI arXiv:1906.01314
   Wang Q., 2022, IEEE T GEOSCI ELECT
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yao Y, 2019, PROC CVPR IEEE, P1467, DOI 10.1109/CVPR.2019.00156
   Yu JC, 2022, MULTIMED TOOLS APPL, V81, P3915, DOI 10.1007/s11042-021-11694-2
   Zhan FN, 2021, PROC CVPR IEEE, P15023, DOI 10.1109/CVPR46437.2021.01478
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhou T, 2016, Arxiv, DOI arXiv:1605.01576
   Zhou XR, 2021, PROC CVPR IEEE, P11460, DOI 10.1109/CVPR46437.2021.01130
   Zhu J., 2014, Advances in Neural Information Processing Systems 27, P1125
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 50
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15318-9
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5VQ1
UT WOS:000989835300001
DA 2024-07-18
ER

PT J
AU Akoushideh, A
   Shahbahrami, A
   Afshany, AJ
AF Akoushideh, Alireza
   Shahbahrami, Asadollah
   Joe Afshany, Abdorreza
TI Parallelization of license plate localization on GPU platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parallelism; Average filter; GPU; CUDA; License plate detection;
   Intelligent transportation systems
ID RECOGNITION
AB Automatic license plate recognition which has many applications in intelligent transportation systems has three main steps, License Plate Detection (LPD), segmentation, and character recognition. The first step, LPD is the main step. This is because the accuracy of other steps depends on this step. While LPD has many challenging problems such as illumination changing, weather conditions, vehicle position, number of cars in each image, etc. In this paper, an algorithm for LPD is proposed. In the proposed technique, to remove noises from input images mean filtering is used. After that, the differences between the filtered image and input image are computed and it is converted to a black and white image. Finally, after applying edge detection and closing and opening morphological operations, license plate candidates are detected. The experimental results on a real Iranian dataset show that about 96.16% of license plates are localized. In addition, results show that the mean filter which has been used for noise removal is the most time-consuming kernel in the proposed algorithm. This important kernel on the GPU platform using CUDA parallel programming model is implemented. The experiments show that speedups of up to 14.54x and 10.77x for kernel- and application-level are achieved.
C1 [Akoushideh, Alireza] Tech & Vocat Univ, Fac Shahid Chamran, Dept Elect & Comp, Guilan Branch, Rasht, Iran.
   [Shahbahrami, Asadollah; Joe Afshany, Abdorreza] Univ Guilan, Fac Engn, Dept Comp Engn, Rasht, Iran.
C3 University of Guilan
RP Akoushideh, A (corresponding author), Tech & Vocat Univ, Fac Shahid Chamran, Dept Elect & Comp, Guilan Branch, Rasht, Iran.
EM akushide@tvu.ac.ir; shahbahrami@guilan.ac.ir;
   joe_afshany@msc.guilan.ac.ir
RI Shahbahrami, Asadollah/ABD-2432-2020; Akoushideh, Alireza/K-8143-2019
OI Shahbahrami, Asadollah/0000-0002-5195-1688; Akoushideh,
   Alireza/0000-0001-9958-4613
CR Abolghasemi V, 2007, LECT NOTES COMPUT SC, V4781, P468
   Afshany AJ., 2019, INT J INTELL SYST AP, V11, P25, DOI [10.5815/ijisa.2019.11.03, DOI 10.5815/IJISA.2019.11.03]
   Anushka, 2021, J PHYS C SER, V1854, P0120212, DOI [10.1088/1742-6596/1854/1/012012, DOI 10.1088/1742-6596/1854/1/012012]
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Fomani BA, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P146, DOI 10.1109/PRIA.2017.7983035
   Huang QY, 2021, IEEE ACCESS, V9, P21777, DOI 10.1109/ACCESS.2021.3055243
   Jamtsho Y, 2020, ICT EXPRESS, V6, P121
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Khazaee S, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421600089
   Laroca R, 2021, IET INTELL TRANSP SY, V15, P483, DOI 10.1049/itr2.12030
   Lubna, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093028
   Luvizon DC, 2017, IEEE T INTELL TRANSP, V18, P1393, DOI 10.1109/TITS.2016.2606369
   Moradifar M, 2019, HIGH PERFORMANCE COM, P459
   Moreno-Barea FJ, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P728, DOI 10.1109/SSCI.2018.8628917
   Oz C, 2005, LECT NOTES COMPUT SC, V3512, P881
   Rashtehroudi A. R., 2020, 2020 INT C MACHINE V, P1, DOI DOI 10.1109/MVIP49855.2020.9116897
   Shafi I, 2022, COMPLEX INTELL SYST, V8, P3627, DOI 10.1007/s40747-021-00419-5
   Shahbahrami A, 2017, IRAN CONF MACH, P76, DOI 10.1109/IranianMVIP.2017.8342372
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Tourani A, 2020, IEEE ACCESS, V8, P201317, DOI 10.1109/ACCESS.2020.3035992
   Young E, 2008, NVISION 08 WORLD VIS
   Zheng D, 2005, PATTERN RECOGN LETT, V26, P2431, DOI 10.1016/j.patrec.2005.04.014
   Zhou WG, 2012, IEEE T IMAGE PROCESS, V21, P4269, DOI 10.1109/TIP.2012.2199506
NR 24
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15656-8
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZR2
UT WOS:000988581800002
DA 2024-07-18
ER

PT J
AU Mehta, S
   Kaur, P
   Agarwal, P
AF Mehta, Shikha
   Kaur, Parmeet
   Agarwal, Parul
TI Improved whale optimization variants for SLA-compliant placement of
   virtual machines in cloud data centers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud computing; Virtual machine placement; Whale optimization
   algorithm; SLA; PSO
ID ANT COLONY SYSTEM; ENERGY-EFFICIENT; MULTIOBJECTIVE OPTIMIZATION;
   RESOURCE-ALLOCATION; ALGORITHM; CONSOLIDATION; AWARE; STRATEGY
AB Infrastructure as a Service (IaaS) model of cloud computing provides resources, such as storage and computation power from cloud-based physical machines to users in the form of virtual machines (VM). This can be cost-efficient for users as well as cloud service providers if the physical machines and related resources are optimally utilized. At the same time, it is also imperative that energy consumption by physical machines in cloud data centers be minimized. A solution to both these challenges can be found by efficient mapping of VMs onto physical machines. This is known as the VM placement problem and the paper aims to find an optimal mapping of VMs to PMs with two objectives. Firstly, the cloud service provider's cost is reduced by increasing the resource utilization and secondly, the energy consumption is reduced by decreasing the number of PMs in use at a time. In this work, two variants of whale optimization algorithm (WOA) are proposed for efficiently placing VMs on the physical machines. In the first variant exploitation phase of WOA is improved via simulated annealing (SWOA). In the second variant Levy (L) distribution is incorporated to improve the exploration phase of WOA (LWOA). Performance of algorithms is assessed on varying workloads under deadline constraints. Experiments are performed on light, medium, heavy and very heavy workloads. Results demonstrate that the proposed variant SWOA provide efficient solutions on light workload while LWOA gives efficient solution on other workloads for the VM placement problem. These algorithms also converge faster as compared to its contemporary counterparts thereby reducing the computational complexity of the problem.
C1 [Mehta, Shikha; Kaur, Parmeet; Agarwal, Parul] Jaypee Inst Informat Technol, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Agarwal, P (corresponding author), Jaypee Inst Informat Technol, Noida, India.
EM shikha.mehta@jiit.ac.in; parmeet.kaur@jiit.ac.in;
   parul.agarwal@jiit.ac.in
OI agarwal, parul/0000-0003-2262-0721
CR Ahmad RW, 2015, J NETW COMPUT APPL, V52, P11, DOI 10.1016/j.jnca.2015.02.002
   Alharbi F, 2019, EXPERT SYST APPL, V120, P228, DOI 10.1016/j.eswa.2018.11.029
   Ashraf A, 2018, INT J PARALLEL EMERG, V33, P103, DOI 10.1080/17445760.2017.1278601
   Azizi S, 2020, CLUSTER COMPUT, V23, P3421, DOI 10.1007/s10586-020-03096-0
   Baran, 2017, RES ADV CLOUD COMPUT, P291, DOI DOI 10.1007/978-981-10-5026-8_12
   Brazdil P B., 2000, COMP RANKING METHODS
   Buyya R, 2010, Arxiv, DOI arXiv:1006.0308
   Caviglione L, 2021, SOFT COMPUT, V25, P12569, DOI 10.1007/s00500-020-05462-x
   Deb K., 2001, MULTIOBJECTIVE OPTIM, DOI DOI 10.1109/TEVC.2002.804322
   Dignan L., 2019, Top cloud providers 2019
   Ding WC, 2018, PEER PEER NETW APPL, V11, P318, DOI 10.1007/s12083-016-0502-z
   El Motaki S, 2019, J SUPERCOMPUT, V75, P6239, DOI 10.1007/s11227-019-02847-0
   Gao YQ, 2013, J COMPUT SYST SCI, V79, P1230, DOI 10.1016/j.jcss.2013.02.004
   Guo LZ, 2012, COMM COM INF SC, V308, P119
   Jing Xu, 2010, Proceedings of the 2010 IEEE/ACM Int'l Conference on Green Computing and Communications (GreenCom) and Int'l Conference on Cyber, Physical and Social Computing (CPSCom), P179, DOI 10.1109/GreenCom-CPSCom.2010.137
   Kaur A, 2019, SCALABLE COMPUT-PRAC, V20, P377, DOI 10.12694/scpe.v20i2.1530
   Kaur P, 2019, AIP CONF PROC, V2061, DOI 10.1063/1.5086633
   Kaur P, 2017, J PARALLEL DISTR COM, V101, P41, DOI 10.1016/j.jpdc.2016.11.003
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li XK, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P61, DOI 10.1109/ICCWAMTIP.2015.7493907
   Li ZH, 2018, FUTURE GENER COMP SY, V80, P139, DOI 10.1016/j.future.2017.09.075
   Ling Y, 2017, IEEE ACCESS, V5, P6168, DOI 10.1109/ACCESS.2017.2695498
   Liu C, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P272, DOI 10.1109/ICSESS.2014.6933561
   Liumei Z., 2016, Journal of Communications and Information Networks, V1, P116
   Lopez Pires Fabio, 2013, 2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing (UCC), P203, DOI 10.1109/UCC.2013.44
   Luo J, 2018, IEEE ACCESS, V6, P23043, DOI 10.1109/ACCESS.2018.2816983
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Malekloo MH, 2018, SUSTAIN COMPUT-INFOR, V17, P9, DOI 10.1016/j.suscom.2018.02.001
   Malekloo M, 2014, IEEE GLOBE WORK, P112, DOI 10.1109/GLOCOMW.2014.7063415
   Mehta S, 2019, INT J COMPUT INTELL, V18, DOI 10.1142/S1469026819500238
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammed HM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8718571
   Nastic S, 2020, IEEE INTERNET COMPUT, V24, P39, DOI 10.1109/MIC.2020.2987739
   Pham NMN, 2017, J INFORM TELECOMMUN, V1, P319, DOI 10.1080/24751839.2017.1356159
   Qin Y, 2020, APPL INTELL, V50, P2370, DOI 10.1007/s10489-020-01633-3
   Ramezani F, 2016, IEEE INT FUZZY SYST, P1259, DOI 10.1109/FUZZ-IEEE.2016.7737833
   Rana N, 2020, NEURAL COMPUT APPL, V32, P16245, DOI 10.1007/s00521-020-04849-z
   Salgotra R, 2019, ARAB J SCI ENG, V44, P9653, DOI 10.1007/s13369-019-04016-0
   Simon D., 2013, EVOLUTIONARY OPTIMIZ
   Sinong Wang, 2013, 2013 IEEE Eighth International Conference on Networking, Architecture and Storage (NAS), P331, DOI 10.1109/NAS.2013.54
   Sun G, 2019, FUTURE GENER COMP SY, V91, P347, DOI 10.1016/j.future.2018.09.037
   Tan MZ, 2017, IIP'17: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION PROCESSING, DOI 10.1145/3144789.3144792
   Varasteh A, 2017, IEEE SYST J, V11, P772, DOI 10.1109/JSYST.2015.2458273
   Wang XL, 2014, FUTURE GENER COMP SY, V36, P91, DOI 10.1016/j.future.2013.12.004
   Xu B, 2015, SOFT COMPUT, V19, P2265, DOI 10.1007/s00500-014-1406-6
   Zheng QH, 2015, IEEE ACM INT SYMP, P687, DOI 10.1109/CCGrid.2015.25
   Zheng QH, 2016, FUTURE GENER COMP SY, V54, P95, DOI 10.1016/j.future.2015.02.010
NR 49
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15528-1
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200003
DA 2024-07-18
ER

PT J
AU Baqach, A
   Battou, A
AF Baqach, Adil
   Battou, Amal
TI CLAS: A new deep learning approach for sentiment analysis from Twitter
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis from text; Deep learning; Natural language
   processing; Attention mechanism
ID MODEL
AB Sentiment analysis from text and natural language processing noticed a significant interest over the last few years. It is due to the expansion of user-generated textual data that has been spread with the growth of social media platforms. Therefore, we can find many textual data carrying sentiment information, product reviews, and online classes. Therefore, it is crucial to be able to understand users' emotions from their generated texts, and this can be very important in a variety of domains; for example, in marketing, if we can understand clients' opinions about products, we can build up a suitable recommendation system based on their emotions. Deep learning showed a good result in sentiment analysis; algorithms such as convolutional neural networks (CNN), which can extract features from the text, and Long Short-Term Memory (LSTM) which can catch the semantic relations with words, showed high performance when combined. In this article, we will propose a new method named CLAS (CNN-LSTM-Attention-SVM), based on CNN, LSTM, Attention mechanism, and Support Vector Machines, and we will also test some of the most potent baselines in sentiment analysis from the text. Experiments were conducted on three known sentiment-labelled datasets, and after experiments, our CLAS model outperformed all other baselines.
C1 [Baqach, Adil; Battou, Amal] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, IRF SIC, Agadir, Morocco.
C3 Ibn Zohr University of Agadir
RP Baqach, A (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, IRF SIC, Agadir, Morocco.
EM baqachadil@gmail.com
RI BATTOU, Amal/HPC-6817-2023
OI BATTOU, Amal/0000-0002-3945-5665; Baqach, Adil/0000-0002-2452-5077
CR Ahmed U, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3165136
   Al-Omari H, 2020, INT CONF INFORM COMM, P226, DOI 10.1109/ICICS49469.2020.239539
   Altrabsheh N, 2014, LECT NOTES ARTIF INT, V8779, P40, DOI 10.1007/978-3-319-11298-5_5
   [Anonymous], IEEE Journals & Magazine | IEEE Xplore
   [Anonymous], 2015, PREDICTING LEARNING
   Antonakaki D, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114006
   Bahdanau D, 2022, ARXIV
   Baqach Adil, 2021, E3S Web of Conferences, V297, DOI 10.1051/e3sconf/202129701010
   Estrada MLB, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113265
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Birjali M, 2018, APPL SOFT COMPUT, V69, P14, DOI 10.1016/j.asoc.2018.04.030
   Carvalho J, 2021, ARTIF INTELL REV, V54, P1887, DOI 10.1007/s10462-020-09895-6
   Cen P., 2020, Journal on Artificial Intelligence (JAI), V2, P17, DOI [10.32604/jai.2020.010132, DOI 10.32604/JAI.2020.010132]
   Chachra A, 2017, INT CONF CONTEMP, P247
   Chen YL, 2018, C IND ELECT APPL, P2731, DOI 10.1109/ICIEA.2018.8398173
   He HH, 2018, LECT NOTES ARTIF INT, V11108, P250, DOI 10.1007/978-3-319-99495-6_21
   Kilimci Zeynep H., 2018, Complexity, V2018, DOI 10.1155/2018/7130146
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Liao WX, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107096
   Madani Y, 2020, J AMB INTEL HUM COMP, V11, P3921, DOI 10.1007/s12652-019-01627-1
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Rodriguez P, 2014, INT J CONTIN ENG EDU, V24, P168, DOI 10.1504/IJCEELL.2014.060156
   Rosenthal Sara, 2017, P 11 INT WORKSH SEM, P502
   Smetanin S, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102484
   Sultana J, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC)
   Teng Z, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (NLP-KE'07), P36, DOI 10.1109/NLPKE.2007.4368008
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562
   Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919
NR 29
TC 2
Z9 2
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47457
EP 47475
DI 10.1007/s11042-023-15784-1
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986346600007
DA 2024-07-18
ER

PT J
AU Kumar, J
   Singh, AK
AF Kumar, Jullius
   Singh, Amit Kumar
TI Copyright protection of medical images: A view of the state-of-the-art
   research and current developments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Watermarking; Data hiding; Attacks
ID REVERSIBLE WATERMARKING SCHEME; SECURE MULTIPLE WATERMARKING; ROBUST;
   DOMAIN; COMPRESSION; BLIND
AB Recently, copyright protection of medical images has been critical, and even small changes can endanger the life of a patient. To verify the authenticity of these images, digital watermarking technology is widely used in the field of healthcare applications. We aim to provide a detailed survey of the state-of-the-art research and current developments of copyright protection schemes, focusing particularly on watermarking in the medical domain. Initially, we present the basic concepts of watermarking along with their major characteristics and novel applications. Further, we comprehensively review the recent literature, including that on watermarking in the spatial and transform domains, encryption- and compression-based watermarking, watermarking using optimisation, watermarking in machine/deep learning, biometric and blockchain environments of watermarking. Finally, we provide a tabular comparison of state-of-the-art research and potential issues in this field.
C1 [Kumar, Jullius; Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM julliusk.ph21.cs@nitp.ac.in; amit.singh@nitp.ac.in
RI KUMAR, JULLIUS/KQU-4465-2024
OI KUMAR, JULLIUS/0000-0002-8567-2038
CR Abdullad MJ, 2021, INT MULTICONF SYST, P445, DOI 10.1109/SSD52085.2021.9429305
   Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ahmed R, 2018, IEEE INT SYMP SIGNAL
   Alquhayz H, 2022, ARAB J SCI ENG, V47, P9471, DOI 10.1007/s13369-021-06254-7
   Alzahrani A, 2021, IEEE ACCESS, V9, P113714, DOI 10.1109/ACCESS.2021.3104985
   Amrit P, 2021, Journal of physics: conference series, V1767
   Amrit P, 2022, COMPUT COMMUN, V188, P52, DOI 10.1016/j.comcom.2022.02.023
   Anand A, 2022, SUSTAIN COMPUT-INFOR, V33, DOI 10.1016/j.suscom.2021.100621
   Anand A, 2022, IEEE TRANSAC INDUST, V19, P1051
   Anand A, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3508365
   Anand A, 2023, IEEE T DEPEND SECURE, V20, P859, DOI 10.1109/TDSC.2022.3144657
   Anand A, 2023, IEEE T COMPUT SOC SY, V10, P2033, DOI 10.1109/TCSS.2022.3140862
   Anand A, 2022, IEEE T COMPUT SOC SY, V9, P1265, DOI 10.1109/TCSS.2021.3125025
   Anand A, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103398
   Anand A, 2020, IEEE MULTIMEDIA, V27, P133, DOI 10.1109/MMUL.2020.2993269
   Anand A, 2020, IEEE MULTIMEDIA, V27, P66, DOI 10.1109/MMUL.2020.2985973
   Anand A, 2021, MULTIMED TOOLS APPL, V80, P30165, DOI 10.1007/s11042-020-08801-0
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Bhowmik D, 2017, INT CONF DIGIT SIG
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P12647, DOI 10.1007/s11042-017-5348-8
   Chi HX, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207942
   Daham A, 2022, INT CONF INFORM COMM, P379, DOI 10.1109/ICICS55353.2022.9811160
   Dharmika B., 2022, 2022 International Conference on Inventive Computation Technologies (ICICT), P96, DOI 10.1109/ICICT54344.2022.9850736
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Geetha SP, 2021, TURK J COMPUT MATH E, V12, P1855
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Hassan B, 2019, IEEE ACCESS, V7, P69758, DOI 10.1109/ACCESS.2019.2919381
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Ingaleshwar S, 2023, MULTIMED TOOLS APPL, V82, P21957, DOI 10.1007/s11042-020-10498-0
   Kallel IF, 2022, 2022 6 INT C ADV TEC, P1
   Kiran P, 2022, MICROPROCESS MICROSY, V91, DOI 10.1016/j.micpro.2022.104546
   Kumar P, 2020, PROCEDIA COMPUT SCI, V167, P1380, DOI 10.1016/j.procs.2020.03.349
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Li QD, 2022, MULTIMED TOOLS APPL, V81, P11415, DOI 10.1007/s11042-022-12266-8
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Magdy M, 2022, MULTIMED TOOLS APPL, V81, P25101, DOI 10.1007/s11042-022-11956-7
   Mashat A, 2022, INTELL AUTOM SOFT CO, V32, P841, DOI 10.32604/iasc.2022.021636
   Mata-Mendoza D, 2022, VISUAL COMPUT, V38, P2073, DOI 10.1007/s00371-021-02267-3
   Mata-Mendoza D, 2021, HEALTH TECHNOL-GER, V11, P835, DOI 10.1007/s12553-021-00562-6
   Megat Abd Mana Nur Alifah, 2022, 2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST), P1, DOI 10.1109/AIST55798.2022.10065211
   Memon NA, 2020, IEEE ACCESS, V8, P75448, DOI 10.1109/ACCESS.2020.2989175
   Meng ZX, 2018, P INT COMP SOFTW APP, P359, DOI 10.1109/COMPSAC.2018.10258
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Mohammed NF, 2020, KUWAIT J SCI, V47
   Priyanka A K Singh, 2022, MEASUREMENT, V196, P1
   Pulgam ND, 2020, 2022 10 INT C EMERG, P1
   Rai A, 2018, J INTELL SYST, V27, P105, DOI 10.1515/jisys-2017-0068
   Roy SS, 2020, MULTIMED TOOLS APPL, V79, P13125, DOI 10.1007/s11042-020-08652-9
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Sahib NF, 2022, PERIOD ENG NAT SCI P, V10, P408
   Sajedi H, 2018, NETW MODEL ANAL HLTH, V7, DOI 10.1007/s13721-018-0169-x
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Sharma N, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.041207
   Singh AK, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3414474
   Singh AK, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382772
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED SYST APPL, P175, DOI 10.1007/978-3-319-57699-2_8
   Singh Harsh Vikram, 2019, Smart Innovations in Communication and Computational Sciences. Proceedings of ICSICCS-2018. Advances in Intelligent Systems and Computing (AISC 851), P485, DOI 10.1007/978-981-13-2414-7_45
   Singh HK, 2022, J ELECTRON IMAGING, V32
   Singh KN, 2022, COGN COMPUT, DOI 10.1007/s12559-022-10040-4
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh OP, 2023, COMPLEX INTELL SYST, V9, P2759, DOI 10.1007/s40747-021-00309-w
   Singh O.P., 2022, IEEE INTELL SYST
   Singh P, 2022, IEEE ACCESS, V10, P8974, DOI 10.1109/ACCESS.2022.3143801
   Singh SP, 2021, IEEE T KNOWL DATA EN, V33, P810, DOI 10.1109/TKDE.2019.2935710
   Swaraja K, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102688
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Verma U, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103694
   Yan F, 2022, IEEE IEEE T INDUSTR
   Yang K, 2020, IEEE IFIP NETW OPER, DOI 10.1109/noms47738.2020.9110372
   Zairi M, 2023, INDONES J ELECT ENG, V29, P1132
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zhaoning Y, 2021, J INF SECUR APPL, V58
NR 88
TC 2
Z9 2
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44591
EP 44621
DI 10.1007/s11042-023-15315-y
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000974364100005
DA 2024-07-18
ER

PT J
AU Gu, FW
   Lu, J
   Cai, CT
AF Gu, Fengwei
   Lu, Jun
   Cai, Chengtao
TI A robust attention-enhanced network with transformer for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Attention-enhanced network; Local feature information
   association module; Global feature information fusion module; Prediction
   network
ID OBJECT TRACKING; SIAMESE
AB Recently, Siamese-based trackers have become particularly popular. The correlation module in these trackers is responsible for fusing the feature information from the template and the search region, to obtain the response results. However, there are very rich contextual information and feature dependencies among video sequences, and it is difficult for a simple correlation module to efficiently integrate useful information. Therefore, the tracker encounters the challenges of information loss and local optimal solutions. In this work, we propose a novel attention-enhanced network with a Transformer variant for robust visual tracking. The proposed method carefully designs the local feature information association module (LFIA) and the global feature information fusion module (GFIF) based on the attention mechanism, which can effectively utilize contextual information and feature dependencies to enhance feature information. Our approach transforms the visual tracking problem into a bounding box prediction problem, using only a simple prediction network for object localization, without any prior knowledge. Ultimately, we propose a robust tracker called RANformer. Experiments show that the proposed tracker achieves state-of-the-art performance on 7 popular tracking benchmarks while meeting real-time requirements with a speed exceeding 40FPS.
C1 [Gu, Fengwei; Lu, Jun; Cai, Chengtao] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Gu, Fengwei; Lu, Jun; Cai, Chengtao] Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Minist Educ, Harbin 150001, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University
RP Lu, J (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.; Lu, J (corresponding author), Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Minist Educ, Harbin 150001, Peoples R China.
EM lujun0260@sina.com
RI jun, lu/A-1694-2012
OI Gu, Fengwei/0000-0001-5964-2022
FU Natural Science Foundation of Heilongjiang Province of China [F201123];
   National Natural Science Foundation of China [52171332]
FX This work is supported in part by the Natural Science Foundation of
   Heilongjiang Province of China under Grant No.F201123 and in part by the
   National Natural Science Foundation of China under Grant 52171332.Data
   availability statementOur manuscript has no available data.
CR Akter L., 2021, SN Comput Sci, V2, P1, DOI DOI 10.1007/S42979-021-00551-6
   Al-Rakhami MS, 2021, medRxiv
   Altan A, 2020, MECH SYST SIGNAL PR, V138, DOI 10.1016/j.ymssp.2019.106548
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Das S, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068754
   Ding XY, 2020, NEUROCOMPUTING, V409, P74, DOI 10.1016/j.neucom.2020.05.035
   Fan BJ, 2018, PATTERN RECOGN, V81, P528, DOI 10.1016/j.patcog.2018.04.002
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Ferdib-Al-Islam, 2021, 2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), P445, DOI 10.1109/ICREST51555.2021.9331108
   Fu HC, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103869
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam M. M., 2020, Social Netw. Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00223-x, DOI 10.1007/S42979-020-00223-X]
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2020, IEEE ACCESS, V8, P166117, DOI 10.1109/ACCESS.2020.3021943
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jha S, 2021, MULTIMED TOOLS APPL, V80, P3981, DOI 10.1007/s11042-020-09749-x
   Kashiani H, 2019, IMAGE VISION COMPUT, V83-84, P17, DOI 10.1016/j.imavis.2019.02.003
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Lersteau C, 2018, EUR J OPER RES, V265, P882, DOI 10.1016/j.ejor.2017.08.045
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Linyu Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P759, DOI 10.1007/978-3-030-58555-6_45
   Liu DY, 2019, IEEE IJCNN
   Loshchilov I., 2018, arXiv
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Luo WH, 2020, IEEE T PATTERN ANAL, V42, P1317, DOI 10.1109/TPAMI.2019.2899570
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Nasr M, 2021, IEEE ACCESS
   Olague G, 2019, MULTIMED TOOLS APPL, V78, P5881, DOI 10.1007/s11042-018-6634-9
   Qi YW, 2020, IEEE T SYST MAN CY-S, V50, P1442, DOI 10.1109/TSMC.2018.2801284
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rahman MM, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P271
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058
   Sun ZJ, 2021, MULTIMED TOOLS APPL, V80, P5351, DOI 10.1007/s11042-020-09713-9
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P930, DOI 10.1109/TMM.2018.2869277
   Wang SJ, 2020, IEEE T INTELL TRANSP, V21, P3409, DOI 10.1109/TITS.2019.2927838
   Wang YM, 2020, IEEE T GEOSCI REMOTE, V58, P7010, DOI 10.1109/TGRS.2020.2978512
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104188
   Xiao Y, 2019, IMAGE VISION COMPUT, V88, P67, DOI 10.1016/j.imavis.2019.05.003
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yang K, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106079
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 81
TC 7
Z9 7
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40761
EP 40782
DI 10.1007/s11042-023-15168-5
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961632300005
DA 2024-07-18
ER

PT J
AU Ehsaeyan, E
AF Ehsaeyan, Ehsan
TI An efficient image segmentation method based on expectation maximization
   and Salp swarm algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multilevel thresholding; Expectation maximization;
   Salp swarm algorithm; Artificial intelligence
ID REGION-SEGMENTATION; EDGE-DETECTION; THRESHOLD
AB Multilevel image thresholding using Expectation Maximization (EM) is an efficient method for image segmentation. However, it has two weaknesses: 1) EM is a greedy algorithm and cannot jump out of local optima. 2) it cannot guarantee the number of required classes while estimating the histogram by Gaussian Mixture Models (GMM). in this paper, to overcome these shortages, a novel thresholding approach by combining EM and Salp Swarm Algorithm (SSA) is developed. SSA suggests potential points to the EM algorithm to fly to a better position. Moreover, a new mechanism is considered to maintain the number of desired clusters. Twenty-four medical test images are selected and examined by standard metrics such as PSNR and FSIM. The proposed method is compared with the traditional EM algorithm, and an average improvement of 5.27% in PSNR values and 2.01% in FSIM values were recorded. Also, the proposed approach is compared with four existing segmentation techniques by using CT scan images that Qatar University has collected. Experimental results depict that the proposed method obtains the first rank in terms of PSNR and the second rank in terms of FSIM. It has been observed that the proposed technique performs better performance in the segmentation result compared to other considered state-of-the-art methods.
C1 [Ehsaeyan, Ehsan] Sirjan Univ Technol, Elect Engn Dept, Sirjan, Iran.
RP Ehsaeyan, E (corresponding author), Sirjan Univ Technol, Elect Engn Dept, Sirjan, Iran.
EM ehsaeyan@sirjantech.ac.ir
OI ehsaeyan, ehsan/0000-0002-8881-5911
CR Abdel-Basset M, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116145
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P11195, DOI 10.1007/s00521-019-04629-4
   Agrawal S, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2022.108172
   Asheri H, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107836
   Baltierra S, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104715
   Chakraborty S, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103324
   Chauhan J, 2021, BURNS, V47, P854, DOI 10.1016/j.burns.2020.08.016
   Chen XW, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2021.105179
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Feng CL, 2021, J BIOMECH, V119, DOI 10.1016/j.jbiomech.2020.110208
   Gao P, 2021, SCRIPTA MATER, DOI [10.2139/ssrn.3979931, DOI 10.2139/SSRN.3979931]
   Guo J, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106124
   Guo JQ, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106610
   GUO R, 2022, J HIGH ENERGY ASTROP, V510, P27965, DOI DOI 10.1016/J.OPTCOM.2022.127965
   Hait SR, 2022, INFORM FUSION, V80, P226, DOI 10.1016/j.inffus.2021.11.002
   Hu XY, 2022, CATENA, V209, DOI 10.1016/j.catena.2021.105840
   Huang B, 2021, COMPUT METH PROG BIO, V212, DOI 10.1016/j.cmpb.2021.106480
   Javed A, 2022, MECH SYST SIGNAL PR, V166, DOI 10.1016/j.ymssp.2021.108437
   Kassani SH, 2022, INT J MED INFORM, V159, DOI 10.1016/j.ijmedinf.2021.104669
   Kim WS, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106371
   Li XY, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103283
   Liang H, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103276
   Liu HJ, 2022, PATTERN RECOGN LETT, V154, P99, DOI 10.1016/j.patrec.2022.01.006
   Liu XW, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103165
   Lyu LF, 2022, J SOUND VIB, V525, DOI 10.1016/j.jsv.2022.116797
   Maksimovic V, 2021, OPTIK, V238, DOI 10.1016/j.ijleo.2021.166476
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Morozov S., 2020, ARXIV
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sathya PD, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114636
   Sowjanya K, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115286
   Sun B., 2022, Med. Nov. Technol. Devices, V14, DOI [10.1016/j.medntd.2022.100114, DOI 10.1016/J.MEDNTD.2022.100114]
   Swain M, 2022, ENG APPL ARTIF INTEL, V109, DOI 10.1016/j.engappai.2021.104599
   Tahir AM, COVID QU EXDATASET
   Tchinda BS., 2021, Informatics in Medicine Unlocked, V23, P100521, DOI [DOI 10.1016/J.IMU.2021.100521, 10.1016/j.imu.2021.100521]
   Umer S, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107917
   Webb JM, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104966
   Xu XY, 2011, PATTERN RECOGN LETT, V32, P956, DOI 10.1016/j.patrec.2011.01.021
   Yan LP, 2022, OPT LASER ENG, V148, DOI 10.1016/j.optlaseng.2021.106780
   Yang CY, 2022, SIGNAL PROCESS, V191, DOI 10.1016/j.sigpro.2021.108363
   Yang YY, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2021.116436
   Yang Z, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102670
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao HL, 2021, OPTIK, V247, DOI 10.1016/j.ijleo.2021.168037
   Zhao YQ, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103527
   Zhou ZH, 2021, DIGIT SIGNAL PROCESS, V114, DOI 10.1016/j.dsp.2021.103061
   Zhu ZM, 2022, OPTIK, V257, DOI 10.1016/j.ijleo.2022.168771
NR 47
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40625
EP 40655
DI 10.1007/s11042-023-15149-8
EA MAR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100010
PM 37362643
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kumar, L
   Singh, DK
AF Kumar, Lalit
   Singh, Dushyant Kumar
TI A comprehensive survey on generative adversarial networks used for
   synthesizing multimedia content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Generative adversarial networks;
   Architectural-variants; Applications of GAN; Artificial intelligence
ID IMAGE; GAN
AB GAN's are playing an important role in creating and generating a new set of data from the previously available content. GAN models are impressive in the results for image and video generation tasks. These models uses convolutional neural networks for generator and discriminator. GAN models are progressively improving by adding more latent approaches of deep learning. GAN model has been implemented for both supervised as well as unsupervised learning for various applications like image inpainting, image blending, video generation, music generation etc. During the implementation of the GAN model for all these applications, some issues arise during the training of discriminators like model collapse, Penalty Gradient etc. This manuscript contains a detailed survey of GAN models presented with varied classifications along with the challenges involved in GAN models. GAN is classified for all the domains in which GAN is used, i.e., Image, Video, and Audio. Along with all these things, we have described some applications where the GAN model is used. This manuscript also presents the performance of various GAN models for understanding its working with evaluation metrics (Qualitative and Quantitative).
C1 [Kumar, Lalit; Singh, Dushyant Kumar] MNNIT, CSED, Allahabad, UP, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Kumar, L (corresponding author), MNNIT, CSED, Allahabad, UP, India.
EM lalitkmr170@gmail.com; dushyant@mnnit.ac.in
RI Kumar, Lalit/JFK-9602-2023; Kumar, Lalit/ABX-0228-2022; Singh, Dushyant
   Kumar/AAD-8512-2021
OI Kumar, Lalit/0000-0002-8441-1696; 
CR Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Armanious K, 2020, COMPUT MED IMAG GRAP, V79, DOI 10.1016/j.compmedimag.2019.101684
   Babaeizadeh M., 2017, ARXIV
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Baraheem SS., 2023, ARTIF INTELL REV, V28, P1
   Biyani N, 2021, ARXIV
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Carreira J., 2018, arXiv
   Cha M, 2019, AAAI CONF ARTIF INTE, P3272
   Chang B, 2018, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2018.00028
   Chen BC, 2019, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2019.00861
   Clark A., 2019, arXiv
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Deng J, 2019, IEEE ACCESS, V7, P9848, DOI 10.1109/ACCESS.2019.2891668
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng KL, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2216
   Ding Z, 2019, ARXIV
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Dong H, 2017, IEEE I CONF COMP VIS, pCP1, DOI 10.1109/ICCV.2017.608
   Dong JF, 2022, IEEE T CIRC SYST VID, V32, P5680, DOI 10.1109/TCSVT.2022.3150959
   Gao Z, 2010, LECT NOTES COMPUT SC, V1
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gorti S.K., 2018, TEXT TO IMAGE TO TEX
   Grover A, 2018, AAAI CONF ARTIF INTE, P3069
   Gui J., 2020, arXiv
   Guimaraes GL., 2017, ARXIV
   Guo JT, 2019, NEUROCOMPUTING, V360, P75, DOI 10.1016/j.neucom.2019.06.010
   Hayashia H, 2019, ARXIV
   Hinton GE, 1993, ADV NEURAL INFORM PR, P3, DOI [DOI 10.1021/JP906511Z, DOI 10.5555/2987189.2987190]
   Hitawala S., 2018, arXiv
   Hong Y, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301282
   Huang J., 2019, ARXIV
   Ji B, 2019, ARXIV
   Kahembwe E, 2020, NEURAL NETWORKS, V132, P506, DOI 10.1016/j.neunet.2020.09.016
   Kaneko T, 2018, EUR SIGNAL PR CONF, P2100, DOI 10.23919/EUSIPCO.2018.8553236
   Kang X, 2021, IEEE INTERNET THINGS, V8, P636, DOI 10.1109/JIOT.2020.3018621
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim D, 2020, IEEE ACCESS, V8, P153113, DOI 10.1109/ACCESS.2020.3017881
   King DB, 2015, ACS SYM SER, V1214, P1
   Lee A.X., 2018, ARXIV
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Li B, 2019, ADV NEUR IN, V32
   Li ZY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107471
   Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194
   Liao WT, 2022, PROC CVPR IEEE, P18166, DOI 10.1109/CVPR52688.2022.01765
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J, 2019, J SUPERCOMPUT, V75, P1922, DOI 10.1007/s11227-017-2218-0
   Liu MY, 2021, P IEEE, V109, P839, DOI 10.1109/JPROC.2021.3049196
   Liu MY, 2017, ADV NEUR IN, V30
   Liu XY, 2018, IEEE IMAGE PROC, P873, DOI 10.1109/ICIP.2018.8451049
   Liu Yinhan, 2019, ARXIV190711692
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1239, DOI 10.1145/3343031.3350986
   Lu JC, 2020, ASIAPAC SIGN INFO PR, P514
   Luc P, 2020, ARXIV
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mittal G, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1096, DOI 10.1145/3123266.3123309
   Mogren O., 2016, ARXIV
   Mukherjee P, 2019, ARXIV
   Nam S, 2018, ADV NEUR IN, V31
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Radford A., 2015, ARXIV
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Reed S, 2016, PR MACH LEARN RES, V48
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Sanyal S, SUPPLEMENTARY DATA F
   Sebastian L, 2018, ARXIV
   Seyfi, 2022, ARXIV
   Siarohin A, 2019, ARXIV
   Sikder F., 2019, P INT JOINT C COMPUT, P547
   Su DY, 2009, ANAT REC, V292, P854, DOI 10.1002/ar.20910
   Sun AY, 2018, GEOPHYS RES LETT, V45, P11137, DOI 10.1029/2018GL080404
   Sushko V, 2021, ARXIV
   Sushko V, 2021, IEEE COMPUT SOC CONF, P2596, DOI 10.1109/CVPRW53098.2021.00293
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Vuppuluri M., 2017, INT J ENG RES COMPUT, V11, P4
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang R., 2023, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z., 2019, arXiv
   Wen SP, 2019, IEEE T CIRC SYST VID, V29, P2337, DOI 10.1109/TCSVT.2018.2867934
   Wu C., 2021, arXiv
   Wu LZ, 2020, INT TEST CONF P, DOI 10.1109/ITC44778.2020.9325258
   Wu YF, 2019, J COMPUT SCI TECH-CH, V34, P47, DOI 10.1007/s11390-019-1898-8
   Xiong F, 2019, IEEE ACCESS, V7, P126651, DOI 10.1109/ACCESS.2019.2939654
   Yamamoto S, 2018, ARXIV
   Yan W., 2021, ARXIV
   Yang X., 2019, ARXIV
   Yang Y, 2021, IEEE T CIRC SYST VID, V31, P4771, DOI 10.1109/TCSVT.2021.3054584
   Ye ZH, 2019, IEEE INT CON MULTI, P85, DOI 10.1109/ICME.2019.00023
   Yin GJ, 2019, PROC CVPR IEEE, P2322, DOI 10.1109/CVPR.2019.00243
   Zhang Hantian, 2016, ARXIV
   Zhao Z, 2020, IEEE T IMAGE PROCESS, V29, P3859, DOI 10.1109/TIP.2020.2963950
NR 102
TC 5
Z9 5
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40585
EP 40624
DI 10.1007/s11042-023-15138-x
EA MAR 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100009
DA 2024-07-18
ER

PT J
AU Madri, VR
   Meruva, S
AF Madri, Vijaya Raju
   Meruva, Sreenivasulu
TI A comprehensive review on MCQ generation from text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Automatic question generation; Multiple choice questions; Corpus-based
   distractors; Natural language processing; and Computer-aided evaluation
ID INFORMATION-RETRIEVAL; AUTOMATIC-GENERATION; QUESTIONS
AB While to save time, effort, and money by making and generating standard multiple choice questions and generation through text is important and it is the current necessity for all educational institutes like universities, colleges, schools, coaching centers, etc., through online as well as offline. The automatic multiple choice questions generation tools are also useful for all basic and expert users in their subject knowledge field. This paper's aim is to understand the various approaches involved in question generation, key selection, and distractor selection based on current trends, needs. In this paper, the precised methods for MCQs generation in different stages has mentioned, and also the areas for improvement in the quality of generating the automatic multiple choice questions based on the text were also suggested. The learner's or stakeholders understood easily based on the understanding of the techniques of the stages for generation of automatic MCQs selection and generations in various domain applications of an unstructured text.
C1 [Madri, Vijaya Raju; Meruva, Sreenivasulu] Jawaharlal Nehru Technol Univ, RM Coll Engn, Anantapur, India.
   [Madri, Vijaya Raju; Meruva, Sreenivasulu] KSRM Coll Engn, Dept Comp Sci & Engn, Kadapa, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Madri, VR (corresponding author), Jawaharlal Nehru Technol Univ, RM Coll Engn, Anantapur, India.; Madri, VR (corresponding author), KSRM Coll Engn, Dept Comp Sci & Engn, Kadapa, India.
EM vijayaraju2122@gmail.com; meruva7@gmail.com
CR Afzal N, 2014, SOFT COMPUT, V18, P1269, DOI 10.1007/s00500-013-1141-4
   Agarwal M., 2011, Proc. of the sixth workshop on innovative use of NLP for building educational applications, P56
   Agarwal M., 2012, CLOZE OPEN CLOZE QUE
   Agarwal R, 2022, LECT NOTES COMPUT SC, V13145, P260, DOI 10.1007/978-3-030-94876-4_18
   Aldabe I, 2007, WORKSH NAT LANG PROC
   Aldabe I, 2006, LECT NOTES COMPUT SC, V4053, P584
   Aldabe I, 2014, IEEE T LEARN TECHNOL, V7, P375, DOI 10.1109/TLT.2014.2355831
   Aldabe I, 2010, LECT NOTES ARTIF INT, V6233, P27, DOI 10.1007/978-3-642-14770-8_5
   Aldabe I, 2009, FRONT ARTIF INTEL AP, V200, P656, DOI 10.3233/978-1-60750-028-5-656
   [Anonymous], 2008, Proceedings of ACL-08: HLT
   Araki J., 2016, P COLING 2016 26 INT, P1125
   Azad HK, 2022, PATTERN RECOGN LETT, V158, P148, DOI 10.1016/j.patrec.2022.04.013
   Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009
   Bednarik L, 2012, 3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM 2012), P687
   BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861
   Brown J.C., 2005, P C HUM LANG TECHN E, P819, DOI DOI 10.3115/1220575.1220678
   Chen C.Y., 2006, P COLING ACL INT PRE, P1, DOI [10.3115/1225403.1225404., DOI 10.1109/GLOCOM.2006.500, DOI 10.3115/1225403.1225404]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chu MH, 2012, CONF TECHNOL APPL, P125, DOI 10.1109/TAAI.2012.38
   Coniam D., 1997, CALICO Journal, V14, P15
   Correia Rui, 2012, Computational Processing of the Portuguese Language. Proceedings of the 10th International Conference, PROPOR 2012, P168, DOI 10.1007/978-3-642-28885-2_19
   Correia R., 2010, Second Language Studies: Acquisition, Learning, Education and Technology
   Curto SdSL., 2010, AUTOMATIC GENERATION
   Das Bidyut, 2018, International Journal of Modern Education and Computer Science, V10, P57, DOI 10.5815/ijmecs.2018.01.06
   Das B, 2022, COGN SYST RES, V72, P14, DOI 10.1016/j.cogsys.2021.11.002
   Das B, 2017, INT J EDUC TECHNOL H, V14, DOI 10.1186/s41239-017-0060-3
   Feeney CM, 2008, LECT NOTES COMPUT SC, V5091, P659
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Goto T., 2009, PROC 17 INT C COMPUT, P415
   Goto T, 2010, KNOWL MANAG E-LEARN, V2, P210
   Heilman M, 2007, WORKSHOP SPEECH LANG
   Heilman M., 2010, HUMAN LANGUAGE TECHN, P609
   Ho Chung Wu, 2008, ACM Transactions on Information Systems, V26
   Hoshino A., 2005, Proceedings of the Second Workshop on Building Educational Applications Using NLP, P17
   Hoshino A., 2007, PROC SOC INF TECHNOL, P2807
   Karamanis N., 2006, P 4 INT NAT LANG GEN, P111
   Kim Y, 2019, AAAI CONF ARTIF INTE, P6602
   Kumar Girish., 2015, IEEE FRONTIERS ED C, P1
   Kurtasov A, 2013, P STUD RES WORKSH AS, P107
   Lee H., 2011, P 15 C COMPUTATIONAL, P28
   Li J, 2019, TURK J ELECTR ENG CO, V27, P1794, DOI 10.3906/elk-1806-38
   Lindberg D., 2013, P 14 EUR WORKSH NAT, P105
   Liu C., 2005, Proceedings of the Second Workshop on Building Educational Applications using Natural Language Processing, P1, DOI 10.3115/1609829.1609830
   Liu M, 2018, IEEE T LEARN TECHNOL, V11, P193, DOI 10.1109/TLT.2017.2679009
   Liu M, 2017, IEEE T LEARN TECHNOL, V10, P194, DOI 10.1109/TLT.2016.2565477
   Majumder M., 2015, P 2 WORKSH NAT LANG, P64, DOI DOI 10.18653/V1/W15-4410
   Malinova A, 2016, PROC CBU, V4, P906, DOI 10.12955/cbup.v4.794
   Mannem P, 2010, OPEN U REPOSITORY RE
   Maurya KK, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1115, DOI 10.1145/3340531.3411997
   Mazidi K, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P321
   Metzler D, 2005, INFORM RETRIEVAL, V8, P481, DOI 10.1007/s10791-005-6995-3
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Mitkov R., 2006, Natural Language Engineering, V12, P177, DOI 10.1017/S1351324906004177
   Mitkov R, 2003, 2003 INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING, PROCEEDINGS, P15
   MITKOV R, 2009, P WORKSH GEOM MOD NA, P49
   Mokhtar M., 2021, INT J INTELL COMPUT, V21, P110
   Mostow J, 2009, FR ART INT, V200, P465, DOI 10.3233/978-1-60750-028-5-465
   Narendra A., 2013, P RECENT ADV NATURAL, P511
   Nielsen RD, 2008, P WORKSH QUEST GEN S
   Pabitha P, 2014, INT C REC TRENDS INF, P1
   Papasalouros A., 2008, E LEARNING, P427
   Perez-Beltrachini L., 2012, P 7 WORKSH BUILD ED, P147
   Pino J., 2008, P WORKSH INT TUT SYS, P22
   Qiu XY, 2021, INT CONF ASIAN LANG, P125, DOI 10.1109/IALP54817.2021.9675153
   Rao CHD, 2020, IEEE T LEARN TECHNOL, V13, P14, DOI 10.1109/TLT.2018.2889100
   Satria AY, 2017, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P379, DOI 10.5220/0006320203790386
   Satria AY, 2017, EVALUATION AUTOMATIC
   SEYLER D, 2017, ASS COMPUTING MACHIN
   Shah R, 2012, AUTOMATIC QUESTION G, P31
   Shah R, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS, COMPUTING AND IT APPLICATIONS (CSCITA), P127, DOI 10.1109/CSCITA.2017.8066538
   Smith S., 2010, Practical tourism research, P1, DOI 10.1079/9781845936327.0001
   Sproat R., 2001, Computer Speech and Language, V15, P287, DOI 10.1006/csla.2001.0169
   Srivastava S., 2017, INT J COMPUTER APPL, V163, P0975, DOI DOI 10.5120/IJCA2017913757
   Stancheva NS, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P741, DOI 10.1109/IS.2016.7737395
   Subramanian S, 2017, ARXIV
   Sumita Eiichiro, 2005, P 2 WORKSH BUILD ED, P61
   Sung L-C, 2007, TECHN ENH LEARN C TE, P161
   Sung LC, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P196, DOI 10.1109/ICALT.2007.56
   Susanti Yuni, 2017, Res Pract Technol Enhanc Learn, V12, P11, DOI 10.1186/s41039-017-0051-y
   Susanti Y, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION, VOL 1 (CSEDU), P267, DOI 10.5220/0005775502670274
   Venitha ME, 2021, INT J ADV ENG SCI IN, V4
   Vinu EV, 2016, ARXIV
   Yao X., 2010, P QG2010 3 WORKSH QU, P68
NR 83
TC 1
Z9 1
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39415
EP 39434
DI 10.1007/s11042-023-14768-5
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500015
DA 2024-07-18
ER

PT J
AU Zakzouk, A
   El-Sayed, A
   Hemdan, EE
AF Zakzouk, Amaal
   El-Sayed, Ayman
   Hemdan, Ezz El-Din
TI A blockchain-based electronic medical records management framework in
   smart healthcare infrastructure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart contract; Ethereum; Healthcare management; Blockchain; Electronic
   medical record; Decentralization; Medical data storage
ID TECHNOLOGY; CHAIN
AB Electronic medical records are considered the main component in the health organizations' system. Recently, the reputation of medical information patients and their privacy is very imperative in the healthcare realm. Therefore, this information is epitomized as proof of social insurance and governance such as the medical conflicts, and medical health insurance. In the last decades, health organizations face more problems regarding medical information management to save the privacy of patient information. Privacy is the main issue for achieving the security of the patients' information in smart healthcare applications. Hence, there is a grave necessity to use the blockchain. The blockchain can be used for achieving transparency and security in medical applications. This helps to attain the possibility of making a trustable and secure healthcare system. Likewise, this paper presents a blockchain-based Electronic Medical Records (EMR) management framework in smart healthcare infrastructure in the context of smart cities. The proposed framework is utilized blockchain technology for providing security and privacy in healthcare organizations, especially for healthcare information management, and supplies secure storage of electronic records presented in this paper. Therefore, privacy can be preserved through the proposed blockchain approach as illuminated in the proposed system. Moreover, it aims for solving the problem of the scalability that faces the blockchain by using off-chain storage for the records and ensuring the authenticity and integrity of the medical record. In addition, more essential is stressing the ownership of the medical record which is the only property of the patient, not any other entity.
C1 [Zakzouk, Amaal] Alexandria Higher Inst Engn & Technol, Alexandria, Egypt.
   [El-Sayed, Ayman; Hemdan, Ezz El-Din] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
EM ezzvip@yahoo.com
RI EL-SAYED, Ayman E./AFM-8547-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X
CR Agbo CC, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020056
   Al Omar A., 2017, INT C SEC PRIV AN CO
   Al Omar A, 2019, FUTURE GENER COMP SY, V95, P511, DOI 10.1016/j.future.2018.12.044
   Alshagathrh F, 2018, INT J MED INFORM, V118, P113, DOI 10.1016/j.ijmedinf.2018.08.005
   builtin.com, US
   Chen HS, 2019, BIOMED J SCI TECHNOL, V20, P15017, DOI DOI 10.26717/BJSTR.2019.20.003448
   Chen MJ, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102771
   Dhillon V, 2021, BLOCKCHAIN ENABLED A, P201
   Dhillon V, 2021, BLOCKCHAIN RES APPL, P357
   Dubovitskaya A, 2017, VLDB WORKSH DAT MAN
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   El-Din Hemdan Ezz, 2020, DIGIT INVEST, P615
   Engelhardt MA, 2017, TECHNOL INNOV MANAG, V7, P22, DOI 10.22215/timreview/1111
   Griggs KN, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0982-x
   Gupta M, 2021, APPL BLOCKCHAIN HEAL, P93, DOI DOI 10.1007/978-981-15-9547-9_4
   Hemdan E.E.D., 2021, EAI/Springer Innovations in Communication and Computing, P177
   Hemdan EE, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03732-0
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Hemdan EE, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Hu J, 2021, IEEE T CIRC SYST VID
   Hussien HM, 2021, J IND INF INTEGR, V22, DOI 10.1016/j.jii.2021.100217
   Investing.com, ABOUT US
   Kamal R, 2021, 2021 INT C ELECT ENG
   Kamal R, 2021, MULTIMED TOOLS APPL, V80, P36183, DOI 10.1007/s11042-021-11350-9
   Kumar R., 2020, Blockchain Cybersecurity, Trust and Privacy, P185
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Mahmoud ASA, 2021, HDB RES DEV SMART CI, P48
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   merehead.com, IMPL BLOCKCH TECHN H
   Miyachi K, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102535
   Nguyen D.C., 2021, ARXIV
   Nwagwu U, 2020, THESIS WICHITA STATE
   Pirtle C, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1025-3
   Pustokhin D.A, 2021, Applications of Blockchain in Healthcare, P253
   Sharaf M, 2021, MULTIMED TOOLS APPL, V80, P17923, DOI 10.1007/s11042-021-10579-8
   Shen BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061207
   Singh K, 2017, FUTURE GENER COMP SY, V72, P250, DOI 10.1016/j.future.2016.11.028
   Usman M, 2021, BLOCKCHAIN HEALTHCAR
   Vahdati M., 2021, Appl. Blockchain Healthc., V83, P141
   Wang X, 2019, INT S SEC PRIV SOC N
   Yang JJ, 2015, FUTURE GENER COMP SY, V43-44, P74, DOI 10.1016/j.future.2014.06.004
   Yoon HJ, 2019, HEALTHC INFORM RES, V25, P59, DOI 10.4258/hir.2019.25.2.59
NR 43
TC 5
Z9 6
U1 9
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35419
EP 35437
DI 10.1007/s11042-023-15152-z
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000956327700002
DA 2024-07-18
ER

PT J
AU Hu, WF
   Zhang, Y
   Li, YJ
   Zhao, J
   Hu, XF
   Cui, Y
   Wang, XJ
AF Hu, Weifeng
   Zhang, Yu
   Li, Yujun
   Zhao, Jia
   Hu, Xifeng
   Cui, Yan
   Wang, Xuejing
TI Query-based video summarization with multi-label classification network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Query-based video summarization; User subjectivity;
   Multi-label classification; Label correlation
ID AVERAGING FUSION STRATEGY
AB Generic video summarization algorithms are characterized by the uniqueness of the final video summary result, which cannot satisfy the different summary requirements of different users for the same video. This paper addresses the task of query-based video summarization, which takes users' queries and long videos as inputs and aims to generate a query-based video summary. In this article, we propose a query-based video summarization algorithm with a multi-label classification network (MLC-SUM). Specifically, we treat video summarization as a target-based multi-label classification problem, and predict the correlation between video content and multi-concept labels by inputting convolutional features into a multi-layer perceptron, then use the cross-correlation of the labels to weight the predicted probability. Finally, we select the part of the video content with the highest relevance to the user's query sentence as the video summary output. Experiments on three common datasets verify the effectiveness and superiority of the proposed algorithm.
C1 [Hu, Weifeng; Zhang, Yu; Li, Yujun; Zhao, Jia; Hu, Xifeng; Wang, Xuejing] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266200, Peoples R China.
   [Zhang, Yu] State Grid China Technol Coll, Jinan 250002, Peoples R China.
   [Cui, Yan] Chinese Acad Social Sci, Inst Sociol, Beijing 100732, Peoples R China.
C3 Shandong University; Chinese Academy of Social Sciences
RP Hu, WF (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao 266200, Peoples R China.
EM huweifeng@mail.sdu.edu.cn; yuzhang_2017@163.com; liyujun@sdu.edu.cn
RI wang, yingying/GRS-3058-2022; Li, Yujun/HGE-8719-2022
FU National key Research and Development plan [2020YFC0832600]
FX AcknowledgmentsThe work is supported by National key Research and
   Development plan (2020YFC0832600).
CR Cizmeciler K, 2022, MULTIMED TOOLS APPL, V81, P17457, DOI 10.1007/s11042-022-12442-w
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Fajtl J, 2019, LECT NOTES COMPUT SC, V11367, P39, DOI 10.1007/978-3-030-21074-8_4
   Fakhar B, 2019, MULTIMED TOOLS APPL, V78, P16995, DOI 10.1007/s11042-018-7083-1
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Gong BQ, 2014, ADV NEUR IN, V27
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hussain T, 2020, IEEE T IND INFORM, V16, P77, DOI 10.1109/TII.2019.2929228
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Jiang YD, 2019, IEEE INT CONF COMP V, P1562, DOI 10.1109/ICCVW.2019.00195
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Kwon H, 2019, IEEE INT CONF COMP V, P1541, DOI 10.1109/ICCVW.2019.00192
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887
   Madheswari K, 2015, QUANT INFR THERM J, P1, DOI [10.21611/qirt.2015.0101, DOI 10.21611/QIRT.2015.0101]
   Mahasseni B, 2017, PROC CVPR IEEE, P2982, DOI 10.1109/CVPR.2017.318
   Mini Zeng, 2011, Proceedings 2011 Fourth International Conference on Information Management, Innovation Management and Industrial Engineering (ICIII 2011), P205, DOI 10.1109/ICIII.2011.332
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Vasudevan AB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P582, DOI 10.1145/3123266.3123297
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Xiao SW, 2020, AAAI CONF ARTIF INTE, V34, P12426
   Xiao SW, 2020, IEEE T IMAGE PROCESS, V29, P5889, DOI 10.1109/TIP.2020.2985868
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang Y., 2021, RES VIDEO SUMMARIZAT
   Zhang YJ, 2018, Arxiv, DOI arXiv:1807.06677
   Zhong R, 2021, IEEE SIGNAL PROC LET, V28, P663, DOI 10.1109/LSP.2021.3066349
   Zhou KY, 2018, Arxiv, DOI arXiv:1801.00054
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 40
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 22
PY 2023
DI 10.1007/s11042-023-15126-1
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XB0
UT WOS:000954481800002
DA 2024-07-18
ER

PT J
AU Zhang, Z
   Li, H
   Yu, Y
   Qin, HL
   Wang, DB
   Zhou, HX
   Song, SZ
   Liu, YY
AF Zhang, Zhe
   Li, Huan
   Yu, Yue
   Qin, Hanlin
   Wang, Dabao
   Zhou, Huixin
   Song, Shangzhen
   Liu, Yanyan
TI A real-time omnidirectional target detection system based on FPGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time; Dim and small targets; Cascaded guided image filter; One-line
   cache; FPGA
AB The Field Programmable Gate Array (FPGA) has been widely used in time-critical tasks such as object detection and tracking. To better accomplish the above tasks, the detection range of the system becomes more and more important. Therefore, a real-time omnidirectional target detection system was carried out. In this system, a dim and small target detection method based on cascaded guided image filter (CGIF) is proposed. Our FPGA-based system shows excellent performance in dim and small target detection with the high detection rate (94%) and the low false alarm rate (5%). First, a target detection algorithm based on cascaded guided image filter is introduced, where the details of large objects can be well suppressed, and the targets are extracted through background suppression and clustering. Second, we design an FPGA-based system, which contains multichannel videos as input through Peripheral Component Interconnect Express (PCIE) interfaces, based on mother-daughter architecture for real-time implementation. Moreover, we also propose a one-line cache display method to exhibit the detection results, which can save much storage space with the same display effect compared with the traditional cache-based scheme. The experimental results show that the proposed system has promising performance and efficiency.
C1 [Zhang, Zhe; Li, Huan; Yu, Yue; Qin, Hanlin; Zhou, Huixin; Song, Shangzhen] Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
   [Wang, Dabao] Beijing Inst Spacecraft Syst Engn, Beijing 100094, Peoples R China.
   [Liu, Yanyan] Sci & Technol Electroopt Informat Secur Control La, Tianjin 300022, Peoples R China.
C3 Xidian University
RP Li, H (corresponding author), Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
EM huanli@xidian.edu.cn
RI Wang, Dabao/ISA-9233-2023
OI Wang, Dabao/0000-0002-4199-4318
FU Equipment Development Research and Key Laboratory Foundation Project of
   China [6142107200208]; Equipment Development Research Project of China
   [61404130316, 61404140506, 61409230214]
FX AcknowledgementsThis work was supported by Equipment Development
   Research and Key Laboratory Foundation Project of China(6142107200208)
   and Equipment Development Research Project of China(61404130316,
   61404140506, 61409230214).
CR Bae TW, 2009, J INFRARED MILLIM TE, V30, P1092, DOI 10.1007/s10762-009-9530-6
   Bai XZ, 2018, IEEE T GEOSCI REMOTE, V56, P2452, DOI 10.1109/TGRS.2017.2781143
   Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Cheng KH, 2021, J REAL-TIME IMAGE PR, V18, P75, DOI 10.1007/s11554-020-00950-7
   Clerentin A, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P1499, DOI 10.1109/IROS.2000.893232
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Farajzadeh M., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P1097, DOI 10.1109/IranianCEE.2012.6292518
   Hagras EAA, 2020, MULTIMED TOOLS APPL, V79, P23203, DOI 10.1007/s11042-019-08517-w
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He Y., 2021, CHIN C PATT REC COMP, P117
   Henzinger TA, 2006, LECT NOTES COMPUT SC, V4085, P1
   Jiang J., 2015, J REAL-TIME IMAGE PR, V15, P1
   Masahiko Y, 1998, COMPUTER VISION VIRT, DOI 10.1109CV-VRHC.1998-06-03,660367
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Phadikar A, 2020, MULTIMED TOOLS APPL, V79, P12507, DOI 10.1007/s11042-019-08392-5
   Qian K, 2017, INFRARED PHYS TECHN, V85, P431, DOI 10.1016/j.infrared.2017.07.004
   Rawat SS, 2020, PROCEDIA COMPUT SCI, V167, P2496, DOI 10.1016/j.procs.2020.03.302
   Shenghui R, 2017, INFRARED PHYS TECHN
   Sivaraman R, 2020, MULTIMED TOOLS APPL, V79, P13841, DOI 10.1007/s11042-019-08592-z
   Song S, 2019, IEEE J-STARS
   Wang HX, 2019, LASER OPTOELECTRON P, V56, DOI 10.3788/LOP56.080001
   Wang J, 2018, 2018 IEEE 16 INT C D
   [叶斌 Ye Bin], 2002, [中国图象图形学报. A, Journal of image and graphics], V7, P638
   Zeng M, 2006, INFRARED PHYS TECHN, V48, P67, DOI 10.1016/j.infrared.2005.04.006
   [朱建鑫 Zhu Jianxin], 2019, [电工技术学报, Transactions of China Electrotechnical Society], V34, P777
   Zou T, 2018, AUTOMATIC TARGET REC
NR 26
TC 0
Z9 0
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30929
EP 30947
DI 10.1007/s11042-023-14585-w
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000983548500005
DA 2024-07-18
ER

PT J
AU Ouni, S
   Fkih, F
   Omri, MN
AF Ouni, Sarra
   Fkih, Fethi
   Omri, Mohamed Nazih
TI A survey of machine learning-based author profiling from texts analysis
   in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Author profiling; Social networkings; Text analysis; Machine learning;
   Performance evaluation
ID ATTRIBUTION
AB Recently, online social networks, such as Twitter, Facebook, LinkedIn, etc., have grown exponentially with a large amount of information. These social networks have huge volumes of data, especially in textual form, which are unstructured and anonymous. This type of data usually leads to cybercrimes like cyberbullying, cyberterrorism, etc. and their analysis has nowadays become a serious challenge. From this perspective and to remedy this topical issue, various techniques have been proposed in the literature. Among the proposed solutions, author profiling represents the newest and most adopted technique by most researchers to discover hidden textual information. The objective of this technique is to identify the demographic or psychological aspects (age, sex, personality, mother tongue, etc.) of an author by examining the text that he has published. In recent years, this area of research has attracted many researchers who seek solutions for potential applications in various fields like marketing, computer forensics, security, etc. Within the scope of this article, we describe the author profiling task. Then, we present a brief thematic taxonomy and an illustration of some profiling solutions from the literature. In particular, different machine and deep learning techniques are detailed and discussed. This work also provides an overview of the main approaches, which we have studied in the literature, highlights the weak points and the strong points of each of these approaches. At the end of this study, a discussion of some research questions is presented and some future directions to circumvent the weaknesses detected in the approaches studied are presented in order to motivate academics and practitioners, who are interested in this problem that we assume essential, to advance solutions for profiling perpetrators on social networks.
C1 [Ouni, Sarra; Fkih, Fethi; Omri, Mohamed Nazih] Univ Sousse, MARS Res Lab LR 17ES05, Sousse, Tunisia.
   [Fkih, Fethi] Qassim Univ, Coll Comp, Dept Comp Sci, Buraydah, Saudi Arabia.
C3 Universite de Sousse; Qassim University
RP Ouni, S (corresponding author), Univ Sousse, MARS Res Lab LR 17ES05, Sousse, Tunisia.
EM sarraouni93@gmail.com; f.fki@qu.edu.sa;
   mohamednazih.omri@eniso.u-sousse.tn
RI Fkih, Fethi/AAG-6213-2020
OI Fkih, Fethi/0000-0001-8937-9616
CR Abbasi A, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1344411.1344413
   Akimushkin C, 2018, PHYSICA A, V495, P49, DOI 10.1016/j.physa.2017.12.054
   Alvarez-Carmona MA, 2018, J INTELL FUZZY SYST, V34, P3133, DOI 10.3233/JIFS-169497
   Alvarez-Carmona MA, 2016, LECT NOTES ARTIF INT, V10022, P151, DOI 10.1007/978-3-319-47955-2_13
   Anjum MW., 2018, INT J COMPUT METH EN, V9, P322
   Ashraf S, 2019, CLEF
   Ashraf S., 2016, WORKING NOTES PAPERS, P992
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Basile A, 2017, Arxiv, DOI arXiv:1707.03764
   Basti R, 2019, WEBIST: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, P110, DOI 10.5220/0008167401100117
   Bayot R, 2016, I C SOFTWARE KNOWL I, P382, DOI 10.1109/SKIMA.2016.7916251
   Bentolila I, 2011, Google Patents, Patent No. [8,046,797, 8046797]
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Bougiatiotis K., 2016, CEUR Workshop Proceedings, V1609, P836
   Boukhari K, APPROXIMATE MATCHING
   Bsir B, 2018, COMPUT SIST, V22, P757, DOI 10.13053/CyS-22-3-3036
   Cui LS, 2017, EXPERT SYST APPL, V83, P94, DOI 10.1016/j.eswa.2017.03.075
   Daneshvar S., 2018, P 9 INT C CLEF ASS C
   Dias R F S, 2019, C LABS EV FOR
   Escalante H J, 2015, EARLY TEXT CLASSIFIC
   Fatima M, 2017, INFORM PROCESS MANAG, V53, P886, DOI 10.1016/j.ipm.2017.03.005
   Fernquist J, 2019, CEUR WORKSHOP PROC, V2380
   Flekova L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P313
   Fourkioti O, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102061
   Gamallo P, 2019, CEUR WORKSHOP PROC, V2380
   Giachanou A, 2020, LECT NOTES COMPUT SC, V12089, P181, DOI 10.1007/978-3-030-51310-8_17
   Johansson F, 2019, CEUR WORKSHOP PROC, V2380
   Joo Y, 2019, AUTHOR PROFILING SOC, P2380
   Juola P., 2015, MATH COMPUT SCI IND, P21
   Kaati L, 2017, EUR INTELL SECUR INF, P155, DOI 10.1109/EISIC.2017.32
   Kapociute-Dzikiene J, 2018, FED CONF COMPUT SCI, P169, DOI 10.15439/2018F22
   Kodiyan D, 2017, CLEF 2017 C LABS EV, V1866
   Kovacs G, 2019, AUTHOR PROFILING USI, V2019, P2380
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Lakkaraju SK, 2018, ENCYCLOPEDIA OF INFORMATION SCIENCE AND TECHNOLOGY, 4TH EDITION, P3861, DOI 10.4018/978-1-5225-2255-3.ch335
   Mabrouk Olfa, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P547, DOI 10.1109/FSKD.2018.8687216
   Mabrouk O., 2018, ISAIM
   Ortega-Mendoz RM, 2018, KNOWL-BASED SYST, V145, P169, DOI 10.1016/j.knosys.2018.01.014
   Ortega-Mendoza RM, 2016, LECT NOTES COMPUT SC, V9822, P110, DOI 10.1007/978-3-319-44564-9_9
   Mechti S, 2016, RES COMPUT SCI, V110, P129, DOI DOI 10.13053/RCS-110-1-11
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Moreno-Sandoval LG, 2019, CELEBRITY PROFILING
   NagaPrasad S, 2015, PROCEDIA COMPUT SCI, V48, P58, DOI 10.1016/j.procs.2015.04.110
   Najib F, 2015, CEUR WORKSHOP PROC, V1391
   Ouni S, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00768-6
   Palomino-Garibay A, 2015, 1391 CLEF, V1391
   Para U., 2021, ENG, V6, P2868
   Pardo Rangel, 2015, CEUR Workshop Proceedings, P1, DOI DOI 10.1007/S13398-014-0173-7.2
   Park G, 2015, J PERS SOC PSYCHOL, V108, P934, DOI 10.1037/pspp0000020
   Pennacchiotti M, 2011, KDD '11, P430, DOI DOI 10.1145/2020408.2020477
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Posadas-Duran J-P, 2015, 1391 CLEF, V1391
   Poulston Adam, 2017, WORKING NOTES CLEF 2, V1866
   Puertas E, 2019, BOTS GENDER PROFILIN, P2380
   Rangel F., 2013, CEUR WORK PROC CEUR, V1096, P34
   Rangel F, 2017, Working notes papers of the CLEF, P1613
   Rangel F, 2014, CLEF 2014 Evaluation Labs and Workshop Working Notes Papers, Sheffield, UK, 2014, V1180, P898
   Rangel F., 2019, PROC CEUR WORKSHOP
   Rangel F., 2013, CEUR Workshop Proceedings, P352
   Rangel F, 2019, WORKING NOTES FORUM
   Rangel F, 2016, INFORM PROCESS MANAG, V52, P73, DOI 10.1016/j.ipm.2015.06.003
   Rico-Sulayes A, 2011, INT J SPEECH LANG LA, V18, P53, DOI 10.1558/ijsll.v18i1.53
   Rosso P., 2020, SN COMPUT SCIE, V1, P1, DOI [10.1007/s42979-020-0073-1, DOI 10.1007/S42979-020-0073-1]
   Safara F, 2020, IEEE ACCESS, V8, P48428, DOI 10.1109/ACCESS.2020.2973509
   Sboev A, 2016, PROCEDIA COMPUT SCI, V101, P135, DOI 10.1016/j.procs.2016.11.017
   Schwartz HA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073791
   Sendi M, 2019, J AMB INTEL HUM COMP, V10, P3409, DOI 10.1007/s12652-018-1050-6
   Sharma M.L., 2018, P 10 ANN M FOR INF R, P16
   Sierra S, 2017, CONVOLUTIONAL NEURAL
   Soler J., 2016, P 10 INT C LANG RES, P1282
   Takahashi T, 2018, TEXT IMAGE SYNERGY F
   Villena-Roman J, 2014, CEUR WORKSHOP PROC, V1180, P1157
   Yang M, 2018, NEUROCOMPUTING, V273, P133, DOI 10.1016/j.neucom.2017.08.022
   Zhang W, 2016, P 10 INT C LANG RES, P2990
NR 74
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-14711-8
EA MAR 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900009
DA 2024-07-18
ER

PT J
AU Rao, KM
   Saikrishna, G
   Supriya, K
AF Rao, K. Mallikharjuna
   Saikrishna, Ghanta
   Supriya, Kundrapu
TI Data preprocessing techniques: emergence and selection towards machine
   learning models-a practical review using HPA dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE MCAR; MAR; MNAR; Mean and median imputation; KNN imputation; Arbitrary
   imputation; End of tail imputation; One-hot encoding; Ordinal encoding;
   Mean encoding; Label encoding; KNN discretization; Decision tree
   discretization; Equal width and frequency discretization; IQR outlier
   handling; Grubbs test; DBSCAN clustering; Isolation Forest;
   Normalization and standardization
ID MISSING DATA; OUTLIER DETECTION; IMPUTATION; NORMALIZATION
AB To compute the frequent metamorphosis of the housing price, the House Price Index (HPI) is one of the effective indicators. Various methodologies are involved in data processing the current house prices, which are affected by factors like house configuration, building class, air conditioning quality, etc. Remarkably, more research papers adopting classical machine learning approaches are introduced to estimate house sale prices accurately. Still, they barely regard the data processing techniques that make the data suitable for modeling more accurate house prices forecasting architectures. This research contributes to a wide variety of adequate data pre-processing. It highlights mechanisms like missingness of data, missing data handling, categorical feature encoding, discretization, outliers, and feature scaling extensively to build efficient predictive models. Comprehensive arguments have been broadly presented to portray the advantages and disadvantages of prevailed data pre-processing techniques at various distribution scenarios of variables in the house price data. The current research conclusions oblige the evolution of modern data-driven research in machine learning.
C1 [Rao, K. Mallikharjuna; Saikrishna, Ghanta] Int Inst Informat Technol Naya Raipur, Data Sci & Artificial Intelligence, Naya Raipur, India.
   [Supriya, Kundrapu] Int Inst Informat Technol Naya Raipur, Comp Sci & Engn, Naya Raipur, India.
RP Rao, KM; Saikrishna, G (corresponding author), Int Inst Informat Technol Naya Raipur, Data Sci & Artificial Intelligence, Naya Raipur, India.
EM rao.mkrao@gmail.com; Ghanta20102@iiitnr.edu.in
RI K, MALLIKHARJUNA RAO/G-8447-2016
OI K, MALLIKHARJUNA RAO/0000-0002-6096-3963
CR Adetunji AB, 2022, PROCEDIA COMPUT SCI, V199, P806, DOI 10.1016/j.procs.2022.01.100
   Anand V., 2020, 2020 International Conference on Data Analytics for Business and Industry: Way Towards a Sustainable Economy (ICDABI), P16, DOI [10.1109/ICDABI51230.2020.9325602, DOI 10.1109/ICDABI51230.2020.9325602]
   Anusha P., 2019, INT J INNOV TECHNOL, V9, P48, DOI DOI 10.35940/IJITEE.A3910.119119
   Dahouda MK, 2021, IEEE ACCESS, V9, P114381, DOI 10.1109/ACCESS.2021.3104357
   Doulah MS, 2019, ALTERNATIVE ROBUST M, P1
   Dow MM, 2009, CROSS-CULT RES, V43, P134, DOI 10.1177/1069397109331612
   Emmanuel T, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00516-9
   Farhangfar A, 2007, IEEE T SYST MAN CY A, V37, P692, DOI 10.1109/TSMCA.2007.902631
   Friedman L, 2019, IEEE T INF FOREN SEC, V14, P2528, DOI 10.1109/TIFS.2019.2904844
   Patro SGK, 2015, Arxiv, DOI arXiv:1503.06462
   Gupta M, 2014, IEEE T KNOWL DATA EN, V26, P2250, DOI 10.1109/TKDE.2013.184
   Hacibeyoglu M, 2018, ARAB J SCI ENG, V43, P7695, DOI 10.1007/s13369-018-3144-z
   He X, 2014, CAN J ELECT COMPUT E, V37, P157, DOI 10.1109/CJECE.2014.2343258
   Jadhav A, 2019, APPL ARTIF INTELL, V33, P913, DOI 10.1080/08839514.2019.1637138
   Jose J, 2021, J KING SAUD UNIV SCI, V33, DOI 10.1016/j.jksus.2021.101403
   Kang H, 2013, KOREAN J ANESTHESIOL, V64, P402, DOI 10.4097/kjae.2013.64.5.402
   Khan SI, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00313-w
   Kim HJ, 2021, IEEE ACCESS, V9, P74802, DOI 10.1109/ACCESS.2021.3080180
   Kumar A, 2007, IEEE T INF FOREN SEC, V2, P181, DOI 10.1109/TIFS.2007.896915
   Lee YJ, 2013, IEEE T KNOWL DATA EN, V25, P1460, DOI 10.1109/TKDE.2012.99
   Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642, DOI 10.1109/69.617056
   Liu XY, 2005, IEEE T KNOWL DATA EN, V17, P1166, DOI 10.1109/TKDE.2005.135
   Luan Siyu, 2021, IEEE Access, V9
   McMahon P, 2020, IEEE ACCESS, V8, P48177, DOI 10.1109/ACCESS.2020.2978902
   Nowak-Brzezinska A., 2017, J APPL COMPUT SCI, V25, P53, DOI DOI 10.34658/JACS.2017.2.53-68
   Pandey Amit, 2017, International Journal of Computer Network and Information Security, V9, P36, DOI 10.5815/ijcnis.2017.11.04
   Potdar K., 2017, International journal of computer applications, V175, P7, DOI 10.5120/ijca2017915495
   Sankepally SR, IEEE C P 3 INT C INN
   Spratt M, 2010, AM J EPIDEMIOL, V172, P478, DOI 10.1093/aje/kwq137
   Sunitha L, 2014, INT J ADV RES COMPUT, V3
   Thi Thu Hien D., 2020, INT J ADV COMPUT SC, DOI [10.14569/IJACSA.2020.0111135, DOI 10.14569/IJACSA.2020.0111135]
   Urvoy M, 2014, IH MMSEC 14
   Uyar A, 2009, IEEE ENG MED BIO, P6214, DOI 10.1109/IEMBS.2009.5334548
   van Capelleveen G, 2016, INT J ACCOUNT INF SY, V21, P18, DOI 10.1016/j.accinf.2016.04.001
   Wang HZ, 2019, IEEE ACCESS, V7, P107964, DOI 10.1109/ACCESS.2019.2932769
   Wilson Machelle D., 2014, Journal of Applied Mathematics, DOI 10.1155/2014/368791
   Xu XL, 2018, IEEE ACCESS, V6, P12983, DOI 10.1109/ACCESS.2018.2803755
   Yousef WA, 2021, IEEE T INF FOREN SEC, V16, P5195, DOI 10.1109/TIFS.2021.3125608
   Yuan P, 2020, T I MEAS CONTROL, V42, P2113, DOI 10.1177/0142331220905951
NR 39
TC 4
Z9 5
U1 11
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-15087-5
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0HO6
UT WOS:000952027100007
DA 2024-07-18
ER

EF