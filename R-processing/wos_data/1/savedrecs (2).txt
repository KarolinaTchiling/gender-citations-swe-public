FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Ha, I
   Oh, KJ
   Jo, GS
AF Ha, Inay
   Oh, Kyeong-Jin
   Jo, Geun-Sik
TI Personalized advertisement system using social relationship based user
   modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Recommendation system; User modeling; Social
   relationship; Social network
ID WORD-OF-MOUTH; RECOMMENDATION
AB The influence of social relationships has received considerable attention in recommendation systems. In this paper, we propose a personalized advertisement recommendation system based on user preference and social network information. The proposed system uses collaborative filtering and frequent pattern network techniques using social network information to recommend personalized advertisements. Frequent pattern network is employed to alleviate cold-start and sparsity problems of collaborative filtering. For the social relationship modeling, direct and indirect relations are considered and relation weight between users is calculated by using six degrees of Kevin Bacon. Weight '1' is given to those who have connections directly, and weight '0' is given to those who are over six steps away and hove no relation to each other. According to a research of Kevin Bacon, everybody can know certain people through six depths of people. In order to improve prediction accuracy, we apply social relationship to user modeling. In our experiments, advertisement information is collected and item rating and user information including social relations are extracted from a social network service. The proposed system applies user modeling between collaborative filtering and frequent pattern network model to recommend advertisements according to user condition. User's types are composed with combinations of both techniques. We compare the performance of the proposed method with that of other methods. From the experimental results, a proposed system applying user modeling using social relationships can achieve better performance and recommendation quality than other recommendation systems.
C1 [Ha, Inay; Oh, Kyeong-Jin] Inha Univ, Dept Informat Engn, Inchon, South Korea.
   [Jo, Geun-Sik] Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea.
C3 Inha University; Inha University
RP Jo, GS (corresponding author), Inha Univ, Sch Comp & Informat Engn, 100 Inha Ro, Inchon, South Korea.
EM inay@eslab.inha.ac.kr; okjkillo@eslab.inha.ac.kr; gsjo@inha.ac.kr
FU National Research Foundation of Korea (NRF) - Korean government (MEST)
   [2012-0005500]; INHA University
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MEST) (No. 2012-0005500).
   This work was also supported by INHA University.
CR Adany R, 2013, MULTIMEDIA SYST, V19, P79, DOI 10.1007/s00530-012-0284-y
   Bennett J, 2007, P KDD CUP WORKSH, P3
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Chang-Tai Hsieh, 2008, 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Workshops, P369, DOI 10.1109/WIIAT.2008.156
   Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345
   Choi K, 2012, ELECTRON COMMER R A, V11, P309, DOI 10.1016/j.elerap.2012.02.004
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P843, DOI 10.1007/s11042-013-1355-6
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P489, DOI 10.1007/s00779-013-0682-y
   Das Abhinandan S, 2007, P 16 INT C WORLD WID, P271
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   Gartrell M, 2011, CUCS108411 U COL BOU
   Godes D, 2004, MARKET SCI, V23, P545, DOI 10.1287/mksc.1040.0071
   Ha I, 2012, LECT NOTES COMPUT SC, V7653, P395, DOI 10.1007/978-3-642-34630-9_41
   Hang CW, 2012, AUTON AGENT MULTI-AG, V25, P475, DOI 10.1007/s10458-011-9186-1
   Hu J, 2012, J COMPUT SCI TECH-CH, V27, P527, DOI 10.1007/s11390-012-1241-0
   Jung G, 2008, P INT WORKSH SOFT CO, P70
   Kim E, 2011, IEEE T BROADCAST, V57, P674, DOI 10.1109/TBC.2011.2161409
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim J, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P895, DOI 10.1109/ICCE.2011.5722924
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kodialam M., 2010, P 2010 IEEE C COMP C, P1
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   LEKAKOS G, 2004, THESIS ATHENS U EC B
   Lekakos G, 2001, INTEGRATED APPROACH, P1
   Li Y, 2005, EXPERT SYST APPL, V28, P67, DOI 10.1016/j.eswa.2004.08.013
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu FK, 2010, EXPERT SYST APPL, V37, P4772, DOI 10.1016/j.eswa.2009.12.061
   Liu HY, 2013, ELECTRON COMMER R A, V12, P14, DOI 10.1016/j.elerap.2012.05.002
   Liu Y, 2006, J MARKETING, V70, P74, DOI 10.1509/jmkg.70.3.74
   López-Nores M, 2009, EXPERT SYST APPL, V36, P4192, DOI 10.1016/j.eswa.2008.04.007
   Schopman B, 2010, WEB SCI C WEBSCI 10, P1
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Shin C, 2009, IEEE T CONSUM ELECTR, V55, P927, DOI 10.1109/TCE.2009.5174476
   Shu WL, 2011, INTERNET RES, V21, P26, DOI 10.1108/10662241111104866
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   Teng-Kai Fan, 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P209, DOI 10.1109/SocialCom.2010.37
   Zhang L., 2009, P WEB SCI, P1, DOI DOI 10.5539/IES.V1N3P21
NR 39
TC 11
Z9 13
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8801
EP 8819
DI 10.1007/s11042-013-1691-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600007
DA 2024-07-18
ER

PT J
AU Kim, J
   Mohaisen, A
   Hong, SN
AF Kim, Joongheon
   Mohaisen, Aziz
   Song-Nam Hong
TI Interference impacts on 60 ghz real-time online video streaming in
   wireless smart tv platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart TV platforms; Video streaming; Interference; 60 GHz; IEEE 802.11ad
AB In this paper we provide a method for computing and estimating the impact of interference on real-time online 1080p@30Hz and 1080p@60Hz high-definition video streaming in 60 GHz wireless smart TV platforms. The analysis involves two different interference scenarios: 1) downlink interference from deployed 60 GHz access points to the associated mobile ad-hoc devices, and 2) uplink interference from randomly deployed 60 GHz ad-hoc mobile devices to their associated access points. With these interference scenarios, the interference impact on the quality of main 1080p@30Hz and 1080p@60Hz wireless high-definition video streaming with various simulation settings are measured and estimated in terms of signal-to-interference-plus-noise ratio.
C1 [Kim, Joongheon; Song-Nam Hong] Univ So Calif, Los Angeles, CA 90089 USA.
   [Mohaisen, Aziz] Verisign Labs, Reston, VA 20190 USA.
C3 University of Southern California
RP Hong, SN (corresponding author), Univ So Calif, EEB 525,3740 McClintock Ave, Los Angeles, CA 90089 USA.
EM joonghek@usc.edu; a.mohaisen@gmail.com; sunny7955@gmail.com
RI Mohaisen, Aziz/ABD-6425-2021; Mohaisen, David/GQP-2695-2022; Hong,
   Songnam/P-8591-2016
OI Hong, Songnam/0000-0002-9535-2521
CR 3Gpp, 2008, TR 36.942, 3rd generation partnership project (3GPP)
   Borges VCM, 2011, AD HOC NETW, V9, P652, DOI 10.1016/j.adhoc.2010.08.017
   Gilbert JM, 2008, IEEE MICRO, V28, P56, DOI 10.1109/MM.2008.20
   Heo J, 2010, IEEE T CIRC SYST VID, V20, P213, DOI 10.1109/TCSVT.2009.2031392
   ITU-R, 2007, REC F 1336 1 REF RAD
   Jeong JW, 2011, IEEE T CONSUM ELECTR, V57, P1830, DOI 10.1109/TCE.2011.6131160
   Kim J., 2013, P IEEE INT C COMM IC
   Kim J., 2009, P IEEE CONS COMM NET
   Kim J., 2011, P IEEE INT S PERS IN
   Kim J, 2014, IEEE COMMUN LETT, V18, P455, DOI 10.1109/LCOMM.2014.012014.132659
   Kim J, 2013, IEEE T BROADCAST, V59, P500, DOI 10.1109/TBC.2013.2273598
   Kwon HJ, 2011, IEEE T CONSUM ELECTR, V57, P1416, DOI 10.1109/TCE.2011.6018902
   Lee W, 2010, IEEE T CONSUM ELECTR, V56, P2481, DOI 10.1109/TCE.2010.5681131
   MALTSEV A, 2009, 80211090553R1 IEEE
   Oh T, 2013, WIRELESS PERS COMMUN, V64, P1925
   Park JS, 2013, IEEE T CONSUM ELECTR, V59, P244, DOI 10.1109/TCE.2013.6490266
   Pepe D, 2010, P IEEE MED EL C VALL
   Perahia E., 2010, P IEEE CONS COMM NET
   Cabrer MR, 2006, IEEE T CONSUM ELECTR, V52, P421, DOI 10.1109/TCE.2006.1649659
   Takahashi M, 2013, MULTIMED TOOLS APPL, V62, P761, DOI 10.1007/s11042-011-0870-6
   Tie X, 2012, P PASS ACT MEAS C PA
   Tiraspolsky S., 2010, P IEEE CONS COMM NET
   Zhang L, 2012, WIRELESS PERS COMMUN, V66, P493, DOI 10.1007/s11277-012-0737-9
   Zhu XQ, 2011, AD HOC NETW, V9, P608, DOI 10.1016/j.adhoc.2010.08.002
NR 24
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8613
EP 8629
DI 10.1007/s11042-014-2349-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600024
DA 2024-07-18
ER

PT J
AU Song, MH
   Lee, YH
AF Song, Mi-Hwa
   Lee, Young-Ho
TI Direct optimization of inference model for human activity and posture
   class recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tri-axial accelerometer; State transition model; Activity recognition;
   Radial basis function networks; Direct loss minimization
ID TRIAXIAL ACCELEROMETER; MOVEMENTS
AB The demand for ambulatory monitoring is rising due to the widespread adoption of home-based healthcare models for the increasing elderly population. Since monitoring patients makes it possible to provide remote medical services based on real-world contexts, context-aware technology is regarded as a crucial element in core module development for ubiquitous healthcare solutions. This paper describes the design and implementation of a class label tagging system for human activity recognition based on sensor data from a single tri-axial accelerometer attached to the waist of a human subject. Our human activity and posture classifier (APC) was designed to model more effectively an event that takes place over a period of time. Consequently, the APC problem becomes the process of tagging class labels onto sequential data from a single tri-axial accelerometer. This sequential tagging naturally led to our hypothesis that a linear combination of the classification model and the prior, approximated by observing a state transition event of human activity and posture (AP), may decrease the error rate of the system. Therefore, this paper aims at testing the aforementioned experimental hypothesis while explicating our method of direct optimization, also known as direct loss minimization. Our experimental hypothesis is based on the view that the task of labeling a series of class tags on a data object of the AP event should be supported by a statistical model capable of robustly capturing the probabilistic context influencing the generation of a set of features at a given discrete time. A radial basis function network algorithm was used for parameter estimation of a class likelihood inference model augmented by training a state transition model to capture the sequential nature of a posture or activity generation event. The linear combination requires our design step to have a further optimization, in addition to learning the parameters of each inference model, of the model parameters that represent the relative contribution to the decision process. Previous studies have elaborated on an effective approach to direct optimization of model parameters when an appropriate evaluation metric exists for a given problem domain. In our case, f-measure was used as an objective function of the direct optimization. We used local beam search to optimize directly the weight vector for the likelihood and the prior. Our method is tested on the set of nine-dimensional feature vectors contained in 69,376 lines of sequential AP data. The experiment shows that embedding prior probability into the recognition process decreases the error rate in a set of categories. Several experiments proved the efficiency of our proposed method and the usefulness of the system.
C1 [Song, Mi-Hwa] Semyung Univ, Dept Informat & Commun Syst, Jecheon, South Korea.
   [Lee, Young-Ho] Gachon Univ, Dept Comp Informat Technol, Inchon 406799, South Korea.
C3 Semyung University; Gachon University
RP Lee, YH (corresponding author), Gachon Univ, Dept Comp Informat Technol, 534-2 Yeonsu Dong, Inchon 406799, South Korea.
EM mhsong@semyung.ac.kr; lyh@gachon.ac.kr
RI Song, Mi-Hwa/GPC-6184-2022
FU Gachon University [GCU-2013-R116]
FX This work was supported by the Gachon University Research Fund of 2013
   (GCU-2013-R116)
CR Alpaydin E, 2004, INTRO MACHINE LEARNI
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Cer Daniel., 2008, Proceedings of the Third Workshop on Statistical Machine Translation, P26
   DeVaul R., 2001, REAL TIME MOTION CLA
   Duong TV, 2005, PROC CVPR IEEE, P838
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   Galley M., 2011, Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP'11, P38
   Györbíró N, 2009, MOBILE NETW APPL, V14, P82, DOI 10.1007/s11036-008-0112-y
   He ZY, 2009, IEEE SYS MAN CYBERN, P5041, DOI 10.1109/ICSMC.2009.5346042
   Helaoui R, 2011, INT CONF PERVAS COMP, P1, DOI 10.1109/PERCOM.2011.5767586
   Jelinek Frederick., 1998, Statistical Methods for Speech Recognition
   Karaman S., 2011, MULTIMED TOOLS APPL, P1
   Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   Kirtley C, 2001, MULTIMED TOOLS APPL, V14, P259, DOI 10.1023/A:1011362113281
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Lukowicz P, 2004, LECT NOTES COMPUT SC, V3001, P18
   Mathie MJ, 2004, MED BIOL ENG COMPUT, V42, P679, DOI 10.1007/BF02347551
   Mathie MJ, 2004, J TELEMED TELECARE, V10, P144, DOI 10.1258/135763304323070788
   Maurer U, 2006, LECT NOTES COMPUT SC, V3864, P86
   Maurer U, 2006, BSN 2006: INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P113
   Modayil J, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P40, DOI 10.1145/1409635.1409641
   Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281
   Mysore P., 2005, AAAI, V5, P1541
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Olguin DO, 2006, HUMAN ACTIVITY RECOG
   Patterson DJ, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P44, DOI 10.1109/ISWC.2005.22
   Pober DM, 2006, MED SCI SPORT EXER, V38, P1626, DOI 10.1249/01.mss.0000227542.43669.45
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Simon C, 2010, MULTIMED TOOLS APPL, V50, P95, DOI 10.1007/s11042-009-0364-y
   Song S K, 2008, CONSUMER ELECT, P1
   van Kasteren T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P1, DOI 10.1145/1409635.1409637
   Veltink P H, 1996, IEEE Trans Rehabil Eng, V4, P375, DOI 10.1109/86.547939
   Yang JY, 2007, LECT NOTES COMPUT SC, V4740, P395
   Yang JY, 2008, PATTERN RECOGN LETT, V29, P2213, DOI 10.1016/j.patrec.2008.08.002
NR 36
TC 3
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8861
EP 8878
DI 10.1007/s11042-013-1665-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600011
DA 2024-07-18
ER

PT J
AU Jung, M
   Han, K
   Cho, J
AF Jung, Minwoo
   Han, Kabsu
   Cho, Jeonghun
TI Advanced verification on WBAN and cloud computing for u-health
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless body area network; Cloud computing; u-Health; Smart device;
   Bluetooth
ID SENSOR NETWORKS; MODEL CHECKING
AB The Wireless Body Area Network (WBAN) that can collect measured vital signs through sensors enables continuous monitoring of the elder and of chronic diseases. As smart devices become popular, development of the WBAN becomes easier. Our research implemented an integration platform that consists of WBAN and cloud computing based on the Transmission Control Protocol (TCP). We optimized the WBAN and the TCP as a sampling rate control. A sampling rate is the number of transfer data per second. The sampling rate is an important factor in the resolution of waveforms, though high sampling rates can cause a decline in network performance. A smart device performs three threads, such as Bluetooth, main, and TCP. The Bluetooth thread was implemented to collect vital signs from sensing nodes. The main thread performs computations for drawing waveforms and transmits data to the TCP thread. The TCP thread transmits vital signs to a server. We verified our proposed integration platform with formal verification and simulation. We expect to contribute to the platform development of WBAN and to cloud computing.
C1 [Jung, Minwoo; Han, Kabsu; Cho, Jeonghun] Kyungpook Natl Univ, Sch E E, Daegu, South Korea.
C3 Kyungpook National University
RP Cho, J (corresponding author), Kyungpook Natl Univ, Sch E E, Daehak Ro 80, Daegu, South Korea.
EM jungminwoo80@knu.ac.kr; kabus@knu.ac.kr; jcho@ee.knu.ac.kr
FU BK21 Plus project - Ministry of Education, Korea [21A20131600011];
   Ministry of Education (MOE); National Research Foundation of Korea (NRF)
   through the Human Resource Training Project for Regional Innovation
   [2011-05- -05-024]; MKE (The Ministry of Knowledge Economy), Korea,
   under the CITRC (Convergence Information Technology Research Center)
   support program [NIPA-2013-H0401-13-1006]; Ministry of Trade, Industry
   Energy (MOTIE); IDEC Platform center (IPC) for Smart car; MSIP(Ministry
   of Science, ICT & Future Planning), Korea, under IT/SW Creative research
   program [NIPA-2013-ITAH0502130110690001000100100]
FX This study was supported by the BK21 Plus project funded by the Ministry
   of Education, Korea (21A20131600011). This research was financially
   supported by the Ministry of Education (MOE) and National Research
   Foundation of Korea (NRF) through the Human Resource Training Project
   for Regional Innovation. (NO. 2011-05- -05-024). This research was
   supported by the MKE (The Ministry of Knowledge Economy), Korea, under
   the CITRC (Convergence Information Technology Research Center) support
   program (NIPA-2013-H0401-13-1006) supervised by the NIPA (National IT
   Industry Promotion Agency). This work was supported by Ministry of
   Trade, Industry & Energy (MOTIE) and IDEC Platform center (IPC) for
   Smart car. This research was supported by the MSIP(Ministry of Science,
   ICT & Future Planning), Korea, under IT/SW Creative research program
   supervised by the NIPA(National IT Industry Promotion Agency)
   (NIPA-2013-ITAH0502130110690001000100100)
CR [Anonymous], UBIQUIT INF TECHNOL
   [Anonymous], INT J COMPUT APPL
   [Anonymous], P 16 INT SPIN WORKSH
   [Anonymous], 2002, Proc. of ACM Workshop on Principle of Mobile Computing, DOI [10.1145/584490.584499, DOI 10.1145/584490.584499]
   [Anonymous], 2013, IEEE VEHICULAR TECHN
   Baronti P, 2007, COMPUT COMMUN, V30, P1655, DOI 10.1016/j.comcom.2006.12.020
   Basu A, 2010, LECT NOTES COMPUT SC, V6418, P330, DOI 10.1007/978-3-642-16612-9_25
   Câmara D, 2007, GLOB TELECOMM CONF, P705
   Corredor I, 2011, J SYST ARCHITECT, V57, P916, DOI 10.1016/j.sysarc.2011.04.005
   Demaille Akim., 2006, PROC 4 IEEE INT C CO, P45
   Duflot M., 2006, International Journal on Software Tools for Technology Transfer, V8, P621, DOI 10.1007/s10009-006-0014-x
   Farella E, 2008, MULTIMED TOOLS APPL, V38, P337, DOI 10.1007/s11042-007-0189-5
   Fei Hu, 2011, Journal of Computing and Information Technology - CIT, V19, P25, DOI 10.2498/cit.1001864
   Fortino G, 2014, FUTURE GENER COMP SY, V35, P62, DOI 10.1016/j.future.2013.12.015
   Heidemann J., 2001, Operating Systems Review, V35, P146, DOI 10.1145/502059.502049
   Jha SK, 2009, LECT N BIOINFORMAT, V5688, P218, DOI 10.1007/978-3-642-03845-7_15
   Jung M, 2013, INT CONF UBIQ FUTUR, P495, DOI 10.1109/ICUFN.2013.6614870
   Kaur PD, 2014, COMPUT METH PROG BIO, V113, P346, DOI 10.1016/j.cmpb.2013.09.013
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim KC, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/345672
   Kotz D., 2004, INT WORKSHOP MODELIN, P78, DOI DOI 10.1145/1023663.1023679
   Kovachev D, 2014, MULTIMED TOOLS APPL, V70, P977, DOI 10.1007/s11042-012-1100-6
   Kwiatkowska M., 2002, Process Algebra and Probabilistic Methods. Performance Modeling and Verification. Second Joint International Workshop PAPM-PROBMIV 2002 Proceedings (Lecture Notes in Computer Science Vol.2399), P169
   Kwiatkowska M., 2003, Formal Aspects of Computing, V14, P295, DOI 10.1007/s001650300007
   Kwiatkowska Marta, 2009, Performance Evaluation Review, V36, P40, DOI 10.1145/1530873.1530882
   Kwon YM, 2006, PROCEEDINGS OF THE 12TH IEEE REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, P49
   McIver AK, 2006, LECT NOTES COMPUT SC, V4085, P131
   Mclver A., 2006, Leveraging Applications of Formal Methods, Verification and Validation, P263
   Pham HN, 2007, PROC 2007 INT S WORL, P1
   Rong CM, 2013, COMPUT ELECTR ENG, V39, P47, DOI 10.1016/j.compeleceng.2012.04.015
   Schuts M, 2009, ELECTRON PROC THEOR, P41, DOI 10.4204/EPTCS.13.4
   Seada K., 2004, P 2 INT C EMBEDDED N, P108
   Wu XL, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/620945
   Yin L, 2014, MULTIMED TOOLS APPL, V72, P843, DOI 10.1007/s11042-013-1368-1
   Zuliani P, 2013, FORM METHOD SYST DES, V43, P338, DOI 10.1007/s10703-013-0195-3
   Zuniga M, 2004, 2004 FIRST ANNUAL IEEE COMMUNICATIONS SOCIETY CONFERENCE ON SENSOR AND AD HOC COMMUNICATIONS AND NETWORKS, P517, DOI 10.1109/SAHCN.2004.1381954
NR 36
TC 7
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6151
EP 6168
DI 10.1007/s11042-014-2095-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700002
DA 2024-07-18
ER

PT J
AU Akhaee, MA
   Sahraeian, SME
AF Akhaee, Mohammad Ali
   Sahraeian, Sayed Mohammad Ebrahim
TI Scaling-based watermarking with universally optimum decoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Maximum likelihood detector; Gaussian distribution
ID ROBUST IMAGE WATERMARKING; CONTOURLET TRANSFORM; DOMAIN; AUDIO
AB In this paper, we propose a blind scaling based image watermarking approach which is highly robust against the noise and gain attacks. Designed independent of the host signal distribution, the proposed scheme can universally be applied in various transform domains with arbitrary distributions. Partitioning the host signal into two patches, we embed the watermark code in one patch while keeping the other one unchanged for blind parameter estimation. We extract the watermark bits using a maximum likelihood decoder approach based on the ratio of the samples summation in each patch. Driving the distribution of the decision variable, we analytically study the performance of the proposed decoder. Employing the ratio of samples as the decision variable makes the proposed scheme invariant to the gain attack. The proposed algorithm is applied to both artificial Gaussian autoregressive signals as well as various test images. The robustness of the proposed decoder to various host signal distribution is verified. Experimental results confirm the validity of our model for low frequency components of natural images and its high robustness against common attacks.
C1 [Akhaee, Mohammad Ali] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
   [Sahraeian, Sayed Mohammad Ebrahim] Univ Calif Berkeley, Dept Plant & Microbial Biol, Berkeley, CA 94720 USA.
C3 University of Tehran; University of California System; University of
   California Berkeley
RP Akhaee, MA (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
EM akhaee@ut.ac.ir; msahraeian@berkeley.edu
CR Akhaee MA, 2010, SIGNAL PROCESS, V90, P2487, DOI 10.1016/j.sigpro.2010.02.013
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   Barni M, 2003, IEEE T SIGNAL PROCES, V51, P1118, DOI 10.1109/TSP.2003.809371
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Bi N, 2007, IEEE T IMAGE PROCESS, V16, P1956, DOI 10.1109/TIP.2007.901206
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Gazor S, 2003, IEEE SIGNAL PROC LET, V10, P204, DOI 10.1109/LSP.2003.813679
   Hamghalam M, 2013, IET IMAGE PROCESS, V7, P451, DOI 10.1049/iet-ipr.2012.0693
   HINKLEY DV, 1969, BIOMETRIKA, V56, P635, DOI 10.1093/biomet/56.3.635
   Hsu CT, 1998, IEEE T CIRCUITS-II, V45, P1097, DOI 10.1109/82.718818
   Hsu HW, 2010, IEEE T SIGNAL PROCES, V58, P3692, DOI 10.1109/TSP.2010.2047105
   Iwahashi M, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P1065
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Katzenbeisser S, 2000, INFORM HIDING TECHNI, V316
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lu C., 2005, MULTIMEDIA SECURITY
   Maor A, 2005, IEEE T INFORM THEORY, V51, P3166, DOI 10.1109/TIT.2005.853315
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Ng TM, 2005, 2005 39TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, VOLS 1 AND 2, P1680
   PEARLMAN WA, 1990, IEEE T COMMUN, V38, P698, DOI 10.1109/26.54984
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Seitz J., 2005, DIGITAL WATERMARKING
   Solachidis V, 2004, EURASIP J APPL SIG P, V2004, P2522, DOI 10.1155/S1110865704408014
   Wang JW, 2008, SIGNAL PROCESS, V88, P117, DOI 10.1016/j.sigpro.2007.07.012
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
NR 34
TC 4
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5995
EP 6018
DI 10.1007/s11042-014-1904-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100031
DA 2024-07-18
ER

PT J
AU Sun, YK
   Dong, YF
   Tang, ZS
AF Sun, Yankui
   Dong, Yafeng
   Tang, Zesheng
TI Internet-based interactive visualization method of 3D lunar model with
   texture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chang'E-1; Interactive visualization method; Visible texture piece;
   Progressive transmission and reconstruction
ID CHANGE-1; MISSION
AB Because of the huge size of the laser altimetry dataset and the CCD dataset obtained by CE-1 (Chang'E-1), how to use these data to visualize a lunar model with texture in real time through the Internet is a problem. This paper proposes a visualization method for a 3D lunar model with texture. The method increases the speed of data transmission through the Internet by using texture divide-and-conquer techniques, view-dependent evaluation of texture piece visibility, and progressive transmission and reconstruction techniques. Using this method, the convergence problem in the polar regions is solved, and multilevel labels can be added and displayed. An Internet-based client/server architecture has been built and implemented, which can be interactively browsed on a client almost in real time. This work offers a popular application (i.e., using personal terminals and the Internet), and the proposed modeling and visualization method could be applied to most global space-exploration datasets.
C1 [Sun, Yankui; Dong, Yafeng; Tang, Zesheng] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Sun, Yankui] Duke Univ, Vis & Image Proc Lab, Durham, NC 27710 USA.
   [Tang, Zesheng] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Peoples R China.
C3 Tsinghua University; Duke University; Macau University of Science &
   Technology
RP Sun, YK (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM syk@mail.tsinghua.edu.cn
RI Sun, Yankui/AAD-2524-2019
FU National High Technology Research and Development Program of China
   ("863" Program) [2013AA013702]
FX This work was supported by the National High Technology Research and
   Development Program of China ("863" Program) under Grant No.
   2013AA013702. Thanks for the anonymous reviewer's valuable comments.
CR [Anonymous], P 2007 IEEE AER C
   Dong YF, 2013, SCI CHINA PHYS MECH, V56, P2002, DOI 10.1007/s11433-013-5263-6
   Gu YH, 2007, COMPUT NETW, V51, P1777, DOI 10.1016/j.comnet.2006.11.009
   Li CL, 2010, SCI CHINA EARTH SCI, V53, P1582, DOI 10.1007/s11430-010-4020-1
   Lindstrom P, 2002, IEEE T VIS COMPUT GR, V8, P239, DOI 10.1109/TVCG.2002.1021577
   Ouyang ZY, 2010, SCI CHINA EARTH SCI, V53, P1565, DOI 10.1007/s11430-010-4056-2
   Ping JS, 2009, SCI CHINA SER G, V52, P1105, DOI 10.1007/s11433-009-0144-8
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sun YK, 2014, ADV SPACE RES, V53, P1848, DOI 10.1016/j.asr.2012.11.010
   Sun YK, 2011, COMPUT GEOSCI-UK, V37, P1460, DOI 10.1016/j.cageo.2011.04.010
   Ye MJ, 2011, J EARTH SCI-CHINA, V22, P610, DOI 10.1007/s12583-011-0212-7
NR 11
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5449
EP 5462
DI 10.1007/s11042-014-1863-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100004
DA 2024-07-18
ER

PT J
AU Yang, TI
   Koong, CS
   Tseng, CC
AF Yang, Tzu-I
   Koong, Chorng-Shiuh
   Tseng, Chien-Chao
TI Game-based image semantic CAPTCHA on handset devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHA; Human interactive proofs; Game-based; Unambiguous image
   semantic; GISCHA
ID RECOGNITION
AB A completely automated public turing test to tell computer and human apart (CAPTCHA) is based on the Turing test, which aims to protect Internet services from automatic script attacks and spams. However, most proposed or deployed CAPTCHAs have been breached. It is possible to enhance the security of an existing CAPTCHA by adding noises systematically adding noises, but distortions would make characters recognition difficult for humans. On the other hand, most of the traditional CPATCHAs require complicated operations using keyboards and mice which may become limitations of modern handset devices. In this study, we propose a novel GISCHA using game-based image semantics with the contributions that 1) use simple keys, mouse, gesture, and accelerometer instead of complex alphabet inputs; 2) is language independent; 3) enhances the security level without annoying users; 4) is based on more advanced human cognitive abilities; and 5) make CAPTCHAs more interesting. The experiment results show that a single GISCHA challenge was completed in 9.06 s on average with a virtual keyboard and 10.25 s on average with accelerometers build in handset devices, and the pass rate of first time use is 94.8 %, which means that it is sufficiently easy for practical use.
C1 [Yang, Tzu-I; Tseng, Chien-Chao] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Koong, Chorng-Shiuh] Natl Taichung Univ Educ, Dept Comp Sci, Taichung 403, Taiwan.
C3 National Yang Ming Chiao Tung University; National Taichung University
   of Education
RP Yang, TI (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM tiyang@cs.nctu.edu.tw; csko@mail.ntcu.edu.tw; cctseng@cs.nctu.edu.tw
OI Tseng, Chien-Chao/0000-0001-9654-0084
FU National Taichung University of Education and Ministry of Education,
   Taiwan
FX The authors would like to thank the National Taichung University of
   Education and Ministry of Education, Taiwan, for financially supporting
   this research under grants of the talent nurturing pioneer program for
   proactive SoC design - embedded systems and software engineering.
CR [Anonymous], INT C SEC COMP NETW
   [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   [Anonymous], 2008, P 15 ACM C COMP COMM
   [Anonymous], 2004, ADV NEURAL INF PROCE
   Bigham JP, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1829
   Birgale L, 2012, J INF PROCESS SYST, V8, P445, DOI 10.3745/JIPS.2012.8.3.445
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Bursztein E, 2010, P IEEE S SECUR PRIV, P399, DOI 10.1109/SP.2010.31
   Chellapilla K, 2005, CEAS 2005 2 INT EM A
   Chew M, 2004, LECT NOTES COMPUT SC, V3225, P268
   Chow R., 2008, P 9 WORKSHOP MOBILE, P91
   Elson J, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P366
   Huang SY, 2010, MULTIMED TOOLS APPL, V48, P267, DOI 10.1007/s11042-009-0341-5
   Kim JJ, 2011, J INF PROCESS SYST, V7, P187, DOI 10.3745/JIPS.2011.7.1.187
   Kim J, 2014, MULTIMED TOOLS APPL, V72, P1215, DOI 10.1007/s11042-013-1422-z
   Kun Fang, 2012, Artificial Intelligence and Computational Intelligence. Proceedings of the 4th International Conference, AICI 2012, P735, DOI 10.1007/978-3-642-33478-8_91
   Li SJ, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P171
   Mori G, 2003, PROC CVPR IEEE, P134
   Satone MP, 2012, J INF PROCESS SYST, V8, P483
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   von Ahn L, 2003, ADV CRYPTOL
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   von Ahn L, 2009, DES AUT CON, P418
   Yamamoto T., 2010, Proceedings of the 13th International Conference on Network-Based Information Systems (NBiS 2010), P575, DOI 10.1109/NBiS.2010.31
   Zhu B, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P187, DOI 10.1145/1866307.1866329
NR 25
TC 11
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5141
EP 5156
DI 10.1007/s11042-013-1666-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900010
DA 2024-07-18
ER

PT J
AU Yu, HF
AF Yu, Hsiang-Fu
TI Efficient periodic broadcasting scheme for video delivery over a single
   channel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near video-on-demand (VoD); Periodic broadcasting; Single channel
ID SCHEDULING SCHEME; WAITING TIME; TRANSITION; DEMAND
AB Periodic broadcasting is one of the cost-effective solutions for distributing popular videos to clients under constant worst playback latency. The broadcasting methods typically transmit video segments across multiple channels simultaneously, thus, requiring a client to receive segments from these channels concurrently. However, numerous practical systems, such as digital video broadcasting-handheld (DVB-H), do not allow clients to download video data from multiple channels because clients usually only have one tuner. To resolve this problem in multiple-channel broadcasting, the alternative broadcasting (AB) scheme, the hopping insertion (HI) scheme, SingBroad, PAS, the reverse-order scheduling (ROS) scheme, and the half-division broadcasting (HDB) scheme have been proposed to broadcast segments over a single channel. This paper presents a novel single-channel broadcasting scheme, which partitions a video into segments as many as possible to reduce video playback latency. Using mathematical analysis, this study verifies the workability of this scheme by demonstrating that client playback continuity is guaranteed. A performance analysis indicates that the proposed scheme yields the smallest waiting time, when compared with AB, HI, SingBroad, PAS, ROS, and HDB under various parameter settings. In addition, comprehensive simulation results show that the proposed scheme and ROS outperform these schemes (The comparison does not include the HI scheme because its buffer requirements are not provided in [24]) regarding smaller client buffer requirements under larger broadcasting bandwidth settings.
C1 Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
C3 National Taipei University of Education
RP Yu, HF (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM yu@tea.ntue.edu.tw
FU National Science Council, Taiwan [NSC 102-2221-E-152-003]
FX This work was financially supported by National Science Council, Taiwan
   under a research grant numbered NSC 102-2221-E-152-003.
CR Chand S, 2010, COMPUT NETW, V54, P462, DOI 10.1016/j.comnet.2009.09.008
   Chen YW, 2012, IET COMMUN, V6, P2949, DOI 10.1049/iet-com.2011.0679
   Chen YW, 2011, IET COMMUN, V5, P951, DOI 10.1049/iet-com.2010.0410
   Chen YN, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/717538
   Chen YW, 2009, COMPUT NETW, V53, P1546, DOI 10.1016/j.comnet.2009.02.004
   Chien WD, 2005, IEEE T BROADCAST, V51, P360, DOI 10.1109/TBC.2005.852251
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Chung Y, 2011, MULTIMEDIA SYST, V17, P165, DOI 10.1007/s00530-011-0227-z
   Digital TV, 2012, SUSTAINED BOOM FOREC
   Febiansyah H, 2012, MULTIMEDIA TOOLS APP
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Juhn LS, 1997, IEEE T CONSUM ELECTR, V43, P1110, DOI 10.1109/30.642378
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Tang W, 2007, COMPUT NETW, V51, P336, DOI 10.1016/j.comnet.2006.05.003
   TechNavio, 2012, GLOB VID DEM MARK 20
   Tseng YC, 2004, IEEE ACM T NETWORK, V12, P559, DOI 10.1109/TNET.2004.828965
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Tseng YC, 2001, IEEE T COMMUN, V49, P863, DOI 10.1109/26.923810
   Van der Auwera G, 2009, IEEE T BROADCAST, V55, P541, DOI 10.1109/TBC.2009.2027399
   Vilas M, 2005, EUROMICRO-SEAA 2005: 31st EUROMICRO Conference on Software Engineering and Advanced Applications, Proceedings, P330
   Wu BS, 2011, IEEE T BROADCAST, V57, P721, DOI 10.1109/TBC.2011.2128530
   Yang ZY, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/373459
   Yoshihisa T, 2006, IEEE T BROADCAST, V52, P1, DOI 10.1109/TBC.2005.859235
   Yoshihisa T, 2007, IEEE T BROADCAST, V53, P628, DOI 10.1109/TBC.2007.903639
   Yoshihisa T, 2013, IEEE T BROADCAST, V59, P62, DOI 10.1109/TBC.2012.2229846
   Yu H-F, 2013, MULTIMEDIA TOOLS APP
   Yu H-F, 2013, J APPL MATH, V629350, P8
   Yu HF, 2008, IEEE T BROADCAST, V54, P304, DOI 10.1109/TBC.2008.915761
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
NR 29
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5811
EP 5824
DI 10.1007/s11042-014-1889-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100021
DA 2024-07-18
ER

PT J
AU Huang, YS
   Chieu, BC
AF Huang, Yung-Sung
   Chieu, Bin-Chang
TI Architecture for video streaming application on heterogeneous platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Streaming library; Quantization parameter; Heterogeneous platform
ID SYSTEM
AB In this paper, we propose a new architecture, which is an efficient streaming media player application on heterogeneous platform. The streaming library can be used in design for reducing the memory bandwidth on processing RTSP/RTP/RTCP network protocols. And the proposed improvement has to do with the I-frame encoding alone. The architecture can receive higher rate for data transfer and packet loss in embedded system. The framework of the key components is able to adopt Direct Memory Access to reduce the time-consumption resulted from the communication between the dual cores. On the other hand, the approach of the dynamic quality adaption improves the video bitstream by periodically adjusting the values of encoding quality parameters. Through the experiment results, it is evident that the new video streaming architecture greatly enhances the coding efficacy. Our experimental results present that the decoding/encoding speed of the dual-core CPU embedded with Direct Memory Access is enhanced up to 50 %, and its usage of CPU resources and memory bandwidth are 50 % lower than that of the popular JRTPLIB.
C1 [Huang, Yung-Sung; Chieu, Bin-Chang] Natl Taiwan Univ Sci, Technol Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Huang, YS (corresponding author), Natl Taiwan Univ Sci, Technol Dept Elect Engn, Taipei, Taiwan.
EM d9502205@mail.ntust.edu.tw; tgi0393@yahoo.com.tw
CR 3GPP 3rd Generation Partnership Project, 2008, 33246 3GPP TS
   Chen X, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-10
   Chi B-D, 2003, IEEE INT C CONS EL 2, p246 
   Feamster N, SR RTP LIB TOOLKIT
   Handley M, 1998, 2327 IETF RFC
   Hatabu A, 2002, QVGA CIF RESOLUTION, p15 
   Hsieh K., 2008, P 37 INT C PAR PROC, P35
   Kepp A, JLIBRTP JAVA RTP LIB
   Le R, 2012, IEEE INT CONF ASAP, P16, DOI 10.1109/ASAP.2012.34
   Lin YH, 2009, IEEE INT CONF EMBED, P69, DOI 10.1109/RTCSA.2009.14
   Liu JJ, 2011, COMPUT DIGIT ENG, V39
   Mohapatra Shivajit., 2003, P 11 ANN ACM INT C M, P582
   Rey J, 2006, 4396 IETF RFC
   Schulzrinne H., 2003, 3550 IETF RFC
   Sun DG, 2005, LECT NOTES COMPUT SC, V3482, P79
   Teodoro G, 2012, CLUSTER COMPUT, V15, P125, DOI 10.1007/s10586-010-0151-6
   *U COLL LOND, UCL COMM MULT LIB
   Zheng Q-Y, 2011, IEEE 23 INT C EL MEC, V4, P1723
   Zhong L, 2006, DES AUT CON, P586, DOI 10.1109/DAC.2006.229291
NR 19
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4927
EP 4945
DI 10.1007/s11042-014-1856-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400023
DA 2024-07-18
ER

PT J
AU Rashedi, E
   Nezamabadi-pour, H
   Saryazdi, S
AF Rashedi, Esmat
   Nezamabadi-pour, Hossein
   Saryazdi, Saeid
TI Information fusion between short term learning and long term learning in
   content based image retrieval systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Relevance feedback; Short term learning;
   Long term learning; Information fusion; Similarity function
ID RELEVANCE FEEDBACK; SEMANTICS; STANDARD
AB Content based image retrieval (CBIR) systems could provide more precise results by taking the user's feedbacks into account. Two types of the relevance feedback learning paradigms are short term learning (STL) and long term learning (LTL). By using both STL and LTL, a collaborative CBIR system is proposed in this paper. The proposed system introduced three fusion methods: including fusion in retrieved images, fusion in ranks, and fusion in similarities to make cooperation between STL and LTL. The proposed fusion methods are examined in a CBIR system equipped with a proposed statistical semantic clustering (SSC) method of LTL. The SSC method works based on the concept of semantic categories of the images by clustering techniques and constructing a relevancy matrix between images and semantic categories. The results of the SSC method with the suggested fusion methods are compared with two state-of-the-art LTL methods, namely virtual feature based method and dynamic semantic clustering. Comparative results confirm the efficiency of the proposed method. Furthermore, experimental results demonstrate that for a unique LTL method, various fusion methods lead to different results.
C1 [Rashedi, Esmat; Nezamabadi-pour, Hossein; Saryazdi, Saeid] Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Rashedi, E (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, POB 76169-133, Kerman, Iran.
EM e.rashedi@kgut.ac.ir; nezam@uk.ac.ir
RI Nezamabadi-pour, Hossein/AAB-4009-2019; Saryazdi, Saeid/GQY-9790-2022;
   Saryazdi, Saeid/GQZ-0186-2022; Saryazdi, Saeid/D-4488-2015; Rashedi,
   Esmat/AAZ-7069-2020
OI Nezamabadi-pour, Hossein/0000-0002-3350-7348; Saryazdi,
   Saeid/0000-0002-4577-1971; Saryazdi, Saeid/0000-0002-4577-1971; Rashedi,
   Esmat/0000-0002-2539-5817
CR [Anonymous], CS200318 FLOR I TECH
   [Anonymous], 2012, PASCAL VISUAL OBJECT
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Barrett S., 2007, CONTENT BASED IMAGE
   Barrett S, 2009, IEEE INT CON MULTI, P838, DOI 10.1109/ICME.2009.5202625
   Bhanu B, 2002, ENG APPL ARTIF INTEL, V15, P123, DOI 10.1016/S0952-1976(02)00026-X
   Bulò SR, 2011, PATTERN RECOGN, V44, P2109, DOI 10.1016/j.patcog.2011.03.016
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Cheng PC, 2008, EXPERT SYST APPL, V34, P2193, DOI 10.1016/j.eswa.2007.02.030
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T., 2008, 19 INT C PATT REC IC
   Ferreira CD, 2011, PATTERN RECOGN LETT, V32, P27, DOI 10.1016/j.patrec.2010.05.015
   Han JW, 2005, IEEE T IMAGE PROCESS, V14, P511, DOI 10.1109/TIP.2004.841205
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Hoi SCH, 2006, IEEE T KNOWL DATA EN, V18, P509, DOI 10.1109/TKDE.2006.1599389
   Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752
   Jing L, 2013, HDB NEURAL INFORM PR, P433
   Kim DH, 2005, J SYST SOFTWARE, V78, P9, DOI 10.1016/j.jss.2005.02.005
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu Y, 2003, IEEE T MULTIMEDIA, V5, P339, DOI 10.1109/TMM.2003.813280
   Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360
   Nezambadi-pour H, 2009, EXPERT SYST APPL, V36, P5948, DOI 10.1016/j.eswa.2008.07.008
   Porkaew K, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P235, DOI 10.1145/319463.319613
   Qi XJ, 2011, INT J INTELL SYST, V26, P1153, DOI 10.1002/int.20503
   Rashedi E, 2013, THESIS SHAHID BAHONA
   Rashedi E, 2012, 20 INT C EL ENG U TE
   Rashedi E, 2012, P 6 INT S TEL IST201
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   RUI Y, 1998, IEEE T CIRCUITS VIDE, V8, P25
   Shamsi A, 2013, MULTIMEDIA TOOLS APP
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Yin PY, 2008, IEEE T KNOWL DATA EN, V20, P352, DOI 10.1109/TKDE.2007.190697
   Yin PY, 2005, IEEE T PATTERN ANAL, V27, P1536, DOI 10.1109/TPAMI.2005.201
NR 37
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3799
EP 3822
DI 10.1007/s11042-013-1800-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800010
DA 2024-07-18
ER

PT J
AU Tsougenis, ED
   Papakostas, GA
   Koulouriotis, D
AF Tsougenis, E. D.
   Papakostas, G. A.
   Koulouriotis, D. E.
TI Image watermarking via separable moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Separable image moments; Geometric distortion
   invariance; Locality
ID QUALITY ASSESSMENT; QUANTIZATION; PERFORMANCE
AB The use of image moments as host coefficients constitutes one of the hot topics in image watermarking field due to their robust behavior. Recenlty, a new approach called separable moments (SMs) has been introduced representing an image as combinations of different orthogonal polynomials that generate a series of new moment families. The scope of the present work is to introduce the specific transformations to the image watermarking field by evaluating their security capability under a wide range of common signal processing and geometric attacks. Furthermore, their ability of carrying large binary watermark messages is also examined. The performance of the proposed moment families is evaluated by a comparison to the original moments and a state-of-the-art method. The experimental results justified that a number of the studied transformations outperforms the benchmark method and occasionally the original moment families. Moreover, specific separable moment families are free of instabilities to the higher order coefficients where the extra watermark information is carried. A significant conclusion lies on the adoption of properties (locality, stability) between the generated separable moment families that lead to the enhancement of the basic watermarking requirements (robustness, imperceptibility and capacity) of the proposed watermarking method. The present work justifies that discrete orthogonal SMs constitute a new attractive transformation for the image moment-based watermarking field.
C1 [Tsougenis, E. D.; Koulouriotis, D. E.] Democritus Univ Thrace, Dept Prod Engn & Management, GR-67100 Xanthi, Greece.
   [Papakostas, G. A.] TEI Eastern Macedonia & Thrace, Human Machines Interact HMI Lab, Dept Comp & Informat Engn, GR-65404 Agios Loukas, Kavala, Greece.
C3 Democritus University of Thrace
RP Tsougenis, ED (corresponding author), Democritus Univ Thrace, Dept Prod Engn & Management, GR-67100 Xanthi, Greece.
EM stsougen@pme.duth.gr; gpapakos@ee.duth.gr; jimk@pme.duth.gr
RI Koulouriotis, Dimitrios/AAI-9437-2021; Papakostas, George A./F-1038-2017
OI Koulouriotis, Dimitrios/0000-0003-0194-0654; Papakostas, George
   A./0000-0001-5545-1499
CR Alghoniemy M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P73, DOI 10.1109/ICIP.2000.899229
   Alghoniemy M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1291, DOI 10.1109/ICME.2000.871003
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Lee J, 2008, PATTERN RECOGN LETT, V29, P1934, DOI 10.1016/j.patrec.2008.06.006
   Liu ZH, 2014, MULTIMED TOOLS APPL, V70, P2271, DOI 10.1007/s11042-012-1235-5
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Papakostas GA, 2013, NEUROCOMPUTING, V99, P358, DOI 10.1016/j.neucom.2012.06.031
   Papakostas GA, 2011, OPT COMMUN, V284, P4394, DOI 10.1016/j.optcom.2011.05.073
   Papakostas G. A., 2010, 2010 IEEE International Conference on Imaging Systems and Techniques (IST 2010), P464, DOI 10.1109/IST.2010.5548512
   Papakostas GA, 2010, PATTERN RECOGN, V43, P58, DOI 10.1016/j.patcog.2009.05.008
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Tsougenis E.D., 2012, 19 INT C SYST SIGN I
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang SJ, 2012, MULTIMED TOOLS APPL, V57, P29, DOI 10.1007/s11042-010-0539-6
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2004, TENCON IEEE REGION, pB73
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang Li, 2007, Journal of Software, V18, P2283, DOI 10.1360/jos182283
   ZHONG S, 1994, PATTERN RECOGN LETT, V15, P1171, DOI 10.1016/0167-8655(94)90106-6
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2012, PATTERN RECOGN, V45, P1540, DOI 10.1016/j.patcog.2011.10.002
NR 29
TC 28
Z9 28
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3985
EP 4012
DI 10.1007/s11042-013-1808-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800018
DA 2024-07-18
ER

PT J
AU Zia, MS
   Jaffar, MA
AF Zia, M. Sultan
   Jaffar, M. Arfan
TI An adaptive training based on classification system for patterns in
   facial expressions using SURF descriptor templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions recognition; Incremental learning; SURF; Template
   matching; Machine learning
AB Most facial expression recognition (FER) systems used facial expression data created during a short period of time and this data is used for learning/training of FER systems. There are many facial expression patterns (i.e. a particular expression can be represented in many different patterns) which cannot be generated and used as learning/training data in a short time. Therefore, in order to maintain its high accuracy and robustness for a long time of a facial expression recognition system, the classifier should be evolved adaptively over time and space. We proposed a facial expression recognition system that has the aptitude of incrementally learning and thus can learn all possible patterns of expressions that may be generated in feature. After extraction of region of interest (face), the system extracts Speeded-Up Robust Features (SURF). A novel SURF descriptor template based nearest neighbor classifier is proposed for classification. This classifier is used as base/weak classifier for incremental learning algorithm Learn++. A vast range of experimentation is performed on five different databases that demonstrate the incremental learning capability of the proposed system. The experiments using the incrementally learning classification demonstrate promising results.
C1 [Zia, M. Sultan; Jaffar, M. Arfan] NU FAST, Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
   [Zia, M. Sultan] COMSATS, Inst Informat Technol, Sahiwal, Pakistan.
   [Jaffar, M. Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); Imam Mohammad Ibn Saud Islamic
   University (IMSIU)
RP Jaffar, MA (corresponding author), Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM ziactn@gmail.com; arfan.jaffar@ccis.imamu.edu.sa
RI Jaffar, Arfan/GQB-2768-2022
CR [Anonymous], 12036722 ARXIV
   [Anonymous], 4 IEEE ICAFGR
   [Anonymous], ATL CIT MPEG M
   [Anonymous], IEEE INT C ROB AUT
   [Anonymous], 2010, P 11 INT WORKSH IM A
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], FEEDTUM FACIAL EXPRE
   [Anonymous], BRIT MACH VIS C 2009
   [Anonymous], ESSAYS ANATOMY EXPRE
   Baron-Cohen S, 1998, NATURE, V392, P459, DOI 10.1038/33076
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cheon YJ, 2009, PATTERN RECOGN, V42, P1340, DOI 10.1016/j.patcog.2008.10.010
   Chin S, 2010, CHIN OPT LETT, V8, P29, DOI 10.3788/COL20100801.0029
   Ekman P, 1978, FACIAL ACTION CODING
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lee CC, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/596842
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Polikar R, 2007, IEEE SIGNAL PROC MAG, V24, P59, DOI 10.1109/MSP.2007.4286565
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Suo JL, 2011, IEEE T SYST MAN CY A, V41, P226, DOI 10.1109/TSMCA.2010.2064304
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zhi RC, 2008, IEEE IMAGE PROC, P1924, DOI 10.1109/ICIP.2008.4712157
   Zhiguo Niu, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P174, DOI 10.1109/ICACTE.2010.5579670
NR 33
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3881
EP 3899
DI 10.1007/s11042-013-1803-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800013
DA 2024-07-18
ER

PT J
AU Tian, LH
   Zheng, NN
   Xue, JR
   Li, C
AF Tian, Lihua
   Zheng, Nanning
   Xue, Jianru
   Li, Ce
TI Authentication and copyright protection watermarking scheme for H.264
   based on visual saliency and secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Copyright protection; Authentication; Visual
   saliency; Secret sharing
ID FRAGILE WATERMARKING; DIGITAL WATERMARKING; VIDEO; ATTENTION
AB This paper proposes a video watermarking scheme based on visual saliency and secret sharing, which can be used for both synchronous authentication and copyright protection. Firstly, video is divided into several different scenes, and region of interest (ROI) for each I frames would be extracted automatically using the proto-object based saliency attention model. Secondly, the robust watermark and fragile watermark are generated according to ROI. The robust watermark is synthesized by copyright information and ROI of the first I frame for each video scene, and the edge map of ROI in each I frame is chosen as the fragile watermark. Finally, the robust watermark and fragile watermark are embedded into I frames of video scenes so that it can achieve video authentication and copyright information simultaneously. Experimental results demonstrate that the proposed method is robust to recompression and frame attack, and is also sensitive to tamper at the same time.
C1 [Tian, Lihua; Zheng, Nanning; Xue, Jianru; Li, Ce] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Tian, LH (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
EM lhtian@mail.xjtu.edu.cn
RI Tian, li/HQY-8623-2023
FU National Basic Research Program of China(973 Program) [2012CB316400];
   National Natural Science Foundation of China [61075007]; Natural Science
   Foundation Research Plan of Shaanxi Province of China [11JK0900]
FX This work was supported in part by the National Basic Research Program
   of China(973 Program) under Grant No. 2012CB316400, the National Natural
   Science Foundation of China under Grant No. 61075007 and the Natural
   Science Foundation Research Plan of Shaanxi Province of China under
   Grant No. 11JK0900.
CR [Anonymous], P IEEE INT S BROADB
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Koz A, 2008, IEEE T CIRC SYST VID, V18, P326, DOI 10.1109/TCSVT.2008.918446
   Li CT, 2004, IEE P-VIS IMAGE SIGN, V151, P460, DOI 10.1049/ip-vis:20040812
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2009, IEEE T CIRC SYST VID, V19, P1169, DOI 10.1109/TCSVT.2009.2020263
   Lin YR, 2006, INT C PATT RECOG, P795
   Liu HM, 2006, IEEE IMAGE PROC, P2569, DOI 10.1109/ICIP.2006.312984
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Park SW, 2011, J INF SCI ENG, V27, P129
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Qiu G, 2004, INT C PATT RECOG, P865
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang CC, 2010, OPT ENG, V49, DOI 10.1117/1.3309472
   Wang RD, 2012, J INFORM COMPUTATION, V9, P3693
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Xu DW, 2009, LECT NOTES COMPUT SC, V5703, P96, DOI 10.1007/978-3-642-03688-0_11
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhong Wei-Dong, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P364, DOI 10.1109/ICCSN.2011.6013734
NR 23
TC 9
Z9 10
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2991
EP 3011
DI 10.1007/s11042-013-1765-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800007
DA 2024-07-18
ER

PT J
AU Xhafa, F
   Li, JW
   Zhao, GS
   Li, J
   Chen, XF
   Wong, DS
AF Xhafa, Fatos
   Li, Jingwei
   Zhao, Gansen
   Li, Jin
   Chen, Xiaofeng
   Wong, Duncan S.
TI Designing cloud-based electronic health record system with
   attribute-based encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic health record; Attribute-based encryption; Cloud computing
ID SECURITY
AB With the development of cloud computing, electronic health record (EHR) system has appeared in the form of patient-centric, in which patients store their personal health records (PHRs) at a remote cloud server and selectively share them with physicians for convenient medical care. Although the newly emerged form has many advantages over traditional client-server model, it inevitably introduces patients' concerns on the privacy of their PHRs due to the fact that cloud servers are very likely to be in a different trusted domain from that of the patients. In this paper, aiming at allowing for efficient storing and sharing PHRs and also eliminating patients' worries about PHR privacy, we design a secure cloud-based EHR system, which guarantees security and privacy of medical data stored in the cloud, relying on cryptographic primitive but not the full trust over cloud servers. Based on our proposed basic EHR system, we provide several extensions including adding searchability, supporting revocation functionality and enabling efficient local decryption, which fills the gap between theoretical proposal and practical application.
C1 [Xhafa, Fatos] Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, Barcelona, Spain.
   [Li, Jingwei] Nankai Univ, Coll Informat Tech Sci, Tianjin 300071, Peoples R China.
   [Zhao, Gansen] S China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Li, Jin] Guangzhou Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Chen, Xiaofeng] Xidian Univ, State Key Lab Integrated Serv Networks ISN, Xian, Peoples R China.
   [Wong, Duncan S.] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Universitat Politecnica de Catalunya; Nankai University; South China
   Normal University; Guangzhou University; Xidian University; City
   University of Hong Kong
RP Xhafa, F (corresponding author), Univ Politecn Cataluna, Dept Llenguatges & Sistemes Informat, Barcelona, Spain.
EM fatos@lsi.upc.edu; lijw1987@gmail.com; zhaogansen@gmail.com;
   jinli71@gmail.com; xfchen@xidian.edu.cn; duncan@cityu.edu.hk
RI Xhafa, Fatos/B-8869-2012; Li, Jingwei/L-1328-2016
OI Xhafa, Fatos/0000-0001-6569-5497; 
FU National Natural Science Foundation of China [61100224, 61272455];
   Guangdong Natural Science Foundation [S2013010013671]; Guangzhou
   Research Infrastructure Development Fund [201222412]; Guangzhou Zhujiang
   Science and Technology Future Fellow Fund [2011J2200089]; MOE-China
   Mobile Research Fund [MCM20121051]
FX This work is supported by National Natural Science Foundation of China
   (Grant No.61100224, No.61272455), Guangdong Natural Science Foundation
   (No.S2013010013671), Guangzhou Research Infrastructure Development Fund
   (No. 201222412), Guangzhou Zhujiang Science and Technology Future Fellow
   Fund (No. 2011J2200089), and the MOE-China Mobile Research Fund (No.
   MCM20121051).
CR [Anonymous], 2010, P INFOCOM, DOI DOI 10.1109/INFCOM.2010.5462196
   [Anonymous], IACR CRYPTOLOGY EPRI
   [Anonymous], COMPUT STAND INTERFA
   [Anonymous], CONCURRENCY COMPUTAT
   [Anonymous], COMPUT METHODS PROG
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Benaloh Josh., 2009, P 2009 ACM WORKSHOP, P103
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Chase M, 2007, LECT NOTES COMPUT SC, V4392, P515
   Chase M, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P121
   Cheung L, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P456
   Farzandipour M, 2010, J MED SYST, V34, P629, DOI 10.1007/s10916-009-9276-7
   Goyal V., 2006, P 2006 INT C PRIVACY, P1
   Green M., 2011, P 20 USENIX C SEC
   Haas S, 2011, INT J MED INFORM, V80, pE26, DOI 10.1016/j.ijmedinf.2010.10.001
   Jingwei Li, 2012, Information and Communication Security. 14th International Conference (ICICS 2012). Proceedings, P191, DOI 10.1007/978-3-642-34129-8_17
   Lee WB, 2008, IEEE T INF TECHNOL B, V12, P34, DOI 10.1109/TITB.2007.906101
   Lewko A, 2012, LECT NOTES COMPUT SC, V7417, P180
   Lewko A, 2011, LECT NOTES COMPUT SC, V6632, P568, DOI 10.1007/978-3-642-20465-4_31
   Lewko A, 2011, LECT NOTES COMPUT SC, V6632, P547, DOI 10.1007/978-3-642-20465-4_30
   Lewko A, 2010, LECT NOTES COMPUT SC, V5978, P455, DOI 10.1007/978-3-642-11799-2_27
   Lewko A, 2010, LECT NOTES COMPUT SC, V6110, P62, DOI 10.1007/978-3-642-13190-5_4
   Li J, 2013, ADV INTEL SYS RES, V50, P592, DOI 10.1007/978-3-642-40203-6_33
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li JW, 2014, FUTURE GENER COMP SY, V30, P98, DOI 10.1016/j.future.2013.06.011
   Li M, 2011, INT CON DISTR COMP S, P383, DOI 10.1109/ICDCS.2011.55
   Fernández-Alemán JL, 2013, J BIOMED INFORM, V46, P541, DOI 10.1016/j.jbi.2012.12.003
   Menachemi N, 2011, RISK MANAG HEALTHC P, V4, P47, DOI 10.2147/RMHP.S12985
   Narayan S, 2010, PROCEEDINGS OF THE 2010 ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'10:), P47, DOI 10.1145/1866835.1866845
   Neubauer T, 2011, INT J MED INFORM, V80, P190, DOI 10.1016/j.ijmedinf.2010.10.016
   Riedl B, 2007, 13TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING, PROCEEDINGS, P397, DOI 10.1109/PRDC.2007.24
   Rodríguez-Vera FJ, 2002, J ROY SOC MED, V95, P545, DOI 10.1258/jrsm.95.11.545
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Waters B, 2011, LECT NOTES COMPUT SC, V6571, P53, DOI 10.1007/978-3-642-19379-8_4
   Winslow EH, 1997, HEART LUNG, V26, P158, DOI 10.1016/S0147-9563(97)90076-5
   Wu D, 2010, INT CONF COMP SCI, P268, DOI 10.1109/ICCSIT.2010.5563744
   Yu SC, 2010, IEEE INFOCOM SER, DOI 10.1109/INFCOM.2010.5462174
   Zhibin Zhou, 2012, 2012 8th International Conference on Network and Service Management (CNSM 2012), P37
NR 41
TC 41
Z9 46
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3441
EP 3458
DI 10.1007/s11042-013-1829-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000014
DA 2024-07-18
ER

PT J
AU Zhen, H
   Kim, HK
   Moon, JY
AF Zhen He
   Kim, Hyo-Kyung
   Moon, Jae-Young
TI A study on the effect of hotel intelligent fusion system on hotel
   strategy, work process, employee satisfaction, and hotel performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hotel intelligent fusion system; Hotel information system; Structural
   equation model
ID ORIENTATION
AB The purpose of this study is to analyze, through causal relationship, what influence hotel intelligent which is hotel information system has on the strategy, work process, employee satisfaction, financial results and customer satisfaction in Hotel business. Empirical findings of this research suggest that hotel information system has positive, direct & indirect effects on financial results and customer satisfaction. There have been a lot of improvements with the short-term & long-term strategy, employee satisfaction and work process by using Hotel information system.
C1 [Zhen He] Tianjin Univ, Coll Management & Econ, Tianjin 300072, Peoples R China.
   [Kim, Hyo-Kyung; Moon, Jae-Young] Dongseo Univ, Div Business, Busan, South Korea.
C3 Tianjin University; Dongseo University
RP Moon, JY (corresponding author), Dongseo Univ, Div Business, Busan, South Korea.
EM zhhe@tju.edu.cn; hyokyung_kim@hanmail.net; jaymoon@gdsu.dongseo.ac.kr
RI Kim, Tae Hyun/P-1470-2019; Kim, Jin/AAS-5810-2021; Moon,
   Jaeyoung/I-6322-2018
OI Kim, Tae Hyun/0000-0001-8413-3385; Kim, Jin/0000-0002-7667-9588; 
FU Dongseo University; National Natural Science Foundation of China [NSFC
   71225006]
FX This research was supported by 2014 research program of Dongseo
   University and National Natural Science Foundation of China (NSFC
   71225006).
CR Barclay CA, 1993, MANAGE INT REV, V1, P87
   Berry FH, 1976, CCAT SRS, V3, P67
   Berry L.L., 1981, J RETAIL BANK, V3, P33, DOI DOI 10.1080/109040182000.10499039
   Brown TJ, 2002, J MARKETING RES, V39, P110, DOI 10.1509/jmkr.39.1.110.18928
   Kasavana ML, 2003, MANAGEMENT TECHNOLOG, V4th
   Kim JM, 1998, TOUR SCI SOC KOREA, V22, P249
   Kirk D., 1998, International Journal of Hospitality Management, V17, P203, DOI 10.1016/S0278-4319(98)00016-4
   Lee JR, 2008, J HOSP TOUR STUD, V29, P84
   Lee S. G., 1992, STUDY HOTEL MANAGEME
   Naver JC, 1990, J MARKETING, V54, P20
   PARASURAMAN A, 1988, J RETAILING, V64, P12
   Park HS, 2005, KOREA ASS INF SYST, V1, P409
   Park J. S., 2004, EFFECT HOTEL ROOM RE
   SIGUAW JA, 1994, J MARKETING RES, V31, P106, DOI 10.2307/3151950
   Song SI, 2003, KOREAN ACAD SOC HOSP, V12, P139
   Uwizeyemungu S, 2010, INFORM SYST MANAGE, V27, P25, DOI 10.1080/10580530903455122
NR 16
TC 2
Z9 2
U1 6
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3377
EP 3385
DI 10.1007/s11042-014-2011-5
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000009
DA 2024-07-18
ER

PT J
AU Park, S
   Chung, H
   Lee, C
   Lee, S
   Lee, K
AF Park, Sooyoung
   Chung, Hyunji
   Lee, Changhoon
   Lee, Sangjin
   Lee, Kyungho
TI Methodology and implementation for tracking the file sharers using
   BitTorrent
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BitTorrent investigation; Illegal file sharing; Digital investigation
   process; Packet analysis; Client-side disk forensics
AB Sharing copyright protected content without the copyright holder's permission is illegal in many countries. Regardless, the number of illegal file sharing using BitTorrent continues to grow and most of file sharers and downloader are unconcerned legal action to transfer copywrite-protected files. However, it is difficult to gather enough probative evidence to prosecute illegal file sharers in criminal court and/or sued for damages in civil court. Further, there is a lack of research on investigation techniques to reveal illegal BitTorrent sharers. This is because the role of the server in BitTorrent networks has been changed compared to servers in conventional P2P networks. As a result, it is difficult to apply previous investigation processes for investigation of conventional P2P networks to the investigation of suspected illegal file sharing using BitTorrent. This paper proposes a methodology for the investigation of illegal file sharers using BitTorrent networks through the use of a P2P digital investigation process.
C1 [Park, Sooyoung; Chung, Hyunji; Lee, Sangjin; Lee, Kyungho] Korea Univ, CIST, Seoul, South Korea.
   [Lee, Changhoon] Seoul Natl Univ Sci & Technol SeoulTech, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Korea University; Seoul National University of Science & Technology
RP Lee, K (corresponding author), Korea Univ, CIST, Anam Campus,Anam Ding 5 Ga, Seoul, South Korea.
EM sooyoung011@korea.ac.kr; foryou7187@korea.ac.kr; chlee@seoultech.ac.kr;
   sangjin@korea.ac.kr; kevinlee@korea.ac.kr
OI Lee, Changhoon/0000-0003-4292-5792
FU National Research Foundation of Korea (NRF) - Ministry of Science, ICT &
   Future Planning [2012M3A2A1051106]
FX This research was supported by the Public Welfare & Safety Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Science, ICT & Future Planning (2012M3A2A1051106)
CR [Anonymous], CARDOZO J INT COMP L
   Hatahet Sinan, 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P708, DOI 10.1109/ISCC.2010.5546536
   Hyunjoo K, 2006, J INF PROCESS SYST, V2
   Lallie HS, 2011, DIGIT INVEST, V7, P127, DOI 10.1016/j.diin.2010.10.002
   Liu JP, 2013, J INF PROCESS SYST, V9, P365, DOI 10.3745/JIPS.2013.9.3.365
   Peng K, 2012, J INF PROCESS SYST, V8, P175, DOI 10.3745/JIPS.2012.8.1.175
   Schrader K, 2009, IFIP ADV INF COMM TE, V306, P159
NR 7
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 271
EP 286
DI 10.1007/s11042-013-1760-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300018
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, X
   Zhang, T
   Zhang, Y
   Li, WX
   Ping, XJ
AF Li, Xing
   Zhang, Tao
   Zhang, Yan
   Li, Wenxiang
   Ping, Xijian
TI Quantitative steganalysis of spatial ±1 steganography in JPEG
   decompressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Image Steganography; Quantitative Steganalysis; LSB
   matching; JPEG decompressed images
ID LSB STEGANOGRAPHY
AB On the basis of the analysis of JPEG error and stegonoise, we propose a novel quantitative steganalyzer for spatial +/- 1 steganography in JPEG decompressed images. First, we present a particular theoretical argument that the cover images, which are originally stored in JPEG format, can be approximately estimated through JPEG recompression with the detected quantization table. Then, on the basis of the relationship between the message embedding rate and the variance of the stegonoise in the discrete cosine transformation (DCT) domain, we construct a polynomial regression model to estimate the secret message length. The extensive experimental results show that the proposed scheme is computationally feasible and that it significantly outperforms the existing state-of-the-art estimators, especially for the images with high quality factors and embedding rates. The order of magnitude of the prediction error using the proposed scheme can remain in the 10-4 range, as measured by the median absolute difference. Moreover, our estimator is stable and robust with respect to the embedding rate and quality factor.
C1 [Li, Xing; Zhang, Tao; Li, Wenxiang; Ping, Xijian] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
   [Zhang, Yan] Zhengzhou Univ Light Ind, Zhengzhou 450002, Henan, Peoples R China.
C3 PLA Information Engineering University; Zhengzhou University of Light
   Industry
RP Li, X (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
EM listarcat@163.com
FU National Natural Science Foundation of China [60903221, 61272490];
   National High Technology Research and Development Program of China
   ("863" Program) [2011AA010603, 2011AA010605]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60903221, No. 61272490) and the National High Technology
   Research and Development Program of China (" 863" Program, No.
   2011AA010603, No. 2011AA010605). The authors would like to thank the
   reviewers for their insightful comments and helpful suggestions.
CR [Anonymous], IMAGE DATABASE STEGA
   Böhme R, 2008, LECT NOTES COMPUT SC, V5284, P178
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Fridrich J, 2005, PROC SPIE, V5681, P595, DOI 10.1117/12.584426
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2001, PROC SPIE, V4518, P275, DOI 10.1117/12.448213
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Luo WQ, 2011, IEEE SIGNAL PROC LET, V18, P39, DOI 10.1109/LSP.2010.2091127
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Zhang J, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P385, DOI 10.1109/MMSP.2007.4412897
   Zhang J, 2010, IEEE SIGNAL PROC LET, V17, P141, DOI 10.1109/LSP.2009.2035379
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zhang T, 2010, INFORM SCIENCES, V180, P4685, DOI 10.1016/j.ins.2010.07.037
   Zheng EG, 2011, KSII T INTERNET INF, V5, P840, DOI 10.3837/tiis.2011.04.012
   Zhu X, 2012, J INF HIDING MULTIME, V3, P164
NR 26
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1487
EP 1506
DI 10.1007/s11042-013-1654-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200018
DA 2024-07-18
ER

PT J
AU Liu, FW
   Koenig, H
AF Liu, Fuwen
   Koenig, Hartmut
TI <i>Puzzle</i> - an efficient, compression independent video encryption
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video encryption; Compression-independent encryption; Real-time
   encryption
ID DESIGN
AB Real-time video streams require an efficient encryption method to ensure their confidentiality. One of the major challenges in designing a video encryption algorithm is to encrypt the vast amount of video data in real-time to satisfy the stringent time requirements. Video encryption algorithms can be classified according to their association with video compression into joint compression and encryption algorithms and compression-independent encryption algorithms. The latter have a clear advantage over the former regarding the incorporation into existing multimedia systems due to their independence of the video compression. In this paper we present the compression-independent video encryption algorithm Puzzle, which was inspired by the children game jigsaw puzzle. It comprises two simple encryption operations with low computational complexity: puzzling and obscuring. The scheme thereby dramatically reduces the encryption overhead compared to conventional encryption algorithms, such as AES, especially for high resolution video. Further outstanding features of Puzzle are a good trade-off between security demands and encryption efficiency, no impairment on video compression efficiency, and an easy integration into existing multimedia systems. This makes Puzzle particularly well-suited for these security-sensitive multimedia applications, such as videoconferencing, where maximal security and minimal encryption overhead are desired simultaneously.
C1 [Liu, Fuwen; Koenig, Hartmut] Brandenburg Tech Univ Cottbus, Dept Comp Sci, D-03013 Cottbus, Germany.
C3 Brandenburg University of Technology Cottbus
RP Liu, FW (corresponding author), Brandenburg Tech Univ Cottbus, Dept Comp Sci, PF 10 13 44, D-03013 Cottbus, Germany.
EM lfw@informatik.tu-cottbus.de; koenig@informatik.tu-cottbus.de
CR Agi I., 1996, Proceedings of the Symposium on Network and Distributed System Security, P137, DOI 10.1109/NDSS.1996.492420
   [Anonymous], 2008, Introduction to Modern Cryptography
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], 2001, FIPS PUB
   Bellare M, 1997, IEEE P 38 S FDN COMP
   Bernstein D. J., SALSA20 DESIGN
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   DURSTENFELD R, 1964, COMMUN ACM, V7, P420, DOI 10.1145/364520.364540
   Dworkin M, 2001, Recommendation for block cipher modes of operation. Methods and Techniques
   Fuhrt, 2004, MULTIMEDIA SECURITY
   Goldwasser Shafi., LECT NOTES CRYPTOGRA
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Johnathan MR, 2001, LNCS, V2216
   KNUTH D. E., 1981, Addison-Wesley Series in Computer Science and Information Processing, V2
   Krawczyk H., 1997, Internet Engineering Task Force (IETF)
   Lei Tang, 1996, Proceedings ACM Multimedia 96, P219, DOI 10.1145/244130.244209
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Liu F., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P69, DOI 10.1145/1065983.1066001
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   Liu FW, 2005, LECT NOTES COMPUT SC, V3677, P88
   LIU X, 2003, IASTED INT C COMM IN
   Mayer-Patel K, 2005, ACM T MULTIM COMPUT, V1, P110, DOI 10.1145/1047936.1047944
   MOSES LE., 1963, TABLES RANDOM PERMUT
   Netravali A. N, 1996, Digital video: an introduction to MPEG-2
   NIST, 2007, 80057 NIST SP
   Pommer A., 2002, PROC MULTIMEDIA SECU, P71
   Qiao L, 1998, COMPUT GRAPH, V22, P437, DOI 10.1016/S0097-8493(98)00033-8
   Qiao LT, 1997, ISCE '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CONSUMER ELECTRONICS, P226, DOI 10.1109/ISCE.1997.658393
   ROGAWAY P, 1993, P 1 INT WORKSH FAST, P56
   Rueppel R. A., 1986, Analysis and Design of Stream Ciphers
   Schneier R, 1996, APPL CRYPTOGRAPHY
   Shi CG, 1999, INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOL VI, PROCEEDINGS, P2822
   Socek D, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/52965
   Spanos G. A., 1995, Proceedings Fourth International Conference on Computer Communications and Networks (ICCCN'95) (Cat. No.95TB8110), P2, DOI 10.1109/ICCCN.1995.540095
   Stanek M, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2, PROCEEDINGS, P20
   Wu C.P., 2000, SPIE INT S INFORM TE, V4209, P284
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Yongcheng Li, 1996, Proceedings International Workshop on Multimedia Software Development, P169, DOI 10.1109/MMSD.1996.557770
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
NR 40
TC 4
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 715
EP 735
DI 10.1007/s11042-012-1185-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700006
DA 2024-07-18
ER

PT J
AU Lee, TKM
   Belkhatir, M
   Sanei, S
AF Lee, Tracey K. M.
   Belkhatir, Mohammed
   Sanei, Saeid
TI A comprehensive review of past and present vision-based techniques for
   gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometry; Gait; Pattern recognition; Gait analysis and recognition
ID HUMAN MOTION ANALYSIS; HUMAN IDENTIFICATION; BIOLOGICAL MOTION;
   FACE-RECOGNITION; WALKING SPEED; SHAPE; RECONSTRUCTION; REPRESENTATION;
   PERCEPTION; SEQUENCES
AB Global security concerns have raised a proliferation of video surveillance devices. Intelligent surveillance systems seek to discover possible threats automatically and raise alerts. Being able to identify the surveyed object can help determine its threat level. The current generation of devices provide digital video data to be analysed for time varying features to assist in the identification process. Commonly, people queue up to access a facility and approach a video camera in full frontal view. In this environment, a variety of biometrics are available-for example, gait which includes temporal features like stride period. Gait can be measured unobtrusively at a distance. The video data will also include face features, which are short-range biometrics. In this way, one can combine biometrics naturally using one set of data. In this paper we survey current techniques of gait recognition and modelling with the environment in which the research was conducted. We also discuss in detail the issues arising from deriving gait data, such as perspective and occlusion effects, together with the associated computer vision challenges of reliable tracking of human movement. Then, after highlighting these issues and challenges related to gait processing, we proceed to discuss the frameworks combining gait with other biometrics. We then provide motivations for a novel paradigm in biometrics-based human recognition, i.e. the use of the fronto-normal view of gait as a far-range biometrics combined with biometrics operating at a near distance.
C1 [Lee, Tracey K. M.] Singapore Polytech, Sch Elect & Elect Engn, Singapore, Singapore.
   [Lee, Tracey K. M.] Monash Univ, Sch Informat Technol, Kuala Lumpur, Malaysia.
   [Belkhatir, Mohammed] Univ Lyon, Fac Comp Sci, Lyon, France.
   [Sanei, Saeid] Univ Surrey, Dept Comp, Surrey, England.
C3 Singapore Polytechnic; Monash University; Monash University Malaysia;
   University of Surrey
RP Belkhatir, M (corresponding author), Univ Lyon, Fac Comp Sci, Lyon, France.
EM tlee@sp.edu.sg; mohammed.belkhatir@univ-lyon1.fr; s.sanei@surrey.ac.uk
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ahad MAR, 2010, MACH VIS APPL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2006, P 18 INT C PATT REC
   [Anonymous], P 5 IEEE INT C AUT F
   [Anonymous], P 5 IEEE INT C AUT F
   [Anonymous], 2006, Handbook of Multibiometrics
   Aqmar MR, 2012, IEICE T INF SYST, VE95D, P668, DOI 10.1587/transinf.E95.D.668
   Aristidou A, 2008, P ICBBE
   Bariska A, 2007, IEEE SIGNAL PROC MAG, V24, P127, DOI 10.1109/MSP.2007.905890
   Bashir K, 2009, P BR MACH VIS C
   Bazin AI, 2006, THESIS U SOUTHAMPTON
   BenAbdelkader C, 2001, P FAC GEST REC
   BenAbdelkader C, 2001, P 3 INT C AUD VID B
   BenAbdelkader C, 2002, P INT ECCV 2002 WORK
   BenAbdelkader C, 2002, P WORKSH BIOM AUTH B
   Birchfield S, 1997, P AS C SIGN SYST COM
   Bissacco A, 2009, INT J COMPUT VISION, V85, P101, DOI 10.1007/s11263-009-0248-7
   Bobick AF, 2001, P 2001 IEEE C COMP V
   Bobick AF, 2001, P 3 INT C AUD VID BA
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   BRADSKI G, 1998, INTEL TECHNOL J Q, V2
   Bregler C, 1998, P 1998 IEEE C COP VI
   Caselles V, 1996, SIAM J NUMER ANAL, V33, P2445, DOI 10.1137/S0036142994275044
   Cham TJ, 1999, P 1999 IEEE C COMP V
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Chen CY, 2010, IEEE T SYST MAN CY B, V40, P208, DOI 10.1109/TSMCB.2009.2025028
   Chowdhury AR, 2003, P 2003 IEEE INT C AC
   Colombo C, 1999, P 7 INT C COMP VIS C
   Comaniciu D., 2000, P 2000 IEEE COMP VIS
   CUNADO D, 1997, P 1 INT C AUD VID BA
   CURWEN R, 1992, ACTIVE VISION, P39
   Cutting J.E., 1981, INTERSENSORY PERCEPT
   CUTTING JE, 1978, J EXP PSYCHOL HUMAN, V4, P357, DOI 10.1037/0096-1523.4.3.357
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   Cutting JE, 1978, BEHAV RES METH INSTR, V10, P191
   Czyz J, 2002, P 2 INT WORKSH PATT
   Dagan E, 2004, P INT VEH S 4
   Davies JW, 1997, P 1997 IEEE C COMP V
   DiFranco DE, 2001, P 2001 IEEE C COMP V
   Eldar YC, 2000, IEEE T SIGNAL PROCES, V48, P2864, DOI 10.1109/78.869037
   Esquef P. A. A., 2003, P 6 INT C DIG AUD EF
   Feichtinger H. G., 1994, Wavelets: Mathematics and Applications, P305
   FERREIRA PJSG, 1994, IEEE T SIGNAL PROCES, V42, P3278, DOI 10.1109/78.330398
   Ferreira PJSG, 2001, SAMPLING THEORY
   Foster JP, 2001, P 3 INT C AUD VID BA
   Fujiyoshi H, 2004, IEICE T INF SYST, VE87D, P113
   GABRIEL PF, 2003, P ADV CONC INT VIS S
   Gavrila DM, 1996, APRA IMAGE UNDERST W
   Geng X, 2007, P IM VIS COMP
   GERCHBERG RW, 1974, OPT ACTA, V21, P709, DOI 10.1080/713818946
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Ho MF, 2009, IEEE INT CON MULTI, P1054, DOI 10.1109/ICME.2009.5202679
   Hogg D., 1983, Image Vision Computing, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   HOWE NR, 1999, ADV NEURAL INF PROCE, V12
   Hu M, 2011, P IEEE INT C IM PROC
   Jain A K, 2011, Introduction to Biometrics
   Jean F, 2009, PATTERN RECOGN, V42, P2936, DOI 10.1016/j.patcog.2009.05.006
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   JOHNSON A, 2001, P 3 INT C AUD VID BA
   Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293, DOI 10.1109/34.485557
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kale A, 2004, OPTICAL DIGITAL TECH
   Kale A, 2004, P 2004 IEEE INT C AC
   Kale A, 2002, P 5 IEEE INT C AUT F
   Kale A, 2003, P INT C AC SPEECH SI
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kellokumpu V, 2009, LECT NOTES COMPUT SC, V5558, P1000, DOI 10.1007/978-3-642-01793-3_101
   Khan JI, 2001, P 9 ACM INT C MULT
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Koller D, 1994, P 2 EUR C COMP VIS E
   Kwon KS, 2007, LECT NOTES COMPUT SC, V4552, P690
   Lee TKM, 2008, P 19 INT C PATT REC
   Lee TKM, 2006, ICASSP 2006, P15
   Lee TKM, 2007, DSP 2007, P1
   Leventon ME, 1998, TECH REP 98 06
   Little JL, 1998, P 1998 IEEE C COMP V
   Liu G, 2006, VISUAL COMPUT, V22, P1432
   Liu ZY, 2007, IMAGE VISION COMPUT, V25, P817, DOI 10.1016/j.imavis.2006.05.022
   Lu JW, 2007, PATTERN RECOGN LETT, V28, P2401, DOI 10.1016/j.patrec.2007.08.004
   Lucas B.D., DARPA IMAGE UNDERSTA
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Maodi Hu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3679, DOI 10.1109/ICPR.2010.897
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090
   MARR D, 1978, COMPUTER VISION SYST
   METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727
   Moeslund TB., 2000, P IEEE WORKSH HUM MO
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morris DD, 1998, P 1998 IEEE C COMP V
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   Ning HZ, 2004, IMAGE VISION COMPUT, V22, P429, DOI 10.1016/j.imavis.2004.01.001
   Ning HZ, 2002, P 4 IEEE INT C MULT
   NIXON MS, 1999, BIOMETRICS PERSONAL
   Niyogi SA, 1994, P 1994 IEEE C COMP V
   Niyogi SA, 1994, P WORKSH NONR MOT AG
   Nizami IF, 2010, INT J IMAG SYST TECH, V20, P400, DOI 10.1002/ima.20256
   Ortega-Garcia J, 2005, REPORT EXISTING BIOM
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ran Y, 2007, INT J COMPUT VISION, V71, P143, DOI 10.1007/s11263-006-8575-4
   Ran Y, 2010, IEEE T SYST MAN CY B, V40, P1009, DOI 10.1109/TSMCB.2010.2044173
   Raviv D, 2000, COMPUT VIS IMAGE UND, V79, P331, DOI 10.1006/cviu.2000.0862
   ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tanawongsuwan R, 2004, PROC CVPR IEEE, P783
   Tanawongsuwan R, 2001, P 2001 IEEE C COMP V
   Taycher L, 2002, P IEEE WORKSH STAT M
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Trivino G, 2010, PATTERN RECOGN, V43, P2572, DOI 10.1016/j.patcog.2010.01.017
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Venkat I, 2011, INT J COMPUT VISION, V91, P7, DOI 10.1007/s11263-010-0362-6
   Verhoeven G, 2007, AARGNEWS         MAR, V34, P30
   Vezzetti E, 2012, MUTLIMEDIA TOLS APL
   Vio R, 2000, PUBL ASTRON SOC PAC, V112, P74, DOI 10.1086/316495
   Wachter S, 1997, P IEEE NONR ART MOT
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2002, P 16 C PATT REC ICPR
   Wang L, 2002, P 9 IEEE INT C IM PR
   Whittle MW, 2007, GAIT ANAL INTRO, P139
   Yee-Hong Yang, 1992, Machine Vision and Applications, V5, P17, DOI 10.1007/BF01213527
   Yu S, 2006, P 7 AS C COMP VIS AC
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang X, 2010, IEEE T SYST MAN CY B, V40, P1034, DOI 10.1109/TSMCB.2010.2044240
   Zhou X, 2006, IEEE T SYST MAN CY B, V37, P1119
NR 129
TC 57
Z9 64
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2833
EP 2869
DI 10.1007/s11042-013-1574-x
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300033
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, N
   Li, Q
   Abd El-Latif, AA
   Peng, JL
   Niu, XM
AF Wang, Ning
   Li, Qiong
   Abd El-Latif, Ahmed A.
   Peng, Jialiang
   Niu, Xiamu
TI An enhanced thermal face recognition method based on multiscale complex
   fusion for Gabor coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal face recognition; Multiscale; Complex Gabor Jet Descriptor;
   Complex LDA; Feature level fusion
ID SCALE
AB The recognition of thermal face is a very promising strategy in biometrics. It is invariant to illumination, robust to pose and immune to forgery. However, thermal face image consist of face heat energy and face counter information mainly, and it makes lower discrimination for inter-class. In this paper, an enhanced thermal face recognition approach based on Multiscale Complex Fusion for Gabor coefficients (MCFG) is proposed. Initially, the Complex Gabor Jet Descriptor (CGJD) is acquired based on the block mean and standard deviation generated from the magnitude, phase, real and imaginary parts of Gabor coefficients. Then, the Complex LDA (CLDA) algorithm and feature level fusion are implemented on multiscale Gabor coefficients to reduce the dimension and enhance the discrimination. Experiments conducted on two thermal face databases NVIE and IRIS, which have some challenging thermal face images, show that the proposed thermal face recognition approach significantly outperforms the state-of-the-art approaches.
C1 [Wang, Ning; Li, Qiong; Abd El-Latif, Ahmed A.; Peng, Jialiang; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm 32511, Egypt.
   [Peng, Jialiang] Heilongjiang Univ, Informat & Network Adm Ctr, Harbin 150080, Peoples R China.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University; Heilongjiang University
RP Li, Q (corresponding author), Sci Zone Harbin Inst Technol, Room 1523,Bldg 2A,2 Yikuang St, Harbin 150080, Peoples R China.
EM qiong.li@hit.edu.cn
RI Abd El-Latif, Ahmed A. A./GRO-1613-2022
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033
FU National Natural Science Foundation of China [61100187]; Fundamental
   Research Funds for the Central Universities [HIT. NSRIF. 2010046, HIT.
   NSRIF. 2013061]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Number: 61100187) and the Fundamental Research Funds for
   the Central Universities (Grant Number: HIT. NSRIF. 2010046, HIT. NSRIF.
   2013061).
CR [Anonymous], 2009, P 2009 1 IEEE INT C
   [Anonymous], BIOMETRIC DECISION L
   [Anonymous], ISOIEC197951
   [Anonymous], 2010, ROBOT SOCCER WORLD C
   [Anonymous], PRCO 6 INT C LAT AM
   Bengio S., 2004, PROC SPEAKER LANGUAG, P279
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Desa SM, 2008, INT C PATT RECOG, P2837
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Heo J., 2004, Computer Vision and Pattern Recognition Workshop, page, P122, DOI DOI 10.1109/CVPR.2004.35
   Hermosilla G, 2012, PATTERN RECOGN, V45, P2445, DOI 10.1016/j.patcog.2012.01.001
   Jain A. K., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P726, DOI 10.1109/FG.2011.5771338
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Kim Y, 2011, IEEE T CONSUM ELECTR, V57, P756, DOI 10.1109/TCE.2011.5955219
   Kwon OK, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR HOMELAND SECURITY AND PERSONAL SAFETY, P112
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Méndez H, 2009, LECT NOTES COMPUT SC, V5558, P327, DOI 10.1007/978-3-642-01793-3_34
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sellahewa H, 2010, IEEE T INSTRUM MEAS, V59, P805, DOI 10.1109/TIM.2009.2037989
   Shen WC, 1997, P IEEE, V85, P1464, DOI 10.1109/5.628719
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Socolinsky DA, 2004, PROC CVPR IEEE, P1012
   Socolinsky DA, 2004, INT C PATT RECOG, P187, DOI 10.1109/ICPR.2004.1333735
   Wang N, 2014, MULTIMED TOOLS APPL, V71, P1411, DOI 10.1007/s11042-012-1278-7
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Yang H, 2003, IMAGE VISION COMPUT, V21, P1037, DOI 10.1016/j.imavis.2003.07.005
   Yang JW, 2003, PATTERN RECOGN LETT, V24, P1805, DOI 10.1010/S0167-8655(03)00005-9
   Zhu ZF, 2007, J VIS COMMUN IMAGE R, V18, P68, DOI 10.1016/j.jvcir.2006.10.001
NR 31
TC 37
Z9 37
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2339
EP 2358
DI 10.1007/s11042-013-1551-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300014
DA 2024-07-18
ER

PT J
AU Anggorosesar, A
   Kim, YJ
AF Anggorosesar, Aldhino
   Kim, Young-Jin
TI High power-saving and fidelity-conserving object-based local dimming for
   LCD systems with LED-based backlight units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Backlight dimming; Object-based local dimming; Power; Fidelity; LED
   BLU-based LCD; Human visual system; Complexity
AB A local dimming technique which is enabled on LED-based LCD systems is expected to give more power saving than a global one. However, prior local dimming techniques have not considered human visual system-awareness much as done in an advanced global dimming technique. In this paper, we propose a novel local dimming technique using an object-based approach for both good human visuality and high power saving. It utilizes prevalent colors of individual objects in a given image to do initial dimming, and then enhances the image using a proper fidelity threshold to reduce visible artifacts. Experimental results show that the proposed technique achieves power saving up to 13 and 12 times higher than human visual system-aware global dimming and prior well-designed local dimming techniques, respectively, with a similar human visual system-aware image quality level in a uniform backlight optical profile. It achieves power saving up to 15 and 6 times higher in a Gaussian-based backlight optical profile. Due to a good use of a simpler image fidelity metric, the proposed technique also can make the complexity go lower while keeping a satisfactory image quality.
C1 [Anggorosesar, Aldhino] Minist Commun & Informat Technol Republ Indonesia, Jakarta 10110, Indonesia.
   [Kim, Young-Jin] Ajou Univ, Dept Elect & Comp Engn, Suwon 443749, South Korea.
C3 Ajou University
RP Kim, YJ (corresponding author), Ajou Univ, Dept Elect & Comp Engn, San 5, Suwon 443749, South Korea.
EM youngkim@ajou.ac.kr
FU new faculty research fund of Ajou University; Ajou university
FX An earlier version of this paper appeared in the Proceedings of
   International Symposium on Low Power Electronics and Design (ISLPED)
   2011, Fukuoka, Japan. This work was supported by the new faculty
   research fund of Ajou University. This work was partially supported by
   the Ajou university research fund.
CR Albrecht M, 2008, 28TH INTERNATIONAL DISPLAY RESEARCH CONFERENCE, P286
   Anggorosesar A, 2011, IEICE T ELECTRON, VE94C, P1760, DOI [10.1587/transele.E94.C.1760, 10.1587/transele.E94.C1760]
   [Anonymous], IEEE INT C AC SPEECH
   Bartolini A, 2009, DES AUT TEST EUROPE, P1428
   Bartolini Andrea., 2009, P 7 ACM INT C EMBEDD, P21
   Carroll A., 2010, P 2010 USENIX C USEN, P21
   Chen HF, 2007, SID INT SYMP DIG TEC, V38, P1339, DOI 10.1889/1.2785560
   Chen HF, 2010, J SOC INF DISPLAY, V18, P57, DOI 10.1889/JSID18.1.57
   Chen MJ, 2010, INT CONF ACOUST SPEE, P994, DOI 10.1109/ICASSP.2010.5495310
   Cheng WC, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P252, DOI 10.1109/DATE.2004.1268857
   Cheng WC, 2006, ISLPED '06: PROCEEDINGS OF THE 2006 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P89, DOI 10.1109/LPE.2006.4271813
   Cui L, 2008, P BRIT MACH VIS C BM, P373
   Hong JJ, 2010, IEEE T CONSUM ELECTR, V56, P240, DOI 10.1109/TCE.2010.5439151
   Iranli A, 2005, DES AUT TEST EUROPE, P346, DOI 10.1109/DATE.2005.174
   Mahesri A, 2005, LECT NOTES COMPUT SC, V3471, P165
   Navas KA, 2011, IETE TECH REV, V28, P50, DOI 10.4103/0256-4602.74507
   Ruggiero Martino., 2008, P 8 ACM INT C EMBEDD, P109
   Wang Z, 2005, INT CONF ACOUST SPEE, P573
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 20
TC 1
Z9 1
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1115
EP 1141
DI 10.1007/s11042-013-1425-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300006
DA 2024-07-18
ER

PT J
AU Asaduzzaman, A
   Gunasekara, GH
AF Asaduzzaman, Abu
   Gunasekara, Govipalagodage H.
TI Power and performance analysis of multimedia applications running on
   low-power devices by cache modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cache memory organization; Cache modeling; Low-power devices; Multimedia
   applications; Power and performance analysis
ID OPTIMIZATION
AB High processing speed is required to support computation intensive applications. Cache memory is used to improve processing speed by reducing the speed gap between the fast processing core and slow main memory. However, the problem of adopting cache into computing systems is twofold: cache is power hungry (that challenges energy constraints) and cache introduces execution time unpredictability (that challenges supporting real-time multimedia applications). Recently published articles suggest that using cache locking improves predictability. However, increased cache activities due to aggressive cache locking make the system consume more energy and become less efficient. In this paper, we investigate the impact of cache parameters and cache locking on power consumption and performance for real-time multimedia applications running on low-power devices. In this work, we consider Intel Pentium-like single-processor and Xeon-like multicore architectures, both with two-level cache memory hierarchy, using three popular multimedia applications: MPEG-4 (the global video coding standard), H.264/AVC (the network friendly video coding standard), and recently introduced H.265/HEVC (for improved video quality and data compression ratio). Experimental results show that cache locking mechanism added to an optimized cache memory structure is very promising to increase the performance/power ratio of low-power systems running multimedia applications. According to the simulation results, performance can be improved by decreasing cache miss rate down to 36 % and the total power consumption can be saved up to 33 %. It is also observed that H.265/HEVC has significant performance advantage over H.264/AVC (and MPEG-4) for smaller caches.
C1 [Asaduzzaman, Abu; Gunasekara, Govipalagodage H.] Wichita State Univ, Wichita, KS 67260 USA.
C3 Wichita State University
RP Asaduzzaman, A (corresponding author), Wichita State Univ, 1845 Fairmt St JB-253, Wichita, KS 67260 USA.
EM abuasaduzzaman@ieee.org; ghgunasekara@wichita.edu
CR Ahmed R.E., 2006, IEEE CCECE CCGEI, P82, DOI [10.1109/CCECE.2006.277390, DOI 10.1109/CCECE.2006.277390]
   [Anonymous], 2012, IEEE T CIRCUITS SYST
   [Anonymous], P DES AUT TEST EUR C
   [Anonymous], MPEG 4 CONT DIG MED
   [Anonymous], IEEE COMPUTER ARCHIT
   Asaduzzaman A, 2012, J COMPUT JCP
   Asaduzzaman A, 2011, ICECS 2011 BEIR LEB
   Campoy AM, 2005, LECT NOTES COMPUT SC, V3820, P150
   Certner O, 2008, DES AUT TEST EUR DAT
   CHASE J, 2002, TECHONLINE
   Ely S., 1995, EBU Technical Review
   Gepner P, 2006, PAR ELEC 2006: INTERNATIONAL SYMPOSIUM ON PARALLEL COMPUTING IN ELECTRICAL ENGINEERING, PROCEEDINGS, P9
   Givargis T, 2005, ACM DATE
   Janapsatya A, 2006, ASIA S PACIF DES AUT, P796, DOI 10.1109/ASPDAC.2006.1594783
   Jerraya A, 2005, COMPUTER, V38, P36, DOI 10.1109/MC.2005.231
   Koenen R, 2002, P INT C COMP DES ICC
   Koopman PJ, 1996, P IKNT C COMP DES IC
   Li YB, 1998, 1998 DESIGN AUTOMATION CONFERENCE, PROCEEDINGS, P188, DOI 10.1109/DAC.1998.724464
   Maxiaguine A, 2004, EMB SYST REAL TIME M, P41
   Molnos A.M., 2003, Proceedings of the 14th Annual Workshop on Circuits, Systems and Signal Processing (ProRISC'03), P529
   Naz A., 2006, Computer Architecture News, V34, P19, DOI 10.1145/1147349.1147355
   Nebel W, 2004, IEEEDSD04
   Nosetti L., 1999, ICECS'99. Proceedings of ICECS '99. 6th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.99EX357), P1783, DOI 10.1109/ICECS.1999.814550
   Panda PR, 2001, ACM T DES AUTOMAT EL, V6, P149, DOI 10.1145/375977.375978
   Puaut I., 2006, Cache Analysis Vs Static Cache Locking for Schedulability Analysis in Multitasking Real-Time Systems
   Richardson lain E. G., H264MPEG4
   Robertson J., 2006, Instruction and data cache locking on the e300 processor core
   Schaphorst R, 1999, ARTECH HOUSE
   Slingerland N, 2012, PORTAL ACM
   Slingerland NT, 2002, MULTIMEDIA SYST, V8, P315, DOI 10.1007/s005300200052
   SODERQUIST P, 1997, ACM MULT 97 EL P
   Soryani M, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P1045
   Wiegand Thomas, 2003, IEEE T CIRCUITS SYST
   Wolf W, 2003, P IEEE, V91, P165, DOI 10.1109/JPROC.2002.805823
   WOLF W, 2005, IEEE DATE 05 P
   Wu Z, 2004, ISSUE 200, V71
   Zhang C., 2004, ACM T EMBED COMPUT S, V3, P407
NR 37
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 207
EP 230
DI 10.1007/s11042-012-1350-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800011
DA 2024-07-18
ER

PT J
AU Yang, S
   Xu, J
   Chen, Y
   Wang, MH
AF Yang, Shuo
   Xu, Jie
   Chen, Yong
   Wang, Minghui
TI On-road vehicle tracking using keypoint-based representation and online
   co-training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-training; Object tracking; Keypoint-based representation; Long-term
   tracking
ID VISUAL TRACKING; OBJECT TRACKING; SPARSE; FEATURES; SIFT
AB This paper addresses the issue of tracking an on-road vehicle from images taken by a camera inside a moving platform. Although existing methods have achieved successful results on tracking general objects such as face and pedestrian, when facing complicated road environments, their performance is unsatisfactory. Therefore, a method specialized for on-road vehicle tracking is needed. The proposed tracking method follows "tracking-by-detection" framework and uses co-training to construct a system with increasing learning ability. The method is mainly composed of tracker, detector, and error collector. The tracker uses keypoint matching to estimate the new location from frame to frame. The detector then fine tunes the location by using templates and knowledge-based methods and outputs the bounding box of the vehicle. At last, the error collector catches all possible errors from tracker and detector, and adds them into a dictionary to avoid similar errors in the future. Due to the error collector, the tracker and the detector can reinforce each other during tracking, thus, we also refer to the detector as online detector. This co-training mechanism leads to an efficient offline detector, which employs integrated information, including classified keypoints, templates, and symmetry, to perform "reappearance detection" when object disappears. The proposed method has been successfully validated by performing experiments with an onboard camera mounted on an on-road vehicle.
C1 [Yang, Shuo; Xu, Jie; Chen, Yong; Wang, Minghui] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Yang, S (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM lyfstnlcd@163.com
FU National Nature Science Foundation of China [61071162]
FX This work was supported by the National Nature Science Foundation of
   China (Grant No. 61071162).
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Ai-hua Chen, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1532, DOI 10.1109/ICOSP.2008.4697425
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], ICPR
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   Chung-Ching Lin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P828, DOI 10.1109/ICCVW.2009.5457616
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Gao T, 2012, MULTIMED TOOLS APPL, V58, P1, DOI 10.1007/s11042-010-0676-y
   Gentile C, 2004, IEEE T IMAGE PROCESS, V13, P166, DOI [10.1109/TIP.2003.817232, 10.1109/tip.2003.817232]
   Hager GD, 2004, PROC CVPR IEEE, P790
   Harris C., 1988, ALVEY VISION C, P147151
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kanitkar A., 2011, P INT C IM INF PROC, P1, DOI DOI 10.1109/ICIIP.2011.6108922
   Kaucic R, 2005, PROC CVPR IEEE, P990
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P626
   Liu H, 2007, IEEE INT CONF ROBOT, P4633, DOI 10.1109/ROBOT.2007.364193
   Liu R, 2009, IEEE I CONF COMP VIS, P1459, DOI 10.1109/ICCV.2009.5459285
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shen CH, 2007, IEEE T IMAGE PROCESS, V16, P1457, DOI 10.1109/TIP.2007.894233
   Shen CH, 2010, IEEE T CIRC SYST VID, V20, P119, DOI 10.1109/TCSVT.2009.2031393
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Szczuko P, 2014, MULTIMED TOOLS APPL, V68, P177, DOI 10.1007/s11042-012-1147-4
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Yang S, 2012, ELECTRON LETT, V48, P995, DOI 10.1049/el.2012.1922
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zhang W, 2012, IEEE T INTELL TRANSP, V13, P140, DOI 10.1109/TITS.2011.2165338
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 44
TC 8
Z9 9
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1561
EP 1583
DI 10.1007/s11042-013-1453-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300024
DA 2024-07-18
ER

PT J
AU Madain, A
   Abu Dalhoum, AL
   Hiary, H
   Ortega, A
   Alfonseca, M
AF Madain, Alia
   Abu Dalhoum, Abdel Latif
   Hiary, Hazem
   Ortega, Alfonso
   Alfonseca, Manuel
TI Audio scrambling technique based on cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio scrambling; Cellular automata; Game of life; Lambda parameter
AB Scrambling is a process that has proved to be very effective in increasing the quality of data hiding, watermarking, and encryption applications. Cellular automata are used in diverse and numerous applications because of their ability to obtain complex global behavior from simple and localized rules. In this paper we apply cellular automata in the field of audio scrambling because of the potential it holds in breaking the correlation between audio samples effectively. We also analyze the effect of using different cellular automata types on audio scrambling and we test different cellular automata rules with different Lambda values. The scrambling degree is measured and the relation between the robustness and the scrambling degree obtained is studied. Experimental results show that the proposed technique is robust to data loss attack where 1/3 of the data is lost and that the algorithm can be applied to music and speech files of different sizes.
C1 [Madain, Alia; Abu Dalhoum, Abdel Latif; Hiary, Hazem] Univ Jordan, Amman 11942, Jordan.
   [Ortega, Alfonso; Alfonseca, Manuel] Univ Autonoma Madrid, Madrid, Spain.
C3 University of Jordan; Autonomous University of Madrid
RP Hiary, H (corresponding author), Univ Jordan, Amman 11942, Jordan.
EM hazemh@ju.edu.jo
RI Alfonseca, Manuel/E-6187-2013; Hiary, Hazem/C-8358-2015
OI Alfonseca, Manuel/0000-0003-4144-2684; Hiary, Hazem/0000-0002-0306-5294;
   Madain, Alia/0000-0001-8865-9755; Ortega de la Puente,
   Alfonso/0009-0009-9173-8783
FU Spanish Ministry of Science and Innovation [TIN2011-28260-C03-00,
   TIN2011-28260-C03-02]; Comunidad Autonoma de Madrid [S2009/TIC-1650]
FX This work is partially supported by the Spanish Ministry of Science and
   Innovation under coordinated research projects TIN2011-28260-C03-00 and
   TIN2011-28260-C03-02 and by the Comunidad Autonoma de Madrid under
   research project e-madrid S2009/TIC-1650
CR Abu Dalhoum AL, 2012, IEEE MULTIMEDIA, V19, P28, DOI 10.1109/MMUL.2011.54
   [Anonymous], COMPLEX SYSTEMS
   Aponte A, 2006, LECT NOTES COMPUT SC, V4173, P502
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   Chen G, 2010, INT CONF COMP SCI, P62, DOI 10.1109/ICCSIT.2010.5564989
   Fu WG, 2005, IEEE INT SYMP CIRC S, P5525
   GARDNER M, 1970, SCI AM, V223, P120, DOI 10.1038/scientificamerican1070-120
   Huang HC, 2009, SOFT COMPUT, V13, P383, DOI 10.1007/s00500-008-0326-8
   Kier Lemont B., 2005, P237, DOI 10.1007/0-387-25871-X_6
   LANGTON CG, 1990, PHYSICA D, V42, P12, DOI 10.1016/0167-2789(90)90064-V
   Li H, 2009, ICEBE 2009: IEEE INTERNATIONAL CONFERENCE ON E-BUSINESS ENGINEERING, PROCEEDINGS, P165, DOI 10.1109/ICEBE.2009.30
   Li H, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, PROCEEDINGS, P316, DOI 10.1109/IIS.2009.105
   Li H, 2009, LECT NOTES COMPUT SC, V5574, P866
   Liu Xiangdong, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P818, DOI 10.1109/CSSE.2008.1424
   Nishio H, 2006, LECT NOTES COMPUT SC, V4173, P122
   Niu Jiping, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P677, DOI 10.1109/CSSE.2008.1172
   Noriega R.M., 2011, J INFORM HIDING MULT, V2, P91
   Sang-Ho Shin, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P399, DOI 10.1109/CSE.2009.299
   Sarkar P, 2000, ACM COMPUT SURV, V32, P80, DOI 10.1145/349194.349202
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Wolfram S., 2002, A new kind of science
   Yan WQ, 2008, IEEE T MULTIMEDIA, V10, P960, DOI 10.1109/TMM.2008.2001373
   Ye RS, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P938, DOI 10.1109/ISECS.2008.138
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
NR 24
TC 28
Z9 28
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1803
EP 1822
DI 10.1007/s11042-012-1306-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000037
DA 2024-07-18
ER

PT J
AU Norouzi, B
   Mirzakuchaki, S
   Seyedzadeh, S
   Mosavi, MR
AF Norouzi, Benyamin
   Mirzakuchaki, Sattar
   Seyedzadeh, Seyed
   Mosavi, Mohammad Reza
TI A simple, sensitive and secure image encryption algorithm based on
   hyper-chaotic system with only one round diffusion process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Diffusion process; Security; Sensitivity; NPCR; UACI
ID FRACTIONAL FOURIER-TRANSFORM; SCHEME; STANDARD; CRYPTANALYSIS;
   CRYPTOGRAPHY; CRYPTOSYSTEM
AB Based on hyper-chaotic systems, a novel image encryption algorithm is introduced in this paper. The advantages of our proposed approach are that it can be realized easily in one round diffusion process and is computationally very simple while attaining high security level, high key sensitivity, high plaintext sensitivity and other properties simultaneously. The key stream generated by hyper-chaotic system is related to the original image. Moreover, to encrypt each pixel, we use the sum of pixels which are located after that pixel. The algorithm uses different summations when encrypting different input images (even with the same sequence based on hyper-chaotic system). This, in turn, will considerably enhance the cryptosystem resistance against known/chosen-plaintext and differential attacks. The change rate of the number of pixels in the cipher-image when only one pixel of the original image is modified (NPCR) and the Unified Average Changing Intensity (UACI) are already very high (NPCR > 99.80233 % and UACI > 33.55484 %). Also, experimental results such as key space analysis, histograms, correlation coefficients, information entropy, peak signal-to-noise ratio, key sensitivity analysis, differential analysis and decryption quality, show that the proposed image encryption algorithm is secure and reliable, with high potential to be adopted for the secure image communication applications.
C1 [Norouzi, Benyamin; Mirzakuchaki, Sattar; Seyedzadeh, Seyed; Mosavi, Mohammad Reza] Iran Univ Sci & Technol, Dept Elect Engn, Tehran 1684613114, Iran.
C3 Iran University Science & Technology
RP Norouzi, B (corresponding author), Iran Univ Sci & Technol, Dept Elect Engn, Tehran 1684613114, Iran.
EM benyamin_norouzi@ieee.org; m_kuchaki@iust.ac.ir;
   sm_seyedzade@elec.iust.ac.ir; M_Mosavi@iust.ac.ir
RI Mirzakuchaki, Sattar/I-8764-2016; Mirzakuchaki, Sattar/JCO-4452-2023;
   Mosavi, Mohammad Reza/P-3505-2018
OI Mirzakuchaki, Sattar/0000-0003-0232-9267; Mosavi, Mohammad
   Reza/0000-0002-2389-644X
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Alvarez E, 1999, PHYS LETT A, V263, P373, DOI 10.1016/S0375-9601(99)00747-1
   Alvarez G, 2000, PHYS LETT A, V276, P191, DOI 10.1016/S0375-9601(00)00642-3
   Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   [Anonymous], INT J ELECT COMPUT E
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Belkhouche F., 2003, P IEEE ANN TECHN C, P39
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Borujeni SE, 2009, MATH PROBL ENG, V2009, DOI 10.1155/2009/762652
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen HC, 2003, EURASIP J APPL SIG P, V2003, P1291, DOI 10.1155/S1110865703309011
   Encinas LH, 2006, OPT COMMUN, V268, P261, DOI 10.1016/j.optcom.2006.07.043
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Ge X, 2010, PHYS LETT A, V374, P1362, DOI 10.1016/j.physleta.2010.01.024
   HABUTSU T, 1991, LECT NOTES COMPUT SC, V547, P127
   Huang X, 2010, J NONLINEAR DYN, V67, P2411
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Niu YJ, 2010, COMMUN NONLINEAR SCI, V15, P3518, DOI 10.1016/j.cnsns.2009.12.005
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Singh N, 2008, OPT LASER ENG, V46, P117, DOI 10.1016/j.optlaseng.2007.09.001
   Sinha A, 2003, OPT COMMUN, V218, P229, DOI 10.1016/S0030-4018(03)01261-6
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Tong XJ, 2009, OPT COMMUN, V282, P2722, DOI 10.1016/j.optcom.2009.03.075
   Wang XG, 2006, OPT COMMUN, V260, P449, DOI 10.1016/j.optcom.2005.11.006
   Wang XY, 2012, NONLINEAR DYNAM, V67, P365, DOI 10.1007/s11071-011-9984-7
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wong KW, 2003, PHYS LETT A, V310, P67, DOI 10.1016/S0375-9601(03)00259-7
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xiao D, J CHAOS SOLITONS FRA, V40, P2191
   Yanchuk S, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.056235
   Yanchuk S, 2001, PHYS LETT A, V290, P139, DOI 10.1016/S0375-9601(01)00651-X
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhao L, 2012, COMMUN NONLINEAR SCI, V17, P3303, DOI 10.1016/j.cnsns.2011.12.015
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 60
TC 163
Z9 167
U1 2
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1469
EP 1497
DI 10.1007/s11042-012-1292-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000023
DA 2024-07-18
ER

PT J
AU Kleinen, A
   Scherp, A
   Staab, S
AF Kleinen, Alexander
   Scherp, Ansgar
   Staab, Steffen
TI Interactive faceted search and exploration of open social media data on
   a touchscreen mobile phone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile computing; Faceted search and exploration; Social media
AB A central challenge of semantic ambient media applications is designing smart user interfaces that are able to dynamically deal with an a-priori unknown number of data categories and data instances received live from different Linked Open Data sources while at the same time being intuitive and easy to use. In the mobile world, this challenge is even more difficult as the mobile devices have limited interaction possibilities and smaller display size. In this paper, we tackle this challenge and present the user-centered, iterative design of a mobile application for faceted search and exploration of a large, multi-dimensional data set of open social media on a touchscreen mobile phone. The application is called Mobile Facets and provides live retrieval and interactive search and exploration of resources like places, persons, organizations, and events originating from different, integrated social media sources like DBpedia, Eventful, Upcoming, Flickr, and GeoNames. In contrast to existing work, we do not know in advance the number and type of data categories and data instances that will be received as the data is queried live from the sources. While developing Mobile Facets, we have applied a participatory design with a small group of five users. For the final prototype we have conducted a task-based, formative evaluation with 12 additional subjects to investigate the applicability and usability of our Mobile Facets application.
C1 [Kleinen, Alexander; Scherp, Ansgar; Staab, Steffen] Univ Koblenz Landau, Inst Web Sci & Technol, Koblenz, Germany.
C3 University of Koblenz & Landau
RP Scherp, A (corresponding author), Univ Koblenz Landau, Inst Web Sci & Technol, Koblenz, Germany.
EM kleinen@uni-koblenz.de; scherp@uni-koblenz.de; staab@uni-koblenz.de
RI ; Scherp, Ansgar/Q-2315-2016
OI Staab, Steffen/0000-0002-0780-4154; Scherp, Ansgar/0000-0002-2653-9245
FU EU [215453, 287975]
FX We thank all subjects participating in the evaluation. This research has
   been co-funded by the EU in FP7 in the IP WeKnowIt (215453) and IP
   SocialSensor (287975).
CR [Anonymous], 2011, LINKED DATA EVOLVING
   [Anonymous], 1994, TASK CTR USER INTERF
   Arndt H, 2006, INTEGRIERTE INFORMAT
   Auer Soren, 2007, ISWC ASWC
   Neto JSD, 2009, SIGDOC'09: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P119
   English Jennifer, 2002, TECHNICAL REPORT
   Franz T., 2009, ISWC
   Gediga G, 1999, BEHAV INFORM TECHNOL, V18, P151, DOI 10.1080/014492999119057
   Gediga G, 2001, ENCY COMPUTER SCI TE, V45
   Hearst MA, 2008, COMPUTER INTERACTION
   Hearst MartiA., 2006, Proc. SIGIR Workshop on Faceted Search, P26
   Hildebrand M, 2006, ISWC
   Jacobson Ivar., 1999, AW OBJ TECHNOL S
   Karlson A., 2006, CHI
   Oren E, 2006, INT SEM WEB C
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Sacco GM, 2009, INFORM RETRIEVAL SER, V25, P1, DOI 10.1007/978-3-642-02359-0
   Schmeiss D, 2010, P INT C MULT MM 2010, P1567
   SCHRAEFEL MC, 2005, HYPERTEXT
   Segerståhl K, 2009, LECT NOTES COMPUT SC, V5727, P354, DOI 10.1007/978-3-642-03658-3_41
   Sohn T, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P433
   Tan S, 2011, P 19 ACM INT C MULT, P243
   Trappeniers L, 2008, BELL LABS TECH J, V13, P5, DOI 10.1002/bltj.20296
   van Aart CJ, 2010, EKAW
   Wilson ML, 2006, CHI
   Wilson ML, 2005, END US SEM WEB WORKS
   Yee K-P, 2003, HUMAN FACTORS COMPUT
NR 27
TC 7
Z9 7
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 39
EP 60
DI 10.1007/s11042-013-1366-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700003
DA 2024-07-18
ER

PT J
AU Lan, ZZ
   Bao, L
   Yu, SI
   Liu, W
   Hauptmann, AG
AF Lan, Zhen-zhong
   Bao, Lei
   Yu, Shoou-I
   Liu, Wei
   Hauptmann, Alexander G.
TI Multimedia classification and event detection using double fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature combination; Early fusion; Late fusion; Double fusion;
   Multimedia event detection
AB Multimedia Event Detection(MED) is a multimedia retrieval task with the goal of finding videos of a particular event in video archives, given example videos and event descriptions; different from MED, multimedia classification is a task that classifies given videos into specified classes. Both tasks require mining features of example videos to learn the most discriminative features, with best performance resulting from a combination of multiple complementary features. How to combine different features is the focus of this paper. Generally, early fusion and late fusion are two popular combination strategies. The former one fuses features before performing classification and the latter one combines output of classifiers from different features. Early fusion can better capture the relationship among features yet is prone to over-fit the training data. Late fusion deals with the over-fitting problem better but does not allow classifiers to train on all the data at the same time. In this paper, we introduce a fusion scheme named double fusion, which simply combines early fusion and late fusion together to incorporate their advantages. Results are reported on the TRECVID MED 2010, MED 2011, UCF50 and HMDB51 datasets. For the MED 2010 dataset, we get a mean minimal normalized detection cost (MMNDC) of 0.49, which exceeds the state-of-the-art performance by more than 12 percent. On the TRECVID MED 2011 test dataset, we achieve a MMNDC of 0.51, which is the second best among all 19 participants. On UCF50 and HMDB51, we obtain classification accuracy of 88.1 % and 48.7 % respectively, which are the best reported results to date.
C1 [Lan, Zhen-zhong; Bao, Lei; Yu, Shoou-I; Liu, Wei; Hauptmann, Alexander G.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Lan, ZZ (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
EM lanzhzh@cs.cmu.edu; lei.bao.cn@gmail.com; iyu@cs.cmu.edu;
   lwbiosoft@gmail.com; alex@cs.cmu.edu
RI Yu, Shoou-I/Z-4199-2019
FU Intelligence Advanced Research Projects Activity (IARPA) via Department
   of Interior National Business Center [D11PC20068]; National Science
   Foundation [CCF-1019104]; Gordon and Betty Moore Foundation
FX This work was supported in part by the Intelligence Advanced Research
   Projects Activity (IARPA) via Department of Interior National Business
   Center contract number D11PC20068. The U.S. Government is authorized to
   reproduce and distribute reprints for Governmental purposes
   notwithstanding any copyright annotation thereon. Disclaimer: The views
   and conclusions contained herein are those of the authors and should not
   be interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of IARPA, DoI/NBC, or the
   U.S. Government. Support was also provided, in part, by the National
   Science Foundation, under award CCF-1019104, and the Gordon and Betty
   Moore Foundation, in the eScience project. We thank the Parallel Data
   Lab for the use of their resources.
CR [Anonymous], INT WORKSH FRONT HAN
   [Anonymous], INT C MULT MOD
   [Anonymous], ACM INT C MULT MM 03
   [Anonymous], TRECVID VIDEO RETRIE
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], TRECVID VIDEO RETRIE
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], CLASSIFCATION EVENTS
   [Anonymous], ACM INT C MULT MM 05
   [Anonymous], TRECVID VIDEO RETRIE
   [Anonymous], 2011, INT C COMP VIS ICCV
   [Anonymous], TRECVID VIDEO RETRIE
   [Anonymous], C UNC ART INT UAI 09
   [Anonymous], EUR C INF RETR ECIR
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], ADV KERNEL METHODS S
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lazebnik S., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.68
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Smeaton AF, 2006, ACM INT WORKSH MULT
   Wang H, 2011, PROC CVPR IEEE
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
NR 26
TC 61
Z9 72
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 333
EP 347
DI 10.1007/s11042-013-1391-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700020
DA 2024-07-18
ER

PT J
AU Fan, MQ
   Wang, HX
   Li, HJ
AF Fan, Ming-Quan
   Wang, Hong-Xia
   Li, Heng-Jian
TI A fingerprint-based audio authentication scheme using frequency domain
   statistical characteristic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio authentication; Digital fingerprint; Non-malicious signal
   processing; Malicious falsification; Non-uniform quantization; Chaos
ID WATERMARKING SCHEME; SPEECH; ROBUST
AB Recently, a major problem faced by digital data providers and owners is protecting data from malicious falsification and distribution. As a solution to this problem, digital fingerprinting technique is now attracting attention as new method for integrity protection. According to frequency domain statistical characteristic, an efficient fingerprint-based audio authentication scheme is proposed in this paper. Initially, the host audio signal is equally divided into non-overlapping frames, moreover, each audio frame is then equally split into non-overlapping segments, and the DFT (discrete Fourier transform) domain relation of each audio segment is computed. Then DFT domain relations of each audio frame are adopted to generate the corresponding binary pattern using non-uniform quantization. Finally, the fingerprint is obtained by performing XOR operation between the binary pattern and binary pseudo-random sequence. Simulation results demonstrate the effectiveness of our scheme in terms of inaudibility, detection reliability, robustness against some non-malicious signal processing operations and vulnerability against malicious falsification.
C1 [Fan, Ming-Quan; Wang, Hong-Xia] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Li, Heng-Jian] Shandong Prov Key Lab Comp Networks, Jinan 250014, Peoples R China.
C3 Southwest Jiaotong University
RP Fan, MQ (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM mqfan_sc@163.com
RI Wang, Hongxia/AAE-2135-2022
FU National Natural Science Foundation of China (NSFC) [61170226]; Shandong
   Province Outstanding Young Scientists Foundation [BS2011DX034]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) under grant No. 61170226, and Shandong Province Outstanding Young
   Scientists Foundation under grant No. BS2011DX034.
CR CHEN N, 2008, IEEE INT C MULT EXP, P221
   Chen OTC, 2008, IEEE T AUDIO SPEECH, V16, P629, DOI 10.1109/TASL.2007.913022
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Fan MQ, 2011, DIGIT SIGNAL PROCESS, V21, P110, DOI 10.1016/j.dsp.2010.09.003
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lu CS, 2000, INT C PATT RECOG, P282, DOI 10.1109/ICPR.2000.903540
   Park CM, 2007, PATTERN RECOGN LETT, V28, P931, DOI 10.1016/j.patrec.2006.12.010
   Rui Liu, 2011, Journal of Multimedia, V6, P458, DOI 10.4304/jmm.6.5.458-466
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang HQ, 2008, APPL ACOUST, V69, P868, DOI 10.1016/j.apacoust.2007.06.001
   Xiang SJ, 2007, LECT NOTES COMPUT SC, V4437, P93
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
NR 17
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2255
EP 2270
DI 10.1007/s11042-012-1203-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500039
DA 2024-07-18
ER

PT J
AU Lin, CC
   Liao, LH
   Hwang, KF
   Chen, SC
AF Lin, Ching-Chiuan
   Liao, Lun Hao
   Hwang, Kuo Feng
   Chen, Shih-Chieh
TI Reversible secret-image sharing with high visual quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Friendly secret sharing; Secret image sharing; Shadow
   images
ID SCHEME; CRYPTOGRAPHY
AB This paper proposes a reversible secret-image sharing scheme for sharing a secret image among 2n shadow images with high visual quality (i.e., they are visually indistinguishable from their original images, respectively). In the proposed scheme, not only can the secret image be completely revealed, but the original cover images can also be losslessly recovered. A difference value between neighboring pixels in a secret image is shared by 2n pixels in 2n shadow images, respectively, where n a parts per thousand yenaEuro parts per thousand 1. A pair of shadow images which are constructed from the same cover image are called brother stego-images. To decrease pixel values changed in shadow images, each pair of brother stego-images is assigned a weighted factor when calculating difference values to be shared. A pixel in a cover image is recovered by calculating the average of corresponding pixels in its brother stego-images. A single stego-image reveals nothing and a pair of pixels in brother stego-images reveals partial difference value between neighboring secret pixels. The more brother stego-images are collected, the more information in the secret image will be revealed. Finally, a secret image will be completely revealed if all of its brother stego-images are collected.
C1 [Lin, Ching-Chiuan; Hwang, Kuo Feng; Chen, Shih-Chieh] Overseas Chinese Univ, Dept Informat Management, Taichung 40721, Taiwan.
   [Liao, Lun Hao] Chaoyang Univ Technol, Deptpartment Informat Management, Taichung 41349, Taiwan.
C3 Chaoyang University of Technology
RP Lin, CC (corresponding author), Overseas Chinese Univ, Dept Informat Management, Taichung 40721, Taiwan.
EM cclin@ocu.edu.tw; Liao.Howard@gmail.com; kfhwang@ocu.edu.tw;
   jackie@ocu.edu.tw
CR Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chang CC, 2007, FUND INFORM, V76, P399
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Chin-Chen Chang, 2011, Journal of Electronic Science and Technology, V9, P325, DOI 10.3969/j.issn.1674-862X.2011.04.008
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Hwa-Ching Hsu, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P996
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Liu ZJ, 2008, OPT COMMUN, V281, P5322, DOI 10.1016/j.optcom.2008.07.048
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Ulutas M, 2011, J SYST SOFTWARE, V84, P341, DOI 10.1016/j.jss.2010.11.928
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang FH, 2007, INFORM SCIENCES, V177, P2522, DOI 10.1016/j.ins.2006.12.025
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wu YS, 2004, PATTERN RECOGN, V37, P1377, DOI 10.1016/j.patcog.2004.01.002
NR 22
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1729
EP 1747
DI 10.1007/s11042-012-1190-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500017
DA 2024-07-18
ER

PT J
AU Lu, WT
   Li, L
   Li, JX
   Li, T
   Zhang, HG
   Guo, J
AF Lu, Wenting
   Li, Lei
   Li, Jingxuan
   Li, Tao
   Zhang, Honggang
   Guo, Jun
TI A multimedia information fusion framework for web image categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web image categorization; Multimedia information fusion; Text; Image;
   Dynamic weighting; Region-based semantic concept integration
ID SEGMENTATION
AB With the rapid development of technologies for fast Internet access and the popularization of digital cameras, an enormous number of digital images are posted and shared online everyday. Web images are usually organized by topic and are often assigned appropriate topic-related textual descriptions. Given a large set of images along with the corresponding texts, a challenging problem is how to utilize the available information to efficiently and effectively perform image retrieval tasks, such as image classification and image clustering. Previous approaches on image categorization focus on either adopting text or image features, or simply combining these two types of information together. In this paper, we improve our previously reported two multi-view classification approaches-(Dynamic Weighting and Region-based Semantic Concept Integration) for categorizing the images under the "supervision" of topic-related textual descriptions-by proposing a novel multimedia information fusion framework, in which these two proposed methods are seamlessly integrated by analyzing the special characteristics of different images. Notice that, the proposed framework is a generic multimedia information fusion framework which is not limited to our previously reported two approaches, and it can also be used to integrate other existing multi-view classification methods or models. Also, our proposed framework is capable of handling the large scale image categorization. Specifically, the proposed framework can automatically choose an appropriate classification model for each testing image according to its special characteristics and consequently achieve better classification performance with relatively less computation time for large scale datasets; Moreover, it is able to categorize images without any textual description in real world applications. Empirical experiments on two different types of web image datasets demonstrate the efficacy and efficiency of our proposed classification framework.
C1 [Lu, Wenting; Zhang, Honggang; Guo, Jun] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligence Syst Lab, Beijing 100876, Peoples R China.
   [Lu, Wenting; Li, Lei; Li, Jingxuan; Li, Tao] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
C3 Beijing University of Posts & Telecommunications; State University
   System of Florida; Florida International University
RP Li, T (corresponding author), Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
EM wlu@cs.fiu.edu; lli003@cs.fiu.edu; jli003@cs.fiu.edu; taoli@cs.fiu.edu;
   zhhg@bupt.edu.cn; guojun@bupt.edu.cn
RI guo, ppdop/KAL-9865-2024; Guo, Jun/AAB-9166-2022; Li, Lei/H-1205-2015
OI Guo, Jun/0000-0001-6944-0731; Li, Lei/0000-0002-0688-9619
FU Army Research Office [W911NF-10-1-0366]; National Natural Science
   Foundation of China [61175011]; China Scholarship Council
FX This work is partially supported by the Army Research Office under grant
   number W911NF-10-1-0366, the National Natural Science Foundation of
   China under Grant No. 61175011, and the China Scholarship Council.
CR Allan M, 2009, BRIT MACH VIS C
   [Anonymous], ACM INT C IM VID RET
   [Anonymous], 1981, Practical Optimization
   [Anonymous], 2009, PROC 17 ACM INT C MU
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Carter RJ, 2001, NUCLEIC ACIDS RES, V29, P3928, DOI 10.1093/nar/29.19.3928
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Giacinto G, 2002, P IEEE INNS ENNS INT, V3, P155
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hare J, 2010, P 2 ACM INT C MULT I
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Indyk P, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P454
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   Kalva PR, 2007, PROC INT CONF DOC, P561
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lee WJ, 2007, LECT NOTES COMPUT SC, V4472, P22
   Li H., 2008, PROC 16 ACM INT C MU, P813
   Li Li, 2011, 2011 IEEE International Conference on Service Operations and Logistics and Informatics (SOLI), P45, DOI 10.1109/SOLI.2011.5986526
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li T, 2005, KNOWL INF SYST, V7, P289, DOI 10.1007/s10115-004-0155-8
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   McCallum A.K., 2002, MALLET MACHINE LEARN
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Peters J, 2017, ADAPT COMPUT MACH LE
   Salton G, 1986, Introduction to Modern Information Retrieval
   Shao B, 2009, IEEE T AUDIO SPEECH, V17, P1602, DOI 10.1109/TASL.2009.2020893
   Wu LZ, 1999, IEEE T MULTIMEDIA, V1, P334, DOI 10.1109/6046.807953
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Yin ZJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P957
   Zhu Q., 2006, Proceedings of ACM MM'06, ACM, P211
NR 33
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1453
EP 1486
DI 10.1007/s11042-012-1165-2
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500005
DA 2024-07-18
ER

PT J
AU Signer, B
   Norrie, MC
   Weibel, N
   Ispas, A
AF Signer, Beat
   Norrie, Moira C.
   Weibel, Nadir
   Ispas, Adriana
TI Advanced authoring of paper-digital systems Introducing templates and
   variable content elements for interactive paper publishing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia authoring; Paper-digital systems; Interactive paper;
   Templates; Variable content; Cross-media publishing
AB Over the last decade, there has been an increasing interest in paper-digital systems that allow regular paper documents to be augmented or integrated with digital information and services. Although a wide variety of technical solutions and applications have been proposed, they all rely on some means of specifying links from areas within paper pages to digital services where these areas correspond to elements of the document's artwork. Various frameworks and tools are available to support the development of paper-digital applications, but they tend to either require some programming skills or focus on specific application domains. We present an advanced publishing solution that is based on an authoring rather than programming approach to the production of interactive paper documents. Our solution is fully general and we describe how it uses concepts of templates and variable content elements to reduce redundancies and increase the flexibility in developing paper-digital applications.
C1 [Signer, Beat] Vrije Univ Brussel, Web & Informat Syst Engn Lab, B-1050 Brussels, Belgium.
   [Norrie, Moira C.; Ispas, Adriana] ETH, Inst Informat Syst, CH-8092 Zurich, Switzerland.
   [Weibel, Nadir] Univ Calif San Diego, DCog HCI Lab, La Jolla, CA 92093 USA.
C3 Vrije Universiteit Brussel; Swiss Federal Institutes of Technology
   Domain; ETH Zurich; University of California System; University of
   California San Diego
RP Signer, B (corresponding author), Vrije Univ Brussel, Web & Informat Syst Engn Lab, B-1050 Brussels, Belgium.
EM bsigner@vub.ac.be; norrie@inf.ethz.ch; weibel@ucsd.edu;
   ispas@inf.ethz.ch
RI Signer, Beat/A-8079-2008
OI Signer, Beat/0000-0001-9916-0837; Weibel, Nadir/0000-0002-3457-4227
CR [Anonymous], 2010, P PAPERCOMP 2010 1 I
   Anoto AB, 2006, FORM DES TOOL US GUI
   Anoto AB, 2006, PAP SDK SPEC DESCR
   Anoto AB, 2006, PEN API PROGR GUID J
   Anoto AB, 2006, AN SDK PC APPL VERS
   Bagley SR, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P44
   Conroy K, 2004, DEMO SESSION UIST, V26, P89
   Giannetti F, 2007, HPL200718
   GUIMBRETIERE F., 2003, P ACM S USER INTERFA, P51
   Heinrichs F, 2010, EICS 2010: PROCEEDINGS OF THE 2010 ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS, P193
   Ikeda H, 2006, P 19 ANN ACM S US IN, P94
   Klemmer S.R., 2003, P SIGCHI C HUMAN FAC, P89
   Liao C, 2008, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1314683.1314686
   Lin Min., 2004, CHI 04, P687
   Luff Paul., 2007, AUGMENTED PAPER DEVE, P275
   Lumley J, 2005, P 2005 ACM S DOC ENG, P32, DOI DOI 10.1145/1096601.1096615
   Mackay W. E., 1999, ACM Transactions on Computer-Human Interaction, V6, P311, DOI 10.1145/331490.331491
   McDowell D, 2005, IPA B, V005, P22
   Norrie M.C., 2006, PROC COPADD 2006, P9
   Norrie M.C., 2006, Proc. of the ACM Symp. on Document Engineering, P34
   Norrie MC, 2005, INFORM SYST, V30, P526, DOI 10.1016/j.is.2004.11.003
   Norrie MC, 2007, WIREL NETW, V13, P855, DOI 10.1007/s11276-006-9858-y
   Robinson P, 1997, P WORLD C WWW INT IN
   Sellen A.J., 2001, MYTH PAPERLESS OFFIC
   Signer B., 2008, Fundamental Concepts for Interactive Paper and Cross-Media Information Spaces
   Signer B., 2007, Proc. of the ACM Conf. on Tangible and Embedded Interaction TEI, P57, DOI DOI 10.1145/1226969.1226981
   Signer B, 2007, LECT NOTES COMPUT SC, V4801, P359
   Signer B, 2007, PROC INT CONF DOC, P954
   Signer B, 2011, INFORM SYST, V36, P538, DOI 10.1016/j.is.2010.08.002
   Signer B, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND APPLICATIONS, VOLS 1 AND 2, P566
   Signer Beat, 2006, P ACM INT C MAN DAT, DOI [10.1145/1142473.1142581, DOI 10.1145/1142473.1142581]
   Steimle J, 2009, IEEE T LEARN TECHNOL, V2, P174, DOI 10.1109/TLT.2009.27
   Tabard A, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P569
   Tsandilas Theophanis, 2010, P INT C ADV VIS INT, P147, DOI [10.1145/1842993.1843020, DOI 10.1145/1842993.1843020]
   Weibel N, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P19
   Weibel W., 2008, Proc. CHI '08, P2349, DOI 10.1145/1358628.1358682
   Wellner P., 1993, COMMUN ACM, V36, P87
   Yeh R, 2007, 200710 STANF COMP SC
   Yeh Ron., 2006, P SIGCHI C HUMAN FAC, P571
   Yeh RB, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P111, DOI 10.1145/1449715.1449734
NR 40
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1309
EP 1332
DI 10.1007/s11042-012-1217-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900031
OA Green Published
DA 2024-07-18
ER

PT J
AU Talukder, A
   Panangadan, A
AF Talukder, Ashit
   Panangadan, Anand
TI Extreme event detection and assimilation from multimedia sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Information retrieval; Matching; Multimedia;
   Representation; Search; Spatio-temporal trajectory; Tracking
ID VIDEO; MODEL
AB A new event-based multimedia processing framework for detection, retrieval, and cross-media content assimilation of geo-spatiotemporal phenomena is described. Multimedia information relevant to geo-spatiotemporal events are available from sources such as remote satellites, in-situ sensors as image streams, and other outlets such as news articles, weather bulletins as text documents and in various formats, each with widely varying properties. We pose an event-based framework to automatically detect geo-spatiotemporal phenomena from raw untagged remote-sensing satellite image streams, extract attributes for such events, match the spatiotemporal properties of the detected phenomenon with events in a database to automatically derive a media-independent event description, and subsequently use the media-independent event descriptions to assimilate relevant information of the same event across other media sources from the web using a mashup. A virtual globe interface enables simultaneous visualization of the assimilated spatiotemporal information annotated with Internet sources. This framework is demonstrated for the automatic detection of tropical cyclones from satellite imagery followed by the retrieval and assimilation of related information from government-run weather sites and commercial news portals.
C1 [Talukder, Ashit] NIST, Gaithersburg, MD 20899 USA.
   [Panangadan, Anand] CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA.
C3 National Institute of Standards & Technology (NIST) - USA; National
   Aeronautics & Space Administration (NASA); NASA Jet Propulsion
   Laboratory (JPL); California Institute of Technology
RP Talukder, A (corresponding author), NIST, 100 Bur Dr,Mail Stop 8940, Gaithersburg, MD 20899 USA.
EM ashit.talukder@nist.gov; Anand.V.Panangadan@jpl.nasa.gov
FU National Aeronautics and Space Administration (NASA) Applied Information
   Systems Research (AISR) Program
FX The research described in this paper was carried out at the Jet
   Propulsion Laboratory, California Institute of Technology with funding
   from the National Aeronautics and Space Administration (NASA) Applied
   Information Systems Research (AISR) Program. The authors acknowledge the
   contributions of Eric Rigor, Andrew Bingham, and Shen-shyang Ho.
CR [Anonymous], 2010, WEB C
   [Anonymous], SIGGRAPH 80 ACM SIGG
   [Anonymous], 1984, Tropical cyclone intensity analysis using satellite data
   Bobick AF, 1998, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1998.698609
   Castano R, 2006, 12 ACM SIGKDD INT C, P845
   DeMenthon D, 2003, P 11 ACM INT C MULT
   Fowler C, 2009, CONT FILM DIRECT, P1
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Franklin J, 2011, NATL HURRICANE CTR F
   Ho S-S, 2008, INT C KNOWL DISC DAT, P928
   Ho S-s, 2009, WORKSH CROSS MED INF
   Hongeng S, 2000, C COMP VIS PATT REC, P1818
   Hwang TH, 2003, INT GEOSCI REMOTE SE, P3641
   Khalid S, 2005, 7 IEEE WORKSH APPL C
   Kim S-S, 2004, MULT EXP 2004 ICME 0, V812, P811
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Li ZY, 2005, IEEE INT SYMP CIRC S, P3845
   Mazzoni D, 2007, REMOTE SENS ENVIRON, V107, P149, DOI 10.1016/j.rse.2006.06.021
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Moncrieff S, 2001, MULT EXP 2001 ICME 2, P989
   Navarrete T, 2006, INT SEM WEB C ISWC
   Nguyen NT, 2005, PROC CVPR IEEE, P955
   Nobre EMN, 2002, P 6 EUR WORKSH MULT
   Oliver N, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P3, DOI 10.1109/ICMI.2002.1166960
   Panangadan A, 2009, 17 ACM SIGSPATIAL IN
   Pasch RJ, 2003, B AM METEOROL SOC, V84, P1415, DOI 10.1175/BAMS-84-10-1415
   PEUQUET DJ, 1995, INT J GEOGR INF SYST, V9, P7, DOI 10.1080/02693799508902022
   Rath TM, 2003, PROC CVPR IEEE, P521
   Rhome JR, 2009, TECHNICAL SUMMARY NA
   Rui Y, 2000, P 8 ACM INT C MULT M
   Stefanidis A, 2003, 11 ACM INT S ADV GEO, P86
   Wei H, 2006, INT GEOSCI REMOTE SE, P835, DOI 10.1109/IGARSS.2006.214
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wimmers A., 2004, P 26 C HURR TROP MET
   Wulder M, 2005, GEO WORLD        NOV
   Zeinalipour-Yazti D, 2006, 15 ACM C INF KNOWL M
   Zhai Y, 2006, SEMANTIC LEARNING AP
   Zotkin D, 2001, DET REC EV VID 2001, P20
NR 38
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 237
EP 261
DI 10.1007/s11042-012-1088-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300010
DA 2024-07-18
ER

PT J
AU Chmielewski, J
AF Chmielewski, Jacek
TI Finding interactive 3D objects by their interaction properties
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metadata; Interactive 3D objects; Virtual reality; Query language
AB The problem of metadata for interactive 3D objects has appeared very recently. It is significant due to the growing demand for interactive applications of 3D technologies. Time required to prepare such applications depends strongly on availability of reusable interactive 3D objects. Easy access to such objects can be increased by search solutions that cover not only object geometry and semantics but also object interactions. However, existing metadata standards provide tools only for general, technical and semantic descriptions of objects. The missing elements of object description solution are metadata of object interactions and an optimized query language. In our previous research we have developed an extensible solution for describing interactions of 3D objects. In this paper, we present the second missing element, a specification of a special query language that enables efficient usage of the interaction metadata.
C1 Poznan Univ Econ, Dept Informat Technol, Poznan, Poland.
C3 Poznan University of Economics & Business
RP Chmielewski, J (corresponding author), Poznan Univ Econ, Dept Informat Technol, Poznan, Poland.
EM chmielewski@kti.ue.poznan.pl
RI Chmielewski, Jacek/B-3204-2010
CR 3D Model Search Engine, 2012, 3D MOD SEARCH ENG
   [Anonymous], PROC OF THE 11TH INT
   [Anonymous], 2006, Proceedings of the ACM Symposium on Virtual Reality Software and Technology
   Apaydin A, 2010, 2010 IEEE 34 ANN COM, P1
   Berners-Lee T., 2005, 3986 RFC IETF
   BILASCO IM, 2005, P 13 ANN ACM INT C M, P471, DOI DOI 10.1145/1101149.1101254
   Bry F., 2005, P 2005 ACM S APPL CO, P1645
   Cellary W, 2012, INTERACTIVE 3D MULTI, P13
   Chmielewski J, 2012, DESCRIBING INTERACTI, P195
   Chmielewski J, 2009, ONTOLOGY ENABLED MET, P59
   Chmielewski J, 2008, 6 INT C ADV MOB COMP, P397
   Chmielewski J, 2008, EUROGR TECH REP SER, P18, DOI 10.1109/HSI.2008.4581401
   Chmielewski J, 2008, PROCEEDINGS OF THE 2008 1ST INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, P313
   Chmielewski J, 2009, KDIR 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND INFORMATION RETRIEVAL, P160
   Chmielewski J, 2008, 22ND EUROPEAN CONFERENCE ON MODELLING AND SIMULATION, PROCEEDINGS, P555
   Demiris A, 2001, P INT WORKSH VER LOW
   DITTRICH KR, 1995, LNCS, V985, P1, DOI DOI 10.1007/3-540-60365-4_116
   FALCIDIENO B, 2004, EUR WORKSH INT KNOWL
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Ghosh H, 2007, ONTOLOGIES, P265
   Goczyla K, 2005, LECT NOTES COMPUT SC, V3528, P163
   Haas W, 2005, 2 EUR WORKSH INT KNO, P339
   Halstead M.H., 1977, OPERATING PROGRAMMIN
   Manjunath B.S., 2002, INTRO MPEG 7
   PAPAMARKOS G, 2003, WORKSH SEM WEB DAT
   Patel M, 2003, P INT C VIS VID GRAP, P189
   Project Looking Glass, 2009, SUN MICR
   Pulli Kari., 2007, Mobile 3D Graphics: with OpenGL ES and M3G
   Rakkolainen I, 2000, P 3 INT WORKSH INT I, P115
   Solomon J, 2007, ACM CROSSROADS M JUN, V13
   Spencer H, 1994, REGEX POSIX 1003 2 R
   Thallinger G, 2009, INT BROADC C IBC 200
   Thome B, 2005, P 2005 ACM SIGMOD IN, P863
   W3C Extended Backus-Naur Form (EBNF) notation, 2008, EXTENSIBLE MARKUP LA
   Walczak K, 2006, COMPUTER, V39, P93, DOI 10.1109/MC.2006.108
   Walczak K, 2003, COMPUTER, V36, P89, DOI 10.1109/MC.2003.1185226
   Walczak K., 2004, Proceedings of 11th International Workshop on Systems, Signals and Image Processing. Ambient Multimedia, P465
   Walczak K, 2005, INT J HUM-COMPUT INT, V1, P23
   Walczak K, 2009, CONFIGURABLE VIRTUAL
   Walczak K, 2007, 8 INT S VIRT REAL AR, P101
   White M, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P622, DOI 10.1109/CGI.2004.1309277
   Wiza W., 2004, Components, V1, P29, DOI DOI 10.1145/985040.985045
   Wojciechowski R, 2008, THESIS GDANSK U TECH
   Zhou Xiao-jun, 2004, Journal of Shanghai Jiaotong University, V38, P14
NR 44
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 773
EP 798
DI 10.1007/s11042-012-1125-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300010
OA hybrid
DA 2024-07-18
ER

PT J
AU Sur, A
   Ramanathan, V
   Mukherjee, J
AF Sur, Arijit
   Ramanathan, Vignesh
   Mukherjee, Jayanta
TI Pixel rearrangement based statistical restoration scheme reducing
   embedding noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Pixel swapping; Additive noise
ID STEGANALYSIS; STEGANOGRAPHY; MOMENTS
AB In this paper, a block based steganographic algorithm has been proposed where a sequence of secret bits are embedded into a set of pixels by rearranging the pixel locations. This algorithm has been devised as an improvement over existing statistical restoration based algorithms in order to reduce the additive noise which occurs due to embedding. It is shown that the proposed scheme substantially reduces the additive noise compared to existing statistical restoration based schemes.
C1 [Sur, Arijit] IIT Guwahati, Dept CSE, Gauhati, Assam, India.
   [Ramanathan, Vignesh] IIT Kharagpur, Dept EE, Kharagpur, W Bengal, India.
   [Mukherjee, Jayanta] IIT Kharagpur, Dept CSE, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Sur, A (corresponding author), IIT Guwahati, Dept CSE, Gauhati, Assam, India.
EM arijit@iitg.ernet.in; vigneshram.iitkgp@gmail.com;
   jay@cse.iitkgp.ernet.in
RI Sur, Arijit/AAB-4216-2020; Ramanathan, Vignesh/N-3304-2018
OI Sur, Arijit/0000-0002-9038-8138
CR Chen CH, 2006, IEEE IMAGE PROC, P105, DOI 10.1109/ICIP.2006.312383
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Eggers JJ, 2002, PROC SPIE, V4675, P26, DOI 10.1117/12.465284
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Li XL, 2008, IEEE IMAGE PROC, P2072, DOI 10.1109/ICIP.2008.4712194
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Provos N, 2001, P 10 USENIX SEC S WA, V10
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Shi YQ, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P768, DOI 10.1109/ITCC.2005.138
   Solanki K, 2006, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2006.312388
   Solanki K., 2005, P IEEE INT C IM PROC, P1118
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Sur A, 2008, INT WORKSH DIG WAT I
   Sur A, 2009, LECT NOTES COMPUT SC, V5909, P297
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   XUAN G., 2005, P IEEE INT WORKSH MU, P1
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Zhang J, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P385, DOI 10.1109/MMSP.2007.4412897
NR 25
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 805
EP 825
DI 10.1007/s11042-012-1078-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000014
DA 2024-07-18
ER

PT J
AU Aved, AJ
   Hua, KA
AF Aved, Alexander J.
   Hua, Kien A.
TI An informatics-based approach to object tracking for distributed live
   video computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed computing; Network; Streaming video; Stream processing;
   Query evaluation; Tracking
ID PATTERN-RECOGNITION; ASSIGNMENT; RETRIEVAL; PRIVACY; IMAGES
AB Omnipresent camera networks have been a popular research topic in recent years. They are applicable to a range of monitoring tasks, from bridges to gas stations to the inside of industrial chemical tanks. Though a large body of existing work focuses on image and video processing techniques, very few address the usability of such systems or the implications of real-time video dissemination. In this article, we present our work on extending the LVDBMS prototype with a multifaceted object model to characterize objects in live video streams. This forms the basis for a cross-camera tracking framework which permits objects to be tracked from one video stream to another. With this infrastructure, real-time queries may be posed to monitor complex events that occur in multiple video streams simultaneously. This live video database environment provides a general-purpose platform for distributed live video computing with the goal of enabling rapid application development for camera networks.
C1 [Aved, Alexander J.] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
   [Hua, Kien A.] Univ Cent Florida, Orlando, FL 32816 USA.
   [Hua, Kien A.] Univ Cent Florida, Data Syst Lab, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida; State
   University System of Florida; University of Central Florida; State
   University System of Florida; University of Central Florida
RP Aved, AJ (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM aaved@ucf.edu; kienhua@cs.ucf.edu
OI Aved, Alexander/0000-0002-7015-7359
CR [Anonymous], 15 C MACH LEARN
   [Anonymous], IJCAI 2001 WORKSHOP
   [Anonymous], STOCHASTIC ADAPTIVE
   [Anonymous], 2005, P 22 INT C MACHINE L
   [Anonymous], 2011, CAVIAR: Context Aware Vision using Image-based Active Recognition
   [Anonymous], TRACKING MULTIPLE CA
   [Anonymous], 10S 1000S CCTV CAMER
   [Anonymous], LATENT SEMANTIC INDE
   [Anonymous], INFERENCE NONOVERLAP
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Aved AJ, 2011, COMM COM INF SC, V149, P120
   Catarci T, 2003, IEEE MULTIMEDIA, V10, P66, DOI 10.1109/MMUL.2003.1167924
   Cheng H, 2010, MULTIMED TOOLS APPL, V47, P507, DOI 10.1007/s11042-009-0335-3
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Du W, 2007, LECT NOTES COMPUT SC, V4843, P365
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gartner T., 2002, P 9 INT C MACH LEARN, P179
   Hampapur I, 2005, IEEE SIGNAL PROC MAG, V22, P38
   Hemayed EE, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P351, DOI 10.1109/AVSS.2003.1217942
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jiang HT, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P344, DOI 10.1109/MMCS.1997.609629
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Peng R, 2010, INT J INTERDISCIP TE, V2, P27, DOI 10.4018/jitn.2010010103
   Senior A, 2005, IEEE SECUR PRIV, V3, P50, DOI 10.1109/MSP.2005.65
   Toroslu IH, 2007, INFORM SCIENCES, V177, P1523, DOI 10.1016/j.ins.2006.05.004
   Velipasalar S, 2010, MULTIMED TOOLS APPL, V50, P249, DOI 10.1007/s11042-010-0489-z
   WEI GQ, 1994, IEEE T PATTERN ANAL, V16, P469, DOI 10.1109/34.291450
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 32
TC 1
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 111
EP 133
DI 10.1007/s11042-012-1204-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600008
DA 2024-07-18
ER

PT J
AU Kim, JY
   Chung, KY
   Jung, JJ
AF Kim, Ji-Yeon
   Chung, Kyung-Yong
   Jung, Jong-Jin
TI Single tag sharing scheme for multiple-object RFID applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RFID Tag; Multiple-object; Authentication Protocol; Security Level
AB RFID systems have been widely adopted in various industrial as well as personal applications. However, traditional RFID systems are limited to address only one tag for each application object. This limitation hinders the usability of RFID applications because it is difficult, if not impossible, to distinguish many tags simultaneously with existing RFID systems. In this paper, we propose a new RFID tag structure to support multiple-objects that can be easily shared by many different RFID applications. That is, the proposed RFID tag structure supports that a tag maintains several different objects and allows those applications to access them simultaneously. We also propose an authentication protocol to support multiple-object RFID applications. Especially, we focus on the efficiency of the authentication protocol by considering different security levels in RFID applications. The proposed protocol includes two types of authentication procedures. In the proposed protocol, an object has its security level and goes through one of different authentication procedures suitable for its security level. We report the results of a simulation to test the performance of the proposed scheme. In our simulation, we considered the safety of our scheme against potential attacks and evaluated the efficiency of the proposed protocol.
C1 [Kim, Ji-Yeon; Jung, Jong-Jin] Daejin Univ, Dept Comp Engn, Gyeonggi, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
C3 Daejin University; Sangji University
RP Jung, JJ (corresponding author), Daejin Univ, Dept Comp Engn, Gyeonggi, South Korea.
EM jini_69@naver.com; dragonhci@hanmail.net; jjjung@daejin.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
OI Kim, Ji Yeon/0000-0001-7964-5060
FU Daejin University
FX This work was supported by the Daejin University Research Grants in
   2013.
CR [Anonymous], 2006, TTAR060013 TTA
   Garfinkel S., 2005, RFID APPL SECURITY P
   *IETF RFC, 2005, 4269 IETF RFC
   Juels A., 2003, P 10 ACM C COMPUTER, P103
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Ko H, 2007, AIP CONF PROC, V2, P571, DOI 10.1063/1.2836143
   OHKUBO MIYAKO., 2003, RFID PRIVACY WORKSHO
   Saito J, 2004, P 2004 S CRYPT INF S, V1, P713
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Weis StephenA., 2003, Security and privacy aspects of low-cost radio frequency identification systems, P201
NR 10
TC 11
Z9 11
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 465
EP 477
DI 10.1007/s11042-013-1357-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400018
DA 2024-07-18
ER

PT J
AU Bhatnagar, G
   Wu, QMJ
   Raman, B
AF Bhatnagar, Gaurav
   Wu, Q. M. Jonathan
   Raman, Balasubramanian
TI A new aspect in robust digital watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Stationary wavelet transform; Oversampling;
   Normalized mass matrix; Singular value decomposition
ID WAVELET-BASED WATERMARKING; DOMAIN; SCHEME
AB Generally, in watermarking scheme the size of the watermark is very small when compare to host image. On the contrary, this is an attempt in which a new watermarking scheme is presented where the size of host image is very small when compare with watermark image. The core idea of the proposed scheme is to scale up the size of host image equal to the size of watermark via over-sampling and then decompose it using stationary wavelet transform. A gray scale watermark is embedded in the low frequency sub-band at the finest level using singular value decomposition. To prevent ambiguity and enhance the security, a binary watermark is also embedded in loss-less manner. Finally, a reliable watermark extraction scheme is developed for extracting both the watermarks. The experimental results demonstrate better visual imperceptibility and resiliency of the proposed scheme against intentional or un-intentional variety of attacks.
C1 [Bhatnagar, Gaurav; Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9C 1M2, Canada.
   [Raman, Balasubramanian] Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 University of Windsor; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Bhatnagar, G (corresponding author), Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9C 1M2, Canada.
EM goravdma@gmail.com; jwu@uwindsor.ca; balarfma@iitr.ernet.in
RI Wu, Q.M.Jonathan/O-3234-2017; Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372; Wu, Q.M.
   Jonathan/0000-0002-5208-7975
CR [Anonymous], 2003, INTRO CHAOTIC DYNAMI
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bhatnagar G, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P1, DOI 10.1109/ICVGIP.2008.15
   Bors AG, 1998, OPT EXPRESS, V3, P512, DOI 10.1364/OE.3.000512
   Carroll J. M., 1992, Cryptologia, V16, P52, DOI 10.1080/0161-119291866766
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Ganic E, 2003, P IASTED INT C COMM, P85
   GORODETSKI V, 2001, P INT WORKSH MATH ME
   Han H, 2004, LECT NOTES COMPUT SC, V3333, P441
   Hsu CT, 1998, IEEE T CIRCUITS-II, V45, P1097, DOI 10.1109/82.718818
   Hsu CT, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P223, DOI 10.1109/ICIP.1996.560424
   Hwang MS, 1999, IEEE T CONSUM ELECTR, V45, P286, DOI 10.1109/30.793411
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   LASOTA A, 1997, CHAOS FRACTALS NOISE
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Meerwald P., 2001, P SPIE ELECT IMAGING, P4314
   Nason Guy P, 1995, Wavelets and Statistics, P281, DOI [DOI 10.1007/978-1-4612-2544-7_17, 10.1007/978-1-4612-2544-7_17]
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   Pun C.M., 2006, IEEE INT C SIGNAL PR, P1
   Shirani S, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P35, DOI 10.1109/ITCC.2001.918761
   Solachidis V, 2004, EURASIP J APPL SIG P, V2004, P2522, DOI 10.1155/S1110865704408014
   Strang G., 1993, INTRO LINEAR ALGEBRA, V3
   Sverldov A., 2005, P EUR SIGN PROC C AN
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Xia XG, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P548, DOI 10.1109/ICIP.1997.647971
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Zeng WJ, 1999, P SOC PHOTO-OPT INS, V3657, P404, DOI 10.1117/12.344691
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 36
TC 13
Z9 13
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 179
EP 200
DI 10.1007/s11042-011-0788-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000003
DA 2024-07-18
ER

PT J
AU Plant, W
   Lumsden, J
   Nabney, IT
AF Plant, William
   Lumsden, Joanna
   Nabney, Ian T.
TI The Mosaic Test: measuring the effectiveness of colour-based image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Image databases; Content-based image retrieval;
   Query-by-sketch; Query-by-colour; Performance evaluation
AB A variety of content-based image retrieval systems exist which enable users to perform image retrieval based on colour content-i.e., colour-based image retrieval. For the production of media for use in television and film, colour-based image retrieval is useful for retrieving specifically coloured animations, graphics or videos from large databases (by comparing user queries to the colour content of extracted key frames). It is also useful to graphic artists creating realistic computer-generated imagery (CGI). Unfortunately, current methods for evaluating colour-based image retrieval systems have 2 major drawbacks. Firstly, the relevance of images retrieved during the task cannot be measured reliably. Secondly, existing methods do not account for the creative design activity known as reflection-in-action. Consequently, the development and application of novel and potentially more effective colour-based image retrieval approaches, better supporting the large number of users creating media for use in television and film productions, is not possible as their efficacy cannot be reliably measured and compared to existing technologies. As a solution to the problem, this paper introduces the Mosaic Test. The Mosaic Test is a user-based evaluation approach in which participants complete an image mosaic of a predetermined target image, using the colour-based image retrieval system that is being evaluated. In this paper, we introduce the Mosaic Test and report on a user evaluation. The findings of the study reveal that the Mosaic Test overcomes the 2 major drawbacks associated with existing evaluation methods and does not require expert participants.
C1 [Plant, William; Lumsden, Joanna; Nabney, Ian T.] Aston Univ, Sch Engn & Appl Sci, Birmingham B4 7ET, W Midlands, England.
C3 Aston University
RP Plant, W (corresponding author), Aston Univ, Sch Engn & Appl Sci, Birmingham B4 7ET, W Midlands, England.
EM plantwr1@aston.ac.uk; j.lumsden@aston.ac.uk; i.t.nabney@aston.ac.uk
OI Nabney, Ian T/0000-0003-1513-993X; Nabney, Ian/0000-0001-7382-2855;
   Lumsden, Joanna M/0000-0002-8637-7647
FU Aston University School of Engineering and Applied Science's EPSRC
FX We would like to sincerely thank everyone that participated in the user
   study described in this work, all of which gave up their spare time for
   no financial award. This work has been funded by the Aston University
   School of Engineering and Applied Science's EPSRC doctoral training
   grant.
CR Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   MacDonald LW, 1999, IEEE COMPUT GRAPH, V19, P20, DOI 10.1109/38.773961
   Microsoft, 2011, BING IM
   Nakade S, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P339, DOI 10.1109/ICCIMA.2007.144
   Ortega M, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P403, DOI 10.1145/266180.266394
   Plant William, 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P248
   Rodden K., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P190, DOI 10.1145/365024.365097
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schon D., 1984, The Reflective Practitioner: How Professionals Think in Action
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Silvers R, 1996, THESIS MIT
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Terry M., 2002, P 4 C CREATIVITY COG, P38
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Zhang Y, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P317
NR 20
TC 8
Z9 9
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 695
EP 716
DI 10.1007/s11042-011-0951-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU De Virgilio, R
   Frasincar, F
   Hop, W
   Lachner, S
AF De Virgilio, Roberto
   Frasincar, Flavius
   Hop, Walter
   Lachner, Stephan
TI A reverse engineering approach for automatic annotation of Web pages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDFa; Rich Snippets; DRE; Web site segmentation
ID SENTIMENT CLASSIFICATION; REVIEWS
AB The Semantic Web is gaining increasing interest to fulfill the need of sharing, retrieving, and reusing information. Since Web pages are designed to be read by people, not machines, searching and reusing information on the Web is a difficult task without human participation. To this aim adding semantics (i.e meaning) to a Web page would help the machines to understand Web contents and better support the Web search process. One of the latest developments in this field is Google's Rich Snippets, a service for Web site owners to add semantics to their Web pages. In this paper we provide a structured approach to automatically annotate a Web page with Rich Snippets RDFa tags. Exploiting a data reverse engineering method, combined with several heuristics, and a named entity recognition technique, our method is capable of recognizing and annotating a subset of Rich Snippets' vocabulary, i.e., all the attributes of its Review concept, and the names of the Person and Organization concepts. We implemented tools and services and evaluated the accuracy of the approach on real E-commerce Web sites.
C1 [De Virgilio, Roberto] Univ Roma Tre, Dipartimento Informat & Automaz, Rome, Italy.
   [Frasincar, Flavius; Hop, Walter; Lachner, Stephan] Erasmus Univ, Erasmus Sch Econ, NL-3000 DR Rotterdam, Netherlands.
C3 Roma Tre University; Erasmus University Rotterdam - Excl Erasmus MC;
   Erasmus University Rotterdam
RP De Virgilio, R (corresponding author), Univ Roma Tre, Dipartimento Informat & Automaz, Rome, Italy.
EM rde79@yahoo.com; frasincar@ese.eur.nl; w.w.hop@student.eur.nl;
   s.lachner@student.eur.nl
RI Frasincar, Flavius/AAC-8253-2021; Frasincar, Flavius/D-3171-2011
OI Frasincar, Flavius/0000-0002-8031-758X; 
CR Adida B., 2008, RDFa Primer - Bridging the Human and Data Webs
   Allison L., 1990, AI MATHS
   [Anonymous], INTRO RICH SNIPPETS
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bizer C, 2006, P 5 INT SEM WEB C IS
   De Virgilio R, 2009, LECT NOTES COMPUT SC, V5648, P91, DOI 10.1007/978-3-642-02818-2_7
   Electrum, 2009, VAL HTML STAT
   Google, 2009, GOOGL WEBM TOOLS REV
   Kennedy A, 2006, COMPUT INTELL-US, V22, P110, DOI 10.1111/j.1467-8640.2006.00277.x
   Krupka GR, 1998, 7 MESS UND C
   Laender AHF, 2002, SIGMOD REC, V31, P84
   Li C, 2005, INTERNATIONAL WORKSHOP ON CHALLENGES IN WEB INFORMATION RETRIEVAL AND INTEGRATION, PROCEEDINGS, P40
   Mikheev A, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS, P1
   Morgan R, 1995, 6 MESS UND C
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Ratinov L., 2009, Proceedings of the 13th conference on computational natural language learning, P147
   Seomoz.org, 2009, SEARCH ENG RANK FACT
   Tomberg V., 2009, 2 INT WORKSH MASH PE, P102
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Virgilio RD, 2008, ER WORKSH WISM 2008
   Yahoo!, 2009, SEARCHMONKEY SIT OWN
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
NR 22
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 119
EP 140
DI 10.1007/s11042-011-0852-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600007
DA 2024-07-18
ER

PT J
AU Doumat, R
   Egyed-Zsigmond, E
   Pinon, JM
AF Doumat, Reim
   Egyed-Zsigmond, Eloed
   Pinon, Jean-Marie
TI A web 2.0 archive to access, annotate and retrieve manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web 2.0 archive; Manuscript annotation; Collaboration; User traces;
   Recommender system
ID SYSTEM
AB The Web development encouraged different organizations and individuals to expose their multimedia documents on the internet. Additionally, the migration to web 2.0 offered users the chance to comment and annotate the contents of these multimedia documents. Museums and libraries are particularly interested in users' feedback and work, because many collections, such as handwritten manuscripts, are still puzzles for archivists. Therefore any feedback concerning these contents will be welcomed. This article focuses on the design and the implementation of a web archive. The main objective is enabling users to annotate easily and remotely manuscript documents using web 2.0 application. User annotations are considered important to enrich the archive contents with essential information nevertheless not all users are experts in the manuscript domain. Accordingly, users need a kind of assistance during the search and annotation processes. The proposed assistant in our archive is a recommender system; it relies on registered traces of the user interaction with the documents to generate suggestions.
C1 [Doumat, Reim; Egyed-Zsigmond, Eloed; Pinon, Jean-Marie] Univ Lyon, INSA Lyon, LIRIS UMR 5205, F-69100 Villeurbanne, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon
RP Doumat, R (corresponding author), Univ Lyon, INSA Lyon, LIRIS UMR 5205, 7Ave Jean Capelle, F-69100 Villeurbanne, France.
EM reim.doumat@insa-lyon.fr; elod.egyed-zsigmond@insa-lyon.fr;
   jean-marie.pinon@insa-lyon.fr
CR AAMODT A, 1994, AI COMMUN, V7, P39
   Albert J, 2003, LECT NOTES COMPUT SC, V2598, P1
   Benel A, 2003, 1 EUR C COMP PHIL
   Bottoni P., 2004, P WORK C ADV VIS INT, DOI DOI 10.1145/989863.989870
   Doumat R, 2007, C INT DOC EL, P151
   Doumat R, 2010, LECT NOTES ARTIF INT, V6176, P360
   Doumat R, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P127
   Frommholz I, 2003, LECT NOTES COMPUT SC, V2769, P434
   Heymann P., 2010, Proceedings of the International Conference on Web Search and Data Mining, WSDM '10, P51, DOI DOI 10.1145/1718487.1718495
   Kahan J., 2001, P INT WORLD WIDE WEB, P623, DOI DOI 10.1145/371920.372166
   Mille A, 1998, ASSOCIER EXPERTISE E
NR 11
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 97
EP 117
DI 10.1007/s11042-011-0851-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600006
DA 2024-07-18
ER

PT J
AU Lee, S
   Park, J
AF Lee, Sangjin
   Park, Jonghun
TI Topic based photo set retrieval using user annotated tags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Set search; Photo set retrieval; Structured data retrieval; Ranking;
   Collaborative tagging; Collection selection; Multimedia retrieval;
   Information retrieval
ID VISUAL CONTENT; SELECTION
AB As a storage and retrieval unit of user generated web objects, set has been receiving increased attention recently in information retrieval research community. Set search requires relevant sets to be retrieved to meet information needs of users. It is different from individual object search in terms of content granularity. While a web object itself is not divisible and independent with each other, a set consists of separable objects that are related in some aspects. This paper proposes a new approach that can effectively measure topical relevance of sets against a user query by utilizing the tags attached to web objects. The main idea of the proposed approach is to prefer the set which covers as many query related subtopics as possible. In particular, in order to compute the topical relevance while addressing the problem of noisy tags, the notion of tag significance score is introduced based on tag co-occurrence frequency. We consider a problem domain of photo set search at flickr.com where individual photos are annotated with texts such as titles and tags. Experimental results show that our proposed method outperforms the previous approaches for photo set retrieval.
C1 [Lee, Sangjin; Park, Jonghun] Seoul Natl Univ, Dept Ind Engn, Seoul 151744, South Korea.
C3 Seoul National University (SNU)
RP Park, J (corresponding author), Seoul Natl Univ, Dept Ind Engn, 599 Gwanak Ro, Seoul 151744, South Korea.
EM jonghun@snu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2010-0012967]; Engineering Research Institute at Seoul National
   University
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No. 2010-0012967) and partly by
   Engineering Research Institute at Seoul National University.
CR [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2009, PROC INT C WORLD WID
   [Anonymous], 2007, P 16 INT C WORLD WID
   Bao S., 2007, P 16 INT C WORLD WID, P501, DOI DOI 10.1145/1242572.1242640
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Dai W., 2005, CIKM, P752
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Han SK, 2009, WORLD WIDE WEB, V12, P381, DOI 10.1007/s11280-009-0067-3
   Hua G, 2009, IEEE INT CON MULTI, P1480, DOI 10.1109/ICME.2009.5202783
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   Koutrika G, 2008, ACM T WEB, V2, DOI 10.1145/1409220.1409225
   Lavrenko V., 2001, SIGIR Forum, P120
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li XR, 2009, INT CONF ACOUST SPEE, P3717, DOI 10.1109/ICASSP.2009.4960434
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Manish G, 2009, SIGKDD EXPLOR, V12, P58
   Melucci M., 2007, SIGIR Forum, V41, P18, DOI 10.1145/1273221.1273223
   Ogilvie P., 2001, TREC, V1
   Powell AL, 2003, ACM T INFORM SYST, V21, P412, DOI 10.1145/944012.944016
   Sangjin Lee, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P1577, DOI 10.1109/NCM.2009.102
   Sawant N, 2011, MULTIMED TOOLS APPL, V51, P213, DOI 10.1007/s11042-010-0650-8
   Seo J., 2008, Proceedings of the 17th ACM conference on Information and knowledge management, P1053
   Sevil SG, 2010, MULTIMED TOOLS APPL, V49, P81, DOI 10.1007/s11042-009-0394-5
   Swaminathan A, 2008, MSRTR2008015
   Zwol R, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P184, DOI 10.1109/WI.2007.22
   van Zwol Roelof., 2008, P 1 ACM INT C MULTIM, P67
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Yoon J, 2009, INFORM PROCESS MANAG, V45, P452, DOI 10.1016/j.ipm.2009.03.004
   ZHAI C.X., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in informaion Retrieval (Toronto, Canada, July 28 - August 01, 2003), P10, DOI [10.1145/860435.860440, DOI 10.1145/860435.860440]
   Zhuang Jinfeng., 2011, WSDM, P625
NR 34
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 7
EP 26
DI 10.1007/s11042-011-0850-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600002
DA 2024-07-18
ER

PT J
AU Song, K
   Hwang, S
   Kim, Y
   Kwak, Y
AF Song, Kieun
   Hwang, Sunjin
   Kim, Yunsik
   Kwak, Youngsik
TI The effects of social network properties on the acceleration of fashion
   information on the web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE e-WOM; Fashion information; On-line fashion community; Social network
ID TECHNOLOGY; CENTRALITY; POWER
AB This study aims to investigate the acceptance of word-of-mouth information that is currently being disseminated between consumers in the internet fashion community. In particular, we suggest the network features formed in the internet fashion information community as variables influencing the acceptance of word-of-mouth information and analyze the actual effects in an empirical way. To do so, first of all, we conducted a social network analysis and investigated the features of the network spread patterns involving fashion information shared between community members. Thereafter, we set up the network variables as factor influencing the acceptance of fashion information in the internet and, including these variables, conducted a significance test on the impact of the informational properties and individual characteristic variables. As a result, in terms of the characteristics of the fashion community network, fashion information is produced intensively by a few information activists focusing on fashion information within the community and influences many information acceptors. In addition, as a result of hypothesis testing on the factors influencing the acceptance of the fashion information, we found that the informational properties, individual characteristic variables, as well as network characteristic variables, have a significant influence on the verbal acceptance, which confirms the importance of the network characteristic variables in the study of word of mouth marketing on the internet.
C1 [Song, Kieun; Hwang, Sunjin; Kim, Yunsik] Sungkyunkwan Univ, Seoul, South Korea.
   [Kwak, Youngsik] Gyengnam Natl Univ Sci & Technol, Seoul, South Korea.
   [Hwang, Sunjin] Sungkyunkwan Univ, Dept Fash Design, Seoul, South Korea.
   [Kim, Yunsik] Sungkyunkwan Univ, Management Res Inst, Seoul, South Korea.
C3 Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU);
   Sungkyunkwan University (SKKU)
RP Kim, Y (corresponding author), Sungkyunkwan Univ, Seoul, South Korea.
EM yunskim@skku.edu
RI Deng, Nianqi/U-2502-2019
CR Ahn K. H., 2010, Fashion marketing
   [Anonymous], 2002, LINKED EVERYTHING IS
   [Anonymous], 2002, IT Society
   Bamasak Omaima, 2011, International Journal of Information Technology, Communications and Convergence, V1, P173, DOI 10.1504/IJITCC.2011.039284
   Bampo M, 2008, INFORM SYST RES, V19, P273, DOI 10.1287/isre.1070.0152
   Bickart B., 2001, Journal of Interactive Marketing, V15, P31, DOI [10.1002/dir.1014, DOI 10.1002/DIR.1014]
   BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631
   BURKHARDT ME, 1990, ADMIN SCI QUART, V35, P104, DOI 10.2307/2393552
   BURT RS, 1992, NETWORKS AND ORGANIZATIONS : STRUCTURE, FORM, AND ACTION, P57
   Buter B., 2011, J CONVERG, V2, P87
   Cacioppo J., 1982, J PERS SOC PSYCHOL, V42, P116, DOI [DOI 10.1037/0022-3514.42.1.116, 10.1037/0022-3514.42.1.116]
   Chevalier JA, 2003, 10148 NBER, P1
   Cohen AR, 2003, J ABNORM SOC PSYCHOL, V51, P291
   Cohen J., 2013, APPL MULTIPLE REGRES
   Constant D, 1996, ORG SCI
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DESHPANDE R, 1982, J MARKETING RES, V19, P14, DOI 10.2307/3151527
   Elliott KM, 2002, THESIS DUKE U
   Garton L., 1997, J. Comput.-Mediat. Commun, V3, DOI DOI 10.1111/J.1083-6101.1997.TB00062.X
   Geissler GL, 2005, J MARK COMMUN, V11, P73, DOI 10.1080/1352726042000286499
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   HANNEMAN R. A., 2005, Introduction to social network methods
   Haugtvedt C., 1992, Journal of Consumer Psychology, V1, P239
   HERR PM, 1991, J CONSUM RES, V17, P454, DOI 10.1086/208570
   IBARRA H, 1993, ACAD MANAGE J, V36, P471, DOI 10.5465/256589
   Kaiser S.B., 1997, SOCIAL PSYCHOL CLOTH, V2nd
   Keller PA, 1997, J CONSUM RES, V24, P295, DOI 10.1086/209511
   Kim Han, 2008, PHYSICS A, V387
   Kim H, 2008, J FASH MARK MANAG, V12, P545, DOI 10.1108/13612020810906182
   Kim Y.-H., 2007, SOCIAL NETWORK ANAL
   Korea Communications Commission and Kisa, 2010, SURV INT US
   Lee DH, 2001, KOREAN ACAD SOC BUSI, V16, P115
   Lee EY, 2004, 2 FACTOR MODEL LINE
   Lee HJ, 2011, J INF PROCESS SYST, V7, P385
   Lee HS, 2009, MARKETING RES
   Lee HS, 2008, CONSUMER BEHAV
   Lee HY, 2007, WEB2 0 SOCIAL DIFFUS
   MOENAERT RK, 1990, J PROD INNOVAT MANAG, V7, P213, DOI 10.1016/0737-6782(90)90005-Y
   No GY, 2008, NEW MEDIA COMMUNICAT
   Okleshen C, 1998, ADV CONSUM RES, V25, P276
   Park JS, 1996, STUDY USES COMPUTER
   Renault É, 2010, J INF PROCESS SYST, V6, P359, DOI 10.3745/JIPS.2010.6.3.359
   Roehrich G, 2004, J BUS RES, V57, P671, DOI 10.1016/S0148-2963(02)00311-9
   Rogers EM, 2003, DIFFUSION INNOVATION
   Schiffman L.G., 1997, CONSUMER BEHAV, V6th
   SCHRANK HL, 1973, SOCIOL QUART, V14, P534, DOI 10.1111/j.1533-8525.1973.tb01389.x
   SCOTT J, 1988, SOCIOLOGY, V22, P109, DOI 10.1177/0038038588022001007
   Sen S, 2007, J INTERACT MARK, V21, P76, DOI 10.1002/dir.20090
   Shiuh-Jeng Wang, 2010, International Journal of Information Technology, Communications and Convergence, V1, P66, DOI 10.1504/IJITCC.2010.035227
   Song YT, 2007, EFFECTS PREANNOUNCEM
   Sunro Lee, 2008, [korean management review, 경영학연구], V37, P957
   Tong L, 2011, JOC, V2, P61
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Watts DJ, 1999, AM J SOCIOL, V105, P493, DOI 10.1086/210318
   Wellman Barry., 1992, Advances in Group Processes, V9, P207
   WILTON PC, 1986, J CONSUM RES, V12, P469, DOI 10.1086/208531
   박찬웅, 2007, [Korean Journal of Sociology, 한국사회학], V41, P280
   김문태, 2007, [Journal of Industrial Economics and Business, 산업경제연구], V20, P1253
   이태민, 2004, [Korean Journal of Marketing, 마케팅연구], V19, P61
NR 59
TC 5
Z9 8
U1 6
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 455
EP 474
DI 10.1007/s11042-012-1068-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200014
DA 2024-07-18
ER

PT J
AU Li, RL
   You, JX
   Sun, B
   Li, C
AF Li, Ruilin
   You, Jianxiong
   Sun, Bing
   Li, Chao
TI Fault analysis study of the block cipher FOX64
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Side-channel attacks; Fault attacks; Block ciphers;
   Lai-Massey scheme; FOX
ID AES KEY SCHEDULE; ATTACK
AB FOX is a family of symmetric block ciphers from MediaCrypt AG that helps to secure digital media, communications, and storage. The high-level structure of FOX is the so-called (extended) Lai-Massey scheme. This paper presents a detailed fault analysis of the block cipher FOX64, the 64-bit version of FOX, based on a differential property of two-round Lai-Massey scheme in a fault model. Previous fault attack on FOX64 shows that each round-key (resp. whole round-keys) could be recovered through 11.45 (resp. 183.20) faults on average. Our proposed fault attack, however, can deduce any round-key (except the first one) through 4.25 faults on average (4 in the best case), and retrieve the whole round-keys through 43.31 faults on average (38 in the best case). This implies that the number of needed faults in the fault attack on FOX64 can be significantly reduced. Furthermore, the technique introduced in this paper can be extended to other series of the block cipher family FOX.
C1 [Li, Ruilin; You, Jianxiong; Sun, Bing; Li, Chao] Natl Univ Def Technol, Dept Math & Syst Sci, Coll Sci, Changsha 410073, Hunan, Peoples R China.
   [Sun, Bing] Chinese Acad Sci, State Key Lab Informat Secur, Inst Software, Beijing 100190, Peoples R China.
   [Li, Chao] Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China; Chinese Academy of
   Sciences; Institute of Software, CAS; National University of Defense
   Technology - China
RP Li, RL (corresponding author), Natl Univ Def Technol, Dept Math & Syst Sci, Coll Sci, Changsha 410073, Hunan, Peoples R China.
EM securitylrl@gmail.com
RI Li, Chao/GSM-8117-2022
OI Li, Chao/0000-0001-6110-6210
FU National Natural Science Foundation of China [61103192, 61070215];
   Program for Changjiang Scholars and Innovative Research Team in
   University of Ministry of Education of China [IRT1012]; Natural Science
   Foundation of Hunan Province, China [11FH002]; State Key Laboratory of
   Information Security [01-02-5]
FX The work in this paper is supported by the National Natural Science
   Foundation of China (No: 61103192, 61070215), the Program for Changjiang
   Scholars and Innovative Research Team in University of Ministry of
   Education of China (No: IRT1012), the Fund for Creative Research Groups
   of the Natural Science Foundation of Hunan Province, China (No:
   11FH002), and the open research fund of State Key Laboratory of
   Information Security (No: 01-02-5).
CR Ali S., 2010, 2010636 CRYPT EPRINT
   Anderson R, 1996, PROCEEDINGS OF THE SECOND USENIX WORKSHOP ON ELECTRONIC COMMERCE, P1
   Anderson R., 1998, Security Protocols. 5th International Workshop Proceedings, P125, DOI 10.1007/BFb0028165
   Armknecht F, 2006, LECT NOTES COMPUT SC, V3897, P36
   Bar-El H, 2006, P IEEE, V94, P370, DOI 10.1109/JPROC.2005.862424
   Bertoni G, 2003, IEEE T COMPUT, V52, P492, DOI 10.1109/TC.2003.1190590
   Berzati A, 2009, LECT NOTES COMPUT SC, V5922, P72, DOI 10.1007/978-3-642-10628-6_5
   Biham E, 2005, LECT NOTES COMPUT SC, V3557, P359
   Biham E, 1997, LECT NOTES COMPUT SC, V1294, P513
   Blömer J, 2003, LECT NOTES COMPUT SC, V2742, P162
   Boneh D., 1997, Advances in Cryptology - EUROCRYPT '97. International Conference on the Theory and Application of Cryptographic Techniques Proceedings, P37
   Boscher A, 2008, FDTC 2008: FAULT DIAGNOSIS AND TOLERANCE IN CRYPTOGRAPHY, PROCEEDINGS, P35, DOI 10.1109/FDTC.2008.12
   Breveglieri L, 2006, LECT NOTES COMPUT SC, V4236, P98
   Chen CN, 2003, LECT NOTES COMPUT SC, V2727, P118
   Clavier C, 2008, LECT NOTES COMPUT SC, V4964, P274, DOI 10.1007/978-3-540-79263-5_17
   Dusart P, 2003, LECT NOTES COMPUT SC, V2846, P293
   Giraud C, 2004, INT FED INFO PROC, V153, P159
   Giraud C, 2005, LECT NOTES COMPUT SC, V3373, P27
   Hoch JJ, 2004, LECT NOTES COMPUT SC, V3156, P240
   Hojsík M, 2008, LECT NOTES COMPUT SC, V5086, P158
   Hojsík M, 2008, LECT NOTES COMPUT SC, V5365, P239, DOI 10.1007/978-3-540-89754-5_19
   Junod P, 2005, LECT NOTES COMPUT SC, V3357, P114
   Karpovsky M, 2004, 2004 INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS, PROCEEDINGS, P93
   Kim CH, 2008, LECT NOTES COMPUT SC, V5189, P48
   Kircanski A, 2010, LECT NOTES COMPUT SC, V6055, P261
   Kircanski A, 2009, LECT NOTES COMPUT SC, V5867, P197, DOI 10.1007/978-3-642-05445-7_13
   Li Y, 2010, LECT NOTES COMPUT SC, V6225, P320, DOI 10.1007/978-3-642-15031-9_22
   Luo YY, 2010, INFORM PROCESS LETT, V111, P90, DOI 10.1016/j.ipl.2010.10.012
   Maistri P, 2008, IEEE T COMPUT, V57, P1528, DOI 10.1109/TC.2008.149
   Moradi A, 2006, LECT NOTES COMPUT SC, V4249, P91
   Mukhopadhyay D, 2009, LECT NOTES COMPUT SC, V5580, P421, DOI 10.1007/978-3-642-02384-2_26
   Piret G, 2003, LECT NOTES COMPUT SC, V2779, P77, DOI 10.1007/978-3-540-45238-6_7
   Rajendran Jeyavijayan, 2010, 2010 IEEE International Symposium on Hardware-Oriented Security and Trust (HOST 2010), P70, DOI 10.1109/HST.2010.5513109
   Satoh A, 2008, LECT NOTES COMPUT SC, V5154, P100, DOI 10.1007/978-3-540-85053-3_7
   Skorobogatov SP, 2002, LECT NOTES COMPUT SC, V2523, P2
   Takahashi J, 2007, Workshop on Fault Diagnosis and Tolerance in Cryptography, Proceedings, P62, DOI 10.1109/FDTC.2007.13
   Vaudenay S, 1999, LECT NOTES COMPUT SC, V1716, P8
NR 37
TC 8
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 691
EP 708
DI 10.1007/s11042-011-0895-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000005
DA 2024-07-18
ER

PT J
AU Überall, C
   Köhnen, C
   Rakocevic, V
   Jäger, R
   Hoy, E
   Rajarajan, M
AF Ueberall, Christian
   Koehnen, Christopher
   Rakocevic, Veselin
   Jaeger, Rudolf
   Hoy, Erich
   Rajarajan, Muttukrishnan
TI Recommendations in a heterogeneous service environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized television; Recommendations; Content-based; Collaborative
   filtering; Similarity; Media convergence; Personal Program Guide; DVB;
   YouTube
ID ALGORITHMS
AB This paper presents novel algorithms which are able to generate recommendations within a heterogeneous service environment. In this work explicitly set preferences as well as implicitly logged viewing behavior are employed to generate recommendations for Digital Video Broadcast (DVB) content. This paper also discusses the similarity between the DVB genres and YouTube categories. In addition it presents results to show the comparison between well known collaborative filtering methods. The outcome of this comparison study is used to identify the most suitable filtering method to use in the proposed environment. Finally the paper presents a novel Personal Program Guide (PPG), which is used as a tool to visualize the generated recommendations within a heterogeneous service environment. This PPG is also capable of showing the linear DVB content and the non-linear YouTube videos in a single view.
C1 [Ueberall, Christian; Koehnen, Christopher; Rakocevic, Veselin; Rajarajan, Muttukrishnan] City Univ London, London EC1V 0HB, England.
   [Ueberall, Christian; Koehnen, Christopher; Jaeger, Rudolf; Hoy, Erich] Univ Appl Sci, Tech Hsch Mittelhessen, D-61169 Friedberg, Germany.
C3 City University London
RP Überall, C (corresponding author), Univ Appl Sci, Tech Hsch Mittelhessen, Wilhelm Leuschner Str 13, D-61169 Friedberg, Germany.
EM christian.ueberall@iem.thm.de; christopher.koehnen@iem.thm.de;
   V.Rakocevic@city.ac.uk; rudolf.jaeger@iem.thm.de; erich.hoy@mnd.thm.de;
   R.Muttukrishnan@city.ac.uk
RI Rakocevic, Veselin/AAF-5601-2019
CR Ardissono L, 2003, P 8 AI IA C
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Blanco Y, 2005, P 3 EUR C INT TV
   Blanco-Fernandez Y, 2008, HYBRID STRATEGY PERS
   Campell I, 1996, P COLIS
   DAI WZ, 2003, P UM 2003 WORKSH PER
   De Pessemier Toon, 2008, 8 FIRW PHD S
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Elsweiler D, 2010, WORKSH 33 ANN INT AC
   European Standard, 2000, TEL SER DIG VID BROA
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herlocker JL, 1998, 3 ACM C DIG LIB PITT
   Hopfgartner F, 2008, 2 INT WORKSH PERS AC
   Hopfgartner F, 2010, MULTIMEDIA SYST, V16, P255, DOI 10.1007/s00530-010-0189-6
   Hsu SH, 2007, LECT NOTES COMPUT SC, V4471, P166
   Konstan Joseph A, 2001, 10 INT C WORLD WID W, DOI DOI 10.1145/371920.372071
   Papagelis M, 2005, ENG APPL ARTIF INTEL, V18, P781, DOI 10.1016/j.engappai.2005.06.010
   Papula L., 2003, Mathematische Formelsammlung fur Ingenieure und Naturwissenschaftler, V8th ed.
   Su JH, 2010, INFORM SCIENCES, V180, P113, DOI 10.1016/j.ins.2009.08.005
   Su X., 2009, SURVEY COLLABORATIVE
   Uberall C, 2009, P ICME IEEE
   ZHANG HG, 2005, P 9 INT S IEEE
NR 22
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 785
EP 820
DI 10.1007/s11042-011-0874-2
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU El Sayad, I
   Martinet, J
   Urruty, T
   Djeraba, C
AF El Sayad, Ismail
   Martinet, Jean
   Urruty, Thierry
   Djeraba, Chabane
TI Toward a higher-level visual representation for content-based image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SURF; Content-based image retrieval; Visual words; Visual phrases;
   Gaussian mixture model; Spatial weighting; pLSA
ID FEATURES; WORDS
AB Having effective methods to access the desired images is essential nowadays with the availability of a huge amount of digital images. The proposed approach is based on an analogy between content-based image retrieval and text retrieval. The aim of the approach is to build a meaningful mid-level representation of images to be used later on for matching between a query image and other images in the desired database. The approach is based firstly on constructing different visual words using local patch extraction and fusion of descriptors. Secondly, we introduce a new method using multilayer pLSA to eliminate the noisiest words generated by the vocabulary building process. Thirdly, a new spatial weighting scheme is introduced that consists of weighting visual words according to the probability of each visual word to belong to each of the n Gaussian. Finally, we construct visual phrases from groups of visual words that are involved in strong association rules. Experimental results show that our approach outperforms the results of traditional image retrieval techniques.
C1 [El Sayad, Ismail; Martinet, Jean; Urruty, Thierry; Djeraba, Chabane] Univ Lille 1, LIFL CNRS UMR 8022, Lille, France.
C3 Universite de Lille
RP El Sayad, I (corresponding author), Univ Lille 1, LIFL CNRS UMR 8022, Lille, France.
EM ismail.elsayad@lifl.fr; jean.martinet@lifl.fr; thierry.urruty@lifl.fr;
   chabane.djeraba@lifl.fr
RI El Sayad, Ismail/HDM-5409-2022; Djeraba, Chaabane/ABI-8490-2020
OI Djeraba, Chaabane/0000-0003-4579-9592; Urruty,
   Thierry/0000-0003-1339-1920
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   [Anonymous], 2007, MIR
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], ICPR WORKSH LEARN AD
   Baeza-Yates R., 1999, Modern information retrieval
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bilmes J, 1997, TR97021ICSI
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Haddad M, 2000, 4 EUR C PRINC PRACT
   Hammouda KM, 2004, IEEE T KNOWL DATA EN, V16, P1279, DOI 10.1109/TKDE.2004.58
   Hoàng NV, 2010, PATTERN RECOGN, V43, P3013, DOI 10.1016/j.patcog.2010.03.024
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jeon J, 2004, LECT NOTES COMPUT SC, V3115, P24
   Jing F, 2003, LECT NOTES COMPUT SC, V2728, P206
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lienhart R., 2009, Proceeding of the ACM International Conference on Image and Video Retrieval, P1, DOI DOI 10.1145/1646396.1646408
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinet J, 2007, INT WORK CONTENT MUL, P344, DOI 10.1109/CBMI.2007.385432
   Morand C, 2010, SIGNAL PROCESS-IMAGE, V25, P450, DOI 10.1016/j.image.2010.04.004
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Witten I.H., 1999, Managing Gigabytes: Compressing and Indexing Documents and Images
   Yang Y., 1997, ICML, V97, P412
   Yuan J, 2007, PROC CVPR IEEE, P1930, DOI 10.1109/CVPR.2007.383222
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zheng QF, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404887
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
NR 39
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 455
EP 482
DI 10.1007/s11042-010-0596-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400012
DA 2024-07-18
ER

PT J
AU Mekouar, L
   Iraqi, Y
   Boutaba, R
AF Mekouar, Loubna
   Iraqi, Youssef
   Boutaba, Raouf
TI An analysis of peer similarity for recommendations in P2P systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Similarity metrics; Personalized recommendations;
   Content adaptation; Multimedia files; Peer-to-Peer systems
AB In this paper, we propose a novel recommender framework for partially decentralized file sharing Peer-to-Peer systems. The proposed recommender system is based on user-based collaborative filtering. We take advantage from the partial search process used in partially decentralized systems to explore the relationships between peers. The proposed recommender system does not require any additional effort from the users since implicit rating is used. The recommender system also does not suffer from the problems that traditional collaborative filtering schemes suffer from like the Cold start and the Data sparseness. To measure the similarity between peers, we propose Files' Popularity Based Recommendation (FP) and Asymmetric Peers' Similarity Based Recommendation with File Popularity (ASFP). We also investigate similarity metrics that were proposed in other fields and adapt them to file sharing P2P systems. We analyze the impact of each similarity metric on the accuracy of the recommendations. Both weighted and non weighted approaches were studied.
C1 [Mekouar, Loubna; Boutaba, Raouf] Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Boutaba, Raouf] POSTECH, Div IT Convergence Engn, Pohang 790784, South Korea.
   [Iraqi, Youssef] Khalifa Univ, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Waterloo; Pohang University of Science & Technology
   (POSTECH); Khalifa University of Science & Technology
RP Mekouar, L (corresponding author), Univ Waterloo, David R Cheriton Sch Comp Sci, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM lmekouar@bbcr.uwaterloo.ca; Youssef.Iraqi@kustar.ac.ae;
   rboutaba@bbcr.uwaterloo.ca
RI Iraqi, Youssef/A-4009-2015; Iraqi, Youssef/I-9066-2019; Boutaba,
   Raouf/AAT-2801-2020; Boutaba, Raouf/G-8483-2017
OI Iraqi, Youssef/0000-0003-0112-2600; Boutaba, Raouf/0000-0001-7936-6862;
   Mekouar, Loubna/0000-0002-2432-9105
FU Natural Science and Engineering Council of Canada (NSERC); WCU (World
   Class University) through the Korea Science and Engineering Foundation;
   Ministry of Education, Science and Technology [R31-2008-000-10100-0]
FX This work was supported in part by the Natural Science and Engineering
   Council of Canada (NSERC) under its Discovery program, and the WCU
   (World Class University) program through the Korea Science and
   Engineering Foundation funded by the Ministry of Education, Science and
   Technology (Project No. R31-2008-000-10100-0).
CR ADAR E, 2000, FREE RIDING GNUTELLA
   Anderberg M.R., 1973, Probability and Mathematical Statistics
   [Anonymous], 2003, PEERSIM
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Duarte JM, 1999, GENET MOL BIOL, V22, P427, DOI 10.1590/S1415-47571999000300024
   Gummadi KrishnaP., 2003, Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles, SOSP '03, P314
   Jaccard P., 1901, B SOCIT VAUDOISE SCI, V37, P547, DOI [10.5169/seals-266440, DOI 10.5169/SEALS-266440]
   Jamali M., 2009, P 3 ACM C REC SYST, P181
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Kulczynski S., 1927, ACAD POLONAISE SCI L, P57
   Lesot M.-J, 2009, International Journal of Knowledge Engineering and Soft Data Paradigms, V1, P63, DOI 10.1504/IJKESDP.2009.021985
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Lourenco F, 2004, JOCLAD
   Massa P, 2004, INT C COOP INF SYST
   Mekouar L, 2009, PEER PEER NETW APPL, V2, P146, DOI 10.1007/s12083-008-0026-2
   Ochiai A, 1957, JAPANESE SOC FISH SC, V22, P526
   ROGERS DJ, 1960, SCIENCE, V132, P1115, DOI 10.1126/science.132.3434.1115
   Ruffo G, 2006, LECT NOTES COMPUT SC, V3976, P618
   Russel P, 1940, HABITAT ASS SPECIES, V3, P153
   Sarwar B., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P158, DOI 10.1145/352871.352887
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Sokal R.R., 1963, PRINCIPLES NUMERIC T
   SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409
   Wang J., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1026, DOI 10.1145/1141277.1141522
   Wang J, 2008, MULTIMED TOOLS APPL, V36, P89, DOI 10.1007/s11042-006-0075-6
NR 26
TC 11
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 277
EP 303
DI 10.1007/s11042-010-0612-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400003
DA 2024-07-18
ER

PT J
AU Chen, DY
   Lin, KY
AF Chen, Duan-Yu
   Lin, Kuan-Yi
TI Face-based multiple instance analysis for smart electronics billboard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Viewer counting; Gender recognition; Electronic billboard
ID GENDER RECOGNITION; ALGORITHMS
AB This paper introduces a visual-based system, which can count the number of viewers and recognize their gender in front of an electronic billboard in real-time video streams. The viewers actually watching an advertisement are captured via frontal face detection techniques. To count the number of viewer precisely, the problem of occlusions between viewers is tackled. Besides, a complementary set of features is extracted from the torso of a viewer due to the fact that the part of the body contains relatively rich discriminative information than other body parts. In addition, for conducting robust viewer recognition, an online classifier trained by AdaBoost is developed. To recognize the gender of the counted viewers, an approach based on spatiotemporal probabilistic framework is proposed. Our experimental results demonstrate the robustness of the proposed system for the viewer counting and gender recognition tasks.
C1 [Chen, Duan-Yu; Lin, Kuan-Yi] Yuan Ze Univ, Dept Elect Engn, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Chen, DY (corresponding author), Yuan Ze Univ, Dept Elect Engn, Tao Yuan, Taiwan.
EM dychen@saturn.yzu.edu.tw; 9955838@gmail.com
CR Andreu Y, 2009, LECT NOTES COMPUT SC, V5524, P481, DOI 10.1007/978-3-642-02172-5_62
   [Anonymous], IEEE 3 INT C IM VIS
   [Anonymous], 2008, P 16 ACM INT C MULT, DOI [DOI 10.1145/1459359.1459470, DOI 10.1145/1459359.1459470.11.P]
   [Anonymous], INT C COMP VIS
   [Anonymous], 2005, 2005 IEEE COMP VIS P
   Balci K, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047869
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Cho SY, 1999, IEEE T SYST MAN CY B, V29, P535, DOI 10.1109/3477.775269
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Fang YC, 2008, INT C WAVEL ANAL PAT, P373, DOI 10.1109/ICWAPR.2008.4635807
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Goh R, 2005, LECT NOTES COMPUT SC, V3723, P255
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Jing-Ming Guo, 2010, 2010 International Conference on System Science and Engineering (ICSSE 2010), P637, DOI 10.1109/ICSSE.2010.5551728
   Kienzle W., 2005, Advances, V17, P673
   Lapedriza A, 2006, INT C PATT RECOG, P834
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lian HC, 2007, INT J NEURAL SYST, V17, P479, DOI 10.1142/S0129065707001317
   Lin H., 2006, Intelligent Control and Automation, V2, P9988
   LU H, 2003, J REAL-TIME IMAGE PR, V3, P109
   Lu HC, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P646
   Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651
   Nikolaus, 2007, LEARNING PARTS OBJEC
   Osuna E, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P276, DOI 10.1109/NNSP.1997.622408
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Regazzoni CS, 1996, SIGNAL PROCESS, V53, P47, DOI 10.1016/0165-1684(96)00075-8
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Shen BC, 2009, INT CONF ACOUST SPEE, P521, DOI 10.1109/ICASSP.2009.4959635
   Verschae R, 2006, LECT NOTES COMPUT SC, V4225, P68
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680
   Wu B, 2004, INT C PATT RECOG, P914, DOI 10.1109/ICPR.2004.1334677
   Wu B, 2003, LECT NOTES COMPUT SC, V2688, P104
   Yedidia JS, 2001, ADV NEUR IN, V13, P689
   Yedidia JS, 2001, P INT C ART INT
NR 41
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 221
EP 240
DI 10.1007/s11042-011-0746-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800011
DA 2024-07-18
ER

PT J
AU Lai, JH
   Chien, SY
AF Lai, Jui-Hsin
   Chien, Shao-Yi
TI Semantic scalability using tennis videos as examples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content adaptive; Scalable video; Video rendering; Video analysis;
   Scalable video coding
AB With advances in broadcasting technologies, people are now able to watch videos on devices such as televisions, computers, and mobile phones. Scalable video provides video bitstreams of different size under different transmission bandwidths. In this paper, a semantic scalability scheme with four levels is proposed, and tennis videos are used as examples in experiments to test the scheme. Rather than detecting shot categories to determine suitable scaling options for Scalable Video Coding (SVC) as in previous studies, the proposed method analyzes a video, transmits video content according to semantic priority, and reintegrates the extracted contents in the receiver. The purpose of the lower bitstream size in the proposed method is to discard video content of low semantic importance instead of decreasing the video quality to reduce the video bitstream. The experimental results show that visual quality is still maintained in our method despite reducing the bitstream size. Further, in a user study, we show that evaluators identify the visual quality as more acceptable and the video information as clearer than those of SVC. Finally, we suggest that the proposed scalability scheme in the semantic domain, which provides a new dimension for scaling videos, can be extended to various video categories.
C1 [Lai, Jui-Hsin; Chien, Shao-Yi] Natl Taiwan Univ, Media IC & Syst Lab, Grad Inst Elect Engn, Taipei 106, Taiwan.
C3 National Taiwan University
RP Lai, JH (corresponding author), Natl Taiwan Univ, Media IC & Syst Lab, Grad Inst Elect Engn, BL-421,1,Sec 4,Roosevelt Rd, Taipei 106, Taiwan.
EM juihsin.lai@gmail.com; sychien@cc.ee.ntu.edu.tw
OI Chien, Shao-Yi/0000-0002-0634-6294
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Akyol E., 2007, EURASIP J APPL SIG P, V2007, P214
   [Anonymous], PAMI
   Han JG, 2008, IEEE T CIRC SYST VID, V18, P1628, DOI 10.1109/TCSVT.2008.2005611
   Inamoto N., 2004, Proceedings of ACM ACE, V74, P42
   *ITU T, 2003, H264 ITUT
   *ITU T, 1993, REC JPEG STAND
   Jui-Hsin Lai, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P672, DOI 10.1109/MMSP.2008.4665160
   Jui-Hsin Lai, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P676, DOI 10.1109/MMSP.2008.4665161
   Lai JH, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P523, DOI 10.1109/ISM.2009.13
   Lai JH, 2009, IEEE INT CON MULTI, P1306, DOI 10.1109/ICME.2009.5202742
   Liang DW, 2007, IEEE T CONSUM ELECTR, V53, P1138, DOI 10.1109/TCE.2007.4341597
   Qing Tang, 2005, 13th Annual ACM International Conference on Multimedia, P271, DOI 10.1145/1101149.1101202
   Thang TC, 2009, SIGNAL PROCESS-IMAGE, V24, P214, DOI 10.1016/j.image.2008.12.006
   Wang Y, 2005, IEEE T CIRC SYST VID, V15, P1270, DOI 10.1109/TCSVT.2005.854224
   WIKSTRAND G, 2002, P 2 NORD C HUM COMP, P255
   Yu X., 2003, PROC 11 ACM INT C MU, P11
NR 17
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 585
EP 599
DI 10.1007/s11042-010-0685-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000009
DA 2024-07-18
ER

PT J
AU Ozturk, O
   Matsunami, T
   Suzuki, Y
   Yamasaki, T
   Aizawa, K
AF Ozturk, Ovgu
   Matsunami, Tomoaki
   Suzuki, Yasuhiro
   Yamasaki, Toshihiko
   Aizawa, Kiyoharu
TI Real-time tracking of humans and visualization of their future footsteps
   in public indoor environments An intelligent interactive system for
   public entertainment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple human tracking; Interactive arts; Camera and projector systems;
   Technology and entertainment; Real-time visualization
AB In this work, an interactive entertainment system which employs multiple-human tracking from a single camera is presented. The proposed system robustly tracks people in an indoor environment and displays their predicted future footsteps in front of them in real-time. The system is composed of a video camera, a computer and a projector. There are three main modules: tracking, analysis and visualization. The tracking module extracts people as moving blobs by using an adaptive background subtraction algorithm. Then, the location and orientation of their next footsteps are predicted. The future footsteps are visualized by a high-paced continuous display of foot images in the predicted location to simulate the natural stepping of a person. To evaluate the performance, the proposed system was exhibited during a public art exhibition in an airport. People showed surprise, excitement, curiosity. They tried to control the display of the footsteps by making various movements.
C1 [Ozturk, Ovgu] Univ Tokyo, Dept Frontier Informat, Tokyo, Japan.
   [Matsunami, Tomoaki; Yamasaki, Toshihiko] Univ Tokyo, Dept Informat & Commun Engn, Tokyo, Japan.
   [Suzuki, Yasuhiro] Univ Tokyo, Res Ctr Adv Sci & Technol, Tokyo, Japan.
   [Aizawa, Kiyoharu] Univ Tokyo, Interfac Initiat Informat Studies, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo; University of Tokyo;
   University of Tokyo
RP Ozturk, O (corresponding author), Univ Tokyo, Dept Frontier Informat, Tokyo, Japan.
EM ovgu@hal.t.u-tokyo.ac.jp; matsunami@hal.t.u-tokyo.ac.jp;
   yasusay@rcast.u-tokyo.ac.jp; yamasaki@hal.t.u-tokyo.ac.jp;
   aizawa@hal.t.u-tokyo.ac.jp
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], ICPR
   Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269
   Bradski G., 2008, LEARNING OPENCV, P370
   Chae YN, 2009, P INT C VIRT REAL CO, P357
   CHAN AB, 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587569
   Chung JY, 2006, INT CONF ACOUST SPEE, P5355
   Chung JY, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P383, DOI 10.1109/VSMM.2001.969693
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Hirose M, 2010, DIGITAL PUBLIC ART H, P1
   James J., 2006, P ACM INT C MULTIMED, P470
   Jin Choi, 2008, International Journal of Virtual Reality, V7, P71
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kong S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P159, DOI 10.1109/AVSS.2007.4425303
   Lee S, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P29
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Michoud B, 2007, LECT NOTES COMPUT SC, V4814, P88
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morita S., 2005, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ88-D-II, P864
   Ohya J, 2002, KLU INT S VIDEO COMP, P1
   Ozturk O, 2010, P INT C VIRT REAL
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Snidaro L, 2005, IEEE T SYST MAN CY A, V35, P133, DOI 10.1109/TSMCA.2004.838478
   Welch GF, 2009, PRESENCE-TELEOP VIRT, V18, P72, DOI 10.1162/pres.18.1.72
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 26
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 65
EP 88
DI 10.1007/s11042-010-0691-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800005
OA hybrid
DA 2024-07-18
ER

PT J
AU van Hage, WR
   Malaisé, V
   de Vries, GKD
   Schreiber, G
   van Someren, MW
AF van Hage, Willem Robert
   Malaise, Veronique
   de Vries, Gerben K. D.
   Schreiber, Guus
   van Someren, Maarten W.
TI Abstracting and reasoning over ship trajectories and web data with the
   Simple Event Model (SEM)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event modeling; Piecewise linear segmentation; Prolog; Semantic web;
   Maritime safety and security; Situational awareness
ID ONTOLOGY; MPEG-7
AB Bridging the gap between low-level features and semantics is a problem commonly acknowledged in the Multimedia community. Event modeling can fill this gap by representing knowledge about the data at different level of abstraction. In this paper we present the Simple Event Model (SEM) and its application in a Maritime Safety and Security use case about Situational Awareness, where the data also come as low-level features (of ship trajectories). We show how we abstract over these low-level features, recognize simple behavior events using a Piecewise Linear Segmentation algorithm, and model the resulting events as instances of SEM. We aggregate web data from different sources, apply deduction rules, spatial proximity reasoning, and semantic web reasoning in SWI-Prolog to derive abstract events from the recognized simple events. The use case described in this paper comes from the Dutch Poseidon project.
C1 [van Hage, Willem Robert; Malaise, Veronique; Schreiber, Guus] Vrije Univ Amsterdam, Web & Media Grp, Amsterdam, Netherlands.
   [de Vries, Gerben K. D.; van Someren, Maarten W.] Univ Amsterdam, TCS Grp, Amsterdam, Netherlands.
C3 Vrije Universiteit Amsterdam; University of Amsterdam
RP van Hage, WR (corresponding author), Vrije Univ Amsterdam, Web & Media Grp, Amsterdam, Netherlands.
EM wrvhage@few.vu.nl; vmalaise@few.vu.nl; G.K.D.deVries@uva.nl;
   schreiber@cs.vu.nl; M.W.vanSomeren@uva.nl
FU Dutch Ministry of Economic Affairs under the BSIK
FX This work has been carried out as a part of the Poseidon project in
   collaboration with Thales Nederland, under the responsibilities of the
   Embedded Systems Institute (ESI). This project is partially supported by
   the Dutch Ministry of Economic Affairs under the BSIK program.
CR Andrienko N., 2007, CARTOGRAPHICA V42 2, P117, DOI DOI 10.3138/CART0.42.2.117
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Cao H, 2006, VLDB J, V15, P211, DOI 10.1007/s00778-005-0163-7
   Ceolin D, 2010, WEBSCI10 EXTENDING F
   Claudio Masolo SB, 2003, WONDERWEB DELIVERABL
   Crofts N., 2009, DEFINITION CIDOC CON
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gangemi A, 2004, STUD HEALTH TECHNOL, V102, P64
   Gudmundsson J, 2009, COMP GEOM-THEOR APPL, V42, P825, DOI 10.1016/j.comgeo.2009.02.002
   Hunter J, 2002, MUS WEB INT C BOST
   Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   Masolo C., 2002, The wonderweb library of foundational ontologies
   Orellana D, 2009, MOVEMENT AWARE APPL
   Raimond Yves, 2007, The Event Ontology
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Ruotsalo T, 2007, 6 INT 2 AS SEM WEB C, P407
   Scherp A., 2009, INT C KNOWL CAPT K C
   Shaw R, 2009, LECT NOTES COMPUT SC, V5926, P153, DOI 10.1007/978-3-642-10871-6_11
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Spaccapietra S, 2008, DATA KNOWL ENG, V65, P126, DOI 10.1016/j.datak.2007.10.008
   Tsinaraki C, 2005, MULTIMED TOOLS APPL, V26, P299, DOI 10.1007/s11042-005-0894-x
   Westermann U., 2006, DATA ENG WORKSHOPS, px106
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wielemaker J, 2008, THEOR PRACT LOG PROG, V8, P363, DOI 10.1017/S1471068407003237
   Wielemaker J, 2008, LECT NOTES COMPUT SC, V5318, P695, DOI 10.1007/978-3-540-88564-1_44
   Worboys M, 2004, LECT NOTES COMPUT SC, V3234, P327
NR 27
TC 19
Z9 24
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 175
EP 197
DI 10.1007/s11042-010-0680-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800011
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Si, S
   Tao, DC
   Wang, M
   Chan, KP
AF Si, Si
   Tao, Dacheng
   Wang, Meng
   Chan, Kwok-Ping
TI Social image annotation via cross-domain subspace learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social image annotation; Cross-domain learning; Subspace learning
ID DIMENSIONALITY REDUCTION; FRAMEWORK
AB In recent years, cross-domain learning algorithms have attracted much attention to solve labeled data insufficient problem. However, these cross-domain learning algorithms cannot be applied for subspace learning, which plays a key role in multimedia processing. This paper envisions the cross-domain discriminative subspace learning and provides an effective solution to cross-domain subspace learning. In particular, we propose the cross-domain discriminative locally linear embedding or CDLLE for short. CDLLE connects the training and the testing samples by minimizing the quadratic distance between the distribution of the training samples and that of the testing samples. Therefore, a common subspace for data representation can be preserved. We basically expect the discriminative information to separate the concepts in the training set can be shared to separate the concepts in the testing set as well and thus we have a chance to address above cross-domain problem duly. The margin maximization is duly adopted in CDLLE so the discriminative information for separating different classes can be well preserved. Finally, CDLLE encodes the local geometry of each training samples through a series of linear coefficients which can reconstruct a given sample by its intra-class neighbour samples and thus can locally preserve the intra-class local geometry. Experimental evidence on NUS-WIDE, a popular social image database collected from Flickr, and MSRA-MM, a popular real-world web image annotation database collected from the Internet by using Microsoft Live Search, demonstrates the effectiveness of CDLLE for real-world cross-domain applications.
C1 [Si, Si; Chan, Kwok-Ping] Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.
   [Tao, Dacheng] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
   [Wang, Meng] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 University of Hong Kong; Nanyang Technological University; Microsoft
   Research Asia; Microsoft
RP Si, S (corresponding author), Univ Hong Kong, Dept Comp Sci, Pokfulam, Hong Kong, Peoples R China.
EM ssi@cs.hku.hk; dacheng.tao@ieee.org; mengewang@microsoft.com;
   kpchan@cs.hku.hk
RI Tao, Dacheng/A-5449-2012; /C-1823-2009
OI Tao, Dacheng/0000-0001-7225-5449; /0000-0002-5733-4023
CR [Anonymous], 2003, P ADV NEUR INF PROC
   [Anonymous], 2008, AAAI
   [Anonymous], 2008, AAAI
   [Anonymous], 2006, P 14 ACM INT C MULTI
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], 2009, P ACM INT C IM VID R
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Dai Wenyuan, 2007, P 24 INT C MACHINE L, P193
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Li H, 2009, ICDM WORKSH INT MULT
   Ling X., 2008, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, P488, DOI [10.1145/1401890.1401951, DOI 10.1145/1401890.1401951]
   Liu D., 2009, INT WORLD WID WEB C
   Liu W, 2008, IEEE DATA MINING, P433, DOI 10.1109/ICDM.2008.101
   Mihalkova L, 2006, ICML WORKSH STRUCT K
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793
   Si S, IEEE T IMAG IN PRESS
   Si S, IEEE T KNOW IN PRESS
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Song D, IEEE T IMAGE IN PRES
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wang J, 2009, P 21 C COMP VIS PATT
   Wang M, 2008, P 16 ACM INT C MULT, P47
   Wang M., 2007, ACM Multi- media, P862
   WANG M, 2009, ACM WORKSH WEB SCAL
   Wu Z, 2009, P 21 C COMP VIS PATT
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yang Jun., 2008, P 1 INT C MULTIMEDIA, P467
   Zhang TH, 2008, LECT NOTES COMPUT SC, V5302, P725, DOI 10.1007/978-3-540-88682-2_55
   Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212
   Zhang TH, 2008, IEEE IJCNN, P1670, DOI 10.1109/IJCNN.2008.4634022
NR 36
TC 8
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 91
EP 108
DI 10.1007/s11042-010-0567-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500005
DA 2024-07-18
ER

PT J
AU Park, JS
AF Park, Jong-Seung
TI AR-Room: a rapid prototyping framework for augmented reality
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Rapid prototyping; Software framework
AB This paper presents a novel software framework called AR-Room for fast prototyping of a variety of augmented reality applications. AR-Room consists of a lot of deployable components for core augmented reality technologies, modules for hardware abstraction, and an authoring toolkit for the rapid content design. On the AR-Room, application developers are only required to describe their content scenarios together with a configuration of software components. A content scenario is represented by a set of event-action pairs. Four major procedures in an augmented reality application are an image analyzer, an interaction handler, a rendering engine and an image synthesizer. According to the provided scenarios the designated components cooperatively provide real-time analysis and synthesis of input video frames. Several augmented reality applications are implemented on the AR-Room to show how the framework can be efficiently used for the fast prototyping of applications.
C1 Univ Incheon, Dept Comp Sci & Engn, Inchon 406772, South Korea.
C3 Incheon National University
RP Park, JS (corresponding author), Univ Incheon, Dept Comp Sci & Engn, 12-1 Songdo Dong, Inchon 406772, South Korea.
EM jong@incheon.ac.kr
FU University of Incheon
FX This work was supported by the University of Incheon Research Grant in
   2010.
CR ABABSA F, 2004, INT C VIRT REAL CONT, P431
   Abawi DF, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P260, DOI 10.1109/ISMAR.2004.8
   AITKIN AL, 2005, THESIS AUSTR NATL U
   [Anonymous], 1995, P INT WORKSH AUT FAC
   Asutay AV, 2005, IEEE ACM DIS SIM, P213, DOI 10.1109/DISTRA.2005.44
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Balcisoy S, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P303, DOI 10.1109/CGI.2000.852346
   BALCISOY S, 2000, P ACM S VIRT REAL SO, P61
   Bauer M, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P45, DOI 10.1109/ISAR.2001.970514
   BLAIR M, 1999, THESIS COLUMBIA U
   Borst CW, 2005, PRESENCE-TELEOP VIRT, V14, P677, DOI 10.1162/105474605775196562
   Bradski G., 2008, LEARNING OPENCV
   Broll W, 2005, IEEE T VIS COMPUT GR, V11, P722, DOI 10.1109/TVCG.2005.90
   Costanza E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1879
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   DOMER R, 2002, P INT WORKSH ENT COM, P405
   FELLNER DW, 2009, P 2 SIN GERM WORKSH, P78
   Fiala M, 2005, PROC CVPR IEEE, P590
   Freeman RM., 2007, 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, P157
   Gandy M, 2004, ACM CHI Lett, V6, P197
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   GOVIL A, 2000, ACM MULT 2000, P489
   Ishii H., 1999, CHI'99 Proceedings, P394, DOI [10.1145/ 302979.303115, DOI 10.1145/302979.303115]
   Jiang BL, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1637, DOI 10.1109/ICME.2000.871084
   Kallmann M, 1999, SPRING COMP SCI, P73
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Lee GA, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P172, DOI 10.1109/ISMAR.2004.34
   Lenman S., 2002, Proc. of the Second Nordic Conference on Human-Computer Interaction, P239, DOI DOI 10.1145/572020.572055
   LOOSER J, 2007, THESIS U CANTERBURY
   LOURAKIS M, 2005, IEEE COMP SOC C COMP, V2, P1190
   Lourakis MIA, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P569, DOI 10.1109/CGI.2004.1309266
   NILSEN T, 2005, P 2 INT WORKSH PERV, P86
   Park JS, 2008, OPT ENG, V47, DOI 10.1117/1.2842382
   PONDER M, 2004, THESIS EPFL
   Sandor C, 2005, PERS UBIQUIT COMPUT, V9, P169, DOI 10.1007/S00779-004-0328-1
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Seichter H, 2008, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2008.4637354
   Uchiyama S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P246, DOI 10.1109/ISMAR.2002.1115095
   UEMATSU Y, 2005, ICAT2005, P48
   von Hardenberg C., 2001, Workshop on Perceptive User Interfaces, P113
   Woodward C., 2004, Proceedings of the 2004 ACM SIGCHI International Conference on Advances in computer entertainment technology, P275
   Xiao F., 2003, P INT WORKSH SOFTW T, P537
   YOON JH, 2006, P INT C ART REAL TEL, P239
   ZAUNER J, 2004, EGVE 2004 GREN FRANC, P87
   Zhang Zhengyou., 2001, WORKSHOP PERCEPTIVE, P1, DOI DOI 10.1145/971478.971522
NR 46
TC 15
Z9 18
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 725
EP 746
DI 10.1007/s11042-010-0592-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600015
DA 2024-07-18
ER

PT J
AU Tsai, MJ
AF Tsai, Min-Jen
TI Dynamic energy enabled differentiation (DEED) image watermarking based
   on human visual system and wavelet tree classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Human visual system (HVS); Tree energy
   differentiation; Wavelet
AB In this paper, we present a novel dynamic energy enabled differentiation (DEED) watermarking algorithm based on the wavelet tree classification and human visual system (HVS). The wavelet coefficients of the image are divided into disjoint trees and a wavelet tree consists of 21 coefficients which are divided into 6 blocks. One watermark bit is embedded into one wavelet tree using the energy differentiation of positive and negative modulation between coefficients of each block. In addition, the contrast sensitive function (CSF) of human visual system is also considered for better weighting in watermarking since the wavelet coefficients across the subbands perform different characteristics and importance. As DEED still requires extra storage of side information during the extraction and results non-blind watermarking approach, a random direction differentiation approach called DEEDR is then proposed which is a truly blind watermarking technique. This study has performed intensive comparison for the proposed scheme with other tree energy differentiation based techniques like WTQ, ABW-TMD and WTGM under various geometric and nongeometric attacks. From the experimental results, the advantage of DEED based algorithms is not only with low complexity, but also outperforms WTGM and WTQ in terms of robustness and imperceptibility of watermarking.
C1 Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
FU National Science Council in Taiwan, Republic of China
   [NSC96-2416-H009-015, NSC97-2410-H009-034, 99-2918-1-009-008]
FX The author would like to thank the anonymous reviewers with their
   valuable comments to improve the quality of this manuscript and Bai-Jiun
   Chen at National Chiao Tung University who helps to write the programs
   for software experiments. This work is partially supported by the
   National Science Council in Taiwan, Republic of China, under Grant
   NSC96-2416-H009-015, NSC97-2410-H009-034 and 99-2918-1-009-008.
CR Al-Otum HM, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2372467
   [Anonymous], Stirmark
   Beegan AP, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P88, DOI 10.1109/DSPWS.2002.1231082
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das TK, 2005, IEEE T SIGNAL PROCES, V53, P768, DOI 10.1109/TSP.2004.839930
   DAS TK, 2004, IWDC 2004, P219
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   KUNDUR D, 1998, P IEEE ICASSP, V5, P2869
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Tsai MJ, 2008, IEICE T FUND ELECTR, VE91A, P1961, DOI 10.1093/ietfec/e91-a.8.1961
   Tsai MJ, 2008, IEICE T FUND ELECTR, VE91A, P1426, DOI 10.1093/ietfec/e91-a.6.1426
   Tsai MJ, 2007, INT CONF ACOUST SPEE, P173
   Tsai MJ, 2009, J VIS COMMUN IMAGE R, V20, P323, DOI 10.1016/j.jvcir.2009.03.011
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang SH, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P589, DOI 10.1109/ICME.2002.1035850
   YONG L, 2004, CHINESE J COMPUTERS, V20, P1533
NR 20
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 385
EP 406
DI 10.1007/s11042-009-0422-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000009
DA 2024-07-18
ER

PT J
AU Soares, LFG
   Rodrigues, RF
   Cerqueira, R
   Barbosa, SDJ
AF Soares, Luiz Fernando G.
   Rodrigues, Rogerio Ferreira
   Cerqueira, Renato
   Junqueira Barbosa, Simone Diniz
TI Variable and state handling in NCL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variable handling; Declarative languages; NCL; Digital TV; Middleware
AB Most time-based declarative languages have limited support for variable definition and manipulation, which causes developers to resort to imperative languages. However, a declarative language should provide a variable handling model sufficiently rich to describe a wide range of interactive applications, avoiding, as much as possible, the help of an imperative scripting language. On the other hand, the declarative simplicity should not be lost, leaving for the imperative objects more complex manipulations, with the necessary care to avoid any impact in the application's temporal graph. Based on this principle, variables and the presentation state are handled by NCL and Ginga-NCL, as discussed in this paper. NCL is the declarative language of the Brazilian Terrestrial Digital TV System (SBTVD) supported by its middleware called Ginga. NCL and Ginga-NCL are part of ISDB standards and also of ITU-T Recommendations for IPTV services.
C1 [Soares, Luiz Fernando G.; Rodrigues, Rogerio Ferreira; Cerqueira, Renato; Junqueira Barbosa, Simone Diniz] Pontificia Univ Catolica Rio de Janeiro, BR-22451900 Rio De Janeiro, Brazil.
   [Rodrigues, Rogerio Ferreira] Microsoft Corp FAST, BR-20090003 Rio De Janeiro, Brazil.
C3 Pontificia Universidade Catolica do Rio de Janeiro; Microsoft
RP Soares, LFG (corresponding author), Pontificia Univ Catolica Rio de Janeiro, Rua Marques Sao Vicente 225, BR-22451900 Rio De Janeiro, Brazil.
EM lfgs@inf.puc-rio.br; roger@microsoft.com; rcerq@inf.puc-rio.br;
   simone@inf.puc-rio.br
RI Barbosa, Simone/F-8012-2014
OI Barbosa, Simone/0000-0002-0044-503X
FU CNPq; FINEP; FAPERJ
FX The authors would like to thank Carlos Salles, Romualdo Costa, Marcio
   Moreno, Marcelo Moreno and Francisco Sant'anna who provided thoughtful
   discussion of this work, and tracked down and fixed problems in the
   initial reference implementation of Ginga. The authors also thank Ethan
   Munson for his careful revision of the paper, and CNPq, FINEP and FAPERJ
   for their support.
CR *ABNT NBR, 2007, DIG TERR TEL STAND 2
   [Anonymous], 2001, 144961 ISOIEC
   [Anonymous], 2006, Lua 5.1 reference manual
   [Anonymous], 2006, 1449620 ISOIEC
   [Anonymous], P 3 ACM SIGPLAN C HI
   *ARIB, 2004, B24 ARIB
   *ECMA, 1999, ECMA262
   *ETSI, 2006, 102812V122 ETSI TS
   GUIMARAES RL, 2008, P EUR INT TV C SALZB
   *ITU T, 2009, H761 ITUT
   JANSEN J, 2009, MULTIMEDIA TOOLS APP, V43
   KING P, 2004, P ACM DOC ENG MILW W
   SOARES LFG, 2009, 0309 MCC DEP INF PUC
   SOARES LFG, 2006, 3506 MCC DEP INF PUC
   SOARES LFG, 2009, P 24 ANN ACM S APPL
   Thompson AM, 2005, DEV NEUROSCI-BASEL, V27, P1, DOI 10.1159/000084527
   *W3C WORLD WID WEB, 2003, SCAL VECT GRAPH SVG
   *W3C WORLD WID WEB, 1999, XML PATH LANG XPATH
   *W3C WORLD WID WEB, 2005, SYNCHR MULT INT LANG
   *W3C WORLD WID WEB, 1998, CASC STYL SHEET LEV
   *W3C WORLD WID WEB, 1998, TIM INT MULT EXT HTM
   W3C World Wide Web Consortium, 2008, SYNCHR MULT INT LANG
   W3C-World Wide Web Consortium, 2004, DOC OBJ MOD DOM LEV
NR 23
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 465
EP 489
DI 10.1007/s11042-010-0478-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100003
DA 2024-07-18
ER

PT J
AU Quénot, G
   Tan, TP
   Le, VB
   Ayache, S
   Besacier, L
   Mulhem, P
AF Quenot, Georges
   Tan, Tien Ping
   Le, Viet Bac
   Ayache, Stephane
   Besacier, Laurent
   Mulhem, Philippe
TI Content-based search in multilingual audiovisual documents using the
   International Phonetic Alphabet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio retrieval; Multilingual; International Phonetic Alphabet; Dynamic
   programming; Star Challenge
AB We present in this paper an approach based on the use of the International Phonetic Alphabet (IPA) for content-based indexing and retrieval of multilingual audiovisual documents. The approach works even if the languages of the document are unknown. It has been validated in the context of the "Star Challenge" search engine competition organized by the Agency for Science, Technology and Research (A*STAR) of Singapore. Our approach includes the building of an IPA-based multilingual acoustic model and a dynamic programming based method for searching document segments by "IPA string spotting". Dynamic programming allows for retrieving the query string in the document string even with a significant transcription error rate at the phone level. The methods that we developed ranked us as first and third on the monolingual (English) search task, as fifth on the multilingual search task and as first on the multimodal (audio and image) search task.
C1 [Quenot, Georges] Multimedia Informat Indexing & Retrieval Grp MRIM, Lab Informat Grenoble, F-38041 Grenoble 9, France.
   [Le, Viet Bac] CNRS, LIMSI, F-91403 Orsay, France.
   [Ayache, Stephane] Lab Informat Fondamentale Marseille, F-13288 Marseille 9, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS); Centre National de la Recherche
   Scientifique (CNRS); Universite Paris Saclay; Aix-Marseille Universite
RP Quénot, G (corresponding author), Multimedia Informat Indexing & Retrieval Grp MRIM, Lab Informat Grenoble, BP 53, F-38041 Grenoble 9, France.
EM Georges.Quenot@imag.fr
RI Tan, Tien-Ping/A-9816-2011
OI Tan, Tien Ping/0000-0002-4154-4747
FU Quaero programme
FX Part of this work has been supported by the Quaero programme.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   Ayache S, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/56928
   CLARKSON P, 1997, EUR C SPEECH COMM TE, P2707
   GAUVAIN JL, 1982, P IEEE ICASSP 82, V2, P891
   LE VB, 2006, P IEEE ICASSP 2006
   LE VB, 2004, LREC 04, P599
   LI H, 2007, IEEE T AUDIO SPEECH, V15, P91
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MATTI OTM, 2000, 15 INT C PATT REC, V3, P951
   MORARU D, 2004, RT2004 FALL WORKSH
   PLACEWAY P, 1997, DARPA SPEECH REC WOR
   Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7
   Singh AN, 1996, J PSYCHIATR NEUROSCI, V21, P29
   Stolcke Andreas., 2002, P 7 INT C SPOKEN LAN
   TAN TP, 2008, INT 2008
NR 15
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 123
EP 140
DI 10.1007/s11042-009-0377-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400008
DA 2024-07-18
ER

PT J
AU Shih, JY
   Tsai, WJ
AF Shih, Jhong-Yu
   Tsai, Wen-Jiin
TI A new unequal error protection scheme based on FMO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unequal error protection; UEP; Flexible macroblock ordering; FMO;
   Converged motion estimation; Error resilience
ID TRANSMISSION
AB This paper presents a novel scheme for video transmission over error-prone networks. The proposed scheme exploits the error resilient features of H.264/AVC and employs an unequal error protection (UEP) approach to protect effectively the streams. A novel algorithm is proposed to classify macroblocks into slice groups using the explicit mode of Flexible Macroblock Ordering (FMO). A rate distortion optimized algorithm is used to assign unequal amounts of FEC protection to the resulting slice groups according to their importance. In addition, a Converged Motion Estimation (CME) is proposed to further improve the proposed UEP scheme. The idea behind the CME is to make the macroblocks be referenced in a skewed manner, such that highly important macroblocks are converged on only a few and the use of redundancy for error protection is efficient. Simulation results show the superiority of the proposed method over other approaches for transmission of H.264/AVC streams.
C1 [Shih, Jhong-Yu; Tsai, Wen-Jiin] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, WJ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM wjtsai@cs.nctu.edu.tw
FU National Science Council of Taiwan [NSC 96-2221-E-009-162-MY2]
FX This work was supported in part by grants from the National Science
   Council of Taiwan under Contracts NSC 96-2221-E-009-162-MY2.
CR [Anonymous], 2016, IEEE Standard 802.11-2020
   [Anonymous], P IEEE INF C NEW YOR
   *IEEE, 1999, 80211 IEEE S
   IM SK, 2005, P IEEE INF COMM SIGN, P1135
   Marx F, 2004, SIGNAL PROCESS-IMAGE, V19, P313, DOI 10.1016/j.image.2003.11.002
   Masala E, 2004, IEEE DATA COMPR CONF, P182
   Masala E, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P111, DOI 10.1109/MMSP.2001.962720
   Rizzo L., 1997, Computer Communication Review, V27, P24, DOI 10.1145/263876.263881
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478
   Stockhammer T, 2004, IEEE IMAGE PROC, P545
   Thomos N, 2005, IEEE T IMAGE PROCESS, V14, P1890, DOI 10.1109/TIP.2005.854482
   THOMOS N, 2005, IEEE INTEGRATION KNO
   van der Schaar M, 2003, IEEE J SEL AREA COMM, V21, P1752, DOI 10.1109/JSAC.2003.815231
   Wang YJ, 2006, IEEE INT SYMP CIRC S, P2137
   ZHAI F, 2004, P IEEE INT C AC SPEE
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 16
TC 8
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 461
EP 476
DI 10.1007/s11042-009-0333-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200006
DA 2024-07-18
ER

PT J
AU Yang, L
   Johnstone, J
   Zhang, CC
AF Yang, Lin
   Johnstone, John
   Zhang, Chengcui
TI Ranking canonical views for tourist attractions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Canonical view ranking; Photo collections; Page Rank; Adaptive
   non-maximal suppression; SIFT; The wisdom of crowds
AB Online photo collections have become truly gigantic. Photo sharing sites such as Flickr (http://www.flickr.com) host billions of photographs, a large portion of which are contributed by tourists. In this paper, we leverage online photo collections to automatically rank canonical views for tourist attractions. Ideal canonical views for a tourist attraction should both be representative of the site and exhibit a diverse set of views (Kennedy and Naaman, International Conference on World Wide Web 297-306, 2008). In order to meet both goals, we rank canonical views in two stages. During the first stage, we use visual features to encode the content of photographs and infer the popularity of each photograph. During the second stage, we rank photographs using a suppression scheme to keep popular views top-ranked while demoting duplicate views. After a ranking is generated, canonical views at various granularities can be retrieved in real-time, which advances over previous work and is a promising feature for real applications. In order to scale canonical view ranking to gigantic online photo collections, we propose to leverage geo-tags (latitudes/longitudes of the location of the scene in the photographs) to speed up the basic algorithm. We preprocess the photo collection to extract subsets of photographs that are geographically clustered (or geo-clusters), and constrain the expensive visual processing within each geo-cluster. We test the algorithm on two large Flickr data sets of Rome and the Yosemite national park, and show promising results on canonical view ranking. For quantitative analysis, we adopt two medium data sets and conduct a subjective comparison with previous work. It shows that while both algorithms are able to produce canonical views of high quality, our algorithm has the advantage of responding in real-time to canonical view retrieval at various granularities.
C1 [Yang, Lin; Johnstone, John; Zhang, Chengcui] Univ Alabama Birmingham, Birmingham, AL USA.
C3 University of Alabama System; University of Alabama Birmingham
RP Yang, L (corresponding author), Univ Alabama Birmingham, Birmingham, AL USA.
EM galabing@cis.uab.edu; jj@cis.uab.edu; zhang@cis.uab.edu
CR [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2008, 2008 IEEE C COMPUTER
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Brown M, 2005, PROC CVPR IEEE, P510
   Bryan K, 2006, SIAM REV, V48, P569, DOI 10.1137/050623280
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hofmann T., 1999, PROBABILISTIC LATENT
   JAFFE A, 2006, GENERATING SUMMARIES, P89
   JING YS, 2008, INT WORLD WID WEB C, P307
   Jing Yushi., 2007, P 6 ACM INT C IMAGE, P280
   KE Y, 2006, DESIGN HIGH LEVEL FE, P419
   KENNEDY L, 2006, SEARCH LABLE PREDICT, P249
   Kennedy L S, 2008, GENERATING DIVERSE R, P297
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   RAGURAM R, 2008, COMPUTING ICONIC SUM, pR4
   SIMON I, 2007, SCENE SUMMARIZATION, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
NR 22
TC 4
Z9 4
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 573
EP 589
DI 10.1007/s11042-009-0345-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300017
DA 2024-07-18
ER

PT J
AU Han, SW
   Park, JW
   Kim, J
AF Han, Sang Woo
   Park, Ju-Won
   Kim, JongWon
TI Open media service architecture for advanced collaboration environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia collaboration; High-quality video over IP; Application-level
   network monitoring; Dynamic network adaptation; Access Grid
ID MULTIMEDIA APPLICATIONS
AB Advanced collaboration environments are extensively utilized for distance learning, e-science, and other distributed global collaboration events. In such environments, high-quality and seamless media services play an important role in improving the quality of user experience to participants. In this paper, to support high-quality media-based services, we design open media service architecture for advanced collaboration environments, by combining the open interface for state-of-the-art media tools, the performance monitoring tools for devices and networks, and application-level adaptation schemes for media streaming. By implementing the proposed architecture on top of an open-source Access Grid (AG) collaboration toolkit, we verify that high-quality collaboration among several collaboration sites can be effectively realized over a multicast-enabled network testbed with improved media quality experience.
C1 [Han, Sang Woo; Park, Ju-Won; Kim, JongWon] Gwangju Inst Sci & Technol, Dept Informat & Commun, Networked Media Lab, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Kim, J (corresponding author), Gwangju Inst Sci & Technol, Dept Informat & Commun, Networked Media Lab, 261 Cheomdan Gwagiro, Kwangju 500712, South Korea.
EM swhan@nm.gist.ac.kr; jwpark@nm.gist.ac.kr; jongwon@nm.gist.ac.kr
RI Park, Ju-Won/JEZ-4921-2023
OI Park, Ju-Won/0000-0003-1388-1583
FU Ministry of Knowledge Economy, Korea [IITA-2009-C1090-0902-0006]
FX We would like to thank several members of KISTI supercomputing center,
   ACE research team of GIST Networked Media Laboratory, AG development
   team of Argonne National Laboratory, and anonymous reviewers for their
   helpful suggestions. This research was supported by the Ministry of
   Knowledge Economy, Korea, under the Information Technology Research
   Center support program supervised by the Institute of Information
   TechnologyAdvancement. (grant number IITA-2009-C1090-0902-0006).
CR Burnett I, 2003, IEEE MULTIMEDIA, V10, P60, DOI 10.1109/MMUL.2003.1237551
   Busse I, 1996, COMPUT COMMUN, V19, P49, DOI 10.1016/0140-3664(95)01038-6
   CHILDERS L, 2000, P INT IMM PROJ TECHN
   CORRIE B, 2003, P WORKSH ADV COLL EN
   *EVO CALT TEAM, 2008, COLL JUST GETS BETT
   FALLON H, 2003, VLC USER GUIDE
   GARCIASANCHEZ AJ, 2007, SOFTWARE ENG ADV
   GARCIASANCHEZ AJ, 2008, EL C 2008 MELECON 20, P120
   HAN S, 2005, P SPIE, V6015
   HANDLEY M, 2000, RFC2974 IETF
   Handley M, 1998, 2327 IETF RFC
   HSU B, 2006, ACCESS GRID RETREAT
   *ITU T, 2007, ADV MULT SYST AMS PR
   Johanson B., 2002, IEEE Pervasive Computing, V1, P67, DOI 10.1109/MPRV.2002.1012339
   Kazunori U, 2003, 2003 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P111, DOI 10.1109/SAINT.2003.1183039
   KIRSTEIN P, 2008, ACCESS GRID RETREAT
   KUTSCHER D, 2005, SESSION DES IN PRESS
   Leigh J, 2006, FUTURE GENER COMP SY, V22, P964, DOI 10.1016/j.future.2006.03.009
   MCCANNE S, 1995, P ACM MULT 95 SAN FR, P511
   MESSER A, 2006, P IEEE PERCOM 06
   Miller BA, 2001, IEEE COMMUN MAG, V39, P104, DOI 10.1109/35.968819
   Mulugeta M, 2007, LECT NOTES COMPUT SC, V4608, P90
   OGAWA A, 2000, PACK VID WORKSH CAGL
   Ooi W, 2002, INDIVA MIDDLEWARE MA
   PARK JW, 2005, P 3 IEEE IFIP WORKSH, P142
   Patrick AS, 2004, FIRST INTERNATIONAL CONFERENCE ON QUALITY OF SERVICE IN HETEROGENEOUS WIRED/WIRELESS NETWORKS, PROCEEDINGS, P319, DOI 10.1109/QSHINE.2004.6
   ROSENBERG J, 2002, 3264 IETF RFC
   Stevens R, 2003, IEEE INTERNET COMPUT, V7, P51, DOI 10.1109/MIC.2003.1215660
   Strauss Jacob., 2003, IMC 03, P39, DOI [DOI 10.1145/948205.948211, 10.1145/948205.948211]
   Wang X, 1999, IEICE T COMMUN, VE82B, P806
   WICHADAKUL D, 2003, THESIS U ILLINOIS UR
   WILLING C, 2007, P C QUEENSL ED SCI T
   Zhang CH, 2003, MULTIMEDIA SYST, V9, P315, DOI 10.1007/s00530-003-0058-7
NR 33
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 133
EP 160
DI 10.1007/s11042-009-0276-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600007
DA 2024-07-18
ER

PT J
AU Halkos, D
   Doulamis, N
   Doulamis, A
AF Halkos, Dimitris
   Doulamis, Nikolaos
   Doulamis, Anastasios
TI A secure framework exploiting content guided and automated algorithms
   for real time video searching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real time video searching; Content guided research; Security
ID INDEXING STRUCTURE; SIMILARITY SEARCH; EFFICIENT; RETRIEVAL; SCHEME;
   TREE
AB This paper presents an architecture that allows End Users, via the services of Search Engines, to search, in a secure and efficient way, the video content belonging to Content Providers. The search can be accomplished with any searching scheme that the Search Engines wish to provide, as long as certain security constraints are met. However we propose specific algorithms that demonstrate an efficient way to search video data without sacrificing security effectiveness of the system. The search is completed without the End Users or Search Engines needing to purchase the premium content beforehand, and without the Content Providers needing to purchase the search technology. The business motivation of this technique is to assist End Users to purchase content best suiting their requirements-they are offered search results only, not actual content. The objective is to face the problem caused by the current segregation between content ownership and video processing technology ownership. To face this segregation, we present an architecture that guarantees security of Content Provider's data and Search Engine's technology and we also present two innovative algorithms that make real time video searching a feasible process. Particularly these algorithms (a) organize video content into a graph based hierarchical structure and (b) perform content guided, non interactive and real time search by exploiting the graph based video structures. The proposed algorithms are incorporated in the presented architecture under the given security constraints. Experimental results and comparisons with conventional techniques are presented to demonstrate the outperformance of the proposed algorithms.
C1 [Halkos, Dimitris; Doulamis, Nikolaos] Natl Tech Univ Athens, Dept Elect & Comp Engn, GR-15773 Athens, Greece.
   [Doulamis, Anastasios] Tech Univ Crete, Lab Decis Support Syst, Polytechnioupolis, Chania, Greece.
C3 National Technical University of Athens; Technical University of Crete
RP Halkos, D (corresponding author), Natl Tech Univ Athens, Dept Elect & Comp Engn, GR-15773 Athens, Greece.
EM dhalk@telecom.ntua.gr; ndoulam@cs.ntua.gr; adoulam@cs.ntua.gr
RI Doulamis, Anastasios/AAL-5972-2021
CR Cheung SCS, 2005, IEEE T MULTIMEDIA, V7, P524, DOI 10.1109/TMM.2005.846906
   Cheung SCS, 2003, IEEE T CIRC SYST VID, V13, P59, DOI 10.1109/TCSVT.2002.808080
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P757, DOI 10.1109/TCSVT.2004.828348
   *FIPA, 2007, SPEC FIPA
   Francis DH, 2008, INFORM SCIENCES, V178, P1442, DOI 10.1016/j.ins.2007.11.004
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   *IBM, IBM MARV PROJ MP7
   *ISO IEC, 2001, 1SC29WG11N3964 ISOIE
   *ISO MPEG, 1999, MPEG7 ISOMPEG
   Jennings N. R., 1998, Autonomous agents and multi-agent systems, P7, DOI DOI 10.1023/A:1010090405266
   Kenny S, 2002, COMPUT SECUR, V21, P648, DOI 10.1016/S0167-4048(02)01117-3
   Kiranyaz S, 2007, IEEE T MULTIMEDIA, V9, P102, DOI 10.1109/TMM.2006.886362
   KWOK SH, 2000, P INT C EL COMM ICEC, P179
   Lin HY, 2008, DATA KNOWL ENG, V64, P365, DOI 10.1016/j.datak.2007.09.009
   Lu GJ, 2002, IEEE T MULTIMEDIA, V4, P372, DOI 10.1109/TMM.2002.802831
   Lu H, 2006, IEEE T KNOWL DATA EN, V18, P1544, DOI 10.1109/TKDE.2006.174
   Meessen J, 2006, IEE P-VIS IMAGE SIGN, V153, P274, DOI 10.1049/ip-vis:20050066
   NAM J, 2000, P IEEE INT WORKSH MU, P117
   Nwana HS, 1999, KNOWL ENG REV, V14, P125, DOI 10.1017/S0269888999142012
   Punitha P, 2008, PATTERN RECOGN, V41, P2068, DOI 10.1016/j.patcog.2007.09.012
   ROSENBLATT B, 2001, DIGITAL RIGHTS MANAG
   Salton G., 1982, INTRO MODERN INFORM
   SAMUELSON P, 1999, COMMUN ACM, V42, P335, DOI DOI 10.1145/295685.295847
   Schöffmann K, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P237, DOI 10.1109/SMAP.2007.11
   Schoeman M., 2003, P 2003 ANN RES C S A
   Smith JR, 1999, IEEE T MULTIMEDIA, V1, P157, DOI 10.1109/6046.766737
   WAGNER G, 1998, FDN KNOWLEDGE SYSTEM
   Wang GR, 2007, INFORM SCIENCES, V177, P2255, DOI 10.1016/j.ins.2006.12.018
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Yannopoulos A, 2004, IEEE T KNOWL DATA EN, V16, P641, DOI 10.1109/TKDE.2004.10
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Yi HR, 2006, INFORM SYST, V31, P638, DOI 10.1016/j.is.2005.12.005
   Zhu XQ, 2005, IEEE T MULTIMEDIA, V7, P648, DOI 10.1109/TMM.2005.850977
   2001, GRASSHOPPER RELEASE
NR 34
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 42
IS 3
BP 343
EP 375
DI 10.1007/s11042-008-0234-z
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 423HN
UT WOS:000264487500005
DA 2024-07-18
ER

PT J
AU Hong, D
   Eleftheriadis, A
AF Hong, Danny
   Eleftheriadis, Alexandros
TI XFlavor: providing XML features in media representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE media representation; XFlavor; Flavor; software tools
ID DIGITAL ITEM ADAPTATION
AB We present XFlavor, a framework for providing XML representation of multimedia data. XFlavor can be used to convert multimedia data back and forth between binary and XML representations. Compared to bitstreams, XML documents are easier to access and manipulate, and consequently, the development of multimedia processing software is greatly facilitated, as one generic XML parser can be used to read and write different types of data in XML form.
C1 [Hong, Danny; Eleftheriadis, Alexandros] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
C3 Columbia University
RP Hong, D (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
EM danny@ee.columbia.edu; eleft@ee.columbia.edu
RI Hong, Danny/GPX-0809-2022
CR AMIELH M, 2002, P 11 INT WORLD WID W
   [Anonymous], 2001, 144961 ISOIEC
   [Anonymous], 1994, 10918 ISOIEC
   [Anonymous], 2000, ASN 1 COMMUNICATION
   Avaro O, 2001, IEEE T CIRC SYST VID, V11, P760, DOI 10.1109/76.927437
   CHENG SF, 1995, P ACM INT C VIS COMM
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DEVILLER S, 2003, P 9 INT C PAR DISTR, V2790
   Devillers S, 2005, IEEE T MULTIMEDIA, V7, P463, DOI 10.1109/TMM.2005.846794
   Eleftheriadis A, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P1
   FANG Y, 1996, P IEEE INT C IM PROC, P426
   Girardot M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P67, DOI 10.1109/ICME.2000.869547
   Hong D, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P773, DOI 10.1109/ICME.2002.1035896
   *IETF RFC, 1995, 1832 IETFRFC
   *ISO IEC, 2002, 2225012002 ISOIEC
   *ISO IEC, 2003, 1975722003 ISOIEC
   *ISO IEC, 1999, 144963 ISOIEC
   *ISO IEC, 1996, 13818 ISOIEC
   *ISO IEC, 1996, 138181 ISOIEC
   *ISO IEC, 1999, 14496 ISOIEC
   *ISO IEC, 2003, 21000 ISOIEC
   *ISO IEC, 1993, 11172 ISOIEC
   Levine J.R., 1992, LEX YACC
   Liefke Hartmut., 2000, P 2000 ACM SIGMOD IN, P153
   OSORIO R, 2002, P IEEE INT C IM PROC, V3, P17
   Panis G, 2003, SIGNAL PROCESS-IMAGE, V18, P721, DOI 10.1016/S0923-5965(03)00061-4
   Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653
   Stevens R, 1999, UNIX NETWORK PROGRAM
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   Vetro A, 2004, IEEE MULTIMEDIA, V11, P84, DOI 10.1109/MMUL.2004.1261111
   VETRO A, 2006, MPEG 21 BOOK
   *W3C NOT, 1999, WAP BIN XML CONT FOR
   *W3C REC, 1999, XSL TRANSF XSLT
   *W3C REC, 2004, EXT MARK LANG XML 1
   *W3C REC, 2001, XML SCH PART 0 PRIME
NR 35
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2008
VL 39
IS 1
BP 101
EP 116
DI 10.1007/s11042-007-0157-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 311TE
UT WOS:000256622500004
DA 2024-07-18
ER

PT J
AU Thomasian, A
   Zhang, LJ
AF Thomasian, Alexander
   Zhang, Lijuan
TI Persistent clustered main memory index for accelerating <i>k</i>-NN
   queries on high dimensional datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Computer Vision Meets Databases
CY JUN 17, 2005
CL Baltimore, MD
DE content based retrieval; feature vectors; nearest neighbor queries;
   multidimensional indexing; feature vectors; SR-trees; vector
   approximation file; ordered partition index; principal component
   analysis; singular value decomposition; Karhunen-Loeve transform
ID APPROXIMATE SIMILARITY SEARCH
AB Similarity search implemented via k-nearest neighbor-k-NN queries on multidimensional indices is an extremely useful paradigm for content-based image retrieval. As the dimensionality of feature vectors increases the curse of dimensionality sets in, i.e., the performance of k-NN search of disk-resident indices in the R-tree family degrades rapidly due to the overlap in index pages in high dimensions. This problem is dealt with in this study by utilizing the double filtering effect of clustering and indexing. The clustering algorithm ensures that the largest cluster fits into main memory and that only clusters closest to a query point need to be searched and hence loaded into main memory. We organize the data in each cluster according to the ordered-partition-OP-tree main memory resident index, which is not prone to the curse of dimensionality and highly efficient for processing k-NN queries. We serialize an OP-tree by writing its dynamically allocated nodes into contiguous memory locations, optimize its parameters, and make it persistent by writing it to disk. The time to read and write clusters constituting an OP-tree with a single sequential access to disk benefits from higher data transfer rates of modern disk drives. The performance of the index is further improved by applying the Karhunen-Loeve transformation-KLT to the dataset, since this results in a more efficient computation of distances for k-NN queries. We compare OP-trees and sequential scans with and without a KL-transformation and with and without using a shortcut method in calculating Euclidean distances. A comparison against the OMNI-sequential scan is also reported. We finally compare a clustered and persistent version of the OP-tree against a clustered version of the SR-tree and the VA-file method. CPU time is measured and elapsed time is estimated in this study. It is observed that the OP-tree index outperforms the other two methods and that the improvement increases with the number of dimensions.
C1 [Thomasian, Alexander; Zhang, Lijuan] New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
   [Thomasian, Alexander] Thomasian & Associates, Pleasantville, NY 10570 USA.
   [Zhang, Lijuan] AMICAS Inc, Boston, MA USA.
C3 New Jersey Institute of Technology
RP Thomasian, A (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
EM alexthomasian@gmail.com; catherine_zh@hotmail.com
RI Zhang, Lijuan/L-9988-2014
CR BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   BOHM C, 2000, P 7 INT C EXT DAT TE, P36
   Castelli V, 2003, IEEE T KNOWL DATA EN, V15, P671, DOI 10.1109/TKDE.2003.1198398
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Castelli Vittorio., 2002, Image Databases: Search and Retrieval of Digital Imagery, P373
   Chakrabarti K., 2000, Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P89
   Dumouchel W., 1997, IEEE Data Eng. Bulletin, V20, P3
   Faloutsos C., 1996, SEARCHING MULTIMEDIA
   Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279
   GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5
   Gray J., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P3, DOI 10.1109/ICDE.2000.839382
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Hjaltason GR, 1999, ACM T DATABASE SYST, V24, P265, DOI 10.1145/320248.320255
   Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83
   Katayama N., 1997, P ACM SIGMOD, P369
   KATAYAMA N, 2002, AMS DIMACS SERIES, V59, P87
   KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761, DOI 10.1109/TPAMI.1986.4767859
   KORN F, 1997, P ACM SIGMOD INT C M, P289, DOI DOI 10.1145/253260.253332
   Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214
   Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production
   ROUSSOPOULOS N, 1998, P ACM SIGMOD INT C M, P154
   SAMET H, 2006, FUNDAMENTALS MULTIDI
   Santos RF, 2001, PROC INT CONF DATA, P623, DOI 10.1109/ICDE.2001.914877
   Thomasian A, 2005, INFORM PROCESS LETT, V94, P247, DOI 10.1016/j.ipl.2005.03.003
   THOMASIAN A, 2005, ISL0501 COMP SCI DEP
   THOMASIAN A, 2003, ISL0301 COMP SCI DEP
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   White DA, 1996, P SOC PHOTO-OPT INS, V2670, P62, DOI 10.1117/12.234810
   ZHANG L, 2005, THESIS NEW JERSY I T
   ZHOU K, 2004, P ACM SIGMOD INT C M, P191
   [No title captured]
NR 35
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2008
VL 38
IS 2
BP 253
EP 270
DI 10.1007/s11042-007-0179-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 301NV
UT WOS:000255903800005
DA 2024-07-18
ER

PT J
AU Dong, L
   Veeravalli, B
AF Dong, Ligang
   Veeravalli, Bharadwaj
TI Design and analysis of a variable bit rate caching algorithm for
   continuous media data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia caching; disk caching; memory caching; resource management;
   non-switch constraint; variable bit rate; interval-level caching
ID VIDEO; PROXY
AB In this paper, the problem of caching continuous media data in a (main) memory and disk caching system is addressed. Caching schemes can significantly reduce the load on the network as well as on the servers, also the retrieval of documents from the cache requires short response time. In interval-level caching algorithms, an interval of data between two adjacent streams is the basic caching entity. In this paper, we design a novel algorithm, referred to as variable bit rate caching (VBRC) algorithm, which belongs to the interval-level caching algorithms. The proposed VBRC algorithm can be used in the system for memory caching or disk caching. VBRC can handle variable retrieval bandwidth as well as constant retrieval bandwidth . In designing the VBRC algorithm, we propose the strategies of reducing the number of switching operation, which will probably cause discontinuity of retrieving data. Also, we propose a just-in-time scheme for resource allocation in our VBRC algorithm and show that the caching performance in comparison with the reservation scheme adopted in the resource-based caching (RBC) algorithm is significantly improved. Our simulation study compares the recent and most popular generalized interval caching, RBC, and VBRC, on several influencing factors such as cache space size, cache I/O bandwidth, request arrival rate, and percentage of requests for large documents, with respect to the byte hit ratio and the number of switching operations. The simulation result confirms our analysis.
C1 [Dong, Ligang] Zhejiang Gongshang Univ, Coll Informt & Elect Engn, Hangzhou 310035, Zhejiang, Peoples R China.
   [Veeravalli, Bharadwaj] Natl Univ Singapore, Dept Elect & Comp Engn, Comp Networks & Distributed Syst Lab, Singapore 119260, Singapore.
C3 Zhejiang Gongshang University; National University of Singapore
RP Dong, L (corresponding author), Zhejiang Gongshang Univ, Coll Informt & Elect Engn, 149 Jiaogong Rd, Hangzhou 310035, Zhejiang, Peoples R China.
EM donglg@mail.zjgsu.edu.cn; elebv@nus.edu.sg
CR Aggarwal C, 1999, IEEE T KNOWL DATA EN, V11, P94, DOI 10.1109/69.755618
   [Anonymous], P IEEE INFOCOM
   Barish G, 2000, IEEE COMMUN MAG, V38, P178, DOI 10.1109/35.841844
   Candan KS, 1998, MULTIMEDIA SYST, V6, P232, DOI 10.1007/s005300050091
   CHEN S, 2004, P IEEE INFOCOM 04 HO
   CHEN S, 2003, P INT WORKSH NETW OP
   CHEN S, 2004, P IEEE ICDCS 04 TOK
   Cho K, 2003, LECT NOTES COMPUT SC, V2869, P276
   CUCCHIARA R, 2001, P 20 IEEE INT PERF C
   Dan A, 1997, MULTIMED TOOLS APPL, V4, P279, DOI 10.1023/A:1009637022889
   DAN A, 1994, 19347 RC IBM RES
   DAN A, 1996, P IS T SPIE MULT COM
   Foong AP, 1999, IEEE INTERNET COMPUT, V3, P27, DOI 10.1109/4236.793455
   Hua KA, 2004, P IEEE, V92, P1439, DOI 10.1109/JPROC.2004.832954
   JIN S, 2000, P 5 INT WORKSH WEB C
   JIN SD, 2002, P 22 INT C DISTR COM
   KIM S, 1999, P IEEE TENCON 99 CHE
   LEE K, 1999, P 6 IEEE INT C MULT
   Lee KO, 2003, COMPUT SYST SCI ENG, V18, P87
   Leff A, 1996, IEEE T PARALL DISTR, V7, P191, DOI 10.1109/71.485508
   Lim H, 2001, ELECTRON LETT, V37, P403, DOI 10.1049/el:20010238
   LIU J, 2004, P IEEE INFOCOM 04 HO
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   OZDEN B, 1996, MULTIMEDIA INFORMATI, P163
   Park SC, 2001, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, P757, DOI 10.1109/ICPADS.2001.934894
   Roberts LG, 2000, COMPUTER, V33, P117, DOI 10.1109/2.963131
   Saroiu S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FIFTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P315, DOI 10.1145/1060289.1060319
   SITARAM D, 1999, MULTIMEDIA SERVERS D
   SONAH B, 1999, P 23 ANN INT COMP SO
   SONAH B, 1999, P 3 INT C COMP INT M
   TEWARI R, 1998, P SPIE ACM C MULT CO
   WANG Y, 1998, P IEEE INFOCOM APR
   YAN H, 2003, P INT C PAR DISTR CO
NR 33
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 91
EP 117
DI 10.1007/s11042-007-0151-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000005
DA 2024-07-18
ER

PT J
AU Wen, K
   Necsulescu, D
   Sasiadek, J
AF Wen, K.
   Necsulescu, D.
   Sasiadek, J.
TI Haptic force control based on impedance/admittance control aided by
   visual feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE robotics; force control; impedance and admittance control; visual
   feedback; virtual system
ID ROBUST COMPLIANT MOTION; IMPEDANCE CONTROL; MANIPULATION
AB This paper demonstrates a haptic device for interaction with a virtual environment. The force control is added by visual feedback that makes the system more responsive and accurate. There are two popular control methods widely used in haptic controller design. First, is impedance control when user motion input is measured, and then, the reaction force is fed back to the operator. The alternative method is admittance control, when forces exerted by user are measured and motion is fed back to the user. Both, impedance and admittance control are also basic ways for interacting with a virtual environment. In this paper, several experiments were performed to evaluate the suitability of force-impedance control for haptic interface development. The difference between conventional application of impedance control in robot motion control and its application in haptic interface development is investigated. Open loop impedance control methodology is implemented for static case and a general-purpose robot under open loop impedance control was developed as a haptic device, while a closed loop model based impedance control was used for haptic controller design in both static and dynamic case. The factors that could affect to the performance of a haptic interface are also investigated experimentally using parametric studies. Experimental results for 1 DOF rotational motion and 2 DOF planar translational motion systems are presented. The results show that the impedance control aided by visual feedback broaden the applicability of the haptic device and makes the system more responsive and accurate.
C1 [Wen, K.; Necsulescu, D.] Univ Ottawa, Dept Mech Engn, Ottawa, ON K1N 6N5, Canada.
   [Sasiadek, J.] Carleton Univ, Dept Mech & Aerosp Engn, Ottawa, ON K1S 5B6, Canada.
C3 University of Ottawa; Carleton University
RP Necsulescu, D (corresponding author), Univ Ottawa, Dept Mech Engn, Ottawa, ON K1N 6N5, Canada.
EM necsules@eng.uottawa.ca; jsas@ccs.carleton.ca
CR [Anonymous], 1996, FORCE TOUCH FEEDBACK
   CARIGNAN CR, 2003, IEEE CONTROL SYS APR
   CARIGNAN CR, 2000, ELECT J HAPTICS RES, V2
   Clover CL, 1999, IEEE T SYST MAN CY C, V29, P481, DOI 10.1109/5326.798763
   Clover CL, 1997, IEEE INT CONF ROBOT, P724, DOI 10.1109/ROBOT.1997.620121
   Hannaford B, 2002, IEEE T ROBOTIC AUTOM, V18, P1, DOI 10.1109/70.988969
   Hogan D.P., 1985, CURRENT PERSPECTIVES, V1, P1
   HOGAN N, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P1626, DOI 10.1109/ROBOT.1989.100210
   Hogan N., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P1047
   HOGAN N, 1985, J DYN SYST-T ASME, V107, P8, DOI 10.1115/1.3140713
   HOGAN N, 1985, J DYN SYST-T ASME, V107, P17, DOI 10.1115/1.3140701
   JASSEMIZARGANI R, 1998, P 1 IFAC WORKSH SPAC
   KAZEROONI H, 1994, IEEE T ROBOTIC AUTOM, V10, P453, DOI 10.1109/70.313096
   KAZEROONI H, 1986, IEEE T ROBOTIC AUTOM, V2, P93, DOI 10.1109/JRA.1986.1087047
   KAZEROONI H, 1986, IEEE T ROBOTIC AUTOM, V2, P83, DOI 10.1109/JRA.1986.1087045
   KAZEROONI H, 1990, IEEE T SYST MAN CY 1, V20
   KAZEROONI H, 1987, IEEE T ROBOTIC AUTOM, V4, P741
   Volpe R. A., 1990, THESIS
   [No title captured]
NR 19
TC 16
Z9 19
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2008
VL 37
IS 1
BP 39
EP 52
DI 10.1007/s11042-007-0172-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 261AT
UT WOS:000253052200004
DA 2024-07-18
ER

PT J
AU El Saddik, A
   Yang, DS
   Georganas, ND
AF El Saddik, Abdulmotaleb
   Yang, Dongsheng
   Georganas, Nicolas D.
TI Tools for transparent synchronous collaborative environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE synchronous collaborative environments
AB Synchronous collaborative environments can provide an identical visual and operable working area among geographically separated participants. There are two basic approaches for providing a shared workspace. They are collaborative-aware approach and collaborative-unaware approach. Since the second approach allows single-user applications to be reused, most users choose to use it. Our work is based on the collaborative-unaware environment. This paper describes the design and implementation of some transparent synchronous collaborative tools. They are: (1) the latecomer support for Java applications, Java applets and JMF players (2) the client synchronization to minimize data transmission latency and (3) the lightweight multi-session support to let different collaboration groups work at the same time. These tools optimize existing transparent synchronous collaboration systems and make them more realistic, more complete and more generic.
C1 Univ Ottawa, SITE, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP El Saddik, A (corresponding author), Univ Ottawa, SITE, Ottawa, ON K1N 6N5, Canada.
EM abed@discover.uottawa.ca; doris@discover.uottawa.ca;
   georganas@discover.uottawa.ca
RI /D-4159-2009
OI /0000-0002-7690-8547
CR CHUNG G, 1998, IFIP WORK C ENG HUM
   ELSADDIK A, 2000, IDMS2000
   ELSADDIK A, 2001, INTERACTIVE MULTIMED, P101
   Floyd S, 1997, IEEE ACM T NETWORK, V5, P784, DOI 10.1109/90.650139
   ILLMANN T, 2002, CSCL2002
   Ionescu M., 2001, IEEE DISTRIBUTED SYS, V2
   JACKSON LS, 2000, LIS 490 PROSEMINAR R
   JOGEL J, 2000, ACM MULT 2000 OCT
   KINDBERG T, 1996, 5 ERCIM WORKSH, P43
   KINDBERG T, 1996, IEEE GLOBAL INTE NOV
   MARSIC I, 1999, ACM COMPUTERING SURV, V31
   ROSEMAN M, 1996, CSCW96 NOAT TAIW U D
   ROSEMAN M, 1996, 4 ANN USENIX TCL TK
   Wang W., 1999, DESIGN DISCIPLE SYNC
NR 14
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2007
VL 33
IS 2
BP 217
EP 240
DI 10.1007/s11042-006-0057-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149GB
UT WOS:000245134000006
DA 2024-07-18
ER

PT J
AU Wong, HS
   Cheung, KKT
   Chiu, CI
   Sha, Y
   Ip, HHS
AF Wong, Hau-San
   Cheung, Kent K. T.
   Chiu, Chun-Ip
   Sha, Yang
   Ip, Horace H. S.
TI Hierarchical multi-classifier system design based on evolutionary
   computation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Distributed Multimedia Systems (DMS
   03)/6th International Conference on Visual Information Systems (VIS
   2003)
CY SEP 24-26, 2003-2006
CL Miami, FL
DE hierarchical classifier; evolutionary computation; multimedia signal
   processing
ID TREE
AB Histogram feature representation is important in many classification applications for characterization of the statistical distribution of different pattern attributes, such as the color and edge orientation distribution in images. While the construction of these feature representations is simple, this very simplicity may compromise the classification accuracy in those cases where the original histogram does not provide adequate discriminative information for making a reliable classification. In view of this, we propose an optimization approach based on evolutionary computation (Back, Evolutionary algorithms in theory and practice, Oxford University Press, New York, 1996; Fogel, Evolutionary computation: toward a new philosophy of machine intelligence, 2nd edn. IEEE, Piscataway, NJ 1998) to identify a suitable transformation on the histogram feature representation, such that the resulting classification performance based on these features is maximally improved while the original simplicity of the representation is retained. To facilitate this optimization process, we propose a hierarchical classifier structure to demarcate the set of categories in such a way that the pair of category subsets with the highest level of dissimilarities is identified at each stage for partition. In this way, the evolutionary search process for the required transformation can be considerably simplified due to the reduced level of complexities in classification for two widely separated category subsets. The proposed approach is applied to two problems in multimedia data classification, namely the categorization of 3D computer graphics models and image classification in the JPEG compressed domain. Experimental results indicate that the evolutionary optimization approach, facilitated by the hierarchical classification process, is capable of significantly improving the classification performance for both applications based on the transformed histogram representations.
C1 City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Kowloon, Hong Kong, Peoples R China.
   City Univ Hong Kong, Ctr Innovat Applicat Internet & Multimedia Techno, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong
RP Wong, HS (corresponding author), City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Kowloon, Hong Kong, Peoples R China.
EM cshswong@cityu.edu.hk
OI IP, Ho Shing Horace/0000-0002-1509-9002; WONG,
   Hau-San/0000-0002-1530-7529
CR Ankerst M, 1999, Proc Int Conf Intell Syst Mol Biol, P34
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 1998, EVOLUTIONARY COMPUTA
   [Anonymous], 7517 REEE PURD U SCH
   Back T, 1998, GENETIC ALGORITHMST
   Bailey A., 1999, Proceedings of the Second International Conference on Information Fusion. FUSION '99, P1196
   Basri R, 1996, IEEE T PATTERN ANAL, V18, P465, DOI 10.1109/34.491630
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Furht B., 1995, Real-Time Imaging, V1, P49, DOI 10.1006/rtim.1995.1005
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   IP HHS, 2002, 15 VIS INT CALG CAN, P314
   KIM BY, 1991, IEEE T GEOSCI REMOTE, V29, P518, DOI 10.1109/36.135813
   LANDEWEERD GH, 1983, PATTERN RECOGN, V16, P571, DOI 10.1016/0031-3203(83)90073-0
   Lau R. W. H., 2002, World Wide Web, V5, P193, DOI 10.1023/A:1020984612969
   Lay JA, 1999, INT CONF ACOUST SPEE, P3009, DOI 10.1109/ICASSP.1999.757474
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   *MPI, 2004, MPI FAC DAT
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pennebaker W.B., 1993, JPEG: Still Image Compression Standard
   ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   YOON Y, 2004, IN PRESS P 1 INT JOI
   YOU KC, 1976, P 3 S MACH PROC REM
NR 26
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2007
VL 33
IS 1
BP 91
EP 108
DI 10.1007/s11042-006-0098-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 149FZ
UT WOS:000245133800007
DA 2024-07-18
ER

PT J
AU Moënne-Loccoz, N
   Janvier, B
   Marchand-Maillet, S
   Bruno, E
AF Moenne-Loccoz, Nicolas
   Janvier, Bruno
   Marchand-Maillet, Stephane
   Bruno, Eric
TI Handling temporal heterogeneous data for content-based management of
   large video collections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Computer Vision Meets Databases
CY JUN 13, 2004
CL Paris, FRANCE
DE video document; MPEG-7; TREC video track; content-based multimedia
   retrieval; ViCoDE
AB Video document retrieval is now an active part of the domain of multimedia retrieval. However, unlike for other media, the management of a collection of video documents adds the problem of efficiently handling an overwhelming volume of temporal data. Challenges include balancing efficient content modeling and storage against fast access at various levels. In this paper, we detail the framework we have built to accommodate our developments in content-based multimedia retrieval. We show that not only our framework facilitates the development of processing and indexing algorithms but it also opens the way to several other possibilities such as rapid interface prototyping or retrieval algorithm benchmarking. Here, we discuss our developments in relation to wider contexts such as MPEG-7 and the TREC Video Track.
C1 Univ Geneva, Viper Grp, Comp Vis & Multimedia Lab, Geneva, Switzerland.
C3 University of Geneva
RP Moënne-Loccoz, N (corresponding author), Univ Geneva, Viper Grp, Comp Vis & Multimedia Lab, Geneva, Switzerland.
EM Nicolas.Moenne-Loccoz@cui.unige.ch
CR AMIR A, 2003, P TRECVID 2003 WORKS
   [Anonymous], P TRECVID 2003 WORKS
   [Anonymous], 2000, VLDB
   [Anonymous], P EUR C CONT BAS MUL
   [Anonymous], P TRECVID 2003 WORKS
   [Anonymous], 2003, P 5 ACM SIGMM INT WO, DOI DOI 10.1145/973264.973269
   Beckmann N., 1990, P ACM SIGMOD INT C M, P322, DOI DOI 10.1145/93597.98741
   BOZKAYA T, 1997, P ACM SIGMOD INT C M, P357
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Gauvain JL, 2002, SPEECH COMMUN, V37, P89, DOI 10.1016/S0167-6393(01)00061-9
   JELMINI C, 2004, P C COUPL APPR COUPL
   MANJUNATH BS, 2001, INTRO MPEG 7 MULTIME
   Moenne-Loccoz N., 2004, OVAL OBJECT BASED VI
   MOENNELOCCOZ N, 2004, P INT C IM VID RETR
   Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592
   Roach M., 2002, P INT C INT MULT SYS
   RUILOBA R, 1999, INT WORKSH CONT BAS
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   TZOURAMANIS T, 2000, P 4 E EUR C ADV DAT, P279
   WEBER R, 2000, ICDE SAN DIEG CAL, P197
   ZHOU X, 2004, CVPR 01, V1, P11
NR 22
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2006
VL 31
IS 3
BP 309
EP 325
DI 10.1007/s11042-006-0042-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 119XW
UT WOS:000243048800005
DA 2024-07-18
ER

PT J
AU Sheu, S
   Tavanapong, W
   Hua, KA
AF Sheu, Simon
   Tavanapong, Wallapak
   Hua, Kien A.
TI A scalable cost-effective video broadcasting system for on-demand video
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video-on-demand; video streaming; periodic broadcast; multicast
AB Recent years have seen intensive investigations of Periodic Broadcast, an attractive paradigm for broadcasting popular videos. In this paradigm, the server simply broadcasts segments of a popular video periodically on a number of communication channels. A large number of clients can be served simultaneously by tuning into these channels to receive segments of the requested video. A playback can begin as soon as a client can access the first segment. Periodic Broadcast guarantees a small maximum service delay regardless of the number of concurrent clients. Existing periodic broadcast techniques are typically evaluated through analytical assessment. While these results are good performance indicators, they cannot demonstrate subtle implementation difficulty that can prohibit these techniques from practical deployment. In this paper, we present the design and implementation of a video broadcasting system based on our periodic broadcast scheme called Striping Broadcast. Our experience with the system confirms that the system offers a low service delay close to its analytical guaranteed delay while requiring small storage space and low download bandwidth at a client.
C1 Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
   Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30013, Taiwan.
   Univ Cent Florida, Comp Sci Program, Sch EECS, Orlando, FL 32816 USA.
C3 Iowa State University; National Tsing Hua University; State University
   System of Florida; University of Central Florida
RP Tavanapong, W (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM sheu@cs.nthu.edu.tw; tavanapo@cs.iastate.edu; kienhua@cs.ucf.edu
CR AGGARWAL CC, 1996, P IEEE INT C MULT SY
   Biersack EW, 2002, PERFORM EVALUATION, V49, P411, DOI 10.1016/S0166-5316(02)00134-7
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   EAGER DL, 1998, P 4 INT WORKSH MULT, P18
   Fei ZM, 1999, LECT NOTES COMPUT SC, V1736, P152
   GAO L, 1998, P INT WORKSH NETW OP
   HELMY A, 2003, PROTOCOL INDEPENDENT
   Hu AL, 2001, IEEE INFOCOM SER, P508, DOI 10.1109/INFCOM.2001.916754
   Hua K., 1997, PROC SIGCOMM, P89
   Hua KA, 1998, IEEE IC COMP COM NET, P848, DOI 10.1109/ICCCN.1998.998852
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   MAHANTI A, 2001, P ACM SIGCOMM 01, P97
   Paris J.-F., 1999, Proceedings Eight International Conference on Computer Communications and Networks (Cat. No.99EX370), P118, DOI 10.1109/ICCCN.1999.805505
   Paris JF, 1998, SIXTH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P127, DOI 10.1109/MASCOT.1998.693685
   PARIS JF, 1999, P 1999 MULT COMP NET, P317
   PARIS JF, 1998, P INT C COMP COMM NE
   PARIS JF, 1999, P ACM MULT 99
   SHEU S, 2003, TR0303 IOW STAT U DE
   SHEU S, 2002, P ICACT PHOEN PARK K
   SHEU S, 2000, P WORKSH VIRT U MULT, P218
   TANTAOUI MA, 2002, P 10 ACM INT C MULT, P29
   Tavanapong W, 2001, SOFTWARE PRACT EXPER, V31, P471, DOI 10.1002/spe.382
   VISWANATHAN S, 1995, P SOC PHOTO-OPT INS, V2417, P66, DOI 10.1117/12.206080
   WITTMANN R, 2001, MULTICAST COMMUNICAT, pCH3
NR 25
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2006
VL 28
IS 3
BP 321
EP 345
DI 10.1007/s11042-006-7717-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 044FO
UT WOS:000237658000004
DA 2024-07-18
ER

PT J
AU Paver, NC
   Khan, MH
   Aldrich, BC
AF Paver, N. C.
   Khan, M. H.
   Aldrich, B. C.
TI Optimizing mobile multimedia using SIMD techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE architecture; mobile; multimedia; programming; SIMD
AB Demand for mobile video applications is growing today in wireless handheld platforms. Optimizing instruction set architectures and employing SIMD techniques is a logical approach towards attaining higher performance in mobile multimedia applications. Intel(R) Wireless MMXTM technology has been designed to accelerate mobile multimedia and applications processing in a power efficient manner. This paper provides an overview of Intel(R) Wireless MMXTM technology, a 64-bit Single Instruction Multiple Data (SIMD) coprocessor for the Intel(R) XScale(R) microarchitecture, and the key features of the architecture that specifically enhance the multi-media performance. Tools and techniques for optimization are also described.
C1 Intel Corp, Austin, TX 78746 USA.
C3 Intel Corporation
RP Khan, MH (corresponding author), Intel Corp, 1501 S Mopac,Suite 400, Austin, TX 78746 USA.
EM nigel.paver@intel.com; moinul.h.khan@intel.com;
   bradley.c.aldrich@intel.com
CR ALDRICH BA, 2004, 8 WORLD MULT SYST CY
   [Anonymous], Integrated Performance Monitoring (IPM)
   Diendroff K., 1999, MICRO PROCESSORS REP, V13, P6
   Furber SB, 2000, ARM SYSTEM ON CHIP A
   *INT, INT XSCAL R COR DEV
   *INT ORG STAND, 1997, JTC1SC29WG11N1902144
   KHAN MH, 2004, OPTIMIZATION TECHNIQ
   KONEN R, ISOIECJTC1SC29WG11N4
   Kuhn P., ALGORITHMS COMPLEXIT
   Lee RB, 1996, IEEE MICRO, V16, P51, DOI 10.1109/40.526925
   PAVER NC, 2004, PROGRAMMING INTEL WI
   PAVER NC, 2003, IEEE WORKSH SIGN PRO
   PAVER NC, 2003, INT C AC SPEECH SIGN
   Peleg A, 1996, IEEE MICRO, V16, P42, DOI 10.1109/40.526924
   SEAL D, 1996, ADV RISC MACHINES AR
   Tremblay M, 1996, IEEE MICRO, V16, P10, DOI 10.1109/40.526921
   WEISER U, 1997, COMPLETE GUIDE MMX T
NR 17
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 221
EP 238
DI 10.1007/s11042-006-6144-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600008
DA 2024-07-18
ER

PT J
AU Cheuk, WK
   Hsung, TC
   Lun, DPK
AF Cheuk, WK
   Hsung, TC
   Lun, DPK
TI Design and implementation of contractual based real-time scheduler for
   multimedia streaming proxy server
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
ID WIDE-AREA NETWORKS; VIDEO
AB In nowadays World Wide Web topology, it is not difficult to find the presence of proxy servers. They reduce network traffic through the cut down of repetitive information. However, traditional proxy server does not support multimedia streaming. One of the reasons is that general scheduling strategy adopted by most of the traditional proxy servers does not provide real-time support to multimedia services. Based on the concept of contractual scheduling, we have developed a proxy server that supports real-time multimedia applications. Moreover, we developed the group scheduling mechanism to enable processing power transfer between tasks that can hardly be achieved by traditional schedulers. They result in a substantially improved performance particularly when both time-constrained and non-time-constrained processes coexist within the proxy server. In this paper, the design and implementation of this proxy server and the proposed scheduler are detailed.
C1 Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Kowloon, Hong Kong, Peoples R China.
EM cheuk@ieee.org
RI Hsung, Tai-Chiu/ADW-8730-2022; Lun, Daniel Pak Kong/H-2120-2017
OI Hsung, Tai-Chiu/0000-0001-7699-1937; Lun, Daniel Pak
   Kong/0000-0003-3891-1363
CR CHEUK WK, 1999, P 1 IEEE COMP SOC IN, P255
   CHEUK WK, 2001, THESIS HONG KONG POL, P73
   FABMI H, 2001, IEEE COMPUT, V34, P54
   GALLMEISTER BO, 1995, POSIX 4 PROGRAMMING, P203
   Gebhard H, 2001, IEEE COMMUN MAG, V39, P182, DOI 10.1109/35.925688
   HANDLEY M, 1998, 2327 RFC
   LAM WK, 1998, P ISCA 12 INT C PAR, P339
   LAM WK, 1995, ANAL CONTRACTOR MODE
   LAM WK, 1997, P INT WORKSH COMP SC, P171
   LAM WK, 1996, PRELIMINARY INVESTIG
   LAM WK, 1999, P EUR WORKSH PAR DIS, P230
   Lin CW, 2001, IEEE T CIRC SYST VID, V11, P415, DOI 10.1109/76.911165
   Ma WH, 2002, IEEE T MULTIMEDIA, V4, P539, DOI 10.1109/TMM.2002.806536
   SCHULZRINNE H, 1996, RFC1889
   SCHULZRINNE H, 1996, 1890 RFC
   Schulzrinne H., 1998, 2326 RFC
   SIU YM, 1996, SUPPORT CLUSTER COMP
   THIRAN P, 2001, INFOCOM 2001, V3, P474
   Wang Q, 2002, IEEE SIGNAL PROC LET, V9, P33, DOI 10.1109/97.991132
   Zhang Q, 2001, IEEE T MULTIMEDIA, V3, P339, DOI 10.1109/6046.944477
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
NR 21
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2006
VL 28
IS 1
BP 69
EP 88
DI 10.1007/s11042-006-5118-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 011ZR
UT WOS:000235308500004
DA 2024-07-18
ER

PT J
AU Pihkala, K
   Vuorimaa, P
AF Pihkala, K
   Vuorimaa, P
TI Nine methods to extend SMIL for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SMIL; XML; XForms; multimedia; extension
AB The SMIL 2.0 multimedia standard has been designed for use on the Web. It supports keyboard and mouse as input devices. Typically, SMIL players can play out text, images, audio, and video. SMIL also has a strong support for declarative synchronization and timing. Being an open standard, SMIL could well be utilized in custom applications, in environments such as info kiosks and multimedia consoles. However, these environments usually require better input and output capabilities not available in SMIL. This paper presents nine methods to extend SMIL for custom multimedia applications. The methods include ways to attach new input sources, output capabilities, and extended internal logic. Also, an implementation of an extensible SMIL player is given. As a conclusion, SMIL can be extended in several ways for custom multimedia applications. These extensions will provide new ideas for the future multimedia languages.
C1 Aalto Univ, Telecommun Software & Multimedia Lab, FI-02015 Espoo, Finland.
C3 Aalto University
RP Pihkala, K (corresponding author), Aalto Univ, Telecommun Software & Multimedia Lab, POB 5400, FI-02015 Espoo, Finland.
EM kari.pihkala@iki.fi
RI Vuorimaa, Petri/G-6303-2011
OI Vuorimaa, Petri/0009-0007-6198-6650
CR [Anonymous], MODULARIZATION XHTML
   [Anonymous], 2000, EXTENSIBLE MARKUP LA
   *APPL COMP INC, 2003, QUICKTIME SMIL
   BECKHAM J, 2001, SMIL FDN MULTIMODAL
   Bray T., 1999, WORLD WIDE WEB CONSO
   *ECMA, 1999, ECMA262
   GOOSE S, 2002, P 11 INT WORLD WID W
   GORDON R, 1998, ESSENTIAL JMF
   HARDMAN L, 2000, REV HYPERMEDIA MULTI, V6, P89
   Honkala M., 2001, WWW J, V4, P151, DOI [10.1023/A:1013853416747, DOI 10.1023/A:1013853416747]
   KIM M, P 2000 ACM WORKSH MU, P71
   NEWMAN D, 2002, W3C XHTML SMIL
   PIHKALA K, 2003, P SMIL EUR 2003 C PA
   PIHKALA K, 2002, P 6 IASTED INT C INT
   PINHKALA K, 2002, P IEEE INT C MULT EX, P189
   *REALNETWORKS INC, 2002, REALNETWORKD PROD GU
   RUTLEDGE L, 1999, IEEE INTERNET COMPUT
   RUTLEDGE L, 1999, P ACM MULT ORL FLOR
   SCHMITZ P, 2002, P 11 INT WORLD WID W
   SCHMITZ P, 2001, MSRTR200101 MICR COR
   VAHASILILA A, 2000, 2806 RFC
   Vierinen J, 2002, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMMUNICATIONS, INTERNET, AND INFORMATION TECHNOLOGY, P54
   VONOSSENBRUGGEN J, 2001, P 10 INT WORLD WID W
   VUORIMAA P, 2002, P 17 ACM S APPL COMP, P1094
   Zagar D, 2002, ITI 2002: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES, P517, DOI 10.1109/ITI.2002.1024725
NR 25
TC 9
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2006
VL 28
IS 1
BP 51
EP 67
DI 10.1007/s11042-006-5120-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 011ZR
UT WOS:000235308500003
DA 2024-07-18
ER

PT J
AU Bauer, D
   Iliadis, I
   Rooney, S
   Scotton, P
AF Bauer, D
   Iliadis, I
   Rooney, S
   Scotton, P
TI Communication architectures for massive multi-player games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Network and System Support for Games
CY APR 16-17, 2002
CL Braunschweig, GERMANY
DE massive multi-player games; scalability assessment; federated
   peer-to-peer systems; client-server systems
AB Massive multi-player games are characterized by a large number of participating players. It is therefore essential that an appropriate communication architecture is deployed in order to support an ever growing number of players. Several such architectures have been proposed, including client-server and peer-to-peer architectures. In this paper, we propose a systematic method to assess the scalability of different architectures in order to identify the most appropriate one for specific game types. The model proposed is very general in that it covers centralized, distributed, and hybrid architectures and it is applied to the client-server, peer-to-peer and the newly introduced federated peer-to-peer architecture. Quantitative expressions that capture the effect of various game types are derived, and the trade-offs among the architectures are identified.
C1 IBM Res Corp, Zurich Lab, CH-8803 Ruschlikon, Switzerland.
C3 International Business Machines (IBM)
RP Bauer, D (corresponding author), IBM Res Corp, Zurich Lab, Saumerstr 4, CH-8803 Ruschlikon, Switzerland.
OI Iliadis, Ilias/0000-0002-3860-5828; Scotton, Paolo/0000-0003-4737-0108
CR *ANSI IEEE, 1993, STAND INF TECHN PROT
   BANGUN RA, 1997, P 1997 INT C TEL ICT, P93
   BAUER D, 2003, IN PRESS P 5 INT WOR
   Baughman NE, 2001, IEEE INFOCOM SER, P104, DOI 10.1109/INFCOM.2001.916692
   BETTNER P, 2001, 2001 GAM DEV C P SAN
   Diot C, 1999, IEEE NETWORK, V13, P6, DOI 10.1109/65.777437
   LEVINE BN, 2000, P IEEE INFOCOM, V2, P470
   LEVINE D, 2002, MASSIVELY MULTIPLAYE
   MACEDONIA MR, 1995, IEEE COMPUT GRAPH, V15, P38, DOI 10.1109/38.403826
   *OPENSKIES, OPENSKIES NETW ARCH
   ROONEY S, 2004, IN PRESS IEEE CO MAY, V42
   SMED J, 2002, 454 TURK CTR COMP SC
   *SON ONL ENT INC, 2002, EVERQUEST
   ZOU L, 2001, P 9 INT S MOD AN SIM
NR 14
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2004
VL 23
IS 1
BP 47
EP 66
DI 10.1023/B:MTAP.0000026841.97579.1f
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 818LR
UT WOS:000221247100004
DA 2024-07-18
ER

PT J
AU Hui, SC
   Wang, F
AF Hui, SC
   Wang, F
TI Remote video monitoring over the WWW
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE remote video monitoring; web-based monitoring; intelligent monitoring;
   real-time video transmission; world wide web
AB Remote video monitoring has become increasingly important for monitoring the security of destined locations. Traditional security monitoring systems using coaxial cables and VCR recording systems are expensive and ineffective. With the rapid growth of the Internet, it is now possible to use it as an intermediate transmission medium to support real-time video transmission. This paper proposes a web-based remote monitoring system known as iSecure. Apart from the essential live or stored video transmission, intelligent monitoring and web-based monitoring are also supported. As the transmission of live video data through the packet switched network environment of the Internet can result in packet loss and quality degradation, the iSecure system has implemented an adaptive transmission and recovery mechanism to enhance the quality of real-time video transmission. Intelligent monitoring for elevator security and face-based door access control applications has been incorporated. The iSecure system can be used as a framework for developing other intelligent remote monitoring applications.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.
EM asschui@ntu.edu.sg; wangfd@yahoo.com
CR AKITA K, 1984, PATTERN RECOGN, V17, P73, DOI 10.1016/0031-3203(84)90036-0
   Amir E, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P415, DOI 10.1145/266180.266395
   [Anonymous], P IEEE INFOCOM SAN F
   ARAVIND R, 1983, AT&T TECH J, V72, P67
   BOLOT JC, 1998, COMPUT COMMUN REV, V28, P4
   BOLOT JC, 1994, P ACM SIGCOMM 94, V24, P58
   BUSSE L, 1998, COMPUT COMMUN, V19, P49
   *CCITT PLEN ASS, 1990, VID COD AUD SERV PX6
   Comer D.E., 1995, INTERNETWORKING TCP, V1
   FELTEN E, 1997, UNDERSTANDING KEYS J
   GAO Y, 1999, AUTOID 99 P WORKSH A, P173
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Haritaoglu I, 1998, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1998.711084
   *INT TECHN, 1999, 1 LIN DIG SURV DXV C
   JAIN R, 1981, IEEE T PATTERN ANAL, V3, P489, DOI 10.1109/TPAMI.1981.4767143
   JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907
   LEUNG MK, 1995, IEEE T PATTERN ANAL, V17, P359, DOI 10.1109/34.385981
   MICHAEL B, 1999, SECURITY WORLD   SEP, P25
   *MPEG, 2001, MPEG STAND
   *MPEG, 2001, MPEG4
   OATMAN B, 2001, SPYCAM
   Pankanti S, 2000, COMPUTER, V33, P46, DOI 10.1109/2.820038
   Pentland A, 2000, COMPUTER, V33, P50, DOI 10.1109/2.820039
   RHEE I, 1998, P ACM SIGCOMM 98 C A, P290
   Schulzrinne H., 1996, Rtp: a transport protocol for real-time applications
   Se Hyun Park, 1999, Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300), P201, DOI 10.1109/ICCIMA.1999.798529
   *SIGN COMM LTD, 2001, TEL PROPH LIN CCTV S
   *SURV CORP, 2001, WEBCAM32
   *SYAC CO, 2001, DIGIEYE MULT DIG CCT
   Turletti T, 1996, IEEE ACM T NETWORK, V4, P340, DOI 10.1109/90.502233
   *U ULM, 2001, WEB MED
   *VER INC, 2001, VER
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   XIAO P, 1999, THESIS NANYANG TECHN
NR 34
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2003
VL 21
IS 2
BP 173
EP 195
DI 10.1023/A:1025520709481
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 718BJ
UT WOS:000185125000004
DA 2024-07-18
ER

PT J
AU Fung, CW
   Leung, EWC
   Li, Q
AF Fung, CW
   Leung, EWC
   Li, Q
TI Efficient query execution techniques in a 4DIS video database system for
   eLearning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia eLearning video database system; four-dimensional information
   space (4DIS); temporal semantics; vertical class partitioning
ID MANAGEMENT
AB In this paper, we describe our work on developing an eLearning video database system. The eLearning video database provides a temporal modeling framework for describing eLearning video data and it supports data distribution by applying vertical class partitioning techniques. Building on top of our previous work on Four Dimensional Information System (4DIS)-an object-oriented temporal modeling framework, we apply vertical class partitioning techniques onto a 4DIS eLearning video database system as a means for efficient query execution. We further describe our work on dynamic fetching of multimedia eLearning video on the Internet. A detailed cost model for query execution through vertical class partitioning is developed. Finally, we demonstrate through the use of a running example the effectiveness of our vertical class partitioning approach.
C1 Vocat Training Council, Dept Informat & Commun Technol, HK Inst Vocat Educ Tuen Mun, Hong Kong, Hong Kong, Peoples R China.
   City Univ Hong Kong, Dept Comp Engn & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Vocat Training Council, Dept Informat & Commun Technol, HK Inst Vocat Educ Tuen Mun, Tsing Wun Rd, Hong Kong, Hong Kong, Peoples R China.
EM cwfung@vtc.edu.hk; iteleung@cityu.edu.hk; itqli@cityu.edu.hk
RI Li, Qing/JMH-1365-2023
OI Li, Qing/0000-0003-3370-471X
CR AFSARMANESH H, 1989, ACM T INFORM SYST, V7, P339, DOI 10.1145/76158.76892
   ALESSI HP, 2000, E VIDEO PRODUCING IN
   Bertino E., 1989, IEEE Transactions on Knowledge and Data Engineering, V1, P196, DOI 10.1109/69.87960
   Bordawekar R., 1993, Proceedings SUPERCOMPUTING '93, P452, DOI 10.1145/169627.169782
   BRADLEY K, 2000, ADAPTIVE HYPERMEDIA, P63
   Cattell R., 1994, OBJECT DATABASE STAN
   CHAN S, 2000, P IEEE INT C MULT EX
   Chan SSM, 1999, LECT NOTES COMPUT SC, V1728, P47
   CHENG C, 1999, THESIS HONG KONG POL
   Chim JHP, 1998, P IEEE INT FORUM RES, P66, DOI 10.1109/ADL.1998.670381
   CHOY M, 2000, J DATABASE MANAGE, V11, P3
   CORNELL D, 1987, P DATA ENG
   EZEIFE CI, 1998, J DISTRIBUTED PARALL, V6, P327
   FUNG CW, 1998, THESIS HONG KONG U S
   FUNG CW, 1997, P 5 INT C DAT SYST A, P11
   GARDARIN G, 1995, P 21 INT C VER LARG, P323
   Jonassen D. H., 1995, Educational Technology, V35, P60
   KARLAPALEM K, 2000, J DISTRIBUTED PARALL, V8, P317
   KARLAPALEM K, 1996, P INT C DISTR COMP S
   KARLAPALEM K, 1994, DISTRIBUTED OBJECT M, P148
   Karlaplem K., 1995, Proceedings RIDE-DOM '95. Fifth International Workshop on Research Issues in Data Engineering-Distributed Object Management (Cat.No.95TH8039), P42, DOI 10.1109/RIDE.1995.378746
   KEMPER A, 1990, SIGMOD REC, V19, P364, DOI 10.1145/93605.98745
   LAU RWH, 1998, LNCS, P60
   LAWTON G, 2000, COMPUTER, V33
   LESSER VR, 1999, IEEE T KNOWLEDGE DAT, V11
   Leung EWC, 2001, LECT NOTES COMPUT SC, V2105, P341
   NAVATHE S, 1984, ACM T DATABASE SYST, V9, P680, DOI 10.1145/1994.2209
   OZSOYOGLU G, 1995, IEEE T KNOWL DATA EN, V7, P513, DOI 10.1109/69.404027
   Patterson D. A., 1988, SIGMOD Record, V17, P109, DOI 10.1145/971701.50214
   Si A, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, pA492
   Si A., 1996, Proceedings First IFCIS International Conference on Cooperative Information Systems, P68, DOI 10.1109/COOPIS.1996.554999
   SI A, 2001, J APPL SYSTEMS STUDI, V2
   SI A, 1998, P ACM S APPL COMP MU, P525
   SI A, 1998, P ACM S APPL COMP DA, P203
   SU S, 1991, P VLDB 91
   Tansel A., 1993, DATABASE SYSTEMS APP
NR 36
TC 3
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2003
VL 20
IS 1
BP 25
EP 49
DI 10.1023/A:1023418316038
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 671JW
UT WOS:000182462500003
DA 2024-07-18
ER

PT J
AU Zhao, YX
   Han, JS
   Hu, XL
   Hu, B
   Zhu, H
   Wang, YL
   Zhu, XL
AF Zhao, Yuxue
   Han, Jiashu
   Hu, Xinlin
   Hu, Bo
   Zhu, Hui
   Wang, Yanlong
   Zhu, Xiuli
TI Hypertension risk prediction models for patients with diabetes based on
   machine learning approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hypertension; Diabetes; Machine learning; Prediction model
ID BLOOD-PRESSURE; OBESITY
AB To construct effective prediction models for hypertension in diabetic patients based on machine learning. This study used electronic data from 2080 diabetic patients attending the specialized outpatient clinic for metabolic diseases of the Affiliated Hospital of Qingdao University from March 2017 to July 2020. We adopted 5 machine learning algorithms (artificial neural network, decision tree, random forest, support vector machine, Bayesian network) and constructed hypertension risk prediction models based on patients' non-invasive variables. The study showed that artificial neural network (ANN) performed best, accuracy, sensitivity, specificity, and area under the receiver curve in the test set were 92.47%, 92.98%, 92.02%, 0.951, respectively. The prediction model showed that the top three predictors and their weight values were systolic blood pressure (w=0.3346), age (w=0.1437) and diastolic blood pressure (w=0.1236). Factors of daily living such as education level, activity, heart rate and fish intake also showed importance. ANN can apply non-invasive data to well predict the risk of secondary hypertension in diabetic patients. Healthcare providers could use this model to rapidly screen high-risk patients and instruct them to monitor blood pressure regularly and maintain a healthy lifestyle, thereby reducing the risk of hypertension in diabetic patients. The model is more suitable for areas with high morbidity of hypertension and poor socioeconomic conditions. It has important implications for achieving health management in a larger target population, in line with the international mission to improve the global burden of hypertension.
C1 [Zhao, Yuxue; Zhu, Xiuli] Qingdao Univ, Sch Nursing, Dept Med, 15 Ningde Rd, Qingdao 266073, Peoples R China.
   [Han, Jiashu] Northeastern Univ, Khoury Coll Comp Sci, Grad Sch, Boston, MA USA.
   [Hu, Xinlin] Qingdao Univ, Affiliated Hosp, Dept Endocrinol & Metab, Qingdao 266003, Peoples R China.
   [Hu, Bo] Qingdao Municipal Hosp, Dept Thorac Surg, Qingdao, Peoples R China.
   [Zhu, Hui] Qingdao Univ, Dept Oncol Radiotherapy, Affiliated Hosp, Qingdao, Peoples R China.
   [Wang, Yanlong] Qingdao Univ, Sch Automat, Qingdao, Peoples R China.
C3 Qingdao University; Northeastern University; Qingdao University; Qingdao
   Municipal Hospital; Qingdao University; Qingdao University
RP Zhu, XL (corresponding author), Qingdao Univ, Sch Nursing, Dept Med, 15 Ningde Rd, Qingdao 266073, Peoples R China.
EM 15820022927@163.com
OI xiu li, zhu/0000-0003-3533-8581
FU Humanities and Social Sciences Research Project of the Ministry of
   Education of China
FX No Statement Available
CR Carson AP, 2013, HYPERTENSION, V62, P1015, DOI 10.1161/HYPERTENSIONAHA.113.01539
   Chaudhary GMD, 2019, CUREUS J MED SCIENCE, V11, DOI 10.7759/cureus.4592
   Chen Y, 2016, J HUM HYPERTENS, V30, P794, DOI 10.1038/jhh.2016.23
   Churpek MM, 2016, CRIT CARE MED, V44, P368, DOI 10.1097/CCM.0000000000001571
   Dinh A, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0918-5
   Du ML, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3279-3
   Echouffo-Tcheugui JB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067370
   Farran B, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2012-002457
   Gebrihet TA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176904
   Guariguata L, 2014, DIABETES RES CLIN PR, V103, P137, DOI 10.1016/j.diabres.2013.11.002
   Harreiter J, 2019, WIEN KLIN WOCHENSCHR, V131, P6, DOI 10.1007/s00508-019-1450-4
   Heo BM, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15112571
   Hong Yhj, 2017, Malays Fam Physician, V12, P18
   Igarashi R, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000004564
   Kahn SE, 2006, NATURE, V444, P840, DOI 10.1038/nature05482
   Katayama S, 2018, HYPERTENS RES, V41, P213, DOI 10.1038/s41440-017-0001-5
   Kengne AP, 2007, J HYPERTENS, V25, P1205
   Lin CC, 2021, J CLIN HYPERTENS, V23, P1570, DOI 10.1111/jch.14322
   Loef M, 2012, PREV MED, V55, P163, DOI 10.1016/j.ypmed.2012.06.017
   Molla GJ, 2020, CAN J DIABETES, V44, P246, DOI 10.1016/j.jcjd.2019.07.002
   Ozemek C, 2018, CURR OPIN CARDIOL, V33, P388, DOI 10.1097/HCO.0000000000000532
   Ozemek C, 2017, CURR OPIN CARDIOL, V32, P381, DOI 10.1097/HCO.0000000000000406
   Petrie JR, 2018, CAN J CARDIOL, V34, P575, DOI 10.1016/j.cjca.2017.12.005
   Ren ZG, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64980-8
   Saheera S, 2020, CELL TRANSPLANT, V29, DOI 10.1177/0963689720920830
   Saladini F, 2016, VASC MED, V21, P422, DOI 10.1177/1358863X16647509
   Shrestha Badri, 2020, J Nepal Health Res Counc, V17, P548, DOI 10.33314/jnhrc.v17i4.1042
   Suh Dong-Churl, 2009, J Hypertens, V27, P1908, DOI 10.1097/HJH.0b013e32832d4aee
   Tatsumi Y, 2017, HYPERTENS RES, V40, P795, DOI 10.1038/hr.2017.67
   Unger T, 2020, J HYPERTENS, V38, P982, DOI [10.1097/HJH.0000000000002453, 10.1161/HYPERTENSIONAHA.120.15026]
   Wan EYF, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-15579-z
   Wang GJ, 2017, AM J PREV MED, V53, pS182, DOI 10.1016/j.amepre.2017.07.018
   Wu XY, 2020, HYPERTENSION, V75, P1271, DOI 10.1161/HYPERTENSIONAHA.119.13404
   Xu F, 2019, J GLOB HEALTH, V9, DOI 10.7189/jogh.09.020601
   Ye CY, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9268
   Zhang BZ, 2015, BREASTFEED MED, V10, P163, DOI 10.1089/bfm.2014.0116
   Zhang YL, 2016, BMC HEALTH SERV RES, V16, DOI 10.1186/s12913-016-1536-x
   Zhao Y, 2020, BRIT J NUTR, V123, P583, DOI 10.1017/S0007114519003143
   Zhu JJ, 2018, AM J EPIDEMIOL, V187, P2372, DOI 10.1093/aje/kwy156
   Zhu NB, 2019, INT J BEHAV NUTR PHY, V16, DOI 10.1186/s12966-019-0860-z
NR 40
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17926-x
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200007
DA 2024-07-18
ER

PT J
AU Brunnström, K
   Djupsjöbacka, A
   Billingham, J
   Wistel, K
   Andrén, B
   Ozolins, O
   Evans, N
AF Brunnstrom, Kjell
   Djupsjobacka, Anders
   Billingham, Johsan
   Wistel, Katharina
   Andren, Borje
   Ozolins, Oskars
   Evans, Nicolas
TI Video expert assessment of high quality video for Video Assistant
   Referee (VAR): A comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Contribution; Football; HDTV; PSNR; SSIM; Subjective and objective video
   quality; Video Assistant Referee (VAR); Video quality; VIF; VMAF; VQM
   General; VQM_VFD
AB The International Football Association Board decided to introduce Video Assistant Referee (VAR) in 2018. This led to the need to develop methods for quality control of the VAR-systems. This article focuses on the important aspect to evaluate the video quality. Video Quality assessment has matured in the sense that there are standardized, commercial products and established open-source solutions to measure it with objective methods. Previous research has primarily focused on the end-user quality assessment. How to assess the video in the contribution phase of the chain is less studied. The novelties of this study are two-fold: 1) The user study is specifically targeting video experts i.e., to assess the perceived quality of video professionals working with video production. 2) Six video quality models have been independently benchmarked against the user data and evaluated to show which of the models could provide the best predictions of perceived quality. The independent evaluation is important to get unbiased results as shown by the Video Quality Experts Group. An experiment was performed involving 25 video experts in which they rated the perceived quality. The video formats tested were High-Definition TV both progressive and interlaced as well as a quarters size format that was scaled down half the size in both width and height. The videos were encoded with both H.264 and Motion JPEG for the full size but only H.264 for the quarter size. Bitrates ranged from 80 Mbit/s down to 10 Mbit/s. We could see that for H.264 that the quality was overall very good but dropped somewhat for 10 Mbit/s. For Motion JPEG the quality dropped over the whole range. For the interlaced format the degradation that was based on a simple deinterlacing method did receive overall low ratings. For the quarter size three different scaling algorithms were evaluated. Lanczos performed the best and Bilinear the worst. The performance of six different video quality models were evaluated for 1080p and 1080i. The Video Quality Metric for Variable Frame Delay had the best performance for both formats, followed by Video Multimethod Assessment Fusion method and the Video Quality Metric General model.
C1 [Brunnstrom, Kjell; Djupsjobacka, Anders; Andren, Borje; Ozolins, Oskars] RISE Res Inst Sweden AB, Stockholm, Sweden.
   [Brunnstrom, Kjell] Mid Sweden Univ, Sundsvall, Sweden.
   [Billingham, Johsan; Wistel, Katharina; Evans, Nicolas] Federat Internatl Football Assoc FIFA, Football Technol Innovat Subdiv, Zurich, Switzerland.
C3 RISE Research Institutes of Sweden; Mid-Sweden University
RP Brunnström, K (corresponding author), RISE Res Inst Sweden AB, Stockholm, Sweden.; Brunnström, K (corresponding author), Mid Sweden Univ, Sundsvall, Sweden.
EM kjell.brunnstrom@ri.se
OI Ozolins, Oskars/0000-0001-9839-7488
FU RISE Research Institutes of Sweden; Federation Internationale de
   Football Association (FIFA); Sweden's innovation agency VINNOVA
   [2021-02107]; RISE; Swedish Research Council [2021-02107] Funding
   Source: Swedish Research Council
FX Open access funding provided by RISE Research Institutes of Sweden. This
   project was funded by Federation Internationale de Football Association
   (FIFA), Sweden's innovation agency VINNOVA (grant nr 2021-02107) and
   internal funding by RISE
CR [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 2008, FINAL REPORT VIDEO Q
   Apple Inc, 2008, Shake: Advanced digital composition
   Barkowsky M, 2012, P 3 WORKSH QUAL EXP
   Berger K, 2015, INT WORK QUAL MULTIM
   Brunnstrom Kjell, 2009, IEEE Signal Processing Magazine, V26, P96, DOI 10.1109/MSP.2009.932162
   Brunnstrom K., 2012, Tech. Rep. Version 1.2, V3, P1
   Brunnstrom K, 2014, VQEGPlayer: open source software for subjective video quality experiments in windows
   Brunnström K, 2023, SPORTS ENG, V26, DOI 10.1007/s12283-023-00408-6
   Brunnström K, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053013
   Cheon M, 2018, IEEE T CIRC SYST VID, V28, P1467, DOI 10.1109/TCSVT.2017.2683504
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Daubechies, 1992, 10 LECT WAVELETS
   De Simone F, 2010, INT CONF ACOUST SPEE, P2430, DOI 10.1109/ICASSP.2010.5496296
   De Simone F, 2009, INT WORK QUAL MULTIM, P204, DOI 10.1109/QOMEX.2009.5246952
   EBU, 2011, Signal Quality in HDTV Production and Broadcast Services (Recommendation R132)
   FFMPEG, 2023, FFMPEG: complete, cross-platform solution to record, convert and stream audio and video
   Haglund L., 2006, SVT HIGH DEFINITION
   Hanhart P, 2013, VQMT: Video Quality Measurement Tool
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hossfeld T, 2011, INT WORK QUAL MULTIM, P131, DOI 10.1109/QoMEX.2011.6065690
   Huynh-Thu Q, 2005, Seventh IASTED International Conference on Signal and Image Processing, P70
   ITU-R, 2015, Rec. ITU-R BT.709-6
   ITU-R, 2023, ITU-R Rec. BT.500-15)
   ITU-T, 2016, ITU-T Rec. J.341
   ITU-T, 2016, ITU-T Rec. H.265)
   ITU-T, 2021, ITU-T Rec. P.913
   ITU-T, 2008, ITU-T Rec. P.910
   ITU-T, 2004, ITU-T Rec. J.144
   ITU-T, 2017, ITU-TRec.P.10/G.100
   ITU-T, 2020, Statistical analysis, evaluation and reporting guidelines of quality measurements (ITU-T P.1401)
   ITU-T, 2021, H.264: Advanced video coding for generic audiovisual services (ITU-T Rec. H.264)
   ITU-T, 2010, ITU-T Rec. J.340)
   Lee C, 2006, PROC SPIE, V6059, DOI 10.1117/12.651056
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   최지환, 2007, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V12, P177
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Liu TJ, 2013, APSIPA TRANS SIGNAL, V2, DOI 10.1017/ATSIP.2013.5
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Matlab, 2006, corr -Linear or rank correlation
   Maxwell S. E., 2003, DESIGNING EXPT ANAL, DOI [DOI 10.4324/9781410609243, 10.4324/9781410609243]
   Pinson M, 2019, VQM-Video Quality Metric
   Pinson MH, 2023, IEEE T BROADCAST, V69, P97, DOI 10.1109/TBC.2022.3191059
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Pitrey Y, 2010, EUR ITV TAMP FINL
   Raake A, 2020, IEEE ACCESS, V8, P193020, DOI 10.1109/ACCESS.2020.3032080
   Rao RRR, 2019, IEEE INT SYM MULTIM, P17, DOI [10.1109/ism46123.2019.00012, 10.1109/ISM46123.2019.00012]
   Rezaee Khosro, 2024, Personal and Ubiquitous Computing, V28, P135, DOI 10.1007/s00779-021-01586-5
   Sedano I, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-4
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shahid M, 2014, Methods for objective and subjective video quality assessment and for speech enhancement
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Speranza Filippo, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P46, DOI 10.1109/QOMEX.2010.5518177
   Suiyi Ling, 2020, QoEVMA'20: Proceedings of the 1st Workshop on Quality of Experience (QoE) in Visual Multimedia Applications, P3, DOI 10.1145/3423328.3423496
   Tominaga Toshiko, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P82, DOI 10.1109/QOMEX.2010.5517948
   VQEG, 2009, Validation of reduced-reference and no-reference objective models for standard definition television, phase I
   VQEG, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment
   VQEG, 2010, Report on the validation of video quality models for high definition video content
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wikipedia, 2023, Shake (software)
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wolf S., 2011, NTIA Technical Memorandum TM-11-482
   Wulf S, 2012, 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS'2012)
NR 67
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17741-4
EA DEC 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE0M1
UT WOS:001130236200002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dandge, SS
   Harshavardhanan, P
AF Dandge, Sangram Sanjayrao
   Harshavardhanan, Pon
TI An efficient covid-19 prediction using Penguin Pelican
   optimization-based recurrent dropout-enabled hybrid deep CNN-BILSTM
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Covid-19 prediction; Penguin pelican optimization; Recurrent dropout;
   Hybrid deep CNN-BiLSTM; And deep learning
AB Problem statementThe global COVID-19 pandemic has had devastating consequences, emphasizing the need for swift and reliable coronavirus patient detection to enhance treatment and reduce transmission.MethodologyThe extracted features are fed into a hybrid deep classifier that combines Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (BiLSTM) layers. The recurrent dropout technique is employed within the BiLSTM layer as a regularization method to prevent overfitting. This architecture leverages the strength of CNNs in feature extraction and the sequential memory handling of BiLSTMs. The research introduces a specialized optimization algorithm, the Penguin Pelican Optimizer (PPO), which is a fusion of characteristics from the Emperor penguin optimizer and the Pelican Optimization algorithm. This algorithm is designed to fine-tune and enhance the efficiency of the system by optimizing model parameters, weights, and biases.ResultsThe findings of this study are highly encouraging. The proposed Penguin Pelican Optimization-based recurrent dropout-enabled hybrid deep CNN-BILSTM approach achieved remarkable results, with accuracy rates of 95.57%, 96.08%, and 95.54% for training percentage, and 95.75%, 96.28%, and 95.70% for k-fold. These outcomes surpass the performance of existing methods. This research underscores the practicality and efficiency of the developed methodology for COVID-19 prediction. It offers valuable insights that can be instrumental in ensuring timely and accurate patient management, thus contributing significantly to the global effort to combat the pandemic.ConclusionThis research underscores the effectiveness and efficiency of the developed approach for COVID-19 prediction, providing valuable insights for improved patient management in the battle against the pandemic.
C1 [Dandge, Sangram Sanjayrao; Harshavardhanan, Pon] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
C3 VIT Bhopal University
RP Dandge, SS (corresponding author), VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
EM sangram.dandge2019@vitbhopal.ac.in
CR Awal MA, 2021, IEEE ACCESS, V9, P10263, DOI 10.1109/ACCESS.2021.3050852
   Babukarthik RG, 2020, IEEE ACCESS, V8, P177647, DOI 10.1109/ACCESS.2020.3025164
   BUNN D, 1991, MANAGE SCI, V37, P501, DOI 10.1287/mnsc.37.5.501
   Chen N, 2023, PHYSICA D, V449, DOI 10.1016/j.physd.2023.133743
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Doo EY, 2021, J CLIN NURS, V30, P1990, DOI 10.1111/jocn.15752
   FILDES R, 1992, INT J FORECASTING, V8, P81, DOI 10.1016/0169-2070(92)90009-X
   Grinshpun SA, 2010, AEROSOL AIR QUAL RES, V10, P414, DOI 10.4209/aaqr.2010.04.0041
   Guan W, 2020, NEW ENGL J MED, V382, P1708, DOI 10.1056/NEJMoa2002032
   Guarrasi V, 2023, COMPUT BIOL MED, V154, DOI 10.1016/j.compbiomed.2023.106625
   Guo HF, 2017, Arxiv, DOI arXiv:1703.04247
   He X, 2020, medRxiv, V2020, P2020
   Huang CJ, 2022, SOCIO-ECON PLAN SCI, V80, DOI 10.1016/j.seps.2020.100976
   Jacobi A, 2020, CLIN IMAG, V64, P35, DOI 10.1016/j.clinimag.2020.04.001
   Kanne JP, 2020, RADIOLOGY, V296, pE113, DOI 10.1148/radiol.2020200527
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Musher DM, 2014, NEW ENGL J MED, V371, P1619, DOI 10.1056/NEJMra1312885
   ncov-ai.big, AI Diagnosis dataset
   Punn N.S., 2020, COVID 19 EPIDEMIC AN, DOI [10.1101/2020.04.08.20057679, DOI 10.1101/2020.04.08.20057679]
   Rajaraman S, 2020, medRxiv, P2020
   Rajaraman Sivaramakrishnan, 2020, medRxiv, DOI 10.1101/2020.05.04.20090803
   Ramchandani A, 2020, IEEE ACCESS, V8, P159915, DOI 10.1109/ACCESS.2020.3019989
   Roy PK, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108018
   Shan F, 2020, Arxiv, DOI arXiv:2003.04655
   Solayman Sanzida, 2023, International Journal of Cognitive Computing in Engineering, V4, P36, DOI [10.1016/j.ijcce.2023.01.003, DOI 10.1016/J.IJCCE.2023.01.003]
   Song YC, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104735
   Tolksdorf K, 2020, EUROSURVEILLANCE, V25, P7, DOI 10.2807/1560-7917.ES.2020.25.11.2000258
   Trojovsky P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030855
   Ukwuoma CC, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101596
   Ukwuoma CC, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106195
   Xiao B, 2022, IEEE T CYBERNETICS, V52, P12163, DOI 10.1109/TCYB.2020.3042837
   Zhou LY, 2023, ENG APPL ARTIF INTEL, V122, DOI 10.1016/j.engappai.2023.106157
NR 33
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17869-3
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE0M1
UT WOS:001130236200003
DA 2024-07-18
ER

PT J
AU Jebur, RS
   Zabil, MHB
   Hammood, DA
   Cheng, LK
AF Jebur, Rusul Sabah
   Zabil, Mohd Hazli Bin Mohamed
   Hammood, Dalal Adulmohsin
   Cheng, Lim Kok
TI A comprehensive review of image denoising in deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Image denoising; Deep learning; Blind denoising; Salt and pepper noise;
   Hybrid noisy images
ID NEURAL-NETWORK; NOISE; ALGORITHM; RESONANCE; SALT
AB Deep learning has gained significant interest in image denoising, but there are notable distinctions in the types of deep learning methods used. Discriminative learning is suitable for handling Gaussian noise, while optimization models are effective in estimating real noise. However, there is limited research that summarizes the different deep learning techniques for image denoising. This paper conducts a comprehensive review of techniques and methods used for image denoising and identifying challenges associated with existing approaches. In this paper, a comparative study of deep techniques is offered in image denoising. The study conducted a comprehensive review of 68 papers on image denoising published between 2018 and 2023, providing a detailed analysis of the field's progress and methodologies over a period of 5 years. Through its literature review, the paper provides a comprehensive summary of image denoising in deep learning, including machine learning methods for image denoising, CNNs for image denoising, additive white noisy-image denoising, real noisy image denoising, blind denoising, hybrid noisy images, state- of-the-art methods for image denoising with deep learning, salt and pepper noise, non-linear filters for digital color images. The main objective of this paper is to provide a comprehensive overview of various approaches used for image denoising, each of which has been explored and developed based on individual research studies. The paper aims to discuss these approaches in a systematic and organized manner, comparing their strengths and weaknesses to provide insights for future research in the field.
C1 [Jebur, Rusul Sabah] UniTeN, Fac Informat & Commun Technol, Kuala Lumpur, Malaysia.
   [Zabil, Mohd Hazli Bin Mohamed; Cheng, Lim Kok] Univ Tenaga Natl UniTeN, Dept Comp, Coll Comp & Informat, Kuala Lumpur, Malaysia.
   [Hammood, Dalal Adulmohsin] Middle Tech Univ MTU, Elect Engn Tech Coll, Baghdad 10022, Iraq.
RP Jebur, RS (corresponding author), UniTeN, Fac Informat & Commun Technol, Kuala Lumpur, Malaysia.
EM rusolsabah85@gmail.com
CR Abubakar A, 2020, IEEE ACCESS, V8, P57451, DOI 10.1109/ACCESS.2020.2982535
   Akinlar MA, 2020, CHAOS SOLITON FRACT, V137, DOI 10.1016/j.chaos.2020.109840
   Awad A, 2019, ENG SCI TECHNOL, V22, P746, DOI 10.1016/j.jestch.2019.01.012
   Bayhaqi YA, 2022, IEEE T MED IMAGING, V41, P2615, DOI 10.1109/TMI.2022.3168793
   Chen C, 2020, IEEE T PATTERN ANAL, V42, P3071, DOI 10.1109/TPAMI.2019.2921548
   Chen JB, 2018, PROBABILIST ENG MECH, V53, P1, DOI 10.1016/j.probengmech.2018.03.002
   Chen JQ, 2019, IEEE ACCESS, V7, P124647, DOI 10.1109/ACCESS.2019.2938799
   Cui JN, 2019, EUR J NUCL MED MOL I, V46, P2780, DOI 10.1007/s00259-019-04468-4
   Thanh DNH, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.163677
   Das Khakon, 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P131, DOI 10.1007/978-981-10-8863-6_14
   Davy A, 2019, IEEE IMAGE PROC, P2409, DOI [10.1109/icip.2019.8803314, 10.1109/ICIP.2019.8803314]
   Dytso A, 2019, IEEE SIGNAL PROC LET, V26, P1325, DOI 10.1109/LSP.2019.2929863
   El Helou M, 2020, IEEE T IMAGE PROCESS, V29, P4885, DOI 10.1109/TIP.2020.2976814
   Fu B, 2022, GENE EXPR PATTERNS, V45, DOI 10.1016/j.gep.2022.119270
   Fu B, 2023, SIGNAL IMAGE VIDEO P, V17, P573, DOI 10.1007/s11760-022-02262-8
   Fu B, 2022, J X-RAY SCI TECHNOL, V30, P531, DOI 10.3233/XST-211098
   Fu B, 2022, INT J IMAG SYST TECH, V32, P144, DOI 10.1002/ima.22658
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P12043, DOI 10.1007/s11042-018-6732-8
   Goncharova Anna S., 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P380, DOI 10.1007/978-3-030-66415-2_25
   Gondara Lovedeep, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10939, P260, DOI 10.1007/978-3-319-93040-4_21
   Gupta Aditi, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P13, DOI 10.1007/978-981-13-3393-4_2
   Gurrola-Ramos J, 2021, IEEE ACCESS, V9, P31742, DOI 10.1109/ACCESS.2021.3061062
   Hashimoto F, 2019, IEEE ACCESS, V7, P96594, DOI 10.1109/ACCESS.2019.2929230
   Holla KS, 2023, IEEE ACCESS, V11, P9613, DOI 10.1109/ACCESS.2023.3239835
   Jin Y, 2020, IEEE COMMUN LETT, V24, P95, DOI 10.1109/LCOMM.2019.2952845
   Kaur C, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102337
   Kaur M, 2021, OPTIK, V244, DOI 10.1016/j.ijleo.2021.167564
   Golbaghi FK, 2020, IRAN J SCI TECHNOL A, V44, P1803, DOI 10.1007/s40995-020-00977-2
   Khmag A, 2018, VISUAL COMPUT, V34, P575, DOI 10.1007/s00371-017-1362-0
   Lan RS, 2021, SIGNAL IMAGE VIDEO P, V15, P1, DOI 10.1007/s11760-019-01537-x
   Lee SE, 2022, IEEE ACCESS, V10, P122286, DOI 10.1109/ACCESS.2022.3222826
   Li Z, 2023, IEEE ACCESS, V11, P11923, DOI 10.1109/ACCESS.2023.3242050
   Liang LM, 2021, NEUROCOMPUTING, V442, P26, DOI 10.1016/j.neucom.2021.02.010
   Liu P, 2019, MED IMAGE ANAL, V54, P306, DOI 10.1016/j.media.2019.03.004
   Manjón JV, 2018, LECT NOTES COMPUT SC, V11075, P12, DOI 10.1007/978-3-030-00500-9_2
   Manju B. R., 2020, Procedia Computer Science, V171, P273, DOI 10.1016/j.procs.2020.04.029
   Meng YZ, 2022, IEEE ACCESS, V10, P49657, DOI 10.1109/ACCESS.2022.3169131
   Nourani V, 2018, STOCH ENV RES RISK A, V32, P545, DOI 10.1007/s00477-017-1400-5
   Park HS, 2019, IEEE ACCESS, V7, P110414, DOI 10.1109/ACCESS.2019.2934178
   Punarselvam E, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1148-6
   Randhawa SK, 2019, MULTIDIM SYST SIGN P, V30, P1545, DOI 10.1007/s11045-018-0616-y
   Rawat S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102859
   Routray S, 2018, OPTIK, V157, P503, DOI 10.1016/j.ijleo.2017.11.116
   Sereethavekul W, 2023, IEEE ACCESS, V11, P26667, DOI 10.1109/ACCESS.2023.3255641
   Shi PM, 2018, CHAOS SOLITON FRACT, V108, P8, DOI 10.1016/j.chaos.2018.01.022
   Shin YH, 2020, IEEE ACCESS, V8, P66898, DOI 10.1109/ACCESS.2020.2986827
   Shipeng Zhu, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11858), P241, DOI 10.1007/978-3-030-31723-2_21
   Song YD, 2020, IEEE SIGNAL PROC LET, V27, P2124, DOI 10.1109/LSP.2020.3039726
   Soverini U, 2020, AUTOMATICA, V115, DOI 10.1016/j.automatica.2020.108879
   Sun H, 2021, IEEE ACCESS, V9, P52378, DOI 10.1109/ACCESS.2021.3069236
   Tassano M, 2019, IEEE IMAGE PROC, P1805, DOI [10.1109/ICIP.2019.8803136, 10.1109/icip.2019.8803136]
   Thanh DNH, 2019, IEEE RIVF INT CONF, P261, DOI 10.1109/rivf.2019.8713669
   Thanh DNH, 2020, MULTIMED TOOLS APPL, V79, P21013, DOI 10.1007/s11042-020-08887-6
   Tian M, 2021, IEEE ACCESS, V9, P62266, DOI 10.1109/ACCESS.2021.3073944
   Tsoutsanis P, 2018, J COMPUT PHYS, V362, P69, DOI 10.1016/j.jcp.2018.02.009
   Vo DM, 2021, INFORM SCIENCES, V570, P225, DOI 10.1016/j.ins.2021.04.045
   Wang FQ, 2020, IEEE T IMAGE PROCESS, V29, P1246, DOI 10.1109/TIP.2019.2940496
   Wang GH, 2018, OPTIK, V173, P157, DOI 10.1016/j.ijleo.2018.08.013
   Wang XW, 2020, IEEE ACCESS, V8, P127622, DOI 10.1109/ACCESS.2020.3008324
   Xu J, 2018, IEEE T IMAGE PROCESS, V27, P2996, DOI 10.1109/TIP.2018.2811546
   Yuan Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3095488
   Zhang D, 2023, IEEE ACCESS, V11, P14340, DOI 10.1109/ACCESS.2023.3243829
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang Q, 2023, CAAI T INTELL TECHNO, V8, P331, DOI 10.1049/cit2.12110
   Zhang XY, 2020, IEEE ACCESS, V8, P104728, DOI 10.1109/ACCESS.2020.2999965
   Zhao Y., 2019, 2019 IEEE VISUAL COM
   Zhu QH, 2016, IEEE ACCESS, V4, P2096, DOI 10.1109/ACCESS.2016.2549546
   Zin T, 2022, IEEE ACCESS, V10, P22420, DOI 10.1109/ACCESS.2022.3152219
NR 68
TC 0
Z9 0
U1 58
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17468-2
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR5X2
UT WOS:001126994000003
DA 2024-07-18
ER

PT J
AU Wu, P
   Wang, C
   Wang, JX
   Wang, YZ
AF Wu, Peng
   Wang, Chen
   Wang, Junxiao
   Wang, Yuanzhi
TI Anchor-free object detection network based on non-local operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object detection; Anchor-free detection; Non-local operation; Keypoints
AB Keypoint detector has achieved satisfactory performance in facial recognition and computer vision-related fields. However, convolutional neural network are somewhat limited for capturing global information, which greatly affects the performance of the detector. This paper proposes an efficient solution which obtains additional global information at a minimal costs. The framework is built upon a representative one-stage keypoint-based detector named CenterNet. The global keypoint network(GKPNet) approach forms a larger receptive field by using non-local modules to obtain more information than stacking multiple convolution modules. Feature pyramid network(FPN) was improved to extract multi-scale information and fuse low-level detail information to enhance the detection of small objects. The proposed approach is efficient and achieve 80.3% average precision on the Pascal VOC validation dataset, thus outperforms the CenterNet detector at least 1.6%. With a higher inference speed, GKPNet demonstrates performance comparable to that of the two-stage detectors and thereby provides a further avenue for anchor-free object detection.
C1 [Wu, Peng; Wang, Chen; Wang, Junxiao] Zhejiang Sci Tech Univ, Sch Mech Engn, 2nd St, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Yuanzhi] Anqing Normal Univ, Sch Comp & Informat, Linghu South Rd, Anqing 246011, Anhui, Peoples R China.
C3 Zhejiang Sci-Tech University; Anqing Normal University
RP Wang, YZ (corresponding author), Anqing Normal Univ, Sch Comp & Informat, Linghu South Rd, Anqing 246011, Anhui, Peoples R China.
EM wangyuanzhi1@sohu.com
RI Yan, Lu/KHW-7015-2024
FU Natural Science Foundation of Zhejiang Province [No.LY21F010016];
   Natural Science Foundation of Zhejiang Province; National Key Research
   and Development Program of China [No.19022397-Y]; Science Foundation of
   Zhejiang Sci-Tech University(ZSTU), China
FX This document is the result of the research project funded by Natural
   Science Foundation of Zhejiang Province under Grant No.LY21F010016. This
   work is supported by National Key Research and Development Program of
   China under Grant No.SQ2020YFF0402315. This work is supported by Science
   Foundation of Zhejiang Sci-Tech University(ZSTU), China under Grant
   No.19022397-Y.
CR Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Dai JF, 2016, ADV NEUR IN, V29
   Dong Z., 2020, P IEEE C COMP VIS PA, P10519, DOI DOI 10.1109/CVPR42600.2020.01053
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu C.-Y., 2017, arXiv
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Liu ST, 2019, Arxiv, DOI arXiv:1911.09516
   Liu W, 2021, Arxiv, DOI arXiv:1904.02948
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yan Y etal, 2021, Anchor-free person search, P7690
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 24
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 16
PY 2023
DI 10.1007/s11042-023-16537-w
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE1R9
UT WOS:001130268000002
DA 2024-07-18
ER

PT J
AU Vidyasri, S
   Saravanan, S
AF Vidyasri, S.
   Saravanan, S.
TI Enhanced deep transfer learning with multi-feature fusion for lung
   disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung disease; Computer aided diagnosis; Multi-feature fusion; Deep
   transfer learning; Chest X-ray images; Dung beetle optimizer
ID BRAIN-TUMOR CLASSIFICATION; SEGMENTATION
AB Early detection of lung disease is important for timely intervention and treatment, enhancing patient outcomes and decreasing healthcare cost. Chest X-rays are a widely employed imaging modality to examine the structures within the chest, including the lungs and surrounding tissues. Lung disease detection using chest X-rays is a critical application of medical imaging and artificial intelligence (AI) in healthcare. Recently, lung disease detection using deep learning (DL) becomes a significant research area, which has the potential to improve early detection rate and decrease mortality rate. Therefore, this article introduces a Multi-Feature Fusion Based Deep Transfer Learning with Enhanced Dung Beetle Optimization Algorithm (MFFTL-EDBOA) for lung disease detection and classification. The MFFTL-EDBOA technique aims to recognize the existence of lung diseases on CXR images. At the primary stage, the MFFTL-EDBOA technique uses adaptive filtering (AF) approach to remove the noise level. Besides, a multi-feature fusion-based feature extraction approach is developed based on three DL models namely DenseNet, EfficientNet, and MobileNet. For accurate lung disease detection and classification purposes, the convolutional fuzzy neural network (CFNN) approach is utilized. The hyperparameter tuning of the CFNN model occurs using the EDBOA. To illustrate the enhanced lung disease detection results of the MFFTL-EDBOA technique, a sequence of experiments is carried out on benchmark medical dataset from Kaggle repository. The experimental values highlighted the greater result of the MFFTL-EDBOA system over other recent approaches with maximum accuracy of 98.99%.
C1 [Vidyasri, S.; Saravanan, S.] Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Annamalainagar, Tamil Nadu, India.
C3 Annamalai University
RP Vidyasri, S (corresponding author), Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Annamalainagar, Tamil Nadu, India.
EM thirukamusaipriya1991@gmail.com; aucissaran@gmail.com
CR Abd-Ellah MK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0332-4
   Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Amin J, 2020, PATTERN RECOGN LETT, V129, P115, DOI 10.1016/j.patrec.2019.11.016
   Amin J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1453-8
   Angulakshmi M, 2020, J KING SAUD UNIV-COM, V32, P1182, DOI 10.1016/j.jksuci.2018.01.009
   Anitha V., 2015, IET Comput Vision, V1751-9632, P1, DOI [10.1049/iet-cvi.2014.0193, DOI 10.1049/IET-CVI.2014.0193]
   Bakas S, 2019, Arxiv, DOI arXiv:1811.02629
   Bhuyan HK, 2022, HEALTH TECHNOL-GER, V12, P987, DOI 10.1007/s12553-022-00687-2
   Bhuyan HK., 2022, IEEE Explore, DOI [10.1109/ICAECT54875.2022.9807903,21845421, DOI 10.1109/ICAECT54875.2022.9807903,21845421]
   Brahma B, 2022, Soft computing and machine learning techniques for e-health data analytics, connected-e-health, P83, DOI [10.1007/978-3-030-97929-4_4, DOI 10.1007/978-3-030-97929-4_4]
   BTATS, 2018, Dataset
   Caver E., 2018, MICCAI BRATS 2018, V63, P63
   Chang YJ, 2018, MICCAI BRATS 2018 PR, P83
   Chithra PL, 2020, INT J IMAG SYST TECH, V30, P674, DOI 10.1002/ima.22407
   Chithra PL, 2020, Int J Innov Technol Explor Eng, V9, P1663
   Dong H., 2017, Comput. Vis. Pattern Recog, V69, P1
   Hachemi B, 2020, INT J IMAG SYST TECH, V30, P104, DOI 10.1002/ima.22376
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hua R, 2019, LECT NOTES COMPUT SC, V11384, P49, DOI 10.1007/978-3-030-11726-9_5
   Johnpeter JH, 2019, INT J IMAG SYST TECH, V29, P431, DOI 10.1002/ima.22318
   Kao PY, 2019, LECT NOTES COMPUT SC, V11384, P128, DOI 10.1007/978-3-030-11726-9_12
   Kermi A, 2018, MICCAI BRATS 2018 PR, P252
   Lefkovits S, 2019, LECT NOTES COMPUT SC, V11384, P334, DOI 10.1007/978-3-030-11726-9_30
   Li S., 2018, MICCAI BRATS 2018, P448
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Madhukumar S, 2015, EGYPT J RADIOL NUC M, V46, P475, DOI 10.1016/j.ejrnm.2015.02.008
   Mariano C., 2018, MICCAI BRATS 2018, P54
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Michal M., 2018, MICCAI BRATS 2018, P314
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Raschke F, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101648
   Serrano-Rubio J., 2018, MICCAI BRATS 2018 PR, P420
   Shenbagarajan A, 2016, BIOMED RES-INDIA, V27, pS191
   Talwar R., 2014, Int J Ethics Eng Manag Educ, V1, P2348
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Wang CJ, 2018, MICCAI BRATS 2018 PR, P482
   Wu Y, 2013, J DIGIT IMAGING, V26, P786, DOI 10.1007/s10278-012-9568-1
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 41
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17767-8
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800017
DA 2024-07-18
ER

PT J
AU Saini, SS
   Sharma, KK
AF Saini, Sundeep Singh
   Sharma, Kamal Kant
TI Power enhancement in distributed system to control the bidirectional
   power flow in electric vehicle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Total Harmonic Distortion; Power Loss; Intelligent Neural Herd Based
   Water Drop Optimization; Bidirectional Power Flow; Battery Energy
   Storage System; Distributed Generation
ID DISTRIBUTION NETWORKS
AB Bidirectional power flow based smart grid system is implemented in the Distributed Generation (DG) sources using Renewable Energy Generators (REG) like solar, wind, etc. Moreover, the unsuitable connection of a load to a grid and DGs can reduce Power Quality (PQ) and bidirectional power flow. Consequently, the existing power generation system has a limited number of power-generation sources, which are linked as millions of end consumers as well as transmission grid. Also, power generation sources has small controller performance over power loss from producing plants to end customers. Moreover, the power-generation sources are having injection points to transfer the power. In the current and future conditions, power systems must accommodate more power from renewable energy sources, be capable of handling bidirectional power flow with distributed generation, and use automatic metering infrastructure, phasor measurement units, power quality conditioners, electric vehicle charging infrastructure, cyber security, and so on.In recent times, the renewable energy-based distribution system is a challenging task in the Battery Energy Storage System (BESS). However, in many cases, power loss, and harmonic moderation are significant issues. Hence in this research, a novel Intelligent Neural Herd Based Water Drop Optimization (INH-WDO) is proposed to control the bidirectional power flow of the converter. The simulation of these proposed methods is actualized in MATLAB platform; subsequently, the projected performance results such as power loss (0.2MV), THD (2.5%) are compared with existing control techniques for proving the significance of the developed controller design. Moreover, the system efficiency in terms of power quality is based on power loss minimization while reducing the Total Harmonic Distortion (THD).
C1 [Saini, Sundeep Singh; Sharma, Kamal Kant] Chandigarh Univ, Dept Elect Engn, Chandigarh 140413, Punjab, India.
C3 Chandigarh University
RP Saini, SS (corresponding author), Chandigarh Univ, Dept Elect Engn, Chandigarh 140413, Punjab, India.
EM sundeeps2787@gmail.com; kamalkant.ee@cumail.in
RI Sharma, Kamal Kant/Y-2407-2019
OI Sharma, Kamal Kant/0000-0002-3807-9370
CR Ali A, 2024, J MOD POWER SYST CLE, V12, P675, DOI 10.35833/MPCE.2023.000107
   Anam Ganesh, 2021, Inventive Communication and Computational Technologies. Proceedings of ICICCT 2020. Lecture Notes in Networks and Systems (LNNS 145), P859, DOI 10.1007/978-981-15-7345-3_73
   Barman P, 2023, RENEW SUST ENERG REV, V183, DOI 10.1016/j.rser.2023.113518
   Bizhani N, 2019, IEEE ACCESS, V7, P105235, DOI 10.1109/ACCESS.2019.2931994
   Brinkel NBG, 2020, INT J ELEC POWER, V118, DOI 10.1016/j.ijepes.2019.105741
   Casaleiro A, 2021, ELECTR POW SYST RES, V191, DOI 10.1016/j.epsr.2020.106891
   Das N, 2023, IEEE ACCESS, V11, P12075, DOI 10.1109/ACCESS.2023.3241244
   García-López FD, 2020, INT J ELEC POWER, V114, DOI 10.1016/j.ijepes.2019.05.078
   Fakhrooeian P, 2023, ELECTR POW SYST RES, V216, DOI 10.1016/j.epsr.2022.109021
   Fathabadi H, 2020, APPL ENERG, V260, DOI 10.1016/j.apenergy.2019.114194
   Fortes RRA, 2020, ELECTR POW SYST RES, V188, DOI 10.1016/j.epsr.2020.106521
   Ghosh A, 2020, IEEE ENER CONV, P1654, DOI 10.1109/ECCE44975.2020.9235606
   Huang YT, 2020, TRANSPORT RES D-TR E, V78, DOI 10.1016/j.trd.2019.11.008
   Khan SA, 2019, IEEE T APPL SUPERCON, V29, DOI 10.1109/TASC.2019.2895526
   Lei X, 2023, ENERGY, V283, DOI 10.1016/j.energy.2023.128354
   Li FC, 2019, J ENG-JOE, P2706, DOI 10.1049/joe.2018.8544
   Mastoi MS, 2023, ENERGY REP, V9, DOI 10.1016/j.egyr.2022.12.139
   Mehdi HM, 2023, J ENERGY STORAGE, V58, DOI 10.1016/j.est.2022.106333
   Merhy G, 2020, SUSTAIN CITIES SOC, V57, DOI 10.1016/j.scs.2020.102129
   Moradisizkoohi H, 2021, IEEE T IND ELECTRON, V68, P1803, DOI 10.1109/TIE.2020.2998757
   Noorollahi Y, 2020, J ENERGY STORAGE, V30, DOI 10.1016/j.est.2020.101553
   Olatunde O, 2020, J ENERGY STORAGE, V31, DOI 10.1016/j.est.2020.101673
   Patil J, 2023, 2023 INT C APPL INT, P1
   Petrusic A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010245
   Pirouzi S, 2019, IEEE SYST J, V13, P3433, DOI 10.1109/JSYST.2019.2896408
   Sadeghi S, 2021, INT J ELEC POWER, V127, DOI 10.1016/j.ijepes.2020.106646
   Saleeb H, 2020, ELECTR ENG, V102, P195, DOI 10.1007/s00202-019-00860-3
   Sarkar K, 2021, MULTIMED TOOLS APPL, V80, P6329, DOI 10.1007/s11042-020-10004-6
   Shi L, 2020, MULTIMED TOOLS APPL, V79, P5321, DOI 10.1007/s11042-018-6317-6
   Singh B, 2020, IEEE T IND APPL, V56, P4007, DOI 10.1109/TIA.2020.2989680
   Suja KR, 2021, J AMB INTEL HUM COMP, V12, P9209, DOI 10.1007/s12652-020-02626-3
   Visakh A, 2022, ELECTR ENG, V104, P2805, DOI 10.1007/s00202-022-01511-w
   Wang B, 2019, IEEE T IND APPL, V55, P6603, DOI 10.1109/TIA.2019.2936474
   Wang JF, 2021, IEEE T IND ELECTRON, V68, P12340, DOI 10.1109/TIE.2020.3040687
   Wu HY, 2020, MULTIMED TOOLS APPL, V79, P263, DOI 10.1007/s11042-019-08075-1
   Wu Y, 2020, J POWER SOURCES, V476, DOI 10.1016/j.jpowsour.2020.228504
   Zhang YM, 2020, IEEE ACCESS, V8, P137209, DOI 10.1109/ACCESS.2020.3011832
NR 37
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17718-3
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800007
DA 2024-07-18
ER

PT J
AU Liu, Q
   Yuan, J
   Kuang, BF
AF Liu, Qiang
   Yuan, Jie
   Kuang, Benfa
TI SIA-SLAM: a robust visual SLAM associated with semantic information in
   dynamic environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual SLAM; Dynamic feature elimination; Feature matching; Semantic
   information association; Dynamic scenes
AB Semantic information associated Simultaneous Localization and Mapping (SIA-SLAM), a visual SLAM algorithm using semantic information association, is proposed to solve the problems that dynamic objects lead to the decreased accuracy of the localization and feature matching between two frames due to the lack of object semantic information. Firstly, a Solov2 instance segmentation network is used to obtain instance segmentation images, and the feature points are extracted from the RBG images simultaneously. Secondly, the feature points on dynamic objects are removed, and the semantic information of static objects is associated with the remaining feature points. Then, the static feature points are utilized to estimate the camera poses and update the static map point set. Finally, the camera poses are optimized by using closed-loop detection. When tracking the camera poses and inter-frame feature matching during the closed-loop detection, the semantic information of the feature points is checked first, and then the bag-of-words model is used for feature matching. The proposed SIA-SLAM algorithm is tested on the Technische Universitat Munchen (TUM) public dataset. As far as the absolute trajectory errors (ATE) are concerned, the Root Mean Square Errors (RMSE) and Standard Deviation (S.D.) improvement values can reach up to 98.15% and 98.18% in high dynamic scene of TUM dataset, respectively. The proposed SIA-SLAM algorithm is superior to other semantic SLAM algorithms which are tested in the specific datasets. Furthermore, the reliability and robustness of the SIA-SLAM algorithm are verified in a real scenario. The SIA-SLAM algorithm effectively improves the accuracy of the camera trajectory estimation and feature matching.
C1 [Liu, Qiang; Yuan, Jie; Kuang, Benfa] Xinjiang Univ, Sch Elect Engn, Urumqi, Peoples R China.
C3 Xinjiang University
RP Yuan, J (corresponding author), Xinjiang Univ, Sch Elect Engn, Urumqi, Peoples R China.
EM yuanjie222@126.com
FU National Natural Science Foundation of China [62263031, 61863033];
   Natural Science Foundation of Xinjiang Uygur Autonomous Region
   [2022D01C53]
FX This work was funded in part by the National Natural Science Foundation
   of China (62263031 and 61863033), and the Natural Science Foundation of
   Xinjiang Uygur Autonomous Region (2022D01C53).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039
   Bochkovskiy A, 2020, ArXiv, V10934
   Brasch N, 2018, IEEE INT C INT ROBOT, P393, DOI 10.1109/IROS.2018.8593828
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hempel T, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104830
   Klein George, 2007, P1
   Li SL, 2017, IEEE ROBOT AUTOM LET, V2, P2263, DOI 10.1109/LRA.2017.2724759
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YB, 2021, IEEE ACCESS, V9, P23772, DOI 10.1109/ACCESS.2021.3050617
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Ran T, 2021, IEEE SENS J, V21, P20657, DOI 10.1109/JSEN.2021.3099511
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sharma K, 2018, MULTIMED TOOLS APPL, V77, P7955, DOI 10.1007/s11042-017-4694-x
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012
   Wang X., 2020, Advances in Neural information processing systems, V33, P17721, DOI DOI 10.48550/ARXIV.2003.10152
   Wei HY, 2021, MULTIMED TOOLS APPL, V80, P31729, DOI 10.1007/s11042-021-11168-5
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691
   Zhong FW, 2018, IEEE WINT CONF APPL, P1001, DOI 10.1109/WACV.2018.00115
   Zou DP, 2013, IEEE T PATTERN ANAL, V35, P354, DOI 10.1109/TPAMI.2012.104
NR 27
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 21
PY 2023
DI 10.1007/s11042-023-17650-6
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y6BH9
UT WOS:001106086000002
DA 2024-07-18
ER

PT J
AU Yang, H
   Mu, N
   Guo, JJ
   Hu, YY
   Wang, R
AF Yang, Heng
   Mu, Nan
   Guo, Jinjia
   Hu, Yiyue
   Wang, Rong
TI Video salient object detection via self-attention-guided multilayer
   cross-stack fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video salient object detection; Self-attention; Transformer block;
   Cross-stack fusion; Global consistency
ID MODEL
AB Video salient object detection is an effective measure for identifying objects of interest within video sequences, which requires the processing of information from spatial-motion patterns. While plenty of traditional video salient object detection models have historically aimed to develop efficient features capturing spatial and motion features to obtain salient objects of global consistency, the presence of repetitive spatial information from consecutive identical objects can reduce the models' generalization ability and stability. Previous attempts have been made to integrate spatial and motion information to enhance the inter-frame correlation of salient objects, but they often focus on simple spatio-temporal fusion, inadvertently introducing redundant information and leading to suboptimal detection performance. Therefore, there is a need to shift the focus towards more effective fusion of the feature information from different modalities to mitigate the negative effects of redundant information. In this study, we propose a self-attention guided fully supervised multilayer cross-stack fusion for video salient object detection, which extracts multimodal features for facilitating bidirectional information transfer. Our approach utilizes spatial and temporal knowledge to complement each other, refining the cross-stack of the interacted information and spatial features to optimize local and global saliency. Consequently, the approach significantly reduces redundant spatial information, mitigating the misidentification of salient objects due to blurred backgrounds or moving objects. Additionally, it adaptively activates more weights of the salient object to achieve globally consistent saliency. Extensive experiments on five publicly available video salient object detection datasets demonstrated that the performance of our approach was superior to those of multiple state-of-the-art video salient object detection models.
C1 [Yang, Heng; Mu, Nan; Hu, Yiyue; Wang, Rong] Sichuan Normal Univ, Sch Comp Sci, Chengdu 610101, Peoples R China.
   [Yang, Heng] Chongqing Coll Finance & Econ, Chongqing 402160, Peoples R China.
   [Mu, Nan; Wang, Rong] Sichuan Normal Univ, Visual Comp & Virtual Real Key Lab Sichuan Prov, Chengdu 610068, Sichuan, Peoples R China.
   [Mu, Nan; Wang, Rong] Educ Big Data Collaborat Innovat Ctr Sichuan 2011, Chengdu 610101, Sichuan, Peoples R China.
   [Guo, Jinjia] Chongqing Univ, Chongqing Univ Univ Cincinnati Joint Coop Inst, Chongqing 40044, Peoples R China.
C3 Sichuan Normal University; Sichuan Normal University; Chongqing
   University
RP Mu, N (corresponding author), Sichuan Normal Univ, Sch Comp Sci, Chengdu 610101, Peoples R China.; Mu, N (corresponding author), Sichuan Normal Univ, Visual Comp & Virtual Real Key Lab Sichuan Prov, Chengdu 610068, Sichuan, Peoples R China.; Mu, N (corresponding author), Educ Big Data Collaborat Innovat Ctr Sichuan 2011, Chengdu 610101, Sichuan, Peoples R China.
EM nanmu@sicnu.edu.cn
OI Mu, Nan/0000-0003-0476-7500; Wang, Rong/0000-0001-9251-3775
FU This work was supported by the National Natural Science Foundation of
   China (62006165) and the Sichuan Science and Technology Program
   (2023NSFSC1397). [62006165]; National Natural Science Foundation of
   China [2023NSFSC1397]; Sichuan Science and Technology Program
FX This work was supported by the National Natural Science Foundation of
   China (62006165) and the Sichuan Science and Technology Program
   (2023NSFSC1397).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gillioz Anthony, 2020, 2020 15th Conference on Computer Science and Information Systems (FedCSIS), P179, DOI 10.15439/2020F20
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Ji W, 2021, PROC CVPR IEEE, P12336, DOI 10.1109/CVPR46437.2021.01216
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Lee H, 2018, IEEE WINT CONF APPL, P1170, DOI 10.1109/WACV.2018.00133
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Liu J, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103700
   Mu N, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102697
   Mu N, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108168
   Mu N, 2019, J VIS COMMUN IMAGE R, V58, P79, DOI 10.1016/j.jvcir.2018.11.012
   Mu N, 2018, NEURAL COMPUT APPL, V29, P181, DOI 10.1007/s00521-017-2870-6
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Shafieyan F, 2014, IEEE IMAGE PROC, P1155, DOI 10.1109/ICIP.2014.7025230
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Su YK, 2024, IEEE T MULTIMEDIA, V26, P313, DOI 10.1109/TMM.2023.3264883
   Tang Y, 2021, arXiv
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang HY, 2021, IEEE SYS MAN CYBERN, P2781, DOI 10.1109/SMC52423.2021.9658855
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
   Zhang M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1533, DOI 10.1109/ICCV48922.2021.00158
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 34
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17652-4
EA NOV 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300002
DA 2024-07-18
ER

PT J
AU Bakhat, K
   Kifayat, K
   Islam, MS
   Islam, MM
AF Bakhat, Khush
   Kifayat, Kashif
   Islam, M. Shujah
   Islam, M. Mattah
TI Utilizing CPG-3D, graph theory anchored approach to recognize human
   action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Complex networks; Graph theory; Human action recognition; CPG-3D;
   Skeleton-based action recognition
AB Graph theory originated as a fun way to solve math problems, but it has now evolved into a significant mathematics subject with several applications in computer vision. The human skeleton has garnered much attention in recent years as a simple depiction of human motion. Three-dimensional joints have limitations in terms of dependability, compatibility, and flexibility, notwithstanding the optimistic results of previous investigations. CPG-3D is a new technique for skeleton-based action recognition that focuses solely on 3D skeleton joint points and their placements as the basic expression of human skeletons rather than any additional information. CPG-3D outperforms previous action recognition algorithms in learning how to describe, is more resilient to pose estimation disturbances, and generalises better across data sets. CPG-3D can also manage various alternatives without incurring additional computational expenses, and its capabilities can be readily fused with other modalities during the early phases of fusion, offering a broad design space to increase efficiency further. CPG-3D consistently beats the competition on four complicated and hard datasets when used alone on three-dimensional skeletal joints.
C1 [Bakhat, Khush; Kifayat, Kashif] Air Univ, Islamabad, Pakistan.
   [Islam, M. Shujah] King Faisal Univ, Coll Comp Sci & Informat Technol, Al Hufuf, Saudi Arabia.
   [Islam, M. Mattah] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
C3 Air University Islamabad; King Faisal University
RP Kifayat, K (corresponding author), Air Univ, Islamabad, Pakistan.
EM khush.bakhat.awar@gmail.com; kashif.kifayat@mail.au.edu.pk;
   msameem@kfu.edu.sa; m.mattahislamsameem@gmail.com
CR Bakhat K, 2022, J Intell Fuzzy Syst Prepr, P1
   Bakhat K, 2023, SIGNAL IMAGE VIDEO P, V17, P1677, DOI 10.1007/s11760-022-02378-x
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Fakhrulddin AH, 2017, INT CONF SYST INFORM, P1461, DOI 10.1109/ICSAI.2017.8248516
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Guo L, 2018, Wirel Commun Mob, VComput2018, P1
   Islam MS, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095437
   Islam MS, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118406
   Islam MS, 2021, APPL INTELL, V51, P6001, DOI 10.1007/s10489-020-02176-3
   Islam MS, 2020, IET IMAGE PROCESS, V14, P417, DOI 10.1049/iet-ipr.2018.6437
   Islam MS, 2022, Multimed Tools Appl, P1
   Islam S, 2018, SIGNAL IMAGE VIDEO P, V12, P853, DOI 10.1007/s11760-017-1228-y
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Ji YL, 2018, SIGNAL PROCESS, V143, P364, DOI 10.1016/j.sigpro.2017.06.001
   Jia CC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P87, DOI 10.1145/2647868.2654928
   Ke Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P536, DOI 10.1007/978-3-030-58586-0_32
   Lemieux N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174946
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li X, 2020, MULTIMED TOOLS APPL, V79, P35761, DOI 10.1007/s11042-020-09593-z
   Liu JJ, 2020, NEUROCOMPUTING, V385, P22, DOI 10.1016/j.neucom.2019.11.048
   Mazzia V, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108487
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Popoviciu T, 1965, Iasi, Sectia Mat, V11
   Reily B, 2020, IEEE INT CONF ROBOT, P8006, DOI [10.1109/icra40945.2020.9196632, 10.1109/ICRA40945.2020.9196632]
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Tasnim N, 2020, INVENTIONS-BASEL, V5, DOI 10.3390/inventions5030049
   Tsai MF, 2022, MULTIMED TOOLS APPL, V81, P7439, DOI 10.1007/s11042-022-12000-4
   Vecchio DA, 2021, ACS NANO, V15, P12847, DOI 10.1021/acsnano.1c04711
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Verma A, 2021, COMPUT INTELL-US, V37, P461, DOI 10.1111/coin.12419
   Waheed M, 2021, IEEE ACCESS, V9, P167434, DOI 10.1109/ACCESS.2021.3130613
   Wang HR, 2021, NEUROCOMPUTING, V423, P1, DOI 10.1016/j.neucom.2020.10.037
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yoshikawa Y, 2021, COMPUT VIS IMAGE UND, V212, DOI 10.1016/j.cviu.2021.103276
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhao DD, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107732
   Zhou L., 2014, 2014 INT C DIG IM CO, P1
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-16157-4
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900001
DA 2024-07-18
ER

PT J
AU Yeratziotis, A
   Achilleos, A
   Koumou, S
   Zampas, G
   Thibodeau, RA
   Geratziotis, G
   Papadopoulos, GA
   Iasonas, I
   Kronis, C
AF Yeratziotis, Alexandros
   Achilleos, Achilleas
   Koumou, Stavroulla
   Zampas, George
   Thibodeau, Regan A.
   Geratziotis, George
   Papadopoulos, George A.
   Iasonas, Iasonos
   Kronis, Christophoros
TI Making social media applications inclusive for deaf end-users with
   access to sign language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inclusive design; Accessibility; Deaf end-user; Face swapping; Mobile
   application; Sign Language Alphabet; Human-Centred Design
AB Social media apps such as WhatsApp, Messenger, Telegram and Viber are primary communication channels for most people today. Even within these Mainstream Social Media Applications, persons who are deaf are not provided with the rights and means to interact using sign language. This work, an outcome of the research project' "Accessible System and Social Media Mobile Application for Deaf Users (ASM4Deaf)", supports the inclusion of deaf end-users in social media applications. This was achieved via: 1) design and development of the ASM4Deaf system, which includes the Connect Deaf mobile application, enabling use of Sign Language Alphabet keyboards in social media apps in 17 different sign languages and 2) the evaluations of Low- and High-Fidelity prototypes aimed to enhance the app's design and functionality, i.e. the ability to browse, search and edit animated videos/GIFs in the American Sign Language (ASL), using the face swapping feature. This makes the full set of features offered by social media applications accessible to deaf end-users and their personal network, which is the main contribution of this work. A Human-Centred Design methodology was employed, with the end-users at the heart of the process, to design and evaluate the Lo-Fi and Hi-Fi prototypes, and based on the evaluation results to develop the ASM4Deaf system and the Connect Deaf mobile application to fully meet the requirements of the deaf end-users.
C1 [Yeratziotis, Alexandros; Geratziotis, George] AG Connect Deaf Ltd, 8 Lakonias St, CY-2021 Nicosia, Cyprus.
   [Achilleos, Achilleas; Iasonas, Iasonos; Kronis, Christophoros] Frederick Univ, Dept Elect Engn Comp Engn & Informat, 7 Y Frederickou Str Pallouriotisa, CY-1036 Nicosia, Cyprus.
   [Koumou, Stavroulla; Zampas, George; Papadopoulos, George A.] Univ Cyprus, Dept Comp Sci, CY-2109 Nicosia, Cyprus.
   [Thibodeau, Regan A.] Annrae Consulting LLC, POB 352, Westbrook, ME 04062 USA.
C3 University of Cyprus
RP Yeratziotis, A (corresponding author), AG Connect Deaf Ltd, 8 Lakonias St, CY-2021 Nicosia, Cyprus.
EM alexis@connectdeaf.com; achilleas.achilleos@frederick.ac.cy;
   skoumo01@ucy.ac.cy; gzampa01@ucy.ac.cy; arclingui@gmail.com;
   george@connectdeaf.com; george@ucy.ac.cy; com.ii@frederick.ac.cy;
   c.kronis@frederick.ac.cy
RI Papadopoulos, George Angelos/ISU-5890-2023
OI Papadopoulos, George Angelos/0000-0001-9250-4916; Yeratziotis,
   Alexandros/0000-0003-2874-416X
FU The project PRE-SEED/0719(B)/0278 is co-financed by the European
   Regional Development Fund and the Republic of Cyprus through the
   Research and Innovation Foundation. [PRE-SEED/0719(B)/0278]; European
   Regional Development Fund; Republic of Cyprus through the Research and
   Innovation Foundation
FX The project PRE-SEED/0719(B)/0278 is co-financed by the European
   Regional Development Fund and the Republic of Cyprus through the
   Research and Innovation Foundation.
CR Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29
   Allen TE, 2014, AM ANN DEAF, V159, P346, DOI 10.1353/aad.2014.0030
   [Anonymous], 2009, 9241 210 2010 ERGONO, DOI DOI 10.3403/30388991
   Barberis D, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P253
   Bottoni P, 2013, UNIVERSAL ACCESS INF, V12, P369, DOI 10.1007/s10209-012-0283-y
   Cabanillas-Carbonell Michael, 2022, International Journal of Interactive Mobile Technologies, P51, DOI 10.3991/ijim.v16i11.29717
   Chen D, 2019, MATH PROBL ENG
   Chesakov D, 2022, ARXIV
   Debevc M, 2012, LECT NOTES COMPUT SC, V7383, P213, DOI 10.1007/978-3-642-31534-3_33
   Ding XY, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-00109-8
   Efthimiou E, 2009, LECT NOTES COMPUT SC, V5614, P21, DOI 10.1007/978-3-642-02707-9_3
   Efthimiou Eleni, 2010, Proceedings of the 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies, P80
   Elliott R., 2008, Universal Access in the Information Society, V6, P375, DOI 10.1007/s10209-007-0102-z
   Elliott R, 2000, P 4 INT ACM C ASS TE, P101, DOI DOI 10.1145/354324.354349
   European Union of the Deaf, MEMBERS
   Fels DI, 2009, LECT NOTES COMPUT SC, V5616, P492, DOI 10.1007/978-3-642-02713-0_52
   Groshev A, 2022, IEEE ACCESS, V10, P83452, DOI 10.1109/ACCESS.2022.3196668
   Hassani A, 2022, TECHNOLOGIES, V10, DOI 10.3390/technologies10020046
   Kemelmacher-Shlizerman I, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925871
   Mitchell RE, 2006, SIGN LANG STUD, V6, P306, DOI 10.1353/sls.2006.0019
   Monteiro CDD, 2012, P 14 INT ACM SIGACCE, P191, DOI 10.1145/2384916.2384950
   Mosaddegh S, 2015, LECT NOTES COMPUT SC, V9005, P159, DOI 10.1007/978-3-319-16811-1_11
   Naruniec J, 2020, COMPUT GRAPH FORUM, V39, P173, DOI 10.1111/cgf.14062
   Neidle C, 2001, BEHAV RES METH INS C, V33, P311, DOI 10.3758/BF03195384
   Nielsen J, 2020, FOCUS GROUPS UX RES
   Pieri K, 2019, J ENABLING TECHNOL, V13, P70, DOI 10.1108/JET-12-2018-0058
   Reface.ai, REFACE FACE SWAP APP
   Samonte MJC, 2019, I C INF COMM TECH CO, P1310, DOI 10.1109/ictc46691.2019.8939866
   Nguyen TT, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103525
   van der Bijl-Brouwer M, 2017, DESIGN STUD, V53, P1, DOI 10.1016/j.destud.2017.06.003
   van Zijl L, 2006, P 8 INT ACM SIGACCES, P233, DOI [10.1145/1168987.1169031, DOI 10.1145/1168987.1169031]
   Web Accessibility Initiative, 2012, WEB CONTENT ACCESSIB
   World Federation of the Deaf, DEAFNESS HEARING LOS
   World Health Organization, 2023, Deafness and hearing loss.
   Yeratziotis Alexandros, 2022, GoodIT 2022: Conference on Information Technology for Social Good, P39, DOI 10.1145/3524458.3547234
   Yeratziotis A, 2018, INT J HUM-COMPUT INT, V34, P195, DOI 10.1080/10447318.2017.1339940
   Yeratziotis A, 2015, LECT NOTES COMPUT SC, V9175, P253, DOI 10.1007/978-3-319-20678-3_25
   Yeratziotis G, 2013, 2013 IST-AFRICA CONFERENCE AND EXHIBITION (IST-AFRICA)
   Zhu YH, 2021, PROC CVPR IEEE, P4832, DOI 10.1109/CVPR46437.2021.00480
NR 39
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46185
EP 46215
DI 10.1007/s11042-023-17196-7
EA NOV 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001101716100004
OA hybrid
DA 2024-07-18
ER

PT J
AU Ahamed, NN
   Vignesh, R
   Alam, T
AF Ahamed, N. Nasurudeen
   Vignesh, R.
   Alam, Tanweer
TI Tracking and tracing the halal food supply chain management using
   blockchain, RFID, and QR code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Smart Contract; Halal Food; RFID; QR Code
ID TRACEABILITY
AB Blockchain is a disseminated open record that is utilized to record the exchange across numerous Personal computers. Blockchain innovation can be applied in any space like banking, medical services, land, travel, food, and store networks. In food products, halal food is served throughout the world. Halal does not only belong to Muslim people it's for everyone globally. Halal means cleanliness of this food product.so, ensure the food products are free from contamination of halal food with other food products. The smart contract was created in the halal food supply chain to ensure consumer trustworthily. Tracking and tracing the halal products in the supply chain from producer to consumer we implement some special tags (RFID/QR Code). These special tags track the food products from farm to consumer and vice versa tracing the halal food from consumer to producer to reduce the contamination of food items with halal food items.
C1 [Ahamed, N. Nasurudeen; Vignesh, R.] Presidency Univ, Sch Comp Sci & Engn, Bengaluru, Karnataka, India.
   [Alam, Tanweer] Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
C3 Presidency University, Bangalore; Islamic University of Al Madinah
RP Alam, T (corresponding author), Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
EM tanweer03@iu.edu.sa
RI Alam, Tanweer/M-7780-2017; N, Dr Nasurudeen Ahamed/AAN-3424-2020
OI Alam, Tanweer/0000-0003-2731-4627; N, Dr Nasurudeen
   Ahamed/0000-0002-2777-8870
CR Abeyratne S. A., 2016, INT J RES ENG TECHNO, V5, P1, DOI [10.15623/ijret.2016.0509001, DOI 10.15623/IJRET.2016.0509001]
   Adams D, 2021, SUSTAIN PROD CONSUMP, V28, P1491, DOI 10.1016/j.spc.2021.08.019
   Aggarwal S, 2021, ADV COMPUT, V121, P301, DOI 10.1016/bs.adcom.2020.08.015
   Ahamed N. N., 2020, International Journal of Intelligent Networks, V1, P92, DOI [10.1016/j. ijin.2020.09.001, DOI 10.1016/J.IJIN.2020.09.001]
   Ahamed NN, 2020, INT CONF ADVAN COMPU, P473, DOI [10.1109/ICACCS48705.2020.9074473, 10.1109/icaccs48705.2020.9074473]
   Aizat JM, 2019, Journal of Halal Industry & Services (JHIS), V1
   Alam T, 2023, COMPUTERS, V12, DOI 10.3390/computers12010006
   Alamsyah A., 2023, Journal of Open Innovation: Technology, Market, and Complexity, V9, P100008, DOI DOI 10.1016/J.JOITMC.2023.100008
   Augusto L., 2019, P 2019 INT YOUNG ENG, DOI [10.1109/YEF-ECE.2019.8740823, DOI 10.1109/YEF-ECE.2019.8740823]
   Baygin M, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116030
   Bencic FM, 2019, IEEE ACCESS, V7, P46198, DOI 10.1109/ACCESS.2019.2909170
   Bhalerao S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P456, DOI 10.1109/iss1.2019.8908031
   Bhutta MNM, 2021, IEEE ACCESS, V9, P65660, DOI 10.1109/ACCESS.2021.3076373
   Blossey G, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P6885
   Cao SF, 2022, BLOCKCHAIN-RES APPL, V3, DOI 10.1016/j.bcra.2022.100091
   Chandra GR, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P349, DOI [10.1109/AICAI.2019.8701321, 10.1109/aicai.2019.8701321]
   Chen CL, 2021, J SUPERCOMPUT, V77, P7791, DOI 10.1007/s11227-020-03558-7
   Chuang PJ, 2021, J SUPERCOMPUT, V77, P9658, DOI 10.1007/s11227-021-03656-0
   Duan J, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051784
   Focardi R, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102369
   Gargouri H, 2021, EUR FOOD RES TECHNOL, V247, P2183, DOI 10.1007/s00217-021-03778-y
   Gonczol P, 2020, IEEE ACCESS, V8, P11856, DOI 10.1109/ACCESS.2020.2964880
   Helo P, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101909
   Hew JJ, 2020, SUPPLY CHAIN MANAG, V25, P863, DOI 10.1108/SCM-01-2020-0044
   Hossain MAM, 2022, CRIT REV FOOD SCI, V62, P285, DOI 10.1080/10408398.2020.1814691
   Kaur A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218174
   Khanna A, 2022, FOODS, V11, DOI 10.3390/foods11172716
   Köhler S, 2022, TECHNOL FORECAST SOC, V185, DOI 10.1016/j.techfore.2022.122094
   Koirala RC, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P538, DOI [10.1109/confluence.2019.8776900, 10.1109/CONFLUENCE.2019.8776900]
   Kwag SI, 2019, TRANSPORT RES E-LOG, V128, P212, DOI 10.1016/j.tre.2019.06.005
   Marchesi L, 2022, BLOCKCHAIN-RES APPL, V3, DOI 10.1016/j.bcra.2022.100088
   Mondal S, 2019, IEEE INTERNET THINGS, V6, P5803, DOI 10.1109/JIOT.2019.2907658
   Nagarajan SM, 2022, SUSTAIN CITIES SOC, V76, DOI 10.1016/j.scs.2021.103448
   Patel AS, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e16526
   Patro PK, 2022, IEEE ACCESS, V10, P81134, DOI 10.1109/ACCESS.2022.3196162
   Pigini D, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9101910
   Rejeb A., 2018, ACTA TECHNICA JAURIN, V11, P218, DOI [10.14513/actatechjaur.v11.n4.467, DOI 10.14513/ACTATECHJAUR.V11.N4.467, 10.14513/ACTATECHJAUR.V11.N4.467]
   Rejeb A, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11070161
   Rohmah D., 2019, P 1 INT C BUS LAW PE, DOI [10.4108/eai.13-2-2019.2286199, DOI 10.4108/EAI.13-2-2019.2286199]
   Saberi S, 2019, INT J PROD RES, V57, P2117, DOI 10.1080/00207543.2018.1533261
   Scanova, QR CODE GENERATOR
   Shabani H, 2015, FOOD CHEM, V184, P203, DOI 10.1016/j.foodchem.2015.02.140
   Sunny J, 2020, COMPUT IND ENG, V150, DOI 10.1016/j.cie.2020.106895
   Tan A, 2022, INT J LOGIST-RES APP, V25, P947, DOI 10.1080/13675567.2020.1825653
   Tharatipyakul A, 2022, IEEE ACCESS, V10, P98783, DOI 10.1109/ACCESS.2022.3206860
   Tsang YP, 2019, IEEE ACCESS, V7, P129000, DOI 10.1109/ACCESS.2019.2940227
   Violino S, 2019, EUR FOOD RES TECHNOL, V245, P2089, DOI 10.1007/s00217-019-03321-0
   Wang L, 2021, IEEE ACCESS, V9, P9296, DOI 10.1109/ACCESS.2021.3050112
   Wang SP, 2019, IEEE ACCESS, V7, P115122, DOI 10.1109/ACCESS.2019.2935873
   Wu PJ, 2018, J CLEAN PROD, V203, P968, DOI 10.1016/j.jclepro.2018.08.178
   Yiu NCK, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13040086
   Yörük NG, 2021, EUR FOOD RES TECHNOL, V247, P2421, DOI 10.1007/s00217-021-03803-0
   Yu WJ, 2018, INT SYM COMPUT INTEL, P339, DOI 10.1109/ISCID.2018.00083
NR 53
TC 2
Z9 2
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17474-4
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500021
DA 2024-07-18
ER

PT J
AU Raja, P
   Suresh, P
AF Raja, P.
   Suresh, P.
TI Variety of ovarian cysts detection and classification using 2D
   Convolutional Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ultrasound image; Ovarian cyst; 2D Convolutional Neural Network
AB Most women, in general, have an ovarian cyst, which causes a variety of disorders. Cervical cysts occur when multiple cysts appear in or on top of the uterus. This is especially true for women who have a good reason for having a baby. Related to menstrual problems and cyst problems in women during pregnancy. Ultrasound imaging techniques are used to detect ovarian cysts. Doctors have many difficulties identifying these types of tumors that are not clearly visible from ultrasound images and what type of ovarian cyst they are To make these problems more useful to the doctors, the system of automatic detection of various cyst type has been implemented. The cyst detection and classification method are implemented using the features extracted from the ultrasound image. Automated detection methods and various ovarian cyst classification are implemented using a 2D Convolutional Neural network, and the proposed prediction model has yielded 99.37% accurate results.
C1 [Raja, P.; Suresh, P.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci, Dept Elect & Commun Engn, Chennai 600062, Tamilnadu, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Raja, P (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci, Dept Elect & Commun Engn, Chennai 600062, Tamilnadu, India.
EM pervasiveking@gmail.com; suresh3982@yahoo.co.in
RI P, SURESH/D-2981-2014
OI P, SURESH/0000-0002-0488-972X
CR Eldesouky MA, 2018, SEMIN OPHTHALMOL, V33, P170, DOI 10.1080/08820538.2016.1182636
   Gaillard F, Cyst. Reference article, DOI [10.53347/rID-6940, DOI 10.53347/RID-6940]
   Gopalakrishnan C, 2019, International Journal of Recent Technology and Engineering (IJRTE), V8
   Hiremath P.S., 2013, Advancements and breakthroughs in ultrasound imaging, P167, DOI DOI 10.5772/56518
   Jones J, Endometrioma, DOI [10.53347/rID-9042, DOI 10.53347/RID-9042]
   Kang K, 2014, Arxiv, DOI arXiv:1411.4464
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Mascalchi M, 2015, J COMPUT ASSIST TOMO, V39, P102, DOI 10.1097/RCT.0000000000000154
   Minelli L, 1996, EUR J OBSTET GYN R B, V65, P81, DOI 10.1016/0028-2243(95)02309-G
   Mobeen S, 2022, Ovarian Cyst
   Munirathinam R, 2022, MULTIMED TOOLS APPL, V81, P13355, DOI 10.1007/s11042-021-11069-7
   Nabilah Anisah, 2020, 2020 International Electronics Symposium (IES), P513, DOI 10.1109/IES50839.2020.9231695
   Parekh AM, 2017, INT CONF COMPUT
   Rachana B., 2021, Glob Transit Proc, V2, P304, DOI [10.1016/j.gltp.2021.08.010, DOI 10.1016/J.GLTP.2021.08.010]
   Radswiki T, 2023, Ovarian follicular cyst, DOI [10.53347/rID-13410, DOI 10.53347/RID-13410]
   Rihana S, 2013, I CON ADV BIOMED ENG, P219, DOI 10.1109/ICABME.2013.6648887
   Sohail AM, 2010, I S BIOMED IMAGING, P288, DOI 10.1109/ISBI.2010.5490352
   Soni1 P, 2019, Int J Comput Sci Eng, V7
   Sowmiya BR., 2018, Int J Innov Technol Explor Eng (IJITEE), V8
   Suresh P, 2017, J OPT-INDIA, V46, P225, DOI 10.1007/s12596-017-0411-4
   Thomassin-Naggara I, 2012, Diagn Interv Imaging, V93, P491, DOI 10.1016/j.diii.2012.04.002
   vanSantbrink EJP, 1997, FERTIL STERIL, V67, P452, DOI 10.1016/S0015-0282(97)80068-4
   Vasavi G, 2017, 2017 INT C TRENDS EL, DOI [10.1109/icoei.2017.8300811, DOI 10.1109/ICOEI.2017.8300811]
   Veldhuis W, Roadmap to evaluate ovarian cysts'
   Weerakkody Y, Ovarian serous cystadenoma, DOI [10.53347/rID-14473, DOI 10.53347/RID-14473]
   Zhu L, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P487, DOI 10.1109/FSKD.2008.54
NR 27
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17439-7
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500014
DA 2024-07-18
ER

PT J
AU Pandian, AA
   Maheswari, S
AF Pandian, A. Anbarasa
   Maheswari, S.
TI Joint Spatio-temporal representation based efficient video event
   detection using and BMCIM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video event representation; Video event detection; Spatio-temporal video
   analysis; Spatio-temporal joint representation; And video event
   inference model
ID LOCALIZATION
AB In recent days, video analytics has become an inevitable research area in surveillance video due to the surveillance cameras placed everywhere and thus increasing video data in megabytes. Therefore, it is difficult to analyze the significant event in the video. To detect the important event in a video, there is a need to represent the video content with spatio-temporal features. As the spatio-temporal representative feature can describe both appearance and motion of the event. This paper introduces a novel technique to effectively achieve event detection. Since the shape and motion of the foreground object are usually balanced with each other, this paper uses the joint spatio-temporal representation using two novel features such as SI-HOG and TI-EOF. The SI-HOG feature captures the shape information of the foreground object with its structural information and the TI-EOF feature efficiently extracts the foreground object's motion. To effectively find the video event, the Bayesian-based Markov Chain Inference Model is being introduced as the data description technique. The proposed work is implemented by using the MATLAB tool and the performance of the proposed work is evaluated by the following existing approaches such as MAC, OCELM, and DAML. The efficiency of the proposed approach is tested on UCSD ped1, UCSD ped2, and UMN datasets. The proposed method achieved high accuracy compared to existing methods in terms of event detection.
C1 [Pandian, A. Anbarasa] Panimalar Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Maheswari, S.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Pandian, AA (corresponding author), Panimalar Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM anbuaec@gmail.com; maheshamrish@gmail.com
RI A, ANBARASA PANDIAN/IXS-4191-2023
OI A, ANBARASA PANDIAN/0000-0003-0562-8027
CR Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi OA, 2022, CLUSTER COMPUT, V25, P2369, DOI 10.1007/s10586-021-03459-1
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Colque RM, 2016, IEEE Trans Circuits Syst Video Technol, P1
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Elhoseny M, 2020, CIRC SYST SIGNAL PR, V39, P611, DOI 10.1007/s00034-019-01234-7
   Fernando W. S. K., 2014, 7th International Conference on Information and Automation for Sustainability (ICIAfS), P1, DOI 10.1109/ICIAFS.2014.7069583
   Gaidon A, 2011, PROC CVPR IEEE
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   Kong S., 2008, PROC INT C PATTERN R, P1
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Li BL, 2023, CURR PSYCHOL, V42, P3024, DOI 10.1007/s12144-021-01654-2
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lim MK, 2014, EXPERT SYST APPL, V41, P4704, DOI 10.1016/j.eswa.2014.02.003
   Lin W, 2014, Neurocomputing, P1
   Lloyd K, 2017, MACH VISION APPL, V28, P361, DOI 10.1007/s00138-017-0830-x
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Schumann AS, 2019, PROC AVSS 2018 2018
   Shehzed Ahsan, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P163, DOI 10.1109/ICAEM.2019.8853756
   Sinhal R, 2020, J REAL-TIME IMAGE PR, V17, P2077, DOI 10.1007/s11554-019-00937-z
   Vennila TJ, 2020, 2020 INT C EMERGING, P1
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Xian Y, 2017, IEEE T CIRC SYST VID, V27, P624, DOI 10.1109/TCSVT.2016.2589838
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1198, DOI 10.1109/TITS.2016.2601655
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44577
EP 44589
DI 10.1007/s11042-023-15055-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8T9
UT WOS:001162908500001
DA 2024-07-18
ER

PT J
AU Fatty, A
   Li, AJ
   Qian, ZG
AF Fatty, Abdoulie
   Li, An-Jui
   Qian, Zhi-Guang
TI An interpretable evolutionary extreme gradient boosting algorithm for
   rock slope stability assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning algorithms; Extreme gradient boosting; Genetic
   algorithm; Slope stability prediction; Model interpretability
ID XGBOOST; OPTIMIZATION; PREDICTION; EARTHQUAKE; GA
AB Globally, slope failures cause severe disasters and substantial financial losses annually. Recent advancements in machine learning (ML) algorithms and dataset collection have created alternate solutions for complex slope stability problems. However, rock slope stability prediction remains a challenging problem due to factors such as inadequate data and insufficient generalization performance of rock slope prediction models. The black-box nature of AI models also causes further criticism of using such models to address issues such as slope stability. In this study, we proposed an artificial intelligence (AI) based technique for rock slope stability prediction based on evolutionary and ML algorithms. The proposed GA-XGBoost model uses XGBoost to model the relationship between the input and output parameters of rock slopes, while Genetic Algorithm (GA) optimizes the hyperparameters of XGBoost. A comprehensive rock slope database of 7525 slope cases is implemented in this study to develop and verify the model. The model attains an impressive performance score of R-2 = 0.9999, MAE = 0.8006, and RMSE = 1.8624 on the training dataset and R-2 = 0.9934, MAE = 2.2793, and RMSE = 11.1090 on the testing dataset. Furthermore, to assess the relative significance of the various influential slope parameters, the SHapley Additive exPlanations (SHAP) algorithm is implemented. This step enables the physical and quantitative interpretations of dependencies between the input and output variables. Generally, this relationship is hidden in traditional machine learning algorithms.
C1 [Fatty, Abdoulie; Li, An-Jui] Natl Taiwan Univ Sci & Technol, Dept Civil & Construct Engn, Taipei 106335, Taiwan.
   [Qian, Zhi-Guang] Deakin Univ, Sch Engn, Geelong, Vic 3220, Australia.
C3 National Taiwan University of Science & Technology; Deakin University
RP Fatty, A (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Civil & Construct Engn, Taipei 106335, Taiwan.
EM afatty13@gmail.com
OI Fatty, Abdoulie/0000-0002-8765-4220
CR Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Fatty A, 2024, IEEE CONSUM ELECTR M, V13, P73, DOI 10.1109/MCE.2022.3174334
   Ghosh JK, 2015, J COMPUT CIVIL ENG, V29, DOI 10.1061/(ASCE)CP.1943-5487.0000372
   Hoek E, 2019, J ROCK MECH GEOTECH, V11, P445, DOI 10.1016/j.jrmge.2018.08.001
   Huang Y, 2021, ENG GEOL, V289, DOI 10.1016/j.enggeo.2021.106198
   Kang F, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000514
   Khazai B, 2004, ENG GEOL, V71, P79, DOI 10.1016/S0013-7952(03)00127-3
   Li AJ, 2008, INT J ROCK MECH MIN, V45, P689, DOI 10.1016/j.ijrmms.2007.08.010
   Li AJ, 2022, KSCE J CIV ENG, V26, P1095, DOI 10.1007/s12205-021-1162-y
   Li AJ, 2020, J CHIN INST ENG, V43, P628, DOI 10.1080/02533839.2020.1719899
   Li YP, 2021, ENERGY, V225, DOI 10.1016/j.energy.2021.120331
   Lim S, 2019, ADV ENG INFORM, V41, DOI 10.1016/j.aei.2019.100922
   Lin Y, 2018, IEEE ACCESS, V6, P31169, DOI 10.1109/ACCESS.2018.2843787
   Lipton ZC., 2018, QUEUE, V16, P31, DOI 10.1145/3236386.3241340
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mangalathu S, 2020, ENG STRUCT, V219, DOI 10.1016/j.engstruct.2020.110927
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Moayedi H, 2020, ENG COMPUT-GERMANY, V36, P227, DOI 10.1007/s00366-018-00694-w
   Hoang ND, 2016, EXPERT SYST APPL, V46, P60, DOI 10.1016/j.eswa.2015.10.020
   Nobre J, 2019, EXPERT SYST APPL, V125, P181, DOI 10.1016/j.eswa.2019.01.083
   Pan SW, 2022, J PETROL SCI ENG, V208, DOI 10.1016/j.petrol.2021.109520
   Pandey M, 2022, ADV SPACE RES, V69, P3301, DOI 10.1016/j.asr.2022.02.027
   Qi CC, 2018, COMPUT IND ENG, V118, P112, DOI 10.1016/j.cie.2018.02.028
   Sagi O, 2021, INFORM SCIENCES, V572, P522, DOI 10.1016/j.ins.2021.05.055
   Shao KS, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132313452
   Song YQ, 2012, COMPUT GEOSCI-UK, V42, P189, DOI 10.1016/j.cageo.2011.09.011
   Vassallo K., 2019, J Comput Theor Nanosci, V16, P3854, DOI DOI 10.1166/JCTN.2019.8261
   Wang L, 2020, ACTA GEOTECH, V15, P3135, DOI 10.1007/s11440-020-00962-4
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yun KK, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115716
   Zednik C., 2019, PHILOS TECHNOLOGY, DOI [10.1007/s13347-019-00382-7, DOI 10.1007/S13347-019-00382-7]
   Zhang L., 2017, INT GEOPH C QINGD CH, DOI [10.1190/igc2017-351, DOI 10.1190/IGC2017-351]
   Zhao XL, 2020, AUTOMAT CONSTR, V113, DOI 10.1016/j.autcon.2020.103140
NR 34
TC 1
Z9 1
U1 13
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17445-9
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700014
DA 2024-07-18
ER

PT J
AU Anilkumar, P
   Venugopal, P
AF Anilkumar, P.
   Venugopal, P.
TI An adaptive multichannel DeepLabv3+for semantic segmentation of aerial
   images using improved Beluga Whale Optimization Algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semantic segmentation; Aerial images; Multi-channel; DeepLabv3+;
   Adaptive Multi-channel DeepLabv3+; Improved Beluga whale optimization;
   Hyperparameters
ID NETWORKS
AB Semantic segmentation of aerial images plays a pivotal role in extracting detailed information about land cover, infrastructure, and natural features. Traditional single-channel segmentation models struggle to harness the rich information present in multi-channel aerial images, such as multi-spectral or hyperspectral data. While the DeepLabV3 + architecture has shown remarkable success in semantic segmentation tasks by exploiting multi-scale context and atrous convolutions, its performance on aerial images remains suboptimal due to the unique challenges of this domain. With the motive of addressing the difficulties in the existing semantic segmentation techniques for aerial images, the adoption of deep learning techniques is utilized. A multi-objective derived Adaptive Multichannel deeplabv3 + (AMC-Deeplabv3 +) with a new meta-heuristic algorithm called Improved Beluga whale optimization (IBWO) algorithm is proposed in this paper. Here, the hyperparameters of Multichannel deeplabv3 + are optimized by the IBWO algorithm and this model intends to set new benchmarks in the accuracy and contextual understanding of aerial image segmentation by integrating multi-channel data processing techniques and preserving spatial context. The proposed model attains improved accuracies of 98.65% & 98.72% for dataset 1 and 2 respectively and also achieves the dice coefficient of 98.73% & 98.85% respectively, with a computation time of 113.0123 s. The evolutional outcomes of the proposed model show significantly better than the state-of-the-art techniques.
C1 [Anilkumar, P.; Venugopal, P.] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Venugopal, P (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM venugopal.p@vit.ac.in
CR Abdollahi A, 2021, IEEE ACCESS, V9, P64381, DOI 10.1109/ACCESS.2021.3075951
   Abro GEM, 2022, 2022 INT C FUT TREND, P218
   Akbari Y, 2020, IEEE ACCESS, V8, P153517, DOI 10.1109/ACCESS.2020.3017783
   Akcay O, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11010023
   Anand T, 2021, IEEE SENS J, V21, P17581, DOI 10.1109/JSEN.2021.3071290
   Anilkumar P, 2023, ARAB J SCI ENG, V48, P10745, DOI 10.1007/s13369-023-07717-9
   Anilkumar P, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/6010912
   Behera TK, 2023, SUSTAIN COMPUT-INFOR, V37, DOI 10.1016/j.suscom.2022.100841
   Behera TK, 2023, IEEE J-STARS, V16, P1771, DOI 10.1109/JSTARS.2023.3239119
   Cao ZY, 2019, IEEE GEOSCI REMOTE S, V16, P1766, DOI 10.1109/LGRS.2019.2907009
   Chakravarthy AS, 2022, IEEE T VEH TECHNOL, V71, P4277, DOI 10.1109/TVT.2022.3144358
   Chang GW, 2020, IEEE ACCESS, V8, P36180, DOI 10.1109/ACCESS.2020.2975107
   Chen KQ, 2018, IEEE GEOSCI REMOTE S, V15, P173, DOI 10.1109/LGRS.2017.2778181
   Deng G., 2022, IEEE Trans Geosci Remote Sens, V60, P1, DOI [10.1109/TGRS.2022.3229302, DOI 10.1109/TGRS.2022.3229302]
   Diao Q, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020305
   Esmael AA, 2018, MULTIMED TOOLS APPL, V77, P24565, DOI 10.1007/s11042-018-6023-4
   Girisha S, 2021, IEEE J-STARS, V14, P4115, DOI 10.1109/JSTARS.2021.3069909
   Gupta A, 2021, NEUROCOMPUTING, V439, P22, DOI 10.1016/j.neucom.2020.02.139
   He P, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3179379
   Hong Z, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3214929
   Huang ZF, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14061498
   Israr A, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9931112
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Khan SD, 2023, MULTIMED TOOLS APPL, V82, P42353, DOI 10.1007/s11042-023-14962-5
   Lee K, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3089623
   Li JH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3134277
   Liu CY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070771
   Liu WJ, 2020, IEEE ACCESS, V8, P131814, DOI 10.1109/ACCESS.2020.3009976
   Luo HF, 2019, IEEE J-STARS, V12, P3492, DOI 10.1109/JSTARS.2019.2930724
   Manickam R, 2020, EARTH SCI INFORM, V13, P1293, DOI 10.1007/s12145-020-00516-y
   Masayoshi K, 2022, Informatics in Medicine Unlocked, V32
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P7557, DOI 10.1109/TGRS.2020.2979552
   Sudo Y, 2020, IEEE/SICE I S SYS IN, P820, DOI [10.1109/SII46433.2020.9025963, 10.1109/sii46433.2020.9025963]
   Sun YJ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108352
   Ulmas P, 2020, arXiv preprintarXiv, V2003
   Volpi M, 2018, ISPRS J PHOTOGRAMM, V144, P48, DOI 10.1016/j.isprsjprs.2018.06.007
   Yadavendra, 2022, MULTIMED TOOLS APPL, V81, P44291, DOI 10.1007/s11042-022-12892-2
   Yao XD, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183617
   Zainal Nurezayana, 2013, Applied Mechanics and Materials, V421, P507, DOI 10.4028/www.scientific.net/AMM.421.507
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhong CT, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109215
   Zhou H, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/7981670
NR 42
TC 0
Z9 0
U1 16
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17247-z
EA OCT 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100010
DA 2024-07-18
ER

PT J
AU Samudrala, S
   Mohan, CK
AF Samudrala, Suresh
   Mohan, C. Krishna
TI Semantic segmentation of breast cancer images using DenseNet with
   proposed PSPNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Contrast enhancement; DenseNet-121; Pyramid scene parsing
   network; Attention gate and Semantic segmentation
ID DIAGNOSIS; NETWORK
AB For early detection of cancer tumors, the semantic segmentation based technique is proposed because the existing numerous methods fail while classifying due to accuracy and ineffectual decision-making. Therefore, in this paper, the hybrid semantic segmentation networks are introduced. In the beginning, the input image sets are applied into the pre-processing phase and after that, subject to the process of segmentation. The pre-processing process of image contrast enhancement is done by Adaptive Local Gamma Correction (ALGC). The semantic segmentation topology is done by using the hybrid network of the DenseNet-121 model with Attention based pyramid scene parsing network (Att-PSPnet). The feature map extraction and scene parsing are handled by the Att-PSPnet network. The Attention Gate mechanism is introduced to improve the quality of the high-dimensional hidden layer features by highlighting the useful information, and unnecessary information and noise are suppressed. To make the efficient decision and enhance prediction accuracy, the pyramid dilated convolution module (PDM) is a branch of the attention-based pyramid pooling module that enlarges the receptive field to extract global information. Additionally, the global average pooling (GAP) layer is introduced at the output of the feature map. The performance of the proposed method is validated using the Google Colab environment with a histologically confirmed dataset. The experimental results are compared with existing methods like FCN, Unet, and PSPNet in terms of IoU, accuracy, precision, recall, F1 score, IoU, and more. The proposed method achieves 94.68% prediction accuracy which is higher than the existing approaches.
C1 [Samudrala, Suresh] Indian Inst Technol Hyderabad IIT Hyderabad, Dept Comp Sci & Engn, Kandi, India.
   [Mohan, C. Krishna] Indian Inst Technol Hyderabad IIT Hyderabad, Dept Comp Sci & Engn & Dean Publ & Corp Relat, Kandi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Hyderabad; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Hyderabad
RP Samudrala, S (corresponding author), Indian Inst Technol Hyderabad IIT Hyderabad, Dept Comp Sci & Engn, Kandi, India.
EM cs19resch01002@iith.ac.in; ckm@cse.iith.ac.in
CR Acharya A, 2020, INT CONF ADVAN COMPU, P110, DOI [10.1109/ICACCS48705.2020.9074386, 10.1109/icaccs48705.2020.9074386]
   Ahmed L, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01680-1
   Akter O, 2021, APPL INTELL, V51, P3391, DOI 10.1007/s10489-020-02046-y
   AlEisa HN, 2022, Computational Intelligence and Neuroscience, V2022
   Altaf MM, 2021, MATH BIOSCI ENG, V18, P5029, DOI 10.3934/mbe.2021256
   Altini N, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10040396
   Amit G, 2017, Proc Med Imag, ComputAided Diagnosis, V10134, P374
   Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453
   Bouget D, 2019, INT J COMPUT ASS RAD, V14, P977, DOI 10.1007/s11548-019-01948-8
   Cho SW, 2022, J KING SAUD UNIV-COM, V34, P10273, DOI 10.1016/j.jksuci.2022.10.020
   Cho SW, 2020, IEEE ACCESS, V8, P93561, DOI 10.1109/ACCESS.2020.2994969
   Cui BE, 2020, IEEE ACCESS, V8, P116744, DOI 10.1109/ACCESS.2020.3003914
   Das N, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0286862
   Dhalla Sabrina, 2023, Procedia Computer Science, P328, DOI 10.1016/j.procs.2023.01.015
   Gómez-Flores W, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104036
   Gridach M, 2021, NEURAL NETWORKS, V140, P274, DOI 10.1016/j.neunet.2021.03.023
   Guo ZL, 2019, IEEE ACCESS, V7, P99381, DOI 10.1109/ACCESS.2019.2928646
   Heidler K, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3064606
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ing N, 2018, PROC SPIE, V10581, DOI 10.1117/12.2293000
   Lee H, 2020, IEEE T ULTRASON FERR, V67, P1344, DOI 10.1109/TUFFC.2020.2972573
   Liu P, 2019, IEEE ACCESS, V7, P37555, DOI 10.1109/ACCESS.2019.2903528
   Maji D, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103077
   Nascimento Carmina Dessana Lima, 2016, Res. Biomed. Eng., V32, P283
   Natarajan VA, 2020, INT C COMP INF TECHN, P1
   Qiu YC, 2017, J X-RAY SCI TECHNOL, V25, P751, DOI 10.3233/XST-16226
   Rasti R, 2017, PATTERN RECOGN, V72, P381, DOI 10.1016/j.patcog.2017.08.004
   Rezaei M, 2020, MULTIMED TOOLS APPL, V79, P15329, DOI 10.1007/s11042-019-7305-1
   Samala RK, 2017, PHYS MED BIOL, V62, P8894, DOI 10.1088/1361-6560/aa93d4
   Sha ZJ, 2020, INT J IMAG SYST TECH, V30, P495, DOI 10.1002/ima.22400
   Soulami KB, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102481
   Tang W, 2020, NEURAL COMPUT APPL, V32, P6769, DOI 10.1007/s00521-019-04700-0
   Turan S, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741715
   Youk JH, 2017, ULTRASONOGRAPHY, V36, P300, DOI 10.14366/usg.17024
   Zebari DA, 2020, IEEE ACCESS, V8, P203097, DOI 10.1109/ACCESS.2020.3036072
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Z, 2023, arXiv
   Zohair Al-Ameen Zohair Al-Ameen, 2015, Applied Medical Informatics, V36, P1
NR 38
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17411-5
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NY9
UT WOS:001088014100003
DA 2024-07-18
ER

PT J
AU Zhiou, A
   Njah, H
AF Zhiou, Asma
   Njah, Hasna
TI AZ-skin: Inclusive system for skin disease recognition from hybrid data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ensemble learning; Hybrid data fusion; Skin disease diagnosis; Web
   application
ID DIAGNOSIS; DESIGN
AB With the aim to alleviate the lack of accessibility to dermatologists, hundreds of skin care applications potentially assist patients in making decisions about their skin condition and about the need of dermatologists' visits. Most of the existing applications are not sufficiently inclusive. On the one hand, they hold the hypothesis that the patient actually has a skin issue (as opposed to the healthy/benignant cases). On the other hand, they do not consider the skin of color in the image-based diagnosis. In this article, we conduct a comprehensive framework for creating a smart web application for a thorough diagnosis of skin conditions' severity. Firstly, we collect a hybrid database that includes images and multivariate pathological data of many common skin disorders, while considering different skin tones. To achieve an optimized recognition of the skin condition, we carefully create a classification system that dynamically combines decisions regarding various data types. Our system employs a data-driven weighting mechanism and the ensemble learning approach. It considers the outstanding performance of classical classifiers, on multivariate symptoms' data, and on CNN-based pre-trained classifiers for clinical skin image data. With an F1-score of 0.92, the experimental findings have demonstrated the effectiveness of our contribution. A smart Web application called AZ-Skin was created using the promising outcomes of our proposed system.
C1 [Zhiou, Asma; Njah, Hasna] Univ Gabes, Higher Inst Comp Sci & multimedia, Gabes, Tunisia.
   [Njah, Hasna] Univ Sfax, MIRACL, Sfax, Tunisia.
C3 Universite de Gabes; Multimedia, InfoRmation Systems & Advancing
   Computing Laboratory (MIRACL); Universite de Sfax
RP Zhiou, A (corresponding author), Univ Gabes, Higher Inst Comp Sci & multimedia, Gabes, Tunisia.
EM asma.zhiou@isimg.tn; hasna.njah@isimg.tn
RI Njah, Hasna/P-5098-2019
OI Njah, Hasna/0000-0002-0050-7173
CR Arnold Andreas W, 2006, J Dtsch Dermatol Ges, V4, P319, DOI 10.1111/j.1610-0387.2006.05933.x
   Bartholomew D, 2010, Analysis and interpretation of multivariate data
   Carcagnì P, 2019, LECT NOTES COMPUT SC, V11751, P335, DOI 10.1007/978-3-030-30642-7_30
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Coustasse A, 2019, TELEMED E-HEALTH, V25, P1022, DOI 10.1089/tmj.2018.0130
   Dabowsa NIA, 2017, I C ENG TECHNOL
   Dadzie OE, 2013, Ethnic Dermatology
   Deepthi Y., 2020, Energy Systems, Drives and Automations. Proceedings of ESDA 2019. Lecture Notes in Electrical Engineering (LNEE 664), P561, DOI 10.1007/978-981-15-5089-8_55
   Demir A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P533, DOI [10.1109/tiptekno47231.2019.8972045, 10.1109/CLEOE-EQEC.2019.8871518]
   Dulmage B, 2020, J INVEST DERMATOL, V141, P1230, DOI 10.1016/j.jid.2020.08.027
   EFRON B, 1994, J AM STAT ASSOC, V89, P463, DOI 10.2307/2290846
   Esteva A, 2015, PROJECT REPORT
   Gaffney R., 2015, Global Dermatol, V2, P209, DOI 10.15761/GOD.1000156
   Gao JC, 2022, J AM ACAD DERMATOL, V86, pE133, DOI 10.1016/j.jaad.2021.10.043
   Giavina-Bianchi M, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.670300
   Gupta A, 2010, STAT PROBABIL LETT, V80, P816, DOI 10.1016/j.spl.2010.01.015
   Guvenir HA, 1998, ARTIF INTELL MED, V13, P147, DOI 10.1016/S0933-3657(98)00028-1
   Karimkhani C, 2017, JAMA DERMATOL, V153, P406, DOI 10.1001/jamadermatol.2016.5538
   Kawahara J, 2019, IEEE J BIOMED HEALTH, V23, P538, DOI 10.1109/JBHI.2018.2824327
   Kindler H, 1998, ST HEAL T, V52, P70
   Kiriakis Kyriakos P, 2012, Infez Med, V20, P105
   Leung K. M., 2007, Polytech Univ Dep Comput Sci Risk Eng, P123
   Li HF, 2021, NEUROCOMPUTING, V464, P364, DOI 10.1016/j.neucom.2021.08.096
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   Lovett L, 2021, Dermatology data sets lack ethnicity, skin type information
   MacGregor J., 2013, Predictive Analysis with SAP
   Maertens J, 2001, EUR J CANCER CARE, V10, P56, DOI 10.1046/j.1365-2354.2001.00241.x
   Okur E, 2018, ENG APPL ARTIF INTEL, V73, P50, DOI 10.1016/j.engappai.2018.04.028
   Pacheco AGC, 2020, DATA BRIEF, V32, DOI 10.1016/j.dib.2020.106221
   Pellacani G, 2002, CLIN DERMATOL, V20, P222, DOI 10.1016/S0738-081X(02)00231-6
   Pisner D.A., 2020, MACH LEARN, P101, DOI [DOI 10.1016/B978-0-12-815739-8.00006-7, 10.1016/B978-0-12-815739-8.00006-7]
   Pratiwi R.A., 2021, IAES International Journal of Artificial Intelligence, V10, P563, DOI [10.11591/ijai.v10.i3.pp563-570, DOI 10.11591/IJAI.V10.I3.PP563-570]
   Rathod Jainesh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1048, DOI 10.1109/ICECA.2018.8474593
   Raza MAA, 2019, INT CONF ADV COMP SC, P61, DOI 10.23919/icacs.2019.8689140
   Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smedley J, 2010, CLIN MED, V10, P487, DOI 10.7861/clinmedicine.10-5-487
   Sun XX, 2016, LECT NOTES COMPUT SC, V9910, P206, DOI 10.1007/978-3-319-46466-4_13
   SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972
   Taylor SC, 2002, J AM ACAD DERMATOL, V46, pS98, DOI 10.1067/mjd.2002.120791
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072
   Verma AK, 2020, APPL BIOCHEM BIOTECH, V190, P341, DOI 10.1007/s12010-019-03093-z
   Verma Anurag Kumar, 2019, Asian Pac J Cancer Prev, V20, P1887, DOI 10.31557/APJCP.2019.20.6.1887
   Weinberg J, 2009, PAN AFR MED J, V3
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Zhang XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0631-9
   Zhu CY, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.626369
NR 48
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17225-5
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400008
DA 2024-07-18
ER

PT J
AU Nogales, A
   Pérez-Lara, F
   García-Tejedor, AJ
AF Nogales, Alberto
   Perez-Lara, Fernando
   Garcia-Tejedor, Alvaro J.
TI Enhancing breast cancer diagnosis with deep learning and evolutionary
   algorithms: A comparison of approaches using different thermographic
   imaging treatments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical imaging; Thermography; Breast cancer diagnosis; Deep learning;
   Convolutional neural networks; Evolutive algorithm
AB The medical field has come a long way in recent years. This fact is directly related to the application of computer science, particularly artificial intelligence. Computer vision is one of its applications with the most significant knowledge transfer to private companies or organizations. Due to the large number of tests based on images, it has multiple benefits in medical diagnosis. These benefits go from health to economics, passing through time savings. Most people know X-rays or scanners, but others have not been applied too much like thermographies. Although they are inexpensive, non-invasive, painless, and easy to implement in remote areas, their scientific evidence is not very extended. In this paper, we evaluate different approaches based on four use cases depending on which treatment we applied to the images. This step leads to various scenarios that could benefit from using advanced hybrid Artificial Intelligence models. Evaluating the solutions will not only provide us with an accurate model. Still, it will also allow us to understand further how the different thermograph information influences the diagnosis. Results show that by separating the thermography by three ranges of temperatures and using a hybrid model of convolutional neural networks and evolutive algorithms, we can achieve accuracy near 94%.
C1 [Nogales, Alberto; Perez-Lara, Fernando; Garcia-Tejedor, Alvaro J.] Univ Francisco Vitoria, CEIEC Res Inst, Ctra M-515 Pozuelo Majadahonda Km 1-800, Madrid, Spain.
C3 Universidad Francisco de Vitoria
RP Nogales, A (corresponding author), Univ Francisco Vitoria, CEIEC Res Inst, Ctra M-515 Pozuelo Majadahonda Km 1-800, Madrid, Spain.
EM alberto.nogales@ceiec.es; fernando.perez.lara@outlook.com;
   a.gtejedor@ceiec.es
OI Nogales, Alberto/0000-0003-4951-8102
FU We also want to thank Avanade Ibrica for providing a scholarship under
   the Avanade-UFV Artificial Intelligence Chair agreement.
FX The work leading to these results has received funding from the
   "Programa estatal de generacion de conocimiento y fortalecimiento
   cientifico y tecnologico del sistema de I+D+i", in the context of the
   project "Cribado coste-efectivo de cancer de mama mediante mamografia,
   ecografia y termografia" (<EM>PID2019-110686RB-I00</EM>).We also want to
   thank Avanade Iberica for providing a scholarship under the Avanade-UFV
   Artificial Intelligence Chair agreement.r We also want to thank Avanade
   Iberica for providing a scholarship under the Avanade-UFV Artificial
   Intelligence Chair agreement.
CR Abdalla H. E. M., 2018, 2018 INT C COMP CONT, P1, DOI [10.1109/ICCCEEE.2018.8515763, DOI 10.1109/ICCCEEE.2018.8515763]
   Abdallah YMY, 2019, Medical Imaging-Principles and Applications
   Afantenos S, 2005, ARTIF INTELL MED, V33, P157, DOI 10.1016/j.artmed.2004.07.017
   Ahuja AS, 2019, PEERJ, V7, DOI 10.7717/peerj.7702
   Al Husaini MAS, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202538
   Alshehri A, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15030582
   Bayomi N, 2021, ENERG BUILDINGS, V233, DOI 10.1016/j.enbuild.2020.110648
   Belkin M, 2019, P NATL ACAD SCI USA, V116, P15849, DOI 10.1073/pnas.1903070116
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chebbah NK, 2023, QUANT INFR THERM J, V20, P62, DOI 10.1080/17686733.2021.2025018
   Daoud H, 2019, IEEE T BIOMED CIRC S, V13, P804, DOI 10.1109/TBCAS.2019.2929053
   Domino M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010191
   Egwom OJ., 2022, BioMedInformatics, V2, P345, DOI DOI 10.3390/BIOMEDINFORMATICS2030022
   Ensafi M, 2022, HEALTH TECHNOL-GER, V12, P1097, DOI 10.1007/s12553-022-00702-6
   Farooq S, 2023, APPL OPTICS, V62, pC80, DOI 10.1364/AO.477409
   Fusco R, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050815
   Gangadhar B., 2019, J. Stem Cells, V14, P35
   Ghafarpour A, 2016, BIOMED RES-INDIA, V27, P543
   Gogoi UR, 2019, INFRARED PHYS TECHN, V99, P201, DOI 10.1016/j.infrared.2019.01.004
   Hawkes PW., 2004, Advances in imaging and electron physics
   Hofvind S, 2012, J MED SCREEN, V19, P57, DOI 10.1258/jms.2012.012083
   Houssein EH, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115651
   Huang TS, 1996, CERN REPORT, V96, P21
   Ji Y, 2019, CANCER IMAGING, V19, DOI 10.1186/s40644-019-0252-2
   Jian Ma, 2019, Vibroengineering PROCEDIA. 40th International Conference on Vibroengineering, P57, DOI 10.21595/vp.2019.20978
   Jiang YL, 2021, RADIOLOGY, V298, P38, DOI 10.1148/radiol.2020200292
   Kadhim R. R., 2023, IAES International Journal of Artificial Intelligence, V12, P415, DOI [10.11591/ijai.v12.i1.pp415-421, DOI 10.11591/IJAI.V12.I1.PP415-421]
   Kakileti ST, 2020, JCO GLOB ONCOL, V6, P1472, DOI 10.1200/GO.20.00168
   Kakileti ST., 2022, Thermol Int, V31, P53
   Keyserlingk JR, 2000, IEEE ENG MED BIOL, V19, P30, DOI 10.1109/51.844378
   Khan AA, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5543101
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lahane SR., 2021, Ann Rom Soc Cell Biol, V25, P3459
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee Y, 2018, ACUTE CRIT CARE, V33, P117, DOI 10.4266/acc.2018.00290
   Morales-Cervantes A, 2018, EXCLI J, V17, P989, DOI 10.17179/excli2018-1735
   Nogales A, 2023, LECT NOTE NETW SYST, V543, P271, DOI 10.1007/978-3-031-16078-3_17
   Park HJ, 2019, Medicine, V98
   Pavithra P., 2018, Syst Rev Pharm, V9, P10, DOI [10.5530/srp.2018.1.3, DOI 10.5530/SRP.2018.1.3]
   Petrillo A, 2022, CANCERS, V14, DOI 10.3390/cancers14092132
   Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3
   Rim B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040969
   Roslidar R, 2020, IEEE ACCESS, V8, P116176, DOI 10.1109/ACCESS.2020.3004056
   Russell S., 2016, Artificial intelligence a modern approach
   Sánchez-Cauce R, 2021, COMPUT METH PROG BIO, V204, DOI 10.1016/j.cmpb.2021.106045
   Santana Maíra Araújo de, 2018, Res. Biomed. Eng., V34, P45, DOI 10.1590/2446-4740.05217
   Sathish D, 2019, VISUAL COMPUT, V35, P57, DOI 10.1007/s00371-017-1447-9
   Saurkar A V., 2018, International Journal on Future Revolution in Computer Science Communication Engineering, V4, P363
   Seo H, 2021, TUNN UNDERGR SP TECH, V116, DOI 10.1016/j.tust.2021.104118
   Silva LF, 2014, J MED IMAG HEALTH IN, V4, P92, DOI 10.1166/jmihi.2014.1226
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tello-Mijares Santiago, 2019, J Healthc Eng, V2019, P9807619, DOI 10.1155/2019/9807619
   Wiley V., 2018, Int. J. Artif. Intell. Res, V2, P29, DOI DOI 10.29099/IJAIR.V2I1.42
   Wu T, 2019, BREAST CANCER RES TR, V173, P365, DOI 10.1007/s10549-018-4984-7
   Zuluaga-Gomez J, 2021, COMP M BIO BIO E-IV, V9, P131, DOI 10.1080/21681163.2020.1824685
NR 58
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17281-x
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900007
DA 2024-07-18
ER

PT J
AU Li, HJ
   Li, JX
AF Li, Hongjun
   Li, Jiaxin
TI TMTB: Transformer based multi-task branching multi-object tracking
   algorithm for wide-view scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-object tracking; Multi-task branches; Wide-view scenes; Unmanned
   aerial vehicle; Transformer
ID INTERNET
AB Combining Unmanned aerial vehicle (UAV) with artificial intelligence can effectively extract information as UAV fly flexibly and have a wide view, but the current processing efficiency of the video information acquired by UAV is low, resulting in insufficient use of resources. In order to enable the tracking algorithm to adapt to wide-angle target scenes and fully utilize the acquired information, we propose a transformer based multi-task branching multi-object tracking algorithm named TMTB. Firstly, a transformer architecture backbone network is designed for extracting target features; then, feature enhancement of multi-stage features through differently focused task branches to suit different objectives in a broad view; finally, the tracking algorithm is optimised according to the motion characteristics of the target in the scene to achieve multi-object tracking in UAV scenes. Experimental results on the VisDrone-MOT2019, and the MOTA is improved by 5.9% compared to JDE, and the operation speed is improved by 75%. The proposed algorithm has good real-time performance and good tracking effect.
C1 [Li, Hongjun; Li, Jiaxin] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 1713071046@stmail.ntu.edu.cn
RI Li, Jiaxin/GOV-4862-2022
OI li, hongjun/0000-0001-7500-4979
FU National Natural Science Foundation of China [61971245, 61976120];
   Nantong Science and Technology Program [JC2021131]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61971245 and Grant 61976120, in part by Nantong
   Science and Technology Program JC2021131
CR Abualigah L, 2021, IEEE SENS J, V21, P25532, DOI 10.1109/JSEN.2021.3114266
   Alavi AH, 2018, MEASUREMENT, V129, P589, DOI 10.1016/j.measurement.2018.07.067
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Castellano G, 2020, IEEE ACCESS, V8, P64534, DOI 10.1109/ACCESS.2020.2984768
   Chanak P, 2020, IEEE T CONSUM ELECTR, V66, P223, DOI 10.1109/TCE.2020.2987433
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chu P, 2023, IEEE WINT CONF APPL, P4859, DOI 10.1109/WACV56688.2023.00485
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dong QS, 2023, MULTIMED TOOLS APPL, V82, P149, DOI 10.1007/s11042-022-12964-3
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HJ, 2023, Multimed. Tools Appl., P1
   Li HJ, 2023, MULTIMED TOOLS APPL, V82, P12557, DOI 10.1007/s11042-022-13834-8
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Parmar N, 2018, PR MACH LEARN RES, V80
   Perreault H, 2020, 2020 17TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2020), P230, DOI 10.1109/CRV50864.2020.00038
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Rezaee Khosro, 2024, Personal and Ubiquitous Computing, V28, P135, DOI 10.1007/s00779-021-01586-5
   Rezaee K, 2023, IEEE T IND INFORM, V19, P813, DOI 10.1109/TII.2022.3174160
   Sharaff Aakanksha, 2020, International Journal of Web-Based Learning and Teaching Technologies, V15, P19, DOI 10.4018/IJWLTT.2020040102
   Sharaff A, 2023, INT J BIOMETRICS, V15, P459, DOI 10.1504/IJBM.2023.130653
   Sharma SK, 2020, IEEE COMMUN SURV TUT, V22, P426, DOI 10.1109/COMST.2019.2916177
   Shidik GF, 2019, IEEE ACCESS, V7, P170457, DOI 10.1109/ACCESS.2019.2955387
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vaswani A, 2017, ADV NEUR IN, V30
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JL, 2021, PROC CVPR IEEE, P12347, DOI 10.1109/CVPR46437.2021.01217
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhao LQ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030537
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 45
TC 0
Z9 0
U1 13
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17255-z
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800015
DA 2024-07-18
ER

PT J
AU Dash, P
   Dara, S
   Mishra, J
AF Dash, Priyanka
   Dara, Suresh
   Mishra, Jyotirmaya
TI A fuzzy inference supportive social media market analysis for predicting
   crowd influence in national elections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Social media marketing; Fuzzy inference; Crowds
   interest prediction; Machine intelligence
AB The interest of the crowd plays a vital role at national level elections not only to predict the influence of participating parties but also to make marketing strategies for the campaign. Beyond person-to-person interaction, social media is also used by society to put their views, comments, and interest toward political parties and their candidates. But, due to the large volume, variety, and velocity of social media data, it becomes difficult to analyze. Moreover, the extracted information from social tweets also raises issues of biased information. Here, in this work, a fuzzy inference supportive framework is proposed to study crowds' preference on social media platforms to make campaign strategies by the political parties in national-level elections. The proposed approach utilizes tweets from Twitter, LinkedIn, and Instagram to predict the crowd's influence on political parties. Further, the approach can be utilized by the parties to change the campaign strategy. In experimentation, the approach is tested on the real-time dataset collected from the social network websites, and found that the proposed approach is performing well to predict the user's interest. Also, when compared with existing methods, the proposed approach's performance is found significant over other methods.
C1 [Dash, Priyanka; Mishra, Jyotirmaya] GIET Univ, Dept Comp Sci & Engn, Gunupur 765022, India.
   [Dara, Suresh] PACE Inst Technol & Sci Autonomous, Dept Comp Sci & Engn, Ongole 523272, Andhra Pradesh, India.
C3 GIET University
RP Dara, S (corresponding author), PACE Inst Technol & Sci Autonomous, Dept Comp Sci & Engn, Ongole 523272, Andhra Pradesh, India.
EM priyankadash2018@gmail.com; darasuresh@live.in; jyoti@giet.edu
RI Dara, Suresh/K-3809-2012
OI Dara, Suresh/0000-0002-1626-8701
CR Ali H, 2022, SOFT COMPUT, V26, P7535, DOI 10.1007/s00500-021-06569-5
   Arora A, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2019.101941
   Babac MB, 2018, INFORM TECHNOL PEOPL, V31, P327, DOI 10.1108/ITP-08-2016-0200
   Bayrak C, 2023, IEEE T COMPUT SOC SY, V10, P2362, DOI 10.1109/TCSS.2022.3178052
   Bermingham Adam, 2011, On using twitter to monitor political sentiment and predict election results, P2
   Brito K, 2022, Gov Inf Quart
   Budiharto W, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0164-1
   Cameron MP, 2016, J POLITICAL MARKETIN, V15, P416, DOI 10.1080/15377857.2014.959690
   Chauhan P, 2021, J AMB INTEL HUM COMP, V12, P2601, DOI 10.1007/s12652-020-02423-y
   Choi J, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102279
   Geissinger A, 2021, J KNOWL MANAG, V25, P500, DOI 10.1108/JKM-01-2020-0038
   He W, 2018, J Enterp Inf Manag
   Ibrahim M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1348, DOI 10.1109/ICDMW.2015.113
   Jose R, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P64, DOI 10.1109/SAPIENCE.2016.7684133
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kristiyanti DA, 2019, PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON NEW MEDIA STUDIES (CONMEDIA 2019), P36, DOI [10.1109/conmedia46929.2019.8981823, 10.1109/CONMEDIA46929.2019.8981823]
   Li YM, 2017, INFORM MANAGE-AMSTER, V54, P638, DOI 10.1016/j.im.2016.12.006
   Martín-Rojas R, 2020, J BUS RES, V112, P396, DOI 10.1016/j.jbusres.2019.11.072
   Moe WW, 2014, SOCIAL MEDIA INTELLIGENCE, P1, DOI 10.1017/CBO9781139381338
   Neri F, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P919, DOI 10.1109/ASONAM.2012.164
   Pan YT, 2019, J INTERNET COMMER, V18, P73, DOI 10.1080/15332861.2019.1567187
   Ramteke J, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 1, P107
   Sharma P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1966, DOI 10.1109/BigData.2016.7840818
   Shawky S, 2020, J BUS RES, V121, P567, DOI 10.1016/j.jbusres.2020.03.030
   Sobaci MZ, 2016, PUB ADMIN INF TECH, V15, P265, DOI 10.1007/978-3-319-17722-9_14
   Stieglitz S, 2018, INT J INFORM MANAGE, V39, P156, DOI 10.1016/j.ijinfomgt.2017.12.002
   Valos MJ, 2017, J MARKET MANAG-UK, V33, P1522, DOI 10.1080/0267257X.2017.1410211
   Zhang XD, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208190
NR 28
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17181-0
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600010
DA 2024-07-18
ER

PT J
AU Pal, T
   Halder, M
   Barua, S
AF Pal, Tannistha
   Halder, Mritunjoy
   Barua, Sattwik
TI A transmission model based deep neural network for image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Foggy; Dynamic; Transmission; Deep neural network
AB In recent years, one of the main contributors to traffic fatalities and poor vision in poor weather conditions has been rising. In order to lower accident rates, improving visibility is essential for driver assistance systems, image acquisition, and surveillance systems. Thus, as a result, this research introduces a novel Deep Neural Network (DNN) based on a scattering model for defogging an image that has been affected with fog. The proposed model consists of two components: the fog dilution model and the diluted fog removal model. In addition, we have incorporated a deep learning-based transmission estimation module. The fog dilution model is designed to mitigate the presence of fog, while the diluted fog removal model aims to completely eliminate the remaining fog. To enhance the accuracy of transmission estimation, we employ a green channel prior-based approach. This approach effectively reduces the distortion caused in the sky in the resulting defogged image. By combining these components, our model offers a comprehensive solution for fog removal, with improved image quality and reduced sky artifacts. In addition to addressing the shortcomings of current vision enhancement techniques as mentioned in the paper, the proposed method also satisfies human perceptual needs. Experimental results have demonstrated that the proposed model delivers superior visibility enhancement results for both non-reference and full-reference metrics following a qualitative comparison with eight state-of-the-art defogging techniques. The experimental results have proven that the proposed method achieves superior performance in terms of qualitative evaluation on non-reference metric (i.e., in terms of e = 0.50, sigma = 0.15, r = 1.49) and reference metric (i.e. in terms of MSE= 397.16, PSNR = 23.38, NCC = 0.99, MD= 24.39, NAE = 0.13) compared with eight state-of-the-art dehazing methods. Furthermore, based on the average computational time achieved by the proposed method (0.17 s using HSTS dataset), it can be highly suitable for real-time applications. The suggested approach could therefore be employed as a viable route for improving vision in surveillance and acquisition systems while lowering the risk to users' safety.
C1 [Pal, Tannistha] Natl Inst Technol Agartala NITA, Dept Comp Sci & Engn, Agartala 799046, Tripura, India.
   [Halder, Mritunjoy] Indian Inst Engn Sci & Technol Shibpur IIESTS, Dept Informat Technol, Bot Garden, Howrah 711103, West Bengal, India.
   [Barua, Sattwik] Indian Inst Engn Sci & Technol Shibpur IIESTS, Dept Comp Sci & Technol, Bot Garden, Howrah 711103, West Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala
RP Pal, T (corresponding author), Natl Inst Technol Agartala NITA, Dept Comp Sci & Engn, Agartala 799046, Tripura, India.
EM tannisthapaul@gmail.com; mritunjoy.ug2019@it.iiests.ac.in;
   sattwik.cst.iiest@gmail.com
OI Pal, Tannistha/0000-0002-1317-7599
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Ngo D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185170
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   Dong F, 2016, P 8 INT C SIGN PROC, P56
   Gang D., 2018, P 2 INT C INNOVATIO, P116
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hooda A, 2022, MOL CRYST LIQ CRYST, V726, P90, DOI 10.1080/15421406.2021.1935162
   Jackson J, 2020, IEEE ACCESS, V8, P73330, DOI 10.1109/ACCESS.2020.2988144
   Jackson JK, 2018, PROCEEDINGS OF 2018 THE 3RD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2018), P110, DOI 10.1145/3195588.3195608
   Jiang YT, 2017, COMPUT VIS IMAGE UND, V165, P17, DOI 10.1016/j.cviu.2017.10.014
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li JF, 2015, NEUROCOMPUTING, V156, P1, DOI 10.1016/j.neucom.2015.01.026
   Li LRH, 2020, IEEE T IMAGE PROCESS, V29, P2766, DOI 10.1109/TIP.2019.2952690
   Li Z, 2021, INT C PATT RECOG, P8267, DOI 10.1109/ICPR48806.2021.9412595
   Liang J, 2015, OPT EXPRESS, V23, P26146, DOI 10.1364/OE.23.026146
   Liu Z, 2019, IEEE SIGNAL PROC LET, V26, P833, DOI 10.1109/LSP.2019.2910403
   Mei W, 2019, IEEE INT CONF ELECTR, P579, DOI [10.1109/ICEIEC.2019.8784493, 10.1109/iceiec.2019.8784493]
   Murthy NS, 2021, J INFORM OPTIM SCI, V42, P29, DOI 10.1080/02522667.2019.1643562
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Ancuti CO, 2018, Arxiv, DOI arXiv:1804.05091
   Organization WH, 2015, Global status report on road safety 2015
   Outay F, 2021, PERS UBIQUIT COMPUT, V25, P51, DOI 10.1007/s00779-019-01334-w
   Pal T, 2022, MULTIMED TOOLS APPL, V81, P35317, DOI 10.1007/s11042-022-12182-x
   Pal T, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2583, DOI 10.1109/TENCON.2016.7848504
   Sahu Geet, 2019, 2019 International Conference on Information Technology (ICIT), P388, DOI 10.1109/ICIT48102.2019.00075
   Salazar-Colores S, 2019, IEEE T IMAGE PROCESS, V28, P2357, DOI 10.1109/TIP.2018.2885490
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song YD, 2023, IEEE T IMAGE PROCESS, V32, P1927, DOI 10.1109/TIP.2023.3256763
   Tan JH, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16193709
   Wriedt T., 2012, The Mie Theory: Basics and Applications, P53, DOI [DOI 10.1007/978-3-642-28738-1, DOI 10.1007/978-3-642-28738-1_2]
   Xu JB, 2019, INT J EMBED SYST, V11, P84, DOI 10.1504/IJES.2019.097574
   Yang D, 2021, IEEE ACCESS, V9, P108542, DOI 10.1109/ACCESS.2021.3101319
   Yang GQ, 2021, J REAL-TIME IMAGE PR, V18, P2511, DOI 10.1007/s11554-021-01143-6
   Yang Y, 2021, SIGNAL IMAGE VIDEO P, V15, P1443, DOI 10.1007/s11760-021-01876-8
   Yu J., 2018, P 3 INT C MULTIMEDIA, P41
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhou Y., 2022, IEEE Trans Neural Netw Learn Syst
NR 45
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17010-4
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600025
DA 2024-07-18
ER

PT J
AU Adiraju, R
   Elias, S
AF Adiraju, Ramavasantha
   Elias, Susan
TI A quantitative analysis of imaging features in lung CT images using the
   RW-T hybrid segmentation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung nodule segmentation; Lung CT images; Single-click ensemble
   segmentation; Random-walk algorithm; Quantitative imaging features;
   Dice-similarity
ID PULMONARY NODULES
AB Lung cancer is the leading cause of cancer death worldwide. A lung nodule is the most common symptom of lung cancer. The analysis of lung cancer relies heavily on the segmentation of nodules, which aids in optimal treatment planning. However, because there are several lung nodules, accurate segmentation remains challenging. We propose an RW-T hybrid approach capable of segmenting all types of nodules, primarily externally attached nodules (juxta-pleural and juxta-vascular), and estimate the effect of nodule segmentation techniques to assess the quantitative Computer Tomography (CT) imaging features in lung adenocarcinoma. On 301 lung CT images from 40 patients with lung adenocarcinoma cases from the LungCT- Diagnosis dataset publicly available in The Cancer Imaging Archive, we used a random-walk strategy and a thresholding method to implement nodule segmentation (TCIA). We extracted two quantitative CT features from the segmented nodule using morphological techniques: convexity and entropy scores. The proposed method's resultant segmented nodules are compared to the single-click ensemble segmentation method and validated using ground-truth segmented nodules. Our proposed segmentation approach had a high level of agreement with ground truth delineations, with a dice-similarity coefficient of 0.7884, compared to single-click ensemble segmentation, with a dice-similarity metric of 0.6407.
C1 [Adiraju, Ramavasantha; Elias, Susan] Vellore Inst Technol, Sch Elect Engn, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Elias, S (corresponding author), Vellore Inst Technol, Sch Elect Engn, Chennai, India.
EM susan.elias@vit.ac.in
OI vasantha adiraju, rama/0000-0003-0981-9090
CR Adiraju Rama Vasantha, 2021, Research on Biomedical Engineering, V37, P403, DOI 10.1007/s42600-021-00138-3
   Araujo LH., 2020, Cancer of the Lung: Non-Small Cell Lung Cancer and Small Cell Lung Cancer, Sixth, VEdition
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen YT, 2010, PATTERN RECOGN, V43, P3699, DOI 10.1016/j.patcog.2010.05.027
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dehmeshi J, 2008, IEEE T MED IMAGING, V27, P467, DOI 10.1109/TMI.2007.907555
   Djenouri Y, 2022, IEEE Sensors J
   Ferlay J., 2018, Global Cancer Observatory: Cancer Today, V3, P2019
   Funke W, 2020, PROC SPIE, V11314, DOI 10.1117/12.2548496
   Ganeshan B, 2012, EUR RADIOL, V22, P796, DOI 10.1007/s00330-011-2319-8
   Gatenby RA, 2013, RADIOLOGY, V269, P8, DOI 10.1148/radiol.13122697
   Goldgof Dmitry HL, 2017, Cancer Imaging Archive
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Grove O, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248541
   Grove O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118261
   Gu YH, 2013, PATTERN RECOGN, V46, P692, DOI 10.1016/j.patcog.2012.10.005
   Hao R, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2183847
   Hawkins SH, 2014, IEEE ACCESS, V2, P1418, DOI 10.1109/ACCESS.2014.2373335
   Henschke CI, 1999, LANCET, V354, P99, DOI 10.1016/S0140-6736(99)06093-6
   Kostis WJ, 2003, IEEE T MED IMAGING, V22, P1259, DOI 10.1109/TMI.2003.817785
   Li XX, 2020, IEEE ACCESS, V8, P37541, DOI 10.1109/ACCESS.2020.2968936
   Lu KK, 2011, COMPUT BIOL MED, V41, P780, DOI 10.1016/j.compbiomed.2011.06.014
   MacMahon H, 2017, RADIOLOGY, V284, P228, DOI 10.1148/radiol.2017161659
   Mukhopadhyay S, 2016, J DIGIT IMAGING, V29, P86, DOI 10.1007/s10278-015-9801-9
   Nie Q, 2021, MOBILE NETW APPL, V26, P404, DOI 10.1007/s11036-020-01675-4
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Parmar C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102107
   Paul R, 2016, TOMOGRAPHY, V2, P388, DOI 10.18383/j.tom.2016.00211
   Qi LL, 2020, EUR RADIOL, V30, P744, DOI 10.1007/s00330-019-06344-z
   Rego John, 2006, Perm J, V10, P26
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   S P Shayesteh, 2020, J Biomed Phys Eng, V10, P479, DOI 10.31661/JBPE.V0I0.1027
   Savic M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051908
   Siegel RL, 2022, CA-CANCER J CLIN, V72, P7, DOI 10.3322/caac.21708
   Sun XJ, 2022, MOBILE NETW APPL, V27, P784, DOI 10.1007/s11036-021-01907-1
   Tao Y, 2009, LECT NOTES COMPUT SC, V5762, P715
   Valente IRS, 2016, COMPUT METH PROG BIO, V124, P91, DOI 10.1016/j.cmpb.2015.10.006
   Velazquez ER, 2013, SCI REP-UK, V3, DOI 10.1038/srep03529
   Wang S, 2017, IEEE ENG MED BIO, P1752, DOI 10.1109/EMBC.2017.8037182
   Wu DJ, 2010, PROC CVPR IEEE, P2791, DOI 10.1109/CVPR.2010.5540008
   Xiang DH, 2011, IEEE T VIS COMPUT GR, V17, P1295, DOI 10.1109/TVCG.2010.239
   Xiao ZT, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111787
   Xiuhua G., 2011, Theory and Applications of CT Imaging and Analysis
   Yushkevich PA, 2019, NEUROINFORMATICS, V17, P83, DOI 10.1007/s12021-018-9385-x
   Yushkevich PA, 2016, IEEE ENG MED BIO, P3342, DOI 10.1109/EMBC.2016.7591443
   Zhang GB, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1327-0
NR 46
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16557-6
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100019
DA 2024-07-18
ER

PT J
AU Cao, YL
   Wu, WJ
   Zhou, ZH
   Xu, HQ
   Yue, WL
   Zhuge, S
AF Cao, Yinglie
   Wu, Wenjin
   Zhou, Zhiheng
   Xu, Haoqi
   Yue, Wanlin
   Zhuge, Shang
TI Fast CU patition based on image similarity using neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; CU partition; Image similarity; Neural network
ID TRUTH
AB High Efficiency Video Coding (HEVC) has introduced a quad-tree (QT) based coding unit (CU) partition structure, which has significantly improved the compression performance compared with Advanced Video Coding (AVC). However, the use of rate-distortion optimization (RDO) techniques in the search for the optimal CU partition has increased the encoding complexity of the video. In this paper, we propose a fast CU partitioning algorithm based on image similarity, which makes decisions on the partitioning of the parent CU by comparing the similarity of the image content of four sub-CUs. We propose four different neural networks based on this algorithm, and experimental results demonstrate that our proposed network structure reduces encoding time by 59.8%, 58.7%, 58.5%, and 59.3% respectively, while increasing the Bjontegaard delta bit-rate (BDBR) by 2.32%, 1.99%, 1.82%, and 1.91%, respectively.
C1 [Cao, Yinglie] Guangzhou City Univ Technol, Guangzhou 510030, Peoples R China.
   [Wu, Wenjin; Zhou, Zhiheng; Xu, Haoqi; Yue, Wanlin; Zhuge, Shang] South China Univ Technol, Guangzhou 510641, Peoples R China.
C3 South China University of Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Guangzhou 510641, Peoples R China.
EM caoyl@gcu.edu.cn; ly1997030408@163.com; zhouzh@scut.edu.cn;
   jiacinker@163.com; 202121014322@mail.scut.edu.cn;
   202221013537@mail.scut.edu.cn
FU National Key Research and Development Program of China
FX The work is supported by the National Key Research and Development
   Program of China(2022YFF0607000), National Natural Science Foundation of
   China (61871188), Guangdong Basic and Applied Basic Research Foundation
   (2023A1515010993), Guangdong Provincial Key Laboratory of Human Digital
   Twin (2022B1212010004), Guangzhou City Science and Technology Research
   Projects (2023B01J0011).
CR Amna Maraoui, 2022, 2022 19th International Multi-Conference on Systems, Signals & Devices (SSD), P480, DOI 10.1109/SSD54932.2022.9955731
   Amna M, 2022, MULTIMED TOOLS APPL, V81, P2777, DOI 10.1007/s11042-021-11678-2
   Amna M, 2021, 2020 10TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), DOI 10.1109/ISIVC49222.2021.9487529
   Chen ZB, 2020, IEEE T IMAGE PROCESS, V29, P5431, DOI 10.1109/TIP.2020.2982832
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Duanmu F, 2016, IEEE J EM SEL TOP C, V6, P517, DOI 10.1109/JETCAS.2016.2597698
   Erabadda B, 2019, I SYMP CONSUM ELECTR
   Feng ZQ, 2018, IEEE ACCESS, V6, P45262, DOI 10.1109/ACCESS.2018.2864881
   Hari Pattimi, 2022, 2022 IEEE International Symposium on Smart Electronic Systems (iSES), P548, DOI 10.1109/iSES54909.2022.00120
   Hou JP, 2013, PROCEEDINGS 2013 INTERNATIONAL CONFERENCE ON MECHATRONIC SCIENCES, ELECTRIC ENGINEERING AND COMPUTER (MEC), P1096, DOI 10.1109/MEC.2013.6885226
   Hu N, 2015, IEEE T CIRC SYST VID, V25, P1521, DOI 10.1109/TCSVT.2015.2395772
   Hu Q, 2016, IEEE INT SYM BROADB
   Imen W, 2022, SIGNAL IMAGE VIDEO P, V16, P1811, DOI 10.1007/s11760-022-02139-w
   Kim K, 2019, IEEE T CIRC SYST VID, V29, P1462, DOI 10.1109/TCSVT.2018.2839113
   Kim N, 2016, IEEE INT SYM BROADB
   Kuang W, 2020, IEEE T IMAGE PROCESS, V29, P170, DOI 10.1109/TIP.2019.2924810
   Lee D, 2017, SIGNAL PROCESS-IMAGE, V55, P121, DOI 10.1016/j.image.2017.03.019
   Li ZM, 2019, SIGNAL PROCESS-IMAGE, V75, P141, DOI 10.1016/j.image.2019.03.018
   Liu XG, 2019, IEEE T CIRC SYST VID, V29, P144, DOI 10.1109/TCSVT.2017.2777903
   Menon VV, 2021, IEEE INT WORKSH MULT, DOI 10.1109/MMSP53017.2021.9733517
   Ruiz-Coll D, 2014, IEEE IMAGE PROC, P4112, DOI 10.1109/ICIP.2014.7025835
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen Y, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P363, DOI 10.1109/ICSPCC.2014.6986216
   Shi H, 2015, 2014 INT C AUD LANG
   Shi J, 2019, 2019 IEEE INT S CIRC
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang ZX, 2021, MULTIMED TOOLS APPL, V80, P2441, DOI 10.1007/s11042-020-09231-8
   Werda I, 2022, 2022 IEEE 9 INT C SC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zaki F, 2021, AIN SHAMS ENG J, V12, P1859, DOI 10.1016/j.asej.2021.01.001
   Zhang MM, 2019, MULTIMED TOOLS APPL, V78, P1035, DOI 10.1007/s11042-018-6105-3
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang YM, 2019, ACM T STORAGE, V15, DOI 10.1145/3289604
   Zhang Y, 2018, IEEE T CIRC SYST VID, V28, P3208, DOI 10.1109/TCSVT.2017.2747659
   Zhao L, 2014, SIGNAL PROCESS-IMAGE, V29, P935, DOI 10.1016/j.image.2014.06.008
   Zhao Rifa, 2023, Signal and Information Processing, Networking and Computers: Proceedings of the 8th International Conference on Signal and Information Processing, Networking and Computers (ICSINC). Lecture Notes in Electrical Engineering (917), P996, DOI 10.1007/978-981-19-3387-5_119
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33185
EP 33205
DI 10.1007/s11042-023-16962-x
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001073965700016
DA 2024-07-18
ER

PT J
AU Srivastava, RP
   Umrao, LS
   Yadav, RS
AF Srivastava, Ratnesh Prasad
   Umrao, Lokendra Singh
   Yadav, Ramjeet Singh
TI Real-time yoga pose classification with 3-D pose estimation model with
   LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Deep learning; Pose Estimation; Recurrent Neural
   Networks; Yoga
AB Yoga has now become a part of life for humans all over the globe enabling them to unite the body with the mind, helping in achieving a healthy lifestyle in the modern day. Practicing yoga with a trainer is always recommended to get maximum benefit but with this fast-paced lifestyle getting time for a lesson with a trainer or under proper guidance gets difficult and also sometimes middle-class families cannot bear the cost of a trainer. Therefore, a system is required which is accessible to everyone and can help in performing yoga poses and improving. This paper introduces a novel framework developed for estimating yoga poses through computer vision using a 3-D top-down semantic key landmark estimator with a Recurrent Neural Network (RNN) for classification. For training and validation of our model, we tailored our custom dataset of 10 different yoga poses having a total of 300 sequences. The model on the dataset gave an average of 92.34% accuracy using Long Short-Term Memory (LSTM) classifier.
C1 [Srivastava, Ratnesh Prasad] Guru Ghasidas Vishwavidyala, CSIT Dept, Bilaspur, India.
   [Umrao, Lokendra Singh] Dr Rammanohar Lohia Avadh Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Faizabad, India.
   [Yadav, Ramjeet Singh] Dr Rammanohar Lohia Avadh Univ, Dept Business Management & Entrepreneurship, Ayodhya, India.
C3 Guru Ghasidas Vishwavidyalaya
RP Umrao, LS (corresponding author), Dr Rammanohar Lohia Avadh Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Faizabad, India.
EM lokendra.rs.cse12@iitbhu.ac.in
RI UMRAO, LOKENDRA/I-5586-2013
OI UMRAO, LOKENDRA/0000-0001-6362-4476
CR Agrawal Y, 2020, INT CONF COMM SYST, P40, DOI [10.1109/CSNT48778.2020.9115758, 10.1109/CSNT.2020.08]
   Ann OC, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM COMPUTING AND ENGINEERING, P389, DOI 10.1109/ICCSCE.2014.7072750
   Ashraf Faisal Bin, 2023, SN Comput Sci, V4, P198, DOI 10.1007/s42979-022-01618-8
   Bazarevsky V, 2020, ARXIV
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Garg Shubham, 2023, Journal of Ambient Intelligence and Humanized Computing, P16551, DOI 10.1007/s12652-022-03910-0
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain S, 2021, NEURAL COMPUT APPL, V33, P6427, DOI 10.1007/s00521-020-05405-5
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin X, 2015, 2015 IEEE 16TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P460, DOI 10.1109/ICCT.2015.7399879
   Jose J., 2021, IOP C SERIES MAT SCI, V1110, P1
   Lustrek Mitja., 2009, INFORMATICA, V33, P205
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   machinelearningmastery.com, US
   Nagalakshmi Vallabhaneni DPP., 2021, Turkish J of Computer and Mathematics Education, V12, P1772, DOI [DOI 10.17762/TURCOMAT.V12I6.4032, 10.17762/turcomat.v12i6.4032]
   Palanimeera J, 2021, MATER TODAY-PROC, V37, P2930, DOI 10.1016/j.matpr.2020.08.700
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Quan J., 2019, arXiv
   Ramachandra S., 2021, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Wang L, 2015, ARXIV
   Yadav SK, 2019, NEURAL COMPUT APPL, V31, P9349, DOI 10.1007/s00521-019-04232-7
   Zhang ZF, 2020, NEUROCOMPUTING, V410, P304, DOI 10.1016/j.neucom.2020.06.032
NR 26
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33019
EP 33030
DI 10.1007/s11042-023-17036-8
EA SEP 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400015
DA 2024-07-18
ER

PT J
AU Thomas, NM
   Jerome, SA
AF Thomas, Neetha Merin
   Jerome, S. Albert
TI Diabetic retinopathy detection using EADBSC and improved dilated
   ensemble CNN-based classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic Retinopathy (DR); Bilateral filter; CLAHEU technique; Extended
   Adaptive Density-Based Spatial Clustering (EADBSC); Ensemble CNN; And
   Improved dilated ensemble CNN Classifier
ID LESION DETECTION; SYSTEM; SEGMENTATION
AB Nowadays high-rated and active research in the ophthalmic field has paved the way for the detection of several retinal disorders which helps the ophthalmologist, in scheduling and executing timely treatment. Due to more number of retinal defective patients and less number of medical professionals regular screening is one the most difficult tasks. The primary objective of this research work is to help doctors and other medical professionals predict the diabetic retinopathy. Here in this research article work retina fundus images are taken from the both Public dataset and the in-house clinical dataset from Chaithanya Eye Hospital Kerala. The first stage is to remove noise from the input image and enhance the contrast of the images. For noise reduction, a Bilateral Filter is utilized first, followed by enhancement utilizing Contrast Limited Adaptive Histogram Equalization with an unsharp technique. Then Thick Blood vessels are segmented from the enhanced image using the Extended Adaptive Density-Based Spatial Clustering (EADBSC) Method. The segmented image is fed to the classifier such as Ensemble CNN & Improved dilated ensemble CNN classification, which classifies the image as Diabetic Retinopathy (DR) or Normal case. Using Ensemble CNN, an accuracy of 97.46% is obtained. Improved dilated ensemble CNN-based classifier has an accuracy of 99.19%. By way of their efficiency estimation, the improved dilated ensemble CNN classifier is higher than most standard classifiers. It is also hoped that the developed automatic detection techniques will assist clinicians to diagnose Diabetic Retinopathy at an early stage.
C1 [Thomas, Neetha Merin] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, TamilNadu, India.
   [Jerome, S. Albert] Noorul Islam Ctr Higher Educ, Dept Biomed Engn, Kumaracoil, TamilNadu, India.
RP Thomas, NM (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, TamilNadu, India.
EM neethamthomas156@gmail.com; albertjerome@niuniv.com
RI Thomas, Neetha Merin/KCJ-4830-2024; JEROME, S ALBERT/AAJ-5555-2021
OI JEROME, S ALBERT/0009-0008-0155-8053; Thomas, Neetha
   Merin/0000-0002-6309-402X
FU The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of freely-accessible Public Messidor, Kaggle
   EyePACS dataset of diabetic retinopathy. Then we; Noorul Islam Center
   for Higher Education; Kaggle EyePACS
FX The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of freely-accessible Public Messidor, Kaggle
   EyePACS dataset of diabetic retinopathy. Then we would like to
   acknowledge Chaithanya Eye hospital Kerala for providing the in-house
   clinical data. Finally, we would like to thank the anonymous reviewers
   for helping to organize this text.
CR Abdallah M.B., 2011, Eighth International Multi-Conference on Systems, Signals Devices, P1, DOI [10.1109/SSD.2011.5767376, DOI 10.1109/SSD.2011.5767376]
   Abràmoff MD, 2010, OPHTHALMOLOGY, V117, P1147, DOI 10.1016/j.ophtha.2010.03.046
   Abramoff MD, 2008, DIABETES CARE, V31, P193, DOI 10.2337/dc07-1312
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Aziz T, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28680-3
   Benita Jeglin B, 2014, AUTOMATED FEATURE EX, V2, P1
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Cai YX, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6316140
   Das D, 2023, MULTIMED TOOLS APPL, V82, P29943, DOI 10.1007/s11042-022-14165-4
   Duan XT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247253
   Eren L, 2019, J SIGNAL PROCESS SYS, V91, P179, DOI 10.1007/s11265-018-1378-3
   Foundation Consumer Healthcare, EYEPACS DIAB RET DET
   Ganesh S, 2015, INT J SCI TECHNOL MA, V4
   Gu K, 2014, IEEE IMAGE PROC, P511, DOI 10.1109/ICIP.2014.7025102
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Inamullah, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8020187
   Ishtiaq U, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101816
   Jero S, 2021, IEEE REAL TIME, P1, DOI 10.1109/RTAS52030.2021.00009
   Jie Cao, 2021, 2021 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS), P709, DOI 10.1109/ICPICS52425.2021.9524125
   Kumar P, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116290
   Kumar S, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105815
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Lin CL, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05293-1
   Manjula Sri R., 2019, INT J ENG ADV TECHNO, V8, P52
   Mardani K, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102837
   Memari N, 2019, J MED BIOL ENG, V39, P713, DOI 10.1007/s40846-018-0454-2
   Nanni L, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135796
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Prakash NB, 2016, J CHEM PHARM RES, V8, P637
   Rajalakshmi R, 2018, EYE, V32, P1138, DOI 10.1038/s41433-018-0064-9
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P4571, DOI 10.1007/s11760-023-02693-x
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P3873, DOI 10.1007/s11760-023-02616-w
   Rani KV, 2023, MULTIMED TOOLS APPL, V82, P47477, DOI 10.1007/s11042-023-15716-z
   Rani KV, 2021, J AMB INTEL HUM COMP, V12, P7667, DOI 10.1007/s12652-020-02485-y
   Rani KV, 2020, INT J IMAG SYST TECH, V30, P899, DOI 10.1002/ima.22422
   Rani N, 2019, P 2019 GLOB C ADV TE, P1, DOI DOI 10.1109/GCAT47503.2019.8978422
   Sahoo M, 2017, MEASUREMENT, V101, P138, DOI 10.1016/j.measurement.2017.01.027
   Sebastian A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13085111
   Sharma C, 2014, AUTOMATIC DIAGNOSIS, V4, P591
   Sheikh S., 2020, Int. J. Simul. Syst. Sci. Technol, DOI [10.5013/IJSSST.a.21.02.16, DOI 10.5013/IJSSST.A.21.02.16, 10.5013/ijssst.a.21.02.16]
   Skouta A, 2023, MULTIMED TOOLS APPL, V82, P41701, DOI 10.1007/s11042-023-15110-9
   Sundaram S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13051001
   Tian SS, 2023, NEUROCOMPUTING, V545, DOI 10.1016/j.neucom.2023.126300
   Toto L, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040474
   Tsiknakis N, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104599
   Uppamma Posham, 2023, J Healthc Eng, V2023, P2728719, DOI 10.1155/2023/2728719
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wang HD, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2021.107670
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wong RL, 2020, EUR J OPHTHALMOL, V20, P1
   Yaqoob MK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113883
   You GR, 2022, INFORM SCIENCES, V606, P292, DOI 10.1016/j.ins.2022.05.064
   Zhang W, 2021, IEEE J BIOMED HEALTH, V25, P2988, DOI 10.1109/JBHI.2020.3046771
NR 54
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33573
EP 33595
DI 10.1007/s11042-023-16923-4
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100011
DA 2024-07-18
ER

PT J
AU Xiao, F
   Luo, HY
   Zhang, WL
   Li, Z
   Gao, XP
AF Xiao, Fen
   Luo, Huiyu
   Zhang, Wenlei
   Li, Zhen
   Gao, Xieping
TI Fusion hierarchy motion feature for video saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video saliency detection; Motion feature fine-tuning; Hierarchical
   fusion; Optical flow
ID OBJECT DETECTION; MODEL; NETWORK; EYE
AB Saliency detection plays an important role in computer vision and scene understanding, which has attracted increasing attention in recent years. Compared to the widely studied image saliency prediction, there are still many problems to be solved in the area of video saliency. Different from images, effectively describing and utilizing the motion information contained in video data is a critical issue. In this paper, we propose a spatial and motion dual-stream framework for video saliency detection. The coarse motion features extracting from optical flow are fine-tuned with higher level semantic spatial features via a residual cross-connection. A hierarchical fusion structure is proposed to maintain contextual information by integrating spatial and motion features in each level. To model the inter-frame correlation in the video, the convolutional gated recurrent unit (convGRU) is used to retain global consistency of the saliency area between neighbor frames. Experimental results on four widely used datasets demonstrate the effectiveness of the proposed method with other state-of-the-art methods. Our source codes can be acquired at https://github.com/banhuML/MFHF.
C1 [Xiao, Fen; Luo, Huiyu; Zhang, Wenlei; Li, Zhen] Xiangtan Univ, MOE Key Lab Intelligent Comp & Informat Proc, Xiangtan, Hunan, Peoples R China.
   [Gao, Xieping] Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language Inf, Changsha, Hunan, Peoples R China.
C3 Xiangtan University; Hunan Normal University
RP Gao, XP (corresponding author), Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp & Language Inf, Changsha, Hunan, Peoples R China.
EM xiaof@xtu.edu.cn; xpgao@hunnu.edu.cn
RI Zhang, Wenlei/ISS-4106-2023
OI Zhang, Wenlei/0000-0001-5126-4135; Xiao, Fen/0000-0001-7511-9418
FU This research was supported by the National Science and Technology Major
   Project (Grant No. 2020YFA0713504), the National Natural Science
   Foundation of China (Nos. 62376238, 62372170), and the Scientific
   Research Foundation of Education Department of Hunan [2020YFA0713504];
   National Science and Technology Major Project [62376238, 62372170];
   National Natural Science Foundation of China [21A0109]; Scientific
   Research Foundation of Education Department of Hunan Province of China
FX This research was supported by the National Science and Technology Major
   Project (Grant No. 2020YFA0713504), the National Natural Science
   Foundation of China (Nos. 62376238, 62372170), and the Scientific
   Research Foundation of Education Department of Hunan Province of China
   (Grant Nos. 21A0109)
CR Abrams RA, 2003, PSYCHOL SCI, V14, P427, DOI 10.1111/1467-9280.01458
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Ballas N., 2015, arXiv
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen CLZ, 2022, IEEE T CIRC SYST VID, V32, P7662, DOI 10.1109/TCSVT.2022.3185252
   Chen CLZ, 2022, IEEE T CIRC SYST VID, V32, P2732, DOI 10.1109/TCSVT.2021.3095843
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CLZ, 2018, IEEE T MULTIMEDIA, V20, P3324, DOI 10.1109/TMM.2018.2839523
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen JZ, 2021, NEUROCOMPUTING, V462, P59, DOI 10.1016/j.neucom.2021.07.088
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cizmeciler K, 2022, MULTIMED TOOLS APPL, V81, P17457, DOI 10.1007/s11042-022-12442-w
   Cong R, 2022, IEEE T EMERG TOP COM
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Craye C, 2016, IEEE INT CONF ROBOT, P2303, DOI 10.1109/ICRA.2016.7487379
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Gao D., 2005, P ADV NEUR INF PROC, P481
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Guo CL, 2008, PROC CVPR IEEE, P2908
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang XG, 2015, 2015 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices (ASEMD), P262, DOI 10.1109/ASEMD.2015.7453564
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Jiang L, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107234
   Jiang L, 2018, LECT NOTES COMPUT SC, V11218, P625, DOI 10.1007/978-3-030-01264-9_37
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kingma D. P., 2014, arXiv
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Li YX, 2020, IEEE T MULTIMEDIA, V22, P1153, DOI 10.1109/TMM.2019.2940851
   Linardos P, 2019, ARXIV
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu NA, 2018, IEEE T NEUR NET LEAR, V29, P392, DOI 10.1109/TNNLS.2016.2628878
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154
   Min K, 2019, IEEE I CONF COMP VIS, P2394, DOI 10.1109/ICCV.2019.00248
   Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith TJ, 2013, J VISION, V13, DOI 10.1167/13.8.16
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Teed Zachary, 2020, EUR C COMP VIS, P402, DOI [DOI 10.1007/978-3-030-58536-524, DOI 10.1007/978-3-030-58536-5_24]
   Ullah J, 2018, MULTIMED TOOLS APPL, V77, P7429, DOI 10.1007/s11042-017-4655-4
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang G, 2021, ARXIV
   Wang W, 2020, IEEE T CYBERNETICS, V50, P3973, DOI 10.1109/TCYB.2019.2917078
   Wang XF, 2020, MULTIMED TOOLS APPL, V79, P7413, DOI 10.1007/s11042-019-08535-8
   Wang Z, 2020, IEEE transactions on cybernetics
   Wang Z, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107275
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P4529, DOI 10.1109/TIP.2018.2837106
   Xu M, 2015, IEEE I CONF COMP VIS, P3907, DOI 10.1109/ICCV.2015.445
   Xue H, 2022, NEUROCOMPUTING, V468, P233, DOI 10.1016/j.neucom.2021.10.024
   Zhang FH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10787, DOI 10.1109/ICCV48922.2021.01063
   Zhang K, 2019, IEEE T CIRC SYST VID, V29, P3544, DOI 10.1109/TCSVT.2018.2883305
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang P, 2020, NEUROCOMPUTING, V377, P256, DOI 10.1016/j.neucom.2019.10.024
   Zhao YT, 2022, NEUROCOMPUTING, V476, P1, DOI 10.1016/j.neucom.2021.12.076
   Zou WB, 2021, PATTERN RECOGN LETT, V147, P78, DOI 10.1016/j.patrec.2021.04.010
NR 69
TC 0
Z9 0
U1 9
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32301
EP 32320
DI 10.1007/s11042-023-16593-2
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400001
DA 2024-07-18
ER

PT J
AU Busa, S
   Somala, J
   Kumar, KK
   Syed, K
   Radhika, KSR
   Ankala, R
AF Busa, Srikanth
   Somala, Jayaprada
   Kumar, K. Kranthi
   Syed, Khasim
   Radhika, K. S. R.
   Ankala, Radhika
TI An efficient breast cancer classification and segmentation system by an
   intelligent gated recurrent framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast MRI image; Cancer cell segmentation; Deep networks; Optimization;
   Feature analysis; Disease tracking
AB One of the most cautious diseases that produced an increased death rate around the world is breast cancer. The early detection of this disease can save the lives of people. Therefore, an efficient detection and segmentation model is required to detect and classify cancer cells. Several past studies required more robust features and have gained more complexity because of the irrelevant features. Hence, a novel Buffalo-based Gated recurrent Cancer cell segmentation (BGRCS) has been implemented for segmenting the cancer cell in the oriented breast MRI images. Initially, the noise features were traced and eliminated using the preprocessing function. Moreover, the segmentation and classification function has been executed with dual classes: cancer and non-cancerous images. Consequently, the disease feature has been tracked for the classified cancerous images, and the buffalo function of the system segmented the traced features. It has earned meaningful features and reduced the computational time to train the system. Finally, the performance was valued and compared with other past studies. The designed framework has gained the highest segmentation accuracy over the compared models.
C1 [Busa, Srikanth] Kallam Haranadhareddy Inst Technol, Dept Comp Sci & Engn, Guntur 522019, Andhra Prades, India.
   [Somala, Jayaprada] Lakireddy Bali Reddy Coll Engn, Dept Comp Sci & Engn, Mylavaram 521230, Andhra Prades, India.
   [Kumar, K. Kranthi] Vasireddy Venkatadri Inst Technol, Dept Informat Technol, Namburu 522508, Andhra Prades, India.
   [Syed, Khasim] VIT AP Univ, Dept Comp Sci & Engn, Amaravati 522237, Andhra Prades, India.
   [Radhika, K. S. R.] TKR Coll Engn & Technol, Dept Comp Sci & Engn, Meerpet 500097, Telangana, India.
   [Ankala, Radhika] SRK Inst Technol, Dept Comp Sci & Engn, Vijayawada 521108, Andhra Prades, India.
C3 VIT-AP University
RP Busa, S (corresponding author), Kallam Haranadhareddy Inst Technol, Dept Comp Sci & Engn, Guntur 522019, Andhra Prades, India.
EM srikanth.busa@gmail.com; jayasomala@gmail.com; kk97976@gmail.com;
   syed.khasim@vitap.ac.in; kammilisrr@gmail.com; radhikaankala@gmail.com
RI Busa, Dr. Srikanth/AEE-8043-2022; Konduru, Dr.Kranthi
   Kumar/AAW-9407-2021
OI Busa, Dr. Srikanth/0000-0003-0639-0743; Konduru, Dr.Kranthi
   Kumar/0000-0002-8419-7386
CR Bacolod MD, 2020, BMC CANCER, V20, DOI 10.1186/s12885-020-6574-4
   Benhammou Y, 2020, NEUROCOMPUTING, V375, P9, DOI 10.1016/j.neucom.2019.09.044
   Chaudhary PK, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102237
   Dembrower K, 2020, RADIOLOGY, V294, P265, DOI 10.1148/radiol.2019190872
   Deshmukh PP, 2019, SENSOR ACTUAT B-CHEM, V281, P8, DOI 10.1016/j.snb.2018.10.072
   dos Santos JCM, 2020, RES BIOMED ENG, P1, DOI DOI 10.1007/S42600-020-00046-Y
   Du J, 2021, IEEE T CYBERNETICS, V51, P1586, DOI 10.1109/TCYB.2020.2969705
   Gong XN, 2019, MULTIMED TOOLS APPL, V78, P31185, DOI 10.1007/s11042-019-07917-2
   Gupta V, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102265
   Han Y, 2023, BIOMED SIGNAL PROCES, V86, DOI 10.1016/j.bspc.2023.105208
   Hu QY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67441-4
   Inan MSK, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103553
   Kashif M., 2020, Innovation in Health Informatics, P145
   Khalil R, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-019-0103-y
   Kim E, 2023, IEEE J TRANSL ENG HE, V11, P32, DOI 10.1109/JTEHM.2022.3221918
   Kumar M, 2020, ALGO INTELL SY, P113, DOI 10.1007/978-981-15-0994-0_7
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Li W, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/6978650
   Madhavan S, 2020, IEEE SENS J, V20, P3078, DOI 10.1109/JSEN.2019.2956072
   Mittal H, 2022, MULTIMED TOOLS APPL, V81, P35001, DOI 10.1007/s11042-021-10594-9
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Panhalkar AR, 2022, J KING SAUD UNIV-COM, V34, P4763, DOI 10.1016/j.jksuci.2021.01.011
   Patil RS, 2021, EVOL INTELL, V14, P1459, DOI 10.1007/s12065-020-00403-x
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Qin CB, 2022, SOFT COMPUT, V26, P8317, DOI 10.1007/s00500-022-07235-0
   Rahimpour M, 2023, EUR RADIOL, V33, P959, DOI 10.1007/s00330-022-09113-7
   Ravi V, 2023, IEEE T ENG MANAGE, V70, P249, DOI 10.1109/TEM.2021.3059664
   Sadhukhan Subham, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P113, DOI 10.1007/978-981-13-7403-6_12
   Sanyal R, 2022, IEEE ACM T COMPUT BI, V19, P2124, DOI 10.1109/TCBB.2021.3071022
   Sheela CJJ, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101657
   Ul Haq I, 2022, ENG SCI TECHNOL, V36, DOI 10.1016/j.jestch.2022.101154
   Yadav SS, 2022, MULTIMED TOOLS APPL, V81, P13139, DOI 10.1007/s11042-020-09600-3
   Yang X, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104373
   Yu XF, 2022, MULTIVAR BEHAV RES, V57, P112, DOI 10.1080/00273171.2020.1809981
   Zhang Y, 2021, EUR RADIOL, V31, P2559, DOI 10.1007/s00330-020-07274-x
   Zhang YG, 2021, NAT HAZARDS, V105, P783, DOI 10.1007/s11069-020-04337-6
   Zhao C, 2022, MULTIMED TOOLS APPL, V81, P24265, DOI 10.1007/s11042-022-12670-0
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
   Zhong Y, 2023, ARXIV
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31567
EP 31586
DI 10.1007/s11042-023-16826-4
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200003
DA 2024-07-18
ER

PT J
AU Liang, S
   Tian, SW
   Yu, L
   Kang, XJ
AF Liang, Shuang
   Tian, Shengwei
   Yu, Long
   Kang, Xiaojing
TI Improved U-Net based on contour attention for efficient segmentation of
   skin lesion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Medical image segmentation;
   Attention mechanism; Skin lesions
ID PROSTATE-CANCER; MRI; CLASSIFICATION; ULTRASOUND
AB In the field of skin disease diagnosis, the segmentation of lesions is a crucial step in auxiliary diagnosis. The U-Net network has achieved many successes in the field of medical segmentation. However, due to the relatively simple encoder and decoder of traditional U-Net, it is easy to be affected by factors such as small sample size, insufficient feature expression, and irregular shape of segmented targets, the good features cannot be extracted, resulting in incorrect segmentation results. In order to solve these problems and improve the performance of lesion segmentation. We designed a new U-Net network by improving the traditional architecture in two ways: 1) We replaced the encoder with a robust classification network to effectively extract feature information. 2) To thoroughly exploit the potential perceptual clues in the multi-scale feature maps generated by the encoder, we designed the Multi-Scale Depth Feature Exploration (MSD) module as the decoder. Additionally, we propose a novel segmentation loss function named Weighted Contour Cross Entropy loss (WCCE), which forces the network pay more attettion to lesion contour information and improve the contour quality of lesion segmentation to achieve better segmentation accuracy. All experiments were conducted on two skin lesion datasets, ISIC2018 and XJUSL. Experimental analysis reveals that the improved U-Net assisted with proposed loss surpasses the traditional U-Net and other typical methods in the performance of all evaluation metrics used in this study. This result reflects that the proposed method can effectively segment the lesion contour and improve the performance of lesion segmentation.
C1 [Liang, Shuang; Tian, Shengwei] Xinjiang Univ, Collage Software, Urumqi 830000, Peoples R China.
   [Liang, Shuang; Tian, Shengwei] Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830000, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Network Ctr, Urumqi 830000, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830000, Peoples R China.
   [Kang, Xiaojing] Peoples Hosp Xinjiang Uygur AutonomousReg, Dept Dermatol & Venereol, Urumqi 830000, Peoples R China.
   [Kang, Xiaojing] Xinjiang Clin Res Ctr Dermatol Dis, Urumqi 830000, Peoples R China.
   [Kang, Xiaojing] Xinjiang Key Lab Dermatol Res XJYS1707, Urumqi 830000, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University; Xinjiang
   University
RP Tian, SW (corresponding author), Xinjiang Univ, Collage Software, Urumqi 830000, Peoples R China.; Tian, SW (corresponding author), Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830000, Peoples R China.; Kang, XJ (corresponding author), Peoples Hosp Xinjiang Uygur AutonomousReg, Dept Dermatol & Venereol, Urumqi 830000, Peoples R China.; Kang, XJ (corresponding author), Xinjiang Clin Res Ctr Dermatol Dis, Urumqi 830000, Peoples R China.; Kang, XJ (corresponding author), Xinjiang Key Lab Dermatol Res XJYS1707, Urumqi 830000, Peoples R China.
EM 107552101645@stu.xju.edu.cn; tianshengwei@163.com; yul_xju@163.com;
   drkangxj666@163.com
FU Xinjiang Uygur Autonomous Region Key R D program
FX The authors thank the research assistances and all staff of Xinjiang
   Uygur Autonomous Region Key R&\documentclass[12pt]{minimal}
   \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts}
   \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs}
   \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt}
   \begin{document}$$ \& $$\end{document}D program and National Natural
   Science Foundation of China.
CR Bokhovkin A, 2019, LECT NOTES COMPUT SC, V11555, P388, DOI 10.1007/978-3-030-22808-8_38
   Chen L.-C., 2018, Pertanika J. Trop. Agric. Sci., P801, DOI [10.1007/978-3-030-01234-2_49, DOI 10.1007/978-3-030-01234-249, DOI 10.1007/978-3-030-01234-2_49]
   Codella N, 2019, Arxiv, DOI arXiv:1902.03368
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Dong CX, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106321
   Duan JW, 2023, MED PHYS, V50, P2715, DOI 10.1002/mp.16299
   Elashiri MA, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103729
   Han Q, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kervadec H, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101851
   Li DA, 2022, COMPUT METH PROG BIO, V213, DOI 10.1016/j.cmpb.2021.106493
   Liang S, 2023, BIOMED SIGNAL PROCES, V86, DOI 10.1016/j.bspc.2023.105187
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Yang X, 2022, Multimed Syst, P1
   Yong L, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31935-8
   Alom MZ, 2018, Arxiv, DOI arXiv:1802.06955
   Zhang B, 2022, MED PHYS, V49, P7025, DOI 10.1002/mp.15848
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 27
TC 1
Z9 1
U1 9
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33371
EP 33391
DI 10.1007/s11042-023-16759-y
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200009
DA 2024-07-18
ER

PT J
AU Bansal, S
   Bansal, RK
   Bhardwaj, R
AF Bansal, Savina
   Bansal, R. K.
   Bhardwaj, Rahul
TI A novel low complexity retinex-based algorithm for enhancing low-light
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinex-based; Low-light image enhancement; Gray transformation;
   Histogram equalization; RBMP
ID HISTOGRAM EQUALIZATION; ENHANCEMENT
AB Retinex-based algorithms, drawing inspiration from the human visual system biology, have emerged as favored techniques in literature for enhancing low-light images. These algorithms aim to mitigate the adverse effects of poor illumination conditions, such as- narrow gray range, low brightness, low contrast, color distortion, and noise- thereby rendering the images more suitable for both human observation and computer processing. This paper presents a low-complexity Improved Retinex-based Multi-Phase algorithm (IRBMP) designed specifically for low light image enhancement. Performance of the proposed algorithm is analysed on the benchmark low-light image dataset Ex-Dark in comparison to various state-of-the-art retinex-based as well as traditional algorithms- MSRCP, NPE, SRIE, RBMP, AHE, log-transform, gamma-transform, and adaptive-sigmoid-transfer-function(ASTF). The proposed algorithm outperforms the baseline RBMP as well as the comparison algorithms in both subjective and objective metrics, such as BRISQUE and NIQE, indicating improved image quality. Additionally, the proposed method demonstrates faster computational time in comparison to other Retinex-based approaches, making it a promising candidate for real-time image processing applications.
C1 [Bansal, Savina; Bansal, R. K.; Bhardwaj, Rahul] Maharaja Ranjit Singh Punjab Tech Univ, Coll Engn & Technol, Giani Zail Singh Campus, Bathinda 151001, Pb, India.
RP Bansal, S (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Coll Engn & Technol, Giani Zail Singh Campus, Bathinda 151001, Pb, India.
EM savina.bansal@gmail.com; drrakeshkbansal@gmail.com;
   rahul28bhardwaj@gmail.com
CR Al-Hashim MA, 2020, TRAIT SIGNAL, V37, P733, DOI 10.18280/ts.370505
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gómez P, 2019, MED BIOL ENG COMPUT, V57, P1451, DOI 10.1007/s11517-019-01965-4
   Guo JW, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14558
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   JOURLIN M, 1988, J MICROSC-OXFORD, V149, P21, DOI 10.1111/j.1365-2818.1988.tb04559.x
   Kang SB, 2010, PROC CVPR IEEE, P1799, DOI 10.1109/CVPR.2010.5539850
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Le-Peng L. I., 2014, COMPUT SYST APPL, V23, P1
   Liu SX, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060746
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   Park S, 2018, INT J GASTROINT INT, V7, P36, DOI [10.18528/gii160029, 10.5573/IEIESPC.2018.7.1.036]
   Peng LY, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1805.11227
   Petrol AB, 2014, IMAGE PROCESS ON LIN, V4, P71, DOI 10.5201/ipol.2014.107
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Singh G., 2014, INT J INNOV SCI RES, V10, P262
   Singh S., 2012, Int. J. Sci. Eng. Res., V3, P1
   Singh S., 2012, Int. J. Adv. Res. Comput. Sci. Softw. Eng., V2, P125
   Srinivas K, 2020, IET IMAGE PROCESS, V14, P668, DOI 10.1049/iet-ipr.2019.0781
   Wang H, 2017, CHIN OPT, V10, P438, DOI 10.3788/CO.20171004.0438
   Wang L, 2019, IEEE INT CONF MULTI, P276, DOI 10.1109/ICMEW.2019.00054
   Wang ML, 2020, IEEE ACCESS, V8, P63162, DOI 10.1109/ACCESS.2020.2983457
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Wu Q, 2002, P ANN INT IEEE EMBS, P1067, DOI 10.1109/IEMBS.2002.1106280
NR 35
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29485
EP 29504
DI 10.1007/s11042-023-16610-4
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900013
DA 2024-07-18
ER

PT J
AU Ma, ZW
   Yao, GL
AF Ma, Zhiwei
   Yao, Guilin
TI Temporal-spatial information mining and aggregation for video matting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double decoder; Spatial continuity; Temporal coherence; Video matting
AB In previous video matting methods, there are some problems that require additional auxiliary information and lack of temporal consistency. To solve these problems, we propose a novel video matting framework (STMI-Net) based on temporal-spatial information mining and aggregation. This framework doesn't require any auxiliary information and adopts a double decoder network structure, specifically, one decoder is composed of the recurrent network, which can make full use of the temporal information in the video frames to ensure the temporal coherence in results; and the other decoder is composed of the convolution network, which deeply restores the frame-by-frame spatial features to achieve the spatial continuity in results. By aggregating these two parts of the information at the global level, our model achieves 0.0066 MSE on the VideoMatte240K dataset, which surpasses the RVM baseline by 13%; and achieves 0.0047 MSE on PPM-100 portrait matting dataset, which surpasses the MG baseline by 26.5%. We also implement an ablation study to demonstrate the specific functions of the temporal decoder and the spatial decoder in our model.
C1 [Ma, Zhiwei; Yao, Guilin] Harbin Univ Commerce, Xuehai St, Harbin 150028, Heilongjiang, Peoples R China.
C3 Harbin University of Commerce
RP Ma, ZW (corresponding author), Harbin Univ Commerce, Xuehai St, Harbin 150028, Heilongjiang, Peoples R China.
EM mzw3652@gmail.com; glyao@hrbcu.edu.cn
RI Ma, Zhiwei/GPX-5773-2022
OI Ma, Zhiwei/0000-0002-3802-9111
FU Youth Innovation Talent Support Program of Harbin University of Commerce
   [2020CX39]
FX This work is supported by the Youth Innovation Talent Support Program of
   Harbin University of Commerce (No. 2020CX39).
CR Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Q, 2018, ARXIV
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Erofeev M., 2015, P BRIT MACH VIS C BM, DOI [DOI 10.5244/C.29.99, 10.5244/C.29.99]
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Ge WB, 2021, PROC CVPR IEEE, P16831, DOI 10.1109/CVPR46437.2021.01656
   He K., 2011, CVPR, P2049, DOI DOI 10.1109/CVPR.2011.5995495
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Kahn JM, 2007, J CRIT CARE, V22, P97, DOI 10.1016/j.jcrc.2006.09.003
   Ke Z., 2020, ARXIV
   Levin A., 2006, Proceedings of the International Conference on Computer Vision and Pattern Recognition, P61, DOI [10.1109/CVPR.2006.18, DOI 10.1109/TPAMI.2007.1177]
   Lin S., 2022, arXiv
   Lin SC, 2021, PROC CVPR IEEE, P8758, DOI 10.1109/CVPR46437.2021.00865
   Liu YH, 2022, J APPL STAT, V49, P1323, DOI 10.1080/02664763.2021.1913103
   Lu X., 2019, ARXIV
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lutz S, 2018, ARXIV
   Mahmoud M, 2011, LECT NOTES COMPUTER, V6974
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Sengupta S, 2020, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR42600.2020.00236
   Seong H, 2022, LECT NOTES COMPUT SC, V13689, P430, DOI 10.1007/978-3-031-19818-2_25
   Shi X., 2015, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1506.04214
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sun YN, 2021, PROC CVPR IEEE, P6971, DOI 10.1109/CVPR46437.2021.00690
   Wang J, 2007, PROC CVPR IEEE, P281
   Wang QM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108540
   Wang TT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4882, DOI 10.1109/ICCV48922.2021.00486
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Xu N, 2017, ARXIV
   Yu QH, 2021, PROC CVPR IEEE, P1154, DOI 10.1109/CVPR46437.2021.00121
NR 32
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29221
EP 29237
DI 10.1007/s11042-023-16747-2
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400010
DA 2024-07-18
ER

PT J
AU Suryawanshi, S
   Goswami, A
   Patil, P
AF Suryawanshi, Shubhangi
   Goswami, Anurag
   Patil, Pramod
TI FakeIDCA: Fake news detection with incremental deep learning based
   concept drift adaption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Deep learning; Incremental learning; Concept drift
AB Social media facilitates rapid information sharing, improving exposure, connections, and content promotion. However, it also poses the challenge of fake news, which can mislead and harm individuals physically, and mentally, and incite violence. Fake news is often known as incorrect or misleading information. Prior research used Machine Learning (ML) and Deep Learning (DL) techniques for fake news detection. These studies predominantly relied on static offline models, overlooking the dynamic and evolving nature of news patterns, assuming their stability over time. Our paper proposes an incremental ensemble neural network for fake news detection that continuously learns from fake news streams, adapting to changes. It employs performance-based pruning to eliminate underperforming classifiers, improving overall performance. Additionally, the model detects concept drift in real-time and triggers adaptation strategies to maintain accuracy and robustness. The models undergo evaluation in two scenarios, utilizing consistent news patterns for training and testing, demonstrating consistent performance among all ML and incremental models. In the second scenario, the study analyzes the impact of news patterns over time, including concept drift due to significant events like the United States election. The analysis reveals that offline-trained methods are susceptible to performance degradation. However, the proposed model exhibits consistent performance with an accuracy of 97.90% and 99.76% on two fake news datasets, despite changes in the news pattern over time. The findings demonstrate how the evolution of the news pattern impacts the effectiveness of fake news detection models. The proposed model used for the experimentation indicates consistent performance even in the presence of drift.
C1 [Suryawanshi, Shubhangi; Goswami, Anurag] Bennett Univ, Greater Noida, India.
   [Suryawanshi, Shubhangi; Patil, Pramod] Dr DY Patil Inst Technol, Pune, India.
RP Suryawanshi, S (corresponding author), Bennett Univ, Greater Noida, India.; Suryawanshi, S (corresponding author), Dr DY Patil Inst Technol, Pune, India.
EM ss5683@bennett.edu.in; anurag.goswami@bennett.edu.in;
   pdpatiljune@gmail.com
RI Suryawanshi, Shubhangi/AAO-1849-2021
OI Suryawanshi, Shubhangi/0000-0002-1780-7068
CR Ahmad I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8885861
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Al-Ash HS, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS 2019), DOI 10.1109/icicos48119.2019.8982409
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Alves JL, 2019, LECT NOTES COMPUT SC, V11896, P72, DOI 10.1007/978-3-030-33904-3_7
   [Anonymous], 2018, DEEP CONTEXTUALIZED, DOI DOI 10.18653/V1/N18-1202
   Baly R, 2019, Arxiv, DOI arXiv:1904.00542
   Baly R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3528
   Bani-Hani A., 2020, IEEE ACS INT C COMP, P1, DOI DOI 10.1109/AICCSA50499.2020.9316504
   Biesialska Magdalena, 2020, ARXIV201209823, DOI [10.18653/v1/2020.coling-main.574, DOI 10.18653/V1/2020.COLING-MAIN.574]
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Das B, 2018, Arxiv, DOI arXiv:1806.06407
   Fu XH, 2017, NEUROCOMPUTING, V241, P18, DOI 10.1016/j.neucom.2017.01.079
   Galhardi CP, 2020, Fato ou Fake? Uma analise da desinformacaofrente a pandemia da Covid-19 no Brasil, P4210, DOI [10.1590/1413-812320202510.2.28922020, DOI 10.1590/1413-812320202510.2.28922020]
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Holan A. D., 2016, 2016 LIE YEAR FAKE N
   Horne BD, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3363818
   Hua JL, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072309
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Ksieniewicz P, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207498
   Lewandowsky S, 2012, PSYCHOL SCI PUBL INT, V13, P106, DOI 10.1177/1529100612451018
   Li ZC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2822907
   Lin Y, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P552, DOI 10.1109/ASONAM.2018.8508244
   Mohawesh R, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114318
   OBrien Nicole, 2018, The language of fake news: Opening the black-box of deep learning-based detectors
   PAGE ES, 1954, BIOMETRIKA, V41, P100, DOI 10.1093/biomet/41.1-2.100
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Rasool T, 2019, INT CONF COMPUT AUTO, P73, DOI 10.1145/3313991.3314008
   Roy Aurko, 2018, ARXIV
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Saikia P, 2022, Arxiv, DOI [arXiv:2207.13500, 10.48550/arXiv.2207.13500, DOI 10.48550/ARXIV.2207.13500]
   Silva M, 2023, J Inform Data Manage, V13, DOI [10.5753/jidm.2022.2542, DOI 10.5753/JIDM.2022.2542]
   Silva RM, 2017, KNOWL-BASED SYST, V118, P152, DOI 10.1016/j.knosys.2016.11.018
   Silva RM, 2021, S KNOWL DISC MIN LEA, DOI [10.5753/kdmile.2021.17469, DOI 10.5753/KDMILE.2021.17469]
   Wong J, 2016, Almost all the traffic to fake news sites is from facebook, new data show
   Zechao Li, 2017, Understanding-Oriented Multimedia News Summarization, P131, DOI [10.1007/978-981-10-3689-7-6, DOI 10.1007/978-981-10-3689-7-6]
   Zhou X, 2020, Digital Threats: Research and Practice, V1, P1, DOI 10.1145/3377478
NR 38
TC 0
Z9 0
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28579
EP 28594
DI 10.1007/s11042-023-16588-z
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000008
DA 2024-07-18
ER

PT J
AU Giri, RN
   Janghel, RR
   Pandey, SK
AF Giri, Ram Nivas
   Janghel, Rekh Ram
   Pandey, Saroj Kumar
TI Band selection using hybridization of particle swarm optimization and
   crow search algorithm for hyperspectral data classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Dimension reduction; Band selection; Particle swarm
   optimization; Crow search algorithm
ID DIMENSIONALITY
AB A Hyperspectral image (HSI) contains numerous spectral bands, providing better differentiation of ground objects. Although the data from HSI are very rich in information, their processing presents some difficulties in terms of computational effort and reduction of information redundancy. These difficulties stem mainly from the fact that the HSI consists of a large number of bands along with some redundant bands. Band selection (BS) is used to select a subset of bands to reduce processing costs and eliminate spectral redundancy. BS methods based on a metaheuristic approach have become popular in recent years. However, most BS methods based on a metaheuristic approach can get stuck in the local optimum and converge slowly due to a lack of balance between exploration and exploitation. In this paper, three BS methods are proposed for HSI data. The first method applies Crow Search Algorithm (CSA) for BS. The other two proposed methods, HPSOCSA_SP and HPSOCSA_SLP, are based on the hybridization of Particle Swarm Optimization (PSO) and CSA. The purpose of these hybridizations is to balance exploration and exploitation in a search process for optimal band selection and fast convergence. In hybridization techniques, PSO and CSA exchange informative data at each iteration. HPSOCSA_SP split the population into two equal parts. PSO is applied to one part and CSA to the other. HPSOCSA_SLP selects half of the top-performing members based on fitness. PSO and CSA are applied to the selected population sequentially. Our proposed models underwent rigorous testing on four HSI datasets and showed superiority over other metaheuristic techniques.
C1 [Giri, Ram Nivas; Janghel, Rekh Ram] Natl Inst Technol, Dept Informat Technol, Raipur 492010, CG, India.
   [Pandey, Saroj Kumar] GLA Univ Mathura, Dept Comp Engn & applicat, Mathura, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; GLA University
RP Giri, RN (corresponding author), Natl Inst Technol, Dept Informat Technol, Raipur 492010, CG, India.
EM rngiri.phd2021.it@nitrr.ac.in; rrjanghel.it@nitrr.ac.in;
   sarojpandey23@gmail.com
RI Janghel, Dr. Rekh Ram/AAU-3531-2020
OI Janghel, Dr. Rekh Ram/0000-0003-1425-6384
CR Adamu A, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100108
   Aghaee R, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3147272
   Anand R, 2022, J IMAGING, V8, DOI 10.3390/jimaging8050126
   Archibald R, 2007, IEEE GEOSCI REMOTE S, V4, P674, DOI 10.1109/LGRS.2007.905116
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Chaudhuri A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114288
   Ding XH, 2020, IEEE ACCESS, V8, P25789, DOI 10.1109/ACCESS.2020.2971327
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Gamel SA, 2024, MULTIMED TOOLS APPL, V83, P7295, DOI 10.1007/s11042-023-15803-1
   Gao HM, 2019, NEURAL PROCESS LETT, V49, P1335, DOI 10.1007/s11063-018-9876-7
   Gao PC, 2019, IEEE GEOSCI REMOTE S, V16, P462, DOI 10.1109/LGRS.2018.2872358
   Ghamisi P, 2015, IEEE GEOSCI REMOTE S, V12, P309, DOI 10.1109/LGRS.2014.2337320
   Ghosh A, 2013, APPL SOFT COMPUT, V13, P1969, DOI 10.1016/j.asoc.2012.11.042
   Groves P, 2004, 2003 IEEE WORKSHOP ON ADVANCES IN TECHNIQUES FOR ANALYSIS OF REMOTELY SENSED DATA, P120
   Hamadache I, 2021, NATURE INSPIRED COMP, P15, DOI [10.1016/B978-0-12-823749-6.00006-4, DOI 10.1016/B978-0-12-823749-6.00006-4]
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   Hssayni El Houssaine, 2023, Journal of Ambient Intelligence and Humanized Computing, P13715, DOI 10.1007/s12652-022-04025-2
   Hssayni E, 2022, COMPUT INTELL-US, V38, P2056, DOI 10.1111/coin.12556
   Hssayni E, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109567
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kumar BLNP, 2021, INT J REMOTE SENS, V42, P5109, DOI 10.1080/01431161.2021.1906979
   Li SJ, 2011, KNOWL-BASED SYST, V24, P40, DOI 10.1016/j.knosys.2010.07.003
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Licciardi G, 2012, IEEE GEOSCI REMOTE S, V9, P447, DOI 10.1109/LGRS.2011.2172185
   Medjahed Seyyid Ahmed, 2015, IAENG International Journal of Computer Science, V42, P183
   Medjahed SA, 2016, APPL SOFT COMPUT, V40, P178, DOI 10.1016/j.asoc.2015.09.045
   Patro RN, 2021, IEEE GEOSC REM SEN M, V9, P72, DOI 10.1109/MGRS.2021.3051979
   Paul A, 2021, EVOL INTELL, V14, P1793, DOI 10.1007/s12065-020-00460-2
   Rashedi E, 2018, SWARM EVOL COMPUT, V41, P141, DOI 10.1016/j.swevo.2018.02.018
   Salimi A, 2018, EGYPT J REMOTE SENS, V21, P27, DOI 10.1016/j.ejrs.2017.02.003
   Samee NA, 2022, CMC-COMPUT MATER CON, V73, P4193, DOI 10.32604/cmc.2022.031147
   Sawant S, 2021, MULTIMED TOOLS APPL, V80, P1725, DOI 10.1007/s11042-020-09705-9
   Sawant SS, 2019, INT J REMOTE SENS, V40, P7852, DOI 10.1080/01431161.2019.1607609
   Su HJ, 2014, IEEE J-STARS, V7, P2659, DOI 10.1109/JSTARS.2014.2312539
   Sun WW, 2019, IEEE GEOSC REM SEN M, V7, P118, DOI 10.1109/MGRS.2019.2911100
   Tschannerl J, 2019, INFORM FUSION, V51, P189, DOI 10.1016/j.inffus.2019.02.005
   Villa A, 2011, IEEE T GEOSCI REMOTE, V49, P4865, DOI 10.1109/TGRS.2011.2153861
   Wang CX, 2019, ADV SPACE RES, V64, P886, DOI 10.1016/j.asr.2019.05.005
   Wang MW, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107805
   Wang MW, 2021, APPL INTELL, V51, P7766, DOI 10.1007/s10489-021-02270-0
   Wang MW, 2019, KNOWL-BASED SYST, V168, P39, DOI 10.1016/j.knosys.2018.12.031
   Xie FD, 2019, APPL SOFT COMPUT, V75, P428, DOI 10.1016/j.asoc.2018.11.014
   Xu Y, 2017, IEEE GEOSCI REMOTE S, V14, P554, DOI 10.1109/LGRS.2017.2658666
   Yan YY, 2022, MULTIMED TOOLS APPL, V81, P22111, DOI 10.1007/s11042-021-11865-1
   Yang H, 2012, IEEE J-STARS, V5, P544, DOI 10.1109/JSTARS.2012.2185822
   Yang XH, 2015, BOUND VALUE PROBL, P1, DOI 10.1186/s13661-015-0300-1
   Zhang WQ, 2018, IEEE GEOSCI REMOTE S, V15, P1750, DOI 10.1109/LGRS.2018.2853805
NR 47
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26901
EP 26927
DI 10.1007/s11042-023-16638-6
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059026300013
DA 2024-07-18
ER

PT J
AU Cao, XW
   Yan, WQ
AF Cao, Xiaowen
   Yan, Wei Qi
TI Pose estimation for swimmers in video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Swimmer; HRNet; DCNN
AB Traditional models for pose estimation in video surveillance are based on graph structures, in this paper, we propose a method that breaks the limitation of template matching within a range of pose changes to obtain robust results. We implement our swimmer pose estimation method based on deep learning. We take use of High-Resolution Net (HRNet) to extract and fuse visual features of visual object and complete the object detection using the key points of human joint. The proposed model could be applied to all kinds of swimming styles throughout appropriate training. Compared with the methods that require multimodel combinations and training, the proposed method directly achieves the end-to-end prediction, which is easily to be implemented and deployed. In addition, a cross-fusion module is added between parallel networks, which assists the network to make use of the characteristics of multiple resolutions. The proposed network has achieved ideal results in the pose estimation of swimmers by comparing HRNet-W32 and HRNet-W48. In addition, we propose an annotated key point dataset of swimmers which was created from the view of underwater swimmers. Compared with side view, the torso of swimmers collected by the underwater view is much suitable for a broad spectrum of machine vision tasks.
C1 [Cao, Xiaowen; Yan, Wei Qi] Auckland Univ Technol, CBD, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, CBD, Auckland 1010, New Zealand.
EM wyan@aut.ac.nz
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Cao X., 2022, Master's Thesis
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Einfalt M, 2018, IEEE WINT CONF APPL, P446, DOI 10.1109/WACV.2018.00055
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Kulon D, 2020, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR42600.2020.00504
   Lienhart R., 2018, International Journal of Computer Science in Sport, V17, P94, DOI 10.2478/ijcss-2018-0005
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Parekh P, 2021, INT C COMP COMM CYB, V203
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yan W, 2023, Computational methods for deep learning
   Yan Wei., 2019, Introduction to intelligent surveillance: surveillance data capture, transmission, and analytics, DOI 10.1007/978-3-030-10713-0
   Yu ZQ, 2020, INT CONF IMAG VIS, DOI 10.1109/ivcnz51579.2020.9290594
   Zecha D, 2012, Research Report
   Zecha Dan, 2017, Electron Imaging, V2017, P21, DOI DOI 10.2352/ISSN.2470-1173.2017.16.CVAS-345
   Zhang F, 2021, ACM Comput Surv, V56, P1
   Zheng C., 2020, ACM COMPUT SUR, V11, P1, DOI [10.1145/3285029, DOI 10.1145/3285029]
NR 22
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26565
EP 26580
DI 10.1007/s11042-023-16618-w
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Suto, J
AF Suto, Jozsef
TI Improving the generalization capability of YOLOv5 on remote sensed
   insect trap images with data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Insect detection; YOLOv5; Faster R-CNN; Remote sensing; Data
   augmentation
ID PESTS
AB In agricultural pest management, the traditional insect population tracking in the case of several insect types is based on outsourced sticky paper traps that are checked periodically by a human operator. However, with the aid of the Internet of Things technology and machine learning, this type of manual monitoring can be automated. Even though great progress has been made in the field of insect pest detector models, the lack of sufficient amount of remote sensed trap images prevents their practical application. Beyond the lack of sufficient data, another issue is the large discrepancy between manually taken and remote sensed trap images (different illumination, quality, background, etc.). In order to improve those problems, this paper proposes three previously unused data augmentation approaches (gamma correction, bilateral filtering, and bit-plate slicing) which artificially enrich the training data and through this increase the generalization capability of deep object detectors on remote sensed trap images. Even with the application of the widely used geometric and texture-based augmentation techniques, the proposed methods can further increase the efficiency of object detector models. To demonstrate their efficiency, we used the Faster Region-based Convolutional Neural Network (R-CNN) and the You Look Only Once version 5 (YOLOv5) object detectors which have been trained on a small set of high-resolution, manually taken trap images while the test set consists of remote sensed images. The experimental results showed that the mean average precision (mAP) of the reference models significantly improved while in some cases their counting error was reduced to a third.
C1 [Suto, Jozsef] Univ Debrecen, Fac Informat, Dept Informat Syst & Networks, Kassai St 26, H-4028 Debrecen, Hungary.
   [Suto, Jozsef] Ekozig Zrt, Kontosgat sor 1-3, H-4031 Debrecen, Hungary.
C3 University of Debrecen
RP Suto, J (corresponding author), Univ Debrecen, Fac Informat, Dept Informat Syst & Networks, Kassai St 26, H-4028 Debrecen, Hungary.; Suto, J (corresponding author), Ekozig Zrt, Kontosgat sor 1-3, H-4031 Debrecen, Hungary.
EM suto.jozsef@inf.unideb.hu
FU University of Debrecen; eKOEZIG Regionalis Informatikai Szolgaltato
   Koezpont Zrt [2020-1.1.2-PIACI-KFI-2021-00249]; Ministry of Innovation
   and Technology of Hungary from the National Research, Development, and
   Innovation Fund under the 2020-1.1.2-PIACI KFI funding scheme
   [2020-1.1.2-PIACI-KFI-2021-00249]
FX Open access funding provided by University of Debrecen. The author was
   supported by eKOEZIG Regionalis Informatikai Szolgaltato Koezpont Zrt
   thanks to the project no. 2020-1.1.2-PIACI-KFI-2021-00249. Project no.
   2020-1.1.2-PIACI-KFI-2021-00249 has been implemented with the support
   provided by the Ministry of Innovation and Technology of Hungary from
   the National Research, Development, and Innovation Fund, financed under
   the 2020-1.1.2-PIACI KFI funding scheme.
CR Barbedo JGA, 2020, AI-BASEL, V1, P312, DOI 10.3390/ai1020021
   Lima MCF, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050161
   Cardoso B, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12189397
   Cirjak D, 2022, HORTICULTURAE, V8, DOI 10.3390/horticulturae8060520
   De Cesaro T, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105784
   Diller Y, 2023, J PEST SCI, V96, P611, DOI 10.1007/s10340-022-01528-x
   Ding WG, 2016, COMPUT ELECTRON AGR, V123, P17, DOI 10.1016/j.compag.2016.02.003
   Domingues T, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12111967
   Du L, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12020248
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He Y, 2020, PRECIS AGRIC, V21, P1385, DOI 10.1007/s11119-020-09726-2
   Hong SJ, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050170
   Hoye TT, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2002545117
   Kaur P, 2021, MIDWEST SYMP CIRCUIT, P537, DOI 10.1109/MWSCAS47672.2021.9531849
   Li W, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12071065
   Li WY, 2021, ECOL INFORM, V66, DOI 10.1016/j.ecoinf.2021.101460
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mamdouh N, 2021, IEEE ACCESS, V9, P84252, DOI 10.1109/ACCESS.2021.3088075
   Muppala C., 2020, J. Phytol., V12, P9, DOI [10.25081/jp.2020.v12.6145, DOI 10.25081/JP.2020.V12.6145]
   Preti M, 2021, B INSECTOL, V74, P147
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roosjen PPJ, 2020, PEST MANAG SCI, V76, P2994, DOI 10.1002/ps.5845
   Rustia DJA, 2021, BIOSYST ENG, V208, P28, DOI 10.1016/j.biosystemseng.2021.05.006
   Shi ZC, 2020, IEEE ACCESS, V8, P163703, DOI 10.1109/ACCESS.2020.3021830
   Sun Y, 2018, BIOSYST ENG, V176, P140, DOI 10.1016/j.biosystemseng.2018.10.012
   Suto J, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12111897
   Suto J, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12101721
   Süto J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151754
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhong YH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051489
NR 31
TC 0
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27921
EP 27934
DI 10.1007/s11042-023-16578-1
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060390500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Appiah, EO
   Mensah, S
AF Appiah, Emmanuel Owusu
   Mensah, Solomon
TI Object detection in adverse weather condition for autonomous vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; Object Detection; Autonomous vehicles; Adverse weather
   condition
ID RECOGNITION; CARS
AB As self-driving or autonomous vehicles proliferate in our society, there is a need for their computing vision systems to be able to identify objects accurately, no matter the weather condition. One major concern in computer vision is improving an autonomous car's capacity to discern between the components of its environment under challenging conditions. For instance, inclement weather like fog and rain can corrupt images which eventually affect how well autonomous vehicles navigate and localise themselves. To provide an efficient and effective approach for autonomous vehicles to accurately detect objects during adverse weather conditions. The study employed the combination of two deep learning approaches, namely YOLOv7 and ESRGAN. The use of ESRGAN is to first learn from a set of training data and adjust for the unfavourable weather conditions in the images before the YOLOv7 detector performs detection of objects. The use of the ESRGAN allowed for the adaptive enhancement of each image for improved detection performance by the YOLOv7. In both good and bad weather, the employed hybrid approach (YOLOv7 + ESRGAN) works well with about 80% accuracy in detecting all objects during adverse weather conditions. We would recommend further study on the methodology utilised in this paper to tackle the trolley-dilemma problem during inclement weather.
C1 [Appiah, Emmanuel Owusu; Mensah, Solomon] Univ Ghana, Dept Comp Sci, Accra, Ghana.
C3 University of Ghana
RP Mensah, S (corresponding author), Univ Ghana, Dept Comp Sci, Accra, Ghana.
EM eowusu_appiah001@st.ug.edu.gh; smensah03@ug.edu.gh
CR Abu Al-Haija Q, 2022, AI-BASEL, V3, P303, DOI 10.3390/ai3020019
   Alshamrani SS, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/8045874
   Aryal M, 2019, P INT TECH M I NAVIG, P870, DOI 10.33012/2019.16731
   Baker-Campbell A, 2020, AUTOVISION NEWS
   Bathla G, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/7632892
   Ben Elallid B, 2022, J KING SAUD UNIV-COM, V34, P7366, DOI 10.1016/j.jksuci.2022.03.013
   Carion Nicolas, 2020, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-030-58452-8_13
   Chakraborty D, 2022, SUPER RESOLUTION GEN
   Chakraborty D, ENHANCED SUPER RESOL
   Chen XZ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205731
   Chu WT, 2017, J VIS COMMUN IMAGE R, V46, P233, DOI 10.1016/j.jvcir.2017.04.002
   Cui Y., 2022, WACV, P3411, DOI 10.1109/WACV51458
   Cui YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8118, DOI 10.1109/ICCV48922.2021.00803
   Cunneen M, 2020, CYBERNET SYST, V51, P59, DOI 10.1080/01969722.2019.1660541
   Ding Q, 2022, CF YOLO CROSS FUSION, V14, P1
   Edelstein S, 2017, NUTONOMY LYFT JOININ
   Fersch T, 2017, PROC SPIE, V10219, DOI 10.1117/12.2260894
   Geisslinger M., 2021, Philosophy & Technology, V34, P1033, DOI [10.1007/s13347-021-00449-4, DOI 10.1007/S13347-021-00449-4]
   Ghasemieh A., 2022, Transportation Engineering, V8, DOI [10.1016/j.treng.2022.100115, DOI 10.1016/J.TRENG.2022.100115]
   Gultepe I., 2007, FOG BOUNDARY LAYER C, DOI [10.1007/978-3-7643-8419-7, DOI 10.1007/978-3-7643-8419-7]
   Hassen AA, 2007, THESIS TU
   Heinzler R, 2019, IEEE INT VEH SYM, P1527, DOI 10.1109/IVS.2019.8814205
   Hnewa M, 2021, IEEE SIGNAL PROC MAG, V38, P53, DOI 10.1109/MSP.2020.2984801
   Ho JS, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15021566
   Hui J, 2018, GAN SUPER RESOLUTION
   Jokela M, 2019, INT C INTELL COMP CO, P27, DOI [10.1109/ICCP48234.2019.8959554, 10.1109/iccp48234.2019.8959554]
   Kenk M.A., 2020, arXiv
   Khan F., 2021, Int. J. Electr. Comput. Eng. (IJECE), V11, P3013
   Kim T.J., 2018, Journal of Transportation Technologies, V8, P137, DOI DOI 10.4236/JTTS.2018.83008
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lin T.-Y., 2015, Microsoft COCO: Common objects in context, P1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litman T., 2020, AUTONOMOUS VEHICLE I
   Liu, 2020, LARGE SCALE SIMULATI
   Liu B, 2017, CHIN AUTOM CONGR, P6233, DOI 10.1109/CAC.2017.8243900
   Liu DF, 2023, IEEE T IMAGE PROCESS, V32, P2678, DOI 10.1109/TIP.2023.3272826
   Liu DF, 2020, INT J SEMANT COMPUT, V14, P153, DOI 10.1142/S1793351X20500038
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WY, 2022, AAAI CONF ARTIF INTE, P1792
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Ma YF, 2020, IEEE-CAA J AUTOMATIC, V7, P315, DOI 10.1109/JAS.2020.1003021
   Mandal S., 2021, Artificial Intelligence for Future Generation Robotics, P119
   Manikandan TD., 2020, REHABILITATION, V24, P380, DOI DOI 10.37200/IJPR/V24I5/PR201704
   Maqsood MH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237903
   Martínez-Díaz M, 2018, TRANSP RES PROC, V33, P275, DOI 10.1016/j.trpro.2018.10.103
   Mertz C, 2013, J FIELD ROBOT, V30, P17, DOI 10.1002/rob.21430
   Mester G, 2022, AUTONOMOUS ROBOTIC S, DOI [10.13140/RG.2.2.26605.26081, DOI 10.13140/RG.2.2.26605.26081]
   Meyer J, 2017, RES TRANSP ECON, V62, P80, DOI 10.1016/j.retrec.2017.03.005
   Musat V, 2021, IEEE INT CONF COMP V, P2906, DOI 10.1109/ICCVW54120.2021.00325
   Naveenkumar A., 2022, Evolution in Computational Intelligence: Proceedings of the 9th International Conference on Frontiers in Intelligent Computing: Theory and Applications (FICTA 2021). Smart Innovation, Systems and Technologies (267), P65, DOI 10.1007/978-981-16-6616-2_7
   Mai NAM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21206711
   Nguyen V. D., 2020, International Journal of Machine Learning and Computing, V10, P549, DOI 10.18178/ijmlc.2020.10.4.971
   Niclass C, 2015, ELECTR COMMUN JPN, V98, P28, DOI 10.1002/ecj.11672
   Ondrus J, 2020, TRANSP RES PROC, V44, P226, DOI 10.1016/j.trpro.2020.02.049
   Owais S, 2018, 2018 IEEE 21 INT MUL
   Parekh D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142162
   Pendleton SD, 2017, MACHINES, V5, DOI 10.3390/machines5010006
   Pisarov J, 2021, FME TRANS, V49, P29, DOI 10.5937/fme2101029P
   Poczter SL., 2014, J BUS CASE STUD 1 Q, V10, P6
   Qian K, 2021, PROC CVPR IEEE, P444, DOI 10.1109/CVPR46437.2021.00051
   Rath S, 2022, YOLOV7 PAPER EXPLANA
   Raza M., 2018, INT J APPL ENG RES, V13, P12710
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Salesky B, 2017, ARGO
   Sharma T, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040563
   Shinde S, 2018, PROCEDIA COMPUT SCI, V133, P831, DOI 10.1016/j.procs.2018.07.112
   Singh Sehajbir, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012028
   Song R, 2020, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON VEHICLE TECHNOLOGY AND INTELLIGENT TRANSPORT SYSTEMS (VEHITS), P331, DOI 10.5220/0009354503310341
   Sundararajan S, 2022, VEHICLE AUTOMATION W
   Tinto R, 2017, RIO TINTO EXPAND AUT
   Tumas P, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080934
   Van Utytsel S, 2021, AUTONOMOUS VEHICLES, P39, DOI DOI 10.1007/978-981-15-9255-3_3
   Vargas J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165397
   Vattem T, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P5093, DOI 10.1109/ICRA46639.2022.9812039
   volvocars, 2020, LIMITATIONS CAMERA R
   Vu T-D, 2010, VEHICLE PERCEPTION L
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang W, 2022, Learning equivariant segmentation with instance-unique querying
   Wang X, 2018, P EUROPEANCONFERENCE
   World Meteorological Organization, 2022, SAND DUST STORMS
   Yao JL, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218577
   Yoneda K, 2019, IATSS RES, V43, P253, DOI 10.1016/j.iatssr.2019.11.005
   Zang SZ, 2019, IEEE VEH TECHNOL MAG, V14, P103, DOI 10.1109/MVT.2019.2892497
   Zhang H., 2022, arXiv
   Zhang YX, 2023, ISPRS J PHOTOGRAMM, V196, P146, DOI 10.1016/j.isprsjprs.2022.12.021
   Zhao XY, 2020, INFORM SOFTWARE TECH, V128, DOI 10.1016/j.infsof.2020.106393
NR 89
TC 1
Z9 1
U1 28
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28235
EP 28261
DI 10.1007/s11042-023-16453-z
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600001
DA 2024-07-18
ER

PT J
AU Ben Abdallah, E
   Boukadi, K
AF Ben Abdallah, Emna
   Boukadi, Khouloud
TI Online consumer review spam detection based reinforcement learning and
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Spam reviews; Detection system; Reinforcement learning; Spammer
   behaviors
ID IDENTIFICATION; ENGAGEMENT
AB Despite cutting-edge approaches for detecting spam reviews, there is still a lack of precision to classify new reviews since spammer strategy/behavior rapidly evolves and goes back over time. Most existing studies are based on static models that cannot detect spammers with new spam behaviors. This study tackles this challenge for the first time and proposes a Dynamic Spam Detection System (DSDS) to improve the detection model over time dynamically. The DSDS system integrates the neural network (NN) with reinforcement learning (RL) to identify spammer assaults in offline and online modes. In offline mode, the RL aims to identify the best NN architecture for the offline/static consumer review dataset. In the online mode, the DSDS system has the merit of handling the limited dataset problem by automatically adding new reviews to the offline dataset. Moreover, a novel feature selection-based algorithm is proposed to explore new spammer behaviors from the new reviews. The experiments that were conducted rigorously using well-known datasets demonstrated the ability of the system to detect new spam behaviors as well as to effectively classify online reviews by achieving a high accuracy rate and a low false-positive rate of 94.23%, and 0.0026%, respectively, for the YelpChi dataset, and of 97% and 0.0021, respectively, for the Amazon dataset. Moreover, a comparison with the state-of-the-art approaches on the same datasets proves the contribution of the proposed system.
C1 [Ben Abdallah, Emna; Boukadi, Khouloud] Sfax Univ, Fac Econ & Management, Miracl Lab, Sfax, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Universite de Monastir
RP Ben Abdallah, E (corresponding author), Sfax Univ, Fac Econ & Management, Miracl Lab, Sfax, Tunisia.
EM emnabenabdallah@ymail.com
RI Boukadi, Khouloud/KRQ-1263-2024
OI Boukadi, Khouloud/0000-0002-6744-711X; ben-abadallah,
   emna/0000-0003-0010-4849
CR Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Ben-Abdallah E, 2018, LECT NOTES COMPUT SC, V11229, P534, DOI 10.1007/978-3-030-02610-3_30
   Bhuvaneshwari P, 2021, MULTIMED TOOLS APPL, V80, P18107, DOI 10.1007/s11042-021-10602-y
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Budhi GS, 2021, MULTIMED TOOLS APPL, V80, P13079, DOI 10.1007/s11042-020-10299-5
   Cardoso EF, 2018, NEUROCOMPUTING, V309, P106, DOI 10.1016/j.neucom.2018.04.074
   Caruccio L, 2018, IEEE INT CONF BIG DA, P5078, DOI 10.1109/BigData.2018.8622011
   CHANG JM, 2013, ABC NEWS
   Chau D, 2018, ABC NEWS
   Chen YB, 2008, MANAGE SCI, V54, P477, DOI 10.1287/mnsc.1070.0810
   Cirillo S, 2023, VISUAL PRIVACY TOOL
   Crawford M., 2015, J BIG DATA, V2, P23, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dewang RK, 2018, J INTELL INF SYST, V50, P231, DOI 10.1007/s10844-017-0454-7
   Fahfouh A, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113517
   Fei Geli., 2013, ICWSM
   Guo ZW, 2021, FUTURE GENER COMP SY, V117, P205, DOI 10.1016/j.future.2020.11.028
   Han YQ, 2021, INT J ADAPT CONTROL, V35, P713, DOI 10.1002/acs.3224
   Hand DJ, 2009, MACH LEARN, V77, P103, DOI 10.1007/s10994-009-5119-5
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hussain N, 2020, IEEE ACCESS, V8, P53801, DOI 10.1109/ACCESS.2020.2979226
   Huys Q.J.M., 2014, encyclopedia of computational neuroscience, P1
   Javed MS, 2021, J COMPUT SOC SCI, V4, P883, DOI 10.1007/s42001-021-00114-y
   Ji SJ, 2020, INFORM SCIENCES, V536, P454, DOI 10.1016/j.ins.2020.05.084
   Kaghazgaran P, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P306, DOI 10.1145/3159652.3159726
   Karakasli MS, 2019, LECT NOTES ELECTR EN, V504, P239, DOI 10.1007/978-981-13-0408-8_20
   Khurshid F, 2019, INT J COMPUT INT SYS, V12, P387, DOI 10.2991/ijcis.2019.125905655
   Li F., 2011, P 22 INT JOINT C ART, P2488, DOI [10.5555/2283696, DOI 10.5591/978-1-57735-516-8/IJCAI11-414, 10.5591/978-1-57735-516-8/IJCAI11-]
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li Y, 2013, CHIN J TRAUMATOL, V16, P225, DOI 10.3760/cma.j.issn.1008-1275.2013.04.008
   Ligthart A, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107023
   Lim E.P., 2010, P ACM INT C INFORM K, P939, DOI DOI 10.1145/1871437.1871557
   Lu RZ, 2018, APPL ENERG, V220, P220, DOI 10.1016/j.apenergy.2018.03.072
   Mathwick C, 2017, J SERV RES-US, V20, P204, DOI 10.1177/1094670516682088
   Mohawesh R, 2021, IEEE ACCESS, V9, P65771, DOI 10.1109/ACCESS.2021.3075573
   Mukherjee A, 2013, 7 INT AAAI C WEBL SO
   Mukherjee A., 2013, UICCS201303
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Ott M., 2011, arXiv
   Qiu T, 2022, IEEE T KNOWL DATA EN, V34, P4622, DOI 10.1109/TKDE.2020.3047857
   Rajamohana SP, 2018, COMPUT ELECTR ENG, V67, P497, DOI 10.1016/j.compeleceng.2018.02.015
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771
   Shan GX, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113198
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang XY, 2020, INFORM SCIENCES, V526, P274, DOI 10.1016/j.ins.2020.03.063
   Thakur R, 2018, J RETAIL CONSUM SERV, V41, P48, DOI 10.1016/j.jretconser.2017.11.002
   Wang Z, 2018, KNOWL INF SYST, V55, P571, DOI 10.1007/s10115-017-1068-7
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Zhang DS, 2016, J MANAGE INFORM SYST, V33, P456, DOI 10.1080/07421222.2016.1205907
   Zhang L, 1999, IEEE T NEURAL NETWOR, V10, P925, DOI 10.1109/72.774263
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
NR 54
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25617
EP 25641
DI 10.1007/s11042-023-16527-y
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600010
DA 2024-07-18
ER

PT J
AU Deb, SD
   Jha, RK
AF Deb, Sagar Deep
   Jha, Rajib Kumar
TI Segmentation of pectoral muscle from mammograms using U-Net having
   densely connected convolutional layers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Digital mammogram; Pectoral muscle segmentation; U-Net
ID BREAST BOUNDARY
AB Segmentation of the pectoral muscle is one of the most fundamental steps in developing a Computer-Aided Diagnosis (CAD) System. Considering the presence of various artifacts and homogeneity among the breast region, the pectoral muscle segmentation is a relatively tricky task. This study proposes a modified U-Net structure for automatic pectoral muscle segmentation from mammogram images. The modified U-Net architecture is different from the traditional U-Net architecture in having densely connected convolution layers. The proposed architecture was trained, validated, and tested by utilizing 322 and 200 mammogram images from two publicly available datasets: Mammographic Image Analysis Society (mini-MIAS) and the INBreast. Mini-MIAS contains scanned filmed mammograms, whereas INBreast contains full-field digital (FFDM) mammograms. Unlike other segmentation techniques, the modified U-Net architecture proposed does not require any pre-processing method and performs equally well on both scanned filmed and FFDM mammograms. We tested the system by fusing both the above datasets to verify our claim. Our proposed architecture has obtained satisfactory results on the mixed dataset. The experimental results showed that the pectoral muscle segmentation approach received a dice coefficient of 96.38 & PLUSMN; 1.52 and 96.82 & PLUSMN; 2.23 on mini-MIAS and the INBreast databases, respectively. Moreover on mixing both the datasets and randomly testing 20% of the samples, the algorithm achieved a Dice coefficient of 95.82 & PLUSMN; 1.23.
C1 [Deb, Sagar Deep; Jha, Rajib Kumar] Indian Inst Technol Patna, Dept Elect Engn, Patna 801106, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System)
RP Deb, SD (corresponding author), Indian Inst Technol Patna, Dept Elect Engn, Patna 801106, Bihar, India.
EM sagardeepdeb@gmail.com; jharajib@iitp.ac.in
OI Deb, Sagar Deep/0000-0002-9586-1131
CR Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Ali MJ, 2020, INT J IMAG SYST TECH, V30, P1108, DOI 10.1002/ima.22410
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Chakraborty J, 2012, J DIGIT IMAGING, V25, P387, DOI 10.1007/s10278-011-9421-y
   de Oliveira HN, 2018, IBEROAMERICAN C PATT, P690, DOI 10.1007/978-3-030-13469-3_80
   Deb S. D, 2022, IEEE T RADIAT PLASMA
   Dubrovina A, 2018, COMP M BIO BIO E-IV, V6, P243, DOI 10.1080/21681163.2015.1131197
   Ferrari RJ, 2004, MED BIOL ENG COMPUT, V42, P201, DOI 10.1007/BF02344632
   Gunderman R. B, 2006, ESSENTIAL RADIOLOGY, P2
   Hong BW, 2010, IEEE T INF TECHNOL B, V14, P129, DOI 10.1109/TITB.2009.2033269
   Houssein EH, 2022, NEURAL COMPUT APPL, V34, P18015, DOI 10.1007/s00521-022-07445-5
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kingma D. P., 2014, arXiv
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma XY, 2019, MED PHYS, V46, P2103, DOI 10.1002/mp.13451
   Mirzaalian H, 2007, IEEE PACIF, P577
   Mohammed MA, 2018, COMPUT ELECTR ENG, V70, P871, DOI 10.1016/j.compeleceng.2018.01.033
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Mustra M, 2016, MED BIOL ENG COMPUT, V54, P1003, DOI 10.1007/s11517-015-1411-7
   Nasr G.E., 2002, Forecasting gasoline demand, P381
   Oliver A, 2014, IEEE IMAGE PROC, P912, DOI 10.1109/ICIP.2014.7025183
   Panigrahi L, 2019, EXPERT SYST APPL, V115, P486, DOI 10.1016/j.eswa.2018.08.013
   Raba D, 2005, LECT NOTES COMPUT SC, V3523, P471
   Rahman M. A, 2021, IEEE T RAD PLASMA ME
   Rahman MA, 2019, IET IMAGE PROCESS, V13, P771, DOI 10.1049/iet-ipr.2018.5290
   Rampun A, 2019, MED IMAGE ANAL, V57, P1, DOI 10.1016/j.media.2019.06.007
   Rampun A, 2017, ARTIF INTELL MED, V79, P28, DOI 10.1016/j.artmed.2017.06.001
   Rodriguez-Ruiz A, 2018, PROC SPIE, V10575, DOI 10.1117/12.2292920
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rubio Y, 2021, AXIOMS, V10, DOI 10.3390/axioms10030180
   Sampat MP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1195, DOI 10.1016/B978-012119792-6/50130-3
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Taghanaki SA, 2017, IEEE T BIO-MED ENG, V64, P2662, DOI 10.1109/TBME.2017.2649481
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Yapa Roshan Dharshana., 2007, International Journal of Medical and Health Sciences, V1, P223
   Yin KM, 2019, INT J COMPUT ASS RAD, V14, P237, DOI 10.1007/s11548-018-1867-7
   Zebari DA, 2020, IEEE ACCESS, V8, P203097, DOI 10.1109/ACCESS.2020.3036072
   Zeebaree Diyar Qader, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P88, DOI 10.1109/ICOASE.2019.8723832
NR 39
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16394-7
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RX5
UT WOS:001050545900002
DA 2024-07-18
ER

PT J
AU Zhao, A
   Zhang, Y
AF Zhao, An
   Zhang, Yi
TI Evota: an enhanced visual object tracking network with attention
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention mechanism; Visual tracking; Transformer
ID SPEED
AB Transformer architecture has made breakthrough in various downstream computer vision tasks and has shown its great potential in visual object tracking. However, existing transformer-based approaches adopt pixel-to-pixel attention strategy to integrate the domain knowledge, but fail to explore the channel and location information from object features, which limits the expressivity of the tracker. To address the above problems, we propose a novel tracking framework, where we propose 2 attention blocks that fuses with Transformer (dubbed EVOTA). It has 4 modules: the feature extraction module, the enhanced attention module, a transformer module and a model predictor. Specifically, a channel-wise attention module re-calibrates the channel-wise feature responses in an adaptive way by modelling interdependencies explicitly between channels. A local cross-channel interaction scheme learns strong channel context information. Meanwhile, an energy function is developed to analyze the importance of each neuron and infers their 3D weights. Extensive experiments have been carried out on 5 prevalent tracking benchmarks to testify the effectiveness of our model, in which EVOTA outperforms several state-of-the-art methods.
C1 [Zhao, An; Zhang, Yi] Sichuan Univ, Dept Comp Sci, Chengdu 610000, Sichuan, Peoples R China.
C3 Sichuan University
RP Zhang, Y (corresponding author), Sichuan Univ, Dept Comp Sci, Chengdu 610000, Sichuan, Peoples R China.
EM yi.zhang@scu.edu.cn
CR Abdelpakey MH, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104550
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Banerjee A, 2023, MULTIMED TOOLS APPL, V82, P10887, DOI 10.1007/s11042-022-13721-2
   Banik D, 2023, SOFT COMPUT, V27, P7513, DOI 10.1007/s00500-022-07700-w
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cao Y, 2022, NEUROCOMPUTING, V492, P76, DOI 10.1016/j.neucom.2022.04.013
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu LH, 2020, MULTIMED TOOLS APPL, V79, P32623, DOI 10.1007/s11042-020-09546-6
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao L, 2022, KNOWL-BASED SYST, V254, DOI 10.1016/j.knosys.2022.109666
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee KH, 2015, IEEE T MULTIMEDIA, V17, P1429, DOI 10.1109/TMM.2015.2455418
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salehifar H., 2011, Proceedings of the 2011 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV 2011), P446
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Webb BS, 2005, J NEUROSCI, V25, P11666, DOI 10.1523/JNEUROSCI.3414-05.2005
   Wu YQ, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2022.103742
   Xie F, 2021, IEEE INT CONF COMP V, P2688, DOI 10.1109/ICCVW54120.2021.00303
   Xu RY, 2015, MULTIMED TOOLS APPL, V74, P729, DOI 10.1007/s11042-014-2177-x
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10428, DOI 10.1109/ICCV48922.2021.01028
   Yang LX, 2021, PR MACH LEARN RES, V139
   Yu B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9836, DOI 10.1109/ICCV48922.2021.00971
   Zhou ZK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9846, DOI 10.1109/ICCV48922.2021.00972
NR 53
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16149-4
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600015
DA 2024-07-18
ER

PT J
AU Zhu, HH
   Chen, XB
   Yang, YX
AF Zhu, Haihua
   Chen, Xiubo
   Yang, Yixian
TI A blind watermarking scheme for TMQIR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Quantum image; Quantum watermarking; Quantum image scrambling; Quantum
   image representation
ID QUANTUM IMAGES; REPRESENTATION; COMPRESSION
AB With the advancement of quantum image research, the security of quantum images has also become the focus. The mutimode quantum image representation based on three dimensional coordinates (TMQIR) is efficient and general. Based on the least significant bit (LSB), a blind watermarking scheme for TMQIR images is proposed in this paper. For color images, a RGB carrier TMQIR image is transformed to grayscale based on any two of three color weights. And any two weights can be used as the key to the conversion between color image and grayscale image. Then the grayscale image with watermark is converted into color image according to the selected color weights. In the LSB of the grayscale TMQIR image used as carrier image and watermarked image, the binary watermark image can be embedded and extracted respectively. In the extracting process, a series of operations are performed in the reverse order of the watermarking process. In addition, the quantum circuits in the watermarking and extracting process of the proposed blind watermarking scheme are simulated on IBM Quantum Lab platform. The simulation results show that the scheme is correct and effective, and the scheme is better than the previous schemes in complexity and key space.
C1 [Zhu, Haihua] Chongqing Univ Post & Telecommun, Sch Cyber Secur & Informat Law, Chongqing 400065, Peoples R China.
   [Zhu, Haihua; Chen, Xiubo; Yang, Yixian] Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Chen, Xiubo; Yang, Yixian] GuiZhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Beijing University
   of Posts & Telecommunications; Guizhou University
RP Chen, XB (corresponding author), Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Chen, XB (corresponding author), GuiZhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Peoples R China.
EM flyover100@163.com
OI Zhu, Haihua/0000-0003-0402-6585
FU Fund of the Fundamental Research Funds for the Central Universities
   [2019XD-A02]
FX This work is supported by the Fund of the Fundamental Research Funds for
   the Central Universities (No. 2019XD-A02).
CR Chen ZG, 2022, QUANTUM INF PROCESS, V21, DOI 10.1007/s11128-022-03510-z
   Chen ZG, 2022, INT J THEOR PHYS, V61, DOI 10.1007/s10773-022-05061-6
   Heidari S, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1694-8
   Heidari S, 2016, INT J THEOR PHYS, V55, P4205, DOI 10.1007/s10773-016-3046-3
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu WW, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-2579-9
   Hu WW, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2138-9
   Iliyasu AM, 2012, INFORM SCIENCES, V186, P126, DOI 10.1016/j.ins.2011.09.028
   Iranmanesh S, 2022, QUANTUM INF PROCESS, V21, DOI 10.1007/s11128-022-03530-9
   Jiang N, 2015, QUANTUM IMAGE SCALIN
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1735, DOI 10.1007/s11128-015-0986-0
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1559, DOI 10.1007/s11128-014-0841-8
   Jiang N, 2014, QUANTUM INF PROCESS, V13, P1545, DOI 10.1007/s11128-014-0749-3
   Jiang SX, 2020, INT J QUANTUM INF, V18, DOI 10.1142/S0219749920500082
   Latorre J. I., 2005, COMPUT SCI
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li HS, 2014, INFORM SCIENCES, V273, P212, DOI 10.1016/j.ins.2014.03.035
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Luo GF, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2165-6
   Luo GF, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2075-7
   Nejad MY, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102495
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Sang JZ, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-016-1463-0
   Tang WX, 2016, IEEE SIGNAL PROC LET, V23, P197, DOI 10.1109/LSP.2015.2504583
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   Venegas-Andraca SE, 2010, PROCESSING IMAGES EN
   [王冬 Wang Dong], 2012, [计算机科学, Computer Science], V39, P302
   Wang S, 2015, MEASUREMENT, V73, P352, DOI 10.1016/j.measurement.2015.05.038
   Wei ZH, 2016, COMMUN THEOR PHYS, V66, P66, DOI 10.1088/0253-6102/66/1/066
   Zeng QW, 2022, INT J THEOR PHYS, V61, DOI 10.1007/s10773-022-04998-y
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P3103, DOI 10.1007/s11128-013-0587-8
   Zhou RG, 2020, INT J QUANTUM INF, V18, DOI 10.1142/S0219749920500227
   Zhou RG, 2018, INT J QUANTUM INF, V16, DOI 10.1142/S0219749918500211
   Zhu HH, 2022, OPTIK, V251, DOI 10.1016/j.ijleo.2021.168321
   Zhu HH, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03255-1
   Zhu HH, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-1514-y
NR 39
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-15368-z
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100004
DA 2024-07-18
ER

PT J
AU Jia, WH
   Zhu, XH
   Zhou, YL
   Hu, MJ
   Liu, C
   Song, Q
AF Jia, Wenhe
   Zhu, Xuhan
   Zhou, Yilin
   Hu, Mengjie
   Liu, Chun
   Song, Qing
TI UV R-CNN: Stable and efficient dense human pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human instance analysis; Dense pose estimation; Loss designing;
   Multi-task learning
AB As a dense prediction task aimed at instance-level human analysis, dense-pose estimation seeks to accurately map 2D pixels onto the 3D surface of the human body. Despite significant progress has been made, two major challenges continue to confront the research community: the first is training instability caused by a large number of surface points to be regressed; the second is the significant amount of time and computational resources to manually adjust multi-task loss weights. To overcome these challenges, we present a novel dense pose estimator, named UV R-CNN, which is based on a detailed analysis of the loss formulation used in existing algorithms. The proposed UV R-CNN first introduces a novel surface point regression loss, which serves to constrain the immense loss and stable the training progress, named Dense Points Loss (DP-Loss). Additionally, we incorporates a Balanced Weighting Strategy (BWS) that allows for the automatic adaptation of loss weights. Remarkably, without auxiliary supervision and external knowledge from other tasks, UV RCNN can be trained with larger learning rate, achieving 65.0% APgps and 66.1% APgpsm on the DensePose-COCO validation subset with ResNet-50-FPN as backbone, competitive to the state-of-the-art methods.
C1 [Jia, Wenhe; Zhou, Yilin; Hu, Mengjie; Liu, Chun; Song, Qing] Beijing Univ Posts & Telecommun, Artificial Intelligence Acad, 10th Xitucheng Rd, Beijing 100086, Peoples R China.
   [Zhu, Xuhan] Chinese Acad Sci, Inst Comp Techonolgy, Beijing 100086, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Chinese Academy of
   Sciences
RP Song, Q (corresponding author), Beijing Univ Posts & Telecommun, Artificial Intelligence Acad, 10th Xitucheng Rd, Beijing 100086, Peoples R China.
EM jiawh@bupt.edu.cn; zhuxuhan21@mails.ucas.ac.cn; ylzhou@bupt.edu.cn;
   mengjie.hu@bupt.edu.cn; chun.liu@bupt.edu.cn; priv@bupt.edu.cn
RI Jia, Wenhe/AHA-1797-2022; Liu, Chun/I-1886-2016
OI Liu, Chun/0000-0002-2834-9461; Zhu, XuHan/0009-0007-8151-4204; Jia,
   Wenhe/0000-0002-7400-072X
CR Bachmann R, 2022, LECT NOTES COMPUT SC, V13697, P348, DOI 10.1007/978-3-031-19836-6_20
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Boudjit K, 2022, J EXP THEOR ARTIF IN, V34, P527, DOI 10.1080/0952813X.2021.1907793
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen XL, 2015, Arxiv, DOI arXiv:1504.00325
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Gkioxari G, 2014, Arxiv, DOI arXiv:1406.5212
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Guo YY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P356, DOI 10.1145/3343031.3350856
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hikmat A., 2020, J. Pharmacy Pharmacol., V8, P24
   Hwang DH, 2020, IEEE WINT CONF APPL, P468, DOI [10.1109/WACV45572.2020.9093595, 10.1109/wacv45572.2020.9093595]
   Jin Y., 2022, The overlooked classifier in human-object interaction recognition
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Khirodkar R., 2021, P IEEECVF INT C COMP, P3122
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Li WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9506, DOI 10.1109/ICCV48922.2021.00939
   Liao Y., 2022, CVPR, P20123
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu K, 2022, CVPR, P4473
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P421, DOI 10.1007/978-3-030-58610-2_25
   Ma LQ, 2021, INT CONF 3D VISION, P721, DOI 10.1109/3DV53792.2021.00081
   Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Rebuffi SA, 2017, ADV NEUR IN, V30
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vandenhende S, 2022, IEEE T PATTERN ANAL, V44, P3614, DOI 10.1109/TPAMI.2021.3054719
   Varga LA, 2022, IEEE WINT CONF APPL, P3686, DOI 10.1109/WACV51458.2022.00374
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3508, DOI 10.1109/TPAMI.2021.3055780
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3780, DOI 10.1145/3394171.3414014
   Wu X, 2022, LECT NOTES COMPUT SC, V13664, P121, DOI 10.1007/978-3-031-19772-7_8
   XuHan Zhu, 2021, ICCBN 2021: 2021 9th International Conference on Communications and Broadband Networking, P66, DOI 10.1145/3456415.3456426
   Yang L, 2022, IEEE-CAA J AUTOMATIC, V9, P1111, DOI 10.1109/JAS.2022.105647
   Yang L, 2021, IEEE T IMAGE PROCESS, V30, P39, DOI 10.1109/TIP.2020.3029901
   Yang L, 2019, PROC CVPR IEEE, P364, DOI 10.1109/CVPR.2019.00045
   Yang L, 2019, IEEE T NEUR NET LEAR, V30, P1744, DOI 10.1109/TNNLS.2018.2873722
   Ye HR, 2022, LECT NOTES COMPUT SC, V13687, P514, DOI 10.1007/978-3-031-19812-0_30
   Yuan HJ, 2022, AAAI CONF ARTIF INTE, P3206
   Zauss D, 2021, P IEEE CVF C COMP VI, P11057
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng AL, 2022, LECT NOTES COMPUT SC, V13665, P607, DOI 10.1007/978-3-031-20065-6_35
   Zhang Q, 2021, IEEE T MULTIMEDIA
   Zhang X, 2022, IEEE T MULTIMEDIA
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhao J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P792, DOI 10.1145/3240508.3240509
   Zhao WY, 2023, IEEE T CIRC SYST VID, V33, P2275, DOI 10.1109/TCSVT.2022.3221611
   Zhao Y, 2022, IEEE T PATTERN ANAL
   Zhu B, 2021, IEEE WINT CONF APPL, P3247, DOI 10.1109/WACV48630.2021.00329
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 58
TC 0
Z9 0
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-15379-w
EA AUG 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sabha, A
   Selwal, A
AF Sabha, Ambreen
   Selwal, Arvind
TI Towards machine vision-based video analysis in smart cities: a survey,
   framework, applications and open issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video analysis; Smart cities; Smart applications; Video summarization;
   Machine learning; Deep learning
ID ACTION RECOGNITION; AUDIO
AB The multifarious video contents generated through various applications is growing exponentially resulting in huge volumes. Analyzing these contents manually is a cumbersome task particularly in terms of extracting key information by satisfying a criterion. The concept of smart city is popular across the world to develop technology-driven cities where facilities are offered intelligently. In smart cities, the video analysis may play a crucial role in several real-life applications such as, smart security surveillance, traffic monitoring, video forensics, sports, entertainment, medical, etc. Thus, video analysis plays a vital role where larger real-time videos can be intelligently analyzed to detect key interesting patterns to yield an application-centric shorter summary. Moreover, machine or deep paradigms can be applied on video data generated in various smart applications in the smart cities to create a real-time model. In this study, we explore the usage of video analysis in various real-time applications in smart cities. Hence, the work aims to expound a detailed investigation of computer vision-based video analysis approaches in various aspects of smart cities. Besides, a generic video analysis layered architecture is also presented which highlights the deployment of video analysis-centric approaches for real-life smart cities facilities. Our analysis of the existing approaches clearly demonstrates the pertinency of video analysis in several smart city's mundane infrastructure. However, the study also reveals numerous scopes where video analysis yet to be explored and that offers a clear insight to the researchers. In addition to opportunities, our study identifies some open research challenges to the active research community. Moreover, the survey can serve as a reference to the investigators as well as to the planning and development authorities of smart cities.
C1 [Sabha, Ambreen; Selwal, Arvind] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, Jammu & Kashmir, India.
C3 Central University of Jammu
RP Sabha, A (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, Jammu & Kashmir, India.
EM ambreensabha45@gmail.com
OI Sabha, Ambreen/0000-0002-6336-7171
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Agyeman R, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P270, DOI 10.1109/MIPR.2019.00055
   Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Ali H, 2020, ARTIF INTELL REV, V53, P2635, DOI 10.1007/s10462-019-09743-2
   Ali JJ., 2020, TELKOMNIKA TELECOMMU, V18, P2447, DOI 10.12928/TELKOMNIKA.V18I5.16634
   Aslan MF, 2020, NEURAL COMPUT APPL, V32, P8585, DOI 10.1007/s00521-019-04365-9
   Basavarajaiah M, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355398
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Choros K, 2014, LECT NOTES COMPUT SC, V8397, P591, DOI 10.1007/978-3-319-05476-6_60
   Davids DM, 2021, MICROPROCESS MICROSY, V83, DOI 10.1016/j.micpro.2021.103960
   del Molino AG, 2017, IEEE T HUM-MACH SYST, V47, P65, DOI 10.1109/THMS.2016.2623480
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Evangelopoulos G, 2009, INT CONF ACOUST SPEE, P3553, DOI 10.1109/ICASSP.2009.4960393
   Fei Mengjuan, 2023, Journal of Ambient Intelligence and Humanized Computing, V14, P14931, DOI 10.1007/s12652-018-0797-0
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   Geertsema EE, 2019, J BIOMECH, V88, P25, DOI 10.1016/j.jbiomech.2019.03.007
   Ghafoor HA, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7586417
   Guan GL, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2632267
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Gupta P, 2016, NAT C ADV COMP COMM, P1
   Han YM, 2018, PATTERN RECOGN LETT, V107, P83, DOI 10.1016/j.patrec.2017.08.015
   Hassan E, 2023, Artificial intelligence for disease diagnosis and prognosis in smart healthcare, DOI 10.1201/9781003251903-6
   Hassan E, 2023, MULTIMED TOOLS APPL, V82, P16591, DOI 10.1007/s11042-022-13820-0
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LJ, 2021, APPL INTELL, V51, P2128, DOI 10.1007/s10489-020-01933-8
   Huang C, 2020, IEEE T CIRC SYST VID, V30, P577, DOI 10.1109/TCSVT.2019.2890899
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   Hussein F, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3063532
   Intel, 2020, ROB HEALTHC FUT ROB
   Kakadiya Rutvik, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P201, DOI 10.1109/ICECA.2019.8822186
   Kalaivani P, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON RECENT TRENDS AND CHALLENGES IN COMPUTATIONAL MODELS (ICRTCCM), P61, DOI 10.1109/ICRTCCM.2017.84
   Keyvanpour MR, 2020, MULTIMED TOOLS APPL, V79, P31819, DOI 10.1007/s11042-020-09485-2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar H, 2017, INT CONF DIGIT SIG
   Kumar KPS, 2019, CLUSTER COMPUT, V22, P10577, DOI 10.1007/s10586-017-1131-x
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li K, 2015, IEEE T PATTERN ANAL, V37, P1233, DOI 10.1109/TPAMI.2014.2361133
   Li Y, 2019, PATTERN ANAL APPL, V22, P601, DOI 10.1007/s10044-017-0660-5
   Liu H., 2011, VIS ANAL HUM, DOI [10.1007/978-0-85729-997-0, DOI 10.1007/978-0-85729-997-0]
   Luna E, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124290
   Mahapatra A, 2015, IEEE IMAGE PROC, P1260, DOI 10.1109/ICIP.2015.7351002
   Mei T, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487269
   Milotta FLM, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102664
   Mirza A, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00523-5
   Mlik N, 2012, OBJECT BASED EVENT D
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2020, PATTERN RECOGN LETT, V130, P370, DOI 10.1016/j.patrec.2018.08.003
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Murugan AS, 2018, MULTIMED TOOLS APPL, V77, P23273, DOI 10.1007/s11042-018-5671-8
   Muszynski M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3175497
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Oskouie P, 2014, ARTIF INTELL REV, V42, P173, DOI 10.1007/s10462-012-9332-4
   Panda R, 2017, IEEE T MULTIMEDIA, V19, P2010, DOI 10.1109/TMM.2017.2708981
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Parihar AS, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102991
   Park H, 2020, IEEE ACCESS, V8, P80010, DOI 10.1109/ACCESS.2020.2990618
   Park H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235114
   Rajpoot Vinay, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P936, DOI 10.1109/ICECA.2018.8474699
   Raposo F, 2016, IEEE-ACM T AUDIO SPE, V24, P1119, DOI 10.1109/TASLP.2016.2541299
   Rouast PV, 2020, IEEE J BIOMED HEALTH, V24, P1727, DOI 10.1109/JBHI.2019.2942845
   Rouvier M, 2015, IEEE-ACM T AUDIO SPE, V23, P1031, DOI 10.1109/TASLP.2014.2387411
   Sabeur Z, 2021, ADV CYBER PHYS SITUA, DOI [10.1007/978-3-030-80285-1, DOI 10.1007/978-3-030-80285-1]
   Sabha A, 2021, P 2021 IEEE INT C IN, P1, DOI [10.1109/ICSES52305.2021.9633804, DOI 10.1109/ICSES52305.2021.9633804]
   Sabha A, 2023, ARTIF INTELL MED, V139, DOI 10.1016/j.artmed.2023.102544
   Sabha A, 2023, MULTIMED TOOLS APPL, V82, P32635, DOI 10.1007/s11042-023-14925-w
   Sahu A, 2020, PATTERN RECOGN LETT, V133, P256, DOI 10.1016/j.patrec.2020.02.029
   Sahu A, 2020, NEUROCOMPUTING, V398, P209, DOI 10.1016/j.neucom.2020.02.099
   Sengönül E, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13084956
   Shammi S, 2019, P 2018 INT C COMMUNI, P36, DOI [10.1109/IC3IoT.2018.8668135, DOI 10.1109/IC3IOT.2018.8668135]
   Sheng B, 2021, IEEE T CYBERNETICS, V51, P1463, DOI 10.1109/TCYB.2020.2988792
   Shingrakhia H, 2022, VISUAL COMPUT, V38, P2285, DOI 10.1007/s00371-021-02111-8
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Song XH, 2016, NEUROCOMPUTING, V187, P66, DOI 10.1016/j.neucom.2015.07.131
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Street W, 2016, DIGITAL DIAGNOSTICS
   Sun S, 2018, MULTIMED TOOLS APPL, V77, P9093, DOI 10.1007/s11042-017-4807-6
   Suresh A.J., 2020, MATER TODAY-PROC, DOI [10.1016/j.matpr.2020.09.609, DOI 10.1016/J.MATPR.2020.09.609]
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tabish M, 2024, MULTIMED TOOLS APPL, V83, P15101, DOI 10.1007/s11042-021-10519-6
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   Thomas S.A., 2017, 2017 IEEE Symposium Series on Computational Intelligence (SSCI), P1, DOI [10.1109/TENCONSpring.2017.8070003, DOI 10.1109/SSCI.2017.8285223]
   Tian ZQ, 2014, MULTIMED TOOLS APPL, V72, P1773, DOI 10.1007/s11042-013-1488-7
   Tiwari V, 2021, MULTIMED TOOLS APPL, V80, P27187, DOI 10.1007/s11042-021-10977-y
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Uemura H, 2008, BMVC 2008 P BRIT MAC, DOI [10.5244/C.22.30, DOI 10.5244/C.22.30]
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Ullah Z, 2020, COMPUT COMMUN, V154, P313, DOI 10.1016/j.comcom.2020.02.069
   K VV, 2019, Arxiv, DOI arXiv:1909.12948
   Verma Kamal Kant, 2022, International Journal of Information Technology, V14, P397, DOI 10.1007/s41870-019-00364-0
   Wang T, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/837275
   Xiao ZJ, 2019, IEEE ACCESS, V7, P129376, DOI 10.1109/ACCESS.2019.2936493
   Xu JF, 2021, MULTIMED TOOLS APPL, V80, P6121, DOI 10.1007/s11042-020-09888-1
   Xu LJ, 2019, IEEE ACCESS, V7, P163806, DOI 10.1109/ACCESS.2019.2952432
   Yasmin G, 2023, NEURAL COMPUT APPL, V35, P4881, DOI 10.1007/s00521-021-06132-1
   Zahra A, 2024, MULTIMED TOOLS APPL, V83, P15313, DOI 10.1007/s11042-021-11468-w
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhang LJ, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/582761
   Zhang Y, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2659520
NR 107
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16434-2
EA AUG 2023
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400009
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Guo, JS
   Zhu, ZF
   Guo, HX
AF Zhou, Zhiyu
   Guo, Jiusen
   Zhu, Zefei
   Guo, Hanxuan
TI Uncalibrated visual servoing based on Kalman filter and mixed-kernel
   online sequential extreme learning machine for robot manipulator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robot manipulator; Visual control; Kalman filter; Mixed-kernel extreme
   learning machine
ID CAPTURE
AB Visual servoing systems may suffer from interference by system noise when a Kalman filter is used to obtain a Jacobian matrix. Such interference may result in slow and poor convergence performance of the servoing system. To overcome these problems, we propose a mixed-kernel online sequential extreme learning machine (MIXEDKOSELM) with Kalman filter, which corrects the error of Kalman filtering algorithm, thus improving the accuracy of the image-based visual servoing (IBVS) system significantly. The proposed KF-MIXEDKOSELM-IBVS does not require the camera parameters in the servoing process, and it is highly robust to disturbance and noise statistical errors. The proposed KF-MIXEDKOSELM-IBVS is validated using the PUMA 560 manipulator in the MATLAB simulation environment. The simulation results clearly reveal that the KF-MIXEDKOSELM-IBVS algorithm has excellent performance by being robust and accurate.
C1 [Zhou, Zhiyu; Guo, Jiusen; Guo, Hanxuan] Zhejiang Sci Tech Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Zhu, Zefei] Hangzhou Dianzi Univ, Sch Mech Engn, Hangzhou 310018, Peoples R China.
C3 Zhejiang Sci-Tech University; Hangzhou Dianzi University
RP Zhou, ZY (corresponding author), Zhejiang Sci Tech Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM zhouzhiyu1993@zstu.edu.cn
OI zhou, zhiyu/0000-0003-4487-8192
FU National Key Ramp;D Program of China [2022YFC2803903]; Key Ramp;D
   Program of Zhejiang Province [2021C03013]
FX We appreciate the support of the National Key R & D Program of China
   (No. 2022YFC2803903) and the Key R & D Program of Zhejiang Province (No.
   2021C03013).
CR Armstrong B., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P510
   Chaumette F, 2006, IEEE ROBOT AUTOM MAG, V13, P82, DOI 10.1109/MRA.2006.250573
   Chen YH, 2018, NEUROCOMPUTING, V312, P90, DOI 10.1016/j.neucom.2018.05.068
   Christou V, 2018, NEUROCOMPUTING, V311, P397, DOI 10.1016/j.neucom.2018.05.064
   Dong GQ, 2019, ROBOT AUTON SYST, V112, P221, DOI 10.1016/j.robot.2018.10.011
   Dong GQ, 2016, ACTA ASTRONAUT, V122, P209, DOI 10.1016/j.actaastro.2016.02.003
   FEDDEMA JT, 1989, IEEE T ROBOTIC AUTOM, V5, P691, DOI 10.1109/70.88086
   Ghandi Y, 2019, IETE J RES, V65, P275, DOI 10.1080/03772063.2017.1417751
   Huang GB, 2005, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, P232
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jin L, 2018, NEUROCOMPUTING, V291, P50, DOI 10.1016/j.neucom.2018.02.059
   Karras GC, 2011, AUTON ROBOT, V31, P67, DOI 10.1007/s10514-011-9231-6
   Kumar PP, 2010, ROBOT AUTON SYST, V58, P978, DOI 10.1016/j.robot.2010.04.001
   Li ST, 2018, INT J CONTROL AUTOM, V16, P844, DOI 10.1007/s12555-016-0720-4
   Liu ST, 2020, T I MEAS CONTROL, V42, P890, DOI 10.1177/0142331219895074
   Lv XD, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2167, DOI 10.1109/IROS.2006.282555
   Matias T, 2014, NEUROCOMPUTING, V129, P428, DOI 10.1016/j.neucom.2013.09.016
   Nohooji HR, 2018, J FRANKLIN I, V355, P693, DOI 10.1016/j.jfranklin.2017.11.036
   Ozawa R, 2013, ADV ROBOTICS, V27, P683, DOI 10.1080/01691864.2013.776967
   Sinopoli B, 2004, IEEE T AUTOMAT CONTR, V49, P1453, DOI 10.1109/TAC.2004.834121
   Tahri O, 2010, IEEE T ROBOT, V26, P684, DOI 10.1109/TRO.2010.2051593
   Wang ZY, 2019, ISA T, V87, P163, DOI 10.1016/j.isatra.2018.11.026
   Xiao L, 2018, IEEE T IND INFORM, V14, P98, DOI 10.1109/TII.2017.2717020
   Yüksel T, 2019, T I MEAS CONTROL, V41, P3, DOI 10.1177/0142331217751599
   Zhang ZJ, 2018, IEEE-ASME T MECH, V23, P679, DOI 10.1109/TMECH.2018.2799724
   Zhong XG, 2019, IEEE ACCESS, V7, P76891, DOI 10.1109/ACCESS.2019.2920941
   Zhong XG, 2015, NEUROCOMPUTING, V151, P268, DOI 10.1016/j.neucom.2014.09.043
   Zhou ZY, 2022, KSII T INTERNET INF, V16, P2529, DOI 10.3837/tiis.2022.08.004
   Zhou ZY, 2019, MULTIMED TOOLS APPL, V78, P26341, DOI 10.1007/s11042-019-07773-0
NR 31
TC 3
Z9 3
U1 7
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18853
EP 18879
DI 10.1007/s11042-023-16381-y
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043360000004
DA 2024-07-18
ER

PT J
AU Hassan, SA
   Akbar, S
   Khan, HU
AF Hassan, Syed Ale
   Akbar, Shahzad
   Khan, Habib Ullah
TI Detection of central serous retinopathy using deep learning through
   retinal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; Central Serous Retinopathy; Fundus Images; Optical
   Coherence Tomography Images; Data Augmentation
ID FUNDUS AUTOFLUORESCENCE
AB The human eye is responsible for the visual reorganization of objects in the environment. The eye is divided into different layers and front/back areas; however, the most important part is the retina, responsible for capturing light and generating electrical impulses for further processing in the brain. Several manual and automated methods have been proposed to detect retinal diseases, though these techniques are time-consuming, inefficient, and unpleasant for patients. This research proposes a deep learning-based CSR detection employing two imaging techniques: OCT and fundus photography. These input images are manually augmented before classification, followed by training of DarkNet and DenseNet networks through both datasets. Moreover, pre-trained DarkNet and DenseNet classifiers are modified according to the need. Finally, the performance of both networks on their datasets is compared using evaluation parameters. After several experiments, the best accuracy of 99.78%, the sensitivity of 99.6%, specificity of 100%, and the F1 score of 99.52% were achieved through OCT images using the DenseNet network. The experimental results demonstrate that the proposed model is effective and efficient for CSR detection using the OCT dataset and suitable for deployment in clinical applications.
C1 [Hassan, Syed Ale; Akbar, Shahzad] Riphah Int Univ, Riphah Coll Comp, Faisalabad Campus, Faisalabad, Pakistan.
   [Khan, Habib Ullah] Qatar Univ, Dept Accounting & Informat Syst, Doha, Qatar.
C3 Qatar University
RP Khan, HU (corresponding author), Qatar Univ, Dept Accounting & Informat Syst, Doha, Qatar.
EM Alehassan1000@gmail.com; Shahzadakbarbzu@gmail.com; habib.khan@qu.edu.qa
RI Khan, Habib Ullah/Q-7429-2016
OI Khan, Habib Ullah/0000-0001-8373-2781
CR Abràmoff MD, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0040-6
   Akbar S, 2019, MICROSC RES TECHNIQ, V82, DOI 10.1002/jemt.23172
   Akbar S, 2018, ARTIF INTELL MED, V90, P15, DOI 10.1016/j.artmed.2018.06.004
   Akbar S, 2018, COMPUT METH PROG BIO, V154, P123, DOI 10.1016/j.cmpb.2017.11.014
   Akbar S, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0712-9
   Akbar Shahzad, 2017, IPCV, P129
   Akram MU, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105282
   Al E. Hassan Syed, 2021, 2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA), P206, DOI 10.1109/CAIDA51941.2021.9425161
   [Anonymous], 2021, KAGGLE RETINAL IMAGI
   [Anonymous], 2022, HUMAN EYE ANATOMY
   Bino N., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1244, DOI 10.1109/ICCMC51019.2021.9418239
   Böger B, 2021, AM J INFECT CONTROL, V49, P21, DOI 10.1016/j.ajic.2020.07.011
   Chen ML, 2021, GRAEF ARCH CLIN EXP, V259, P2401, DOI 10.1007/s00417-021-05151-x
   Coiner B, 2019, BRAIN STRUCT FUNCT, V224, P2603, DOI 10.1007/s00429-019-01932-7
   David J, 2009, IFMBE PROC, V23, P331
   Dinc UA, 2011, CLIN EXP OPTOM, V94, P452, DOI 10.1111/j.1444-0938.2011.00598.x
   Ferreira CA, 2019, 2019 IEEE 6 PORT M B, P1, DOI DOI 10.1109/ENBENG.2019.8692560
   Forrester J.V., 2020, The eye e-book: basic sciences in practice
   Gholami P, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106532
   Gull S., 2021, Arti Intelli Inte Thin, P241, DOI [10.1201/9781003097204-10, DOI 10.1201/9781003097204-10]
   Hassan B, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P252, DOI [10.1109/C-CODE.2019.8680996, 10.1109/c-code.2019.8680996]
   Hassan SA, 2021, INTELLIGENT COMPUTIN, V19, P23, DOI [10.1201/9781003141105, DOI 10.1201/9781003141105]
   Hassan SA, 2021, IEEE ACCESS, V9, P168731, DOI 10.1109/ACCESS.2021.3108395
   Huang ZW, 2020, IEEE ACCESS, V8, P24697, DOI 10.1109/ACCESS.2020.2971225
   Ji ZX, 2018, LECT NOTES COMPUT SC, V11071, P372, DOI 10.1007/978-3-030-00934-2_42
   Khalid S, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/7148245
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Kumar S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P359, DOI 10.1109/SPIN.2018.8474264
   Lee WJ, 2016, EYE, V30, P1336, DOI 10.1038/eye.2016.113
   Li T, 2021, NAT RESOUR RES, V30, P27, DOI 10.1007/s11053-020-09742-z
   Mohammadpoory Z, 2019, MEASUREMENT, V140, P133, DOI 10.1016/j.measurement.2019.02.089
   Saba T, 2021, MICROSC RES TECHNIQ, V84, P3066, DOI 10.1002/jemt.23865
   Sekiryu T, 2010, INVEST OPHTH VIS SCI, V51, P4956, DOI 10.1167/iovs.09-5009
   Sharib A, 2014, RETINAL IMAGE REGIST
   Shoukat A, 2021, ARTIF INTELL, P209, DOI DOI 10.1201/9781003097204-9
   Teja RV, 2019, IEEE ENG MED BIO, P48, DOI [10.1109/EMBC.2019.8857075, 10.1109/embc.2019.8857075]
   Vasavi S, 2021, IEEE SENS J, V21, P11417, DOI 10.1109/JSEN.2020.3007883
   Wang FP, 2018, EYE VISION, V5, DOI 10.1186/s40662-018-0113-2
   Wen Y, 2020, IEEE INT C BIOINFORM, P1161, DOI 10.1109/BIBM49941.2020.9313274
   Xiong JL, 2019, INT C INTEL HUM MACH, P80, DOI 10.1109/IHMSC.2019.10114
   Xu Lijuan., 2019, 2019 11th International Conference on Wireless Communications and Signal Processing (WCSP), P1
   Zhen Y, 2020, RETINA-J RET VIT DIS, V40, P1558, DOI 10.1097/IAE.0000000000002621
   Zheng QH, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/4706576
   Zola M, 2018, ACTA OPHTHALMOL, V96, pE835, DOI 10.1111/aos.13742
NR 44
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21369
EP 21396
DI 10.1007/s11042-023-16206-y
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001041470800004
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Pradhan, A
   Pradhan, MP
   Pradhan, R
AF Pradhan, Ashis
   Pradhan, Mohan P.
   Pradhan, Ratika
TI An automated approach towards generation of stream attributes for use in
   GIS applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE River Network; Knowledge-Based Automated Computational Program; Network
   Types; Advanced Abilities; Stream Attributes
ID RIVER; CLASSIFICATION; EXTRACTION; CONTINUUM; DRAINAGE; HORTONS; LAWS;
   ECOSYSTEMS; SURFACE; ORDER
AB A river network is a beautiful natural geomorphological arrangement of stream segments extending from the headstream to the medium streams eventually moving further to join the main streams. Through morphological assessment, it has been observed that the structure of the river network is greatly influenced and dictated by the geographical landscaping of the terrain. Research initiatives conceived towards the morphological analysis of the river network necessarily mandate a sound knowledge of network types as well as the generation of attributes associated with various streams. Some of the important stream attributes associated with a stream segment belonging to a river network are stream order, stream number, bifurcation ratio, weighted mean bifurcation ratio, stream length, mean stream length, length ratio, weighted mean length ratio, area coverage, carriage capacity, coordinate trails and length of the mainstream. Traditionally, river network digitization and estimation of attributes were performed through the deployment of labor-intensive manual techniques. These techniques are intensive, extremely time-consuming and expensive, moreover, the results obtained are often found biased towards the digitizer's experience. Inaccurate digitization will not only influence the structure of the river network but also generate erroneous attributes. It will also have an adverse impact on the confidence of the inferences drawn from the analysis process. This problem can be tactfully handled by conceiving and realizing effective and efficient knowledge-based automated computational programs aided by the selection of appropriate data structures. Further, such programs can be easily advanced to generate desired stream attributes. With due regard to the above, this research initiative proposes an effective and efficient generic knowledge-based automated computational program equipped with a proficient spiral traversal technique capable of accurately digitizing river networks of different types with advanced abilities for generating various stream attributes with the desired level of confidence. Further, this work also highlights some of the prominent application domain of the proposed initiative.
C1 [Pradhan, Ashis] Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Comp Sci & Engn, Gangtok, India.
   [Pradhan, Mohan P.; Pradhan, Ratika] Sikkim Univ, Dept Comp Applicat, Gangtok, India.
C3 Sikkim Manipal University; Sikkim Manipal Institute of Technology;
   Sikkim University
RP Pradhan, A (corresponding author), Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Comp Sci & Engn, Gangtok, India.
EM ashis.pradhan.2010@gmail.com
RI PRADHAN, RATIKA/KHE-2411-2024
CR Agency EE, 2018, EUR WAT ASS STAT PRE, DOI [10.2800/303664, DOI 10.2800/303664]
   [Anonymous], 1963, Transactions of the American Society of Civil Engineers
   [Anonymous], 2003, Tools in Fluvial Geomorphology, DOI [DOI 10.1002/9781118648551.CH7, 10.1002/9781118648551.ch7]
   BARILA TY, 1981, J APPL ECOL, V18, P125, DOI 10.2307/2402482
   Beechie TJ, 2006, GEOMORPHOLOGY, V78, P124, DOI 10.1016/j.geomorph.2006.01.030
   Birk S, 2012, ECOL INDIC, V18, P31, DOI 10.1016/j.ecolind.2011.10.009
   BOWDEN KL, 1964, GEOL SOC AM BULL, V75, P767, DOI 10.1130/0016-7606(1964)75[767:EOSTOH]2.0.CO;2
   Bridge J.S., 1993, GEOLOGICAL SOC LONDO, V75, P13, DOI [10.1144/GSL.SP.1993.075.01.02, DOI 10.1144/GSL.SP.1993.075.01.02]
   Brierley GJ, 2005, GEOMORPHOLOGY AND RIVER MANAGEMENT: APPLICATIONS OF THE RIVER STYLES FRAMEWORK, P143
   Bryndal T, 2015, QUAEST GEOGR, V34, P85, DOI 10.1515/quageo-2015-0008
   Buffington J.M., 2003, Restoration of Puget Sound Rivers, P46
   Büttner O, 2020, ENVIRON RES LETT, V15, DOI 10.1088/1748-9326/abb62e
   Chorley R, 1995, PROG PHYS GEOG, V19, P533, DOI 10.1177/030913339501900406
   Church M, 2002, FRESHWATER BIOL, V47, P541, DOI 10.1046/j.1365-2427.2002.00919.x
   Ciaburri C., 2020, ACCENTS TRANSIMAGE P, V6, P32, DOI [10.19101/tipcv.2020.618040, DOI 10.19101/TIPCV.2020.618040]
   CUMMINS KW, 1974, BIOSCIENCE, V24, P631, DOI 10.2307/1296676
   CUSHING CE, 1983, ARCH HYDROBIOL, V98, P317
   Dade WB, 2000, GEOMORPHOLOGY, V35, P119, DOI 10.1016/S0169-555X(00)00030-1
   Dai ZX., 2019, INT ARCH PHOTOGRAMM, VXLII-4/W16, P169, DOI [10.5194/isprs-archives-xlii-4-w16-169-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W16-169-2019]
   DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5
   Dawson FH, 2002, AQUAT CONSERV, V12, P391, DOI 10.1002/aqc.534
   DESLOGES JR, 1989, CAN GEOGR-GEOGR CAN, V33, P360, DOI 10.1111/j.1541-0064.1989.tb00922.x
   Directive WF, 2003, COMM IMPL STRAT WAT
   Dupas Remi, 2019, Frontiers in Environmental Science, V7, DOI 10.3389/fenvs.2019.00043
   Epstein CM, 2002, J AM WATER RESOUR AS, V38, P69, DOI 10.1111/j.1752-1688.2002.tb01535.x
   Fang Y, 2018, EARTHS FUTURE, V6, P1134, DOI 10.1029/2017EF000746
   Gasnier N, 2021, IEEE J-STARS, V14, P5720, DOI 10.1109/JSTARS.2021.3083413
   Geographic Information Technology Training Alliance, 2016, HIER TREES
   Giusti E.V., 1965, DISTRIBUTION BRANCHE
   Goodwin CN, 1999, WILDLAND HYDROLOGY, PROCEEDINGS, P229
   Graf WL., 2010, SYST GEOGRAPH ANAL, V7, P335, DOI [10.1111/j.1538-4632.1975.tb01047.x, DOI 10.1111/J.1538-4632.1975.TB01047.X]
   Gul S., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P593, DOI 10.1109/DICTA.2010.105
   Harmel RD, 1999, J AM WATER RESOUR AS, V35, P113, DOI 10.1111/j.1752-1688.1999.tb05456.x
   Hering D, 2015, SCI TOTAL ENVIRON, V503, P10, DOI 10.1016/j.scitotenv.2014.06.106
   Huang PC, 2021, J HYDROL, V603, DOI 10.1016/j.jhydrol.2021.126856
   Hynes HBN., 1975, VERH INT VEREIN LIMN, V19, P1, DOI DOI 10.1080/03680770.1974.11896033
   Jäger CG, 2018, J THEOR BIOL, V442, P66, DOI 10.1016/j.jtbi.2018.01.009
   Jiang YY, 2022, FRONT APPL MATH STAT, V8, DOI 10.3389/fams.2022.918357
   KELLERHALS R, 1976, J HYDR ENG DIV-ASCE, V102, P813
   KIRCHNER JW, 1993, GEOLOGY, V21, P591, DOI 10.1130/0091-7613(1993)021<0591:SIOHSL>2.3.CO;2
   KNIGHTON AD, 1993, EARTH SURF PROCESSES, V18, P613, DOI 10.1002/esp.3290180705
   Kondolf GM, 2001, ENVIRON MANAGE, V28, P761, DOI 10.1007/s002670010260
   Kuemmerlen M, 2019, SCI TOTAL ENVIRON, V650, P1613, DOI 10.1016/j.scitotenv.2018.09.019
   Lane EW., 1957, STUDY SHAPE CHANNELS
   Lichtner W, 1988, AUTOMATIC DIGITIZATI, P218
   Liu TG, 2016, MULTIMED TOOLS APPL, V75, P5417, DOI 10.1007/s11042-015-2510-z
   Lorenz A, 2004, LIMNOLOGICA, V34, P379, DOI 10.1016/S0075-9511(04)80007-0
   LOTSPEICH FB, 1980, WATER RESOUR BULL, V16, P581
   Ma QY, 2023, GEOMORPHOLOGY, V425, DOI 10.1016/j.geomorph.2023.108587
   McDavitt WN, 2004, APPL STREAM CHANNEL
   MONTGOMERY DR, 1993, WATER RESOUR RES, V29, P3925, DOI 10.1029/93WR02463
   Montgomery DR, 1999, J AM WATER RESOUR AS, V35, P397, DOI 10.1111/j.1752-1688.1999.tb03598.x
   Muthusamy M, 2021, J HYDROL, V596, DOI 10.1016/j.jhydrol.2021.126088
   Naiman Robert J., 1998, P97
   Omernik JM, 2003, J AM WATER RESOUR AS, V39, P563, DOI 10.1111/j.1752-1688.2003.tb06066.x
   OSGeo, 2022, About us
   Pareta Kuldeep, 2011, International Journal of Geomatics and Geosciences, V2, P248
   Paustian S.J., 2010, A channel type users guide for the Tongass National Forest, Southeast Alaska
   Pavlidis T, 1981, FLEXIBLE PARALLEL TH
   Poole GC, 2004, EARTH SURF PROC LAND, V29, P1259, DOI 10.1002/esp.1091
   Powell JohnWesley., 1875, Exploration of the Colorado River of the West and its Tributaries Explored in 1869-1872 Under the Direction of the Secretary of the Smithsonian Institution
   Pradhan M, 2013, INT J COMPUT APPL, V65
   Pradhan MP, 2012, INT J ADV COMPUT SC, V3, P30
   Priess JA, 2019, ATLAS ECOSYSTEM SERV, P135, DOI [10.1007/978-3-319-96229-0_22, DOI 10.1007/978-3-319-96229-0_22]
   Rieger W., 1993, INT ARCH PHOTOGRAMME, V29, P642
   ROSGEN DL, 1994, CATENA, V22, P169, DOI 10.1016/0341-8162(94)90001-9
   Samet R, 2010, APPL COMPUT MATH-BAK, V9, P116
   Scheidegger A., 1966, Bulletin of the International Association of Scientific Hydrology, V11, P56, DOI [10.1080/02626666609493480, DOI 10.1080/02626666609493480]
   Scheidegger A.E., 1965, US GEOLOGICAL SURVEY, V525-B, P187, DOI DOI 10.1023/A:1015745629794
   SCHEIDEGGER AE, 1968, WATER RESOUR RES, V4, P167, DOI 10.1029/WR004i001p00167
   Sen A, 2012, P GIS OSTR 2012 SURF
   SHREVE RL, 1967, J GEOL, V75, P178, DOI 10.1086/627245
   SHREVE RL, 1966, J GEOL, V74, P17, DOI 10.1086/627137
   Storey R., 2009, An assessment of the lengths of permanent, intermittent and ephemeral streams in the Auckland region
   Strahler A.N., 1957, EOS T AM GEOPHYS UN, V38, P913, DOI [10.1029/TR038i006p00913, DOI 10.1029/TR038I006P00913, 10.1029/tr038i006p00913]
   TARBOTON D.G., 2003, 23 ESRI INT USERS C
   Tockner K, 2010, FRESHWATER BIOL, V55, P135, DOI 10.1111/j.1365-2427.2009.02371.x
   VANNOTE RL, 1980, CAN J FISH AQUAT SCI, V37, P130, DOI 10.1139/f80-017
   Venkatachalam P., 2001, 22 AS C REM SENS, V5, P1096
   Ward A.D., 2015, Environmental Hydrology, Vthird, DOI [10.1201/b19120, DOI 10.1201/B19120]
   Wimmer MH, 2021, J HYDROL X, V13, DOI 10.1016/j.hydroa.2021.100106
   WINTERBOURN MJ, 1982, NEW ZEAL J MAR FRESH, V16, P229, DOI 10.1080/00288330.1982.9515966
   Xue Y, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14102370
   Yang S, 2019, WATER RESOUR RES, V55, P6138, DOI 10.1029/2018WR024614
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 85
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20307
EP 20356
DI 10.1007/s11042-023-16426-2
EA AUG 2023
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400009
DA 2024-07-18
ER

PT J
AU Dargan, S
   Kumar, M
   Mittal, A
   Kumar, K
AF Dargan, Shaveta
   Kumar, Munish
   Mittal, Ajay
   Kumar, Krishan
TI Handwriting-based gender classification using machine learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Feature extraction; Gender prediction; Gurumukhi;
   Handwriting recognition
ID CHARACTER; IDENTIFICATION; RECOGNITION
AB Biometrics encloses the science of measuring human body characteristics and authorizing the user based on biometric modalities. Physiological and behavioural biometrics identifiers are the two kinds of biometrics. The present article i.e. Gender Classification system (GCS) is one of the most challenging and serviceable application among the many behavioural biometric based artificial intelligence and machine learning systems. In the current experiment, handwriting modality has been in practice for the gender classification. For the experimental evaluation, a corpus consisting of 200 writers with offline handwriting samples from 100 males and 100 females in Gurumukhi script has been pre-processed using pre-processing algorithms, followed by extracting features by exploiting Zoning, Diagonal, Peak extent, Transition and hybridization of feature extraction algorithms. Based on the extracted features, gender is classified using classification techniques, namely, K-NN, Decision trees, Random Forest, and Adaptive boosting methodology. Performance of the experiment has been analysed using evaluation metrics such as classification accuracy, precision rate, area under the curve, root mean square error and false-positive rate. The proposed system achieves maximum accuracy of 94.6% for gender classification using hybridization of features based on offline handwriting in Gurumukhi script.
C1 [Dargan, Shaveta; Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Mittal, Ajay; Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM shavetagnc@gmail.com; munishcse@gmail.com; ajaymittal@pu.ac.in;
   k.saluja@pu.ac.in
RI Berwal, Krishan/AAC-3473-2020; Kumar, Munish/P-7756-2018
OI Berwal, Krishan/0000-0002-7068-6541; Kumar, Munish/0000-0003-0115-1620
CR Afifi M, 2019, MULTIMED TOOLS APPL, V78, P20835, DOI 10.1007/s11042-019-7424-8
   Aggarwal Arpit, 2015, 2015 International Conference on Advanced Computing and Communication Systems (ICACCS). Proceedings, P1, DOI 10.1109/ICACCS.2015.7324099
   Aggarwal K., 2016, PROCEED INT C INVENT, V3, P1
   Ahmed M, 2017, EXPERT SYST APPL, V85, P158, DOI 10.1016/j.eswa.2017.05.033
   Akbari Y, 2017, IMAGE VISION COMPUT, V59, P17, DOI 10.1016/j.imavis.2016.11.017
   Al Maadeed S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-10
   Aubin V, 2017, EXPERT SYST APPL, V89, P241, DOI 10.1016/j.eswa.2017.07.039
   Bartle A, 2015, 17 STANF
   Bi N, 2019, PATTERN RECOGN LETT, V121, P123, DOI 10.1016/j.patrec.2018.05.005
   Botchkarev A., 2019, IJIKM, V14, P45, DOI [10.48550/arXiv.1809.03006, 10.28945/4184, DOI 10.28945/4184]
   Bouadjenek N, 2015, INISTA 2015A 2015A I, DOI [10.1109/INISTA.2015.7276752, DOI 10.1109/INISTA.2015.7276752]
   Bouadjenek N, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P43, DOI 10.1109/SOCPAR.2014.7007979
   Cha SH, 2001, PROC INT CONF DOC, P1022, DOI 10.1109/ICDAR.2001.953940
   Cordasco G, 2020, INT CONF COGN INFO, P197, DOI [10.1109/CogInfoCom50765.2020.9237863, 10.1109/coginfocom50765.2020.9237863]
   Cui YH, 2020, MULTIMED TOOLS APPL, V79, P7669, DOI 10.1007/s11042-019-08355-w
   Dargan S, 2019, ARCH COMPUT METHOD E, V26, P1283, DOI 10.1007/s11831-018-9278-z
   DARMATASIA M, 2017, P 5 INT C INFORM COM, P1
   Fallah B, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P120, DOI 10.1109/RIOS.2016.7529501
   Gader PD, 1997, IEEE T SYST MAN CY B, V27, P158, DOI 10.1109/3477.552199
   Garain A, 2021, IEEE ACCESS, V9, P85672, DOI 10.1109/ACCESS.2021.3085971
   Garg Anupam, 2021, International Journal of Information Technology, V13, P2389, DOI 10.1007/s41870-019-00398-4
   Gattal A, 2018, EXPERT SYST APPL, V99, P155, DOI 10.1016/j.eswa.2018.01.038
   Guerbai Y, 2017, P 7 INT C IMAGE PROC, P1, DOI DOI 10.1109/IPTA.2017.8310136
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Hussain R, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0102-5
   Illouz E, 2018, LECT NOTES COMPUT SC, V11141, P613, DOI 10.1007/978-3-030-01424-7_60
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Katna R, 2022, MULTIMED TOOLS APPL, V81, P27799, DOI 10.1007/s11042-022-12920-1
   Kumar M, 2011, INT C IM INF PROC IC, P1
   Kumar M., 2013, Smart Comput Rev, V3, P346, DOI [10.6029/smartcr.2013.05.005, DOI 10.6029/SMARTCR.2013.05.005]
   Kumar M, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0966-z
   Kumar M, 2017, P NATL A SCI INDIA A, V87, P137, DOI 10.1007/s40010-016-0284-y
   Kumar M, 2014, NATL ACAD SCI LETT, V37, P567, DOI 10.1007/s40009-014-0280-1
   Kumar M, 2014, NATL ACAD SCI LETT, V37, P381, DOI 10.1007/s40009-014-0253-4
   Kumar M, 2013, IETE J RES, V59, P687, DOI 10.4103/0377-2063.126961
   Kumar S, 2022, MULTIMED TOOLS APPL, V81, P42285, DOI 10.1007/s11042-021-11499-3
   Levi G, 2015, IEEE COMPUT SOC CONF
   Liwicki M, 2011, PATTERN ANAL APPL, V14, P87, DOI 10.1007/s10044-010-0178-6
   Maken P, 2021, MULTIMED TOOLS APPL, V80, P24573, DOI 10.1007/s11042-021-10837-9
   Mekhaznia T, 2021, COMMUN COMPUT PHYS, V1322, DOI [10.1007/978-3-030-71804-6_12, DOI 10.1007/978-3-030-71804-6_12]
   Mirza A, 2016, INT CONF FRONT HAND, P395, DOI [10.1109/ICFHR.2016.0080, 10.1109/ICFHR.2016.75]
   Morera A, 2018, COMPLEXITY, DOI 10.1155/2018/3891624
   Mudjirahardjo P, 2015, P INT EL S IES, DOI [10.1109/ELECSYM.2015.7380826, DOI 10.1109/ELECSYM.2015.7380826]
   Rabaev I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249650
   Rahmanian M, 2021, MULTIMED TOOLS APPL, V80, P35341, DOI 10.1007/s11042-020-10170-7
   Rai P, 2015, INT CONF COMPUT INTE, P254, DOI 10.1109/CICN.2015.58
   Sharma A, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P391, DOI 10.1109/CISP.2008.297
   Siddiqi I, 2015, PATTERN ANAL APPL, V18, P887, DOI 10.1007/s10044-014-0371-0
   Singh H., 2018, NEURAL COMPUT APPL, V31, P3857
   Singh H, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0961-4
   Singh S, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3282441
   Verma K, 2018, P NATL A SCI INDIA A, V88, P297, DOI 10.1007/s40010-017-0416-z
   Yang WK, 2017, MULTIMED TOOLS APPL, V76, P4491, DOI 10.1007/s11042-016-3446-7
   Youssef AE, 2013, P INT C S AFR I PHYS, P1
   Zarifi A, 2023, MULTIMED TOOLS APPL, V82, P17097, DOI 10.1007/s11042-022-14141-y
NR 55
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19871
EP 19895
DI 10.1007/s11042-023-16354-1
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500006
DA 2024-07-18
ER

PT J
AU Minija, SJ
   Rejula, MA
   Ross, BS
AF Minija, S. Jasmine
   Rejula, M. Anline
   Ross, B. Shamina
TI Automated detection of diabetic retinopathy using optimized
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy (DR); Optimized convolutional neural network
   (OpCoNet); Gray wolf optimizer (GWO); Diabetes mellitus (DM)
ID FUNDUS PHOTOGRAPHY
AB Diabetes is one of the most common diseases across the world. It affects numerous parts of our body. Diabetic Retinopathy has an effect on retina which causes Diabetes Mellitus (DM) and it may even lead to blindness. Hence, detecting Diabetic Retinopathy (DR) is important during the early stages of diabetes which can prevent the patients from blindness. The publically accessible dataset of Diabetic Retinopathy (DR) contains numerous images of the retina and its results on Diabetic Retinopathy (DR). Our proposed ideology is to classify the images of the retina using an optimized convolutional neural network (OpCoNet) to detect whether the Diabetic Retinopathy (DR) is proliferative or severe or moderate or mild or normal. The optimized convolutional neural network has enhanced feature extraction and classification mechanism. Gray wolf optimization is used to train the CNN layers. The tested model is compared with the existing methodologies used for the detection of Diabetic Retinopathy (DR). The proposed technique effectually provides an accuracy of 98% and sensitivity of 98.5%. The automatic detection of Diabetic Retinopathy (DR) efficaciously proved in the screening process as well as lessens the trouble on medical services support.
C1 [Minija, S. Jasmine; Rejula, M. Anline; Ross, B. Shamina] Scott Christian Coll Autonomous, Nagercoil 629001, Tamil Nadu, India.
RP Minija, SJ (corresponding author), Scott Christian Coll Autonomous, Nagercoil 629001, Tamil Nadu, India.
EM minijakenson@gmail.com; rejula77@gmail.com
CR Achary R, 2008, IMAGE MODELING HUMAN
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   *EARL TREATM DIAB, 1991, OPHTHALMOLOGY, V98, P786, DOI DOI 10.1016/S0161-6420(13)38012-9
   Gardiner TA., 2022, Int J Transl Med, V2, P41, DOI [DOI 10.3390/IJTM2010004, 10.3390/ijtm2010004]
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Goel T, 2021, APPL INTELL, V51, P1351, DOI 10.1007/s10489-020-01904-z
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Khan Z, 2021, IEEE ACCESS, V9, P61408, DOI 10.1109/ACCESS.2021.3074422
   Li F, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.4
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Ong GL, 2004, AM J OPHTHALMOL, V137, P445, DOI 10.1016/j.ajo.2003.10.021
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P15847, DOI 10.1109/JIOT.2021.3051080
   Rajalakshmi R, 2018, EYE, V32, P1138, DOI 10.1038/s41433-018-0064-9
   Riaz H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10010024
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Wu H, 2018, OPTIK, V156, P772, DOI 10.1016/j.ijleo.2017.11.153
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yaqoob MK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113883
NR 20
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21065
EP 21080
DI 10.1007/s11042-023-16204-0
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043237000006
DA 2024-07-18
ER

PT J
AU Maitre, J
   Bergeron-Leclerc, C
   Maltais, D
   Gaboury, S
AF Maitre, Julien
   Bergeron-Leclerc, Christiane
   Maltais, Danielle
   Gaboury, Sebastien
TI Investigating anxiety levels in the Quebec university community during
   the COVID-19 pandemic using machine learning and data exploration
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anxiety; Pandemic; Machine learning; Predictive modeling; Explainable AI
ID PERSONAL BELIEFS; METAANALYSIS; PREVALENCE; STUDENTS
AB Numerous studies have demonstrated the adverse impact of the COVID-19 global pandemic on the mental health of post-secondary students worldwide. However, there have been relatively few investigations conducted in a university setting that encompasses both students and employees. Furthermore, almost all previous studies relied on conventional statistical analysis. Our research specifically examined anxiety levels among the Quebec university community during the COVID-19 pandemic, with a focus on the Generalized Anxiety Disorder (GAD-7) score using both conventional data exploration and predictive machine learning techniques. We found that the CatBoost algorithm was the best predictor of the GAD-7 score, achieving a squared Pearson correlation coefficient of r(2) = 0.5656. Additionally, we utilized SHapley Additive exPlanations (SHAP) to explore variable importance and interaction effects between the variables in the predictive model. Finally, we also examined anxiety levels from the perspective of a classification task. Unfortunately, the results obtained were not as satisfactory as those obtained by the regression approach.
C1 [Maitre, Julien; Gaboury, Sebastien] Univ Quebec Chicoutimi, Dept Informat & Math, 555 Blvd Univ, Chicoutimi, PQ G7H2B1, Canada.
   [Bergeron-Leclerc, Christiane; Maltais, Danielle] Univ Quebec Chicoutimi, Dept Sci Humaines & Sociales, 555 Blvd Univ, Chicoutimi, PQ G7H2B1, Canada.
C3 University of Quebec; University of Quebec Chicoutimi; University of
   Quebec; University of Quebec Chicoutimi
RP Gaboury, S (corresponding author), Univ Quebec Chicoutimi, Dept Informat & Math, 555 Blvd Univ, Chicoutimi, PQ G7H2B1, Canada.
EM Julien1_Maitre@uqac.ca; Christiane_Bergeron-Leclerc@uqac.ca;
   Danielle_Maltais@uqac.ca; Sebastien_Gaboury@uqac.ca
CR Ahmed I, 2023, BMC PSYCHIATRY, V23, DOI 10.1186/s12888-023-04645-8
   Al Miskry ASA, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.682757
   Al-Tammemi AB, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.562213
   Alam MD, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.707342
   Amaral-Prado HM, 2021, INT J SOC PSYCHIATR, V67, P720, DOI 10.1177/0020764020971318
   American psychiatric association, WHAT ARE ANX DIS, DOI [10.3389/fpsyt.2021.707342, DOI 10.3389/FPSYT.2021.707342]
   Auerbach RP, 2018, J ABNORM PSYCHOL, V127, P623, DOI 10.1037/abn0000362
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Caron J, 1996, Sante Ment Que, V21, P158
   Caron J, 2013, SANTE MENT QUE, V38, P297, DOI 10.7202/1019198ar
   Carr E, 2022, OCCUP ENVIRON MED, V79, P259, DOI 10.1136/oemed-2021-107667
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cheng MWT, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13116176
   Chi T, 2023, BRAIN BEHAV, V13, DOI 10.1002/brb3.2909
   Correia KM, 2022, J MICROBIOL BIOL EDU, V23, DOI 10.1128/jmbe.00224-21
   Das D, 2021, AEM EDUC TRAIN, V5, P91, DOI 10.1002/aet2.10539
   Delpino FM, 2022, J AFFECT DISORDERS, V318, P272, DOI 10.1016/j.jad.2022.09.003
   Santamaría MD, 2021, GLOB MENT HEALTH, V8, DOI 10.1017/gmh.2021.14
   Doyle JM, 2021, J CLIN TRANSL SCI, V5, DOI 10.1017/cts.2021.851
   Duckworth C, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02481-y
   Freibott CE, 2022, DRUG ALC DEPEND REP, V3, DOI 10.1016/j.dadr.2022.100060
   Ge FF, 2020, NEUROPSYCH DIS TREAT, V16, P2111, DOI 10.2147/NDT.S262004
   Gelezelyte O, 2022, DEATH STUD, V46, P2395, DOI 10.1080/07481187.2021.1947417
   Gonzales G, 2020, J ADOLESCENT HEALTH, V67, P645, DOI 10.1016/j.jadohealth.2020.08.006
   Heiden M, 2021, HIGH EDUC, V81, P707, DOI 10.1007/s10734-020-00569-4
   Horita R, 2021, PSYCHIAT RES, V295, DOI 10.1016/j.psychres.2020.113561
   Husky MM, 2020, COMPR PSYCHIAT, V102, DOI 10.1016/j.comppsych.2020.152191
   Kecojevic A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239696
   Ligus K, 2021, TRANSL BEHAV MED, V11, P802, DOI 10.1093/tbm/ibab020
   Liu C, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18136730
   Lopes DG, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.689919
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma K, 2022, WORK, V73, P3, DOI 10.3233/WOR-220062
   Ma Z, 2020, EPIDEMIOL PSYCH SCI, V29, DOI 10.1017/S2045796020000931
   Madaus JW, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.872733
   Mandhouj O, 2012, HEALTH QUAL LIFE OUT, V10, DOI 10.1186/1477-7525-10-39
   McMaughan DJ, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.782793
   O'Connell KA, 2006, SOC SCI MED, V62, P1486, DOI 10.1016/j.socscimed.2005.08.001
   Ochnik D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97697-3
   Orpana HM., 2019, RECHERCHE POLITIQUES, V39, P352
   Padrón I, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.589927
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Rakhmanov O, 2020, J RES MED DENT SCI, V8, P53
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Saravanan C, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.582189
   Schröpfer K, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18126611
   Shapley Lloyd S, 1953, Contributions to the Theory of Games (AM-28), V2, P307, DOI DOI 10.1515/9781400881970-018
   Shen P., 2021, International Education Studies, V14, P82, DOI DOI 10.5539/IES.V14N3P82
   Skevington SM, 2013, QUAL LIFE RES, V22, P1073, DOI 10.1007/s11136-012-0237-0
   Song YX, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-02951-x
   Spitzer RL, 2006, ARCH INTERN MED, V166, P1092, DOI 10.1001/archinte.166.10.1092
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Villani L, 2021, GLOBALIZATION HEALTH, V17, DOI 10.1186/s12992-021-00680-w
   Weyandt LL, 2020, HEALTH BEHAV POLICY, V7, P532, DOI 10.14485/HBPR.7.6.3
   who, Mental disorders
   Winkel Carmen, 2023, Illn Crises Loss, V31, P4, DOI 10.1177/10541373211029079
   Wo NKH, 2020, TRANSCULT PSYCHIATRY, V57, P263, DOI 10.1177/1363461519861824
   Woolston C, 2020, NATURE, V585, P147, DOI 10.1038/d41586-020-02439-6
   Wray S, 2022, OCCUP MED-OXFORD, V72, P2, DOI 10.1093/occmed/kqab007
   Zhu J, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.777251
NR 60
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46109
EP 46127
DI 10.1007/s11042-023-16096-0
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001035582300004
DA 2024-07-18
ER

PT J
AU Srividhya, L
   Sowmya, 
   Ravi, V
   Gopalakrishnan, EA
   Soman, KP
AF Srividhya, L.
   Sowmya, V
   Ravi, Vinayakumar
   Gopalakrishnan, E. A.
   Soman, K. P.
TI Deep learning-based approach for multi-stage diagnosis of Alzheimer's
   disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's Disease (AD); Alzheimer's Disease Neuroimaging Initiative
   (ADNI); Convolutional Neural Networks (CNN); Deep learning; Mild
   Cognitive Impairment (MCI); Structural Magnetic Resonance Imaging
   (sMRI); ResNet-50v2; Grad-CAM; Saliency map
ID CLASSIFICATION
AB Alzheimer's Disease (AD) is a common neurological brain disorder that causes the brain cells to die and shrink (Atrophy) gradually, resulting in a continuous decline in one's ability to function independently. Early diagnosis increases the possibility of preventing or delaying the advancement of this mental disorder. Magnetic Resonance Imaging (MRI) offers the potential of non-invasive longitudinal monitoring and plays a vital role as a biomarker of the disease progression. Structural Magnetic Resonance Imaging (sMRI) helps to measure Atrophy, which is considered to be the most dependable biomarker to assess the exact stage and severity of the neuro-degenerative aspect of AD pathology. There are five stages associated with AD, which include Normal Control (NC), Early Mild Cognitive Impairment (EMCI), Mild Cognitive Impairment (MCI), Late Mild Cognitive Impairment (LMCI), and Alzheimer's Disease (AD). In this work, we have used the Alzheimer's Disease Neuroimaging Initiative (ADNI2) sMRI image dataset to measure and classify the stage of AD. In recent years, Convolutional Neural Networks (CNNs) are widely used for medical image analysis. This work focuses on applying different Deep Learning algorithms for the multi-class classification of AD MRI images and proposes the best pre-trained model that can accurately predict the patient's stage. It is observed that ResNet-50v2 gives the best accuracy of 91.84% and f1-score of 0.97 for AD class. Visualization techniques such as Grad-CAM and Saliency Map are applied on the model that gave the best accuracy to understand the region of focus in the image which led to predicting its class.
C1 [Srividhya, L.; Sowmya, V; Gopalakrishnan, E. A.; Soman, K. P.] Amrita Vishwa Vidyapeetham, Ctr Computat Engn & Networking CEN, Amrita Sch Engn Coimbatore, Coimbatore, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore;
   Prince Mohammad Bin Fahd University
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM srividhya.amrita@gmail.com; v_sowmya@cb.amrita.edu; vravi@pmu.edu.sa;
   ea_gopalakrishnan@cb.amrita.edu; kp_soman@amrita.edu
RI Ravi, Vinayakumar/L-4202-2018; V, Sowmya/R-5897-2017
OI Ravi, Vinayakumar/0000-0001-6873-6469; V, Sowmya/0000-0003-3745-6944
CR adni, 2004, ALZH ADNI DAT
   Al-Shoukry S, 2020, IEEE ACCESS, V8, P77131, DOI 10.1109/ACCESS.2020.2989396
   Aloysius N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P588, DOI 10.1109/ICCSP.2017.8286426
   Altinkaya E., 2020, J Institut Electron Comp, V1, P39
   Bae JB, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79243-9
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Bin Tufail A, 2020, J DIGIT IMAGING, V33, P1073, DOI 10.1007/s10278-019-00265-5
   Burgos N, 2021, BRIEF BIOINFORM, V22, P1560, DOI 10.1093/bib/bbaa310
   Castellazzi G, 2020, FRONT NEUROINFORM, V14, DOI 10.3389/fninf.2020.00025
   Cedazo-Minguez A, 2010, EXP GERONTOL, V45, P5, DOI 10.1016/j.exger.2009.09.008
   Chandra A, 2019, J NEUROL, V266, P1293, DOI 10.1007/s00415-018-9016-3
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chitradevi D, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105857
   Cohen David S, 2019, Curr Neurobiol, V10, P141
   Farooq A, 2017, IEEE CONF IMAGING SY, P111
   Feng W, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S012906572050032X
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Islam Jyoti, 2018, Brain Inform, V5, P2, DOI 10.1186/s40708-018-0080-3
   Jo T, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00220
   Khan R., 2022, Front Neurosci, V16
   Knight MJ, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00139
   Lee GY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36999-5
   Lin WM, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00777
   Ma D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00853
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   McCrackin Laura, 2018, Advances in Artificial Intelligence. 31st Canadian Conference on Artificial Intelligence, Canadian AI 2018. Proceedings: LNAI 10832, P355, DOI 10.1007/978-3-319-89656-4_40
   Murugan S, 2021, IEEE ACCESS, V9, P90319, DOI 10.1109/ACCESS.2021.3090474
   Nagaraju S, 2021, J HETEROCYCLIC CHEM, V58, P1252, DOI 10.1002/jhet.4251
   Nair JJ, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1232, DOI 10.1109/ICCSP.2017.8286577
   Noor Manan Binth Taj, 2020, Brain Inform, V7, P11, DOI 10.1186/s40708-020-00112-2
   Odusami M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061071
   Oh K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54548-6
   Pereira MEDC etal, 2019, EXT 2D CNN APPR DIAG
   Rana SS, 2020, 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES (BDCAT 2020), P9, DOI 10.1109/BDCAT50828.2020.00013
   Rasmussen J, 2019, DEGENER NEUROL NEURO, V9, P123, DOI 10.2147/DNND.S228939
   Sarraf S., 2016, PREPRINT
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Spasov SE, 2018, IEEE ENG MED BIO, P1271, DOI 10.1109/EMBC.2018.8512468
   Thushara A., 2020, 2020 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA), P249, DOI 10.1109/ACCTHPA49271.2020.9213211
   Toshkhujaev S, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/3743171
   Trojachanec K, 2018, IEEE ACCESS, V6, P9703, DOI 10.1109/ACCESS.2017.2773359
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Veetil I.K., 2021, 2021 IEEE 18th India Council International Conference (INDICON), P1
   Vemuri P, 2010, ALZHEIMERS RES THER, V2, DOI 10.1186/alzrt47
   Venugopalan J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-74399-w
   Wada A, 2019, MAGN RESON MED SCI, V18, P219, DOI 10.2463/mrms.mp.2018-0091
   Xiaoling Lu, 2019, Journal of Physics: Conference Series, V1345, DOI 10.1088/1742-6596/1345/4/042012
   Xu ZF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093445
   Zhang TT, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00572
NR 52
TC 2
Z9 2
U1 12
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16799
EP 16822
DI 10.1007/s11042-023-16026-0
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032703400004
DA 2024-07-18
ER

PT J
AU Tsai, CS
   Wu, HC
   Chen, WT
   Ying, JJC
AF Tsai, Chwei-Shyong
   Wu, Hsien-Chu
   Chen, Wei-Ting
   Ying, Josh Jia-Ching
TI ATFS: A deep learning framework for angle transformation and face
   swapping of face de-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face de-identification; Face swapping; Angle transformation; Generative
   adversarial network
ID RECOGNITION; NETWORK
AB This paper proposes an effective framework for improving angle transformation and face replacement. This ATFS framework aims to solve the image distortion caused by angled face swapping in face de-identification. In the ATFS framework, TransNet and SWGAN were proposed based on generative adversarial networks. When TransNet uses neural networks to reconstruct images, it combines the predicted facial points. As a result, Transnet can locate the target's facial features and generate multi-angle transformed images to achieve angle transformation. The SWGAN applies a complicated neural network that combines residual operations and self-attention modules to extract the input image features and replace the face region of the input image with the target image to achieve face de-identification. Both TransNet and SWGAN adopt discriminators and various loss functions to train the neural network and accurately accelerate the training process. The experimental results show that the proposed method can maintain high-quality images and avoid image distortion during face swapping for image angle transformation compared to previously proposed methods.
C1 [Tsai, Chwei-Shyong; Chen, Wei-Ting; Ying, Josh Jia-Ching] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 402, Taiwan.
   [Wu, Hsien-Chu] Natl Chin Yi Univ Technol, Language Ctr, Taichung 411, Taiwan.
   [Wu, Hsien-Chu] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 404, Taiwan.
C3 National Chung Hsing University; National Chin-Yi University of
   Technology; National Taichung University of Science & Technology
RP Ying, JJC (corresponding author), Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 402, Taiwan.
EM tsaics@nchu.edu.tw; wuhc@nutc.edu.tw; 7108029134@smail.nchu.edu.tw;
   jashying@gmail.com
FU Ministry of Science and Technology [MOST 109-2221-E-005-057-MY2]
FX This research was funded by Ministry of Science and Technology grant
   number MOST 109-2221-E-005-057-MY2 and .
CR Amelio A, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119391
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chen D., 2019, Mathematical Problems in Engineering, V2019
   Chen Datong., 2009, Protecting_Privacy_in_Video_Surveillance, P115
   Cho D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031120
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iglovikov V, 2018, Arxiv, DOI arXiv:1801.05746
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Lin CH, 2020, IEEE SENS J, V20, P9510, DOI 10.1109/JSEN.2020.2986098
   Meden B, 2017, IET SIGNAL PROCESS, V11, P1046, DOI 10.1049/iet-spr.2017.0049
   Naruniec J, 2020, COMPUT GRAPH FORUM, V39, P173, DOI 10.1111/cgf.14062
   Nirkin Y, 2023, IEEE T PATTERN ANAL, V45, P560, DOI 10.1109/TPAMI.2022.3155571
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Perov I, 2021, Arxiv, DOI arXiv:2005.05535
   Ribaric S, 2015, IEEE INT CONF AUTOMA
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Samarzija B, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1246, DOI 10.1109/MIPRO.2014.6859758
   Shu C., 2022, P IEEECVF C COMPUTER, P10789
   Souček T, 2019, Arxiv, DOI arXiv:1906.03363
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Wu JQ, 2019, PROC CVPR IEEE, P3708, DOI 10.1109/CVPR.2019.00383
   Wu YF, 2019, J COMPUT SCI TECH-CH, V34, P47, DOI 10.1007/s11390-019-1898-8
   Xu YY, 2022, PROC CVPR IEEE, P7632, DOI 10.1109/CVPR52688.2022.00749
NR 29
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 14
PY 2023
DI 10.1007/s11042-023-16123-0
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M5HW6
UT WOS:001030536100001
DA 2024-07-18
ER

PT J
AU Pratama, RA
   Yudistira, N
   Bachtiar, FA
AF Pratama, Raka Aditya
   Yudistira, Novanto
   Bachtiar, Fitra Abdurrachman
TI Violence recognition on videos using two-stream 3D CNN with custom
   spatiotemporal crop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video classification; ResNet; Transfer learning; Freeze layer
AB Violence may happen anywhere. One of the ways to know and oversee the violence in some places is by installing Closed-circuit Television (CCTV). The recorded video captured by CCTV can be used as proof in a law court. Violence video classification is also one of the topics being discussed in deep learning. The latest violence video dataset is RWF-2000. That dataset contains violent and non-violent videos, 5 seconds duration, 30 frames per second, with the amount of 2000 videos. That publication also has the best accuracy of 87.25% by their proposed method. In this study, we will use a Residual Network known to have the advantage of solving the vanishing gradient problem. Beside that, we also implement transfer learning from Kinetics and Kinetics + Moments in Time pre-trained data. We also test the number of frames and the location range of the sampled frames. RGB and optical flow inputs are separately trained with different configurations. The RGB input best accuracy is 89.25% with pre-trained Kinetics + Moments in Time, using frame location of 49-149. The optical flow input best accuracy is 88.5% with pre-trained Kinetics, using 74 frames. We also try to sum the output of both inputs making accuracy of 90.5%.
C1 [Pratama, Raka Aditya; Yudistira, Novanto; Bachtiar, Fitra Abdurrachman] Brawijaya Univ, Fac Comp Sci, Informat Dept, Jalan Vet 8, Malang 65145, Indonesia.
C3 Brawijaya University
RP Yudistira, N (corresponding author), Brawijaya Univ, Fac Comp Sci, Informat Dept, Jalan Vet 8, Malang 65145, Indonesia.
EM rakdit@gmail.com; yudistira@ub.ac.id; fitra.bachtiar@ub.ac.id
RI Yudistira, Novanto/AAR-9802-2021; Bachtiar, Fitra/X-6753-2019
OI Bachtiar, Fitra/0000-0002-0845-247X; Yudistira,
   Novanto/0000-0001-5330-5930
CR Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Carreira J, 2019, Arxiv, DOI arXiv:1907.06987
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng M, 2021, INT C PATT RECOG, P4183, DOI 10.1109/ICPR48806.2021.9412502
   detikNews, 2021, AKSI KELOMPOK PEMUDA
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Haque M, EFFICIENT DEEP LEARN
   Hara K, 2018, INT C PATT RECOG, P2516, DOI 10.1109/ICPR.2018.8546325
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Islam Z., 2021, 2021 INT JOINT C NEU, P1
   Kataoka H, 2020, Arxiv, DOI [arXiv:2004.04968, DOI 10.48550/ARXIV.2004.04968]
   Kompas.com, 2020, TEREKAM CCTV KASARI
   Liang QM, 2021, MATEC WEB CONF, V336, DOI 10.1051/matecconf/202133605013
   Lu ZZ, 2021, INT J COGN INFORM NA, V15, DOI 10.4018/IJCINI.287601
   Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464
   Mumtaz N, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239383
   Rendón-Segador FJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131601
   Sudhakaran S., 2017, 2017 14 IEEE INT C A, P1, DOI DOI 10.1109/AVSS.2017.8078468
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tran D, 2018, Arxiv, DOI [arXiv:1711.11248, 10.48550/arXiv.1711.11248, DOI 10.48550/ARXIV.1711.11248]
   Ullah A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207595
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Yudistira N, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0235-9
   Zhao YX, 2022, J SUPERCOMPUT, V78, P3940, DOI 10.1007/s11227-021-04007-9
NR 25
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 5
PY 2023
DI 10.1007/s11042-023-15599-0
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L5TV5
UT WOS:001023897700010
DA 2024-07-18
ER

PT J
AU Bengamra, S
   Mzoughi, O
   Bigand, A
   Zagrouba, E
AF Bengamra, Siwar
   Mzoughi, Olfa
   Bigand, Andre
   Zagrouba, Ezzeddine
TI A comprehensive survey on object detection in Visual Art: taxonomy and
   challenge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Painting; Object detection; Deep learning;
   Explainability
ID COMPUTER VISION; RECOGNITION; PAINTINGS; IMAGE; MODEL
AB Cultural heritage data plays a key role in the understanding of past human history and culture, enriches the present and prepares the future. A wealth of information is buried in artwork images that can be extracted via digitization and analysis. While a huge number of methods exists, a deep review of the literature concerning object detection in visual art is still lacking. In this study, after reviewing several related papers, a comprehensive review is presented, including (i) an overview of major computer vision applications for visual art, (ii) a presentation of previous related surveys, (iii) a comprehensive overview of relevant object detection methods for artistic images. Considering the studied object detection methods, we propose a new taxonomy based on the supervision learning degree, the adopted framework, the adopted methodology (classical or deep-learning based method), the type of object to detect and the depictive style of the painting images. Then the several challenges for object detection in artistic images are described and the proposed ways of solving some encountered problems are discussed. In addition, available artwork datasets and metrics used for object detection performance evaluation are presented. Finally, we provide potential future directions to improve object detection performances in paintings.
C1 [Bengamra, Siwar; Zagrouba, Ezzeddine] Univ Tunis El Manar, Higher Inst Comp Sci, LIMT Lab, 2 Rue Abou Raihan El Bayrouni, Ariana 2080, Tunisia.
   [Bengamra, Siwar; Bigand, Andre] Univ Littoral Opal Coast ULCO, LISIC Lab, 50 Rue Ferdinand Buisson, F-62228 Calais, France.
   [Mzoughi, Olfa] Prince Sattam Bin Abdulaziz Univ, Dept Comp Sci, Al Aflaj 16733, Saudi Arabia.
C3 Universite de Tunis-El-Manar; Universite du Littoral-Cote-d'Opale;
   Prince Sattam Bin Abdulaziz University
RP Bengamra, S (corresponding author), Univ Tunis El Manar, Higher Inst Comp Sci, LIMT Lab, 2 Rue Abou Raihan El Bayrouni, Ariana 2080, Tunisia.; Bengamra, S (corresponding author), Univ Littoral Opal Coast ULCO, LISIC Lab, 50 Rue Ferdinand Buisson, F-62228 Calais, France.
EM bengamra.siwar@gmail.com; olfa.mzoughi@gmail.com;
   bigand@univ-littoral.fr; e.zagrouba@gmail.com
RI Zagrouba, Ezzeddine/D-7896-2014; mzoughi, olfa/HMW-1127-2023
OI Zagrouba, Ezzeddine/0000-0002-2574-9080; mzoughi,
   olfa/0000-0001-8758-9740; BEN GAMRA, siwar/0000-0001-5546-5292
CR Achlioptas P, 2021, PROC CVPR IEEE, P11564, DOI 10.1109/CVPR46437.2021.01140
   Al-Yasiri D., 2018, J ADV RES DYN CONTRO, V10, P2345
   Amura A., 2020, COLOR CULTURE SCI J, V12, P07
   [Anonymous], 2014, PEOPLEART DATASET
   [Anonymous], 2010, WIKIART VISUAL ART E
   [Anonymous], 2019, BRUEGHEL DATASET
   [Anonymous], 2014, PAINTINGS DATASET
   [Anonymous], 2018, CASPA DATASET
   [Anonymous], 2018, MAFD 150 DATASET
   [Anonymous], 2019, ARTISTIC FACES DATAS
   [Anonymous], 2019, KOTENSEKI DATASET
   [Anonymous], 2018, ICONART DATASET
   [Anonymous], 2016, PHOTOART50 DATASET
   Goenaga MA, 2020, AUSART, V8, P51, DOI 10.1387/ausart.21490
   Arora RS, 2012, INT C PATT RECOG, P3541
   Bai Y, 2020, IEEE IMAGE PROC, P1256, DOI [10.1109/ICIP40778.2020.9190892, 10.1109/icip40778.2020.9190892]
   Barnard K., 2001, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V2, pII
   Bekkouch IEI, 2021, LECT NOTES NETWORKS, P674, DOI [10.1007/978-3-030-82196-8_50, DOI 10.1007/978-3-030-82196-8_50]
   Bengamra S, 2023, P 12 INT C PATT REC, P832, DOI [10.5220/0011670300003411, DOI 10.5220/0011670300003411]
   Bengamra S, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP, P311, DOI 10.5220/0010243703110320
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Brachmann A, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00102
   Bradski G, 2000, DR DOBBS J, V25, P120
   Bredow T, 2021, DEEP LEARNING COMPUT
   Brochu E., 2010, arXiv:1012.2599
   Buchana P, 2016, IEEE IMAGE PROC, P146, DOI 10.1109/ICIP.2016.7532336
   Cai H, ARXIV
   Cai HP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P74, DOI 10.1109/ICCVW.2015.19
   Carneiro G, 2012, LECT NOTES COMPUT SC, V7575, P143, DOI 10.1007/978-3-642-33765-9_11
   Castellan G., 2020, P487, DOI 10.1007/978-3-030-68796-0_35
   Castellano G, 2022, INT J COMPUT VISION, V130, P2590, DOI 10.1007/s11263-022-01664-y
   Castellano G, 2020, COMM COM INF SC, V1177, P105, DOI 10.1007/978-3-030-39905-4_11
   Castellano G, 2021, MULTIMED TOOLS APPL, V80, P6599, DOI 10.1007/s11042-020-09995-z
   Cetinic Eva, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12663), P502, DOI 10.1007/978-3-030-68796-0_36
   Cetinic Eva, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P19
   Cetinic E, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3475799
   Cetinic E, 2021, J IMAGING, V7, DOI 10.3390/jimaging7080123
   Cetinic E, 2019, IEEE ACCESS, V7, P73694, DOI 10.1109/ACCESS.2019.2921101
   Cetinic E, 2018, EXPERT SYST APPL, V114, P107, DOI 10.1016/j.eswa.2018.07.026
   Chen WJ, 2021, VISUAL COMPUT, V37, P805, DOI 10.1007/s00371-020-01831-7
   Chen XY, 2019, IEEE T IMAGE PROCESS, V28, P546, DOI 10.1109/TIP.2018.2869695
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Chu WT, 2019, ITE TRANS MEDIA TECH, V7, P60, DOI 10.3169/mta.7.60
   Crowley E., 2014, BRIT MACH VIS C BMVC
   Crowley Elliot J., 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P721, DOI 10.1007/978-3-319-46604-0_50
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Del Chiaro R, 2019, PATTERN RECOGN LETT, V128, P420, DOI 10.1016/j.patrec.2019.09.027
   Dominguez V., 2017, Proceedings of the 2nd workshop on deep learning for recommender systems p, P55, DOI DOI 10.1145/3125486.3125495DOI.ORG/10.1145/3125486.3125495
   Elgammal A, 2018, AAAI CONF ARTIF INTE, P2183
   Elgammal AM, 2015, ARXIV 1506 00711
   Falomir Z, 2018, EXPERT SYST APPL, V97, P83, DOI 10.1016/j.eswa.2017.11.056
   Fiorucci M, 2020, PATTERN RECOGN LETT, V133, P102, DOI 10.1016/j.patrec.2020.02.017
   Florea C, 2017, LECT NOTES COMPUT SC, V10269, P337, DOI 10.1007/978-3-319-59126-1_28
   Foka A., 2021, P EVA, P73
   Folego G, 2016, IEEE IMAGE PROC, P141, DOI 10.1109/ICIP.2016.7532335
   Frank Steven J., 2021, IEEE Spectrum, V58, P26, DOI 10.1109/MSPEC.2021.9531029
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gao X, 2020, IEEE T IMAGE PROCESS, V29, P8706, DOI 10.1109/TIP.2020.3018856
   Garcia N, 2019, LECT NOTES COMPUT SC, V11130, P676, DOI 10.1007/978-3-030-11012-3_52
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Geirhos Robert, 2019, INT C LEARNING REPRE
   Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112
   Ginosar S, 2015, LECT NOTES COMPUT SC, V8925, P101, DOI 10.1007/978-3-319-16178-5_7
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   github, 2023, YOLO V5
   Gonthier N., 2022, COMPUT VIS IMAGE UND, V214, P299
   Gonthier N, 2019, LECT NOTES COMPUT SC, V11130, P692, DOI 10.1007/978-3-030-11012-3_53
   Goodfellow I. J., 2014, ARXIV
   Gultepe E, 2018, J CULT HERIT, V31, P13, DOI 10.1016/j.culher.2017.11.008
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hayn-Leichsenring GU, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517715474
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hosainl MK, 2020, INT CONF COMPUT INFO, DOI 10.1109/ICCIT51783.2020.9392688
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   Hu X, 2018, TENSORFLOW IMPLEMENT
   Ibrahim BIE, 2022, J IMAGING, V8, DOI 10.3390/jimaging8020018
   Iliadis LA, 2022, TECHNOLOGIES, V10, DOI 10.3390/technologies10010002
   Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525
   Jeon HJ, 2020, I C INF COMM TECH CO, P1312, DOI 10.1109/ICTC49870.2020.9289321
   Johnson MK, 2008, PROC SPIE, V6810, DOI 10.1117/12.759726
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Junger A, 2021, DEEP LEARNING COMPUT
   Kadish D, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534264
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Keren D, 2002, INT C PATT RECOG, P474, DOI 10.1109/ICPR.2002.1048341
   Khalili A, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23020153
   Kumar KK, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6852
   Lang S, 2018, DIGIT SCHOLARSH HUM, V33, P845, DOI 10.1093/llc/fqy006
   Lecoutre A., 2017, ASIAN C MACHINE LEAR, P327
   Lin Y, 2020, INT C APPL INT SYST, P651, DOI [10.1007/978-3-030-51556-0_96, DOI 10.1007/978-3-030-51556-0_96]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104087
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu Y, 2022, NEUROCOMPUTING, V490, P163, DOI 10.1016/j.neucom.2022.01.068
   Ma DQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1174, DOI 10.1145/3123266.3123325
   Madhu P, 2019, SUMAC'19: PROCEEDINGS OF THE 1ST WORKSHOP ON STRUCTURING AND UNDERSTANDING OF MULTIMEDIA HERITAGE CONTENTS, P15, DOI 10.1145/3347317.3357242
   Maji B, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091328
   Mao H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1183, DOI 10.1145/3123266.3123405
   Marinescu MC, 2020, INT CONF DAT MIN WOR, P926, DOI 10.1109/ICDMW51313.2020.00133
   Mensink T, 2014, P INT C MULT RETR, P451, DOI DOI 10.1145/2578726.2578791
   Mermet A, 2020, P 2 WORKSH STRUCT UN, P23, DOI [10.1145/3423323.3423412, DOI 10.1145/3423323.3423412]
   Messina P, 2017, ARXIV
   Mohammad S., 2018, Proceedings of the 11th International Conference on Language Resources and Evaluation (LREC 2018)
   Moutafidou A, 2018, INT C TRANSD MULT MO, P141
   Mustageem, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122133
   Mustaqeem, 2022, SUSTAIN ENERGY TECHN, V52, DOI 10.1016/j.seta.2022.102275
   Mustaqeem, 2021, INT J INTELL SYST, V36, P5116, DOI 10.1002/int.22505
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Mustaqeem, 2021, CMC-COMPUT MATER CON, V67, P4039, DOI 10.32604/cmc.2021.015070
   Mzoughi O, 2018, LECT NOTES COMPUT SC, V11182, P333, DOI 10.1007/978-3-030-01449-0_28
   Nasir IM, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107805
   Pasqualino G, 2021, INT C PATT RECOG, P983, DOI 10.1109/ICPR48806.2021.9412661
   Pasqualino G, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104098
   Peleshko D, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON THE EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS (CADSM 2013), P284
   Polatkan G, 2009, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2009.5413338
   Ranjgar B, 2019, IEEE ACCESS, V7, P120857, DOI 10.1109/ACCESS.2019.2936896
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodrigues J.B., 2018, INT C APPL HUM FACT, P243
   Rombach R., 2022, ARXIV
   Sabatelli M, 2019, LECT NOTES COMPUT SC, V11130, P631, DOI 10.1007/978-3-030-11012-3_48
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Saleh B, 2015, ARXIV
   Sargentis GF, 2020, HERITAGE-BASEL, V3, P283, DOI 10.3390/heritage3020017
   Sari C, 2019, DIGIT SCHOLARSH HUM, V34, P156, DOI 10.1093/llc/fqz055
   Schlecht J, 2011, IEEE IMAGE PROC, P1285, DOI 10.1109/ICIP.2011.6115669
   Seguin Benoit, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P753, DOI 10.1007/978-3-319-46604-0_52
   Shen X, 2019, PROC CVPR IEEE, P9270, DOI 10.1109/CVPR.2019.00950
   Sheng SR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2478, DOI 10.1145/3343031.3350972
   Sindel Aline, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13801), P298, DOI 10.1007/978-3-031-25056-9_20
   Sirirattanapol C, 2017, IEEE INT SYM MULTIM, P495, DOI 10.1109/ISM.2017.98
   Smirnov S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON METROLOGY FOR ARCHAEOLOGY AND CULTURAL HERITAGE (METROARCHAEO 2018), P45, DOI 10.1109/MetroArchaeo43810.2018.9089828
   Song YC, 2022, COMPUT METH PROG BIO, V220, DOI 10.1016/j.cmpb.2022.106821
   Spehr M., 2009, COMPUTATIONAL AESTHE, P57
   Srinivasan R, 2013, P 21 ACM INT C MULTI, P581, DOI [10.1145/2502081.2502153, DOI 10.1145/2502081.2502153]
   Srinivasan R, 2015, IEEE SIGNAL PROC MAG, V32, P85, DOI 10.1109/MSP.2015.2410783
   Stork DG, 2006, IEEE MULTIMEDIA, V13, P12, DOI 10.1109/MMUL.2006.78
   Stork DG, 2011, PROC SPIE, V7869, DOI 10.1117/12.873190
   Stork DG, 2009, LECT NOTES COMPUT SC, V5702, P9, DOI 10.1007/978-3-642-03767-2_2
   Strezoski G, 2017, ARXIV
   Surawijaya S, 2020, 2020 55TH INTERNATIONAL UNIVERSITIES POWER ENGINEERING CONFERENCE (UPEC), DOI [10.1109/SIEDS49339.2020.9106656, 10.1109/upec49904.2020.9209885]
   Tan W., 2018, CNN MODELS CLASSIFYI
   Tan WR, 2017, IEEE IMAGE PROC, P3760, DOI 10.1109/ICIP.2017.8296985
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   Tian Y, 2020, ARXIV
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tyler CW, 2012, HUMAN VISION ELECT I, V8291, P407
   van Noord N, 2015, IEEE SIGNAL PROC MAG, V32, P46, DOI 10.1109/MSP.2015.2406955
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Volpe Y., 2014, International Journal of Computer Aided Engineering and Technology, V6, P88, DOI 10.1504/IJCAET.2014.058012
   Wechsler H, 2019, PATTERN RECOGN LETT, V126, P3, DOI 10.1016/j.patrec.2018.02.014
   Westlake Nicholas, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P825, DOI 10.1007/978-3-319-46604-0_57
   Wikicommons, 2004, US
   Winarno E, 2018, J PHYS C SER
   Winston JJ, 2022, MULTIMED TOOLS APPL, P1
   Wu Q, 2014, LECT NOTES COMPUT SC, V8695, P313, DOI 10.1007/978-3-319-10584-0_21
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yakar M, 2018, INT J ENG GEOSCI, V3, P50, DOI 10.26833/ijeg.378257
   Yang H, 2020, VISUAL COMPUT, V36, P559, DOI 10.1007/s00371-019-01641-6
   Yang H, 2019, KSII T INTERNET INF, V13, P2558, DOI 10.3837/tiis.2019.05.018
   Yaniv J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322984
   Yanulevskaya V, 2012, P 20 ACM INT C MULT, P349, DOI [10.1145/2393347.2393399, DOI 10.1145/2393347.2393399]
   Yi R, 2019, PROC CVPR IEEE, P10735, DOI 10.1109/CVPR.2019.01100
   Yoloface, 2019, US
   Young-Min K, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0222-3
   Zhang CJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1231, DOI 10.1145/3240508.3241386
   Zhang HW, 2018, IEEE T INF FOREN SEC, V13, P2409, DOI 10.1109/TIFS.2018.2800901
   Zhao L, 2020, COMPUT VIS IMAGE UND, V199, DOI 10.1016/j.cviu.2020.103024
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu YZ, 2022, MULTIMED TOOLS APPL, V81, P17779, DOI 10.1007/s11042-022-12163-0
   Zihan Yang, 2021, Journal of Physics: Conference Series, V1774, DOI 10.1088/1742-6596/1774/1/012043
   Zujovic J, 2009, IEEE INT WORKSH MULT, P501
NR 178
TC 3
Z9 3
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14637
EP 14670
DI 10.1007/s11042-023-15968-9
EA JUL 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001021388000003
DA 2024-07-18
ER

PT J
AU Attri, I
   Awasthi, LK
   Sharma, TP
AF Attri, Ishana
   Awasthi, Lalit Kumar
   Sharma, Teek Parval
TI Machine learning in agriculture: a review of crop management
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Machine learning; Agriculture; Stress detection; Plant disease
   detection; Pest and weed detection; Smart farms; Crop yield prediction
ID SUPPORT VECTOR MACHINES; WEED DETECTION; ARTIFICIAL-INTELLIGENCE;
   DISEASE DETECTION; NEURAL-NETWORKS; FOOD SECURITY; VISION; PLANTS;
   SMART; IMAGES
AB Machine learning has created new opportunities for data-intensive study in interdisciplinary domains as a result of the advancement of big data technologies and high-performance computers. Search engines, email spam filters, websites that offer personalized recommendations, banking software that alerts users to suspicious activity, and a plethora of smartphone apps that perform tasks like voice recognition, image recognition, and natural language processing are just a few examples of the online and offline services that have incorporated machine learning in recent years. One of the most crucial areas where machine learning applications still has to be investigated is agriculture, which directly affects people's well-being. In this article, a literature review on machine learning algorithms used in agriculture is presented. The proposed paper deal with various crop management applications which are categorised into five parts i.e., Weed and pest detection, Plant disease detection, Stress detection in plants, Smart farms or automation in farms and the last one is Crop yield estimation and prediction. The articles' filtering and categorization show how machine learning may improve agriculture. This article examines machine learning breakthroughs in agriculture. This paper's findings show that by using novel machine learning approaches, models may achieve improved accuracy and shorter inference time for real-world applications.
C1 [Attri, Ishana; Awasthi, Lalit Kumar; Sharma, Teek Parval] NIT, Comp Sci & Engn, Hamirpur 177005, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Attri, I (corresponding author), NIT, Comp Sci & Engn, Hamirpur 177005, HP, India.
EM ishana_phdcse@nith.ac.in; lalit@nith.ac.in; teek@nith.ac.in
RI Attri, Ishana/JOJ-5753-2023; Arjmandmanesh, Saba/AGA-7907-2022; Awasthi,
   Lalit Kumar/V-3485-2019
OI Attri, Ishana/0000-0001-8779-3231; Awasthi, Lalit
   Kumar/0000-0001-8396-9025
CR Abade A, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106125
   Alam M, 2020, 2020 7TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ICEEE 2020), P273, DOI [10.1109/ICEEE49618.2020.9102505, 10.1109/iceee49618.2020.9102505]
   Albuquerque CKG, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR AGRICULTURE AND FORESTRY (METROAGRIFOR), P236, DOI [10.1109/metroagrifor50201.2020.9277542, 10.1109/MetroAgriFor50201.2020.9277542]
   Alessandrini M, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106809
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Ang KLM, 2021, IEEE ACCESS, V9, P36699, DOI 10.1109/ACCESS.2021.3051196
   Appeltans S, 2021, COMPUT ELECTRON AGR, V190, DOI 10.1016/j.compag.2021.106453
   Barbedo JGA, 2019, COMPUT ELECTRON AGR, V162, P482, DOI 10.1016/j.compag.2019.04.035
   Asad Muhammad Hamza, 2020, Information Processing in Agriculture, V7, P535, DOI 10.1016/j.inpa.2019.12.002
   Atas M, 2012, COMPUT ELECTRON AGR, V87, P129, DOI 10.1016/j.compag.2012.06.001
   Bah MD, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111690
   Bakhshipour A, 2018, COMPUT ELECTRON AGR, V145, P153, DOI 10.1016/j.compag.2017.12.032
   Benos L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113758
   Bhange M, 2015, PROCEDIA COMPUT SCI, V58, P280, DOI 10.1016/j.procs.2015.08.022
   Bienertova-Vasku J, 2020, BIOESSAYS, V42, DOI 10.1002/bies.201900238
   Boissard P, 2008, COMPUT ELECTRON AGR, V62, P81, DOI 10.1016/j.compag.2007.11.009
   Brinkhoff J, 2020, REMOTE SENS-BASEL, V12
   Cattivelli L, 2008, FIELD CROP RES, V105, P1, DOI 10.1016/j.fcr.2007.07.004
   Chen JJ, 2021, SINGAP ECON REV, DOI 10.1142/S0217590821480015
   Chen MT, 2021, AGR WATER MANAGE, V250, DOI 10.1016/j.agwat.2021.106838
   Chen Y-R, MACHINE VISION TECHN
   Conrad AO, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/8954085
   Cravero A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050552
   Daniya T., 2019, Int. J. Adv. Sci. Technol, V28, P49
   de Castro AI, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020285
   Etienne A, 2019, INT SOC OPT PHOTONIC, V11008
   Evstatiev B. I., 2021, IOP Conference Series: Materials Science and Engineering, V1032, DOI 10.1088/1757-899X/1032/1/012053
   Ferreira AD, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104963
   Friedel CC, 2005, BIOINFORMATICS, V21, P1383, DOI 10.1093/bioinformatics/bti200
   Babu RG, 2022, J BIOSCIENCES, V47, DOI 10.1007/s12038-021-00241-8
   Garibaldi-marquez F, 2022, WEED CLASSIFICATION, P1
   Guo QH, 2005, ECOL MODEL, V182, P75, DOI 10.1016/j.ecolmodel.2004.07.012
   Harakannanavar S. S., 2022, Global Trans. Proc, V3, P305, DOI [10.1016/j.gltp.2022.03.016, DOI 10.1016/J.GLTP.2022.03.016]
   Helm JM, 2020, CURR REV MUSCULOSKE, V13, P69, DOI 10.1007/s12178-020-09600-8
   Islam N, 2021, AGRIC, V11
   Jansen MAK, 2017, PLANT STRESS PHYSIOLOGY, 2ND EDITION, pIX
   Javidan SM, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100081
   Jiang QY, 2021, INFRARED PHYS TECHN, V118, DOI 10.1016/j.infrared.2021.103898
   Jose A, 2021, ANN ROM SOC CELL BIO, V25, P2580
   Jung JH, 2021, CURR OPIN BIOTECH, V70, P15, DOI 10.1016/j.copbio.2020.09.003
   Karadag K, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2019.01.001
   Kaur N., 2020, MATER TODAY-PROC
   Khan MA, 2021, INTELL AUTOM SOFT CO, V30, P771, DOI 10.32604/iasc.2021.018039
   Kong WW, 2014, SPECTROCHIM ACTA A, V118, P498, DOI 10.1016/j.saa.2013.09.009
   Kounalakis T, 2019, COMPUT ELECTRON AGR, V165, DOI [10.1016/j.compag.2019.104973, 10.1016/j.compag.201]
   Kulkarni P, PLANT DIS DETECTION
   Kumar KK, 2022, AGRON J, V114, P2213, DOI 10.1002/agj2.21070
   Lampridi MG, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11185120
   Lan YB, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105234
   Langemeier M, 2021, PURDUE CROP COST RET
   Leonardo MM, 2018, SIBGRAPI, P41, DOI 10.1109/SIBGRAPI.2018.00012
   Li DL, 2010, COMPUT ELECTRON AGR, V74, P274, DOI 10.1016/j.compag.2010.09.002
   Li N, 2020, ANIMAL, V14, P617, DOI 10.1017/S1751731119002155
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Lindenthal M, 2005, PHYTOPATHOLOGY, V95, P233, DOI 10.1094/PHYTO-95-0233
   Liu Y, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106625
   Loey M., 2020, INT J SERV SCI MANAG, V11, P41
   Araus JL, 2014, TRENDS PLANT SCI, V19, P52, DOI 10.1016/j.tplants.2013.09.008
   Mayuri KP., 2018, INT J ADV RES COMPUT, V9, P975, DOI [10.26483/ijarcs.v9i2.5793, DOI 10.26483/IJARCS.V9I2.5793]
   Meng T, 2020, INFORM FUSION, V57, P115, DOI 10.1016/j.inffus.2019.12.001
   Meshram V., 2021, Artif Intell Life Sci, V1, P100010, DOI DOI 10.1016/J.AILSCI.2021.100010
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017
   Moshia ME, 2019, ACTA AGR SCAND B-S P, V69, P228, DOI 10.1080/09064710.2018.1536225
   Mourtzinis S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97380-7
   Myers SS, 2017, ANNU REV PUBL HEALTH, V38, P259, DOI 10.1146/annurev-publhealth-031816-044356
   Neelakantan P, 2021, MATER TODAY-PROC
   NILSSON HE, 1995, ANNU REV PHYTOPATHOL, V33, P489, DOI 10.1146/annurev.py.33.090195.002421
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Ning X, 2023, IEEE T COGN DEV SYST, V15, P774, DOI 10.1109/TCDS.2022.3182650
   Oppermann R., 2012, High Nature Value Farming in Europe: 35 European CountriesExperiences and Perspectives, DOI DOI 10.1659/MRD.MM126
   Ouhami M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132486
   Ozyurt B, 1998, COMPUT CHEM ENG, V22, P299, DOI 10.1016/S0098-1354(97)88453-0
   Partel V, 2019, COMPUT ELECTRON AGR, V157, P339, DOI 10.1016/j.compag.2018.12.048
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Peng HX, 2022, COMPUT ELECTRON AGR, V199, DOI 10.1016/j.compag.2022.107179
   Pérez AJ, 2000, COMPUT ELECTRON AGR, V25, P197, DOI 10.1016/S0168-1699(99)00068-X
   Prasad BR, 2020, J SCI IND RES INDIA, V79, P619
   Pritam Patil MC, 2020, INT RES J ENG TECHNO
   Pushpanathan K, 2021, ARTIF INTELL REV, V54, P305, DOI 10.1007/s10462-020-09847-0
   Raza SEA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123262
   Römer C, 2011, COMPUT ELECTRON AGR, V79, P180, DOI 10.1016/j.compag.2011.09.011
   Rosegrant MW, 2009, ANNU REV ENV RESOUR, V34, P205, DOI 10.1146/annurev.environ.030308.090351
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Saggi MK, 2019, COMPUT ELECTRON AGR, V156, P387, DOI 10.1016/j.compag.2018.11.031
   Saleem R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112411901
   SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Silva Diogo M., 2022, Procedia Computer Science, P125, DOI 10.1016/j.procs.2021.11.081
   Sobiyaa P, 2022, MATER TODAY-PROC
   Soltani N, 2016, WEED TECHNOL, V30, P979, DOI 10.1614/WT-D-16-00046.1
   Song XD, 2016, J ARID LAND, V8, P734, DOI 10.1007/s40333-016-0049-0
   Sonka S., 2016, Journal of Innovation Management, V4, P114, DOI DOI 10.24840/2183-0606_004.001_0008
   Sorensen C.A.G., 2019, Information and Communication Technologies in Modern Agricultural Development, V953, P1, DOI DOI 10.1007/978-3-030-12998-9_1
   Sowmya BJ, 2020, CHAPTER 7 UTILITY SY, P149
   Su WH, 2020, SMART CITIES-BASEL, V3, P767, DOI 10.3390/smartcities3030039
   Subeesh A, 2022, ARTIF INTELL AGR, V6, P47, DOI 10.1016/j.aiia.2022.01.002
   Sundmaeker H, 2016, RIVER PUBL SER COMM, V49, P129
   Sunil G, 2022, J AGR FOOD RES, V9, DOI 10.1016/j.jafr.2022.100325
   Tang JW, 2021, WATER-SUI, V13, DOI 10.3390/w13030298
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   van Klompenburg T, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105709
   Vázquez-Hernández MC, 2019, SCI HORTIC-AMSTERDAM, V250, P223, DOI 10.1016/j.scienta.2019.02.053
   Virnodkar SS, 2020, PRECIS AGRIC, V21, P1121, DOI 10.1007/s11119-020-09711-9
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Wang AC, 2020, IEEE ACCESS, V8, P81724, DOI 10.1109/ACCESS.2020.2991354
   Wang AC, 2019, COMPUT ELECTRON AGR, V158, P226, DOI 10.1016/j.compag.2019.02.005
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang DW, 2019, J SCI FOOD AGR, V99, P4524, DOI 10.1002/jsfa.9689
   Wen ZQ, 1999, EXPERT SYST APPL, V16, P307, DOI 10.1016/S0957-4174(98)00079-7
   Xu GL, 2011, PATTERN RECOGN LETT, V32, P1584, DOI 10.1016/j.patrec.2011.04.020
   Yashodha G, 2021, MATER TODAY-PROC, V37, P484, DOI 10.1016/j.matpr.2020.05.458
   Yuan Yuan, 2022, Information Processing in Agriculture, P48, DOI [10.1016/j.inpa.2021.01.003, 10.1007/s40789-020-00398-x]
   Zamani A, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/1598796
   Zecca F, 2019, INT J CIV ENG TECHNO, V10, P494
   Zhou J, 2019, COMPUT ELECTRON AGR, V162, P143, DOI 10.1016/j.compag.2019.04.014
   Zhou R, 2014, COMPUT ELECTRON AGR, V108, P58, DOI 10.1016/j.compag.2014.07.004
   Zou KL, 2021, INFORM PROCESS AGR, V8, P505, DOI 10.1016/j.inpa.2020.12.003
   Zubler AV, 2020, BIOSENSORS-BASEL, V10, DOI 10.3390/bios10120193
NR 119
TC 6
Z9 6
U1 23
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12875
EP 12915
DI 10.1007/s11042-023-16105-2
EA JUL 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200009
DA 2024-07-18
ER

PT J
AU Chen, Y
   Wan, WB
   Zhao, YM
   Huang, B
AF Chen, Yang
   Wan, Weibing
   Zhao, Yuming
   Huang, Bo
TI Generalization performance optimization of KBQA system for Chinese open
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE KBQA; Entity linking; Dual-channel; Attention mechanism; Generalization
   performance
AB Knowledge-Based Question Answering (KBQA) is a technique that utilizes the rich semantic information present in knowledge bases to comprehensively understand questions and obtain answers. The mainstream approaches consist of two methods: Semantic Parsing-Based (SP-based) and Information Retrieval-Based (IR-based). The former converts the question into a logical form that can be understood and executed by machines through semantic analysis, and then queries the knowledge base for answers. The latter first identifies the topic entity in the question and retrieves candidate answers, and then extracts features from both the question and candidate answers. Finally, a ranking model is used to model and predict the question and candidate answers. Compared to the impressive results achieved by English KBQA systems, Chinese KBQA systems face challenges due to the sparse semantic expression and limited features of the Chinese knowledge base, as well as the large number of similar entities that are difficult to differentiate. This makes it difficult for general models to properly understand the text's characteristics, resulting in a challenge to improve the accuracy of Entity Linking and to maximize the performance of the KBQA system. To address this, this paper proposes two steps to improve Entity Linking in the KBQA system: Candidate Generation (CG) and Entity Disambiguation (ED), with a focus on realizing Entity Disambiguation. In this paper, Entity Disambiguation is treated as a classification task, and a Dual-Channel Network Model based on Bi-LSTM and CNN is constructed. By combining different featuresextracted from Bi-LSTM and CNN, this paper also introduces an attention mechanism to fully explore the weak semantic relationship between the question answering system and candidate entity, effectively reducing the reliance of the question answering system on additional feature rules. Experimental results show that the Entity Linking model proposed in this paper can effectively improve the performance of the question and answer system, has strong generalization, weakens dependence on additional information, and ensures the quality of Q & A while reducing manual intervention. Our method has achieved the current best average F1 value in the Chinese open domain datasets NLPCC-2016KBQA and CCKS2019KBQA.
C1 [Chen, Yang; Wan, Weibing; Huang, Bo] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
   [Zhao, Yuming] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
C3 Shanghai University of Engineering Science; Shanghai Jiao Tong
   University
RP Wan, WB (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
EM wbwan@sues.edu.cn
RI Wan, Weibing/ACW-4829-2022; Huang, Bo/J-5101-2019
OI Huang, Bo/0000-0002-7954-3205
FU National Key R amp;D Program of China [2020AAA0109300]
FX AcknowledgementsThe authors gratefully acknowledge the financial
   supports by the National Key R &D Program of China (Grant No.
   2020AAA0109300).
CR Abujabal A, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1191, DOI 10.1145/3038912.3052583
   [Anonymous], 2011, P 2011 C EMP METH NA
   Berant J., 2013, P 2013 C EMPIRICAL M, P1533
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Bollacker K., 2008, P 2008 ACM SIGMOD IN, P1247, DOI 10.1145/1376616.1376746
   Bordes A., 2015, ARXIV
   BotongZhou CS, 2018, J PEKING U NATURAL S, P286
   ChangZhao HL, 2019, CHINESE J INFORM TEC
   conference.bj.bcebos, US
   Ding J., 2019, ARXIV
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hao Y., 2018, P 27 INT C COMP LING, P3272
   Hu SZ, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040453
   Lai YX, 2016, LECT NOTES COMPUT SC, V10102, P722, DOI 10.1007/978-3-319-50496-4_65
   Lan YS, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5046
   Li YD, 2019, INT CONF ASIAN LANG, P273, DOI [10.1109/ialp48816.2019.9037712, 10.1109/IALP48816.2019.9037712]
   Liu AT, 2019, LECT NOTES ARTIF INT, V11856, P81, DOI 10.1007/978-3-030-32381-3_7
   Luo KQ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2185
   Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w
   Reddy S., 2014, TACL, V2, P377, DOI [DOI 10.1162/TACL_A_00190, /10.1162/tacla00190, 10.1162/tacl_a_00190]
   Schopf T, 2022, ARXIV
   Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028
   Sowa J.F., 2014, Principles of Semantic Networks: Explorations in the representation of knowledge
   SreedharKumar S, 2019, INT J RECENT TECHNOL, V8
   Stern R, 2012, EACL 2012 WORKSHOP I
   Suchanek F.M., 2007, P 16 INT C WORLD WID, DOI [10.1145/1242572.1242667, DOI 10.1145/1242572.1242667]
   Usbeck R., 2018, CEUR Workshop Proceedings, V2241, P58
   Wang ZYL, 2020, IEEE INT C INTELL TR, DOI 10.1109/itsc45102.2020.9294342
   Wu T, 2021, COMPUT ENG, V47, P7
   Yih WT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1321
   Yin W., 2016, ARXIV
   Yu M, 2017, ARXIV
   Yu Y, 2018, COMM COM INF SC, V909, P286, DOI 10.1007/978-3-030-00063-9_27
   Zettlemoyer LS, 2012, ARXIV
   Zhang F, 2020, COMPUTER ENG APPL
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang LH, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101167
NR 37
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12445
EP 12466
DI 10.1007/s11042-023-16011-7
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200001
DA 2024-07-18
ER

PT J
AU Yue, GH
   Gao, J
   Duan, LY
   Du, JF
   Yan, WQ
   Wang, SG
   Wang, TF
AF Yue, Guanghui
   Gao, Jie
   Duan, Lvyin
   Du, Jingfeng
   Yan, Weiqing
   Wang, Shuigen
   Wang, Tianfu
TI Colorectal endoscopic image enhancement via unsupervised deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image; Endoscopic image enhancement; Unsupervised deep learning;
   Image quality
ID DYNAMIC HISTOGRAM EQUALIZATION; QUALITY ASSESSMENT; ILLUMINATION;
   STATISTICS; GAN
AB Currently, various deep learning methods have been developed to address the image enhancement tasks based on paired high-quality images as references. For the low-light endoscopic image enhancement task, it is difficult to obtain paired high-quality images and to extract features from dark areas. In addition, the enhanced images easily appear color distortions. In this study, we propose an unsupervised deep learning scheme based on the Cycle Generative Adversarial Network to enhance the endoscopic image. Because extracting features in the dark areas is important but challenging, we embedded an adaptive reverse attention module in generators to help the network focus on low-light areas and enhance these areas. We also introduce a color consistency constraint to maintain color constancy. To evaluate the performance of the proposed enhancement method, a blind evaluation methodology is proposed in view of no specific quality assessment metric specially designed on this field. Extensive subjective and objective experiment results demonstrate that the proposed method is competent for the colorectal endoscopic image enhancement task, and performs better than both conventional methods and popular deep learning-based methods on 200 real-captured colonoscopy images. In the objective experiment, the proposed method ranks first with a PIQE score of 11.1525 and an NIQE score of 11.1525, outperforming five competing methods. It also receives the best results from an average score of 1.455 over 200 test images of the subjective experiment.
C1 [Yue, Guanghui; Gao, Jie; Duan, Lvyin; Wang, Tianfu] Shenzhen Univ, Shenzhen Univ, Sch Biomed Engn, Med Sch, Shenzhen 518060, Peoples R China.
   [Du, Jingfeng] Shenzhen Univ, Dept Gastroenterol & Hepatol, Gen Hosp, Shenzhen 518000, Peoples R China.
   [Yan, Weiqing] Yantai Univ, Sch Comp & Control Engn, Yantai 261400, Peoples R China.
   [Wang, Shuigen] Yantai IRay Technol Co Ltd, Yantai 261400, Peoples R China.
C3 Shenzhen University; Shenzhen University; Yantai University
RP Yue, GH; Duan, LY (corresponding author), Shenzhen Univ, Shenzhen Univ, Sch Biomed Engn, Med Sch, Shenzhen 518060, Peoples R China.
EM yueguanghui@szu.edu.cn; duanlvyin@tju.edu.cn
FU Shenzhen Science and Technology Program [RCBS20200714114920379];
   Guangdong Basic and Applied Basic Research Foundation [2021A1515011348,
   2019A1515111205, 2019A1515110401]; National Natural Science Foundation
   of China [62001302, 62103286]; Natural Science Foundation of Shenzhen
   [JCYJ20190808145011259]; Tencent "Rhinoceros Birds"- Scientific Research
   Foundation for Young Teachers of Shenzhen University
FX AcknowledgementsWe thank the support of Shenzhen Science and Technology
   Program under Grant RCBS20200714114920379, Guangdong Basic and Applied
   Basic Research Foundation under Grant 2021A1515011348, Grant
   2019A1515111205, and Grant 2019A1515110401, National Natural Science
   Foundation of China under Grant 62001302 and Grant 62103286, Natural
   Science Foundation of Shenzhen under Grant JCYJ20190808145011259, and
   Tencent "Rhinoceros Birds"- Scientific Research Foundation for Young
   Teachers of Shenzhen University.
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Asif M, 2021, APPL INTELL, V51, P1959, DOI 10.1007/s10489-020-01923-w
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Wei WYJL, 2018, BRIT MACHINE VISION
   Chou YC, 2023, MULTIMED TOOLS APPL, V82, P16817, DOI 10.1007/s11042-022-13995-6
   Das A, 2021, MULTIMED TOOLS APPL, V80, P6235, DOI 10.1007/s11042-020-09951-x
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Gu SH, 2020, IEEE T PATTERN ANAL, V42, P2437, DOI 10.1109/TPAMI.2019.2961672
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   Häfner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lei HJ, 2022, IEEE J BIOMED HEALTH, V26, P90, DOI 10.1109/JBHI.2021.3085770
   Li CY, 2021, Arxiv, DOI [arXiv:2103.00860, DOI 10.48550/ARXIV.2103.00860, DOI 10.1109/TPAMI.2021.3063604]
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li Jiaqian, 2020, IEEE T MULTIMEDIA, P1
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liang Liao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P683, DOI 10.1007/978-3-030-58583-9_41
   Liao L, 2022, IEEE T IMAGE PROCESS, V31, P3525, DOI 10.1109/TIP.2022.3172208
   Liao L, 2021, PROC CVPR IEEE, P6535, DOI 10.1109/CVPR46437.2021.00647
   Liao L, 2021, IEEE J-STSP, V15, P310, DOI 10.1109/JSTSP.2020.3045627
   Lim S, 2020, IEEE T MULTIMEDIA PP, P1
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Luo XB, 2019, IEEE T MED IMAGING, V38, P2863, DOI 10.1109/TMI.2019.2916101
   Ma YH, 2021, IEEE T MED IMAGING, V40, P3955, DOI 10.1109/TMI.2021.3101937
   McLeod A.I., 2005, R package Kendall, V602, P1
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mukherjee R, 2016, SIGNAL PROCESS-IMAGE, V47, P426, DOI 10.1016/j.image.2016.08.001
   Okuhata Hiroyuki, 2013, Annu Int Conf IEEE Eng Med Biol Soc, V2013, P3407, DOI 10.1109/EMBC.2013.6610273
   Öztürk S, 2020, MULTIMED TOOLS APPL, V79, P28825, DOI 10.1007/s11042-020-09468-3
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu H., 2023, DISCOVQA TEMPORAL DI
   Xie H, 2020, NEURAL NETWORKS, V132, P477, DOI 10.1016/j.neunet.2020.09.005
   Xu JW, 2022, COMPUT METH PROG BIO, V214, DOI 10.1016/j.cmpb.2021.106576
   Yue G., 2020, ADAPTIVE CONTEXT EXP
   Yue GH, 2023, IEEE T MULTIMEDIA, V25, P6499, DOI 10.1109/TMM.2022.3209889
   Yue GH, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3264047
   Yue GH, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104370
   Yue GH, 2023, IEEE T MED IMAGING, V42, P119, DOI 10.1109/TMI.2022.3204646
   Yue GH, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103846
   Yue GH, 2022, IEEE J BIOMED HEALTH, V26, P4090, DOI 10.1109/JBHI.2022.3173948
   Yue GH, 2019, DIGIT SIGNAL PROCESS, V91, P21, DOI 10.1016/j.dsp.2018.12.007
   ZAR JH, 1972, J AM STAT ASSOC, V67, P578, DOI 10.2307/2284441
   Zhu A, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR INDUSTRIES (AI4I 2020), P1, DOI 10.1109/AI4I49448.2020.00007
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 56
TC 0
Z9 0
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 1
PY 2023
DI 10.1007/s11042-023-15761-8
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L0HT2
UT WOS:001020157200003
DA 2024-07-18
ER

PT J
AU Chakraverti, S
   Agarwal, P
   Pattanayak, HS
   Chauhan, SPS
   Chakraverti, AK
   Kumar, M
AF Chakraverti, Sugandha
   Agarwal, Pankaj
   Pattanayak, Himansu Sekhar
   Chauhan, Sanjay Pratap Singh
   Chakraverti, Ashish Kumar
   Kumar, Manoj
TI De-noising the image using DBST-LCM-CLAHE: A deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Histogram Equalization; DBST LCM CLAHE; Image
   preprocessing; Noise; Denoising
ID CONTRAST ENHANCEMENT; HISTOGRAM EQUALIZATION
AB Histogram Equalization (HE) is one of the most popular techniques for this purpose. Most histogram equalization techniques, including Contrast Limited Adaptive Histogram Equalization (CLAHE) and Local Contrast Modification CLAHE (LCM CLAHE), use a fixed block size technique for feature enhancement. Due to this, all these state of art techniques are used to give poor denoising performance after feature enhancement. In this paper, a deep learning based new approach, namely Dynamic Block Size Technique (DBST), is used to improve image denoising. In this approach, we use the Categorical Subjective Image Quality (CSIQ) image set, an image database generally used for preprocessing of images. The results obtained from experiments show better performance for different important parameters (used by state of art techniques). The work is novel in the preprocessing of images because in this work, we classify the image depending upon the image features for selecting appropriate block sizes dynamically during preprocessing. Proposed work outperforms in terms of PSNR, MSE, NRMSE, SSIM and SYNTROPY. The average respective values are 18.92, 863.86, 0.25, 0.81 and 19.35 and are better in comparison of CLAHE and LCM CLAHE.
C1 [Chakraverti, Sugandha] AKTU, Greater Noida Inst Technol, Dept Comp Sci & Engn, Lucknow, UP, India.
   [Agarwal, Pankaj] KR Mangalam Univ, Sch Engn & Technol, Dept CSE, Gurgaon 122017, Haryana, India.
   [Pattanayak, Himansu Sekhar] Jaypee Inst Informat Technol, Dept CSE&IT, Sect 62, Noida, India.
   [Chauhan, Sanjay Pratap Singh] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida 203201, UP, India.
   [Chakraverti, Ashish Kumar] Sharda Univ, Sharda Sch Engn & Technol, Dept Comp Sci & Engn, Greater Noida, UP, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Greater Noida
   Institute of Technology; Jaypee Institute of Information Technology
   (JIIT); Galgotias University; Sharda University; Middle East University
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM sugandha0708@gmaill.com; pankaj.agarwal7877@gmail.com;
   himansusekharpattanayak@gmail.com; spschauhan75@gmail.com;
   ashish.me08@gmail.com; wss.manojkumar@gmail.com
RI Kumar, Manoj/AFS-0700-2022; agarwal, Pankaj/AAN-7463-2021; Chakraverti,
   Ashish Kumar/A-9141-2016
OI Kumar, Manoj/0000-0001-9598-0280; agarwal, Pankaj/0000-0002-1027-2419;
   Chakraverti, Ashish Kumar/0000-0002-7336-1304
FU CAUL and its Member Institutions
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions No funding received to perform this work.
CR [Anonymous], 2018, MEDIUMCOM, V1
   Chen SD, 2012, DIGIT SIGNAL PROCESS, V22, P640, DOI 10.1016/j.dsp.2012.04.002
   Chen XQ, 2021, IEEE T INTELL TRANSP, V22, P3190, DOI 10.1109/TITS.2020.3003782
   Dhir V, 2016, INT J ADV COMPUT SCI
   Dhir V, 2017, INT J ADV RES COMPUT, V8
   Eltahawi Ahmed., 2021, INT J INTELL COMPUT, V20, P53
   Fang FM, 2021, IEEE T NEUR NET LEAR, V32, P3956, DOI 10.1109/TNNLS.2020.3016321
   Fari Muhammad Abubakar, 2012, INT J SCI RES, V1, P15
   Gao JB, 2012, PROC NAECON IEEE NAT, P103, DOI 10.1109/NAECON.2012.6531037
   Garg R., 2011, International Journal of Electronics and Comunication Technologies, V2, P107
   Ghose S, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P511, DOI [10.1109/confluence47617.2020.9057895, 10.1109/Confluence47617.2020.9057895]
   Golshan H, 2021, IEEE T FUZZY SYST, V29, P686, DOI 10.1109/TFUZZ.2019.2961336
   Ilesanmi AE, 2021, COMPLEX INTELL SYST, V7, P2179, DOI 10.1007/s40747-021-00428-4
   Jabeen A, 2016, IEEE SENS J, V16, P7534, DOI 10.1109/JSEN.2016.2600483
   Jung C, 2017, IEEE T CIRC SYST VID, V27, P1161, DOI 10.1109/TCSVT.2016.2527339
   Kaur A, 2017, APPL SOFT COMPUT, V51, P180, DOI 10.1016/j.asoc.2016.11.046
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li ZH, 2021, IEEE T RADIAT PLASMA, V5, P224, DOI [10.1109/TRPMS.2020.3007583, 10.1109/trpms.2020.3007583]
   Li Z, 2023, IEEE ACCESS, V11, P11923, DOI 10.1109/ACCESS.2023.3242050
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Liu NH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3152984
   Liu Y, 2020, IEEE COMPUT SOC CONF, P2140, DOI 10.1109/CVPRW50498.2020.00262
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   Min BS, 2013, 7 INT C INF SEC ASS, V21, P204
   Mishro PK, 2022, IEEE REV BIOMED ENG, V15, P184, DOI 10.1109/RBME.2021.3055556
   Mohan S., 2013, INT C ADV INF TECHN, V296 CCIS, P397, DOI DOI 10.1007/978-3-642-35864-7_60
   Mohan S, 2013, SHORT PAPER ACEEE IN, V3, P1
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Prabbhu, 2022, UNDERSTANDING CONVOL, P45
   Ren C, 2021, IEEE T CYBERNETICS, V51, P3535, DOI 10.1109/TCYB.2019.2933257
   Shah Nisarg., 2015, INT J APPL INNOV ENG, V4, P16
   Shalash WM, 2006, RADIO SCI C 2006 NRS, VC24, P1
   Shao YN, 2021, PATTERN RECOGN LETT, V145, P157, DOI 10.1016/j.patrec.2021.02.008
   Sonka M., 1993, Image Processing, Analysis and Machine Vision, DOI [DOI 10.1007/978-1-4899-3216-7, 10.1007/978-1-4899-3216-7]
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tsai YW, 2017, MULTIMED TOOLS APPL, V76, P1121, DOI 10.1007/s11042-015-3082-7
   Wang FL, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3144385
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Wei KX, 2021, IEEE T NEUR NET LEAR, V32, P363, DOI 10.1109/TNNLS.2020.2978756
   Xiong J, 2021, SHOCK VIB, P1
   Xu JY, 2022, IEEE SIGNAL PROC LET, V29, P1202, DOI 10.1109/LSP.2022.3175096
   Yao M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P309, DOI 10.1109/ICIVC.2017.7984567
   Ye HL, 2021, IEEE T CYBERNETICS, V51, P4450, DOI 10.1109/TCYB.2020.2978500
   Yu SW, 2019, GEOPHYSICS, V84, pV333, DOI 10.1190/GEO2018-0668.1
   Yu WJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P37, DOI 10.1145/3394171.3413912
   Zhang M, 2017, IET IMAGE PROC, V11
   Zhang WW, 2017, LECT NOTES COMPUT SC, V10082, P159, DOI 10.1007/978-3-319-53465-7_12
   Zheng YF, 2021, IEEE T DEPEND SECURE, V18, P1261, DOI 10.1109/TDSC.2019.2907081
   Zhu HY, 2021, IEEE T CYBERNETICS, V51, P829, DOI 10.1109/TCYB.2019.2955092
   Zuiderveld K, 2021, GRAPH GEMS, P474
NR 52
TC 3
Z9 3
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11017
EP 11042
DI 10.1007/s11042-023-16016-2
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800008
OA hybrid
DA 2024-07-18
ER

PT J
AU Pang, C
   Fan, JJ
   Liang, RY
   Zhao, L
   Cheng, JM
AF Pang, Cong
   Fan, Jingjie
   Liang, Ruiyu
   Zhao, Li
   Cheng, Jiaming
TI An improved TF-GSC for dual-microphone interference suppression in the
   specific direction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interference suppression; Speech enhancement; Generalized sidelobe
   canceller; Distributed microphone array
ID SPEECH SEPARATION; NOISE
AB The performance of the speech enhancement (SE) algorithm will decrease rapidly in the presence of interference, especially competing or interfering speech. In this article, an improved real-time implementation of the transfer function generalized sidelobe canceller(TF-GSC) method based on distributed dual-microphone is proposed for interference suppression in the specific direction. In our method, we first derive an improved TF-GSC method based on a primary microphone and a secondary microphone which is abbreviated as GSC-PS in the following. GSC-PS estimates the desired signal by the dual-microphone structure based on estimation of time delay of arrival and calculation of the transfer functions. After that, we propose a new adaptive interference canceller based on the multichannel speech presence probability (MC-SPP) and the output gate unit. The calculated MC-SPP is applied to the step size adjustment and cost function modification of the adaptive interference canceller, while the output gate is designed based on the normalized posterior signal-to-interference ratio difference, which is sensitive to the direction of signal sources. The simulation results show that the proposed GSC-PS algorithm outperforms the current mainstream single-channel and multi-channel SE algorithms in suppressing interference and causes less damage to the quality of the target speech. In addition, experimental results confirm the usability of the proposed algorithm in real world acoustic environment with multiple sources of noises.
C1 [Pang, Cong; Fan, Jingjie; Liang, Ruiyu; Zhao, Li; Cheng, Jiaming] Southeast Univ, Sch Informat Sci & Engn, Southeast Univ Rd, Nanjing 211189, Jiangsu, Peoples R China.
   [Liang, Ruiyu] Nanjing Inst Technol, Sch Informat & Commun Engn, Hongjing Ave, Nanjing 211167, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing Institute of Technology
RP Pang, C (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Southeast Univ Rd, Nanjing 211189, Jiangsu, Peoples R China.
EM pangcong@seu.edu.cn; 220210848@seu.edu.cn; liangry@njit.edu.cn;
   zhaoli@seu.edu.cn; 230198469@seu.edu.com
RI guo, ppdop/KAL-9865-2024; jingjie, fan/JZS-8902-2024; Liu,
   Yiwei/JUF-2477-2023; Li, YiXue/JRW-6306-2023; Wang, Luyao/JLL-2001-2023;
   pang, congpang/JDN-4887-2023; chen, wang/KGK-5932-2024; Liu,
   Zhihao/JUF-7651-2023
OI pang, congpang/0000-0001-5351-5014; Fan, JingJie/0009-0008-1714-5405
FU National Key Research and Development Program of China [2020YFC2004003,
   2020YFC2004002]; National Natural Science Foundation of China
   [62001215]; Key Research and Development Program of Jiangsu Province
   [BE2022059-3]
FX AcknowledgementsThe work was supported in part by the National Key
   Research and Development Program of China under Grant Nos.
   2020YFC2004003 and 2020YFC2004002, the National Natural Science
   Foundation of China under Grant No. 62001215, and the Key Research and
   Development Program of Jiangsu Province under Grant BE2022059-3.
CR Ali R., 2021, EURASIP J AUDIO SPEE, V2021, P1
   Ali R, 2017, P EUR SIGN PROC C EU
   Ali R, 2019, IEEE-ACM T AUDIO SPE, V27, P1349, DOI 10.1109/TASLP.2019.2918400
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   ALLEN JB, 1977, J ACOUST SOC AM, V62, P912, DOI 10.1121/1.381621
   Barnov A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING (ICSEE)
   Choi JH, 2014, IEEE-ACM T AUDIO SPE, V22, P1069, DOI 10.1109/TASLP.2014.2313917
   Corey RM, 2021, IEEE WORK APPL SIG, P1, DOI 10.1109/WASPAA52581.2021.9632703
   CROCHIERE RE, 1980, IEEE T ACOUST SPEECH, V28, P99, DOI 10.1109/TASSP.1980.1163353
   Defossez A., 2020, arXiv
   Diaz A, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2011.01965
   Fejgin D, 2021, EUR SIGNAL PR CONF, P241, DOI 10.23919/EUSIPCO54536.2021.9616327
   Gannot S, 2004, IEEE T SPEECH AUDI P, V12, P561, DOI 10.1109/TSA.2004.834599
   Gannot S, 2001, IEEE T SIGNAL PROCES, V49, P1614, DOI 10.1109/78.934132
   GRIFFITHS LJ, 1982, IEEE T ANTENN PROPAG, V30, P27, DOI 10.1109/TAP.1982.1142739
   Guo HQ, 2022, I C DEPEND SYS NETWO, P355, DOI 10.1109/DSN53405.2022.00044
   Hendriks RC, 2012, IEEE T AUDIO SPEECH, V20, P223, DOI 10.1109/TASL.2011.2159711
   Higuchi T, 2017, IEEE-ACM T AUDIO SPE, V25, P780, DOI 10.1109/TASLP.2017.2665341
   Jeub M, 2012, INT CONF ACOUST SPEE, P1693, DOI 10.1109/ICASSP.2012.6288223
   KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830
   Kolbæk M, 2017, IEEE-ACM T AUDIO SPE, V25, P1901, DOI 10.1109/TASLP.2017.2726762
   Kowalk U, 2022, INT WORKSH ACOUSTIC, DOI 10.1109/IWAENC53105.2022.9914754
   Liu X, 2022, ARXIV
   Michelsanti D, 2021, IEEE-ACM T AUDIO SPE, V29, P1368, DOI 10.1109/TASLP.2021.3066303
   Middelberg W, 2021, SPEECH COMMUN, P1
   Mimura M, 2017, INTERSPEECH, P2451, DOI 10.21437/Interspeech.2017-642
   Potamitis I, 2004, IEEE SIGNAL PROC LET, V11, P956, DOI 10.1109/LSP.2004.838200
   Rahmani M, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P225
   Saric Z, 2019, MULTIMED TOOLS APPL, V78, P15235, DOI 10.1007/s11042-018-6895-3
   Schwartz O, 2015, IEEE-ACM T AUDIO SPE, V23, P240, DOI 10.1109/TASLP.2014.2372335
   Souden M, 2011, IEEE T AUDIO SPEECH, V19, P2159, DOI 10.1109/TASL.2011.2118205
   Souden M, 2010, IEEE T AUDIO SPEECH, V18, P1072, DOI 10.1109/TASL.2009.2035150
   Tolooshams B, 2020, INT CONF ACOUST SPEE, P836, DOI [10.1109/icassp40776.2020.9053989, 10.1109/ICASSP40776.2020.9053989]
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Veaux C, 2013, INT CONF SPEECH DATA
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Yee D, 2018, IEEE-ACM T AUDIO SPE, V26, P5, DOI 10.1109/TASLP.2017.2727684
   Yee D, 2016, INT CONF ACOUST SPEE, P246, DOI 10.1109/ICASSP.2016.7471674
NR 38
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11769
EP 11783
DI 10.1007/s11042-023-15817-9
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Zhao, MC
AF Wang, Xingyuan
   Zhao, Maochang
TI A new spatiotemporal chaos model and its application in bit-level image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; DCPML; Image encryption; Bit-level; Security
ID SEMI-TENSOR PRODUCT; ALGORITHM; MATRIX; SYSTEMS
AB With the development of network technology, multimedia security has attracted extensive attention. Although chaotic system is widely used in this field because of its own characteristics, designing a more secure and efficient chaotic system and encryption algorithm has great application potential. In this paper, a new spatiotemporal chaos model, dynamic coupled perturbation map lattice (DCPML), is proposed. The variable function is introduced to replace the coupling input variable of spatiotemporal chaotic system, and the output of two-dimensional Logistic map is used as dynamic coupling coefficient and disturbance term to improve the pseudo randomness and chaos of the system. Through a series of analysis, it is proved that the model has excellent chaotic characteristics. The system is applied to chaotic encryption, and a new bit-level image encryption algorithm is designed. The algorithm breaks the correlation between pixels through bit-level confusion and diffusion operation. A large number of experiments and security analysis show that the algorithm can resist common attacks and has high security and robustness.
C1 [Wang, Xingyuan; Zhao, Maochang] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Dalian Maritime University; Guangxi Normal University
RP Wang, XY; Zhao, MC (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM xywang@dlmu.edu.cn; 17853117953@163.com
OI Zhao, Maochang/0000-0001-5513-6288
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key Ramp;D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City 20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining amp;
   Security [MIMS20-M-02]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R & D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City 20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Adeli H, 2007, IEEE T BIO-MED ENG, V54, P205, DOI 10.1109/TBME.2006.886855
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Babiceanu RF, 2016, COMPUT IND, V81, P128, DOI 10.1016/j.compind.2016.02.004
   Ding Y, 2023, VISUAL COMPUT, V39, P1517, DOI 10.1007/s00371-022-02426-0
   Dong WL, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111539
   Ghosh Gopal, 2021, Intelligent Computing and Innovation on Data Science: Proceedings of ICTIDS 2021. Lecture Notes in Networks and Systems (248), P465, DOI 10.1007/978-981-16-3153-5_49
   Ghosh Gopal, 2020, IOP Conference Series: Materials Science and Engineering, V993, DOI 10.1088/1757-899X/993/1/012062
   HEIDARIBATENI G, 1994, IEEE T COMMUN, V42, P1524, DOI 10.1109/TCOMM.1994.582834
   Hosny KM, 2023, VISUAL COMPUT, V39, P1027, DOI 10.1007/s00371-021-02382-1
   Hu HP, 2008, CHAOS SOLITON FRACT, V38, P439, DOI 10.1016/j.chaos.2006.11.027
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   Khellat F, 2011, CHAOS SOLITON FRACT, V44, P934, DOI 10.1016/j.chaos.2011.07.015
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Liao TL, 2000, CHAOS SOLITON FRACT, V11, P1387, DOI 10.1016/S0960-0779(99)00051-X
   Liu LF, 2015, PHYS SCRIPTA, V90, DOI 10.1088/0031-8949/90/8/085205
   Liu XL, 2022, MULTIMED TOOLS APPL, V81, P21779, DOI 10.1007/s11042-022-12472-4
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Ma B, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107544
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Mansouri A, 2021, MULTIMED TOOLS APPL, V80, P21955, DOI 10.1007/s11042-021-10757-8
   Meherzi S., 2006, P NOLT, P147
   Riyahi M, 2021, NEURAL COMPUT APPL, V33, P14311, DOI 10.1007/s00521-021-06077-5
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shen CW, 2014, IEEE T CIRCUITS-I, V61, P2380, DOI 10.1109/TCSI.2014.2304655
   Shevchenko II, 2014, PHYS LETT A, V378, P34, DOI 10.1016/j.physleta.2013.10.035
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Wang J, 2020, MULTIMED TOOLS APPL, V79, P9363, DOI 10.1007/s11042-019-7704-3
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang XY, 2023, VISUAL COMPUT, V39, P43, DOI 10.1007/s00371-021-02311-2
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107316
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2018, IEEE ACCESS, V6, P39705, DOI 10.1109/ACCESS.2018.2855726
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xian YS, 2022, INT J COAL PREP UTIL, V42, P3249, DOI 10.1080/19392699.2021.1949712
   Xiong L, 2022, NONLINEAR DYNAM, V107, P2911, DOI 10.1007/s11071-021-07131-6
   Xu LD, 2014, IEEE T IND INFORM, V10, P2233, DOI 10.1109/TII.2014.2300753
   Ye XL, 2020, NONLINEAR DYNAM, V99, P1489, DOI 10.1007/s11071-019-05370-2
   Yildirim M, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111631
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang YQ, 2014, PHYSICA A, V402, P104, DOI 10.1016/j.physa.2014.01.051
   Zhang YQ, 2013, NONLINEAR ANAL-MODEL, V18, P526, DOI 10.15388/NA.18.4.13977
NR 46
TC 1
Z9 1
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10481
EP 10502
DI 10.1007/s11042-023-16031-3
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200003
DA 2024-07-18
ER

PT J
AU Singh, UP
   Singh, KP
   Thakur, M
AF Singh, Upendra Pratap
   Singh, Krishna Pratap
   Thakur, Manoj
TI A nuclear norm-induced robust and lightweight relation network for
   few-shots classification of hyperspectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meta-learning; Episodes; Hyperspectral; Relation network; Relative
   reconstruction loss; Nuclear norm; Rank minimization
ID SPECTRAL-SPATIAL CLASSIFICATION; PROTOTYPICAL NETWORK
AB Few-shots learning is a popular transfer learning paradigm and leverages an additional source of side information to compensate for the limited labelled training exemplars in application domains like healthcare, military and space. Most few-shots learners do not capture useful data manifolds and have numerous trainable parameters. This large parameter space makes the inference computationally expensive and energy-draining. Consequently, these models are not robust and cannot be deployed on devices with limited computation (energy) faculties. This work proposes NucNormFSL, a novel nuclear norm-induced lightweight relation network, for the few-shots classification of hyperspectral images. The embedding and relation modules in the proposed network are trained end-to-end by minimizing a dictionary learning-based loss function with only a few trainable parameters. Additionally, the embedding module loss function is regularized using a nuclear norm to give low-ranked solutions that are robust to environmental noise; lastly, a relative reconstruction loss metric is introduced to quantify the embedding's robustness to noise. Experiments are conducted on four benchmark hyperspectral datasets, namely, Indian Pines, Pavia Center, Pavia University and Salinas dataset; the relative reconstruction loss values computed confirm the robustness of the embeddings and hence the proposed network to environmental noise. Additionally, the proposed network's performance is compared with the baseline (without a nuclear norm term in its embedding loss function) model. The proposed approach beats the baseline for most few-shots settings and datasets and remains competitive with the state-of-the-art despite being severely lightweight. In this way, the proposed network is futuristic, lightweight and immune to noise; consequently, it can be deployed in noisy environments on devices with limited computation facilities.
C1 [Singh, Upendra Pratap] Siksha OAnusandhan Univ, Inst Tech Educ & Res, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
   [Singh, Krishna Pratap] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, Uttar Pradesh, India.
   [Thakur, Manoj] Indian Inst Technol Mandi, Sch Basic Sci, Mandi, Himachal Prades, India.
C3 Siksha 'O' Anusandhan University; Indian Institute of Information
   Technology Allahabad; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Mandi
RP Singh, UP (corresponding author), Siksha OAnusandhan Univ, Inst Tech Educ & Res, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
EM upendrapratapsingh@soa.ac.in; kpsingh@iiita.ac.in; manoj@iitmandi.ac.in
OI Pratap Singh, Upendra/0000-0002-6438-8222
CR Alajaji D, 2020, 2020 MEDITERRANEAN AND MIDDLE-EAST GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (M2GARSS), P81, DOI [10.1109/m2garss47143.2020.9105154, 10.1109/M2GARSS47143.2020.9105154]
   Alloghani M., 2020, Supervised and unsupervised learning for data science, P3, DOI [DOI 10.1007/978-3-030-22475-2_1, 10.1007/978-3-030-22475-2_1, DOI 10.1007/978-3-030-22475-21]
   Alomari A, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101276
   Bai J, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3119344
   Bau TC, 2010, IEEE T GEOSCI REMOTE, V48, P3457, DOI 10.1109/TGRS.2010.2046494
   Bhangale KB, 2021, INT J SPEECH TECHNOL, V24, P367, DOI 10.1007/s10772-021-09808-0
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3099033
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Cremer CZ, 2021, PROG ARTIF INTELL, V10, P449, DOI 10.1007/s13748-021-00239-1
   Deng B, 2020, IEEE T GEOSCI REMOTE, V58, P1422, DOI 10.1109/TGRS.2019.2946318
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Falco N, 2014, INT GEOSCI REMOTE SE, P3470, DOI 10.1109/IGARSS.2014.6947229
   Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730
   Gao KL, 2021, INT J REMOTE SENS, V42, P3090, DOI 10.1080/01431161.2020.1864060
   Gao KL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060923
   Geng CX, 2021, IEEE T PATTERN ANAL, V43, P3614, DOI 10.1109/TPAMI.2020.2981604
   Gong ZQ, 2019, IEEE T GEOSCI REMOTE, V57, P3599, DOI 10.1109/TGRS.2018.2886022
   Harikiran J, 2022, J SPECT IMAG, V11
   He L, 2016, INT GEOSCI REMOTE SE, P2746, DOI 10.1109/IGARSS.2016.7729709
   Huang WD, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14010111
   Iwata T, 2022, MACH LEARN, V111, P1239, DOI 10.1007/s10994-021-06118-z
   Jia S, 2021, NEUROCOMPUTING, V448, P179, DOI 10.1016/j.neucom.2021.03.035
   Jia S, 2017, IEEE T GEOSCI REMOTE, V55, P2399, DOI 10.1109/TGRS.2016.2642951
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   Le N, 2022, ARTIF INTELL REV, V55, P2733, DOI 10.1007/s10462-021-10061-9
   Li XQ, 2021, INT J CONTROL AUTOM, V19, P3285, DOI 10.1007/s12555-020-0289-9
   Li ZK, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3057066
   Liao WZ, 2010, IEEE IMAGE PROC, P1317, DOI 10.1109/ICIP.2010.5651670
   Licciardi G, 2012, IEEE GEOSCI REMOTE S, V9, P447, DOI 10.1109/LGRS.2011.2172185
   Liu B, 2019, IEEE T GEOSCIENCE RE, V57
   [刘冰 Liu Bing], 2020, [测绘学报, Acta Geodetica et Cartographica Sinica], V49, P1331
   Liu Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111752
   Lixin Hu, 2020, Journal of Physics: Conference Series, V1549, DOI 10.1088/1742-6596/1549/5/052011
   Ma CH, 2021, REMOTE SENS LETT, V12, P531, DOI 10.1080/2150704X.2021.1903609
   Mankolli E, 2020, INT C ICT INNOVATION, P71
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mughees A, 2019, TSINGHUA SCI TECHNOL, V24, P183, DOI 10.26599/TST.2018.9010043
   Pal D, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3085522
   Pandey SK, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P197
   Patel H, 2022, MULTIMED TOOLS APPL, V81, P695, DOI 10.1007/s11042-021-11422-w
   Quesada-Barriuso P, 2014, IEEE J-STARS, V7, P1177, DOI 10.1109/JSTARS.2014.2308425
   Rao MB, 2019, IEEE J-STARS, V12, P5086, DOI 10.1109/JSTARS.2019.2957047
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Ren L, 2022, NEURAL COMPUT APPL, V34, P7393, DOI 10.1007/s00521-021-06840-8
   Ren YM, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P344, DOI 10.1109/IWECA.2014.6845627
   Sagar R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010097
   Sanghvi K, 2020, SURVEY IMAGE CLASSIF
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P377, DOI 10.1007/s42979-021-00765-8
   Singh UP, 2022, NEURAL COMPUT APPL, V34, P2353, DOI 10.1007/s00521-021-06461-1
   Tang HJ, 2020, IEEE GEOSCI REMOTE S, V17, P167, DOI 10.1109/LGRS.2019.2916083
   Tong XY, 2020, IEEE IMAGE PROC, P1686, DOI 10.1109/ICIP40778.2020.9190752
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Vangara RVB, 2020, INT J ANAL EXP MODAL, P1390
   Wang G., 2021, 2021 IEEE INT C EL T, P673, DOI [10.1109/ICETCI53161.2021.9563257, DOI 10.1109/ICETCI53161.2021.9563257]
   Wang S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3100496
   Wang YM, 2022, IEEE GEOSCI REMOTE S, V19, DOI [10.1109/LGRS.2022.3214633, 10.1109/LGRS.2020.3047635]
   Yanfang Hu, 2022, 2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE), P601, DOI 10.1109/ICCECE54139.2022.9712772
   Yang, 2018, ARXIV
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zhang CY, 2020, IEEE J-STARS, V13, P4748, DOI 10.1109/JSTARS.2020.3017544
   Zhang CY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12040647
   Zhang P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010108
   Zhang YX, 2022, INT CONF ACOUST SPEE, P3573, DOI 10.1109/ICASSP43922.2022.9747622
   Zhao JL, 2021, INT J APPL EARTH OBS, V102, DOI 10.1016/j.jag.2021.102459
   Zheng C, 2014, SPIE ASIA PAC REMOTE
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zohuri B., 2020, Mod. Approaches Mater. Sci., V2, P241, DOI [DOI 10.32474/MAMS.2020.02.000138, 10.32474/MAMS.2020.02.000138, 10.32474/mams.2020.02.000138]
NR 75
TC 0
Z9 0
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9279
EP 9306
DI 10.1007/s11042-023-15500-z
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012974800002
DA 2024-07-18
ER

PT J
AU Prashanth, A
   Jayalakshmi, SL
   Vedhapriyavadhana, R
AF Prashanth, Arjun
   Jayalakshmi, S. L.
   Vedhapriyavadhana, R.
TI A review of deep learning techniques in audio event recognition (AER)
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Audio event recognition; Deep learning techniques; Features;
   Classifiers; Datasets; Convolutional neural network (CNN); Mel frequency
   cepstral coefficients (MFCCs)
ID CLASSIFICATION
AB In our day-to-day life, observation of human and social actions are highly important for public protection and security. Additionally, identifying suspicious activity is also essential in critical environments, such as industry, smart homes, nursing homes, and old age homes. In most of the audio-based applications, the Audio Event Recognition (AER) task plays a vital role to recognize audio events. Even though many approaches focus on the effective implementation of audio-based applications, still there exist major research problems such as overlapping events, the presence of background noise, and the lack of benchmark data sets. The main objective of this survey is to identify effective feature extraction methods, robust classifiers, and benchmark datasets. To achieve this, we have presented a detailed survey on features, deep learning classifiers, and data sets used in the AER applications. Also, we summarised the various methods involved in AER applications such as audio spoofing, audio surveillance, and audio fingerprinting. The future direction includes setting up a benchmark dataset, identifying the semantic features, and exploring the transfer learning-based classifiers.
C1 [Prashanth, Arjun; Vedhapriyavadhana, R.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
   [Jayalakshmi, S. L.] Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Main Campus, Pondicherry, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Pondicherry
   University
RP Jayalakshmi, SL (corresponding author), Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Main Campus, Pondicherry, India.
EM arjun.prashanth2020@vitstudent.ac.in;
   sathishjayalakshmi02@pondiuni.ac.in; vedhapriyavadhana.r@vit.ac.in
CR Abbasi A, 2022, IEEE ACCESS, V10, P38885, DOI 10.1109/ACCESS.2022.3166602
   *ACH MAN TRIP AND, 2023, IEEEACM T AUDIO SPEE, V31, P1100, DOI DOI 10.1109/TASLP.2023.3244507
   Alim S. A., 2018, IntechOpen
   Altalbe A, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09827-x
   Alzantot M, 2019, ARXIV
   [Anonymous], 2019, ABS190504348 CORR
   [Anonymous], 2017, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2017.7966291
   Bandara M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042032
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Chandrakala S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3322240
   Colangelo F., 2017, 2017 14 IEEE INT C A, P1, DOI [10.1109/AVSS.2017.8078496, DOI 10.1109/AVSS.2017.8078496]
   Drossos K, 2017, IEEE WORK APPL SIG, P374, DOI 10.1109/WASPAA.2017.8170058
   Fang Y, 2023, J HEALTHCARE ENG, V2023
   Gao L, 2022, MULTIMED TOOLS APPL, V81, P5089, DOI 10.1007/s11042-021-11610-8
   Greco A, 2020, IEEE T INF FOREN SEC, V15, P3610, DOI 10.1109/TIFS.2020.2994740
   Greco A, 2019, IEEE SYS MAN CYBERN, P546, DOI 10.1109/SMC.2019.8914435
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Inik O, 2023, APPL ACOUST, V202, DOI 10.1016/j.apacoust.2022.109168
   Jiang Z, 2023, ARXIV
   Kuçukbay SE, 2022, MULTIMED TOOLS APPL, V81, P30911, DOI 10.1007/s11042-022-12873-5
   Lipton Z. C., 2015, ARXIV
   Mnasri Z, 2022, MULTIMED TOOLS APPL, V81, P5537, DOI 10.1007/s11042-021-11817-9
   Mnasri Z, 2020, IEEE MEDITERR ELECT, P99, DOI [10.1109/melecon48756.2020.9140594, 10.1109/MELECON48756.2020.9140594]
   Mohaimenuzzaman M, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109025
   Poorjam AH, 2018, WHY WE TAKE ONLY 12, P05
   Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700
   Qamhan MA, 2021, IEEE ACCESS, V9, P62719, DOI 10.1109/ACCESS.2021.3073786
   Ray R, 2021, 2021 12 INT C COMP C, P1
   Renaud J, 2023, EXPERT SYST APPL, V218, DOI 10.1016/j.eswa.2023.119568
   Shaer I, 2022, ARXIV
   Shi QY, 2022, APPL ACOUST, V190, DOI 10.1016/j.apacoust.2022.108638
   Shim HJ, 2018, CONF TECHNOL APPL, P172, DOI 10.1109/TAAI.2018.00046
   Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
   Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
   Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
   Su C., 2017, P 31 PAC AS C LANG I, P140
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   Turab M, 2022, ARXIV
   Venkatesh S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073293
   Zhao YJ, 2019, IEEE CIRC SYST MAG, V19, P19, DOI 10.1109/MCAS.2019.2945210
NR 40
TC 1
Z9 1
U1 10
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8129
EP 8143
DI 10.1007/s11042-023-15891-z
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000001
DA 2024-07-18
ER

PT J
AU Zefreh, EZ
   Abdali, M
AF Zefreh, Ebrahim Zarei
   Abdali, Masoumeh
TI LSIE: a fast and secure Latin square-based image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Latin square; Image encryption; SHA256; Chaotic system
ID CHAOTIC MAP; ALGORITHM; PERMUTATION; EFFICIENT; DESIGN
AB The current paper proposes LSIE, a fast and secure Latin square-based image encryption scheme using SHA256 hash function and chaotic systems. LSIE uses a 3-tier architecture consisting of diffusion-confusion-diffusion based on Latin squares to design an efficient cryptographic algorithm. Firstly, the initial values and parameters of the 3D exponent chaotic map (3D-ECM) is obtained from the SHA256 hash value of the external secret key and the plain image. Next, two orthogonal Latin squares are constructed using chaotic sequences generated by the 3D-ECM. In the first diffusion phase, one of the Latin squares is considered as a key image to Exclusive-OR (XOR) with the plain image. In the confusion phase, a 2D permutation based on the orthogonal Latin squares is presented to permute pixel positions of the diffused image. In the second diffusion phase, another Latin square is considered as a key image to XOR with the permuted image. The analysis and simulation results indicate that the proposed LSIE could efficiently resist common security attacks, as also that it is a fast method for real-time applications. The MATLAB source code of the proposed LSIE is available at the URL: .
C1 [Zefreh, Ebrahim Zarei] Univ Isfahan, Dept Comp Sci, Khansar Campus, Esfahan, Iran.
   [Abdali, Masoumeh] Univ Isfahan, Dept Math, Khansar Campus, Esfahan, Iran.
C3 University of Isfahan; University of Isfahan
RP Zefreh, EZ (corresponding author), Univ Isfahan, Dept Comp Sci, Khansar Campus, Esfahan, Iran.
EM e.zarei@khc.ui.ac.ir
RI ZareiZefreh, Ebrahim/KVB-6115-2024
OI Zarei Zefreh, Ebrahim/0000-0002-8318-7485
CR Abel RJR., 1996, CRC HDB COMB, V2, P160
   Ahmad M, 2015, ADV INTELL SYST, V327, P481, DOI 10.1007/978-3-319-11933-5_53
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Boyadzhiyska S, 2020, DES CODES CRYPT, P1
   Chai X, 2021, NEURAL COMPUT APPL, P1
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Dobbertin H., 1996, Fast Software Encryption. Third International Workshop Proceedings, P71
   Evans AB, 2018, DEV MATH, V57, DOI 10.1007/978-3-319-94430-2
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Ionin YJ, 2006, COMBINATORICS SYMMET
   Li TY, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013008
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Lin M, 2016, CHIN CONT DECIS CONF, P2787, DOI 10.1109/CCDC.2016.7531456
   Liu HJ, 2021, SOFT COMPUT, V25, P11077, DOI 10.1007/s00500-021-05849-4
   Machkour M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0068-1
   McKinley KS, 1996, ACM T PROGR LANG SYS, V18, P424, DOI 10.1145/233561.233564
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Pal SK, 2010, J DISCRET MATH SCI C, V13, P233, DOI 10.1080/09720529.2010.10698290
   Panduranga HT, 2014, EUR PHYS J-SPEC TOP, V223, P1663, DOI 10.1140/epjst/e2014-02119-9
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Schmidt NO, 2016, LATIN SQUARES THEIR
   Stinson D., 2007, Combinatorial Designs: Constructions and Analysis, DOI DOI 10.1007/B97564
   Vanpoucke J, 2012, THESIS FS GHENT U
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2016, INFORM SCIENCES, V327, P91, DOI 10.1016/j.ins.2015.08.013
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu M, 2021, INFORM SCIENCES, V551, P39, DOI 10.1016/j.ins.2020.11.029
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Xu M, 2018, OPTIK, V171, P891, DOI 10.1016/j.ijleo.2018.06.112
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang H, 2020, IEEE ACCESS, V8, P122104, DOI 10.1109/ACCESS.2020.3006513
   Zhang SJ, 2021, MATH COMPUT SIMULAT, V190, P723, DOI 10.1016/j.matcom.2021.06.012
   Zhang ZQ, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21090888
   Zhou J, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106437
   Zhu CY, 2019, MICROSC MICROANAL, V25, P912, DOI 10.1017/S1431927619000710
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
NR 44
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7939
EP 7979
DI 10.1007/s11042-023-14786-3
EA JUN 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400005
DA 2024-07-18
ER

PT J
AU Vellela, SS
   Balamanigandan, R
AF Vellela, Sai Srinivas
   Balamanigandan, R.
TI Optimized clustering routing framework to maintain the optimal energy
   status in the wsn mobile cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chimp optimization algorithm; Shortest path estimation; Clustering route
   protocol; Optimal routing; Wireless sensor networks
ID ALGORITHM
AB Nowadays, energy-efficient data transmission is one of the biggest challenges in Wireless Sensor Networks (WSNs). Therefore, various routing protocols were developed to minimize energy consumption to find the shortest path in the WSN. However, they face issues due to delays and energy consumption. Thus, this article has developed a novel hybrid Chimp-based Clustering Flat Routing Protocol (CbCFRP) to overcome these demerits. The chimp fitness function in the designed model finds the optimal route for data transmission. Thus the energy consumption and delay are minimized. The clustering protocol helps to find the shortest route by determining the possible routes. The presented model is designed and validated in the MATLAB environment. Furthermore, the results of the developed model are estimated in terms of throughput, delay, packet drop, and delivery rate. Moreover, the robustness of the technique is verified with a comparative analysis. The comparative analysis confirms that the developed model earned better results than the existing approaches.
C1 [Vellela, Sai Srinivas] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 600124, Tamil Nadu, India.
   [Balamanigandan, R.] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Artific Intelligence, Chennai 600124, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering; Saveetha Institute of Medical & Technical Science; Saveetha
   School of Engineering
RP Vellela, SS (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 600124, Tamil Nadu, India.
EM sais1916@gmail.com; balamanigandanr.sse@saveetha.com
RI Ramachandran, Balamanigandan/AAM-4458-2021; Vellela, Sai
   Srinivas/HOF-3429-2023
OI Ramachandran, Balamanigandan/0000-0002-3325-4029; Vellela, Sai
   Srinivas/0000-0002-0118-6703
CR Al-Kaseem BR, 2021, IEEE ACCESS, V9, P82833, DOI 10.1109/ACCESS.2021.3087086
   Alhayani BSA, 2021, J INTELL MANUF, V32, P597, DOI 10.1007/s10845-020-01590-1
   Chauhan V, 2020, J AMB INTEL HUM COMP, V11, P4453, DOI 10.1007/s12652-019-01509-6
   Chithaluru P, 2019, COMPUT NETW, V162, DOI 10.1016/j.comnet.2019.106863
   Fang WD, 2020, WIREL NETW, V26, P3169, DOI 10.1007/s11276-019-02129-w
   Farsi M, 2019, IEEE ACCESS, V7, P28940, DOI 10.1109/ACCESS.2019.2902072
   Firouzi Farshad., 2020, Intelligent internet of things, P3, DOI DOI 10.1007/978-3-030-30367-9_1
   Goyal S., 2021, IOT ENABLED TECHNOLO, P25, DOI [10.1007/978-3-030-55833-8_2, DOI 10.1007/978-3-030-55833-8_2]
   Gulati K, 2022, MATER TODAY-PROC, V51, P161, DOI 10.1016/j.matpr.2021.05.067
   Jaiswal K, 2021, TELECOMMUN SYST, V78, P559, DOI 10.1007/s11235-021-00831-9
   Kalidoss T, 2020, WIRELESS PERS COMMUN, V110, P1637, DOI 10.1007/s11277-019-06788-y
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Kumar Pawan, 2020, CSI Transactions on ICT, V8, P331, DOI 10.1007/s40012-020-00289-1
   Majumdar A, 2021, INFORM SYST FRONT, V23, P1039, DOI 10.1007/s10796-020-10016-5
   Mazumdar N, 2021, AD HOC NETW, V111, DOI 10.1016/j.adhoc.2020.102348
   Mir M, 2023, MULTIMED TOOLS APPL, V82, P5133, DOI 10.1007/s11042-021-11841-9
   Nandan AS, 2022, IEEE INTERNET THINGS, V9, P5027, DOI 10.1109/JIOT.2021.3107295
   Nandan AS, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107318
   Nayyar A, 2020, MULTIMED TOOLS APPL, V79, P35221, DOI 10.1007/s11042-019-7627-z
   Niu Q, 2021, 2021 IEEE 5 INF TECH, DOI [10.1109/ITNEC52019.2021.9587089, DOI 10.1109/ITNEC52019.2021.9587089]
   Rishiwal Vinay, 2021, International Journal of Information Technology, V13, P1951, DOI 10.1007/s41870-020-00584-9
   Saba T, 2020, ENERGIES, V13, DOI 10.3390/en13164072
   Saba T, 2020, J INFECT PUBLIC HEAL, V13, P1567, DOI [10.1016/j.ijph.2020.06.027, 10.1016/j.jiph.2020.06.027]
   Sahoo BM, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102237
   Shanmugam R, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4752
   Shobana M, 2021, WIRELESS PERS COMMUN, V117, P2865, DOI 10.1007/s11277-020-07054-2
   Subashini S, 2020, WIRELESS PERS COMMUN, V112, P1601, DOI 10.1007/s11277-020-07118-3
   Vinodhini R, 2021, WIRELESS PERS COMMUN, V118, P3501, DOI 10.1007/s11277-021-08191-y
   Wei ZB, 2021, J POWER SOURCES, V489, DOI 10.1016/j.jpowsour.2021.229462
   Yadav G, 2020, J CLEAN PROD, V254, DOI 10.1016/j.jclepro.2020.120112
   Yang J, 2020, MULTIMED TOOLS APPL, V79, P35353, DOI 10.1007/s11042-019-07759-y
NR 31
TC 5
Z9 5
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7919
EP 7938
DI 10.1007/s11042-023-15926-5
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003131400003
DA 2024-07-18
ER

PT J
AU Kumar, P
   Kota, SR
AF Kumar, Prashant
   Kota, Solomon Raju
TI Machine learning models in structural engineering research and a secured
   framework for structural health monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence (AI); Deep learning (DL); Machine learning (ML);
   Structural health monitoring (SHM); Blockchain; Private Blockchain;
   Public Blockchain; Internet of things; Civil; structural engineering
ID SUPPORT VECTOR MACHINE; DAMAGE DETECTION; CRACK DETECTION;
   NEURAL-NETWORKS; STATISTICAL FEATURES; RELIABILITY-ANALYSIS; VIBRATION
   SIGNALS; EARTH DAM; IDENTIFICATION; PREDICTION
AB Health inspection of public structures is intended to detect incipient damage at an initial stage in order to improve maintenance. Artificial intelligence alludes to the part of computer science that comprises various techniques for fulfilling the requirements of Structural Health Monitoring (SHM). Deep Learning (DL), and Machine Learning (ML) are often utilized. Deep Learning is an instance of Machine Learning built on deep neural networks that have demonstrated remarkable achievement in numerous applications over the years. This article deals with recent literature reviews on the advent of machine learning models in the performance monitoring of civil structures. Recently, machine learning has gained considerable attention and is being built up as another class of astute techniques for the health inspection of civil structures. The main concern of this examination is to epitomize the strategies built over the last decade for the practice of ML techniques in civil engineering. In addition, types of sensors, number of sensors, sampling frequency, types of structure, structure material, data collection time, and types of excitation in the domain are also explored. Initially, a brief summary of the ML is given, and the implications of the ML in structural/civil engineering are depicted. Afterward, applications of ML methods in the domain are presented and the potential of these approaches to overcome the deficiencies of conventional methods is addressed. The observations after researching the literature, along with research opportunities and future directions in the use of ML, are then discussed. Eventually, a novel, secured framework for Structural Health Monitoring (SHM) using the Ethereum Blockchain is proposed established on the studies.
C1 [Kumar, Prashant] Cent Elect Engn Res Inst, CSIR, Pilani 333031, Rajasthan, India.
   [Kumar, Prashant; Kota, Solomon Raju] Acad Sci & Innovating Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
   [Kota, Solomon Raju] Natl Aerosp Labs, CSIR, Bengaluru 560017, Karnataka, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Electronics Engineering Research Institute (CEERI); Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - National
   Aerospace Laboratories (NAL)
RP Kumar, P (corresponding author), Cent Elect Engn Res Inst, CSIR, Pilani 333031, Rajasthan, India.; Kumar, P (corresponding author), Acad Sci & Innovating Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
EM prashant.mnnit10@gmail.com; kotasolomonraju@gmail.com
RI Kumar, Prashant/AAC-2412-2022
OI Kumar, Prashant/0000-0002-7902-8924; Kota, Solomon
   Raju/0000-0001-9128-2653
CR Abdeljaber O, 2018, NEUROCOMPUTING, V275, P1308, DOI 10.1016/j.neucom.2017.09.069
   Abdeljaber O, 2017, J SOUND VIB, V388, P154, DOI 10.1016/j.jsv.2016.10.043
   Abu-Mahfouz I, 2017, PROCEDIA COMPUT SCI, V114, P266, DOI 10.1016/j.procs.2017.09.038
   Alamdari MM, 2017, MECH SYST SIGNAL PR, V87, P384, DOI 10.1016/j.ymssp.2016.10.033
   Alves V, 2015, ENG STRUCT, V99, P439, DOI 10.1016/j.engstruct.2015.05.003
   Anaissi Ali, 2018, Neural Information Processing. 25th International Conference, ICONIP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11303), P612, DOI 10.1007/978-3-030-04182-3_54
   Anaissi A, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3230708
   Anaissi A, 2017, LECT NOTES ARTIF INT, V10234, P42, DOI 10.1007/978-3-319-57454-7_4
   Avci O, 2021, MECH SYST SIGNAL PR, V147, DOI 10.1016/j.ymssp.2020.107077
   Avci O, 2018, J SOUND VIB, V424, P158, DOI 10.1016/j.jsv.2018.03.008
   Aygün B, 2011, SENSOR REV, V31, P261, DOI 10.1108/02602281111140038
   Balingit M, 2020, WASH POST
   Bao YQ, 2019, ENGINEERING-PRC, V5, P234, DOI 10.1016/j.eng.2018.11.027
   Beckman GH, 2019, AUTOMAT CONSTR, V99, P114, DOI 10.1016/j.autcon.2018.12.006
   Behnia A, 2019, ENG FRACT MECH, V210, P212, DOI 10.1016/j.engfracmech.2018.07.005
   Behnia A, 2016, CONSTR BUILD MATER, V122, P823, DOI 10.1016/j.conbuildmat.2016.06.130
   Buyukozturk O, 2014, EWSHM 7 EUR WORKSH S
   Cao T, 2015, LECT NOTES COMPUT SC, V9077, P0, DOI [10.1007/978-3-319-18038-0, DOI 10.1007/978-3-319-18038-0]
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Chalouhi EK, 2017, PROCEDIA ENGINEER, V199, P1931, DOI 10.1016/j.proeng.2017.09.287
   Champneys MD, 2021, STRUCT HEALTH MONIT, V20, P1476, DOI 10.1177/1475921720920233
   Chang CM, 2018, MEASUREMENT, V129, P457, DOI 10.1016/j.measurement.2018.07.051
   Chen B, 2009, LECT NOTES COMPUT SC, V5666, P206, DOI 10.1007/978-3-642-03246-2_21
   Chen ZS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092151
   Choy Alex W. H., 2018, International MultiConference of Engineers and Computer Scientists 2018 (IMECS 2018). Proceedings, P557
   Coletta G, 2019, ENG STRUCT, V183, P1014, DOI 10.1016/j.engstruct.2018.12.044
   Cury A, 2012, MECH SYST SIGNAL PR, V33, P13, DOI 10.1016/j.ymssp.2012.07.005
   de Oliveira MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092955
   de Oliveira MA, 2018, EXPERT SYST APPL, V95, P1, DOI 10.1016/j.eswa.2017.11.022
   Demarie GV, 2019, STRUCT HEALTH MONIT, V18, P819, DOI 10.1177/1475921718779193
   Ding ZH, 2019, ENG STRUCT, V185, P301, DOI 10.1016/j.engstruct.2019.01.118
   Dong YF, 2008, J SOUND VIB, V311, P886, DOI 10.1016/j.jsv.2007.09.054
   Dorafshan S, 2018, CONSTR BUILD MATER, V186, P1031, DOI 10.1016/j.conbuildmat.2018.08.011
   Dzunic Z, 2017, MECH SYST SIGNAL PR, V96, P239, DOI 10.1016/j.ymssp.2017.03.043
   Fawzy DE, 2015, WORLD CONFERENCE ON TECHNOLOGY, INNOVATION AND ENTREPRENEURSHIP, P2290, DOI 10.1016/j.sbspro.2015.06.179
   Finotti RP, 2017, PROCEDIA ENGINEER, V199, P3314, DOI 10.1016/j.proeng.2017.09.438
   Fisher WD, 2017, J COMPUT SCI-NETH, V20, P143, DOI 10.1016/j.jocs.2016.11.016
   Fisher WD, 2016, PROCEDIA COMPUT SCI, V80, P577, DOI 10.1016/j.procs.2016.05.339
   Fredo ARJ, 2019, COMPOS PART B-ENG, V168, P77, DOI 10.1016/j.compositesb.2018.12.064
   Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363
   Ghrib M, 2019, J PROCESS CONTR, V83, P136, DOI 10.1016/j.jprocont.2018.08.002
   Gordan M, 2017, LAT AM J SOLIDS STRU, V14, P2373, DOI 10.1590/1679-78254378
   Guan W, 2019, MEASUREMENT, V132, P238, DOI 10.1016/j.measurement.2018.09.052
   Guo JQ, 2014, PERS UBIQUIT COMPUT, V18, P1977, DOI 10.1007/s00779-014-0800-5
   Hariri-Ardebili MA, 2018, SOIL DYN EARTHQ ENG, V104, P276, DOI 10.1016/j.soildyn.2017.09.016
   HosseinAbadi HZ, 2014, APPL ACOUST, V86, P59, DOI 10.1016/j.apacoust.2014.05.002
   Huang HW, 2018, TUNN UNDERGR SP TECH, V77, P166, DOI 10.1016/j.tust.2018.04.002
   Ince NF, 2009, INT CONF ACOUST SPEE, P2201, DOI 10.1109/ICASSP.2009.4960055
   Jung S, 2018, OCEAN ENG, V161, P88, DOI 10.1016/j.oceaneng.2018.04.090
   Kang DH, 2018, COMPUT-AIDED CIV INF, V33, P885, DOI 10.1111/mice.12375
   Kang F, 2019, ENG STRUCT, V180, P642, DOI 10.1016/j.engstruct.2018.11.065
   Khan A, 2019, COMPOS PART B-ENG, V161, P586, DOI 10.1016/j.compositesb.2018.12.118
   Khoa NLD, 2014, STRUCT HEALTH MONIT, V13, P406, DOI 10.1177/1475921714532989
   Khoa NLD, 2018, HUM-COMPUT INT-SPRIN, P409, DOI 10.1007/978-3-319-90403-0_20
   Kim D, 2011, PROC SPIE, V7981, DOI 10.1117/12.882016
   Kromanis R, 2014, COMPUT STRUCT, V136, P64, DOI 10.1016/j.compstruc.2014.01.026
   Langone R, 2017, MECH SYST SIGNAL PR, V90, P64, DOI 10.1016/j.ymssp.2016.12.002
   Laory I, 2014, ENG STRUCT, V80, P211, DOI 10.1016/j.engstruct.2014.09.001
   Li SW, 2018, J WIND ENG IND AEROD, V172, P196, DOI 10.1016/j.jweia.2017.10.022
   Li ZR, 2014, LECT NOTES COMPUT SC, V8491, P236, DOI 10.1007/978-3-319-07782-6_22
   Liang Y, 2016, DIGIT COMMUN NETW, V2, P97, DOI 10.1016/j.dcan.2016.05.002
   Lim HJ, 2018, MECH SYST SIGNAL PR, V109, P185, DOI 10.1016/j.ymssp.2018.03.003
   Lim ZW, 2009, LECT NOTES COMPUT SC, V5769, P976
   Lin JCW, 2021, IEEE INTERNET THINGS, V8, P5340, DOI 10.1109/JIOT.2020.3032896
   Lin JCW, 2019, IEEE ACCESS, V7, P25359, DOI 10.1109/ACCESS.2019.2899831
   Liu H, 2019, MEASUREMENT, V133, P168, DOI 10.1016/j.measurement.2018.09.081
   Liu SD, 2013, NDT&E INT, V54, P9, DOI 10.1016/j.ndteint.2012.11.004
   Liu WL, 2018, AUTOMAT CONSTR, V94, P135, DOI 10.1016/j.autcon.2018.06.008
   Lorenzo GF, 2015, 6 INT OP MOD AN C IO
   Mechbal N, 2015, MECH SYST SIGNAL PR, V60-61, P106, DOI 10.1016/j.ymssp.2015.01.017
   Melville J, 2018, AIP CONF PROC, V1949, DOI 10.1063/1.5031651
   Nazarko P, 2010, LECT NOTES ARTIF INT, V6114, P56, DOI 10.1007/978-3-642-13232-2_8
   News A, 2020, AP NEWS
   Hoang ND, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7913952
   Nick William, 2015, International Journal of Machine Learning and Computing, V5, P313, DOI 10.7763/IJMLC.2015.V5.526
   Oiwa R, 2017, IEEE INT CONF COMP, P123, DOI 10.1109/CIVEMSA.2017.7995313
   Pathirage CSN, 2018, ENG STRUCT, V172, P13, DOI 10.1016/j.engstruct.2018.05.109
   Paul S., 2018, ADV SCI TECHNOL ENG, V3, P339, DOI [10.25046/aj030540, DOI 10.25046/AJ030540]
   Paulraj MP, 2013, PROCEDIA ENGINEER, V53, P376, DOI 10.1016/j.proeng.2013.02.049
   Prada MA, 2012, NEUROCOMPUTING, V80, P119, DOI 10.1016/j.neucom.2011.07.030
   Prasanna P, 2016, IEEE T AUTOM SCI ENG, V13, P591, DOI 10.1109/TASE.2014.2354314
   Quaranta G, 2019, REV INT METOD NUMER, V35, DOI 10.23967/j.rimni.2018.12.001
   Rafiei MH, 2018, ENG STRUCT, V156, P598, DOI 10.1016/j.engstruct.2017.10.070
   Raj JS., 2021, J ISMAC, V2, P121, DOI [10.36548/jismac.2021.2.005, DOI 10.36548/JISMAC.2021.2.005]
   Rankovic V, 2014, STRUCT SAF, V48, P33, DOI 10.1016/j.strusafe.2014.02.004
   Rogers TJ, 2019, MECH SYST SIGNAL PR, V119, P100, DOI 10.1016/j.ymssp.2018.09.013
   Roia D, 2015, 2015 IEEE WORKSHOP ON ENVIRONMENTAL, ENERGY AND STRUCTURAL MONITORING SYSTEMS (EESMS), P119, DOI 10.1109/EESMS.2015.7175863
   Rosales MJ, 2017, J PHYS CONF SER, V842, DOI 10.1088/1742-6596/842/1/012012
   Salehi H, 2019, MEASUREMENT, V135, P23, DOI 10.1016/j.measurement.2018.11.023
   Salehi H, 2018, ENG STRUCT, V171, P170, DOI 10.1016/j.engstruct.2018.05.084
   Santos A, 2016, J SOUND VIB, V363, P584, DOI 10.1016/j.jsv.2015.11.008
   Sen D, 2019, MECH SYST SIGNAL PR, V117, P333, DOI 10.1016/j.ymssp.2018.08.019
   Sevim B., 2018, Civil Engineering Research Journal, V3, DOI [DOI 10.19080/CERJ.2018.03.555623, 10.19080/cerj.2018.03.555623]
   Sevim B, 2013, ADV CONCR CONSTR, V1, P227, DOI 10.12989/acc2013.1.3.227
   Shan L, 2012, COMM COM INF SC, V307, P97
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Silva M, 2017, MECH SYST SIGNAL PR, V92, P196, DOI 10.1016/j.ymssp.2017.01.024
   Silva M, 2016, ENG APPL ARTIF INTEL, V52, P168, DOI 10.1016/j.engappai.2016.03.002
   Simonov E, 2020, THETHIRDPOLE
   Smarsly K., 2007, COMPUTING CIVIL ENG, P111, DOI [10.1061/40937(261)1, DOI 10.1061/40937(261)1]
   Smarsly K., 2016, 8 EUROPEAN WORKSHOP, P5
   Srinivasu PN, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121437
   Sun L, 2020, J STRUCT ENG, V146, DOI 10.1061/(ASCE)ST.1943-541X.0002535
   Taffese WZ, 2017, AUTOMAT CONSTR, V77, P1, DOI 10.1016/j.autcon.2017.01.016
   Talaei S, 2018, STRUCTURES, V16, P10, DOI 10.1016/j.istruc.2018.08.006
   Tan ZX, 2017, ENG FAIL ANAL, V79, P253, DOI 10.1016/j.engfailanal.2017.04.035
   Tang Y., 2020, Artif. Intell. Evol., P8, DOI DOI 10.37256/AIE.112020250
   Tanida R, 2018, IEEE CIVEMSA, P1, DOI [10.1109/CIVEMSA.2018.8439967, DOI 10.1109/CIVEMSA.2018.8439967]
   Tibaduiza Burgos D, 2016, E J NONDESTRUCTIVE T, V21
   Tibaduiza DA, 2013, STRUCT CONTROL HLTH, V20, P1303, DOI 10.1002/stc.1540
   Tibaduiza D A., 2011, Advances in Dynamics, Control, Monitoring and Applications, Universitat Politecnica de Catalunya, Departament de Matematica Aplicada, V3, P8
   Tibaduiza D, 2018, COMPLEXITY, DOI 10.1155/2018/5081283
   Toivola J, 2010, LECT NOTES COMPUT SC, V6065, P208
   Vallathan G, 2021, J SUPERCOMPUT, V77, P3242, DOI 10.1007/s11227-020-03387-8
   Worden K, 2018, MECH SYST SIGNAL PR, V98, P139, DOI 10.1016/j.ymssp.2017.04.022
   Xie J, 2010, ICCET 2010 2010 INT, V6
   Yang YC, 2014, MECH SYST SIGNAL PR, V45, P1, DOI 10.1016/j.ymssp.2013.09.009
   Yousefianmoghadam S, 2018, EARTHQ ENG STRUCT D, V47, P25, DOI 10.1002/eqe.2935
   Yu L., 2010, 2010 Prognostics and System Health Management Conference, P1, DOI [DOI 10.1109/ICBBE.2010.5516478, 10.1109/PHM.2010.5413428, DOI 10.1109/PHM.2010.5413488]
   Zhang J, STRUCTURE HLTH MONIT
   Zhang J, 2008, ENG STRUCT, V30, P1439, DOI 10.1016/j.engstruct.2007.08.006
   Zhang XD, 2021, IEEE T MULTIMEDIA, V23, P611, DOI 10.1109/TMM.2020.2985526
   Zhou C, 2019, ADV ENG INFORM, V39, P259, DOI 10.1016/j.aei.2019.01.007
   Zhou QF, 2015, APPL SOFT COMPUT, V36, P368, DOI 10.1016/j.asoc.2015.06.057
   Zio E, 2012, EXPERT SYST APPL, V39, P10681, DOI 10.1016/j.eswa.2012.02.199
NR 125
TC 1
Z9 1
U1 17
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7721
EP 7759
DI 10.1007/s11042-023-15853-5
EA JUN 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900008
DA 2024-07-18
ER

PT J
AU Zhang, YC
   Qi, Q
   Li, KQ
   Liu, DD
AF Zhang, Yongchang
   Qi, Qi
   Li, Kunqian
   Liu, Dandan
TI Underwater video consistent enhancement: a real-world dataset and
   solution with progressive quality learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater video enhancement; Image quality assessment; Color transfer;
   Video processing
ID IMAGE-ENHANCEMENT; COLOR CORRECTION; MODEL; NETWORK; WATER
AB Underwater image and video enhancement task is of great significance for ocean exploration. Compared with a single image, underwater video enhancement is more susceptible to scene and light changes, which causes inconsistency between the frames of enhanced video. In this paper, we construct a high-quality dataset named UVE38K to establish a benchmark for underwater video enhancement, which consists of 50 real-world videos from various environments. To understand the difference in quality between underwater video frames. We propose a quality superiority decision network (QSDNet) to distinguish the high-quality and low-quality frames in enhanced videos. Our QSDNet can achieve an accuracy of 87.9%. We also propose two underwater video enhancement algorithms PUVE and BUVE for online and offline situations respectively. Experiments on the UVE38K dataset show that our methods outperform existing methods.
C1 [Zhang, Yongchang] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing, Peoples R China.
   [Qi, Qi] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao, Peoples R China.
   [Li, Kunqian; Liu, Dandan] Ocean Univ China, Coll Engn, Qingdao, Peoples R China.
   [Liu, Dandan] Yancheng Inst Technol, Coll Elect Engn, Yancheng, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Qingdao University of
   Technology; Ocean University of China; Yancheng Institute of Technology
RP Qi, Q (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao, Peoples R China.
EM qiqi2013@stu.ouc.edu.cn
RI Liu, Dan-Dan/HGE-7080-2022
OI Liu, Dan-Dan/0000-0002-1480-0290
FU National Natural Science Foundation of China [61906177]; Natural Science
   Foundation of Shandong Province [ZR2019BF034]; Significant Applied
   Technology Innovation Projects for Agriculture of Shandong Province
   [SD2019NJ020]; Fundamental Research Funds for the Central Universities
   [201813022, 201964013]
FX AcknowledgmentsThe research has been supported by the National Natural
   Science Foundation of China under Grant 61906177, in part by the Natural
   Science Foundation of Shandong Province under Grant ZR2019BF034, in part
   by Significant Applied Technology Innovation Projects for Agriculture of
   Shandong Province under Grant SD2019NJ020, and in part by Fundamental
   Research Funds for the Central Universities, under Grants 201813022 and
   201964013.
CR Akkaynak D, 2019, PROC CVPR IEEE, P1682, DOI 10.1109/CVPR.2019.00178
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Anwar S., 2018, arXiv
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Azmi KZM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105810
   Bai LF, 2020, IEEE ACCESS, V8, P128973, DOI 10.1109/ACCESS.2020.3009161
   Berman D., 2017, BRIT MACHINE VISION
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Boom BJ, 2014, ECOL INFORM, V23, P83, DOI 10.1016/j.ecoinf.2013.10.006
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chambah M, 2004, PROC SPIE, V5293, P157
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Cutter G, 2015, 2015 IEEE WINTER APPLICATIONS AND COMPUTER VISION WORKSHOPS (WACVW), P57, DOI 10.1109/WACVW.2015.11
   Dai CG, 2020, OPT LASER TECHNOL, V123, DOI 10.1016/j.optlastec.2019.105947
   Ding DD, 2022, IEEE T CYBERNETICS, V52, P1207, DOI 10.1109/TCYB.2020.2998481
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XY, 2020, SIGNAL PROCESS-IMAGE, V86, DOI 10.1016/j.image.2020.115892
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Ghani Ahmad Shahrizan Abdul, 2014, Proceedings 2014 IEEE Fourth International Conference on Consumer Electronics - Berlin (ICCEBerlin), P219, DOI 10.1109/ICCE-Berlin.2014.7034265
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Guan ZY, 2021, IEEE T PATTERN ANAL, V43, P949, DOI 10.1109/TPAMI.2019.2944806
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou GJ, 2020, IEEE ACCESS, V8, P122078, DOI 10.1109/ACCESS.2020.3006359
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Hou MJ, 2018, IEEE IMAGE PROC, P4043, DOI 10.1109/ICIP.2018.8451209
   Hu JK, 2021, IEEE SIGNAL PROC LET, V28, P2152, DOI 10.1109/LSP.2021.3099746
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Jian MW, 2017, IEEE INT CON MULTI, P1297, DOI 10.1109/ICME.2017.8019324
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2019, MULTIMED TOOLS APPL, V78, P15121, DOI 10.1007/s11042-018-6849-9
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2016, INT CONF ACOUST SPEE, P1731, DOI 10.1109/ICASSP.2016.7471973
   Li H., 2019, ARXIV, DOI 1905.09979
   Li YJ, 2019, OPT LASER TECHNOL, V110, P2, DOI 10.1016/j.optlastec.2017.09.017
   Lin WH, 2020, INT CONF ACOUST SPEE, P2588, DOI [10.1109/icassp40776.2020.9053829, 10.1109/ICASSP40776.2020.9053829]
   Liu Chao, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P35, DOI 10.1109/ICCET.2010.5485339
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Liu XD, 2021, NEUROCOMPUTING, V453, P538, DOI 10.1016/j.neucom.2020.07.130
   Liu XD, 2020, IEEE GEOSCI REMOTE S, V17, P1488, DOI 10.1109/LGRS.2019.2950056
   Lu JY, 2019, OPT LASER TECHNOL, V110, P105, DOI 10.1016/j.optlastec.2018.05.048
   M Uplavikar P, 2019, IEEE C COMPUTER VISI
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Oleari F, 2015, OCEANS 2015 - GENOVA, DOI 10.1109/OCEANS-Genova.2015.7271529
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srividhya K, 2017, MULTIMED TOOLS APPL, V76, P25679, DOI 10.1007/s11042-017-4459-6
   Tang C, 2019, SIGNAL IMAGE VIDEO P, V13, P1011, DOI 10.1007/s11760-019-01439-y
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P511, DOI 10.1109/JOE.2004.836395
   Wang Y, 2010, MODELLING SIMULATION, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang M, 2019, IEEE ACCESS, V7, P123638, DOI 10.1109/ACCESS.2019.2932611
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 73
TC 0
Z9 0
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7335
EP 7361
DI 10.1007/s11042-023-15542-3
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400009
DA 2024-07-18
ER

PT J
AU Babavalian, MR
   Kiani, K
AF Babavalian, Mohammad Reza
   Kiani, Kourosh
TI Learning distribution of video captions using conditional GAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video captioning; Captions distribution; Conditional GAN;
   Encoder-decoder; Captions generation; Adversarial Video Captioning
ID GENERATION; NETWORKS; SEQGAN; IMAGE
AB Automatic video captioning aims to generate captions with textual descriptions to express video content in natural language by a machine. This is a difficult task as the videos contain dynamic challenges. Most of the available approaches for video captioning are often focused on providing a single descriptive sentence. Encoder-decoder is the most popular architecture developed for video captioning. The proposed method in this research aims to learn the distribution of captions to generate more relevant and diverse captions and increase generalizability. A novel architecture was developed based on conditional SeqGAN to learn the distribution for video captioning and increase the generalizability. This architecture consists of two modules: encoding and caption generation. The goal of encoding is to obtain encoded rich spatial-temporal features. The encoding vector is fed as the input of conditional SeqGAN to generate captions. The main novelty of this paper lies in the use of an adversarial approach to learn the distribution of captions and generate diverse captions that fit the characteristics of the video. Experimental results from two popular datasets, MSVD and MSRVTT, showed that the proposed approach achieved more relevant video captions than other state-of-the-art methods.
C1 [Babavalian, Mohammad Reza; Kiani, Kourosh] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Kiani, K (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM kourosh.kiani@semnan.ac.ir
RI Kiani, Kourosh/T-7468-2019
OI Kiani, Kourosh/0000-0001-6582-8691
CR Aafaq N, 2021, ARRAY-NY, V9, DOI 10.1016/j.array.2020.100052
   Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aldausari N, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3487891
   Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Amirian S, 2021, TRANS COMP SCI C INT, P17, DOI 10.1007/978-3-030-70296-0_2
   Amirian S, 2020, IEEE ACCESS, V8, P218386, DOI 10.1109/ACCESS.2020.3042484
   Ballas N., 2015, arXiv
   Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088
   Brownlee J, 2019, MACH LEARN, VMastery
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dasgupta M, 2023, MULTIMED TOOLS APPL, V82, P5857, DOI 10.1007/s11042-022-13473-z
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Islam S., 2021, SN COMPUT SCI, V2, P120, DOI [10.1007/s42979-021-00487-x, DOI 10.1007/S42979-021-00487-X]
   Jain V, 2022, MULTIMED TOOLS APPL, V81, P35619, DOI 10.1007/s11042-021-11878-w
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Ji WT, 2022, APPL SOFT COMPUT, V117, DOI 10.1016/j.asoc.2021.108332
   Jia N, 2019, INT C INTEL HUM MACH, P106, DOI 10.1109/IHMSC.2019.00033
   Keneshloo Y, 2020, IEEE T NEUR NET LEAR, V31, P2469, DOI 10.1109/TNNLS.2019.2929141
   Khanday NY, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100374
   Kim H, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13042250
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Lavie A., 2007, P 2 WORKSH STAT MACH, P228
   Lei Z, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020055
   Li LJ, 2019, IEEE WINT CONF APPL, P339, DOI 10.1109/WACV.2019.00042
   Li LH, 2022, IEEE T CIRC SYST VID, V32, P17, DOI 10.1109/TCSVT.2020.3045735
   Li SH, 2022, IEEE ACCESS, V10, P31751, DOI 10.1109/ACCESS.2022.3160451
   Li S, 2019, IEEE T EM TOP COMP I, V3, P297, DOI 10.1109/TETCI.2019.2892755
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu S, 2021, IEEE T PATTERN ANAL, V43, P3259, DOI 10.1109/TPAMI.2019.2940007
   Liu Y, 2017, AAAI CONF ARTIF INTE, P4197
   Luo JW, 2021, IEEE ACCESS, V9, P99922, DOI 10.1109/ACCESS.2021.3094023
   Mingxing Wang, 2020, 2020 IEEE 3rd International Conference on Computer and Communication Engineering Technology (CCET), P10, DOI 10.1109/CCET50901.2020.9213129
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Najari S, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-021-00800-9
   Niu TZ, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109202
   Pan J.-X., 2002, Growth Curve Models and Statistical Diagnostics, P77, DOI [10.1007/978-0-387-21812-0_3, DOI 10.1007/978-0-387-21812-0_3]
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Park JS, 2019, PROC CVPR IEEE, P6591, DOI 10.1109/CVPR.2019.00676
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qian HZ, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5217578
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Sasithradevi A., 2021, GENERATIVE ADVERSARI, DOI [10.1016/B978-0-12-823519-5.00008-7, DOI 10.1016/B978-0-12-823519-5.00008-7]
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shi XX, 2020, NEUROCOMPUTING, V417, P347, DOI 10.1016/j.neucom.2020.08.035
   Singh A, 2022, MULTIMED TOOLS APPL, V81, P17989, DOI 10.1007/s11042-022-12343-y
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2737
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tu YB, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109204
   Tuan YL, 2019, IEEE-ACM T AUDIO SPE, V27, P788, DOI 10.1109/TASLP.2019.2896437
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Venugopalan S., 2016, EMNLP, P1961
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2019, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2019.00273
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443
   Wang ZW, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439723
   Wu YX, 2020, IEEE ACCESS, V8, P11880, DOI 10.1109/ACCESS.2020.2966291
   Wu Z., 2017, FRONTIERS MULTIMEDIA, P3, DOI DOI 10.1145/3122865.3122867
   Xiao HH, 2022, PATTERN RECOGN LETT, V160, P19, DOI 10.1016/j.patrec.2022.05.021
   Xiong YL, 2018, LECT NOTES COMPUT SC, V11215, P489, DOI 10.1007/978-3-030-01252-6_29
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan J, 2022, INT J MULTIMED INF R, V11, P111, DOI 10.1007/s13735-022-00228-7
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Yu L, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23241
   Zheng Q., 2020, 2020 CVPR, P13093, DOI 10.1109/CVPR42600.2020.01311
NR 80
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9137
EP 9159
DI 10.1007/s11042-023-15933-6
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600010
DA 2024-07-18
ER

PT J
AU Escobar-Grisales, D
   Vásquez-Correa, JC
   Orozco-Arroyave, JR
AF Escobar-Grisales, Daniel
   Vasquez-Correa, Juan Camilo
   Orozco-Arroyave, Juan Rafael
TI Evaluation of effectiveness in conversations between humans and chatbots
   using parallel convolutional neural networks with multiple temporal
   resolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Customer service; Natural language processing; Chatbot; Effectiveness
   evaluation; Convolutional neural networks
ID KNOWLEDGE
AB Chatbots enable the automation of several components in customer service and allow the support of multiple users. Despite their multiple advantages, due to the large amount of conversations generated by a chatbot, it is difficult to determine whether customer requests are well-addressed. For practical reasons, chatbot's effectiveness is evaluated manually based upon a small sample (randomly chosen) of conversations or through self-reported user satisfaction. This procedure does not guarantee the correct evaluation of the service because the sample is generally not large enough and self-reports might be influenced by different external factors not directly associated to the chatbot's functioning. This study proposes a methodology for automatic evaluation of chatbot effectiveness in real production environments. The analysis considers convolutional neural networks adapted for natural language processing, using two parallel convolutional layers to evaluate questions and answers independently. The proposed model also incorporates filters to extract features with multiple temporal resolution. This methodology is tested upon real conversations of chatbots that provide service to two different companies. The results are compared to baseline models based on classical techniques with different pre-trained word embedding models. According to our results, the proposed approach provides accuracies between 78.95% and 80.18%, which outperforms the best result of the baseline models by 2.9%.
C1 [Escobar-Grisales, Daniel; Vasquez-Correa, Juan Camilo; Orozco-Arroyave, Juan Rafael] Univ Antioquia, Fac Engn, GITA Lab, Medellin, Colombia.
   [Vasquez-Correa, Juan Camilo; Orozco-Arroyave, Juan Rafael] Univ Erlangen Nurnberg, Pattern Recognit Lab, Erlangen, Germany.
   [Vasquez-Correa, Juan Camilo] Pratech Grp, Medellin, Colombia.
C3 Universidad de Antioquia; University of Erlangen Nuremberg
RP Escobar-Grisales, D (corresponding author), Univ Antioquia, Fac Engn, GITA Lab, Medellin, Colombia.
EM daniel.esobar@udea.edu.co; jcamilo.vasquez@udea.edu.co;
   rafael.orozco@udea.edu.co
RI Vasquez-Correa, Juan Camilo/AAE-7371-2019
OI Vasquez-Correa, Juan Camilo/0000-0003-4946-9232
FU Universidad de Antioquia [PRG2020-34068]; European Union [766287];
   Pratech Group [PI2019-24110]
FX This work was funded by CODI from Universidad de Antioquia grant #
   PRG2020-34068. Juan Camilo Vasquez is funded by the European Union
   (Horizon 2020) research and innovation programme under the Marie
   Sklodowska-Curie Grant Agreement No. 766287. The work received funding
   also from Pratech Group grant # PI2019-24110.
CR Aksu H, 2013, CUSTOMER SERVICE NEW
   [Anonymous], 2017, P 2017 C EMP METH NA, DOI DOI 10.18653/V1/D17-1254
   [Anonymous], 2009, P 18 ACM C INFORM KN
   Bakarov A, 2018, Arxiv, DOI arXiv:1801.09536
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Cahn J., 2017, CHATBOT: Architecture, design
   Canete J., 2020, PML4DC ICLR 2020, P2020
   Caselles-Dupré H, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P352, DOI 10.1145/3240323.3240377
   Chakrabarti C, 2013, 26 INT FLOR ART INT
   Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P97, DOI 10.18653/v1/P17-4017
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, 10.48550/arXiv.1802.05365]
   Feine J., 2019, P 14 INT C WIRTSCH W
   Ghazvininejad M, 2018, AAAI CONF ARTIF INTE, P5110
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gridach Mourad., 2017, P 3 WORKSH NOIS US G, P21
   Gu X, 2018, INT C LEARNING REPRE
   Heller B., 2005, EdMedia+ Innovate Learning, P3913
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hoang M., 2019, P 22 NORD C COMP LIN, P187
   Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z
   Hung V, 2009, IEEE SYS MAN CYBERN, P1236, DOI 10.1109/ICSMC.2009.5345904
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Jenkins MC, 2007, LECT NOTES COMPUT SC, V4552, P76
   Jia JY, 2009, KNOWL-BASED SYST, V22, P249, DOI 10.1016/j.knosys.2008.09.001
   Jwalapuram Prathyusha, 2017, P STUDENT RES WORKSH, P17
   Kannan Anjuli, 2017, arXiv
   Kim H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112347
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BF, 2019, DATA SCI ENG, V4, P157, DOI 10.1007/s41019-019-0096-6
   Li J, 2015, 2015 ANN C N AM CHAP
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu Chia-Wei, 2016, P 2016 C EMPIRICAL M
   Luo LX, 2019, PERS UBIQUIT COMPUT, V23, P405, DOI 10.1007/s00779-018-1183-9
   Miaschi A, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P110
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Minaee S, 2019, Arxiv, DOI [arXiv:1904.04206, DOI 10.48550/ARXIV.1904.04206]
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   Oliver R.L., 2010, Satisfaction: A Behavioral Perspective on the Consumer, V2nd, DOI [10.4324/9781315700892, DOI 10.4324/9781315700892]
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peras D, 2018, EC SOC DEVELOP, P89
   Pereira J, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P2144, DOI 10.1145/3167132.3167362
   Perez PA, 2021, P ICASSP, P8338
   Perez-Toro P. A., 2020, PAUPEREZT WEBERT WOR, DOI [10.5281/zenodo.3964244, DOI 10.5281/ZENODO.3964244]
   Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1525, DOI 10.1109/ICACCI.2017.8126057
   Reese S, 2010, 7 INT C LANG RES EV
   Roccetti Marco, 2017, JMIR Public Health Surveill, V3, pe51, DOI 10.2196/publichealth.7004
   Rodrigues Makiuchi M, 2019, P 9 INT AUD VIS EM C, P55, DOI DOI 10.1145/3347320.3357694
   Rong X, 2016, Arxiv, DOI arXiv:1411.2738
   Schumaker RP, 2007, DECIS SUPPORT SYST, V42, P2236, DOI 10.1016/j.dss.2006.07.001
   Sedoc J, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P60
   Shang LF, 2015, Arxiv, DOI arXiv:1503.02364
   Siddiqui M H., 2010, Journal of Targeting, Measurement and Analysis for Marketing, V18, P221, DOI DOI 10.1057/JT.2010.17
   Song YP, 2016, Arxiv, DOI arXiv:1610.07149
   Sordoni A., 2015, ARXIV
   Suhaili SM, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115461
   Tang S, 2018, EXPLORING ASYMMETRIC
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Venkatesh Anu, 2018, arXiv preprint arXiv:1801.03625
   Wang GY, 2018, Arxiv, DOI arXiv:1805.04174
   Wang Zhuoran, 2017, P C EMP METH NAT LAN, P617, DOI [DOI 10.18653/V1/D17-1065, 10.18653/v1/D17-1065]
   Xiang Y., 2014, Proc. of the 3rd CIPS-SIGHAN Joint Conf. on Chin. Lang. Process, P43
   Yan J, 2009, TEXT REPRESENTATION
   Yao K, 2016, P 53 ANN M ASS COMP
   Zhao R, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P239, DOI 10.1145/3267851.3267880
   Zhong JM, 2019, 3RD INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE (ICIAI 2019), P55, DOI 10.1145/3319921.3319937
NR 71
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 3
PY 2023
DI 10.1007/s11042-023-14896-y
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0SS7
UT WOS:000999967700002
OA hybrid
DA 2024-07-18
ER

PT J
AU He, HT
   Zhang, RX
   Zhang, YS
   Ren, JD
AF He, Haitao
   Zhang, Ruixi
   Zhang, Yangsen
   Ren, Jiadong
TI USBE: User-similarity based estimator for multimedia cold-start
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender system; Collaborative filtering; Cold-start challenge; Deep
   learning
AB To address user cold-start challenge in multimedia recommender systems, we proposed a new model named USBE in this paper. The model doesn't take the new user's personal and social information as the necessary parameters to solve cold-start challenge, and new user can complete cold-start by having a simple system experience. Based on the user-similarity and the discrimination of the multimedia items, the model can recommend suitable items for cold-start users and let users choose and give feedback independently. Our model is lightweight and low delay, and provides a new cold-start mode. To complement USBE model, we proposed a cyclic training multilayer perceptron model (Re-NN) to get the strategy of new user's user-similarity changes. Experiments on a real-world movie recommendation dataset Movielens show: Our model has good results and achieves state-of-the-art after 4 rounds of cold-start recommendations.
C1 [He, Haitao; Zhang, Ruixi; Ren, Jiadong] Yanshan Univ, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zhang, Yangsen] Beijing Informat Sci & Technol Univ, Beijing 100192, Peoples R China.
C3 Yanshan University; Beijing Information Science & Technology University
RP Zhang, RX (corresponding author), Yanshan Univ, Qinhuangdao 066004, Hebei, Peoples R China.
EM 609789865@qq.com
FU National Natural Science Foundation of China [61772449]; Natural Science
   Foundation of Hebei Province China [F2019203120]
FX AcknowledgmentsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 61772449, and in part by the
   Natural Science Foundation of Hebei Province China under Grant
   F2019203120.
CR Bobadilla J, 2012, KNOWL-BASED SYST, V26, P225, DOI 10.1016/j.knosys.2011.07.021
   Cheng H., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [DOI 10.1145/2988450.2988454, 10.1145/2988450.2988454]
   Deldjoo Y, 2019, MED 2019 WORKSH
   Gantner Z., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P176, DOI 10.1109/ICDM.2010.129
   Golbandi Nadav, 2011, P 4 INT C WEB SEARCH, P595
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Jaiswal S, 2019, MULTIMED TOOLS APPL, V78, P14231, DOI 10.1007/s11042-018-6755-1
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Kula M, 2015, Proceedings of the 2nd Workshop on New Trends on Content-Based Recommender Systems co-located with 9th ACM Conference on Recommender Systems (RecSys 2015), Vienna, Austria, September 16-20, 2015, P14
   Kumar S, 2020, IEEE T COMPUT SOC SY, V7, P915, DOI 10.1109/TCSS.2020.2993585
   Lee H, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1073, DOI 10.1145/3292500.3330859
   Lika B, 2014, EXPERT SYST APPL, V41, P2065, DOI 10.1016/j.eswa.2013.09.005
   Man T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2464
   Qu YR, 2016, IEEE DATA MINING, P1149, DOI [10.1109/ICDM.2016.0151, 10.1109/ICDM.2016.57]
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Sedhain S, 2017, AAAI CONF ARTIF INTE, P1502
   Shan Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P255, DOI 10.1145/2939672.2939704
   Shen J, 2013, INT ACM SIG C RES DE
   Dureddy HV, 2018, Arxiv, DOI arXiv:1806.06192
   Volkovs M, 2017, ADV NEUR IN, V30
   Xiao J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3119
   Zheng GJ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P167, DOI 10.1145/3178876.3185994
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
   Zhou K, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P315
NR 28
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 2
PY 2023
DI 10.1007/s11042-023-15493-9
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0KI8
UT WOS:000999746300007
DA 2024-07-18
ER

PT J
AU Vatankhah, M
   Momenzadeh, M
AF Vatankhah, Mehrdad
   Momenzadeh, Mohammadreza
TI Self-regularized Lasso for selection of most informative features in
   microarray cancer classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cancer classification; DNA microarray; Feature selection; Lasso
ID VARIABLE SELECTION; CLASS PREDICTION; GENE; REGRESSION
AB In this article, a new method is employed for maximizing the performance of the Least Absolute Shrinkage and Selection Operator (Lasso) feature selection model. In fact, we presented a novel regularization for the Lasso by employing an approach to find the best regularization parameter automatically which guarantees best performance of the Lasso in DNA microarray data classification. In our experiment, four well-known publicly available microarray datasets including breast cancer, Diffuse Large B-cell Lymphoma (DLBCL), leukemia and prostate cancer were utilized for evaluation the proposed methods. Experimental results demonstrated the significant dominance of the proposed Lasso against other widely used feature selection methods in terms of best features that led to best performance, robustness and stability in microarray data classification. Accordingly, the proposed method is a powerful algorithm for selection of most informative features which can be used for cancer diagnosis by gene expression profiles.
C1 [Vatankhah, Mehrdad; Momenzadeh, Mohammadreza] Smart Univ Med Sci, Dept Artificial Intelligence, Tehran, Iran.
RP Momenzadeh, M (corresponding author), Smart Univ Med Sci, Dept Artificial Intelligence, Tehran, Iran.
EM Mehrdad.vatankhah@gmail.com; momenzadeh.mr@gmail.com
OI Momenzadeh, Mohammadreza/0000-0002-6506-7295
CR Algamal ZY, 2015, EXPERT SYST APPL, V42, P9326, DOI 10.1016/j.eswa.2015.08.016
   Alshalalfah M, 2009, INTELL DATA ANAL, V13, P671, DOI 10.3233/IDA-2009-0386
   Bergadano F, 1994, ESTIMATING ATTRIBUTE
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bolón-Canedo V, 2019, INFORM FUSION, V52, P1, DOI 10.1016/j.inffus.2018.11.008
   Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185
   Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419
   Chen X. wen, 2008, P 14 ACM SIGKDD INT, P124, DOI [DOI 10.1145/1401890.1401910, 10.1145/1401890.1401910]
   Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004
   Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5
   Fu GH, 2014, APPL MECH MATER, V444-445, P604, DOI 10.4028/www.scientific.net/AMM.0.604
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Hsu NJ, 2008, COMPUT STAT DATA AN, V52, P3645, DOI 10.1016/j.csda.2007.12.004
   Huang HH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149675
   Huang SQ, 2020, IET IMAGE PROCESS, V14, P3324, DOI 10.1049/iet-ipr.2019.0772
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jiang L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66466-z
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kang CZ, 2019, J THEOR BIOL, V463, P77, DOI 10.1016/j.jtbi.2018.12.010
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kratsios A, 2021, J MACH LEARN RES, V22
   Lal T.N., 2006, Embedded methods
   Liu H., 2010, Feature Selection, P402, DOI DOI 10.1007/978-0-387-30164-8306
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Momenzadeh M, 2020, J BIOMED INFORM, V111, DOI 10.1016/j.jbi.2020.103570
   Momenzadeh M, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103213
   Mundra PA, 2010, IEEE T NANOBIOSCI, V9, P31, DOI 10.1109/TNB.2009.2035284
   Muthukrishnan R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P18, DOI 10.1109/ICACA.2016.7887916
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Sánchez-Maroño N, 2007, LECT NOTES COMPUT SC, V4881, P178
   Shah SH, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05367-8
   Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68
   Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Nguyen T, 2015, PATTERN RECOGN LETT, V60-61, P16, DOI 10.1016/j.patrec.2015.03.018
   Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009
   Zeebaree Diyar Qader, 2018, 2018 International Conference on Advanced Science and Engineering (ICOASE), P145, DOI 10.1109/ICOASE.2018.8548836
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
NR 45
TC 2
Z9 2
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15207-1
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700012
DA 2024-07-18
ER

PT J
AU Wang, L
   Liao, CF
   Yao, RZ
   Zhang, R
   Zhang, WX
   Chen, XX
   Meng, N
   Yan, ZH
   Jiang, B
   Liu, C
AF Wang, Lin
   Liao, Chengfeng
   Yao, Runzhao
   Zhang, Rui
   Zhang, Wanxu
   Chen, Xiaoxuan
   Meng, Na
   Yan, Zenghui
   Jiang, Bo
   Liu, Cheng
TI Fixing algorithm of Kinect depth image based on non-local means
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Kinect; Image fixing; Depth image; Non-local means
ID LIDAR
AB The three-dimensional (3D) geometrical information that depth maps contain is useful in many applications such as 3D reconstruction or simultaneous localization and mapping (SLAM). Kinect is widely used in depth image acquisition due to its low cost and good real-time performance. However, the quality of depth images obtained by Kinect is influenced by holes which make depth image inadequate for further applications. To suppress the influence of holes on a subsequent application, a fixing algorithm of Kinect depth image based on non-local means (NLM) is proposed in this paper. The holes in depth image are filled using the weights which are calculated on the corresponding gray image by distance factor and value consistent factor. And the experiment results demonstrate that the proposed method achieves good performance in both evaluation in metrics and subjectively visual effect. This research provides a solution idea for depth image fixing algorithm with low complexity.
C1 [Wang, Lin; Liao, Chengfeng; Zhang, Rui; Zhang, Wanxu; Chen, Xiaoxuan; Meng, Na; Yan, Zenghui; Jiang, Bo; Liu, Cheng] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Yao, Runzhao] Xi An Jiao Tong Univ, Coll Artificial Intelligence, Xian 710049, Shaanxi, Peoples R China.
C3 Northwest University Xi'an; Xi'an Jiaotong University
RP Jiang, B; Liu, C (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM jiangbo@nwu.edu.cn; lc@nwu.edu.cn
OI Wang, Lin/0000-0003-1026-0060
FU Key Research and Development Program of Shaanxi [2020KW-010]; National
   Natural Science Foundation of China [61801384, 61971343]; Natural
   Science Basic Research Plan in Shaanxi Province of China [2020JM-415];
   Northwest University Paleontological Bioinformatics Innovation Team
   [2019TD-012]
FX AcknowledgementsThis work was supported in part by Key Research and
   Development Program of Shaanxi under Grant 2020KW-010, in part by
   National Natural Science Foundation of China under Grant 61801384 and
   Grant 61971343, in part by Natural Science Basic Research Plan in
   Shaanxi Province of China under Grant 2020JM-415, and in part by
   Northwest University Paleontological Bioinformatics Innovation Team
   under Grant 2019TD-012.
CR Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   AshaJayachandran, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1117, DOI 10.1109/RTEICT.2016.7808005
   Behroozpour B, 2017, IEEE COMMUN MAG, V55, P135, DOI 10.1109/MCOM.2017.1700030
   Bi XD, 2021, MICROELECTRON J, V114, DOI 10.1016/j.mejo.2021.105140
   Buades A, 2005, INT CONF ACOUST SPEE, P25
   Cai MX, 2019, CHIN CONTR CONF, P4576, DOI [10.23919/ChiCC.2019.8865762, 10.23919/chicc.2019.8865762]
   Chang TA, 2018, IET SIGNAL PROCESS, V12, P119, DOI 10.1049/iet-spr.2016.0550
   Chen MH, 2014, INT CONF 3D IMAG
   Chen ZF, 2020, IEEE I C VI COM I PR, P54, DOI 10.1109/vcip49819.2020.9301857
   Cho JM, 2020, IEEE ACCESS, V8, P53901, DOI 10.1109/ACCESS.2020.2981378
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Feng C, 2014, 2014 IEEE CHINESE GUIDANCE, NAVIGATION AND CONTROL CONFERENCE (CGNCC), P2568, DOI 10.1109/CGNCC.2014.7007571
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hung SW, 2019, IEEE IMAGE PROC, P2374, DOI [10.1109/icip.2019.8803360, 10.1109/ICIP.2019.8803360]
   Jin X, 2016, SIGNAL PROCESS-IMAGE, V47, P56, DOI 10.1016/j.image.2016.05.006
   Jing NB, 2018, INT SYMP COMP CONS, P278, DOI 10.1109/IS3C.2018.00077
   Lee GW, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427596
   Liang CC, 2017, INT CONF SYST SCI EN, P125, DOI 10.1109/ICSSE.2017.8030850
   Liao X, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Pan LY, 2018, IEEE WINT CONF APPL, P1377, DOI 10.1109/WACV.2018.00155
   Rossi Mattia, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12151, DOI 10.1109/CVPR42600.2020.01217
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sharma N, 2020, PROCEEDINGS
   Song W, 2017, MULTIMED TOOLS APPL, V76, P4357, DOI 10.1007/s11042-016-3523-y
   Sun MJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030732
   Nguyen TD, 2019, IEEE T MULTIMEDIA, V21, P1345, DOI 10.1109/TMM.2018.2880954
   Xiang S, 2019, SIGNAL PROCESS-IMAGE, V71, P56, DOI 10.1016/j.image.2018.07.005
   Yicheng Zhong, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P6, DOI 10.1109/TBIOM.2020.3025466
   Zhang LY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236725
   Zhang S, 2018, OPT LASER ENG, V106, P119, DOI 10.1016/j.optlaseng.2018.02.017
   Zhou H, 2015, 2015 IET INT C BIOM, P1
NR 31
TC 1
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 24
PY 2023
DI 10.1007/s11042-023-15194-3
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CU8
UT WOS:000994104400006
DA 2024-07-18
ER

PT J
AU Athira, B
   Idicula, SM
   Jones, J
   Kulanthaivel, A
AF Athira, B.
   Idicula, Sumam Mary
   Jones, Josette
   Kulanthaivel, Anand
TI An answer recommendation framework for an online cancer community forum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Answer recommendation; Breast cancer community; Query similarity;
   Summarization
ID SYSTEMS
AB Health community forums are a kind of online platform to discuss various matters related to management of illness. People are increasingly searching for answers online, particularly when they are diagnosed with cancer like life-threatening diseases. People seek suggestions or advice through these platforms to make decisions during their treatments. However, locating the correct information or similar people is often a great challenge for them. In this scenario, this paper proposes an answer recommendation system in an online breast cancer community forum that provide guidance and valuable references to users while making decisions. The answer is the summary of already discussed topic in the forum, so that they do not need to go through all the answer posts which spans over multiple pages or initiate a thread once again. There are three phases for the answer recommendation system, including query similarity model to retrieve the past similar query, query-answer pair generation and answer recommendation. Query similarity model is employed by a Siamese network with Bi-LSTM architecture which could achieve an F1-score of 85.5%. Also, the paper shows the efficacy of transfer learning technique to generalize the model well in our breast cancer query-query pair data set. The query-answer pairs are generated by an extractive summarization technique that is based on an optimization algorithm. The effectiveness of the generated summary is evaluated based on a manually generated summary, and the result shows a ROUGE-1 score of 49%.
C1 [Athira, B.] Amrita Vishwa Vidyapeetham, Sch Comp, Deparment CS & IT, Kochi, India.
   [Idicula, Sumam Mary] Muthoot Inst Technol & Sci, Dept Comp Sci, Kochi, India.
   [Jones, Josette; Kulanthaivel, Anand] IUPUI, Biohlth Informat Dept, Indianapolis, IN 46202 USA.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Kochi; Indiana
   University System; Indiana University Indianapolis
RP Athira, B (corresponding author), Amrita Vishwa Vidyapeetham, Sch Comp, Deparment CS & IT, Kochi, India.
EM athiramalu@gmail.com; sumamdavid123@gmail.com; jofjones@iupui.edu;
   akulanth@iu.edu
RI Idicula, Sumam/KIH-5568-2024
OI Idicula, Sumam/0000-0001-7088-6909; Balakrishnan,
   Athira/0000-0001-7830-2461
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Alahmari N, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14063313
   [Anonymous], 2015, P 19 C COMP NAT LANG, DOI DOI 10.18653/V1/K15-1013
   [Anonymous], 2012, P 1 INT WORKSHOP REC
   Arora S, 2019, 5 INT C LEARN REPR I
   Asgari H, 2014, 2014 IRANIAN CONFERENCE ON INTELLIGENT SYSTEMS (ICIS)
   Badry RM, 2013, INT J COMPUT APPL, V81
   Balakrishnan A, 2021, HEALTH INFORM J, V27, DOI 10.1177/14604582211007537
   Baumel T, 2018, Arxiv, DOI arXiv:1801.07704
   Ben Abacha A, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3119-4
   Bhatia S, 2014, P 2014 C EMP METH NA
   Chali Y, 2018, P 10 ANN M FOR INF R, V21aAS28
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Elsweiler D, 2015, DRMS WORKSH
   Fan H, 2010, 21 AUSTR C INF SYST
   Gupta R, 2014, SEMEVAL COLING
   He YX, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2659
   Jones J, 2018, JMIR MED INF, V6, P22, DOI 10.2196/medinform.9162
   Karwa S, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT), P129, DOI 10.1109/ICIT.2014.28
   Kiros R, 2015, 29 ANN C NEURAL INFO, V28
   Le Quoc V., 2014, P INT C MACH LEARN I
   Lee J, 2020, arXiv
   Li M, 2019, 2019 IEEE INT C HEAL
   Lin C-Y, 2003, P LANG TECHN C HLT N
   McCreery CH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3458, DOI 10.1145/3394486.3412861
   Mirosevic S, 2019, EUR J CANCER CARE, V28, DOI 10.1111/ecc.13060
   Mueller J, 2016, AAAI CONF ARTIF INTE, P2786
   Nasralah T., 2017, ONLINE HLTH RECOMMEN
   Nielsen LR, 2017, MED QUESTION ANSWER
   Pagliardini M., 2018, P C N AM CHAPT ASS C, P528, DOI [10.18653/v1/n18-1049, DOI 10.18653/V1/N18-1049]
   Rautray Rasmita, 2018, Applied Computing and Informatics, V14, P134, DOI 10.1016/j.aci.2017.05.003
   Rautray R, 2015, Intelligent Computing, Communication and Devices, P371
   Roitman H., 2010, P 1 ACM INT HLTH INF, P430, DOI DOI 10.1145/1882992.1883057
   Rokicki M, 2015, P UMAP, V15
   Sarkar Kamal, 2009, International Journal of Recent Trends in Engineering, V1, P200
   Sezgin E, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707249
   Shareghi Ehsan, 2008, Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology 2008. In Memory of Professor Yasuhiko Dote, P226, DOI 10.1145/1456223.1456272
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Verberne S, 2018, LANG RESOUR EVAL, V52, P461, DOI 10.1007/s10579-017-9389-4
   Verma P, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1082-4
   Wang J, 2016, 2016 IEEE INT C SERV
   WATERWORTH S, 1990, J ADV NURS, V15, P971, DOI 10.1111/j.1365-2648.1990.tb01953.x
   Wiesner M, 2014, INT J ENV RES PUB HE, V11, P2580, DOI 10.3390/ijerph110302580
   Xiaojuan Zhao, 2010, 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P968, DOI 10.1109/ICMTMA.2010.429
   Xu YC, 2019, Arxiv, DOI arXiv:1906.04382
   Yang CC, 2018, IEEE T COMPUT SOC SY, V5, P1049, DOI 10.1109/TCSS.2018.2879044
NR 46
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15477-9
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700008
PM 37362684
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Chen, YJ
   Xu, F
   Chen, GD
   Liang, ZQ
   Li, J
AF Chen, Yanjie
   Xu, Feng
   Chen, Guodong
   Liang, Zhiqiang
   Li, Jin
TI Point cloud 3D object detection method based on density
   information-local feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D Object detection; Point cloud; Density information; Local feature;
   Attention mechanism
AB Nowadays, three-dimensional (3D) point cloud is widely used in unmanned driving, high-precision mapping, robot grasping, mapping and virtual reality (VR) / augmented reality (AR), etc. Especially, many studies have focused on object detection through directly processing point cloud, but they don't take into account the uneven density of point clouds on the surface of object and lack of feature information. Inspired by this, we propose a new 3D object detection method based on density information-local feature fusion for point cloud. Firstly, the 3D coordinate features, high-dimensional features and density features of the point cloud are extracted through the backbone feature extraction network, and the local features of the point cloud are extracted through the sampling and grouping operation. Secondly, attention mechanism is used to encode the information between local features with density information. Then, the voting network is used to make the point clouds return to the center of the object. Finally, the point clouds are clustered and proposed to generate 3D bounding boxes. The proposed method can reduce the influence brought by the uneven sampling of point cloud and enhance the feature information of object, thereby improving the accuracy of 3D object detection. Specifically, the proposed method is validated on the SUNRGB-D and ScanNet datasets. Through various experiments, we confirm the proposed method's effectiveness and robustness to improve the performance of 3D object detection.
C1 [Chen, Yanjie; Xu, Feng; Chen, Guodong; Liang, Zhiqiang; Li, Jin] Southwest Univ Sci & Technol, Fac Informat & Engn, Mianyang 621000, Sichuan, Peoples R China.
   [Chen, Yanjie; Xu, Feng; Chen, Guodong; Liang, Zhiqiang; Li, Jin] Robot Technol Used Special Environm Key Lab Sichua, Mianyang 621000, Sichuan, Peoples R China.
C3 Southwest University of Science & Technology - China
RP Xu, F (corresponding author), Southwest Univ Sci & Technol, Fac Informat & Engn, Mianyang 621000, Sichuan, Peoples R China.; Xu, F (corresponding author), Robot Technol Used Special Environm Key Lab Sichua, Mianyang 621000, Sichuan, Peoples R China.
EM xufeng@swust.edu.cn
RI Chen, Guodong/AAP-9578-2021
OI Chen, Guodong/0000-0002-3294-4749
FU National Natural Science Foundation of China [61701421]; Longshan Young
   Scholars Support Program of SWUST [18LZX636]; National scholarship
   Foundation of China [CSC202108510088]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant No. 61701421), the Longshan Young Scholars
   Support Program of SWUST (Grant No. 18LZX636) and the National
   scholarship Foundation of China (Grant No. CSC202108510088).
CR Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI [10.1109/iccv.2019.00987, 10.1109/ICCV.2019.00987]
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Hou J, 2021, PROC CVPR IEEE, P15582, DOI 10.1109/CVPR46437.2021.01533
   Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455
   Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lahoud J, 2017, IEEE I CONF COMP VIS, P4632, DOI 10.1109/ICCV.2017.495
   Li HY, 2019, Arxiv, DOI arXiv:1903.11851
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liu Shu, 2017, IEEE INT C COMPUT VI, P3496
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   McCormac J, 2018, INT CONF 3D VISION, P32, DOI 10.1109/3DV.2018.00015
   Mutlu B, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58740
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2016, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2016.169
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang DZ, 2015, Proceedings of the Robotics: Science and Systems, V1, P10
   Xie Qizhe, 2020, SELF TRAINING NOISY, DOI 10.1109/cvpr42600.2020.01046
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Yue K, 2018, ADV NEURAL INF PROCE, V2018, P31
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 36
TC 1
Z9 1
U1 12
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15702-5
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200008
DA 2024-07-18
ER

PT J
AU Rani, KV
AF Rani, K. Vijila
TI Content based image retrieval using hybrid feature extraction and
   HWBMMBO feature selection method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content Based Satellite Image Retrieval (CBSIR); TOA (Top of
   Atmosphere); LST (Land Surface Temperature); Convolutional Neural
   Network (CNN); Adjusted Intensity Based Variant of Adaptive Histogram
   Equalization (AIBVAHE) filter; Hierarchy Weighted-Brownian Motion
   Monarch Butterfly Optimization Algorithm (HWBMMBO)
ID FIRE
AB Content Based Satellite Image Retrieval system is used for images processing, weather forecasting, climate monitoring, disaster management, forest fire detection etc. In this research forest, the fire retrieval approach is focused on protecting the forests from fire incidents which can generate an impact on natural resources and living organisms. This research proposed forest fire retrieval approach using proposed hybrid feature extraction technique and Hierarchy Weighted-Brownian Motion Monarch Butterfly Optimization Algorithm based feature selection approach. For application basis, both the proposed feature extraction and feature selection approach are implemented in forest fire retrieval system. The performances of the forest fire retrieval approach are analyzed in terms of precision, recall and accuracy. The efficiency of the proposed approach is evaluated by varying the features such as ground temperature, Top of Atmosphere, Land Surface Temperature, water vapour and intensity. The recall of the proposed fire retrieval approach is increased by 1.68%, 0.6%, 0.62%, 0.54% and precision by 0.82%, 0.41%, 0.75%, and 0.37% when compared with active fire detection, Convolutional Neural Network and hybrid intelligent algorithm respectively. The accuracy of the proposed fire retrieval approach is 98.91% better than the existing approaches.
C1 [Rani, K. Vijila] Udaya Sch Engn, Dept ECE, Kanyakumari, Tamil Nadu, India.
RP Rani, KV (corresponding author), Udaya Sch Engn, Dept ECE, Kanyakumari, Tamil Nadu, India.
EM vijilaranijournal@gmail.com
RI K, VIJILA RANI/ABI-1263-2020
OI K, VIJILA RANI/0000-0002-5007-1507
CR Alzu'bi A., 2019, INT J COMPUT SCI, V46, P1
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Baig F, 2020, IJST-T ELECTR ENG, V44, P99, DOI 10.1007/s40998-019-00237-z
   Benjamin SG, 2016, INT C EM TECHN TREND, P1
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhutto Amna, 2021, 2021 7th International Conference on Computer and Communications (ICCC), P917, DOI 10.1109/ICCC54389.2021.9674390
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Demir B, 2015, IEEE T GEOSCI REMOTE, V53, P2323, DOI 10.1109/TGRS.2014.2358804
   Di Biase V, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050741
   Franke J, 2012, IEEE J-STARS, V5, P1811, DOI 10.1109/JSTARS.2012.2202638
   Giftlin JGC, 2019, ICTACT J SOFT COMPUT, V10, P2015
   Hanamaraddi Priyadarshini M, 2016, IJITR, V4, P2695
   Khatami A, 2017, EXPERT SYST APPL, V68, P69, DOI 10.1016/j.eswa.2016.09.021
   Kumar SS, 2018, INT J DIGIT EARTH, V11, P154, DOI 10.1080/17538947.2017.1391341
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Nair LR, 2021, J AMB INTEL HUM COMP, V12, P5917, DOI 10.1007/s12652-020-02139-z
   Nurmaini S., 2015, J INF PROCESS SYST, V11, P2015
   Rao SS., 2021, SN COMPUTER SCI, V2, P1, DOI [10.1007/s42979-021-00563-2, DOI 10.1007/S42979-021-00563-2]
   Srivastava D., 2015, Int. J. Comput. Eng. Manage., V18, P9
   Starovoitov V, 2008, MULTISPECTRAL IMAGE, P1
   Yo-Ping H., 2008, J SYST CYBERN INFORM, V6, P1
   Zarkasi A., 2017, COMPUT ENG APPL J, V6, P139
NR 24
TC 5
Z9 5
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47477
EP 47493
DI 10.1007/s11042-023-15716-z
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000988577200001
DA 2024-07-18
ER

PT J
AU Michalski, R
AF Michalski, Rafal
TI The influence of product digital visual presentation on purchase
   willingness: effects of roundedness axes and degree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital package perception; Visual processing; Roundedness axis;
   Electronic commerce; Marketing
ID PACKAGE DESIGN; ADVERTISING WORKS; PREFERENCES; PERCEPTION; IMPACT;
   SHAPE; COLOR; REAL; BOX
AB The research examines the influence of digital visual product package presentations on perceived purchase willingness. Subjects pairwise compared the graphical stimuli displayed on a computer monitor. Gathered purchase willingness preference weights were calculated by means of the Analytic Hierarchy Process technique. Two studies focused on the package edge roundedness effect applied along different axes are reported. The first one included the following factors: Roundedness axis defined on three levels (X, Y, Z) and Roundedness degree also specified on three levels (Small, Medium, Large). The second involved Roundedness type (two levels: All edges rounded, Only sides rounded - along one axis) and Roundedness degree (Tiny, Small, Medium, Large). Both package Roundedness axis and Roundedness degree influenced perception and purchase willingness. This research extends existing knowledge by presenting empirical evidence on how a variety of product digital forms influences visual perception and purchase willingness. The results deliver useful and detailed information for practitioners and the outcomes may be applied as guidelines for computer graphics designers preparing visual appearance for articles in electronic shops, websites, banners, or advertisements displayed in networked screens.
C1 [Michalski, Rafal] Wroclaw Univ Sci & Technol, Fac Management, 27 Wybrzeze Wyspianskiego, PL-50370 Wroclaw, Poland.
C3 Wroclaw University of Science & Technology
RP Michalski, R (corresponding author), Wroclaw Univ Sci & Technol, Fac Management, 27 Wybrzeze Wyspianskiego, PL-50370 Wroclaw, Poland.
EM rafal.michalski@pwr.edu.pl
RI Michalski, Rafał/D-7289-2011
OI Michalski, Rafał/0000-0002-0807-1925
FU Polish National Science Centre [2017/27/B/HS4/01876]
FX AcknowledgementsThis research was partially financially supported by
   Polish National Science Centre under Grant No. 2017/27/B/HS4/01876. The
   author thanks the anonymous reviewers for their constructive comments
   and suggestions on the previous versions of the paper.
CR ADOLPHS R, 1995, J NEUROSCI, V15, P5879
   Azzi A, 2012, PACKAG TECHNOL SCI, V25, P435, DOI 10.1002/pts.993
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   Bar M, 2007, NEUROPSYCHOLOGIA, V45, P2191, DOI 10.1016/j.neuropsychologia.2007.03.008
   Bar M, 2006, PSYCHOL SCI, V17, P645, DOI 10.1111/j.1467-9280.2006.01759.x
   Bar Moshe., 2008, J CONSUMER BEHAV, V7, P319, DOI [10.1002/cb.254, DOI 10.1002/CB.254]
   Becker L, 2011, FOOD QUAL PREFER, V22, P17, DOI 10.1016/j.foodqual.2010.06.007
   Berlyne D.E., 1960, CONFLICT AROUSAL CUR, P350, DOI DOI 10.1037/11164-000
   BERLYNE DE, 1976, INT J PSYCHOL, V11, P43, DOI 10.1080/00207597608247346
   BLOCH PH, 1995, J MARKETING, V59, P16, DOI 10.2307/1252116
   BOOTHROYD G, 1994, COMPUT AIDED DESIGN, V26, P505, DOI 10.1016/0010-4485(94)90082-5
   BURKE RR, 1992, J CONSUM RES, V19, P71, DOI 10.1086/209287
   Capelli S, 2021, J RETAIL CONSUM SERV, V61, DOI 10.1016/j.jretconser.2020.102061
   Chang TW, 2022, MULTIMED TOOLS APPL, V81, P14617, DOI 10.1007/s11042-022-12179-6
   Cheng ZD, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.812579
   Citrin AV, 2003, J BUS RES, V56, P915, DOI 10.1016/S0148-2963(01)00278-8
   Clement J, 2013, J RETAIL CONSUM SERV, V20, P234, DOI 10.1016/j.jretconser.2013.01.003
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cowley Don., 1991, UNDERSTANDING BRANDS
   Deng XY, 2009, J MARKETING RES, V46, P725, DOI 10.1509/jmkr.46.6.725
   Dichter E., 1957, PACKAGE LABEL
   Favier M, 2019, J RETAIL CONSUM SERV, V46, P11, DOI 10.1016/j.jretconser.2018.09.013
   Franck K., 1949, J CONSULT PSYCHOL, V13, P247
   Gal D, 2010, SOC PSYCHOL PERS SCI, V1, P291, DOI 10.1177/1948550610365003
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Ghee S, 1998, MECH ENG, V120, P60, DOI 10.1115/1.1998-JUN-1
   Ghodhbani H, 2022, MULTIMED TOOLS APPL, V81, P19967, DOI 10.1007/s11042-022-12802-6
   Gofman A, 2010, J CONSUM MARK, V27, P157, DOI 10.1108/07363761011027259
   Grobelny J, 2015, COMPUT HUM BEHAV, V43, P85, DOI 10.1016/j.chb.2014.10.036
   Ho N, 2018, MULTIMED TOOLS APPL, V77, P30651, DOI 10.1007/s11042-018-6216-x
   Jia H, 2020, J MARKETING, V84, P100, DOI 10.1177/0022242920925054
   Kalender M, 2018, MULTIMED TOOLS APPL, V77, P567, DOI 10.1007/s11042-016-4275-4
   Kang XM, 2014, INT J INTERACT DES M, V8, P121, DOI 10.1007/s12008-014-0220-9
   Kauppinen-Räisänen H, 2012, INT J PHARM HEALTHC, V6, P230, DOI 10.1108/17506121211259403
   Kauppinen-Räisänen H, 2010, MANAG RES REV, V33, P161, DOI 10.1108/01409171011015847
   Kayaert G, 2003, J NEUROSCI, V23, P3016
   Kim JG, 2012, NEUROIMAGE, V63, P1818, DOI 10.1016/j.neuroimage.2012.08.066
   Kirpes C, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5020029
   Kochhar S, 1996, COMPUT GRAPH FORUM, V15, P229, DOI 10.1111/1467-8659.1540229
   Koczkodaj WW, 1998, J STAT PLAN INFER, V69, P21, DOI 10.1016/S0378-3758(97)00131-6
   Krishna A, 2017, J RETAILING, V93, P43, DOI 10.1016/j.jretai.2016.12.002
   Lacoste-Badie S, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2019.102000
   Leake M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376519
   Li B, 2021, MULTIMED TOOLS APPL, V80, P9569, DOI 10.1007/s11042-020-10033-1
   Limon Y, 2009, J INT MARKETING, V17, P30, DOI 10.1509/jimk.17.1.30
   Littel S, 2013, EUR J MARKETING, V47, P198, DOI 10.1108/03090561311285510
   Liu JC, 2020, MULTIMED TOOLS APPL, V79, P18121, DOI 10.1007/s11042-020-08677-0
   Martins NC, 2022, MULTIMED TOOLS APPL, V81, P14749, DOI 10.1007/s11042-021-10971-4
   Michalski Rafal, 2020, Advances in Ergonomics in Design. Proceedings of the AHFE 2020 Virtual Conference on Ergonomics in Design. Advances in Intelligent Systems and Computing (AISC 1203), P24, DOI 10.1007/978-3-030-51038-1_4
   Michalski R, 2022, LECT NOTES COMPUT SC, V13321, P246, DOI 10.1007/978-3-031-05897-4_18
   MIDDLESTADT SE, 1990, ADV CONSUM RES, V17, P244
   Miranda BP, 2022, MULTIMED TOOLS APPL, V81, P14773, DOI 10.1007/s11042-021-11141-2
   NAJORK MA, 1995, IEEE T VIS COMPUT GR, V1, P175, DOI 10.1109/2945.468402
   Ohta H, 1999, PERCEPTION, V28, P505, DOI 10.1068/p2787
   Orth UR, 2010, J MARKET THEORY PRAC, V18, P23, DOI 10.2753/MTP1069-6679180102
   Orth UR, 2008, J MARKETING, V72, P64, DOI 10.1509/jmkg.72.3.64
   Pelet JÉ, 2020, J RETAIL CONSUM SERV, V55
   Pham B, 1999, P SOC PHOTO-OPT INS, V3644, P364, DOI 10.1117/12.348457
   Plonka M, 2023, INT J INF TECH DECIS, V22, P1551, DOI 10.1142/S0219622022500766
   Raghubir P, 2006, J MARKETING, V70, P95, DOI 10.1509/jmkg.70.2.95
   Reber R, 2004, PERS SOC PSYCHOL REV, V8, P364, DOI 10.1207/s15327957pspr0804_3
   Reimann M, 2010, J CONSUM PSYCHOL, V20, P431, DOI 10.1016/j.jcps.2010.06.009
   Robertson GordonL., 2006, FOOD PACKAGING PRINC
   Roggeveen AL, 2015, J MARKETING, V79, P34, DOI 10.1509/jm.13.0521
   Saaty T.L, 1980, Advanced Optimization and Decision-Making Techniques in Textile Manufacturing, DOI DOI 10.1201/9780429504419-2
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Sample KL, 2020, J ACAD MARKET SCI, V48, P405, DOI 10.1007/s11747-019-00684-4
   Silvia P. J., 2009, EMPIR STUD ARTS, V27, P25, DOI [10.2190/EM.27.1.b, DOI 10.2190/EM.27.1.B, https://doi.org/10.2190/EM.27.1.b]
   Simmonds G, 2017, FOOD QUAL PREFER, V62, P340, DOI 10.1016/j.foodqual.2016.11.010
   Spence A., 2004, International Journal of Clothing Science and Technology, V16, P51, DOI 10.1108/09556220410520351
   Sung B, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2020.102034
   Suzianti A, 2015, INT J TECHNOL, V6, P659
   Tepe T, 2023, MULTIMED TOOLS APPL, V82, P14307, DOI 10.1007/s11042-022-13794-z
   Togawa T, 2019, J RETAILING, V95, P204, DOI 10.1016/j.jretai.2019.11.001
   Tsai CY, 2020, MULTIMED TOOLS APPL, V79, P31981, DOI 10.1007/s11042-020-09584-0
   Varlamis I, 2004, MULTIMED TOOLS APPL, V22, P5, DOI 10.1023/B:MTAP.0000008657.07799.b0
   VAUGHN R, 1980, J ADVERTISING RES, V20, P27
   VAUGHN R, 1986, J ADVERTISING RES, V26, P57
   Wang CCL, 2005, COMPUT AIDED DESIGN, V37, P675, DOI 10.1016/j.cad.2004.08.007
   Westerman SJ, 2013, FOOD QUAL PREFER, V27, P8, DOI 10.1016/j.foodqual.2012.05.007
   Whalen PJ, 1998, J NEUROSCI, V18, P411
   Zajonc RB, 2001, CURR DIR PSYCHOL SCI, V10, P224, DOI 10.1111/1467-8721.00154
   Zhang YL, 2006, PERS SOC PSYCHOL B, V32, P794, DOI 10.1177/0146167206286626
NR 83
TC 2
Z9 2
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15786-z
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Nayak, D
   Ray, KB
   Kar, T
   Kwan, C
AF Nayak, D.
   Ray, K. B.
   Kar, T.
   Kwan, Chiman
TI A novel saliency based image compression algorithm using low complexity
   block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BTC; Saliency Feature extraction; Quantization
ID SCHEME
AB Image features are better captured by saliency values, which can be deployed for subsequent high level processing at a reduced computational complexity. In this paper, we proposed a novel algorithm that integrates saliency and a low complexity block truncation coding (LCBTC) in a single framework. The proposed LCBTC framework has great potential in low power hardware implementation. The two phases of the algorithm are computation of the saliency strength of image blocks based on the probability of the pixels followed by a low complex Block Truncation coding method.The blocks having high saliency value are encoded using LCBTC and blocks having low saliency value are encoded using mean value of the blocks, thereby increasing the computational efficiency than the traditional BTC method. The efficacy of the proposed algorithm is evaluated based on objective fidelity criteria considering SSIM, QSSIM, FSIM, PSNR and bpp as well as subjective evaluation. The proposed method outperformed recent and baseline BTC methods in terms of objective and subjective measures. Proposed method shows significant improvements in performance over traditional BTC and recent approaches at lower bpp. It achieved an average PSNR of 33.03 dB and an average FSIM of 0.92,QSSIM of 0.91 and SSIM of 0.90 at a bpp of 1.65 and better perceptual quality with lower visual artifacts.
C1 [Nayak, D.; Ray, K. B.; Kar, T.] KIIT Deemed Univ, Sch Elect Engn, Bhubaneswar, India.
   [Kwan, Chiman] Signal Proc Inc, Rockville, MD USA.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Nayak, D (corresponding author), KIIT Deemed Univ, Sch Elect Engn, Bhubaneswar, India.
EM dibyalekhanayak@gmail.com
RI Nayak, Dibyalekha/JRY-1815-2023
CR Ahmad N, 2019, ADV INTELL SYST, V697, P597, DOI 10.1007/978-981-13-1822-1_56
   [Anonymous], 2016, 2016 INT C SIGNAL PR
   [Anonymous], KODAK LOSSLESS TRUE
   Boucetta Aldjia, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P476, DOI 10.1007/978-3-642-31254-0_54
   Chen SL, 2018, J REAL-TIME IMAGE PR, V14, P803, DOI 10.1007/s11554-015-0553-z
   Chen SL, 2017, IEEE SENS J, V17, P4999, DOI 10.1109/JSEN.2017.2712908
   Chen TS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020619
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho J, 2021, IEEE ACCESS, V9, P113213, DOI 10.1109/ACCESS.2021.3102235
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Chuang JC, 2020, MULTIMED TOOLS APPL, V79, P28189, DOI 10.1007/s11042-020-09325-3
   Daga RRM, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P178, DOI 10.1109/SIPROCESS.2017.8124528
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   El Aakif M., 2011, 2011 Faible Tension Faible Consommation (FTFC 2011) [2011 Low Voltage, Low Power Consumption], P63, DOI 10.1109/FTFC.2011.5948920
   FRANTI P, 1995, IEEE T COMMUN, V43, P1677, DOI 10.1109/26.380217
   Guo JM, 2011, IEEE SIGNAL PROC LET, V18, P694, DOI 10.1109/LSP.2011.2168207
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Jisha B., 2013, IJSRD INT J SCI RES, V1, P2321
   Kanwal M, 2022, MULTIMED TOOLS APPL, V81, P16243, DOI 10.1007/s11042-022-12165-y
   Kolaman A, 2012, IEEE T IMAGE PROCESS, V21, P1526, DOI 10.1109/TIP.2011.2181522
   Kumar R, 2022, MULTIMED TOOLS APPL, V81, P20817, DOI 10.1007/s11042-022-12634-4
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P903, DOI [10.1109/SPIN.2019.8711635, 10.1109/spin.2019.8711635]
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Mathews J, 2015, COMPUT ELECTR ENG, V43, P169, DOI 10.1016/j.compeleceng.2015.01.001
   Messaoudi A, 2019, SIGNAL IMAGE VIDEO P, V13, P1441, DOI 10.1007/s11760-019-01492-7
   Rahul K, 2018, IET IMAGE PROCESS, V12, P1142, DOI 10.1049/iet-ipr.2017.0554
   Saif S, 2006, 6TH INTERNATIONAL WORKSHOP ON SYSTEM-ON-CHIP FOR REAL-TIME APPLICATIONS, PROCEEDINGS, P169, DOI 10.1109/IWSOC.2006.348230
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Nguyen T, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P233, DOI 10.1109/PCS.2012.6213335
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang XY, 2009, FRACTALS, V17, P109, DOI 10.1142/S0218348X09004247
   Wang XY, 2013, NONLINEAR DYNAM, V73, P347, DOI 10.1007/s11071-013-0790-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A. G., 1997, USC-SIPI Report, V315
   WU YY, 1991, IEEE T COMMUN, V39, P1283, DOI 10.1109/26.99132
   Xiang ZY, 2019, MULTIMED TOOLS APPL, V78, P7895, DOI 10.1007/s11042-018-6030-5
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang M., 2014, Math. Probl. Eng, V2014
   Zhang Y, 2012, NONLINEAR ANAL-REAL, V13, P106, DOI 10.1016/j.nonrwa.2011.07.017
   Zhou YM, 2018, INT CONF SIGN PROCES, P450, DOI 10.1109/ICSP.2018.8652455
NR 40
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47367
EP 47385
DI 10.1007/s11042-023-15694-2
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985244300003
DA 2024-07-18
ER

PT J
AU Singh, R
   Rana, PS
   Jindal, N
AF Singh, Rakesh
   Rana, Prashant Singh
   Jindal, Neeru
TI A novel approach to identify kink in 2D map using the spline technique
   on real map data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road; Maps; Kink; Spline
ID GENERATION; VEHICLES
AB A Map is a collection of linear and polygonal geometry lines in 2D space. In an actual Map, these lines act as unique features such as roads, carto, points of interest .etc. This paper focuses on providing a solution to one of the basic, though practical, open problems; There is a need to identify kinks in forming a Road in 2D Maps, which is the linear collection of the lines. The kink in the road is inversely proportional to the number of lines presenting them, which means more number of lines less is the kink. In practical cases, there is a balance between them, which results in the kink on specific points. This paper proposed a technique to identify those points by spline interpolation with length manipulation, where the difference in the interpolated lines with points is calculated, and the threshold is defined accordingly. The novelty of the work is that no practical technique identifies kink in the Real Map data, which is deterministic and can be used with ease as the best knowledge of the authors. With the threshold of 10 cm, for Frankfurt and USA, the identifications were 91 and 83 per cent, respectively.
C1 [Singh, Rakesh; Rana, Prashant Singh] Thapar Inst Engn & Technol, Dept Comp Sci, Patiala, Punjab, India.
   [Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Singh, R (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci, Patiala, Punjab, India.
EM f25527180@gmail.com; prashant.singh@thapar.edu; neeru.jindal@thapar.edu
OI Singh, Rakesh/0000-0003-4125-638X
CR Andrade DC, 2019, IEEE T INTELL TRANSP, V20, P1497, DOI 10.1109/TITS.2018.2856361
   Arvo J., 2013, Graphics Gems II
   Avsar E, 2022, MULTIMED TOOLS APPL, V81, P6653, DOI 10.1007/s11042-021-11804-0
   Berglund T, 2010, IEEE T AUTOM SCI ENG, V7, P167, DOI 10.1109/TASE.2009.2015886
   Chang SR, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60718
   Dai JG, 2020, IEEE J-STARS, V13, P227, DOI 10.1109/JSTARS.2019.2955277
   De Bock J, 2023, MULTIMED TOOLS APPL, V82, P8359, DOI 10.1007/s11042-022-13552-1
   Barros TAD, 2018, IEEE ACCESS, V6, P26011, DOI 10.1109/ACCESS.2018.2825607
   Elbanhawi M, 2016, IEEE T INTELL TRANSP, V17, P406, DOI 10.1109/TITS.2015.2477355
   Gao S, 2020, IEEE INTERNET THINGS, V7, P2005, DOI 10.1109/JIOT.2019.2960827
   Hasircioglu I., 2008, GECCO 08, P1499, DOI DOI 10.1145/1389095.1389386
   Huang C, 2020, IEEE T SUSTAIN ENERG, V11, P1309, DOI 10.1109/TSTE.2019.2923732
   Jo K, 2014, IEEE T INTELL TRANSP, V15, P925, DOI 10.1109/TITS.2013.2291395
   Kano H, 2018, P AMER CONTR CONF, P1963, DOI 10.23919/ACC.2018.8431703
   Khaldi B, 2022, IEEE T COGN DEV SYST, V14, P565, DOI 10.1109/TCDS.2021.3054997
   Li XH, 2016, IEEE-ASME T MECH, V21, P740, DOI 10.1109/TMECH.2015.2493980
   Liu D, 2019, IEEE T MED IMAGING, V38, P2533, DOI 10.1109/TMI.2019.2905245
   Maekawa T, 2010, COMPUT AIDED DESIGN, V42, P350, DOI 10.1016/j.cad.2009.12.007
   NELSON W, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P1260, DOI 10.1109/ROBOT.1989.100153
   Nikolos IK, 2007, STUD COMPUT INTELL, V70, P77
   Peters J, 2003, LECT NOTES COMPUT SC, V2768, P297
   Piegl LA, 2000, ENG COMPUT, V16, P73, DOI 10.1007/s003660050038
   Richards A., AIAA GUIDANCE NAVIGA, DOI [10.2514/6.2002-4588, DOI 10.2514/6.2002-4588]
   Schreier M, 2016, IEEE T INTELL TRANSP, V17, P367, DOI 10.1109/TITS.2015.2472965
   Singh R, 2020, MULTIMED TOOLS APPL, V79, P30785, DOI 10.1007/s11042-020-09558-2
   Strelkovskaya Irina, 2022, 2022 IEEE 16th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering (TCSET), P602, DOI 10.1109/TCSET55632.2022.9766876
   Sudhakara Priyanka, 2018, 2018 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS). Proceedings, P64, DOI 10.1109/ICPECTS.2018.8521614
   Sun PP, 2019, IEEE ACCESS, V7, P29623, DOI 10.1109/ACCESS.2019.2902170
   Suzuki T, 2018, IEEE T INTELL VEHICL, V3, P547, DOI 10.1109/TIV.2018.2874532
   Tounsi M, 1996, MATH COMPUT SIMULAT, V41, P367, DOI 10.1016/0378-4754(95)00085-2
   Dung VT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173857
   Wang WC, 2022, MULTIMED TOOLS APPL, V81, P39873, DOI 10.1007/s11042-022-12300-9
   Zeng DQ, 2019, IEEE ACCESS, V7, P165365, DOI 10.1109/ACCESS.2019.2953510
   Zygmunt M, 2020, ISPRS INT GEO-INF, V9, DOI 10.3390/ijgi9010027
NR 34
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46387
EP 46401
DI 10.1007/s11042-023-15387-w
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985378600004
DA 2024-07-18
ER

PT J
AU Fu, ZH
   Wang, SS
   Zhao, X
   Long, SF
   Wang, BL
AF Fu, Zihao
   Wang, Shengsheng
   Zhao, Xin
   Long, Sifan
   Wang, Bilin
TI Causal view mechanism for adversarial domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Transfer learning; Deep learning; Causal inference;
   Image classification
AB Studies show that the challenge for adversarial domain adaptation is learning domain-invariant representations and alleviating the domain gap. However, the construction of domain-invariant representations suppresses the class-level structure information, and the pursuit of class-level structure information distorts the constructed domain-invariant representations. Till present, it still has difficulty to capture the domain-invariant representations while preserving the class-level structure information in the adversarial training process explicitly. In this paper, we propose a Causal view Mechanism for adversarial Domain Adaptation (CMDA). Firstly, a causal effect model of adversarial DA is proposed and reveals the influence of potential confounders in the adversarial training process. Then, CMDA is proposed to disentangle the domain-specific representations into multiple underlying factors and filter out irrelevant confounding characteristics. Specifically, CMDA capture the desired domain-invariant representations by subtracting the domain-level and class-level confounding characteristics. CMDA not only could preserve the class-level structure information to reduce classification error, but also improve transferability simultaneously. Finally, experiments carried out on Office-31, Office-Home, and VisDA-2017 datasets show that our CMDA method presents strong competition among some recent domain adaptation methods, and the average accuracies achieve 71.3%, 89.3% and 76.1% respectively.
C1 [Fu, Zihao; Wang, Shengsheng; Zhao, Xin; Long, Sifan; Wang, Bilin] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Fu, Zihao; Wang, Shengsheng; Zhao, Xin; Long, Sifan; Wang, Bilin] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Wang, SS (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM yeahfzh@yeah.net; wss@jlu.edu.cn; focusxin@outlook.com;
   summitlsf@outlook.com; blwang19@mails.jlu.edu.cn
RI Long, Sifan/JED-7733-2023
OI Long, Sifan/0000-0001-7060-1133
FU Innovation Capacity Construction Project of Jilin Province Development
   and Reform Commission [2021FGWCXNLJSSZ10,2019C053-3]; National Key
   Research and Development Program of China [2020YFA0714103]; Fundamental
   Research Funds for the Central Universities
FX AcknowledgementsThis work is supported by the Innovation Capacity
   Construction Project of Jilin Province Development and Reform
   Commission(2021FGWCXNLJSSZ10,2019C053-3), the National Key Research and
   Development Program of China (No. 2020YFA0714103) and the Fundamental
   Research Funds for the Central Universities, JLU.
CR Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Chen MH, 2020, AAAI CONF ARTIF INTE, V34, P3521
   Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guangrui Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P440, DOI 10.1007/978-3-030-58568-6_26
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZH, 2020, MULTIMED TOOLS APPL, V79, P33973, DOI 10.1007/s11042-020-08877-8
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Jing MM, 2021, IEEE T CYBERNETICS, V51, P3390, DOI 10.1109/TCYB.2020.2974106
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JJ, 2021, IEEE T PATTERN ANAL, V43, P3918, DOI 10.1109/TPAMI.2020.2991050
   Li JJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P747, DOI 10.1145/3343031.3350902
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li JY, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114490
   Li S, 2018, IEEE T IMAGE PROCESS, V27, P4260, DOI 10.1109/TIP.2018.2839528
   Liu H, 2019, 36 INT C MACHINE LEA, V97
   Liu HJ, 2021, MULTIMED TOOLS APPL, V80, P29321, DOI 10.1007/s11042-021-11139-w
   Liu MY, 2017, ADV NEUR IN, V30
   Long M, 2017, ARXIV
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Niu YL, 2021, PROC CVPR IEEE, P12695, DOI 10.1109/CVPR46437.2021.01251
   Pearl J, 2016, J CAUSAL INFERENCE, V4, DOI 10.1515/jci-2016-0021
   Pearl Judea, 2000, Models, reasoning and inference, P19
   Peng X., 2017, ARXIV
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Qi Jiaxin, 2020, CVPR
   Rubin Donald B, 2019, Biostat. Epidemiol., V3, P140, DOI DOI 10.1080/24709360.2019.1670513
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Shuhao Cui, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12452, DOI 10.1109/CVPR42600.2020.01247
   Sugiyama M, 2007, J MACH LEARN RES, V8, P985
   Sur C, 2019, MULTIMED TOOLS APPL, V78, P32187, DOI 10.1007/s11042-019-08021-1
   Tan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10757, DOI 10.1109/CVPR42600.2020.01077
   Tang K, 2020, C NEURAL INFORM PROC
   Tang K. H., 2021, ARXIV
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wei GQ, 2021, PROC CVPR IEEE, P16638, DOI 10.1109/CVPR46437.2021.01637
   Xie Y, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105222
   Yang X, 2023, IEEE T PATTERN ANAL, V45, P12996, DOI 10.1109/TPAMI.2021.3121705
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yue ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8579, DOI 10.1109/ICCV48922.2021.00848
   Zhang Q, 2019, Proc. Adv. Neural Inf. Process. Syst., V32, P1
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 53
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47347
EP 47366
DI 10.1007/s11042-023-15683-5
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800001
DA 2024-07-18
ER

PT J
AU Rathika, S
   Gayathri, R
AF Rathika, S.
   Gayathri, R.
TI An ensemble of monarchy butterfly optimization based encryption
   techniques on image steganography for data hiding in thermal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Thermal images; Security; Optimal pixel selection;
   Monarchy butterfly optimization algorithm
ID CRYPTANALYSIS; ALGORITHM
AB Information security provides a process of hiding secret information to protect the sensitive data from attackers. To achieve secure data transmission, data hiding and steganographic techniques are being developed. Image steganography is commonly employed in several areas such as telecommunication, mobile computing, online voting system, image retrieval, and privacy of patient details. Furthermore, encryption technique acts as an integral part to save the original data from illegal access. In this view, this paper presents a new monarchy butterfly optimization algorithm-based encryption with image steganography for hiding information in thermal images (MBOA-ESTI). The presented MBOA-ESTI method includes various phases of operations like ensemble of encryption, channel extraction, optimal pixel selection, embedded process, and decomposition. Then, the encryption of the images takes place by using three encryption systems Rubik's Cube Principle (RCP), Henon map (HM), and improved chaotic map (ICM). In addition, the presented MBOA-ESTI model involves multilevel discrete wavelet transform (DWT) based image decomposition process. In addition, the optimum pixel selection technique is performed using MBOA over the encrypted R, G, and B channels. For investigating the outcome of the MBOA-ESTI technique, wide-ranging experimentation was performed using MATLAB R2014a tool and the outcomes are examined interms of discrete performance measures. The experimental outcomes pointed out that the MBOA-ESTI model has resulted in an average mean square error (MSE) of 0.093, peak signal to noise ratio (PSNR) of 58.46dB, and normalized cross-correlation (NCC) of 0.997.
C1 [Rathika, S.; Gayathri, R.] Annamalai Univ, Dept Elect & Commun Engn, Chidambaram 608002, Tamil Nadu, India.
C3 Annamalai University
RP Rathika, S (corresponding author), Annamalai Univ, Dept Elect & Commun Engn, Chidambaram 608002, Tamil Nadu, India.
EM rathikaresearchscholar@gmail.com; drrgayathriau@gmail.com
RI R, Gayathri/AGZ-2078-2022
OI /0000-0003-2060-3629
CR Ambika, 2022, International Journal of Computers and Applications, P1140, DOI 10.1080/1206212X.2019.1692442
   Amuthadevi C, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02724-2
   Atee HA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170329
   Daniel E, 2017, BIOMED SIGNAL PROCES, V34, P36, DOI 10.1016/j.bspc.2017.01.003
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   Duan XT, 2018, CMC-COMPUT MATER CON, V55, P483, DOI 10.3970/cmc.2018.01798
   Hashim FA, 2021, APPL INTELL, V51, P1531, DOI 10.1007/s10489-020-01893-z
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Kamil S, 2021, IEEE ACCESS, V9, P168981, DOI 10.1109/ACCESS.2021.3133672
   Kaur A., 2015, INT J COMPUT APPL, V122, P18
   Li M, 2019, IEEE ACCESS, V7, P145798, DOI 10.1109/ACCESS.2019.2945578
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Mandal PC, 2022, MULTIMED TOOLS APPL, V81, P5325, DOI 10.1007/s11042-021-11605-5
   Manjunatha Reddy HS., 2009, INT J COMPUTER SCI S, V4, P462
   Melman Anna, 2021, 2021 XVII International Symposium "Problems of Redundancy in Information and Control Systems" (REDUNDANCY), P49, DOI 10.1109/REDUNDANCY52534.2021.9606459
   Priyanka BG, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1351, DOI 10.1109/IC3I.2014.7019666
   Rajput SS, 2019, APPL INTELL, V49, P1324, DOI 10.1007/s10489-018-1340-x
   Rathika S, 2021, MATER TODAY-PROC, V46, P10164, DOI 10.1016/j.matpr.2020.10.874
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Sun L, 2019, COMPLEXITY, DOI 10.1155/2019/4182148
   Teja JD., 2017, INT J AD HOC UBIQ CO, V2, P104
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
   Vatsa M, 2006, IEICE ELECTRON EXPR, V3, P23, DOI 10.1587/elex.3.23
   Vijayan DS, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02666-9
   Wang RZ, 2000, ELECTRON LETT, V36, P2069, DOI 10.1049/el:20001429
   Wang S, 2008, IEEE COMMUN LETT, V12, P149, DOI 10.1109/LCOMM.2008.071307
   Zhou ZL, 2018, IEEE ACCESS, V6, P15021, DOI 10.1109/ACCESS.2018.2811722
NR 30
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47235
EP 47252
DI 10.1007/s11042-023-15693-3
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984658600001
DA 2024-07-18
ER

PT J
AU Prasad, SA
   Mary, L
   Koshy, BI
AF Prasad, S. Anuja
   Mary, Leena
   Koshy, Bino I.
TI Detection and classification of vehicles using audio visual cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle classification; Short Time Energy (STE); Speeded Up Robust
   Feature (SURF); Convolutional Neural Network (CNN); Single Shot Multibox
   Detector (SSD)
ID MULTIPLE VEHICLE; TRACKING; DEEP; SYSTEM
AB This paper presents a software-based vehicle detection and classification system capable of classifying traffic into four different classes, namely two-wheeler, three-wheeler, car, and heavy motor vehicle. It uses traffic video collected by a camera mounted on a vehicle parked by the side of a two-lane undivided road. Video frames containing vehicles are identified, both by automatically detecting peaks in Short Time Energy (STE) of the corresponding audio signal and adaptive background subtraction of the video frames, followed by blob subtraction and morphological operations. This may result in multiple images containing the same vehicle, which is eliminated using a Speeded Up Robust Feature (SURF) matching algorithm. Classification of resulting images is attempted in three different ways. In System 1, an SVM trained with explicit features such as Histogram of Gradient (HOG), Local Binary Pattern (LBP), and KAZE are used as a classifier and their performance is compared. In System 2, the task is performed using a deep neural network namely Single Shot Multibox Detector (SSD). The accuracy of the SSD system deteriorates when it is tested using video collected by another camera in a different environment. This issue is addressed in System 3 by retraining the SSD in the new set of images, without the use of manually labeled images. The effectiveness of all the proposed systems is validated using the collected heterogeneous traffic data.
C1 [Prasad, S. Anuja] APJ Abdul Kalam Technol Univ, Rajiv Gandhi Inst Technol, Dept Elect & Commun Engn, Kottayam 686501, Kerala, India.
   [Mary, Leena] Rajiv Gandhi Inst Technol, Dept Elect & Commun Engn, Kottayam 686501, Kerala, India.
   [Koshy, Bino I.] Amal Jyothi Coll Engn, Dept Civil Engn, Kanjirappally 686518, Kerala, India.
C3 Rajiv Gandhi Institute of Technology Kottayam; Rajiv Gandhi Institute of
   Technology Kottayam
RP Prasad, SA (corresponding author), APJ Abdul Kalam Technol Univ, Rajiv Gandhi Inst Technol, Dept Elect & Commun Engn, Kottayam 686501, Kerala, India.
EM anujashajan@rit.ac.in; leena.mary@rit.ac.in; binoikoshy@amaljyothi.ac.in
OI Koshy, Bino/0000-0002-6199-0939
FU Transportation Research Center, College of Engineering,
   Thiruvananthapuram (Government of Kerala), India
FX The authors would like to thank the Transportation Research Center,
   College of Engineering, Thiruvananthapuram (Government of Kerala),
   India, for the support provided for this work.
CR Adu-Gyamfi YO, 2017, TRANSPORT RES REC, P113, DOI 10.3141/2645-13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Almusaylim ZA, 2018, 2018 4 INT C COMPUTE, P1, DOI [DOI 10.1109/ICCOINS.2018.8510588, 10.1109/iccoins.2018.8510588]
   Arróspide J, 2014, SCI WORLD J, DOI 10.1155/2014/196251
   Ban XJ, 2013, VEHICLE CLASSIFICATI, P164
   Barth A, 2009, IEEE T INTELL TRANSP, V10, P560, DOI 10.1109/TITS.2009.2029643
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126
   Chellappa R, 2004, IEEE INT C AC SPEECH, V3, P790
   Chen YF, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P754, DOI 10.1109/ICNC.2015.7378085
   Chen ZZ, 2012, IEEE INT C INTELL TR, P951, DOI 10.1109/ITSC.2012.6338852
   Chen ZZ, 2011, IEEE INT C INTELL TR, P74, DOI 10.1109/ITSC.2011.6083075
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Cheung SY, 2005, TRANSPORT RES REC, P173, DOI 10.3141/1917-19
   Chung J, 2018, IEEE T INTELL TRANSP, V19, P1670, DOI 10.1109/TITS.2017.2732029
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Czapla Z, 2016, ZESZYTY NAUKOWE TRAN, P11
   DANIEL C, 2016, INT C NEXT GENERATIO, P1
   Dargahi F, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2014), P1, DOI 10.1109/SCC.2014.10
   Das J, 2017, IEEE INT C SIGNAL PR, P1
   Dedeoglu Y, 2008, MULTIMED SYST APPL, P143, DOI 10.1007/978-0-387-76316-3_6
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang JJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P719
   George J., 2013, International Journal on Soft Computing, V4, P29, DOI [10.5121/ijsc.2013.4203, DOI 10.5121/IJSC.2013.4203]
   George J, 2013, 2013 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION AND COMPUTING (ICCC), P436, DOI 10.1109/ICCC.2013.6731694
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoiem D, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383045
   Hu QC, 2017, IEEE T INTELL TRANSP, V18, P3147, DOI 10.1109/TITS.2017.2679114
   Humayun M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040510
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P939
   Kim HT, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P1342, DOI 10.1109/ICCAS.2013.6704164
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li SG, 2014, IET INTELL TRANSP SY, V8, P164, DOI 10.1049/iet-its.2012.0099
   Li Suhao, 2018, Procedia Computer Science, V131, P564, DOI 10.1016/j.procs.2018.04.281
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe G., 2004, Int. J, V2, P2
   Ma XX, 2005, IEEE I CONF COMP VIS, P1185
   Ma ZY, 2019, IEEE T VEH TECHNOL, V68, P3224, DOI 10.1109/TVT.2019.2899972
   Mian ZF, 2013, US Patent, Patent No. [8,478,480, 8478480]
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mishra PK, 2013, INT J COMPUT APPL, V71
   Mithun NC, 2012, IEEE T INTELL TRANSP, V13, P1215, DOI 10.1109/TITS.2012.2186128
   Nooralahiyan AY, 1998, MATH COMPUT MODEL, V27, P205, DOI 10.1016/S0895-7177(98)00060-0
   Ntalampiras S, 2018, IEEE TETCI, V2, P129, DOI 10.1109/TETCI.2017.2783340
   Paszke A., 2016, ARXIV160602147
   Piyush P., 2016, 2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN), P726, DOI 10.1109/SPIN.2016.7566793
   Prasad SA, 2019, P INT C COMP INT DAT, P1, DOI DOI 10.1109/INCOS45849.2019.8951417
   Qiong W, 2017, DESTECH T ENG TECHNO, P22
   Rachmadi RF, 2018, J VIS COMMUN IMAGE R, V56, P265, DOI 10.1016/j.jvcir.2018.09.021
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Renganathan Dhanalakshmi, 2018, 2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), P1979, DOI 10.1109/RTEICT42901.2018.9012411
   Russakovsky O, 2013, P INT C COMP VIS ICC, P1
   Selbes B, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sermanet P., 2013, ARXIV
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Shvai N, 2020, IEEE T INTELL TRANSP, V21, P1288, DOI 10.1109/TITS.2019.2906821
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sivaraman S, 2012, IEEE INT C INTELL TR, P1519, DOI 10.1109/ITSC.2012.6338886
   Song KT, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P647
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang CC, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P416, DOI 10.1109/IVS.2003.1212947
   Wang T, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P440, DOI 10.1109/AVSS.2012.47
   Wei Liu, 2007, Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, P252
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Zhang RL, 2012, PROCEDIA ENGINEER, V29, P1351, DOI 10.1016/j.proeng.2012.01.139
NR 75
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44087
EP 44106
DI 10.1007/s11042-023-14868-2
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979936300003
DA 2024-07-18
ER

PT J
AU Ouali, I
   Ben Halima, M
   Wali, A
AF Ouali, Imene
   Ben Halima, Mohamed
   Wali, Ali
TI An augmented reality for an arabic text reading and visualization
   assistant for the visually impaired
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text visualization; Text to speech; Text detection; Text recognition;
   Arabic; Augmented reality; Deep learning; Visually impaired
ID RECOGNITION
AB Text, as one of humanity's most influential innovations, has played an important role in shaping our lives. Reading a text is a difficult task due to several reasons factors, such as luminosity, text orientation, writing style, and very light colors. However, the visually impaired, on the other hand, have difficulty reading a text in all of these situations. In particular, a handwritten text is more difficult to read than a digital text due to the different forms and styles of the handwriting of different writers or, sometimes, of the same writer. Therefore, they would benefit from a device or a system to help them to solve this problem and improve their quality of life. Arabic language recognition and identification is a very difficult task because of diacritics such as consonant score, tashkil, and others. In this context, we propose a recognition and identification system for Arabic Handwritten Texts with Diacritics (AHTD) based on deep learning by using the convolutional neural network. Text images are trained, tested, and validated with our Arabic Handwritten Texts with a Diacritical Dataset (AHT2D). Then, the recognized text is enhanced with augmented reality technology and produced as a 2D image. Finally, the recognized text is converted into an audio output using AR technology. Voice output and visual output are given to the visually impaired user. The experimental results show that the proposed system is robust, with an accuracy rate of 95%.
C1 [Ouali, Imene; Ben Halima, Mohamed; Wali, Ali] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Ouali, I (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax, Tunisia.
EM imene.ouali@enis.tn; mohamed.benhlima@isims.usf.tn;
   ali.wali@isims.usf.tn
RI Wali, Ali/J-7961-2012; BenHalima, Mohamed/AAD-4725-2021
OI Wali, Ali/0000-0002-8423-7923; BenHalima, Mohamed/0000-0002-3224-2552
CR Abbes R, 2008, P JADT, P12
   Abuzaraida MA, 2021, INT J ELECT COMPUTER, V11
   Almansari OA, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON MECHATRONICS ENGINEERING (ICOM), P107, DOI 10.1109/icom47790.2019.8952035
   Almisreb AA, 2022, PERTANIKA J SCI TECH, V30
   Alrobah N, 2021, IEEE ACCESS, V9, P87058, DOI 10.1109/ACCESS.2021.3087647
   Andriyandi AP., 2020, TELKOMNIKA (telecommunication Computing Electronics and Control), V18, P208, DOI [10.12928/TELKOMNIKA.V18I1.14750, DOI 10.12928/TELKOMNIKA.V18I1.14750]
   [Anonymous], 2012, GUIDE OCR ARABIC SCR
   Ardian Z, 2018, J PHYS CONF SER, V1019, DOI 10.1088/1742-6596/1019/1/012074
   Balhara S, 2022, IET COMMUN, DOI 10.1049/cmu2.12447
   Busaeed S, 2022, REQUIREMENTS CHALLEN
   Butt H, 2021, FORECASTING-BASEL, V3, P520, DOI 10.3390/forecast3030033
   Callaos N, 2022, INTELLECTUAL DEV VIA
   Chen LJ, 2020, IEEE ACCESS, V8, P75264, DOI 10.1109/ACCESS.2020.2988510
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Eltay M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.861
   Eltay M, 2020, IEEE ACCESS, V8, P89882, DOI 10.1109/ACCESS.2020.2994248
   GHOSH M, 2021, COGN COMPUT, P1
   Hamdi Y, 2021, INT J DOC ANAL RECOG, V24, P283, DOI 10.1007/s10032-021-00376-2
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Lei L, 2020, IEEE COMMUN SURV TUT, V22, P1722, DOI 10.1109/COMST.2020.2988367
   Mohammed MJ., 2021, INDONESIAN J ELECT E, V22, P193, DOI [10.11591/ijeecs.v22.i2.pp801-808, DOI 10.11591/IJEECS.V22.I2.PP801-808]
   Mori B, 2020, VIRTUAL AUGMENTED RE, P324
   Mostafa Aly, 2021, 2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P182, DOI 10.1109/MIUCC52538.2021.9447608
   Mostafa A, 2020, SMART ED GAME BASED
   Muaad A.Y., 2021, Computer Sciences & Mathematics Forum, V14, P1, DOI 10.3390/IOCA2021-10903
   Muaad AY, 2021, ALGORITHMS, V14, DOI 10.3390/a14070216
   Ouali Imene, 2022, Procedia Computer Science, P158, DOI 10.1016/j.procs.2022.09.048
   Ouali Imene, 2020, Procedia Computer Science, V176, P602, DOI 10.1016/j.procs.2020.08.062
   Ouali Imene, 2021, Advanced Information Networking and Applications. Proceedings of the 35th International Conference on Advanced Information Networking and Applications (AINA-2021). Lecture Notes in Networks and Systems (LNNS 225), P285, DOI 10.1007/978-3-030-75100-5_25
   Ouali I, 2022, INT WIREL COMMUN, P678, DOI 10.1109/IWCMC55113.2022.9825089
   Ouali I, 2022, LECT NOTE NETW SYST, V449, P13, DOI 10.1007/978-3-030-99584-3_2
   Ouali I, 2019, PROCEDIA COMPUT SCI, V159, P746, DOI 10.1016/j.procs.2019.09.230
   Pei YQ, 2019, I C VIRTUAL REALITY, P11, DOI 10.1109/ICVRV47840.2019.00011
   Peng FG, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P1049, DOI 10.1109/ICIVC.2017.7984714
   Safabakhsh R, 2005, ARAB J SCI ENG, V30, P95
   Selmi Z, 2017, PROC INT CONF DOC, P1132, DOI 10.1109/ICDAR.2017.187
   Selmi Z, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268567
   Sheehan S, 2021, P EACL HACKASH NEWS, P56
   Syahidi AA, 2018, 2018 5TH IEEE INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGIES AND APPLIED SCIENCES (IEEE ICETAS)
   Turki H, 2016, 2016 IEEE ACS 13 INT, P1
   Turki H, 2017, PROC INT CONF DOC, P949, DOI 10.1109/ICDAR.2017.159
   Yan RJ, 2017, PROC INT CONF DOC, P1031, DOI 10.1109/ICDAR.2017.171
   Yongyong Ge, 2019, 2019 6th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS), P72, DOI 10.1109/ICCSS48103.2019.9115469
   Zayene O, 2015, PROC INT CONF DOC, P996, DOI 10.1109/ICDAR.2015.7333911
NR 45
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43569
EP 43597
DI 10.1007/s11042-023-14880-6
EA APR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000970708600001
DA 2024-07-18
ER

PT J
AU Ajay, D
   Selvachandran, G
   Aldring, J
   Thong, PH
   Son, LH
   Cuong, BC
AF Ajay, D.
   Selvachandran, Ganeshsree
   Aldring, J.
   Thong, Pham Huy
   Son, Le Hoang
   Cuong, Bui Cong
TI Einstein exponential operation laws of spherical fuzzy sets and
   aggregation operators in decision making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spherical fuzzy set; Exponential operational laws; Einstein exponential
   operational laws; Aggregate operator; Decision making
AB The spherical fuzzy set (SFS) model is one of the newly developed extensions of fuzzy sets (FS) for the purpose of dealing with uncertainty or vagueness in decision making. The aim of this paper is to define new exponential and Einstein exponential operational laws for spherical fuzzy sets and their corresponding aggregation operators. We introduce the operational laws for exponential and Einstein exponential SFSs in which the base values are crisp numbers and the exponents (weights) are spherical fuzzy numbers. Some of the properties and characteristics of the proposed operations are then discussed. Based on these operational laws, some new aggregation operators for the SFS model, namely Spherical Fuzzy Weighted Exponential Averaging (SFWEA) and Spherical Fuzzy Einstein Weighted Exponential Averaging (SFEWEA) operators are introduced. Finally, a decision-making algorithm based on these newly introduced aggregation operators is proposed and applied to a multi-criteria decision making (MCDM) problem related to ranking different types of psychotherapy.
C1 [Ajay, D.; Aldring, J.] Sacred Heart Coll, Dept Math, Tirupattur, Tamil Nadu, India.
   [Selvachandran, Ganeshsree] UCSI Univ, Inst Actuarial Sci & Data Analyt, Jalan Menara Gading, Kuala Lumpur 56000, Malaysia.
   [Selvachandran, Ganeshsree] Symbiosis Int Univ, Symbiosis Inst Technol, Pune 412115, India.
   [Aldring, J.] Panimalar Engn Coll, Dept Math, Chennai 600123, Tamil Nadu, India.
   [Thong, Pham Huy; Son, Le Hoang] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Cuong, Bui Cong] Vietnam Acad Sci & Technol, Inst Math, Hanoi, Vietnam.
C3 UCSI University; Symbiosis International University; Symbiosis Institute
   of Technology (SIT); Vietnam National University Hanoi; Vietnam Academy
   of Science & Technology (VAST)
RP Cuong, BC (corresponding author), Vietnam Acad Sci & Technol, Inst Math, Hanoi, Vietnam.
EM dajaypravin@gmail.com; Ganeshsree@ucsiuniversity.edu.my;
   jaldring24@gmail.com; thongph@vnu.edu.vn; sonlh@vnu.edu.vn;
   cuongbuicong46@gmail.com
RI John, Aldring/AAR-1283-2020; Selvachandran, Ganeshsree/P-3000-2017
OI John, Aldring/0000-0002-6655-9435; Selvachandran,
   Ganeshsree/0000-0001-7161-2109
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.05-2018.02]; Fundamental Research Grant Scheme (FRGS)
   given by the Ministry of Higher Education, Malaysia
   [FRGS/1/2020/STG06/UCSI/02/1]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.05-2018.02 and
   the Fundamental Research Grant Scheme (FRGS) given by the Ministry of
   Higher Education, Malaysia under grant number
   FRGS/1/2020/STG06/UCSI/02/1.
CR ACHARJYA DP, 2021, ARAB J SCI ENG, P1, DOI DOI 10.1007/S11042-021-10518-7
   Ajay D, 2020, NEUTROSOPHIC SETS SY, V32, P187
   Akram M, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106793
   Akram M, 2020, MATH COMPUT APPL, V25, DOI 10.3390/mca25010008
   Ali Z, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8101739
   Ali Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081311
   Alia M., 2016, J INTELL FUZZY SYST, V30, P1
   Ashraf S, 2023, SOFT COMPUT, V27, P1809, DOI 10.1007/s00500-020-05287-8
   Ashraf S, 2020, J AMB INTEL HUM COMP, V11, P2731, DOI 10.1007/s12652-019-01333-y
   Ashraf S, 2019, INT J INTELL SYST, V34, P493, DOI 10.1002/int.22062
   Ashraf S, 2018, MATH SCI, V12, P263, DOI 10.1007/s40096-018-0266-0
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Atta R, 2021, MULTIMED TOOLS APPL, V80, P21751, DOI 10.1007/s11042-021-10784-5
   Aydogdu A, 2020, INT J INTELL SYST, V35, P1354, DOI 10.1002/int.22256
   Barukab O, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21121231
   Borg SJ., 2020, ADV MATH SCI J, V9, P6107, DOI [10.37418/amsj.9.8.78, DOI 10.37418/AMSJ.9.8.78]
   Farrokhizadeh E, 2021, ENG APPL ARTIF INTEL, V101, DOI 10.1016/j.engappai.2021.104212
   Garg H, 2021, J AMB INTEL HUM COMP, V12, P9067, DOI 10.1007/s12652-020-02600-z
   Garg H, 2018, INT J INTELL SYST, V33, P653, DOI 10.1002/int.21966
   Gou XJ, 2016, INT J MACH LEARN CYB, V7, P501, DOI 10.1007/s13042-015-0434-6
   Guleria A, 2021, SCI IRAN, V28, P1014, DOI 10.24200/sci.2019.53027.3018
   Gündogdu FK, 2019, ENG APPL ARTIF INTEL, V85, P307, DOI 10.1016/j.engappai.2019.06.003
   Gündogdu FK, 2019, J INTELL FUZZY SYST, V36, P337, DOI 10.3233/JIFS-181401
   Gundogdu FK, 2020, SPHERICAL FUZZY VIKO, DOI [10.1007/978-3-030-23756-1_118, DOI 10.1007/978-3-030-23756-1_118]
   Haque TS, 2020, CAAI T INTELL TECHNO, V5, P106, DOI 10.1049/trit.2019.0078
   Jin Y, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070628
   Jun YB, 2017, NEW MATH NAT COMPUT, V13, P41, DOI 10.1142/S1793005717500041
   Liu P., 1032, ENG APPL ARTIF INTEL, V87, P95
   Mathew M., 1039, ENG APPL ARTIF INTEL, V96, P88
   Quek SG, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7090780
   Rafiq M, 2019, J INTELL FUZZY SYST, V36, P6059, DOI 10.3233/JIFS-181922
   Sharaf IM, 2021, INT J MANAG SCI ENG, V16, P1, DOI 10.1080/17509653.2020.1788467
   Sharaff A, 2018, LECT NOTES NETWORKS, V24, DOI [10.1007/978-981-10-6890-4-8, DOI 10.1007/978-981-10-6890-4-8]
   Sharaff A, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P906, DOI [10.1109/ICCS45141.2019.9065722, 10.1109/iccs45141.2019.9065722]
   Shishavan SAS, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103837
   Smarandache F., 2005, A Unifying Field in Logics: Neutrosophic Probability, Set and Logic, V4th ed.
   Yager RR, 2013, PROCEEDINGS OF THE 2013 JOINT IFSA WORLD CONGRESS AND NAFIPS ANNUAL MEETING (IFSA/NAFIPS), P57, DOI 10.1109/IFSA-NAFIPS.2013.6608375
   Yager RR, 2013, INT J INTELL SYST, V28, P436, DOI 10.1002/int.21584
   Ye J, 2018, SOFT COMPUT, V22, P7435, DOI 10.1007/s00500-018-3194-x
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 40
TC 2
Z9 2
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41767
EP 41790
DI 10.1007/s11042-023-14532-9
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200004
PM 37362734
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zereen, AN
   Gurung, A
   Rajak, A
   Moonrinta, J
   Dailey, MN
   Ekpanyapong, M
   Vachalathiti, R
   Bovonsunthonchai, S
AF Zereen, Aniqua Nusrat
   Gurung, Anubinda
   Rajak, Amir
   Moonrinta, Jednipat
   Dailey, Matthew N.
   Ekpanyapong, Mongkol
   Vachalathiti, Roongtiwa
   Bovonsunthonchai, Sunee
TI Video analytic system for activity profiling, fall detection, and
   unstable motion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elder care; Activity profiling; Fall warning; Unstable motion
AB Real time detection of falls and unstable movement by elderly people is vital to their quality of life and safety. We present an edge processing device integrated with a cloud computation framework that can be used for activity profiling as well as trigger alerts for falls and unstable motion by elderly people at home. The proposed system uses fixed cameras to track and analyze each visible person in the scene, classifying their actions into nine ordinary activities, a fall, or unstable movement. An alert notification is sent to caregivers whenever a fall or unstable movement is detected. The major components of the system include an embedded device (NVIDIA JETSON TX2) and cloud-based storage and analysis infrastructure. The system is composed of modules for detecting, tracking and recognizing humans, a cascaded hierarchical classifier for nine ordinary activities and falls, and a long short-term memory (LSTM) module to predict unstable movement in video. The system is designed for accuracy, usability, and cost. A prototype system has been subjected to individual module tests along with a field test within a volunteer's household. It achieved an accuracy of 91.6% for ordinary actions and falls with a recall of 97.02% for unstable motion. Future phases will expand deployment to multiple homes.
C1 [Zereen, Aniqua Nusrat; Gurung, Anubinda; Rajak, Amir; Moonrinta, Jednipat; Dailey, Matthew N.; Ekpanyapong, Mongkol] Asian Inst Technol, Sch Engn & Technol, 58 Moo 9,Paholyothin Highway Klong Luang, Phatum Thani 12120, Thailand.
   [Vachalathiti, Roongtiwa; Bovonsunthonchai, Sunee] Mahidol Univ, Fac Phys Therapy, 999 Phutthamonthon Sai 4 Rd, Nakhon Pathom 73170, Thailand.
C3 Asian Institute of Technology; Mahidol University
RP Zereen, AN (corresponding author), Asian Inst Technol, Sch Engn & Technol, 58 Moo 9,Paholyothin Highway Klong Luang, Phatum Thani 12120, Thailand.
EM aniqua.zereen@gmail.com; gurung.anubinda93@gmail.com;
   arajak.aic@gmail.com; st117746@ait.ac.th; mdailey@ait.ac.th;
   mongkol@ait.ac.th; roongtiwa.vac@mahidol.edu; sunee.bov@mahidol.edu
RI Zereen, Aniqua Nusrat/JMA-9189-2023
OI Zereen, Aniqua Nusrat/0000-0002-8655-8667
CR Al-Aama T, 2011, CAN FAM PHYSICIAN, V57, P771
   Anderson Derek, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6388
   Andrade-Ambriz YA, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116287
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chung J, 2017, J BIOMED INFORM, V71, P82, DOI 10.1016/j.jbi.2017.05.010
   Chung PC, 2008, PATTERN RECOGN, V41, P1572, DOI 10.1016/j.patcog.2007.10.022
   Ghorbani S., 2020, BOREALIS, DOI DOI 10.5683/SP2
   Groos D, 2021, APPL INTELL, V51, P2518, DOI 10.1007/s10489-020-01918-7
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ibrahim MJ, 2022, EFFECTIVE APPROACH H
   Karim NT, 2018, PROC INT WORKSH ADV
   Li C, 2017, IEEE INT CONF MULTI
   Lin T., 2017, J HEALTHC ENG, V2017, P1
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   NVIDIA AI IOT, 2020, JETS BENCHM REP
   Pumpinyo S., 2020, ADV SCI TECHNOL-RES, V3, P14, DOI [10.33422/jarss.v3i3.517, DOI 10.33422/JARSS.V3I3.517]
   Rim Beanbonyka, 2020, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V21, P21, DOI 10.7472/jksii.2020.21.5.21
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stone E. E., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P71, DOI 10.4108/icst.pervasivehealth.2011.246034
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yen HY, 2018, J EXERC SCI FIT, V16, P49, DOI 10.1016/j.jesf.2018.06.001
   Zereen AN., 2021, NBTC J, V5, P117
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Zhou ZN, 2008, IEEE T CIRC SYST VID, V18, P1489, DOI 10.1109/TCSVT.2008.2005612
   Zhou ZN, 2009, IEEE ENG MED BIO, P6115, DOI 10.1109/IEMBS.2009.5334915
NR 30
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42395
EP 42415
DI 10.1007/s11042-023-14993-y
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200005
OA hybrid
DA 2024-07-18
ER

PT J
AU Hao, ZH
   Zhang, BB
   Mao, DH
   Yen, JRM
   Zhao, ZH
   Zuo, M
   Li, HS
   Xu, CZ
AF Hao, Zhihao
   Zhang, Bob
   Mao, Dianhui
   Yen, Jerome
   Zhao, Zhihua
   Zuo, Min
   Li, Haisheng
   Xu, Cheng-Zhong
TI A novel method using LSTM-RNN to generate smart contracts code templates
   for improved usability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Smart contracts; Usability; Deep learning
AB Recently, the development of blockchain technology has given us an opportunity to improve the security and trustworthiness of multimedia. With the applications of blockchain technology, smart contracts have been widely used in many industries. However, the current development of smart contracts faces many challenges. One of the challenges is that the coding process is complicated for developers, leading to unnormalized code and can cause development and maintenance issues. Also, this is an important limitation factor in the development of smart contracts. To solve this problem, this paper proposes a method of generating contract templates based on the Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) to simplify the coding process. First, the contracts available online were crawled, before detecting the vulnerabilities of these contracts. Contracts with less vulnerabilities are used as training data. For better generation effects, the Abstract Syntax Tree (AST) and the word2vec are used to extract the lexical unit sequence features to obtain a word vector in order to analyze the semantics of the code. Afterwards, the generated sequence vector features are fed to LSTM-RNN for template generation. The efficiency of four types of vectorization method models were tested and the results showed that the Skip-Gram+ HS used in this paper achieved the highest performance. In addition, a security test was conducted based on the contracts before and after using the contract templates for normalized coding. The results show that the proposed method is not only a beneficial attempt to combine deep learning with blockchain technology, but also provides an effective guidance for improving the security of smart contracts.
C1 [Hao, Zhihao; Zhang, Bob] Univ Macau, Dept Comp & Informat Sci, PAMI Res Grp, Macau 999078, Peoples R China.
   [Hao, Zhihao; Zhang, Bob; Mao, Dianhui; Zuo, Min; Li, Haisheng] Beijing Technol & Business Univ, Sch Comp, Beijing Key Lab Big Data Technol Food Safety, 33,Fucheng Rd, Beijing 100048, Peoples R China.
   [Hao, Zhihao; Mao, Dianhui; Zuo, Min; Li, Haisheng] Beijing Technol & Business Univ, Natl Engn Lab Agriprod Qual Traceabil, 33,Fucheng Rd, Beijing 100048, Peoples R China.
   [Hao, Zhihao] China Ind Control Syst Cyber Emergency Response Te, Beijing 100040, Peoples R China.
   [Yen, Jerome] Univ Macau, Dept Comp & Informat Sci, Macau 999078, Peoples R China.
   [Zhao, Zhihua] China Univ Polit Sci & Law, Sch Law, 25,Xitucheng Rd, Beijing 102249, Peoples R China.
   [Xu, Cheng-Zhong] Univ Macau, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China.
C3 University of Macau; Beijing Technology & Business University; Beijing
   Technology & Business University; University of Macau; China University
   of Political Science & Law; University of Macau
RP Zhang, BB (corresponding author), Univ Macau, Dept Comp & Informat Sci, PAMI Res Grp, Macau 999078, Peoples R China.; Zhang, BB; Mao, DH (corresponding author), Beijing Technol & Business Univ, Sch Comp, Beijing Key Lab Big Data Technol Food Safety, 33,Fucheng Rd, Beijing 100048, Peoples R China.; Mao, DH (corresponding author), Beijing Technol & Business Univ, Natl Engn Lab Agriprod Qual Traceabil, 33,Fucheng Rd, Beijing 100048, Peoples R China.
EM hao_zhihao@126.com; bobzhang@um.edu.mo; maodh@th.btbu.edu.cn;
   jeromeyen@um.edu.mo; zhaozhihua@cupl.edu.cn; zuomin@th.btbu.edu.cn;
   lihsh@th.btbu.edu.cn; czxu@um.edu.mo
RI Zhang, Bob/HIR-3656-2022; XU, CHENGZHONG/AAX-1707-2020
OI Zhang, Bob/0000-0001-6512-0474; XU, CHENGZHONG/0000-0001-9480-0356;
   Zhang, Bob/0000-0003-2497-9519; Hao, Zhihao/0000-0002-1079-7063
FU National Natural Science Foundation of China [62277001]; National Key
   Technology R&D Program of China [SQ2020YFB10027, ZT2025002]; Scientific
   Research Program of Beijing Municipal Education Commission
   [KZ202110011017]; Natural Science Foundation of Beijing Municipality
   [9232005]; Beijing Municipal Philosophy and Social Science Foundation
   [19GLB036]; Major Science and Technology Special Project of Yunnan
   Province [202102AD080006]; Open Research Fund of the Beijing Key
   Laboratory of Big Data Technology for Food Safety [BTBD-2021KF05];
   University of Macau [MYRG2019-00006-FST]; Science and Technology
   Development Fund of the Macau SAR [0091/2020/A2]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62277001, in part by the National Key
   Technology R&D Program of China under Grant SQ2020YFB10027, ZT2025002 in
   part by the Scientific Research Program of Beijing Municipal Education
   Commission under Grant KZ202110011017, in part by the Natural Science
   Foundation of Beijing Municipality under Grant 9232005, in part by the
   Beijing Municipal Philosophy and Social Science Foundation under Grant
   19GLB036, in part by Major Science and Technology Special Project of
   Yunnan Province under Grant 202102AD080006, in part by the Open Research
   Fund of the Beijing Key Laboratory of Big Data Technology for Food
   Safety (Project No. BTBD-2021KF05), in part by University of Macau (File
   no. MYRG2019-00006-FST), and in part by the Science and Technology
   Development Fund of the Macau SAR (0091/2020/A2).
CR Alexandru CV, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P1068, DOI 10.1145/2950290.2983951
   Alharby M, 2017, ARXIV
   Almadhoun R, 2018, I C COMP SYST APPLIC
   Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8
   Brabrand C, 2008, INFORM SYST, V33, P385, DOI 10.1016/j.is.2008.01.006
   Das AK, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101938
   Datta S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03591-1
   Dingman W, 2019, INT J NETW DISTRIB C, V7, P121, DOI 10.2991/ijndc.k.190710.003
   Durieux T, 2020, PROC INT CONF SOFTW, P530, DOI 10.1145/3377811.3380364
   Fluss R, 2005, BIOMETRICAL J, V47, P458, DOI 10.1002/bimj.200410135
   Fotiou N, 2019, I S WORLD WIREL MOBI, DOI 10.1109/wowmom.2019.8793047
   Halgamuge MN, 2022, MULTIMED TOOLS APPL, V81, P1523, DOI 10.1007/s11042-021-11078-6
   Hao ZH, 2021, FOODS, V10, DOI 10.3390/foods10061398
   Hao ZH, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072300
   Hasan HR, 2018, IEEE ACCESS, V6, P65439, DOI 10.1109/ACCESS.2018.2876971
   Ho Chung Wu, 2008, ACM Transactions on Information Systems, V26
   Hou L, 2019, ADV NEUR IN, V32
   Jiang B, 2018, IEEE INT CONF AUTOM, P259, DOI 10.1145/3238147.3238177
   Jiang F, 2020, IEEE T SUST COMPUT, V5, P204, DOI 10.1109/TSUSC.2018.2793284
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Kim G, 2016, ARXIV
   Kim HK, 2017, NEUROCOMPUTING, V266, P336, DOI 10.1016/j.neucom.2017.05.046
   Kosba A, 2016, P IEEE S SECUR PRIV, P839, DOI 10.1109/SP.2016.55
   Le P., 2015, ARXIV
   Lee D, 2021, MULTIMED TOOLS APPL, V80, P34517, DOI 10.1007/s11042-020-08776-y
   Li JQ, 2016, KNOWL-BASED SYST, V106, P220, DOI 10.1016/j.knosys.2016.05.045
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30707, DOI 10.1007/s11042-021-10558-z
   Luu L, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P254, DOI 10.1145/2976749.2978309
   Ma ZW, 2021, INT J SENS NETW, V37, P69, DOI 10.1504/IJSNET.2021.118486
   Mao DH, 2019, IEEE ACCESS, V7, P73131, DOI 10.1109/ACCESS.2019.2920776
   Mao DH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050703
   Mao DH, 2019, ARAB J SCI ENG, V44, P3439, DOI 10.1007/s13369-018-3537-z
   Mao DH, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093149
   McCorry P, 2017, LECT NOTES COMPUT SC, V10322, P357, DOI 10.1007/978-3-319-70972-7_20
   Mehar MI, 2019, J CASES INF TECHNOL, V21, P19, DOI 10.4018/JCIT.2019010102
   Morin F, 2005, P AISTATS, V5, P246
   Mou LL, 2016, AAAI CONF ARTIF INTE, P1287
   Nugaliyadde A, 2019, IEEE IJCNN
   Parizi RM, 2018, LECT NOTES COMPUT SC, V10974, P75, DOI 10.1007/978-3-319-94478-4_6
   PARR TJ, 1995, SOFTWARE PRACT EXPER, V25, P789, DOI 10.1002/spe.4380250705
   Peng H, 2015, LECT NOTES ARTIF INT, V9403, P547, DOI 10.1007/978-3-319-25159-2_49
   PRECHTEL D, 2019, 2019 10 IFIP INT C N, P1
   Rozario AndreaM., 2018, International Journal of Digital Accounting Research, V18, DOI [10.4192/1577-8517-v18_1, DOI 10.4192/1577-8517-V18_1]
   Sinha D, 2019, ADV INTELL SYST COMP, P133, DOI DOI 10.1007/978-3-030-39875-0_14
   Somasundaram N, 2019, UBS INTRO SMART CONT
   Tariq N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010023
   Tikhomirov S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB), P9, DOI 10.1145/3194113.3194115
   Tsankov P, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P67, DOI 10.1145/3243734.3243780
   Vukolic M, 2017, BCC '17: PROCEEDINGS OF THE ACM WORKSHOP ON BLOCKCHAIN, CRYPTOCURRENCIES AND CONTRACTS, P3, DOI 10.1145/3055518.3055526
   Wang GC, 2022, INFORM SCIENCES, V588, P106, DOI 10.1016/j.ins.2021.12.039
   White M, 2015, 12TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2015), P334, DOI 10.1109/MSR.2015.38
   Xu YJ, 2014, IEEE T PARALL DISTR, V25, P3135, DOI 10.1109/TPDS.2014.2306193
   Yang N, 2019, J PHYS CONF SER, V1187, DOI 10.1088/1742-6596/1187/5/052074
   Zen H, 2015, ACOUSTIC MODELING ST
   Zhao ZH, 2022, J THEOR APPL EL COMM, V17, P1, DOI 10.3390/jtaer17010001
NR 55
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41669
EP 41699
DI 10.1007/s11042-023-14592-x
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000964979100002
DA 2024-07-18
ER

PT J
AU Singh, LK
   Khanna, M
   Thawkar, S
   Singh, R
AF Singh, Law Kumar
   Khanna, Munish
   Thawkar, Shankar
   Singh, Rekha
TI Nature-inspired computing and machine learning based classification
   approach for glaucoma in retinal fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Retinal fundus images; Structural features; Non-structural
   features; Particle swarm optimization (PSO); Artificial bee colony
   optimization (ABC); Binary cuckoo search (BCS)
ID PARTICLE SWARM OPTIMIZATION; CUCKOO SEARCH ALGORITHM; ARTIFICIAL BEE
   COLONY; FEATURE-SELECTION; NEURAL-NETWORK; AUTOMATED DIAGNOSIS; OPTIC
   DISC; DESIGN; SYSTEM; SEGMENTATION
AB Glaucoma, commonly known as the silent thief of sight, is the second most common cause of blindness in humans, and the number of cases is steadily increasing. Conventional diagnostic methods utilized by ophthalmologists include the assessment of intraocular pressure using tonometry, pachymetry, etc. Yet, each of these evaluations is time-consuming, requires human involvement, and is prone to subjective errors. In order to overcome these hurdles, practitioners are studying retinal pictures for glaucoma diagnosis within the field of medical imaging. In addition, computer-assisted diagnosis (CAD) systems can be created to solve these obstacles by using machine learning approaches to classify retinal pictures as "healthy" or "infected." This work presents a reduced set of structural and nonstructural features(characteristics) to characterize pictures of the retinal fundus. The grey level co-occurrence matrix (GLCM), the grey level run length matrix (GLRM), the first order statistical matrix (FOS), the wavelet, and the structural features (like disc damage likelihood scale (DDLS) and cup to disc ratio (CDR)) are extracted. This set of features is sent to three classical soft computing algorithms (Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), and Binary Cuckoo Search (BCS)) and their two-layered model (PSO-ABC) to generate subset of reduced features (feature selection phase) that computes auspicious accuracy when sent to three machine learning classifiers (Random Forest (RF), Support Vector Machine (SVM), and Ensemble of RF, SVM, and Logistic Regression). According to our understanding, these four soft computing algorithms are rarely employed in this application field. For analyzing the performance of suggested strategy, the ORIGA, REFUGE, and their combinations are chosen as subject datasets. Standard statistical performance indicators, including accuracy, specificity, precision, and sensitivity, are calculated. The BCS delivers remarkable performance with a minimum of 91% accuracy and a maximum of 98.46% accuracy. PSO-ABC heavily decreases the original feature set, with minor accuracy sacrifices. The quantitative results are also compared in light of the most recent state-of-the-art published research. Owing to its exemplary performance, the suggested method will undoubtedly serve as a second opinion for ophthalmologists.
C1 [Singh, Law Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
   [Khanna, Munish] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Thawkar, Shankar] Hindustan Coll Sci & Technol, Dept Informat Technol, Mathura 281122, India.
   [Singh, Rekha] Uttar Pradesh Rajarshi Tandon Open Univ, Dept Phys, Prayagraj 211013, Uttar Pradesh, India.
C3 GLA University
RP Singh, LK (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
EM lawkumarcs@gmail.com; munishkhanna.official@rocketmail.com;
   shankarthawkar@gmail.com; singh.rekha70@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852; Thawkar,
   Shankar/0000-0002-0118-9605
CR Abd El Aziz M, 2018, NEURAL COMPUT APPL, V29, P925, DOI 10.1007/s00521-016-2473-7
   Abdelaziz AY, 2015, INT J ELEC POWER, V73, P632, DOI 10.1016/j.ijepes.2015.05.050
   Acharya UR, 2015, BIOMED SIGNAL PROCES, V15, P18, DOI 10.1016/j.bspc.2014.09.004
   Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322
   Agboola Hafeez Alani, 2023, BMC Biomed Eng, V5, P1, DOI 10.1186/s42490-023-00067-5
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Andrushia AD, 2020, EVOL SYST-GER, V11, P105, DOI 10.1007/s12530-019-09289-2
   Ang KM, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112882
   Aydilek IB, 2018, APPL SOFT COMPUT, V66, P232, DOI 10.1016/j.asoc.2018.02.025
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   Bulatovic RR, 2013, MECH MACH THEORY, V61, P1, DOI 10.1016/j.mechmachtheory.2012.10.010
   Burnwal S, 2013, INT J ADV MANUF TECH, V64, P951, DOI 10.1007/s00170-012-4061-z
   Cao M, 2015, INT J GEOGR INF SCI, V29, P806, DOI 10.1080/13658816.2014.999245
   Chaine Sabita, 2015, Journal of Electrical Systems and Information Technology, V2, P1, DOI 10.1016/j.jesit.2015.03.001
   Chaudhary A, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105747
   Chen K, 2019, EXPERT SYST APPL, V128, P140, DOI 10.1016/j.eswa.2019.03.039
   Chitara D, 2018, IEEE T IND APPL, V54, P3056, DOI 10.1109/TIA.2018.2811725
   Claro Maíla, 2016, CLEIej, V19, P5
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Cui ZH, 2020, INFORM SCIENCES, V518, P256, DOI 10.1016/j.ins.2020.01.018
   Daniel E, 2016, COMPUT BIOL MED, V71, P149, DOI 10.1016/j.compbiomed.2016.02.011
   Darwish A, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100616
   de Sousa JA, 2017, MULTIMED TOOLS APPL, V76, P19173, DOI 10.1007/s11042-017-4608-y
   Dev A, 2021, INT J E-HEALTH MED C, V12, P67, DOI 10.4018/IJEHMC.20210901.oa5
   Dhivja M., 2011, International J. Communications, P249, DOI DOI 10.4236/IJCNS.2011.44030
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Dokeroglu T, 2019, APPL SOFT COMPUT, V76, P595, DOI 10.1016/j.asoc.2019.01.001
   Dua S, 2012, IEEE T INF TECHNOL B, V16, P80, DOI 10.1109/TITB.2011.2176540
   Durgun I, 2012, MATER TEST, V54, P185
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   Elmoufidi A, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500122
   Famila S, 2020, PEER PEER NETW APPL, V13, P1071, DOI 10.1007/s12083-019-00805-4
   Fernandes FE Jr, 2019, SWARM EVOL COMPUT, V49, P62, DOI 10.1016/j.swevo.2019.05.010
   Franco P, 2021, medRxiv
   Fu HZ, 2019, ADV COMPUT VIS PATT, P119, DOI 10.1007/978-3-030-13969-8_6
   Garg H, 2022, MULTIMED TOOLS APPL, V81, P34737, DOI 10.1007/s11042-021-11559-8
   Gherboudj A, 2012, INT J BIO-INSPIR COM, V4, P229, DOI 10.1504/IJBIC.2012.048063
   Goceri E, 2023, ARTIF INTELL REV, V56, P12561, DOI 10.1007/s10462-023-10453-z
   Guo F, 2020, MED BIOL ENG COMPUT, V58, P2567, DOI 10.1007/s11517-020-02237-2
   Guo F, 2018, IEEE ACCESS, V6, P77414, DOI 10.1109/ACCESS.2018.2882946
   Guru Prasad MS., 2023, SN COMPUT SCI, V4, P192, DOI [10.1007/s42979-022-01592-1, DOI 10.1007/S42979-022-01592-1]
   Haider A, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.117968
   Hajimirzaei B, 2019, ICT EXPRESS, V5, P56, DOI 10.1016/j.icte.2018.01.014
   Haleem MS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0482-9
   Hancer E, 2018, INFORM SCIENCES, V422, P462, DOI 10.1016/j.ins.2017.09.028
   Ibrahim RA, 2019, J AMB INTEL HUM COMP, V10, P3155, DOI 10.1007/s12652-018-1031-9
   Issac A, 2015, COMPUT METH PROG BIO, V122, P229, DOI 10.1016/j.cmpb.2015.08.002
   Jati GK, 2012, 2012 7TH INTERNATIONAL CONFERENCE ON COMPUTING AND CONVERGENCE TECHNOLOGY (ICCCT2012), P993
   Jayaraman V., 2019, J. AmbientIntell. Humanized Comput., P1, DOI [10.1007/s12652-019-01193-6, DOI 10.1007/S12652-019-01193-6]
   Jovanovic R, 2014, ARXIV
   Juneja M, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117202
   Juneja M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108009
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kanagaraj G., 2014, 2014 IEEE International Conference on Automation Science and Engineering (CASE), P373, DOI 10.1109/CoASE.2014.6899353
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Karaboga D, 2019, ARAB J SCI ENG, V44, P3531, DOI 10.1007/s13369-018-3562-y
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Koh JEW, 2017, COMPUT BIOL MED, V84, P89, DOI 10.1016/j.compbiomed.2017.03.008
   Kumar SKP, 2019, J SUPERCOMPUT, V75, P8293, DOI 10.1007/s11227-019-02999-z
   Kumari A., 2015, INT J ENG SCI TECHNO, V7, P298
   Li XT, 2012, CHINESE PHYS B, V21, DOI 10.1088/1674-1056/21/5/050507
   Liao CJ, 2007, COMPUT OPER RES, V34, P3099, DOI 10.1016/j.cor.2005.11.017
   Lim HT, 2010, RECENT ADV NURSE SCH
   Liu SP, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103485
   Maheshwari S, 2019, COMPUT BIOL MED, V105, P72, DOI 10.1016/j.compbiomed.2018.11.028
   Maheshwari S, 2017, COMPUT BIOL MED, V88, P142, DOI 10.1016/j.compbiomed.2017.06.017
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   Mahmoudi S, 2015, APPL SOFT COMPUT, V33, P48, DOI 10.1016/j.asoc.2015.04.020
   Mallika C, 2021, INT J COMPUT INT SYS, V14, DOI 10.1007/s44196-021-00013-0
   Martins J, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105341
   Ming B, 2015, WATER RESOUR MANAG, V29, P5671, DOI 10.1007/s11269-015-1140-6
   Mohapatra P, 2015, SWARM EVOL COMPUT, V24, P25, DOI 10.1016/j.swevo.2015.05.003
   Mookiah MRK, 2012, KNOWL-BASED SYST, V33, P73, DOI 10.1016/j.knosys.2012.02.010
   Naik MK, 2016, APPL SOFT COMPUT, V38, P661, DOI 10.1016/j.asoc.2015.10.039
   Nancharaiah B., 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1729, DOI 10.1109/ICCSP.2014.6950142
   Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z
   Noghrehabadi A., 2011, INT J MULTIDISCIP SC, V2, P22
   Noronha KP, 2014, BIOMED SIGNAL PROCES, V10, P174, DOI 10.1016/j.bspc.2013.11.006
   Orlando JI., 2019, MED IMAGE ANAL, V2020
   Ouaarab A, 2014, NEURAL COMPUT APPL, V24, P1659, DOI 10.1007/s00521-013-1402-2
   Ouyang XX, 2013, APPL MATH INFORM SCI, V7, P777, DOI 10.12785/amis/070248
   Öztürk S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106799
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Patil N, 2021, MULTIMED TOOLS APPL, V80, P29481, DOI 10.1007/s11042-021-11087-5
   Piechocki J, 2014, APPL ENERG, V114, P901, DOI 10.1016/j.apenergy.2013.07.057
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Pongchairerks P, 2009, SCIENCEASIA, V35, P89, DOI 10.2306/scienceasia1513-1874.2009.35.089
   Prabukumar M, 2019, J AMB INTEL HUM COMP, V10, P267, DOI 10.1007/s12652-017-0655-5
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Raghavendra U, 2018, BIOCYBERN BIOMED ENG, V38, P170, DOI 10.1016/j.bbe.2017.11.002
   Rahaman M, 2020, SOFT COMPUT, V24, P15341, DOI 10.1007/s00500-020-04867-y
   Rakhshani H, 2017, APPL SOFT COMPUT, V52, P771, DOI 10.1016/j.asoc.2016.09.048
   Ramakrishnan B., 2015, INT J COMPUTER NETWO, V2, P173
   Rao H, 2019, APPL SOFT COMPUT, V74, P634, DOI 10.1016/j.asoc.2018.10.036
   Renukalatha S, 2019, BIOMED ENG-APP BAS C, V31, DOI 10.4015/S101623721950039X
   Sadiq Al-Obaidi Ahmed T., 2013, International Journal of Advanced Research in Artificial Intelligence, V2, P61
   Sakri SB, 2018, IEEE ACCESS, V6, P29637, DOI 10.1109/ACCESS.2018.2843443
   Salam AA, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3175-4
   Saxena A, 2020, J INTERDISCIP MATH, V23, P617, DOI 10.1080/09720502.2020.1731967
   Selvathi D., 2018, BIOMED PHARMACOL J, V11, P795, DOI [DOI 10.13005/bpj/1434, 10.13005/bpj/1434]
   Sengupta S, 2017, COMPUT ELECTRON AGR, V140, P443, DOI 10.1016/j.compag.2017.06.024
   Septiarini A, 2018, HEALTHC INFORM RES, V24, P53, DOI 10.4258/hir.2018.24.1.53
   Shafipour M, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115620
   Shahid AH, 2020, BIOCYBERN BIOMED ENG, V40, P1568, DOI 10.1016/j.bbe.2020.09.005
   Sharma R, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419400116
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Shubhangi DC., 2019, Int J Comput Sci. Mobile Comput, V8, P82
   Singh A, 2016, COMPUT METH PROG BIO, V124, P108, DOI 10.1016/j.cmpb.2015.10.010
   Singh LK, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103468
   Singh LK, 2022, MULTIMED TOOLS APPL, V81, P27737, DOI 10.1007/s11042-022-12826-y
   SK PK, 2021, CONCURR COMP-PRACT E, V33, P5312
   Sreng S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144916
   Srivastava AK, 2021, INT J E-HEALTH MED C, V12, P32, DOI 10.4018/IJEHMC.2021030102
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Talatahari S, 2013, KSCE J CIV ENG, V17, P1099
   Tarle Balasaheb, 2019, International Journal of Business Intelligence and Data Mining, V15, P288
   Thakur N, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102137
   Nguyen TT, 2015, APPL SOFT COMPUT, V37, P763, DOI 10.1016/j.asoc.2015.09.010
   Nguyen TAT, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND APPLICATIONS (ACOMP), P1, DOI 10.1109/ACOMP.2015.23
   Nguyen TT, 2015, INT J ELEC POWER, V68, P233, DOI 10.1016/j.ijepes.2014.12.075
   Tulsani A, 2021, BIOCYBERN BIOMED ENG, V41, P819, DOI 10.1016/j.bbe.2021.05.011
   Wang F, 2018, INFORM SCIENCES, V436, P162, DOI 10.1016/j.ins.2018.01.027
   Wang LX, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115365
   Wang Z, 2015, ENERG CONVERS MANAGE, V101, P126, DOI 10.1016/j.enconman.2015.05.009
   Xue B, 2014, APPL SOFT COMPUT, V18, P261, DOI 10.1016/j.asoc.2013.09.018
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yekkala I, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P691, DOI 10.1109/SmartTechCon.2017.8358460
   Yildiz AR, 2013, INT J ADV MANUF TECH, V64, P55, DOI 10.1007/s00170-012-4013-7
   Zhan ZH, 2009, LECT NOTES COMPUT SC, V5484, P117, DOI 10.1007/978-3-642-01129-0_15
   Zhang QB, 2019, EXPERT SYST APPL, V135, P181, DOI 10.1016/j.eswa.2019.06.006
   Zhang XW, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103905
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
   Zomorodi-moghadam M, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12485
NR 135
TC 6
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42851
EP 42899
DI 10.1007/s11042-023-15175-6
EA APR 2023
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900007
DA 2024-07-18
ER

PT J
AU Narmada, A
   Shukla, MK
AF Narmada, A.
   Shukla, M. K.
TI A novel adaptive artifacts wavelet Denoising for EEG artifacts removal
   using deep learning with Meta-heuristic approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive artifacts wavelet Denoising; Electroencephalogram artifacts
   removal; Discrete wavelet transform; Improved CycleGAN; Opposition
   searched-elephant herding optimization
ID INDEPENDENT COMPONENT ANALYSIS; HIGHER-ORDER STATISTICS; SUPPRESSION;
   RECORDINGS; SVM; ICA
AB Electroencephalogram (EEG) is said to be a common tool to control neurological disorders, performed medical diagnoses, and cognitive research. But, EEG is generally polluted through various kinds of artifacts, which further causes complexities in interpreting the EEG data. These artifacts affect the efficiency of the wearable or portable EEG recording systems. Further, it results in more difficulties in the implementation of "neurologically-oriented mobile health solutions". While comparing with the five most common neurological disorders, epilepsy has more dependency on EEG for diagnosis. Recently, a combined form of "Independent Component Analysis (ICA) and Discrete Wavelet Transform (DWT)" has been developed and is said to be a standard technique for EEG artifact removal. Moreover, the wavelet-ICA procedure depends on the requirements of arbitrary thresholding or visual inspection for finding the artifactual components in the EEG signals. This task introduces a deep learning and heuristic-based adaptive artifacts wavelet denoising approach for making epilepsy detection the most accurate. Initially, the EEG signal is decomposed by the Empirical Mode Decomposition (EMD) approach. In the decomposed signal, the first level of adaptive artifacts wavelet denoising is based on DWT. The second level of artifact removal is performed by a deep learning approach termed Improved CycleGAN (I-CycleGAN) with parameter optimization by the Opposition Searched-Elephant Herding Optimization (OS-EHO). With a deeply learned wavelet coefficient, the adaptive artifacts wavelet denoising is performed with OS-EHO-based thresholding. Further, the adoption of inverse DWT is applied followed by the signal reconstruction to generate the final artifacts removed signal. From the simulation findings, the proposed OS-EHO-CycleGAN secures 28%, 5.12%, 28.12%, and 24.2% improved than PSO-CycleGAN, GWO-CycleGAN, WOA-CycleGAN, and EHO-CycleGAN in terms of PSNR values with other existing meta-heuristic algorithms. The experimentation is evaluated on various biological artifacts such as "ECG, EMG, and EOG", and the results reveal the superior efficiency of the suggested method while comparing with an existing approach based on different quality measures.
C1 [Narmada, A.] Matrusri Engn Coll, Hyderabad, Telangana, India.
   [Narmada, A.; Shukla, M. K.] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara, Punjab, India.
C3 Lovely Professional University
RP Narmada, A (corresponding author), Matrusri Engn Coll, Hyderabad, Telangana, India.; Narmada, A (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara, Punjab, India.
EM narmada8116@gmail.com; manoj.22223@lpu.co.in
CR Akhtar MT, 2012, SIGNAL PROCESS, V92, P401, DOI 10.1016/j.sigpro.2011.08.005
   Bahoura M, 2012, CIRC SYST SIGNAL PR, V31, P987, DOI 10.1007/s00034-011-9355-0
   Bansal Sumit, 2022, International Journal of Information Technology, V14, P999, DOI 10.1007/s41870-019-00346-2
   Barbati G, 2004, CLIN NEUROPHYSIOL, V115, P1220, DOI 10.1016/j.clinph.2003.12.015
   Behera S., 2022, MEAS SENS, V24, P100465, DOI 10.1016/j.measen.2022.100465
   Castellanos NP, 2006, J NEUROSCI METH, V158, P300, DOI 10.1016/j.jneumeth.2006.05.033
   Chen D, 2011, MICROSYST TECHNOL, V17, P1, DOI 10.1007/s00542-010-1169-7
   Chuang CH, 2022, NEUROIMAGE, V263, DOI 10.1016/j.neuroimage.2022.119586
   Dagdevir E, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102548
   Dai CX, 2019, IEEE ACCESS, V7, P158872, DOI 10.1109/ACCESS.2019.2949842
   DEBEER NAM, 1995, J CLIN MONITOR, V11, P381
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Ghandeharion H, 2010, MED ENG PHYS, V32, P720, DOI 10.1016/j.medengphy.2010.04.010
   Gorji H.T., 2013, J. Information Engineering and Applications, V3, P39
   Guo K, 2022, APPL INTELL, V52, P9919, DOI 10.1007/s10489-021-02999-8
   Hagemann D, 2001, CLIN NEUROPHYSIOL, V112, P215, DOI 10.1016/S1388-2457(00)00541-1
   Hamaneh MB, 2014, IEEE T BIO-MED ENG, V61, P1634, DOI 10.1109/TBME.2013.2295173
   Han WH, 2017, RUSS J NONDESTRUCT+, V53, P862, DOI 10.1134/S1061830917120075
   Islam MS, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101638
   Jana R, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102767
   Jha CK, 2020, IRBM, V42, P65
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Kelly JW, 2011, IEEE T BIO-MED ENG, V58, P598, DOI 10.1109/TBME.2010.2093932
   Krishnaveni V, 2006, Meas. Sci. Rev, V6, P45
   Kumar PS, 2008, International Journal of Open Problems in Computer Science and Mathematics, V1, P188, DOI DOI 10.1007/S11277-014-1961-2
   Lin CW, 2015, APPL INTELL, V42, P210, DOI 10.1007/s10489-014-0590-5
   Lin JCW, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107422
   Lin JCW, 2019, SOFT COMPUT, V23, P12779, DOI 10.1007/s00500-019-03829-3
   Lin JCW, 2016, ENG APPL ARTIF INTEL, V53, P1, DOI 10.1016/j.engappai.2016.03.007
   Mahajan R, 2015, IEEE J BIOMED HEALTH, V19, P158, DOI 10.1109/JBHI.2014.2333010
   Meselhi MA, 2021, IEEE C EVOL COMPUTAT, P2577, DOI 10.1109/CEC45853.2021.9504925
   Noorbasha SK, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101987
   Parmar M, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902961
   Patel R, 2017, J MED BIOL ENG, V37, P201, DOI 10.1007/s40846-016-0208-y
   Raghavendra B.S., 2011, World Academy of Science, Engineering and Technology, V57, P1027, DOI [DOI 10.5281/ZENODO.1075224, 10.5281/zenodo.1075224]
   Ramanan SV, 2004, 2004 INTERNATIONAL CONFERENCE ON COMMUNICATION, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P1027, DOI 10.1109/ICCCAS.2004.1346353
   Ramesh D, 2018, L N COMPUT VIS BIOME, V28, P937, DOI 10.1007/978-3-319-71767-8_80
   Sahoo RM, 2020, ADV INTELL SYST COMP, V1120, P217, DOI 10.1007/978-981-15-2449-3_18
   Sahoo SK, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/4875399
   Sai CY, 2018, IEEE J BIOMED HEALTH, V22, P664, DOI 10.1109/JBHI.2017.2723420
   Shaoliang Yu, 2021, 2021 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEO/Europe-EQEC52157.2021.9541891
   Shoker L, 2005, IEEE SIGNAL PROC LET, V12, P721, DOI 10.1109/LSP.2005.855539
   Shukla SK, 2020, NEURAL COMPUT APPL, V32, P17059, DOI 10.1007/s00521-020-04938-z
   WOESTENBURG JC, 1983, BIOL PSYCHOL, V16, P127, DOI 10.1016/0301-0511(83)90059-5
   Yang Q, 2021, J CENT SOUTH UNIV, V28, P2451, DOI 10.1007/s11771-021-4779-6
   Zhang SH, 2017, J NEUROSCI METH, V291, P213, DOI 10.1016/j.jneumeth.2017.08.031
   Zhou Y, 2021, NEURAL COMPUT APPL
   Zima M, 2012, PHYSIOL MEAS, V33, pN39, DOI 10.1088/0967-3334/33/8/N39
NR 48
TC 8
Z9 8
U1 9
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40403
EP 40441
DI 10.1007/s11042-023-14949-2
EA MAR 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983485500010
DA 2024-07-18
ER

PT J
AU Amine, K
   Redouane, KM
   Sayah, MM
AF Amine, Khaldi
   Redouane, Kafi Med
   Sayah, Moad Med
TI A wavelet-based watermarking for secure medical image transmission in
   telemedicine application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Digital watermarking; Stationary wavelet transform;
   Discrete wavelet transform; Continuous wavelet transform; Schur
   decomposition
ID SCHEME
AB One method for securing multimedia data, and images in particular, from malicious attacks is watermarking, which involves adding a signature to the images. Traditional watermarking techniques, however, have drawbacks when used on sensitive images like those used in medicine. A reliable and blind watermarking method is suggested in this work to secure medical image exchanged in telemedicine. Medical image watermarking enables accurate patient identification, prevents scan confusion, and minimizes the risk of diagnostic mistakes that might have detrimental effects. In this method, three distinct transformations are used to get the frequency content of the picture. The low frequency subbands are subsequently subjected to Schur decomposition. In order to incorporate the watermark bits, the resultant upper triangular matrix values are modified. The suggested approaches effectively retain a considerable quality of watermarked images, according to experimental results on imperceptibility and robustness, and are resistant against various common attacks.
C1 [Amine, Khaldi] Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LIN, Ouargla 30000, Algeria.
   [Redouane, Kafi Med; Sayah, Moad Med] Univ Kasdi Merbah, Fac Sci & Technol, Dept Elect, Elect Engn Lab, Ouargla 30000, Algeria.
C3 Universite Kasdi Merbah Ouargla; Universite Kasdi Merbah Ouargla
RP Amine, K (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LIN, Ouargla 30000, Algeria.
EM Khaldi.Amine@univ-ouargla.dz; Kafi.Redouane@univ-ouargla.dz;
   Sayah.Moad@univ-ouargla.dz
RI Kafi, Mohamed Redouane/AAT-2301-2021; Moad, Mohamed
   Essayah/IST-2295-2023; Khaldi, Amine/AAV-1266-2020
OI Kafi, Mohamed Redouane/0000-0002-5500-0943; Khaldi,
   Amine/0000-0002-1637-9129
FU "La Direction Generale de la Recherche Scientifque et du Developpement
   Technologique (DGRSDT)" of Algeria
FX This work was supported by "La Direction Generale de la Recherche
   Scientifque et du Developpement Technologique (DGRSDT)" of Algeria.
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ahmadi SBB, 2019, 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P682, DOI [10.1109/IEMCON.2019.8936229, 10.1109/iemcon.2019.8936229]
   Amine K, 2022, CIRC SYST SIGNAL PR, V41, P5856, DOI 10.1007/s00034-022-02063-x
   Amine K, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622500979
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Dai Q., 2019, INNOVATION MED HEALT, V145, P93, DOI [10.1007/978-981-13-8566-7_9, DOI 10.1007/978-981-13-8566-7_9/COVER]
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Farri E, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03771-7
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Janeliukstis R, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108897
   Kahlessenane F, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02793-3
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khaldi Amine, 2023, Journal of Ambient Intelligence and Humanized Computing, P13901, DOI 10.1007/s12652-022-04101-7
   Khaldi A, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103540
   Khare P, 2021, MULTIDIM SYST SIGN P, V32, P131, DOI 10.1007/s11045-020-00732-1
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Madhu B, 2020, J ENVIRON HEALTH SCI, V18, P2, DOI [10.11591/ijeecs.v18.i2, DOI 10.11591/IJEECS.V18.I2]
   Manikandan VM, 2021, ISA T, V108, P269, DOI 10.1016/j.isatra.2020.08.019
   Mathivanan P, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165838
   Mathivanan P, 2021, INT J IMAG SYST TECH, V31, P270, DOI 10.1002/ima.22477
   Mathivanan P., 2019, Proceedings of International Conference on Intelligent Computing and Applications (ICICA 2018). Advances in Intelligent Systems and Computing (AISC 846), P171, DOI 10.1007/978-981-13-2182-5_18
   Mathivanan P, 2019, MULTIMED TOOLS APPL, V78, P6763, DOI 10.1007/s11042-018-6471-x
   Mathivanan P, 2018, AUSTRALAS PHYS ENG S, V41, P1057, DOI 10.1007/s13246-018-0695-y
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Moad MS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103114
   Nardecchia A, 2021, TALANTA, V224, DOI 10.1016/j.talanta.2020.121835
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Salah E, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621502108
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Sayah MM, 2022, MULTIMED TOOLS APPL, V81, P43613, DOI 10.1007/s11042-021-11791-2
   Shen YX, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114414
   Sivananthamaitrey P, 2018, INT J ENG TECHNOL, V7, DOI DOI 10.14419/IJET.V7I3.29.18463
   Sivananthamaitrey P., 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2021.01.711, DOI 10.1016/J.MATPR.2021.01.711]
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Zermi N, 2022, CYBERNET SYST, V53, P282, DOI 10.1080/01969722.2021.1983700
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
NR 53
TC 6
Z9 6
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35401
EP 35417
DI 10.1007/s11042-023-14792-5
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000955291700001
DA 2024-07-18
ER

PT J
AU Mehra, S
   Susan, S
AF Mehra, Sunakshi
   Susan, Seba
TI Deep fusion framework for speech command recognition using acoustic and
   linguistic features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic features; Linguistic features; Fusion framework;
   Self-attention; Bidirectional long short-term memory
ID WORD RECOGNITION; SPECTROGRAM; SYSTEM
AB The research problem addressed in this study is how to effectively combine multimodal data from imperfect text transcripts and raw audio in a deep framework for automatic speech recognition. In this study, we suggest combining audio and text modalities late in the process. We propose a self-attention based deep bidirectional long short-term memory (SA-deep BiLSTM) for processing audio and text data independently. For training each type of feature, we use the SA-deep BiLSTM model which comprises of five BiLSTM layers and a self-attention module between the third and fourth layers. The linguistic data, like the word stem extracted from the text transcript, and acoustic features like Mel frequency cepstral coefficients (MFCC) and Mel-spectrogram are taken into consideration. The GloVe word embedding is used to vectorize the linguistic data. By fusing the posterior class probabilities of SA-deep BiLSTM models trained on individual modalities, we were able to achieve an accuracy of 98.80% on the 10-word categories of the Google speech command dataset. Numerous tests using the Google speech command dataset and ablation analysis prove that the suggested method performs better than the state of the art because of the high classification accuracies attained.
C1 [Mehra, Sunakshi; Susan, Seba] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
C3 Delhi Technological University
RP Mehra, S (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM mehra.sunakshi623@gmail.com
RI Mehra, Sunakshi/IZD-5670-2023; Susan, Dr. Seba/KHY-0356-2024; Susan,
   Seba/V-4527-2019
OI Susan, Seba/0000-0002-6709-6591; Mehra, Sunakshi/0000-0002-6397-6049
CR Abdelmaksoud E., 2021, Egyptian J. Lang. Eng, V8, P27, DOI 10.21608/ejle.2020.47685.1015
   Aldarmaki H, 2022, SPEECH COMMUN, V139, P76, DOI 10.1016/j.specom.2022.02.005
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bastanfard A, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349583
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Boigne J, 2020, ARXIV
   Cabrera R, 2021, ARXIV
   Cances L, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P361, DOI 10.1109/ICASSP39728.2021.9415116
   Cheng J., 2016, ARXIV
   Chi PH, 2021, IEEE W SP LANG TECH, P344, DOI 10.1109/SLT48900.2021.9383575
   Cui ZY, 2020, TRANSPORT RES C-EMER, V118, DOI 10.1016/j.trc.2020.102674
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   De Andrade DC, 2018, ARXIV
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P69
   Gallardo-Antolín A, 2021, NEUROCOMPUTING, V456, P49, DOI 10.1016/j.neucom.2021.05.065
   Haque MA, 2020, ADV INTELL SYST COMP, V1045, P507, DOI 10.1007/978-981-15-0029-9_40
   Higy B., 2018, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hyder R, 2017, INTERSPEECH, P3073, DOI 10.21437/Interspeech.2017-431
   Kardakis S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093883
   Kim S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7333, DOI 10.1109/ICASSP39728.2021.9414784
   Kumaran U, 2021, INT J SPEECH TECHNOL, V24, P303, DOI 10.1007/s10772-020-09792-x
   Le D.-T., 2021, ARXIV
   Lezhenin I, 2019, FED CONF COMPUT SCI, P57, DOI 10.15439/2019F185
   Li J., 2021, MULTIMED TOOLS APPL, V81, P1
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Liu G.K., 2018, arXiv
   Macary M, 2021, IEEE W SP LANG TECH, P373, DOI 10.1109/SLT48900.2021.9383456
   Mahdavi R, 2020, IEEE INT COMPUT C, P1
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   McDermott E, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P434, DOI [10.1109/ASRU46091.2019.9003790, 10.1109/asru46091.2019.9003790]
   Meghanani A, 2021, IEEE W SP LANG TECH, P670, DOI 10.1109/SLT48900.2021.9383491
   Mehra S., 2020, INT ADV COMP C, P256
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Nagrani A, 2021, ARXIV
   Oganyan M, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12060750
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Phaye SSR, 2019, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2019.8683288
   Porter M, 1999, PORTER STEMMING ALGO
   Ravuri S, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P135
   Sakashita Y, 2018, Acoustic scene classification by ensemble of spectrograms based on adaptive temporal divisions
   Schneider S, 2019, INTERSPEECH, P3465, DOI 10.21437/Interspeech.2019-1873
   Shah VH, 2021, ADV MACHINE LEARNING, P695
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Su Y, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107050
   Susan J., 2019, INT C MINING INTELLI, P320
   Susan S., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P842, DOI 10.1109/CICN.2012.16
   Susan S, 2021, MULTIMED TOOLS APPL, V80, P29601, DOI 10.1007/s11042-021-11092-8
   Susan S, 2017, INT CONF CONTEMP, P78
   Tripathi Mayank, 2020, Artificial Intelligence and Soft Computing. 19th International Conference, ICAISC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12415), P252, DOI 10.1007/978-3-030-61401-0_24
   Tur Gokhan, 2011, SPOKEN LANGUAGE UNDE
   Veisi H., 2021, J Signal Data Process, V17, P67, DOI [10.29252/jsdp.17.4.67, DOI 10.29252/JSDP.17.4.67]
   Warden P, 2018, ArXiv e-prints: 1804.03209
   Wazir ASMBA, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P339, DOI [10.1109/i2cacis.2019.8825004, 10.1109/I2CACIS.2019.8825004]
   Wei Y., 2021, J AMB INTEL HUM COMP, V13, P1
   Yi C, 2021, IEEE SIGNAL PROC LET, V28, P788, DOI 10.1109/LSP.2021.3071668
   Zeng MJ, 2019, IEEE ACCESS, V7, P10767, DOI 10.1109/ACCESS.2019.2891838
   Zhang S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6249, DOI 10.1109/ICASSP39728.2021.9414428
   Zheng R., 2021, ARXIV
   Zia T, 2019, INT J SPEECH TECHNOL, V22, P21, DOI 10.1007/s10772-018-09573-7
NR 62
TC 5
Z9 5
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38667
EP 38691
DI 10.1007/s11042-023-15118-1
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000955293100014
DA 2024-07-18
ER

PT J
AU Yang, KX
   Wang, HY
   Du, M
   Wang, ZZ
   Tan, ZY
   Zhang, J
   Xiao, YY
AF Yang, Kaixiang
   Wang, Hongya
   Du, Ming
   Wang, Zhizheng
   Tan, Zongyuan
   Zhang, Jie
   Xiao, Yingyuan
TI An efficient indexing technique for billion-scale nearest neighbor
   search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Approximate nearest neighbor search; Hierarchical navigable small world
   graph; Product quantization; Re-rank
ID CODES
AB Approximate nearest neighbor search is an indispensable component in many computer vision applications. To index more data, such as images, on one commercial server, Douze et al. introduced L&C that works on operating points considering 64-128 bytes per vector. While the idea is inspiring, we observe that L&C still suffers the accuracy saturation problem, which it is aimed to solve. To this end, we propose a simple yet effective two-layer graph index structure, together with dual residual encoding, to attain higher accuracy. Particularly, we partition vectors into multiple clusters and build the top-layer graph using the corresponding centroids. For each cluster, a subgraph is created with compact codes of the first-level vector residuals. Such an index structure provides better graph search precision as well as saves quite a few bytes for compression. We employ the second-level residual quantization to re-rank the candidates obtained through graph traversal, which is more efficient than regression-from-neighbors adopted by L&C. Comprehensive experiments show that our proposal obtains over 10% and 30% higher recall@1 than the state-of-the-arts, and achieves up to 7.7x and 6.1x speedup over L&C on Deep1B and Sift1B, respectively. Our proposal also attains 90%+ recall@10 and recall@100 on two billion-sized datasets at the cost of 10ms per query.
C1 [Yang, Kaixiang; Wang, Hongya; Du, Ming; Wang, Zhizheng; Tan, Zongyuan] Donghua Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
   [Yang, Kaixiang; Wang, Hongya] Chinese Acad Sci, State Key Lab Comp Architecture, ICT, Beijing, Peoples R China.
   [Yang, Kaixiang; Wang, Hongya] Shanghai Key Lab Comp Software Evaluating & Testin, Shanghai, Peoples R China.
   [Zhang, Jie] Donghua Univ, Inst Artificial Intelligence, Shanghai, Peoples R China.
   [Xiao, Yingyuan] Tianjin Univ Technol, Sch CSE, Tianjin, Peoples R China.
C3 Donghua University; Chinese Academy of Sciences; Donghua University;
   Tianjin University of Technology
RP Wang, HY (corresponding author), Donghua Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.; Wang, HY (corresponding author), Chinese Acad Sci, State Key Lab Comp Architecture, ICT, Beijing, Peoples R China.; Wang, HY (corresponding author), Shanghai Key Lab Comp Software Evaluating & Testin, Shanghai, Peoples R China.
EM hywang@dhu.edu.cn
RI zou, yao/KCK-8222-2024; chen, huan/KEC-2019-2024; yan, su/KHT-1728-2024;
   Wang, Ling/AGR-4917-2022; Li, Chun/KBC-9591-2024; Wang,
   Siying/KHX-1894-2024; Ma, Wei/JXY-5019-2024; Yang,
   Kaixiang/AGZ-1602-2022; Zhao, Hang/KCL-7278-2024; Wang,
   Ling/KBA-9814-2024; li, yuan/KBQ-4200-2024
OI Wang, Ling/0000-0003-0272-2974; Ma, Wei/0000-0002-7344-998X; Yang,
   Kaixiang/0000-0003-2180-2101; Wang, Ling/0000-0003-0272-2974; 
FU NSF of Shanghai [22ZR1402000]; Fundamental Research Funds for the
   Central Universities [2232021A-08]; State Key Laboratory of Computer
   Architecture (ICT,CAS) [CARCHB 202118]; Information Development Project
   of Shanghai Economic and Information Commission [202002009]; National
   Natural Science Foundation of China [61906035]
FX The work reported in this paper is partially supported by NSF of
   Shanghai under grant number 22ZR1402000, the Fundamental Research Funds
   for the Central Universities under grant number 2232021A-08, State Key
   Laboratory of Computer Architecture (ICT,CAS) under Grant No. CARCHB
   202118, Information Development Project of Shanghai Economic and
   Information Commission (202002009) and National Natural Science
   Foundation of China (No.61906035).
CR Andre F, 2018, ARXIV
   [Anonymous], 2011, P 17 ACM SIGKDD INT, DOI DOI 10.1145/2020408.2020576
   ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271
   Babenko A, 2014, ARXIV
   Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226
   Babenko A, 2015, PROC CVPR IEEE, P4240, DOI 10.1109/CVPR.2015.7299052
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Baranchuk D, 2019, PR MACH LEARN RES, V97
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Beyer K., 1999, Proceedings of the 7th International Conference on Database Theory, ICDT'99, DOI [10.1007/3-540-49257-7_15, DOI 10.1007/3-540-49257-7_15]
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Douze M, 2018, PROC CVPR IEEE, P3646, DOI 10.1109/CVPR.2018.00384
   Douze M, 2018, PROC CVPR IEEE, P3349, DOI 10.1109/CVPR.2018.00353
   Douze M, 2016, LECT NOTES COMPUT SC, V9906, P785, DOI 10.1007/978-3-319-46475-6_48
   Fu C, 2019, PROC VLDB ENDOW, V12, P461, DOI 10.14778/3303753.3303754
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Gupta S, 2020, PATTERN ANAL APPL, V23, P1569, DOI 10.1007/s10044-020-00879-4
   Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616
   He R, 2015, PATTERN RECOGN, V48, P3160, DOI 10.1016/j.patcog.2015.03.016
   Jégou H, 2011, INT CONF ACOUST SPEE, P861
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jin L, 2023, IEEE T NEUR NET LEAR, V34, P1838, DOI 10.1109/TNNLS.2020.2997020
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Li W, 2020, IEEE T KNOWL DATA EN, V32, P1475, DOI 10.1109/TKDE.2019.2909204
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Lin P.-M., 2019, ARXIV
   Liu S., 2017, 2017 International Conference on Algorithms, Methodology, Models and Applications in Emerging Technologies (ICAMMAET), Chennai, P1, DOI DOI 10.1109/ICAMMAET.2017.8186747
   Liu YF, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P667, DOI 10.1145/3132847.3132901
   Lv Qin, 2004, P 13 ACM INT C INF K, P208, DOI DOI 10.1145/1031171.1031213
   Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473
   Matsui Y, 2018, ITE TRANS MEDIA TECH
   Matsui Y, 2018, IEEE T MULTIMEDIA, V20, P1809, DOI 10.1109/TMM.2017.2774009
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Shakhnarovich G., 2006, NEAREST NEIGHBOR MET
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Teodoro G, 2014, VLDB J, V23, P427, DOI 10.1007/s00778-013-0329-7
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Zhang T, 2014, ICML, V2, P3
   Zhansheng Jiang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P325, DOI 10.1007/978-3-319-27671-7_27
   Zhao K, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2567, DOI 10.1145/3357384.3357834
NR 45
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31673
EP 31689
DI 10.1007/s11042-023-14825-z
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000955293100006
DA 2024-07-18
ER

PT J
AU Mathew, D
   Kumar, CS
   Cherian, KA
AF Mathew, Deepthy
   Kumar, C. Sathish
   Cherian, K. Anita
TI Integration of nondecimated quaternion wavelet transform and
   neighborhood texture patterns for disease classification in banana
   (<i>Musa</i> spp.) foliage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nondecimated quaternion wavelet transform; Local binary pattern; Plant
   disease classification; Texture analysis
ID IMAGE-PROCESSING TECHNIQUES; LOCAL BINARY PATTERN; IDENTIFICATION;
   DIAGNOSIS; FEATURES
AB Fungal diseases of banana is a global threat to banana production and cultivation. Diagnosis of these diseases using an identification system limited by human visual capabilities often lead to misinterpretation of diseases, causing severe yield losses. An automated fungal disease identification method in banana plants using nondecimated quaternion wavelet Transform (NDQWT) and texture features is being detailed in this paper. The discoloration pattern appearing on banana leaf blade, at the early stages of infection, are used for classifying three major fungal diseases namely, Sigatoka, Cordana and Deightoneilla. The captured leaf images are enhanced and segmentation algorithms are applied to identify the infected regions. The segmented images are converted to transform domain using spatial-frequency transforms (discrete wavelet transforms (DWT), dual tree complex wavelet transforms (DTCWT) and NDQWT). Texture features are extracted from transform domain images using local neighborhood patterns. The feature vectors are applied to five popular classifiers and performance metrics are estimated. A comparative analysis of these methods shows best classification performance (accuracy, precision, sensitivity, specificity, F-score) for gradient directional pattern (GDP) and noise resistant local binary pattern (NRLBP) based feature vectors extracted from combined magnitude and phase components of NDQWT transformed images. To the best of our knowledge, this methodology of feature extraction from combined phase and magnitude components of NDQWT transformed images is novel and efficient when compared with traditional methods.
C1 [Mathew, Deepthy; Kumar, C. Sathish] APJ Abdul Kalam Technol Univ, Rajiv Gandhi Inst Technol, Dept Elect & Commun Engn, Pampady, Kottayam 686501, Kerala, India.
   [Cherian, K. Anita] Kerala Agr Univ, Coll Agr, Dept Plant Pathol, Trichur 680656, Kerala, India.
C3 Rajiv Gandhi Institute of Technology Kottayam
RP Kumar, CS (corresponding author), APJ Abdul Kalam Technol Univ, Rajiv Gandhi Inst Technol, Dept Elect & Commun Engn, Pampady, Kottayam 686501, Kerala, India.
EM deepthygigin@gmail.com; kumarcsathish@gmail.com; anitacheriank@gmail.com
OI Kumar, Dr C Sathish/0000-0002-1008-7467
FU Center for Engineering Research and Development, Government of Kerala,
   India [KTU/Research/2743/2017]
FX This work has received funding from Center for Engineering Research and
   Development, Government of Kerala, India, vide grant no.
   KTU/Research/2743/2017.
CR Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Amara J., 2017, LECT NOTES INFORM LN
   Anjna, 2020, PROCEDIA COMPUT SCI, V167, P1056, DOI 10.1016/j.procs.2020.03.404
   [Anonymous], 2016, INT J ENG SCI COMPUT
   Aruraj Akshaya, 2019, 2019 2nd International Conference on Signal Processing and Communication (ICSPC). Proceedings, P231, DOI 10.1109/ICSPC46172.2019.8976582
   Basavaiah J, 2020, WIRELESS PERS COMMUN, V115, P633, DOI 10.1007/s11277-020-07590-x
   Bharath R, 2018, BIOCYBERN BIOMED ENG, V38, P145, DOI 10.1016/j.bbe.2017.12.004
   Bulow, 1999, HYPERCOMPLEX SPECTRA
   Dhingra G, 2019, MEASUREMENT, V135, P782, DOI 10.1016/j.measurement.2018.12.027
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Diwakar Manoj, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P343, DOI 10.1007/978-981-13-0589-4_32
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   FAO, 2021, BAN MARK REV, V20
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gajalakshmi K, 2018, OPTIK, V157, P724, DOI 10.1016/j.ijleo.2017.11.183
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   GROSS MH, 1994, IEEE IMAGE PROC, P412, DOI 10.1109/ICIP.1994.413816
   Ilhan HO, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P577, DOI 10.1109/TSP.2018.8441431
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Islam ST, 2019, 2019 3 INT C EL COMP, P53
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Jones D. R., 2000, P1
   Jose S, 2020, SIGNAL IMAGE VIDEO P, V14, P601, DOI 10.1007/s11760-019-01590-6
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Koh JEW, 2019, FUTURE GENER COMP SY, V90, P86, DOI 10.1016/j.future.2018.07.044
   Kong TW, 2019, Arxiv, DOI arXiv:1903.00790
   Kumar P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3985
   Kumar V., 2018, 2016 3 INT C ARTIFIC, V3, P452
   Kumari CU, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P1095, DOI [10.1109/iccmc.2019.8819750, 10.1109/ICCMC.2019.8819750]
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Mary NAB, 2020, MULTIMED TOOLS APPL, V79, P30601, DOI 10.1007/s11042-020-09521-1
   Mathew D, 2021, INFORM PROCESS AGR, V8, P581, DOI 10.1016/j.inpa.2020.11.002
   Mustafa MS, 2020, NEURAL COMPUT APPL, V32, P11419, DOI 10.1007/s00521-019-04634-7
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Pridham G, 2020, MAGN RESON IMAGING, V72, P150, DOI 10.1016/j.mri.2020.07.007
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Salman A., 2017, 2017 International Conference on Inventive Systems and Control (ICISC). p, P1, DOI 10.1109/ICISC.2017.8068597
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharma M, 2018, INT J FUZZY SYST, V20, P1297, DOI 10.1007/s40815-018-0455-x
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Srinivas J, 2018, Period Eng Nat Sci, V7, P593
   Sun YY, 2019, COMPUT ELECTRON AGR, V157, P102, DOI 10.1016/j.compag.2018.12.042
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Vipindas M, 2016, Int J Adv Eng Res Sci, V3, P120
   Wang G, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2917536
   Xie CQ, 2017, COMPUT ELECTRON AGR, V135, P154, DOI 10.1016/j.compag.2016.12.015
   Yang P, 2016, NEUROCOMPUTING, V197, P212, DOI 10.1016/j.neucom.2016.02.061
   Yepez J, 2018, IET INTELL TRANSP SY, V12, P542, DOI 10.1049/iet-its.2017.0224
NR 53
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-14869-1
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XA1
UT WOS:000954480900002
DA 2024-07-18
ER

PT J
AU Sun, CL
   Xiong, W
   Wang, HT
   Guan, GF
AF Sun, Changle
   Xiong, Wei
   Wang, Haitao
   Guan, Guangfeng
TI Design reuse oriented retrieval of mechanical 3D model using function
   dimension matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Function dimension; Engineering shape matching; Retrieval; Design reuse
ID CAD MODELS; ALGEBRA
AB In the process of modern mechanical product design, retrieval and reuse of the pre-existed 3D CAD models would greatly save time and cost. Mechanical models, as artificial models, are mainly composed of regular surfaces, and the function of the models is to constrain mechanical movements. The purpose of retrieval is to reuse the functions of models designed by predecessors. To mine the functions contained in mechanical models, this paper proposes an original function dimension (FD)-based engineering shape matching method. Firstly, the function vector of each face making up the model is defined according to its use, machining or assembly method. Then the vectors are grouped to form the FDs of the model by using parallel relation which describes the function dimension of the model. The similarity between CAD models can be obtained by weighting the similarity between the matched FDs using area and angle. Based on FDs, the performance of model retrieval can be improved to facility functional reuse from geometric similarity. We validate the FD-based 3D model retrieval method using the popular ESB database and one novel multi-modal dataset. Extensive experiments show the superiority of the proposed method through comparisons. It has better retrieval accuracy and higher efficiency (3 x 10(9) models/second). Moreover, to the best of our knowledge, the novel engineering 3D object dataset that we contribute is closest to real engineering models presently.
C1 [Sun, Changle; Xiong, Wei; Wang, Haitao; Guan, Guangfeng] Dalian Maritime Univ, Dept Mech Engn, Linghai Rd 1, Dalian 116026, Liaoning, Peoples R China.
C3 Dalian Maritime University
RP Sun, CL (corresponding author), Dalian Maritime Univ, Dept Mech Engn, Linghai Rd 1, Dalian 116026, Liaoning, Peoples R China.
EM xxcl1999@126.com
OI Sun, Changle/0000-0002-4016-5817
FU Unveiling and Commanding Science and Technology Project of Liaoning
   Province [2021JH1/10400093]; National Key R&D Program of China
   [2022YFC3006004]
FX AcknowledgmentsThis work was supported by Unveiling and Commanding
   Science and Technology Project of Liaoning Province
   (No.2021JH1/10400093), National Key R&D Program of China
   (2022YFC3006004).
CR Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   [Anonymous], 2004, P 13 TEXT RETR C
   Bai J, 2010, COMPUT AIDED DESIGN, V42, P1069, DOI 10.1016/j.cad.2010.07.002
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Biasotti S, 2014, EUROGRAPHICS 2014 ST
   Bruno IJ, 1997, CARBOHYD RES, V304, P61, DOI 10.1016/S0008-6215(97)00196-1
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Cheng HC, 2011, COMPUT IND, V62, P269, DOI 10.1016/j.compind.2010.09.001
   Daras P, 2006, IEEE ACM T COMPUT BI, V3, P193, DOI 10.1109/TCBB.2006.43
   Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142
   Fish N, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982409
   Gao HH, 2023, IEEE T INTELL TRANSP, V24, P8831, DOI 10.1109/TITS.2022.3219474
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Z, 2022, IEEE T CIRC SYST VID, V32, P2264, DOI 10.1109/TCSVT.2021.3091581
   Giannini F, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4036120
   Goodall S, 2004, LECT NOTES COMPUT SC, V3115, P638
   Gunn T. G., 1982, Scientific American, V247, P86, DOI 10.1038/scientificamerican0982-114
   Han ZP, 2018, J ADV MECH DES SYST, V12, DOI 10.1299/jamdsm.2018jamdsm0023
   Huangfu ZM, 2017, MULTIMED TOOLS APPL, V76, P8145, DOI 10.1007/s11042-016-3456-5
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Jackson C., 2007, The design reuse benchmark report: seizing the opportunity to shorten product development
   Jakovljevic Z, 2015, IEEE T IND INFORM, V11, P342, DOI 10.1109/TII.2015.2389195
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Jing H, 2009, APPL MECH MATER, V16-19, P65, DOI 10.4028/www.scientific.net/AMM.16-19.65
   Kastenmuller G, 1998, P GERM C BIOINF GCB
   Kim H, 2017, J MECH SCI TECHNOL, V31, P5627, DOI 10.1007/s12206-017-1103-3
   Kim H, 2017, MULTIMED TOOLS APPL, V76, P15867, DOI 10.1007/s11042-016-3881-5
   Li M, 2009, J MECH DESIGN, V131, DOI 10.1115/1.4000253
   Li PJ, 2011, MM 2011 P 19 ACM INT, V11, P1425
   Lin X, 2018, IEEE T IND INFORM, V14, P265, DOI 10.1109/TII.2017.2696042
   Liu AA, 2022, IEEE T CYBERNETICS, V52, P13862, DOI 10.1109/TCYB.2021.3139927
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu YJ, 2013, IEEE T AUTOM SCI ENG, V10, P783, DOI 10.1109/TASE.2012.2228481
   LLEWELYN AI, 1989, COMPUT AIDED DESIGN, V21, P297, DOI 10.1016/0010-4485(89)90036-5
   Lun ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766929
   Lupinetti K, 2019, COMPUT AIDED DESIGN, V113, P62, DOI 10.1016/j.cad.2019.03.005
   Machalica D, 2019, ARCH MECH ENG, V66, P133, DOI 10.24425/ame.2019.128441
   Orio N, 2004, 2 INT S 3D DATA PROC
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   POPE AR, 1994, 9404 U BRIT COL DEP
   Rowe J, 2001, P 4 INT C DIG LIB
   Schulz A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983618
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tao SQ, 2018, MULTIMED TOOLS APPL, V77, P16249, DOI 10.1007/s11042-017-5197-5
   Ullman D.G., 1997, MECH DESIGN PROCESS
   Wang P, 2016, INT J ADV MANUF TECH, V86, P2635, DOI 10.1007/s00170-016-8368-z
   Wu YH, 2013, CHIN J MECH ENG-EN, V26, P248, DOI 10.3901/CJME.2013.02.248
   Zarpalas D, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/23912
   Zehtaban L, 2016, J COMPUT DES ENG, V3, P274, DOI 10.1016/j.jcde.2016.04.002
   Zhang C, 2019, ADV ENG SOFTW, V127, P82, DOI 10.1016/j.advengsoft.2018.09.001
   Zhang J, 2018, ROBOT CIM-INT MANUF, V51, P103, DOI 10.1016/j.rcim.2017.11.012
   Zhuang T, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/6049750
NR 56
TC 0
Z9 0
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24521
EP 24545
DI 10.1007/s11042-023-15102-9
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000983548500004
DA 2024-07-18
ER

PT J
AU Poornima, E
   Muthu, B
   Agrawal, R
   Kumar, SP
   Dhingra, M
   Asaad, RR
   Jumani, AK
AF Poornima, E.
   Muthu, BalaAnand
   Agrawal, Ruchi
   Kumar, S. Pradeep
   Dhingra, Mallika
   Asaad, Renas Rajab
   Jumani, Awais Khan
TI Fog robotics-based intelligence transportation system using
   line-of-sight intelligent transportation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Autonomous driving; Decentralized wireless
   sensor; Fabrication framework; Fog- robotics transportation
ID NEURAL-NETWORKS
AB Intelligent Transportation System (ITS) idea was developed to improve road safety, traffic management efficiency, and environmental preservation. The fog- robotics Based Intelligent Transportation Systems integrate Internet of Vehicles (IoV) devices to Fog Computing (FC) centers, which process the data. On the other hand, providing massive data from widely distant devices causes network overhead and bottlenecks in Autonomous Driving and a drain on Energy Management. To fill this research gap, fog-robotics-based intelligent transportation systems are proposed to cover the line-of-sight direction for path adopting self-directed intelligent transportation. The Intelligent Transportation Systems with FC Techniques work towards the Fog Robotics Platform for making efficient fog- robotics Transportation Systems. The Proposed System has two functionalities; firstly, the analysis of automatic Fog- robotics transportation systems is introducing decentralized wireless sensor transfer assisted flocking autonomous driving for energy management of fog- robotics transportation systems. It Shows the Sensor activities as per the "scanning of the roadside meter." It enumerates speed control. Secondly, Artificial Intelligence Enabled Intelligent speed assistance is formed based on Vehicle Infrastructure Integration (VII). This Vehicle infrastructure integration is used to show the Smart highway, which is adaptable with the fog- robotics Transportation Systems. Although the formation of "Digital modeling and fabrication framework" procedural aspect employed to connect the "Fog- robotics Transportation Systems" and "Vehicle infrastructure integration." This Artificial Intelligence configuration is used to Enabled Intelligent speed assistance for controlling the car for their atmosphere. Finally, these rely on are consolidated with the position/navigation system, and the vehicle detection ratio is analyzed with the vehicle efficiency and economic activity for intelligent speed assistance.
C1 [Poornima, E.] Gokaraju Rangaraju Inst Engn & Technol, Dept CSE AI ML, Hyderabad, India.
   [Muthu, BalaAnand] Tagore Inst Engn & Technol, Dept Comp Sci & Engn, Salem, India.
   [Agrawal, Ruchi] GLA Univ, Mathura, India.
   [Kumar, S. Pradeep] SK Univ, Univ Coll Engn & Technol, Dept Civil Engn, Ananthapuram, India.
   [Dhingra, Mallika] Manipal Univ Jaipur, Dept Math & Stat, Jaipur 303007, Rajasthan, India.
   [Asaad, Renas Rajab] Nawroz Univ, Dept Comp Sci, Duhok, Kurdistan Regio, Iraq.
   [Jumani, Awais Khan] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Jumani, Awais Khan] ILMA Univ Karachi, Dept Comp Sci, Karachi, Sindh, Pakistan.
C3 Gokaraju Rangaraju Institute of Engineering & Technology; GLA
   University; Manipal University Jaipur; Nawroz University; South China
   University of Technology
RP Poornima, E (corresponding author), Gokaraju Rangaraju Inst Engn & Technol, Dept CSE AI ML, Hyderabad, India.
EM poornimacse561@gmail.com; balavdy@gmail.com; ruchi.agrawal@gla.ac.in;
   pradeepkumar.ksrm@gmail.com; mallikadhingra13@gmail.com;
   renas.rekany@nawroz.edu.krd; awaisjumani@yahoo.com
RI Jumani, Awais Khan/AAB-2591-2020; Dhingra, Mallika/IYJ-0668-2023; Rajab
   Asaad, Renas/AAS-7862-2020; E, Poornima/KHY-5921-2024; Anand,
   Bala/AFO-6912-2022
OI Jumani, Awais Khan/0000-0001-9468-0446; Rajab Asaad,
   Renas/0000-0002-1762-662X; E, Poornima/0000-0003-0438-0867; Anand,
   Bala/0000-0002-9509-6943; Dhingra, Dr. Mallika/0000-0001-6838-0933; ,
   renas khalid/0009-0007-0497-7117
CR Anthes E, 2017, NATURE, V550, P316, DOI 10.1038/550316a
   Azadani MN, 2022, IEEE T INTELL TRANSP, V23, P6027, DOI 10.1109/TITS.2021.3076140
   Baggio G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21554-0
   Chen BZ, 2022, NAT CHEM BIOL, V18, P289, DOI 10.1038/s41589-021-00934-z
   Feng S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21007-8
   Gargoum S, 2022, INFRASTRUCTURES-BASE, V7, DOI 10.3390/infrastructures7010007
   Göppert A, 2023, J INTELL MANUF, V34, P2133, DOI 10.1007/s10845-021-01860-6
   Gohar A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13095188
   Goldberg K, 2019, NAT MACH INTELL, V1, P2, DOI 10.1038/s42256-018-0008-x
   Guerrero-Ibañez J, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4169
   Gupta Ambika, 2020, 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA). Proceedings, P236, DOI 10.1109/ICIMIA48430.2020.9074911
   Gupta A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25874-z
   Hoeft M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13073779
   Ko KKK, 2022, NAT MICROBIOL, V7, P486, DOI 10.1038/s41564-022-01089-w
   Kosacka-Olejnik M, 2021, ENERGIES, V14, DOI 10.3390/en14164919
   Kumar Anuj, 2020, 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC), P514, DOI 10.1109/PARC49193.2020.236666
   Kumar M, 2021, 2021 CONFERENCE ON LASERS AND ELECTRO-OPTICS EUROPE & EUROPEAN QUANTUM ELECTRONICS CONFERENCE (CLEO/EUROPE-EQEC), DOI 10.1109/CLEO/Europe-EQEC52157.2021.9542121
   Lee D, 2021, AUTOMAT CONSTR, V127, DOI 10.1016/j.autcon.2021.103688
   Leung EKH, 2022, INT J PROD ECON, V244, DOI 10.1016/j.ijpe.2021.108353
   [Lin Yue 蔺玥], 2021, [系统仿真学报, Journal of System Simulation], V33, P1600
   Ling C, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00713-x
   Liu YS, 2021, SCI TOTAL ENVIRON, V795, DOI 10.1016/j.scitotenv.2021.148926
   [刘宗巍 Liu Zongwei], 2021, [中国工程科学, Strategic Study of CAE], V23, P153
   Mahani MAN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-03521-2
   Massari L, 2022, NAT MACH INTELL, V4, P425, DOI 10.1038/s42256-022-00487-3
   Mishra M., 2021, Autonomous Driving and Advanced Driver-Assistance Systems (ADAS), P401, DOI 10.1201/9781003048381-21
   Mo YH, 2022, MULTIMED TOOLS APPL, V81, P4603, DOI 10.1007/s11042-020-10488-2
   Moussa R, 2022, J ENG RES-KUWAIT, V10
   Narkhede MM, 2021, INT C MACH LEARN BIG, P253
   Pradhan Rahul, 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P433, DOI 10.1007/978-981-15-0694-9_41
   Qian Y, 2021, CICTP 2021: ADVANCED TRANSPORTATION, ENHANCED CONNECTION, P2128
   Rahmani B, 2020, NAT MACH INTELL, V2, P403, DOI 10.1038/s42256-020-0199-9
   Rana MM, 2023, INT J PAVEMENT RES T, V16, P264, DOI 10.1007/s42947-021-00130-1
   Rohde CB, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1266
   Sahal R, 2021, MACHINES, V9, DOI 10.3390/machines9090193
   Sanghvi A, 2021, IEEE TRANSP ELECT C, P573, DOI 10.1109/ITEC51675.2021.9490069
   Shou YX, 2021, AEROSP SCI TECHNOL, V111, DOI 10.1016/j.ast.2021.106564
   Sirina N., 2021, Transp Res Procedia, V54, P208, DOI [10.1016/j.trpro.2021.02.066, DOI 10.1016/J.TRPRO.2021.02.066]
   Vasiliev A, 2021, MACHINES, V9, DOI 10.3390/machines9010008
   Won S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12679-4
   Wu BB, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49380-x
   Wu YW, 2021, IEEE INTERNET THINGS, V8, P13789, DOI 10.1109/JIOT.2021.3079510
   Zemmar A, 2020, NAT MACH INTELL, V2, P566, DOI 10.1038/s42256-020-00238-2
   Zhang Jian, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428368
   Zheng ZQ, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20697-w
   Zholl SP, 2021, ASSEMBLY AUTOM, V41, P384, DOI 10.1108/AA-02-2021-0017
   Zhu ZJ, 2021, NAT REV MATER, V6, P27, DOI 10.1038/s41578-020-00235-2
NR 47
TC 6
Z9 6
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 17
PY 2023
DI 10.1007/s11042-023-15086-6
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A2FH1
UT WOS:000953336200001
DA 2024-07-18
ER

PT J
AU Tang, PJ
   Tan, YL
   Xia, JW
AF Tang, Pengjie
   Tan, Yunlan
   Xia, Jiewu
TI Deep sequential collaborative cognition of vision and language based
   model for video description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video description; Collaborative cognition; Multi-modal alignment;
   Sequential fusion; Joint optimization
AB Video description is to translate video into natural language with appropriate sentence patterns and decent words. The task is challenging due to the great semantic gap between visual content and language. Nowadays, many well-designed models are developed. However, the language information is often insufficiently discovered and cannot be effectively integrated with visual representation, leading to that the correlations of vision and language are difficult to be constructed. Inspired by the process of human learning and cognition for vision and language, a deep collaborative cognition of vision and language based model (VL-DCC) is proposed in this work. In detail, an extra language encoding branch is designed and integrated with the visual motion encoding branch based on sequence to sequence pipeline during model learning, to simulate the process of human learning visual information and language. Additionally, a double VL-DCC (DVL-DCC) framework is developed to further improve the quality of generated sentences, where the element-wise addition and feature concatenation operation are employed and implemented on two different VL-DCC modules respectively to comprehensively capture visual and language semantics. Experiments on MSVD and MSR-VTT2016 datasets are conducted to evaluate the proposed model, and better results are achieved compared with the baseline model and other popular works, with the CIDEr reaching to 81.3 and 46.7 on the two datasets respectively.
C1 [Tang, Pengjie; Tan, Yunlan; Xia, Jiewu] Jinggangshan Univ, Elect & Informat Engn Coll, Jian 343009, Peoples R China.
   [Tang, Pengjie; Tan, Yunlan; Xia, Jiewu] Jinggangshan Univ, Engn Lab IoT Technol Crop Growth, Jian 343009, Peoples R China.
C3 Jinggangshan University; Jinggangshan University
RP Tang, PJ (corresponding author), Jinggangshan Univ, Elect & Informat Engn Coll, Jian 343009, Peoples R China.; Tang, PJ (corresponding author), Jinggangshan Univ, Engn Lab IoT Technol Crop Growth, Jian 343009, Peoples R China.
EM tangpengjie@jgsu.edu.cn
FU National Natural Science Foundation of China [62062041, 62141203];
   Jiangxi Provincial Natural Science Foundation [20212BAB202020];
   Scientific Research Foundation of Education Bureau of Jiangxi Province
   [GJJ211009]; Jinggangshan University [JZB1923, JZB1807]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 62062041, 62141203), Jiangxi Provincial Natural Science
   Foundation (No. 20212BAB202020), Scientific Research Foundation of
   Education Bureau of Jiangxi Province (No. GJJ211009), and Ph.D. Research
   Initiation Project of Jinggangshan University (No. JZB1923, JZB1807).
CR [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   Bai Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3556, DOI 10.1145/3474085.3475519
   Ballas N., 2016, ICLR, P1
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen JW, 2019, AAAI CONF ARTIF INTE, P8167
   Chen SX, 2019, AAAI CONF ARTIF INTE, P8191
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Deb T., 2022, WACV 2022, P4070
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Guo YY, 2019, WORLD WIDE WEB, V22, P735, DOI 10.1007/s11280-018-0530-0
   Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou JY, 2019, IEEE I CONF COMP VIS, P8917, DOI 10.1109/ICCV.2019.00901
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin Chin-Yew, 2004, P 42 ANN M AOC COMP, P605, DOI [DOI 10.3115/.1218955.1219032, DOI 10.3115/1218955.1219032]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long Xiang, 2018, T ASSOC COMPUT LING, V6, P173, DOI DOI 10.1162/TACL_A_00013
   NAGEL HH, 1994, ARTIF INTELL REV, V8, P189, DOI 10.1007/BF00849074
   Nakamura K, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4220, DOI 10.1145/3474085.3475557
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryu H, 2021, AAAI CONF ART INT, P1
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2737
   Song YQ, 2021, PROC CVPR IEEE, P11240, DOI 10.1109/CVPR46437.2021.01109
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang PJ, 2020, MULTIMED TOOLS APPL, V79, P33193, DOI 10.1007/s11042-020-09674-z
   Tang PJ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3303083
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S., 2015, P ANN C N AM CHAPT A, P1494, DOI 10.3115/v1/N15-1173
   Venugopalan S., 2016, EMNLP, P1961
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wang T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6827, DOI 10.1109/ICCV48922.2021.00677
   Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu WR, 2021, IEEE T MULTIMEDIA, V23, P1772, DOI 10.1109/TMM.2020.3002669
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347
   Zhang W, 2020, IEEE T PATTERN ANAL, V42, P3088, DOI 10.1109/TPAMI.2019.2920899
NR 57
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36207
EP 36230
DI 10.1007/s11042-023-14887-z
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200016
DA 2024-07-18
ER

PT J
AU Karthikeyan, M
   Raja, D
AF Karthikeyan, M.
   Raja, D.
TI Deep transfer learning enabled DenseNet model for content based image
   retrieval in agricultural plant disease images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Agriculture; Plant disease; Content based image retrieval; Deep
   learning; Computer vision; SGD optimizer
AB Content based image retrieval (CBIR) is an effective method to retrieve the images depending upon the visual contents such as color, shape, texture, etc. Recently, the CBIR models can be employed in the agricultural sector for plant disease detection. Though several CBIR models are existed in the literature, only few works have few works have focused on the design of CBIR for plant diseases. In this aspect, this study introduces a Deep Transfer Learning Enabled DenseNet Model for Content Based Image Retrieval in Agricultural Plant Disease Images, named DTLDN-CBIRA model. Since limited number of samples exist in the dataset, data augmentation is carried out using two processes namely rotation and flipping. In addition, the DTLDN-CBIRA model uses densely connected networks (DenseNet-201) model as a feature extractor. At the same time, the hyperparameters of the deep learning (DL) models considerably influence the retrieval performance and the stochastic gradient descent (SGD) optimizer is used for hyperparameter tuning of the DenseNet-201 model. Finally, Manhattan distance metric is used to measure the similarity between the images and the images with high similarity will be retrieved from the database. The design of DTLDN-CBIRA technique for plant disease image retrieval process shows the novelty of the work. The performance validation of the DTLDN-CBIRA model takes place using benchmark dataset and the results reported the supremacy of the DTLDN-CBIRA model over the recent methods with maximum precision of 100%, recall of 81.90%, and F-score of 89.90%.
C1 [Karthikeyan, M.] Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
   [Raja, D.] DGG Arts Coll Women, Dept Comp Sci, Mayiladuthurai, Tamil Nadu, India.
C3 Annamalai University
RP Raja, D (corresponding author), DGG Arts Coll Women, Dept Comp Sci, Mayiladuthurai, Tamil Nadu, India.
EM karthiaucse@gmail.com; agdrajaphd@gmail.com
RI Karthikeyan, M./H-3492-2018
CR [Anonymous], 2010, Proceedings of the Conference on Image and Video Retrieval
   Bauer A, 2019, HORTIC RES-ENGLAND, V6, DOI 10.1038/s41438-019-0151-5
   Chiu MT, 2020, PROC CVPR IEEE, P2825, DOI 10.1109/CVPR42600.2020.00290
   Desai P., 2021, SN Comput Sci, V2, P170, DOI [10.1007/s42979-021-00529-4, DOI 10.1007/S42979-021-00529-4]
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Gravina Michela, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P296, DOI 10.1007/978-3-030-68790-8_24
   Hussein A. N., 2011, 2011 Proceedings of IEEE 7th International Colloquium on Signal Processing & its Applications (CSPA 2011), P11, DOI 10.1109/CSPA.2011.5759833
   Jadoon MM, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/3640901
   Kavitha PK, 2021, J AMB INTEL HUM COMP, V12, P5541, DOI 10.1007/s12652-020-02064-1
   Lu T, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95218-w
   Patil J.K., 2017, Engineering in agriculture, environment and food, V10, P69
   Patil JK, 2013, IAES INT J ARTIFICIA, V1
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Ramani S, 2022, MED TEACH, V44, P737, DOI 10.1080/0142159X.2021.2020739
   Rasywir E., 2022, TELKOMNIKA, V20, P118, DOI [10.12928/telkomnika.v20i1.19759, DOI 10.12928/TELKOMNIKA.V20I1.19759]
   Raval MS, 2022, DATA SCI AGR NATURAL, P97
   Singh P., 2021, Recent Advances in Computer Science and Communications, V14, P257, DOI [10.2174/2666255813666200129111928, DOI 10.2174/2666255813666200129111928]
   Sukhia KN, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102765
   Sumbul G., 2021, Deep Learning for Image Search and Retrieval in Large Remote Sensing Archives, P150, DOI [10.1002/9781119646181.ch11, DOI 10.1002/9781119646181.CH11]
   Tripathi Mukesh Kumar, 2020, Information Processing in Agriculture, V7, P183, DOI 10.1016/j.inpa.2019.07.003
   Veni S., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P243, DOI 10.1109/ICACCS51430.2021.9441805
   Wang SH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3341095
   Yaqub M, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10070427
NR 24
TC 3
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36067
EP 36090
DI 10.1007/s11042-023-14992-z
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000949737500007
DA 2024-07-18
ER

PT J
AU Luo, YJ
   Sa, JM
   Song, YY
   Jiang, H
   Zhang, C
   Zhang, ZSY
AF Luo, Yijie
   Sa, Jiming
   Song, Yuyan
   Jiang, He
   Zhang, Chi
   Zhang, Zhushanying
TI Texture classification combining improved local binary pattern and
   threshold segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; Local binary pattern; Feature extraction
AB Local Binary Pattern (LBP) is a feature extraction operator with both high texture discrimination ability and low computational complexity. Many LBP variants have been proposed to improve the performance of texture classification or overcome the drawbacks of LBP. There are three shortcomings in some LBP variants: discarding the magnitude component between local differences, adopting fixed weights in the encoding process and discarding the absolute information of the pixel gray level. Based on the three points, this paper proposes an improved LBP with two operators, local binary pattern operator based on magnitude ranking and global threshold segmentation operator, to further improve the performance. This improved LBP can achieve excellent texture classification accuracy across six common datasets, with an average of 1% lower than the best LBP variants. Meanwhile, the computational complexity of the proposed improved LBP is several times lower than that of the best LBP variants.
C1 [Luo, Yijie; Sa, Jiming; Song, Yuyan; Jiang, He; Zhang, Chi] Wuhan Univ Technol, Sch Informat Engn, Wuhan 430070, Peoples R China.
   [Sa, Jiming] Wuhan Univ Technol, Hubei Key Lab Broadband Wireless Commun & Sensor N, Wuhan 430070, Peoples R China.
   [Sa, Jiming; Jiang, He; Zhang, Zhushanying] Hubei Key Lab Med Informat Anal & Tumor Diag & Tre, Wuhan 430074, Peoples R China.
   [Zhang, Zhushanying] South Cent Minzu Univ, Coll Biomed Engn, Wuhan 430074, Peoples R China.
   [Zhang, Zhushanying] South Cent Minzu Univ, Key Lab Cognit Sci, State Ethn Affairs Commiss, Wuhan 430074, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology; South
   Central Minzu University; South Central Minzu University
RP Sa, JM (corresponding author), Wuhan Univ Technol, Sch Informat Engn, Wuhan 430070, Peoples R China.; Sa, JM (corresponding author), Wuhan Univ Technol, Hubei Key Lab Broadband Wireless Commun & Sensor N, Wuhan 430070, Peoples R China.; Sa, JM (corresponding author), Hubei Key Lab Med Informat Anal & Tumor Diag & Tre, Wuhan 430074, Peoples R China.
EM jimingsa@whut.edu.cn
RI Cheng, Lin/KFQ-3111-2024; chen, xiao/KFQ-6812-2024; Wang,
   Yitong/KBA-1959-2024; li, chunlin/KFS-0761-2024; Wang,
   Junzhe/KCK-4991-2024
CR Alkhatib M, 2019, IEEE T IMAGE PROCESS, V28, P5407, DOI 10.1109/TIP.2019.2916742
   Bedi AK, 2021, MULTIMED TOOLS APPL, V80, P20773, DOI 10.1007/s11042-021-10758-7
   Chou KY, 2020, IEEE T CIRC SYST VID, V30, P4380, DOI 10.1109/TCSVT.2019.2955926
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Khan AH, 2022, EXP TECHNIQUES, V46, P335, DOI 10.1007/s40799-021-00470-4
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   [刘丽 Liu Li], 2018, [自动化学报, Acta Automatica Sinica], V44, P584
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Liu Y, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204222
   Mallikarjuna PM Fritz., 2006, The kth-tips and kth-tips2 databases
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Song TC, 2021, IEEE T CIRC SYST VID, V31, P189, DOI 10.1109/TCSVT.2020.2972155
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Zhang T, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122016
NR 22
TC 4
Z9 4
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25899
EP 25916
DI 10.1007/s11042-023-14749-8
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000948950300003
DA 2024-07-18
ER

PT J
AU Li, K
   Liu, ZD
AF Li, Ke
   Liu, ZhanDong
TI MCANet: multi-scale contextual feature fusion network based on Atrous
   convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Atrous convolution; YOLOv5; VisDrone; VOC
AB In past studies, atrous convolution is efficient in segmentation tasks to reinforce the receptive field and detection tasks. In addition, the attention module is efficient for feature extraction and enhancement. In this paper, we introduce atrous convolution, design a feature enhancement module, and utilize a plug-and-play technique, i.e., (AFE) module. Atrous convolution has been shown to be essential for expanding the perceptual field in past studies. We achieve this by fusing multiple layers of features of atrous convolution and adding a detection head to cope with the problem of varying object size scales. We achieve the purpose of extracting multi-scale contextual feature information while using an attention mechanism to effectively enhance the features and improve the overall multi-scale detection performance of the model. It can be added to a well-established backbone network or neck network. Therefore, based on this, we designed the C3 based on the atrous convolution (C3AT) module on the AFE module, replaced the C3 module in YOLOv5, and proposed the Multi-Scale Contextual Feature Enhancement Network (MCANet) as the neck network to obtain the final network structure. Experimental results indicate that the proposed method significantly improves inference speed and AP compared to the benchmark model. Single-model object detection results on the VisDrone2021 test set-dev dataset achieved 32.7% AP and 52.2%AP(50), a significant improvement of 8.1% AP and 11.4%AP(50) compared with the baseline model. The single-model object detection results on the VOC2007 test dataset reached 89.6% mAP.
C1 [Li, Ke; Liu, ZhanDong] Xinjiang Normal Univ, Dept Comp Sci & Technol, 102 New Med Rd, Urumqi 830054, Xinjiang, Peoples R China.
C3 Xinjiang Normal University
RP Liu, ZD (corresponding author), Xinjiang Normal Univ, Dept Comp Sci & Technol, 102 New Med Rd, Urumqi 830054, Xinjiang, Peoples R China.
EM like.em@foxmail.com; lzd0825@mail.ustc.edu.cn
FU National Natural Science Foundation of China [62162061]
FX This work is supported by the National Natural Science Foundation of
   China under grant no.62162061.
CR [Anonymous], Darknet: Open source neural networks in c
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Du D., 2019, IEEE INT CONF COMP V
   Everingham M., 2011, Pattern Analysis, Statistical Modelling and Computational Learning, V8, P5
   Gao H, 2022, IEEE T NEUR NET LEAR
   Gao HH, 2023, IEEE T NETW SCI ENG, V10, P2978, DOI 10.1109/TNSE.2022.3163144
   Gao HH, 2023, IEEE T INTELL TRANSP, V24, P7599, DOI 10.1109/TITS.2022.3169421
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Ghiasi G, 2021, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR46437.2021.00294
   Gong YQ, 2021, IEEE WINT CONF APPL, P1159, DOI 10.1109/WACV48630.2021.00120
   He J, 2021, ADV NEUR IN, V34
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Leng ZQ, 2022, Arxiv, DOI [arXiv:2204.12511, DOI 10.48550/ARXIV.2204.12511]
   Lian J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093031
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ZD, 2019, MULTIMED TOOLS APPL, V78, P18205, DOI 10.1007/s11042-019-7177-4
   Luo Y, 2022, Multimed Tool Appl, P1
   Maaz M, 2022, Arxiv, DOI arXiv:2111.11430
   Castelló VO, 2020, J IMAGING, V6, DOI 10.3390/jimaging6120142
   Qu Z, 2022, IET IMAGE PROCESS, V16, P1752, DOI 10.1049/ipr2.12445
   Samyal A S, 2022, ARXIV
   Shi YX, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14050887
   Singh B, 2018, 32 C NEURAL INFORM P
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Team V, 2020, VISDR 2020 LEAD
   ultralytics, 2020, YOLOV5 V5 0 OP SOURC
   Viriyasaranon T, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07898-7
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang JQ, 2021, PROC CVPR IEEE, P9690, DOI 10.1109/CVPR46437.2021.00957
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu L, 2021, ADV NEURAL INF PROCE, V34
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Yang LX, 2021, PR MACH LEARN RES, V139
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhang HY, 2021, PROC CVPR IEEE, P8510, DOI 10.1109/CVPR46437.2021.00841
   Zhang H, 2021, Arxiv, DOI arXiv:2105.14447
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou SR, 2021, MULTIMED TOOLS APPL, V80, P11539, DOI 10.1007/s11042-020-10191-2
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
NR 47
TC 2
Z9 2
U1 10
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34679
EP 34702
DI 10.1007/s11042-023-14800-8
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000010
DA 2024-07-18
ER

PT J
AU Sahu, P
   Chug, A
   Singh, AP
   Singh, D
AF Sahu, Priyanka
   Chug, Anuradha
   Singh, Amit Prakash
   Singh, Dinesh
TI Classification of crop leaf diseases using image to image translation
   with deep-dream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Crop leaf disease detection; Deep-dream; Images;
   Convolutional neural network; Classification
ID RECOGNITION; DIAGNOSIS
AB Crop diseases are one of the primary triggers of yield devastation. As a result, early detection of crop diseases is critical to avert crop losses. In this study, a Deep-Dream (DD) based crop leaf disease detection (CLDD) architecture is proposed using a combination of Deep Learning (DL) along with Machine Learning (ML) techniques. DD is used to pre-process and segment the lesions present in leaves. The proposed novel framework involves 24 different Hybrid Deep Neural (HDN) Models that comprise the integration of eight distinct variations of the pre-trained DL model, namely EfficientNet (EffiNet) ranges from EffiNet B0-B7 in form of a feature extractor. Subsequently, three ML algorithms, namely Random Forest (RF), AdaBoost (ADB), and Stochastic Gradient Boosting (SGB) are employed as classifiers. In this study, the Optuna framework was also applied to tune the hyperparameters of these classifiers. For this implementation, the tomato crop dataset (a subset of the PlantVillage dataset) was used. It has been observed that the proposed model achieved the highest accuracy with the DD-EffiNet-B4-ADB model. The accuracy results of all the models have ranged from 84% to 96%. Moreover, DD shows a better interpretation of the disease lesions, and hence classification accuracy is also enhanced by 3% (93% to 96%) after applying DD segmentation. The proposed model was also validated with an actual-field tomato crop leaf image database gathered from the Indian Agricultural Research Institute with a high-level accuracy of 100%. This technique could help farmers to predict the pathogenic diseases at an early stage of disease visibility.
C1 [Sahu, Priyanka; Chug, Anuradha; Singh, Amit Prakash] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi, India.
   [Singh, Dinesh] Indian Agr Res Inst, Div Plant Pathol, New Delhi, India.
C3 GGS Indraprastha University; Indian Council of Agricultural Research
   (ICAR); ICAR - Indian Agricultural Research Institute
RP Sahu, P (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi, India.
EM er.priyankasahu40@gmail.com; anuradha@ipu.ac.in; amit@ipu.ac.in;
   dinesh_iari@rediffmail.com
RI Singh, Amit Prakash/J-9317-2016; Sahu, Priyanka/IAM-3922-2023
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Albattah W, 2022, COMPLEX INTELL SYST, V8, P507, DOI 10.1007/s40747-021-00536-1
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Annrose J, 2022, WIRELESS PERS COMMUN, V122, P2995, DOI 10.1007/s11277-021-09038-2
   [Anonymous], 2015, Google Research
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Aslani S, 2023, CLIN RADIOL, V78, P150, DOI 10.1016/j.crad.2022.11.006
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Bedi P, 2021, ARTIF INTELL AGR, V5, P90, DOI 10.1016/j.aiia.2021.05.002
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen JD, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100415
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chollet F., 2017, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4
   Couteaux Vincent, 2019, Interpretability of Machine Intelligence in Medical Image Computing and Multimodal Learning for Clinical Decision Support. Second International Workshop, iMIMIC 2019 and 9th International Workshop, ML-CDS 2019. Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11797), P56, DOI 10.1007/978-3-030-33850-3_7
   Deniz E, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0057-x
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Guo Y, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/7349162
   Han JH, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060886
   Haridasan A, 2023, ENVIRON MONIT ASSESS, V195, DOI 10.1007/s10661-022-10656-x
   Hughes D., 2015, ABS151108060 CORR
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2021, IEEE SENS J, V21, P17455, DOI 10.1109/JSEN.2020.3046295
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu XY, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13040546
   Maceachern CB, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100099
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mokhtar U, 2015, ADV INTELL SYST, V323, P641, DOI 10.1007/978-3-319-11310-4_55
   Nanehkaran YA, 2021, J SUPERCOMPUT, V77, P3193, DOI 10.1007/s11227-020-03388-7
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panchal P., 2019, CSITSS 2019 2019 4 I, DOI [DOI 10.1109/CSITSS47250.2019.9031029, 10.1109/CSITSS47250.2019.9031029]
   Pantazi XE, 2016, IFIP ADV INF COMM TE, V475, P319, DOI 10.1007/978-3-319-44944-9_27
   Pattnaik Gayatri, 2021, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2019. Advances in Intelligent Systems and Computing (AISC 1199), P49, DOI 10.1007/978-981-15-6353-9_5
   Punithavathi R, 2023, COMPUT SYST SCI ENG, V44, P2759, DOI 10.32604/csse.2023.027647
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Rehman MZU, 2022, CMC-COMPUT MATER CON, V70, P1401, DOI 10.32604/cmc.2022.019046
   Revathi P., 2014, International Journal of Engineering and Technology, V5, P4637
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salamai AA, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118658
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sami M, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12010212
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schmitt M., 2023, International Journal of Information Management Data Insights, V3, DOI [10.1016/J.JJIMEI.2022.100146, DOI 10.1016/J.JJIMEI.2022.100146]
   Shah D, 2022, INFORM PROCESS AGR, V9, P212, DOI 10.1016/j.inpa.2021.06.001
   Sharifi A, 2022, J INDIAN SOC REMOTE, V50, P417, DOI 10.1007/s12524-021-01475-7
   Sharma M, 2022, ARCH PHYTOPATH PLANT, V55, P259, DOI 10.1080/03235408.2021.2015866
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Sravan K., 2021, MATER TODAY-PROC
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Tsuneki M, 2022, J ORAL BIOSCI, V64, P312, DOI 10.1016/j.job.2022.03.003
   Wani JA, 2022, ARCH COMPUT METHOD E, V29, P641, DOI 10.1007/s11831-021-09588-5
   Xu JL, 2022, J SUPERCOMPUT, V78, P10876, DOI 10.1007/s11227-021-04238-w
NR 69
TC 1
Z9 1
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35585
EP 35619
DI 10.1007/s11042-023-14994-x
EA MAR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000945792800009
DA 2024-07-18
ER

PT J
AU Sasmal, B
   Dhal, KG
AF Sasmal, Buddhadev
   Dhal, Krishna Gopal
TI A survey on the utilization of Superpixel image for clustering based
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel; Clustering; Image segmentation; Optimization; Leaf images;
   Oral histopathology
ID FUZZY C-MEANS; INSPIRED OPTIMIZATION ALGORITHMS; K-MEANS; LOCAL
   INFORMATION; FIREFLY ALGORITHM; GENERATION; CLASSIFICATION; DATABASE;
   FUSION; SHIFT
AB Superpixel become increasingly popular in image segmentation field as it greatly helps image segmentation techniques to segment the region of interest accurately in noisy environment and also reduces the computation effort to a great extent. However, selection of proper superpixel generation techniques and superpixel image segmentation techniques play a very crucial role in the domain of different kinds of image segmentation. Clustering is a well-accepted image segmentation technique and proved their effective performance over various image segmentation field. Therefore, this study presents an up-to-date survey on the employment of superpixel image in combined with clustering techniques for the various image segmentation. The contribution of the survey has four parts namely (i) overview of superpixel image generation techniques, (ii) clustering techniques especially efficient partitional clustering techniques, their issues and overcoming strategies, (iii) Review of superpixel combined with clustering strategies exist in literature for various image segmentation, (iv) lastly, the comparative study among superpixel combined with partitional clustering techniques has been performed over oral pathology and leaf images to find out the efficacy of the combination of superpixel and partitional clustering approaches. Our evaluations and observation provide in-depth understanding of several superpixel generation strategies and how they apply to the partitional clustering method.
C1 [Sasmal, Buddhadev; Dhal, Krishna Gopal] Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
C3 Midnapore College
RP Dhal, KG (corresponding author), Midnapore Coll Autonomous, Dept Comp Sci & Applicat, Paschim Medinipur, W Bengal, India.
EM buddhadev.sasmal@midnaporecollege.ac.in;
   krishnagopal.dhal@midnaporecollege.ac.in
RI Dhal, Krishna Gopal/JCD-8250-2023; Sasmal, Buddhadev/ABH-2481-2021
OI Sasmal, Buddhadev/0009-0009-4244-9897; dhal, krishna
   gopal/0000-0002-6748-0569
CR Abd Elaziz M, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9192383
   Abdellahoum H, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114063
   Achanta R., 2010, SLIC Superpixels
   Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Albayrak A, 2019, MED BIOL ENG COMPUT, V57, P653, DOI 10.1007/s11517-018-1906-0
   andrewjanowczyk, US CAS 1 NUCL SEGM A
   Angulakshmi M, 2020, J KING SAUD UNIV-COM, V32, P1182, DOI 10.1016/j.jksuci.2018.01.009
   Anter AM, 2019, ARTIF INTELL MED, V97, P105, DOI 10.1016/j.artmed.2018.11.007
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Armato SG, 2004, RADIOLOGY, V232, P739, DOI 10.1148/radiol.2323032035
   Benesova W., 2014, C MACHINE VISION MAC, P67
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bouguettaya A, 2015, EXPERT SYST APPL, V42, P2785, DOI 10.1016/j.eswa.2014.09.054
   Buyssens P, 2014, IRBM, V35, P20, DOI 10.1016/j.irbm.2013.12.007
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Capor Hrosik R, 2019, STUD INFORM CONTROL, V28, P167, DOI 10.24846/v28i2y201905
   Celebi ME, 2015, J REAL-TIME IMAGE PR, V10, P329, DOI 10.1007/s11554-012-0291-4
   Chakraborty S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114142
   Chavent M, 2007, COMPUT STAT DATA AN, V52, P687, DOI 10.1016/j.csda.2007.03.013
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chouhan SS, 2020, ARCH COMPUT METHOD E, V27, P611, DOI [10.1007/s11831-019-09324-0, 10.33552/abeb.2018.01.000510]
   COLORNI A, 1992, FROM ANIM ANIMAT, P134
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cong L, 2018, IET IMAGE PROCESS, V12, P2030, DOI 10.1049/iet-ipr.2018.5439
   Conrad Christian, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P280, DOI 10.1007/978-3-642-40395-8_21
   Dai Tang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P765, DOI 10.1109/ICME.2012.184
   Das A, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.108008
   Das A, 2022, NEURAL COMPUT APPL, V34, P4531, DOI 10.1007/s00521-021-06610-6
   Das S., 2006, IEEE CONGRES EVOLUT, V2006, P2026, DOI [10.1109/CEC.2006.1688556, DOI 10.1109/CEC.2006.1688556]
   Dash M, 2020, COMPUT BIOL CHEM, V86, DOI 10.1016/j.compbiolchem.2020.107247
   Dhal KG, 2018, P 5 STUDENT COMPUTER, P47, DOI [10.26493/978-961-7055-26-9.47-54, DOI 10.26493/978-961-7055-26-9.47-54]
   Dhal KG, 2022, ARCH COMPUT METHOD E, V29, P1643, DOI 10.1007/s11831-021-09629-z
   Dhal KG, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106814
   Dhal KG, 2020, PATTERN RECOGN IMAGE, V30, P614, DOI 10.1134/S1054661820040100
   Dhal KG, 2020, MULTIMED TOOLS APPL, V79, P12227, DOI 10.1007/s11042-019-08417-z
   Dhal KG, 2020, ARCH COMPUT METHOD E, V27, P855, DOI 10.1007/s11831-019-09334-y
   Dhal KG, 2021, ARCH COMPUT METHOD E, V28, P1471, DOI 10.1007/s11831-020-09425-1
   Dhal KG, 2020, NEURAL COMPUT APPL, V32, P3059, DOI 10.1007/s00521-019-04585-z
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhal KG, 2019, PATTERN RECOGN IMAGE, V29, P344, DOI 10.1134/S1054661819030052
   Dhal KG, 2019, J INDIAN SOC REMOTE, V47, P1391, DOI 10.1007/s12524-019-01005-6
   Dhillon I. S., 2003, Journal of Machine Learning Research, V3, P1265, DOI 10.1162/153244303322753661
   Drucker F, 2009, WORKSH MOT VID COMP, P1
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Elkhateeb E, 2021, IEEE ACCESS, V9, P53902, DOI 10.1109/ACCESS.2021.3065246
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fred A. L., 2020, Applications of hybrid metaheuristic algorithms for image processing, P413
   Fu HZ, 2014, IEEE T MULTIMEDIA, V16, P1165, DOI 10.1109/TMM.2014.2305571
   Fu ZL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081289
   Fumero F, 2011, COMP MED SY
   Gao Y, 2021, IEEE T IND INFORM, V17, P3450, DOI 10.1109/TII.2020.3013277
   George Y, 2016, IEEE ENG MED BIO, P1352, DOI 10.1109/EMBC.2016.7590958
   George Y, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.044004
   Ghaffari R, 2020, INT J REMOTE SENS, V41, P3535, DOI 10.1080/01431161.2019.1706202
   Ghosal D, 2022, PATTERN RECOGN IMAGE, V32, P129, DOI 10.1134/S1054661821040118
   Giraud R, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902729
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goyal P, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P268, DOI [10.1109/HPCC-SmartCity-DSS.2016.0047, 10.1109/HPCC-SmartCity-DSS.2016.36]
   Gronau I, 2007, INFORM PROCESS LETT, V104, P205, DOI 10.1016/j.ipl.2007.07.002
   GUENOCHE A, 1991, J CLASSIF, V8, P5, DOI 10.1007/BF02616245
   Guha S., 1998, SIGMOD Record, V27, P73, DOI 10.1145/276305.276312
   Hamamci A., 2012, P MICCAI BRATS, P19
   Humayun A, 2015, IEEE I CONF COMP VIS, P1600, DOI 10.1109/ICCV.2015.187
   Ibrahim A, 2020, J COMPUT SCI INF SYS, V15
   Ilesanmi AE, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103879
   Irshad H, 2015, BIOCOMPUT-PAC SYM, P294
   Ishizaka A, 2021, OMEGA-INT J MANAGE S, V103, DOI 10.1016/j.omega.2020.102370
   Jia XH, 2020, IEEE ACCESS, V8, P211526, DOI 10.1109/ACCESS.2020.3039742
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kate Vandana, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P207, DOI 10.1007/978-981-15-2071-6_17
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Khrissi Lahbib, 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P489, DOI 10.1007/978-981-15-0947-6_46
   Kim DH, 2019, J ELECTR ENG TECHNOL, V14, P2549, DOI 10.1007/s42835-019-00259-x
   Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095
   Kim YI., 1992, KOR J GASTROENTEROL, V24, P216
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kumar SN, 2019, J DIGIT IMAGING, V32, P322, DOI 10.1007/s10278-018-0149-9
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li HY, 2015, OPTIK, V126, P4817, DOI 10.1016/j.ijleo.2015.09.127
   Li H, 2021, IEEE T IND INFORM, V17, P7501, DOI 10.1109/TII.2020.3044068
   Li SN, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6010030
   Li XL, 2018, IEEE T CYBERNETICS, V48, P2609, DOI 10.1109/TCYB.2017.2747143
   Liu GY, 2015, IEEE GEOSCI REMOTE S, V12, P1770, DOI 10.1109/LGRS.2015.2425225
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P477, DOI 10.1007/s11042-019-08044-8
   Machairas V, 2014, IEEE IMAGE PROC, P4343, DOI 10.1109/ICIP.2014.7025882
   Meyer F, 2012, ARXIV, DOI DOI 10.48550/ARXIV.1202.0216
   Minervini M, 2016, PATTERN RECOGN LETT, V81, P80, DOI 10.1016/j.patrec.2015.10.013
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Mittal H, 2022, MULTIMED TOOLS APPL, V81, P35001, DOI 10.1007/s11042-021-10594-9
   Mittal H, 2021, EVOL INTELL, V14, P1293, DOI 10.1007/s12065-018-0192-y
   Mittal H, 2019, SWARM EVOL COMPUT, V45, P15, DOI 10.1016/j.swevo.2018.12.005
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Mohamed NA, 2019, BIOMED SIGNAL PROCES, V53, DOI [10.1016/j.bspc.2019.01.003, 10.1080/09291016.2019.1629167]
   Murtagh F., 2011, ARXIV, DOI DOI 10.48550/ARXIV.1105.0121
   Ha NT, 2021, INT J REMOTE SENS, V42, P4716, DOI 10.1080/01431161.2021.1899335
   Nanda SJ, 2019, APPL ARTIF INTELL, V33, P152, DOI 10.1080/08839514.2018.1530869
   Narmatha C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02470-5
   Neubert P, 2014, INT C PATT RECOG, P996, DOI 10.1109/ICPR.2014.181
   Niharika E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IOT AND ITS APPLICATIONS (IEEE ICIOT)
   Omran M, 2005, INT J PATTERN RECOGN, V19, P297, DOI 10.1142/S0218001405004083
   Özdemir D, 2002, PATTERN RECOGN, V35, P1785, DOI 10.1016/S0031-3203(01)00170-4
   Pakhira MK, 2015, INT J ENG-IRAN, V28, P35, DOI 10.5829/idosi.ije.2015.28.01a.05
   Patel S., 2018, 2018 2 INT C TRENDS, P1454, DOI [10.1109/ICOEI.2018.8553834, DOI 10.1109/ICOEI.2018.8553834]
   Potenza F, 2020, J CIV STRUCT HEALTH, V10, P471, DOI 10.1007/s13349-020-00395-3
   Price K.V, 1999, New Ideas in Optimization, P79
   Rahman TY, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105114
   Ran Siyuan, 2020, Journal of Physics: Conference Series, V1533, DOI 10.1088/1742-6596/1533/3/032067
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Rapaka S, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-020-04110-1
   Ray S, 2021, NEURAL COMPUT APPL, V33, P5917, DOI 10.1007/s00521-020-05368-7
   Rela M, 2020, INT J ADV COMPUT SC, V11, P380
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rottensteiner F., 2012, ISPRS ANN PHOTOGRAMM, V1, P293, DOI 10.5194/isprsannals-I-3-293-2012
   Saxena A, 2017, NEUROCOMPUTING, V267, P664, DOI 10.1016/j.neucom.2017.06.053
   Sharma S., 2019, 2019 INT C MACH LEAR, P568, DOI [10.1109/COMITCON.2019.8862232, DOI 10.1109/COMITCON.2019.8862232, 10.1109/COMITCon.2019.8862232]
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Soltani A, 2018, BIOMED SIGNAL PROCES, V40, P366, DOI 10.1016/j.bspc.2017.10.009
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tasli HE, 2015, SIGNAL PROCESS-IMAGE, V33, P71, DOI 10.1016/j.image.2015.02.005
   Tiwari Varun, 2020, International Journal of Intelligent Information and Database Systems, V13, P118, DOI 10.1504/IJIIDS.2020.109452
   Tongbram S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02762-w
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Vishnoi S, 2021, EVOL INTELL, V14, P1367, DOI 10.1007/s12065-019-00288-5
   Wang H, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7050436
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P1241, DOI 10.1109/TPAMI.2012.47
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wei X, 2018, IEEE T IMAGE PROCESS, V27, P4838, DOI 10.1109/TIP.2018.2836300
   Weikersdorfer D, 2012, INT C PATT RECOG, P2087
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu C, 2021, IEEE T CIRC SYST VID, V31, P2114, DOI 10.1109/TCSVT.2020.3019109
   Wu C, 2019, IEEE IMAGE PROC, P1455, DOI [10.1109/icip.2019.8803039, 10.1109/ICIP.2019.8803039]
   Wu X, 2018, APPL INTELL, V48, P4485, DOI 10.1007/s10489-018-1223-1
   Xiang DL, 2019, IEEE T GEOSCI REMOTE, V57, P3873, DOI 10.1109/TGRS.2018.2888891
   Xiang DL, 2017, IEEE T GEOSCI REMOTE, V55, P3115, DOI 10.1109/TGRS.2017.2662010
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   YANG XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI [DOI 10.1504/IJBIC.2010.032124, 10.1504/IJBIC.2010.032124]
   Yao H, 2013, MATH COMPUT MODEL, V58, P784, DOI 10.1016/j.mcm.2012.12.025
   Yao J, 2015, PROC CVPR IEEE, P2947, DOI 10.1109/CVPR.2015.7298913
   Yuan CA, 2018, J ENG-JOE, P1704, DOI 10.1049/joe.2018.8320
   Zandi M, 2014, IEEE INT WORKS INFOR, P119, DOI 10.1109/WIFS.2014.7084314
   Zhang Q, 2017, COMPUT VIS IMAGE UND, V161, P51, DOI 10.1016/j.cviu.2017.04.015
   Zhang SW, 2018, OPTIK, V157, P866, DOI 10.1016/j.ijleo.2017.11.190
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Zhang W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184290
   Zhang XW, 2014, MED IMAGE ANAL, V18, P1026, DOI 10.1016/j.media.2014.05.004
   Zhang YQ, 2013, LIVER INT, V33, P1239, DOI 10.1111/liv.12173
   Zhang YH, 2011, IEEE I CONF COMP VIS, P1387, DOI 10.1109/ICCV.2011.6126393
   Zhengqin L., 2015, PROC CVPR IEEE, P1356, DOI DOI 10.1109/CVPR.2015.7298741
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhou W, 2017, IEEE ACCESS, V5, P17077, DOI 10.1109/ACCESS.2017.2740239
NR 167
TC 10
Z9 11
U1 9
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35493
EP 35555
DI 10.1007/s11042-023-14861-9
EA MAR 2023
PG 63
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000945311800002
PM 37362658
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, J
   Xu, BM
   Yin, HF
AF Zhang, Jiao
   Xu, Baomin
   Yin, Hongfeng
TI Depression screening using hybrid neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram (EEG); Depression detection; CNN-LSTM; Deep
   learning; Hybrid deep models
ID NONLINEAR FEATURES; EEG; CLASSIFICATION; DECOMPOSITION; PATTERN
AB Depression is a common cause of increased suicides worldwide, and studies have shown that the number of patients suffering from major depressive disorder (MDD) increased several-fold during the COVID-19 pandemic, highlighting the importance of disease detection and depression management, while increasing the need for effective diagnostic tools. In recent years, machine learning and deep learning methods based on electroencephalography (EEG) have achieved significant results in the field of automatic depression detection. However, most current studies have focused on a small number of EEG signal channels, and experimental data require special processing by professionals. In this study, 128 channels of EEG signals were simply filtered and 24-fold leave-one-out cross-validation experiments were performed using 2DCNN-LSTM classifier, support vector machine, K-nearest neighbor and decision tree. The current results show that the proposed 2DCNN-LSTM model has an average classification accuracy of 95.1% with an AUC of 0.98 for depression detection of 6-second participant EEG signals, and the model is much better than 72.05%, 79.7% and 79.49% for support vector machine, K nearest neighbor and decision tree. In addition, we found that the model achieved a 100% probability of correctly classifying the EEG signals of 300-second participants.
C1 [Zhang, Jiao; Xu, Baomin] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Yin, Hongfeng] Cangzhou Jiaotong Coll, Sch Comp & Informat Technol, Cangzhou, Hebei, Peoples R China.
C3 Beijing Jiaotong University
RP Zhang, J (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.; Yin, HF (corresponding author), Cangzhou Jiaotong Coll, Sch Comp & Informat Technol, Cangzhou, Hebei, Peoples R China.
EM jiaozhang@bjtu.edu.cn; hfyin@bjtuhbxy.edu.cn
OI zhang, jiao/0000-0002-3726-1226
FU Cangzhou key research and development plan [204102013]
FX This research was funded by Cangzhou key research and development plan
   [204102013].
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Acharya UR, 2018, COMPUT METH PROG BIO, V161, P103, DOI 10.1016/j.cmpb.2018.04.012
   Ahmadlou M, 2012, INT J PSYCHOPHYSIOL, V85, P206, DOI 10.1016/j.ijpsycho.2012.05.001
   Ajcevic M, 2021, MED BIOL ENG COMPUT, V59, P121, DOI 10.1007/s11517-020-02280-z
   Akar SA, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500088
   Akbari H, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00139-7
   Ay B, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1345-y
   Bairy GM, 2017, J MED IMAG HEALTH IN, V7, P1857, DOI 10.1166/jmihi.2017.2204
   BINNIE CD, 1994, J NEUROL NEUROSUR PS, V57, P1308, DOI 10.1136/jnnp.57.11.1308
   Bueno-Notivol J, 2021, INT J CLIN HLTH PSYC, V21, DOI 10.1016/j.ijchp.2020.07.007
   Cai HS, 2018, COMPLEXITY, DOI 10.1155/2018/5238028
   Chakraborty B, 2021, IEEE T IMAGE PROCESS, V30, P9014, DOI 10.1109/TIP.2021.3122092
   Correa A.G, 2007, J. Phys, Conf. Ser., V90, DOI DOI 10.1088/1742-6596/90/1/012081
   Croft RJ, 2000, NEUROPHYSIOL CLIN, V30, P5, DOI 10.1016/S0987-7053(00)00055-1
   CUN YL, 1986, DISORDERED SYSTEMS B
   Do LN, 2021, J SUPERCOMPUT, V77, P10773, DOI 10.1007/s11227-021-03690-y
   Erguzel TT, 2016, NEURAL COMPUT APPL, V27, P1607, DOI 10.1007/s00521-015-1959-z
   Faust O, 2014, J MECH MED BIOL, V14, DOI 10.1142/S0219519414500353
   Fingelkurts AA, 2015, BIOL PSYCHIAT, V77, P1050, DOI 10.1016/j.biopsych.2014.12.011
   Francis A, 2021, MULTIMED TOOLS APPL, V80, P29585, DOI 10.1007/s11042-021-11161-y
   Güler I, 2007, IEEE T INF TECHNOL B, V11, P117, DOI 10.1109/TITB.2006.879600
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseinifard B, 2013, COMPUT METH PROG BIO, V109, P339, DOI 10.1016/j.cmpb.2012.10.008
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ikram ST, 2022, J SUPERCOMPUT, V78, P10725, DOI 10.1007/s11227-021-04284-4
   Jia ZY, 2010, AM J PSYCHIAT, V167, P1381, DOI 10.1176/appi.ajp.2010.09101513
   Kar MK., 2021, SN Computer Sci, V2, P397, DOI DOI 10.1007/S42979-021-00784-5
   Khan MA, 2017, MULTIMED TOOLS APPL, V76, P16683, DOI 10.1007/s11042-016-3944-7
   Kim AY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35147-3
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XW, 2019, MED BIOL ENG COMPUT, V57, P1341, DOI 10.1007/s11517-019-01959-2
   Li XW, 2016, COMPUT METH PROG BIO, V136, P151, DOI 10.1016/j.cmpb.2016.08.010
   Li YL, 2019, IEEE ACCESS, V7, P7814, DOI 10.1109/ACCESS.2018.2883480
   Liao SC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061385
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30261, DOI 10.1007/s11042-020-09135-7
   Loh HW, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12773
   Mahato S, 2019, MICROSYST TECHNOL, V25, P1065, DOI 10.1007/s00542-018-4075-z
   Mantri S, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P518, DOI 10.1109/IntelliSys.2015.7361188
   Mohamed EA, 2018, MULTIMED TOOLS APPL, V77, P21305, DOI 10.1007/s11042-017-5586-9
   Morabito FC, 2017, INT J NEURAL SYST, V27, DOI 10.1142/S0129065716500398
   Mumtaz W, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103983
   Mumtaz W, 2017, BIOMED SIGNAL PROCES, V31, P108, DOI 10.1016/j.bspc.2016.07.006
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Özçoban MA, 2018, MED BIOL ENG COMPUT, V56, P331, DOI 10.1007/s11517-017-1689-8
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Peng H, 2019, IEEE ACCESS, V7, P92630, DOI 10.1109/ACCESS.2019.2927121
   Polat K, 2007, APPL MATH COMPUT, V187, P1017, DOI 10.1016/j.amc.2006.09.022
   Puthankattil SD, 2012, J MECH MED BIOL, V12, DOI 10.1142/S0219519412400192
   Ravi S, 2022, MULTIMED TOOLS APPL, V81, P6585, DOI 10.1007/s11042-021-11608-2
   Saeedi A, 2021, COGN NEURODYNAMICS, V15, P239, DOI 10.1007/s11571-020-09619-0
   Saeedi M, 2020, PHYS ENG SCI MED, V43, P1007, DOI 10.1007/s13246-020-00897-w
   Samar VJ, 1999, BRAIN LANG, V66, P7, DOI 10.1006/brln.1998.2024
   Sandheep P, 2019, TENCON IEEE REGION, P1339, DOI [10.1109/TENCON.2019.8929254, 10.1109/tencon.2019.8929254]
   Satapathy SK, 2023, MULTIMED TOOLS APPL, V82, P8049, DOI 10.1007/s11042-022-13195-2
   Sharma G, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102393
   Sharma N, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.041210
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Sreeja SR, 2020, MULTIMED TOOLS APPL, V79, P13775, DOI 10.1007/s11042-019-08602-0
   Srinivasan G, 2016, SCI REP-UK, V6, DOI 10.1038/srep29545
   Sujatha K, 2020, MULTIMED TOOLS APPL, V79, P9871, DOI 10.1007/s11042-019-08359-6
   Sung M., 2005, OBJECTIVE PHYSL BEHA, P595
   Swetaa, 2019, DRUG INVENT TODAY, V11
   Thoduparambil PP, 2020, PHYS ENG SCI MED, V43, P1349, DOI 10.1007/s13246-020-00938-4
   Tonoyan Y, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500052
   Tuncer T, 2021, MULTIMED TOOLS APPL, V80, P25197, DOI 10.1007/s11042-021-10882-4
   Uyulan C, 2021, CLIN EEG NEUROSCI, V52, P38, DOI 10.1177/1550059420916634
   Wei, 2022, APPL INTELL, P1
   WHO, 2017, Other common mental disorders: global health estimates
NR 69
TC 3
Z9 3
U1 14
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26955
EP 26970
DI 10.1007/s11042-023-14860-w
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000945792800013
PM 37362740
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Jung, KH
AF Agarwal, Saurabh
   Jung, Ki-Hyun
TI Median filtering detection using optimal multi-direction threshold on
   higher-order difference pixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Median filtering detection; Image forgery detection; Image forensics;
   Markov process
ID FORENSICS; ENHANCEMENT
AB Image forgery detection is a challenging issue because fake images can be prepared accurately using precise editing tools. In this paper, a robust image forensics technique based on a multi-direction threshold (MDT) is proposed to detect median filtering. In the proposed method, an optimal thresholded array is derived from difference arrays in multiple directions. The Markov process is applied to fetch the joint probability statistics of neighboring pixels on optimally thresholded difference arrays. The proposed optimal MDT utilizes both first and second-order difference arrays for additional information that leads to a more comprehensive feature set. As a result, the proposed technique achieves 93.40%, 90.59%, and 85.76% detection accuracy on JPEG compressed images of size 64 x 64 pixels with quality factors 70, 50, and 30, correspondingly. The non-filtered and median filtered images are classified using LDA and SVM classifiers. The superiority of the proposed technique is analyzed through exhaustive experimental analysis on centrally cropped and zero-padded median filtered images.
C1 [Agarwal, Saurabh] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
   [Agarwal, Saurabh; Jung, Ki-Hyun] Andong Natl Univ, Dept Software Convergence, Andong, Gyeongbuk, South Korea.
C3 Amity University Noida; Andong National University
RP Jung, KH (corresponding author), Andong Natl Univ, Dept Software Convergence, Andong, Gyeongbuk, South Korea.
EM saurabhnsit2510@gmail.com; khanny.jung@gmail.com
RI Agarwal, Saurabh/AAC-5460-2020
OI Agarwal, Saurabh/0000-0003-3836-2595; Jung, Ki-Hyun/0000-0002-0662-8355
FU Brain Pool program - Ministry of Science and ICT through the National
   Research Foundation of Korea [2019H1D3A1A01101687]; Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   - Ministry of Education [2021R1I1A3049788]
FX This research was supported by Brain Pool program funded by the Ministry
   of Science and ICT through the National Research Foundation of Korea
   (2019H1D3A1A01101687) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2021R1I1A3049788).
CR Agarwal S, 2016, SECUR COMMUN NETW, V9, P4089, DOI 10.1002/sec.1590
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2008, BREAK OUR WATERMARKI
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chaira T, 2012, APPL SOFT COMPUT, V12, P1259, DOI 10.1016/j.asoc.2011.12.011
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Cheng-Chang Lien, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P232, DOI 10.1109/IIHMSP.2010.65
   Colreavy-Donnelly S, 2020, INTEGR COMPUT-AID E, V27, P403, DOI 10.3233/ICA-200638
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gupta A, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3321508
   Halima I, 2020, INTEGR COMPUT-AID E, V27, P195, DOI 10.3233/ICA-190615
   ifc, IMAGES CORPUS 1 IEEE
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Li WJ, 2019, MULTIMED TOOLS APPL, V78, P8363, DOI 10.1007/s11042-018-6831-6
   Liu AN, 2017, MULTIMED TOOLS APPL, V76, P22119, DOI 10.1007/s11042-017-4845-0
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Luo SH, 2019, IEEE ACCESS, V7, P80614, DOI 10.1109/ACCESS.2019.2923000
   Peng AJ, 2019, IEEE ACCESS, V7, P28525, DOI 10.1109/ACCESS.2019.2897761
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rhee KH, 2020, IEEE ACCESS, V8, P188970, DOI 10.1109/ACCESS.2020.3029087
   Rhee KH, 2019, IEEE ACCESS, V7, P77524, DOI 10.1109/ACCESS.2019.2921573
   Rhee RH, 2019, IEEE ACCESS, V7, P92586, DOI 10.1109/ACCESS.2019.2927540
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shan WY, 2019, IEEE ACCESS, V7, P17174, DOI 10.1109/ACCESS.2019.2894981
   Shu-ping Li, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1166, DOI 10.1109/CISP.2010.5646732
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yu L, 2019, IEEE ACCESS, V7, P120594, DOI 10.1109/ACCESS.2019.2932810
   Zhang WW, 2019, MULTIMED TOOLS APPL, V78, P20113, DOI 10.1007/s11042-019-7288-y
NR 33
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30875
EP 30893
DI 10.1007/s11042-023-14480-4
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000945313000001
DA 2024-07-18
ER

PT J
AU Mefteh, S
   Kaaniche, MB
   Ksantini, R
   Bouhoula, A
AF Mefteh, Safa
   Kaaniche, Mohamed-Becha
   Ksantini, Riadh
   Bouhoula, Adel
TI A novel multispectral corner detector and a new local descriptor: an
   application to human posture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colour-depth human posture recognition; Corner detector; Multi-spectral
   HOG descriptor; Machine learning; MCD; Multispectral Corner Detector;
   CNN
AB Human posture recognition is an important task for intelligent systems specially those performing action recognition. In this paper, we propose a novel multispectral corner detector and a new HOG-based multispectral local descriptor. First, we select salient features which are extracted from an edge image obtained by picking the maximum eigenvalue of the jacobian matrix. Second, we extract for each feature point a local descriptor which combines both the Lab colour channels and depth information in a well-posed way using the Jacobian matrix. Last, we conduct a one-against-all learning strategy using both an incremental Covariance-guided One-Class Support Vector Machine (iCOSVM) and a Convolutional Neural Network (CNN). Experimental results show that we outperform the state-of-the-art methods whether our descriptor is combined with iCOSVM and with CNN.
C1 [Mefteh, Safa; Kaaniche, Mohamed-Becha] Univ Carthage, Higher Sch Commun Tunis, InnovCom Lab, Digital Secur Lab, Aryanah, Tunisia.
   [Ksantini, Riadh] Univ Bahrain, Coll IT, Dept Comp Sci, Manama, Bahrain.
   [Bouhoula, Adel] Arabian Gulf Univ, Coll Grad Studies, Dept Next Generat Comp, Manama, Bahrain.
C3 Universite de Carthage; University of Bahrain; Arabian Gulf University
RP Mefteh, S (corresponding author), Univ Carthage, Higher Sch Commun Tunis, InnovCom Lab, Digital Secur Lab, Aryanah, Tunisia.
EM safa.mefteh@supcom.tn; medbecha.kaaniche@supcom.tn;
   rksantini@uob.edu.bh; a.bouhoula@agu.edu.bh
RI Ksantini, Riadh/KGM-9060-2024
OI Mefteh, Safa/0000-0002-7395-6455; ksantini, riadh/0000-0001-8143-1600;
   Kaaniche, Mohamed-Becha/0000-0003-4443-5658
CR Abou Bakr N, 2018, CORR ARXIV 180109477
   Ahamed H., 2018, International Conference on Advancement in Electrical and Electronic Engineering (ICAEEE), P1, DOI 10.1109/ICAEEE.2018.8642989
   Banerji S, 2012, IEEE SYS MAN CYBERN, P2294, DOI 10.1109/ICSMC.2012.6378083
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boulay B., 2005, IEE International Symposium on Imaging for Crime Detection and Prevention (ICDP 2005), P135, DOI 10.1049/ic:20050085
   Brahnam S., 2014, LOCAL BINARY PATTERN, DOI DOI 10.1007/978-3-642-39289-4
   Chandrakar R, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116306
   Chandrakar R, 2022, MULTIMED TOOLS APPL, V81, P42149, DOI 10.1007/s11042-021-11290-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elforaici MEA, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P69, DOI 10.1109/LSC.2018.8572079
   Haritaoglu I, 1998, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1998.711084
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hasib Rabia, 2021, Proceedings of 2021 International Conference on Artificial Intelligence (ICAI), P74, DOI 10.1109/ICAI52203.2021.9445263
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Huang XP, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061464
   Janbandhu VP, 2014, HUMAN DETECTION NONL
   JiaXin Wang, 2020, EITCE 2020: Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering, P475, DOI 10.1145/3443467.3443801
   Kalake L, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062123
   Kale H, 2018, IEEE INT ADV COMPUT, P272, DOI 10.1109/IADCC.2018.8692143
   Kefi T, 2016, ECMLPKDD
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leng CC, 2019, IEEE ACCESS, V7, P6424, DOI 10.1109/ACCESS.2018.2888856
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li S., 2020, 2020 INT C HIGH PERF, P1
   Lipetski Y., 2017, Electronic Imaging, V2017, P11
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manu B, 2019, INT J INNOVATIVE TEC, V8
   Mefteh S, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P272, DOI 10.5220/0007380502720279
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Patel P, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P473, DOI 10.1109/ICIMIA.2017.7975660
   Pellegrini S., 2007, EURASIP J IMAGE VIDE, V2008, P476151
   Prest A, 2013, IEEE T PATTERN ANAL, V35, P835, DOI 10.1109/TPAMI.2012.175
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P371, DOI 10.1007/s42979-021-00762-x
   Raja R, 2022, CMC-COMPUT MATER CON, V72, P2015, DOI 10.32604/cmc.2022.022904
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Riahi D, 2018, MID EAST CONF BIO, P177, DOI 10.1109/MECBME.2018.8402429
   Rui T, 2017, MULTIMED TOOLS APPL, V76, P25079, DOI 10.1007/s11042-017-4837-0
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Susanto Kumar Ghosh MRI., 2021, COMP M BIO BIO E-IV, V6, P733, DOI [10.25046/aj060285, DOI 10.25046/AJ060285]
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   Verma A, 2019, COMM COM INF SC, V955, P149, DOI 10.1007/978-981-13-3140-4_14
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang BH, 2005, LECT NOTES COMPUT SC, V3687, P626
   Wang WJ, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/62163
   Wanner S., 2013, INT S VIS MOD VIS, P225
   Zhang SM, 2021, INT J MACH LEARN CYB, V12, P489, DOI 10.1007/s13042-020-01182-8
NR 47
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28937
EP 28956
DI 10.1007/s11042-023-14788-1
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943970200010
DA 2024-07-18
ER

PT J
AU Dey, RK
   Das, AK
AF Dey, Ranit Kumar
   Das, Asit Kumar
TI Modified term frequency-inverse document frequency based deep hybrid
   framework for sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Sentiment analysis; Term frequency-inverse
   document frequency; Deep learning; Convolutional neural network; Long
   short term memory
ID NEURAL-NETWORKS; WEIGHTING SCHEME; LSTM
AB Sentiment Analysis is a highly crucial subfield in Natural Language Processing that attempts to extract the public sentiment from the accessible user opinions. This paper proposes a hybridized neural network based sentiment analysis framework using a modified term frequency-inverse document frequency approach. After preprocessing of data, the basic term frequency-inverse document frequency scheme is improved by introducing a non-linear global weighting factor. This improved scheme is combined with the k-best selection method to vectorize textual features. Next, the pre-trained embedding technique is employed for the mathematical representation of the textual features to process them efficiently by the Deep Learning methodologies. The embedded features are then passed to the deep neural network, consisting of Convolutional Neural Network and Long Short Term Memory. Convolutional Neural Networks can build hierarchical representations for capturing locally embedded features within the feature space, and Long Short Term Memory tries to recall useful historical information for sentiment polarization. This deep neural network finally provides the sentiment label. The proposed model is compared with different state-of-the-art baseline models in terms of various performance metrics using several datasets to demonstrate its efficacy.
C1 [Dey, Ranit Kumar; Das, Asit Kumar] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, West Bengal, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Das, AK (corresponding author), Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah 711103, West Bengal, India.
EM akdas@cs.iiests.ac.in
OI Das, Asit Kumar/0000-0002-9886-1735
CR Agrawal D., Tweetsentimentanalysis/twitter.csv at master dakshitagrawal/tweetsentimentanalysis github
   Ahuja Ravinder, 2019, Procedia Computer Science, V152, P341, DOI 10.1016/j.procs.2019.05.008
   [Anonymous], WEK 3 DAT MIN OP SOU
   [Anonymous], NLP REPL AP SHORT WO
   [Anonymous], COH KAPP WIK
   [Anonymous], COMPL LIST TEXT ABBR
   [Anonymous], EMOJI PYPI
   [Anonymous], INT SLANG DICT TEXT
   [Anonymous], NATURAL LANGUAGE TOO
   [Anonymous], GITH MMIH WORD2VEC G
   [Anonymous], ABD ETS REV KAGGL AB
   [Anonymous], NLTK TOK TREEB NLTK3
   [Anonymous], INTR WORD EMB WORD2V
   [Anonymous], NLTK TOK PUNKT NLTK
   [Anonymous], CATEGORIZING TAGGING
   Ansari A, 2018, IEEE WRK SIG PRO SYS, P7, DOI 10.1109/SiPS.2018.8598348
   Baclic O., 2020, CCDR, V46, P1
   Bodapati Jyostna Devi, 2019, Ingenierie des systemes d'information, V24, P125, DOI 10.18280/isi.240119
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Chen G., 2016, ARXIV
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen LS, 2011, J INFORMETR, V5, P313, DOI 10.1016/j.joi.2011.01.003
   Collomb A., 2014, Rapport de recherche RR-LIRIS-2014-002
   Das B, 2018, ARXIV
   Das P, 2021, NEUROCOMPUTING, V459, P465, DOI 10.1016/j.neucom.2019.10.109
   Deng ZH, 2014, EXPERT SYST APPL, V41, P3506, DOI 10.1016/j.eswa.2013.10.056
   Enríquez F, 2016, EXPERT SYST APPL, V66, P1, DOI 10.1016/j.eswa.2016.09.005
   Ghag K, 2014, INT J ADV COMPUT SC, V5, P36
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ishaq A, 2020, IEEE ACCESS, V8, P135499, DOI 10.1109/ACCESS.2020.3011802
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Krishan, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P671, DOI 10.1007/978-981-15-0751-9_62
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar KP, 2017, ADV BUS STRATEGY COM, P1, DOI 10.4018/978-1-5225-1008-6.ch001
   Kumar S, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Martín-Valdivia MT, 2013, EXPERT SYST APPL, V40, P3934, DOI 10.1016/j.eswa.2012.12.084
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Muhammad PF, 2021, PROCEDIA COMPUT SCI, V179, P728, DOI 10.1016/j.procs.2021.01.061
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003
   Qu SN, 2008, 2008 INTERNATIONAL SEMINAR ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, PROCEEDINGS, P79, DOI 10.1109/FITME.2008.25
   Rai R, WINE REV KAGGLE
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Siddhartha M, AMAZON ALEXA REV KAG
   Sing HK, 2017, PROCEEDINGS OF 3RD INTERNATIONAL CONFERENCE ON EDUCATION 2017 (ICEDU- 2017), P29, DOI 10.17501/icedu.2017.3104
   Sinha A, Sentiment analysis for financial news | kaggle
   Solanki Akshay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P905, DOI 10.1007/978-981-15-0751-9_83
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Tokunaga Takenobu., 1994, Special Interest Groups and Information Process Society of Japan SIG-IPSJ.
   Tripathi M., 2021, J ARTIFICIAL INTELLI, V3, P151, DOI [DOI 10.36548/JAICN.2021.3.001, 10.36548/jaicn.2021.3.001]
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Varshney A., Big basket"google play app reviews for basic nlp | kaggle
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Wang C, 2012, COMMUN ASSOC INF SYS, V31, P105
   Wolber L, Facebook_reviews_trustpilot | kaggle
   Yang CS, 2012, RULE BASED APPROACH
   Yasmin G, 2022, SOFT COMPUT, DOI 10.1007/s00500-022-07074-z
   Zhang H, 2012, ENTERP INF SYST-UK, V6, P433, DOI 10.1080/17517575.2012.665945
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhao JH, 2020, PATTERN RECOGN LETT, V138, P397, DOI 10.1016/j.patrec.2020.07.035
NR 72
TC 4
Z9 4
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32967
EP 32990
DI 10.1007/s11042-023-14653-1
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900007
PM 37362742
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Chawla, V
   Kapoor, Y
AF Chawla, Vaishali
   Kapoor, Yatin
TI A hybrid framework for bot detection on twitter: Fusing digital DNA with
   BERT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Bot detection; Digital DNA; BERT; Sentiment analysis; Spambots
ID SOCIAL MEDIA; EMPIRICAL-EVALUATION; SPAM; DESIGN
AB With the recognition and influence of Twitter on modern society, an enormous amount of multimedia information is regularly generated and rapidly disseminated on the platform. These characteristics have caught the attention of automated accounts called bots that are frequently leveraged for malevolent activities. From distorting the political elections to crashing the stock markets to spreading conspiracy theories and fake news, various bot accounts have become a source of grave concern. Particularly, spambots have been known to mimic the behaviour of a legitimate user, making them almost insurmountable to detect. Of late, DNA inspired behaviour encoding of Twitter accounts such as B-Type,(3) and B-Content(3) DNA has achieved promising results in detecting the social spambots. However, the evolving nature of spambots drives academia and the industries to devise adaptive strategies to keep pace with the progressing capabilities of these spambots and curtail the menace caused by them. Therefore, this study proposes a hybrid technique utilizing digital DNA as a base approach and augmenting it with the state-of-the-art BERT model pre-trained on the sentiment classification task. The proposed hybrid encoding is termed B-Sentiment(3) DNA. Further, the study extends B-Content(3) encoding and proposes B-Content(5) DNA encoding to make spambot detection more robust. B-Content(5) encoding achieved an accuracy of 75.23%, surpassing B-Content(3) encoding, while the proposed hybrid approach, B-Sentiment(3) DNA, achieved an accuracy of 85.79%, significantly outperforming all the DNA encoding techniques considered in this study.
C1 [Chawla, Vaishali; Kapoor, Yatin] Univ Delhi, Dept Comp Sci, New Delhi, India.
C3 University of Delhi
RP Kapoor, Y (corresponding author), Univ Delhi, Dept Comp Sci, New Delhi, India.
EM vaishali.mcs18.du@gmail.com; yatin.mcs19.du@gmail.com
OI Chawla, Vaishali/0000-0002-9181-8179
CR Abu-El-Rub N, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2529, DOI 10.1145/3308558.3313420
   Ackermann Marcel R, 2012, Journal of Experimental Algorithmics (JEA), V17, P2, DOI [DOI 10.1145/2133803.2184450, 10.1145/2133803.2184450]
   Alom Zulfikar, 2020, Online Social Networks and Media, V18, P1, DOI 10.1016/j.osnem.2020.100079
   Alowibdi JS, 2015, SOC NETW ANAL MIN, V5, DOI 10.1007/s13278-015-0273-1
   Alterkavi S, 2021, MULTIMED TOOLS APPL, V80, P13575, DOI 10.1007/s11042-020-10361-2
   Amleshwaram AA, 2013, INT CONF COMMUN SYST
   Andriotis P, 2018, IEEE INT WORKS INFOR
   [Anonymous], 2012, 19 ANN NETWORK DISTR
   [Anonymous], MOST POPULAR MOBILE
   [Anonymous], 2012, P 9 USENIX S NETW SY
   Anwar A, 2020, BOT DETECTION TWITTE, DOI [10.1145/3396956.3401801, DOI 10.1145/3396956.3401801]
   Arnold M, 2011, ALGORITHMICA, V60, P806, DOI 10.1007/s00453-009-9369-1
   Badawy Adam, 2018, 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P258, DOI 10.1109/ASONAM.2018.8508646
   Benevenuto Fabricio., 2010, CEAS
   Bessi A., 2016, First Monday, V21, DOI 10.5210/fm.v21i11.7090
   Binsaeed K, 2020, INT J ADV COMPUT SC, V11, P11
   Boshmaf Y, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23260
   Cao F, 2006, SIAM PROC S, P328, DOI 10.1137/1.9781611972764.29
   Chavoshi N, 2016, IEEE DATA MINING, P817, DOI [10.1109/ICDM.2016.0096, 10.1109/ICDM.2016.86]
   Cresci S, 2018, IEEE T DEPEND SECURE, V15, P561, DOI 10.1109/TDSC.2017.2681672
   Cresci S, 2017, PR INT CONF DATA SC, P686, DOI 10.1109/DSAA.2017.57
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Cresci S, 2016, IEEE INTELL SYST, V31, P58, DOI 10.1109/MIS.2016.29
   Dalianis, 2018, CLIN TEXT MINING, DOI DOI 10.1007/978-3-319-78503-5_6
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhingra A., 2015, INT J LATEST TRENDS, V5, P9
   Dickerson JP, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P620, DOI 10.1109/ASONAM.2014.6921650
   Ersahin B, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P388, DOI 10.1109/UBMK.2017.8093420
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferrara Emilio, 2018, First Monday, V22, DOI 10.5210/fm.v22i18.8005
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Gamallo P, 2019, NAIVE BAYESIAN CLASS
   Garcia S, 2014, COMPUT SECUR, V45, P100, DOI 10.1016/j.cose.2014.05.011
   Gayo-Avello D, 2017, IEEE INTERNET COMPUT, V21, P98, DOI 10.1109/MIC.2017.2911439
   Ghosh S., 2012, P INT C WORLD WID WE, P61
   Gilani Zafar, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P489, DOI 10.1145/3110025.3110091
   Gong QY, 2018, IEEE COMMUN MAG, V56, P21, DOI 10.1109/MCOM.2018.1700575
   Grier C, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P27, DOI 10.1145/1866307.1866311
   Gupta Aditi, 2013, 2013 APWG eCrime Researchers Summit, DOI 10.1109/eCRS.2013.6805772
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu X, 2014, AAAI CONF ARTIF INTE, P59
   internetlivestats, TWITTER USAGE STAT
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaubiyal J, 2018, 3RD INTERNATIONAL CONFERENCE ON BIG DATA AND INTERNET OF THINGS (BDIOT 2019), P135, DOI 10.1145/3361758.3361784
   Khalil H., 2020, 2020 3 INT C COMPUT, P1, DOI DOI 10.1109/ICOMET48670.2020.9074131
   Khan K, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT), P232, DOI 10.1109/ICADIWT.2014.6814687
   Koggalahewa D, 2020, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2020), DOI 10.1145/3373017.3373025
   Kosmanos D., 2019, P 3 INT C NAT LANG S, P1, DOI DOI 10.1109/SEEDA-CECNSM.2019.8908528
   Kramer S, IDENTIFYING VIRAL BO
   Kuchling A.M, Regular expression howto
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Lee K, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P435, DOI 10.1145/1835449.1835522
   Lee Kyumin, 2011, P INT AAAI C WEB SOC, V5, P185, DOI [10.1609/icwsm.v5i1.14106, DOI 10.1145/3110025.3110090]
   Lee S, 2013, IEEE T DEPEND SECURE, V10, P183, DOI 10.1109/TDSC.2013.3
   Lingam Greeshma, 2020, ASIA CCS '20: Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, P708, DOI 10.1145/3320269.3384770
   Lingam G, 2019, APPL INTELL, V49, P3947, DOI 10.1007/s10489-019-01488-3
   Liu H, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0162-z
   Liu YS, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P492, DOI 10.1145/2976749.2978319
   Loader BD, 2011, INFORM COMMUN SOC, V14, P757, DOI 10.1080/1369118X.2011.592648
   Locker M, TWITTER IS AUTOMATIC
   Luo LH, 2020, IOP CONF SER-MAT SCI, V719, DOI 10.1088/1757-899X/719/1/012063
   Mahmood A, 2019, CLEF
   Mazza M, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P183, DOI 10.1145/3292522.3326015
   Meda C., 2014, PROC INT CARNAHAN C, P177
   Metaxas PT, 2012, SCIENCE, V338, P472, DOI 10.1126/science.1230456
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Mostrous A, RUSSIA USED TWITTER
   Orabi M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102250
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Paudel P, 2019, TABLES HAVE TURNED S, DOI [10.1145/3341161.3342898, DOI 10.1145/3341161.3342898]
   Potts C, 2020, ARXIV
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rathore S, 2017, INFORM SCIENCES, V421, P43, DOI 10.1016/j.ins.2017.08.063
   Ratkiewicz J, 2011, P 20 INT C COMP WORL
   Rodríguez-Ruiz J, 2020, COMPUT SECUR, V91, DOI 10.1016/j.cose.2020.101715
   Rossi S, 2020, DETECTING POLITICAL, DOI [10.24251/HICSS.2020.298, DOI 10.24251/HICSS.2020.298]
   Sang ETK, 2012, P WORKSH SEM AN SOC, P53
   Sasirekha K, 2013, AGGLOMERATIVE HIERAR
   Shafahi M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3703, DOI 10.1109/BigData.2016.7841038
   Shahapure KR, 2020, PR INT CONF DATA SC, P747, DOI 10.1109/DSAA49011.2020.00096
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Stella M, 2018, ARXIV
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Subrahmanian VS, 2016, COMPUTER, V49, P38, DOI 10.1109/MC.2016.183
   SZPANKOWSKI W, 1993, SIAM J COMPUT, V22, P1176, DOI 10.1137/0222070
   Thomas K, 2011, P IEEE S SECUR PRIV, P447, DOI 10.1109/SP.2011.25
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   TwitterIR, Q4 FISC YEAR 2017 LE
   Varol O, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0111-y
   Varol Onur, 2017, P INT AAAI C WEB SOC, P280, DOI DOI 10.1609/ICWSM.V11I1.14871
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkatesh R., 2017, LECT NOTES ELECTR EN, P34, DOI [10.1007/978-81-322-3592-7, DOI 10.1007/978-81-322-3592-7]
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Viswanath B, 2010, ACM SIGCOMM COMP COM, V40, P363, DOI 10.1145/1851275.1851226
   Wang AH, 2010, SECRYPT 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, P142
   Wang AH, 2010, LECT NOTES COMPUT SC, V6166, P335, DOI 10.1007/978-3-642-13739-6_25
   Wang B., 2015, ARXIV PREPRINT ARXIV, P10
   Wei F, 2019, 2019 FIRST IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS (TPS-ISA 2019), P101, DOI 10.1109/TPS-ISA48467.2019.00021
   Wu JS, 2012, ATLAS OF INTESTINAL STOMAS, P1, DOI 10.1007/978-0-387-78851-7_1
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Xie Y, 2012, P 2012 ACM C COMP CO, P353, DOI [10.1145/, 10.1145/2382196.2382235, DOI 10.1145/2382196.2382235]
   Yang C, 2012, P 21 INT C WORLD WID, P71, DOI DOI 10.1145/2187836.2187847
   Yang C, 2013, IEEE T INF FOREN SEC, V8, P1280, DOI 10.1109/TIFS.2013.2267732
   Yang C, 2011, LECT NOTES COMPUT SC, V6961, P318, DOI 10.1007/978-3-642-23644-0_17
   Yang F., 2012, P ACM SIGKDD WORKSHO, P1
   Yardi Sarita, 2010, First Monday
   Zhang XC, 2012, IEEE DATA MINING, P1194, DOI 10.1109/ICDM.2012.28
NR 107
TC 2
Z9 2
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30831
EP 30854
DI 10.1007/s11042-023-14730-5
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940725400002
DA 2024-07-18
ER

PT J
AU Singh, S
   Tripathi, BK
   Rawat, SS
AF Singh, Sukhendra
   Tripathi, B. K.
   Rawat, Sur Singh
TI Deep quaternion convolutional neural networks for breast Cancer
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Computer-aided detection; Diagnosis; Deep
   learning; Quaternion convolution neural network; Residual network
AB Breast Cancer nowadays has been a major cause of death in women worldwide and this has also been confirmed by the World Health Organization. The severity of this disease can be minimized to a large extent if it is diagnosed properly at an early stage. Two important types of tumors found in the case of breast cancer are malignant and benign. Moreover, It has been observed that, unlike benign tumors, malignant tumors are more dangerous because of their invasive nature. Therefore, the proper treatment of a patient having cancer can be processed in a better way, if the type of tumor can be identified as early as possible. Deep neural networks have delivered a remarkable performance for detecting malignant tumors in histopathological images of breast tissues. However, the existing works today, are focused much on real-valued numbers. When data is multi-channel such as images and audio, conventional real-valued CNN on flattening and concatenating loses spatial relation within a channel. To address the above-said issues, we have exploited a quaternion residual network for detecting breast cancer in a dataset of histopathological images, which are publically available in the dataset of Kaggle. In this work, we first transform breast histopathological images into quaternion domains. Second, the Residual CNN was customized to work in the quaternion domain so that it extracts the better representative features for multidimensional input objects. Extensive experimental results demonstrate that our model architecture although takes slightly more time to train but it offers an increased classification accuracy of 97.20% which is more than the performance of a residual network compatible with real numbers. Also, the proposed model outperforms when compared against the baseline neural network models.
C1 [Singh, Sukhendra] JSS Acad Tech Educ, Informat Technol Dept, Noida, India.
   [Tripathi, B. K.] Harcourt Butler Technol Univ Kanpur, Comp Sci Dept, Kanpur, India.
   [Rawat, Sur Singh] JSS Acad Tech Educ, Comp Sci Dept, Noida, India.
C3 Harcourt Butler Technical University (HBTU)
RP Singh, S (corresponding author), JSS Acad Tech Educ, Informat Technol Dept, Noida, India.
EM sukhendrasingh@gmail.com; abkt.iitk@gmail.com; sur.rawat@jssaten.ac.in
RI Rawat, Sur Singh/V-9496-2018; singh, sukhendra/W-7248-2018
OI Rawat, Sur Singh/0000-0001-7394-6161; singh,
   sukhendra/0000-0001-7980-9889
CR Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Bejnordi BE, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.044504
   Chapala H., 2020, P 2020 INT C ELECT S, P60, DOI DOI 10.1109/ICESC48915.2020.9155805
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Clevert D., 2016, ARXIV151107289
   Comminiello D, 2019, INT CONF ACOUST SPEE, P8533, DOI [10.1109/icassp.2019.8682711, 10.1109/ICASSP.2019.8682711]
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   de Senna FR, 2021, TESSARINE QUATERNION, P350, DOI [10.5753/eniac.2021.18266, DOI 10.5753/ENIAC.2021.18266]
   Eberly D, 2002, MAGIC SOFTWARE INC, V26, P1
   Fonseca P, 2015, PROC SPIE, V9414, DOI 10.1117/12.2081576
   Garbin C, 2020, MULTIMED TOOLS APPL, V79, P12777, DOI 10.1007/s11042-019-08453-9
   Gaudet A. S., 2018, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/IJCNN.2018.8489651
   Grassucci E, 2021, QUATERNION GENERATIV
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516
   Holte R. C., 2003, Workshop on learning from imbalanced datasets II, V11, P1
   Kahya M.A., 2017, J. Appl. Math. Bioinf., V7, P49
   Kallenberg M, 2010, IEEE TMI SPECIAL ISS, P1
   Kominami Y, 2017, IEEE IJCNN, P2673, DOI 10.1109/IJCNN.2017.7966183
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Mooney P., 2017, KAGGLE
   Nazeri K, 2018, LECT NOTES COMPUT SC
   Negi A, 2021, LECT NOTES COMPUTER
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Negi A., 2021, Data Science and Its Applications, P63
   Parcollet T., 2018, Quaternion convolutional neural networks for end-to-end automatic speech recognition
   Parcollet T, 2020, ARTIF INTELL REV, V53, P2957, DOI 10.1007/s10462-019-09752-1
   Parcollet T, 2019, INT CONF ACOUST SPEE, P8514, DOI [10.1109/icassp.2019.8682495, 10.1109/ICASSP.2019.8682495]
   Petrick N, 2013, MED PHYS, V40, DOI 10.1118/1.4816310
   Qiu XC, 2020, INTERSPEECH, P329, DOI 10.21437/Interspeech.2020-1682
   Rakhlin A, 2018, LECT NOTES COMPUT SC, V10882, P737, DOI 10.1007/978-3-319-93000-8_83
   Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222
   Seemendra A, 2021, BREAST CANC CLASSIFI
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P5849, DOI 10.1007/s11042-021-11775-2
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P1743, DOI 10.1007/s11042-021-11409-7
   Sunku K., 1998, BREAST J, V4, P49, DOI [10.1046/j.1524-4741.1998.410049.x, DOI 10.1046/J.1524-4741.1998.410049.X]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   Trabelsi C., 2017, ARXIV
   Vandenberghe ME, 2017, SCI REP-UK, V7, DOI 10.1038/srep45938
   Wen W, 2016, ADV NEUR IN, V29
   Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514
   Yao Y., 2019, 57 ANN M ASS COMP
   Yin QL, 2019, IEEE ACCESS, V7, P20293, DOI 10.1109/ACCESS.2019.2897000
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang Q, 2016, ULTRASONICS, V72, P150, DOI 10.1016/j.ultras.2016.08.004
   Zhu XY, 2018, LECT NOTES COMPUT SC, V11212, P645, DOI 10.1007/978-3-030-01237-3_39
NR 53
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31285
EP 31308
DI 10.1007/s11042-023-14688-4
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000941926100017
DA 2024-07-18
ER

PT J
AU Jia, MX
   Li, XL
   Zhang, Y
AF Jia, Mengxue
   Li, Xiangli
   Zhang, Ying
TI An algorithm of non-negative matrix factorization with the nearest
   neighbor after per-treatments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Nonnegative matrix factorization; Per-treatment; The nearest
   neighbor; Initialization
AB Clustering is a hot topic in machine learning. For high dimension data, nonnegative matrix factorization (NMF) is a crucial technology in clustering. However, NMF has some disadvantages. First, NMF clusters data in original space while outliers and noise will weaken NMF clustering results. Second, NMF does not take local structure which is beneficial for clustering of data into consideration. To address these two disadvantages, a new algorithm is proposed called nonnegative matrix factorization with the nearest neighbor after per-treatments (PNNMF). Per-treatments are used to alleviate effects of outliers and noise. After per-treatments, some credible connected components generated by the nesrest neighbor of data are chosen to capture local structure. Moreover a new initialization for basis matrix is proposed basing these credible connected components. Experiments on real data sets confirm the effectiveness of PNNMF.
C1 [Jia, Mengxue; Li, Xiangli; Zhang, Ying] Guilin Univ Elect Technol, Sch Math & Comp Sci, Guilin 541004, Guangxi, Peoples R China.
   [Jia, Mengxue; Zhang, Ying] Xidian Univ, Sch Math & Stat, Xian 710126, Shaanxi, Peoples R China.
   [Li, Xiangli] Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Data Anal & Computat, Guilin 541004, Guangxi, Peoples R China.
   [Li, Xiangli] Ctr Appl Math Guangxi, GUET, Guilin 541004, Guangxi, Peoples R China.
C3 Guilin University of Electronic Technology; Xidian University; Guilin
   University of Electronic Technology; Guilin University of Electronic
   Technology
RP Li, XL (corresponding author), Guilin Univ Elect Technol, Sch Math & Comp Sci, Guilin 541004, Guangxi, Peoples R China.; Li, XL (corresponding author), Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Data Anal & Computat, Guilin 541004, Guangxi, Peoples R China.; Li, XL (corresponding author), Ctr Appl Math Guangxi, GUET, Guilin 541004, Guangxi, Peoples R China.
EM Jing8029@163.com; lixiangli@guet.edu.cn; zhangying751009@gmail.com
RI li, xiangli/JPX-9556-2023
FU National Natural Science Foundation of China [11961010, 61967004]
FX AcknowledgmentsThis work is supported by the National Natural Science
   Foundation of China(11961010, 61967004).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chen WS, 2019, NEUROCOMPUTING, V348, P40, DOI 10.1016/j.neucom.2018.06.083
   Ding C, 2006, P 12 ACM SIGKDD INT, P126, DOI 10.1145/1150402.1150420
   Gao B, 2012, IEEE T NEUR NET LEAR, V23, P703, DOI 10.1109/TNNLS.2012.2187925
   Hedjam R, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2021.107814
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kong D., 2011, P 20 ACM INT C INF K, P673, DOI DOI 10.1145/2063576.2063676
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2018, IEEE T NEUR NET LEAR, V29, P1947, DOI 10.1109/TNNLS.2017.2691725
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Peng SY, 2020, KNOWL-BASED SYST, V201, DOI 10.1016/j.knosys.2020.106054
   Sarfraz MS, 2019, PROC CVPR IEEE, P8926, DOI 10.1109/CVPR.2019.00914
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun YF, 2022, IET IMAGE PROCESS, V16, P2577, DOI 10.1049/ipr2.12510
   Tang C, 2019, NEURAL NETWORKS, V117, P163, DOI 10.1016/j.neunet.2019.04.015
   Wang YT, 2014, IEEE INT FUZZY SYST, P2511, DOI 10.1109/FUZZ-IEEE.2014.6891755
   Xu W, 2004, P 27 ANN INT ACM SIG, P202, DOI DOI 10.1145/1008992.1009029
   Zhang XY, 2018, INFORM SCIENCES, V432, P463, DOI 10.1016/j.ins.2017.11.038
   Zhang Z, 2018, NEURAL NETWORKS, V108, P128, DOI 10.1016/j.neunet.2018.07.017
   Zhou J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030354
   Zurada JM, 2013, FED CONF COMPUT SCI, P11
NR 26
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30669
EP 30688
DI 10.1007/s11042-023-14571-2
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500002
DA 2024-07-18
ER

PT J
AU Thakur, N
   Ghai, D
   Kumar, S
AF Thakur, Neha
   Ghai, Deepika
   Kumar, Sandeep
TI Automatic imagery Bank Cheque data extraction based on machine learning
   approaches: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bank Cheque processing; Courtesy amount recognition; Date recognition;
   Legal amount recognition; MICR code; Signature verification
ID LEGAL AMOUNTS; HANDWRITTEN; RECOGNITION; BINARIZATION; SYSTEM
AB Bank Cheques are used mainly for financial transactions due to which they are processed in enormous amounts on daily basis around the globe. Often, Cheque execution time and expenses can be saved if the whole method of recognition and verification of the Cheque becomes automatic. Automatic bank Cheque processing system is an emerging research field in the area of computer vision, image processing, pattern recognition, machine learning, and deep learning. The article emphasizes the stages of the proceedings of image acquisition, pre-processing, and extraction and recognition in the automatic bank Cheque processing system. This paper describes the various steps involved in the system of automatic data extraction. It further classifies and examines existing challenges in different stages of automated processing of bank Cheques. An attempt is made in this paper to present state-of-the-art techniques for the automatic processing of bank Cheque images. The categories and sub-categories of various fields related to bank Cheque images are illustrated, benchmark datasets are enumerated, and the performance of the most representative approaches is compared. Moreover, it also contains some information about the products available in the market for automatic Cheque processing. This review provides a fundamental comparison and analysis of the remaining problems in the field. It is found that multilayer feed-forward neural network gave an accuracy of 97.31% for payee's name recognition systems; HMM-MLP gave an accuracy of 95.5% for date recognition system. In the courtesy and legal amount system, DNN gave an accuracy of 98.5% for digit recognition, MLP gave an accuracy of 93.2% for courtesy amount, MQDF gave an accuracy of 97.04% for the legal amount. Further, the SVM classifier gave an accuracy of 99.13% for signature recognition, and deep learning-based Convolutional Neural Networks (CNN) gave an accuracy of 99.14% for handwritten numeric character recognition. This survey paper predicts a promising direction for finding an efficient technique for future research.
C1 [Thakur, Neha; Ghai, Deepika] Lovely Profess Univ, Phagwara 144411, Punjab, India.
   [Kumar, Sandeep] Koneru Lakshmaiah Educ Fdn, Vaddeswaram, Andhra Pradesh, India.
C3 Lovely Professional University; Koneru Lakshmaiah Education Foundation
   (K L Deemed to be University)
RP Kumar, S (corresponding author), Koneru Lakshmaiah Educ Fdn, Vaddeswaram, Andhra Pradesh, India.
EM nehathakur16187@gmail.com; deepika.21507@lpu.co.in;
   er.sandeepsahratia@gmail.com
RI Kumar, Sandeep/ADM-4627-2022
OI Kumar, Sandeep/0000-0002-4752-7884
CR 3i-infotech, 2021, US
   Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Agrawal P, 2021, MULTIMED TOOLS APPL, V80, P5319, DOI 10.1007/s11042-020-09818-1
   Akbari Y, 2018, PATTERN RECOGN, V74, P253, DOI 10.1016/j.patcog.2017.09.011
   Akhtar MS, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P143, DOI 10.1109/ICDIM.2013.6693992
   Ali Ashar, 2016, 2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN), P498, DOI 10.1109/SPIN.2016.7566746
   Ambikapathy, 2018, LECT NOTES ELECTR EN, V442, P287, DOI 10.1007/978-981-10-4762-6_27
   Andersson Linda, 2014, Multidisciplinary Information Retrieval. 7th Information Retrieval Facility Conference, IRFC 2014. Proceedings: LNCS 8849, P1, DOI 10.1007/978-3-319-12979-2_1
   [Anonymous], 2021, ANN CHEQUE USAGE STA
   [Anonymous], MITEK SYSTEMS
   [Anonymous], 2017, CHEQUE UK
   [Anonymous], 2018, BANK ACCOUNT NUMBER
   [Anonymous], 2013, INT J COMPUT APPL
   [Anonymous], HANDWRITTEN DATABASE
   [Anonymous], OMNIXTRACT DATA EXTR
   [Anonymous], 2021, HANDWRITTEN DATA
   [Anonymous], 2018, J INF SECUR
   [Anonymous], 2021, CLEAR DIGITAL CHECK
   [Anonymous], 2017, RECENT PATENTS COMPU
   [Anonymous], 2012, REVISED VALIDITY PER
   [Anonymous], A2IA CHECKREADER CHE
   [Anonymous], 2021, INFOMAX ICHEQUE SUIT
   [Anonymous], 2022, PAYMENTS ARE CHANGIN
   [Anonymous], 2014, ARABIAN BANK CHEQUE
   [Anonymous], 2021, VOID PANTOGRAPH
   [Anonymous], 2017, INDIAN BANK CHEQUE C
   [Anonymous], SMART DOCUMENT PROCE
   [Anonymous], 2021, MICR LINE CHECK
   [Anonymous], 2006, 10 TH INT WORKSHOP F
   [Anonymous], 2017, ADV COMPUT SCI TECHN
   [Anonymous], CHEQUE TRUNCATION SY
   [Anonymous], SEAC REMOTE CAPTURE
   Asha Paul M.K., 2018, Recent Pat. Comput. Sci, V11, P3, DOI DOI 10.2174/2213275911666180719111118
   Cheriet M, 1998, IEEE T IMAGE PROCESS, V7, P918, DOI 10.1109/83.679444
   Coelho F, 2008, SIGMAP 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P320
   Dansena P, 2015, INT CONF CONTEMP, P183, DOI 10.1109/IC3.2015.7346676
   Das Gupta J, 2018, IET IMAGE PROCESS, V12, P1467, DOI 10.1049/iet-ipr.2017.0745
   Dawoud A, 2004, IEEE T IMAGE PROCESS, V13, P1223, DOI 10.1109/TIP.2004.833101
   Deng PS, 1999, COMPUT VIS IMAGE UND, V76, P173, DOI 10.1006/cviu.1999.0799
   Dimauro G, 1997, INT J PATTERN RECOGN, V11, P467, DOI 10.1142/S0218001497000214
   Drew JH, 2000, COMPUT STAT DATA AN, V34, P1, DOI 10.1016/S0167-9473(99)00069-9
   Garg Naresh., 2013, Int. J. Comput. Appl., V71, P8, DOI [10.5120/12320-8533, DOI 10.5120/12320-8533]
   Gari A, 2017, 2017 INT C WIR TECHN, P1
   Gattal A, 2017, PATTERN ANAL APPL, V20, P307, DOI 10.1007/s10044-017-0607-x
   Ghai D., 2013, INT J GRAPH IMAGE PR, V3, P210
   Ghai D, 2019, WIRELESS PERS COMMUN, V109, P455, DOI 10.1007/s11277-019-06574-w
   Ghai D, 2016, INT J COMPUT INT SYS, V9, P900, DOI 10.1080/18756891.2016.1237189
   Gidde KV., 2018, INT RES J ENG TECHNO, V5, P2121
   Govindarajan M, 2016, INT ARAB J INF TECHN, V13, P1092
   Graf R, 2012, PROGR CULTURAL HERIT, P251
   Guillevic D, 1998, PATTERN ANAL APPL, V1, P28, DOI 10.1007/BF01238024
   Gunawan T.S., 2018, INDONES J ELECT ENG, V10, P562, DOI [10.11591/ijeecs.v10.i2.pp562-568, DOI 10.11591/IJEECS.V10.I2.PP562-568]
   Gupta N., 2017, INT J SCI RES COMPUT, V2, P1055
   Hafemann LG, 2020, IEEE T INF FOREN SEC, V15, P1735, DOI 10.1109/TIFS.2019.2949425
   Honggang Z, 2005, IEEE INT C INF COMM, P1430
   Iqbal K., 2017, PROC PAK ACAD SCI PH, V54, P269
   Jayadevan R, 2012, INT J DOC ANAL RECOG, V15, P267, DOI 10.1007/s10032-011-0170-8
   Jayadevan R, 2009, J PATTERN RECOGNIT R, V4, P52
   Jayadevan R., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P166, DOI 10.1109/ICFHR.2010.33
   Jha Mukesh, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P309, DOI 10.1109/ICSSIT46314.2019.8987925
   Karthik S., 2018, CLUSTER COMPUT, V22, P4673
   Ke Liu, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P798, DOI 10.1109/ICPR.1996.547278
   Khatode CV., 2015, INT J ENG SCI RES TE, V4, P1098
   Kim KK, 2001, PROC INT CONF DOC, P964, DOI 10.1109/ICDAR.2001.953928
   Kimura F., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P906, DOI 10.1109/ICDAR.1995.602048
   Kiran YC., 2018, 2018 INT C BIG DATA, V5, P4206
   Knerr S, 1997, INT J PATTERN RECOGN, V11, P505, DOI 10.1142/S0218001497000226
   Kumar DA., 2014, INT J EMERGING TREND, V3, P46
   Lam L., 1876, LECT NOTES COMPUT SC, P163
   Liang XY., 2017, BRIT J ANAESTH, V10, P80
   Madasu VK, 2005, P DIG IM COMP TECHN, P33, DOI DOI 10.1109/DICTA.2005.18
   Maheshwari M., 2018, INT J APPL ENG RES, V13, P8090
   Truong MTN, 2018, SOFT COMPUT, V22, P4197, DOI 10.1007/s00500-017-2709-1
   Mehta M., 2010, International Journal of Computer and Electrical Engineering, V2, P761
   Mello CAB, 2007, IEEE SYS MAN CYBERN, P1137
   Miah Mohammad Badrul Alam, 2015, INT J COMPUT APPL, V118, P21
   Mishra VC., 2018, INT J SCI ENG RES, V6, P34
   Morita M, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P105, DOI 10.1109/IWFHR.2002.1030894
   Mukesh V., 2017, 2017 INT C ADV COMPU, V6, P200
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Nancy GG., 2014, INT J RECENT INNOV T, V2, P1239
   Nath RSS., 2015, INT J SCI RES PUBL, V5, P623
   Nel EM, 2005, IEEE T PATTERN ANAL, V27, P1733, DOI 10.1109/TPAMI.2005.221
   Neves RFP, 2008, INT CONF SYST SIGNAL, P93, DOI 10.1109/IWSSIP.2008.4604375
   Neves RFP, 2011, IEEE SYS MAN CYBERN, P510, DOI 10.1109/ICSMC.2011.6083734
   Palacios R., 2002, MACH VISION APPL, V5, P1
   PALACIOS R, 2004, INT J IMAGE GRAPH, V4, P203, DOI DOI 10.1142/S0219467804001373
   Parven S., 2018, INT J ENG SCI COMPUT, V3, P167
   Rabelo JCB, 2011, IEEE SYS MAN CYBERN, P2523, DOI 10.1109/ICSMC.2011.6084056
   Raghavendra SP, 2015, 2015 IEEE INT C MULT, P1, DOI DOI 10.1109/ITACT.2015.7492682
   Rahman AFR, 1997, PATTERN RECOGN LETT, V18, P781, DOI 10.1016/S0167-8655(97)00078-0
   Reserve Bank of India, 2021, US
   Sadri J, 2014, PATTERN ANAL APPL, V17, P849, DOI 10.1007/s10044-014-0385-7
   Saha A., 2018, IRAN CONF ELECTR ENG, V5, P30
   Sahare P, 2018, ARAB J SCI ENG, V43, P8159, DOI 10.1007/s13369-018-3365-1
   Sahoo S, 2018, J INTELL FUZZY SYST, V35, P1765, DOI 10.3233/JIFS-169712
   Santos JEB., 1997, ADV DOC IMAGE ANAL, V1, P334
   Shridhar M., 2009, 2009 IEEE International Conference on Electro/Information Technology (EIT '09), P170, DOI 10.1109/EIT.2009.5189604
   Singh Santosh Kumar, 2015, 2015 International Conference on Energy Economics and Environment (ICEEE), P1, DOI 10.1109/EnergyEconomics.2015.7235065
   Souza S, 2013, PROCEDIA COMPUT SCI, V22, P1083, DOI 10.1016/j.procs.2013.09.194
   Srivastava S, 2019, ADV INTELL SYST, V697, P589, DOI 10.1007/978-981-13-1822-1_55
   Suen CY, 1999, PATTERN RECOGN LETT, V20, P1287, DOI 10.1016/S0167-8655(99)00098-7
   Sun Y., 2016, 2016 INT COMPUTER S, V9, P13
   Thomas S., 2018, Information and Communication Technology for Sustainable Development, P475
   Vargas JF, 2011, PATTERN RECOGN, V44, P375, DOI 10.1016/j.patcog.2010.07.028
   Verma RN, 2015, PROCEDIA COMPUT SCI, V45, P322, DOI 10.1016/j.procs.2015.03.151
   Viard-Gaudin C., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P455, DOI 10.1109/ICDAR.1999.791823
   Wang M, 2014, INT C PATT RECOG, P3002, DOI 10.1109/ICPR.2014.518
   Wang S, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, P2560, DOI 10.1109/ICNN.1997.614705
   Xiong W, 2018, OPTIK, V164, P218, DOI 10.1016/j.ijleo.2018.02.072
   Xu QZ, 2003, PROC INT CONF DOC, P704
   Zhang Yudong., 2011, INT J DIGITAL CONTEN, V5, P209
   Zheng H., 2017, RECENT PAT COMPUT SC, V10, P62
   Zhou J, 2001, PROC INT CONF DOC, P887, DOI 10.1109/ICDAR.2001.953914
   Zimmer A, 2004, LECT NOTES COMPUT SC, V3072, P562
NR 117
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30543
EP 30598
DI 10.1007/s11042-023-14534-7
EA FEB 2023
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000939106100002
DA 2024-07-18
ER

PT J
AU Arora, N
   Sharma, SC
AF Arora, Nitin
   Sharma, Subhash C.
TI The practical applications of HLBP texture descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; LBP; HLBP; Feature descriptor; Texture feature
ID LOCAL BINARY PATTERNS; FACE RECOGNITION; IMAGE RETRIEVAL
AB The traditional Local binary pattern (LBP) compares the central pixel with all 8-neighboring pixels in a 3 x 3 pixel window to generate LBP codes. However, its circular structure may result in similar LBP codes for different structural patterns. The technique also resulted in high-dimensional feature vectors, which cause a computational burden. Researchers have proposed several LBP variants; however, none of them addressed the aforementioned issues. This paper proposes a Hyperbolic local binary pattern (HLBP) that follows the hyperbolic structure to extract the discriminative features. In particular, HLBP combines 3 x 5 Horizontal hyperbolic-LBP (HHLBP) and 5 x 3 Vertical hyperbolic-LBP (VHLBP) movements. Experiments are conducted on facial and texture image databases to test the robustness of HLBP. The experiment outcomes demonstrate that HLBP with comparative low-dimensional feature vector outperforms the state-of-the-art descriptors.
C1 [Arora, Nitin; Sharma, Subhash C.] Indian Inst Technol, Roorkee, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Arora, N (corresponding author), Indian Inst Technol, Roorkee, India.
EM nitinarora.iitr@gmail.com; scs60fpt@gmail.com
OI ARORA, NITIN/0000-0002-0132-2648
CR Ahmed F., 2011, 2011 Proceedings of IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI 2011), P391, DOI 10.1109/CINTI.2011.6108536
   ALHALAFAWY WS, 2014, LIFE SCI J, V11, P865
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], 2020, BROD TEXT DAT
   Arora N, 2019, INT J IMAGE GRAPH SI, V11
   AT&T laboratories Cambridge, 2008, AT T DAT FAC
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2001, ITE TECHNICAL REPORT, P65
   Bedi AK, 2020, PATTERN RECOGN IMAGE, V30, P578
   Bhowmik MK, 2013, PROC TECH, V10, P724, DOI 10.1016/j.protcy.2013.12.415
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   Das A, 2012, INT C EMERG TRENDS E, P143, DOI 10.1109/ICETEEEM.2012.6494458
   Dehshibi MM, 2007, IRANIAN FACE DATABAS
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   GeorgiaTech, 2018, GEORGIA TECH FACE DA
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Karakas S, 2022, MINIM INVASIV THER, V31, P803, DOI 10.1080/13645706.2021.2025111
   Karanwal Shekhar, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P877, DOI 10.1109/ICIRCA51532.2021.9544765
   Karanwal S, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.166965
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Karanwal S, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.166007
   Li ZM, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419560044
   Liao S, 2007, LECT NOTES COMPUT SC, V4844, P672
   Liu BY, 2019, IEEE I CONF COMP VIS, P10051, DOI 10.1109/ICCV.2019.01015
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Martolia M., 2020, Int. J. Adv. Sci. Technol., V29, P1630
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Sasaki Y., 2007, Teach Tutor Mater, V1, P1
   Shunqing X, 2012, LECT NOTE ELECT ENG, P59
   Singhal A, 2021, MULTIMED TOOLS APPL, V80, P15901, DOI 10.1007/s11042-020-10319-4
   Sucharitha D., 2018, J ENG APPL SCI, V13, P6777, DOI DOI 10.3923/JEASCI.2018.6777.6786
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   The Japanese female facial expression (JAFFE) Dataset, 1998, LYONS MICH KAM MIYUK
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Wang XB, 2019, IEEE I CONF COMP VIS, P9357, DOI 10.1109/ICCV.2019.00945
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhou NN, 2018, NEURAL COMPUT APPL, V30, P3791, DOI 10.1007/s00521-017-2963-2
NR 51
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29379
EP 29404
DI 10.1007/s11042-023-14406-0
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000937854600002
DA 2024-07-18
ER

PT J
AU Denic, N
   Nesic, Z
   Ilic, I
   Zlatkovic, D
   Stojiljkovic, B
   Stojanovic, J
   Petkovic, D
AF Denic, Nebojsa
   Nesic, Zoran
   Ilic, Ivana
   Zlatkovic, Dragan
   Stojiljkovic, Bojan
   Stojanovic, Jelena
   Petkovic, Dalibor
TI Adaptive neuro fuzzy estimation of the most influential speckle noise
   distributions in color images for denoising performance prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speckle noise; Noise level; Images; Forecasting; ANFIS
ID WAVELET
AB This research paper analyzes the speckle noise distributions in images for denoising performance prediction through the prism of spatial domain. The values at the maximum, minimum and middle of spectrum in spatial domain are taken as reference values. All obtained results give a better overview of the "nature" of the digital images in comparison to the theoretical definitions of noises and images as digital signals. Therefore, analyses of the noises in the 2D spectrum give good recommendations for improvement of the filters. The main aim in this study is to investigate which speckle noise distributions in images has the strongest influence for denoising performance prediction. The clean images are available and we adopt it for evaluating our network. In our experiments, Peak Signal to Noise Ratio (PSNR), normalized color difference (NCD), and feature similarity index for color image quality assessment (FSIMc), are used to measure denoising performance. is selected as the evaluation index of the image. Studies on speckle noise distributions in images show that such distribution do have certain disciplines. ALOHA filter is the most influential for the denoising performance prediction.
C1 [Denic, Nebojsa; Nesic, Zoran; Ilic, Ivana; Zlatkovic, Dragan; Stojanovic, Jelena] Univ Pristina, Fac Nat Sci Kosovska Mitrov, Kosovska Mitrovica, Serbia.
   [Stojiljkovic, Bojan] Alfa BK Univ, Fac Math & Comp Sci, Belgrade, Serbia.
   [Petkovic, Dalibor] Univ Nis, Pedag Fac Vranje, Partizanska 14, Vranje 17500, Serbia.
C3 Universiteti i Prishtines; University of Nis
RP Petkovic, D (corresponding author), Univ Nis, Pedag Fac Vranje, Partizanska 14, Vranje 17500, Serbia.
EM dalibortc@gmail.com
OI Ilic, Ivana/0000-0002-6887-3268
CR ABSoft, 2017, NEAT IMAGE
   Bovik, 2000, HDB IMAGE VIDEO PROC
   BUDEVSKI E, 1989, ELECTROCHIM ACTA, V34, P1023, DOI 10.1016/0013-4686(89)87135-X
   Chowdhury D, 2018, 4 INT C OPTO ELECT A, DOI [10.1109/OPTRONIX.2017.8349973, DOI 10.1109/OPTRONIX.2017.8349973]
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Edward RD., 1998, RANDOM PROCESSES IMA
   Esmaeilpour M, 2016, INT J INTERACT MULTI, V4, P12, DOI 10.9781/ijimai.2016.422
   Espinosa LAD, 2018, INT J REMOTE SENS, V39, P2884, DOI 10.1080/01431161.2018.1433894
   Farhane N, 2017, INT J INTERACT MULTI, V4, P88, DOI 10.9781/ijimai.2017.08.001
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Ghulyani M, 2018, IEEE 15 INT S BIOMED, DOI [10.1109/ISBI.2018.8363801, DOI 10.1109/ISBI.2018.8363801]
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hou L, 2018, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2017.8296710, DOI 10.1109/ICIP.2017.8296710]
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   VANVLIET LJ, 1989, COMPUT VISION GRAPH, V45, P167, DOI 10.1016/0734-189X(89)90131-X
   Vijaykumar V. R., 2008, IAENG International Journal of Computer Science, V35, P259
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Yue HJ, 2017, IEEE IMAGE PROC, P2976, DOI 10.1109/ICIP.2017.8296828
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang WH, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105558
   Zhu Y, 2017, 3 DIMENSIONAL BILATE, DOI [10.1049/cp.2017.0083, DOI 10.1049/CP.2017.0083]
NR 29
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21729
EP 21742
DI 10.1007/s11042-023-14633-5
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000936302600013
DA 2024-07-18
ER

PT J
AU Osuna-Coutiño, JAD
   Martinez-Carranza, J
AF Osuna-Coutino, J. A. de Jesus
   Martinez-Carranza, Jose
TI High level structure recognition in single urban images using a CNN and
   SuperPixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High level structure recognition; Superpixel; CNN; Single image; Urban
   scenes
AB High-Level Structure (HLS) recognition locates elements on human-made surfaces (objects, buildings, ground, etc.). There are several approaches to HLS recognition, however, most of these approaches are based on processing 3D data in the form of point clouds extracted from the camera images. In general, 3D point cloud approaches have good performance for certain scenes with video sequences or image sequences, but they need sufficient parallax in order to guarantee accuracy. To address this problem, an alternative is to process a single RGB image seeking to interpret areas of the images where the human-made structure may be observed, thus removing parallax dependency, but adding the challenge of having to interpret image ambiguities correctly. Motivated by the latter, this work presents the results of a novel methodology for HLS recognition using a CNN-Superpixel approach from a single image. For that, our approach has three steps. First, the superpixel and centroid analysis obtains the RGB section and the superpixel to analyze. This section is a portion of the input image that our CNN uses to provide a label. Second, the structure recognition step provides a segmentation, location, and delimitation of the urbanized structures in the scene. For that, we propose a CNN-superpixel configuration, this configuration combines the abstraction power of deep learning and fast computational processing using superpixel segmentation. Third, the connectivity analysis replaces the superpixel label considering the connection between the neighbor superpixels. On the other hand, experimental results are encouraging, our approach has high performance under real-world scenarios. Also, the proposed methodology is 6.53 to 12.18 faster than previous work.
C1 [Osuna-Coutino, J. A. de Jesus; Martinez-Carranza, Jose] Inst Nacl Astrofis Opt & Electr, Dept Comp Sci, Luis Enr Erro 1, Cholula 72840, Puebla, Mexico.
   [Osuna-Coutino, J. A. de Jesus] Univ Ciencia & Tecnol Descartes SC, Dept Sci, Cipres 480, Tuxtla 29065, Chiapas, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica
RP Martinez-Carranza, J (corresponding author), Inst Nacl Astrofis Opt & Electr, Dept Comp Sci, Luis Enr Erro 1, Cholula 72840, Puebla, Mexico.
EM carranza@inaoep.mx
RI Martinez-Carranza, Jose/Y-1190-2019
OI Martinez-Carranza, Jose/0000-0002-8914-1904
FU Royal Society-Newton Advanced Fellowship [NA140454]
FX The first author is thankful the internal call for collaboration
   scholarships INAOE 2021-2002. The second author is thankful for the
   support received through his Royal Society-Newton Advanced Fellowship
   with reference NA140454
CR Achanta R., 2010, SLIC Superpixels
   Aguilar-González A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010053
   Alhashim I., 2019, arXiv
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Osuna-Coutiño JAD, 2022, VISUAL COMPUT, V38, P2899, DOI 10.1007/s00371-021-02163-w
   Osuna-Coutiño JAD, 2019, LECT NOTES COMPUT SC, V11524, P271, DOI 10.1007/978-3-030-21077-9_25
   Osuna-Coutiño JAD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030563
   Osuna-Coutiño JAD, 2016, INT C PATT RECOG, P1923, DOI 10.1109/ICPR.2016.7899917
   Osuna-Coutino JAD, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P135, DOI [10.1109/ISMAR-Adjunct.2016.53, 10.1109/ISMAR-Adjunct.2016.0060]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Feng RW, 2021, IEEE J BIOMED HEALTH, V25, P3700, DOI 10.1109/JBHI.2020.3040269
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Haines Osian, 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P289
   Haines O, 2015, IEEE T PATTERN ANAL, V37, P1849, DOI 10.1109/TPAMI.2014.2382097
   Hashim HA, 2021, AEROSP SCI TECHNOL, V111, DOI 10.1016/j.ast.2021.106569
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang JW, 2019, IEEE I CONF COMP VIS, P8637, DOI 10.1109/ICCV.2019.00873
   Joo K, 2019, IEEE T PATTERN ANAL, V41, P682, DOI 10.1109/TPAMI.2018.2799944
   Kang ZZ, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9050330
   Kim P, 2018, LECT NOTES COMPUT SC, V11208, P350, DOI 10.1007/978-3-030-01225-0_21
   Kosecká J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu Shichen, 2021, P IEEE CVF INT C COM, P12859
   Luo ST, 2021, PROC CVPR IEEE, P2836, DOI 10.1109/CVPR46437.2021.00286
   Mahmoud Mohamed H., 2023, Personal and Ubiquitous Computing, P751, DOI 10.1007/s00779-020-01519-8
   McClean Eric, 2011, 2011 Irish Machine Vision and Image Processing Conference, P1, DOI 10.1109/IMVIP.2011.10
   Micusík B, 2008, PROC CVPR IEEE, P1127
   Osuna-Coutino J., 2019, IEEE INT C CONTR DEC
   Osuna-Coutiño JAD, 2020, INT J REMOTE SENS, V41, P8256, DOI 10.1080/01431161.2020.1767821
   Peng X., 2022, P IEEE CVF WINT C AP, P119
   Ren ZZ, 2018, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.2018.00086
   Rosen DM, 2021, ANNU REV CONTR ROBOT, V4, P215, DOI 10.1146/annurev-control-072720-082553
   Ruder S., 2016, ARXIV
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012
   Wang C, 2019, NEUROCOMPUTING, V323, P139, DOI 10.1016/j.neucom.2018.09.075
   Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Yu Xumin, 2022, CVPR, P19313
   Zhao RB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051248
   Zhu H, 2022, IEEE T PATTERN ANAL, V44, P7363, DOI 10.1109/TPAMI.2021.3102128
   Zhu YH, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1605-z
NR 51
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25175
EP 25196
DI 10.1007/s11042-023-14422-0
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000929502800001
DA 2024-07-18
ER

PT J
AU Manju
   Singh, S
AF Manju, Samayveer
   Singh, Samayveer
TI Modified energy-proficient partial coverage methodology for optimizing
   coverage in WSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target coverage; NP-completeness; alpha-coverage; Energy-efficiency;
   alpha-lifetime; Upper bound
ID BARRIER COVERAGE; AREA COVERAGE; NETWORK LIFETIME; SENSOR NETWORKS;
   ALGORITHM
AB In energy-constrained wireless sensor network, one way is to the maximize network lifetime to cover all the targets (full coverage) is to group sensor nodes proficiently in such a way that each subset (called cover set) is capable enough of monitoring all the targets in the given area of interest. In some of WSNs applications, such as average temperature or humidity measurement in an area, neglecting some of the targets do not affects the outcome of the network. By excluding a fraction of targets, network lifetime increases considerably because fewer sensors are required to monitor targets in each cover set. This variant of coverage is called alpha-Coverage (0 < alpha < 1) or partial coverage. This paper proposes an energy-proficient heuristic to maximize the network lifetime under alpha-Coverage scenario. Under alpha-Coverage constraint, while neglecting a fraction (1-alpha) of targets, a set of neglected targets may never change. Due to this, some of the targets may face negligible or zero coverage. In order to avoid neglecting the same set of targets over subsequent cover sets, we further propose a minimum coverage bound for each target in the given networks. Simulation results show that the proposed heuristic achieves better solution as compared to the existing approaches while calculating the network lifetime.
C1 [Manju, Samayveer] Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
   [Singh, Samayveer] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, India.
C3 Jaypee Institute of Information Technology (JIIT); National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Manju (corresponding author), Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
EM manju.nunia@gmail.com
RI Singh, Samayveer/X-8119-2019
OI Singh, Samayveer/0000-0002-4199-721X
CR Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422
   Cardei M., 2005, P IEEE INFOCOM
   Carrabs F, 2015, J NETW COMPUT APPL, V58, P12, DOI 10.1016/j.jnca.2015.08.018
   Charr JC, 2020, AD HOC NETW, V107, DOI 10.1016/j.adhoc.2020.102264
   Chaudhary M, 2009, LECT NOTES COMPUT SC, V5408, P325
   DeWitt J, 2017, AD HOC NETW, V56, P72, DOI 10.1016/j.adhoc.2016.11.014
   Gentili M, 2013, OPTIM LETT, V7, P157, DOI 10.1007/s11590-011-0405-0
   Ghaffari F, 2022, IET NETW, V11, P58, DOI 10.1049/ntw2.12034
   Gong XW, 2016, IEEE ACM T NETWORK, V24, P259, DOI 10.1109/TNET.2014.2360849
   Kong HS, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1294, DOI [10.1109/itaic.2019.8785849, 10.1109/ITAIC.2019.8785849]
   Lu MM, 2005, LECT NOTES COMPUT SC, V3619, P43
   Manju, 2022, WIRELESS PERS COMMUN, V122, P963, DOI 10.1007/s11277-021-08935-w
   Manju, 2011, INT J AD HOC SENS UB, V2, P45, DOI [10.5121/ijasuc.2011.2105, DOI 10.5121/IJASUC.2011.2105]
   Mehra Pawan Singh, 2019, International Journal of Information Technology, V11, P507, DOI 10.1007/s41870-017-0071-2
   Mehra PS, 2019, SCALABLE COMPUT-PRAC, V20, P41, DOI 10.12694/scpe.v20i1.1443
   Mehra PS., 2018, ADV INTELLIGENT SYST, V638, P479, DOI DOI 10.1007/978-981-10-6005-2_48
   Mini S, 2011, AD HOC SENS WIREL NE, V13, P251
   Hanh NT, 2019, INFORM SCIENCES, V488, P58, DOI 10.1016/j.ins.2019.02.059
   Saha D, 2016, INNOV SYST SOFTW ENG, V12, P227, DOI 10.1007/s11334-016-0277-7
   Singh D, 2018, IEEE INT ADV COMPUT, P33, DOI 10.1109/IADCC.2018.8692098
   Singh S, 2017, ENG SCI TECHNOL, V20, P345, DOI 10.1016/j.jestch.2016.08.009
   Singh Satendra, 2019, Indian J Med Ethics, V4, P29, DOI [10.20529/IJME.2018.064, 10.1109/ICCABS.2018.8542085]
   Slijepcevic S, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-10, CONFERENCE RECORD, P472, DOI 10.1109/ICC.2001.936985
   Nguyen T, 2017, PEER PEER NETW APPL, V10, P519, DOI 10.1007/s12083-016-0524-6
   Wang J, 2018, CMC-COMPUT MATER CON, V56, P433, DOI 10.3970/cmc.2018.04132
   Wang ZB, 2017, AD HOC NETW, V64, P65, DOI 10.1016/j.adhoc.2017.06.004
   Xu BF, 2016, WIREL NETW, V22, P1, DOI 10.1007/s11276-015-0946-8
   Yu J, 2017, IEEE VTS VEH TECHNOL, V66
   Zhang H., 2006, International Journal of Sensor Networks, V1, P64, DOI [10.1504/IJSNET.2006.010835, DOI 10.1504/IJSNET.2006.010835]
NR 29
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22669
EP 22685
DI 10.1007/s11042-023-14563-2
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000933104800009
DA 2024-07-18
ER

PT J
AU Martínez-González, EA
   Alba, A
   Arce-Santana, E
   Fernández-Wong, J
   Mendez, MO
AF Martinez-Gonzalez, Eduardo A.
   Alba, Alfonso
   Arce-Santana, Edgar
   Fernandez-Wong, Jorge
   Mendez, Martin O.
TI A novel system for the automatic reconstruction of visual field based on
   eye tracking and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Eye movement perimetry; Eye tracker; Visual field
   assessment
AB Eye movement perimetry (EMP) is a paradigm developed to assess the visual field without the necessity of suppressing the natural eye movements during the test. Unlike the standard automated perimetry (SAP) where the patient's responses are recorded using a button, EMP uses the natural eye movements reflex as responses during the evaluation. The reliability of EMP depends on correctly determining whether a stimulus is seen or not which, in turn, depends on an adequate analysis of the eye movement data. However, many studies in EMP have focused on characterizing eye movements and only a few authors have documented their methods to determine whether a peripheral stimulus was seen during the test. Furthermore, many of them use static thresholds to perform the classification, but it is not clear how these threshold values were obtained. Based on the foregoing, we develop a threshold test based on FASTPAC C24-2 and EMP for the visual field assessment. Our method uses two machine learning techniques: (1) cascaded K-Means and Bayesian classifiers (KBC) and (2) an Artificial Neural Network (ANN) to classify whether a stimulus was seen or not. Our method was validated with twenty healthy participants (13 women and 7 men) aged 19-43 years (mu = 26 +/- 5 years), where the participants performed both an EMP test and an SAP emulation test. Results were compared with gaze trajectories annotations performed by an expert, obtaining accuracy values between 96.8% and 98.9% for KBC and ANN, and values between 90.5% and 92% for SAP emulation.
C1 [Martinez-Gonzalez, Eduardo A.; Alba, Alfonso; Arce-Santana, Edgar; Mendez, Martin O.] Univ Autonoma San Luis Potosi, Fac Ciencias, San Luis Potosi, SLP, Mexico.
   [Alba, Alfonso; Arce-Santana, Edgar; Mendez, Martin O.] Univ Autonoma San Luis Potosi, Lab Nacl CI3M, San Luis Potosi, SLP, Mexico.
   [Fernandez-Wong, Jorge] Hosp Especial Med Salud, San Luis Potosi, SLP, Mexico.
C3 Universidad Autonoma de San Luis Potosi; Universidad Autonoma de San
   Luis Potosi
RP Mendez, MO (corresponding author), Univ Autonoma San Luis Potosi, Fac Ciencias, San Luis Potosi, SLP, Mexico.; Mendez, MO (corresponding author), Univ Autonoma San Luis Potosi, Lab Nacl CI3M, San Luis Potosi, SLP, Mexico.
EM martin.mendez@uaslp.mx
RI Alba, Alfonso/KIJ-1643-2024
FU CONACYT- Mexico [712805]
FX E.A. Martinez-Gonzalez acknowledges CONACYT- Mexico for the scholarship
   712805.
CR Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Demirel S, 1994, J Glaucoma, V3, P28
   Duda R., 1973, Pattern Classification and Scene Analysis
   Heijl A, 2019, AM J OPHTHALMOL, V198, P154, DOI 10.1016/j.ajo.2018.10.010
   JERNIGAN ME, 1980, COMPUT BIOL MED, V10, P11, DOI 10.1016/0010-4825(80)90003-7
   JOHNSON CA, 1988, APPL OPTICS, V27, P1030, DOI 10.1364/AO.27.001030
   Jones PR, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.8.18
   Jones PR, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.1.17
   Kim DE, 1995, ENG MED BIOL SOC, P629
   KOSNIK W, 1986, INVEST OPHTH VIS SCI, V27, P1720
   Martinez-Gonzalez EA, 2020, HEALTH TECHNOL-GER, V10, P437, DOI 10.1007/s12553-019-00366-9
   Mazumdar D, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.4.13
   McTrusty AD, 2017, TRANSL VIS SCI TECHN, V6, DOI 10.1167/tvst.6.5.4
   Montolio FGJ, 2012, INVEST OPHTH VIS SCI, V53, P7010, DOI 10.1167/iovs.12-10268
   Murray IC, 2017, TRANSL VIS SCI TECHN, V6, DOI 10.1167/tvst.6.5.3
   Murray IC, 2016, TRANSL VIS SCI TECHN, V5, DOI 10.1167/tvst.5.4.15
   Murray IC, 2009, OPHTHALMOLOGY, V116, P2017, DOI 10.1016/j.ophtha.2009.03.015
   Pel JJM, 2013, TRANSL VIS SCI TECHN, V2, DOI 10.1167/tvst.2.7.3
NR 18
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27193
EP 27215
DI 10.1007/s11042-023-14464-4
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000929402100001
DA 2024-07-18
ER

PT J
AU Liu, GQ
   Ge, HW
   Su, SZ
   Wang, SX
AF Liu, Guoqing
   Ge, Hongwei
   Su, Shuzhi
   Wang, Shuangxi
TI Low-rank tensor multi-view subspace clustering via cooperative
   regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hypergraph regularization; Tikhonov regularization; Low-rank; Tensor;
   Subspace clustering
ID DIMENSIONALITY REDUCTION; CLASSIFICATION
AB In order to explore the importance of the hypergraph regularization and the Tikhonov regularization in multi-view clustering, this paper proposes a novel multi-view clustering model, termed as low-rank tensor multi-view subspace clustering via collaborative regularization (LT-MSCCR). The LT-MSCCR model introduces the idea of tensor. The tensor is designed to represent the result of superimposing the subspace representation matrix, which is used to explore the high order correlations between different views, and the low-rank restriction is performed for this tensor to effectively reduce redundant information. Furthermore, we adopt the hypergraph regularization to mine effective geometric information in multi-view data. Meanwhile, we also impose the Tikhonov regularization constraint on the subspace representation matrix so as to improve the smoothness of the subspace representation matrix and enhance the recognition performance of the proposed method. In addition, we also designed a valuable approach to optimizing the proposed model and theoretically analyzing the convergence of the LT-MSCCR method. The experimental results on some datasets show that the proposed model is better than many advanced multi-view clustering methods.
C1 [Liu, Guoqing; Ge, Hongwei; Wang, Shuangxi] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Liu, Guoqing; Ge, Hongwei; Wang, Shuangxi] Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
   [Su, Shuzhi] Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan 232001, Anhui, Peoples R China.
C3 Jiangnan University; Jiangnan University; Anhui University of Science &
   Technology
RP Ge, HW (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Ge, HW (corresponding author), Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
EM ghw8601@163.com
RI Zhang, Xiaoxi/KBP-8753-2024; Zhang, Chi/JSK-0744-2023; Wang,
   lingyu/JLM-2013-2023; Wang, Xingyu/JNE-0602-2023; chen,
   wang/KGK-5932-2024; liu, wenli/JRW-0517-2023; Wang,
   Yuchen/JPW-9345-2023; Wang, Siying/KHX-1894-2024; ZHANG,
   YINGFANG/JQW-2816-2023
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2011, INT C NEURAL INF PRO
   [Anonymous], 2010, UILUENG092215 UIUC
   Avants BB, 2021, NAT COMPUT SCI, V1, P143, DOI 10.1038/s43588-021-00029-8
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657
   Chen HZ, 2022, APPL INTELL, V52, P9239, DOI 10.1007/s10489-021-02895-1
   Chen MS, 2021, INFORM FUSION, V68, P8, DOI 10.1016/j.inffus.2020.10.013
   Chen YY, 2021, IEEE T IMAGE PROCESS, V30, P4022, DOI 10.1109/TIP.2021.3068646
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   Han YH, 2022, MULTIMED TOOLS APPL, V81, P2259, DOI 10.1007/s11042-021-11667-5
   Huang AP, 2020, IEEE T IMAGE PROCESS, V29, P9600, DOI 10.1109/TIP.2020.3029883
   Jiang GQ, 2021, NEUROCOMPUTING, V427, P225, DOI 10.1016/j.neucom.2020.07.132
   Jiao ZY, 2017, INT CONF ACOUST SPEE, P2851, DOI 10.1109/ICASSP.2017.7952677
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kang Z, 2022, IEEE T CYBERNETICS, V52, P8976, DOI 10.1109/TCYB.2021.3061660
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Li ZH, 2022, NEUROCOMPUTING, V471, P251, DOI 10.1016/j.neucom.2020.08.049
   Lin Y., P IEEE CVPR, V2021, P11174
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu J, 2009, IEEE I CONF COMP VIS, P2114
   Lu GF, 2020, NEURAL NETWORKS, V125, P214, DOI 10.1016/j.neunet.2020.02.014
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan GX, 2021, IEEE T BIO-MED ENG, V68, P2529, DOI 10.1109/TBME.2020.3048594
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sun YQ, 2019, J VIS COMMUN IMAGE R, V62, P253, DOI 10.1016/j.jvcir.2019.05.016
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Loon W, 2020, INFORM FUSION, V61, P113, DOI 10.1016/j.inffus.2020.03.007
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2
   Xu HL, 2020, NEURAL NETWORKS, V132, P245, DOI 10.1016/j.neunet.2020.08.019
   Xu YJ, 2021, FUTURE GENER COMP SY, V117, P138, DOI 10.1016/j.future.2020.11.005
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968
   Zhang CJ, 2020, IEEE T IMAGE PROCESS, V29, P617, DOI 10.1109/TIP.2019.2934576
   Zhou D., 2006, ADV NEURAL INFORM PR, P1601, DOI DOI 10.7551/MITPRESS/7503.003.0205
   Zhu XF, 2020, NEUROCOMPUTING, V403, P53, DOI 10.1016/j.neucom.2020.03.052
NR 45
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 27
PY 2022
DI 10.1007/s11042-022-14298-6
EA DEC 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7I6TJ
UT WOS:000904017400003
DA 2024-07-18
ER

PT J
AU Yan, YF
   Chen, CLZ
   Gao, JY
AF Yan, Yifan
   Chen, Chenglizhao
   Gao, Jingyang
TI Lossless segmentation of cardiac medical images by a resolution
   consistent network with nondamage data preprocessing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiac segmentation; Deep learning; Dilated convolution; Data
   preprocessing
ID MULTI-ATLAS SEGMENTATION
AB Convolutional neural networks originate from image classification tasks. The pooling operation can expand the receptive field and reduce the amount of calculation, but a large amount of pixel information can be lost, which is obviously harmful to pixel-level segmentation accuracy. Dilation convolution expands the receptive field and keeps the resolution unchanged, but it increases the amount of data storage and calculation. Therefore, dilation convolution can only be applied to a limited number of deep layers in a network. It is common that different samples have different sizes in medical image dataset. The resize operation is widely used in the field to obtain uniform sizes. However, the resize operation adds, deletes and modifies a large number of pixels based on the interpolation method. In this way, an image after resizing is damaged to a certain extent at the pixel level, which also significantly affects the performance of the segmentation network. We propose a resolution-consistent network (RCN), which removes all pooling layers and keeps all resolutions consistent to solve the data loss problem caused by downsampling operations. To solve the problem of the increased amount of data storage and calculation caused by dilated convolution and the data damage caused by the resize operation, we propose a nondamage data preprocessing method that includes a coarse segmentation network, cardiac center point positioning algorithm and nondamage cropping to avoid any resize operations. We achieve state-of-the-art performance and reach first place with respect to some indicators on the widely-used automated cardiac diagnosis challenge (ACDC) dataset. Our average dice scores are 0.951 (left ventricle), 0.915 (right ventricle) and 0.910 (myocardium) on the test set.
C1 [Yan, Yifan; Gao, Jingyang] Beijing Univ Chem Technol, Beijing, Peoples R China.
   [Chen, Chenglizhao] China Univ Petr East China, Qingdao, Peoples R China.
C3 Beijing University of Chemical Technology; China University of Petroleum
RP Gao, JY (corresponding author), Beijing Univ Chem Technol, Beijing, Peoples R China.
EM 542250984@qq.com; cclz123@163.com; gaojy@mail.buct.edu.cn
FU Beijing Natural Science Foundation [5182018]; NationalNatural Science
   Foundation of China [62172246]; Open Project Program of State Key
   Laboratoryof Virtual Reality Technology and Systems [VRLAB2021A05];
   Youth Innovation and TechnologySupport Plan of Colleges and Universities
   in Shandong Province [2021KJ062]
FX This research is supported in part by Beijing Natural Science Foundation
   (5182018), the NationalNatural Science Foundation of China (No.
   62172246), the Open Project Program of State Key Laboratoryof Virtual
   Reality Technology and Systems (VRLAB2021A05), and the Youth Innovation
   and TechnologySupport Plan of Colleges and Universities in Shandong
   Province (2021KJ062).
CR [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2017, INT WORKSH STAT ATL
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   Bustamante M, 2018, MED IMAGE ANAL, V49, P128, DOI 10.1016/j.media.2018.08.003
   Calisto MB, 2020, NEURAL NETWORKS, V126, P76, DOI 10.1016/j.neunet.2020.03.007
   Chaudhury A, 2018, INDIAN J HEMATOL BLO, V34, P530, DOI 10.1007/s12288-017-0895-8
   Chen C, 2020, ARXIV200802973
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.04191
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Dou Q, 2017, MED IMAGE ANAL, V41, P40, DOI 10.1016/j.media.2017.05.001
   Duan JM, 2019, IEEE T MED IMAGING, V38, P2151, DOI 10.1109/TMI.2019.2894322
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Ganaye PA, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101551
   Geng L, 2019, COMPUT ASSIST SURG, V24, P27, DOI 10.1080/24699322.2019.1649071
   Guan DY, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107764
   Ieracitano C, 2021, IEEE-CAA J AUTOMATIC, V8, P64, DOI 10.1109/JAS.2020.1003387
   Isensee F, 2018, LECT NOTES COMPUT SC, V10663, P120, DOI 10.1007/978-3-319-75541-0_13
   Islam MA, 2017, PROC CVPR IEEE, P4877, DOI 10.1109/CVPR.2017.518
   Jang Y, 2018, LECT NOTES COMPUT SC, V10663, P161, DOI 10.1007/978-3-319-75541-0_17
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kirisli HA, 2010, PROC SPIE, V7623, DOI 10.1117/12.838370
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kudo Y, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P452, DOI 10.23919/MVA.2017.7986898
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lieman-Sifry J, 2017, LECT NOTES COMPUT SC, V10263, P127, DOI 10.1007/978-3-319-59448-4_13
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Painchaud N, 2020, IEEE T MED IMAGING, V39, P3703, DOI 10.1109/TMI.2020.3003240
   Poudel RPK, 2017, LECT NOTES COMPUT SC, V10129, P83, DOI 10.1007/978-3-319-52280-7_8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santos Claudio Filipi Goncalves dos, 2020, SN Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00295-9, DOI 10.1007/S42979-020-00295-9]
   Skandarani Y, 2020, ARXIV200509026
   Tran PV, 2016, ARXIV160400494, DOI [10.48550/arXiv.1604.00494, DOI 10.48550/ARXIV.1604.00494]
   Ullah I, 2021, MULTIMED TOOLS APPL, V80, P7145, DOI 10.1007/s11042-020-10111-4
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wei ZH, 2020, MULTIMED TOOLS APPL, V79, P27115, DOI 10.1007/s11042-020-09334-2
   Wu Huikai, 2019, ARXIV190311816
   Xia PF, 2020, MULTIMED TOOLS APPL, V79, P24225, DOI 10.1007/s11042-020-09110-2
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yamashita T, 2018, IEEE IMAGE PROC, P1593, DOI 10.1109/ICIP.2018.8451033
   Zhang JM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132686
   Zhang L, 2018, BOUND VALUE PROBL, DOI 10.1186/s13661-018-1099-3
   Zhang Q, 2017, LECT NOTES COMPUT SC, V10635, P364, DOI 10.1007/978-3-319-70096-0_38
   Zhou RR, 2017, RADIOTHER ONCOL, V122, P66, DOI 10.1016/j.radonc.2016.11.016
   Zhuang XH, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101537
   Zhuang XH, 2015, MED PHYS, V42, P3822, DOI 10.1118/1.4921366
   Zotti C, 2019, IEEE J BIOMED HEALTH, V23, P1119, DOI 10.1109/JBHI.2018.2865450
   Zuluaga MA, 2013, LECT NOTES COMPUT SC, V7945, P174, DOI 10.1007/978-3-642-38899-6_21
NR 53
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20951
EP 20973
DI 10.1007/s11042-022-14202-2
EA DEC 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000894530200002
DA 2024-07-18
ER

PT J
AU Moridvaisi, H
   Razzazi, F
   Pourmina, M
   Dousti, M
AF Moridvaisi, Hooman
   Razzazi, Farbod
   Pourmina, Mohammadali
   Dousti, Massoud
TI An extended TLD tracking algorithm using co-training learning for low
   frame rate videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Kalman filter; Mean-shift algorithm; Learning
   algorithm; Tracking learning detection
ID TARGET TRACKING; SYSTEM
AB The conventional tracking-learning-detection (TLD) algorithm is sensitive to illumination changes, clutter, significant changes of target shape between consecutive frames. In addition, low frame rate scenarios result in drift in object position or even missing the object. To solve these problems and enhance the tracking robustness, in this paper, TLD algorithm was extended in two folds. First, Kalman filter and Mean-shift algorithms were combined for the tracking part and second, co-training semi-supervised learning algorithm was used for the learning part of the conventional TLD structure. The Kalman filter estimates the position of the target in the next frame based on the previous positions of the target. This reduces tracking failure. On the other hands, the Mean-shift tracking algorithm is robust to rotation, partial occlusion and scale changing. In the learning part of TLD structure, two training tracking algorithms with two independent classifiers were run on the current frame simultaneously. Its structure makes data of both pools (color features and target templates) update by the results of other algorithm, in addition to the results of the corresponding algorithm in each of the tracking and detection algorithms. Therefore, classifiers can learn faster changing features of the target during the consecutive frames in online tracking process. Finally, the extended structure can solve the problem of lost object in LFR videos tracking and other similar challenges simultaneously. In terms of overlap ratio metric, comparing with conventional TLD and extended kernelized correlation filters (EKCF) algorithms, the success rate of our algorithm under various scenarios has increased by 161.03% and 255.82% respectively and under other scenarios, in terms of precision metric, it has increased by 18.46% and 1479.47%, respectively. Accordingly, comparative evaluations of the proposed method to other top state-of-the-art tracking algorithms under various scenarios present in TB-100 dataset, the superior performance of the proposed algorithm was demonstrated compared to other tracking algorithms in terms of tracking robustness, stability and real-time performance.
C1 [Moridvaisi, Hooman; Razzazi, Farbod; Pourmina, Mohammadali; Dousti, Massoud] Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University
RP Razzazi, F (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
EM h.moridvasi@srbiau.ac.ir; razzazi@srbiau.ac.ir; pourmian@srbiau.ac.ir;
   M_dousti@srbiau.ac.ir
CR Ahmadkelayeh S, 2023, CHEM ENG COMMUN, V210, P398, DOI 10.1080/00986445.2022.2050711
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Boroujeni HS, 2012, COMM COM INF SC, V295, P143
   Carneiro G, 2011, IEEE I CONF COMP VIS, P1700, DOI 10.1109/ICCV.2011.6126433
   Chenchen Yue, 2020, IOP Conference Series: Materials Science and Engineering, V790, DOI 10.1088/1757-899X/790/1/012063
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Chuang MC, 2014, IEEE IMAGE PROC, P5232, DOI 10.1109/ICIP.2014.7026059
   Dai WJ, 2016, AER ADV ENG RES, V81, P398
   Dong EZ, 2019, IET COMPUT VIS, V13, P730, DOI 10.1049/iet-cvi.2018.5787
   Duan HY, 2020, IOP C SER EARTH ENV, V440, DOI 10.1088/1755-1315/440/3/032015
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Gaxiola LN, 2016, OPT COMMUN, V365, P140, DOI 10.1016/j.optcom.2015.11.077
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu JH, 2017, CHIN CONT DECIS CONF, P6096, DOI 10.1109/CCDC.2017.7978266
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Jalali V, 2020, INT J MULTIMED INF R, V9, P271, DOI 10.1007/s13735-020-00199-7
   Jeong J, 2017, EXPERT SYST APPL, V79, P194, DOI 10.1016/j.eswa.2017.02.043
   Junsong Zhang, 2021, 2021 China Automation Congress (CAC), P310, DOI 10.1109/CAC53003.2021.9727475
   Junxiu Zhou, 2013, 2013 5th International Conference on Intelligent Networking and Collaborative Systems, P716, DOI 10.1109/INCoS.2013.138
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kong WW, 2015, CHIN CONTR CONF, P5359, DOI 10.1109/ChiCC.2015.7260477
   Lee G, 2017, EXPERT SYST APPL, V80, P46, DOI 10.1016/j.eswa.2017.03.023
   Li T, 2016, 8 INT C DIGITAL IMAG, P100330
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Li Z, 2008, 2008 19 INT C PATTER, P1051
   Miao F, 2017, ELECT DESIGN ENG, V7
   Moridvaisi H, 2020, MULTIMED TOOLS APPL, V79, P20995, DOI 10.1007/s11042-020-08867-w
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Otoom M, 2021, J REAL-TIME IMAGE PR, V18, P937, DOI 10.1007/s11554-020-01050-2
   Palaniappan K., 2010, INFORM FUSION FUSION, P1, DOI DOI 10.1109/ICIF.2010.5711891
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Pang Y, 2013, PROC SPIE, V8742, DOI 10.1117/12.2015954
   Park E, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P234, DOI 10.1109/KSE.2015.59
   Piao S, 2014, FIELD ASSIST ROBOT A, P74
   Porikli F, 2012, STUD COMPUT INTELL, V409, P3
   Rosenfeld, 2005, SEMISUPERVISED LEARN
   Sathish PK, 2018, INT J MULTIMED INF R, V7, P221, DOI 10.1007/s13735-018-0153-3
   Siqueira DL, 2016, IEEE LAT AM T, V14, P1966, DOI 10.1109/TLA.2016.7483541
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Wang FL, 2007, MEAS SCI TECHNOL, V18, P2546, DOI 10.1088/0957-0233/18/8/030
   Wang T, 2019, MULTIMED TOOLS APPL, V78, P4347, DOI 10.1007/s11042-018-5739-5
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Xu T, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P2051, DOI 10.1109/ICInfA.2016.7832157
   Yang X, 2020, VISUAL COMPUT, V36, P1783, DOI 10.1007/s00371-019-01772-w
   Yu L., 2016, J SIGN PROCESS IMAGE, V9, P431
   Zanina MA, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P108
   Zhang J, 2017, INT J PERFORMABILITY, V13, P458
   Zhang L, 2020, CHIN AUTOM CONGR, P3193, DOI 10.1109/CAC51589.2020.9326983
   Zhang Song, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P387, DOI 10.1109/ICEMI.2017.8265827
   Zhang T, 2009, IEEE DECIS CONTR P, P2552, DOI 10.1109/CDC.2009.5400892
   Zhang XQ, 2015, INT J COMPUT VISION, V115, P279, DOI 10.1007/s11263-015-0819-8
   Zhao LL, 2017, AIP CONF PROC, V1839, DOI 10.1063/1.4982579
   Zhen XX, 2020, ALGORITHMS, V13, DOI 10.3390/a13010015
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 62
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24743
EP 24769
DI 10.1007/s11042-022-14106-1
EA DEC 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000915219100003
DA 2024-07-18
ER

PT J
AU Kumar, R
   Malik, A
AF Kumar, Rajeev
   Malik, Aruna
TI Multimedia information hiding method for AMBTC compressed images using
   LSB substitution technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; AMBTC; LSB substitution; Stego-image
ID SCHEME; STEGANOGRAPHY
AB Communication bandwidth plays a significant role in real-time communication. For this, absolute moment block truncation coding (AMBTC) has been popular. An AMBTC based high capacity multimedia data hiding method for covert communication is proposed in this paper. The proposed method applies AMBTC to the host image to get the compressed image in the form of AMBTC trios. The trios are then classified into three categories based on the difference between their quantization levels. The proposed method then adaptively conceals the secret message bits in the bitmaps of the trios based on their type. Additionally, the proposed method conceals two bits of secret data in every combination of quantization levels irrespective of their block types using the LSB substitution technique. The experimental results show that the proposed AMBTC based method is perform better to the other related data hiding based methods in terms of embedding capacity while providing comparable PSNR.
C1 [Kumar, Rajeev] Delhi Technol Univ New Delhi, Dept CSE, New Delhi, India.
   [Malik, Aruna] Natl Inst Technol Jalandhar, Dept CSE, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Malik, A (corresponding author), Natl Inst Technol Jalandhar, Dept CSE, Jalandhar, Punjab, India.
EM rajeevkumar@dtu.ac.in; arunacsrke@gmail.com
RI Kumar, Rajeev/IUP-5006-2023
OI Kumar, Rajeev/0000-0002-5000-7644
CR Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Cai-Hua Li, 2011, Information Technology Journal, V10, P1421, DOI 10.3923/itj.2011.1421.1426
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   Hong W, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020036
   Hu YC, 2000, OPT ENG, V39, P464, DOI 10.1117/1.602384
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P6159, DOI 10.1007/s11042-015-3208-y
   Kumar N, 2022, MULTIMED TOOLS APPL, V81, P35027, DOI 10.1007/s11042-021-10832-0
   Kumar R, 2022, MULTIMED TOOLS APPL, V81, P20817, DOI 10.1007/s11042-022-12634-4
   Kumar R, 2020, MULTIDIM SYST SIGN P, V31, P1145, DOI 10.1007/s11045-020-00701-8
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P32239, DOI 10.1007/s11042-019-07997-0
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li F, 2016, MULTIMED TOOLS APPL, V75, P16153, DOI 10.1007/s11042-015-2924-7
   Lin CC, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030281
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Pan JS, 2014, COMM COM INF SC, V473, P427
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Xia TT, 2021, INT J EMBED SYST, V14, P313, DOI 10.1504/IJES.2021.117943
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
NR 30
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8623
EP 8642
DI 10.1007/s11042-022-14221-z
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000889417700005
DA 2024-07-18
ER

PT J
AU Li, GD
   Yang, X
AF Li, Guandong
   Yang, Xian
TI Smartbanner: intelligent banner design framework that strikes a balance
   between creative freedom and design rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Banner design; Creative freefom; Planner; Actuator; Adjuster
AB Companies use banners extensively to promote their products, and the intelligent automatic synthesis of banners is a challenging event. Under the premise of inputting only a small amount of information such as product, text and size, it can synthesize styles with high freedom and richness, but at the same time, it must satisfy the design specifications of advertisers for advertising and scenes. We propose an intelligent banner design framework that strikes a balance between creative freedom and design rules, called smartbanner. Smartbanner consists of planner, actuator, adjuster and generator. The banner is synthesized through the combined framework, which fully liberates the designer and reduces the threshold and cost of design. It increases the click-through rate by 30%, improves the human efficiency of designers by 500% under the condition of ensuring the quality of creation, and synthesizes hundreds of millions of pictures in batches throughout the year.
EM leeguandon@gmail.com
CR Chen J, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2304, DOI 10.1145/3442381.3449909
   Devlin J., 2018, BERT PRE TRAINING DE
   Guo SN, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445117
   Hua XS, 2018, ACM/SIGIR PROCEEDINGS 2018, P1343, DOI 10.1145/3209978.3210214
   Jahanian A, 2016, SPRINGER THESES-RECO, P69, DOI 10.1007/978-3-319-31486-0_5
   Ke GL, 2017, ADV NEUR IN, V30
   Li J., 2019, ARXIV
   Liu H, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2686, DOI 10.1145/3394486.3403319
   Lok S., 2001, Proceedings of Smart Graphics, P61
   Mackinlay J., 1988, Proceedings of the ACM SIGGRAPH Symposium on User Interface Software, P179, DOI 10.1145/62402.62431
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Qiang YT, 2019, J COMPUT SCI TECH-CH, V34, P155, DOI 10.1007/s11390-019-1904-1
   Radford A., 2015, ARXIV
   Tabata S, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338574
   Tang YC, 2019, FRONT INFORM TECH EL, V20, P1595, DOI 10.1631/FITEE.1900398
   Todi K, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P543, DOI 10.1145/2901790.2901817
   Vempati S., 2020, Fashion Recommender Systems, P25
   Yang XY, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818709
   Zhang YK, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P451, DOI 10.1145/3126686.3126718
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
NR 20
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18653
EP 18667
DI 10.1007/s11042-022-14138-7
EA NOV 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886859100011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, LL
   Liang, PX
   Han, J
   Bai, LF
   Chen, DZ
AF Xu, Linli
   Liang, Peixian
   Han, Jing
   Bai, Lianfa
   Chen, Danny Z.
TI A two-stage enhancement network with optimized effective receptive field
   for speckle image reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inverse scattering imaging; Deep learning; Speckle image reconstruction;
   Dilated convolution; Effective receptive field
ID DEEP LEARNING APPROACH; SCATTERING; TIME
AB Reconstructing target objects from strong speckle images is a key step for solving complex inverse scattering imaging problems. Deep learning (DL) methods are very effective for producing high quality object reconstruction, especially for speckle image reconstruction (SIR). Understanding the relationship between DL network structures and reconstruction results helps improve the reconstruction quality. Although previous studies have explored this issue, few of them considered dilated convolution adjustment and effective receptive field optimization of DL networks in image reconstruction for improving the reconstruction quality. In this paper, we propose a two stage enhancement network for speckle image reconstruction, in addition, we present an effective receptive field optimization method for maximizing the usage of the network capability. Specifically, in the first stage, we propose a growth model exploiting the dilation rates under the assumption that the central area pixels of images have a much bigger impact on the output field than the outer area pixels, and accordingly optimize the effective receptive field of the networks. Then, based on our growth model, in the second stage, the enhancement network jointly utilizes complementary information from the objective loss and perceptual loss when reconstructing objects. Extensive experiments show that our new network outperforms five state-of-the-art methods in the MAE, MSE, PSNR, and SSIM evaluating measures.
C1 [Xu, Linli; Han, Jing; Bai, Lianfa] Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Nanjing 210094, Jiangsu, Peoples R China.
   [Liang, Peixian; Chen, Danny Z.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 Nanjing University of Science & Technology; University of Notre Dame
RP Han, J (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Nanjing 210094, Jiangsu, Peoples R China.
EM xulinli@njust.edu.cn; pliang@nd.edu; eohj@njust.edu.cn;
   blf@njust.edu.cn; dchen@nd.edu
FU National Natural Science Foundation of China [62031018, 61971227]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants (62031018, 61971227).
CR Anoop B, 2019, ADV CLASSIFICATION T, P286, DOI DOI 10.4018/978-1-5225-7796-6.CH013
   Candès EJ, 2015, IEEE T INFORM THEORY, V61, P1985, DOI 10.1109/TIT.2015.2399924
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Deng X, 2019, IEEE I CONF COMP VIS, P3076, DOI 10.1109/ICCV.2019.00317
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gupta RK, 2020, LASER PHOTONICS REV, V14, DOI 10.1002/lpor.202000120
   Hore A., 2020, IMAGE QUALITY METRIC
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Hyun D, 2019, IEEE T ULTRASON FERR, V66, P898, DOI 10.1109/TUFFC.2019.2903795
   Kakkava E, 2019, OPT FIBER TECHNOL, V52, DOI 10.1016/j.yofte.2019.101985
   Katz O, 2014, NAT PHOTONICS, V8, P784, DOI [10.1038/NPHOTON.2014.189, 10.1038/nphoton.2014.189]
   Kim M, 2015, OPT EXPRESS, V23, P12648, DOI 10.1364/OE.23.012648
   Lan T, 2021, IEEE T IND INFORM, V17, P4657, DOI 10.1109/TII.2020.3025182
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li S, 2018, OPTICA, V5, P803, DOI 10.1364/OPTICA.5.000803
   Li YZ, 2021, OPT EXPRESS, V29, P2244, DOI 10.1364/OE.411291
   Li YZ, 2018, OPTICA, V5, P1181, DOI 10.1364/OPTICA.5.001181
   Liu YG, 2018, MULTIMED TOOLS APPL, V77, P22159, DOI 10.1007/s11042-018-5704-3
   Luo WJ, 2016, ADV NEUR IN, V29
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mishra S, 2020, I S BIOMED IMAGING, P1254, DOI [10.1109/isbi45749.2020.9098403, 10.1109/ISBI45749.2020.9098403]
   Mohan E, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6239
   Mosk AP, 2012, NAT PHOTONICS, V6, P283, DOI [10.1038/nphoton.2012.88, 10.1038/NPHOTON.2012.88]
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Sanghvi Y, 2020, IEEE T COMPUT IMAG, V6, P46, DOI 10.1109/TCI.2019.2915580
   Santos Marcel Santana, 2020, ACM Transactions on Graphics, V39, DOI 10.1145/3386569.3392403
   Satat G, 2017, IEEE T COMPUT IMAG, V3, P398, DOI 10.1109/TCI.2017.2684624
   Sharma MK, 2020, IEEE T COMPUT IMAG, V6, P95, DOI 10.1109/TCI.2019.2919257
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Sinha A, 2017, OPTICA, V4, P1117, DOI 10.1364/OPTICA.4.001117
   Sun YW, 2019, OPT EXPRESS, V27, P16032, DOI 10.1364/OE.27.016032
   Tan HL, 2013, IEEE T IMAGE PROCESS, V22, P4447, DOI 10.1109/TIP.2013.2273671
   Uelwer T, 2021, INT C PATT RECOG, P731, DOI 10.1109/ICPR48806.2021.9412523
   Vellekoop IM, 2007, OPT LETT, V32, P2309, DOI 10.1364/OL.32.002309
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2486, DOI 10.1145/3219819.3219944
   Xiao H., 2017, arXiv
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao HM, 2020, IEEE ANTENN WIREL PR, V19, P1211, DOI 10.1109/LAWP.2020.2995455
   Yao HM, 2019, IEEE ANTENN WIREL PR, V18, P2254, DOI 10.1109/LAWP.2019.2925578
   Yoon S, 2020, NAT REV PHYS, V2, P141, DOI 10.1038/s42254-019-0143-2
   Yu F., 2015, ARXIV
   Yuan Z., ARXIV
   Yukuan Yang, 2020, 2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA), P1132, DOI 10.1109/ICIEA48937.2020.9248182
   Zhou ZX, 2020, IEEE T BIO-MED ENG, V67, P298, DOI 10.1109/TBME.2019.2912986
   Zhu HH, 2023, NEURAL COMPUT APPL, V35, P16051, DOI 10.1007/s00521-021-06684-2
NR 49
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19923
EP 19943
DI 10.1007/s11042-022-14208-w
EA NOV 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886859100010
DA 2024-07-18
ER

PT J
AU Ghodhbani, H
   Neji, M
   Qahtani, AM
   Almutiry, O
   Dhahri, H
   Alimi, AM
AF Ghodhbani, Hajer
   Neji, Mohamed
   Qahtani, Abdulrahman M.
   Almutiry, Omar
   Dhahri, Habib
   Alimi, Adel M.
TI Dress-up: deep neural framework for image-based human appearance
   transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Outfit generation; Garment interchange; Virtual
   try-on; Semantic segmentation
ID RECOMMENDATION SYSTEM
AB The fashion industry is at the brink of radical transformation. The emergence of Artificial Intelligence (AI) in fashion applications creates many opportunities for this industry and make fashion a better space for everyone. Interesting to this matter, we proposed a virtual try-on interface to stimulate consumers purchase intentions and facilitate their online buying decision process. Thus, we present, in this paper, our flexible person generation system for virtual try-on that aiming to treat the task of human appearance transfer across images while preserving texture details and structural coherence of the generated outfit. This challenging task has drawn increasing attention and made huge development of intelligent fashion applications. However, it requires different challenges, especially in the case of a wide divergences between the source and target images. To solve this problem, we proposed a flexible person generation framework called Dress-up to treat the 2D virtual try-on task. Dress-up is an end-to-end generation pipeline with three modules based on the task of image-to-image translation aiming to sequentially interchange garments between images, and produce dressing effects not achievable by existing works. The core idea of our solution is to explicitly encode the body pose and the target clothes by a pre-processing module based on the semantic segmentation process. Then, a conditional adversarial network is implemented to generate target segmentation feeding respectively, to the alignment and translation networks to generate the final output results. The novelty of this work lies in realizing the appearance transfer across images with high quality by reconstructing garments on a person in different orders and looks from simlpy semantic maps and 2D images without using 3D modeling. Our system can produce dressing effects and provide significant results over the state-of-the-art methods on the widely used DeepFashion dataset. Extensive evaluations show that Dress-up outperforms other recent methods in terms of output quality, and handles a wide range of editing functions for which there is no direct supervision. Different types of results were computed to verify the performance of our proposed framework and show that the robustness and effectiveness are high by utilizing our method.
C1 [Ghodhbani, Hajer; Neji, Mohamed; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, REs Grp Intelligent Machines REGIM Lab, BP 1173, Sfax 3038, Tunisia.
   [Neji, Mohamed] Natl Sch Elect & Telecommun Sfax Technopk, BP 1163, Sfax 3018, Tunisia.
   [Qahtani, Abdulrahman M.] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, POB 11099, Taif 21944, Saudi Arabia.
   [Almutiry, Omar; Dhahri, Habib] King Saud Univ, Coll Appl Comp Sci, Riyadh, Saudi Arabia.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Taif
   University; King Saud University; University of Johannesburg
RP Ghodhbani, H (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REs Grp Intelligent Machines REGIM Lab, BP 1173, Sfax 3038, Tunisia.
EM hajer.ghodhbani@regim.usf.tn; mohamed.neji@ieee.org;
   amqahtani@tu.edu.sa; oalmutiry@ksu.edu.sa; hdhahri@ksu.edu.sa;
   adel.alimi@regim.usf.tn
RI Dhahri, Habib/L-7833-2018; Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384
FU Taif University, Taif, Saudi Arabia [TURSP-2020/327]; Ministry of Higher
   Education and Scientific Research of Tunisia [LR11ES48]
FX We deeply acknowledge Taif University for Supporting this study through
   Taif University Researchers Supporting Project number (TURSP-2020/327),
   Taif University, Taif, Saudi Arabia. The research leading to these
   results has received funding from the Ministry of Higher Education and
   Scientific Research of Tunisia under the grant agreement number
   LR11ES48.
CR Arashpour M, 2021, J BUILD ENG, V33, DOI 10.1016/j.jobe.2020.101672
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Choi S, 2021, PROC CVPR IEEE, P14126, DOI 10.1109/CVPR46437.2021.01391
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Cui A., 2021, P IEEE CVF INT C COM, P14638
   DeBogota CDC, 2021, STATE FASHION 2021
   Dong H, 2019, IEEE I CONF COMP VIS, P9025, DOI 10.1109/ICCV.2019.00912
   Etoundi CML, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030493
   Fele Benjamin, 2022, P IEEE CVF WINT C AP, P3144
   Fincato M., 2022, T MULTIMED COMPUT CO, V18, P1, DOI [10.1145/3491226, DOI 10.1145/3491226]
   Ghodhbani H, 2023, MULTIMED TOOLS APPL, V82, P23151, DOI 10.1007/s11042-022-14127-w
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   Guan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185531
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Han Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7847, DOI 10.1109/CVPR42600.2020.00787
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hobley M. A., 2018, AS C COMP VIS, P135
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Ivan VA, 2021, IEEE INT CONF COMP V, P1963, DOI 10.1109/ICCVW54120.2021.00223
   Jetchev N, 2017, IEEE INT CONF COMP V, P2287, DOI 10.1109/ICCVW.2017.269
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Lassner C., 2017, PROC CVPR IEEE, V2, P3, DOI DOI 10.1109/CVPR.2017.500
   Lewis KM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459884
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Men YF, 2020, PROC CVPR IEEE, P5083, DOI 10.1109/CVPR42600.2020.00513
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T., 2018, ARXIV
   Neuberger A, 2020, PROC CVPR IEEE, P5183, DOI 10.1109/CVPR42600.2020.00523
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Patel Chaitanya, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7363, DOI 10.1109/CVPR42600.2020.00739
   PONSMOLL G, 2017, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/3072959.3073711
   Rahman M., 2021, TECHNIUM ROMANIAN J, V3, P114
   Raj A., 2018, P EUR C COMP VIS ECC, P666
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santesteban I, 2019, COMPUT GRAPH FORUM, V38, P355, DOI 10.1111/cgf.13643
   Sarkar K, 2021, ARXIV
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Theobalt Christian, 2020, COMPUTER VISION ECCV
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yuan ML, 2013, IEEE T MULTIMEDIA, V15, P1958, DOI 10.1109/TMM.2013.2280560
   Yuan Y, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311215
   Yuan Y, 2019, J INF PROCESS SYST, V15, P1277, DOI 10.3745/JIPS.04.0148
   Yuan Y, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110270
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
   Zhu Z, 2020, PROC CVPR IEEE, P5466, DOI 10.1109/CVPR42600.2020.00551
NR 65
TC 4
Z9 5
U1 11
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23151
EP 23178
DI 10.1007/s11042-022-14127-w
EA NOV 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000881891300004
PM 36404934
OA Green Published, Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Zhu, M
   Zhao, C
   Wang, NA
   Tang, J
   Yan, P
AF Zhu, Ming
   Zhao, Chen
   Wang, Nian
   Tang, Jun
   Yan, Pu
TI Multi-feature fusion for fine-grained sketch-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-feature fusion; DR-triplet loss; Sketch-based image retrieval;
   Mixed attention
AB Fine-grained sketch-based image retrieval has become an important research topic in the computer vision area. To take advantage of more fine-grained information, we proposed a multi-feature fusion network for fine-grained sketch-based image retrieval. Multi-feature consists of a coarse-grained feature and two fine-grained features which can make better use of fine-grained information. Moreover, a mixed attention module is introduced into the network to extract more discriminating features. Finally, we use the DR-triplet loss to achieve more optimal directions of pair displacements to improve the retrieval performance. Experiments on two extended FG-SBIR datasets, QMUL-Shoe and QMUL-Chair, prove the effectiveness of our method.
C1 [Zhu, Ming; Zhao, Chen; Wang, Nian; Tang, Jun] Anhui Univ, Hefei, Peoples R China.
   [Yan, Pu] Anhui Jianzhu Univ, Hefei, Peoples R China.
C3 Anhui University; Anhui Jianzhu University
RP Zhu, M (corresponding author), Anhui Univ, Hefei, Peoples R China.
EM zhuming@ahu.edu.cn; 3260776163@qq.com; wn_xlb@ahu.edu.cn;
   tangjunahu@163.com; yp8188@ahjzu.edu.cn
RI zhu, ming/ABI-2777-2020
FU Open Research Fund of National Engineering Research Center for
   Agro-Ecological Big Data Analysis and Application, Anhui University
   [AE201903]; National Natural Science Foundation of China [61772032,
   61901006]
FX This work was supported by The Open Research Fund of National
   Engineering Research Center for Agro-Ecological Big Data Analysis and
   Application, Anhui University (No. AE201903), and the National Natural
   Science Foundation of China (No. 61772032, 61901006).
CR Dutta A, 2020, INT J COMPUT VISION, V128, P2684, DOI 10.1007/s11263-020-01350-x
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   He JY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P448, DOI 10.1145/3123266.3123321
   Sarvadevabhatla RK, 2015, Arxiv, DOI arXiv:1502.00254
   Li Yi, 2014, BMVC
   Mohan Deen Dayal, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14579, DOI 10.1109/CVPR42600.2020.01460
   Ni Kong, 2020, Science and Technologies for Smart Cities. 5th EAI International Summit SmartCity360. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 323), P428, DOI 10.1007/978-3-030-51005-3_35
   Qian Y, 2015, BMVC
   Radenovic F, 2018, LECT NOTES COMPUT SC, V11209, P774, DOI 10.1007/978-3-030-01228-1_46
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sert M, 2019, MULTIMED TOOLS APPL, V78, P17095, DOI 10.1007/s11042-018-7067-1
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Shi Y., 2019, COMPUT SCI ENG, V6, P2456
   Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Xia Y, 2019, LECT NOTES COMPUT SC, V11542, P424, DOI 10.1007/978-3-030-22514-8_40
   Yang ZT, 2021, IEEE SIGNAL PROC LET, V28, P264, DOI 10.1109/LSP.2020.3043972
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yu Q, 2015, Arxiv, DOI arXiv:1501.07873
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Zhang H, 2019, IEEE T IMAGE PROCESS, V28, P4486, DOI 10.1109/TIP.2019.2910398
   Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19
   Zhang KH, 2019, AAAI CONF ARTIF INTE, P9203
   Zhang XL, 2022, PATTERN RECOGN, V125, DOI 10.1016/j.patcog.2021.108508
   Zhang XY, 2020, PATTERN RECOGN LETT, V130, P73, DOI 10.1016/j.patrec.2019.01.006
   Zhu M, 2021, APPL INTELL, V51, P7298, DOI 10.1007/s10489-021-02211-x
   Zhu M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217168
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 28
TC 0
Z9 0
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 NOV 12
PY 2022
DI 10.1007/s11042-022-14115-0
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6C3AI
UT WOS:000881891300001
DA 2024-07-18
ER

PT J
AU Othmani, A
   Han, DQ
   Gao, X
   Ye, RP
   Hadid, A
AF Othmani, Alice
   Han, Duqing
   Gao, Xin
   Ye, Runpeng
   Hadid, Abdenour
TI Kinship recognition from faces using deep learning with imbalanced data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Kinship recognition; Deep visual learning;
   Deep learning; Biometrics
ID VERIFICATION; IMAGES
AB Kinship verification from faces aims to determine whether two person share some family relationship based only on the visual facial patterns. This has attracted a significant interests among the scientific community due to its potential applications in social media mining and finding missing children. In this work, We propose a novel pattern analysis technique for kinship verification based on a new deep learning-based approach. More specifically, given a pair of face images, we first use Resnet50 to extract deep features from each image. Then, feature distances between each pair of images are computed. Importantly, to overcome the problem of unbalanced data, One Hot Encoding for labels is utilised. The distances finally are fed to a deep neural networks to determine the kinship relation. Extensive experiments are conducted on FIW dataset containing 11 classes of kinship relationships. The experiments showed very promising results and pointed out the importance of balancing the training dataset. Moreover, our approach showed interesting ability of generalization. Results show that our approach performs better than all existing approaches on grandparents-grandchildren type of kinship. To support the principle of open and reproducible research, we are soon making our code publicly available to the research community: github.com/Steven-HDQ/Kinship-Recognition.
C1 [Othmani, Alice] Univ Paris Est Creteil UPEC, LISSI, F-94400 Vitry Sur Seine, France.
   [Han, Duqing; Gao, Xin; Ye, Runpeng] Ecole Ingn Generaliste Numer EFREI Paris, F-94800 Villejuif, France.
   [Hadid, Abdenour] Sorbonne Univ Abu Dhabi, Sorbonne Ctr Artificial Intelligence, Abu Dhabi, U Arab Emirates.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC); Universite
   Paris-Pantheon-Assas
RP Othmani, A (corresponding author), Univ Paris Est Creteil UPEC, LISSI, F-94400 Vitry Sur Seine, France.
EM alice.othmani@u-pec.fr; duqing.han@efrei.net; xin.gao@efrei.net;
   runpeng.ye@efrei.net; Abdenour.Hadid@sorbonne.ae
RI Gao, Xin/D-5487-2013
CR Aliradi R, 2018, Multimed Tools Appl, V28, P1
   Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5
   Bisogni, 2022, PROCEDIA COMPUTER SC, V198, P225
   Chen XJ, 2017, MULTIMED TOOLS APPL, V76, P4105, DOI 10.1007/s11042-015-2930-9
   Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227
   Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Goyal A, 2021, IEEE T IMAGE PROCESS, V30, P191, DOI 10.1109/TIP.2020.3034027
   Goyal A, 2021, PATTERN ANAL APPL, V24, P119, DOI 10.1007/s10044-020-00906-4
   Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735
   Hazourli AR, 2021, MULTIMED TOOLS APPL, V80, P13639, DOI 10.1007/s11042-020-10332-7
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu JL, 2015, LECT NOTES COMPUT SC, V9005, P252, DOI 10.1007/978-3-319-16811-1_17
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Laiadi O, 2021, INT J MACH LEARN CYB, V12, P171, DOI 10.1007/s13042-020-01163-x
   Laiadi O, 2019, MULTIMED TOOLS APPL, V78, P16465, DOI 10.1007/s11042-018-7027-9
   Li YY, 2017, ADV SOC SCI EDUC HUM, V159, P13
   Lu JW, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Mukherjee M, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103470
   Nader N., 2021, PEERJ COMPUT SCI, Ve735, P7
   Othmani A, 2020, COMPUT VIS IMAGE UND, V196, DOI 10.1016/j.cviu.2020.102961
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qin XQ, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P580, DOI 10.1109/MVA.2015.7153258
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Robinson JP, 2020, IEEE INT CONF AUTOMA, P857, DOI [10.1109/fg47880.2020.00138, 10.1109/FG47880.2020.00138]
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   Robinson JP, 2020, VISUAL KINSHIP RECOG, V2006, P16033
   Schoneveld L, 2021, IEEE IMAGE PROC, P2339, DOI 10.1109/ICIP42928.2021.9506025
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Sellam A, 2020, MULTIMED TOOLS APPL, V79, P20861, DOI 10.1007/s11042-020-08906-6
   Shadrikov A, 2020, IEEE INT CONF AUTOMA, P872, DOI 10.1109/FG47880.2020.00137
   Somasundaram A, 2016, 1 INT C RES ENG COMP
   Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI [10.1109/INTMAG.2018.8508542, 10.1109/TNNLS.2017.2771290, 10.1109/TPAMI.2018.2861871]
   Wang SY, 2017, IEEE INT CONF AUTOMA, P216, DOI [10.1109/FG.2017.35, 10.1109/ICEMI.2017.8265769]
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Zhang K., 2015, Proc. BMVC, DOI [DOI 10.5244/C.29.148, 10.5244/C.29.148]
NR 37
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15859
EP 15874
DI 10.1007/s11042-022-14058-6
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000871318400001
DA 2024-07-18
ER

PT J
AU Tao, HJ
   Wang, J
   Xin, ZX
AF Tao, Huanjie
   Wang, Jing
   Xin, Zhouxin
TI Controllable smoke image generation network based on smoke imaging
   principle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Component separation; Smoke component; Smoke image generation; Smoke
   recognition
AB Smoke recognition is a critical task in fire prevention and environmental protection. However, existing methods still face the problems of high false alarm rates and low detection rates because of lacking diverse smoke images and enough supervision information. To solve these issues, we propose a controllable smoke image generation network (SGNet) based on smoke imaging principle. Specifically, to enhance training sample diversity, a component separation module, a smoke component fine-tuning module (SFM) and an image synthesis module are designed to integrate smoke imaging principle into deep models to generate controllable and realistic smoke images. The smoke component latent codes in SFM control the smoke component in generated smoke images. Diverse smoke images can be generated by fine-tuning smoke component in smoke images, changing smoke component to diverse assigned smoke component, adding smoke component to background images. Furthermore, to increase supervision information, a three-stage interactive training method is designed to train SGNet using synthetic dataset as well as real dataset for generating smoke images as well as corresponding smoke component and background component images. Extensive experiments show that our SGNet performs better than existing image generation methods. In addition, using the generated samples of SGNet, a new smoke recognition method with sufficient supervision information is designed and achieves the best results with 0.9876 detection rate and 0.0526 false alarm rate in smoke recognition.
C1 [Tao, Huanjie; Wang, Jing; Xin, Zhouxin] Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.
   [Tao, Huanjie] Minist Educ, Engn Res Ctr Embedded Syst Integrat, Xian 710129, Peoples R China.
   [Tao, Huanjie] Natl Engn Lab Integrated Aerosp Ground Ocean Big, Xian 710129, Peoples R China.
C3 Northwestern Polytechnical University
RP Tao, HJ (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.; Tao, HJ (corresponding author), Minist Educ, Engn Res Ctr Embedded Syst Integrat, Xian 710129, Peoples R China.; Tao, HJ (corresponding author), Natl Engn Lab Integrated Aerosp Ground Ocean Big, Xian 710129, Peoples R China.
EM huanjie_tao@126.com
RI Xin, Zhou/IXD-2060-2023; zhu, yujie/KBC-4009-2024; xin,
   zhou/HTP-7186-2023; zhao, hang/JVM-8270-2024; zheng,
   liang/JVO-2610-2024; Zhao, Chunxia/KBB-4190-2024
FU National Natural Science Foundation of China [62102320]; Fundamental
   Research Funds for the Central Universities [D5000210737]
FX This work was partly supported by the National Natural Science
   Foundation of China (No. 62102320), and the Fundamental Research Funds
   for the Central Universities (No. D5000210737.
CR Berthelot D, 2017, ARXIV
   Bounliphone W, 2015, ARXIV
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Chen X, 2021, IEEE T IMAGE PROCESS, V30, P3041, DOI 10.1109/TIP.2021.3055936
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dung NM, 2018, KSII T INTERNET INF, V12, P6018, DOI 10.3837/tiis.2018.12.022
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Filonenko A, 2018, IEEE T IND INFORM, V14, P725, DOI 10.1109/TII.2017.2757457
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Higgins I., 2016, BETA VAE LEARNING BA
   Huang HB, 2018, ADV NEUR IN, V31
   Gulrajani I, 2017, ADV NEUR IN, V30
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Khan S, 2019, IEEE INTERNET THINGS, V6, P9237, DOI 10.1109/JIOT.2019.2896120
   Kingma D. P., 2014, arXiv
   Lopez-Paz D., 2017, ARXIV
   Qi-xing Zhang, 2018, Procedia Engineering, V211, P441, DOI 10.1016/j.proeng.2017.12.034
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467
   Sheng CY, 2021, MULTIMED TOOLS APPL, V80, P17785, DOI 10.1007/s11042-021-10601-z
   Tao H, 2022, IEEE INTERNET THINGS, P1, DOI DOI 10.1080/15435075.2022.2040508.00
   Tao HJ, 2022, IEEE T IND INFORM, V18, P7653, DOI 10.1109/TII.2022.3146142
   Tao HJ, 2020, IEEE T CIRC SYST VID, V30, P3301, DOI 10.1109/TCSVT.2019.2920657
   Wen JH, 2020, VISUAL COMPUT, V36, P1385, DOI 10.1007/s00371-019-01738-y
   Xie C, 2020, IEEE ACCESS, V8, P201418, DOI 10.1109/ACCESS.2020.3036105
   Yuan FN, 2020, IEEE T IMAGE PROCESS, V29, P2301, DOI 10.1109/TIP.2019.2946126
   Yuan FN, 2019, MACH VISION APPL, V30, P345, DOI 10.1007/s00138-018-0990-3
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 30
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16057
EP 16079
DI 10.1007/s11042-022-14040-2
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000866314400003
DA 2024-07-18
ER

PT J
AU Zhang, YP
   Xiang, HY
   Zhang, SJ
   Liu, LF
AF Zhang, Yingpeng
   Xiang, Hongyue
   Zhang, Shijie
   Liu, Lingfeng
TI Construction of high-dimensional cyclic symmetric chaotic map with
   one-dimensional chaotic map and its security application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyclic symmetric chaotic map; Image encryption; DNA coding
ID IMAGE ENCRYPTION ALGORITHM; OPTIMIZATION ALGORITHM; NEURAL-NETWORK;
   SYSTEM
AB Classical one-dimensional chaotic map has many ideal characteristics which is quite suitable for many different kinds of scientific fields, especially cryptography. In this paper, we propose an idea of constructing high-dimensional (HD) cyclic symmetric chaotic maps by using one-dimensional (1D) chaotic map. Two constructed 3D cyclic symmetric chaotic maps are taken as the examples, named three-dimensional cyclic symmetric logistic map (3D-CSLM) and three-dimensional cyclic symmetric Chebyshev map (3D-CSCM), respectively. Numerical experiments show that the new maps possesses better dynamical performances, and their parameters have a wider range, compared with the original map. Furthermore, to verify its effect in image encryption, a novel image encryption algorithm based on 3D-CSLM and DNA coding is proposed. DNA method for image encryption can improve the efficiency of permutation and diffusion. Firstly, the algorithm uses 3D-CSLM to generate chaotic sequences for DNA operation rule selection and pixel permutation. Then through the DNA XOR operation to achieve diffusion, and finally form an encrypted image. Several simulation tests results indicate that the proposal has a promising security performance and strong anti-attack ability.
C1 [Zhang, Yingpeng; Xiang, Hongyue; Zhang, Shijie; Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330031, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018; ZHANG, SHIJIE/JHU-0023-2023
FU National Natural Science Foundation of China [61862042]
FX This work is supported by the National Natural Science Foundation of
   China (61862042). Yingpeng Zhang and Hongyue Xiang are co-first authors.
CR Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Chatterjee I., 2021, Int. J. Mod. Res, V1, P15
   Chen LP, 2020, FRONT INFORM TECH EL, V21, P866, DOI 10.1631/FITEE.1900709
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, P286, DOI [10.22266/ijies2020.1031.26, DOI 10.22266/IJIES2020.1031.26]
   Dehghani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186173
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   El-Latif AAA, 2012, SENS IMAGING, V13, P67, DOI 10.1007/s11220-012-0071-z
   Han CY, 2019, OPTIK, V181, P779, DOI 10.1016/j.ijleo.2018.12.178
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Jain K, 2021, KRISHNAN P MEDICAL I
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Nezhad SYD, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165661
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   SHORT KM, 1994, INT J BIFURCAT CHAOS, V4, P959, DOI 10.1142/S021812749400068X
   Vaishnav P.K., 2021, Int. J. Mod. Res, V1, P22, DOI DOI 10.31838/IJPR/2021.13.01.268
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zeidabadi FA, 2022, CMC-COMPUT MATER CON, V70, P5631, DOI 10.32604/cmc.2022.021072
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang XC, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6919675
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
NR 51
TC 4
Z9 4
U1 8
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17715
EP 17740
DI 10.1007/s11042-022-14044-y
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000866314400002
PM 36250182
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Szucs, G
   Kiss, R
AF Szucs, Gabor
   Kiss, Richard
TI 2N labeling defense method against adversarial attacks by filtering and
   extended class label set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial attack; Deep learning; Defense method; Filtering; Image
   classification
AB The fast improvement of deep learning methods resulted in breakthroughs in image classification, however, these models are sensitive to adversarial perturbations, which can cause serious problems. Adversarial attacks try to change the model output by adding noise to the input, in our research we propose a combined defense method against it. Two defense approaches have been evolved in the literature, one robustizes the attacked model for higher accuracy, and the other approach detects the adversarial examples. Only very few papers discuss both approaches, thus our aim was to combine them to obtain a more robust model and to examine the combination, in particular the filtering capability of the detector. Our contribution was that the filtering based on the decision of the detector is able to enhance the accuracy, which was theoretically proved. Besides that, we developed a novel defense method called 2N labeling, where we extended the idea of the NULL labeling method. While the NULL labeling suggests only one new class for the adversarial examples, the 2N labeling method suggests twice as much. The novelty of our idea is that a new extended class is assigned to each original class, as the adversarial version of it, thus it assists the detector and robust classifier as well. The 2N labeling method was compared to competitor methods on two test datasets. The results presented that our method surpassed the others, and it can operate with a constant classification performance regardless of the presence or amplitude of adversarial attacks.
C1 [Szucs, Gabor; Kiss, Richard] Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Magyar Tudosok Krt 2, H-1117 Budapest, Hungary.
C3 Budapest University of Technology & Economics
RP Szucs, G (corresponding author), Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Magyar Tudosok Krt 2, H-1117 Budapest, Hungary.
EM szucs@tmit.bme.hu
OI Szucs, Gabor/0000-0002-5781-1088
FU Institute of Transport Sciences (KTI) within the Innovative Mobility
   Program; Ministry of Innovation and Technology NRDI Office
FX The research was supported by the Institute of Transport Sciences (KTI)
   within the Innovative Mobility Program. The research was supported by
   the Ministry of Innovation and Technology NRDI Office within the
   framework of the Autonomous Systems National Laboratory Program.
CR Abdu-Aguye MG, 2020, INT CONF ACOUST SPEE, P3092, DOI [10.1109/ICASSP40776.2020.9053311, 10.1109/icassp40776.2020.9053311]
   Ahmadi MA, 2021, MULTIMED TOOLS APPL, V80, P10985, DOI 10.1007/s11042-020-10261-5
   Alparslan Y, 2020, ARXIV
   Brendel W, 2017, ARXIV
   Breve B, 2020, ITASEC, P71
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Caruccio L, 2020, IEEE ACCESS, V8, P205034, DOI 10.1109/ACCESS.2020.3036916
   Cerruto F, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00566-7
   Chakraborty A, 2021, CAAI T INTELL TECHNO, V6, P25, DOI 10.1049/cit2.12028
   Chen JB, 2020, P IEEE S SECUR PRIV, P1277, DOI 10.1109/SP40000.2020.00045
   Chen Y.-C., 2015, ARXIV
   Chengzhi Mao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P158, DOI 10.1007/978-3-030-58536-5_10
   Dong YP, 2019, PROC CVPR IEEE, P7706, DOI 10.1109/CVPR.2019.00790
   Fan WQ, 2019, MULTIMED TOOLS APPL, V78, P20409, DOI 10.1007/s11042-019-7353-6
   Goodfellow I. J., 2014, ARXIV
   Gotmare A., 2018, ARXIV
   Harder P, 2021, ARXIV
   Hashemi AS, 2021, MULTIMED TOOLS APPL, V80, P22077, DOI 10.1007/s11042-020-10379-6
   He ZZ, 2019, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2019.00068
   Hosseini H., 2017, ARXIV
   Iyyer M, 2018, ARXIV
   Ketkar N, 2017, Deep Learning With Python, P113, DOI DOI 10.1007/978-1-4842-2766-4_8
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kurakin Alexey, 2017, INT C LEARN REPR
   Kwon H, 2021, MULTIMED TOOLS APPL, V80, P10339, DOI 10.1007/s11042-020-09167-z
   Li F, 2022, DISCRETE DYN NAT SOC, V2022, DOI 10.1155/2022/6124895
   Li MW, 2022, NONLINEAR DYNAM, V107, P2447, DOI 10.1007/s11071-021-07139-y
   Liu ZH, 2019, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2019.00095
   Ma PC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6403, DOI 10.1109/ICASSP39728.2021.9413661
   Madry A., 2018, ARXIV
   Mekala RR, 2020, P IEEEACM 42 INT C S, P410
   Meng LB, 2019, LECT NOTES COMPUT SC, V11953, P476, DOI 10.1007/978-3-030-36708-4_39
   Miller DJ, 2020, P IEEE, V108, P402, DOI 10.1109/JPROC.2020.2970615
   Müller R, 2019, ADV NEUR IN, V32
   Naderi H, 2022, MULTIMED TOOLS APPL, V81, P21919, DOI 10.1007/s11042-022-12007-x
   Papernot N., 2016, CORR
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Pereyra G, 2017, ARXIV
   Qayyum A, 2021, IEEE REV BIOMED ENG, V14, P156, DOI 10.1109/RBME.2020.3013489
   Qiu SL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050909
   Shaham U., 2018, ARXIV
   Sharif M, 2019, ACM T PRIV SECUR, V22, DOI 10.1145/3317611
   Shuai Jia, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P69, DOI 10.1007/978-3-030-58529-7_5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Wachter S., 2018, Harv. JL & Tech., V31, P841, DOI DOI 10.2139/SSRN.3063289
   Xu W., 2017, arXiv
   Yang L, 2021, MULTIMED TOOLS APPL, V80, P855, DOI 10.1007/s11042-020-09604-z
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Yin M., 2021, P IEEECVF INT C COMP, P7858
   Zheng Y, 2021, IEEE IMAGE PROC, P844, DOI 10.1109/ICIP42928.2021.9506511
NR 54
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16717
EP 16740
DI 10.1007/s11042-022-14021-5
EA OCT 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000864966800003
OA hybrid
DA 2024-07-18
ER

PT J
AU Vankdothu, R
   Hameed, MA
   Bhukya, R
   Garg, G
AF Vankdothu, Ramdas
   Hameed, Mohd Abdul
   Bhukya, Raju
   Garg, Gaurav
TI Entropy and sigmoid based K-means clustering and AGWO for effective big
   data handling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous data; Entropy; And sigmoid-based K-means clustering; AGWO
   algorithm
ID CHALLENGES; INFORMATION; ALGORITHMS
AB In this article, we have presented the effective handling of big data using adaptive clustering and optimization techniques. Initially, heterogeneous data is collected from multiple sources and then transformed the data into desired network graphs. Then finding patterns in the graphs, the module distributes the data into the right data blocks using Entropy and sigmoid based K-means clustering. Subsequently, an adaptive grey wolf optimization (AGWO) algorithm in Hadoop distributed file system (HDFS) distributes the data blocks into the right machine. This optimized HDFS serves as a data source for services to execute queries and provide a platform to apply graph algorithms efficiently as well as reduce resource usage. Finally, we can handle a broad range of data types, query time, and resource usage. The experimental results of the proposed work provide better results in comparison with the existing methods such as GWO and PSOin terms of the algorithm run Time, loading time, resource usage, Query time, Query execution time and convergence.
C1 [Vankdothu, Ramdas; Hameed, Mohd Abdul] Osmania Univ, Dept Comp Sci & Engn, Hyderabad, Andhra Pradesh, India.
   [Bhukya, Raju] Natl Inst Technol, Dept Comp Sci & Engn, Trichy, India.
   [Garg, Gaurav] Chitkara Univ, Sch Engn & Technol Comp Sci & Engn, Baddi, India.
C3 Osmania University; National Institute of Technology (NIT System);
   National Institute of Technology Tiruchirappalli
RP Vankdothu, R (corresponding author), Osmania Univ, Dept Comp Sci & Engn, Hyderabad, Andhra Pradesh, India.
EM vramdas786sap@gmail.com
RI Garg, Gaurav/O-4916-2018
OI Garg, Gaurav/0000-0002-8257-562X; VANKDOTHU, RAMDAS/0000-0002-8478-1291
CR Abualigah L, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020101
   Acharjya DP, 2016, INT J ADV COMPUT SC, V7, P511
   Alzyadat WJ., 2019, COMPUSOFT, V8, P3112
   Anagnostopoulos I, 2016, J SUPERCOMPUT, V72, P1494, DOI 10.1007/s11227-016-1677-z
   [Anonymous], 2015, INT J COMPUT APPL
   Azzedin F, 2019, INT J ADV COMPUT SC, V10, DOI [10.14569/IJACSA.2019.0100269, DOI 10.14569/IJACSA.2019.0100269]
   Berahmand K, 2022, CLUSTER COMPUT, V25, P869, DOI 10.1007/s10586-021-03430-0
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P1869, DOI 10.1016/j.jksuci.2020.08.013
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Bharill Neha, 2016, IEEE Transactions on Big Data, V2, P339, DOI 10.1109/TBDATA.2016.2622288
   Bharill N., 2014, ADV TRENDS SOFT COMP, V312, P219, DOI [10.1007/978-3-319-03674-8_21, DOI 10.1007/978-3-319-03674-8_21]
   Casado R, 2015, CONCURR COMP-PRACT E, V27, P2078, DOI 10.1002/cpe.3398
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Chowdhury K, 2021, NEURAL COMPUT APPL, V33, P6965, DOI 10.1007/s00521-020-05471-9
   Hajeer M, 2019, IEEE T BIG DATA, V5, P134, DOI 10.1109/TBDATA.2017.2782785
   Havens TC, 2012, IEEE T FUZZY SYST, V20, P1130, DOI 10.1109/TFUZZ.2012.2201485
   Huang JW, 2011, PROC VLDB ENDOW, V4, P1123
   Jin XL, 2015, BIG DATA RES, V2, P59, DOI 10.1016/j.bdr.2015.01.006
   Khan N, 2014, SCI WORLD J, DOI 10.1155/2014/712826
   Ramírez-Gallego S, 2018, INFORM FUSION, V42, P51, DOI 10.1016/j.inffus.2017.10.001
   Rodriguez SIR, 2021, ARXIV
   Rohloff K., 2011, P 4 INT WORKSH DAT I, P35, DOI [10.1145/1996014.1996021, DOI 10.1145/1996014.1996021]
   Sassi Hidri M, 2018, FUZZY SET SYST, V348, P50, DOI 10.1016/j.fss.2017.11.003
   Shekhar H, SPECIAL C ISSUE NATL, P72
   Singh DK, 2016, 6 INT C ADV COMP INF, P119
   Yang CW, 2017, INT J DIGIT EARTH, V10, P13, DOI 10.1080/17538947.2016.1239771
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zeng G, 2015, INT J ENG RES APPL, P46
   Zhen C, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5554444
   Zhu L, 2019, IEEE T INTELL TRANSP, V20, P383, DOI 10.1109/TITS.2018.2815678
NR 32
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15287
EP 15304
DI 10.1007/s11042-022-13929-2
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864205500004
DA 2024-07-18
ER

PT J
AU Kumar, Y
   Koul, A
   Singh, C
AF Kumar, Yogesh
   Koul, Apeksha
   Singh, Chamkaur
TI A deep learning approaches in text-to-speech system: a systematic review
   and recent research perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Text-to-speech; Artificial intelligence; Speech synthesis; Deep
   learning; Pronunciation generation; Linguistic analysis
ID RECOGNITION SYSTEM; FREQUENCY; FEATURES; PROSODY; TIME
AB Text-to-speech systems (TTS) have come a long way in the last decade and are now a popular research topic for creating various human-computer interaction systems. Although, a range of speech synthesis models for various languages with several motive applications is available based on domain requirements. However, recent developments in speech synthesis have primarily attributed to deep learning-based techniques that have improved a variety of application scenarios, including intelligent speech interaction, chatbots, and conversational artificial intelligence (AI). Text-to-speech systems are discussed in this survey article as an active topic of study that has achieved significant progress in the recent decade, particularly for Indian and non-Indian languages. Furthermore, the study also covers the lifecycle of text-to-speech systems as well as developed platforms in it. We performed an efficient search for published survey articles up to May 2021 in the web of science, PubMed, Scopus, EBSCO(Elton B. Stephens CO (company)) and Google Scholar for Text-to-speech Systems (TTS) in various languages based on different approaches. This survey article offers a study of the contributions made by various researchers in Indian and non-Indian language text-to-speech systems and the techniques used to implement it with associated challenges in designing TTS systems. The work also compared different language text-to-speech systems based on the quality metrics such as recognition rate, accuracy, TTS score, precision, recall, and F1-score. Further, the study summarizes existing ideas and their shortcomings, emphasizing the scope of future research in Indian and non-Indian languages TTS, which may assist beginners in designing robust TTS systems.
C1 [Kumar, Yogesh] Pandit Deendayal Energy Univ, Sch Technol, Dept Comp Sci & Engn, Gandhinagar, Gujarat, India.
   [Koul, Apeksha] Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Singh, Chamkaur] Chandigarh Grp Coll, Dept Comp Applicat, Mohali, Punjab, India.
C3 Pandit Deendayal Energy University; Punjabi University
RP Kumar, Y (corresponding author), Pandit Deendayal Energy Univ, Sch Technol, Dept Comp Sci & Engn, Gandhinagar, Gujarat, India.
EM yogesh.arora10744@gmail.com; apekshakoulo9@gmail.com;
   dhillon.chamkaur@gmail.com
RI Singh, Chamkaur/GXA-2484-2022; kumar, yogesh/AAD-8469-2021
OI Singh, Chamkaur/0000-0002-9480-8910; kumar, yogesh/0000-0002-2879-0441
CR Adam E.E. B., 2020, Journal of Soft Computing Paradigm, V2, P209
   Adeeba Farah, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P79, DOI 10.1109/ICSDA.2016.7918988
   Ahmad A, 2022, EXPRESSIVE SPEECH SY
   Alam F, 2007, TEXT SPEECH BANGLA L
   Alsharhan E, 2019, INFORM PROCESS MANAG, V56, P343, DOI 10.1016/j.ipm.2017.07.002
   Amrouche A, 2022, 2022 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ICEEE 2022), P378, DOI 10.1109/ICEEE55327.2022.9772602
   Anto A, 2016, IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGICAL TRENDS IN COMPUTING, COMMUNICATIONS AND ELECTRICAL ENGINEERING (ICETT)
   Arik SO, 2017, PR MACH LEARN RES, V70
   Aryal S, 2016, COMPUT SPEECH LANG, V36, P260, DOI 10.1016/j.csl.2015.02.003
   Bahrampour A, 2009, LECT NOTES COMPUT SC, V5856, P321, DOI 10.1007/978-3-642-10268-4_38
   Barkana BD, 2020, APPL ACOUST, V162, DOI 10.1016/j.apacoust.2019.107203
   Bhuyan MP, 2020, 2020 5 INT C COMMUNI, P1179
   Bhuyan MP, 2019, INT J ENG ADV TECHNO, V8, P2921
   Birkholz P, 2017, COMPUT SPEECH LANG, V41, P116, DOI 10.1016/j.csl.2016.06.004
   Cataldo E, 2006, MECH RES COMMUN, V33, P250, DOI 10.1016/j.mechrescom.2005.05.007
   Chan KY, 2019, J PHONETICS, V77, DOI 10.1016/j.wocn.2019.100919
   Chauhan, 2011, IJCST, V2
   Chen LW, 2022, INT CONF ACOUST SPEE, P7907, DOI 10.1109/ICASSP43922.2022.9747747
   Chen MN, 2019, INTERSPEECH, P2105, DOI 10.21437/Interspeech.2019-1632
   Dagba TK, 2014, PROCEDIA COMPUT SCI, V35, P447, DOI 10.1016/j.procs.2014.08.125
   Dessai Nilesh Fal, 2016, 2016 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT), P344, DOI 10.1109/ICCICCT.2016.7987971
   Dhananjaya MS, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P168, DOI 10.1109/ICEECCOT.2016.7955208
   Dong Yuan, 2010, Acta Automatica Sinica, V36, P1569, DOI 10.3724/SP.J.1004.2010.01569
   Dootio MA, 2019, J KING SAUD U COMPUT
   Du C, 2022, ARXIV
   Fahmy FK, 2022, INT J SPEECH TECHNOL, V25, P79, DOI 10.1007/s10772-022-09961-0
   Görmez Z, 2008, REC ADV COMPUT ENG, P977
   Gupta A, 2022, ARXIV
   Gutkin A, 2016, TTS LOW RESOURCE LAN
   Hakan T, 2017, ANADOLU UNIV SANAT T, V18, P584, DOI DOI 10.18038/AUBTDA.283172
   Haq M.R., 2019, 2019 International Joint Conference on Neural Network (IJCNN'19), P1
   Haq R, 2023, COMPUT J, V66, P1856, DOI 10.1093/comjnl/bxac047
   Hasnat Md Abul, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P671, DOI 10.1109/ICDAR.2009.62
   Hebbi Chandravva, 2022, Evolution in Computational Intelligence: Proceedings of the 9th International Conference on Frontiers in Intelligent Computing: Theory and Applications (FICTA 2021). Smart Innovation, Systems and Technologies (267), P21, DOI 10.1007/978-981-16-6616-2_3
   Himmy D, 2017, INT J ADV RES COMPUT, V6
   Hossain PS, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115463
   Htun H., 2015, INT J SCI TECHNOLOGY, V4, P104
   Ifeanyi N., 2014, INT J RES INFORM TEC, V2, P154
   Ilyes R, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P452, DOI 10.1109/ATSIP.2014.6834654
   Inoue K, 2021, SPEECH COMMUN, V126, P35, DOI 10.1016/j.specom.2020.11.004
   Isewon I., 2012, INT J APPL INFORM SY, V7, P26
   Jariwala N, 2018, SPEECH LANGUAGE PROC, P67
   Jia Y, 2018, ADV NEUR IN, V31
   Karpov Alexey, 2013, Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8009, P520, DOI 10.1007/978-3-642-39188-0_56
   Kaur N, 2022, MULTIMED TOOLS APPL, P1
   Kayt Sangramsing N., 2015, INT J COMPUTER APPL, P35
   Koshi B, 2016, IFAC PAPERSONLINE, V49, P259, DOI 10.1016/j.ifacol.2016.11.063
   Krnoul Z, 2008, LECT NOTES COMPUT SC, V4892, P180
   Kumar Y, 2022, SOFT COMPUT, V26, P8253, DOI 10.1007/s00500-022-07261-y
   Kumar Y, 2021, ARTIF INTELL REV, V54, P5897, DOI 10.1007/s10462-021-09964-4
   Kumar Y, 2021, SOFT COMPUT, V25, P1617, DOI 10.1007/s00500-020-05248-1
   Kumar Y, 2017, INT J SPEECH TECHNOL, V20, P297, DOI 10.1007/s10772-017-9408-2
   Kumari L, 2022, ARCH COMPUT METHOD E, V29, P1085, DOI 10.1007/s11831-021-09605-7
   Li JB, 2022, INT CONF ACOUST SPEE, P7917, DOI 10.1109/ICASSP43922.2022.9747837
   Li RN, 2017, INT CONF ACOUST SPEE, P5510, DOI 10.1109/ICASSP.2017.7953210
   Li X, 2022, INT C ELECT INFORM E, V12256, P667
   Li XX, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105908
   Mache S, 2016, J COMPUT ENG, V18, P35
   Mache Suhas., 2015, International Journal of Advanced Research in Computer and Communication Engineering, V4, P54, DOI DOI 10.17148/IJARCCE.2015.4812
   Malloy ML, 2014, IEEE T INFORM THEORY, V60, P4001, DOI 10.1109/TIT.2014.2321552
   Manoharan JS, 2022, LECT NOTE NETW SYST, V351, P305, DOI 10.1007/978-981-16-7657-4_26
   Matousek J, 2006, LECT NOTES ARTIF INT, V4188, P439
   Mitsui K, 2022, ARXIV
   Narendra NP, 2011, INT J SPEECH TECHNOL, V14, P167, DOI 10.1007/s10772-011-9094-4
   Ni J, 2022, ARXIV
   Ning YS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194050
   Nongmeikapam K, 2012, ARXIV
   Panda SP, 2020, MULTIMEDIA SYST, V26, P453, DOI 10.1007/s00530-020-00659-4
   Panda SP, 2016, ADV INTELL SYST, V410, P483, DOI 10.1007/978-81-322-2734-2_48
   Panda SP., 2018, INT J ELECT COMPUT E, V8, P2088
   Pellicani AD, 2018, J VOICE, V32, P177, DOI 10.1016/j.jvoice.2017.04.011
   Prafianto H, 2019, SPEECH COMMUN, V111, P14, DOI 10.1016/j.specom.2019.06.001
   Pribilová A, 2006, SPEECH COMMUN, V48, P1691, DOI 10.1016/j.specom.2006.08.001
   Rahman M., 2019, INT J INNOV TECHNOL, V9, P900, DOI [10.35940/ijitee.A4435.119119, DOI 10.35940/IJITEE.A4435.119119]
   Raj AA, 2007, SSW, P188
   Rajendran Vibavi, 2015, INDIAN J SCI TECHNOL, V8, P112, DOI DOI 10.17485/IJST/2015/V8I29/72294
   Ramlia I, 2015, PROCEDIA COMPUT SCI, V76, P417, DOI 10.1016/j.procs.2015.12.280
   Ramsay A, 2008, COMPUT SPEECH LANG, V22, P84, DOI 10.1016/j.csl.2007.06.004
   Rebai I, 2015, COMPUT SPEECH LANG, V34, P43, DOI 10.1016/j.csl.2015.04.002
   Reddy MV, 2015, 2015 INT C SOFT COMP, P1
   Rojc M, 2007, SPEECH COMMUN, V49, P230, DOI 10.1016/j.specom.2007.01.007
   Romportl J, 2007, PROSODY MODELLING CZ
   Sak H., 2006, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V14, P209
   Sarungbam JK, 2014, 2014 5TH INTERNATIONAL CONFERENCE CONFLUENCE THE NEXT GENERATION INFORMATION TECHNOLOGY SUMMIT (CONFLUENCE), P669, DOI 10.1109/CONFLUENCE.2014.6949300
   Sharma B., 2015, TENCON 2015 2015 IEE, P1
   Sharma P, 2018, COMPUT SPEECH LANG, V52, P191, DOI 10.1016/j.csl.2018.05.003
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Shetake PS., 2014, INT J IND ELECT ELEC, V2, P29
   Shivakumar K., 2016, 2016 INT C INVENTIVE, V3, P1
   Singh P., 2006, P INT C MULT INF SCI
   Smit P, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101158
   Soman A., 2011, INT J COMPUT APPL, V29, P0975
   Sultana T, 2016, INT J ADV COMPUT SC, V7, P24
   Sun JM, 2013, IET COMMUN, V7, P1412, DOI 10.1049/iet-com.2013.0030
   Sunil M. E., 2022, Sentimental Analysis and Deep Learning: Proceedings of ICSADL 2021. Advances in Intelligent Systems and Computing (1408), P677, DOI 10.1007/978-981-16-5157-1_53
   Suzuki M, 2017, IEICE T INF SYST, VE100D, P655, DOI 10.1587/transinf.2016AWI0004
   Tachibana H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4784, DOI 10.1109/ICASSP.2018.8461829
   Takamichi S, 2022, ARXIV
   Tan X, 2022, ARXIV
   Thu CST., 2014, INT J ENG RES TECHNO, V3, P911
   Ngo T, 2020, SPEECH COMMUN, V117, P13, DOI 10.1016/j.specom.2020.01.004
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852
   Toth B., 2008, J INFOCOMMUN, V7, P30
   Tran DC, 2020, DATA BRIEF, V31, DOI 10.1016/j.dib.2020.105775
   Uliniansyah MT, 2016, PROCEDIA COMPUT SCI, V81, P188, DOI 10.1016/j.procs.2016.04.048
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151
   Varghese JM, 2015, INT J RES, V2, P1017
   Veisi H, 2022, LANG RESOUR EVAL, V56, P917, DOI 10.1007/s10579-022-09594-4
   Venkateswarlu S, 2016, Indian Journal of Science and Technology, V9, DOI [10.17485/ijst/2016/v9i38/102967, DOI 10.17485/IJST/2016/V9I38/102967]
   Vijayarani S., 2015, INT J CYBERN INFORM, V4, P25
   Wang WF, 2016, INTERSPEECH, P2243, DOI 10.21437/Interspeech.2016-134
   Weiss RJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5679, DOI 10.1109/ICASSP39728.2021.9413851
   Ye Z, 2022, ARXIV
   Yilmaz E, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P792
   Zelasko P, 2016, LANG RESOUR EVAL, V50, P585, DOI 10.1007/s10579-015-9302-y
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
   Zhang CX, 2019, ASIAPAC SIGN INFO PR, P165, DOI 10.1109/APSIPAASC47483.2019.9023283
   Zhou, 2022, ARXIV
NR 120
TC 12
Z9 12
U1 4
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15171
EP 15197
DI 10.1007/s11042-022-13943-4
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863188000002
DA 2024-07-18
ER

PT J
AU Ouyang, JL
   Huang, JT
   Wen, XZ
   Shao, ZH
AF Ouyang, Junlin
   Huang, Jingtao
   Wen, Xingzi
   Shao, Zhuhong
TI A semi-fragile watermarking tamper localization method based on QDFT and
   multi-view fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-fragile watermarking; Quaternion discrete Fourier transform; Tamper
   localization; Iimage forensics
ID IMAGE AUTHENTICATION; ALGORITHM; SCHEME; DIFFERENCE; RANKING; WAVELET
AB Accurate tamper localization is one of the most challenging problems in semi-fragile watermarking authentication schemes. The existing semi-fragile watermarking methods have some problems, such as blurred localization shape and high false alarm rate, which stem from the rough analysis of tampering information. To address these problems, this paper proposes a semi-fragile watermarking tamper localization method based on quaternion discrete Fourier transform (QDFT) and multi-view fusion, which embeds two watermarks in the QDFT domain for robust resistance to the geometric attack and integrity protection of host image, respectively. On the receiver side, considering that the difference map in binary mode is difficult to identify tampering, the global information and local smoothing cues are used in the method, to obtain the multi-scale candidate maps with real values instead of binary. Then, local adaptive fusion is accomplished by minimizing the energy function, to obtain a more consistent single tampering map. The design of the energy function integrates the image content and multi-scale feature views. Finally, a tamper seed-based propagation strategy is designed to generate a binary map of the tampered regions. Experimental results show that the proposed method provides better resistant to signal processing attacks, and the F-measure value of tamper localization is improved by 11.17% on average compared to the state-of-the-art methods.
C1 [Ouyang, Junlin; Huang, Jingtao] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Ouyang, Junlin; Huang, Jingtao; Wen, Xingzi] Hunan Key Lab Serv Comp & Novel Software Technol, Xiangtan 411201, Peoples R China.
   [Ouyang, Junlin] Hunan Software Vocat & Tech Univ, Xiangtan 411100, Peoples R China.
   [Shao, Zhuhong] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
C3 Hunan University of Science & Technology; Capital Normal University
RP Ouyang, JL (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.; Ouyang, JL (corresponding author), Hunan Key Lab Serv Comp & Novel Software Technol, Xiangtan 411201, Peoples R China.; Ouyang, JL (corresponding author), Hunan Software Vocat & Tech Univ, Xiangtan 411100, Peoples R China.
EM yangjunlin0732@163.com
RI huang, jing/JDC-2548-2023; Shao, Zhuhong/AAD-4129-2022
OI Ouyang, Junlin/0000-0001-7155-2732
FU natural science foundation of Hunan province [2021JJ30277, 2019JJ50168];
   project of Hunan province education department [19 K035, 19B202];
   projects of national social science foundation of China [21BXW077];
   Ministry of Education humanities social sciences the youth fund project
   [20YJCZH179]
FX The authors would like to thank the anonymous reviewers for their valued
   comments and suggestions. This work was supported by the natural science
   foundation of Hunan province under Grants 2021JJ30277, 2019JJ50168, by
   the project of Hunan province education department under Grants 19 K035,
   19B202, by theMinistry of Education humanities social sciences the youth
   fund project under Grants 20YJCZH179, and by the projects of national
   social science foundation of China under Grant 21BXW077. The code
   related to this paper is available at
   https://github.com/jingtaohuang/A-Novel-Semi-Fragile-Watermarking.git.
CR Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Al-Mualla ME, 2007, IEEE I C ELECT CIRC, P1256, DOI 10.1109/ICECS.2007.4511225
   Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   [Anonymous], 1997, USC SIPI
   [Anonymous], 2017, CASIA
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Biswas S, 2005, IEEE T INSTRUM MEAS, V54, P1853, DOI 10.1109/TIM.2005.855084
   Chakravarthy S, 2019, MULTIMED TOOLS APPL, V78, P18693, DOI 10.1007/s11042-019-7265-5
   Chen BJ, 2019, MATH BIOSCI ENG, V16, P6907, DOI 10.3934/mbe.2019346
   Chen F, 2017, MULTIMED TOOLS APPL, V76, P9681, DOI 10.1007/s11042-016-3574-0
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Ding WJ, 2019, MULTIMED TOOLS APPL, V78, P5305, DOI 10.1007/s11042-018-5732-z
   Duan SH, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8840779
   Feng B, 2020, MOBILE NETW APPL, V25, P82, DOI 10.1007/s11036-018-1186-9
   Fletcher P, 2017, SIGNAL PROCESS, V136, P2, DOI 10.1016/j.sigpro.2016.12.025
   Fu JJ, 2020, SOFT COMPUT, V24, P5755, DOI 10.1007/s00500-019-04318-3
   Haghighi BB, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107029
   Haghighi BB, 2020, COGN COMPUT, V12, P863, DOI 10.1007/s12559-019-09700-9
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Jun Xiao, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P579, DOI 10.1109/CSSE.2008.331
   Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P15487, DOI 10.1007/s11042-020-10322-9
   Li CL, 2015, MULTIMED TOOLS APPL, V74, P10581, DOI 10.1007/s11042-014-2188-7
   Li H., 2015, COMPUTATIONAL VISUAL, V1, P183
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li JZ, 2018, SOFT COMPUT, V22, P47, DOI 10.1007/s00500-016-2320-x
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Liu XL, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108275
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Miller ML, 2004, IEEE T IMAGE PROCESS, V13, P792, DOI 10.1109/TIP.2003.821551
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Rhayma H, 2019, MULTIMED TOOLS APPL, V78, P14067, DOI 10.1007/s11042-019-7244-x
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Schmalz MS, 2005, MATH DATAIMAGE CODIN
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Shojanazeri H, 2017, MULTIMED TOOLS APPL, V76, P577, DOI 10.1007/s11042-015-3018-2
   Sivasubramanian N, 2020, COMPUTING, V102, P1365, DOI 10.1007/s00607-020-00797-7
   Soualmi A, 2021, MULTIMED TOOLS APPL, V80, P2279, DOI 10.1007/s11042-020-09614-x
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Thabit R, 2021, MULTIMED TOOLS APPL, V80, P13439, DOI 10.1007/s11042-020-10421-7
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Tsai CC, 2017, INT CONF ACOUST SPEE, P1897, DOI 10.1109/ICASSP.2017.7952486
   Yan CP, 2017, IEEE T INF FOREN SEC, V12, P2144, DOI 10.1109/TIFS.2017.2699942
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yu XY, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040056
   Yuan YC, 2018, IEEE T IMAGE PROCESS, V27, P1311, DOI 10.1109/TIP.2017.2762422
   Zhang L, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3074029
   Zhao HM, 2016, COGN COMPUT, V8, P246, DOI 10.1007/s12559-015-9357-5
   Zhou K, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091506
   Zhuang PY, 2021, IEEE T INF FOREN SEC, V16, P2986, DOI 10.1109/TIFS.2021.3070444
NR 62
TC 5
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15113
EP 15141
DI 10.1007/s11042-022-13938-1
EA SEP 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000859866600007
DA 2024-07-18
ER

PT J
AU Kundu, R
   Chattopadhyay, S
AF Kundu, Rohit
   Chattopadhyay, Soham
TI Deep features selection through genetic algorithm for cervical
   pre-cancerous cell classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical cancer detection; Deep learning; Genetic algorithm; Transfer
   learning; Support vector machines; Evolutionary metaheuristic
AB Cervical cancer affects more than 500,000 women in the world annually accounting for about 6-9% of all cancer cases, but, its tedious detection procedure makes population-wide screening impossible. Classification of cervical pre-cancerous cells using computer-aided diagnosis tools is a challenging task and is posed an open problem for several decades. The most concerning issue is that only a small amount of data is available publicly. In this study, Deep Learning along with an evolutionary metaheuristic algorithm called the Genetic Algorithm is incorporated for cervical cell classification. Pre-trained Convolutional Neural Networks, namely GoogLeNet and ResNet-18 have been utilized to account for the fewer data available, for extracting deep features from the images. The extracted features are optimized by employing a Genetic Algorithm for feature selection which is coupled with the Support Vector Machines classifier for the final classification. The proposed method has been validated on two publicly available datasets which obtained promising results on 5-fold cross-validation justifying the framework to be reliable. The relevant source codes for the proposed framework has been provided in https://github.com/Rohit-Kundu/ Cervical-Cancer-CNN-GAGitHub.
C1 [Kundu, Rohit; Chattopadhyay, Soham] Jadavpur Univ, Dept Elect Engn, 188 Raja SC Mullick Rd, Kolkata 700032, India.
C3 Jadavpur University
RP Kundu, R (corresponding author), Jadavpur Univ, Dept Elect Engn, 188 Raja SC Mullick Rd, Kolkata 700032, India.
EM rohitkunduju@gmail.com; chattopadhyaysoham99@gmail.com
OI CHATTOPADHYAY, SOHAM/0000-0001-6890-2965
CR Alnabelsi, 2013, J THEOR APPL INFORM, V57, P1
   Alyafeai Z, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112951
   Basak Hritam, 2020, 2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS), P219, DOI 10.1109/ICIIS51140.2020.9342688
   Basak H., 2020, INT S SIGNAL PROCESS, P352
   Chattopadhyay S., 2020, ARXIV
   Chattopadhyay S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020315
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dewi EM, 2019, INT J ONLINE BIOMED, V15, P91, DOI 10.3991/ijoe.v15i02.9796
   Dey A, 2020, IEEE ACCESS, V8, P200953, DOI 10.1109/ACCESS.2020.3035531
   Erlich I., 2010, IEEE Power Energy Soc. Gen. Meet, P1, DOI [10.1109/CEC.2010.5586027, DOI 10.1109/PES.2010.5589911]
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Gandomi AH, 2011, COMPUT STRUCT, V89, P2325, DOI 10.1016/j.compstruc.2011.08.002
   Gill G.W., 2013, Papanicolaou stain. Cytopreparation, P143, DOI DOI 10.1007/978-1-4614-4933-1_10
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Hussain E, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105589
   Iliyasu AM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122935
   Ivakhnenko AG, 1967, Cybernetics and forecasting techniques
   Kenndy J., 1995, P ICNN 95 INT C NEUR, P1942
   Li C, 2019, THIRD INTERNATIONAL SYMPOSIUM ON IMAGE COMPUTING AND DIGITAL MEDICINE (ISICDM 2019), P102, DOI 10.1145/3364836.3364857
   MEYER F, 1986, COMPUT VISION GRAPH, V35, P356, DOI 10.1016/0734-189X(86)90005-8
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   NGUYEN NG, 1983, PATTERN RECOGN, V16, P401, DOI 10.1016/0031-3203(83)90062-6
   Papanicolaou GN, 1997, ARCH PATHOL LAB MED, V121, P211
   Plissiti ME, 2018, IEEE IMAGE PROC, P3144, DOI 10.1109/ICIP.2018.8451588
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha R, 2016, 2016 INT C DIG IM CO, DOI [10.1109/dicta.2016.7797086, DOI 10.1109/DICTA.2016.7797086]
   Sevi O., 2020, HLTH SCI
   Shi, 2019, 2 MICCAI WORKSHOP CO
   Shortliffe E. H., 1975, Mathematical Biosciences, V23, P351, DOI 10.1016/0025-5564(75)90047-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tseng CJ, 2014, NEURAL COMPUT APPL, V24, P1311, DOI 10.1007/s00521-013-1359-1
   Van Belle V, 2011, ARTIF INTELL MED, V53, P107, DOI 10.1016/j.artmed.2011.06.006
   William W, 2018, COMPUT METH PROG BIO, V164, P15, DOI 10.1016/j.cmpb.2018.05.034
   Win KP, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051800
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Zare MR, 2018, INT CONF INFORM RETR, P73, DOI 10.1109/INFRKM.2018.8464688
   Zhang L, 2017, COMPUT MED IMAG GRAP, V56, P38, DOI 10.1016/j.compmedimag.2017.01.002
NR 42
TC 12
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13431
EP 13452
DI 10.1007/s11042-022-13736-9
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000857685800006
DA 2024-07-18
ER

PT J
AU Sirenden, BH
   Mursanto, P
   Wijonarko, S
AF Sirenden, Bernadus H.
   Mursanto, Petrus
   Wijonarko, Sensus
TI Galois field transformation effect on space-time-volume velocimetry
   method for water surface velocity video analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Galois Field; Space-Time-Volume Velocimetry; Water Surface Velocity;
   Video Processing; Open Channel Flow Measurement; Region of Interest
ID FLOW
AB This paper presents a novel method of image processing that combines Galois Field (GF) image representation and Space Time Volume Velocimetry (STVV) algorithms namely GF-STVV. STVV is an emerging method to analyze river water flows from video sequences. This study aimed to improve the performance of STVV when applied to close-range measurements (1 to 1.5 m) by reducing the variability (repeatibility and reproducibility) of computational results. Variability is related to the precision of the water flow measurement results. Small variability values indicate high measurement precision. Experiments were carried out using two main methods. The first method was by rotating videos data virtually, and the second one was by rotating the camera directly during video captures. The Experiment result shows that GF reduced the variability of computation results if applied to a particular Region Of Interest (ROI) in video frames of water flow. The particular ROI was obtained by dividing the video frame into several small regions. The GF-STVV generate 0.0 % for both repeatibility and reproducibility, while STVV generate 2.3 % for repeatibility and 3.3 % for reproducibility.
C1 [Sirenden, Bernadus H.; Mursanto, Petrus] Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
   [Sirenden, Bernadus H.] Natl Res & Innovat Agcy Indonesia, Res Ctr Elect, Tangerang Selatan, Indonesia.
   [Wijonarko, Sensus] Natl Res & Innovat Agcy Indonesia, Res Ctr Photon, Tangerang Selatan, Indonesia.
C3 University of Indonesia
RP Mursanto, P (corresponding author), Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
EM santo@cs.ui.acid
OI MURSANTO, Petrus/0000-0002-4831-4629; Wijonarko,
   Sensus/0000-0003-1869-8737
FU University Grant for Internationally Indexed Publication of Students'
   Final Project (Hibah PUTI Doctor) [NKB-563/UN2.RST/HKP.05.00/2020]
FX This work was supported by funding from University Grant for
   Internationally Indexed Publication of Students' Final Project (Hibah
   PUTI Doctor) Contract No: NKB-563/UN2.RST/HKP.05.00/2020, administered
   by the Directorate of Research and Community Engagement (DRPM),
   Universitas Indonesia.
CR Bahjat H., 2014, INT J COMPUTER APPL, V89, P7
   Frost, 2020, MEASURES VARIABILITY
   Fujita I., 2012, 15 INT S FLOW VIS JU
   Fujita I, 2017, WATER-SUI, V9, DOI 10.3390/w9040269
   Fujita I, 2007, INT J RIVER BASIN MA, V5, P105, DOI 10.1080/15715124.2007.9635310
   Garria J, 2002, 2002 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P63, DOI 10.1109/SIPS.2002.1049686
   Jansson Y, 2018, J MATH IMAGING VIS, V60, P1369, DOI 10.1007/s10851-018-0826-9
   Khalid M, 2019, FLOW MEAS INSTRUM, V65, P110, DOI 10.1016/j.flowmeasinst.2018.11.009
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P59, DOI 10.1111/cgf.13619
   Kingma D. P., 2014, arXiv
   Lin S., 2016, UNIVERS J ELECT ELEC, V4, P104, DOI [10.13189/ujeee.2016.040402, DOI 10.13189/UJEEE.2016.040402]
   Liu, 2016, 2 ANN INT C ELECT EL, DOI [10.2991/eeeis-16.2017.81, DOI 10.2991/EEEIS-16.2017.81]
   LIU T, 2021, Journal of Open Research Software, V9, P3
   Liu TS, 2008, J FLUID MECH, V614, P253, DOI 10.1017/S0022112008003273
   Perks MT, 2020, GEOSCI MODEL DEV, V13, P6111, DOI 10.5194/gmd-13-6111-2020
   Rajagopalan S., 2014, RES J INFORM TECHNOL, V6, P308
   REED IS, 1977, IEEE T COMPUT, V26, P874, DOI 10.1109/TC.1977.1674935
   Schumm WR, 2017, MARRIAGE FAM REV, V53, P1, DOI 10.1080/01494929.2016.1199196
   Sharma N., 2014, GEOSCI INSTRUM METH, V3, P233
   Shivashankar S., 2018, International Journal of Image, Graphics and Signal Processing, V10, P56, DOI 10.5815/ijigsp.2018.09.07
   Shivashankar S., 2018, INT J APPL ENG RES, V13, P13460
   Sirenden BH, 2020, 2020 INTERNATIONAL CONFERENCE ON RADAR, ANTENNA, MICROWAVE, ELECTRONICS, AND TELECOMMUNICATIONS (ICRAMET), P51, DOI [10.1109/icramet51080.2020.9298601, 10.1109/ICRAMET51080.2020.9298601]
   Sirenden BH, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P47, DOI [10.1109/ic3ina48034.2019.8949591, 10.1109/IC3INA48034.2019.8949591]
   Slezák P, 2011, PHYSIOL RES, V60, P203
   Strelnikova D, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030384
   Tauro F, 2016, GEOSCI INSTRUM METH, V5, P241, DOI 10.5194/gi-5-241-2016
   Thapa S, 2020, PROC CVPR IEEE, P21, DOI 10.1109/CVPR42600.2020.00010
   Tsubaki R, 2017, WATER RESOUR RES, V53, P10908, DOI 10.1002/2017WR021913
   Tsuji I, 2018, E3S WEB CONF, V40, DOI 10.1051/e3sconf/20184006011
   Watanabe K, 2021, WATER-SUI, V13, DOI 10.3390/w13152079
   Wu H, 2019, WATER-SUI, V11, DOI 10.3390/w11112320
   Yu CX, 2019, IEEE T COMPUT AID D, V38, P354, DOI 10.1109/TCAD.2018.2808457
NR 32
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12167
EP 12189
DI 10.1007/s11042-022-13627-z
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000855612200015
DA 2024-07-18
ER

PT J
AU Sharma, M
   Ranjan, RK
   Bharti, V
AF Sharma, Madhu
   Ranjan, Ranjeet Kumar
   Bharti, Vishal
TI An image encryption algorithm based on a novel hyperchaotic Henon sine
   map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Security analysis; 2D-Henon sine map
ID SCHEME; CRYPTANALYSIS; COMPRESSION; COMBINATION; DIFFUSION; INTERNET;
   ENTROPY
AB Chaotic maps are widely being researched for application in cryptography. In this paper, a new chaotic 2-Dimensional Henon Sine Map (2D-HSM) is derived from the well-known Henon and sine maps. The resulting chaotic map's performance is demonstrated with the help of trajectory plots, bifurcation diagrams, Lyapunov exponents and Kolmogorov entropy. A novel Image Encryption Algorithm (IEA) is, then, proposed utilising the 2D-HSM to ensure the two essential characteristics of a good cryptographic system - diffusion and confusion. The IEA performs operations in two rounds for achieving a highly secure cipher-image. The simulation results and performance analysis are compared with some recently proposed cryptosystems which are also based on two dimensional chaotic maps. Simulations are carried out with the help of parameters like sensitivity to initial conditions and resistance to brute force attacks. The simulation results establish the security of the proposed 2D-HSM based IEA.
C1 [Sharma, Madhu; Ranjan, Ranjeet Kumar] DIT Univ, Dehra Dun 248009, Uttarakhand, India.
   [Bharti, Vishal] Chandigarh Univ, Mohali 140413, India.
C3 DIT University; Chandigarh University
RP Sharma, M (corresponding author), DIT Univ, Dehra Dun 248009, Uttarakhand, India.
EM madhuashishsharma@gmail.com; ranjeetghitm@gmail.com;
   mevishalbharti@yahoo.com
RI Ranjan, Ranjeet Kumar/AAQ-4566-2021; Bharti, Vishal/AGG-2108-2022;
   Sharma, Madhu/ABC-0334-2022
OI Ranjan, Ranjeet Kumar/0000-0002-8796-4579; Bharti,
   Vishal/0000-0002-7806-9169; Sharma, Madhu/0000-0002-3303-5651
CR Alawida M, 2020, INFORM SCIENCES, V512, P1155, DOI 10.1016/j.ins.2019.10.055
   [Anonymous], LENA512 BMP
   [Anonymous], USC SIPI IMAGE DATAB
   Broumandnia A, 2020, MULTIMED TOOLS APPL, V79, P11327, DOI 10.1007/s11042-019-08337-y
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   Eskicioglu AM, 2001, SIGNAL PROCESS-IMAGE, V16, P681, DOI 10.1016/S0923-5965(00)00050-3
   Farsana FJ, 2023, APPL COMPUT INFORM, V19, P239, DOI 10.1016/j.aci.2019.10.001
   Franko DL, 2013, BODY IMAGE, V10, P481, DOI 10.1016/j.bodyim.2013.04.008
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Graf F, 2002, COMPUT GRAPH-UK, V26, P355, DOI 10.1016/S0097-8493(02)00062-6
   GRASSBERGER P, 1983, PHYS REV A, V28, P2591, DOI 10.1103/PhysRevA.28.2591
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hikal NA, 2020, J KING SAUD UNIV-COM, V32, P870, DOI 10.1016/j.jksuci.2018.09.006
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kang J, 2014, INFORM SCIENCES, V269, P1, DOI 10.1016/j.ins.2014.02.011
   Kopácsi S, 2013, COMPUT IND, V64, P1282, DOI 10.1016/j.compind.2013.06.007
   Lai YL, 2019, INFORM SCIENCES, V502, P492, DOI 10.1016/j.ins.2019.05.064
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li M, 2019, IEEE ACCESS, V7, P63336, DOI 10.1109/ACCESS.2019.2916402
   Li P, 2010, J NETW COMPUT APPL, V33, P207, DOI 10.1016/j.jnca.2009.12.003
   Maniccam SS, 2001, PATTERN RECOGN, V34, P1229, DOI 10.1016/S0031-3203(00)00062-5
   Natiq H, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11834-2
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Qin XL, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103639
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Strogatz S.H., 2018, Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering, DOI [10.1201/9780429492563, DOI 10.1201/9780429492563]
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wilde SJ., 2004, Journal of Retailing and Consumer Services, V11, P131, DOI DOI 10.1016/S0969-6989(03)00012-2
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhang Q, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101850
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 48
TC 1
Z9 1
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11949
EP 11972
DI 10.1007/s11042-022-13733-y
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854695000008
DA 2024-07-18
ER

PT J
AU Shi, JY
   Sun, YM
   Du, XH
AF Shi, Jinyu
   Sun, Yuming
   Du, Xiaohan
TI The detection algorithm for disguised missing value based on
   filter-Kmeans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-frequency disguised missing value; Filter; Silhouette coefficient;
   Bernoulli's law of large numbers
AB In order to reduce the impact of disguised missing value on data analysis, this paper proposes a new algorithm - The Detection Algorithm for Disguised Missing Value Based on Filter-Kmeans. The algorithm identifies mainly disguised missing value by the clustering effect, and is applied to the data set with certain probability of data points. Firstly, the suitable data object points are selected using the silhouette coefficient method and Bernoulli's law of large numbers. And then the weighted average distance is used to control the cluster traversal. Finally, the filtering operation is performed during the process of cluster traversal. According to the experimental results, the algorithm achieves better improvement in the precision ratio, recall ratio and F1-measure on the open dataset.
C1 [Shi, Jinyu; Sun, Yuming; Du, Xiaohan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Shi, JY; Sun, YM (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM sjy1967@dlmu.edu.cn; sym2018@dlmu.edu.cn
FU National Natural Science Foundation of China [62103072]; Fundamental
   Research Funds for the Central Universities [3132021242]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62103072, and in part by the Fundamental
   Research Funds for the Central Universities under Grant 3132021242.
CR Avdiienko V, 2017, PROC IEEE ACM INT C, P201, DOI 10.1109/ICSE-C.2017.130
   Bhattacharyya C, 2020, ALGORITHMS FINDING K
   Chu X, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2201, DOI 10.1145/2882903.2912574
   Delaporte G, 2019, CHEMOMETR INTELL LAB, V188, P54, DOI 10.1016/j.chemolab.2019.03.005
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   Hua M, 2008, KDD 08, P1077
   Ilyas I. F., 2015, FOUND TRENDS DATABAS, V5, P281, DOI [DOI 10.1561/1900000045, 10.1561/1900000045]
   Koren O., 2018, P SAI INT SYST C C, P1025
   Lin CH, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103988
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MacQueen J., 1967, P 5 BERKL S MATH STA, P281
   Mao S., 2011, PROBABILITY THEORY M, V2nd
   Pearson RK., 2006, ACM SIGKDD EXPLOR NE, V8, P83, DOI DOI 10.1145/1147234.1147247
   Pham DT, 2005, P I MECH ENG C-J MEC, V219, P103, DOI 10.1243/095440605X8298
   Pit-Claudel C, OUTLIER DETECTION HE
   Qahtan AA, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2100, DOI 10.1145/3219819.3220109
   Sinha A, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1875, DOI 10.1109/ICACCI.2016.7732323
   Stojanovic N, 2017, IEEE INT CONF BIG DA, P1560, DOI 10.1109/BigData.2017.8258090
   Wang Jianren, 2019, Computer Engineering and Applications, V55, P27, DOI 10.3778/j.issn.1002-8331.1810-0075
   [王景云 Wang Jingyun], 2017, [地球信息科学学报, Journal of Geo-Information Science], V19, P605
   Wang LL, 2018, INFORM SCIENCES, V467, P59, DOI 10.1016/j.ins.2018.07.044
   Yang W., 2018, FUTURE GENER COMP SY, V85, P9, DOI [10.1016/j.future.2018.02.032, DOI 10.1016/J.FUTURE.2018.02.032]
NR 22
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7583
EP 7598
DI 10.1007/s11042-022-13421-x
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000849151100002
DA 2024-07-18
ER

PT J
AU Nair, RR
   Singh, T
   Basavapattana, A
   Pawar, MM
AF Nair, Rekha R.
   Singh, Tripty
   Basavapattana, Abhinandan
   Pawar, Manasa M.
TI Multi-layer, multi-modal medical image intelligent fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image fusion; Activity level map; Block based average operator;
   l(1)-norm; VGG-19; VGG-11; SqueezeNet
AB Recently, deep learning has high popularity in the field of image processing due to its unique feature extraction property. This paper, proposes a novel multi-layer, multi-tier system called Multi-Layer Intelligent Image Fusion(MLIIF) with deep learning(DL) networks for visually enhanced medical images through fusion. Implemented deep feature based multilayer fusion strategy for both high frequency and low frequency components to obtain more informative fused image from the source image sets. The hybrid MLIIF consists of VGG-19, VGG-11, and Squeezenet DL networks for different layer deep feature extraction from approximation and detailed frequency components of the source images. The robustness of the proposed multi-layer, multi-tier fusion system is validated by subjective and objective analysis. The effectiveness of the proposed MLIIF system is evaluated by error image calculation with the ground truth image and thus accuracy of the system. The source images utilized for the experimentations are collected from the website www.med.harvard.edu and the proposed MLIIF system obtained an accuracy of 95%. The experimental findings indicate that the proposed system outperforms compared with existing DL networks.
C1 [Nair, Rekha R.] Dayananda Sagar Univ, Sch Engn, Dept Comp Applicat, Bengaluru, India.
   [Singh, Tripty; Basavapattana, Abhinandan; Pawar, Manasa M.] Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Singh, T (corresponding author), Amrita Vishwa Vidyapeetham, Dept Comp Sci & Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
EM tripty_singh@blr.amrita.edu
RI Nair, Rekha R/IUQ-1674-2023
OI Nair, Rekha R/0000-0002-7207-2877; Singh, Tripty/0000-0002-3688-4392
CR Calhoun VD, 2009, IEEE T INF TECHNOL B, V13, P711, DOI 10.1109/TITB.2008.923773
   Dasarathy BV, 2012, INFORM FUSION, V13, P1, DOI 10.1016/j.inffus.2011.06.003
   Garcia-Gasulla D, 2018, J ARTIF INTELL RES, V61, P563, DOI 10.1613/jair.5756
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Hariss K, 2017, 2017 1ST CYBER SECURITY IN NETWORKING CONFERENCE (CSNET)
   Hermessi H, 2018, NEURAL COMPUT APPL, V30, P2029, DOI 10.1007/s00521-018-3441-1
   Hou RC, 2019, MED BIOL ENG COMPUT, V57, P887, DOI 10.1007/s11517-018-1935-8
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, P228, DOI 10.1109/CVPRW.2018.00042
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Johnson K.A., 2021, The Whole Brain Atlas
   Kaur J., 2020, ADV COMPUTATIONAL TE, DOI 10.1016/B978-0-12-820024-7.00002-5
   Krishnamoorthy S., 2010, Int. J. Comput. Appl, V9, P25, DOI [DOI 10.5120/1357-1832, 10.5120/1357-1832]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Moushmi S, 2016, ADV INTELL SYST, V397, P257, DOI 10.1007/978-81-322-2671-0_25
   Nair RR, 2021, MULTIMED TOOLS APPL, V80, P19079, DOI 10.1007/s11042-020-10439-x
   Nair RR, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165742
   Nair RR, 2019, IET IMAGE PROCESS, V13, P1447, DOI 10.1049/iet-ipr.2018.6556
   Nair Rekha R., 2020, IJAST, V29, P5353
   Nair S, 2007, IJAREEIE ISO, P3297
   Parameswaran L., 2013, EUROP J SCI RES, V112, P469
   Parvathy VS, 2020, PHYS COMMUN-AMST, V41, DOI 10.1016/j.phycom.2020.101119
   Qassim H., 2017, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wu F, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107632
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
   Zhao YF, 2008, 2008 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-11, P2411, DOI 10.1109/CCDC.2008.4597757
NR 33
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42821
EP 42847
DI 10.1007/s11042-022-13482-y
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840056800003
DA 2024-07-18
ER

PT J
AU Ghaleb, E
   Niehues, J
   Asteriadis, S
AF Ghaleb, Esam
   Niehues, Jan
   Asteriadis, Stylianos
TI Joint modelling of audio-visual cues using attention mechanisms for
   emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Emotion recognition; Multimodal learning; Attention
   mechanisms
ID PERCEPTION
AB Emotions play a crucial role in human-human communications with complex socio-psychological nature. In order to enhance emotion communication in human-computer interaction, this paper studies emotion recognition from audio and visual signals in video clips, utilizing facial expressions and vocal utterances. Thereby, the study aims to exploit temporal information of audio-visual cues and detect their informative time segments. Attention mechanisms are used to exploit the importance of each modality over time. We propose a novel framework that consists of bi-modal time windows spanning short video clips labeled with discrete emotions. The framework employs two networks, with each one being dedicated to one modality. As input to a modality-specific network, we consider a time-dependent signal deriving from the embeddings of the video and audio modalities. We employ the encoder part of the Transformer on the visual embeddings and another one on the audio embeddings. The research in this paper introduces detailed studies and meta-analysis findings, linking the outputs of our proposition to research from psychology. Specifically, it presents a framework to understand underlying principles of emotion recognition as functions of three separate setups in terms of modalities: audio only, video only, and the fusion of audio and video. Experimental results on two datasets show that the proposed framework achieves improved accuracy in emotion recognition, compared to state-of-the-art techniques and baseline methods not using attention mechanisms. The proposed method improves the results over baseline methods by at least 5.4%. Our experiments show that attention mechanisms reduce the gap between the entropies of unimodal predictions, which increases the bimodal predictions' certainty and, therefore, improves the bimodal recognition rates. Furthermore, evaluations with noisy data in different scenarios are presented during the training and testing processes to check the framework's consistency and the attention mechanism's behavior. The results demonstrate that attention mechanisms increase the framework's robustness when exposed to similar conditions during the training and the testing phases. Finally, we present comprehensive evaluations of emotion recognition as a function of time. The study shows that the middle time segments of a video clip are essential in the case of using audio modality. However, in the case of video modality, the importance of time windows is distributed equally.
C1 [Ghaleb, Esam; Niehues, Jan; Asteriadis, Stylianos] Maastricht Univ, Dept Data Sci & Knowledge Engn, Maastricht, Netherlands.
C3 Maastricht University
RP Ghaleb, E (corresponding author), Maastricht Univ, Dept Data Sci & Knowledge Engn, Maastricht, Netherlands.
EM esam.ghaleb@maastrichtuniversity.nl;
   jan.niehues@maastrichtuniversity.nl;
   stelios.asteriadis@maastrichtuniversity.nl
RI ; Asteriadis, Stylianos/O-2140-2016
OI Niehues, Jan/0000-0002-4231-6543; Asteriadis,
   Stylianos/0000-0002-4298-6870; Ghaleb, Esam/0000-0002-0603-9817
CR Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   Albanie S, 2016, LEARNING GRIMACES WA
   [Anonymous], 2016, arXiv
   [Anonymous], 2019, P 9 INT AUD VIS EM C, P3, DOI DOI 10.1145/3347320.3357688
   Athanasiadis C, 2020, NEUROCOMPUTING, V397, P331, DOI 10.1016/j.neucom.2019.09.106
   Aubergé V, 2003, SPEECH COMMUN, V40, P87, DOI 10.1016/S0167-6393(02)00077-8
   Aytar Y, 2016, ADV NEUR IN, V29
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Barkhuysen P, 2010, LANG SPEECH, V53, P3, DOI 10.1177/0023830909348993
   Beard R., 2018, P 22 C COMP NAT LANG, P251
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chatfield K., 2014, ARXIV
   Cosentino S, 2018, IEEE INT C INT ROBOT, P813, DOI 10.1109/IROS.2018.8593503
   D'Mello S, 2018, EMOT REV, V10, P174, DOI 10.1177/1754073917696583
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ghaleb E, 2019, IEEE MULTIMED
   Ghaleb E, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925444, 10.1109/ACII.2019.8925444]
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hori C, 2019, INT CONF ACOUST SPEE, P2352, DOI 10.1109/ICASSP.2019.8682583
   Kappas A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00051
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kim Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P92, DOI 10.1145/2993148.2993151
   Kingma D. P., 2014, arXiv
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Mano LY, 2016, COMPUT COMMUN, V89-90, P178, DOI 10.1016/j.comcom.2016.03.010
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Picard R.W., 2000, Affective Computing
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Radoi A, 2021, IEEE ACCESS, V9, P135559, DOI 10.1109/ACCESS.2021.3116530
   Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471
   Shi Y., 2019, ADV NEURAL INFORM PR, P15718
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang D., 2020, P IEEECVF C COMPUTER, P12695, DOI DOI 10.1109/CVPR42600.2020.01271
   Wu CH, 2016, BRIT J EDUC TECHNOL, V47, P1304, DOI 10.1111/bjet.12324
   Wu ZX, 2019, INT CONF AFFECT, DOI 10.1109/acii.2019.8925497
   Xu HY, 2019, INTERSPEECH, P3569, DOI 10.21437/Interspeech.2019-3247
   Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448
NR 41
TC 5
Z9 5
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11239
EP 11264
DI 10.1007/s11042-022-13557-w
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000836525000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Saboo, S
   Singha, J
   Laskar, RH
AF Saboo, Shweta
   Singha, Joyeeta
   Laskar, Rabul Hussain
TI Self co-articulation removal and hybrid classifier-feature combination
   for dynamic hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic hand gesture recognition; Extreme machine learning; Feature
   extraction; Hybrid classifier-feature combination; Self co-articulation
AB Gestures have been considered as a way to reinforce information as interfaces that can effectively deliver more natural, creative and intuitive methods for communication with devices. During gesticulation, some unwanted strokes known as self co-articulated strokes occur which create confusion between many of the gestures. Existing approaches track the gestures with single strokes but fails to remove the unwanted strokes. In order to recognize the correct gestures, these self co-articulated strokes need to be identified and removed from the gesture trajectory. In this paper, a hand gesture recognition system is proposed for bare-hand dataset which tries to solve the problem of self co-articulation of gestures present in numerals and alphabets. A two-step slope-angle system is used for detecting and removing the self co-articulated strokes. These strokes which are removed from the tracked trajectory can be used as added features along with proposed features. Twelve new features like curliness feature, sharpness feature etc. are being extracted and added to existing features to form a feature matrix of forty features. Recognition accuracy for different classifiers such as SVM, k-NN, ANN, ELM, Naive Bayes and Decision tree along with hybrid classifier-feature combination models is being calculated. The experimental results suggest that highest accuracy achieved for individual classifiers is 96.11% for ELM type of classifier. There is an improvement of 2.66% when ELM and k-NN classifier fusion takes place with new feature matrix.
C1 [Saboo, Shweta; Singha, Joyeeta; Laskar, Rabul Hussain] Dept Elect & Commun Engn, Jaipur, Rajasthan, India.
   [Saboo, Shweta; Singha, Joyeeta] LNM Inst Informat Technol, Jaipur 302031, Rajasthan, India.
   [Laskar, Rabul Hussain] Natl Inst Technol, Silchar 788010, Assam, India.
C3 LNM Institute of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Silchar
RP Singha, J (corresponding author), Dept Elect & Commun Engn, Jaipur, Rajasthan, India.; Singha, J (corresponding author), LNM Inst Informat Technol, Jaipur 302031, Rajasthan, India.
EM shweta.saboo.y18pg@lnmiit.ac.in; joyeeta.singha@lnmiit.ac.in;
   rabul18@yahoo.com
RI Singha, Joyeeta/C-3650-2017
OI Singha, Joyeeta/0000-0001-9077-1842
FU DST; SEED Division [SP/YO/407/2018]
FX This work is supported by DST (Govt. of India) under the SEED Division
   [SP/YO/407/2018].
CR Bamwenda J, 2019, DICLE U MUHENDISLIK, V10, P561
   Bhuyan MK, 2006, LECT NOTES COMPUT SC, V4338, P564
   Bhuyan MK, 2006, CONF CYBERN INTELL S, P748
   Bhuyan MK, 2014, J MULTIMODAL USER IN, V8, P333, DOI 10.1007/s12193-014-0165-0
   Bhuyan M. K., 2005, TENCON IEEE REG NOV, P1, DOI 10.1109/TENCON.2005.300947
   Blagojevic Rachel, 2010, SBIM, V10, P79
   Chai D, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P124, DOI 10.1109/AFGR.1998.670936
   Chen Q, 2020, IEEE T VIS COMPUT GR, V26, P1622, DOI 10.1109/TVCG.2018.2872961
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Fang YK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P995
   Kaur Sanmukh, 2018, 2018 8th International Conference on Cloud Computing, Data Science & Engineering (Confluence), P371, DOI 10.1109/CONFLUENCE.2018.8442982
   Liu HP, 2016, NEUROCOMPUTING, V174, P322, DOI 10.1016/j.neucom.2015.01.093
   Misra S, 2018, NEURAL COMPUT APPL, V29, P117, DOI 10.1007/s00521-017-2838-6
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Parvathy P, 2021, J AMB INTEL HUM COMP, V12, P6793, DOI 10.1007/s12652-020-02314-2
   Rahman MA, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS AGENTS, NETWORKS AND SYSTEMS (INAGENTSYS), P58, DOI 10.1109/INAGENTSYS.2014.7005726
   RUBINE D, 1991, COMP GRAPH, V25, P329, DOI 10.1145/127719.122753
   Saha S, 2018, ADV INTELL SYST, V518, P287, DOI 10.1007/978-981-10-3373-5_29
   Saxe D, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P379, DOI 10.1109/AFGR.1996.557295
   Singha J, 2016, NEUROCOMPUTING, V208, P269, DOI 10.1016/j.neucom.2016.05.049
   Singha J, 2016, J MULTIMODAL USER IN, V10, P77, DOI 10.1007/s12193-016-0212-0
   Singha J, 2016, IET COMPUT VIS, V10, P143, DOI 10.1049/iet-cvi.2014.0432
   Sridevi P, 2018, IEEE REG 10 HUMANIT
   Thirumuruganathan S., 2010, Retrieved March, V20, P2012
   Xiu CB, 2018, CHIN CONT DECIS CONF, P4449, DOI 10.1109/CCDC.2018.8407900
   Xu D, 2015, J INTELL ROBOT SYST, V77, P583, DOI 10.1007/s10846-014-0039-4
   Yang J, 1998, ACCV98, P687
   Yang WM, 2019, IEEE ACCESS, V7, P50466, DOI 10.1109/ACCESS.2019.2910835
   Yu YS, 2016, IEEE ANN INT CONF CY, P337, DOI 10.1109/CYBER.2016.7574846
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6033
EP 6052
DI 10.1007/s11042-022-13571-y
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000835601400007
DA 2024-07-18
ER

PT J
AU Sharma, T
   Verma, NK
   Masood, S
AF Sharma, Teena
   Verma, Nishchal K.
   Masood, Shahrukh
TI Mixed fuzzy pooling in convolutional neural networks for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Fuzzy logic; Mixed pooling; MNIST;
   CIFAR-10
AB Convolutional Neural Networks (CNN) are being widely practised in computer vision applications, where pooling indicates as an integral part. Pooling significantly reduces the training time and computational cost of any network. The pooling operations generally being used are max, average, or stochastic. The performance of the CNN architecture can be increased by using more than one pooling operations. Herein, a novel mixed fuzzy pooling is proposed for image classification in the CNN architecture. In the proposed mixed fuzzy pooling, max pooling and fuzzy pooling are combined together to boost the classification accuracy. The proposed mixed fuzzy pooling is designed as a function of max pooling, fuzzy pooling, and alpha parameter where the learning of the proposed pooling function takes place with the value of alpha. In fuzzy pooling, Type-2 fuzzy logic is used to get the convolved dominant features. This is obtained by the estimation of a threshold for image region to be pooled. Thereafter, Type-1 fuzzy logic is used to get the pooling output by a weighted average of convolved dominant features. The performance of various pooling strategies on MNIST dataset for handwritten digits classification and CIFAR-10 dataset for RGB images classification have been compared and analysed. The experimental results show better image classification accuracy for the proposed mixed fuzzy pooling than conventional pooling operations.
C1 [Sharma, Teena; Verma, Nishchal K.; Masood, Shahrukh] IIT Kanpur, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Sharma, T (corresponding author), IIT Kanpur, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
EM tee.shar6@gmail.com; nishchal@iitk.ac.in; shahrukhmasood5399@gmail.com
CR [Anonymous], 2007, Advances in Neural Information Processing Systems
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555
   Chauhan R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P278, DOI 10.1109/ICSCCC.2018.8703316
   Chen JF, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P496, DOI 10.1109/CIS.2017.00115
   Green M.C., 2017, INT ENCY MEDIA EFFEC, P1, DOI DOI 10.1002/9781118783764.WBIEME0083
   Juang CF, 2005, IEEE T SYST MAN CY B, V35, P646, DOI 10.1109/TSMCB.2005.844594
   Juang CF, 2010, IEEE T FUZZY SYST, V18, P261, DOI 10.1109/TFUZZ.2010.2040185
   Kebria PM, 2020, IEEE T FUZZY SYST, V28, P2543, DOI 10.1109/TFUZZ.2019.2941173
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, IEEE APP IMG PAT, DOI 10.1109/aipr47015.2019.9174579
   Kumar M, 2016, IEEE T FUZZY SYST, V24, P195, DOI 10.1109/TFUZZ.2015.2451706
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee CY, 2018, IEEE T PATTERN ANAL, V40, P863, DOI 10.1109/TPAMI.2017.2703082
   Lee CS, 2005, IEEE T SYST MAN CY B, V35, P694, DOI 10.1109/TSMCB.2005.845397
   MIZUMOTO M, 1976, INFORM CONTROL, V31, P312, DOI 10.1016/S0019-9958(76)80011-3
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Sharma Teena, 2021, IEEE Transactions on Artificial Intelligence, V2, P83, DOI 10.1109/TAI.2021.3077522
   Sharma T., 2019, IEEE INT C FUZZY SYS, P1, DOI [10.1109/FUZZ-IEEE.2019.8859010, DOI 10.1109/FUZZ-IEEE.2019.8859010, 10.1109/FUZZIEEE.2019.8859010]
   Sharma T, 2022, IEEE T EM TOP COMP I, V6, P93, DOI 10.1109/TETCI.2020.3032970
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   Zeiler M. D., 2013, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1301.3557
   Zhou SS, 2014, NEUROCOMPUTING, V131, P312, DOI 10.1016/j.neucom.2013.10.011
NR 27
TC 2
Z9 2
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8405
EP 8421
DI 10.1007/s11042-022-13553-0
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000834736500003
DA 2024-07-18
ER

PT J
AU Alamgeer, S
   Farias, MCQ
AF Alamgeer, Sana
   Farias, Mylene C. Q.
TI A two-stream cnn based visual quality assessment method for light field
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Epipolar planes; Canny edge detector;
   Two-stream convolution neural network; 4D Light field images
AB Light Field (LF) cameras are able to capture both the intensity and the direction of light rays from the scene. This rich information demands a certain amount of memory and bandwidth for storage and transmission and, to alleviate this requirement, the LF content is processed and compressed. These operations often add degradations to the LF content that may affect their visual quality, requiring the use of methods to estimate the visual quality as perceived by the end consumer. In this paper, we propose a no-reference LF image quality assessment (LF-IQA) method that is based on a two-stream CNN architecture. The two-stream CNN extracts rich distortion-related spatial and angular binocular characteristics of LF contents to estimate their quality. More specifically, the first stream extracts angular information by processing Canny maps of Epipolar Plane Images (EPIs) generated from the corresponding LF contents, while the second stream extracts spatial information by processing mean canny maps generated from canny maps of sub-aperture images (SAIs). We also propose a novel approach to generate multiple epipolar-plane images - the MultiEPL. Results show that the proposed LF-IQA method outperforms state-of-the-art methods.
C1 [Alamgeer, Sana; Farias, Mylene C. Q.] Univ Brasilia, Dept Elect Engn, Brasilia, DF, Brazil.
C3 Universidade de Brasilia
RP Alamgeer, S (corresponding author), Univ Brasilia, Dept Elect Engn, Brasilia, DF, Brazil.
EM sanaalamgeer@gmail.com; mylene@ieee.org
RI Farias, Mylene/C-4900-2015
OI Farias, Mylene/0000-0002-1957-9943; Alamgeer, Sana/0000-0002-6472-7570
FU FundacAo de Apoio a Pesquisa do Distrito Federal (FAP-DF); CoordenacAo
   de Aperfeicoamento de Pessoal de Nivel Superior (CAPES); University of
   Brasilia (UnB)
FX This work was supported by the FundacAo de Apoio a Pesquisa do Distrito
   Federal (FAP-DF), by the CoordenacAo de Aperfeicoamento de Pessoal de
   Nivel Superior (CAPES), and by the University of Brasilia (UnB).
CR Adhikarla VK, 2017, PROC CVPR IEEE, P3720, DOI 10.1109/CVPR.2017.396
   Ak Ali, 2020, IEEE INT CONF MULTI, DOI DOI 10.1109/icmew46912.2020.9105975
   Algina J, 1999, PSYCHOL METHODS, V4, P76, DOI 10.1037/1082-989X.4.1.76
   Astola P., 2020, ITU J ICT DISCOVERIE, V3
   BAKIR N, 2019, EUR SIGNAL PR CONF
   Bobko P., 2001, CORRELATION REGRESSI
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Fang YC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240823
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Grill-Spector K, 2004, ANNU REV NEUROSCI, V27, P649, DOI 10.1146/annurev.neuro.27.070203.144220
   Hahne C., 2016, Ph. D. Dissertation
   Hahne C, 2018, INT J COMPUT VISION, V126, P21, DOI 10.1007/s11263-017-1036-4
   Hahne C, 2016, OPT EXPRESS, V24, P21521, DOI 10.1364/OE.24.021521
   Jiang G, 2018, NEW QUALITY ASSESSME, V11, P44
   Lamichhane K, 2021, PICT COD SYMP, P126, DOI 10.1109/PCS50896.2021.9477451
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Luo Z., 2019, ARXIV
   Mahapattanakul, 2019, HUMAN VISION COMPUTE
   Mahmoudpour S, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123130
   Medda D, 2019, OBJECTIVE IMAGE QUAL, V10, P163
   Meng CL, 2020, IEEE SIGNAL PROC LET, V27, P525, DOI 10.1109/LSP.2020.2982060
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Paudyal P., 2017, IEEE T BROADCAST, V99, P1
   Paudyal P, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P374, DOI 10.1145/2910017.2910623
   Paudyal P, 2019, IEEE T BROADCAST, V65, P152, DOI 10.1109/TBC.2019.2892092
   Qu Q, 2021, IEEE T BROADCAST, V67, P837, DOI 10.1109/TBC.2021.3099737
   Sandic-Stankovic D, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0124-7
   Shan L, 2019, IEEE ACCESS, V7, P127217, DOI 10.1109/ACCESS.2019.2940093
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shi L, 2019, ARXIV
   Shi LK, 2019, IEEE IMAGE PROC, P3781, DOI [10.1109/icip.2019.8803559, 10.1109/ICIP.2019.8803559]
   Shi LK, 2018, IEEE IMAGE PROC, P41, DOI 10.1109/ICIP.2018.8451077
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Sze V., 2014, INTEGRATED CIRCUITS
   Tian Y, 2021, IEEE T CIRC SYST VID, V31, P2046, DOI 10.1109/TCSVT.2020.2971256
   Tian Y, 2020, IEEE T IMAGE PROCESS, V29, P7945, DOI 10.1109/TIP.2020.3008856
   Tian Y, 2018, J VIS COMMUN IMAGE R, V57, P212, DOI 10.1016/j.jvcir.2018.11.005
   Viola I, 2019, INDEPTH ANAL SINGLE, V06, P1
   Viola I, 2018, INT WORK QUAL MULTIM, P189
   Vu PV, 2011, IEEE IMAGE PROC
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wietzke Lennart, 2008, Raytrix: 3D light field camera technology
   Xiang J., 2020, P IEEE INT C MULT EX, P1
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhou W, 2019, TENSOR ORIENTED NO R, V9
   Zhou W, 2019, IEEE T IMAGE PROCESS, V28, P3946, DOI 10.1109/TIP.2019.2902831
NR 54
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5743
EP 5762
DI 10.1007/s11042-022-13436-4
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000833514100007
DA 2024-07-18
ER

PT J
AU Behrouzi, T
   Toosi, R
   Akhaee, MA
AF Behrouzi, Tina
   Toosi, Ramin
   Akhaee, Mohammad Ali
TI Multimodal movie genre classification using recurrent neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie genre detection; Multi-label classification; Gated recurrent unit
   (GRU); Long short-term memory (LSTM); 1D Convolutional neural network
   (1D_Conv)
ID GRAPH CONVOLUTIONAL NETWORKS; SCENE
AB Genre is one of the features of a movie that defines its structure and type of audience. The number of streaming companies interested in automatically deriving movies' genres is rapidly increasing. Genre categorization of trailers is a challenging problem because of the conceptual nature of the genre, which is not presented physically within a frame and can only be perceived by the whole trailer. Moreover, several genres may appear in the movie at the same time. The multi-label learning algorithms have not been improved as significantly as the single-label classification models, which causes the genre categorization problem to be highly complicated. In this paper, we propose a novel multi-modal deep recurrent model for movie genre classification. A new structure based on Gated Recurrent Unit (GRU) is designed to derive spatial-temporal features of movie frames. The video features are then concatenated with the audio features to predict the final genres of the movie. The proposed design outperforms the state-of-art models based on accuracy and computational cost and substantially improves the movie genre classifier system's performance.
C1 [Behrouzi, Tina] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Toosi, Ramin; Akhaee, Mohammad Ali] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
C3 University of Toronto; University of Tehran
RP Akhaee, MA (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
EM tina.behrouzi@mail.utoronto.ca; r.toosi@ut.ac.ir; akhaee@ut.ac.ir
OI Toosi, Ramin/0000-0002-7099-9353
CR Alvarez F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211406
   [Anonymous], 2010, Proceedings of the 18th International Conference on Multimedea, DOI [DOI 10.1145/1873951.1874068, 10.1145/1873951.1874068]
   Aytar Y., 2016, Advances in neural information processing systems (NeurIPS), V29, P892
   Badamdorj T., 2021, P IEEECVF INT C COMP, P8127
   Ben-Ahmed O, 2018, INT WORK CONTENT MUL
   Bhoraniya DM, 2017, 2017 INT C INTELLIGE, P1
   Bordwell D., 2008, FILM ART INTRO, VEighth
   Choros, 2019, J INTELL FUZZY SYST, P1
   Chung Junyoung, 2014, ARXIV14123555
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fu SC, 2021, NEUROCOMPUTING, V461, P63, DOI 10.1016/j.neucom.2021.07.048
   Fu SC, 2020, INFORM SCIENCES, V514, P484, DOI 10.1016/j.ins.2019.11.019
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain Sanjay K., 2009, 2009 24th International Symposium on Computer and Information Sciences (ISCIS), P575, DOI 10.1109/ISCIS.2009.5291884
   Kingma D. P., 2014, arXiv
   Li Y., 2015, ARXIV
   Liu WF, 2019, IEEE T CYBERNETICS, V49, P2927, DOI 10.1109/TCYB.2018.2833843
   Mangolin RB, 2022, MULTIMED TOOLS APPL, V81, P19071, DOI 10.1007/s11042-020-10086-2
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pant P, 2019, ADV INTELL SYST COMP, V841, P433, DOI 10.1007/978-981-13-2285-3_51
   Pillai I, 2013, PATTERN RECOGN, V46, P2055, DOI 10.1016/j.patcog.2013.01.012
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Schwarz D., 2015, SOUND MUSIC COMPUTIN, P6
   Serban I.V., 2015, arXiv
   Simoes GS, 2016, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2016.7727207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Somappa, 2016, MOVIESCOPE MOVIE TRA
   Srinivas S, 2016, FRONT ROBOT AI, V2, DOI 10.3389/frobt.2015.00036
   Tian YP, 2021, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR46437.2021.00555
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varghese Jina, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P685, DOI 10.1007/978-981-13-1742-2_68
   Wang W, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.4.040901
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Wehrmann J, 2016, PROCEEDINGS OF 2016 5TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS 2016), P1, DOI [10.1109/BRACIS.2016.012, 10.1109/BRACIS.2016.11]
   Wessel D. L., 1979, Computer Music Journal, V3, P45, DOI 10.2307/3680283
   Wu JN, 2008, PROC CVPR IEEE, P2221
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yi Y, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115640
   Yin-Fu Huang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P1, DOI 10.1007/978-3-642-35236-2_1
   Yu YT, 2021, MULTIMED TOOLS APPL, V80, P9749, DOI 10.1007/s11042-020-10125-y
   Zhou Y, 2019, NEURAL COMPUT APPL, V31, P1855, DOI 10.1007/s00521-017-3162-x
NR 45
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5763
EP 5784
DI 10.1007/s11042-022-13418-6
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000833514100006
DA 2024-07-18
ER

PT J
AU Bi, J
   Zhang, Y
AF Bi, Jie
   Zhang, Yong
TI An improved atom search optimization for optimization tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Atom search optimization; Non-linear inertia weightm; Global topology;
   Update learning
ID BIO-INSPIRED OPTIMIZER; GLOBAL OPTIMIZATION; PARTICLE SWARM; ALGORITHM;
   DESIGN; INTELLIGENCE; PERFORMANCE; METHODOLOGY; STATE; TESTS
AB Atom search optimization (ASO) is a newly developed metaheuristic algorithm inspired by molecular basis dynamics. The paramount challenge in ASO is that it is easily trapped into the local optima and premature convergence. To address these issues, this paper presented an improved atom search optimization with three strategies, global topology with secant factor, non-linear inertia weight and update learning. First, the global topology provides the best solution for each individual and enriches the information exchange of the population, and prevents premature convergence under the effect of the secant factor. Second, smooth properties of non-linear inertia weights are introduced to balance exploration and exploitation. Third, update learning provides more opportunities to jump out of the local optima. Thus, these three strategies are used to improve the performance of ASO, which is called GNUASO. Finally, the proposed GNUASO algorithm was evaluated in the CEC2017 benchmark functions and two real-world engineering problems, compared with some excellent algorithms to confirm the performance of the proposed GNUASO. Experimental results and statistical analysis show that the proposed GNUASO algorithm outperforms the other selected algorithms in CEC2017 benchmark functions and engineering design problems.
C1 [Bi, Jie; Zhang, Yong] Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan 114051, Peoples R China.
C3 University of Science & Technology Liaoning
RP Zhang, Y (corresponding author), Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan 114051, Peoples R China.
EM zy9091@163.com
RI Yong, Zhang/JAZ-0797-2023
FU National Science Foundation of China [61473054]
FX This work is supported by National Science Foundation of China under
   Grant No. 61473054. The authors also gratefully acknowledge the helpful
   comments and suggestions of the reviewers, which have improved the
   presentation.
CR Abd Elaziz M, 2019, IEEE C EVOL COMPUTAT, P2315, DOI [10.1109/CEC.2019.8790361, 10.1109/cec.2019.8790361]
   Agwa AM, 2019, ENERGIES, V12, DOI 10.3390/en12101884
   Almagboul MA, 2019, AEU-INT J ELECTRON C, V111, DOI 10.1016/j.aeue.2019.152854
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   BREIMAN L, 1993, MATH PROGRAM, V58, P179, DOI 10.1007/BF01581266
   Civicioglu P, 2013, APPL MATH COMPUT, V219, P8121, DOI 10.1016/j.amc.2013.02.017
   Civicioglu P, 2012, COMPUT GEOSCI-UK, V46, P229, DOI 10.1016/j.cageo.2011.12.011
   de Carvalho DF, 2009, INT J INTELL COMPUT, V2, P197, DOI 10.1108/17563780910959875
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dorigo M, 2003, INT SER OPER RES MAN, V57, P251
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Engelbrecht AP, 2013, 2013 1ST BRICS COUNTRIES CONGRESS ON COMPUTATIONAL INTELLIGENCE AND 11TH BRAZILIAN CONGRESS ON COMPUTATIONAL INTELLIGENCE (BRICS-CCI & CBIC), P124, DOI 10.1109/BRICS-CCI-CBIC.2013.31
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Figueiredo EMN, 2014, NEUROCOMPUTING, V127, P4, DOI 10.1016/j.neucom.2013.05.047
   Floudas C. A., 2013, Deterministic Global Optimization: Theory, Methods and Applications, V37
   Fu YM, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4568906
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Goldstein H., 2002, CLASSICAL MECH
   Gupta S, 2021, ENG COMPUT-GERMANY, V37, P1049, DOI 10.1007/s00366-019-00871-5
   Gupta S, 2019, SWARM EVOL COMPUT, V44, P101, DOI 10.1016/j.swevo.2018.01.001
   Hekimoglu B, 2019, IEEE ACCESS, V7, P38100, DOI 10.1109/ACCESS.2019.2905961
   Holland JH., 1975, Ann Arbor
   Houck C. R., 1995, NCSU IE T, V95, P1
   Jain M, 2018, J INTELL FUZZY SYST, V34, P1573, DOI 10.3233/JIFS-169452
   Jones JE, 1924, P R SOC LOND A-CONTA, V106, P463, DOI 10.1098/rspa.1924.0082
   Kamel S., 2019, P 2019 INT C COMPUTE, DOI [10.1109/iccceee46830.2019.9071384, DOI 10.1109/ICCCEEE46830.2019.9071384]
   Ghosh KK, 2020, Arxiv, DOI arXiv:2005.08642
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim MJ, 2007, J POWER SOURCES, V165, P819, DOI 10.1016/j.jpowsour.2006.12.038
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Li XT, 2014, NEURAL COMPUT APPL, V24, P1867, DOI 10.1007/s00521-013-1433-8
   Li XD, 2010, IEEE T EVOLUT COMPUT, V14, P150, DOI 10.1109/TEVC.2009.2026270
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Lin AP, 2019, APPL SOFT COMPUT, V77, P533, DOI 10.1016/j.asoc.2019.01.047
   Lin MH, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/756023
   Mendes R, 2004, IEEE T EVOLUT COMPUT, V8, P204, DOI [10.1109/TEVC.2004.826074, 10.1109/tevc.2004.826074]
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Peterson C., 1989, International Journal of Neural Systems, V1, P3, DOI 10.1142/S0129065789000414
   Rashedi E, 2010, NAT COMPUT, V9, P727, DOI 10.1007/s11047-009-9175-3
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rizk-Allah RM, 2020, NEURAL COMPUT APPL, V32, P13971, DOI 10.1007/s00521-020-04799-6
   SANDGREN E, 1990, J MECH DESIGN, V112, P223, DOI 10.1115/1.2912596
   Schweidtmann AM, 2019, J OPTIMIZ THEORY APP, V180, P925, DOI 10.1007/s10957-018-1396-0
   Sexton RS, 1998, DECIS SUPPORT SYST, V22, P171, DOI 10.1016/S0167-9236(97)00040-7
   Shang Y, 1996, COMPUTER, V29, P45, DOI 10.1109/2.485892
   Stone A., 2013, THEORY INTERMOLECULA
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Suganthan P, 2016, Problem definitions and evaluation criteria for the CEC 2017 special session and competition on single objective bound constrained real-parameter numerical optimization
   Sun P, 2020, IEEE ACCESS, V8, P49137, DOI 10.1109/ACCESS.2020.2979921
   Sun R, 2006, US Patent App., Patent No. [11/097,435, 11097435]
   Too J, 2020, ARAB J SCI ENG, V45, P6063, DOI 10.1007/s13369-020-04486-7
   TORN A, 1989, LECT NOTES COMPUT SC, V350, P1
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yang X.S., 2019, Mathematical Foundations of Nature-Inspired Methods
   Yao T, 2009, NETW SPAT ECON, V9, P171, DOI 10.1007/s11067-009-9103-1
   Zhan ZH, 2009, IEEE T SYST MAN CY B, V39, P1362, DOI 10.1109/TSMCB.2009.2015956
   Zhang QY, 2019, SOFT COMPUT, V23, P7333, DOI 10.1007/s00500-018-3381-9
   Zhao WG, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103300
   Zhao WG, 2019, KNOWL-BASED SYST, V163, P283, DOI 10.1016/j.knosys.2018.08.030
NR 65
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6375
EP 6429
DI 10.1007/s11042-022-13171-w
EA JUL 2022
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000829140300002
DA 2024-07-18
ER

PT J
AU Patri, SR
   Nithyanandan, L
AF Patri, Srinivasa Rao
   Nithyanandan, L.
TI Network throughput optimization for grouping based NB-CR-IoT wireless
   body area network for healthcare monitoring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Narrow band IOT; Cognitive radio networks; Energy harvesting; Spectrum
   sensing; Network throughput optimization; Wireless body area networks
   (WBANs)
ID COGNITIVE RADIO NETWORKS; ENERGY; INFORMATION; SPECTRUM; COMMUNICATION;
   ALLOCATION; DEVICE; ARCHITECTURE
AB This paper studies how to efficiently harvest energy and improve network throughput so that the narrowband user equipment has a longer life span instead of replacing batteries every few years to keep them working. To harvest enough energy for spectrum sensing and data transmission, we propose a grouping-based network which also maximizes the network throughput. Initially, instead of sensing the spectrum, we first harvest the energy and then use this harvested energy for spectrum sensing and data transmission. The grouping is done in such a way that the users which are in closer proximity to the AP are considered a group. The devices which are out of the range of access point (AP) can harvest energy, but it is comparatively less than those devices which are grouped with AP. In such cases, they are grouped with the AP that is closer to them. The main aim is to escalate the amount of harvested energy and extend the life span of the devices to have as many successful data transmissions as possible. Since the devices use the spectrum allocated to primary users (Pu) for data transmissions and the devices can transmit data only when the PU's spectrum is free, the proposed model is beneficial for wireless body area networks where electronic health monitoring is one of the major applications.
C1 [Patri, Srinivasa Rao] VNR Vignana Jyothi Inst Engn & Technol, Hyderabad, India.
   [Nithyanandan, L.] Pondicherry Engn Coll, Pondicherry, India.
C3 Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering
   &Technology (VNR VJIET); Pondicherry Engineering College
RP Patri, SR (corresponding author), VNR Vignana Jyothi Inst Engn & Technol, Hyderabad, India.
EM srinivasarao.patri@gmail.com; nithi@pec.edu
RI Patri, Srinivasa Rao/GQH-0582-2022; Lakshmanan,
   Nithyanandan/AFI-8345-2022
OI Patri, Srinivasa Rao/0000-0001-7149-304X
CR Aijaz A, 2015, IEEE INTERNET THINGS, V2, P103, DOI 10.1109/JIOT.2015.2390775
   Ali A, 2017, IEEE COMMUN SURV TUT, V19, P1277, DOI 10.1109/COMST.2016.2631080
   Alnakhli M, 2017, IEEE T COGN COMMUN, V3, P217, DOI 10.1109/TCCN.2017.2689015
   Amjad O, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2019.2946851
   Ansari N., 2017, Green Mobile Networks: A Networking Perspective
   Bhowmick A, 2016, IEEE WIREL COMMUN LE, V5, P136, DOI 10.1109/LWC.2015.2508806
   Chung W, 2014, IEEE T WIREL COMMUN, V13, P2601, DOI 10.1109/TWC.2014.032514.130637
   Ding HY, 2011, IEEE T VEH TECHNOL, V60, P457, DOI 10.1109/TVT.2010.2100053
   Ding JF, 2018, IEEE COMMUN LETT, V22, P165, DOI 10.1109/LCOMM.2017.2763589
   Ding ZG, 2014, IEEE T WIREL COMMUN, V13, P846, DOI 10.1109/TWC.2013.010213.130484
   Flint I, 2014, IEEE GLOB COMM CONF, P1448, DOI 10.1109/GLOCOM.2014.7037012
   Ghasemi A, 2007, IEEE T WIREL COMMUN, V6, P649, DOI 10.1109/TWC.2007.05447
   Goldsmith A, 2009, P IEEE, V97, P894, DOI 10.1109/JPROC.2009.2015717
   Ha T, 2018, IEEE T WIREL COMMUN, V17, P3, DOI 10.1109/TWC.2017.2757024
   He YF, 2011, IEEE T MOBILE COMPUT, V10, P1558, DOI 10.1109/TMC.2011.83
   Hu S, 2016, IEEE ACCESS, V4, P4583, DOI 10.1109/ACCESS.2016.2598401
   Huang XQ, 2015, IEEE WIREL COMMUN, V22, P144, DOI 10.1109/MWC.2015.7143338
   Kang X, 2015, IEEE T WIREL COMMUN, V14, P5539, DOI 10.1109/TWC.2015.2439673
   Kaur N, 2017, IEEE SYST J, V11, P796, DOI 10.1109/JSYST.2015.2469676
   Kawabata H, 2017, IEEE INTERNET THINGS, V4, P384, DOI 10.1109/JIOT.2016.2586581
   Kong PY, 2020, IEEE SENS J, V20, P13139, DOI 10.1109/JSEN.2020.3001727
   Le T, 2008, IEEE J SOLID-ST CIRC, V43, P1287, DOI 10.1109/JSSC.2008.920318
   Liu L, 2013, IEEE T WIREL COMMUN, V12, P288, DOI 10.1109/TWC.2012.113012.120500
   Majumdar C, 2017, IEEE ACCESS, V5, P6325, DOI 10.1109/ACCESS.2016.2619358
   Nasir AA, 2013, IEEE T WIREL COMMUN, V12, P3622, DOI 10.1109/TWC.2013.062413.122042
   Nobar SK, 2017, IEEE SENS J, V17, P1549, DOI 10.1109/JSEN.2017.2647878
   Prasad B, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2009, DOI 10.1109/ICACCI.2016.7732346
   Shahini A, 2016, IEEE SARNOFF SYMPOS, P13
   Sharma V, 2017, J NETW COMPUT APPL, V97, P79, DOI 10.1016/j.jnca.2017.08.013
   Varshney LR, 2008, IEEE INT SYMP INFO, P1612, DOI 10.1109/ISIT.2008.4595260
   Xu C, 2017, IEEE T WIREL COMMUN, V16, P3561, DOI 10.1109/TWC.2017.2684125
   Yang ZH, 2018, IEEE INTERNET THINGS, V5, P229, DOI 10.1109/JIOT.2017.2778766
   Zhang D, 2016, IEEE INTERNET THINGS, V3, P1346, DOI 10.1109/JIOT.2016.2599852
   Zhang R, 2013, IEEE T WIREL COMMUN, V12, P1989, DOI 10.1109/TWC.2013.031813.120224
   Zhang YY, 2015, IEEE T SIGNAL PROCES, V63, P6200, DOI 10.1109/TSP.2015.2464191
   Zhou X, 2013, IEEE T COMMUN, V61, P4754, DOI 10.1109/TCOMM.2013.13.120855
NR 36
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42041
EP 42055
DI 10.1007/s11042-021-11475-x
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700009
DA 2024-07-18
ER

PT J
AU Ramadan, RA
   Khedr, AY
   Yadav, K
   Alreshidi, EJ
   Sharif, MH
   Azar, AT
   Kamberaj, H
AF Ramadan, Rabie A.
   Khedr, Ahmed Y.
   Yadav, Kusum
   Alreshidi, Eissa Jaber
   Sharif, Md Haidar
   Azar, Ahmad Taher
   Kamberaj, Hiqmet
TI Convolution neural network based automatic localization of landmarks on
   lateral x-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cephalometric analysis; Landmarks; Deep learning; X-ray; Lateral
   cephalogram
ID CEPHALOMETRIC ANALYSIS; SEGMENTATION; RELIABILITY; PHARYNGEAL; ACCURACY
AB Cephalometric analysis is very essential for the patient having dentofacial and craniofacial deformities. The manual localization of the cephalometric landmarks is also important and critical for the observer that is required to be performed by the orthodontics only. The manual localization is the time consuming and the tedious task for the observer. Therefore, we proposes a method to automatically detect cephalometric landmarks on lateral cephalometric x-ray image. The proposed method is a deep learning approach where centroid based registration was performed on the same size images then ResNet50 was applied on the different patches which were made based on the geometrical position of the landmarks. Total ten patches were made for the 19 landmarks. The average landmark detection rate during the testing was achieved as 90.39% and 92.37% under 2-mm and 3-mm error respectively for testset1 database. The average landmark detection rate during the testing was achieved as 82.66% and 84.53% under 2-mm and 3-mm error respectively for testset2 database. The average mean error and standard deviation on testset1 was found as 1.23 mm and 0.73 respectively and average mean error and standard deviation on testset2 was found as 1.37 mm, and 0.88 respectively. The proposed method was compared with the state-of-the-art methods and found the improved results in terms of successful landmark detection rate under 2-mm. The results were found very promising and the proposed method may be helpful to use in clinics further.
C1 [Ramadan, Rabie A.; Khedr, Ahmed Y.; Yadav, Kusum; Alreshidi, Eissa Jaber; Sharif, Md Haidar] Univ Hail, Coll Comp Sci & Engn, Hail 81481, Saudi Arabia.
   [Azar, Ahmad Taher] Benha Univ, Fac Comp & Artificial Intelligence, Banha, Egypt.
   [Kamberaj, Hiqmet] Int Balkan Univ, Dept Comp Engn, Skopje, North Macedonia.
C3 University Ha'il; Egyptian Knowledge Bank (EKB); Benha University
RP Yadav, K (corresponding author), Univ Hail, Coll Comp Sci & Engn, Hail 81481, Saudi Arabia.
EM kusumasyadav0@gmail.com
RI Kamberaj, Hiqmet/B-4529-2014; Ramadan, Rabie/H-9543-2016; Yadav,
   Kusum/AAR-2008-2021; Sharif, Haidar/AAR-6783-2021; Khedr,
   Ahmed/JXN-4885-2024; Azar, Ahmad Taher/O-5566-2014
OI Kamberaj, Hiqmet/0000-0001-7357-7490; Ramadan,
   Rabie/0000-0002-0281-9381; Yadav, Kusum/0000-0002-6658-6839; Sharif,
   Haidar/0000-0001-7235-6004; Khedr, Ahmed/0000-0003-4880-6698; Azar,
   Ahmad Taher/0000-0002-7869-6373
CR Arik SÖ, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.1.014501
   Ashok M, 2021, 2021 INT C ARTIFICIA, P198, DOI [10.1109/ICAIS50930.2021.9396016, DOI 10.1109/ICAIS50930.2021.9396016]
   Ashok M, 2021, ARCH COMPUT METHOD E, V28, P3245, DOI 10.1007/s11831-020-09497-z
   BAUMRIND S, 1980, AM J ORTHOD DENTOFAC, V78, P41, DOI 10.1016/0002-9416(80)90039-1
   BAUMRIND S, 1971, AMER J ORTHODONTICS, V60, P111, DOI 10.1016/0002-9416(71)90028-5
   Berco M, 2009, AM J ORTHOD DENTOFAC, V136, DOI 10.1016/j.ajodo.2008.08.021
   Broadbent B.H., 1931, ANGLE ORTHOD, V1, P45, DOI DOI 10.1043/0003-3219(1931)001<0045:ANXTAI>2.0.CO;2
   Dula Karl, 2014, Swiss Dent J, V124, P1169
   Gupta A., 2020, Int J Comput Vis Robot, V10, P360, DOI [10.1504/IJCVR.2020.108153, DOI 10.1504/IJCVR.2020.108153]
   Gupta A, 2019, US Patent, Patent No. [US10318839B2, 10318839]
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta A, 2017, AM J ORTHOD DENTOFAC, V151, P118, DOI 10.1016/j.ajodo.2016.06.027
   Gupta A, 2016, INT J COMPUT ASS RAD, V11, P1297, DOI 10.1007/s11548-015-1334-7
   Gupta A, 2015, INT J COMPUT ASS RAD, V10, P1737, DOI 10.1007/s11548-015-1173-6
   Halazonetis DJ, 2005, AM J ORTHOD DENTOFAC, V127, P627, DOI 10.1016/j.ajodo.2005.01.004
   Horner K, 2009, DENTOMAXILLOFAC RAD, V38, P187, DOI 10.1259/dmfr/74941012
   Huete MI, 2015, LEGAL MED-TOKYO, V17, P267, DOI 10.1016/j.legalmed.2015.02.001
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Ibragimov B, 2016, COMPUTERIZED CEPHALO
   Kochhar AS, 2021, J CLIN MED, V10, DOI 10.3390/jcm10030535
   Lee H., 2017, CEPHALOMETRIC LANDMA
   Lee JH, 2020, BMC ORAL HEALTH, V20, DOI 10.1186/s12903-020-01256-7
   Lee SM, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab00c9
   Leonardi R, 2008, ANGLE ORTHOD, V78, P145, DOI 10.2319/120506-491.1
   Lindner C, 2016, SCI REP-UK, V6, DOI 10.1038/srep33581
   Makdissi J, 2013, INT ORTHOD, V11, P1, DOI 10.1016/j.ortho.2012.12.011
   Moshiri M, 2007, AM J ORTHOD DENTOFAC, V132, P550, DOI 10.1016/j.ajodo.2006.09.046
   Neelapu BC, 2018, DENTOMAXILLOFAC RAD, V47, DOI 10.1259/dmfr.20170054
   Neelapu BC, 2017, OR SURG OR MED OR PA, V124, P577, DOI 10.1016/j.oooo.2017.08.020
   Neelapu BC, 2017, INT J COMPUT ASS RAD, V12, P1877, DOI 10.1007/s11548-017-1650-1
   Neelapu BC, 2017, SLEEP MED REV, V31, P79, DOI 10.1016/j.smrv.2016.01.007
   Neelapu BC, 2018, US Patent, Patent No. [US10699415B2, 10699415]
   Paula Leonardo Koerich de, 2015, Dental Press J. Orthod., V20, P29, DOI 10.1590/2176-9451.20.2.029-034.oar
   Petrick N, 2013, MED PHYS, V40, DOI 10.1118/1.4816310
   Qian JH, 2019, I S BIOMED IMAGING, P868, DOI [10.1109/ISBI.2019.8759437, 10.1109/isbi.2019.8759437]
   Rossini G, 2011, ANN STOMATOL, V2, P31
   Song Y, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072547
   Wang CW, 2016, MED IMAGE ANAL, V31, P63, DOI 10.1016/j.media.2016.02.004
   Wang SM, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1797502
   Yue WN, 2006, IEEE T BIO-MED ENG, V53, P1615, DOI 10.1109/TBME.2006.876638
NR 40
TC 6
Z9 6
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37403
EP 37415
DI 10.1007/s11042-021-11596-3
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000823376700010
DA 2024-07-18
ER

PT J
AU Goncalves, P
   Correa, G
   Agostini, L
   Porto, M
AF Goncalves, Paulo
   Correa, Guilherme
   Agostini, Luciano
   Porto, Marcelo
TI Learning-based bypass zone search algorithm for fast motion estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Machine learning; Search pattern; Video coding; High
   efficiency video coding
ID MODE DECISION
AB Video coding has been widely explored by academia and industry in recent years, mainly due to the great popularization of video applications and multimedia-capable devices. The Motion Estimation (ME) process receives special attention since it is one of the most complex steps in video coding. The Test Zone Search (TZS) is the main algorithm employed for integer ME in recent video codecs, such as those based on the High Efficiency Video Coding (HEVC), and has been used in the standardization process of the future Versatile Video Coding (VVC) standard. However, even though it is designed as a fast ME algorithm, the computational effort required by TZS is still very high, compromising the encoding process in multimedia-capable devices that operate on limited energy or computational resources. This work presents the Bypass Zone Search (BZS) algorithm, a learning-based solution for fast ME that improves TZS, aiming at a better tradeoff between compression efficiency and computational cost. First, a set of analyses on TZS is presented, which allowed the design of two strategies to reduce the ME computational cost. The first one, named as Learning-based Bypass Motion Estimation (LBME), consists of a machine learning-based approach that predicts whether the best motion vector has already been found and bypasses the remaining ME steps. The second strategy, named as Astroid Raster Pattern (ARP), is a novel search pattern developed for the most complex TZS step, the Raster Search. By combining the two proposed strategies in BZS, the ME processing time is reduced by 60.98% (Random Access) and 63.05% (Low Delay) in comparison to TZS. The overall HEVC encoding time is reduced by 14.32% (Random Access) and 17.64% (Low Delay), with a negligible loss of 0.0837% (Random Access) and 0.04% (Low Delay) in BD-rate.
C1 [Goncalves, Paulo; Correa, Guilherme; Agostini, Luciano; Porto, Marcelo] Fed Univ Pelotas UFPel, Grad Program Comp PPGC, Video Technol Res Grp ViTech, Pelotas, RS, Brazil.
C3 Universidade Federal de Pelotas
RP Correa, G (corresponding author), Fed Univ Pelotas UFPel, Grad Program Comp PPGC, Video Technol Res Grp ViTech, Pelotas, RS, Brazil.
EM phrgoncalves@inf.ufpel.edu.br; gcorrea@inf.ufpel.edu.br;
   agostini@inf.ufpel.edu.br; porto@inf.ufpel.edu.br
OI Correa, Guilherme/0000-0002-2739-6194
FU Brazilian Agency for Scientific and Technological Development (CNPq,
   Brazil); CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior -
   Brasil (CAPES) [001]; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico - Brasil (CNPq); FundacAo de Amparo a Pesquisa do Rio Grande
   do Sul - Brasil (FAPERGS)
FX This work was supported by the Brazilian Agency for Scientific and
   Technological Development (CNPq, Brazil). This research was financed in
   part by the CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior
   - Brasil (CAPES) - Finance code 001, the Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico - Brasil (CNPq), and the
   FundacAo de Amparo a Pesquisa do Rio Grande do Sul - Brasil (FAPERGS).
CR Agarwal PK, 1998, ACM COMPUT SURV, V30, P412, DOI 10.1145/299917.299918
   [Anonymous], VIDEO TECHNOLOGY RES
   [Anonymous], 2014, CISCO VISUAL NETWORK
   [Anonymous], 2020, ISOIECJCT1SC29WG11
   [Anonymous], 1993, MORGAN KAUFMANN SERI
   [Anonymous], 2004, DATA MINING TOOLS SE
   [Anonymous], 2016, Journal of Integrated Circuits and Systems
   [Anonymous], 2010, INT J INFORM TECHNOL
   Belghith F, 2016, J REAL-TIME IMAGE PR, V11, P675, DOI 10.1007/s11554-014-0407-0
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bross B., 2020, JVET-S2001
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Fan R, 2017, IEEE T MULTIMEDIA, V19, P893, DOI 10.1109/TMM.2016.2642786
   Goncalves P., 2019, Journal of Integrated Circuits and Systems, V14, P1
   Goncalves P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1763, DOI 10.1109/ICASSP.2018.8462580
   Gonçalves P, 2017, IEEE INT WORKSH MULT
   Hu N, 2014, IEEE T CIRC SYST VID, V24, P1310, DOI 10.1109/TCSVT.2014.2306035
   ITU Telecommunication Standardization, 2003, ITU T RECOMMENDATION
   ITU-T, 2008, ITU T P910 SUBJECTIV
   Jia LH, 2019, IEEE T MULTIMEDIA, V21, P835, DOI 10.1109/TMM.2018.2866762
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Li N, 2019, J VIS COMMUN IMAGE R, V60, P276, DOI 10.1016/j.jvcir.2019.02.021
   Linck I, 2018, 2018 IEEE 20 INT WOR, P1
   Liu ZY, 2016, J VIS COMMUN IMAGE R, V38, P474, DOI 10.1016/j.jvcir.2016.03.025
   Luo FL, 2019, IEEE T MULTIMEDIA, V21, P851, DOI 10.1109/TMM.2018.2867260
   Nalluri P, 2015, SIGNAL PROCESS-IMAGE, V39, P280, DOI 10.1016/j.image.2015.09.015
   Pakdaman F, 2020, MULTIMED TOOLS APPL, V79, P11639, DOI 10.1007/s11042-019-08593-y
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Sharman K., 2018, AC1100 JCTVC
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   U.V. Group, 2019, ULTR VID GROUP
   Valizadeh S, 2021, MULTIMED TOOLS APPL, V80, P10235, DOI 10.1007/s11042-020-09442-z
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wang Y, 2021, INT C INDOOR POSIT, DOI 10.1109/IPIN51156.2021.9662628
   Zhang Y, 2019, IEEE T CIRCUITS SYST, P1
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 39
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3535
EP 3560
DI 10.1007/s11042-022-13094-6
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000823376500001
DA 2024-07-18
ER

PT J
AU Wang, XH
   Zhai, YX
   Ma, XC
   Zeng, J
   Liang, YC
AF Wang, Xiaohong
   Zhai, Yanxiu
   Ma, Xiangcai
   Zeng, Jing
   Liang, Youci
TI Low-light image enhancement based on GAN with attention mechanism and
   color Constancy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-light image enhancement; GAN; Attention mechanism; Color constancy
AB Images captured in low-light often suffer from severe quality degraded problems, such as low contrast and color distortion, which make it intractable for further computer vision tasks. To solve the problems above, we proposed a trainable parallel network including Brightness Enhancement Module based on GAN and Color Fidelity Module, which are guided by attention mechanism and color constancy respectively. The experimental results show that the proposed method could effectively improve the image contrast and preserve the color. The proposed method performs better than the state-of-the-art image enhancement methods (e. g. GAN based method) for improving the quantitative assessment including PSNR (19.72, up arrow 2.6%), BIQI (71.37, up arrow 1%), CIEDE2000 (4.97, down arrow 52%) and Pearson Correlation Coefficient (0.86, up arrow 105%).
C1 [Wang, Xiaohong; Zhai, Yanxiu; Ma, Xiangcai; Zeng, Jing; Liang, Youci] Univ Shanghai Sci & Technol, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Zhai, YX (corresponding author), Univ Shanghai Sci & Technol, Shanghai 200093, Peoples R China.
EM 1420190127@st.usst.edu.cn
RI zeng, jing/JDW-4350-2023
FU Key Lab of Intelligent and Green Flexographic Printing [ZBKT202108]
FX This work was supported by Key Lab of Intelligent and Green Flexographic
   Printing [grant number ZBKT202108].
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Babu KK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114431
   Baiju PS, 2021, AMBIENT INTELL HUMAN, V13, P903, DOI [10.1007/s12652-021-02947-x, DOI 10.1007/S12652-021-02947-X]
   Brock A., 2018, INT C LEARN REPR
   Cao HY, LASER OPTOELECTRON P, P1
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen QJ, 2021, CHIN J LIQ CRYST DIS, V36, P305, DOI 10.37188/CJLCD.2020-0168
   Cheng YM., 2020, J CHENGDU U INF TECH, V35, P621
   Endo H, 2019, 19 INT S COMMUNICATI
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He W., 2015, COMPUT SCI, V42, P241
   [黄鐄 Huang Huang], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P2149
   Huang HX, 2020, LASER OPTOELECTRON P, V57, DOI 10.3788/LOP57.201004
   Iqbal M, 2020, OPTIK, V209, DOI 10.1016/j.ijleo.2020.164260
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Jia XY., 2019, INFORM TECHNOL INFOR, V2, P107
   Jiang Y, 2020, IEEE ACCESS, V8, P22884, DOI 10.1109/ACCESS.2020.2970169
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jin Yanghua, 2017, ARXIV170805509
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   King DB, 2015, ACS SYM SER, V1214, P1
   Lee H, 2020, IEEE SIGNAL PROC LET, V27, P251, DOI 10.1109/LSP.2020.2965824
   Li Q.Z., 2015, CHIN J LASERS, V42, P272, DOI 10.3788/CJL201542.0209001
   Meng YY, 2019, NEURAL PROCESS LETT, V50, P799, DOI 10.1007/s11063-018-09968-2
   Pang XL., 2020, PLANT MAINT ENG, V18, P76
   Parihar AS, 2017, IEEE T IMAGE PROCESS, V26, P1810, DOI 10.1109/TIP.2017.2665975
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Shi ZH, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0251-4
   Shin YG, 2018, 2018 DIGITAL IMAGE C
   Singh K, 2019, 2019 IEEE INT C SYST
   Suk S, 2018, 2018 INT C PLATFORM, P1, DOI [10.1109/PlatCon.2018.8472743, DOI 10.1109/PLATCON.2018.8472743]
   Sun YH, 2017, IEEE ICC
   Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Wang YF, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P220, DOI 10.1109/SIPROCESS.2018.8600429
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Wei X, 2020, ARXIV ABS200502818
   Xu M, 2021, PROC SPIE, V11720, DOI 10.1117/12.2589358
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang JX., 2021, COMPUT APPL SOFTW, V38, P232
   Zhang N, 2019, 2019 IEEE VISUAL COM, P1
   Zhong ZL, 2020, IEEE T CYBERNETICS, V50, P3318, DOI 10.1109/TCYB.2019.2915094
NR 47
TC 8
Z9 8
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 28
PY 2022
DI 10.1007/s11042-022-13335-8
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2L5FB
UT WOS:000817041500001
DA 2024-07-18
ER

PT J
AU Yang, L
   Song, Q
   Fan, ZM
   Liu, C
   Hu, MJ
AF Yang, Lu
   Song, Qing
   Fan, Zimeng
   Liu, Chun
   Hu, Mengjie
TI Rethinking the activation function in lightweight network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lightweight network; Activation function; Depthwise convolution; Object
   recognition
AB Activation function plays an important role in neural network. Applying activation function in network appropriately can improve accuracy and speed up converging. In this paper, we study the information loss caused by activation function in lightweight network, and discusses how to use activation function with negative value to solve this issue. We propose a method to minimize the changes to the existing network, we only need to replace ReLU with Swish in the appropriate position of lightweight network. We call this method enriching activation. Enriching activation is achieved by utilizing activation functions with negative value in the position where ReLU causes information loss. We also propose a novel activation function called (H)-SwishX for enriching activation, which adds a learnable maximal value to (H)-Swish. (H)-SwishX learns significant maximal value in each layer of network to reduce the accuracy reduction during the lightweight network quantization. We verify this enriching activation scheme on popular lightweight networks. Compared to existing activation schemes adopted by these lightweight networks, we demonstrate performance improvements on CIFAR-10 and ImageNet datasets. We further demonstrate that enriching activation has a good ability for transfer learning, and measure the performance on MSCOCO object detection.
C1 [Yang, Lu; Song, Qing; Fan, Zimeng; Liu, Chun; Hu, Mengjie] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligence Vis Lab, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Song, Q (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligence Vis Lab, Beijing, Peoples R China.
EM soeaver@bupt.edu.cn; priv@bupt.edu.cn; fanzimeng@bupt.edu.cn;
   chun.liu@bupt.edu.cn; mengjie.hu@bupt.edu.cn
RI yang, lu/GLV-5144-2022; Liu, Chun/I-1886-2016
OI Liu, Chun/0000-0002-2834-9461
CR Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008
   Bender G, 2018, INT C MACH LEARN STO, P549
   Cai H, 2019, ARXIV 190809791
   Cai Han, 2019, INT C LEARN REPR
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chu X, 2019, ARXIV 190701845
   Clevert D. A., 2015, FAST ACCURATE DEEP N
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goyal P, 2017, ARXIV 170602677
   Han S, 2015, ARXIV 151000149V3
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2018, ARXIV 180609055
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pham H, 2018, PR MACH LEARN RES, V80
   Prajit R, 2017, ARXIV 171005941
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, ARXIV 180104381
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun G, 2017, ARXIV 170901507
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang M, 2016, ARXIV 160804337
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang L, 2018, ACCV
   Zhang QR, 2019, NEUROCOMPUTING, V323, P37, DOI 10.1016/j.neucom.2018.09.038
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 53
TC 2
Z9 2
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1355
EP 1371
DI 10.1007/s11042-022-13217-z
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000812445100006
DA 2024-07-18
ER

PT J
AU Hatami, E
   Kanan, HR
   Layeghi, K
   Harounabadi, A
AF Hatami, Einolah
   Kanan, Hamidreza Rashidy
   Layeghi, Kamran
   Harounabadi, Ali
TI An optimized robust and invisible digital image watermarking scheme in
   Contourlet domain for protecting rightful ownership
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Contourlet transform (CNT); Singular value
   decomposition (SVD); Multi-objective optimization; False positive
   problem (FPP)
ID SINGULAR-VALUE DECOMPOSITION; PARTICLE SWARM OPTIMIZATION; DISCRETE
   WAVELET TRANSFORM; SVD; DCT; ALGORITHM; DWT; SECURITY; SYSTEM
AB Imperceptibility, robustness, security and capacity are the main features of a digital image-watermarking scheme, and their simultaneous acquisition is a challenging problem. In the recently presented watermarking algorithms, the focus was mainly on increasing robustness against different attacks and the lack of a comprehensive and robust method to these attacks while maintaining acceptable imperceptibility and capacity is evident. By considering the watermarking as a multi-objective problem, this paper presents a new intelligent hybrid method to increase the robustness to a large number of attacks while increasing imperceptibility and embedding capacity. In the proposed algorithm, the cover image is decomposed into the set of non-overlapping blockes and by analyzing the eadge map of each block, the proper blocks are selected and transferred to the frequency domain using Contourlet Transform (CNT). Using the outstanding features of the CNT, i.e. multidirectional and multiresolution, the suitable frequency coefficients are selected which form the feature matrix for the embedding procedure. Then, SVD transform is performed on the feature matrix as well as the watermark image. In addition, to increase the robustness without losing the transparency, the dynamic scaling factors are automatically selected by PSO based on the attack test results, instead of using fixed or manually set the scaling factors. Moreover, to increase the security and solve the False Positive Problem (FPP), which is a common problem in the most SVD-based watermarking techniques, a new method is proposed to increase the partial information of matrix U to the singular values with a security key. Finally, the watermark image is inserted into the cover image based on the obtained optimal values of the scaling factors. The experimental and comparative results in terms of imperceptibility, robustness, capacity and security, demonstrate that our algorithm offers very good imperceptibility with a PSNR value of 57.31 dB and a significant enhancement in robustness against a wide range of geometric and destructive attacks. The proposed scheme also obtains a large capacity and sufficient security. Moreover, the proposed method is free of false positive detection error.
C1 [Hatami, Einolah; Layeghi, Kamran] Islamic Azad Univ, North Tehran Branch, Dept Comp Engn, Tehran, Iran.
   [Kanan, Hamidreza Rashidy] Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
   [Harounabadi, Ali] Islamic Azad Univ, Cent Tehran Branch, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Shahid Rajaee Teacher Training University
   (SRTTU); Islamic Azad University
RP Kanan, HR (corresponding author), Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
EM h.rashidykanan@sru.ac.ir
RI Harounabadi, Ali/KAL-7256-2024
OI Harounabadi, Ali/0000-0003-2382-5120; Rashidy Kanan,
   Hamidreza/0000-0001-8789-8658
CR Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Abdulazeez AM, 2021, Indones J Electr Eng Comput Sci, V21, P1218
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Alshoura WH, 2021, IEEE ACCESS, V9, P32931, DOI 10.1109/ACCESS.2021.3060861
   Altay SY, 2021, MULTIMED TOOLS APPL, V80, P23457, DOI 10.1007/s11042-020-10251-7
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   [Anonymous], USC SIPI IMAGE DATAB
   [Anonymous], 1999, DIGITAL WATERMARKING
   Ansari IA, 2018, INT J SYST ASSUR ENG, V9, P274, DOI 10.1007/s13198-016-0568-2
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Bajaj A, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ENGINEERING AND TECHNOLOGY RESEARCH (ICAETR)
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bartolini F, 2001, P IEEE, V89, P1403, DOI 10.1109/5.959338
   Bentley PJ, 1998, SOFT COMPUTING IN ENGINEERING DESIGN AND MANUFACTURING, P231
   Cayre F, 2005, IEEE T SIGNAL PROCES, V53, P3976, DOI 10.1109/TSP.2005.855418
   Cetinel Gokcen, 2016, International Journal of Image, Graphics and Signal Processing, V8, P58, DOI 10.5815/ijigsp.2016.08.08
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Cheng Mingzhi, 2012, Journal of Multimedia, V8, P299, DOI 10.4304/jmm.8.3.299-305
   Choudhary R, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION CONTROL AND INTELLIGENT SYSTEMS (CCIS), P120, DOI 10.1109/CCIntelS.2016.7878213
   Cox IJ, 2002, EURASIP J APPL SIG P, V2002, P126, DOI 10.1155/S1110865702000525
   Meneses AAD, 2009, PROG NUCL ENERG, V51, P319, DOI 10.1016/j.pnucene.2008.07.002
   Do M., 2003, Studies in Computational Mathematics, V10, P83, DOI DOI 10.1016/S1570-579X(03)80032-0
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Thakkar F, 2021, MULTIMED TOOLS APPL, V80, P12275, DOI 10.1007/s11042-020-10220-0
   Fan D, 2019, MULTIMED TOOLS APPL, V78, P8981, DOI 10.1007/s11042-018-7140-9
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gaur S, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P399, DOI 10.1109/SPIN.2017.8049982
   Gong Mao-Guo, 2009, Journal of Software, V20, P271, DOI 10.3724/SP.J.1001.2009.03483
   homepages, IMAGE LIB
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Jain C, 2008, RELIABLE SVD BASED W
   Jimson N., 2018, INT J ADV RES COMPUT, V9, P540, DOI [10.26483/ijarcs.v9i2.5747, DOI 10.26483/IJARCS.V9I2.5747]
   Kang XB, 2020, SOFT COMPUT, V24, P10561, DOI 10.1007/s00500-019-04563-6
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim WH, 2019, MULTIMED TOOLS APPL, V78, P16887, DOI 10.1007/s11042-018-6879-3
   Kusyk J., 2005, MULTIMED SYST APPL 8, V6015
   Lala H, 2017, Int J Eng Res Technol, V4, P1682
   Liu F, 2015, CHEMOMETR INTELL LAB, V147, P147, DOI 10.1016/j.chemolab.2015.08.015
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha Khaled, 2017, Journal of Electrical Systems and Information Technology, V4, P359, DOI 10.1016/j.jesit.2016.12.011
   Loukhaoukha K, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3327935
   Lu Y, 2003, PROC SPIE, V5207, P655, DOI 10.1117/12.506566
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mehta R, 2020, MULTIMED TOOLS APPL, V79, P18657, DOI 10.1007/s11042-020-08634-x
   Mekarsari Yudit Arum, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P623, DOI 10.1109/ICOIACT.2018.8350793
   Mohan A, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107385
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Najafi E, 2017, MATH SCI, V11, P307, DOI 10.1007/s40096-017-0233-1
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P2653, DOI 10.1007/s11042-013-1577-7
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Prajwalasimha SN., 2019, INDONES J ELECT ENG, V15, P750, DOI [10.11591/ijeecs.v15.i2.pp750-757, DOI 10.11591/IJEECS.V15.I2.PP750-757]
   Rao VSV, 2012, 2012 STUD C ENG SYST, P1
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Salehnia T, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115058
   Sangeetha N, 2018, OPTIK, V160, P380, DOI 10.1016/j.ijleo.2018.01.136
   Saxena V., 2010, International Journal of Computer Applications, V3, P28
   Shaik A, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106923
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2013, LECT NOTES COMPUT SC, V8271, P235, DOI 10.1007/978-3-642-44949-9_22
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh R, 2020, INTELLIGENT WAVELET, P13
   Singh SK, 2009, UKSIM EURO SYMP COMP, P241, DOI 10.1109/EMS.2009.114
   Singh SK, 2011, PERTANIKA J SCI TECH, V19, P229
   Sisaudia V, 2021, MULTIMED TOOLS APPL, V80, P8667, DOI 10.1007/s11042-020-10028-y
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Soppari K, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100287
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Taha DB., 2020, B ELECT ENG INFORM, V9, P1005, DOI DOI 10.11591/EEI.V9I3.1754
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Vali MH, 2018, EXPERT SYST APPL, V114, P296, DOI 10.1016/j.eswa.2018.07.004
   Varghese J, 2016, TURK J ELECTR ENG CO, V24, P3432, DOI 10.3906/elk-1409-12
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Wang XY, 2019, INFORM SCIENCES, V503, P274, DOI 10.1016/j.ins.2019.06.059
   Wu JY, 2020, MULTIMED TOOLS APPL, V79, P22727, DOI 10.1007/s11042-020-08987-3
   Yusof Y, 2007, ICT-MICC: 2007 IEEE INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1 AND 2, PROCEEDINGS, P665
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang YF, 2019, OPTIK, V186, P379, DOI 10.1016/j.ijleo.2019.04.091
   Zhao ZZ, 2018, MULTIMED TOOLS APPL, V77, P14093, DOI 10.1007/s11042-017-5016-z
   Zheng ZG, 2018, FUTURE GENER COMP SY, V88, P92, DOI 10.1016/j.future.2018.05.027
   Zhou AM, 2011, SWARM EVOL COMPUT, V1, P32, DOI 10.1016/j.swevo.2011.03.001
NR 94
TC 5
Z9 6
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2021
EP 2051
DI 10.1007/s11042-022-13197-0
EA JUN 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000811988200001
DA 2024-07-18
ER

PT J
AU Khurana, A
   Mittal, S
   Kumar, D
   Gupta, S
   Gupta, A
AF Khurana, Aayush
   Mittal, Sweta
   Kumar, Deepika
   Gupta, Sonali
   Gupta, Ayushi
TI Tri-integrated convolutional neural network for audio image
   classification using Mel-frequency spectrograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; VGG16; VGG19; TiCNN; Data augmentation
ID EMOTION RECOGNITION; SPEECH; FEATURES
AB Emotion is a state which encompasses a variety of physiological phenomena. Classification of emotions has many applications in fields like customer review, product evaluation, national security, etc., thus making it a prominent area of research. The state-of-art methodologies have used either text or audio files to classify emotions which is in contrast to the proposed work which utilizes the Mel-frequency spectrograms. An integrated methodology TiCNN (Tri integrated Convolutional Neural Network) has been proposed for classifying emotions into eight different classes. Three models namely VGG16, VGG19, and a proposed CNN architecture have been integrated and trained on the RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) dataset. The proposed integrated TiCNN approach classifies emotions into eight different classes with an accuracy of 93.27%. Precision, recall and F1-Score of 0.93, 0.92 and 0.92 have also been used as metrics to evaluate the performance of the proposed model. Further, for model validation, the efficiency and efficacy of the proposed methodology have been compared and analysed with the EMO-DB (Berlin Database of Emotional Speech) dataset. The proposed TiCNN model gives an accuracy of 92.78% on the EMO-DB dataset. Empirical evaluation of the proposed methodology has been compared with conventional transfer learning models and state-of-the-art methodologies, where it has shown its superiority over others.
C1 [Khurana, Aayush; Mittal, Sweta; Kumar, Deepika; Gupta, Sonali; Gupta, Ayushi] Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, New Delhi 110063, India.
RP Kumar, D (corresponding author), Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, New Delhi 110063, India.
EM deepika.kumar@bharatividyapeeth.edu
RI Gupta, Ayushi/JAX-9098-2023; Kumar, Dr. Deepika/G-9148-2015
CR Akyol K, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113239
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Arriaga O., 2017, Real-time Convolutional Neural Networks for Emotion and Gender Classification', P221
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Beard R., 2018, P 22 C COMP NAT LANG, P251
   Bloch S., 1991, International Journal of Psychophysiology, V11, P141154
   Bourbakis, 2010, COGN COMPUT, V3
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Braunschweiler N, 2022, IEEE SIGNAL PROC LET, V29, P722, DOI 10.1109/LSP.2022.3151551
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Byun SW, 2021, MULTIMED TOOLS APPL, V80, P35871, DOI 10.1007/s11042-020-09842-1
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Chatziagapi A, 2019, INTERSPEECH, P171, DOI 10.21437/Interspeech.2019-2561
   Chetouani M, 2009, COGN COMPUT, V1, P194, DOI 10.1007/s12559-009-9016-9
   Cummins N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P478, DOI 10.1145/3123266.3123371
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Esposito A, 2009, COGN COMPUT, V1, P268, DOI 10.1007/s12559-009-9017-8
   Fan YR, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P584, DOI 10.1145/3242969.3264978
   Farooq M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216008
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Flanagan J.L., 2013, Speech analysis synthesis and perception (3˚edicao)
   González G, 2007, I C DATA ENGIN WORKS, P845, DOI 10.1109/ICDEW.2007.4401075
   Goodwin J., 2006, HDB SOCIOLOGY EMOTIO, P611, DOI DOI 10.1007/978-0-387-30715-2_27
   Huang KY, 2019, INT CONF ACOUST SPEE, P5866, DOI 10.1109/ICASSP.2019.8682283
   Hussain M., 2018, ARXIV PREPRINT ARXIV
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jahangir R, 2021, MULTIMED TOOLS APPL, V80, P23745, DOI 10.1007/s11042-020-09874-7
   Jiang PX, 2019, ENG LET, V27, P901
   Jung J.w., 2019, In INTERSPEECH
   Kennedy-Moore E., 2001, EXPRESSING EMOTION M
   Kumar D, 2020, IEEE ACCESS, V8, P142521, DOI 10.1109/ACCESS.2020.3012292
   Kumaran U, 2021, INT J SPEECH TECHNOL, V24, P303, DOI 10.1007/s10772-020-09792-x
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   LEEPER LH, 1995, FOLIA PHONIATR LOGO, V47, P1, DOI 10.1159/000266337
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Li SN, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P589, DOI 10.1145/3340555.3355719
   Likitha MS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2257, DOI 10.1109/WiSPNET.2017.8300161
   Lindblom B, 1996, J ACOUST SOC AM, V99, P1683, DOI 10.1121/1.414691
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Luna-Jiménez C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227665
   Ma F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010527
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Nguyen D, 2017, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2017.140
   Ocquaye ENN, 2021, INT J INTELL SYST, V36, P53, DOI 10.1002/int.22291
   Ouyang, 2017, INT C MULT INT UK GL
   Popova AS, 2018, STUD COMPUT INTELL, V736, P117, DOI 10.1007/978-3-319-66604-4_18
   Rodríguez P, 2018, IMAGE VISION COMPUT, V75, P21, DOI 10.1016/j.imavis.2018.04.004
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Schluter J., 2015, 16 INT SOC MUS INF R, P121
   Schuller B, 2013, COMPUT SPEECH LANG, V27, P4, DOI 10.1016/j.csl.2012.02.005
   Shahin I, 2022, EXPERT SYST APPL, V188, DOI 10.1016/j.eswa.2021.116080
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song P, 2014, IEICE T INF SYST, VE97D, P2530, DOI 10.1587/transinf.2014EDL8038
   Tits, 2018, ARXIV PREPRINT ARXIV
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Venkataramanan, 2019, ARXIV PREPRINT ARXIV
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhang HP, 2020, PATTERN RECOGN LETT, V131, P128, DOI 10.1016/j.patrec.2019.12.013
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang Weinan, 2016, ADV INFORM RETRIEVAL, P45
NR 64
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5521
EP 5546
DI 10.1007/s11042-022-13358-1
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000810859000003
DA 2024-07-18
ER

PT J
AU Garcia-Garcia, JM
   Lozano, MD
   Penichet, VMR
   Law, ELC
AF Maria Garcia-Garcia, Jose
   Dolores Lozano, Maria
   Penichet, Victor M. R.
   Lai-Chong Law, Effie
TI Building a three-level multimodal emotion recognition framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Multimodal detector; Emotion recognition;
   Multimedia aggregator
ID SENTIMENT ANALYSIS; DIMENSIONS; MODELS; GAZE
AB Multimodal emotion detection has been one of the main lines of research in the field of Affective Computing (AC) in recent years. Multimodal detectors aggregate information coming from different channels or modalities to determine what emotion users are expressing with a higher degree of accuracy. However, despite the benefits offered by this kind of detectors, their presence in real implementations is still scarce for various reasons. In this paper, we propose a technology-agnostic framework, HERA, to facilitate the creation of multimodal emotion detectors, offering a tool characterized by its modularity and the interface-based programming approach adopted in its development. HERA (Heterogeneous Emotional Results Aggregator) offers an architecture to integrate different emotion detection services and aggregate their heterogeneous results to produce a final result using a common format. This proposal constitutes a step forward in the development of multimodal detectors, providing an architecture to manage different detectors and fuse the results produced by them in a sensible way. We assessed the validity of the proposal by testing the system with several developers with no previous knowledge about affective technology and emotion detection. The assessment was performed applying the Computer System Usability Questionnaire and the Twelve Cognitive Dimensions Questionnaire, used by The Visual Studio Usability group at Microsoft, obtaining positive results and important feedback for future versions of the system.
C1 [Maria Garcia-Garcia, Jose] Informat Res Inst Albacete, Albacete 02006, Spain.
   [Dolores Lozano, Maria; Penichet, Victor M. R.] Univ Castilla La Mancha, Dept Comp Syst, Albacete 02006, Spain.
   [Lai-Chong Law, Effie] Univ Durham, Dept Comp Sci, Durham DH1 3LE, England.
C3 Universidad de Castilla-La Mancha; Durham University
RP Garcia-Garcia, JM (corresponding author), Informat Res Inst Albacete, Albacete 02006, Spain.
EM Josemaria.garcia@uclm.es; Maria.Lozano@uclm.es; Victor.Penichet@uclm.es;
   lai-chong.law@durham.ac.uk
RI Penichet, Victor M. R./L-5524-2014; Lozano, Maria Dolores/L-6607-2014
OI Penichet, Victor M. R./0000-0003-1125-9344; Lozano, Maria
   Dolores/0000-0003-4069-2112; Garcia-Garcia, Jose
   Maria/0000-0002-2085-8544
FU Ministry of Science, Innovation and Universities (Spain)
   [RTI2018-099942-B-I00, SBPLY/17/180501/000495]; European Regional
   Development Funds (FEDER)
FX This work has been partially supported by the national project granted
   by the Ministry of Science, Innovation and Universities (Spain) with
   reference RTI2018-099942-B-I00 and by the regional project (ref:
   SBPLY/17/180501/000495) granted by the regional government (JCCM) and
   the European Regional Development Funds (FEDER).
CR Al Osman Hussein., 2017, Emotion and Attention Recognition Based on Biological Signals and Images, DOI DOI 10.5772/65683
   Alepis E, 2012, MULTIMED TOOLS APPL, V59, P41, DOI 10.1007/s11042-011-0744-y
   Arroyo I, 2009, FRONT ARTIF INTEL AP, V200, P17, DOI 10.3233/978-1-60750-028-5-17
   Blackwell AF, 2000, P 12 ANN M PSYCH PRO, P137
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cambria E, 2012, MULTIMED TOOLS APPL, V59, P557, DOI 10.1007/s11042-011-0815-0
   Chen J, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P505, DOI 10.1109/CISIS.2013.92
   Chen LS, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P366, DOI 10.1109/AFGR.1998.670976
   Clarke S, 2020, DR DOBBS WORLD SOFTW
   Clarke S, 2003, P 1 JOINT C EASE PPI
   D'Mello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Dai W, 2020, MODALITY TRANSFERABL
   Darekar RV, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3242, DOI 10.1109/ICEEOT.2016.7755303
   De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P332, DOI 10.1109/AFGR.2000.840655
   De Silva LC, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P397, DOI 10.1109/ICICS.1997.647126
   Ekman P., 1999, HDB COGNITION EMOTIO, V98, P16
   Express, 2020, EXPRESS
   Garcia-Garcia JM, 2017, P 18 INT C HUMAN COM, V17, P18
   Garcia-Garcia Jose Maria, HERA SYSTEM 3 LEVEL
   GONZALEZ-BARRERA Julian, 2011, Estudio a Expostulatio Spongiae. Fuego cruzado en el nombre de Lope, P1
   Gonzalez-Sanchez J, 2011, 2011 9TH WORKING IEEE/IFIP CONFERENCE ON SOFTWARE ARCHITECTURE (WICSA), P187, DOI 10.1109/WICSA.2011.32
   Green T. R. G., 1989, People and Computers V. Proceedings of the Fifth Conference of the British Computer Society Human-Computer Interaction Specialist Group, P443
   Green TRG, 1996, J VISUAL LANG COMPUT, V7, P131, DOI 10.1006/jvlc.1996.0009
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   HAUPTMANN AG, 1993, INT J MAN MACH STUD, V38, P231, DOI 10.1006/imms.1993.1011
   Hung JCS, 2017, MULTIMED TOOLS APPL, V76, P18361, DOI 10.1007/s11042-016-4101-z
   Jaiswal S, 2019, MULTIMED TOOLS APPL, V78, P14231, DOI 10.1007/s11042-018-6755-1
   Jaques N, 2014, LECT NOTES COMPUT SC, V8474, P29, DOI 10.1007/978-3-319-07221-0_4
   Jarraya SK, 2021, MULTIMED TOOLS APPL, V80, P83, DOI 10.1007/s11042-020-09451-y
   Khanh TL, 2021, MULTIMED TOOLS APPL, V80, P9479, DOI 10.1007/s11042-020-10106-1
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kolakowska A., 2015, Information Systems Development and Applications, P55
   Kossaifi J, 2021, IEEE T PATTERN ANAL, V43, P1022, DOI 10.1109/TPAMI.2019.2944808
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Landowska A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8020274
   Larson JamesA., 2003, W3C Multimodal Interaction Framework
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P1148, DOI 10.1080/10447318.2017.1418805
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Maat L, 2007, LECT NOTES COMPUT SC, V4451, P251
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Garcia-Garcia JM, 2019, PROCEEDINGS OF THE XX INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION (INTERACCION'2019), DOI 10.1145/3335595.3335639
   Garcia-Garcia JM, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/8751426
   Martin B., 2012, UNIVERSAL METHODS DE, P204
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Mel Fabien, 2019, MULTIMODAL EMOTION R
   Mittal Trisha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14222, DOI 10.1109/CVPR42600.2020.01424
   Myeongjang Pyeon, 2018, IEMO WEB BAS INT MUL
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Oehl M, 2011, LECT NOTES COMPUT SC, V6763, P577, DOI 10.1007/978-3-642-21616-9_65
   Oviatt S. L., 1997, P SIGCHI C HUM FACT
   Pantic M, 2005, PROC 13 ACM INT C MU
   Patwardhan Amol S., 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P139, DOI 10.1109/CESYS.2017.8321250
   PICARD R.W, 1995, M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 321
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Ringeval F, 2015, PATTERN RECOGN LETT, V66, P22, DOI 10.1016/j.patrec.2014.11.007
   Rousidis D, 2020, MULTIMED TOOLS APPL, V79, P6279, DOI 10.1007/s11042-019-08291-9
   Sekhavat YA, 2021, MULTIMED TOOLS APPL, V80, P5225, DOI 10.1007/s11042-020-10006-4
   Sethu V, 2019, AMBIGUOUS WORLD EMOT
   Siriwardhana S, 2020, IEEE ACCESS, V8, P176274, DOI 10.1109/ACCESS.2020.3026823
   W3C, 2014, EM MARK LANG
   Wang ZX, 2020, MULTIMED TOOLS APPL, V79, P35553, DOI 10.1007/s11042-019-08328-z
   Wijayarathna C, 2017, USING COGNITIVE DIME
   Woolf B., 2007, Workshop on Modeling and Scaffolding Affective Experiences to Impact Learning at 13th International Conference on Artificial Intelligence in Education, P6
   Xu C, 2008, FBIE: 2008 INTERNATIONAL SEMINAR ON FUTURE BIOMEDICAL INFORMATION ENGINEERING, PROCEEDINGS, P429, DOI 10.1109/FBIE.2008.52
   Yamauchi T, 2013, INT CONF AFFECT, P399, DOI 10.1109/ACII.2013.72
   Zhang S, 2010, SMART INNOV SYST TEC, V1, P109
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhao SC, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3233184
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zheng WL, 2019, IEEE T CYBERNETICS, V49, P1110, DOI 10.1109/TCYB.2018.2797176
NR 75
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 239
EP 269
DI 10.1007/s11042-022-13254-8
EA JUN 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806706500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Baziyad, M
   Rabie, T
   Kamel, I
   Benkhelifa, M
AF Baziyad, Mohammed
   Rabie, Tamer
   Kamel, Ibrahim
   Benkhelifa, Mahdi
TI Polynomial fitting: enhancing the stego quality of DCT-based
   Steganography schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Discrete Cosine Transform; Capacity; Modeling; Quality;
   Correlation
ID CAPACITY; IMAGES
AB The strong energy compaction property of the Discrete Cosine Transform (DCT) has been widely proposed as a solution to the capacity-quality trade-off problem in steganography. However, several recent steganography schemes did not fully exploit the strong compaction property of the DCT and hide in the whole large region that contains the less significant coefficients. Instead, hiding regions were usually approximated by regular regions, such as squares or rectangles. The reason was justified to reduce the communication overhead required to be sent to the receiver to be able to locate and extract the secret data. For example, for a squared hiding region, the receiver will only need the information of the dimension of the squared hiding area to be able to allocate and extract the secret data. This paper proposes a novel scheme to maximize the region used to hide the secret message, yet keep the communication cost within the required limit. The proposed scheme provides a mathematical model for a control mechanism for trading the communication cost with the stego quality. To reduce the communication cost, the proposed scheme suggests establishing a polynomial curve between the significant and less significant DCT coefficients, and then hide under the curve in the full area of the less significant DCT coefficients. In this case, only the polynomial coefficients are required to be sent to assist the receiver to locate the secret data. In addition to the reasonable communication cost, hiding in the whole area of the less significant coefficients will ensure a smooth transition between the DCT coefficients and the hidden data mimicking the effect of introducing a Gaussian function in the frequency domain which will smooth noisy areas in the stego image. Moreover, to maximize the stego quality, the secret data is embedded by superimposing a scaled-down version of the secret signal on the less significant coefficients instead of the conventional method of replacing the less significant coefficients with the secret data. This hiding procedure ensures maintaining the structure of the less significant DCT coefficients instead of completely removing them. Therefore, the experimental results have proven that the proposed hiding scheme is able to effectively handle the capacity-quality trade-off and achieve superior performance over competitive hiding schemes in terms of the hiding capacity and the stego quality.
C1 [Baziyad, Mohammed; Benkhelifa, Mahdi] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
   [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah
RP Baziyad, M (corresponding author), Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
EM mbaziyad@sharjah.ac.ae; trabie@sharjah.ac.ae; kamel@sharjah.ac.ae;
   U15104594@sharjah.ac.ae
OI Baziyad, Mohammed/0000-0003-0272-2659
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Baziyad Mohammed, 2020, 2020 14th International Conference on Innovations in Information Technology (IIT), P40, DOI 10.1109/IIT50501.2020.9299010
   Baziyad Mohammed, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P791, DOI 10.1109/ICCCA49541.2020.9250849
   Baziyad Mohammed, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1160), P251, DOI 10.1007/978-3-030-45691-7_24
   Baziyad M, 2021, MULTIMED TOOLS APPL, V80, P8611, DOI 10.1007/s11042-020-10008-2
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Biswas R, 2020, MULTIMED TOOLS APPL, V79, P7101, DOI 10.1007/s11042-019-08497-x
   Devi S, 2019, FUTURE GENER COMP SY, V99, P235, DOI 10.1016/j.future.2019.01.047
   Elhadad A, 2021, ALEX ENG J, V60, P2471, DOI 10.1016/j.aej.2020.12.050
   Mukherjee N, 2020, MULTIMED TOOLS APPL, V79, P13449, DOI 10.1007/s11042-019-08178-9
   Grajeda-Marín IR, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600108
   Khari M, 2020, IEEE T SYST MAN CY-S, V50, P73, DOI 10.1109/TSMC.2019.2903785
   Mandavifar S, 2019, NEUROCOMPUTING, V347, P149, DOI 10.1016/j.neucom.2019.02.056
   Mohamed N, 2020, MULTIMED TOOLS APPL, V79, P25089, DOI 10.1007/s11042-020-09129-5
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Ostertagová E, 2012, PROCEDIA ENGINEER, V48, P500, DOI 10.1016/j.proeng.2012.09.545
   Rabie T, 2019, INT C COMM SIG PROC, P1
   Rabie T, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620500425
   Rabie T, 2019, IEEE ACCESS, V7, P21948, DOI 10.1109/ACCESS.2019.2898838
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063001
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
NR 28
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43999
EP 44019
DI 10.1007/s11042-022-13004-w
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000803780600001
DA 2024-07-18
ER

PT J
AU Zoraghchian, AA
   Sohrabi, MK
   Yaghmaee, F
AF Zoraghchian, Ali Abbas
   Sohrabi, Mohammad Karim
   Yaghmaee, Farzin
TI Parallel frequent itemsets mining using distributed graphic processing
   units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frequent itemset mining; Apriori; GPGPU; Distributed architecture; CUDA
ID PATTERNS; ALGORITHM; CUDA
AB Data mining is an essential technique in knowledge discovery which is widely used for pattern extraction and information classification. Extracting useful rules and knowledge by considering the relationships and association of the data is as an important data mining technique used for data analysis, called association rule mining (ARM). Several scans of the dataset are necessary to extract frequent patterns and association rules during a time-consuming process. Discovery of frequent patterns within data is the major phase of the ARM process, which is very expensive in terms of execution times. Powerful parallel systems with multiple graphics processing units (GPUs) and multiple general-purpose graphics processing units (GPGPUs) are appropriate choices to reduce the execution time. Although GPU architectures can speed up the mining process, a single GPU is usually unable to use a large amount of data to extract frequent patterns. It is therefore necessary to use multiple GPU processors on a system or distribute them within a network to improve the efficiency of parallelization. In this paper, multiple GPUs are parallelized to propose a new framework, called GPApbmp, for parallelization of the Apriori algorithm, which is a well-known level-wise frequent pattern mining method, for faster extraction of association rules. The proposed framework uses multiple GPUs, on which the dataset is distributed to reduce the execution time and the number of database scans in the Apriori method using a vertical approach. The experimental results on standard datasets show that the proposed method reduces the execution time speeds up the mining process. The results obtained from two and four parallelized NVidia GeForce 710 processors evaluated in CUDA.
C1 [Zoraghchian, Ali Abbas; Sohrabi, Mohammad Karim; Yaghmaee, Farzin] Islamic Azad Univ, Dept Comp Engn, Semnan Branch, Semnan, Iran.
   [Yaghmaee, Farzin] Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
C3 Islamic Azad University; Semnan University
RP Sohrabi, MK (corresponding author), Islamic Azad Univ, Dept Comp Engn, Semnan Branch, Semnan, Iran.
EM Zaliabbass@yahoo.com; Amir_sohraby@aut.ac.ir; F_yaghmaee@semnan.ac.ir
RI Sohrabi, Mohammad Karim/AAD-8618-2019
OI Sohrabi, Mohammad Karim/0000-0001-8066-0356
CR Abdelaal AA, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114530
   Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Agrawal R., 1994, Proceedings of the 20th international conference on very large data bases (VLDB94). Morgan Kaufmann, P487499
   Ahamed AKC, 2017, ADV ENG SOFTW, V111, P32, DOI 10.1016/j.advengsoft.2016.10.002
   AvadheshPratapSingh, 2015, PROCEDIA COMPUT SCI, V48, P5, DOI 10.1016/j.procs.2015.04.103
   Bagnall A, 2017, DATA MIN KNOWL DISC, V31, P606, DOI 10.1007/s10618-016-0483-9
   Baralis E, 2009, IEEE T KNOWL DATA EN, V21, P493, DOI 10.1109/TKDE.2008.180
   Bustio-Martínez L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3472289
   CHENG J., 2014, Professional CUDA c Programming
   Chon KW, 2018, INFORM SCIENCES, V439, P19, DOI 10.1016/j.ins.2018.01.046
   D'Angelo G, 2017, SOFT COMPUT, V21, P6297, DOI 10.1007/s00500-016-2183-1
   Davashi R, 2021, INFORM SCIENCES, V564, P1, DOI 10.1016/j.ins.2021.02.067
   Deng ZH, 2016, APPL SOFT COMPUT, V41, P214, DOI 10.1016/j.asoc.2016.01.010
   Deng ZH, 2015, EXPERT SYST APPL, V42, P5424, DOI 10.1016/j.eswa.2015.03.004
   Deng ZH, 2014, EXPERT SYST APPL, V41, P4505, DOI 10.1016/j.eswa.2014.01.025
   Deng ZH, 2012, SCI CHINA INFORM SCI, V55, P2008, DOI 10.1007/s11432-012-4638-z
   Deng ZH, 2010, INT J COMPUT INT SYS, V3, P733
   DJENOURI Y, 2017, INT C GEN EV COMP, P59
   Djenouri Y, 2019, INFORM SCIENCES, V496, P363, DOI 10.1016/j.ins.2018.07.020
   Djenouri Y, 2019, INTELL DATA ANAL, V23, P57, DOI 10.3233/IDA-173785
   Djenouri Y, 2017, INFORM SCIENCES, V420, P1, DOI 10.1016/j.ins.2017.08.043
   Djenouri Y, 2017, EUROMICRO WORKSHOP P, P262, DOI 10.1109/PDP.2017.16
   Djenouri Y, 2015, J SUPERCOMPUT, V71, P1318, DOI 10.1007/s11227-014-1366-8
   Djenouri Y, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P401, DOI 10.1109/SOCPAR.2014.7008040
   Han J, 2012, MOR KAUF D, P1
   Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83
   Hosseinabady M, 2019, ARXIV PREPRINT ARXIV
   Hung CL, 2015, COMPUT BIOL CHEM, V58, P62, DOI 10.1016/j.compbiolchem.2015.05.004
   Jiang H, 2017, ITM WEB CONF, V12, DOI 10.1051/itmconf/20171203046
   Jiawei Han, 2000, SIGMOD Record, V29, P1, DOI 10.1145/335191.335372
   Jong Soo Park, 1995, SIGMOD Record, V24, P175, DOI 10.1145/568271.223813
   Kalaiselvi T., 2017, Informatics in Medicine Unlocked, V9, P133, DOI 10.1016/j.imu.2017.08.001
   Kalivarapu V, 2015, STRUCT MULTIDISCIP O, V51, P1281, DOI 10.1007/s00158-014-1215-7
   Kalra M, 2018, INFORM COMMUNICATION, P61, DOI DOI 10.1007/978-981-10-3920-1_7
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   Lee H, 2015, INFORM SCIENCES, V315, P56, DOI 10.1016/j.ins.2015.04.016
   Li CY, 2020, MULTIMED TOOLS APPL, V79, P16771, DOI 10.1007/s11042-019-08361-y
   Mordvanyuk N, 2021, VERTTIRP ROBUST EFFI, V168
   Pavithra A., 2018, DATA MINING KNOWL EN, V10, P74
   Roberge V, 2017, IEEE T SMART GRID, V8, P1689, DOI 10.1109/TSG.2015.2502066
   Sohrabi MK, 2014, 6 INT C GRAPH IM PRO
   Sohrabi MK, 2018, ENTERP INF SYST-UK, V12, P674, DOI 10.1080/17517575.2017.1405286
   Sohrabi MK, 2018, J CHIN INST ENG, V41, P229, DOI 10.1080/02533839.2018.1454853
   Sohrabi MK, 2016, 2016 4TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P186, DOI 10.1109/ISCBI.2016.7743281
   Sohrabi MK, 2013, KNOWL-BASED SYST, V37, P462, DOI 10.1016/j.knosys.2012.09.005
   TIWARY M, 2014, 2014 INT C HIGH PERF
   Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134
   Zhang F, 2011, IEEE INT C CL COMP, P590, DOI 10.1109/CLUSTER.2011.61
   Zoraghchian AA, 2021, CLUSTER COMPUT, V24, P3767, DOI 10.1007/s10586-021-03369-2
   US
NR 50
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43873
EP 43895
DI 10.1007/s11042-022-13225-z
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802134900002
DA 2024-07-18
ER

PT J
AU Chandra, S
   Kumar, V
AF Chandra, Subhash
   Kumar, Vinay
TI A novel approach to validate online signature using dynamic features
   based on locally weighted learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomertic; Signature verification; Locally Weighted Learning (LWL);
   False Acceptance Rate (FAR); False Rejection Rate (FRR)
ID FEATURE-EXTRACTION; VERIFICATION
AB Online signature verification is most popular in the field of biometrics and forensics. Due to its popularity and recent demand, the major challenges are to improve its performance and complexity. This paper presents a novel approach for online signature validation based on local weight learning. The different features like, x coordinate, y coordinates time stamp, pen up and down, azimuth, height, pressure, displacement, velocity and acceleration are extracted from online signature. The extracted features are then passed to locally weighted learning classifier algorithms. Our experimentation is performed on local weight learning classifier of a machine learning method. Locally weighted learning classifier is experimentally found to be effective having False acceptance rate and False rejection rate as 1.18 and 0.02, respectively. The proposed methods gives better performance when compared with other well-known existing models for online signature verification. This result demonstrates that the method is suitable for a real-time system.The popular SVC2004 dataset is used in the experiments, which confirms the effectiveness of the proposed method in simultaneously achieving lower false positive and false negative rate.
C1 [Chandra, Subhash] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Kumar, Vinay] Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; National Institute of Technology (NIT System);
   National Institute of Technology Jamshedpur
RP Chandra, S (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM subhash.cs@nitp.ac.in; vkumar.cse@nitjsr.ac.in
RI Chandra, Subhash/JAX-6130-2023
OI Chandra, Subhash/0000-0001-7710-4375
CR [Anonymous], 2014, INT J DARSHAN I ENG
   Chan S, 2021, NEPHROLOGY, V26, P471, DOI 10.1111/nep.13853
   Chandra S, 2020, NEURAL COMPUT APPL, V32, P11875, DOI 10.1007/s00521-019-04669-w
   Diaz M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3274658
   Englert P., 2012, Seminar Class on Autonomous Learning Systems, V1, P1
   Ferrer MA, 2013, INT CONF BIOMETR
   Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012
   Hafs T, 2016, IET BIOMETRICS, V5, P190, DOI 10.1049/iet-bmt.2014.0041
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Kumar MM, 2014, IET BIOMETRICS, V3, P347, DOI 10.1049/iet-bmt.2014.0024
   Okawa M, 2019, IEEE ACCESS, V7, P81010, DOI 10.1109/ACCESS.2019.2923093
   Oliveira LS, 2007, 2007 INT JOINT C NEU
   Parziale A, 2019, PATTERN RECOGN LETT, V121, P113, DOI 10.1016/j.patrec.2018.07.029
   Pramanik R, 2020, IET IMAGE PROCESS, V14, P959, DOI 10.1049/iet-ipr.2019.0208
   Riesen K, 2019, INT J DOC ANAL RECOG, V22, P41, DOI 10.1007/s10032-019-00316-1
   Schaal S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P288, DOI 10.1109/ROBOT.2000.844072
   Schneider J, 2000, LOCALLY WEIGHTED LEA, V149
   Shuai M, 2008, P 16 ACM SIGSPATIAL, P14
   Tan H, MULTIMED TOOLS APPL, P1
   Vorugunti CS, 2020, NEUROCOMPUTING, V409, P157, DOI 10.1016/j.neucom.2020.05.072
   Xiao W, 2019, 2018 INTERNATIONAL WORKSHOP ON ADVANCES IN SOCIAL SCIENCES (IWASS 2018), P1103, DOI [10.1109/ICDAR.2019.00179, 10.25236/iwass.2018.239]
   Yahyatabar ME, 2015, ONLINE SIGNATURE VER
   Yahyatabar ME, 2017, IET BIOMETRICS, V6, P393, DOI 10.1049/iet-bmt.2016.0103
   Yang L, 2018, SOFT COMPUT, V22, P7811, DOI 10.1007/s00500-018-3477-2
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
NR 25
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40959
EP 40976
DI 10.1007/s11042-022-13159-6
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177800002
DA 2024-07-18
ER

PT J
AU Toffa, OK
   Mignotte, M
AF Toffa, O. K.
   Mignotte, M.
TI Dataset and semantic based-approach for image sonification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sonification; Visually impaired; Touch screen; Image accessibility;
   Auditory feedback
AB This paper presents an image-audio dataset and a mid-level image sonification system that strives to help visually impaired users understand the semantic content of an image and access visual information via a combination of semantic audio and an easily decodable audio generated in real time, both triggered by sliding, taping, holding actions when the users explore the image on a touch screen or with a pointer. Firstly, we segmented the original image using a label fusion model and based on the user position in the image, a sonified signal is generated using musical notes and meaningful visual information within the active region like the color and the luminance, then the gradient and the texture. Secondly, we integrated the semantic understanding of the image into our model using DeepLab semantic segmentation of the image and created a dataset of audio and images aligned on the 20 classes of the PASCAL VOC 2012 dataset. The dataset of images are organized based on color, gradient, texture for low-level sonification and on semantic content with sounds for mid-level sonification. Thirdly, in order to provide both types of information in a complementary way, the slide, tap and hold actions of a touch screen are incorporated in the model. The semantic audio providing a brief description of the visual object is played on slide action, the generated signal with color details of the object on the tap action, gradient and texture of the object on hold action. Finally, we validated our sonification model on the provided dataset during a pilot study and the subjects were generally able to identify the objects in the image, the color of the objects and even provide a general description of the scene of the image. Our system could be useful to visually impaired persons in a photo sharing application using a smartphone or for painting art description in a digital museum.
C1 [Toffa, O. K.; Mignotte, M.] Univ Montreal, Dept Informat & Rech Operat DIRO, Vis Lab, Montreal, PQ H3C 3J7, Canada.
   [Toffa, O. K.; Mignotte, M.] Univ Montreal, Fac Arts & Sci, Montreal, PQ H3C 3J7, Canada.
C3 Universite de Montreal; Universite de Montreal
RP Toffa, OK (corresponding author), Univ Montreal, Dept Informat & Rech Operat DIRO, Vis Lab, Montreal, PQ H3C 3J7, Canada.; Toffa, OK (corresponding author), Univ Montreal, Fac Arts & Sci, Montreal, PQ H3C 3J7, Canada.
EM ohini.kafui.toffa@umontreal.ca; mignotte@iro.umontreal.ca
RI Mignotte, Max/F-7014-2015
OI Toffa, ohini kafui/0000-0002-6646-6001
CR Balakrishnan G., 2008, INT J INF CONTROL CO, V2, P1
   Banf M, 2016, J REHABIL ASSIST TER, V3
   Banf Michael, 2013, Fourth International Conference on Augmented Human, P162, DOI [10.1145/2459236.2459264, DOI 10.1145/2459236.2459264]
   Bartolome JI, 2019, TEI'19: PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P383, DOI 10.1145/3294109.3300994
   Capp M, 2000, ENG SCI EDUC J, V9, P137, DOI 10.1049/esej:20000306
   Cavaco S., 2013, Procedia Technology, V9, P1048, DOI DOI 10.1016/J.PROTCY.2013.12.117
   Chidester B., 2013, 2013 IEEE INT C MULT, P1, DOI DOI 10.1109/ICMEW.2013.6618381
   Chu S, 2009, IEEE T AUDIO SPEECH, P17
   Degara N, 2015, IEEE MULTIMEDIA, V22, P20, DOI 10.1109/MMUL.2015.8
   Dubus G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082491
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Götzelmann T, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3186894
   Goudarzi V, 2015, IEEE MULTIMEDIA, V22, P41, DOI 10.1109/MMUL.2015.4
   Ivan K, 2008, P INT C CONV HYBR IN
   Kwon N, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P600, DOI 10.1145/3308561.3354620
   Le Cun Y., 2015, DEEP LEARNING NATURE, V521, P444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Martin D, 2001, P 8 INT C COMP VIS, V2
   Martins ACG, 2001, J ELECTRON IMAGING, V10, P690, DOI 10.1117/1.1382811
   Matta S, 2004, ISCCSP : 2004 FIRST INTERNATIONAL SYMPOSIUM ON CONTROL, COMMUNICATIONS AND SIGNAL PROCESSING, P431
   MEIJER PBL, 1992, IEEE T BIO-MED ENG, V39, P112, DOI 10.1109/10.121642
   Mignotte M, 2014, INFORM FUSION, V20, P7, DOI 10.1016/j.inffus.2013.10.012
   Morris MR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173633
   Munshell AH, 1912, AM J PSYCHOL, V23, P236, DOI 10.2307/1412843
   Oh U, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080953
   Quero LC, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P346, DOI 10.1145/3234695.3241033
   Rodrigues JB, 2019, ADV INTELL SYST, V793, P243, DOI 10.1007/978-3-319-94196-7_23
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schaffert N, 2015, IEEE MULTIMEDIA, V22, P58, DOI 10.1109/MMUL.2015.9
   Sudol Jeremi, 2010, Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2010.5543725
   Tajadura-Jiménez A, 2015, IEEE MULTIMEDIA, V22, P48, DOI 10.1109/MMUL.2015.14
   Toffa OK, 2021, IEEE T MULTIMEDIA, V23, P706, DOI 10.1109/TMM.2020.2987710
   Winters RM, 2019, ERGON DES, V27, P11, DOI 10.1177/1064804618788098
   Wobbrock J.O., 2013, Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility, page, P1, DOI DOI 10.1145/2513383.2513442
   Wu Xiaoying., 2008, Multimedia and Expo, 2008 IEEE International Conference on, P1345, DOI DOI 10.1109/ICME.2008.4607692
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yeo WS, 2006, P INT C DIG AUD EFF, P309
   Yoshida Tsubasa., 2011, P 2 AUGMENTED HUMAN, P11, DOI DOI 10.1145/1959826.1959837
   Zhao Y, 2017, PROC ACM HUM COMPUT
NR 38
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1505
EP 1518
DI 10.1007/s11042-022-12914-z
EA MAY 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000790129700003
DA 2024-07-18
ER

PT J
AU Rai, M
   Goyal, S
AF Rai, Manish
   Goyal, Sachin
TI A hybrid digital image watermarking technique based on fuzzy-BPNN and
   shark smell optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark embedding; Watermark extraction; Optimization; Neural network;
   Fuzzy; Digital image
ID ALGORITHM; SECURE; SVD
AB Digital Image Watermarking (DIW) has recently gained attention due to the increase in copyright issues. The robustness, imperceptibility, and security in the prevailing techniques are not efficient because of the poor selection of embedding parameters. Therefore, we make use of the benefits from some techniques like Human Visual System (HVS), Fuzzy Inference Systems (FIS), Back Propagation Neural Network (BPNN), and Shark Smell Optimization (SSO) to develop a robust as well as secure watermarking system. HVS helps to identify the areas with noise that may not be identified by the human eye. Therefore, by using this technique, the information can be made invisible to the human eye by adjusting the values of the pixel. The FIS and BPNN are then used to get the weight factor. Moreover, the introduction of the SSO algorithm helps to attain the ideal embedding parameter. The SSO is adopted based on the hunting behavior of the shark. Sharks have the capability to identify the prey very quickly even in large search spaces. This makes the shark a superior hunter. Therefore, the SSO can obtain optimal embedding parameters compared to other existing techniques such as Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC) optimization, etc. At the end of this process, the watermarked image will be obtained. The attacks are then applied to the watermarked images and finally, the watermark extraction process takes place in which the watermarks are extracted from the attacked image. The conducted performance analysis reveals that the proposed hybrid Fuzzy-BPNN with SSO approach outperforms other recent techniques.
C1 [Rai, Manish] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Dept Comp Sci & Engn, Bhopal, India.
   [Goyal, Sachin] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Dept Informat Technol, Bhopal, Madhya Pradesh, India.
C3 Rajiv Gandhi Technological University; Rajiv Gandhi Technological
   University
RP Rai, M (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Dept Comp Sci & Engn, Bhopal, India.
EM manishrai2587@gmail.com; sachingoyal@rgtu.net
RI rai, MANISH/JJC-5324-2023
OI rai, MANISH/0000-0003-0531-4386
CR Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Bao ZK, 2020, J AMB INTEL HUM COMP, V11, P1889, DOI 10.1007/s12652-019-01345-8
   Dai Q., 2019, INNOVATION MED HEALT, V145, P93, DOI [10.1007/978-981-13-8566-7_9, DOI 10.1007/978-981-13-8566-7_9/COVER]
   El Houby EMF, 2020, MULTIMED TOOLS APPL, V79, P28453, DOI 10.1007/s11042-020-09333-3
   LEE HM, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P1583, DOI 10.1109/ICNN.1994.374392
   Majumder S, 2010, COMM COM INF SC, V70, P1
   Mehta R, 2020, MULTIMED TOOLS APPL, V79, P18657, DOI 10.1007/s11042-020-08634-x
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P997, DOI 10.1007/s10044-017-0613-z
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Naseem MT, 2019, MULTIMED TOOLS APPL, V78, P7691, DOI 10.1007/s11042-018-6501-8
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Quan Y, 2020, IEEE T NEURAL NETW L
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Thakkar FN, 2019, MULTIDIM SYST SIGN P, V30, P1769, DOI 10.1007/s11045-018-0627-8
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Wang SQ, 2019, OPT LASER ENG, V114, P76, DOI 10.1016/j.optlaseng.2018.10.014
   Wang XY, 2020, PATTERN ANAL APPL, V23, P933, DOI 10.1007/s10044-019-00828-w
   Yang JL, 2019, LECT NOTES COMPUT SC, V11983, P263, DOI 10.1007/978-3-030-37352-8_23
   Yuan ZH, 2021, VISUAL COMPUT, V37, P1867, DOI 10.1007/s00371-020-01945-y
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
NR 23
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39471
EP 39489
DI 10.1007/s11042-022-12712-7
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000010
DA 2024-07-18
ER

PT J
AU Kaur, J
   Singh, W
AF Kaur, Jaskirat
   Singh, Williamjeet
TI Tools, techniques, datasets and application areas for object detection
   in an image: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computer vision; Object detection; Dataset; Deep learning
ID REMOTE-SENSING IMAGES; CONVOLUTIONAL NEURAL-NETWORK; TRAFFIC SIGN
   DETECTION; VEHICLE DETECTION; TARGET DETECTION; TEXT DETECTION;
   RECOGNITION; MULTISCALE; SYSTEM; CHALLENGE
AB Object detection is one of the most fundamental and challenging tasks to locate objects in images and videos. Over the past, it has gained much attention to do more research on computer vision tasks such as object classification, counting of objects, and object monitoring. This study provides a detailed literature review focusing on object detection and discusses the object detection techniques. A systematic review has been followed to summarize the current research work's findings and discuss seven research questions related to object detection. Our contribution to the current research work is (i) analysis of traditional, two-stage, one-stage object detection techniques, (ii) Dataset preparation and available standard dataset, (iii) Annotation tools, and (iv) performance evaluation metrics. In addition, a comparative analysis has been performed and analyzed that the proposed techniques are different in their architecture, optimization function, and training strategies. With the remarkable success of deep neural networks in object detection, the performance of the detectors has improved. Various research challenges and future directions for object detection also has been discussed in this research paper.
C1 [Kaur, Jaskirat] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
   [Singh, Williamjeet] Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Punjabi University; Punjabi University
RP Kaur, J (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
EM jaskirat.scholar21@gmail.com; williamjeet@gmail.com
OI Kaur, Jaskirat/0000-0001-8819-7327
CR Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   Alam A, 2020, INT J INTELL TRANSP, V18, P98, DOI 10.1007/s13177-019-00178-1
   Sánchez JA, 2017, PROC INT CONF DOC, P1383, DOI 10.1109/ICDAR.2017.226
   Sánchez JA, 2015, PROC INT CONF DOC, P1166, DOI 10.1109/ICDAR.2015.7333944
   [Anonymous], 2009, MM 09 P 2009 ACM MUL, DOI DOI 10.1145/1631272.1631456
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298803
   Bach M, 2018, IEEE INT C INTELL TR, P851, DOI 10.1109/ITSC.2018.8569522
   Banerjee K, 2018, IEEE INT VEH SYM, P1632, DOI 10.1109/IVS.2018.8500699
   BECKER BC, 2008, 2008 8 IEEE INT C AU, P1
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Bhandari A, 2021, DISABIL REHABIL-ASSI, V16, P280, DOI 10.1080/17483107.2019.1673834
   Bhangale Ujwala, 2020, Procedia Computer Science, V171, P770, DOI 10.1016/j.procs.2020.04.084
   Bin Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163158
   Bouras C, 2022, 36TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2022), P62, DOI 10.1109/ICOIN53446.2022.9687212
   Bouti A, 2020, SOFT COMPUT, V24, P6721, DOI 10.1007/s00500-019-04307-6
   Braun M, 2019, IEEE T PATTERN ANAL, V41, P1844, DOI 10.1109/TPAMI.2019.2897684
   Bui Thanh Hung, 2021, Research in Intelligent and Computing in Engineering. Select Proceedings of RICE 2020. Advances in Intelligent Systems and Computing (AISC 1254), P715, DOI 10.1007/978-981-15-7527-3_67
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Chatterjee S, 2020, P A I C C AUT ROBOT, P202, DOI [10.1109/iccar49639.2020.9108054, 10.1109/ICCAR49639.2020.9108054]
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YD, 2021, INT C PATT RECOG, P850, DOI 10.1109/ICPR48806.2021.9412258
   Chen Z, 2021, INT J COMPUT VISION, V129, P1121, DOI 10.1007/s11263-020-01412-0
   Chen ZY, 2021, CAN J REMOTE SENS, V47, P83, DOI 10.1080/07038992.2021.1894915
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dam, 2019, US GEOLOGICAL SURVEY
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   de Charette R, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P333, DOI 10.1109/IROS.2009.5353941
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dominguez-Sanchez A, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110301
   Du FK, 2020, EVOL APPL, V13, P2377, DOI 10.1111/eva.13030
   Dutta Abhishek, 2019, MM '19: Proceedings of the 27th ACM International Conference on Multimedia, P2276, DOI 10.1145/3343031.3350535
   Ertler C, 2019, COMPUT VIS PATTERN R, P1
   Everingham M, 2006, LECT NOTES ARTIF INT, V3944, P117
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fengxin Li, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P130, DOI 10.1007/978-3-030-64221-1_12
   Fregin A, 2018, IEEE INT CONF ROBOT, P3376
   Fu C. -Y., Dssd: Deconvolutional single shot detector, DOI DOI 10.1109/CVPR.2016.90
   Fu JY, 2020, MULTIMED TOOLS APPL, V79, P12615, DOI 10.1007/s11042-019-08523-y
   Fu K, 2020, ISPRS J PHOTOGRAMM, V161, P294, DOI 10.1016/j.isprsjprs.2020.01.025
   Fu MY, 2010, INT C WAVEL ANAL PAT, P119, DOI 10.1109/ICWAPR.2010.5576425
   Gawande U, 2022, APPL INTELL, V52, P10398, DOI 10.1007/s10489-021-03073-z
   Ge Z, 2021, NEUROCOMPUTING, V462, P272, DOI 10.1016/j.neucom.2021.07.094
   Geiger A., 2012, CVPR
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   De Oliveira BAG, 2018, IEEE ACCESS, V6, P8714, DOI 10.1109/ACCESS.2018.2801813
   Grosicki E, 2011, PROC INT CONF DOC, P1459, DOI 10.1109/ICDAR.2011.290
   Guo ZX, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108063
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hadid A, 2007, 2007 FIRST ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P96
   Halaschek WC, 2005, POSTER TRACK 4 INT S, P2
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He WH, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107026
   Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Hua X, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106495
   Huang QY, 2021, IEEE ACCESS, V9, P21777, DOI 10.1109/ACCESS.2021.3055243
   Hung Goon Li, 2020, SN Comp. Sci., V1, P1
   I-Kuei Chen, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P412, DOI 10.1109/ICCE.2014.6776063
   Irbaz Mohammad Sabik, 2022, Proceedings of the International Conference on Big Data, IoT, and Machine Learning: BIM 2021. Lecture Notes on Data Engineering and Communications Technologies (95), P153, DOI 10.1007/978-981-16-6636-0_13
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jakob J, 2020, ACTA POLYTECH HUNG, V17, P125
   Jamiya SS, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165818
   Jamtsho Y, 2021, ICT EXPRESS, V7, P104, DOI 10.1016/j.icte.2020.07.008
   Jin Y, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107846
   Jinda Hu, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P1, DOI 10.1109/ICIVC50857.2020.9177438
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karatzas D, 2011, PROC INT CONF DOC, P1485, DOI 10.1109/ICDAR.2011.295
   Kaur RP, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03687-8
   Khurana K., 2013, Int J Adv Res Comput Eng Technol (IJARCET), V2, P1383
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar R, 2014, IEEE AS PAC WORLD C, P2, DOI [10.13140/2.1.4379.2165, DOI 10.13140/2.1.4379.2165]
   Kuznetsova Anna, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P233, DOI 10.1007/978-3-030-64221-1_20
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lam Darius, 2018, xview: Objects in context in overhead imagery
   Lamba PS, 2020, SOFT COMPUT, V24, P16829, DOI 10.1007/s00500-020-04979-5
   Laroca R, 2021, IET INTELL TRANSP SY, V15, P483, DOI 10.1049/itr2.12030
   Li CY, 2020, NEUROCOMPUTING, V415, P411, DOI 10.1016/j.neucom.2020.05.108
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li QP, 2019, IEEE T GEOSCI REMOTE, V57, P5028, DOI 10.1109/TGRS.2019.2895362
   Liao JJ, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-021-00056-3
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2022, INT J REMOTE SENS, V43, P270, DOI 10.1080/01431161.2021.2018146
   Liu ZK, 2016, IEEE GEOSCI REMOTE S, V13, P1074, DOI 10.1109/LGRS.2016.2565705
   Lu WX, 2019, PROC CVPR IEEE, P6382, DOI 10.1109/CVPR.2019.00655
   Lu XC, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3052575
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Lv X, MICROPROCESSORS
   Ma CX, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107684
   Madani Mehdi., 2011, P 2011 INT ACM WORKS, P13, DOI [10.1145/2072652.2072656, DOI 10.1145/2072652.2072656]
   Maeda H, 2021, COMPUT-AIDED CIV INF, V36, P47, DOI 10.1111/mice.12561
   Mahmoud HAH, 2021, PERS UBIQUIT COMPUT, V25, P129, DOI 10.1007/s00779-020-01419-x
   Manikandan NS, 2019, DEEP LEARNING BASED
   Masita Katleho L., 2022, Proceedings of Sixth International Congress on Information and Communication Technology: ICICT 2021. Lecture Notes in Networks and Systems (216), P1, DOI 10.1007/978-981-16-1781-2_1
   Mathias Markus, 2013, The 2013 International Joint Conference on Neural Networks (IJCNN), DOI 10.1109/IJCNN.2013.6707049
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Mehedi Shamrat F. M. Javed, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P760, DOI 10.1109/ICOEI51242.2021.9452896
   Mehta R, 2019, LECT NOTES COMPUT SC, V11133, P659, DOI 10.1007/978-3-030-11021-5_41
   Mei X, 2015, IEEE T NEUR NET LEAR, V26, P2874, DOI 10.1109/TNNLS.2015.2399233
   Melnyk P, 2020, SOFT COMPUT, V24, P7977, DOI 10.1007/s00500-019-04083-3
   Merkulova IY, 2019, IFAC PAPERSONLINE, V52, P79, DOI 10.1016/j.ifacol.2019.08.128
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Murdock M, 2015, PROC INT CONF DOC, P1171, DOI 10.1109/ICDAR.2015.7333945
   Nada H, 2018, INT CONF BIOMETR THE
   Naiemi F, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114549
   Nayagam MG., 2015, Int J Appl Eng Res, V10, P8290
   Nepal U, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020464
   Neumann L, 2019, LECT NOTES COMPUT SC, V11361, P691, DOI 10.1007/978-3-030-20887-5_43
   Nguyen CC., 2019, J COMPUT SCI CYBERN, V35, P135, DOI [10.15625/1813-9663/35/2/13315, DOI 10.15625/1813-9663/35/2/13315]
   Nguyen ND, 2020, J ELECTR COMPUT ENG, V2020, DOI 10.1155/2020/3189691
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Ogura R, 2020, ELECTR COMMUN JPN, V103, P35, DOI 10.1002/ecj.12268
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pattewar T., 2019, INT RES J ENG TECHNO, V06, P231
   Qian R, 2021, A SURVEY, V14, P1
   Qin SX, 2022, NEURAL COMPUT APPL, V34, P21551, DOI 10.1007/s00521-021-06147-8
   Rahman Md Mahfujur, 2021, Proceedings of International Conference on Trends in Computational and Cognitive Engineering. Proceedings of TCCE 2020. Advances in Intelligent Systems and Computing (AISC 1309), P581, DOI 10.1007/978-981-33-4673-4_47
   Ravishankar V, 2022, SENSOR INTEGRATION F, P759, DOI DOI 10.1007/978-981-16-6407-6_65
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Saathoff C, 2008, P SAMT, P1
   Sai Srinath Namburi Gnvv Satya, 2020, Procedia Computer Science, V171, P207, DOI 10.1016/j.procs.2020.04.022
   Santra S, 2019, 2019 INTERNATIONAL CONFERENCE ON OPTO-ELECTRONICS AND APPLIED OPTICS (OPTRONIX 2019), DOI 10.1109/optronix.2019.8862323
   Schöller FET, 2019, IFAC PAPERSONLINE, V52, P64, DOI 10.1016/j.ifacol.2019.12.284
   Setta Showmik, 2022, Data Management, Analytics and Innovation: Proceedings of ICDMAI 2021. Lecture Notes on Data Engineering and Communications Technologies (71), P505, DOI 10.1007/978-981-16-2937-2_32
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shao S, 2019, IEEE I CONF COMP VIS, P8429, DOI 10.1109/ICCV.2019.00852
   Shao ZC, 2021, IEEE T COMMUN, V69, P3423, DOI 10.1109/TCOMM.2021.3059303
   Sharma N, 2015, PROC INT CONF DOC, P1196, DOI 10.1109/ICDAR.2015.7333950
   SHASHIRANGANA J, INT J INTELL SYST, P1
   Shi Y, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2019.102740
   Song XB, 2019, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2019.00560
   Sudha D, 2020, SOFT COMPUT, V24, P17417, DOI 10.1007/s00500-020-05042-z
   Sun F, 2021, EUR J REMOTE SENS, V54, P102, DOI 10.1080/22797254.2021.1880975
   Sun P, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104036
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   Susanto, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON ENGINEERING TECHNOLOGY AND APPLICATIONS (IES-ETA), P146, DOI 10.1109/ELECSYM.2017.8240393
   Suzuki T, 2020, IEEJ T ELECTR ELECTR, V15, P1448, DOI 10.1002/tee.23215
   Tamilselvi M, 2022, ALEX ENG J, V61, P4307, DOI 10.1016/j.aej.2021.09.043
   Tanner F, 2009, P IEEE APPL IM PATT, P1, DOI DOI 10.1109/AIPR.2009.5466304
   Tarchoun B, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP'2020), DOI 10.1109/atsip49331.2020.9231712
   Tian ZZ, 2020, REMOTE SENS LETT, V11, P416, DOI 10.1080/2150704X.2020.1722330
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017
   Tran P., 2021, The 19th International Conference on Computer Analysis of Images and Patterns (CAIP), P252
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tzutalin Rflynn, 2018, LabelImg
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Varma S, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P299, DOI 10.1109/RAICS.2013.6745491
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   VENNELAKANTI A, 2019, 2019 IEEE INT C CONS, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   VoTT, 2019, VOTT VIS OBJ TAGG TO
   Wang GQ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3064599
   Wang HY, 2022, EUR J REMOTE SENS, V55, P71, DOI 10.1080/22797254.2021.2018944
   Wang JH, 2019, CHIN CONTR CONF, P8507, DOI [10.23919/chicc.2019.8865157, 10.23919/ChiCC.2019.8865157]
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wei X, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107195
   Wong A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P95, DOI 10.1109/CRV.2018.00023
   Wu JJ, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108214
   Wu JL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2012, DOI 10.1145/3394171.3413634
   Wu KJ, 2021, IEEE ACCESS, V9, P113889, DOI 10.1109/ACCESS.2021.3103522
   Wu SX, 2018, INT SYM COMPUT INTEL, P280, DOI 10.1109/ISCID.2018.00070
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xu BB, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106675
   Xu H, 2022, IEEE T INTELL TRANSP, V23, P19760, DOI 10.1109/TITS.2021.3137253
   Xue CH, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108494
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yifan Lu, 2018, Computational Visual Media, V4, P253, DOI 10.1007/s41095-018-0116-x
   Yipeng Sun, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1557, DOI 10.1109/ICDAR.2019.00250
   Yuan L, 2018, INT CONF MACH LEARN, P115, DOI 10.1109/ICMLC.2018.8526987
   Yucel MK, 2018, WILDEST FACES FACE D
   Yuliang L, 2017, DETECTING CURVE TEXT
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zakria, 2022, IEEE J-STARS, V15, P1039, DOI 10.1109/JSTARS.2022.3140776
   Zhang H, 2019, MULTIMED TOOLS APPL, V78, P27809, DOI 10.1007/s11042-019-07898-2
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang LB, 2021, IEEE T GEOSCI REMOTE, V59, P9682, DOI 10.1109/TGRS.2020.3045708
   Zhang X, 2022, NEUROCOMPUTING, V468, P384, DOI 10.1016/j.neucom.2021.10.068
   Zhao XL, 2021, INT J REMOTE SENS, V42, P5754, DOI 10.1080/01431161.2021.1931537
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zheng Huang, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1516, DOI 10.1109/ICDAR.2019.00244
   Zhou J, 2019, IN ASIAN C MACHINE L, P912
   Zhu HG, 2015, IEEE IMAGE PROC, P3735, DOI 10.1109/ICIP.2015.7351502
   Zhu YH, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104023
   Zhu YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107336
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 218
TC 31
Z9 31
U1 94
U2 511
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38297
EP 38351
DI 10.1007/s11042-022-13153-y
EA APR 2022
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000786824400001
PM 35493415
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Bajpai, S
AF Bajpai, Shrish
TI Low complexity block tree coding for hyperspectral image sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossy hyperspectral image compression; Wavelet transform; Computational
   complexity; Zero block cube tree
ID COMPRESSION; LOSSLESS; SPIHT
AB Complexity of any onboard hyperspectral image sensor is a challenging issue. The existing hyperspectral image compression algorithm plays a great role in reducing the data transmission bandwidth, data processing time, processing power and coding memory. Many wavelet transform-based set partitioned hyperspectral image compression algorithms are proposed in the past which work with lossy and lossless compression. These compression algorithms use lists or state tables to keep track of significant and insignificant sets or coefficients. The 3D wavelet block tree coding (3D-WBTC) has superior coding performance due to the exploitation of the inter sub-band & intra sub-band redundancy. The 3D-Low-Complexity Block Tree Coding (3D-LCBTC) is a novel implementation of 3D-WBTC which uses two state tables and very small size link lists. The 3D-LCBTC uses depth-first search approach which reduces the complexity of the compression process significantly. Thus, the proposed compression algorithm is a suitable candidate for resources-constrained onboard hyperspectral image sensors.
C1 [Bajpai, Shrish] Integral Univ, Fac Engn, Elect & Commun Engn, Lucknow, Uttar Pradesh, India.
C3 Integral University
RP Bajpai, S (corresponding author), Integral Univ, Fac Engn, Elect & Commun Engn, Lucknow, Uttar Pradesh, India.
EM shrishbajpai@gmail.com
RI Bajpai, Shrish/GPC-4732-2022
OI Bajpai, Shrish/0000-0001-5598-1940
CR Achard V, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13051020
   Anand R, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1808, DOI 10.1109/ICACCI.2017.8126107
   Bairagi V. K., 2013, Journal of the Institution of Engineers (India) Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V94, P135, DOI 10.1007/s40031-013-0049-9
   Baisantry M, 2021, J INDIAN SOC REMOTE, V49, P843, DOI 10.1007/s12524-020-01262-w
   Bajpai S., 2019, INT J INNOVATIVE TEC, V8, P64
   Bajpai S., 2019, INDONESIAN J ELECT E, V15, P1001, DOI [10.11591/ijeecs.v15.i2.pp1001-1008, DOI 10.11591/IJEECS.V15.I2.PP1001-1008]
   Bajpai S, 2022, MULTIMED TOOLS APPL, V81, P841, DOI 10.1007/s11042-021-11456-0
   Bajpai S, 2019, MULTIMED TOOLS APPL, V78, P27193, DOI 10.1007/s11042-019-07797-6
   Bajpai S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P97, DOI 10.1109/MSPCT.2017.8363982
   Bajpai Shrish, 2020, LOW MEMORY WAVELET B, V11, P25, DOI [10.34218/IJEET.11.6.2020.003, DOI 10.34218/IJEET.11.6.2020.003]
   Báscones D, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162563
   Báscones D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060907
   Bhardwaj R, 2021, J AMB INTEL HUM COMP, V12, P2915, DOI 10.1007/s12652-020-02449-2
   Bhardwaj R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023017
   Bilgin A, 2000, APPL OPTICS, V39, P1799, DOI 10.1364/AO.39.001799
   Boettcher JB, 2007, INT GEOSCI REMOTE SE, P1033, DOI 10.1109/IGARSS.2007.4422977
   Chen Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3110769
   Cheng KJ, 2014, IEEE T GEOSCI REMOTE, V52, P5765, DOI 10.1109/TGRS.2013.2292366
   Cheng TK, 2021, IEEE J-STARS, V14, P1872, DOI 10.1109/JSTARS.2021.3049843
   Christophe E, 2008, IEEE T IMAGE PROCESS, V17, P2334, DOI 10.1109/TIP.2008.2005824
   Chutia D, 2016, T GIS, V20, P463, DOI 10.1111/tgis.12164
   Coic L, 2021, ANAL CHIM ACTA, V1155, DOI 10.1016/j.aca.2021.338361
   Das S, 2021, IET IMAGE PROCESS, V15, P964, DOI 10.1049/ipr2.12077
   Datta A, 2017, IEEE GEOSCI REMOTE S, V14, P82, DOI 10.1109/LGRS.2016.2628078
   Dmitriev EV, 2018, OPTOELECTRON INSTRUM, V54, P213, DOI 10.3103/S8756699018030019
   Dragotti PL, 2000, IEEE T GEOSCI REMOTE, V38, P416, DOI 10.1109/36.823937
   Dua Y, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116255
   Dua Y, 2021, J PARALLEL DISTR COM, V150, P60, DOI 10.1016/j.jpdc.2020.12.004
   Dua Y, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.9.090902
   Dussarrat P, 2021, ATMOSPHERIC MEASUREM, P1, DOI [10.5194/amt-2021-121, DOI 10.5194/AMT-2021-121]
   Gnutti A, 2021, MULTIDIM SYST SIGN P, V32, P791, DOI 10.1007/s11045-020-00753-w
   Goetz AFH, 2009, REMOTE SENS ENVIRON, V113, pS5, DOI 10.1016/j.rse.2007.12.014
   Gross W, 2021, PROC SPIE, V11865, DOI 10.1117/12.2597991
   Hou Y, 2007, PROC SPIE, V6790, DOI 10.1117/12.750975
   Hou Y, 2008, 2008 INTERNATIONAL WORKSHOP ON EARTH OBSERVATION AND REMOTE SENSING APPLICATIONS, P106
   Jiang ZC, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060038
   Karami A, 2010, 2010 2 INT C IM PROC, P122, DOI [10.1109/IPTA.2010.5586739, DOI 10.1109/IPTA.2010.5586739]
   Kidwai NR, 2016, IEEE SENS J, V16, P2575, DOI 10.1109/JSEN.2016.2519600
   Kumar RS, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101862
   Lee HS, 2002, INT GEOSCI REMOTE SE, P3317, DOI 10.1109/IGARSS.2002.1027168
   Li R, 2019, MULTIMED TOOLS APPL, V78, P11701, DOI 10.1007/s11042-018-6724-8
   Liu RN, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3100407
   Liu RM, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/9962057
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Medus LD, 2021, FOOD CONTROL, V125, DOI 10.1016/j.foodcont.2021.107962
   Mishra MK, 2019, CURR SCI INDIA, V116, P1089, DOI 10.18520/cs/v116/i7/1089-1100
   Mitran T, 2021, J INDIAN SOC REMOTE, V49, P2611, DOI 10.1007/s12524-021-01415-5
   Miyoshi GT, 2018, INT J REMOTE SENS, V39, P4910, DOI 10.1080/01431161.2018.1425570
   Mohan BK, 2015, CURR SCI INDIA, V108, P833
   Morales A, 2014, INT CARN CONF SECU
   Nagendran R, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S021969131941008X
   Ngadiran R., 2010, IEEE INT C COMP COMM, P1, DOI [10.1109/ICCCE.2010.5556843, DOI 10.1109/ICCCE.2010.5556843]
   Pan W, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1237, DOI 10.1109/ISKE.2008.4731119
   Paul A, 2022, MULTIMED TOOLS APPL, V81, P2529, DOI 10.1007/s11042-021-11689-z
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   Penna B, 2006, INT GEOSCI REMOTE SE, P3525, DOI 10.1109/IGARSS.2006.904
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Raikwar SC, 2022, MULTIMED TOOLS APPL, V81, P5349, DOI 10.1007/s11042-021-11752-9
   Ramakrishnan D, 2015, CURR SCI INDIA, V108, P879
   Ren W., 2018, NEURIPS, P297
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Saha S., 2021, ISPRS Ann. Photogramm. Remote Sens. Spat. Inf. Sci, V3, P311, DOI [10.5194/isprs-annals-V-3-2021-311-2021, DOI 10.5194/ISPRS-ANNALS-V-3-2021-311-2021]
   Sahoo RN, 2015, CURR SCI INDIA, V108, P848
   Sharma D, 2020, IETE TECH REV, V37, P36, DOI 10.1080/02564602.2018.1557569
   Sharma D, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.7.076102
   Subrahmanyam KV, 2020, IETE TECH REV, V37, P211, DOI 10.1080/02564602.2019.1593890
   Sudha VK, 2013, J SCI IND RES INDIA, V72, P735
   Sujitha B, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3976
   Tang X, 2006, HYPERSPECTRAL DATA COMPRESSION, P273, DOI 10.1007/0-387-28600-4_10
   Tang XL, 2004, IEEE IMAGE PROC, P3283
   Tausif M, 2015, IEEE SENS J, V15, P6218, DOI 10.1109/JSEN.2015.2456332
   Uddin MP, 2021, IETE TECH REV, V38, P377, DOI 10.1080/02564602.2020.1740615
   UmaMaheswari S, 2021, J AMB INTEL HUM COMP, V12, P4127, DOI 10.1007/s12652-020-01792-8
   Valsesia D, 2017, IEEE GEOSCI REMOTE S, V14, P394, DOI 10.1109/LGRS.2016.2644726
   Vura Swetha, 2023, Materials Today: Proceedings, P2193, DOI 10.1016/j.matpr.2021.06.175
   Wang XH, 2018, J INDIAN SOC REMOTE, V46, P667, DOI 10.1007/s12524-017-0735-1
   Wildenstein D, 2021, 2021 IEEE INT C EL C, P1, DOI 10.1/CONECCT52877.2021.9622585
   Wu JJ, 2006, OPT ENG, V45, DOI 10.1117/1.2173996
   Ying Hou, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P963, DOI 10.1109/CSSE.2008.1351
   Zhang LF, 2015, NEUROCOMPUTING, V147, P358, DOI 10.1016/j.neucom.2014.06.052
   Zikiou N, 2020, VISUAL COMPUT, V36, P1473, DOI 10.1007/s00371-019-01753-z
NR 81
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33205
EP 33232
DI 10.1007/s11042-022-13057-x
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000783091400004
DA 2024-07-18
ER

PT J
AU Salma, W
   Eltrass, AS
AF Salma, Wessam
   Eltrass, Ahmed S.
TI Automated deep learning approach for classification of malignant
   melanoma and benign skin lesions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
ID SEGMENTATION; IMPLEMENTATION
AB Skin cancer becomes a significant health problem worldwide with an increasing incidence over the past decades. Due to the fine-grained differences in the appearance of skin lesions, it is very challenging to develop an automated system for benign-malignant classification through images. This paper proposes a novel automated Computer Aided Diagnosis (CAD) system for skin lesion classification with high classification performance using accuracy low computational complexity. A pre-processing step based on morphological filtering is employed for hair removal and artifacts removal. Skin lesions are segmented automatically using Grab-cut with minimal human interaction in HSV color space. Image processing techniques are investigated for an automatic implementation of the ABCD (asymmetry, border irregularity. color and dermoscopic patterns) rule to separate malignant melanoma from benign lesions. To classify skin lesions into benign or malignant, different pretrained convolutional neural networks (CNNs), including VGG-16, ResNet50, ResNetX, InceptionV3, and MobileNet are examined. The average 5-fold cross validation results show that ResNet50 architecture combined with Support Vector Machine (SVM) achieve the best performance. The results also show the effectiveness of data augmentation in both training and testing with achieving better performance than obtaining new images. The proposed diagnosis framework is applied to real clinical skin lesions, and the experimental results reveal the superior performance of the proposed framework over other recent techniques in terms of area under the ROC curve 99.52%, accuracy 99.87%, sensitivity 98.87%, precision 98.77%, F1-score 97.83%, and consumed time 3.2 s. This reveals that the proposed framework can he utilized to help medical practitioners in classifying different skin lesions.
C1 [Salma, Wessam] Pharos Univ, Fac Engn, Basic Sci Dept, Alexandria, Egypt.
   [Eltrass, Ahmed S.] Alexandria Univ, Fac Engn, Elect Engn Dept, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Pharos University in Alexandria; Egyptian
   Knowledge Bank (EKB); Alexandria University
RP Eltrass, AS (corresponding author), Alexandria Univ, Fac Engn, Elect Engn Dept, Alexandria, Egypt.
EM Wessam.salama@pua.edu.eg; ahmed.eltrass@alexu.edu.eg
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abbas Q, 2016, COMPUTERS, V5, DOI 10.3390/computers5030013
   Albahar MA, 2019, IEEE ACCESS, V7, P38306, DOI 10.1109/ACCESS.2019.2906241
   [Anonymous], 2018, Revista Brasileira de Cancerologia, V64, P119, DOI DOI 10.32635/2176-9745.RBC.2018V64N1.115
   [Anonymous], 2019, CVPR
   [Anonymous], 2017, arXiv preprint arXiv:1703.03108
   Brinker TJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11936
   Chen BL, 2019, ANAL CHEM, V91, P10640, DOI 10.1021/acs.analchem.9b01866
   Dalila F, 2017, OPTIK, V140, P749, DOI 10.1016/j.ijleo.2017.04.084
   Demyanov S, 2016, I S BIOMED IMAGING, P364, DOI 10.1109/ISBI.2016.7493284
   Eltrass AS, 2020, IET IMAGE PROCESS, V14, P495, DOI 10.1049/iet-ipr.2018.5953
   Feng XJ, 2019, SIGNAL IMAGE VIDEO P, V13, P959, DOI 10.1007/s11760-019-01433-4
   Garnavi R, 2012, IEEE T INF TECHNOL B, V16, P1239, DOI 10.1109/TITB.2012.2212282
   Hardie R.C., 2018, ARXIV PREPRINT ARXIV
   Hastie T., 2009, The Elements of Statistical Learning
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hopkins ZH, 2019, AM J HEALTH PROMOT, V33, P611, DOI 10.1177/0890117118811754
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   K. Inc, 2019, SKIN CANC MNIST HAM1
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Li YB, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P311, DOI 10.1109/ICIVC.2018.8492818
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Majtner T, 2016, INT CONF IMAG PROC, DOI 10.1109/IPTA.2016.7821017
   Marcot BG, 2021, COMPUTATION STAT, V36, P2009, DOI 10.1007/s00180-020-00999-9
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Monisha M, 2019, CLUSTER COMPUT, V22, P12897, DOI 10.1007/s10586-018-1798-7
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perez F, 2018, LECT NOTES COMPUT SC, V11041, P303, DOI 10.1007/978-3-030-01201-4_33
   Ramezani Maryam, 2014, J Med Signals Sens, V4, P281
   Rembielak A, 2019, CLIN ONCOL-UK, V31, P735, DOI 10.1016/j.clon.2019.08.013
   Salama MS, 2018, IEEE INT SYM MED MEA, P526
   SERRA J, 1994, SIGNAL PROCESS, V38, P3, DOI 10.1016/0165-1684(94)90052-3
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   STONE M, 1977, J R STAT SOC B, V39, P44, DOI 10.1111/j.2517-6161.1977.tb01603.x
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Thanh DNH, 2020, J DIGIT IMAGING, V33, P574, DOI 10.1007/s10278-019-00316-x
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Tschandl P, 2019, LANCET ONCOL, V20, P938, DOI 10.1016/S1470-2045(19)30333-X
   Vasconcelos CN, 2020, PATTERN RECOGN LETT, V139, P95, DOI 10.1016/j.patrec.2017.11.005
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Yoshida T, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3439, DOI 10.1109/BigData.2016.7841005
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   Zhang C, 2020, MULTIMED TOOLS APPL, V79, P7049, DOI 10.1007/s11042-019-08210-y
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
   Zhang XQ, 2018, J MED IMAG HEALTH IN, V8, P1408, DOI 10.1166/jmihi.2018.2448
NR 53
TC 13
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32643
EP 32660
DI 10.1007/s11042-022-13081-x
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000782551600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Jia, N
   Zheng, CJ
   Sun, W
AF Jia, Ning
   Zheng, Chunjun
   Sun, Wei
TI A multimodal emotion recognition model integrating speech, video and
   MoCAP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial motion speech emotion recognition; Dual spectrograms; 3D
   convolutional neural networks; The attention mechanism; Long short-term
   memory
ID NETWORK
AB As one of the core technologies in the field of human-computer interaction, emotion recognition focuses on the simulation of human emotion perception and understanding process. Emotion recognition is widely used in medical, education, life, transportation and other fields. At present, the emotion recognition is still a challenging topic. The accuracy of emotion recognition in multimodal is discussed, different emotion features are extracted from speech, video and motion capture (MoCAP) by using deep learning methods, and a matching emotion recognition model called facial motion speech emotion recognition (FM-SER) model is designed. Local and global information of speech, dual spectrograms are designed in audio mode to choose the time-domain and frequency-domain information, and convolutional neural networks (CNN), gated recurrent unit (GRU) and attention models are used to realize speech emotion recognition. A 3D CNN model based on attention mechanism is used in the video mode to capture the potential emotional expression. The sequential features of hand and head movements are extracted from MoCAP, and import into a bidirectional three-layer long short-term memory (LSTM) model with the attention mechanism. Based on the complementary relationship between multimodal, the decision level integrating scheme is designed with higher-precision, stronger generalization ability of emotion recognition. Through a lot of experiments, we compared the results of several popular emotion recognition models on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) corpus. The results showed that the proposed method had higher recognition accuracies in single modality and multimodal, and the average accuracies of one modality and multimodal were improved by 16.3% and 9%. The effectiveness of FM-SER model in emotion recognition was proved.
C1 [Jia, Ning; Zheng, Chunjun; Sun, Wei] Dalian Neusoft Univ Informat, Sch Software, Dalian, Peoples R China.
   [Zheng, Chunjun] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Jia, N (corresponding author), Dalian Neusoft Univ Informat, Sch Software, Dalian, Peoples R China.
EM jianing@neusoft.edu.cn
RI jia, ning/ABB-9496-2021
FU Liaoning Province Key Laboratory for the Application Research of Big
   Data; Dalian Science and Technology Star Project [2019RQ120];
   Intercollegiate cooperation projects of Liaoning Provincial Department
   of Education [86896244]
FX This paper was funded by the Liaoning Province Key Laboratory for the
   Application Research of Big Data, the Dalian Science and Technology Star
   Project, grant number 2019RQ120, and the Intercollegiate cooperation
   projects of Liaoning Provincial Department of Education, grant number
   86896244.
CR Ahmed F, 2020, IEEE ACCESS, V8, P11761, DOI 10.1109/ACCESS.2019.2963113
   Ajili I, 2019, VISUAL COMPUT, V35, P1411, DOI 10.1007/s00371-018-01619-w
   Bertero D., 2016, P 2016 C EMP METH NA, P1042, DOI DOI 10.18653/V1/D16-1110
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Ding I Jr, 2022, MICROSYST TECHNOL, V28, P403, DOI 10.1007/s00542-020-04868-9
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2594
   Huang L, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420560108
   Jiahui PAN., 2020, CAAI T INTELL SYST, V15, P1
   Kan W., 2020, J PHYS C SER, V1607, DOI 10.1088/1742-6596/1607/1/012107
   Latif S, 2019, INTERSPEECH, P3920, DOI 10.21437/Interspeech.2019-3252
   Li J, 2019, INT J HUM ROBOT, V16, DOI 10.1142/S0219843619410020
   Lin M, 2019, 2019 3 INT C
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Mohammed SN., 2020, INT J INTELL ENG SYS, V13, P257
   Nie WZ, 2021, MULTIMED TOOLS APPL, V80, P16205, DOI 10.1007/s11042-020-08796-8
   Pan Z., 2020, INTERSPEECH 2020
   Poria S, 2018, IEEE INTELL SYST, V33, P17, DOI 10.1109/MIS.2018.2882362
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Ramanarayanan V, PROC IWSDS 2018 INT, V2018
   Ren MJ, 2019, VIS INFORM, V3, P150, DOI 10.1016/j.visinf.2019.10.003
   Sahu G, 2019, Multimodal Speech Emotion Recognition and Ambiguity Resolution
   Salama ES, 2021, EGYPT INFORM J, V22, P167, DOI 10.1016/j.eij.2020.07.005
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Tripathi S., 2018, Multi-modal emotion recognition on iemocap with neural networks
   Wang WY, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2738221
   Wu S., 2019, 2019 15 INT WIRELESS
   Xu Y, 2020, SOFT COMPUT, V24, P5971, DOI 10.1007/s00500-019-04530-1
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zhang L., 2018, INT C NEURAL INFORM
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 31
TC 8
Z9 9
U1 4
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32265
EP 32286
DI 10.1007/s11042-022-13091-9
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600001
DA 2024-07-18
ER

PT J
AU Rajput, NK
   Grover, BA
AF Rajput, Nikhil Kumar
   Grover, Bhavya Ahuja
TI A multi-label movie genre classification scheme based on the movie's
   subtitles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-label classification; Movie genre prediction; Movie subtitles;
   K-Nearest neighbour; Neural networks
AB Prediction of movie genres is an intriguing problem that has several applications in designing recommendation systems for the audiences, analyzing movie box office performance and understanding the theme of the movie to list some. This is a classic multi-label classification problem. An algorithm for movie genre detection has been proposed built on the yet unused movie's subtitles which are a documented account of the movie's visual content and dialogues. The basic idea is to identify words that have high frequency in a particular genre and use them as features for training the classification machine learning models. The performance of the algorithm was tested on English subtitles of 964 movies of six genres: Action, Fantasy, Horror, Romance, Sports and War. Experiments were conducted with varied number of features and six machine learning models. The best result was obtained using K-Nearest Neighbour (kNN) with the average precision for all genres being 77.7% with 200 features. Another noteworthy result was an average precision of 75.2% using kNN with merely 50 features. The algorithm performed very well for the genres: Sports and War with above 90% precision in some cases.
C1 [Rajput, Nikhil Kumar; Grover, Bhavya Ahuja] Univ Delhi, Dept Comp Sci, Ramanujan Coll, New Delhi, India.
C3 University of Delhi
RP Grover, BA (corresponding author), Univ Delhi, Dept Comp Sci, Ramanujan Coll, New Delhi, India.
EM n.rajput@ramanujan.du.ac.in; b.ahuja@ramanujan.du.ac.in
CR [Anonymous], 2010, Proceedings of the 18th International Conference on Multimedea, DOI [DOI 10.1145/1873951.1874068, 10.1145/1873951.1874068]
   Austin A, 2010, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2010.5495763
   BHATTACHARYYA R, 2009, THESIS U WOLVERHAMPT, P1
   Choi SM, 2012, EXPERT SYST APPL, V39, P8079, DOI 10.1016/j.eswa.2012.01.132
   Chu W. -T., 2017, MUSA2 2017 PROC WORK, P39, DOI DOI 10.1145/3132515.3132516
   Ding DW, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P603
   Doshi P, 2018, LECT NOTES ARTIF INT, V11171, P117, DOI 10.1007/978-3-030-00810-9_11
   Doudpota SM, 2013, INFORM PROCESS MANAG, V49, P529, DOI 10.1016/j.ipm.2012.09.005
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337
   Han Y, 2017, APPL COMPUT REV, V17, P36, DOI 10.1145/3131080.3131084
   Hong HZ, 2015, LECT NOTES COMPUT SC, V9132, P159, DOI 10.1007/978-3-319-20248-8_14
   Hwang TG, 2016, MULTIMED TOOLS APPL, V75, P12843, DOI 10.1007/s11042-016-3526-8
   Irie G, 2010, IEEE T MULTIMEDIA, V12, P523, DOI 10.1109/TMM.2010.2051871
   Ivasic-Kos M, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1198, DOI 10.1109/MIPRO.2014.6859750
   Kaimann D, 2013, CTR INT EC WORKING P, P2011
   Kim KR, 2012, MULTIMED TOOLS APPL, V61, P87, DOI 10.1007/s11042-011-0728-y
   Pais G, 2012, 2012 10 INT WORKSH C, P1
   Rasheed Z, 2002, INT C PATT RECOG, P1086, DOI 10.1109/ICPR.2002.1048494
   Saumya S, 2018, ADV INTELL SYST, V666, P167, DOI 10.1007/978-981-10-8180-4_11
   ScikitLearn, SELECTKBEST
   Shon JH, 2012, DISSECTING MOVIE GEN
   Sirattanajakarin S, 2019, ACM INT C PROC SERIE, P23, DOI [10.1145/3348445.3348475, DOI 10.1145/3348445.3348475]
   Ul Haq I, 2019, COMPLEXITY, DOI 10.1155/2019/3581419
   Ul Haq I, 2019, IEEE ACCESS, V7, P9265, DOI 10.1109/ACCESS.2018.2890560
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Xu BH, 2018, IEEE T AFFECT COMPUT, V9, P255, DOI 10.1109/TAFFC.2016.2622690
   Yin-Fu Huang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P1, DOI 10.1007/978-3-642-35236-2_1
NR 28
TC 4
Z9 4
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32469
EP 32490
DI 10.1007/s11042-022-12961-6
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600009
DA 2024-07-18
ER

PT J
AU Zaghloul, R
   Hiary, H
AF Zaghloul, Rawan
   Hiary, Hazem
TI A pair-mode model for underwater single image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image; Rotors; Geometric mean histogram equalization;
   Contrast enhancement; Chromaticity enhancement; Image restoration
AB Enhancing underwater images is a challenging problem owing to light scattering and absorption in underwater environments. Such environments provoke several combined degradations in images including color attenuation, blurring and low contrast. Using image processing techniques to enhance this kind of image remains very attractive because of its low-cost of implementation and typically its small number of parameters when compared to more complex learning techniques. This paper proposes an image processing model which first, analyses the color characteristics of the degraded image. Second, decides about the suitable enhancement steps (i.e., mode of operation) to be performed. It operates in two modes (mode-1 and mode-2), both of which investigate a combination of contrast and chromaticity enhancement techniques. The proposed model was tested on 5141 images collected from various, well-known datasets. It was evaluated using eight different measures, some of which are reference-based, and the rest are blind-based. A set of qualitative and quantitative comparisons was conducted, applying more than 20 methods varying between image processing and deep learning. Besides its efficiency and simplicity, the proposed model demonstrates an ability to achieve good contrast ranges, natural-looking colors, and superior or equivalent quality enhancements when compared to other methods.
C1 [Zaghloul, Rawan] Al Balqa Appl Univ, Amman 11934, Jordan.
   [Hiary, Hazem] Univ Jordan, Amman 11942, Jordan.
C3 Al-Balqa Applied University; University of Jordan
RP Zaghloul, R (corresponding author), Al Balqa Appl Univ, Amman 11934, Jordan.
EM rawanzaghloul@bau.edu.jo
RI Hiary, Hazem/C-8358-2015; zaghloul, rawan/X-5560-2018
OI Hiary, Hazem/0000-0002-0306-5294; zaghloul, rawan/0000-0002-4793-6717
CR Akkaynak D, 2019, PROC CVPR IEEE, P1682, DOI 10.1109/CVPR.2019.00178
   Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   bt. Shamsuddin Norsila, 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P490, DOI 10.1109/ICCISci.2012.6297295
   Cai CH, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P816, DOI 10.1109/ICIP.2000.899834
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Chiang JY, 2011, LECT NOTES COMPUT SC, V6915, P372, DOI 10.1007/978-3-642-23687-7_34
   CHIU K, 1993, GRAPH INTER, P245
   Dive+World's Diving Community 4+, COL CORR DIV LOGS
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   DUNTLEY SQ, 1963, J OPT SOC AM, V53, P214, DOI 10.1364/JOSA.53.000214
   Emberton S., 2015, PROC BRIT MACH VIS C, V125, DOI 10.5244/C.29.125
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Finlayson, 2014, P BRIT MACH VIS C, DOI [10.13140/RG.2.1.4625.6806, DOI 10.13140/RG.2.1.4625.6806]
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gonzalez R.C., 2018, Digital Image Processing
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hiary H, 2017, SIGNAL IMAGE VIDEO P, V11, P833, DOI 10.1007/s11760-016-1029-8
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Liu YB, 2020, IEEE ACCESS, V8, P91116, DOI 10.1109/ACCESS.2020.2994614
   Matkovic K., 2005, Computational Aesthetics, P159
   McCamy C. S., 1976, Journal of Applied Photographic Engineering, V2, P95
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Porikli F., 2018, ARXIV PREPRINT ARXIV
   Pratt W., 2007, DIGITAL IMAGE PROCES, V4th
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Schlick C., 1995, Photorealistic Rendering Techniques, P7
   Tumblin J, 1999, COMP GRAPH, P83, DOI 10.1145/311535.311544
   Wang N., 2019, ARXIV191210269, P1
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang M, 2019, IEEE ACCESS, V7, P123638, DOI 10.1109/ACCESS.2019.2932611
   Zaghloul RI, 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500017
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhang WD, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116030
NR 54
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31953
EP 31974
DI 10.1007/s11042-022-12135-4
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000014
DA 2024-07-18
ER

PT J
AU Fan, JS
   Zhong, DX
   Zhang, YK
   Yu, SH
   Chu, JJ
   Yu, MJ
   Zhao, H
   Huang, YX
AF Fan, Jiashuang
   Zhong, Daixing
   Zhang, Yukun
   Yu, Suihuai
   Chu, Jianjie
   Yu, Mingjiu
   Zhao, Hang
   Huang, Yuexin
TI A hybrid approach based on rough-AHP for evaluation in-flight service
   quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ergonomic simulation; Simulation experimental system; Civil aircraft;
   Seat comfort; Rough set theory; Flight service
ID CUSTOMER SATISFACTION; THERMAL COMFORT; DISCOMFORT; FATIGUE;
   QUESTIONNAIRE; PERFORMANCE; AIRLINES; HEALTH; IMPACT
AB With the rapid development of civil aviation industry and the continuous improvement in passenger demand, higher requirements have been put forward for safety and comfort in the design process of civil aircraft. In order to develop a special ergonomic simulation experimental system for civil aircraft cabin seats, from the perspective of "human", this paper comprehensively considers the impact on civil aircraft cabin seats environment on human physiology and psychology, and puts forward an evaluation method of civil aircraft cabin ergonomic simulation experimental system based on passengers' perception of key design features. Based on the principles of ergonomics, the connection between key design features of seat comfort and the requirements of user preference is comprehensively considered, a simulation experimental system based on comfort evaluation is constructed using subjective and objective evaluation methods. Moreover, according to the experimental requirements of the simulation experimental system and the characteristics of seat structure, an ergonomic simulation experimental system for civil aircraft cabin is developed. The final experimental results prove the practicability and validity of the simulation experiment system designed.
C1 [Fan, Jiashuang] Taiyuan Univ Sci & Technol, Sch Art, Taiyuan 030024, Peoples R China.
   [Fan, Jiashuang; Yu, Suihuai; Chu, Jianjie; Yu, Mingjiu; Zhao, Hang; Huang, Yuexin] Northwestern Polytech Univ, Key Lab Ind Design & Ergon, Minist Ind & Informat Technol, Xian 770072, Peoples R China.
   [Zhong, Daixing] Air Force Med Univ, Tangdu Hosp, Dept Thorac Surg, Xian 710038, Peoples R China.
   [Zhang, Yukun] Air Force Med Univ, Tangdu Hosp, Dept Cardiol, Xian 710038, Peoples R China.
C3 Taiyuan University of Science & Technology; Northwestern Polytechnical
   University; Air Force Military Medical University; Air Force Military
   Medical University
RP Fan, JS (corresponding author), Taiyuan Univ Sci & Technol, Sch Art, Taiyuan 030024, Peoples R China.; Fan, JS (corresponding author), Northwestern Polytech Univ, Key Lab Ind Design & Ergon, Minist Ind & Informat Technol, Xian 770072, Peoples R China.
EM 1450630672@qq.com
RI Huang, Yuexin/IZP-5599-2023; Wang, Xiaoman/JYP-1144-2024
FU Key Laboratory of Industrial Design and Ergonomics (Ministry of Industry
   and Information Technology of China)
FX The authors would like to acknowledge the support of the students and
   staff of the Key Laboratory of Industrial Design and Ergonomics
   (Ministry of Industry and Information Technology of China) for their
   assistance in data collection and analysis.
CR Abu Arqub O, 2019, FUND INFORM, V166, P87, DOI 10.3233/FI-2019-1795
   Abu Arqub O, 2019, FUND INFORM, V166, P111, DOI 10.3233/FI-2019-1796
   Abu Arqub O, 2018, CALCOLO, V55, DOI 10.1007/s10092-018-0274-3
   Agarwal I, 2021, MATER TODAY-PROC, V37, P1341, DOI 10.1016/j.matpr.2020.06.557
   Ahmadpour N, 2016, APPL ERGON, V52, P301, DOI 10.1016/j.apergo.2015.07.029
   ANDERSSON G B J, 1979, Spine, V4, P52, DOI 10.1097/00007632-197901000-00009
   Anggrayni I., 2020, ADV TRANSPORTATION L, V3, P244
   Atalay KD, 2019, J AIR TRANSP MANAG, V76, P67, DOI 10.1016/j.jairtraman.2019.02.004
   Atalik Ö, 2019, ADM SCI, V9, DOI 10.3390/admsci9010026
   Bakir M., 2021, ''Decis. Making, Appl. Manage. Eng., V4, P127, DOI [DOI 10.31181/DMAME2104127B, 10.31181/dmame2104127b]
   Balasubramanian V, 2014, TRANSPORT RES F-TRAF, V22, P150, DOI 10.1016/j.trf.2013.12.010
   Batouei A, 2019, ASIA PAC J TOUR RES, V24, P710, DOI 10.1080/10941665.2019.1630457
   Brown TP, 2001, J R SOC PROMO HEALTH, V121, P177, DOI 10.1177/146642400112100315
   CORLETT EN, 1976, ERGONOMICS, V19, P175, DOI 10.1080/00140137608931530
   Cui WL, 2014, BUILD ENVIRON, V80, P213, DOI 10.1016/j.buildenv.2014.06.004
   De Rossi SMM, 2011, SENSORS-BASEL, V11, P207, DOI 10.3390/s110100207
   Durkin JL, 2006, ERGONOMICS, V49, P28, DOI 10.1080/00140130500356882
   Fan JS, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100932
   Fan JS, 2019, INT J COMPUT INTEG M, V32, P1134, DOI 10.1080/0951192X.2019.1686172
   Farooq MS, 2018, J AIR TRANSP MANAG, V67, P169, DOI 10.1016/j.jairtraman.2017.12.008
   Frey J, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/2758103
   Fu YK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/8545379
   Keshavarz Ghorabaee M, 2017, J AIR TRANSP MANAG, V63, P45, DOI 10.1016/j.jairtraman.2017.05.008
   Khudhair HY., 2019, International Review of Management and Marketing, V9, P74, DOI DOI 10.32479/IRMM.8144
   Kolich M, 2008, APPL ERGON, V39, P15, DOI 10.1016/j.apergo.2007.01.003
   Li WH, 2017, INT J IND ERGONOM, V58, P12, DOI 10.1016/j.ergon.2017.01.002
   Li WH, 2017, J AIR TRANSP MANAG, V60, P49, DOI 10.1016/j.jairtraman.2017.01.006
   Liu JH, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3451864
   Liu J, 2017, HUM FACTOR ERGON MAN, V27, P289, DOI 10.1002/hfm.20712
   Mellert V, 2008, AEROSP SCI TECHNOL, V12, P18, DOI 10.1016/j.ast.2007.10.009
   Momani S., 2016, Applied Mathematics Information Sciences, V10, P225, DOI DOI 10.18576/AMIS/100122
   Navid H., 2017, Economics, Management and Sustainability, V2, P31
   Noyes JM, 2007, ERGONOMICS, V50, P514, DOI 10.1080/00140130701235232
   Park SB., 2017, INT INF I TOKYO INF, V20, P6071
   Park SJ, 2000, INT J IND ERGONOM, V26, P489, DOI 10.1016/S0169-8141(00)00020-2
   Reid GB., 1989, SUBJECTIVE WORKLOAD, P1
   RICHARDS LG, 1977, ERGONOMICS, V20, P499, DOI 10.1080/00140137708931659
   Samad S., 2021, J SOFT COMPUT DECIS, V8, P1
   Schinkel-Ivy A, 2013, J ELECTROMYOGR KINES, V23, P778, DOI 10.1016/j.jelekin.2013.02.001
   SHACKEL B, 1969, ERGONOMICS, V12, P269, DOI 10.1080/00140136908931053
   Shen KQ, 2008, CLIN NEUROPHYSIOL, V119, P1524, DOI 10.1016/j.clinph.2008.03.012
   Tahanisaz S, 2020, J AIR TRANSP MANAG, V83, DOI 10.1016/j.jairtraman.2020.101764
   Tsafarakis S, 2018, J AIR TRANSP MANAG, V68, P61, DOI 10.1016/j.jairtraman.2017.09.010
   Tsang S, 2018, TOUR ANAL, V23, P31, DOI 10.3727/108354218X15143857349477
   van Rosmalen Dori M. K., 2009, Journal of Design Research, V8, P87, DOI 10.1504/JDR.2009.031001
   Wang A, 2008, BUILD ENVIRON, V43, P337, DOI 10.1016/j.buildenv.2006.02.024
   Wu T, 2017, MATERIALS, V10, DOI 10.3390/ma10101187
   Yang ZL, 2009, INT C COMP AID IND D, P1443, DOI 10.1109/CAIDCD.2009.5375350
   Zhang Z, 2009, BUILD ENVIRON, V44, P85, DOI 10.1016/j.buildenv.2008.01.012
   Zhao C, 2019, HUM FACTOR ERGON MAN, V29, P154, DOI 10.1002/hfm.20767
   Zhu H, 2018, SCI TOTAL ENVIRON, V616, P1124, DOI 10.1016/j.scitotenv.2017.10.208
NR 51
TC 1
Z9 1
U1 8
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30797
EP 30819
DI 10.1007/s11042-022-12015-x
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200006
DA 2024-07-18
ER

PT J
AU Suneetha, M
   Prasad, MVD
   Kishore, PVV
AF Suneetha, M.
   Prasad, M. V. D.
   Kishore, P. V. V.
TI Sharable and unshareable within class multi view deep metric latent
   feature learning for video-based sign language recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video sign language recognition; Multi view; Deep metric learning
AB Mobile based sign language recognition (SLR) is challenging in real time due to camera shudder and the signer movements for capturing continuous video data for recognition. Even though there are many state-of-the-art methods for SLR, they have ignored view sensitivity and its effects on the accuracy of the system. This work proposes a novel multi view deep metric feature learning (MVslDML) model for building a view sensitive environment into SLR, which is being investigated profoundly in human action recognition. The MVslDMLNet is an end-to-end trainable convolutional neural network where the features extracted from multiple views are learned based on the sharable and unshareable latent features within class multi view data through metric learning. Experiments performed on our multi view sign language and four benchmark action video datasets indicate a higher accuracy for the proposed framework.
C1 [Suneetha, M.; Prasad, M. V. D.; Kishore, P. V. V.] Koneru Lakshmiah Educ Fdn, Biomech & Vis Comp Res Ctr, Dept Elect & Commun Engn, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kishore, PVV (corresponding author), Koneru Lakshmiah Educ Fdn, Biomech & Vis Comp Res Ctr, Dept Elect & Commun Engn, Vaddeswaram, Andhra Pradesh, India.
EM pvvkishore@kluniversity.in
RI Kishore, P.V.V./R-3293-2017; , MVD Prasad/U-6732-2018
OI , MVD Prasad/0000-0003-2410-1175
CR Achmed I, 2014, THESIS U W CAPE
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bashir FI, 2006, MULTIMEDIA SYST, V12, P45, DOI 10.1007/s00530-006-0024-2
   Camgoz N C, 2020, 2020 IEEE CVF C COMP, DOI 10.1109/cvpr42600.2020.01004
   Chen L, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719847112
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cui RP, 2019, IEEE T MULTIMEDIA, V21, P1880, DOI 10.1109/TMM.2018.2889563
   De Coster M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6018
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Efthymiou N, 2018, IEEE IMAGE PROC, P455, DOI 10.1109/ICIP.2018.8451146
   Elons AS, 2013, APPL SOFT COMPUT, V13, P1646, DOI 10.1016/j.asoc.2012.11.036
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Ghahabi O, 2017, IEEE-ACM T AUDIO SPE, V25, P807, DOI 10.1109/TASLP.2017.2661705
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   He ZP, 2019, MULTIMED TOOLS APPL, V78, P5863, DOI 10.1007/s11042-018-6408-4
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang KK, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107744
   Iosifidis A, 2013, SIGNAL PROCESS, V93, P1445, DOI 10.1016/j.sigpro.2012.08.015
   Ji XF, 2016, MULTIMED TOOLS APPL, V75, P11847, DOI 10.1007/s11042-015-2661-y
   Ji YF, 2020, IEEE T GEOSCI REMOTE, V58, P3941, DOI 10.1109/TGRS.2019.2959702
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kishore PVV, 2018, IEEE SENS J, V18, P3327, DOI 10.1109/JSEN.2018.2810449
   Kishore PVV, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2165, DOI 10.1109/WiSPNET.2016.7566526
   Kishore PVV, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P34, DOI 10.1109/SPACES.2015.7058288
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Li C, 2019, PROC CVPR IEEE, P7864, DOI 10.1109/CVPR.2019.00806
   Li DX, 2020, IEEE WINT CONF APPL, P1448, DOI [10.1109/WACV45572.2020.9093512, 10.1109/wacv45572.2020.9093512]
   Li Y, 2022, IEEE T PATTERN ANAL, V44, P302, DOI 10.1109/TPAMI.2020.3011063
   Liao YQ, 2019, IEEE ACCESS, V7, P38044, DOI 10.1109/ACCESS.2019.2904749
   López-Sánchez D, 2019, NEUROCOMPUTING, V338, P418, DOI 10.1016/j.neucom.2018.08.086
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Mustafa M, 2021, J AMB INTEL HUM COMP, V12, P4101, DOI 10.1007/s12652-020-01790-w
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Pezzuoli F, 2020, ADV INTELL SYST, V973, P70, DOI 10.1007/978-3-030-20476-1_9
   Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655
   Qu FM, 2021, IEEE T SUSTAIN ENERG, V12, P127, DOI 10.1109/TSTE.2020.2985217
   RAO GA, 2018, 2018 C SIGN PROC COM
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Ravi S, 2019, J COMPUT LANG, V52, P88, DOI 10.1016/j.cola.2019.04.002
   Ravi S, 2018, TURK J ELECTR ENG CO, V26, P2871, DOI 10.3906/elk-1711-139
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Singh S, 2010, 2010 7 IEEE INT C AD, DOI 10.1109/avss.2010.63
   Sohn K, 2016, ADV NEUR IN, V29
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Wang DG, 2018, LECT NOTES COMPUT SC, V11213, P457, DOI 10.1007/978-3-030-01240-3_28
   Wang HB, 2017, NEUROCOMPUTING, V238, P269, DOI 10.1016/j.neucom.2017.01.062
   Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI [10.1109/ICCV.2017.283, 10.1109/ICCV.2017.65]
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   Wang Q, 2007, COMPUT VIS IMAGE UND, V108, P87, DOI 10.1016/j.cviu.2006.11.009
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Yan Y, 2013, 2013 IEEE INT C IM P, DOI 10.1109/icip.2013.6738585
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zare A, 2020, PATTERN ANAL APPL, V23, P265, DOI 10.1007/s10044-019-00788-1
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zheng WZ, 2019, PROC CVPR IEEE, P72, DOI 10.1109/CVPR.2019.00016
   Zhu F, 2013, PATTERN RECOGN LETT, V34, P20, DOI 10.1016/j.patrec.2012.04.016
   Zhu JG, 2019, IEEE SIGNAL PROC LET, V26, P1633, DOI 10.1109/LSP.2019.2942739
   Zhu KJ, 2020, IEEE T MULTIMEDIA, V22, P2977, DOI 10.1109/TMM.2019.2962304
   Zhu YS, 2020, VISUAL COMPUT, V36, P1771, DOI 10.1007/s00371-019-01770-y
NR 70
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27247
EP 27273
DI 10.1007/s11042-022-12646-0
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000773206100006
DA 2024-07-18
ER

PT J
AU Singh, S
   Singh, D
   Sajwan, M
   Rathor, VS
   Garg, D
AF Singh, Simranjit
   Singh, Deepak
   Sajwan, Mohit
   Rathor, Vijaypal Singh
   Garg, Deepak
TI Hyperspectral image classification using multiobjective optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral images; Classification; Multiobjective optimization; MOEAD
ID INFORMATION; ALGORITHM; PCA
AB Hyperspectral images constitute a substantial amount of data in the form of spectral bands. This information is used for land cover analysis, specifically in classifying a hyperspectral pixel, which is a popular domain in remote sensing. This paper proposed an efficient framework to classify spectral-spatial hyperspectral images by employing multiobjective optimization. Spectral-spatial features of hyperspectral images are passed for optimization. As hyperspectral images have a high dimensional feature set, many classifiers cannot perform well. Multiobjective optimization reduces the feature set without affecting the discrimination ability of the classifier. The proposed work is validated on a standard hyperspectral image set, Pavia University and Kennedy Space Centre.
C1 [Singh, Simranjit; Sajwan, Mohit; Garg, Deepak] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, UP, India.
   [Singh, Deepak] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Chhattisgarh, India.
   [Rathor, Vijaypal Singh] PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; Indian Institute of Information Technology Design &
   Manufacturing, Jabalpur
RP Singh, S (corresponding author), Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, UP, India.
EM simranjit.singh@bennett.edu.in; dsingh.cs@nitrr.ac.in;
   mohit.sajwan@bennett.edu.in; vrathor@iiitdmj.ac.in;
   deepak.garg@bennett.edu.in
RI ; Garg, Deepak/F-2643-2010
OI SAJWAN, MOHIT/0000-0002-3072-6617; Singh, Simranjit/0000-0001-5324-2116;
   Garg, Deepak/0000-0002-7243-3599; Singh, Simranjit/0009-0003-9857-8950
CR Anderson GP, 2002, P SOC PHOTO-OPT INS, V4725, P65, DOI 10.1117/12.478737
   de CarvalhoO.A. P.R. Meneses., 2000, NASA JPL AVIRIS WORK, P1
   Deb K., 2014, SEARCH METHODOLOGIES, P403, DOI DOI 10.1007/978-1-4614-6940-7_15
   Ettabaa KS, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P42, DOI 10.1109/ATSIP.2014.6834635
   Fang XP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051262
   Farrell MD, 2005, IEEE GEOSCI REMOTE S, V2, P192, DOI 10.1109/LGRS.2005.846011
   Ghamisi P, 2016, IEEE GEOSCI REMOTE S, V13, P1641, DOI 10.1109/LGRS.2016.2600244
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P544, DOI 10.1109/TGRS.2015.2461653
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   KRISHNA R, 2020, IEEE CONSUM ELECTR M
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Li W, 2012, IEEE T GEOSCI REMOTE, V50, P1185, DOI 10.1109/TGRS.2011.2165957
   Lincy RB, 2021, MULTIMED TOOLS APPL, V80, P5917, DOI 10.1007/s11042-020-09771-z
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Lv WJ, 2020, J SENSORS, V2020, DOI 10.1155/2020/4817234
   Ma JP, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2810, DOI 10.1109/ICMLC.2003.1260030
   Ma XR, 2016, IEEE J-STARS, V9, P4073, DOI 10.1109/JSTARS.2016.2517204
   Palsson F, 2015, IEEE T GEOSCI REMOTE, V53, P2652, DOI 10.1109/TGRS.2014.2363477
   Pan B, 2017, IEEE J-STARS, V10, P1975, DOI 10.1109/JSTARS.2017.2655516
   Rodarmel C., 2002, Surveying and Land Information Science, V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Sawant SS, 2020, INT J REMOTE SENS, V41, P3948, DOI 10.1080/01431161.2019.1711242
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Singh S, 2019, 40 AS C REM SENS, P1
   Singh S, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P411, DOI [10.1109/AICAI.2019.8701243, 10.1109/aicai.2019.8701243]
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Sohn Y, 2002, PHOTOGRAMM ENG REM S, V68, P1271
   Solanki A., 2020, VEDL NOVEL VIDEO EVE, V2, P6
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang X, 2021, IEEE GEOSCI REMOTE S
   Xia J, 2018, IEEE T GEOSCI REMOTE, V56, P202, DOI 10.1109/TGRS.2017.2744662
   Xie FD, 2019, APPL SOFT COMPUT, V75, P428, DOI 10.1016/j.asoc.2018.11.014
   Xu X, 2017, IEEE GEOSCI REMOTE S, V14, P2112, DOI 10.1109/LGRS.2017.2753237
   Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0
   Zhang HK, 2017, REMOTE SENS LETT, V8, P438, DOI 10.1080/2150704X.2017.1280200
   Zhang MY, 2018, APPL SOFT COMPUT, V70, P604, DOI 10.1016/j.asoc.2018.06.009
   Zhuo L., 2008, Proc. SPIE, V7147, P503, DOI 10.1117/ 12.813256
NR 40
TC 3
Z9 3
U1 7
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25345
EP 25362
DI 10.1007/s11042-022-12462-6
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200007
DA 2024-07-18
ER

PT J
AU Xie, YZ
   Wang, YT
   Liu, Y
   Zhou, K
AF Xie, Yanzhao
   Wang, Yangtao
   Liu, Yu
   Zhou, Ke
TI Label graph learning for multi-label image recognition with cross-modal
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-label image recognition; Label graph; Graph convolution network;
   Multi-modal fusion
AB It has become popular to learn the correlation between labels in most existing multi-label image recognition tasks. Existing approaches begin to construct a label graph to learn the label dependencies but they suffer from a low convergence efficiency when fusing image features and label embeddings, and also limit the performance improvement on multi-label images. To overcome this challenge, we propose a l abel g raph l earning m odel (termed as LGLM) for multi-label image recognition, which integrates a multi-modal fusion component to efficiently fuse cross-modal embeddings. First, LGLM uses convolution neural network to learn the feature for each image. Second, LGLM first constructs a label graph according to the word vector of each object and then adopts graph convolution network to learn the label correlations to generate label co-occurrence embeddings. Finally, the multi-modal fusion component efficiently fuses image features and label co-occurrence embeddings to generate an end-to-end image recognition model. We conduct extensive experiments on MS-COCO and FLICKR25K and the experimental results demonstrate the superiority of LGLM compared with the state-of-the-art image recognition methods. The code of LGLM has been released on GitHub: .
C1 [Xie, Yanzhao; Liu, Yu; Zhou, Ke] Huazhong Univ Sci & Technol, Wuhan Natl Lab Optoelect, 1037 Luoyu Rd, Wuhan, Peoples R China.
   [Wang, Yangtao] Guangzhou Univ, Sch Comp Sci & Cyber Engn, 230 Wai Huan Xi Rd, Guangzhou, Peoples R China.
C3 Huazhong University of Science & Technology; Guangzhou University
RP Wang, YT (corresponding author), Guangzhou Univ, Sch Comp Sci & Cyber Engn, 230 Wai Huan Xi Rd, Guangzhou, Peoples R China.
EM yzxie@hust.edu.cn; ytaowang@gzhu.edu.cn; liu_yu@hust.edu.cn;
   zhke@hust.edu.cn
RI XIE, Yan-zhao/B-9619-2011
OI Wang, Yangtao/0000-0003-4605-9270; Liu, Yu/0000-0002-1964-9278
FU Innovation Group Project of the National Natural Science Foundation of
   China [61821003]; National Natural Science Foundation of China
   [61902135]
FX Thanks for the support of the Innovation Group Project of the National
   Natural Science Foundation of China No.61821003 and the National Natural
   Science Foundation of China No.61902135.
CR [Anonymous], 2011, Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-220
   [Anonymous], Simple baseline for visual question answering
   [Anonymous], 2005, Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM'05, DOI [DOI 10.1145/1099554.1099591, 10.1145/1099554.1099591]
   [Anonymous], 2014, ICLR
   Chen SJ, 2018, IEEE INT CON MULTI
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Defferrard M, 2016, ADV NEUR IN, V29
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P382, DOI 10.1145/3323873.3326593
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huang FR, 2021, IEEE T CYBERNETICS, V51, P1506, DOI 10.1109/TCYB.2019.2896100
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Inoue N, 2017, IEEE INT CONF COMP V, P2261, DOI 10.1109/ICCVW.2017.265
   Jin Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P649, DOI 10.1007/978-3-030-58589-1_39
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947
   Kipf TN, 2017, INT C LEARN REPR
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Li Q, 2020, PATTERN RECOGN LETT, V138, P378, DOI 10.1016/j.patrec.2020.07.040
   Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Malinowski M, 2014, ADV NEUR IN, V27
   Molchanov P., 2017, INT C LEARN REPR ICL, P1, DOI DOI 10.1002/9781118786352.WBIEG1156
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
NR 37
TC 0
Z9 1
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25363
EP 25381
DI 10.1007/s11042-022-12397-y
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200004
DA 2024-07-18
ER

PT J
AU Nagi, R
   Tripathy, SS
AF Nagi, Reva
   Tripathy, Sanjaya Shankar
TI Deep convolutional neural network based disease identification in
   grapevine leaf images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural networks; Plant disease identification; Grapevine
ID CLASSIFICATION
AB Grapevine (Vitis vinifera L.) is a major fruit crop with commercial importance worldwide. Black rot, Black measles, and Leaf blight are three diseases commonly found in the grapevine. The timely and accurate diagnosis is crucial in preventing the spread of the disease and reducing loss in production. The advancement in deep learning has opened doors for new diagnostic algorithms in the domain of plant disease identification. In this paper, we propose a grapevine disease identification method using a convolutional neural network (CNN). A light weight 6-layer CNN model was designed from scratch and trained using an open repository with 3 disease classes and 1 healthy leaf image dataset. The dataset contained a total of 3423 grapevine leaf images. The model was trained with a 70-30 train-test ratio. Image augmentation and early stopping techniques were used to avoid overfitting of the model. The proposed model achieved 98.4% classification accuracy on the test dataset. Additionally, the key feature of the proposed 6-layer model is that it has lesser number of trainable parameters which reduces its computational complexity as compared to the existing pre-trained models.
C1 [Nagi, Reva; Tripathy, Sanjaya Shankar] BIT Mesra, Dept Elect & Commun Engn, Ranchi, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Tripathy, SS (corresponding author), BIT Mesra, Dept Elect & Commun Engn, Ranchi, Bihar, India.
EM reva.nagi0502@gmail.com; sstripathy@bitmesra.ac.in
RI Tripathy, Sanjaya Shankar/O-9636-2017
FU Department of Electronics and Communication Engineering, Birla Institute
   of Technology Mesra, INDIA
FX We express our thanks to Department of Electronics and Communication
   Engineering, Birla Institute of Technology Mesra, INDIA for providing
   institute fellowship to pursue doctoral research.
CR Akbarzadeh S, 2018, COMPUT ELECTRON AGR, V148, P250, DOI 10.1016/j.compag.2018.03.026
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   [Anonymous], 2016, JOURNEE TECHNIQUE VI
   Basso MF, 2017, REV BRAS FRUTIC, V39
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Coulibaly S, 2019, COMPUT IND, V108, P115, DOI 10.1016/j.compind.2019.02.003
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gill H.K., 2014, Pesticides-Toxic Aspects, P187, DOI 10.5772/57399
   Griffel LM, 2018, COMPUT ELECTRON AGR, V153, P318, DOI 10.1016/j.compag.2018.08.027
   Hughes D., 2015, ARXIV PREPRINT ARXIV, V1511
   Kerkech M, 2018, COMPUT ELECTRON AGR, V155, P237, DOI 10.1016/j.compag.2018.10.006
   Kim KH, 2017, SCI TOTAL ENVIRON, V575, P525, DOI 10.1016/j.scitotenv.2016.09.009
   Kour VP, 2019, IEEE ACCESS, V7, P29374, DOI 10.1109/ACCESS.2019.2901900
   Liang QK, 2019, COMPUT ELECTRON AGR, V157, P518, DOI 10.1016/j.compag.2019.01.034
   Lingwal S, 2021, MULTIMED TOOLS APPL, V80, P35441, DOI 10.1007/s11042-020-10174-3
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Oppenheim D, 2017, Adv. Anim. Biosci., V8, P244, DOI DOI 10.1017/S2040470017001376
   Prabhakar M, 2020, MULTIMED TOOLS APPL, V79, P28773, DOI 10.1007/s11042-020-09461-w
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Wagh TA., 2019, INT J COMPUT APPL, V975, P8887
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
NR 25
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 24995
EP 25006
DI 10.1007/s11042-022-12662-0
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300013
DA 2024-07-18
ER

PT J
AU Tuladhar, S
   Alsadoon, A
   Prasad, PWC
   Ali, AE
   Alrubaie, A
AF Tuladhar, Sanira
   Alsadoon, Abeer
   Prasad, P. W. C.
   Ali, Akbas Ezaldeen
   Alrubaie, Ahmad
TI A novel solution of deep learning for endoscopic ultrasound image
   segmentation: enhanced computer aided diagnosis of gastrointestinal
   stromal tumor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Class activation mapping; Multi-scale
   Gaussian kernel fuzzy; Multi-scale vector field convolution; Region of
   interest; And automatic segmentation
AB Gastrointestinal stromal tumor is one of the critical tumors that doctors do not suggest to get frequent endoscopy, so there is a need for a diagnosis system which can process ultrasound images and figure out the tumor. Many gastrointestinal tumor diagnosis methods were developed, but all of these methods used manual contour rather than automatic segmentation. The research adopts enhanced automatic segmentation to improve the diagnosis of the gastrointestinal stromal tumor with deep convolutional neural networks. This solution's proposed system is an enhanced automated segmentation methodology using multi-scale Gaussian kernel fuzzy clustering and multi-scale vector field convolution, which segments the ultrasound image automatically into the region of interest (the infected area). Convolutional Neural Network with Class Activation Mapping is done to diagnose an image with the tumor for Four datasets, namely (USS1, SH Hospital, SNUH, BUSI). This proposed system helps to get a clearer tumor image, and the accuracy has increased from 84.275% to 88.4%, and the processing time has reduced from 28.525% to 24.575%. The proposed solution enhanced Automatic Segmentation helped to get clearer tumor image which resulted in increased accuracy and decreased performance time compared to the state-of-the-art. Automatic segmentation overcomes the dependency on the expert for drawing the Region of Interest (ROI).
C1 [Tuladhar, Sanira; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Ali, Akbas Ezaldeen] Univ Technol Baghdad, Dept Comp Sci, Baghdad, Iraq.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; University of
   Technology- Iraq; University of New South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Ali, Akbas Ezaldeen/F-8290-2019
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Bi H, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105097
   Bonmati E, 2018, INT J COMPUT ASS RAD, V13, P875, DOI 10.1007/s11548-018-1762-2
   Chen T, 2020, COMPUT METH PROG BIO, V185, DOI [10.1016/j.cmph.2019.105118, 10.1016/j.cmpb.2019.105118]
   Fan D, 2020, ARXIV200611392V4EESS
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Henry C, 2019, EXPERT SYST APPL, V133, P242, DOI 10.1016/j.eswa.2019.05.019
   Huang QH, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101657
   Li JY, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101601
   Li XY, 2019, INT J COMPUT ASS RAD, V14, P1635, DOI 10.1007/s11548-019-01993-3
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Panigrahi L, 2019, EXPERT SYST APPL, V115, P486, DOI 10.1016/j.eswa.2018.08.013
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Robinson K, 2019, MED PHYS, V46, P2145, DOI 10.1002/mp.13455
   Rubinstein E, 2019, MED IMAGE ANAL, V55, P27, DOI 10.1016/j.media.2019.04.001
   Shi ZW, 2019, MED PHYS, V46, P5677, DOI 10.1002/mp.13844
   Tian Y, 2020, ARXIV200614811V1CSCV
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Vieira PM, 2020, MED PHYS, V47, P52, DOI 10.1002/mp.13709
   Wang LT, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101665
   Yan J, 2020, ARXIV200712881V1CSCV
   Zhang R., 2020, MED IMAGE COMPUTING, DOI 10.1007/978-3-030-59725-2_25
NR 21
TC 3
Z9 3
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23845
EP 23865
DI 10.1007/s11042-022-11936-x
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800033
OA hybrid
DA 2024-07-18
ER

PT J
AU Liu, XL
   Tong, XJ
   Wang, Z
   Zhang, M
AF Liu, Xilin
   Tong, Xiaojun
   Wang, Zhu
   Zhang, Miao
TI A novel hyperchaotic encryption algorithm for color image utilizing DNA
   dynamic encoding and self-adapting permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA dynamic encoding; Self-adapting permutation;
   Hyperchaotic system; Hash value
ID SEMI-TENSOR PRODUCT; CHAOTIC SYSTEM; MAP; SCHEME; MATRIX; DIFFUSION;
   KEYS
AB Image encryption has been an attractive research filed in recent years. In this paper, we propose a novel hyperchaotic encryption algorithm for color image utilizing DNA dynamic encoding and self-adapting permutation. Firstly, A new 4-dimensional hyperchaotic system is designed, and the detailed dynamic analysis shows that the system has strong pseudo-randomness and a large range of chaotic parameters. Secondly, based on the new 4-D hyperchaotic system, we devise the methods of DNA dynamic encoding, DNA dynamic calculation and DNA dynamic decoding in the image encryption algorithm, and the sequences generated by the hyperchaotic control these coding rules dynamically to make the results of operation more unpredictable. Moreover, the initial keystream is designed dependent upon the plaintext image, and the method of plaintext-related self-adapting permutation is proposed at the bit level and DNA level of the image respectively, which enhances the sensitivity of the algorithm to plaintext image and key. The theoretical analysis and numerical simulation show that the image algorithm has good security and can resist various attacks.
C1 [Liu, Xilin; Tong, Xiaojun; Zhang, Miao] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
   [Wang, Zhu] Harbin Inst Technol, Sch Informat Sci & Engn, Weihai 264209, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
EM tong_xiaojun@163.com
FU Shandong Provincial Natural Science Foundation [ZR2019MF054]; National
   Natural Science Foundation of China [61902091]; Innovation Research
   Foundation of Harbin Institute of Technology [HIT.NSRIF.2020099]; 2017
   Weihai University Co-construction Project
FX This work was supported by the following projects and foundations:
   project ZR2019MF054 supported by Shandong Provincial Natural Science
   Foundation, the National Natural Science Foundation of China
   (No.61902091) and Innovation Research Foundation of Harbin Institute of
   Technology (HIT.NSRIF.2020099), 2017 Weihai University Co-construction
   Project.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P8065, DOI 10.1007/s00521-019-04312-8
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen YM, 2015, MATH COMPUT SIMULAT, V112, P40, DOI 10.1016/j.matcom.2014.11.006
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Iwasaki A, 2018, JSIAM LETT, V10, P1, DOI 10.14495/jsiaml.10.1
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500160
   Ma J, 2015, NONLINEAR DYNAM, V81, P1275, DOI 10.1007/s11071-015-2067-4
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Raza SF, 2019, NONLINEAR DYNAM, V95, P859, DOI 10.1007/s11071-018-4600-8
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Shiu HJ, 2010, INFORM SCIENCES, V180, P2196, DOI 10.1016/j.ins.2010.01.030
   Suri S, 2020, NEURAL COMPUT APPL, V32, P11859, DOI 10.1007/s00521-019-04668-x
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Volos CK, 2013, SIGNAL PROCESS, V93, P1328, DOI 10.1016/j.sigpro.2012.11.008
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164884
   Wang XY, 2019, OPT LASER ENG, V122, P335, DOI 10.1016/j.optlaseng.2019.06.015
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yao LL, 2017, OPT LASER ENG, V89, P72, DOI 10.1016/j.optlaseng.2016.06.006
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang YQ, 2018, PHYSICA A, V490, P148, DOI 10.1016/j.physa.2017.07.019
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
NR 62
TC 21
Z9 21
U1 6
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21779
EP 21810
DI 10.1007/s11042-022-12472-4
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800009
DA 2024-07-18
ER

PT J
AU Ou, Y
   Zhang, B
   Li, BL
AF Ou, Yang
   Zhang, Bo
   Li, Bailin
TI Multi-scale low-rank approximation method for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-scale nonlocal self-similarity; Low-rank approximation; Singular
   value decomposition; Image denoising
ID SPARSE REPRESENTATION; SELF-SIMILARITY
AB Nonlocal self-similarity (NSS) as a prior has been widely used in image denoising techniques, such as block-matching and 3-D filtering (BM3D) and weighted nuclear norm minimization (WNNM). However, for local regions that do not have sufficiently similar structures in the image, these methods usually produce ringing artifacts. In light of the fact that NSS exists within both the same scale and different scales, this paper proposes an image denoising method that simultaneously explores multi-scale NSS prior and low-rank prior of natural images. Specifically, we first select similar patches from different scales to make full use of multi-scale NSS prior. Then, a constrained nuclear norm minimization model is introduced to account for low-rank prior. Finally, eigenvalue thresholding technique is exploited to obtain the solution. We demonstrate the proposed method on both synthetic and real noisy image denoising. Results show competitive performance in terms of quantification and visualization compared to state-of-the-art competing methods.
C1 [Ou, Yang; Li, Bailin] Southwest Jiaotong Univ, Sch Mech Engn, Chengdu 610031, Peoples R China.
   [Zhang, Bo] Xi An Jiao Tong Univ, Sch Elect Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Southwest Jiaotong University; Xi'an Jiaotong University
RP Li, BL (corresponding author), Southwest Jiaotong Univ, Sch Mech Engn, Chengdu 610031, Peoples R China.
EM blli62@swjtu.edu.cn
RI Zhu, Li/JTT-9093-2023; li, bai/JNE-1502-2023; Wang,
   Jiacheng/ABE-5948-2020; shi, chen/KEH-8339-2024; Ou, Yang/HNG-6403-2023;
   Li, Shiyu/KHE-1376-2024; zhang, bx/HNR-3314-2023
OI Wang, Jiacheng/0000-0003-4327-1508; Li, Bailin/0000-0003-1126-6165
FU China Scholarship Council [202007000084]
FX This work was supported by the China Scholarship Council (No.
   202007000084).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2018, SIAM J IMAGING SCI, V11, P2568, DOI 10.1137/18M116890X
   Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Fedorov V, 2017, IEEE T IMAGE PROCESS, V26, P2137, DOI 10.1109/TIP.2017.2681421
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Guan DD, 2020, IEEE GEOSCI REMOTE S, V17, P421, DOI 10.1109/LGRS.2019.2926196
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   Huo FC, 2021, MULTIMED TOOLS APPL, V80, P14101, DOI 10.1007/s11042-020-10428-0
   Kumar A, 2019, IEEE T IMAGE PROCESS, V28, P2921, DOI 10.1109/TIP.2019.2892663
   Kumar A, 2019, ISA T, V85, P293, DOI 10.1016/j.isatra.2018.10.030
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu HF, 2018, IEEE T CIRC SYST VID, V28, P3321, DOI 10.1109/TCSVT.2017.2759187
   Luo EM, 2016, IEEE T IMAGE PROCESS, V25, P4489, DOI 10.1109/TIP.2016.2590318
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P1013, DOI 10.1007/s10044-017-0617-8
   Ou Y, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102895
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie C, 2017, NEUROCOMPUTING, V260, P92, DOI 10.1016/j.neucom.2017.03.073
   Xu J, 2018, IEEE T IMAGE PROCESS, V27, P2996, DOI 10.1109/TIP.2018.2811546
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yair N, 2018, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2018.00334
   Yang JX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102822
   Zha ZY, 2020, IEEE T IMAGE PROCESS, V29, P3254, DOI 10.1109/TIP.2019.2958309
   Zha ZY, 2018, NEUROCOMPUTING, V275, P2294, DOI 10.1016/j.neucom.2017.11.004
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 39
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20357
EP 20371
DI 10.1007/s11042-022-12083-z
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600004
DA 2024-07-18
ER

PT J
AU Yin, HH
   Liu, JC
   Chen, XH
   Li, GQ
AF Yin, Huanghao
   Liu, Jiacheng
   Chen, Xiaohong
   Li, Guoqiang
TI WeAnimate: Motion-coherent animation generation from video data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User-generated-content; Animation generation; Machine learning;
   Motion-coherent
AB Due to the lack of easy-to-use tools, User-Generated-Animation (UGA) only has limited development compared with the rapid development of user participatory culture and the resulting User-Generated Contents (UGC). In this paper, we develop a machine learning based tool called WeAnimate that can generate a clip of animation using only a character picture and a source video. Users are able to provide character movements by the video. In the tool, a classifier model is trained to identify every motion in the video and to obtain therefrom the motion sequences. Then a strategy combining skeletal animation with neural network is presented to produce multiple auxiliary images from one original image of the new character. Eventually, these images will be spliced into a new animation according to the time order of the motion sequences of video frames. We evaluate the capability, effects, and performance of this animation generation tool with practical applications. The evaluation shows the usage and effectiveness of WeAnimate.
C1 [Yin, Huanghao; Liu, Jiacheng; Chen, Xiaohong] East China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai, Peoples R China.
   [Li, Guoqiang] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
C3 East China Normal University; Shanghai Jiao Tong University
RP Chen, XH (corresponding author), East China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai, Peoples R China.
EM xhchen@sei.ecnu.edu.cn; li.g@sjtu.edu.cn
RI Liu, Jiacheng/GNW-5828-2022; Wang, Ji/A-3774-2009
OI Wang, Ji/0000-0002-0724-7538
CR Agarap A.F., 2019, An Architecture Combining Convolutional Neural Network (CNN) and Support Vector Machine (SVM) for Image Classification
   Albrecht I, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P77, DOI 10.1109/PCCGA.2002.1167841
   Beer D, 2010, J CONSUM CULT, V10, P3, DOI 10.1177/1469540509354009
   Berney S, 2016, COMPUT EDUC, V101, P150, DOI 10.1016/j.compedu.2016.06.005
   Burgess J., 2018, YouTube: Online video and participatory culture
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chandra Mayank Arya, 2021, International Journal of Information Technology, V13, P1, DOI 10.1007/s41870-017-0080-1
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Condry I., 2013, SOUL ANIME COLLABORA, DOI [10.1215/9780822397557, DOI 10.1215/9780822397557]
   Dai H, 2010, SKELETAL ANIMATION B
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Delorme Maxime, 2009, 2009 2 INT C ADV COM, P386
   Eskimez SE, 2018, LECT NOTES COMPUT SC, V10891, P372, DOI 10.1007/978-3-319-93764-9_35
   Hayashi M., 2014, ITE Transactions on Media Technology and Applications, V2, P74
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Kang N, 2019, VISUAL COMPUT, V35, P849, DOI 10.1007/s00371-019-01678-7
   Khungurn, 2020, TALKING HEAD ANIME S
   Kim RE, 2018, INDIAN J PUBLIC HLTH, V9
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Lee E, 2015, CYBERPSYCH BEH SOC N, V18, P552, DOI 10.1089/cyber.2015.0157
   Li JH, 2014, MULTIMED TOOLS APPL, V71, P469, DOI 10.1007/s11042-013-1541-6
   Li YB, 2018, AAAI CONF ARTIF INTE, P7041
   Lin TH, 2013, US Patent, Patent No. [8,462,198, 8462198]
   Liu YL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818122
   Meena HK, 2021, IETE J RES, V67, P667, DOI 10.1080/03772063.2019.1565952
   O'Byrne WI, 2018, INT J EDUC MATH SCI, V6, P182, DOI 10.18404/ijemst.408942
   Pan JJ, 2011, SKETCH BASED SKELETO
   Pena-Lopez I., 2007, Participative Web and User-Created Content. Web
   Richard A, 2021, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV48630.2021.00009
   Shim H, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P596
   Sinha, 2016, PROUNITY ANIMATION
   Song Y., 2018, ARXIV180404786
   Sugisaki E, 2009, ACM SIGGRAPH ASIA 20, P1
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Tian GZ, 2019, IEEE INT CONF MULTI, P366, DOI 10.1109/ICMEW.2019.00069
   Vrhovski, 2017, THESIS U RIJEKA
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2018, EDUC SCI-THEOR PRACT, V18, P1678, DOI 10.12738/estp.2018.5.067
   Yoon H, 2019, GEOFORUM, V99, P267, DOI 10.1016/j.geoforum.2018.08.013
   Yu JR, 2005, LECT NOTES ARTIF INT, V3809, P1187
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201285
NR 43
TC 0
Z9 0
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20685
EP 20703
DI 10.1007/s11042-022-12359-4
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600007
DA 2024-07-18
ER

PT J
AU Aminian, M
   Khotanlou, H
AF Aminian, Mohammad
   Khotanlou, Hassan
TI CapsNet-based brain tumor segmentation in multimodal MRI images using
   inhomogeneous voxels in Del vector domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Capsule networks; Magnetic resonance imaging;
   Vector space; Del operator; Inhomogeneous voxel
ID CONVOLUTIONAL NEURAL-NETWORKS; TEXTURE; FEATURES; MODEL
AB Glioma is a type of brain tumor that is the most typical and most aggressive tumor. Magnetic resonance imaging (MRI) has a widespread utilization as an imaging method for assessing the tumor; however, a lot of information obtained from MRI would prevent manual segmentation in an acceptable timeframe. Therefore, we need reliable and automatic segmentation techniques. Nonetheless, broad structural and spatial variability amongst the brain tumors made automatic segmentation a difficult issue. Capsule Network (CapsNet) is an improved convolutional neural network, which involves responding to challenges. Consequently, CapsNet has been considered to be a perfect candidate to perform brain tumor segmentation. In this paper, a new model containing CapsNet, that operates in the Del vector domain and works with inhomogeneous voxels, is presented. Flair and T-1 MR images are first transformed from the time domain to the vector domain using the Del operator. MVGC (Mean Value Guided Contour) algorithm is then applied on the Flair image to segment ROI (Region of Interest). Inhomogeneous voxels are then extracted from ROI of Flair and T-1 MR images. In the final phase, a new two-path CapsNet architecture is applied to classify voxels. The introduced technique is verified according to BRATS 2015 and BRATS 2013 datasets. The outputs show that this technique achieves a competitive result with the average Dice similarity equal to 0.90 for the whole tumor in Brats2013 and 0.88 for the entire tumor in Brats2015. In addition, this technique took just similar to 86.2 s for the segmentation of a patient case.
C1 [Aminian, Mohammad; Khotanlou, Hassan] Bu Ali Sina Univ, Dept Comp Engn, RIV Lab, Hamadan, Hamadan, Iran.
C3 Bu Ali Sina University
RP Khotanlou, H (corresponding author), Bu Ali Sina Univ, Dept Comp Engn, RIV Lab, Hamadan, Hamadan, Iran.
EM Khotanlou@basu.ac.ir
OI Khotanlou, Hassan/0000-0001-7351-9397
CR [Anonymous], 2013, P NCI MICCAI BRATS
   Aslian H, 2013, INT J RADIAT ONCOL, V87, P195, DOI 10.1016/j.ijrobp.2013.04.049
   Bal A., 2020, IMAGE CLASSIFIER ASS, DOI [10.1007/978-81-322-2653-6, DOI 10.1007/978-81-322-2653-6]
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Bonte S, 2018, COMPUT BIOL MED, V98, P39, DOI 10.1016/j.compbiomed.2018.05.005
   Chen H, 2020, NEUROCOMPUTING, V392, P305, DOI 10.1016/j.neucom.2019.01.111
   Ciresan D., 2012, NIPS, P2843
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Devi CN, 2015, COMPUT BIOL MED, V64, P163, DOI 10.1016/j.compbiomed.2015.06.016
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Geremia E, 2013, I S BIOMED IMAGING, P1344
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Havaei Mohammad, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P195, DOI 10.1007/978-3-319-30858-6_17
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoseini F, 2018, J DIGIT IMAGING, V31, P738, DOI 10.1007/s10278-018-0062-2
   Hsieh TM, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-54
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Juan-Albarracín J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125143
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kanas VG, 2015, BIOMED SIGNAL PROCES, V22, P19, DOI 10.1016/j.bspc.2015.06.004
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Kiaei AA, 2017, MED IMAGE ANAL, V40, P111, DOI 10.1016/j.media.2017.06.005
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P59, DOI 10.1016/j.imu.2018.12.001
   Lee CH, 2008, LECT NOTES COMPUT SC, V5241, P359
   Li HC, 2019, COMPUT BIOL MED, V108, P150, DOI 10.1016/j.compbiomed.2019.03.014
   Li Y., 2021, Int J Cogn Comput Eng, V2, P21, DOI DOI 10.1016/J.IJCCE.2020.12.004
   Li Y, 2019, MULTIMED TOOLS APPL, V78, P34459, DOI 10.1007/s11042-019-08027-9
   Liang Z-P, 2000, PRINCIPLES MAGNETIC
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Meier R, 2014, P MICCAI BRATS CHALL, DOI [10.13140/2.1.3766.7846, DOI 10.13140/2.1.3766.7846]
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Menze BH, 2010, LECT NOTES COMPUT SC, V6362, P151
   Mercer P.R., 2014, More calculus of a single variable
   Mirajkar G., 2010, Proceedings of the 2010 17th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2010), P702, DOI 10.1109/ICECS.2010.5724609
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Naser MA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103758
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Odland A, 2015, ACTA RADIOL, V56, P1396, DOI 10.1177/0284185114554822
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Pei LM, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101648
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pinto A, 2015, IEEE ENG MED BIO, P3037, DOI 10.1109/EMBC.2015.7319032
   Ronneberger O., 2015, CONVOLUTIONAL NETWOR, P174
   Sabour S, 2017, ADV NEUR IN, V30
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Szilágyi L, 2015, LECT NOTES COMPUT SC, V9492, P174, DOI 10.1007/978-3-319-26561-2_21
   Tong JJ, 2019, BIOMED SIGNAL PROCES, V47, P387, DOI 10.1016/j.bspc.2018.06.001
   Tseng KL, 2017, PROC CVPR IEEE, P3739, DOI 10.1109/CVPR.2017.398
   Tustison NJ, 2015, NEUROINFORMATICS, V13, P209, DOI 10.1007/s12021-014-9245-2
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Zhao LY, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P306, DOI 10.1109/IIH-MSP.2015.41
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhao XM, 2016, LECT NOTES COMPUT SC, V10154, P75, DOI 10.1007/978-3-319-55524-9_8
   Zhou CH, 2020, IEEE T IMAGE PROCESS, V29, P4516, DOI 10.1109/TIP.2020.2973510
   Zhou ZX, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103766
NR 59
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17793
EP 17815
DI 10.1007/s11042-022-12403-3
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900017
DA 2024-07-18
ER

PT J
AU Ranjan, R
   Jindal, N
   Singh, AK
AF Ranjan, Rajeev
   Jindal, Neeru
   Singh, A. K.
TI The identities of n-dimensional s-transform and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generalized S-transform; Time-frequency analysis; Linearity; Shifting;
   Scaling; Filtering
ID SAMPLING THEOREM; LOCALIZATION
AB The Stockwell transform is a signal processing tool based on Fourier transform (FT) with a specific window function. The important properties of 1-dimensional (1-D) and 2-dimensional (2-D) S-transform (ST) are available in the literature. This paper includes the generalized case of these ST as n-dimensional (n-D) ST. First, a definition of n-D ST is given followed by the definitions of its important properties. This definition of n-D ST utilizes the approach of separable function to achieve its closed-form definition starting from the conventional definition for 1-D ST. Thereafter, these analytical concepts are being utilized in filtering the unwanted component and the performance of the proposed technique is compared with the discrete cosine transform (DCT) based filtering.
C1 [Ranjan, Rajeev; Jindal, Neeru; Singh, A. K.] Dept Elect & Commun Engn, Ludhiana, Punjab, India.
   [Ranjan, Rajeev] Chandigarh Univ, Mohali, Punjab, India.
   [Jindal, Neeru; Singh, A. K.] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Chandigarh University; Thapar Institute of Engineering & Technology
RP Ranjan, R (corresponding author), Dept Elect & Commun Engn, Ludhiana, Punjab, India.; Ranjan, R (corresponding author), Chandigarh Univ, Mohali, Punjab, India.
EM rajeevranjan1134@gmail.com; neeru.jindal@thapar.edu; aaasma4u@gmail.com
RI Ranjan, Rajeev/GMX-0032-2022
OI Ranjan, Rajeev/0000-0003-2359-4879
CR Drabycz S, 2009, J DIGIT IMAGING, V22, P696, DOI 10.1007/s10278-008-9138-8
   Iglewska-Nowak I, 2015, APPL COMPUT HARMON A, V39, P248, DOI 10.1016/j.acha.2014.09.006
   Man WS, 2009, COMPUT GEOSCI-UK, V35, P1079, DOI 10.1016/j.cageo.2008.07.003
   Mansinha L, 1997, PHYSICA A, V239, P286, DOI 10.1016/S0378-4371(96)00487-6
   Nithya B, 2015, PROCEDIA COMPUT SCI, V45, P290, DOI 10.1016/j.procs.2015.03.143
   Ranjan R, 2020, WIRELESS PERS COMMUN, V113, P2519, DOI 10.1007/s11277-020-07339-6
   Ranjan R, 2019, CIRC SYST SIGNAL PR, V38, P5212, DOI 10.1007/s00034-019-01118-w
   Ranjan R, 2019, DIGIT SIGNAL PROCESS, V93, P138, DOI 10.1016/j.dsp.2019.07.011
   Ranjan R, 2019, INTEGR TRANSF SPEC F, V30, P471, DOI 10.1080/10652469.2019.1590353
   Ranjan R, 2018, OPTIK, V168, P913, DOI 10.1016/j.ijleo.2018.05.009
   Sahoo BC, 2007, CAN J REMOTE SENS, V33, P551, DOI 10.5589/m07-057
   Schimmel M, 2005, IEEE T SIGNAL PROCES, V53, P4417, DOI 10.1109/TSP.2005.857065
   Stockwell RG, 1996, IEEE T SIGNAL PROCES, V44, P998, DOI 10.1109/78.492555
   Upadhyay S. K., 2009, SURVEYS MATH APPL, V4, P239
   Wang YW, 2008, AIP CONF PROC, V1048, P585, DOI 10.1063/1.2990992
   Zidelmal Z, 2017, DIGIT SIGNAL PROCESS, V62, P137, DOI 10.1016/j.dsp.2016.11.008
NR 16
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16661
EP 16677
DI 10.1007/s11042-022-12757-8
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100018
DA 2024-07-18
ER

PT J
AU Gao, GX
   Lai, HC
   Wang, LJ
   Jia, ZH
AF Gao, GuXue
   Lai, HuiCheng
   Wang, LieJue
   Jia, ZhenHong
TI Color balance and sand-dust image enhancement in lab space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sand-dust image; Color balance; Guided filtering; Detail component;
   Nonlinear mapping function; Gamma function
ID ALGORITHM
AB Due to the scattering and absorption of light, the captured image under sand-dust weather has serious color shift and poor visibility, which can affect the application of computer vision. To solve those problems, the present study proposes a color balance and sand-dust image enhancement algorithm in Lab space. To correct the color of the sand-dust image, a color balance technique is put forward. At first, the color balance technique employs the green channel to compensate the lost value of the blue channel. Then, the technique based on statistical strategy is employed to remove the color shift. The proposed color balance technique can effectively remove the color shift while reducing the blue artifact. The brightness component L is decomposed by guided filtering to obtain the detail component. In the meanwhile, to enhance the detail information of the image, the nonlinear mapping function and gamma function are introduced to the detail component. Experimental results based on qualitative and quantitative evaluation demonstrate that the proposed method can effectively remove color shift, enhance details and contrast of the image and produce results superior to those of other state-of-the-art methods. Additionally, the proposed algorithm can satisfy real-time applications, which can also be used to restore images of turbid underwater and haze images.
C1 [Gao, GuXue; Lai, HuiCheng; Wang, LieJue; Jia, ZhenHong] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Gao, GuXue; Lai, HuiCheng; Wang, LieJue; Jia, ZhenHong] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Xinjiang Uygur, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Lai, HC (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.; Lai, HC (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Xinjiang Uygur, Peoples R China.
EM lai@xju.edu.cn
CR Afifi M, 2019, PROC CVPR IEEE, P1535, DOI 10.1109/CVPR.2019.00163
   Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Al-Sammaraie MF, 2015, INT CONF COMP SCI ED, P95, DOI 10.1109/ICCSE.2015.7250224
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cho Y, 2018, IEEE ROBOT AUTOM LET, V3, P2822, DOI 10.1109/LRA.2018.2843127
   Fu X, 2014, 2014 IEEE 16 INT WOR, P1, DOI [10.1109/MMSP.2014.6958791, DOI 10.1109/MMSP.2014.6958791]
   Gao GX, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165659
   Gao GX, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2975833
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huo JY, 2006, IEEE T CONSUM ELECTR, V52, P541, DOI 10.1109/TCE.2006.1649677
   Dhara SK, 2021, IEEE T CIRC SYST VID, V31, P2076, DOI 10.1109/TCSVT.2020.3007850
   Kim SE, 2020, IEEE T IMAGE PROCESS, V29, P1985, DOI 10.1109/TIP.2019.2948279
   Koscevic K, 2019, INT SYMP IMAGE SIG, P372, DOI 10.1109/ISPA.2019.8868806
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2017, IEICE T INF SYST, VE100D, P211, DOI 10.1587/transinf.2016EDL8180
   Ou FZ, 2019, IEEE IMAGE PROC, P1004, DOI [10.1109/icip.2019.8803047, 10.1109/ICIP.2019.8803047]
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Rong Z, 2014, OPTIK, V125, P3064, DOI 10.1016/j.ijleo.2013.12.077
   Shen-Chuan Tai, 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P571
   Shi ZH, 2019, IEEE ACCESS, V7, P116722, DOI 10.1109/ACCESS.2019.2936444
   Talebi H, 2016, IEEE T COMPUT IMAG, V2, P496, DOI 10.1109/TCI.2016.2607142
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Yang Y, 2020, MULTIDIM SYST SIGN P, V31, P619, DOI 10.1007/s11045-019-00678-z
   Yu SY, 2016, J MOD OPTIC, V63, P2121, DOI 10.1080/09500340.2016.1184340
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P72, DOI 10.1109/TIP.2019.2922837
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 34
TC 11
Z9 11
U1 5
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15349
EP 15365
DI 10.1007/s11042-022-12276-6
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600008
DA 2024-07-18
ER

PT J
AU Al-Zoube, MA
AF Al-Zoube, Mohammed A.
TI Efficient vision-based multi-target augmented reality in the browser
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Web AR; Pose estimation; MobileNets; WebAssembly;
   Deep learning; Cross-platform
ID POSE ESTIMATION
AB Augmented Reality (AR) has gained rising attention from both industry and academia as it enhances the way we interact with the physical world. Compared with native AR apps, implementing AR with web technologies (Web AR) can provide lightweight and universal cross-platform deployment that does not involve extra downloading and installation in advance. However, there are some challenges when developing Web AR apps, such as computational efficiency and networking. The limited capabilities of the browser, especially on mobile devices, make it more challenging to develop efficient web apps. Fortunately, several technical advances have emerged that could change the status of Web AR. This paper presents an efficient implementation of a vision-based and multi-target Web AR app that runs at real-time frame rates on standard web browsers on mobile devices and PCs. A method based on natural features tracking (NFT) is used, and several new web technologies are optimized to achieve specific tasks. The proposed implementation takes advantage of an efficient and lightweight class of convolutional neural networks (CNN) to classify image targets. It uses an image registration method that eliminates the need for a database of the feature points' descriptors, which is usually used in natural feature tracking methods. Computation-intensive tasks, such as target extraction and pose estimation, were computed with separate threads. Thus, the main thread which handles the HTML rendering runs smoothly and is not blocked by these computation-intensive tasks. To evaluate the performance of the proposed architecture and validate its performance, a prototype app was developed. The findings demonstrate that the app can track multiple image targets with real-time frame rates and stable interaction.
C1 [Al-Zoube, Mohammed A.] Princess Sumaya Univ Technol PSUT, Dept Comp Graph, POB 1438, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology
RP Al-Zoube, MA (corresponding author), Princess Sumaya Univ Technol PSUT, Dept Comp Graph, POB 1438, Amman 11941, Jordan.
EM mzoube@psut.edu.jo
CR Abadi Martin, 2016, arXiv
   Abriata Luciano A., 2018, ARXIV PREPRINT ARXIV
   Acuna R, 2018, ARXIV PREPRINT ARXIV
   Akgul O, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P47, DOI 10.1109/SITIS.2016.17
   Al-Zoube MA, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P320, DOI 10.1109/ICTCS.2017.44
   [Anonymous], 2017, AR JS PROJECT HOMEPA
   Belghit H, 2018, ARXIV PREPRINT ARXIV
   Bonenberger Y, 2018, LECT NOTES COMPUT SC, V11162, P18, DOI 10.1007/978-3-030-01790-3_2
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Danchilla B., 2012, Three. js framework. Beginning WebGL for HTML5, P173, DOI DOI 10.1007/978-1-4302-3997-0_7
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Garro V, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P262, DOI 10.1109/3DIMPVT.2012.40
   Göttl F, 2018, WEB3D 2018: THE 23RD INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3208806.3208815
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jensen P, 2015, WORKSH PROGR MOD SIM
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lalonde J., 2018, WORKSH INFORM OPTICS, P1
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Moller A, 2018, COMMUN ACM, V61, P106, DOI 10.1145/3282508
   Oberkampf D, 1996, COMPUT VIS IMAGE UND, V63, P495, DOI 10.1006/cviu.1996.0037
   Petrovic N, 2020, 2020 55TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATION, COMMUNICATION AND ENERGY SYSTEMS AND TECHNOLOGIES (IEEE ICEST 2020), P33, DOI [10.1109/icest49890.2020.9232713, 10.1109/ICEST49890.2020.9232713]
   Qiao XQ, 2019, P IEEE, V107, P651, DOI 10.1109/JPROC.2019.2895105
   Rao JM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17091951
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Smilkov, 2019, ABS190105350 ARXIV
   Timchenko Ruslan, 2020, 2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP), P211, DOI 10.1109/DSMP47368.2020.9204240
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zakai A., 2011, Proceedings of the ACM international conference companion on object oriented programming systems languages and applications companion, P301, DOI DOI 10.1145/2048147.2048224
   Zhang JS, 2017, IEEE I CONF COMP VIS, P4529, DOI 10.1109/ICCV.2017.484
   Zhang YX, 2019, LECT NOTES COMPUT SC, V11614, P13, DOI 10.1007/978-3-030-25999-0_2
   Zhou B, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P756, DOI 10.1145/3241539.3267771
NR 37
TC 3
Z9 3
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14303
EP 14320
DI 10.1007/s11042-022-12206-6
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300023
DA 2024-07-18
ER

PT J
AU Goyal, S
   Khan, N
   Chattopadhyay, C
   Bhatnagar, G
AF Goyal, Shreya
   Khan, Naimul
   Chattopadhyay, Chiranjoy
   Bhatnagar, Gaurav
TI GRIHA: synthesizing 2-dimensional building layouts from images captured
   using a smart phone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Floor plan; ARCore; Graphical documents; Applications
AB Indoor scene reconstruction and generating a 2D/3D floor plan is a widely explored problem. In the recent years a few algorithms have been proposed, which either use RGB-D images, requiring a depth capturing camera or depend upon panoramic images, assuming little to no occlusion in the room. In this work, we propose a framework named GRIHA (Generating Room Interior of a House using ARcore), which takes advantage of RGB images taken from a conventional mobile phone camera. The proposed work uses Simultaneous Localization And Mapping (SLAM) technology to estimate the 3D transformations required for layout generation. GRIHA uses SLAM based Google ARcore library for camera pose estimation while capturing the images. It gives the user freedom to generate a layout by merely taking a few conventional photos, rather than relying on specialized depth hardware or occlusion-free panoramic images. We have compared GRIHA with other existing methods and obtained superior results. Moreover, the system is tested on multiple hardware platforms to test the dependency and efficiency.
C1 [Goyal, Shreya; Chattopadhyay, Chiranjoy; Bhatnagar, Gaurav] Indian Inst Technol Jodhpur, Jodhpur, Rajasthan, India.
   [Khan, Naimul] Ryerson Univ, Toronto, ON, Canada.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur; Toronto Metropolitan University
RP Goyal, S (corresponding author), Indian Inst Technol Jodhpur, Jodhpur, Rajasthan, India.
EM goyal.3@iitj.ac.in; n77khan@ryerson.ca; chiranjoy@iitj.ac.in;
   goravb@iitj.ac.in
RI CHATTOPADHYAY, CHIRANJOY/AFP-0794-2022
OI CHATTOPADHYAY, CHIRANJOY/0000-0002-3431-0483
FU Science and Engineering Research Board, India [ECR/2016/000953]; Natural
   Sciences and Engineering Research Council of Canada (NSERC)
   [CRDPJ530666-18]
FX This work is partially supported by Science and Engineering Research
   Board, India under the project id ECR/2016/000953 and the Natural
   Sciences and Engineering Research Council of Canada (NSERC) under grant
   no. CRDPJ530666-18.
CR Alhashim I., 2018, High quality monocular depth estimation via transfer learning
   Angladon V, 2018, THESIS U TOULOUSE
   [Anonymous], MAGICPLAN CREATE FLO
   [Anonymous], FASTEST WAY MEASURE
   ARcore, FUNDAMENTAL CONCEPTS
   Arduengo Miguel., 2019, Robust and Adaptive Door Operation with a Mobile Robot
   Bao SY, 2014, IEEE WINT CONF APPL, P690, DOI 10.1109/WACV.2014.6836035
   Cabral R, 2014, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2014.546
   Chelani K, 2018, ICVGIP
   Chen S, 2015, INT CON DISTR COMP S, P1, DOI 10.1109/ICDCS.2015.9
   Dasgupta S, 2016, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2016.73
   Dong J, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P85, DOI 10.1145/2809695.2809722
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535
   Fernandez-Labrador C, 2018, IEEE ROBOT AUTOM LET, V3, P3153, DOI 10.1109/LRA.2018.2850532
   Furlan A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.24
   Goyal S, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P272, DOI 10.1109/BigMM50055.2020.00047
   Hsiao Chi-Wei, 2019, ARXIV190512571
   Laignel G, 2021, AUTOMAT CONSTR, V123, DOI 10.1016/j.autcon.2020.103491
   Lin C., 2018, ARXIV181206677
   Liu CX, 2015, PROC CVPR IEEE, P3413, DOI 10.1109/CVPR.2015.7298963
   Murali S, 2017, IEEE INT C INT ROBOT, P6126, DOI 10.1109/IROS.2017.8206513
   Murez Zak, 2020, ECCV
   Mutlu B, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58740
   Okorn B., 2010, Proceedings of the Symposium on 3D Data Processing, Visualization and Transmission
   Phalak A, 2020, ARXIV200307356
   Sun C, 2019, PROC CVPR IEEE, P1047, DOI 10.1109/CVPR.2019.00114
   Turner E, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P22
   Xu J, 2017, IEEE WINT CONF APPL, P354, DOI 10.1109/WACV.2017.46
   Zhang J, 2013, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2013.161
   Zhang W., 2019, EDGE SEMANTIC LEARNI
   Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43
   Zou CH, 2018, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2018.00219
NR 32
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14589
EP 14612
DI 10.1007/s11042-022-11918-z
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shu, QZ
   Lai, HC
   Jia, ZH
   Wang, LJ
AF Shu, Qingzhong
   Lai, Huicheng
   Jia, Zhenhong
   Wang, Liejun
TI Target re-location kernel correlation filtered visual tracking with
   fused deep feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel correlation filtering; Depth features; Scale search;
   Anti-occlusion processing; Model updates
AB To enhance the tracking robustness of the kernel correlation filtering algorithm in complex scenarios, the present study combines the traditional kernel correlation filtering algorithm with depth features and proposes a correlation filtering algorithm incorporating depth features. At first, HOG features, CN features and depth features are extracted and fused, while the dimensionality of the features is reduced separately with the aim to reduce the computational effort. Secondly, a scale pool is established, and the scale search method is employed to improve the computational efficiency of scale estimation. Thirdly, an active detection mechanism for occlusion is introduced, which uses different methods for anti-occlusion processing by classifying the degree of occlusion. Finally, the tracking confidence of current and historical frames is calculated and a threshold is set for adaptive model updating. We have conducted comparison experiments on the OTB-100, VOT2018, LaSOT, and UAV123 datasets, respectively. The experimental results demonstrate that the algorithm in this paper possesses good robustness in complex scenes.
C1 [Shu, Qingzhong; Lai, Huicheng; Jia, Zhenhong; Wang, Liejun] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Xinjiang, Peoples R China.
   [Shu, Qingzhong; Lai, Huicheng; Wang, Liejun] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Lai, HC (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Xinjiang, Peoples R China.; Lai, HC (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Xinjiang, Peoples R China.
EM lai@xju.edu.cn
FU National Natural Science Foundation of China [U1803261, U1903213]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. U1803261, Grant No. U1903213).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baig M. A., 2019, P INT C EL EL COMP E, P1, DOI DOI 10.1109/UPCON47278.2019.8980171
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chenyang Ma, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P674, DOI 10.1109/ICIVC47709.2019.8981004
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Guan J, 2012, 2012 6 INT C DISTR S, P1
   Gundogdu E, 2017, IEEE T IMAGE PROCESS, V26, P5270, DOI 10.1109/TIP.2017.2733199
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Kristan Matej, 2018, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-030-11009-3_1
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li SM, 2020, IEEE ACCESS, V8, P122772, DOI 10.1109/ACCESS.2020.3007261
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lu W.-L., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P6
   Lu X, 2018, 15 EUR C MUN GERM 14
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma HY, 2020, IEEE T IMAGE PROCESS, V29, P3546, DOI 10.1109/TIP.2019.2962694
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yabo Xu, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1564, DOI 10.1109/IMCEC.2018.8469578
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
NR 44
TC 0
Z9 0
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14451
EP 14473
DI 10.1007/s11042-022-12437-7
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300009
DA 2024-07-18
ER

PT J
AU Gill, HS
   Khehra, BS
AF Gill, Harmandeep Singh
   Khehra, Baljit Singh
TI Apple image segmentation using teacher learner based optimization based
   minimum cross entropy thresholding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross entropy; TLBO-MCET; PSNR; Uniformity; Segmentation
ID ALGORITHM
AB Fruit image segmentation is the primary phase during fruit image analysis to develop an artificial intelligence system for fruit classification. In this paper, apple images are considered for segmentation using the concept of teaching learning strategy. In the proposed approach, firstly cross entropy based objective function is designed and then teacher leaner based optimization algorithm is applied to minimize the objective function for finding optimal threshold values at the different levels. Selected threshold values by the proposed approach are used to segment red, green and golden apple images. The proposed approach is called TLBO-MCET. The proposed approach is inspired by teaching learning philosophy, where students learn from teacher in the classroom and from each other mutually. For performance evaluation, PSNR and uniformity measures are used. The results of proposed approach are compared with GA-MCET and HBMO-MCET. From simulation and experimental works, it has been observed that the performance of proposed approach is quite promising. In future, the proposed work will be used for automatic grading of different varieties of apple.
C1 [Gill, Harmandeep Singh] Bibi Sharan Kaur Khalsa Coll, Chamkaur Sahib 140112, Punjab, India.
   [Khehra, Baljit Singh] BAM Khalsa Coll, Garhshankar, India.
RP Gill, HS (corresponding author), Bibi Sharan Kaur Khalsa Coll, Chamkaur Sahib 140112, Punjab, India.
EM profhdsgill@gmail.com; baljitkhehra74@gmail.com
RI Gill, Harmandeep singh/AAY-9120-2020
OI Gill, Harmandeep singh/0000-0001-8699-2087
CR Crepinsek M, 2012, INFORM SCIENCES, V212, P79, DOI 10.1016/j.ins.2012.05.009
   Gill HS, 2021, MULTIMED TOOLS APPL, V80, P27495, DOI 10.1007/s11042-021-10772-9
   Gill HS, 2019, EGYPT INFORM J, V20, P11, DOI 10.1016/j.eij.2018.03.006
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Kalyani R, 2020, INT C SYST COMP AUT, P2020
   Kanungo D.P., 2016, Int. J. Rough. Sets Data Anal., V3, P1, DOI 10.4018/IJRSDA.2016010101
   Ledermann S., 1962, Population, V17, P377, DOI [10.2307/1527125, DOI 10.2307/1527125]
   Lei DM, 2018, IEEE T ENG MANAGE, V65, P330, DOI 10.1109/TEM.2017.2774281
   Li W, 2020, IEEE ACCESS, V8, P65923, DOI 10.1109/ACCESS.2020.2984272
   Liu J, 2019, CHIN AUT C CAC, P2019
   Lopez-Martinez A, 2019, APPL INTELL, V49, P2001, DOI 10.1007/s10489-018-1372-2
   Lv JD, 2019, SCI HORTIC-AMSTERDAM, V246, P411, DOI 10.1016/j.scienta.2018.11.030
   Mizushima A, 2013, COMPUT ELECTRON AGR, V94, P29, DOI 10.1016/j.compag.2013.02.009
   Mohanty Banaja, 2016, Journal of Electrical Systems and Information Technology, V3, P33, DOI 10.1016/j.jesit.2015.11.007
   Nie FY, 2011, COMPUT ELECTR ENG, V37, P757, DOI 10.1016/j.compeleceng.2011.06.006
   Rao CS, 2013, P INT C ADV COMP SCI
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rao RV, 2013, SCI IRAN, V20, P710, DOI 10.1016/j.scient.2012.12.005
   Singh VP, 2016, INT J ARTIF INTELL T, V25, DOI 10.1142/S0218213016500305
   Singla S, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16796-3
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   Wang M, 2019, MATH PROBL ENG, V2019
NR 24
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11005
EP 11026
DI 10.1007/s11042-022-12093-x
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200010
DA 2024-07-18
ER

PT J
AU Singh, JP
   Jain, S
   Singh, UP
   Arora, S
AF Singh, Jasvinder Pal
   Jain, Sanjeev
   Singh, Uday Pratap
   Arora, Sakshi
TI Hybrid neural network model for reconstruction of occluded regions in
   multi-gait scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-gait; Dynamic occlusion; ROIs reconstruction; Particle swarm
   optimization; Neural network
ID RECOGNITION
AB In real-time situations such as airports, railway stations, and shopping complexes, etc. people walk in a group, and such a group of walking persons termed as multi-gait (MG). In these situations, occlusion is a serious issue that affects gait recognition performance. This issue of occlusion of body regions affects the extraction of gait features for the correct recognition of an object. The objective of this article is to reconstruct occluded regions at the preprocessing stage, which can be used for human recognition in the MG scenario. The article is divided into two folds. Firstly, we segment five regions of interest such as ankle, knee, wrist, elbow, and shoulder. We propose a particle swarm optimization (PSO) based neural network (NN) called hybrid NN to solve this problem. The performance of the proposed model is validated on our constructed dataset (SMVDU-MG), considering two view directions i.e. lateral (left to right) and oblique (left to right diagonal). Experimental results show that the proposed model gives better performance compared to an artificial neural network and alternating least square (ALS) method based on mean square error (MSE) and mean absolute percentage error (MAPE) as a performance measure function.
C1 [Singh, Jasvinder Pal; Arora, Sakshi] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, India.
   [Jain, Sanjeev] IIITDM, Sch Comp Sci & Engn, Jabalpur 482005, India.
   [Singh, Uday Pratap] Shri Mata Vaishno Devi Univ, Sch Math, Katra 182320, India.
C3 Shri Mata Vaishno Devi University; Indian Institute of Information
   Technology Design & Manufacturing, Jabalpur; Shri Mata Vaishno Devi
   University
RP Singh, JP (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, India.
EM jasvinder162@gmail.com
RI Singh, Uday Pratap/AAW-9594-2020; JAIN, SANJEEV/M-1736-2018; Singh,
   Jasvinder Pal/AAV-3427-2020
OI Singh, Uday Pratap/0000-0003-2077-0793; 
CR Aristidou Andreas, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P1343, DOI 10.1109/ICBBE.2008.665
   Arora P, 2015, PATTERN RECOGN LETT, V68, P336, DOI 10.1016/j.patrec.2015.05.016
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Begg R., 2006, AUSTRALASIAN PHYSICAL & ENGINEERING SCIENCES IN MEDICINE, V29, P188, DOI 10.1007/BF03178892
   Chen J, 2018, CLMF FINE GRAINED PO
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Chen X, 2017, MACH VISION APPL, V28, P117, DOI 10.1007/s00138-016-0810-6
   Chen X, 2016, MULTIMED TOOLS APPL, V75, P6505, DOI 10.1007/s11042-015-2585-6
   Federolf PA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078689
   Gloersen O, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152616
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M, 2011, WSCG 2011: COMMUNICATION PAPERS PROCEEDINGS, P99
   Hu Q, 2019, DATA MINING AUSDM 20, V996, DOI [10.1007/978-981-13-6661-1_24, DOI 10.1007/978-981-13-6661-1_24]
   Iwashita Y, 2015, LECT NOTES COMPUT SC, V9279, P141, DOI 10.1007/978-3-319-23231-7_13
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kovac J, 2019, MULTIMED TOOLS APPL, V78, P5621, DOI 10.1007/s11042-017-5469-0
   Lishani AO, 2017, SIGNAL IMAGE VIDEO P, V11, P1123, DOI 10.1007/s11760-017-1066-y
   Liu GD, 2006, VISUAL COMPUT, V22, P721, DOI 10.1007/s00371-006-0080-9
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Masood H, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P357, DOI 10.1109/C-CODE.2017.7918957
   Nandy A, 2016, NEUROCOMPUTING, V191, P117, DOI 10.1016/j.neucom.2016.01.002
   Raja SN, 2017, NANOSCALE, V9, P15515, DOI 10.1039/c7nr05346k
   Rida I, 2016, SIGNAL IMAGE VIDEO P, V10, P463, DOI 10.1007/s11760-015-0766-4
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Roy A, 2011, SIGNAL IMAGE VIDEO P, V5, P415, DOI 10.1007/s11760-011-0245-5
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Singh JP, 2021, ARCH COMPUT METHOD E, V28, P107, DOI 10.1007/s11831-019-09375-3
   Singh JP, 2020, MULTIMEDIA SYST, V26, P249, DOI 10.1007/s00530-019-00641-9
   Singh Jasvinder Pal, 2019, 2019 INT C ISSUES CH, P1
   Songmin Jia, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P226, DOI 10.1109/JAS.2015.7081662
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Yoo JH, 2011, ETRI J, V33, P259, DOI 10.4218/etrij.11.1510.0068
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yuhui Shi, 1998, Evolutionary Programming VII. 7th International Conference, EP98. Proceedings, P591, DOI 10.1007/BFb0040810
   Zeng W, 2014, COGN COMPUT, V6, P218, DOI 10.1007/s12559-013-9221-4
   Zhang JR, 2007, APPL MATH COMPUT, V185, P1026, DOI 10.1016/j.amc.2006.07.025
NR 39
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 10
PY 2022
DI 10.1007/s11042-022-11964-7
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YW9NT
UT WOS:000753738300002
DA 2024-07-18
ER

PT J
AU Alsudais, A
AF Alsudais, Abdulkareem
TI Extending ImageNet to Arabic using Arabic WordNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ImageNet; Computer vision; Arabic WordNet; Arabic computer vision;
   Language and computer vision; Linked data
ID NAMED ENTITY RECOGNITION; SENTIMENT ANALYSIS; MODEL
AB This paper investigates the extension of ImageNet and its millions of English-labeled images to Arabic using Arabic WordNet. The primary finding is the identification of Arabic synsets for 1219 of the 21,841 synsets used in ImageNet, which represents 1.1 million images. By leveraging the parent-child structure of synsets in ImageNet, this dataset is extended to 10,462 synsets (and 7.1 million images) that have an Arabic label, which is either a match or a direct hypernym, and to 17,438 synsets (and 11 million images) when a hypernym of a hypernym is included. Samples evaluated suggest that generating Arabic labels for images in ImageNet using hypernyms does indeed produce meaningful results. The precision values for seven evaluated samples exceeded 90%. Moreover, when all the images in the samples were combined, the precision value equaled 93%. For the entire ImageNet, when all hypernyms for a node are considered, an Arabic synset is found for all but four synsets. This represents the major contribution of this work: a dataset of 14,195,756 images that have Arabic labels. The resulting dataset presents Arabic labels for 99.9% of the images in ImageNet.
C1 [Alsudais, Abdulkareem] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Informat Syst Dept, Al Kharj 11942, Saudi Arabia.
C3 Prince Sattam Bin Abdulaziz University
RP Alsudais, A (corresponding author), Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Informat Syst Dept, Al Kharj 11942, Saudi Arabia.
EM A.Alsudais@psau.edu.sa
OI Alsudais, Abdulkareem/0000-0002-9961-6889
FU Deanship of Scientific Research at Prince Sattam bin Abdulaziz
   University, Al-Kharj, Saudi Arabia
FX This project was supported by the Deanship of Scientific Research at
   Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia.
CR Abbes I, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6265
   Abdul-Mageed M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3653
   Abouenour L, 2013, LANG RESOUR EVAL, V47, P891, DOI 10.1007/s10579-013-9237-0
   Abu Shaqra F, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2019), P324, DOI 10.1109/FiCloud.2019.00054
   Al-Ayyoub M, 2019, INFORM PROCESS MANAG, V56, P320, DOI 10.1016/j.ipm.2018.07.006
   Al-Muzaini HA, 2018, INT J ADV COMPUT SC, V9, P67
   Al-Smadi M, 2020, IEEE ACCESS, V8, P37736, DOI 10.1109/ACCESS.2020.2973319
   Al-Smadi M, 2019, IEEE ACCESS, V7, P177122, DOI 10.1109/ACCESS.2019.2956233
   Al-Smadi M, 2019, INFORM PROCESS MANAG, V56, P308, DOI 10.1016/j.ipm.2018.01.006
   Alkhalifa Musa, 2009, 3 INT C AR LANG PROC, P20
   Alsudais A, 2020, ADVANCES IN LANGUAGE AND VISION RESEARCH, P1
   Alsudais A, 2019, IEEE ACCESS, V7, P122730, DOI 10.1109/ACCESS.2019.2926924
   [Anonymous], 2018, Proceedings of the AAAI Conference on Artificial Intelligence
   [Anonymous], 2010, About WordNet
   [Anonymous], 2013, P 2013 C EMPIRICAL M
   Batita MA, 2019, COMPUT SIST, V23, P935, DOI [10.13053/CyS-23-3-3240, 10.13053/cys-23-3-3240]
   Bird S., 2009, NATURAL LANGUAGE PRO
   Black W., 2006, P 3 INT WORDNET C, P295
   Bond F., 2012, PROC GLOBAL WORDNET, P64
   Bond Francis, 2013, Long Papers, V1, P1352
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Cavaliere D, 2019, KNOWL-BASED SYST, V178, P163, DOI 10.1016/j.knosys.2019.04.026
   Cetinic E, 2018, EXPERT SYST APPL, V114, P107, DOI 10.1016/j.eswa.2018.07.026
   Chen X, 2017, CHINESEFOODNET LARGE
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Deng J., 2009, IEEE C COMP VIS PATT
   Ding ST, 2019, PATTERN RECOGN LETT, V123, P89, DOI 10.1016/j.patrec.2019.03.021
   Dost S, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P2021, DOI 10.1145/3341105.3373958
   Elliott D., 2016, P ACL 2016, P70
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Elrefaei Lamiaa A., 2019, Procedia Computer Science, V163, P400, DOI 10.1016/j.procs.2019.12.122
   Fang ZW, 2019, PATTERN RECOGN, V90, P404, DOI 10.1016/j.patcog.2019.01.038
   Farhan W, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102181
   Goikoetxea J, 2018, KNOWL-BASED SYST, V150, P218, DOI 10.1016/j.knosys.2018.03.017
   Helwe C, 2019, ARTIF INTELL REV, V52, P197, DOI 10.1007/s10462-019-09688-6
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Huang FR, 2018, KNOWL-BASED SYST, V160, P251, DOI 10.1016/j.knosys.2018.07.020
   Huang L, 2017, MULTIMED TOOLS APPL, V76, P20341, DOI 10.1007/s11042-017-4781-z
   Ibn Khedher M, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107144
   Kastner MA, 2019, MULTIMED TOOLS APPL, V78, P9463, DOI 10.1007/s11042-018-6528-x
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102141
   Li P, 2020, KNOWL-BASED SYST, P193, DOI 10.1016/j.knosys.2019.105436
   Li Q, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105488
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Liu MF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102178
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Pedersen BS, 2009, LANG RESOUR EVAL, V43, P269, DOI 10.1007/s10579-009-9092-1
   Qaroush A, 2022, J KING SAUD UNIV-COM, V34, P1330, DOI 10.1016/j.jksuci.2019.08.013
   Reed S, 2016, PR MACH LEARN RES, V48
   Regragui Y., 2016, P 8 GLOBAL WORDNET C, P330
   Romeo S, 2019, INFORM PROCESS MANAG, V56, P274, DOI 10.1016/j.ipm.2017.07.003
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ruwa N, 2019, NEUROCOMPUTING, V330, P305, DOI 10.1016/j.neucom.2018.11.049
   Saad RSM, 2016, PETRA 16
   Sagot B., 2008, ONTOLEX 2008
   Sanabria Ramon, 2018, ARXIV181100347
   Shankar S., 2017, NIPS 2017 WORK MACH
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Simonyan K., 2014, 14091556 ARXIV
   Stock P, 2018, LECT NOTES COMPUT SC, V11210, P504, DOI 10.1007/978-3-030-01231-1_31
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102186
   Tian Y., 2020, PREMODERN JAPANESE A
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Vo N, 2019, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2019.00660
   Wang X, 2019, IEEE I CONF COMP VIS, P4580, DOI 10.1109/ICCV.2019.00468
   Xu J, 2019, KNOWL-BASED SYST, V178, P61, DOI 10.1016/j.knosys.2019.04.018
   Yang KY, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P547, DOI 10.1145/3351095.3375709
   Ye YN, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102265
   Yoshikawa Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P417, DOI 10.18653/v1/P17-2066
   Zhang J, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105245
   Zhang JP, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102152
   Zhou T, 2020, MULTIMED TOOLS APPL, V79, P6871, DOI 10.1007/s11042-019-08568-z
NR 78
TC 0
Z9 0
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8835
EP 8852
DI 10.1007/s11042-022-11981-6
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000752200300002
DA 2024-07-18
ER

PT J
AU Bhowmick, S
   Kuiry, S
   Das, A
   Das, N
   Nasipuri, M
AF Bhowmick, Shubhadeep
   Kuiry, Somenath
   Das, Alaka
   Das, Nibaran
   Nasipuri, Mita
TI Deep Learning-Based Outdoor Object Detection Using Visible and
   Near-Infrared Spectrum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Multispectral object detection dataset; Near-infrared
   image; YOLO v3 algorithm; YOLOv4
ID RECOGNITION
AB Object detection is one of the essential branches of computer vision. However, detecting objects in the natural scene is challenging due to various reasons, for example, different sizes of objects, overlapping and similarities of colour, the texture of different objects, etc. The visible spectrum is not suited for standard computer vision tasks in many real-life scenarios. In low visibility settings, moving outside the visible spectrum range, such as to the thermal spectrum or near-infrared (NIR) imaging, is significantly more beneficial. For the object detection task in this study, we used photos from both the RGB and NIR spectrums. The purpose of this paper is to see if it's possible to use the information offered by the near-infrared (NIR) spectrum in conjunction with the visible band for object detection because they both have multimodal information. For example, because near-infrared wavelengths are less prone to haze and distortion, some visually indistinguishable things in the RGB spectrum can be spotted in the NIR image. We gathered a well-organized dataset of outdoor scenes in three spectra: visible (RGB), near-infrared (NIR), and thermal to train such a multispectral object recognition system. For the experiments, we use the YOLOv3 algorithm to train and evaluate our object detection models for NIR and RGB images separately, then train the model with four-channel input (3 channels from RGB images and one channel from NIR images) and the corresponding annotations to see if the model's performance improves even more in detecting the underlying objects. To determine the effectiveness of our approach, we conducted trials on YOLOv4 and SSD models and compared our results with existing related state-of-the-art models.
C1 [Bhowmick, Shubhadeep; Das, Nibaran; Nasipuri, Mita] Jadavpur Univ, Dept CSE, Kolkata 700032, India.
   [Kuiry, Somenath; Das, Alaka] Jadavpur Univ, Dept Math, Kolkata 700032, India.
C3 Jadavpur University; Jadavpur University
RP Kuiry, S (corresponding author), Jadavpur Univ, Dept Math, Kolkata 700032, India.
EM bhowmickshubhadeep@gmail.com; skuiry.math.rs@jadavpuruniversity.in;
   alakadas2012@gmail.com; nibaran.das@jadavpuruniversity.in;
   mitanasipuri@yahoo.com
FU SERB (Government of India) [SB/S3/EECE/054/2016]; Department of Science
   and Technology [IF170641]
FX This work is supported by the project sponsored by SERB (Government of
   India, order no. SB/S3/EECE/054/2016) (dated 25/11/2016) and carried out
   at the Centre for Microprocessor Application for Training Education and
   Research, CSE Department, Jadavpur University. The second author would
   like to thank The Department of Science and Technology for their INSPIRE
   Fellowship program (IF170641) for the financial support.
CR Aguilera Cristhian, 2017, INT C PRACT APPL AG
   Alldieck T, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111947
   Ambinder M, 2011, NATL J, V3
   Angermann M, 2017, P INST NAVIG PAC PNT, P56, DOI 10.33012/2017.15050
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Choe G, 2018, IEEE ROBOT AUTOM LET, V3, P1808, DOI 10.1109/LRA.2018.2801390
   Correa M, 2012, J INTELL ROBOT SYST, V66, P223, DOI 10.1007/s10846-011-9612-2
   Davis JW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P364
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farley V, 2007, P SOC PHOTO-OPT INS, V6739, P73918, DOI 10.1117/12.736864
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Gani M. O., 2021, INT C COMP INT COMM, P105
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Govardhan P, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1435, DOI 10.1109/ICACCCT.2014.7019339
   Gudzius P, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01209-2
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   Hunt ER, 2010, REMOTE SENS-BASEL, V2, P290, DOI 10.3390/rs2010290
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Karasawa T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P35, DOI 10.1145/3126686.3126727
   Kingma D. P., 2014, arXiv
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J., 2016, ARXIV161102644, P1, DOI DOI 10.5244/C.30.73
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Mundy JL, 1998, PHILOS T R SOC A, V356, P1213, DOI 10.1098/rsta.1998.0218
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Osorio K, 2020, AGRIENGINEERING, V2, P471, DOI 10.3390/agriengineering2030032
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shahidi AM, 2013, EXP EYE RES, V113, P143, DOI 10.1016/j.exer.2013.06.001
   Zeng Bo., 2013, ENGINEERING, V05, P553, DOI [10.4236/eng.2013.510B114, DOI 10.4236/ENG.2013.510B114]
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 36
TC 2
Z9 2
U1 8
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9385
EP 9402
DI 10.1007/s11042-021-11848-2
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000751584600003
DA 2024-07-18
ER

PT J
AU Ornek, AH
   Ceylan, M
AF Ornek, Ahmet Haydar
   Ceylan, Murat
TI Medical thermograms' classification using deep transfer learning models
   and methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Convolutional neural networks; Deep learning; Medicine;
   Neonate; Thermography; Transfer learning
ID SVM
AB Infrared thermal imaging and deep learning provide intelligent monitoring systems that detect diseases in early phases. However, deep learning models require thousands of labeled images to be effectively trained from scratch. Since such a dataset cannot be collected from a neonatal intensive care unit (NICU), deep transfer learning models and methods were used for the first time in this study to classify neonates in the NICU as healthy and unhealthy. When nine different pre-trained models (VGG16, VGG19, Xception, ResNet101, ResNet50, Inceptionv3, InceptionResNetv2, MobileNet and DenseNet201) and two different classification methods (Multilayer Perceptrons and Support Vector Machines (SVMs)) were compared, best results were obtained as 100.00% specificity, sensitivity and accuracy with VGG19, and SVMs. This study proposes highest classification performance when comparing other studies that detect health status of neonates.
C1 [Ornek, Ahmet Haydar; Ceylan, Murat] Konya Tech Univ, Konya, Turkey.
C3 Konya Technical University
RP Ornek, AH (corresponding author), Konya Tech Univ, Konya, Turkey.
EM ahmethaydarornek@gmail.com
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [215E019]
FX This study was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK, project number: 215E019).
CR Abbas AK, 2014, BMC MED IMAGING, V14, DOI 10.1186/1471-2342-14-9
   Abbas AK, 2014, NEONATAL IRTHERMOGRA
   Abbas A, 2020, IEEE ACCESS, V8, P74901, DOI 10.1109/ACCESS.2020.2989273
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   CLARK RP, 1980, J PHYSIOL-LONDON, V302, P323
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Gour N, 2020, PATTERN RECOGN LETT, V137, P3, DOI 10.1016/j.patrec.2019.04.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hildebrandt C, 2012, INT PERSPECTIVE TOPI, V10, DOI [10.5772/28383, DOI 10.5772/28383]
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Kasprzyk-Kucewicz T, 2021, J THERM ANAL CALORIM, V144, P139, DOI 10.1007/s10973-020-09457-6
   Khan KA, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112895
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SJ, 2020, PATTERN RECOGN LETT, V131, P15, DOI 10.1016/j.patrec.2019.11.026
   Li W, 2021, MOBILE NETW APPL, V26, P381, DOI 10.1007/s11036-020-01674-5
   da Nóbrega RVM, 2018, COMP MED SY, P244, DOI 10.1109/CBMS.2018.00050
   Mishra Chhavi, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2020. Lecture Notes in Electrical Engineering (LNEE 661), P633, DOI 10.1007/978-981-15-4692-1_49
   Nur R, 2014, THESIS CARLETON U
   Ornek AH, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103044
   Raj RJS, 2020, IEEE ACCESS, V8, P58006, DOI 10.1109/ACCESS.2020.2981337
   Rice HE., 2010, J SURG RES, V1, P61
   Rojas-Domínguez A, 2018, IEEE ACCESS, V6, P7164, DOI 10.1109/ACCESS.2017.2779794
   Rosenblatt F., 1957, The Perceptron-A Perceiving and Recognizing Automaton
   Savasci D., 2019, CLASSIFICATION TECHN, P1, DOI DOI 10.1016/B978-0-12-818004-4.00001-7
   Savasci D, 2018, SIG PROCESS COMMUN
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Villarroel M, 2014, HEALTHC TECHNOL LETT, V1, P87, DOI 10.1049/htl.2014.0077
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Wang N, 2010, NESUG PROC HLTH CARE, P1, DOI DOI 10.1016/J.JAD.2016.09.032
NR 35
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9367
EP 9384
DI 10.1007/s11042-021-11852-6
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000751584600004
DA 2024-07-18
ER

PT J
AU Srivastava, S
   Kumar, A
   Singh, A
   Prakash, S
   Kumar, A
AF Srivastava, Shubhi
   Kumar, Ankit
   Singh, Anupam
   Prakash, Shiv
   Kumar, Arun
TI An improved approach towards biometric face recognition using artificial
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; ILBP; ANN; Feature extraction; HEP; MTS; CS-LBP; BTCS;
   CSLBP-M; and coordinated cluster representation
ID FACIAL EXPRESSION RECOGNITION; FEATURES; MODEL
AB In a biometric-based security system, rather than depending on the system configuration itself, failure rate also relies upon feature extraction and its related statistics. In this paper, a significant approach is being presented to minimize the failure rate and maintain high recognition accuracy and uniformity for non-symmetrical feature points. This work contributes a detailed analysis of stable parameters of captured biometric feature points by using a flexible learning model named as adopted Artificial Neural Network (ANN). The paper also discusses a comparative study of different global and local methods of Histogram of an Equivalent Pattern (HEP) technique for facial feature detection and extraction. The HEP, is further classified by using adopted ANN model, which depends on partitioning the feature area of a predefined image. This task has been accomplished by providing the appropriate definition of local and global functions based on pixel intensities. The literature available for face detection shows many shortcomings such as false acceptance and rejection rates. Among all defined global and local techniques, this paper primarily endorsed an adopted method of Improved Local Binary Pattern (ILBP) which works on local pixel values of a facial image for feature extraction. The classification and recognition task are performed by adopted ANN for various defined global and local features. The paper also derives a detailed comparison with the other existing techniques. As a result, the proposed ILBP technique ensures the consistency of acceptable results in unpredictable variations in the dataset.
C1 [Srivastava, Shubhi; Kumar, Ankit; Kumar, Arun] Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
   [Singh, Anupam] Shri Ramswaroop Mem Univ, Lucknow, Uttar Pradesh, India.
   [Prakash, Shiv] Univ Allahabad, Dept Elect & Commun, Prayagraj, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); Shri Ramswaroop Memorial University; University of
   Allahabad
RP Prakash, S (corresponding author), Univ Allahabad, Dept Elect & Commun, Prayagraj, India.
EM shubhisrivastava1095@gmail.com; 7667ankit@gmail.com;
   anupamsingh089@gmail.com; shivprakash@cas.res.in; drarun@cas.res.in
RI Singh, Anupam/KIE-5291-2024; Kumar, Arun/IZP-9017-2023
OI Kumar, Arun/0000-0001-5694-5861; kumar, Ankit/0000-0002-2059-5545
CR Abdullah AS, 2019, PERIODICALS ENG NATU, DOI 10.21533/pen.v7i2.485
   Agarwal M, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P310, DOI 10.1109/ICSAP.2010.51
   Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Arsic M, 2020, OZONE-SCI ENG, V42, P79, DOI 10.1080/01919512.2019.1598844
   Bah SM, 2020, ARRAY-NY, V5, DOI 10.1016/j.array.2019.100014
   Bakhtiyari K, 2014, NEURAL COMPUT APPL, V25, P1467, DOI 10.1007/s00521-014-1637-6
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Beli ILK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030037
   Chrysos GG, 2020, PROC CVPR IEEE, P7323, DOI 10.1109/CVPR42600.2020.00735
   Cliff D., 1996, From Animals to Animats 4. Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior, P506
   Deeba F, 2019, INT J ADV COMPUT SC, V10, P274
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   Fang YC, 2002, INT C PATT RECOG, P382, DOI 10.1109/ICPR.2002.1048319
   Fernández A, 2013, J MATH IMAGING VIS, V45, P76, DOI 10.1007/s10851-012-0349-8
   Ferreira PM, 2018, IEEE ACCESS, V6, P53930, DOI 10.1109/ACCESS.2018.2870063
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   Gupta Shreya, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P13, DOI 10.1007/978-981-13-8798-2_2
   Harandi M, 2018, IEEE T PATTERN ANAL, V40, P48, DOI 10.1109/TPAMI.2017.2655048
   Hu M, 2019, IEEE ACCESS, V7, P29882, DOI 10.1109/ACCESS.2019.2899024
   Hua WT, 2019, IEEE ACCESS, V7, P24321, DOI 10.1109/ACCESS.2019.2900231
   Kasinski A, 2010, PATTERN ANAL APPL, V13, P197, DOI 10.1007/s10044-009-0150-5
   Khan MZ, 2019, IEEE ACCESS, V7, P72622, DOI 10.1109/ACCESS.2019.2918275
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Kölsch M, 2004, INT C PATT RECOG, P107, DOI 10.1109/ICPR.2004.1334480
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Malov Dmitrii, 2020, Proceedings of 14th International Conference on Electromechanics and Robotics Zavalishins Readings. ER(ZR) 2019. Smart Innovation, Systems and Technologies (SIST 154), P501, DOI 10.1007/978-981-13-9267-2_41
   Monkaresi H, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P657, DOI 10.1145/2254556.2254678
   Moussa M, 2018, STUD INFORM CONTROL, V27, P127, DOI 10.24846/v27i1y201813
   Pan XZ, 2019, IEEE ACCESS, V7, P48807, DOI 10.1109/ACCESS.2019.2907271
   Ruiz-Garcia A, 2018, NEURAL COMPUT APPL, V29, P359, DOI 10.1007/s00521-018-3358-8
   Silwal R, 2020, MULTIMED TOOLS APPL, V79, P31027, DOI 10.1007/s11042-020-09559-1
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Tang Y, 2018, IEEE ACCESS, V6, P42532, DOI 10.1109/ACCESS.2018.2858278
   Thomas T., 2020, Machine Learning Approaches in Cyber Security Analytics
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Vishwanathan S, 2002, IEEE IJCNN, P2393, DOI 10.1109/IJCNN.2002.1007516
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
   Zhang Z, 2011, IEEE SIGNAL PROC LET, V18, P643, DOI 10.1109/LSP.2011.2165538
   Zhao F, 2020, MULTIVIEW FACE RECOG
NR 43
TC 4
Z9 4
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8471
EP 8497
DI 10.1007/s11042-021-11721-2
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800004
DA 2024-07-18
ER

PT J
AU Wang, B
   Xiang, W
   Wang, E
   Peng, Q
   Gao, P
   Wu, X
AF Wang, Bing
   Xiang, Wei
   Wang, Eric
   Peng, Qiang
   Gao, Pan
   Wu, Xiao
TI Learning-based high-efficiency compression framework for light field
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field video compression; Prediction structure; Sparse coding; View
   synthesis
ID NEURAL-NETWORK; IMAGE; PREDICTION
AB The massive amount of data usage for light field (LF) information poses grand challenges for efficient compression designs. There have been several LF video compression methods focusing on exploring efficient prediction structures reported in the literature. However, the number of possible prediction structures is infinite, and these methods fail to fully exploit the intrinsic geometry between views of an LF video. In this paper, we propose a deep learning-based high-efficiency LF video compression framework by exploiting the inherent geometrical structure of LF videos. The proposed framework is composed of several crucial components, namely sparse coding based on a universal view sampling method (UVSM) and a CNN-based LF view synthesis algorithm (LF-CNN), a high-efficiency adaptive prediction structure (APS), and a synthesized candidate reference (SCR)-based inter-frame prediction strategy. Specifically, instead of encoding all the views in an LF video, only parts of views are compressed while the remaining views are reconstructed from the encoded views with LF-CNN. The prediction structure of the selected views is able to adapt itself to the similarity between views. Inspired by the effectiveness of view synthesis algorithms, synthesized results are served as additional candidate references to further reduce inter-frame redundancies. Experimental results show that the proposed LF video compression framework can achieve an average of over 34% bitrate savings against state-of-the-art LF video compression methods over multiple LF video datasets.
C1 [Wang, Bing; Wang, Eric] James Cook Univ, Coll Sci & Engn, Cairns, Qld 4878, Australia.
   [Wang, Bing; Peng, Qiang; Wu, Xiao] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Xiang, Wei] La Trobe Univ, Sch Engn & Math Sci, Melbourne, Vic 3686, Australia.
   [Gao, Pan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
C3 James Cook University; Southwest Jiaotong University; La Trobe
   University; Nanjing University of Aeronautics & Astronautics
RP Wang, B (corresponding author), James Cook Univ, Coll Sci & Engn, Cairns, Qld 4878, Australia.; Wang, B (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
EM iceice_wang@outlook.com
RI Xiang, Wei/C-6765-2009
OI Xiang, Wei/0000-0002-0608-065X
FU China Scholarship Council (CSC) [201707000093]
FX The work of Bing Wang was partially supported by the China Scholarship
   Council (CSC) under Grant 201707000093.
CR Alam MM, 2015, PROC SPIE, V9599, DOI 10.1117/12.2188913
   [Anonymous], 2007, P 15 EUR SIGN PROC C
   Avramelos V, 2020, MULTIMED TOOLS APPL, V79, P12847, DOI 10.1007/s11042-019-08605-x
   Bakir N, 2018, IEEE IMAGE PROC, P1128, DOI 10.1109/ICIP.2018.8451597
   Bjontegaard G, 2001, VCEGM33
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen ZB, 2020, IEEE T CIRC SYST VID, V30, P566, DOI 10.1109/TCSVT.2019.2892608
   Dabala L, 2016, COMPUT GRAPH FORUM, V35, P401, DOI 10.1111/cgf.13037
   Dai F, 2015, IEEE IMAGE PROC, P4733, DOI 10.1109/ICIP.2015.7351705
   Fecker Ulrich, 2005, 2005 13th European Signal Processing Conference, P1
   Guillo L., 2018, Light Field Video Dataset Captured by a R8 Raytrix Camera (with Disparity Maps)
   Gul MSK, 2018, IEEE T IMAGE PROCESS, V27, P2146, DOI 10.1109/TIP.2018.2794181
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jia CM, 2019, IEEE J EM SEL TOP C, V9, P177, DOI 10.1109/JETCAS.2018.2886642
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Khoury J, 2019, INT CONF COMPUT NETW, P588, DOI [10.1109/ICCNC.2019.8685526, 10.1109/iccnc.2019.8685526]
   King DB, 2015, ACS SYM SER, V1214, P1
   Kovacs P. T., 2014, 3DTV C TRUE VIS CAPT, P1
   Lafruit G., 2016, ELECT IMAGING, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.5.SDA-426
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu DY, 2018, MULTIMED TOOLS APPL, V77, P31929, DOI 10.1007/s11042-018-6255-3
   Liu D, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574674
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Mehajabin N, 2019, IEEE IMAGE PROC, P3567, DOI [10.1109/icip.2019.8803668, 10.1109/ICIP.2019.8803668]
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Paul M, 2018, IEEE T BROADCAST, V64, P235, DOI 10.1109/TBC.2017.2781118
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Perra C, 2016, IEEE INT CONF MULTI
   Perwass C, 2012, PROC SPIE, V8291, DOI 10.1117/12.909882
   Sabater N, 2017, IEEE COMPUT SOC CONF, P1743, DOI 10.1109/CVPRW.2017.221
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Traore BB, 2018, ECOL INFORM, V48, P257, DOI 10.1016/j.ecoinf.2018.10.002
   Umer S, 2021, MULTIMED TOOLS APPL, V80, P34997, DOI 10.1007/s11042-020-09079-y
   Vijayalakshmi A, 2020, MULTIMED TOOLS APPL, V79, P15297, DOI 10.1007/s11042-019-7162-y
   Wang B, 2016, 2016 INT C IND POS I, P1, DOI DOI 10.1109/DEIV.2016.7763952
   Wang B, 2019, IEEE ACCESS, V7, P41183, DOI 10.1109/ACCESS.2019.2907572
   Wang G, 2016, IEEE T IMAGE PROCESS, V25, P5104, DOI 10.1109/TIP.2016.2603602
   Wang TC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073614
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   WU G, 2017, P IEEE C COMP VIS PA, P6319
   Wu GC, 2019, IEEE T IMAGE PROCESS, V28, P3261, DOI 10.1109/TIP.2019.2895463
   Wu GC, 2019, IEEE T PATTERN ANAL, V41, P1681, DOI 10.1109/TPAMI.2018.2845393
   Yan N, 2019, IEEE T CIRC SYST VID, V29, P840, DOI 10.1109/TCSVT.2018.2816932
   Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9
   Yun Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P539, DOI 10.1109/ICASSP.2014.6853654
   Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010
   Zhao S, 2016, 2016 VISUAL COMMUNIC, P1, DOI [DOI 10.1109/ICME.2016.7552952., DOI 10.1109/INEC.2016.7589349]
   Zhao SY, 2017, IEEE IMAGE PROC, P4562, DOI 10.1109/ICIP.2017.8297146
   Zhao ZH, 2018, IEEE INT CON MULTI
   Zhong R, 2016, PICT COD SYMP
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
NR 67
TC 3
Z9 3
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7527
EP 7560
DI 10.1007/s11042-022-11955-8
EA JAN 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600009
DA 2024-07-18
ER

PT J
AU Ping, P
   Zhang, XJ
   Yang, XH
   Hashems, YAA
AF Ping, Ping
   Zhang, Xiaojuan
   Yang, Xiaohui
   Hashems, Yara Abdelsattar Abdelmageed
TI A novel medical image encryption based on cellular automata with ROI
   position embedded
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region of interest; Medical image security; Life-like cellular automata;
   Histogram shifting
ID SELECTIVE ENCRYPTION; ALGORITHM; SYSTEMS; TRANSMISSION; CIPHER; SECURE
AB Medical images are critical to medical diagnosis and clinical treatment. However, the transmission of medical images over the Internet without any protection may cause malicious attacks and privacy leakage. Different from the natural image, the medical image contains a large number of black backgrounds. For privacy protection, the background of the medical image is unnecessary to be encrypted. Therefore, the encryption scheme based on the region of interest (ROI) is especially fit for medical image encryption, which paves a promising way to improve efficiency without sacrificing security. However, most of the existing ROI-based encryption schemes occupy exceptional space and time to transmit the marking information of ROI. To overcome this drawback, we present a novel ROI encryption scheme based on life-like cellular automata (life-like CA) and histogram shifting (HS). In the encryption stage, the life-like CA with balanced rules is used to encrypt ROI. Unlike most known image encryption algorithms, this model can support parallel computing. Furthermore, the marking information of ROI and electronic medical record (EMR) are embedded into the cipher image, which reduce the number of bits to be transmitted. The experiments and security analysis demonstrate that the proposed scheme can effectively protect ROI of different types and sizes of medical images, and is robust in resisting various attacks.
C1 [Ping, Ping; Zhang, Xiaojuan; Yang, Xiaohui; Hashems, Yara Abdelsattar Abdelmageed] Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
C3 Hohai University
RP Ping, P (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
EM pingpingnjust@163.com
FU National Natural Science Foundation of China [61902110]; Fundamental
   Research Funds for the Central Universities [B200202178]; National Key
   Technology Research and Development Program of theMinistry of Science
   and Technology of China [2018YFC0407105]; Key Technology Project of
   China Hueneng Group [SGTYHT/19-JS-217, HHNKJ19 H12]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61902110), the Fundamental Research Funds for the
   Central Universities under Grant No. B200202178, the National Key
   Technology Research and Development Program of theMinistry of Science
   and Technology of China under Grant No. 2018YFC0407105, Key Technology
   Project of China Hueneng Group under Grant (No. HHNKJ19 H12,
   SGTYHT/19-JS-217).
CR Abdmouleh MK, 2017, I C COMP GRAPH IM VI, P79, DOI 10.1109/CGiV.2017.10
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dridi M, 2016, IET IMAGE PROCESS, V10, P830, DOI 10.1049/iet-ipr.2015.0868
   Eppstein D, 2010, GAME OF LIFE CELLULAR AUTOMATA, P71, DOI 10.1007/978-1-84996-217-9_6
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Kabirirad S, 2019, J SUPERCOMPUT, V75, P7314, DOI 10.1007/s11227-019-02910-w
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Li M, 2018, SIGNAL PROCESS-IMAGE, V62, P164, DOI 10.1016/j.image.2018.01.002
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Machicao J, 2012, EXPERT SYST APPL, V39, P12626, DOI 10.1016/j.eswa.2012.05.020
   del Rey AM, 2016, EXPERT SYST APPL, V54, P379, DOI 10.1016/j.eswa.2016.02.001
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Norcen R, 2003, COMPUT BIOL MED, V33, P277, DOI 10.1016/S0010-4825(02)00094-X
   Noura M, 2018, MULTIMED TOOLS APPL, V77, P31397, DOI 10.1007/s11042-018-6051-0
   Patel V, 2019, HEALTH INFORM J, V25, P1398, DOI 10.1177/1460458218769699
   Peng HP, 2020, IEEE INTERNET THINGS, V7, P2432, DOI 10.1109/JIOT.2019.2957747
   Ping P, 2018, SIGNAL PROCESS, V150, P233, DOI 10.1016/j.sigpro.2018.04.018
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Shen YX, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106911
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Su YR, 2019, SIGNAL PROCESS-IMAGE, V72, P134, DOI 10.1016/j.image.2018.12.008
   Sun JL, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500730
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   van den Assem R., 1986, Computers & Security, V5, P36, DOI 10.1016/0167-4048(86)90116-1
   Wang QZ, 2018, MULTIMED TOOLS APPL, V77, P1715, DOI 10.1007/s11042-017-4349-y
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu JJ, 2015, OPT COMMUN, V338, P164, DOI 10.1016/j.optcom.2014.10.050
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiao D, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501935
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhou J, 2020, IEEE ACCESS, V8, P122210, DOI 10.1109/ACCESS.2020.3007550
NR 38
TC 7
Z9 7
U1 8
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7323
EP 7343
DI 10.1007/s11042-021-11799-8
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780500001
DA 2024-07-18
ER

PT J
AU De, A
   Saha, A
   Kumar, P
AF De, Anurag
   Saha, Ashim
   Kumar, Praveen
TI Fall detection approach based on combined displacement of spatial
   features for intelligent indoor surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance; Fall detection; Spatial feature; Abrupt fall;
   Classification
ID DETECTION SYSTEM
AB Automatic human fall detection plays a significant role in monitoring senior citizens. Detecting fall events in an intelligent indoor condition can be used as a medium to reduce the consequences of older people being alone. In recent researches, the vision-based approach provides encouraging and practical results for fall detection. This article proposes a fall detection approach, which analyses the fall movement based on a combination of multiple benchmark spatial features. Further, it classifies them into abrupt fall or high impact fall, normal fall, and activities of daily living resembling a falling posture. The steps required to build the model are divided into four main phases: frame extraction, moving object detection, fall event analysis, and keyframe-based decision-making. The extraction of frames depends on a pre-defined interval between frames to reduce the time complexity. The Gaussian mixture model based background subtraction algorithm is used for moving object detection and foreground segmentation. Fall event analysis is carried out evaluating the combined displacement of the spatial features of the foreground. Finally, the keyframes representing different fall events are classified using fuzzy logic. The model delivers a sensitivity of 96.66% and specificity of 95% in detecting fall and fall-like activities, respectively. The proposed system can differentiate between a normal fall and an abrupt fall with a recognition rate of 90% and 96.66%. The system provides an automatic notification based on the type of fall event for appropriate care.
C1 [De, Anurag; Saha, Ashim] NIT Agartala, Dept Comp Sci & Engn, Agartala, India.
   [Kumar, Praveen] VNIT Nagpur, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala; National Institute of Technology (NIT System);
   Visvesvaraya National Institute of Technology, Nagpur
RP De, A (corresponding author), NIT Agartala, Dept Comp Sci & Engn, Agartala, India.
EM anurag.de111@gmail.com; ashim.cse@nita.ac.in;
   praveenkumar@cse.vnit.ac.in
RI Kumar, Praveen/AAA-8584-2022; Saha, Ashim/E-9959-2018; Saha,
   Ashim/AAE-3596-2022; De, Anurag/AAE-4333-2022
OI Kumar, Praveen/0000-0003-4820-3088; Saha, Ashim/0000-0003-1987-1247; De,
   Anurag/0000-0003-4829-1583
FU TEQIP-III [F.NITA.2 (265-Estt)/2019/TEQIP -III/Research Grant/9469-71]
FX This research has been carried out in MMWT lab of NIT Agartala, India
   sponsored by TEQIP-III vide order no F.NITA.2 (265-Estt)/2019/TEQIP
   -III/Research Grant/9469-71 dated 17.12.2019.
CR [Anonymous], 2018, FALLS
   Bhandari S, 2017, IEEE GLOB CONF CONSU
   Buzin CL, 2018, IEEE LAT AM T, V16, P1084, DOI 10.1109/TLA.2018.8362141
   Chen MC, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/839124
   de Quadros T, 2018, IEEE SENS J, V18, P5082, DOI 10.1109/JSEN.2018.2829815
   Directalert, WIR EM RESP SYST
   Geertsema EE, 2019, J BIOMECH, V88, P25, DOI 10.1016/j.jbiomech.2019.03.007
   Gracewell JJ, 2021, J AMB INTEL HUM COMP, V12, P3581, DOI 10.1007/s12652-019-01600-y
   Han Q, 2020, IEEE ACCESS, V8, P17556, DOI 10.1109/ACCESS.2019.2962778
   Htun SNN, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060049
   Huang YD, 2019, ANN IEEE INT CONF SE, DOI 10.1109/sahcn.2019.8824827
   Hussain F, 2019, IEEE SENS J, V19, P4528, DOI 10.1109/JSEN.2019.2898891
   Jamil N, 2008, INTERNATIONAL SYMPOSIUM OF INFORMATION TECHNOLOGY 2008, VOLS 1-4, PROCEEDINGS, P2838
   Kalinga T, 2020, P A I C C AUT ROBOT, P706, DOI [10.1109/ICCAR49639.2020.9108003, 10.1109/iccar49639.2020.9108003]
   Kerdjidj O, 2020, J AMB INTEL HUM COMP, V11, P349, DOI 10.1007/s12652-019-01214-4
   Krumholz A, 2008, NEUROLOGY, V70, P1874, DOI 10.1212/01.wnl.0000312285.73631.ff
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lu KL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101995
   Makhlouf A, 2019, J AMB INTEL HUM COMP, V10, P1527, DOI 10.1007/s12652-018-0724-4
   MAMDANI EH, 1974, P I ELECTR ENG, V121, P1585, DOI 10.1049/piee.1974.0328
   Merrouche F, 2017, ACM PROCEEDINGS OF INTERNATIONAL CONFERENCE OF COMPUTING FOR ENGINEERING AND SCIENCE (ICCES'17), P29, DOI 10.1145/3129186.3129192
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-176
   Peng YF, 2019, PROCEDIA COMPUT SCI, V147, P271, DOI 10.1016/j.procs.2019.01.253
   Ramachandran A, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/2167160
   Rubenstein LZ, 2006, AGE AGEING, V35, P37, DOI 10.1093/ageing/afl084
   RUSSELLJONES DL, 1989, J NEUROL NEUROSUR PS, V52, P659, DOI 10.1136/jnnp.52.5.659
   Sabatini AM, 2016, IEEE T NEUR SYS REH, V24, P774, DOI 10.1109/TNSRE.2015.2460373
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sulman N, 2008, INT C PATT RECOG, P1850
   United Nations, 2017, WORLD POP AG 2017 HI
   Valaskova K, 2014, 2 INT C MAN INN BUS, P1
   Vollset SE, 2020, LANCET, V396, P1285, DOI 10.1016/S0140-6736(20)30677-2
   Wang H, 2017, IEEE T MOBILE COMPUT, V16, P511, DOI 10.1109/TMC.2016.2557795
   Wang XY, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00071
   Zhang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030946
   Zhanjun Hao, 2019, IOP Conference Series: Materials Science and Engineering, V569, DOI 10.1088/1757-899X/569/3/032068
   Zhao S., 2018, P 2018 CHI C HUMAN F, P1, DOI [10.1109/ICNSC.2018.8361365, DOI 10.1109/ICNSC.2018.8361365]
   Zitouni M., 2019, J. Sens. Technol., V9, P71, DOI [10.4236/jst.2019.94007, DOI 10.4236/JST.2019.94007]
NR 39
TC 2
Z9 2
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5113
EP 5136
DI 10.1007/s11042-021-11646-w
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700025
DA 2024-07-18
ER

PT J
AU Gupta, SK
   Kumar, S
   Tyagi, S
   Tanwar, S
AF Gupta, Sumit Kumar
   Kumar, Sachin
   Tyagi, Sudhanshu
   Tanwar, Sudeep
TI SSEER: Segmented sectors in energy efficient routing for wireless sensor
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Energy efficiency; Clustering; Routing protocol
ID SHARED SPECTRUM ACCESS; ENHANCE LIFETIME; PROTOCOLS
AB Nowadays, wireless sensor network (WSN) is an essential segment in the Internet of Things (IoT) paradigm. Essentially, WSN provides access to location, latest information of different objects of the environment, computing and communication for IoT monitoring. Considering distance as a critical factor, the communication process is energy healing as compared to computing; due to this, energy is found as one of the major constraints for WSN. As per the application, sensor devices may have either limited or unlimited power backup. Hence, they must connect directly from the power supply or battery, which needs energy-efficiency to sustain in the network. In this paper, we propose a segmented sector network that can work efficiently to increase the lifetime of the network. Heterogeneity parameters for sensor nodes are used, normal nodes transmit the information using direct diffusion & advanced nodes participate in the clustering process. With such integration of direct diffusion and clustering, the network lifetime and stability increase significantly by sectoring the network field. Simulation results of the proposed scheme show significant improvement in the energy efficiency by 11% and stability by 19% compared to the Z-SEP protocol.
C1 [Gupta, Sumit Kumar] AKTU, Dept ECE, SRMS Coll Engn Technol & Res, Lucknow, Uttar Pradesh, India.
   [Gupta, Sumit Kumar; Kumar, Sachin] Amity Sch Engn & Technol, Dept ECE, Lucknow Campus, Lucknow, Uttar Pradesh, India.
   [Tyagi, Sudhanshu] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
   [Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci Engn, Ahmadabad, Gujarat, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Thapar Institute of
   Engineering & Technology; Nirma University
RP Tyagi, S (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM skumar3@lko.amity.edu; s.tyagi@thapar.edu
RI Gupta, Sumit Kumar/ISB-2441-2023; kumar, sachin/JXY-1719-2024; Tanwar,
   Sudeep/AAI-6709-2020
OI Gupta, Sumit Kumar/0000-0003-2292-950X; Tanwar,
   Sudeep/0000-0002-1776-4651; Tyagi, Sudhanshu/0000-0002-2989-3098
CR Aderohunmu F.A., 2009, ENHANCED STABLE ELEC
   Agrawal A, 2018, AEU-INT J ELECTRON C, V94, P1, DOI 10.1016/j.aeue.2018.06.036
   Agrawal S., 2019, ENERGY EFFICIENT SEC, V46, P117
   Alghamdi TA, 2020, TELECOMMUN SYST, V74, P331, DOI 10.1007/s11235-020-00659-9
   Anandh SJ, 2020, WIRELESS PERS COMMUN, V114, P3419, DOI 10.1007/s11277-020-07539-0
   [Anonymous], 2017, OP FOG REF ARCH COMP
   Arikumar KS, 2020, ARAB J SCI ENG, V45, P10245, DOI 10.1007/s13369-020-04616-1
   BenSaleh MS, 2020, J SENSORS, V2020, DOI 10.1155/2020/9592836
   Boubrima A, 2017, IEEE T WIREL COMMUN, V16, P2723, DOI 10.1109/TWC.2017.2658601
   Faisal S, 2013, ARXIV13035364
   Famila S, 2020, WIRELESS PERS COMMUN, V110, P2195, DOI 10.1007/s11277-019-06837-6
   Gupta P, 2020, SOFT COMPUT, V24, P1737, DOI 10.1007/s00500-019-04000-8
   Haosong Gou, 2009, Proceedings of the 2009 Ninth IEEE International Conference on Computer and Information Technology. CIT 2009, P40, DOI 10.1109/CIT.2009.21
   Hari C., 2000, P 33 ANN HAW INT C S
   Hong C, 2018, AD HOC NETW, V70, P121, DOI 10.1016/j.adhoc.2017.11.013
   Intanagonwiwat C., 2000, P ACM MOBICOM, P56, DOI DOI 10.1145/345910.345920
   Jain N, 2012, NIRMA UNIV INT CONF
   Nori MK, 2020, WIREL NETW, V26, P4303, DOI 10.1007/s11276-020-02328-w
   Kumar H., 2017, J Telecommun Electr Comput Eng (JTEC), V9, P79
   Kumar N, 2014, J NETW COMPUT APPL, V46, P264, DOI 10.1016/j.jnca.2014.07.015
   Li Y, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1506-1
   Loganathan S, 2020, MULTIDIM SYST SIGN P, V31, P829, DOI 10.1007/s11045-019-00687-y
   Mahboub A, 2016, COLLOQ INF SCI TECH, P912, DOI 10.1109/CIST.2016.7805018
   Malaver A, 2015, SENSORS-BASEL, V15, P4072, DOI 10.3390/s150204072
   Micheletti M, 2019, IEEE ACCESS, V7, P125481, DOI 10.1109/ACCESS.2019.2938619
   Pati A, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON POWER, CONTROL & EMBEDDED SYSTEMS (ICPCES)
   Rishiwal V, 2018, IEEE GLOBE WORK
   Roy SK, 2015, IEEE ICC, P7059, DOI 10.1109/ICC.2015.7249452
   Sah DK, 2020, WIREL NETW, V26, P4723, DOI 10.1007/s11276-020-02351-x
   Sharma R, 2019, SCALABLE COMPUT-PRAC, V20, P55, DOI 10.12694/scpe.v20i1.1432
   Singh PK, 2017, IEEE INT CONF SIG PR, P647, DOI 10.1109/ISPCC.2017.8269757
   Smaragdakis G., 2004, Technical report
   Sudha C., 2020, Innovations in Electronics and Communication Engineering. Proceedings of the 8th ICIECE 2019. Lecture Notes in Networks and Systems (LNNS 107), P215, DOI 10.1007/978-981-15-3172-9_22
   Sundaran K, 2019, CLUSTER COMPUT, V22, pS9599, DOI 10.1007/s10586-017-1279-4
   Tanwar S., 2020, ENERGY EFFICIENT ROU, V1132
   Tanwar S, 2019, IEEE SYST J, V13, P313, DOI 10.1109/JSYST.2018.2818618
   Tyagi Sudhanshu, 2014, ZTE Communications, V12, P22, DOI 10.3969/j.issn.1673-5188.2014.03.003
   Tyagi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P78, DOI 10.1109/ICACCE.2015.20
   Tyagi S, 2015, PERVASIVE MOB COMPUT, V22, P90, DOI 10.1016/j.pmcj.2015.01.005
   Tyagi S, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1485, DOI 10.1109/ICACCI.2013.6637399
   Tyagi S, 2013, J NETW COMPUT APPL, V36, P623, DOI 10.1016/j.jnca.2012.12.001
NR 41
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34697
EP 34715
DI 10.1007/s11042-021-11829-5
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000740419000001
DA 2024-07-18
ER

PT J
AU Tahaoglu, G
   Ulutas, G
   Ustubioglu, B
   Ulutas, M
   Nabiyev, VV
AF Tahaoglu, Gul
   Ulutas, Guzin
   Ustubioglu, Beste
   Ulutas, Mustafa
   Nabiyev, Vasif V.
TI Ciratefi based copy move forgery detection on digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Copy move forgery; Ciratefi
ID WATERMARKING
AB There is an increase in the requirement of digital image authentication in law, journalism, and medicine, even in the industry. Copy move forgery is the most common method of forgery methods which are applied to digital images. The importance of verifying digital images that are used in important areas with real-time systems is increasing. Taking this need into consideration, in this study, a robust digital image copy move forgery detection method is proposed to realize in real time. The proposed method first extracts the textural form of the input image. The SIFT keypoints and descriptors are obtained from textual images thus more robust keypoints and descriptors will be utilized. Keypoint matching is realized to reveal the image is forged or not and suspicious regions are determined. The localization of forged pixel is realized via Ciratefi based approach. The post-processing step is applied to make the labeling pixels more accurate by utilizing Connected Component Labeling and morphological operation. The GRIP and CMH datasets are used to showing the effectiveness of the state-of-the-art and proposed method. The method is robust to geometric distortion attacks and image degradation attacks. The results indicate that the proposed method has the highest performance especially against geometric distortion attacks suck as rotation and scaling.
C1 [Tahaoglu, Gul; Ulutas, Guzin; Ustubioglu, Beste; Ulutas, Mustafa; Nabiyev, Vasif V.] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Tahaoglu, G (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM tahaoglugul@gmail.com
RI Tahaoglu, Gul/AAK-5783-2021; USTUBIOGLU, Beste/AAJ-8187-2021; Ulutas,
   Guzin/ABI-4484-2020
OI Tahaoglu, Gul/0000-0002-8828-5674; 
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [119E045]
FX This work was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) with Project No: 119E045.
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2017, INFORM SCIENCES, V418, P531, DOI 10.1016/j.ins.2017.08.044
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   de Araújo SA, 2011, INTEGR COMPUT-AID E, V18, P75, DOI 10.3233/ICA-2011-0358
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gani G, 2021, EVOL SYST-GER, V12, P503, DOI 10.1007/s12530-019-09309-1
   Haralick RM., 1992, CONNECTED COMPONENT
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   LI Y, 2019, IEEE T INF FORENSICS
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Lowe DG, 1999, P INT C COMP VIS SEP, P1150
   Luo W., 2009, PROC INT CONF PATT R, V4, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muzaffer G, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P595, DOI 10.1109/TSP.2017.8076056
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rey C., 2002, EURASIP Journal on Applied Signal Processing, V2002, P613, DOI 10.1155/S1110865702204047
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shi WC, 2016, CHINA COMMUN, V13, P139, DOI 10.1109/CC.2016.7405711
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Ulutas G, 2017, J DIGIT IMAGING, V30, P695, DOI 10.1007/s10278-017-9961-x
   Ustubioglu B., 2016, J ENERGY POWER ENG, V10, P358
   Ustubioglu B, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P185, DOI 10.1109/ELECO.2015.7394438
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang HY, 2019, MULTIMED TOOLS APPL, V78, P34585, DOI 10.1007/s11042-019-08169-w
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhu Y., 2015, MULTIMED TOOLS APPL, V75, P1
NR 44
TC 12
Z9 12
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22867
EP 22902
DI 10.1007/s11042-021-11503-w
EA JAN 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000740429700024
DA 2024-07-18
ER

PT J
AU Kumar, SG
   Sridhar, SS
   Hussain, A
   Manikanthan, SV
   Padmapriya, T
AF Kumar, S. Ganesh
   Sridhar, S. S.
   Hussain, Azham
   Manikanthan, S., V
   Padmapriya, T.
TI Personalized web service recommendation through mishmash technique and
   deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic web services; Deep lLearning; Adaptive learning; Resource
   description framework; Mishmash technique
ID ONTOLOGY; ALGORITHMS; MANAGEMENT; FRAMEWORK
AB Discovering the relevant web services for specific applications in the dynamically changing business world becomes very critical. Researchers have used many ontology based approaches to address the heterogeneity prevailing in many business problems. Our work focuses on Mishmash technique with rich semantics representation focusing on word segmentation and segregation to reduce load on the server side. We also propose a tokenized, stemmed feature weighted RDF data producing SPARQL result set for generating relevant web services. A deep learning model to learn the retrieved web services using adaptive learning approach was also used, so that a composition of relevant service domain is framed for reducing the time taken for future queries. The model classifier is dynamically built based on the new information's at every iteration, and once an acceptable range defined is achieved, the training accuracy is calculated. The trial results show that the relevant web services are grouped together by the weights in the deep learning model with a training accuracy of 94% by the Mishmash method when compared to Hyperclique method. The testing accuracy of Mishmash method was found to be 95.5% when compared to Hyperclique, which was found to be 92%. Thus the proposed Mishmash method along with Deep learning model can be used as a dynamic decision making model in the Service oriented architecture space.
C1 [Kumar, S. Ganesh; Sridhar, S. S.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Hussain, Azham] Univ Utara Malaysia, Sch Comp, Sintok 06010, Kedah, Malaysia.
   [Manikanthan, S., V; Padmapriya, T.] Melange Acad Res Associates, Pondicherry, India.
C3 SRM Institute of Science & Technology Chennai; Universiti Utara Malaysia
RP Kumar, SG (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM ganeshk1@srmist.edu.in; sridhars@srmist.edu.in; azham.h@uum.edu.my;
   manikanthmelangetech@gmail.com; padmapriyaa85@pec.edu
RI manikanth, venkatesan/GRR-1580-2022; Subramanian, Sridhar/ABE-7568-2021;
   Subramaniam, Ganesh Kumar/AFE-2230-2022
OI manikanth, venkatesan/0000-0002-0507-6691; 
CR [Anonymous], 1997, ISUCSTR9706
   Bai B, 2020, IEEE T SERV COMPUT, V13, P73, DOI 10.1109/TSC.2017.2681666
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Cai M, 2011, IEEE T SYST MAN CY A, V41, P574, DOI 10.1109/TSMCA.2010.2076395
   Cao FL, 2009, APPL MATH MODEL, V33, P1441, DOI 10.1016/j.apm.2008.02.009
   Ganesh Kumar S, 2015, J THEORETICAL APPL I, V74
   Islam MM, 2009, IEEE T SYST MAN CY B, V39, P1590, DOI 10.1109/TSMCB.2009.2021849
   Islam MM, 2009, IEEE T SYST MAN CY B, V39, P705, DOI 10.1109/TSMCB.2008.2008724
   Kumar G., 2017, J COMPUT THEOR NANOS, V14, P2021, DOI [10.1166/jctn.2017.6537, DOI 10.1166/JCTN.2017.6537]
   Kumar S., 2016, IJCTA, V9, P889
   Liang QH, 2011, IEEE T SYST MAN CY A, V41, P717, DOI 10.1109/TSMCA.2011.2132710
   Liu O, 2010, EXPERT SYST APPL, V37, P4626, DOI 10.1016/j.eswa.2009.12.046
   Subirats JL, 2008, LECT NOTES COMPUT SC, V5164, P803, DOI 10.1007/978-3-540-87559-8_83
   Nagy M, 2011, IEEE T SYST MAN CY A, V41, P693, DOI 10.1109/TSMCA.2011.2132704
   Nicoletti MD, 2009, STUD COMPUT INTELL, V258, P1
   Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013
   Sridhar S. S., 2009, Journal of Computer Sciences, V5, P843, DOI 10.3844/jcssp.2009.843.848
   Sridhar SS., 2011, INT J COMPUT ELECT E, V3, P1
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
NR 19
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9091
EP 9109
DI 10.1007/s11042-021-11452-4
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000739790800011
DA 2024-07-18
ER

PT J
AU Yu, L
   Zeng, Z
   Wang, HQ
   Pedrycz, W
AF Yu, Lei
   Zeng, Zhi
   Wang, Huiqi
   Pedrycz, Witold
TI Fractional-order differentiation based sparse representation for
   multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Fractional-order differentiation; Sparse representation;
   Histograms of oriented gradients
ID REGION-SEGMENTATION; TRANSFORM; FRAMEWORK
AB The aim of image fusion is to obtain a clear image by combining useful information coming from multiple images, so it is crucial to extract the salient features of source images as the activity level measurement effectively. In this paper, a novel algorithm called fractional-order differentiation based sparse representation (FD-SR) is presented for multi-focus image fusion. In this algorithm, the source images are first convoluted with fractional-order differentiation masks to acquire the feature maps, from which the histograms of oriented gradients (HOG) are computed to capture human vision-related salient information. Next, to construct a representative dictionary for sparse representation, the HOG patterns are then partitioned into many patches which are clustered to retain the structural information. From these clusters, compact sub-dictionaries are learned using orthogonal matching pursuit (OMP) respectively and then combined to form the overcomplete dictionary. Finally, the fused sub-images are reconstructed with the dictionary based on max l1 rule, and all these sub-images constitute the whole fused image. The experimental results on multi-focus image datasets and medical image dataset validate the effectiveness of the proposed method for image fusion task.
C1 [Yu, Lei; Zeng, Zhi] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Wang, Huiqi] Chongqing Univ, Coll Math & Stat, Chongqing 401331, Peoples R China.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2V4, Canada.
C3 Chongqing Normal University; Chongqing University; University of Alberta
RP Wang, HQ (corresponding author), Chongqing Univ, Coll Math & Stat, Chongqing 401331, Peoples R China.
EM wanghuiqi@cqu.edu.cn
OI Wang, Huiqi/0000-0003-3241-3865
FU National Natural Science Foundation of China [72071019]; Natural Science
   Foundation of Chongqing [cstc2020jcyj-msxmX0068,
   cstc2021jcyj-msxmX0185]; Fundamental Research Funds for the Central
   Universities [2020CDJ-LHZZ-026]
FX The authors would like to thank the anonymous reviewers for their
   critical and constructive comments and suggestions. Thank Wenchang Gao
   for conducting more comparison experiments on image fusion datasets.
   This research is partially supported by grant from the National Natural
   Science Foundation of China (No. 72071019), grant from the Natural
   Science Foundation of Chongqing (No. cstc2020jcyj-msxmX0068, No.
   cstc2021jcyj-msxmX0185), and grant from the Fundamental Research Funds
   for the Central Universities (No. 2020CDJ-LHZZ-026).
CR Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472
   Cheng BY, 2018, INFRARED PHYS TECHN, V91, P153, DOI 10.1016/j.infrared.2018.04.004
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   David SA, 2011, REV BRAS ENSINO FIS, V33, DOI 10.1590/S1806-11172011000400002
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Gai D, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107681
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Guo BL, 2008, CHIN OPT LETT, V6, P338
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   He KJ, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.015011
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jiang Q, 2017, IEEE ACCESS, V5, P20286, DOI 10.1109/ACCESS.2017.2758644
   Jin X, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.025023
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li XS, 2021, SIGNAL PROCESS, V184, DOI 10.1016/j.sigpro.2021.108062
   Liang JL, 2012, IEEE T IMAGE PROCESS, V21, P2898, DOI 10.1109/TIP.2012.2183140
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2007, PATTERN RECOGN LETT, V28, P166, DOI 10.1016/j.patrec.2006.06.019
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Luo XQ, 2014, INT C PATT RECOG, P1049, DOI 10.1109/ICPR.2014.190
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Toet A, 1997, DISPLAYS, V18, P85, DOI 10.1016/S0141-9382(97)00014-0
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wan T, 2009, IEEE T MULTIMEDIA, V11, P624, DOI 10.1109/TMM.2009.2017640
   Wei CY, 2018, MULTIMED TOOLS APPL, V77, P8327, DOI 10.1007/s11042-017-4731-9
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang Y, 2016, IEEE ACCESS, V4, P4573, DOI 10.1109/ACCESS.2016.2599403
   Yin WL, 2019, OPT LASER TECHNOL, V110, P62, DOI 10.1016/j.optlastec.2018.07.045
   Yu S, 2021, MULTIMED TOOLS APPL, V80, P5673, DOI 10.1007/s11042-020-09877-4
   Zaveri T, 2011, J PATTERN RECOGNIT R, V6, P140, DOI 10.13176/11.175
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang QH, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.5.057006
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang ZC, 2021, MULTIMED TOOLS APPL, V80, P2847, DOI 10.1007/s11042-020-09647-2
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
   Zong JJ, 2017, BIOMED SIGNAL PROCES, V34, P195, DOI 10.1016/j.bspc.2017.02.005
NR 60
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4387
EP 4411
DI 10.1007/s11042-021-11758-3
EA DEC 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000728243900003
DA 2024-07-18
ER

PT J
AU Sun, FY
   Lv, ZW
AF Sun, Fuyan
   Lv, Zongwang
TI A secure image encryption based on spatial surface chaotic system and
   AES algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial surface chaotic system; Image encryption; Cryptography
ID SELF-ADAPTIVE PERMUTATION; HYBRID GENETIC ALGORITHM; SCHEME; DIFFUSION;
   MAP
AB We propose a secure image encryption method using the combination of spatial surface chaotic system(SSCS) and the improved AES algorithm structure. In this scheme, the key of cryptosystem is obtained from the SSCS, this system has better encryption characteristics and its model structure fits the image exactly, and it is designed for image cryptosystems contrasted with the existing a lot of low-dimensional chaotic maps and couple map lattices. The plain image is encrypted with the improved AES algorithm and by performing each round encryption, the key is generated by SSCS in each round, an improved permutation algorithm(IPA) and a reverse diffusion have been presented. The proposed scheme not only improves the efficiency because of the same key stream is shared, but also increases the diffusion effect which can resist differential attack. The presented scheme provides huge key space to deal with the brute-force attacks using the round keys obtained by SSCS, and also very sensitive to initial values of SSCS and plain image. The results of simulation analysis and performance evaluation show that the presented cryptosystem provides strong security performance and may be used as a candidate for real-time implementations.
C1 [Sun, Fuyan; Lv, Zongwang] Henan Univ Technol, Sch Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
C3 Henan University of Technology
RP Sun, FY (corresponding author), Henan Univ Technol, Sch Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
EM fuyan_sun@126.com; zongwang_lv@126.com
OI sun, fuyan/0000-0001-8531-5674
FU Basic Scientific Research Special Fund of Henan University of Technology
   [2015RCJH18]; Open Project of the Key Laboratory of Food Information
   Processing and Control of Ministry of Education [KFJJ-2020-109]
FX The authors would like to thank the Basic Scientific Research Special
   Fund of Henan University of Technology(Grant No.2015RCJH18), and the
   Open Project of the Key Laboratory of Food Information Processing and
   Control of Ministry of Education(Grant No.KFJJ-2020-109) for supporting
   this research.
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alabaichi A, 2015, 2015 FIFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION PROCESSING AND COMMUNICATIONS (ICDIPC), P44, DOI 10.1109/ICDIPC.2015.7323004
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Cambel A., 1993, APPL CHAOS THEORY PA
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   CHEN G, 2003, INT J BIFURCAT CHAOS, V15, P867
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   D'souza FJ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P647, DOI 10.1109/CCAA.2017.8229881
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   HUANG LQ, 2018, ENTROPY-SWITZ, V20
   Juremi J., 2012, P INT C CYBER SECURI, P38, DOI DOI 10.1109/CYBERSEC.2012.6246172
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu J, 2017, OPT COMMUN, V396, P174, DOI 10.1016/j.optcom.2017.03.049
   Liu ST, 2003, INT J BIFURCAT CHAOS, V13, P1163, DOI 10.1142/S0218127403007126
   Mahmood S, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5823230
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Qiao ZC, 2020, AEU-INT J ELECTRON C, V121, DOI 10.1016/j.aeue.2020.153205
   Ran QW, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1958-y
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
   Zhou SH, 2016, AEU-INT J ELECTRON C, V70, P1, DOI 10.1016/j.aeue.2015.08.010
NR 53
TC 7
Z9 8
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3959
EP 3979
DI 10.1007/s11042-021-11690-6
EA NOV 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722484100003
DA 2024-07-18
ER

PT J
AU Huang, YB
   Hou, HX
   Chen, TF
   Li, H
   Zhang, QY
AF Huang, Yi-bo
   Hou, Hexiang
   Chen, Tengfei
   Li, Hao
   Zhang, Qiu-yu
TI Long sequence biometric hashing authentication based on 2D-SIMM and CQCC
   cosine values
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech content authentication; Biometric security template; 2D-SIMM;
   CQCC cosine; Discrimination; Unidirectional
ID TEMPLATE PROTECTION; ALGORITHM; ROBUST; AUDIO; MFCC; TRANSFORM
AB The existing speech authentication algorithms hash extracted speech features directly and saved them to the cloud, which is easy to cause speech feature leakage. In the process of constructing hashing, the utilization efficiency of speech feature is poor, and the short hashing sequence will lead to the lack of discrimination of hashing sequence and the deviation of authentication. In order to solve the above problems, a long sequence biometric hashing authentication algorithm based on two-dimensional Sine ICMI Cmodulation map (2D-SIMM) and constant Q cepstral coefficients (CQCC) cosine was proposed. First, this algorithm extracts the CQCC of the speech signal, then obtains the eigenvalue of the space cosine distance of the adjacent speech frame CQCC, and finally performs projection mapping between the eigenvalue and the pseudorandom matrix generated by 2D-SIMM to construct a biometric hashing sequence. This paper evaluates the proposed robust feature schemes of MFCC and CQCC space cosine distance through experiments. The experimental results show that CQCC spatial distance combined with 2D-SIMM biometrics characteristics can reach 10(-21). when the threshold is 0.35. The BER mean was only 0.0383 for maintaining the robustness of operation for different contents. When the SNR is -5 dB, the matching rate of different noises can reach 45%. At the same time, it also improves the security of the biological template, and the overall performance is greatly improved compared with the existing algorithm.
C1 [Huang, Yi-bo; Hou, Hexiang; Chen, Tengfei; Li, Hao] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM 17853487160@163.com; lhnwnu@163.com; zhangqylz@163.com
RI zhang, qiu/GXG-5600-2022
OI /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Youth Science
   and Technology Fund of Gansu Province of China [1606RJYA274]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61862041 and Youth Science and
   Technology Fund of Gansu Province of China under Grant 1606RJYA274.
CR Abdullahi SM, 2020, IEEE T INF FOREN SEC, V15, P2587, DOI 10.1109/TIFS.2020.2971142
   [Anonymous], 2015, J INF HIDING MULTIME
   Atighehchi K, 2019, FUTURE GENER COMP SY, V101, P819, DOI 10.1016/j.future.2019.07.022
   Boujelben O, 2018, J SYST ARCHITECT, V88, P54, DOI 10.1016/j.sysarc.2018.05.010
   Cao DY, 2017, WIRELESS PERS COMMUN, V95, P2073, DOI 10.1007/s11277-017-3958-0
   Chan DKC, 2021, INFECT CONT HOSP EP, V42, P375, DOI 10.1017/ice.2020.245
   Chen WS, 2019, LECT NOTES COMPUT SC, V11936, P278, DOI 10.1007/978-3-030-36204-1_23
   Chen YZ, 2019, SIGNAL PROCESS, V154, P314, DOI 10.1016/j.sigpro.2018.09.013
   Deng MQ, 2020, NEURAL NETWORKS, V130, P22, DOI 10.1016/j.neunet.2020.06.015
   George A, 2020, IEEE T INF FOREN SEC, V15, P42, DOI 10.1109/TIFS.2019.2916652
   Gomez-Barrero M, 2016, IEEE COMPUT SOC CONF, P259, DOI 10.1109/CVPRW.2016.39
   Hamd M.H., 2019, INT J MOD ED COMPUT, V5, P1, DOI DOI 10.5815/IJMECS.2019.05.01
   Hong-xia W, 2015, CHINESE J ELECTRON, V03, P579
   Huang YB, 2020, MULTIMED TOOLS APPL, V79, P24889, DOI 10.1007/s11042-020-09211-y
   Huang Yibo, 2015, Journal of Huazhong University of Science and Technology (Natural Science Edition), V43, P124, DOI 10.13245/j.hust.150226
   Jain V, 2019, J DISCRET MATH SCI C, V22, P191, DOI 10.1080/09720529.2019.1582867
   JAMI SK, 2019, 2019 IEEE INT C CONS, P1
   Jiang YT, 2019, MULTIMED TOOLS APPL, V78, P30011, DOI 10.1007/s11042-018-6802-y
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P1883, DOI 10.1007/s11042-020-09708-6
   [李金凤 Li Jinfeng], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P89
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Ouali C, 2016, MULTIMED TOOLS APPL, V75, P9145, DOI 10.1007/s11042-015-3081-8
   Sandhya M, 2017, SIGNAL PROC SEC TEC, P323, DOI 10.1007/978-3-319-47301-7_14
   Selwal A., 2020, DECISION ANAL APPL I, P173
   Shao H., 2020, ARXIV200403303
   Sonnleitner R, 2016, IEEE-ACM T AUDIO SPE, V24, P409, DOI 10.1109/TASLP.2015.2509248
   Tak H., 2020, P SPEAK OD WORKSH, P333
   Nguyen AT, 2019, ADV INTELL SYST, V935, P723, DOI 10.1007/978-3-030-19063-7_58
   Weishi Z., 2016, CHIN J ENTIFIC INSTR
   Yang JC, 2019, DIGIT SIGNAL PROCESS, V89, P30, DOI 10.1016/j.dsp.2019.02.018
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang Qiuyu, 2017, Journal of Huazhong University of Science and Technology (Natural Science Edition), V45, P33, DOI 10.13245/j.hust.170907
   Zhang QY., 2019, INT J NETW SECUR, V21, P259
   Zhong DX, 2019, IEEE T INF FOREN SEC, V14, P3140, DOI 10.1109/TIFS.2019.2912552
NR 38
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2873
EP 2899
DI 10.1007/s11042-021-11708-z
EA NOV 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000715720000001
DA 2024-07-18
ER

PT J
AU Shaik, AS
   Karsh, RK
   Islam, M
   Laskar, RH
AF Shaik, Abdul Subhani
   Karsh, Ram Kumar
   Islam, Mohiul
   Laskar, Rabul Hussain
TI A review of hashing based image authentication techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Perceptual image hashing; Image authentication; Tamper detection;
   Security
ID RING PARTITION; FEATURE POINTS; ROBUST; SECURE; TRANSFORM; ALGORITHM;
   PATTERN; SCHEME; ANGLE
AB In the recent digitization era, image hashing is a key technology, including image recognition, authentication and manipulation detection, among many multimedia security applications. The primary challenge in hashing schemes is to extract its robust feature. For a better understanding and design of a robust image hashing algorithm, it is very crucial to look into few important parameters like discrimination, robustness, reliability, etc. This paper reflects a detailed study of the existing literature on hashing-based image authentication techniques. This work provides a systematic overview and highlights the merits and demerits associated with various state-of-the-art techniques. In particular, the basic features and categories of image authentication techniques based on hashing are explored along with their properties. Moreover, different performance measures such as output metrices, receiver operating characteristics (ROC) parameters, execution time, etc., have been discussed in this work. The paper also compares the performances of various existing algorithms related to different content preserving operations on diverse data sets. This paper summarizes all the techniques and provides the most optimum solutions in regard to image hashing techniques based on different parameters.
C1 [Shaik, Abdul Subhani; Karsh, Ram Kumar; Laskar, Rabul Hussain] Natl Inst Technol Silchar, Dept ECE, Silchar 788010, Assam, India.
   [Shaik, Abdul Subhani; Islam, Mohiul] CMR Coll Engn & Technol, Dept ECE, Hyderabad 501401, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Shaik, AS (corresponding author), Natl Inst Technol Silchar, Dept ECE, Silchar 788010, Assam, India.; Shaik, AS (corresponding author), CMR Coll Engn & Technol, Dept ECE, Hyderabad 501401, Telangana, India.
EM subhanijuly25@gmail.com
RI Laskar, Rabul Hussain/AFU-7180-2022; , ABDUL SUBHANI SHAIK/AAA-6258-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; , ABDUL SUBHANI
   SHAIK/0000-0003-1553-7380; Karsh, Ram/0000-0002-2341-341X
CR Abdullahi SM, 2020, IEEE T INF FOREN SEC, V15, P2587, DOI 10.1109/TIFS.2020.2971142
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   ALI N, 2020, IOP C SER MAT SCI EN
   BISWAS R, 2019, NEUROCOMPUTING
   Chen YC, 2014, OPTIK, V125, P5582, DOI 10.1016/j.ijleo.2014.07.006
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   Das UK, 2018, LECT NOTE NETW SYST, V19, P141, DOI 10.1007/978-981-10-5523-2_14
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Ding KM, 2018, ALGORITHMS, V11, DOI 10.3390/a11010006
   Du L, 2021, MULTIMED TOOLS APPL, V80, P22927, DOI 10.1007/s11042-020-08736-6
   Ge LW, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102577
   Gharde ND, 2018, MULTIMED TOOLS APPL, V77, P30815, DOI 10.1007/s11042-018-6115-1
   Ghouti L, 2018, MULTIMED TOOLS APPL, V77, P19895, DOI 10.1007/s11042-017-5355-9
   Hadmi A., 2012, WATERMARKING, V2, P68
   Hamid H, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106648
   Hosny KM, 2018, CIRC SYST SIGNAL PR, V37, P5441, DOI 10.1007/s00034-018-0822-8
   Huang ZQ, 2021, IEEE T MULTIMEDIA, V23, P1516, DOI 10.1109/TMM.2020.2999188
   Huang ZQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1389, DOI 10.1145/3240508.3240690
   Jin L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P916, DOI 10.1145/3394171.3414022
   Jin L, 2019, IEEE T NEUR NET LEAR, V30, P1429, DOI 10.1109/TNNLS.2018.2869601
   Karsh RK, 2018, MULTIMED TOOLS APPL, V77, P25409, DOI 10.1007/s11042-018-5799-6
   Karsh RK, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0179-0
   Karsh RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3639-6
   Kekre HB, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN TECHNOLOGY AND ENGINEERING (ICATE)
   Khelaifi F, 2020, MULTIMED TOOLS APPL, V79, P19025, DOI 10.1007/s11042-020-08619-w
   Khelifi F, 2010, IEEE T IMAGE PROCESS, V19, P981, DOI 10.1109/TIP.2009.2038637
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Li YN, 2012, IEEE T IMAGE PROCESS, V21, P1963, DOI 10.1109/TIP.2011.2171698
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Lu HM, 2021, IEEE T FUZZY SYST, V29, P166, DOI 10.1109/TFUZZ.2020.2984991
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Lv XD, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/859859
   Ma Q, 2018, MULTIMED TOOLS APPL, V77, P7131, DOI 10.1007/s11042-017-4625-x
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Ng WWY, 2020, NEUROCOMPUTING, V399, P171, DOI 10.1016/j.neucom.2020.02.046
   Ouyang JL, 2015, DIGIT SIGNAL PROCESS, V41, P98, DOI 10.1016/j.dsp.2015.03.006
   Patil V. H., 2019, Journal Computing, V14, P210
   Paul M, 2021, NEURAL COMPUT APPL, V33, P13317, DOI 10.1007/s00521-021-05956-1
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Pun CM, 2018, MULTIMED TOOLS APPL, V77, P11609, DOI 10.1007/s11042-017-4809-4
   Qin C, 2019, IEEE ACCESS, V7, P45460, DOI 10.1109/ACCESS.2019.2908029
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2018, SIGNAL PROCESS, V142, P194, DOI 10.1016/j.sigpro.2017.07.019
   Qin C, 2016, DISPLAYS, V45, P26, DOI 10.1016/j.displa.2016.09.003
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Sebastian LS, 2015, PROCEDIA COMPUT SCI, V46, P1554, DOI 10.1016/j.procs.2015.02.081
   Shen Q, 2019, ARTIFICIAL INTELLIGE
   Shen Q, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107244
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang J., 2017, 2017 Conference on Lasers and Electro-Optics Pacific Rim (CLEO-PR), P1
   Tang Z., 2012, INT J DIGITAL CONTEN, V3, P39, DOI DOI 10.4156/JDCTA.V0L6.ISSUE23.5
   Tang ZJ, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00509-3
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Tang ZJ, 2018, NEUROCOMPUTING, V308, P147, DOI 10.1016/j.neucom.2018.04.057
   Tang ZJ, 2017, SIGNAL PROCESS, V137, P240, DOI 10.1016/j.sigpro.2017.02.008
   Tang ZJ, 2016, COMPUT SECUR, V62, P133, DOI 10.1016/j.cose.2016.07.006
   Tang ZJ, 2016, AEU-INT J ELECTRON C, V70, P833, DOI 10.1016/j.aeue.2016.03.010
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2015, DIGIT SIGNAL PROCESS, V43, P17, DOI 10.1016/j.dsp.2015.05.002
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2014, IET IMAGE PROCESS, V8, P142, DOI 10.1049/iet-ipr.2013.0332
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang ZJ, 2013, SIGNAL PROCESS, V93, P2061, DOI 10.1016/j.sigpro.2013.01.008
   Tang ZJ, 2011, FUND INFORM, V106, P75, DOI 10.3233/FI-2011-377
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Tao F, 2019, MEASUREMENT, V134, P866, DOI 10.1016/j.measurement.2018.11.079
   Tian X, 2021, IEEE T MULTIMEDIA, V23, P1210, DOI 10.1109/TMM.2020.2994509
   Vadlamudi LN, 2018, ICT EXPRESS, V4, P154, DOI 10.1016/j.icte.2017.12.004
   Wang H, 2018, SECUR COMMUN NETW, DOI [10.1155/2018/6853696, 10.1155/2018/1402697]
   Wang XF, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115642
   Wang ZJ, 2021, IEEE T MULTIMEDIA, V23, P1274, DOI 10.1109/TMM.2020.2995267
   Weng L, 2011, LECT NOTES COMPUT SC, V7025, P108, DOI 10.1007/978-3-642-24712-5_9
   Wu D, 2009, SIGNAL PROCESS, V89, P2415, DOI 10.1016/j.sigpro.2009.05.016
   Xiang SJ, 2011, LECT NOTES COMPUT SC, V6730, P83, DOI 10.1007/978-3-642-24556-5_5
   Xiang SJ, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-77
   Yan CP, 2016, IEEE T INF FOREN SEC, V11, P2664, DOI 10.1109/TIFS.2016.2594136
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   YANG H, 2018, APPL SCI
   YANG J, 2019, PATTERN RECOGNIT
   Yao H, 2020, J REAL-TIME IMAGE PR, V17, P41, DOI 10.1007/s11554-019-00904-8
   Zhai HJ, 2021, IEEE T CIRC SYST VID, V31, P742, DOI 10.1109/TCSVT.2020.2991171
   Zhang TL, 2021, COMPUTING, V103, P231, DOI 10.1007/s00607-020-00832-7
   Zhang XY, 2020, INFECT DIS POVERTY, V9, DOI 10.1186/s40249-020-00691-6
   Zhao Y, 2020, IEEE ACCESS, V8, P26041, DOI 10.1109/ACCESS.2020.2970757
   Zhenjun Tang, 2013, ICIC Express Letters, V7, P2961
   Zhenjun Tang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P237, DOI 10.1007/978-3-642-35236-2_24
   Zhou M, 2019, PATTERN RECOGN, V95, P114, DOI 10.1016/j.patcog.2019.06.005
   Zhu L, 2020, IEEE T IMAGE PROCESS, V29, P4643, DOI 10.1109/TIP.2020.2974065
NR 92
TC 11
Z9 11
U1 4
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2489
EP 2516
DI 10.1007/s11042-021-11649-7
EA OCT 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712714400003
DA 2024-07-18
ER

PT J
AU Deorukhkar, K
   Ket, S
AF Deorukhkar, Kalpana
   Ket, Satish
TI A detailed review of prevailing image captioning methods using deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Image Captioning; CNN; RNN; Attention Mechanism; GAN
AB Image captioning is a challenging task of computer vision and natural language processing. The big challenge lies in obtaining semantic information from images and translating that into the human language using machines. The interaction of computer vision and natural language processing further increases the complexity of image captioning. Notably, research has been carried out in image captioning to narrow down the semantic gap using deep learning techniques effectively. Deep learning techniques are proficient in dealing with the complexities of image captioning. A detailed study is carried out to identify the various state-of-the-art techniques for image captioning. The working algorithm of technique, positive highlights, and weakness of every technique is discussed in this paper. We also discussed the quantitative evaluation measures used for deep learning techniques and available datasets.
C1 [Deorukhkar, Kalpana] Fr CRCE, Dept Comp Engn, Mumbai, Maharashtra, India.
   [Ket, Satish] RGIT, Dept Comp Engn, Mumbai, Maharashtra, India.
RP Deorukhkar, K (corresponding author), Fr CRCE, Dept Comp Engn, Mumbai, Maharashtra, India.
EM kalpanas@fragnel.edu.in; satish.ket@mctrgit.ac.in
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2006, Proceedings of the Human Language Technology Conference of the NAACL, Main Conference
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bin Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1345, DOI 10.1145/3123266.3123391
   Cao PF, 2019, NEURAL PROCESS LETT, V50, P103, DOI 10.1007/s11063-018-09973-5
   Chen F, 2019, SEMANTIC AWARE IMAGE
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen TL, 2018, LECT NOTES COMPUT SC, V11214, P527, DOI 10.1007/978-3-030-01249-6_32
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Cho K., 2014, ARXIV14061078
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Dognin P, 2019, PROC CVPR IEEE, P10455, DOI 10.1109/CVPR.2019.01071
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Gimenez J., 2007, ACL WORKSHOP, P256
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Huang Z, 2020, INT C INT INF PROC S
   Jin J., 2015, Aligning where to see and what to tell: image caption with region-based attention and scene factorization
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li S, 2019, IEEE T EM TOP COMP I, V3, P297, DOI 10.1109/TETCI.2019.2892755
   Li XY, 2019, IEEE T MULTIMEDIA, V21, P2117, DOI 10.1109/TMM.2019.2896516
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mavridis, 2007, THESIS I TECHNOL DEP
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   REN Z, 2017, PROC CVPR IEEE, P1151, DOI DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shi Haichao., 2018, Proceedings of the 10th International Conference on Internet Multimedia Computing and Service, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wallraven C., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P484, DOI 10.1109/FG.2011.5771446
   Wang LW, 2017, ADV NEUR IN, V30
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan SY, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107329
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
NR 51
TC 6
Z9 6
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1313
EP 1336
DI 10.1007/s11042-021-11293-1
EA SEP 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000701393200003
DA 2024-07-18
ER

PT J
AU Vatavu, RD
   Rusu, PP
   Schipor, OA
   Schipor, MD
AF Vatavu, Radu-Daniel
   Rusu, Petruta-Paraschiva
   Schipor, Ovidiu-Andrei
   Schipor, Maria-Doina
TI Preferences of people with visual impairments for augmented and mediated
   vision: A vignette experiment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented reality; Mediated reality; Alternate reality; Mediated vision;
   Smartglasses; Head-mounted displays; Visual impairments; Assisted
   vision; Vignette study; Questionnaire; Interview
ID QUALITY-OF-LIFE; CHILDREN; REALITY; YOUNG; DEPRESSION; ACUITY; IMPACT
AB We examine in this work the desirability and preferences of people with visual impairments for assistive vision, i.e., vision rehabilitation and enhancement, delivered by smart eyewear devices. We present results from a vignette experiment with N = 17 participants with visual impairments, who reported their preferences regarding 32 hypothetical scenarios that we formulated for assistive vision, e.g., long-distance vision, peripheral vision, highly sensitive perception of colors, thermal vision, night vision, and others. Our results show higher desirability (average score of 4.21 out of 5) for assistive vision scenarios addressing rehabilitation of lost vision functions compared to scenarios that propose Augmented Reality-based enhancements of human vision (3.76) or visual perception in other regions of the electromagnetic spectrum, such as thermal or infrared vision (3.36). To understand these results, we conduct a second vignette study involving N = 178 participants without visual impairments, for which we report lower desirability for vision augmentation (3.44/5) compared to participants with visual impairments (3.75/5). We discuss implications of our results for augmented and mediated vision delivered by smart eyewear devices.
C1 [Vatavu, Radu-Daniel; Schipor, Ovidiu-Andrei; Schipor, Maria-Doina] Univ Stefan Cel Mare Suceava, MANSiD Res Ctr, MintViz Lab, Suceava 720229, Romania.
   [Rusu, Petruta-Paraschiva] Univ Stefan Cel Mare Suceava, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava; Stefan cel Mare University of
   Suceava
RP Vatavu, RD (corresponding author), Univ Stefan Cel Mare Suceava, MANSiD Res Ctr, MintViz Lab, Suceava 720229, Romania.
EM radu.vatavu@usm.ro; petruta.rusu@usm.ro; schipor@eed.usv.ro;
   doina.schipor@usm.ro
RI Vatavu, Radu-Daniel/AAA-3282-2022; Schipor, Ovidiu-Andrei/CAF-1234-2022;
   Vatavu, Radu-Daniel/F-1820-2017
OI Schipor, Ovidiu-Andrei/0000-0003-1614-2196; Rusu,
   Petruta-Paraschiva/0000-0003-0868-6054; Vatavu,
   Radu-Daniel/0000-0002-7631-6445
FU Ministry of Research and Innovation, CNCS-UEFISCDI within PNCDI III
   [PN-III-P1-1.1-TE-2016-2173 (TE141/2018)]; European Regional Development
   Fund [671/09.04.2015]
FX This work was supported by a grant of the Ministry of Research and
   Innovation, CNCS-UEFISCDI, project no. PN-III-P1-1.1-TE-2016-2173
   (TE141/2018), within PNCDI III. The work was carried out in the Machine
   Intelligence and Information Visualization Lab (MintViz) of the MANSiD
   Research Center. The infrastructure was provided by the University of
   Suceava and was partially supported from the project "Integrated center
   for research, development and innovation in Advanced Materials,
   Nanotechnologies, and Distributed Systems for fabrication and control",
   No. 671/09.04.2015, Sectoral Operational Program for Increase of the
   Economic Competitiveness, co-funded from the European Regional
   Development Fund. The HoloLens device used in this work was kindly
   provided by OSF Global Services, the Mobile Division, Suceava.
CR Abdelrahman Y, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P245, DOI 10.1145/3282894.3282920
   Aiordachioae A, 2020, 2020 15TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS), P146, DOI [10.1109/DAS49615.2020.9108915, 10.1109/das49615.2020.9108915]
   Aiordchioae A., 2020, P 19 INT C MOB UB MU, P329, DOI [https://doi.org/10.1145/3428361.3432080, DOI 10.1145/3428361.3432080]
   [Anonymous], 2018, ARXIV180408386CS
   Atzmüller C, 2010, METHODOLOGY-EUR, V6, P128, DOI 10.1027/1614-2241/a000014
   Augestad LB, 2017, J VISUAL IMPAIR BLIN, V111, P411
   Azenkot Shiri, 2017, ACM SIGACCESS Accessibility and Computing, P19, DOI 10.1145/3167902.3167905
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bach M, 1996, OPTOMETRY VISION SCI, V73, P49, DOI 10.1097/00006324-199601000-00008
   Bach M, 2014, MANUAL FREIBURG VISI
   Barrera D, 2007, INT SOCIOL, V22, P367, DOI 10.1177/0268580907076576
   Barter C., 1999, SOCIAL RES UPDATE, V25, P1, DOI DOI 10.3171/jns.2000.93.1.0033
   Ben-Zur H, 2005, J VISUAL IMPAIR BLIN, V99, P151, DOI 10.1177/0145482X0509900304
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Birnbaum MH, 1999, PSYCHOL METHODS, V4, P243, DOI 10.1037/1082-989X.4.3.243
   Brady E., 2013, P SIGCHI C HUM FACT, P2117
   Brunes A, 2019, HEALTH QUAL LIFE OUT, V17, DOI 10.1186/s12955-019-1096-y
   Chambel Teresa, 2016, ALTMM 16 P 1 INT WOR, DOI [10.1145/2983298, DOI 10.1145/2983298]
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Coughlan JM, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P288, DOI 10.1109/ISMAR-Adjunct.2017.89
   Dorrington P, 2016, J USABILITY STUD, V11, P66
   Evans JR, 2007, OPHTHALMOLOGY, V114, P283, DOI 10.1016/j.ophtha.2006.10.006
   Everingham MR., 1998, INT J VIRTUAL REALIT, V3, P1, DOI [10.20870/IJVR.1998.3.4.2629, DOI 10.20870/IJVR.1998.3.4.2629]
   Fenwick E, 2012, CLIN EXP OPHTHALMOL, V40, P27, DOI 10.1111/j.1442-9071.2011.02599.x
   Fenwick EK, 2017, BRIT J OPHTHALMOL, V101, P686, DOI 10.1136/bjophthalmol-2016-308701
   FINCH J, 1987, SOCIOLOGY, V21, P105, DOI 10.1177/0038038587021001008
   Fuller TL, 2017, IEEE IMAGE PROC, P1985, DOI 10.1109/ICIP.2017.8296629
   Garcia GA, 2017, CLIN OPHTHALMOL, V11, P417, DOI 10.2147/OPTH.S113414
   Garnefski N, 2010, DISABIL REHABIL, V32, P142, DOI 10.3109/09638280903071859
   Goodman E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1061
   Guo AH, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P651, DOI 10.1145/2984511.2984518
   Hicks SL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067695
   Hoyle R, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380960
   Huang J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210630
   Itoh Yuta, 2015, P 6 AUGM HUM INT C A, P1, DOI [10.1145/2735711.2735787, DOI 10.1145/2735711.2735787]
   Kress B, 2014, PROC SPIE, V9202, DOI 10.1117/12.2064351
   Lang M, 2017, BRIT J VISUAL IMPA, V35, P29, DOI 10.1177/0264619616677171
   Langlotz T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173964
   Lehane CM, 2018, BRIT J HEALTH PSYCH, V23, P646, DOI 10.1111/bjhp.12309
   Lehane CM, 2017, AGING MENT HEALTH, V21, P337, DOI 10.1080/13607863.2015.1132675
   Lindgaard G, 2010, IFIP ADV INF COMM TE, V332, P15
   Lupón M, 2018, RES DEV DISABIL, V83, P120, DOI 10.1016/j.ridd.2018.08.013
   Lyubomirsky S, 1999, SOC INDIC RES, V46, P137, DOI 10.1023/A:1006824100041
   Mangione CM, 2001, ARCH OPHTHALMOL-CHIC, V119, P1050, DOI 10.1001/archopht.119.7.1050
   Mann Steve., 1999, LINUX J, V59es, P5
   Melillo P, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2679746
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milgram PJr., 1999, TAXONOMY REAL VIRTUA, DOI [10.1007/978-3-642-87512-0_1, DOI 10.1007/978-3-642-87512-0_1]
   Niforatos E, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311858
   Pamparau C., 2020, P 19 ACM INT C MOB U, DOI [10.1145/3428361.3432089, DOI 10.1145/3428361.3432089]
   Pamparau C, 2021, MULTIMED TOOLS APPL, V80, P30943, DOI 10.1007/s11042-020-10164-5
   Paradiso JA, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.47
   Peli E, 2001, OPTOMETRY VISION SCI, V78, P304, DOI 10.1097/00006324-200105000-00014
   Popovici I, 2019, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR.2019.00024
   Profita H, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4884, DOI 10.1145/2858036.2858130
   Rainey L, 2016, QUAL LIFE RES, V25, P2633, DOI 10.1007/s11136-016-1292-8
   Rusu PP, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/ehb47216.2019.8970074
   Sandnes FE, 2016, LECT NOTES COMPUT SC, V9758, P187, DOI 10.1007/978-3-319-41264-1_25
   Sarsenbayeva Z., 2017, OZCHI '17: Proceedings of the 29th Australian Conference on Computer-Human Interaction, P477, DOI DOI 10.1145/3152771.3156161
   Schipor MD, 2017, E-HEALTH BIOENG CONF, P353, DOI 10.1109/EHB.2017.7995434
   Schneider O, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P877, DOI 10.1145/3242587.3242604
   Schulze-Bonsel K, 2006, INVEST OPHTH VIS SCI, V47, P1236, DOI 10.1167/iovs.05-0981
   Stearns L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P361, DOI 10.1145/3132525.3134512
   Stearns L, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P28, DOI 10.1145/3234695.3236361
   Sturrock BA, 2016, INVEST OPHTH VIS SCI, V57, P3032, DOI 10.1167/iovs.16-19110
   Sturrock BA, 2015, INVEST OPHTH VIS SCI, V56, P2416, DOI 10.1167/iovs.14-16223
   Szpiro S, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P61, DOI 10.1145/2971648.2971723
   Szpiro S, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P171, DOI 10.1145/2982142.2982168
   Tang Y, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284407
   Tanuwidjaja E, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P799, DOI 10.1145/2632048.2632091
   Vanderdonckt Jean, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3331160
   Vatavu RD, 2020, PROCEEDINGS OF THE 2020 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2020, P1, DOI 10.1145/3391614.3393660
   Vatavu RD, 2018, IEEE PERVAS COMPUT, V17, P27, DOI 10.1109/MPRV.2018.011591059
   Vatavu RD., 2020, P 19 INT C MOB UB MU, DOI [10.1145/3428361.3428467, DOI 10.1145/3428361.3428467]
   Verbeek P., 2005, HUMAN EYE MEDIATED V
   Vinayagamoorthy V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300762
   Wilcox R., 2012, Modern statistics for the social and behavioral sciences: A practical introduction
   Wilks T., 2004, QUAL SOC WORK, V3, P78, DOI DOI 10.1177/1473325004041133
   Wobbrock JO, 2019, PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS (EICS'19), DOI 10.1145/3319499.3330292
   Wobbrock JO, 2018, COMMUN ACM, V61, P62, DOI 10.1145/3148051
   World Health Organization, 2019, World Report on Vision
   Yuhang Zhao, 2018, ACM SIGACCESS Accessibility and Computing, P38, DOI 10.1145/3178412.3178421
   Zhao YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P387, DOI 10.1145/3332165.3347906
   Zhao YH, 2019, ACM T ACCESS COMPUT, V12, DOI 10.1145/3361866
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
   Zhao YH, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173789
   Zhao YH, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4170, DOI 10.1145/3025453.3025949
   Zhao YH, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P73, DOI 10.1145/2971648.2971730
   Zhao YH, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P239, DOI 10.1145/2700648.2809865
   Zolyomi A, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P220, DOI 10.1145/3132525.3132552
NR 91
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2021 SEP 15
PY 2021
DI 10.1007/s11042-021-11498-4
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ5ZY
UT WOS:000696143500003
DA 2024-07-18
ER

PT J
AU Das, A
   Saha, D
AF Das, Arijit
   Saha, Diganta
TI Deep learning based Bengali question answering system using semantic
   textual similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NLP; Bengali question answering system; Semantic search; Deep Belief
   Network; Modified density peak clustering
AB Recently, Question answering system is a major research area in language processing. Bengali isone of the most popular spoken languages in India. Still, it has faced difficulties in natural language processing.Among the semantic based systems, word mapping and keyword based approaches achieved the best results and got better attention on the user side. These systems are already implemented in various languages but not much in Indian language like Bengali. This work presents an efficient question answering system for retrieving Bengali language text. This system includes word embedding clustering and deep level feature representation for providing better grammatical similarities for retrieving the Bengali textual contents relevant to user queries. The pre-trained word embedding module is created by the help of a deep belief network. The modified density peak algorithm is employed to perform word embedding clustering.The presented work has been tested on a dataset from the Bengali corpus developed by TDIL and synthetic Bengali translated datasets accessible in English called SQuAD 2.0. This question answering system is implemented in python with NLTK tool kit and got good performance while retrieving the Bengali textual data.
C1 [Das, Arijit; Saha, Diganta] Jadavpur Univ, Dept CSE, Kolkata, India.
C3 Jadavpur University
RP Das, A (corresponding author), Jadavpur Univ, Dept CSE, Kolkata, India.
EM arijit.mcse.ju@gmail.com
RI DAS, ARIJIT/AAB-7285-2021
OI DAS, ARIJIT/0000-0002-7202-5800
CR Ahmad A., 2018, INT C BANGL SPEECH L, V2018, P1
   Ahmed R, 2018, 2018 IEEE INT S SIGN, P1, DOI DOI 10.1109/EI2.2018.8582239
   Banerjee S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1224-8
   Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005
   Carrino C. P., 2019, ARXIV191205200
   Choudhary L., 2012, International Journal of Artificial Intelligence Applications, V3, P203
   Chowdhury Sohini Roy, 2017, 2017 8th International Conference on Information Technology (ICIT), P11, DOI 10.1109/ICIT.2017.12
   Cui Y., 2018, ARXIV PREPRINT ARXIV
   Das A., 2019, ABS190206056 CORR
   Das A, 2017, IEEE REG 10 HUMANIT, P502, DOI 10.1109/R10-HTC.2017.8289008
   Das A, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P953, DOI 10.1109/RTEICT.2017.8256739
   Dhar A, 2018, CATEGORIZATION BANGL, P477
   Efimov P, 2020, CLEF 2020, V12260
   Garcia-Penalvo, 2018, SOFT COMPUT, P1
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Gupta D, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2777
   Gupta D, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3359988
   Islam MA, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P445, DOI 10.1109/ICIEV.2016.7760043
   Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x
   Khatun S., 2018, INT C BANGL SPEECH L, V2018, P1
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   LEE K, 2018, LREC, P2758
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Mahmudand A, 2007, RES REPORT BENGLA TA
   Manna Partha Pratim, 2019, 2019 International Conference on Applied Machine Learning (ICAML). Proceedings, P175, DOI 10.1109/ICAML48257.2019.00041
   Monica S, 2019, IEEE ENABL TECHNOL, P1, DOI 10.1109/WETICE.2019.00009
   Mozannar H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P108
   Nguyen GH, 2018, LECT NOTES COMPUT SC, V10843, P445, DOI 10.1007/978-3-319-93417-4_29
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Noraset T, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102431
   Pandey HM, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P728, DOI 10.1109/CONFLUENCE.2016.7508215
   Prasad SS, 2016, INT CONF CONTEMP, P323
   Prottasha N., 2019, 2019 1 INT C ADV SCI, P1, DOI [10.1109/ICCIT48885.2019.9038332, DOI 10.1109/ICASERT.2019.8934592]
   Pundge A.M., 2016, INT J COMPUT APPL, V141, p0975
   Purkaystha B., 2018, 2018 21 INT C COMPUT, P1, DOI 10.1109/ICCITECHN.2017.8281852
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Sarkar K, 2017, COMMUN COMPUT INF SC, P552
   Shajalal M, 2018, 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING (ICBSLP)
   Srba I, 2016, ACM T WEB, V10, DOI 10.1145/2934687
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Zhang Zaixi, 2020, ARXIV PREPRINT ARXIV
   Zhou SP, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1322, DOI 10.1145/3343031.3351059
NR 42
TC 5
Z9 6
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 589
EP 613
DI 10.1007/s11042-021-11228-w
EA SEP 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695454300002
DA 2024-07-18
ER

PT J
AU Baghel, N
   Verma, U
   Nagwanshi, KK
AF Baghel, Neeraj
   Verma, Upendra
   Nagwanshi, Kapil Kumar
TI WBCs-Net: type identification of white blood cells using convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Blood cell; Convolutional neural network; Deep
   learning; Multi-label classification
ID CLASSIFICATION
AB On monitoring an individual's health condition, White Blood Cells play a significant role. The opinion on blood-related disease requires the detection and description of the blood of a patient. Blood cell defects are responsible for numerous health conditions. The conventional technique of manually visualizing White Blood Cells under the microscope is a time-consuming, tedious process and its interpretation requires professionals. There are significant medical applications for an automated method for detecting and classifying blood cells and their subtypes. This work presents an automatic classification method with the help of machine learning for blood cell classification from blood sample medical images. The proposed method can identify and classify the function of each segmented White Blood Cells cell image as granular and non-granular White Blood Cells cell type. It further classifies granular into Eosinophil, Neutrophil and non-granular into Lymphocyte, Monocyte in various forms. Because of its high precision, the proposed framework includes a neural network model to detect white blood cell types. To improve the accuracy of multiple cells overlapping and increase the robustness, data augmentation techniques have been used in the proposed system. Which has improved the accuracy in binary and multi-classification of blood cell subtypes.
C1 [Baghel, Neeraj] Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
   [Verma, Upendra] SVKMS NMIMS Univ, Mumbai, Maharashtra, India.
   [Nagwanshi, Kapil Kumar] Amity Univ Rajasthan, ASET, Jaipur, Rajasthan, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); SVKM's NMIMS (Deemed
   to be University)
RP Baghel, N (corresponding author), Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
EM nbaghel777@gmail.com; upendra.verma@nmims.edu; dr.kapil@ieee.org
RI Nagwanshi, Kapil Kumar/W-4185-2019
OI Nagwanshi, Kapil Kumar/0000-0003-3133-978X; Baghel,
   Neeraj/0000-0002-0081-6224; , Dr. Upendra Verma/0000-0002-3503-5858
CR Abu Daqqa Khaled A. S., 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P638, DOI 10.1109/ICITECH.2017.8079919
   Acevedo A, 2019, COMPUT METH PROG BIO, V180, DOI 10.1016/j.cmpb.2019.105020
   Alam MM, 2019, HEALTHC TECHNOL LETT, V6, P103, DOI 10.1049/htl.2018.5098
   Aliyu HA, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON BIOSIGNAL ANALYSIS, PROCESSING AND SYSTEMS (ICBAPS 2018), P142, DOI 10.1109/ICBAPS.2018.8527398
   Alom M. Z., 2018, ARXIV180206955, V6, P014006, DOI 10.1109/NAECON.2018.8556686
   [Anonymous], 2018, Biomed. J. Sci. Tech. Res., DOI [DOI 10.26717/BJSTR.2018.09.001755, 10.26717/bjstr.2018.09.001755]
   Baghel N, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105750
   Bani-Hani D., 2018, P 7 ANN WORLD C SOC, P1
   Bikhet SF, 2000, INT CONF ACOUST SPEE, P2259, DOI 10.1109/ICASSP.2000.859289
   Burton A.G., 2018, Textbook of Small Animal Emergency Medicine, P405, DOI [10.1002/9781119028994.ch64, DOI 10.1002/9781119028994.CH64]
   Gautam A, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1023, DOI 10.1109/TENCON.2016.7848161
   King DB, 2015, ACS SYM SER, V1214, P1
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Kulkarni SS, 2013, INDIAN J RES
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Malihi L, 2013, IRAN CONF MACH, P360, DOI 10.1109/IranianMVIP.2013.6780011
   Medsker Larry R., 2001, INT SER COMPUTAT INT, V5, P64
   Naz I, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500556
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Pandey C, 2021, MULTIMED TOOLS APPL, V80, P13407, DOI 10.1007/s11042-020-10309-6
   Pansombut T, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7519603
   Patil AM, 2021, IRBM, V42, P378, DOI 10.1016/j.irbm.2020.08.005
   Rosyadi T, 2016, 2016 6TH INTERNATIONAL ANNUAL ENGINEERING SEMINAR (INAES), P245, DOI 10.1109/INAES.2016.7821942
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Singh Alpna, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P187, DOI 10.1109/IC3A48958.2020.233294
   Sukhia KN, 2019, IET IMAGE PROCESS, V13, P2548, DOI 10.1049/iet-ipr.2018.5471
   Tai W-L, 2011, 2011 IEEE INT S MULT
   Ushizima DM, 2005, HIS 2005: 5TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, PROCEEDINGS, P379
   YOUNG IT, 1972, IEEE T BIO-MED ENG, VBM19, P291, DOI 10.1109/TBME.1972.324072
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zandecki M, 2007, INT J LAB HEMATOL, V29, P21, DOI 10.1111/j.1365-2257.2006.00871.x
   Zhao JW, 2017, MED BIOL ENG COMPUT, V55, P1287, DOI 10.1007/s11517-016-1590-x
NR 33
TC 13
Z9 13
U1 3
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42131
EP 42147
DI 10.1007/s11042-021-11449-z
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000691930500002
DA 2024-07-18
ER

PT J
AU Kumar, S
   Gupta, H
   Yadav, D
   Ansari, IA
   Verma, OP
AF Kumar, Saurav
   Gupta, Himanshu
   Yadav, Drishti
   Ansari, Irshad Ahmad
   Verma, Om Prakash
TI YOLOv4 algorithm for the real-time detection of fire and personal
   protective equipments at construction sites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Fire; Object detection; PPE; Surveillance; YOLOv4 algorithm
ID CONVOLUTIONAL NEURAL-NETWORKS; SMOKE DETECTION; CLASSIFICATION;
   SURVEILLANCE; OBJECTS
AB Many difficulties are encountered during evacuation from construction sites in hazardous situations, which may lead to severe fatalities. These fatalities, especially caused by fire, may be significantly reduced by ensuring personal protective equipment (PPE) compliance of construction site workers and fire detection through proper surveillance. Thus, the detection of PPEs, fire and injured or trapped persons, can greatly assist in the reduction of fatalities and economic loss. This article presents a novel approach towards the detection of fire and PPEs to assist in the monitoring and evacuation tasks. This work utilizes the YOLOv4 and YOLOv4-tiny algorithms based on deep learning for carrying out the detection task. A self-made dataset has been utilized to train the model in the Darknet neural network framework. Moreover, a comparative analysis with previous works has been carried out in order to endorse the real-time efficacy of the proposed work. The results verify the strength of YOLOv4 algorithm in real-time detection and surveillance at construction sites with maximum mean average precision (mAP) of 76.86 %.
C1 [Kumar, Saurav] Indian Inst Technol, Dept Elect Engn, Roorkee, Uttar Pradesh, India.
   [Gupta, Himanshu; Verma, Om Prakash] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Instrumentat & Control Engn, Jalandhar, Punjab, India.
   [Yadav, Drishti] Tech Univ Wien, Fac Informat, A-1040 Vienna, Austria.
   [Ansari, Irshad Ahmad] PDPM Indian Inst Informat Technol, Dept Elect & Commun Engn, Design & Mfg, Jabalpur, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; National Institute of Technology (NIT
   System); Dr B R Ambedkar National Institute of Technology Jalandhar;
   Technische Universitat Wien; Indian Institute of Information Technology
   Design & Manufacturing, Jabalpur
RP Verma, OP (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Instrumentat & Control Engn, Jalandhar, Punjab, India.
EM saurav_k@ee.iitr.ac.in; guptah.nitj@gmail.com; drish131196@gmail.com;
   irshad@iiitdmj.ac.in; vermaop@nitj.ac.in
RI Gupta, Himanshu/AAW-2278-2021; Verma, Om/AAD-1007-2019; Ansari, Irshad
   Ahmad/AAT-2761-2020
OI Gupta, Himanshu/0000-0003-4799-5693; Verma, Om/0000-0002-7421-295X;
   Ansari, Irshad Ahmad/0000-0003-2991-0908; YADAV,
   DRISHTI/0000-0002-2974-0323
CR Akbar-Khanzadeh F, 1998, J Hum Ergol (Tokyo), V27, P70
   Balakreshnan B., 2020, Procedia Manuf, V45, P277, DOI [10.1016/j.promfg.2020.04.017, DOI 10.1016/J.PROMFG.2020.04.017]
   Barro-Torres S, 2012, COMPUT COMMUN, V36, P42, DOI 10.1016/j.comcom.2012.01.005
   Bhole, 2016, International Journal of Engineering and Techniques. Vol, V2, P24
   Bochkovskiy A., 2020, PREPRINT
   Rangel JC, 2018, APPL SOFT COMPUT, V65, P603, DOI 10.1016/j.asoc.2018.02.005
   Ding LY, 2018, AUTOMAT CONSTR, V86, P118, DOI 10.1016/j.autcon.2017.11.002
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Fang Q, 2018, AUTOMAT CONSTR, V85, P1, DOI 10.1016/j.autcon.2017.09.018
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kelm A, 2013, AUTOMAT CONSTR, V36, P38, DOI 10.1016/j.autcon.2013.08.009
   Kolar Z, 2018, AUTOMAT CONSTR, V89, P58, DOI 10.1016/j.autcon.2018.01.003
   Kumar S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010014
   Lee DH, 2021, MULTIMED TOOLS APPL, V80, P34237, DOI 10.1007/s11042-020-09924-0
   Li P, 2020, CASE STUD THERM ENG, V19, DOI 10.1016/j.csite.2020.100625
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Mao WT, 2018, FIRE TECHNOL, V54, P531, DOI 10.1007/s10694-017-0695-6
   Mneymneh BE, 2019, J COMPUT CIVIL ENG, V33, DOI 10.1061/(ASCE)CP.1943-5487.0000813
   Mneymneh BE, 2017, PROCEDIA ENGINEER, V196, P895, DOI 10.1016/j.proeng.2017.08.022
   Muhammad K, 2020, EFFICIENT CONVOLUTIO, DOI 10.1201/9781351003827-3
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Namozov A, 2018, ADV ELECTR COMPUT EN, V18, P121, DOI 10.4316/AECE.2018.04015
   Nath ND, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103085
   Nath ND, 2019, J INF TECHNOL CONSTR, V24, P511, DOI 10.36680/j.itcon.2019.028
   Naticchia B, 2013, AUTOMAT CONSTR, V29, P148, DOI 10.1016/j.autcon.2012.09.016
   Nie X, 2019, IEEE INT C INTELL TR, P47, DOI 10.1109/ITSC.2019.8917475
   Park MW, 2015, J CONSTR ENG M, V141, DOI 10.1061/(ASCE)CO.1943-7862.0000974
   Park MW, 2012, AUTOMAT CONSTR, V28, P15, DOI 10.1016/j.autcon.2012.06.001
   Redmon J., 2018, COMPUTER VISION PATT
   Seo J, 2015, ADV ENG INFORM, V29, P239, DOI 10.1016/j.aei.2015.02.001
   Seong H, 2018, KSCE J CIV ENG, V22, P4254, DOI 10.1007/s12205-017-1730-3
   Siddula M, 2016, PROCEDIA ENGINEER, V145, P428, DOI 10.1016/j.proeng.2016.04.010
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tran Q.-H., 2019, KICS KOREA VIETNAM I, V2019, P1
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Wu JX, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102894
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
NR 40
TC 21
Z9 21
U1 6
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22163
EP 22183
DI 10.1007/s11042-021-11280-6
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000691718600001
DA 2024-07-18
ER

PT J
AU Yang, SL
   Chong, X
AF Yang, Senlin
   Chong, Xin
TI Study on feature extraction technology of real-time video acquisition
   based on deep CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep CNN; Video acquisition; Feature extraction
AB In the process of image acquisition, the existing image-based real-time video acquisition system is susceptible to noise and distortion due to the influence of attitude, illumination and other conditions, which reduces the quality and stability of the acquired image, and thus makes it difficult to locate the image feature area. Therefore, the feature extraction technology of real-time video capture based on deep convolution neural network is proposed. Cut out high-quality images by locating reference points in feature connection areas, smooth each part of the image by using mean image filter, extract texture features by using convolution, transform, discrete cosine transform and statistical features, and replace random initialization weights with pre-trained models. In the process of model training and recognition, the methods of feature state division, image preprocessing and observation vector calculation are studied. The experimental results on ORL database verify the effectiveness of the image feature extraction method, which can meet the needs of current real-time video capture.
C1 [Yang, Senlin] Xian Univ, Shaanxi Key Lab Surface Engn & Remfg, Xian 710065, Shaanxi, Peoples R China.
   [Yang, Senlin] Xian Univ, Sch Mech & Mat Engn, Xian 710065, Shaanxi, Peoples R China.
   [Chong, Xin] Vertiv Technol Ltd, Xian 710075, Peoples R China.
C3 Xi'an University; Xi'an University
RP Yang, SL (corresponding author), Xian Univ, Shaanxi Key Lab Surface Engn & Remfg, Xian 710065, Shaanxi, Peoples R China.; Yang, SL (corresponding author), Xian Univ, Sch Mech & Mat Engn, Xian 710065, Shaanxi, Peoples R China.
EM hepupoy35@163.com
RI Yang, Senlin/GRO-2659-2022
FU Natural Science Fund of China [61401356]; Special Fund for Technological
   Innovation Guidance of Shaanxi Province [2020CGXNG-015]; Youth
   Innovation Team Building Scientific Research Project of Shaanxi Province
   [21JP106]; Science and Technology Project of Xi'an [2019KJWL07,
   2020kjrc0104]
FX This work is partially supported by the Natural Science Fund of China
   (under Grant 61401356), the Special Fund for Technological Innovation
   Guidance of Shaanxi Province (under grant 2020CGXNG-015), Youth
   Innovation Team Building Scientific Research Project of Shaanxi Province
   (under Grant 21JP106), and the Science and Technology Project of Xi'an
   (under Grant 2019KJWL07, 2020kjrc0104).
CR Abderazek S, 2019, J NET COMPUT APPL
   Bai, 2017, VIDEO CLOUD PROTECTS
   Cai YF, 2017, J SE U NAT SCI ED
   Cao SC, 2018, APPL MATH COMPUT, V332, P136, DOI 10.1016/j.amc.2018.03.048
   Choi J, 2018, COMPUT VIS IMAGE UND, V171, P10, DOI 10.1016/j.cviu.2018.05.009
   Fei L, 2015, AUTOTECHNOL APPL
   Gao QW, 2017, COMPUT SCI
   Guan W, 2016, J AUTO
   Hanxi L, 2016, COMPUT VIS IMAGE UND
   Hao TZ, 2018, NEUROCOMPUTING
   Ji JW, 2018, PHYSICA A, V509, P1034, DOI 10.1016/j.physa.2018.06.055
   Jiang T, 2018, COMPUT RES DEV
   Lian W, 2016, POLICE TECHNOL
   Liang, 2016, ZYNQ BASED PEDESTRIA
   Liu, 2014, ART ED RES
   Liu Q, 2018, CHIN J COMPUT
   Liu WT, 2018, COMPUT ENG APPL
   Luo HB, 2017, INFRARED LASER ENG
   Qian J, 2018, EXPERT SYST APPL
   Sanaz B, 2019, EXPERT SYST APPL
   Sun R, 2014, OPTOELECTRONIC ENG
   Tingting S, 2018, J CLIN PERIODONTOL
   Wang HF, 2018, J GARMENT
   Wang R, 2016, FASH DES ENG
   Wen XX, 2018, COMMUN POWER TECHNOL
   Xu Y, 2016, COMPUT ENG
   Yu, 2017, W LEATHER
   Yu, 2016, HENAN SCI
   Yu JY, 2018, COMPUT SCI
   Yuki Y, 2019, EXPERT SYST APPL
   Zeng, 2019, APPL MATH COMPUT
   Zhang, 2018, COMPUT APPL RES
   Zhao, 2018, CHIN SEC PROTECT CER
   Zhe X., 2019, INFORM SCIENCES
NR 34
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33937
EP 33950
DI 10.1007/s11042-021-11417-7
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000691163100002
DA 2024-07-18
ER

PT J
AU Signing, VRF
   Mogue, RLT
   Kengne, J
   Kountchou, M
   Saïdou
AF Signing, V. R. Folifack
   Mogue, R. L. Tagne
   Kengne, J.
   Kountchou, M.
   Saidou
TI Dynamic phenomena of a financial hyperchaotic system and DNA sequences
   for image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Financial Hyperchaotic system; Multistability; Offset
   boosting; DNA coding
ID CHAOTIC CIRCUIT; HYPER-CHAOS; ALGORITHM; OPERATION; PERMUTATION;
   ATTRACTORS; DIFFUSION; INTERNET; PRIVACY; SECURE
AB With advances in modern technology, the security of information, including the protection of digital images, is of particular interest. Due to the type of special storage format of images and the fateful dimension of 1D map that have a small secret key space, in this paper, a joint-based encryption technique on the pseudo-random and sophisticated character of hyperchaotic behavior and DNA coding is proposed. The entire dynamics of a financial hyperchaotic system is studied for a better selection of the sequence key using nonlinear analysis tools. A rich dynamic of this analysis reveals a plethora of phenomena such as multistability and offset boosting, which, to our knowledge, have not yet been the subject of a study on financial hyperchaotic systems. The set consisting of the pseudo-random aspect of the financial hyperchaotic system used in all stages of encryption, DNA coding (algebraic operations, complementation, and DNA rules), and the scrambling of the positions of each image pixel is exploited to reinforce the effectiveness of the confusion and diffusion of digital images. To analyze the security and robustness of the proposed algorithm, some security tests such as histogram analysis, correlation, information entropy, as well as key analysis are carried out. The values of correlation coefficients of the encrypted images using the proposed scheme are close to zero, The entropy values of the test images are overall greater than 7.99 and the key space of the is greater than 2(100). Besides, differential analysis shows that the number of pixel change rate (NPCR) and unified average change intensity (UACI) for the proposed technique are greater than 99.50% and 30%, respectively. Furthermore, the quantitative analyses of occlusion and data loss attacks as well as the results of comparison with some advanced algorithms show the efficiency and security of the proposed cryptosystem.
C1 [Signing, V. R. Folifack; Mogue, R. L. Tagne; Kengne, J.] Univ Dschang, Dept Elect Engn, Unite Rech, Lab Automat & Informat Appl URAIA,IUT FV Bandjoun, Dschang, Cameroon.
   [Signing, V. R. Folifack; Mogue, R. L. Tagne; Kountchou, M.] Univ Dschang, Dept Phys, Unite Rech Matiere Condensee Elect & Traitement S, POB 67, Dschang, Cameroon.
   [Signing, V. R. Folifack; Mogue, R. L. Tagne; Kountchou, M.; Saidou] Inst Geol & Min Res, Res Ctr Nucl Sci & Technol, POB 4110, Yaounde, Cameroon.
   [Saidou] Univ Yaounde I, Fac Sci, Nucl Phys Lab, POB 812, Yaounde, Cameroon.
C3 Universite de Dschang; Universite de Dschang; University of Yaounde I
RP Signing, VRF (corresponding author), Univ Dschang, Dept Elect Engn, Unite Rech, Lab Automat & Informat Appl URAIA,IUT FV Bandjoun, Dschang, Cameroon.; Signing, VRF (corresponding author), Univ Dschang, Dept Phys, Unite Rech Matiere Condensee Elect & Traitement S, POB 67, Dschang, Cameroon.; Signing, VRF (corresponding author), Inst Geol & Min Res, Res Ctr Nucl Sci & Technol, POB 4110, Yaounde, Cameroon.
EM signingruben@yahoo.fr
RI Folifack Signing, Vitrice Ruben/AGV-5777-2022; -, Saïdou/AAJ-8167-2021
OI Folifack Signing, Vitrice Ruben/0000-0002-8385-8058; -,
   Saïdou/0000-0001-7427-0239; KOUNTCHOU NOUBE, MICHAUX/0000-0002-7141-2032
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Argyris J., 2015, An Exploration of Dynamical Systems and Chaos: Completely Revised and Enlarged Second Edition
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Biham E., 1993, Advances in Cryptology - CRYPTO '92. 12th Annual International Cryptology Conference Proceedings, P487
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Cui, 2019, INT C BIOINSP COMP T, P189
   Dagadu J.C., 2019, INT J NETW SECUR, V21, P83
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Faragallah OS, 2015, SIGNAL IMAGE VIDEO P, V9, P1917, DOI 10.1007/s11760-014-0683-y
   Folifack Signing VR., 2019, INT J DYNAM CONTROL, V7, P439
   Gehani, 2000, DNA BASED CRYPTOGRAP, VV
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Guan ZT, 2017, IEEE ACCESS, V5, P3250, DOI 10.1109/ACCESS.2017.2662940
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Jahanshahi H, 2019, CHAOS SOLITON FRACT, V126, P66, DOI 10.1016/j.chaos.2019.05.023
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Jian JG, 2009, LECT NOTES COMPUT SC, V5551, P253, DOI 10.1007/978-3-642-01507-6_30
   Kengne J., CHAOS COEXISTING BIF
   Kengne J., 2019, INT J DYNAMICS CONTR, V7, P112, DOI DOI 10.1007/S40435-018-0444-9
   Kengne J., 2018, INT J DYN CONTROL, V6, P1543, DOI [10.1007/s40435-018-0414-2, DOI 10.1007/S40435-018-0414-2]
   Kengne J, 2017, NONLINEAR DYNAM, V87, P363, DOI 10.1007/s11071-016-3047-z
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Kocarev L, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P28
   Li B, 2018, MULTIMED TOOLS APPL, V77, P8911, DOI 10.1007/s11042-017-4786-7
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Luo YL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105836
   Mylrea M, 2017, J WORLD ENERGY LAW B, V10, P147, DOI 10.1093/jwelb/jwx001
   Negou AN, 2018, AEU-INT J ELECTRON C, V90, P1, DOI 10.1016/j.aeue.2018.04.003
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Signing VRF, 2018, CHAOS SOLITON FRACT, V113, P263, DOI 10.1016/j.chaos.2018.06.008
   Singh JP, 2017, NONLINEAR DYNAM, V89, P1845, DOI 10.1007/s11071-017-3556-4
   Singh JP, 2016, CHAOS SOLITON FRACT, V92, P73, DOI 10.1016/j.chaos.2016.09.010
   Strogatz S. H., 1994, NONLINEAR DYNAMICS C
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Sun K-H, 2012, CRYPTANALYSIS IMPROV
   Tenny R, 2003, PHYS REV LETT, V90, DOI 10.1103/PhysRevLett.90.047903
   Tsafack N, 2018, ScientificWorldJournal, V2018, P1260325, DOI 10.1155/2018/1260325
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Vaidyanathan S, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11872-8
   Volos C, 2017, NONLINEAR DYNAM, V89, P1047, DOI 10.1007/s11071-017-3499-9
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1595, DOI 10.1007/s11071-015-2590-3
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XW, 2022, MECH BASED DES STRUC, V50, P331, DOI 10.1080/15397734.2020.1717342
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wei ZC, 2014, INT J BIFURCAT CHAOS, V24, DOI 10.1142/S0218127414501272
   Wei ZC, 2014, MATH COMPUT SIMULAT, V100, P13, DOI 10.1016/j.matcom.2014.01.001
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Yu HJ, 2012, NONLINEAR DYNAM, V67, P2171, DOI 10.1007/s11071-011-0137-9
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang XY, 2020, MULTIMED TOOLS APPL, V79, P33793, DOI 10.1007/s11042-019-08550-9
   Zhao XS, 2011, APPL MATH COMPUT, V217, P6031, DOI 10.1016/j.amc.2010.07.017
   [朱从旭 Zhu Congxu], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P1735
NR 80
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32689
EP 32723
DI 10.1007/s11042-021-11180-9
EA AUG 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000680824700004
DA 2024-07-18
ER

PT J
AU Deng, JH
   Wei, HM
   He, DD
   Gu, GS
   Kang, XD
   Liang, HJ
   Liu, C
   Wu, PJ
   Zhong, YL
   Xu, SH
   Ling, WK
   Zhao, J
AF Deng, Jiehang
   Wei, Haomin
   He, Dongdong
   Gu, Guosheng
   Kang, Xiaodong
   Liang, Hongjin
   Liu, Chao
   Wu, Peijie
   Zhong, Yuanli
   Xu, Shihe
   Ling, Wing-Kuen
   Zhao, Jian
TI A coarse to fine framework for recognizing and locating multiple diatoms
   with highly complex backgrounds in forensic investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diatom; Forensic medicine; Deep learning; Object detection; Complex
   backgrounds
AB In the forensic investigation, recognizing and locating the multiple diatom objects in an image is a challenging issue due to the interferences of the highly complex backgrounds. To address this issue, a coarse to fine diatom recognition and a localization framework based on the deep learning network is proposed in this paper. Firstly, the diatom images are obtained by performing the anatomic study on the cadavers. Next, a high definition electron microscope is scanned. Then, a coarse to fine deep learning framework is constructed to locate and recognize the diatom objects. Unlike the existing diatom classification and recognition methods, which used light microscopy with low resolution and completed under a simple backgrounds, our framework utilizes the high definition electron scanning microscopy with much higher resolution and suffers from the complex backgrounds interferences. To demonstrate the effectiveness of the proposed framework, 4 diatom image datasets with different background interference degrees are constructed. Also, 3 computer numerical simulation analysis are performed. They are (1) the limitations of the traditional methods in the diatom recognition, (2) the optimized composition of the training strategies and the network models, and (3) the performance of the proposed framework. The computer numerical simulation results show that the proposed framework achieves a recognition accuracy of 0.852. This is greater than 0.758 achieved by the AlexNet. Moreover, it can overcome the problem of the highly complex backgrounds interferences in the forensic investigation. Furthermore, it can locate and recognize the multiple objects in various diatom images simultaneously.
C1 [Deng, Jiehang; Wei, Haomin; He, Dongdong; Gu, Guosheng; Liang, Hongjin; Wu, Peijie; Zhong, Yuanli] Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
   [Deng, Jiehang] Zhaoqing Univ, Sch Comp Sci & Software, Zhaoqing, Peoples R China.
   [Kang, Xiaodong; Liu, Chao; Zhao, Jian] Minist Publ Secur, Guangzhou Forens Sci Inst, Guangzhou, Peoples R China.
   [Kang, Xiaodong; Liu, Chao; Zhao, Jian] Minist Publ Secur, Key Lab Forens Pathol, Guangzhou, Peoples R China.
   [Xu, Shihe] Zhaoqing Univ, Sch Math & Stat, Zhaoqing, Peoples R China.
   [Ling, Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Peoples R China.
C3 Guangdong University of Technology; Zhaoqing University; Ministry of
   Public Security (China); Ministry of Public Security (China); Zhaoqing
   University; Guangdong University of Technology
RP Gu, GS (corresponding author), Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
EM gsgu@gdut.edu.cn; zhaojian0721@163.com
FU Key Areas Research and Development Program of Guangdong Province
   [2019B010139002]; project of Guangzhou Science and Technology
   [201902020006, 201902020007, 201807010058]
FX This work is supported by the Key Areas Research and Development Program
   of Guangdong Province under Grant 2019B010139002, the project of
   Guangzhou Science and Technology under Grant 201902020006, 201902020007,
   201807010058.
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang L, 2012, EXPERT SYST APPL, V39, P1679, DOI 10.1016/j.eswa.2011.06.059
   Deng J., 2019, COMPUT ENG DES, V40, P167
   Fang WL, 2018, ADV ENG INFORM, V37, P139, DOI 10.1016/j.aei.2018.05.003
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Krause LMK, 2020, ENVIRON SCI TECHNOL, V54, P10022, DOI 10.1021/acs.est.0c01982
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WY, 2016, PR MACH LEARN RES, V48
   Ludes B, 1999, INT J LEGAL MED, V112, P163, DOI 10.1007/s004140050224
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Pedraza A, 2018, PROC SPIE, V10679, DOI 10.1117/12.2309488
   Pedraza A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7050460
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Verikas A, 2012, PATTERN RECOGN, V45, P1659, DOI 10.1016/j.patcog.2011.10.019
   [谢杰镇 Xie Jiezhen], 2013, [计算机科学, Computer Science], V40, P293
   Yu WM, 2021, INT J LEGAL MED, V135, P497, DOI 10.1007/s00414-020-02392-z
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang, 2016, J BEIJING INFORM SCI, V31, P28
   Zhang, 2018, NEUROCOMPUTING
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhao J, 2013, INT J LEGAL MED, V127, P459, DOI 10.1007/s00414-012-0756-9
   Zhong ZY, 2017, PROC INT CONF DOC, P923, DOI 10.1109/ICDAR.2017.155
   Zhou YY, 2019, FORENSIC SCI INT, V302, DOI 10.1016/j.forsciint.2019.109922
NR 30
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4839
EP 4857
DI 10.1007/s11042-021-11169-4
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000679762700004
DA 2024-07-18
ER

PT J
AU Nasir, M
   Dutta, P
   Nandi, A
AF Nasir, Md
   Dutta, Paramartha
   Nandi, Avishek
TI Fuzzy triangulation signature for detection of change in human emotion
   from face video image sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Universal facial expression; Dynamic facial expression; Geometric
   feature extraction; Facial transition; Image sequence; Landmarks; Fuzzy
   triangle signature; AAM; MLP
ID FACIAL EXPRESSION RECOGNITION; GEOMETRIC FEATURES; SHAPE
AB The present article proposes a geometry-based fuzzy relational technique for capturing gradual change in human emotion over time available from relevant face image sequences. As associated features, we make use of fuzzy membership arising out of five triangle signatures such as - (i) Fuzzy Isosceles Triangle Signature (FIS), (ii) Fuzzy Right Triangle Signature (FRS), (iii) Fuzzy Right Isosceles Triangle Signature (FIRS), (iv) Fuzzy Equilateral Triangle Signature (FES), and (v) Other Fuzzy Triangles Signature (OFS) to achieve the task of appropriate classification of facial transition from neutrality to one among the six expressions viz. anger (AN), disgust (DI), fear (FE), happiness (HA), sadness (SA) and surprise (SU). The effectiveness of the Multilayer Perceptron (MLP) classifier is tested and validated through 10 fold cross-validation method on three benchmark image sequence datasets namely Extended Cohn-Kanade (CK+), M&M Initiative (MMI), and Multimedia Understanding Group (MUG). Experimental outcomes are found to have achieved accuracy to the tune of 98.47%, 93.56%, and 99.25% on CK+, MMI, and MUG respectively vindicating the effectiveness by exhibiting the superiority of our proposed technique in comparison to other state-of-the-art methods in this regard.
C1 [Nasir, Md; Dutta, Paramartha; Nandi, Avishek] Visva BharatiUniv, Santini Ketan, W Bengal, India.
C3 Visva Bharati University
RP Nasir, M (corresponding author), Visva BharatiUniv, Santini Ketan, W Bengal, India.
EM nasir.vb@gmail.com; paramartha.dutta@gmail.com; avisheknandi10@gmail.com
RI Dutta, Paramartha/AAD-1635-2021
OI Dutta, Paramartha/0000-0003-3946-2440
FU Department of Science and Technology, Ministry of Science and
   Technology, Government of India [If160285, DST/INSPIRE
   Fellowship/[If160285]]
FX The authors want to state their gratitude to Prof. Maja Pantic and Dr.
   A. Delopoulos for making available to use the MMI and MUG databases. The
   authors also like to express thanks to the Department of Science and
   Technology, Ministry of Science and Technology, Government of India for
   supporting with DST-INSPIRE Fellowship (INSPIRE Reg. no. If160285, Ref.
   No.: DST/INSPIRE Fellowship/[If160285]) to carry out this research work
   apart from the Department of Computer & System Sciences, Visva-Bharati
   University for providing infrastructure support.
CR Ahn B, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT INTELLIGENCE (URAL), P541, DOI 10.1109/URAI.2012.6463068
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Barman A, 2017, PATTERN RECOGNIT LET
   Barman A., 2020, HUMAN EMOTION RECOGN
   Barman A, 2019, IET IMAGE PROCESS, V13, P1349, DOI 10.1049/iet-ipr.2018.5481
   Barman A, 2019, APPL SOFT COMPUT, V77, P88, DOI 10.1016/j.asoc.2019.01.011
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Choi HL, 2006, 2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13, P4592
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Ekman P., 2003, UNMASKING FACE GUIDE
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7921, DOI 10.1007/s11042-016-3428-9
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861
   Happy SL, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P67
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Meftah IT, 2012, LECT NOTES COMPUT SC, V7663, P234, DOI 10.1007/978-3-642-34475-6_29
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Mohammadian A, 2015, IET IMAGE PROCESS, V9, P596, DOI 10.1049/iet-ipr.2013.0697
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Perikos I, 2014, IFIP INT C ART INT A, P236
   Priya RV, 2019, MULTIMED TOOLS APPL, V78, P17847, DOI 10.1007/s11042-018-6954-9
   Rahul M, 2019, INT J GRID UTIL COMP, V10, P488, DOI 10.1504/IJGUC.2019.102018
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Saeed A, 2014, ADV HUM-COMPUT INTER, V2014, DOI 10.1155/2014/408953
   Samadiani N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081863
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sharma G, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0224-0
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Valstar MF, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, pJ65
   Wolf L, 2009, ENCY BIOMET, V2
   Yaddaden Y, 2017, Facial expression recognition from video using geometric features
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zangeneh E, 2018, IMAGING SCI J, V66, P463, DOI 10.1080/13682199.2018.1509176
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3017608
NR 44
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31993
EP 32022
DI 10.1007/s11042-021-11196-1
EA JUL 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678031600004
DA 2024-07-18
ER

PT J
AU Raikwar, SC
   Tapaswi, S
AF Raikwar, Suresh Chandra
   Tapaswi, Shashikala
TI Estimation of minimum color channel using difference channel in single
   image Dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dark channel prior; Defogging; Dehazing; Haze; Image enhancement;
   Restoration; Transmission estimation
ID CONTRAST ENHANCEMENT; UNDERWATER IMAGE; VISIBILITY; FRAMEWORK; WEATHER;
   MODEL
AB Single image dehazing (SID) solves the atmospheric scattering model (ATSM). The ill-defined nature of the SID makes it a challenging problem. The transmission is the prime parameter of ATSM. Hence, accurate transmission is essential for quality of SID. The existing methods of SID estimate the transmission based on priors with strong assumptions (such as dark channel prior). These methods do not recover original colors, structure and visibility due to wrong transmission under invalidity of these assumptions. Therefor, the difference channel (DCH) is proposed to estimate accurate transmission. The DCH non-linearly translates the minimum channel of hazy image into minimum channel of haze-free image, which is used to compute the value of transmission. The DCH is based on an observation that difference of maximum and minimum color channel of the hazy image is negatively correlated with depth. The proposed method is able to recover the details from hazy image in the form of structure, edges, corners, colors and visibility due to the DCH. The accuracy and robustness of the proposed method is proved by comparing the results with known dehazing methods based on qualitative and quantitative analysis using benchmark data sets.
C1 [Raikwar, Suresh Chandra] Thapar Inst Engn & Technol, Patiala 147001, Punjab, India.
   [Tapaswi, Shashikala] ABV Indian Inst Informat Technol & Management, Morena Link Rd, Gwalior 474015, Madhya Pradesh, India.
C3 Thapar Institute of Engineering & Technology; ABV-Indian Institute of
   Information Technology & Management, Gwalior
RP Raikwar, SC (corresponding author), Thapar Inst Engn & Technol, Patiala 147001, Punjab, India.
EM suresh.raikwar@thapar.edu
RI TAPASWI, SHASHIKALA/AGZ-7714-2022
CR Ancuti CO, 2019, IEEE C COMP VIS PATT
   Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   [Anonymous], 2018, IEEE T MULTIMEDIA, DOI DOI 10.1109/TMM.2018.2807593
   [Anonymous], 2003, The SSIM index for image quality assessment
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jha DK, 2016, IET COMPUT VIS, V10, P331, DOI 10.1049/iet-cvi.2014.0449
   Jiang YT, 2017, COMPUT VIS IMAGE UND, V165, P17, DOI 10.1016/j.cviu.2017.10.014
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CS, 2020, IEEE T SUSTAIN ENERG, V11, P1370, DOI 10.1109/TSTE.2019.2926147
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Li YA, 2016, NEUROCOMPUTING, V182, P221, DOI 10.1016/j.neucom.2015.12.032
   Ling ZG, 2017, NEUROCOMPUTING, V224, P82, DOI 10.1016/j.neucom.2016.10.050
   Liu SL, 2017, COMPUT ELECTR ENG, V62, P345, DOI 10.1016/j.compeleceng.2016.11.021
   Lu HM, 2016, IEEE IMAGE PROC, P1998, DOI 10.1109/ICIP.2016.7532708
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Narasimhan SG, 2004, THESIS NEW YORK
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nayar SK, 2003, P IEEE WORKSH COL PH
   Raikwar SC, 2020, VISUAL COMPUT, V36, P191, DOI 10.1007/s00371-018-1596-5
   Raikwar SC, 2020, MULTIMED TOOLS APPL, V79, P891, DOI 10.1007/s11042-019-08120-z
   Raikwar SC, 2018, MULTIMED TOOLS APPL, V77, P19719, DOI 10.1007/s11042-017-5398-y
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan KK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P788, DOI 10.1109/ICIP.2000.899827
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang ML, 2019, IEEE T COMPUT, V68, P882, DOI 10.1109/TC.2018.2889985
   Yuan F, 2018, IEEE T IMAGE PROCESS, V27, P4395, DOI 10.1109/TIP.2018.2837900
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 61
TC 0
Z9 0
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31837
EP 31863
DI 10.1007/s11042-021-11175-6
EA JUL 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000675042800001
DA 2024-07-18
ER

PT J
AU Ogundokun, RO
   Awotunde, JB
   Adeniyi, EA
   Ayo, FE
AF Ogundokun, Roseline Oluwaseun
   Awotunde, Joseph Bamidele
   Adeniyi, Emmanuel Abidemi
   Ayo, Femi Emmanuel
TI Crypto-Stegno based model for securing medical information on IOMT
   platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of medical things; Cryptography; Steganography; Medical
   information; Patient
ID HEALTH-CARE; ENABLING TECHNOLOGIES; IMAGE STEGANOGRAPHY; INTERNET;
   THINGS; PRIVACY; CHALLENGES; SEARCH; CLOUD; TRUST
AB The integration of the Internet of Things in medical systems referred to as the Internet of Medical Things (IoMT), which supports medical events for instance real-time diagnosis, remote monitoring of patients, real-time drug prescriptions, among others. This aids the quality of services provided by the health workers thereby improve patients' satisfaction. However, the integrity and confidentiality of medical information on the IoMT platform remain one of the contentions that causes problems in medical services. Another serious concern with achieving protection for medical records is information confidentiality for patient's records over the IoMT environment. Therefore, this paper proposed a Crypto-Stegno model to secure medical information on the IoMT environment. The paper validates the system on healthcare information datasets and revealed extraordinary results in respect to the quality of perceptibility, extreme opposition to data loss, extreme embedding capability and security, which made the proposed system an authentic strategy for resourceful and efficient medical information on IoTM platform.
C1 [Ogundokun, Roseline Oluwaseun; Adeniyi, Emmanuel Abidemi] Landmark Univ, Dept Comp Sci, Omu Aran, Kwara State, Nigeria.
   [Awotunde, Joseph Bamidele] Univ Ilorin, Dept Comp Sci, Ilorin, Nigeria.
   [Ayo, Femi Emmanuel] McPherson Univ, Dept Phys & Comp Sci, Seriki Sotayo, Ogun State, Nigeria.
C3 Landmark University; University of Ilorin
RP Ogundokun, RO (corresponding author), Landmark Univ, Dept Comp Sci, Omu Aran, Kwara State, Nigeria.
EM ogundokun.roseline@lmu.edu.ng; awotunde.jb@unilorin.edu.ng;
   adeniyi.emmanuel@lmu.edu.ng; ayo.fe@muc.edu.ng
RI AWOTUNDE, Joseph Bamidele/AAC-7971-2021; OGUNDOKUN, ROSELINE/B-2783-2019
OI AWOTUNDE, Joseph Bamidele/0000-0002-1020-4432; OGUNDOKUN,
   ROSELINE/0000-0002-2592-2824; Ayo, Femi Emmanuel/0000-0001-8889-5985
CR Abd-El-Atty B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113108
   Abikoye OC, 2020, MULTIMED TOOLS APPL, V79, P23483, DOI 10.1007/s11042-020-08971-x
   Adeniyi E.A., 2021, IoT in healthcare and ambient assisted living, P103, DOI DOI 10.1007/978-981-15-9897-5_6
   Akande NO, 2019, LECT NOTES COMPUT SC, V11623, P166, DOI 10.1007/978-3-030-24308-1_14
   Akande ON, 2020, LECT NOTES COMPUT SC, V12254, P487, DOI 10.1007/978-3-030-58817-5_36
   Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   Ali S, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10120114
   Alsubaei F, 2017, 2017 IEEE 42ND CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS 2017), P112, DOI 10.1109/LCN.Workshops.2017.72
   Anandarajan M., 2018, Cogent Medicine, V5, P1513349, DOI DOI 10.1080/2331205X.2018
   [Anonymous], 1996, HDB APPL CRYPTOGRAPH
   Awan KA, 2019, IEEE ACCESS, V7, P62095, DOI 10.1109/ACCESS.2019.2916340
   Ayo FE, 2020, INF SECUR J, V29, P267, DOI 10.1080/19393555.2020.1767240
   Biglow J., 2016, MINN J SCI TECH, V17, P943
   Borgia E, 2014, COMPUT COMMUN, V54, P1, DOI 10.1016/j.comcom.2014.09.008
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Christiana AO, 2019, J PHYS CONF SER, V1299, DOI 10.1088/1742-6596/1299/1/012059
   Crandall R, 1988, SOME NOTES STEGANOGR
   D'agapeyeff A, 2016, CODES CIPHERS A HIST, P1
   Din IU, 2019, IEEE ACCESS, V7, P89967, DOI 10.1109/ACCESS.2019.2927082
   Din IU, 2019, IEEE ACCESS, V7, P29763, DOI 10.1109/ACCESS.2018.2880838
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Filkins B, 2014, Health care cyberthreat report: widespread compromises detected, compliance nightmare on horizon
   Goforth C., 2019, Campbell L. Rev., V41, P47
   Halperin D, 2008, IEEE PERVAS COMPUT, V7, P30, DOI 10.1109/MPRV.2008.16
   He YL, 2021, IEEE T IND ELECTRON, V68, P7535, DOI 10.1109/TIE.2020.3003635
   Hoffman DL, 2018, J CONSUM RES, V44, P1178, DOI 10.1093/jcr/ucx105
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Huang MF, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/9715428
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Jagadeeswari V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0049-x
   Kapusta K., 2019, INT CONF NEW TECHNOL, P1
   Khan M, 2018, WIRELESS PERS COMMUN, V99, P1683, DOI 10.1007/s11277-018-5336-y
   Khan SA, 2020, MICRO NANO TECHNOL, P1, DOI 10.1016/B978-0-12-816960-5.00001-X
   Khan SU, 2019, FUTURE GENER COMP SY, V98, P286, DOI 10.1016/j.future.2019.01.033
   Khan SR, 2020, FUTURE GENER COMP SY, V109, P360, DOI 10.1016/j.future.2020.03.054
   Khari M, 2020, IEEE T SYST MAN CY-S, V50, P73, DOI 10.1109/TSMC.2019.2903785
   Kim J, 2015, IEEE T IND INFORM, V11, P1653, DOI 10.1109/TII.2015.2434773
   Kingsley K. A., 2020, Journal of Information Hiding and Multimedia Signal Processing, V11, P14
   Laishram D., 2018, P 3 INT C INT THINGS, P26
   Lakshmanaprabu SK, 2018, IEEE ACCESS, V6, P24196, DOI 10.1109/ACCESS.2018.2830651
   Li TF, 2020, IEEE ACCESS, V8, P12845, DOI 10.1109/ACCESS.2020.2964830
   Mahmoud MME, 2018, IEEE ACCESS, V6, P31950, DOI 10.1109/ACCESS.2018.2845399
   Mishra TK, DESIGN IMPLEMENTATIO
   Molaei A.M., 2017, AUT J ELECT ENG, V49, P53
   Moosavi SR, 2016, FUTURE GENER COMP SY, V64, P108, DOI 10.1016/j.future.2016.02.020
   Moses AK, 2021, INT J COMPUT MATH-CO, V6, P7, DOI 10.1080/23799927.2020.1854864
   Mutlag AA, 2019, FUTURE GENER COMP SY, V90, P62, DOI 10.1016/j.future.2018.07.049
   NANAYAKKARA N, 2019, SECURITY PRIVACY INT
   Nassrullah HA., 2020, J INFORM HIDING MULT, V11, P126
   Ogundokun Roseline Oluwaseun, 2020, Information Systems. 17th European, Mediterranean, and Middle Eastern Conference, EMCIS 2020. Proceedings. Lecture Notes in Business Information Processing (LNBIP 402), P553, DOI 10.1007/978-3-030-63396-7_37
   Rajendran S., 2020, RECENT TRENDS IMAGE, P181
   Rawat P, 2016, COMPUT COMMUN, V94, P1, DOI 10.1016/j.comcom.2016.07.012
   Saracevic M, 2020, IET INTELL TRANSP SY, V14, P1456, DOI 10.1049/iet-its.2019.0855
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Schuessler JH, 2017, J APPL SEC RES, V12, P512, DOI 10.1080/19361610.2017.1354275
   Shankar K, 2017, CHINA COMMUN, V14, P118, DOI 10.1109/CC.2017.7868160
   Shanthakumari R, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1106-0
   Shin D, 2017, INTERNET RES, V27, P1227, DOI 10.1108/IntR-07-2016-0200
   Sicari S, 2015, COMPUT NETW, V76, P146, DOI 10.1016/j.comnet.2014.11.008
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Sun WC, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5978636
   Taha MS, 2019, IOP CONF SER-MAT SCI, V518, DOI 10.1088/1757-899X/518/5/052003
   Tahir S, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719851977
   Tan CC, 2009, IEEE T INF TECHNOL B, V13, P926, DOI 10.1109/TITB.2009.2033055
   Tang JW, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6328504
   Ul Islam S, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.042
   Wang FH, 2009, STUD COMPUT INTELL, V232, P11
   Wencheng Sun, 2017, 2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom), P1, DOI 10.1109/HealthCom.2017.8210774
   Williams PAH, 2015, MED DEVICES-EVID RES, V8, P305, DOI 10.2147/MDER.S50048
   Wood A., 2006, University of Virginia Computer Science Department Technical Report, V2, P17
   Yang YC, 2017, IEEE INTERNET THINGS, V4, P1250, DOI 10.1109/JIOT.2017.2694844
   Yaqoob I, 2017, COMPUT NETW, V129, P444, DOI 10.1016/j.comnet.2017.09.003
   Yin MY, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/6803801
NR 76
TC 24
Z9 24
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31705
EP 31727
DI 10.1007/s11042-021-11125-2
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674550000004
DA 2024-07-18
ER

PT J
AU Liu, HJ
   Guo, F
   Xia, DX
AF Liu, Haojie
   Guo, Fang
   Xia, Daoxun
TI Domain adaptation with structural knowledge transfer learning for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Domain adaptation; Transfer learning;
   Unsupervised learning; Cross domain; Adversarial training
ID FEATURES; NETWORK
AB Recently, supervised person re-identification (Re-ID) algorithms have achieved great performance on benchmarks. However, it highly depends on labeled training samples and may not generalize well to new domains, limiting the applicability of person Re-ID in practical. To this end, we propose a novel unsupervised domain adaptive approach to transfer the learned knowledge across diverse domains. To address the issue of lacking target domain annotations, we perform a supervised classification task using only labeled source data and share weights of two feature extraction networks. Considering unbalanced data distribution between the source domain and target domain, we then adopt a generative adversarial approach with GAN-based losses to reduce domain discrepancy and further improve Re-ID performance. The entire framework can be trained in an unsupervised manner with standard deep neural networks. Extensive experiments demonstrate that our proposed approach performs favourably against state-of-the-art methods.
C1 [Liu, Haojie; Guo, Fang; Xia, Daoxun] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang 550025, Peoples R China.
   [Liu, Haojie; Xia, Daoxun] Guizhou Normal Univ, Engn Lab Appl Technol Big Data Educ, Guiyang 550025, Peoples R China.
C3 Guizhou Normal University; Guizhou Normal University
RP Xia, DX (corresponding author), Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang 550025, Peoples R China.; Xia, DX (corresponding author), Guizhou Normal Univ, Engn Lab Appl Technol Big Data Educ, Guiyang 550025, Peoples R China.
EM dxxia@gznu.edu.cn
OI Liu, Haojie/0000-0003-1270-1771
FU Nature Science Foundation of China [61762023]; Sprouts Come Special
   Project of GuiZhou Department of Science and Technology [QKHPTRC
   [2017]5726]; Startup Project of Doctoral Research of Guizhou Normal
   University (2017)
FX This work was supported by the Nature Science Foundation of China
   (No.61762023), the Sprouts Come Special Project of GuiZhou Department of
   Science and Technology (No. QKHPTRC [2017]5726) and the Startup Project
   of Doctoral Research of Guizhou Normal University (2017).
CR An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   El Madany NE, 2019, INT CONF ACOUST SPEE, P3487, DOI 10.1109/ICASSP.2019.8682786
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Genç A, 2019, MULTIMED TOOLS APPL, V78, P5843, DOI 10.1007/s11042-018-6409-3
   Hermans Alexander, 2017, ARXIV170307737
   Iman M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P29, DOI 10.1109/IranianMVIP.2015.7397497
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Luo Z., 2017, P 31 INT C NEUR INF, P165
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Ma WJ, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1154, DOI 10.1109/ICCT.2018.8600061
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Ren CX, 2020, IEEE T INF FOREN SEC, V15, P1290, DOI 10.1109/TIFS.2019.2939750
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tian YM, 2019, MULTIMED TOOLS APPL, V78, P24187, DOI 10.1007/s11042-018-6998-x
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Watson G, 2020, MULTIMED TOOLS APPL, V79, P6463, DOI 10.1007/s11042-019-08499-9
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wenbi Rao, 2020, 2020 Proceedings of IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), P212, DOI 10.1109/ICAICA50127.2020.9181918
   Xiao-Yu Zhang, 2016, 2016 IEEE Conference on Computer Communications: Workshops (INFOCOM WKSHPS), P674, DOI 10.1109/INFCOMW.2016.7562161
   Xie SA, 2018, PR MACH LEARN RES, V80
   Yang X, 2019, IEEE T NEUR NET LEAR, V30, P2987, DOI [10.1109/TNNLS.2018.2861991, 10.1109/TNNLS.2018.2790479]
   Yanwen Chong, 2019, Intelligent Computing Theories and Application. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11643), P54, DOI 10.1007/978-3-030-26763-6_6
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   ZHONG Z, 2018, PROC CVPR IEEE, P5157, DOI DOI 10.1109/CVPR.2018.00541
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 11
Z9 11
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29321
EP 29337
DI 10.1007/s11042-021-11139-w
EA JUN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000664856100002
DA 2024-07-18
ER

PT J
AU Li, N
   Huang, JC
   Feng, YH
AF Ning, Li
   Jincai, Huang
   Yanghe, Feng
TI Construction of multi-channel fusion salient object detection network
   based on gating mechanism and pooling network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salienct object recognition; Gating mechanism; Pooling network;
   Multi-channel fusion; Convolutional Neural network
AB We combine SNet network based on gating mechanism with poolnet network to solve the problem of salient object detection. The network construction of this paper is based on FPN, which is a classic U-net backbone network. Inspired by poolnet, we also introduce the global feature guidance module. By aggregating the high-level semantic information into the transposition convolution stage of different scales, the higher-level semantic features can be used more effectively. Although the introduction of global information can effectively improve the effect of saliency monitoring, how to aggregate the global and local features of different scales still needs to be further explored. Inspired by SNet network, we also integrate snet into our network. In the specific feature fusion process, the feature values of different channels are weighted, and each channel is given different weights. The more important semantic information is extracted from multiple channels, and the key semantic information in the feature map is retained. Compared with the current typical methods, we find that the introduction of snet module can reduce the generation of error areas of saliency map, and further improve the integrity of saliency map. For different regions of the same object, due to the difference of color contrast and texture, the saliency map generated by the previous method is inconsistent in the same object region. Our method can effectively solve this problem. For the same object, we can generate consistent results of saliency probability. Through quantitative evaluation with the existing 15 methods (including SOTA method). Our network can process 300 * 267 images faster than 11FPS, which is at a medium level compared with the most advanced networks. These networks include DGRL, PiCANet, PoolNet and so on. The Precision and Recall curve results show that our network performs well on DUT-O, DUT-S and ECSSD data sets, and the minimum precision values are all above 0.47. The false positive prediction of salient objects in the graph is low, and the overall performance of the model is good.
C1 [Ning, Li; Jincai, Huang; Yanghe, Feng] Natl Univ Def Technol, Coll Syst Engn, Changsha, Hunan, Peoples R China.
   [Ning, Li] China Inst Marine Technol & Econ, Marine Human Factors Engn Lab, Beijing, Peoples R China.
C3 National University of Defense Technology - China
RP Feng, YH (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha, Hunan, Peoples R China.
EM fengyanghe@nudt.edu.cn
RI HUANG, Jincai/AAH-2517-2021
OI feng, yanghe/0000-0003-1608-8695
FU National Natural Science Foundation of China 263 [71471174]; National
   Defence Pre-research Foundation [41412040304]
FX Thanks for the technical support provided by the National Natural
   Science Foundation of China 263 (No. 71471174) and National Defence
   Pre-research Foundation (No. 41412040304).
CR [Anonymous], 2018, ARXIV180309860
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cook A-p-f-o-l, 2017, Global average pooling layers for object localization
   Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Hand D, 2018, STAT COMPUT, V28, P539, DOI 10.1007/s11222-017-9746-6
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Ketkar N, 2017, DEEP LEARNING PYTHON, P195, DOI [10.1007/978-1-4842-2766-4_12, DOI 10.1007/978-1-4842-2766-4_12]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu L, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329061
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sethi A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/74243
   Simonyan K., 2014, CORR
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   van Wyk Gerard Jacques, 2019, IEEE IJCNN
   Wang L, 2018, IEEE IPCCC
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou K, 2016, DESTECH TRANS COMP
NR 55
TC 1
Z9 1
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12111
EP 12126
DI 10.1007/s11042-021-11031-7
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000663271700005
DA 2024-07-18
ER

PT J
AU Lin, YM
   Fu, Y
   Li, Y
   Cai, GY
   Zhou, AY
AF Lin, Yuming
   Fu, Yu
   Li, You
   Cai, Guoyong
   Zhou, Aoying
TI Self-attention-based neural networks for refining the overlength product
   titles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Product title refinement; Self-attention mechanism; GRU neural network;
   Gating mechanism
AB Online sellers often produce redundant and lengthy product textual titles with extra information on e-commerce platforms to attract the attentions of customers. Such overlength product titles become a problem when they are displayed on mobile applications. In this paper, the problem of refining redundant and overlength product titles is studied to generate concise and informative titles. First, the task of refining the long title is transformed into a sequential classification problem by predicting whether a word in original title will remain in finial short title. Then, a self-attention-based neural network is proposed to extract the most informative words from original title to construct the short title. The proposed basic model is also extended with a gated recurrent unit (GRU) neural network and a gating mechanism to improve the position encoding process and learn the weights of encoding features from different directions. Moreover, an algorithm is designed to construct the datasets for redundant product title compression analysis based on the open dataset LESD4EC. Finally, extensive experiments are implemented on the rebuilt datasets to demonstrate the effectiveness and efficiency of the proposed methods. The experimental results show that the proposed methods significantly outperform the state-of-the-art methods based on the precision, recall, F-1 value and the mean absolute error, as well as runtime and space cost.
C1 [Lin, Yuming; Fu, Yu; Li, You; Cai, Guoyong] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
   [Zhou, Aoying] East China Normal Univ, Sch Data Sci & Engn, Shanghai 200062, Peoples R China.
C3 Guilin University of Electronic Technology; East China Normal University
RP Li, Y (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
EM ymlin@guet.edu.cn; fuzzyu@foxmail.com; liyou@guet.edu.cn;
   ccgycai@guet.edu.cn; ayzhou@sei.ecnu.edu.cn
RI Lin, Yuming/HGF-3286-2022
OI , Yuming/0000-0001-6850-5222
FU National Natural Science Foundation of China [62062027, U1711263];
   Guangxi Natural Science Foundations [2018GXNSFDA281049,
   2020GXNSFAA159012, 2018GXNSFAA281326]; Science and Technology Major
   Project of Guangxi Province [AA19046004]; Innovation Project of Guest
   Graduate Education [2019YCXS040]; project of Guangxi Key Laboratory of
   Trusted Software [kx201916]
FX The authors thank the anonymous reviewers for their valuable comments
   and suggestions to improve the quality of this paper. This work was
   partially supported by the National Natural Science Foundation of China
   (No. 62062027, U1711263), the Guangxi Natural Science Foundations (No.
   2018GXNSFDA281049, 2020GXNSFAA159012, 2018GXNSFAA281326), the Science
   and Technology Major Project of Guangxi Province (No. AA19046004), the
   Innovation Project of Guest Graduate Education (No. 2019YCXS040) and the
   project of Guangxi Key Laboratory of Trusted Software (No. kx201916).
CR [Anonymous], 2011, P 49 ANN M ASS COMP
   [Anonymous], 2014, P WORKSH CONT VECT S, DOI DOI 10.3115/V1/W14-1504
   Chen IF, 2015, INT CONF ACOUST SPEE, P5196, DOI 10.1109/ICASSP.2015.7178962
   Chen MH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1511
   Chopra Sumit, 2016, P 2016 C N AM CHAPT, P93, DOI DOI 10.18653/V1/N16-1012
   Cohn T, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2483669.2483674
   Cohn Trevor, 2008, Proceedings of the 22nd International Conference on Computational Linguistics-Volume, P137
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Gong Y, 2019, AAAI CONF ARTIF INTE, P9460
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kingma D. P., 2014, arXiv
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   McDonald R, 2007, LECT NOTES COMPUT SC, V4425, P557
   McDonald Ryan, 2006, EACL 2006
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Rose D., 2010, TEXT MINING APPL THE, V1, P1, DOI [DOI 10.1002/9780470689646.CH1, 10.1002/9780470689646.CH1]
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Sun F, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P7, DOI 10.1145/3269206.3271722
   Sun X, 2016, P 2016 C EMP METH NA, P1787
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O., 2015, Advances in neural information processing systems, P2692
   Wang JG, 2018, AAAI CONF ARTIF INTE, P451
   Zhang JG, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES(NAACL HLT 2019), VOL. 2 (INDUSTRY PAPERS), P64
NR 28
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28501
EP 28519
DI 10.1007/s11042-021-10908-x
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658231800002
DA 2024-07-18
ER

PT J
AU Baldassarre, MT
   Caivano, D
   Romano, S
   Cagnetta, F
   Fernandez-Cervantes, V
   Stroulia, E
AF Baldassarre, Maria Teresa
   Caivano, Danilo
   Romano, Simone
   Cagnetta, Francesco
   Fernandez-Cervantes, Victor
   Stroulia, Eleni
TI PhyDSL<sub>K</sub>: a model-driven framework for generating exergames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model-driven game development; Rehabilitation exergames; Model-driven
   software engineering
ID SYSTEM
AB In recent years, we have been witnessing a rapid increase of research on exergames-i.e., computer games that require users to move during gameplay as a form of physical activity and rehabilitation. Properly balancing the need to develop an effective exercise activity with the requirements for a smooth interaction with the software system and an engaging game experience is a challenge. Model-driven software engineering enables the fast prototyping of multiple system variants, which can be very useful for exergame development. In this paper, we propose a framework, PhyDSL(K), which eases the development process of personalized and engaging Kinect-based exergames for rehabilitation purposes, providing high-level tools that abstract the technical details of using the Kinect sensor and allows developers to focus on the game design and user experience. The system relies on model-driven software engineering technologies and is made of two main components: (i) an authoring environment relying on a domain-specific language to define the exergame model encapsulating the gameplay that the exergame designer has envisioned and (ii) a code generator that transforms the exergame model into executable code. To validate our approach, we performed a preliminary empirical evaluation addressing development effort and usability of the PhyDSL(K) framework. The results are promising and provide evidence that people with no experience in game development are able to create exergames with different complexity levels in one hour, after a less-than-two-hour training on PhyDSL(K). Also, they consider PhyDSL(K) usable regardless of the exergame complexity.
C1 [Baldassarre, Maria Teresa; Caivano, Danilo; Romano, Simone; Cagnetta, Francesco] Univ Bari, Bari, Italy.
   [Fernandez-Cervantes, Victor; Stroulia, Eleni] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.
C3 Universita degli Studi di Bari Aldo Moro; University of Alberta
RP Baldassarre, MT (corresponding author), Univ Bari, Bari, Italy.
EM mariateresa.baldassarre@uniba.it
RI Romano, Simone/JVZ-6529-2024; Stroulia, Eleni/H-6518-2018
OI Stroulia, Eleni/0000-0002-8784-8236; Romano, Simone/0000-0003-4880-3622;
   baldassarre, maria teresa/0000-0001-8589-2850
FU Universita degli Studi di Bari Aldo Moro within the CRUICARE Agreement;
   Project "HEVOLUS+" by FSC -APQ Sviluppo Locale 2007-2013-Titolo II-Capo
   2 -Regione Puglia [OH4JBL3]
FX Open access funding provided by Universit`a degli Studi di Bari Aldo
   Moro within the CRUICARE Agreement. This study has been partially funded
   by the Project "HEVOLUS+" (Cod.OH4JBL3) funded by FSC -APQ Sviluppo
   Locale 2007-2013-Titolo II-Capo 2 -Regione Puglia.
CR [Anonymous], 2011, P ANN INT C IEEE ENG
   Averell E, 2019, 2019 AES INTERNATIONAL CONFERENCE ON IMMERSIVE AND INTERACTIVE AUDIO
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   BASILI VR, 1988, IEEE T SOFTWARE ENG, V14, P758, DOI 10.1109/32.6156
   Brambilla M., 2017, Model-Driven Software Engineering in Practice, Second Edition, ser. Synthesis Lectures on Software Engineering, VSecond
   Patón-Romero JD, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9101761
   Dunstan J, 2015, PURE CODE APPROACH U
   Fernandez-Cervantes V, 2018, ENTERTAIN COMPUT, V27, P60, DOI 10.1016/j.entcom.2018.04.001
   Fernandez-Cervantes V, 2016, LECT NOTES COMPUT SC, V9926, P38, DOI 10.1007/978-3-319-46100-7_4
   France R, 2007, FOSE 2007: FUTURE OF SOFTWARE ENGINEERING, P37, DOI 10.1109/FOSE.2007.14
   Galna B, 2014, GAIT POSTURE, V39, P1062, DOI 10.1016/j.gaitpost.2014.01.008
   Gao Z, 2016, GAMES HEALTH J, V5, P318, DOI 10.1089/g4h.2016.0049
   Gómez-Portes C, 2020, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 2, P533, DOI 10.5220/0009574005330543
   Guana V, 2015, 2015 IEEE/ACM 4TH INTERNATIONAL WORKSHOP ON GAMES AND SOFTWARE ENGINEERING, P15, DOI 10.1109/GAS.2015.11
   Hardy S, 2015, MULTIMED TOOLS APPL, V74, P5289, DOI 10.1007/s11042-014-2009-z
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Li JH, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P296, DOI 10.1109/CW.2018.00061
   Mocanu I, 2016, INT C INTELL COMP CO, P117, DOI 10.1109/ICCP.2016.7737132
   Ofli F, 2016, IEEE J BIOMED HEALTH, V20, P201, DOI 10.1109/JBHI.2015.2391671
   Pastor I, 2012, IEEE ENG MED BIO, P1286, DOI 10.1109/EMBC.2012.6346173
   Sáenz-de-Urturi Z, 2015, BEHAV INFORM TECHNOL, V34, P1040, DOI 10.1080/0144929X.2015.1077889
   Staiano AE, 2011, ENTERTAIN COMPUT, V2, P17, DOI 10.1016/j.entcom.2011.03.008
   Vegas S, 2016, IEEE T SOFTWARE ENG, V42, P120, DOI 10.1109/TSE.2015.2467378
   Wohlin C., 2012, Experimentation in Software Engineering
NR 24
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27947
EP 27971
DI 10.1007/s11042-021-10980-3
EA MAY 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655574500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, H
   Cui, W
AF Chen, Hui
   Cui, Wen
TI Holes filling of scattered point cloud based on simplification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Holes filling; Simplification; Features; Curvature
AB To address the problem of feature points missing and surface holes after 3D reconstruction. A method of filling holes after extracting feature points of point cloud data is proposed. In this paper, the method of extracting feature points by multi-discriminant parameters is used to simplify the point cloud. The original shape features are retained while the data are simplified. Then, the initial triangulation of the point cloud is carried out. The resulting triangular mesh is least squared to get a relatively normal mesh, and finally the curvature of the surface is adjusted and optimized. The experimental results show that the simplification rate corresponding to improving the efficiency and retaining the original features is different for the point cloud data of different magnitude. The simplification rate of tens of thousands point cloud data is 70-80%, and that of hundreds of thousands of point cloud data is 40%. It also shows that the combination of feature point extraction and hole repair not only improves the efficiency of the repair process, but also retains the original features of the data.
C1 [Chen, Hui; Cui, Wen] Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
C3 Shanghai University of Electric Power
RP Chen, H (corresponding author), Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
EM chenhui@shiep.edu.cn; cuiwen@mail.shiep.edu.cn
RI cui, wen/GPX-7131-2022; Hui, .Chen/AER-3973-2022
OI cui, wen/0000-0002-7846-2534; Hui, .Chen/0000-0002-5386-4078
FU National Natural Science Foundation oc China [51705304]; Natrual Science
   Foundation of Shanghai [20ZR1421300]
FX This work was supported by National Natural Science Foundation oc China
   (Grant No.51705304), Natrual Science Foundation of Shanghai(Grant
   No.20ZR1421300).
CR Bin XU, 2014, COMPUTER ENG DESIGN
   Chen Hui, 2020, 2020 5th International Conference on Power and Renewable Energy (ICPRE), P387, DOI 10.1109/ICPRE51194.2020.9233241
   Davis J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P428, DOI 10.1109/TDPVT.2002.1024098
   Dong JX., 2008, J ZHEJIANG U
   Feipeng D., 2013, Acta Optica Sinica, V33, DOI 10.3788/AOS201333.0815001
   Gai SY, 2019, J OPT SOC AM A, V36, pA39, DOI 10.1364/JOSAA.36.000A39
   Gao Y, 2017, NUM ALG, V78, P1
   Geng G., 2018, APPL RES COMPUTERS
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han HY, 2015, OPTIK, V126, P2157, DOI 10.1016/j.ijleo.2015.05.092
   Hao JB, 2017, MULTIMED TOOLS APPL, V76, P19591, DOI 10.1007/s11042-015-3232-y
   Huang R., 2017, ACTA GEODAETICA CART
   Jian D., 2016, COMPUTER ENG DESIGN
   Lan Q., 2017, ENG SURVEYING MAPPIN
   Liu Shifan, 2018, Journal of Xi'an Jiaotong University, V52, P37, DOI 10.7652/xjtuxb201808006
   Liu WQ, 2019, CONTROL DECISION, V35, P2986
   Meng F., 2014, MECH SCI TECHNOLOGY
   Miao Y., 2016, J COMPUTER AIDED DES
   Mukherjee A, 2021, MULTIMED TOOLS APPL, V80, P35171, DOI 10.1007/s11042-020-09841-2
   Nie EJ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), P2456, DOI 10.1109/ROBIO.2017.8324788
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Pai Feng Lee, 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P1, DOI 10.1109/CGIV.2011.26
   Shi BQ, 2011, COMPUT AIDED DESIGN, V43, P910, DOI 10.1016/j.cad.2011.04.001
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   [王春香 Wang Chunxiang], 2018, [现代制造工程, Modern Manufacturing Engineering], P44
   Wang D., 2017, J TEST MEASUREMENT T
   Wang WD, 2019, MULTIMED TOOLS APPL, V78, P8737, DOI 10.1007/s11042-018-6244-6
   Wu XJ, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P5329, DOI 10.1109/WCICA.2014.7053624
   Xiao-Ran W, 2017, COMPUT ENG, V31, P512
   Xie Qian-ru, 2013, Application Research of Computers, V30, P3175, DOI 10.3969/j.issn.1001-3695.2013.10.074
   Yuan Xiao-cui, 2015, Optics and Precision Engineering, V23, P2666, DOI 10.3788/OPE.20152309.2666
   Zhao JT., 2009, SCI TECHNOLOGY ENG
NR 32
TC 5
Z9 6
U1 4
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14641
EP 14661
DI 10.1007/s11042-021-11019-3
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000652106100001
DA 2024-07-18
ER

PT J
AU Kaul, S
   Kumar, Y
   Ghosh, U
   Alnumay, W
AF Kaul, Surabhi
   Kumar, Yogesh
   Ghosh, Uttam
   Alnumay, Waleed
TI Nature-inspired optimization algorithms for different computing systems:
   novel perspective and systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Sustainability; Energy efficiency; Load balancing; Scheduling; Grid
   computing; Cloud computing; Distributed computing; Fog computing; Edge
   computing
ID PRIVACY PROTECTION; ENERGY EFFICIENCY; FOG; TASKS; ALLOCATION; SERVICE
AB Nature inspired algorithm plays a very vibrant role in solving the different optimization problems these days. The fundamental attitude of naturalistic approaches is to boost the competence, improvement, proficiency, success in the task except from it to help in underrating the energy use, cost, size. Several computing techniques are taking the benefits from nature inspired algorithms for solving their problems related to load balancing, scheduling and many others. These algorithms have come up with lots of improvements in the results. The aim of this analysis is to make efforts in the betterment in different areas of computing and help in solving various problems related to load balancing, scheduling and energy efficiency. The structure of the paper includes an introduction, contribution to the work, background study, which includes the role of nature inspired techniques in a different computing environment, research challenges and its applications. The sustainable goal and objective of the article is to perform the energy efficiency, load balancing and scheduling on different computing systems which include grid, cloud, distributed, fog and edge computing by using various nature inspired algorithms. This comprehensive study gives the awareness and valuable provision for the researchers in this area by providing a thorough study of different computing techniques in different research fields.
C1 [Kaul, Surabhi] Chandigarh Univ, Mohali 140413, Punjab, India.
   [Kumar, Yogesh] Chandigarh Grp Coll, Mohali 140307, Punjab, India.
   [Ghosh, Uttam] Vanderbilt Univ, Nashville, TN 37235 USA.
   [Alnumay, Waleed] King Saud Univ, Riyadh 11451, Saudi Arabia.
C3 Chandigarh University; Vanderbilt University; King Saud University
RP Ghosh, U (corresponding author), Vanderbilt Univ, Nashville, TN 37235 USA.
EM surabhi93kaul@gmail.com; yogesh.arora10744@gmail.com;
   ghosh.uttam@ieee.org; wnumay@ksu.edu.sa
RI Ghosh, Uttam/CAI-5749-2022; Kumar, Yogesh/AAW-1656-2021; Ghosh,
   Uttam/V-8237-2018; kumar, yogesh/AAD-8469-2021; Ghosh,
   Uttam/CAF-9098-2022; Alnumay, Waleed/AAP-1781-2021
OI Ghosh, Uttam/0000-0003-1698-8888; Kumar, Yogesh/0000-0002-8169-7481;
   Ghosh, Uttam/0000-0003-1698-8888; kumar, yogesh/0000-0002-2879-0441;
   Ghosh, Uttam/0000-0003-1698-8888; Alnumay, Waleed/0000-0001-5076-2060
FU King Saud University, Riyadh, Saudi Arabia [RSP-2020/250]
FX This work was supported by Researchers Supporting Project number
   (RSP-2020/250), King Saud University, Riyadh, Saudi Arabia.
CR Abawajy JH, 2017, IEEE COMMUN MAG, V55, P48, DOI 10.1109/MCOM.2017.1600374CM
   Abdelaziz A, 2018, MEASUREMENT, V119, P117, DOI 10.1016/j.measurement.2018.01.022
   Abdulhamid SM, 2018, NEURAL COMPUT APPL, V29, P279, DOI 10.1007/s00521-016-2448-8
   Adil SH, 2015, 2015 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS & TECHNOLOGIES (ICOSST), P158, DOI 10.1109/ICOSST.2015.7396420
   Adithyan T. Ajay, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P1131, DOI 10.1109/ICOEI.2017.8300889
   Agarwal Yash, 2018, International Journal of Transportation Science and Technology, V7, P60, DOI 10.1016/j.ijtst.2017.12.001
   Alamri A, 2016, CLUSTER COMPUT, V19, P2251, DOI 10.1007/s10586-016-0647-9
   Ali HGEH, 2017, EGYPT INFORM J, V18, P11, DOI 10.1016/j.eij.2016.07.002
   Bansal S, 2009, COMM COM INF SC, V31, P110
   Beloglazov A, 2012, FUTURE GENER COMP SY, V28, P755, DOI 10.1016/j.future.2011.04.017
   Bhatia MK, 2017, ADV COMPUT SCI TECHN, V10, P1707
   Bui DM, 2017, J PARALLEL DISTR COM, V102, P103, DOI 10.1016/j.jpdc.2016.11.011
   Butt AA, 2019, INT WIREL COMMUN, P1588
   Cao JW, 2005, FUTURE GENER COMP SY, V21, P135, DOI 10.1016/j.future.2004.09.032
   CARRERA EV, 2001, P 8 ACM SIGPLAN S PR, P113
   Chabra, 2019, INT J FUTURE REVOLUT, V5, P364
   Deng RL, 2016, IEEE INTERNET THINGS, V3, P1171, DOI 10.1109/JIOT.2016.2565516
   Djemai T, 2019, INT SYMP PARA DISTR, P32, DOI 10.1109/ISPDC.2019.00020
   Duan YC, 2019, ENG APPL ARTIF INTEL, V81, P323, DOI 10.1016/j.engappai.2019.03.002
   Elzeki O., 2012, International Journal of Soft Computing and Engineering, V2, P470
   Erskine SK, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8040455
   Feng J., 2018, 2018 IEEE INT C COMM, P1
   Fernández-Montes A, 2012, EXPERT SYST APPL, V39, P9443, DOI 10.1016/j.eswa.2012.02.115
   Gabi D, 2018, J INF COMMUN TECHNOL, V17, P435
   Gai KK, 2018, APPL SOFT COMPUT, V70, P12, DOI 10.1016/j.asoc.2018.03.056
   Gandhi A, 2009, PERF E R SI, V37, P157
   Garg S.K., 2009, P 17 INT C ADV COMP
   Gaur K., 2019, P 2019 2 INT C ADV C, P1, DOI DOI 10.1109/ICACCP.2019.8882917
   Griffin T., 2000, Proceedings of the 33rd Annual Hawaii International Conference on Systems Sciences
   Guan YG, 2018, IEEE NETWORK, V32, P106, DOI 10.1109/MNET.2018.1700250
   Guo Q, 2017, AIP CONF PROC, V1834, DOI 10.1063/1.4981635
   Han JJ., 2003, INT C GRID COOP COMP, P141
   Hao YS, 2012, FUTURE GENER COMP SY, V28, P657, DOI 10.1016/j.future.2011.10.010
   Hosseinioun P, 2020, J PARALLEL DISTR COM, V143, P88, DOI 10.1016/j.jpdc.2020.04.008
   Isa ISM, 2018, INT C TRANS OPT NETW
   Kamalam GK, 2010, INT J COMPUT SCI NET, V10, P24
   Karlekar NP, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3700
   Karlekar NP, 2017, INT J MODEL SIMUL SC, V8, DOI 10.1142/S1793962317500210
   Kaul S, 2017, INT J ADV RES COMPUT, V8
   Kaur N, 2017, IEEE SYST J, V11, P796, DOI 10.1109/JSYST.2015.2469676
   Khanli LM, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2, P639, DOI 10.1109/CIMCA.2008.30
   Khater BS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010178
   Khattar N, 2019, J SUPERCOMPUT, V75, P4750, DOI 10.1007/s11227-019-02764-2
   Kitanov S, 2017, 17TH IEEE INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES - IEEE EUROCON 2017 CONFERENCE PROCEEDINGS, P491, DOI 10.1109/EUROCON.2017.8011159
   Kumar D., 2019, J ISMAC, V1, P72
   Kumar Y, 2019, INT C ADV ENG SCI MA
   Kumar Y., 2020, BIG DATA ANAL HEALTH, DOI [DOI 10.1007/978-3-030-31672-3_1, 10.1007/978-3-030-31672-3_1]
   Lamb ZW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061303
   Lawanyashri M., 2017, Informatics in Medicine Unlocked, V8, P42, DOI 10.1016/j.imu.2017.02.005
   Li GS, 2019, PROCEDIA COMPUT SCI, V147, P463, DOI [10.1109/ICISCAE48440.2019.221676, 10.1016/j.procs.2019.01.273]
   Liao ML, 2016, BMC NEPHROL, V17, DOI 10.1186/s12882-016-0238-2
   Lin L, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON MOBILE AD-HOC AND SENSOR NETWORKS (MSN 2018), P165, DOI 10.1109/MSN.2018.000-1
   Liu HH, 2007, SOFTWARE PRACT EXPER, V37, P1215, DOI 10.1002/spe.814
   Liu J, 2016, IEEE INT SYMP INFO, P1451, DOI 10.1109/ISIT.2016.7541539
   Liu LD, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/2102348
   Mahajan K, 2013, J INF PROCESS SYST, V9, P379, DOI 10.3745/JIPS.2013.9.3.379
   Mallikarjuna B, 2015, CYBERN INF TECHNOL, V15, P138, DOI 10.1515/cait-2015-0060
   Meddeber M, 2010, DISTRIBUTED LOAD BAL, V12, P43
   Meng WZ, 2018, LECT NOTES COMPUT SC, V10946, P759, DOI 10.1007/978-3-319-93638-3_44
   Mocnej J, 2018, IFAC PAPERSONLINE, V51, P162, DOI 10.1016/j.ifacol.2018.07.147
   Nayak J, 2018, STUD BIG DATA, V39, P1, DOI 10.1007/978-3-319-73676-1_1
   Nigam A, 2018, COMPREHENSIVE REV OP, V5, P159
   Ogbuabor Godwin, 2018, International Journal of Computer Science & Information Technology, V10, P27, DOI 10.5121/ijcsit.2018.10203
   Oueida S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124307
   Pan JW, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1494-1
   Pizzuti C, 2012, IEEE T EVOLUT COMPUT, V16, P418, DOI 10.1109/TEVC.2011.2161090
   Plosila, 2016, INT J DIGITAL CONTEN
   Prabavathy S, 2018, J COMMUN NETW-S KOR, V20, P291, DOI 10.1109/JCN.2018.000041
   Randles Martin, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P551, DOI 10.1109/WAINA.2010.85
   Rashidi S, 2017, J SUPERCOMPUT, V73, P3796, DOI 10.1007/s11227-017-1983-0
   Rizvandi NB., 2014, PERFORMANCE PROVISIO
   Scoca V, 2018, CLOSER: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND SERVICES SCIENCE, P158, DOI 10.5220/0006706201580168
   Sen J., 2010, 2010 1st International Conference on Parallel, Distributed and Grid Computing (PDGC 2010), P123, DOI 10.1109/PDGC.2010.5679879
   Setia, 2016, INT J SCI ENG RES, V7, P1709
   Sharma G., 2019, INT J ENG ADV TECHNO, V8
   Shi T, 2016, PERVASIVE MOB COMPUT, V27, P90, DOI 10.1016/j.pmcj.2015.07.005
   Shobana G., 2014, INT C INFORM COMMUNI, P1, DOI DOI 10.1109/ICICES.2014.7033816
   Singh, 2014, INT J SCI ENG TECHNO, V3
   Sivanandam, 2010, ICTACT J SOFT COMPUT, V2, P85
   Sood SK, 2020, MULTIMED TOOLS APPL, V79, P10717, DOI 10.1007/s11042-019-08573-2
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Taheri J, 2013, COMPUT OPER RES, V40, P1564, DOI 10.1016/j.cor.2011.11.012
   Dang TD, 2017, IEEE TRUST, P1109, DOI 10.1109/Trustcom/BigDataSE/ICESS.2017.360
   Tiefu Zhao, 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7356397
   Toor A, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1394-4
   Tychalas D, 2020, SIMUL MODEL PRACT TH, V98, DOI 10.1016/j.simpat.2019.101982
   Vasques TL, 2019, ENERG EFFIC, V12, P1399, DOI 10.1007/s12053-018-9753-2
   Velliangiri S, 2019, CLUSTER COMPUT, V22, P10615, DOI 10.1007/s10586-017-1149-0
   Ventura Daniela, 2014, Ubiquitous Computing and Ambient Intelligence. Personalisation and User Adapted Services. 8th International Conference, UCAmI 2014. Proceedings: LNCS 8867, P444, DOI 10.1007/978-3-319-13102-3_72
   Viswanathan H, 2012, IEEE COMMUN MAG, V50, P92, DOI 10.1109/MCOM.2012.6194388
   Wang CS, 2004, IEEE T POWER SYST, V19, P2068, DOI 10.1109/TPWRS.2004.836189
   Wang HY, 2017, IEEE INT CONF BIG DA, P1213, DOI 10.1109/BigData.2017.8258047
   Wang H, 2018, INFORM SCIENCES, V438, P95, DOI 10.1016/j.ins.2018.01.041
   Wills, 2020, MULTIMED TOOLS APPL, P1
   Woo SH, 1997, HIGH PERFORMANCE COMPUTING ON THE INFORMATION SUPERHIGHWAY - HPC ASIA '97, PROCEEDINGS, P301, DOI 10.1109/HPC.1997.592164
   Yang X-S, 2019, NATURE INSPIRED ALGO, P21, DOI DOI 10.1007/978-3-030-16936-7
   Yi SH, 2015, LECT NOTES COMPUT SC, V9204, P685, DOI 10.1007/978-3-319-21837-3_67
   Yousifi A, 2015, INT J GRID DISTRIB, V8, P125, DOI 10.14257/ijgdc.2015.8.6.13
   Zhang K, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL WORKSHOP ON RESILIENT NETWORKS DESIGN AND MODELING (RNDM), P288, DOI 10.1109/RNDM.2016.7608300
   Zhang K, 2016, IEEE ACCESS, V4, P5896, DOI 10.1109/ACCESS.2016.2597169
   Zhou FH, 2018, IEEE NETWORK, V32, P152, DOI 10.1109/MNET.2017.1700208
   Zhou H, 2018, J PARALLEL DISTR COM, V121, P15, DOI 10.1016/j.jpdc.2018.06.011
   Zhou Z, 2020, NEURAL COMPUT APPL, V32, P1531, DOI 10.1007/s00521-019-04119-7
NR 103
TC 4
Z9 4
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26779
EP 26801
DI 10.1007/s11042-021-11011-x
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000652455300001
DA 2024-07-18
ER

PT J
AU Wang, HQ
   He, SJ
   Liu, T
   Pang, Y
   Lin, JZ
   Liu, QH
   Han, KN
   Wang, JC
   Jeon, G
AF Wang, Huiqian
   He, Sijia
   Liu, Ting
   Pang, Yu
   Lin, Jinzhao
   Liu, Qinghui
   Han, Kaining
   Wang, Junchao
   Jeon, Gwanggil
TI QRS detection of ECG signal using U-Net and DBSCAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QRS detection; QRS complex; ECG signal; U-Net; CNN
ID R-PEAKS; COMPLEX DETECTION; CLASSIFICATION
AB QRS detection is a crucial task for ECG signal analysis, which is the preliminary and essential step to further recognition and diagnosis. This paper proposes a U-Net based method for QRS detection. The method consists of three steps including preprocessing, U-Net model, and density-based spatial clustering of applications with noise(DBSCAN). The normalization is carried out using the Z-score method in preprocessing. In this study, location prediction is conducted by the U-Net model. Subsequently, the U-Net outputs are thresholded and clustered by DBSCAN. Finally, the middle points of the cluster are regards as the R-peak of the QRS complex. We demonstrate that the proposed method achieving high accuracy on ECG signals from the MIT-BIH Arrhythmia Database(MITDB). The experimental results show an average sensitivity of 99.98 %, positive predictivity of 99.95 %, accuracy of 99.93 %, and F1-score of 99.97 %. Compared with other existing methods, the overall performance is comparable and even better in terms of accuracy and F1-score.
C1 [Wang, Huiqian; He, Sijia; Liu, Ting; Pang, Yu; Lin, Jinzhao; Liu, Qinghui] Chongqing Univ Posts & Telecommun, Chongqing 400065, Peoples R China.
   [Han, Kaining; Wang, Junchao] Shantou Univ, Shantou 515063, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
C3 Chongqing University of Posts & Telecommunications; Shantou University;
   Incheon National University
RP Wang, JC (corresponding author), Shantou Univ, Shantou 515063, Peoples R China.; Jeon, G (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
EM wanghq@cqupt.edu.cn; 386200128@qq.com; tliu@cqupt.edu.cn;
   pangyu@cqupt.edu.cn; linjz@cqupt.edu.cn; ql67@nau.edu; knhan@stu.edu.cn;
   junchaowang@stu.edu.cn; gjeon@inu.ac.kr
RI wang, yi/JYO-8193-2024; He, Sijia/KVY-5878-2024
FU Wenfeng Innovation Foundation of CQUPT; University Innovation Team
   Construction Plan Funding Project of Chongqing (Smart Medical System and
   Key Techniques); Chongqing Key Laboratory Improvement Plan (Chongqing
   Key Laboratory of Photoelectronic Information Sensing and Transmitting
   Technology); National Natural Science Foundation of China [62001276,
   61971079]; Guangdong Basic and Applied Basic Research Fundation
   [2019A1515110560]; Chongqing Research Program of Basic Research and
   Frontier Technology [cstc2017jcyjAX0328]; Science and Technology
   Research Program of Chongqing Municipal Education Commission
   [KJQN201800614, KJQN201800643, KJQN202000604]; Regional Creative
   Cooperation Program of Sichuan [2020YFQ0025]; Innovation Group of
   Chongqing [cstc2020jcyj-cxttX0002]; Scientific Research Foundation of
   CQUPT [A2016-73]
FX This work is supported by Wenfeng Innovation Foundation of CQUPT,
   University Innovation Team Construction Plan Funding Project of
   Chongqing (Smart Medical System and Key Techniques), Chongqing Key
   Laboratory Improvement Plan (Chongqing Key Laboratory of Photoelectronic
   Information Sensing and Transmitting Technology), National Natural
   Science Foundation of China (62001276, 61971079), Guangdong Basic and
   Applied Basic Research Fundation (2019A1515110560), Chongqing Research
   Program of Basic Research and Frontier Technology
   (cstc2017jcyjAX0328),the Science and Technology Research Program of
   Chongqing Municipal Education Commission (KJQN201800614, KJQN201800643,
   KJQN202000604), the Regional Creative Cooperation Program of Sichuan
   (2020YFQ0025), the Innovation Group of Chongqing
   (cstc2020jcyj-cxttX0002), the Scientific Research Foundation of
   CQUPT(A2016-73).
CR Arzeno NM, 2008, IEEE T BIO-MED ENG, V55, P478, DOI 10.1109/TBME.2007.912658
   Benitez DS, 2000, COMPUT CARDIOL, V27, P379, DOI 10.1109/CIC.2000.898536
   Cai WJ, 2020, IEEE ACCESS, V8, P97082, DOI 10.1109/ACCESS.2020.2997473
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Farashi S, 2016, BIOMED SIGNAL PROCES, V24, P63, DOI 10.1016/j.bspc.2015.09.008
   Faster R, 2019, 2019 COMP CARD CINC, P4, DOI [10.23919/CinC49843.2019.9005798, DOI 10.23919/CINC49843.2019.9005798]
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hamdi S, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0322-2
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Jia MH, 2020, IEEE ACCESS, V8, P16979, DOI 10.1109/ACCESS.2020.2967775
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Labati RD, 2019, PATTERN RECOGN LETT, V126, P78, DOI 10.1016/j.patrec.2018.03.028
   Lee JS, 2019, EXPERT SYST APPL, V134, P66, DOI 10.1016/j.eswa.2019.05.033
   Manikandan MS, 2012, BIOMED SIGNAL PROCES, V7, P118, DOI 10.1016/j.bspc.2011.03.004
   Merah M, 2015, COMPUT METH PROG BIO, V121, P149, DOI 10.1016/j.cmpb.2015.06.003
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Nakai Y, 2014, IEEE ENG MED BIO, P34, DOI 10.1109/EMBC.2014.6943522
   Nayak C, 2019, BIOMED SIGNAL PROCES, V49, P440, DOI 10.1016/j.bspc.2018.09.005
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Peimankar A, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113911
   Phukpattaranont P, 2015, EXPERT SYST APPL, V42, P4867, DOI 10.1016/j.eswa.2015.02.012
   Qin Q, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/5980541
   Rakshit M, 2017, BIOCYBERN BIOMED ENG, V37, P566, DOI 10.1016/j.bbe.2017.02.002
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarlija M, 2017, INT SYMP IMAGE SIG, P121, DOI 10.1109/ISPA.2017.8073581
   Sharma T, 2017, COMPUT BIOL MED, V87, P187, DOI 10.1016/j.compbiomed.2017.05.027
   Wang XJ, 2019, I C COMM SOFTW NET, P73, DOI [10.1109/iccsn.2019.8905308, 10.1109/ICCSN.2019.8905308]
   Xiang YD, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0441-4
   Xu XM, 2004, P ANN INT IEEE EMBS, V26, P3597
   Zhou YC, 2016, PHYSIOL MEAS, V37, P2093, DOI 10.1088/0967-3334/37/12/2093
NR 31
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13319
EP 13333
DI 10.1007/s11042-021-10994-x
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000650124400002
DA 2024-07-18
ER

PT J
AU Lou, M
   Wang, RZ
   Qi, YL
   Zhao, WW
   Xu, CB
   Meng, J
   Deng, XY
   Ma, YD
AF Lou, Meng
   Wang, Runze
   Qi, Yunliang
   Zhao, Wenwei
   Xu, Chunbo
   Meng, Jie
   Deng, Xiangyu
   Ma, Yide
TI MGBN: Convolutional neural networks for automated benign and malignant
   breast masses classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammograms; Mass classification; Convolutional neural networks;
   Branch-attention module
ID SEGMENTATION; DIAGNOSIS
AB Automated benign and malignant breast masses classification is a crucial yet challenging topic. Recently, many studies based on convolutional neural network (CNN) are presented to address this task, but most of these CNN-based methods neglect the effective global contextual information. Moreover, their methods do not further analyze the reliability and interpretability of CNN models, which does not correspond to the clinical diagnosis. In this work, we firstly propose a novel multi-level global-guided branch-attention network (MGBN) for mass classification, which aims to fully leverage the multi-level global contextual information to refine the feature representation. Specifically, the MGBN includes a stem module and a branch module. The former extracts the local information through standard local convolutional operations of ResNet-50. The latter embeds the global contextual information and establishes the relationships of different feature levels via global pooling and Multi-layer Perceptron (MLP). The final prediction is computed by local information and global information together. Then, we discuss the reliability and interpretability of our mass classification network by visualizing the coarse localization map through Gradient-weighted Class Activation Mapping (Grad-CAM), which is important in clinical diagnosis. Finally, our proposed MGBN is greatly demonstrated on two public mammographic mass classification databases including the DDSM and INbreast databases, resulting in AUC of 0.8375 and 0.9311, respectively.
C1 [Lou, Meng; Qi, Yunliang; Zhao, Wenwei; Xu, Chunbo; Meng, Jie; Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
   [Wang, Runze] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai, Peoples R China.
   [Deng, Xiangyu] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou, Gansu, Peoples R China.
C3 Lanzhou University; Shanghai Jiao Tong University; Northwest Normal
   University - China
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
EM ydma@lzu.edu.cn
RI Wang, Runze/HTN-5131-2023; Lou, Meng/JYX-3663-2024
OI Wang, Runze/0000-0002-5429-2163; Lou, Meng/0000-0001-5409-0281
FU National Natural Science Foundation of China [61961037]; Natural Science
   Foundation of Gansu Province [18JR3RA288]; Fundamental Research Funds
   for the Central Universities [lzuxxxy-2019-tm23]
FX We would like to thank the Breast Research Group, INESC Porto, Portugal
   for the INbreast database. This work is jointly supported by the
   National Natural Science Foundation of China (Nos.61961037), Natural
   Science Foundation of Gansu Province (Nos.18JR3RA288), and the
   Fundamental Research Funds for the Central Universities
   (Nos.lzuxxxy-2019-tm23).
CR Amrane M., 2018, 2018 ELECT ELECT COM, P1, DOI DOI 10.1109/EBBT.2018.8391453
   Angra S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS AND COMPUTATIONAL INTELLIGENCE (ICBDAC), P57, DOI 10.1109/ICBDACI.2017.8070809
   Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523
   Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeSantis CE, 2019, CA-CANCER J CLIN, V69, P438, DOI 10.3322/caac.21583
   Dhungel Neeraj, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P106, DOI 10.1007/978-3-319-46723-8_13
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu Y, 2020, MED PHYS, V47, P4895, DOI 10.1002/mp.14397
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Giger ML, 2013, ANNU REV BIOMED ENG, V15, P327, DOI 10.1146/annurev-bioeng-071812-152416
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidari M, 2020, IEEE T MED IMAGING, V39, P1235, DOI 10.1109/TMI.2019.2946490
   Henriksen EL, 2019, ACTA RADIOL, V60, P13, DOI 10.1177/0284185118770917
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang QH, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/5137904
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Izonin I, 2019, LECT NOTES COMPUT SC, V11506, P467, DOI 10.1007/978-3-030-20521-8_39
   Jemal A, 2010, CA-CANCER J CLIN, V60, P277, DOI 10.3322/caac.20073
   Khan HN, 2019, IEEE ACCESS, V7, P165724, DOI 10.1109/ACCESS.2019.2953318
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Lehman CD, 2017, RADIOLOGY, V283, P49, DOI 10.1148/radiol.2016161174
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mnih V, 2014, ADV NEUR IN, V27
   Monshi MMA, 2020, ARTIF INTELL MED, V106, DOI 10.1016/j.artmed.2020.101878
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Pang T, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113501
   Park J., 2018, BRIT MACH VIS C, P147
   Paszke A, 2019, ADV NEUR IN, V32
   Perek S, 2019, LECT NOTES COMPUT SC, V11769, P712, DOI 10.1007/978-3-030-32226-7_79
   Qi YL, 2021, MULTIMED TOOLS APPL, V80, P2821, DOI 10.1007/s11042-020-09796-4
   Rampun A., 2018, 2018 IEEE 20 INT C E, P1
   Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shams S, 2018, LECT NOTES COMPUT SC, V11071, P859, DOI 10.1007/978-3-030-00934-2_95
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Talo M, 2019, ARTIF INTELL MED, V101, DOI 10.1016/j.artmed.2019.101743
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P112, DOI 10.1007/978-3-319-91008-6_12
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P578, DOI 10.1007/978-3-319-91008-6_58
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang HY, 2018, PATTERN RECOGN, V80, P42, DOI 10.1016/j.patcog.2018.02.026
   Wang N, 2018, LECT NOTES COMPUT SC, V11073, P641, DOI 10.1007/978-3-030-00937-3_73
   Wang RZ, 2019, NEUROCOMPUTING, V363, P313, DOI 10.1016/j.neucom.2019.06.045
   Waring J, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101822
   Wei CH, 2012, COMPUT METH PROG BIO, V106, P234, DOI 10.1016/j.cmpb.2010.09.002
   Wentao Zhu, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P603, DOI 10.1007/978-3-319-66179-7_69
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie WY, 2016, NEUROCOMPUTING, V173, P930, DOI 10.1016/j.neucom.2015.08.048
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Yassin NIR, 2018, COMPUT METH PROG BIO, V156, P25, DOI 10.1016/j.cmpb.2017.12.012
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang FD, 2019, PROC CVPR IEEE, P12570, DOI 10.1109/CVPR.2019.01286
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 70
TC 11
Z9 11
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26731
EP 26750
DI 10.1007/s11042-021-10929-6
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648376700005
DA 2024-07-18
ER

PT J
AU Mallahi, ME
   Boukili, B
   Zouhri, A
   Hmamed, A
   Qjidaa, H
AF Mallahi, Mostafa El
   Boukili, Bensalem
   Zouhri, Amal
   Hmamed, Abdelaziz
   Qjidaa, Hassan
TI Robust <i>H</i><sub>∞</sub> deconvolution filtering of 2-D digital
   systems of orthogonal local descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deconvolution filtering; 2-D systems; H-infinity performance index;
   Linear Matrix Inequality (LMI); Orthogonal polynomial; Local descriptor;
   Color image reconstruction
AB In this work, we propose a new set of H-infinity deconvolution filtering of 2-D color image using feature extraction of local descriptor and Fornasini-Machesini II (FM-II) model. The principal goal is to design 2-D deconvolution filter to reconstruct the noisy color image with the minimal information extracted from local Krawtchouk moment, Moreover, the filtering error system is asymptotically stable and satisfy the H-infinity performance index. the sufficient condition is given to ensure the H-infinity performance of the filtering error system through the Lyapunov theory, and the local Krawtckouk moment to give the feature extraction according to the order defined in advance instead of the global color image. Moreover, the 2-D deconvolution filter is designed to achieve the H-infinity performance index which the filter parameters are determined with certain optimization resolution. Finally, simulation example is provided to demonstrate the usefulness of the proposed design methods.
C1 [Mallahi, Mostafa El] Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Dept Math & Comp Sci, Lab Comp Sci & Interdisciplinary Phys, Fes, Morocco.
   [Boukili, Bensalem; Zouhri, Amal; Hmamed, Abdelaziz; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Dept Phys, Comp Sci Signals Automat & Cognitivism Lab, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Mallahi, ME (corresponding author), Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Dept Math & Comp Sci, Lab Comp Sci & Interdisciplinary Phys, Fes, Morocco.
EM mostafa.elmallahi@usmba.ac.ma; b_boukili@yahoo.fr;
   Amal.zouhri@usmba.ac.ma; hammed_abdelaziz@yahoo.fr;
   hassan.qjidaa@usmba.ac.ma
RI ZOUHRI, Amal/AAA-4511-2022; BOUKILI, Bensalem/AAS-7075-2020
OI BOUKILI, Bensalem/0000-0002-9345-177X; El Mallahi,
   Mostafa/0000-0001-9735-6799
CR Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Amakdouf H, 2020, MULTIMED TOOLS APPL, V79, P26571, DOI 10.1007/s11042-020-09120-0
   Benzaouia A, 2019, CIRC SYST SIGNAL PR, V38, P4504, DOI 10.1007/s00034-019-01082-5
   Boukili B, 2016, J CONTROL AUTOM ELEC, V27, P597, DOI 10.1007/s40313-016-0271-1
   Boukili B, 2016, J CONTROL AUTOM ELEC, V27, P497, DOI 10.1007/s40313-016-0251-5
   Boukili B, 2014, CIRC SYST SIGNAL PR, V33, P1737, DOI 10.1007/s00034-013-9720-2
   CHEN BS, 1991, SIGNAL PROCESS, V25, P361, DOI 10.1016/0165-1684(91)90120-8
   Chen SF, 2006, IEEE T SIGNAL PROCES, V54, P274, DOI 10.1109/TSP.2005.861055
   CHUCU L, 1994, AUTOMATICA, V30, P1197
   Cui Jia-Rui, 2010, Acta Automatica Sinica, V36, P755, DOI 10.3724/SP.J.1004.2010.00755
   Dami L, 2020, MULTIDIM SYST SIGN P, V31, P673, DOI 10.1007/s11045-019-00681-4
   Ding DW, 2015, IEEE T AUTOMAT CONTR, V60, P1624, DOI 10.1109/TAC.2014.2359305
   Du CL, 2000, IEEE T SIGNAL PROCES, V48, P1760, DOI 10.1109/78.845933
   El Mallahi M., 2017, Pattern Recognition and Image Analysis, V27, P810
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   El-Amrani A, 2018, INT J SYST SCI, V49, P43, DOI 10.1080/00207721.2017.1391960
   Gao HJ, 2005, OPTIM CONTR APPL MET, V26, P199, DOI 10.1002/oca.760
   Kaczorek T, 2009, MULTIDIM SYST SIGN P, V20, P39, DOI 10.1007/s11045-008-0050-7
   Kririm S, 2015, CIRC SYST SIGNAL PR, V34, P2213, DOI 10.1007/s00034-015-9967-x
   Lacerda MJ, 2011, SIGNAL PROCESS, V91, P1115, DOI 10.1016/j.sigpro.2010.10.013
   Mesbah A., 2017, ROBUST RECONSTRUCTIO, V18, DOI [10.1007/s13319-016-0113-8, DOI 10.1007/S13319-016-0113-8]
   Nathan, 1966, 32877 JET PROP LAB
   Rajan S, 1996, CIRC SYST SIGNAL PR, V15, P395, DOI 10.1007/BF01182594
   SOUZA CE, 2010, AUTOMATICA, V46, P673
   Wei G, 2007, CIRC SYST SIGNAL PR, V26, P495, DOI 10.1007/s00034-007-4004-x
   Wu LG, 2008, AUTOMATICA, V44, P1849, DOI 10.1016/j.automatica.2007.10.027
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Xiao B, 2012, J VIS COMMUN IMAGE R, V23, P381, DOI 10.1016/j.jvcir.2011.11.008
   Xie LH, 2000, SIGNAL PROCESS, V80, P2365, DOI 10.1016/S0165-1684(00)00123-7
   Xie LH, 2002, IEEE T SIGNAL PROCES, V50, P2319, DOI 10.1109/TSP.2002.800401
   Xu SY, 2005, IEEE T SIGNAL PROCES, V53, P1731, DOI 10.1109/TSP.2005.845464
   Zhang BY, 2009, SIGNAL PROCESS, V89, P605, DOI 10.1016/j.sigpro.2008.10.008
   Zouhri A, 2020, PATTERN RECOGN IMAGE, V30, P87, DOI 10.1134/S1054661820010186
NR 35
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25965
EP 25983
DI 10.1007/s11042-021-10845-9
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643591900001
DA 2024-07-18
ER

PT J
AU Belkadi, MA
   Daamouche, A
AF Belkadi, Mohamed Amine
   Daamouche, Abdelhamid
TI A robust QRS detection approach using stationary wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QRS detection; Noisy environment; ECG signal analysis; Scale analysis;
   Stationary wavelet transform (SWT); First level approximation
   coefficients; Pan-Tompkins thresholding
AB Accurate QRS detection is crucial for reliable ECG signal analysis and the development of automatic diagnosis tools. In this paper, we propose a simple yet efficient new algorithm for QRS detection using the Stationary Wavelet Transform (SWT). The wavelet transform has been extensively exploited for QRS detection and proved to be an efficient mathematical tool for scale analysis; it provides good frequency components estimation for the input signal and has good localization capability. The proposed procedure exploits solely the first level approximation coefficients of the wavelet transform applied to the bandpass-filtered ECG signal. Therefore, it resulted in a reduced complexity algorithm compared to the existing methods which use many decomposition levels. Thresholding has been implemented using the Pan-Tompkins procedure which is known to be very powerful. Our approach has been assessed over the MIT/BIH benchmark database, the MIT noise stress test database for noise robustness evaluation and the European ST-T database. The obtained results show competitive performance with state-of-the-art algorithms. The proposed scheme achieved a sensitivity of 99.83%, a positive predictivity of 99.94% and a detection error rate of 0.228% using Lead I MIT-BIH Database, this performance is one of the best results over this benchmark, and 99.35% of sensitivity, 99.76% of positive predictivity and detection error rate of 0.9% using the European ST-T Database, hence, our algorithm achieved high performance on Holter environment. Using the MIT noise stress test database, our algorithm achieved 98.77% of sensitivity, 91.01% of positive predictivity, and 10.12% of DER. Thus, our algorithm is robust and outperforms state-of-the-art algorithms on noisy recordings.
C1 [Belkadi, Mohamed Amine; Daamouche, Abdelhamid] Univ MHamed Bougara, Inst Elect & Elect Engn, Lab Signals & Syst, Boumerdes, Algeria.
C3 Universite de M'hammed Bougara Boumerdes
RP Daamouche, A (corresponding author), Univ MHamed Bougara, Inst Elect & Elect Engn, Lab Signals & Syst, Boumerdes, Algeria.
EM ma.belkadi@univ-boumerdes.dz; adaamouche@univ-boumerdes.dz
RI Daamouche, Abdelhamid/AAJ-4478-2020
OI Daamouche, Abdelhamid/0000-0002-8085-879X
FU Directorate General for Scientific Research and Technological
   Development (DG-RSDT), Algeria
FX The authors would like to acknowledge the support of the Directorate
   General for Scientific Research and Technological Development (DG-RSDT),
   Algeria.
CR Arzeno NM, 2008, IEEE T BIO-MED ENG, V55, P478, DOI 10.1109/TBME.2007.912658
   Belkadi M, 2020, INT ARAB J INF TECHN, V17, P480, DOI 10.34028/iajit/17/4/6
   Belkadi MA, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING - BOUMERDES (ICEE-B)
   Benmalek M, 2009, IET SIGNAL PROCESS, V3, P381, DOI 10.1049/iet-spr.2008.0094
   Bouaziz F, 2014, IET SIGNAL PROCESS, V8, P774, DOI 10.1049/iet-spr.2013.0391
   Choi S, 2010, EXPERT SYST APPL, V37, P5208, DOI 10.1016/j.eswa.2009.12.069
   Chouakri SA, 2011, APPL MATH COMPUT, V217, P9508, DOI 10.1016/j.amc.2011.03.001
   Christov II, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-28
   Dass S., 2013, IJERT, V2, P636
   Elgendi M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073557
   Ghailan K., 2012, INT J COMPUTER SCI I, V9, P205
   Gutiérrez-Rivas R, 2015, IEEE SENS J, V15, P6036, DOI 10.1109/JSEN.2015.2450773
   HAMILTON PS, 1986, IEEE T BIO-MED ENG, V33, P1157, DOI 10.1109/TBME.1986.325695
   Kadambe S, 1999, IEEE T BIO-MED ENG, V46, P838, DOI 10.1109/10.771194
   Kiymik MK, 2005, COMPUT BIOL MED, V35, P603, DOI 10.1016/j.compbiomed.2004.05.001
   LI CW, 1995, IEEE T BIO-MED ENG, V42, P21, DOI 10.1109/10.362922
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manikandan MS, 2014, HEALTHC TECHNOL LETT, V1, P40, DOI 10.1049/htl.2013.0019
   Merah M, 2015, COMPUT METH PROG BIO, V121, P149, DOI 10.1016/j.cmpb.2015.06.003
   Nason GP, 1995, STATISTICS NY
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Shivappriya S. N., 2006, ADCOM 2006: Autonomic Computing Fourteenth International Conference on Advanced Computing and Communications, P271
   Suárez KV, 2007, IEEE T BIO-MED ENG, V54, P641, DOI 10.1109/TBME.2006.889944
   Yoon UJ, 2010, INT C WAVEL ANAL PAT, P300, DOI 10.1109/ICWAPR.2010.5576361
   Zhang CF, 2012, IEEE J EM SEL TOP C, V2, P52, DOI 10.1109/JETCAS.2012.2187706
NR 25
TC 10
Z9 10
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22843
EP 22864
DI 10.1007/s11042-020-10500-9
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000639743500002
DA 2024-07-18
ER

PT J
AU Cohen-Kalaf, M
   Lanir, J
   Bak, P
   Mokryn, O
AF Cohen-Kalaf, Miki
   Lanir, Joel
   Bak, Peter
   Mokryn, Osnat
TI Movie emotion map: an interactive tool for exploring movies according to
   their emotional signature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotions; Plutchik&#8217; s wheel of emotion; Glyphs; Dimension
   reduction
ID VISUALIZATION; INFORMATION; SENTIMENTS
AB We present Movie Emotion Map - a novel system that enables to view and browse through a large collection of movies according to the movies' emotional characteristics. The system enables to view both the high-level structure of the movies emotional space and the low-level details of a single movie. We create an eight-dimensional emotional signature for each movie based on Plutchik's theory of emotions, according to its reviews obtained from IMDb. We projected glyphs representing emotional signatures of the movies on a 2D plane using dimension reduction, thus, providing a topology of emotions for easy browsing and exploring. Results from a qualitative evaluation with 18 participants indicate that users could easily browse through movies according to the visualized landscape and that the tool enabled them to search, filter and find movies based on their emotional characteristics.
C1 [Cohen-Kalaf, Miki; Lanir, Joel; Mokryn, Osnat] Univ Haifa, Haifa, Israel.
   [Bak, Peter] K Hlth Res & Dev, Tel Aviv, Israel.
C3 University of Haifa
RP Lanir, J (corresponding author), Univ Haifa, Haifa, Israel.
EM mikcohen@gmail.com; ylanir@is.haifa.ac.il; peter.bak@khealth.ai;
   ossimo@gmail.com
OI Mokryn, Osnat/0000-0002-1241-9015; Lanir, Joel/0000-0002-9838-5142
CR Abras C., 2004, Encyclopedia of Human-Computer Interaction, P445, DOI [10.3233/WOR-2010-1109, DOI 10.3233/WOR-2010-1109]
   Ahlberg C, 1994, C HUMAN FACTORS COMP, P433, DOI [10.1145/259963.260431, DOI 10.1145/259963.260431]
   Albo Y, 2016, IEEE T VIS COMPUT GR, V22, P569, DOI 10.1109/TVCG.2015.2467322
   Andjelkovic I, 2019, INT J HUM-COMPUT ST, V121, P142, DOI 10.1016/j.ijhcs.2018.04.004
   [Anonymous], 2000, Information Visualization: Perception for Design
   Aurier P, 2015, INT J ARTS MANAG, V17, P5
   Bader N., 2017, Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion, P35
   Chambel T., 2013, International Journal of Advanced Media and Communication, V5, P58
   Chen Y-X., 2010, THESIS CITESEER
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fodor I. K, 2002, SURVEY DIMENSION RED
   Fortuna B., 2005, Informatica, V29
   Gil N., 2012, Proceeding of the 16th International Academic MindTrek Conference, P158, DOI DOI 10.1145/2393132.2393163
   Glisczinski D, 2018, J TRANSFORM EDUC, V16, P175, DOI 10.1177/1541344618777367
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Jorge Ana, 2014, International Journal of Creative Interfaces and Computer Graphics, V5, P40, DOI 10.4018/ijcicg.2014070103
   Kempter R, 2014, 8 INT AAAI C WEBL SO
   Kennedy Alistair, 2012, Advances in Artificial Intelligence. Proceedings 25th Canadian Conference on Artificial Intelligence, Canadian AI 2012, P121, DOI 10.1007/978-3-642-30353-1_11
   Kleiman Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P995, DOI 10.1145/2702123.2702224
   Kucher K, 2018, COMPUT GRAPH FORUM, V37, P71, DOI 10.1111/cgf.13217
   Martinho J., 2009, Proceedings of the 13th International MindTrek Conference: Everyday Life in the Ubiquitous Era, P190
   Mohammad S., 2011, P 5 ACL HLT WORKSH L, P105
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Mokryn O, 2020, INFORM RETRIEVAL J, V23, P475, DOI 10.1007/s10791-020-09373-1
   Munezero M, 2015, LECT NOTES COMPUT SC, V9042, P78, DOI 10.1007/978-3-319-18117-2_6
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   NELSON P, 1970, J POLIT ECON, V78, P311, DOI 10.1086/259630
   Pavel A, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P181, DOI 10.1145/2807442.2807502
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Plutchik R., 1980, EMOTION THEORY RES E, V1, P3, DOI DOI 10.1016/B978-0-12-558701-3.50007-7
   Qian YF, 2019, INFORM FUSION, V46, P141, DOI 10.1016/j.inffus.2018.06.004
   Ray RD, 2007, HDB EMOTION ELICITAT, V9
   Roberts K, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3806
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   Tan E.S., 2013, EMOTION STRUCTURE NA
   Tanin E, 2007, INFORM SYST, V32, P402, DOI 10.1016/j.is.2005.12.006
   Tkalcic Marko., 2011, Proc. The RecSys 2011 Workshop on Human Decision Making in Recommender Systems, P9
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Van Someren MW, 1994, AcademicPress
   Wang FY, 2015, IEEE PAC VIS SYMP, P129, DOI 10.1109/PACIFICVIS.2015.7156368
   Yu Y, 2015, COMPUT HUM BEHAV, V48, P392, DOI 10.1016/j.chb.2015.01.075
   Zhang SL, 2009, IEEE IMAGE PROC, P1853, DOI 10.1109/ICIP.2009.5413590
   Zhao J, 2014, IEEE CONF VIS ANAL, P203, DOI 10.1109/VAST.2014.7042496
   Zheng Y., 2013, Decis. RecSys, P21
NR 45
TC 6
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14663
EP 14684
DI 10.1007/s11042-021-10803-5
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000639518700005
DA 2024-07-18
ER

PT J
AU Zhang, HW
   Kong, XW
   Zhang, YJ
AF Zhang, Hongwei
   Kong, Xiangwei
   Zhang, Yujia
TI Enhanced knowledge transfer for collaborative filtering with
   multi-source heterogeneous feedbacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Collaborative filtering; Sparsity; Heterogeneous
   feedbacks
ID RECOMMENDER SYSTEMS; FACTORIZATION
AB Collaborative filtering (CF) is a widely used method in recommender systems due to its simplicity and efficiency. But most existing CF methods suffer from data scarcity, which arises from the situation with only a limited number of interactions between users and items. One solution to address is how to introduce Transfer Learning (TL)-based CF methods with heterogeneous feedbacks to deal with multi-source and heterogeneous data, such as rating vs. clicks or rating vs. purchase. However, in some applications, extremely sparse (i.e., sparsity level <= 0.1%) target data could cause under-transfer and negative transfer. To address the above issue, we propose an Enhanced Knowledge Transfer for Collaborative Filtering with Multi-Source Heterogeneous Feedbacks (EKT). Specifically, we first propose a weighted collective matrix tri-factorization framework. The proposed framework constrains the auxiliary data and the target data to share the same latent factors of users and items as well as partial cluster-level user-item rating pattern in order to enhance knowledge transfer and alleviate the under-transfer issue. Then, to alleviate the negative transfer issue, we integrate the graph co-regularization terms into a proposed framework, which contains the neighborhood structure information of users and items. At last, we simultaneously minimize the objective function of EKT, which consists of weighted collective matrix tri-factorization and the graph co-regularization of user and item graphs. Since the EKT framework is a non-convex optimization problem, we use an alternating optimization procedure to solve it and further prove its convergence. The experimental results on two benchmark datasets show that our proposed EKT method performs better than other baseline methods at almost all sparsity levels except for the denser case of 1% on ML10M and Netflix.
C1 [Zhang, Hongwei] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
   [Zhang, Hongwei] Tonghua Normal Univ, Sch Math, Tonghua 134002, Peoples R China.
   [Kong, Xiangwei] Zhejiang Univ, Dept Data Sci & Engn Management, Hangzhou 310058, Peoples R China.
   [Zhang, Yujia] Univ Penn, Sch Engn & Appl Sci, Philadelphia, PA 19104 USA.
C3 Dalian University of Technology; Tonghua Normal University; Zhejiang
   University; University of Pennsylvania
RP Kong, XW (corresponding author), Zhejiang Univ, Dept Data Sci & Engn Management, Hangzhou 310058, Peoples R China.; Kong, XW (corresponding author), Univ Penn, Sch Engn & Appl Sci, Philadelphia, PA 19104 USA.
EM hwzhang82@mail.dlut.edu.cn; kongxiangwei@zju.edu.cn;
   yjzhang7@seas.upenn.edu
RI Kong, Xiangwei/IWL-9350-2023
FU Foundation for Innovative Research Groups of the National Natural
   Science Foundation of China [71421001]; National Natural Science
   Foundation of China [61772111]
FX This work was supported in part by the Foundation for Innovative
   Research Groups of the National Natural Science Foundation of China
   (71421001), and in part by the National Natural Science Foundation of
   China (61772111).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bell RM, 2007, IEEE DATA MINING, P43, DOI 10.1109/ICDM.2007.90
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cai D, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1010
   Chen G, 2009, INFORM PROCESS MANAG, V45, P368, DOI 10.1016/j.ipm.2008.12.004
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Gu Q., 2010, P SIAM INT C DAT MIN, P199, DOI 10.1137/1.9781611972801.18
   Hao P, 2019, IEEE T CYBERNETICS, V49, P83, DOI 10.1109/TCYB.2017.2764918
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hernando A, 2016, KNOWL-BASED SYST, V97, P188, DOI 10.1016/j.knosys.2015.12.018
   Hu GN, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P667, DOI 10.1145/3269206.3271684
   Jiangfeng Shi, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference, PAKDD 2013. Proceedings, P496, DOI 10.1007/978-3-642-37453-1_41
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454
   Li B, 2015, IEEE T CYBERNETICS, V45, P1054, DOI 10.1109/TCYB.2014.2343982
   Li B, 2011, PROC INT C TOOLS ART, P1085, DOI 10.1109/ICTAI.2011.184
   Li B, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2052
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1805, DOI 10.1109/TKDE.2013.97
   Lu Z., 2012, P 2013 SIAM INT C DA, P641
   Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI [DOI 10.1145/1458082.1458205, 10.1145/1458082.1458205]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan WK, 2016, NEUROCOMPUTING, V177, P447, DOI 10.1016/j.neucom.2015.11.059
   Pan WK, 2016, INFORM SCIENCES, V332, P84, DOI 10.1016/j.ins.2015.10.044
   Pan WK, 2014, IEEE INTELL SYST, V29, P48, DOI 10.1109/MIS.2014.2
   Pan WK, 2013, ARTIF INTELL, V197, P39, DOI 10.1016/j.artint.2013.01.003
   Pan WK, 2010, AAAI CONF ARTIF INTE, P230
   Pan Weike, 2011, P 22 INT JOINT C ART, P2318
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Sheng Gao, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P161, DOI 10.1007/978-3-642-40991-2_11
   Sindhwani V, 2009, P 3 ACM C REC SYST R
   Singh A, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P650
   Smith B, 2017, IEEE INTERNET COMPUT, V21, P12, DOI 10.1109/MIC.2017.72
   Srebro N., 2005, ADV NEURAL INFORM PR, P1329
   Wu LB, 2019, IEEE SENS J, V19, P47, DOI 10.1109/JSEN.2018.2875659
   Yang B, 2017, IEEE T PATTERN ANAL, V39, P1633, DOI 10.1109/TPAMI.2016.2605085
   Zhang HD, 2018, IEEE T SYST MAN CY-S, V48, P177, DOI 10.1109/TSMC.2016.2599705
   Zhang MY, 2016, DECIS SUPPORT SYST, V83, P10, DOI 10.1016/j.dss.2015.12.004
   Zhang Q, 2019, IEEE T NEUR NET LEAR, V30, P1998, DOI 10.1109/TNNLS.2018.2875144
   Zhang Q, 2017, DECIS SUPPORT SYST, V104, P49, DOI 10.1016/j.dss.2017.10.002
   Zhang S, 2006, SIAM PROC S, P549
   Zhao LL, 2017, ARTIF INTELL, V245, P38, DOI 10.1016/j.artint.2016.12.004
NR 46
TC 2
Z9 2
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24245
EP 24270
DI 10.1007/s11042-021-10834-y
EA APR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636427800003
DA 2024-07-18
ER

PT J
AU Marvasti-Zadeh, SM
   Ghanei-Yakhdan, H
   Kasaei, S
AF Marvasti-Zadeh, Seyed Mojtaba
   Ghanei-Yakhdan, Hossein
   Kasaei, Shohreh
TI Adaptive exploitation of pre-trained deep convolutional neural networks
   for robust visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discriminative correlation filters; Deep convolutional neural networks;
   Robust visual tracking
ID CORRELATION FILTERS; OBJECT TRACKING
AB Due to the automatic feature extraction procedure via multi-layer nonlinear transformations, the deep learning-based visual trackers have recently achieved a great success in challenging scenarios for visual tracking purposes. Although many of those trackers utilize the feature maps from pre-trained convolutional neural networks (CNNs), the effects of selecting different models and exploiting various combinations of their feature maps are still not compared completely. To the best of our knowledge, all those methods use a fixed number of convolutional feature maps without considering the scene attributes (e.g., occlusion, deformation, and fast motion) that might occur during tracking. As a pre-requisition, this paper proposes adaptive discriminative correlation filters (DCF) based on the methods that can exploit CNN models with different topologies. First, the paper provides a comprehensive analysis of four commonly used CNN models to determine the best feature maps of each model. Second, with the aid of analysis results as attribute dictionaries, an adaptive exploitation of deep features is proposed to improve the accuracy and robustness of visual trackers regarding video characteristics. Third, the generalization of proposed method is validated on various tracking datasets as well as CNN models with similar architectures. Finally, extensive experimental results demonstrate the effectiveness of proposed adaptive method compared with the state-of-the-art visual tracking methods.
C1 [Marvasti-Zadeh, Seyed Mojtaba; Ghanei-Yakhdan, Hossein] Yazd Univ, Dept Elect Engn, Digital Image & Video Proc Lab DIVPL, Yazd, Iran.
   [Marvasti-Zadeh, Seyed Mojtaba; Kasaei, Shohreh] Sharif Univ Technol, Image Proc Lab IPL, Dept Comp Engn, Tehran, Iran.
   [Marvasti-Zadeh, Seyed Mojtaba] Univ Alberta, Dept Elect & Comp Engn, Vis & Learning Lab, Edmonton, AB, Canada.
C3 University of Yazd; Sharif University of Technology; University of
   Alberta
RP Ghanei-Yakhdan, H (corresponding author), Yazd Univ, Dept Elect Engn, Digital Image & Video Proc Lab DIVPL, Yazd, Iran.
EM mojtaba.marvasti@ualberta.ca; hghaneiy@yazd.ac.ir; kasaei@sharif.edu
RI Ghanei-Yakhdan, Hossein/D-7382-2018; Marvasti-Zadeh, Seyed
   Mojtaba/H-7445-2017; Ghanei-Yakhdan, Hossein/JAC-4508-2023
OI Marvasti-Zadeh, Seyed Mojtaba/0000-0003-0536-0796; Ghanei-Yakhdan,
   Hosein/0000-0003-4575-1062
FU Iran National Science Foundation (INSF) [96013046]
FX This work was partly supported by a grant (No. 96013046) from Iran
   National Science Foundation (INSF).
CR [Anonymous], ARXIV160702568
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Chang Ming-Fang, 2019, CVPR
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Che MQ, 2019, LECT NOTES COMPUT SC, V11129, P70, DOI 10.1007/978-3-030-11009-3_3
   Chen J, 2018, IEEE T CIRCUITS SYST
   Chi ZZ, 2017, IEEE T IMAGE PROCESS, V26, P2005, DOI 10.1109/TIP.2017.2669880
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Du F, 2018, SIGNAL PROCESS-IMAGE, V67, P58, DOI 10.1016/j.image.2018.05.013
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, IEEE T IMAGE PROCESS, V28, P4130, DOI 10.1109/TIP.2019.2904789
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Gladh S, 2016, INT C PATT RECOG, P1243, DOI 10.1109/ICPR.2016.7899807
   Gu YY, 2019, INT CONF ACOUST SPEE, P2242, DOI 10.1109/ICASSP.2019.8683186
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZQ, 2017, IEEE INT CONF COMP V, P1992, DOI 10.1109/ICCVW.2017.233
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DD, 2019, J VIS COMMUN IMAGE R, V58, P149, DOI 10.1016/j.jvcir.2018.11.036
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li F, 2017, IEEE INT CONF COMP V, P2001, DOI 10.1109/ICCVW.2017.234
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin ZG, 2018, IEEE IMAGE PROC, P4103, DOI 10.1109/ICIP.2018.8451826
   Liu L., 2017, arXiv, P1, DOI DOI 10.7480/ABE.2017.17
   Liu M, 2018, IET IMAGE PROCESS, V12, P2023, DOI 10.1049/iet-ipr.2018.5454
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Marvasti-Zadeh S. M., 2020, P ACCV, P594, DOI DOI 10.1016/J.CVIU.2017.02.002
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Marvasti-Zadeh SM, 2019, IRAN CONF ELECTR ENG, P1272, DOI [10.1109/IranianCEE.2019.8786548, 10.1109/iraniancee.2019.8786548]
   Mozhdehi RJ, 2017, IEEE IMAGE PROC, P3650, DOI 10.1109/ICIP.2017.8296963
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Rout L, 2019, LECT NOTES COMPUT SC, V11129, P83, DOI 10.1007/978-3-030-11009-3_4
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shreyamsha Kumar BK, 2019, MULTIMED TOOLS APPL, V78, P7243, DOI 10.1007/s11042-018-6453-z
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058
   Sun YX, 2019, PROC CVPR IEEE, P5776, DOI 10.1109/CVPR.2019.00593
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang C., 2019, CVPR
   Tang FH, 2019, NEUROCOMPUTING, V333, P29, DOI 10.1016/j.neucom.2018.12.035
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q., 2017, arXiv preprint arXiv:1704.04057
   Wang XY, 2017, IEEE IMAGE PROC, P660, DOI 10.1109/ICIP.2017.8296363
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Yi Y, 2019, MULTIMED TOOLS APPL, V78, P12333, DOI 10.1007/s11042-018-6787-6
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 70
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22027
EP 22076
DI 10.1007/s11042-020-10382-x
EA MAR 2021
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631790800004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Japar, N
   Kok, VJ
   Chan, CS
AF Japar, Nurul
   Kok, Ven Jyn
   Chan, Chee Seng
TI Coherent group detection in still image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd analysis; Coherent group detection
AB Collective behaviors of coherent groups convey semantic relations among individuals in a crowd scene. Detecting coherent groups is primitive for crowd behavior analysis and practically useful in crowd surveillance. However, classically, crowd analysis in still image is focused on crowd counting estimation or crowd segmentation only. In this paper, we present a novel framework that merges these two classical approaches to achieve a higher level of crowd understanding, i.e., detecting coherent groups within a crowd in a still image. Essentially, in addition to crowd counting estimation, our work can infer crowd segments at both image-level and coherent group level. Extensive experiments and analysis of crowd scene images with a variety of crowd densities demonstrate the efficacy of the proposed framework. The proposed framework also shows its potential application, especially in crowd understanding.
C1 [Japar, Nurul; Chan, Chee Seng] Univ Malaya, Kuala Lumpur, Malaysia.
   [Kok, Ven Jyn] Natl Univ Malaysia, Bangi, Malaysia.
C3 Universiti Malaya; Universiti Kebangsaan Malaysia
RP Chan, CS (corresponding author), Univ Malaya, Kuala Lumpur, Malaysia.
EM nuruljapar@um.edu.my; vj.kok@ukm.edu.my; cs.chan@um.edu.my
RI Chan, Chee Seng/B-9754-2011; Japar, Nurul/HCH-0645-2022
OI Chan, Chee Seng/0000-0001-7677-2865; JAPAR, NURUL/0000-0002-3054-1874
FU National University of Malaysia (UKM) [FRGS/1/2019/ICT02/UKM/02/11]
FX This research is partially supported by FRGS/1/2019/ICT02/UKM/02/11
   grant, from the National University of Malaysia (UKM).
CR Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95
   Bon GustaveLe., 1897, CROWD STUDY POPULAR
   Cao JM, 2020, MULTIMED TOOLS APPL, V79, P2837, DOI 10.1007/s11042-019-08467-3
   Chen ML, 2017, INT CONF ACOUST SPEE, P1378, DOI 10.1109/ICASSP.2017.7952382
   Fernando Tharindu, 2018, ASIAN C COMPUTER VIS, P314
   Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Japar N., 2019, IEEE INT WORKSH MULT, P1
   Kok VJ, 2017, IEEE T CYBERNETICS, V47, P1157, DOI 10.1109/TCYB.2016.2538765
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lian DZ, 2019, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2019.00192
   Lim MK, 2014, INT C PATT RECOG, P3957, DOI 10.1109/ICPR.2014.678
   LIN W, 2016, IEEE I CONF COMP VIS, V25, P1674
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu M, 2018, IEEE IMAGE PROC, P953, DOI 10.1109/ICIP.2018.8451787
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   Muñoz-Salinas R, 2012, MACH VISION APPL, V23, P479, DOI 10.1007/s00138-012-0410-z
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Peng X, 2018, IEEE T NEUR NET LEAR, V29, P218, DOI 10.1109/TNNLS.2016.2608834
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shao J, 2017, IEEE T CIRC SYST VID, V27, P1290, DOI 10.1109/TCSVT.2016.2539878
   Shao T, 2015, INT CONF SYST SIGNAL, P77, DOI 10.1109/IWSSIP.2015.7314181
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Solera F, 2016, IEEE T PATTERN ANAL, V38, P995, DOI 10.1109/TPAMI.2015.2470658
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Stolley KathyS., 2005, BASICS SOCIOLOGY
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thida M., 2013, Intelligent multimedia surveillance, P17, DOI DOI 10.1007/978-3-642-41512-8_2
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang Q, 2017, AAAI CONF ARTIF INTE, P4292
   Wang Q, 2018, IEEE IPCCC
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wu YP, 2018, IEEE T MULTIMEDIA, V20, P1418, DOI 10.1109/TMM.2017.2771477
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao WQ, 2018, PATTERN RECOGN, V75, P112, DOI 10.1016/j.patcog.2017.06.020
   Zhao Y, 2017, LANGUAGE IMAGE PROCE, P771
   Zheng S, 2019, IEEE T KNOWL DATA EN, V31, P1520, DOI 10.1109/TKDE.2018.2861858
   Zhou BL, 2012, LECT NOTES COMPUT SC, V7573, P857, DOI 10.1007/978-3-642-33709-3_61
   Zhou BL, 2014, IEEE T PATTERN ANAL, V36, P1586, DOI 10.1109/TPAMI.2014.2300484
NR 50
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22007
EP 22026
DI 10.1007/s11042-021-10763-w
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631328800002
DA 2024-07-18
ER

PT J
AU Hussain, M
   Riaz, Q
   Saleem, S
   Ghafoor, A
   Jung, KH
AF Hussain, Mehdi
   Riaz, Qaiser
   Saleem, Shahzad
   Ghafoor, Abdul
   Jung, Ki-Hyun
TI Enhanced adaptive data hiding method using LSB and pixel value
   differencing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Adaptive data hiding; Adaptive LSB with PVD; PVD; LSB
AB High embedding capacity is considered as one of the significant challenges in information hiding. In the spatial domain, most of the high capacity based strategies employed the least significant bit (LSB) and pixel value differencing (PVD) techniques. However, these are suffered from the incorrect recovery of secret data, inefficient utilization of pixel intensities, and limited usage of pixel difference range table. In this paper, a new solution is proposed to alleviate the shortcoming by exploiting the pixel intensities ranges for high embedding rates while achieving the 100% recovery of secret data in the extraction phase. The proposed method divides the pixels into non-overlapping pixels block; further, compute the pixels differences along with respective ranges to determine the size of secret bits for the underlined adaptive LSB embedding process. In the extensive experiments, the proposed scheme outperforms the embedding capacity and maintains acceptable visual imperceptibility at various embedding rates, and also shows successfully the resistance against RS analysis and machine learning-based detection attacks.
C1 [Hussain, Mehdi; Riaz, Qaiser; Saleem, Shahzad; Ghafoor, Abdul] Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci, Dept Comp, Islamabad 44000, Pakistan.
   [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
C3 National University of Sciences & Technology - Pakistan; Kyungil
   University
RP Hussain, M (corresponding author), Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci, Dept Comp, Islamabad 44000, Pakistan.; Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
EM mehdi.hussain@seecs.edu.pk; khanny.jung@gmail.com
RI Riaz, Qaiser/AEZ-4665-2022; Saleem, Shahzad/KPY-5537-2024
OI Riaz, Qaiser/0000-0003-3722-4764; Saleem, Shahzad/0000-0002-0264-5887;
   Jung, Ki-Hyun/0000-0002-0662-8355
FU National University of Sciences and Technology (NUST) under the
   Department of Computing, School of Electrical Engineering and Computer
   Science, Islamabad, Pakistan; Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2018R1D1A1A09081842]; Korea Research Fellowship Program through the
   National Research Foundation of Korea(NRF) - Ministry of Science and ICT
   [2019H1D3A1A01101687]
FX This research was supported by the National University of Sciences and
   Technology (NUST) under the Department of Computing, School of
   Electrical Engineering and Computer Science, Islamabad, Pakistan. This
   research was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2018R1D1A1A09081842) and Korea Research Fellowship
   Program through the National Research Foundation of Korea(NRF) funded by
   the Ministry of Science and ICT(2019H1D3A1A01101687).
CR [Anonymous], 2019, USC SIPI IMAGE DATAB
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang KC, 2008, J MULTIMED, V3
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Hameed MA, 2019, IEEE ACCESS, V7, P185189, DOI 10.1109/ACCESS.2019.2960254
   Hosam O, 2016, SECUR COMMUN NETW, V9, P5036, DOI 10.1002/sec.1676
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P127, DOI 10.1007/s11554-017-0719-y
   Jung KH, 2010, IMAGING SCI J, V58, P213, DOI 10.1179/136821910X12651933390584
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Khodaei M, 2016, CYBERNET SYST, V47, P617, DOI 10.1080/01969722.2016.1214459
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Sahu AK, 2020, Digital Media Steganography, P41, DOI [10.1016/B978-0-12-819438-6.00011-6, DOI 10.1016/B978-0-12-819438-6.00011-6]
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Swain G, 2019, OPTIK, V180, P807, DOI 10.1016/j.ijleo.2018.11.015
   Swain G, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1505896
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu YQ, 2020, INT J COOP INF SYST, V29, DOI 10.1142/S0218843020400067
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu WL, 2016, DISPLAYS, V42, P36, DOI 10.1016/j.displa.2016.03.002
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
NR 32
TC 23
Z9 23
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20381
EP 20401
DI 10.1007/s11042-021-10652-2
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612700001
DA 2024-07-18
ER

PT J
AU Govind, PVS
   Varghese, BM
   Judy, MV
AF Sabeen Govind, P. V.
   Varghese, Bindiya M.
   Judy, M. V.
TI A high imperceptible data hiding technique using quorum function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpolation; Quorum function; Data hiding; Imperceptibility; Image
   quality
ID MEDICAL IMAGES; HIGH-CAPACITY; SCHEME; INTERPOLATION
AB In today's digitalized age and generation, where there is need of secure storage and transmission of data, the need of hiding information becomes a pre-requisite. In like situations, when we desire to send across data through images, we require an algorithm that can embed maximum data without degrading the original visual quality of the image that is being sent. The data embedding and retrieval process can be classified as reversible or irreversible. In this paper, we propose a general data-embedding algorithm which utilises the quorum function and optimal bit change operation, thus improving the visual quality of the stego image and being computationally efficient. Quorum function is used to embed the secret data in an efficient manner. So as to implement the algorithm for reversible data-embedding, the original image is interpolated and the interpolated values are utilised. The efficiency of the proposed method has been tested on various benchmark images and images from USC-SIPI image database. Our proposed method guarantees a peak signal to noise ratio (PSNR) value of more than 45 dB in all the test images. The result on comparison with the recent state of the art techniques shows the superiority of the proposed method in terms of visual quality and computational time.
C1 [Sabeen Govind, P. V.; Judy, M. V.] Cochin Univ Sci & Technol, Dept Comp Applicat, Kochi 682022, Kerala, India.
   [Sabeen Govind, P. V.; Varghese, Bindiya M.] Rajagiri Coll Social Sci Autonomous, Kochi 683104, Kerala, India.
C3 Cochin University Science & Technology; Rajagiri College of Social
   Sciences
RP Judy, MV (corresponding author), Cochin Univ Sci & Technol, Dept Comp Applicat, Kochi 682022, Kerala, India.
EM sabingovindpv@gmail.com; bindiya@rajagiri.edu; judy.nair@gmail.com
RI Judy, M V/Q-9879-2016
OI Varghese, Bindiya/0000-0001-7791-0537
FU Rajagiri College of Social Sciences(Autonomous), under Faculty Minor
   Research Scheme
FX This work was financially supported by Rajagiri College of Social
   Sciences(Autonomous), under Faculty Minor Research Scheme.
CR Ahvanooey MT, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5325040
   [Anonymous], 2013, NOVEL STEGANOGRAPHY
   [Anonymous], USC SIPI IMAGE DATAB
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   AZIZ F, 2020, PLOS ONE, V15
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Joshi K, 2018, J COMPUT NETW COMMUN, V2018, DOI 10.1155/2018/9475142
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2014, MULTIMED TOOLS APPL, V71, P1455, DOI 10.1007/s11042-012-1293-8
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Lakshmanan S., 2018, J COMPUT THEOR NANOS, V15, P2400, DOI [10.1166/jctn.2018.7477, DOI 10.1166/JCTN.2018.7477]
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Maniriho P, 2018, ENG LET, V26, P45
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Rajkumar R, 2019, CLUSTER COMPUT, V22, P12313, DOI 10.1007/s10586-017-1614-9
   Shaik A, 2019, MULTIMED TOOLS APPL, V78, P9717, DOI 10.1007/s11042-018-6544-x
   Solak S, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043025
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang WQ, 2018, SIGNAL PROCESS, V150, P102, DOI 10.1016/j.sigpro.2018.04.008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wedaj FT, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0206-1
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
NR 37
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20527
EP 20545
DI 10.1007/s11042-021-10780-9
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625713700002
DA 2024-07-18
ER

PT J
AU Kumari, A
   Tanwar, S
AF Kumari, Aparna
   Tanwar, Sudeep
TI A secure data analytics scheme for multimedia communication in a
   decentralized smart grid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia system; Big data; Smart grid; Secure data analytics;
   Blockchain; Deep learning; Data security &amp; privacy
ID DEMAND RESPONSE SCHEME; FRAMEWORK; INTERNET
AB With the exponential increase in energy demands (commercial as well as residential), the traditional grid infrastructure significantly shifted to intelligent ICT-based Smart Grid (SG) infrastructure. In the SG environment, only efficient energy management may not be sufficient as the SG dynamics have significant impacts on multimedia communications such as video surveillance of the technical/non-technical losses of energy and many more. The inevitable energy losses can be identified by process and analyze the massive amount of heterogeneous data, i.e., Big Data (BD) generated through smart devices such as sensors, Smart Meters (SMs), and others. The key challenges in analyzing multimedia BD are computational complexity, operational integration complexity, data security, and privacy. To overcome the aforementioned issues, this paper proposes a blockchain-based data analytics scheme called ChoIce, which offers secure data collection, analysis, and decision support for the SG systems. It works in two phases; (i) secure data collection over Ethereum and (ii) BD analytics and decision-making using deep learning (DL). The robust and secure data analytics, efficient network management, and high-performance computing for BD are crucial towards the optimization of SG operation. The performance of ChoIce is evaluated considering parameters such as the data storage cost, multimedia communication latency, and prediction accuracy. Thus, the results of ChoIce shows that it outperforms in contrast to other state-of-the-art approaches.
C1 [Kumari, Aparna; Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
C3 Nirma University
RP Tanwar, S (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
EM 17ftphde22@nirmauni.ac.in; sudeep.tanwar@nirmauni.ac.in
RI Tanwar, Sudeep/AAI-6709-2020
OI Tanwar, Sudeep/0000-0002-1776-4651
CR Altulyan M, 2020, MULTIMED TOOLS APPL, V79, P4989, DOI 10.1007/s11042-019-7182-7
   Atef S, 2019, INT C CONTROL DECISI, P1043, DOI [10.1109/codit.2019.8820363, 10.1109/CoDIT.2019.8820363]
   Bu SR, 2014, IEEE T VEH TECHNOL, V63, P2115, DOI 10.1109/TVT.2014.2313604
   De Dutta S, 2020, WIRELESS PERS COMMUN, V113, P1385, DOI 10.1007/s11277-020-07478-w
   Dhupia B, 2020, ADV INTELL SYST COMP, V1054, P403, DOI 10.1007/978-981-15-0135-7_38
   Dorri A, 2019, IEEE COMMUN MAG, V57, P120, DOI 10.1109/MCOM.2019.1800577
   Etherscan, 2020, ETH DAIL PRIC US CHA
   Ghafouri M, 2020, IEEE T SMART GRID, V11, P5227, DOI 10.1109/TSG.2020.3004303
   Guan ZT, 2018, IEEE COMMUN MAG, V56, P82, DOI 10.1109/MCOM.2018.1700401
   Gupta R, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3981
   He X, 2017, IEEE T SMART GRID, V8, P674, DOI 10.1109/TSG.2015.2445828
   Jindal A, 2020, IEEE T IND INFORM, V16, P3242, DOI 10.1109/TII.2019.2912816
   Jindal A, 2019, COMPUT NETW, V153, P36, DOI 10.1016/j.comnet.2019.02.002
   Jindal A, 2018, IEEE T IND ELECTRON, V65, P8993, DOI 10.1109/TIE.2018.2813990
   Kang JW, 2017, IEEE T IND INFORM, V13, P3154, DOI 10.1109/TII.2017.2709784
   Kumar D., 2020, Multimedia Big Data Computing for IoT Applications, P3, DOI DOI 10.1007/978-981-13-8759-3_1
   Kumar N, 2019, IEEE T IND INFORM, V15, P6572, DOI 10.1109/TII.2019.2922697
   Kumar Sumit, 2018, 2018 Fifth International Conference on Emerging Applications of Information Technology (EAIT). Proceedings, DOI 10.1109/EAIT.2018.8470406
   Kumarage H, 2016, IEEE CLOUD COMPUT, V3, P46, DOI 10.1109/MCC.2016.30
   Kumari A, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100427
   Kumari A, 2018, J NETW COMPUT APPL, V124, P169, DOI 10.1016/j.jnca.2018.09.014
   Latif Z, 2019, MULTIMED TOOLS APPL, V78, P27127, DOI 10.1007/s11042-017-5161-4
   Li X, 2019, J PARALLEL DISTR COM, V132, P242, DOI 10.1016/j.jpdc.2017.11.008
   Liang GQ, 2019, IEEE T SMART GRID, V10, P3162, DOI 10.1109/TSG.2018.2819663
   Liu C, 2017, IEEE PES INNOV SMART
   Mahmood K, 2016, COMPUT ELECTR ENG, V52, P114, DOI 10.1016/j.compeleceng.2016.02.017
   Munshi AA, 2017, ELECTR POW SYST RES, V151, P369, DOI 10.1016/j.epsr.2017.06.006
   Norvill R, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1121, DOI 10.1109/Cybermatics_2018.2018.00204
   OpenEI, 2020, OP EN INF
   Passerini F, 2019, IEEE T SMART GRID, V10, P6178, DOI 10.1109/TSG.2019.2899264
   Pee SJ, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P322, DOI [10.1109/ICAIIC.2019.8668978, 10.1109/icaiic.2019.8668978]
   Prasad G, 2020, IEEE COMMUN MAG, V58, P106, DOI 10.1109/MCOM.001.1900519
   Raju Leo, 2020, Proceeding of the International Conference on Computer Networks, Big Data and IoT (ICCBI - 2019). Lecture Notes on Data Engineering and Communications Technologies (LNDECT 49), P590, DOI 10.1007/978-3-030-43192-1_67
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Saleem A, 2020, IEEE INTERNET THINGS, V7, P6132, DOI 10.1109/JIOT.2019.2957314
   Shi H, 2018, IEEE T SMART GRID, V9, P5271, DOI 10.1109/TSG.2017.2686012
   Shi L, 2020, MULTIMED TOOLS APPL, V79, P5321, DOI 10.1007/s11042-018-6317-6
   Statista, 2020, BIG DAT MARK SIZ REV
   Stimmel C.L., 2014, BIG DATA ANAL STRATE
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Tanwar S, 2018, LECT NOTE NETW SYST, V19, P23, DOI 10.1007/978-981-10-5523-2_3
   Verma OP, 2020, MULTIMED TOOLS APPL, V79, P9757, DOI 10.1007/s11042-019-7677-2
   Wilcox T, 2019, COMPUT IND, V105, P250, DOI 10.1016/j.compind.2018.12.010
   Wood G., 2014, Ethereum project yellow paper, V151, P1
   Ye F, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417459
NR 45
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34797
EP 34822
DI 10.1007/s11042-021-10512-z
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000621742800004
DA 2024-07-18
ER

PT J
AU Raj, NRN
   Shreelekshmi, R
AF Raj, N. R. Neena
   Shreelekshmi, R.
TI A survey on fragile watermarking based image authentication schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Fragile watermarking; Tamper localization; Image
   recovery
ID TAMPER DETECTION; RESTORATION; SECURE; LOCALIZATION; OWNERSHIP;
   MECHANISM
AB Ensuring the image content authentication is a necessity need when images are used as supporting evidence in critical applications such as law enforcement, medical diagnosis, news reporting, and forensic investigation. Fragile watermarking is an effective solution for ensuring image content authentication. This paper presents a survey on fragile watermarking schemes for tamper localization and self-recovery. The characteristics and general framework are included to get an overview of these schemes. A brief review and comparison of various fragile watermarking schemes along with their merits and limitations are also given. The observations drawn from the comparative study are included to aid further research in this area. In addition to this, experimental evaluation of state-of-the-art tamper localization and self-recovery schemes in terms of watermarked image quality, tamper localization accuracy, and recovery capability is carried out.
C1 [Raj, N. R. Neena] Coll Engn Trivandrum, Dept Comp Sci & Engn, Thiruvananthapuram 695016, Kerala, India.
   [Raj, N. R. Neena] APJ Abdul Kalam Technol Univ, Thiruvananthapuram 695016, Kerala, India.
   [Shreelekshmi, R.] Govt Engn Coll, Dept Comp Sci & Engn, Trichur 680009, Kerala, India.
C3 College of Engineering, Trivandrum; Government Engineering College
   Thrissur
RP Raj, NRN (corresponding author), Coll Engn Trivandrum, Dept Comp Sci & Engn, Thiruvananthapuram 695016, Kerala, India.; Raj, NRN (corresponding author), APJ Abdul Kalam Technol Univ, Thiruvananthapuram 695016, Kerala, India.
EM nr4neenaraj@gmail.com
RI R, NEENA RAJ N/AAI-4366-2021; R, Shreelekshmi/AAH-6910-2020
OI R, NEENA RAJ N/0000-0002-3462-6074; R, Shreelekshmi/0000-0002-6523-3652
FU Department of Higher Education, Government of Kerala
FX Authors extend gratitude to the Department of Higher Education,
   Government of Kerala, for granting the research fellowship.
CR [Anonymous], 2020, CVG UGR IMAGE DATABA
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Benrhouma O, 2017, MULTIMED TOOLS APPL, V76, P21133, DOI 10.1007/s11042-016-4054-2
   Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   Geetha R, 2020, MULTIMED TOOLS APPL, V79, P12869, DOI 10.1007/s11042-019-08484-2
   Gonzalez, 2020, IMAGE DATABASES
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   He HJ, 2012, TELECOMMUN SYST, V49, P231, DOI 10.1007/s11235-010-9380-5
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Huang SC, 2012, J MAR SCI TECH-TAIW, V20, P49
   Kim C, 2018, PERS UBIQUIT COMPUT, V22, P11, DOI 10.1007/s00779-017-1061-x
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2013, MULTIMED TOOLS APPL, V64, P757, DOI 10.1007/s11042-011-0974-z
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Neena Raj N. R., 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P441, DOI 10.1109/CETIC4.2018.8530950
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Phan RCW, 2008, PATTERN RECOGN, V41, P3493, DOI 10.1016/j.patcog.2008.05.009
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P20897, DOI 10.1007/s11042-020-08715-x
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Raj N. R. Neena, 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P651, DOI 10.1109/ICICICT46008.2019.8993317
   Rajput V., 2019, MULTIMED TOOLS APPL, V79, P1
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040548
   Wang MS, 2007, COMPUT STAND INTER, V29, P561, DOI 10.1016/j.csi.2006.11.009
   Wong PW, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P374
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
NR 57
TC 16
Z9 16
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19307
EP 19333
DI 10.1007/s11042-021-10664-y
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621742800003
DA 2024-07-18
ER

PT J
AU Yu, LH
   Liu, NZ
   Zhou, WG
   Dong, S
   Fan, Y
   Abbas, K
AF Yu, LaiHang
   Liu, NingZhong
   Zhou, WenGang
   Dong, Shi
   Fan, Yu
   Abbas, Khushnood
TI Weber's law based multi-level convolution correlation features for image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Feature extraction; Weber&#8217; s law; Image saliency
   feature
ID FEATURE DESCRIPTOR; CLASSIFICATION; PATTERNS
AB Weber's law reveals the relationship between human perception and perceptual stimuli. Inspired by the theory, this paper designs a multi-level convolution correlation feature statistic method for image retrieval. Firstly, the difference between a central pixel and its neighbors is described by Weber's law through computing the differential excitation of image. Then, a multi-level saliency map is obtained by binary transformation and convolution operation. Thirdly, to exploit spatial correlation information of the image, a pixels pair-wise correlation and hierarchy statistic model is constructed. Finally, all intermediate features are concatenated into one histogram, which includes salient color and texture features. Extensive experiments demonstrate the proposed method of this paper has excellent performance.
C1 [Yu, LaiHang; Zhou, WenGang; Dong, Shi; Abbas, Khushnood] ZhouKou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466001, Peoples R China.
   [Yu, LaiHang; Liu, NingZhong] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Technol, Nanjing 210016, Peoples R China.
   [Fan, Yu] ZhouKou Normal Univ, Sch Network Engn, Zhoukou 466001, Peoples R China.
C3 Zhoukou Normal University; Nanjing University of Aeronautics &
   Astronautics; Zhoukou Normal University
RP Yu, LH (corresponding author), ZhouKou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466001, Peoples R China.; Yu, LH; Liu, NZ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Technol, Nanjing 210016, Peoples R China.
EM yulaihang@zknu.edu.cn; liunz@163.com; 20942317@qq.com; njbsok@gmail.com;
   1098420470@qq.com; abbas@cigit.ac.cn
RI Dong, Shi/ITT-3871-2023; Dong, Shi/P-7294-2014; Yu,
   Laihang/AAU-8586-2021
OI Yu, Laihang/0000-0001-7313-8914; Dong, Shi/0000-0003-4616-6519
FU Key Development Plan Project of the Science and Technology Department of
   Henan Province [212102210400, 182102310034, 182102210151]; Key Science
   and Technology Research Project of the Education Department of Henan
   Province [20A520047]; Zhoukou Normal University High-level Talents
   Research Funding Project [ZKNUC2018005]; National Nature Science
   Foundation of China [61672130]
FX This work was supported by Key Development Plan Project of the Science
   and Technology Department of Henan Province(No.212102210400,
   No.182102310034, No.182102210151), Key Science and Technology Research
   Project of the Education Department of Henan Province(No.20A520047),
   Zhoukou Normal University High-level Talents Research Funding Project
   (No.ZKNUC2018005), National Nature Science Foundation of
   China(No.61672130).
CR [Anonymous], IEEE C COMP VIS PATT
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   He L, 2019, MULTIMED TOOLS APPL, V78, P24519, DOI 10.1007/s11042-019-7157-8
   Kalaiarasi G, 2019, CLUSTER COMPUT, V22, P11997, DOI 10.1007/s10586-017-1539-3
   Kalaiarsasi G, 2013, 2013 INTERNATIONAL CONFERENCE ON GREEN COMPUTING, COMMUNICATION AND CONSERVATION OF ENERGY (ICGCE), P767, DOI 10.1109/ICGCE.2013.6823537
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Li YN, 2019, MULTIMED TOOLS APPL, V78, P24431, DOI 10.1007/s11042-018-7072-4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo QW, 2019, IEEE T INSTRUM MEAS, V68, P667, DOI 10.1109/TIM.2018.2852918
   Minu RI, 2014, INT J AUTOM COMPUT, V11, P489, DOI 10.1007/s11633-014-0832-3
   Minu RI, 2013, ADV INTELL SYST, V182, P333
   Murala S, 2013, PROC SPIE, V8663, DOI 10.1117/12.2002185
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thyagharajan KK, 2018, ADV ELECTR COMPUT EN, V18, P87, DOI 10.4316/AECE.2018.03012
   Thyagharajan KK., 2019, Archives of Computational Methods in Engineering, V26, P933, DOI DOI 10.1007/S11831-018-9266-3
   Tiwari D, 2017, MULTIMED TOOLS APPL, V76, P6623, DOI 10.1007/s11042-016-3362-x
   Uzuntarla M, 2019, NEURAL NETWORKS, V110, P131, DOI 10.1016/j.neunet.2018.11.007
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Vigneshl T., 2014, Int Conf Sci Eng Manag, P1, DOI DOI 10.1109/ICSEMR.2014.7043591
   WAN J, 2014, P 2014 ACM C MULTIME
   Wiatowski T, 2018, IEEE T INFORM THEORY, V64, P1845, DOI 10.1109/TIT.2017.2776228
   Yu LH, 2018, SIGNAL IMAGE VIDEO P, V12, P247, DOI 10.1007/s11760-017-1152-1
   Yu LH, 2016, IEEE ACCESS, V4, P6204, DOI 10.1109/ACCESS.2016.2607841
   Zeng FF, 2019, MULTIMED TOOLS APPL, V78, P32419, DOI 10.1007/s11042-019-07980-9
   Zhang SP, 2017, IEEE T NEUR NET LEAR, V28, P2357, DOI 10.1109/TNNLS.2016.2586194
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
   Zhou HB, 2019, MULTIMED TOOLS APPL, V78, P24391, DOI 10.1007/s11042-018-7036-8
   Zhou W., 2017, Recent Advance in Content-based Image Retrieval: A Literature Survey
NR 35
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19157
EP 19177
DI 10.1007/s11042-020-10355-0
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621282300002
DA 2024-07-18
ER

PT J
AU Behera, SK
   Rath, AK
   Sethy, PK
AF Behera, Santi Kumari
   Rath, Amiya Kumar
   Sethy, Prabira Kumar
TI Fruits yield estimation using Faster R-CNN with MIoU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fruit yield estimation; Faster R-CNN; VGG16; Modified intersection over
   union; On-plant images
ID DEEP; CLASSIFICATION
AB Fruit yield estimation is one of the challenging tasks using on-plant images to support smart farming and provide information about the product so that storage and export facility can be arranged. The detection and counting of on-plant fruits is a challenging task in complex vision. In this paper, we modify the intersection of union (IoU) in original Faster R-CNN (FR-CNN) for on-plant fruit detection. The modified IoU (MIoU) introduces good distance metric with the minimum area containing ground truth and predicted bounding box. Again, the MIoU pays extra attention to overlapping areas, which overcome the inefficiency of original R-CNN and enhance the detection accuracy. The proposed FR-CNN with MIoU achieved the correlation coefficient (R2) of mango, pomegranate, tomato, apple & orange are 0.98,0.92, 0.96, 0.98 & 0.95 respectively with the variation of imaging condition. In the same image sample, FR-CNN achieved the correlation coefficient (R-2) of mango, pomegranate, tomato, apple & orange are 0.81,0.91,0.89, 0.90 & 0.92 respectively. So, the FR-CNN with MIoU enhances the detection accuracy compared to original FR-CNN. Again, the F1 score for apple, orange, tomato, pomegranate and mango is 0.9534, 0.9794, 0.9424, 0.9534 and mango 0.9383 respectively. In addition, the proposed method is efficient enough with less complex compared to state-of-art models for fruit detection. Again, the proposed methodology is evaluated using other state-of-art fruits datasets, namely ACFR dataset and KFuji RGB-DS dataset. The proposed methodology achieved F1 score of 0.9523 & 0.9432 for yield estimation of apple & mango of ACFR dataset and 0.8912 for KFuji RGB-DS dataset.
C1 [Behera, Santi Kumari; Rath, Amiya Kumar] VSSUT, Dept Comp Sci & Engn, Burla, Odisha, India.
   [Sethy, Prabira Kumar] Sambalpur Univ, Dept Elect, Sambalpur, Odisha, India.
C3 Veer Surendra Sai University of Technology; Sambalpur University
RP Sethy, PK (corresponding author), Sambalpur Univ, Dept Elect, Sambalpur, Odisha, India.
EM prabirsethy.05@gmail.com
RI Behera, Santi Kumari/GPF-3681-2022; Sethy, Prabira kumar/W-5929-2019
OI Behera, Santi Kumari/0000-0003-4857-7821; Sethy, Prabira
   kumar/0000-0003-3477-6715
FU "Collaborative and Innovation Scheme" of TEQIP-III; project title
   "Development of Novel Approaches for Recognition and Grading of Fruits
   using Image processing and Computer Intelligence" [VSSUT/TEQIP/113/2020]
FX This work is supported by the research grant under "Collaborative and
   Innovation Scheme" of TEQIP-III with project title "Development of Novel
   Approaches for Recognition and Grading of Fruits using Image processing
   and Computer Intelligence", with reference letter No.
   VSSUT/TEQIP/113/2020.
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   [Anonymous], 2018, HORTICULTURAL STAT G
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Behera Santi Kumari, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 813), P71, DOI 10.1007/978-981-13-1498-8_7
   Behera S.K., 2019, INT J INNOV TECHNOL, V8, P103
   Behera S. K., 2018, Int. J. Appl. Eng. Res., V13, P6
   Behera S.K., 2019, INT J INNOV TECHNOL, V8, P798
   Behera SK, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01865-8
   BORIANNE P, 2019, ARXIV190910939
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Chu J, 2020, IEEE ACCESS, V8, P114705, DOI 10.1109/ACCESS.2020.3003917
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Gené-Mola J, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105591
   Gené-Mola J, 2019, COMPUT ELECTRON AGR, V162, P689, DOI 10.1016/j.compag.2019.05.016
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gongal A, 2015, COMPUT ELECTRON AGR, V116, P8, DOI 10.1016/j.compag.2015.05.021
   Häni N, 2020, J FIELD ROBOT, V37, P263, DOI 10.1002/rob.21902
   Kang H, 2010, COMPUT ELECT AGR
   Kestur R, 2019, ENG APPL ARTIF INTEL, V77, P59, DOI 10.1016/j.engappai.2018.09.011
   Koirala A, 2019, PRECIS AGRIC, V20, P1107, DOI 10.1007/s11119-019-09642-0
   Koirala A, 2019, COMPUT ELECTRON AGR, V162, P219, DOI 10.1016/j.compag.2019.04.017
   Lal S, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON SENSING, SIGNAL PROCESSING AND SECURITY (ICSSS), P361, DOI 10.1109/SSPS.2017.8071621
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Mühling M, 2017, MULTIMED TOOLS APPL, V76, P22169, DOI 10.1007/s11042-017-4962-9
   Qureshi WS, 2017, PRECIS AGRIC, V18, P224, DOI 10.1007/s11119-016-9458-5
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ramu SM, 2019, MULTIMED TOOLS APPL, V78, P21391, DOI 10.1007/s11042-019-7328-7
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sethy PK, 2016, INT J COMPUT APPL, V156, P16, DOI [10.5120/ijca2016912487, DOI 10.5120/IJCA2016912487]
   Tu SQ, 2018, BIOSYST ENG, V175, P156, DOI 10.1016/j.biosystemseng.2018.09.004
   Xu LM, 2018, MULTIMED TOOLS APPL, V77, P7205, DOI 10.1007/s11042-017-4629-6
   Yong BB, 2021, MULTIMED TOOLS APPL, V80, P34103, DOI 10.1007/s11042-020-08911-9
   Yu HQ, 2019, BDCAT'19: PROCEEDINGS OF THE 6TH IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES, P145
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Yuchi S, 2019, MULTIMED TOOLS APPL, DOI 10.1007/s11042-019-7637-x
   Zhang H, 2020, MULTIMED TOOLS APPL, V79, P9331, DOI 10.1007/s11042-019-7508-5
   Zhang Yanning, 2020, Sensors, V20
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhu HY, 2018, MULTIMED TOOLS APPL, V77, P29779, DOI 10.1007/s11042-017-5578-9
NR 45
TC 28
Z9 29
U1 1
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 19043
EP 19056
DI 10.1007/s11042-021-10704-7
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000621015900001
DA 2024-07-18
ER

PT J
AU Awad, M
   Abougindia, IT
   Elliethy, A
   Aly, HA
AF Awad, Mohamed
   Abougindia, Islam T.
   Elliethy, Ahmed
   Aly, Hussein A.
TI Flexible architecture for real-time synchronized processing of
   multimedia signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia simultaneous processing; Multimedia synchronization;
   Real-time multimedia fusion; Video processing
AB Simultaneous processing of multiple multimedia appears in many applications. However, there is a lack of a generalized hardware platform that fits all application needs from the number to the format of the input and output multimedia. The processing is also associated with synchronization problems such as startup delays and deviating frame rates of the multimedia. This paper presents a flexible platform with co-design of hardware and software for the applications specific needs. On the hardware side, it presents modular and scalable architecture that considers: the required number of input and output multimedia signals, the mixed analog and digital multimedia signals and their processing hardware components crosstalk to minimize the signal-to-noise ratio on the platform, and finally the low power consumption. On the processing side, a synchronization module is proposed and efficiently implemented to handle the startup delays and the deviating frame rates of the input multimedia signals. The system hardware and software were implemented for two case studies. A case study for fusion of multimedia signals of different modalities (visible and near infra-red (RGBN)), that is needed for modern smart phone cameras, is presented. Another case study for producing a 4K format required for larger displays is included, that stitches 9 high-definition videos simultaneously. The multimedia pipeline: decoding, processing, encoding were all realized and implemented successfully. The system performed in real-time of 30 frames per second. The platform end-to-end signal-to-noise ratio where above 56 and reaching 102 decibels, and the power consumption was below 2 Watts, making it suitable for real-time embedded multimedia systems.
C1 [Awad, Mohamed; Abougindia, Islam T.; Elliethy, Ahmed; Aly, Hussein A.] Mil Tech Coll, Cairo, Egypt.
C3 Military Technical College
RP Aly, HA (corresponding author), Mil Tech Coll, Cairo, Egypt.
EM awad.mrms@gmail.com; iabougindia@ieee.org; a.s.elliethy@mtc.edu.eg;
   haly@ieee.org
RI Elliethy, Ahmed/GSN-9676-2022; Aly, Hussein/S-9624-2019
OI Elliethy, Ahmed/0000-0002-5120-253X; Aly, Hussein/0000-0001-5604-7252;
   Awad, Mohamed/0000-0002-5181-2506
CR Ahmad I., 2007, IEEE Distributed Systems Online, V8
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], 2014, IEEE NVMTS
   [Anonymous], 2010, PROC IEEE INT C ELEC, DOI [DOI 10.1109/EIT.2010.5612173, 10.1109/EIT.2010.5612173]
   Awad M, 2018, IEEE IMAGE PROC, P3968, DOI 10.1109/ICIP.2018.8451602
   Bennett EP, 2007, IEEE T IMAGE PROCESS, V16, P1185, DOI 10.1109/TIP.2007.894236
   Brooks, 2000, SPLITTING PLANES SPE
   Card RA, 1995, U.S. Patent, Patent No. [5384,912, 5384912]
   Eastman NL, 1996, WESCON - 96, CONFERENCE PROCEEDINGS, P297, DOI 10.1109/WESCON.1996.554004
   El-Hashash MM, 2019, J REAL-TIME IMAGE PR, V16, P1117, DOI 10.1007/s11554-016-0603-1
   Elliethy AS, 2014, PROC SPIE, V9011, DOI 10.1117/12.2040837
   Fouad MM, 2016, ADV ELECTR ELECTRON, V14, P196, DOI 10.15598/aeee.v14i2.1597
   Guo X., 2017, Identification of cyst nematode B-type CLE peptides and modulation of the vascular stem cell pathway for feeding cell formation, DOI [DOI 10.1371/JOURNAL.PPAT.1006142, 10.1371/journal.ppat.1006142, 10.1109/CISP-BMEI.2017.8301926]
   Jack, 2004, VIDEO DEMYSTIFIED HD
   Khalifa AA, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.12.123102
   Khodary AG, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P703, DOI 10.1109/GlobalSIP.2014.7032209
   Menon, 2019, J REAL-TIME IMAGE PR, P1, DOI DOI 10.1007/S11554-019-00889-4
   Nilsson M., 2015, ULTRAHIGH DEFINITION
   Ott H. W., 2001, Printed Circuit Design, V18, P8
   Pandey J. G., 2012, 2012 International Conference on Devices, Circuits and Systems (ICDCS 2012), P191, DOI 10.1109/ICDCSyst.2012.6188702
   Park MW, 2012, IEEE T CONSUM ELECTR, V58, P535, DOI 10.1109/TCE.2012.6227458
   Radiocommunication Sector of ITU,, 2007, BT SERIES
   ROSKA T, 1993, IEEE T CIRCUITS-II, V40, P163, DOI 10.1109/82.222815
   Said Yahia, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P85, DOI 10.1007/978-3-642-31254-0_10
   Sun J., 2003, Method for determining defect depth using thermal imaging, V6, P542, Patent No. US6,566,145B2
   Taylor RJ, 1979, U.S. Patent, Patent No. [4148,070, 4148070]
   Toledo FJ, 2007, 2007 3RD SOUTHERN CONFERENCE ON PROGRAMMABLE LOGIC, PROCEEDINGS, P171, DOI 10.1109/SPL.2007.371743
   Touil L., 2014, INT J EMB SYS APP IJ, V4, P1
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Vetro A, 2014, U.S. Patent, Patent No. 8823821
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yamazaki S, 1991, U.S. Patent, Patent No. [5040,067, 5040067]
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
NR 33
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18531
EP 18551
DI 10.1007/s11042-021-10575-y
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300010
DA 2024-07-18
ER

PT J
AU Chen, WB
   Lu, Y
   Ma, H
   Chen, QL
   Wu, XB
   Wu, PL
AF Chen, Wenbai
   Lu, Yue
   Ma, Hang
   Chen, Qili
   Wu, Xibao
   Wu, Peiliang
TI Self-attention mechanism in person re-identification models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep neural network; Self-attention; Computer
   vision
ID NEURAL-NETWORK
AB In recent years, person re-identification based on video has become a hot topic in the field of person re-identification. The self-attention mechanism can improve the ability of deep neural networks in computer vision tasks such as image classification, image segmentation and natural language processing tasks. In order to verify whether the self-attention can improve the performance or not in person re-identification tasks, this paper applies two self-attention mechanisms, non-local attention and recurrent criss-cross attention to person re-identification model, and experiments are conducted on Market-1501, DukeMTMC-reID and MSMT17 person re-identification datasets. The results show that the self-attention mechanism can improve the accuracy of the person re-identification model. The accuracy is higher when the self-attention module is inserted into the convolutional layers of the re-identification network.
C1 [Chen, Wenbai; Lu, Yue; Ma, Hang; Chen, Qili; Wu, Xibao] Beijing Informat Sci & Technol Univ, Sch Automat, Beijing 100192, Peoples R China.
   [Wu, Peiliang] Yanshan Univ, Sch Informat & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Wu, Peiliang] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
C3 Beijing Information Science & Technology University; Yanshan University;
   Chinese Academy of Sciences; Institute of Automation, CAS
RP Chen, WB (corresponding author), Beijing Informat Sci & Technol Univ, Sch Automat, Beijing 100192, Peoples R China.
EM chenwb@bistu.edu.cn; luyue163@126.com; mh@bistu.edu.cn;
   qilichen@hotmail.com; wuxibao@bistu.edu.cn; peiliangwu@ysu.edu.cn
OI Chen, Wenbai/0000-0001-7683-2776; LU, Yue/0000-0002-9805-1732
FU National Key R&D Program of China [2018YFB1308300]; China Postdoctoral
   Science Foundation [2018M631620]; CrossTraining Plan of High Level
   Talents and Training Project of Beijing; Beijing Natural Science
   Foundation [4202026]
FX This work was partially supported by the National Key R&D Program of
   China (2018YFB1308300), China Postdoctoral Science Foundation
   (2018M631620), and partially by CrossTraining Plan of High Level Talents
   and Training Project of Beijing, and Beijing Natural Science
   Foundation(Grant No.4202026).
CR Bazzani L., 2010, INT C PATT REC, P1413, DOI [DOI 10.1109/ICPR.2010.349, 10.1109/ICPR.2010.349]
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   [李幼蛟 Li Youjiao], 2018, [自动化学报, Acta Automatica Sinica], V44, P1554
   [刘建伟 Liu Jianwei], 2020, [自动化学报, Acta Automatica Sinica], V46, P1090
   Liu Ziyan, 2020, Journal of Computer Applications, V40, P672
   [罗浩 Luo Hao], 2019, [自动化学报, Acta Automatica Sinica], V45, P2032
   Qin LL, 2018, TEH VJESN, V25, P528, DOI 10.17559/TV-20171229024444
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   [宋婉茹 Song Wanru], 2017, [智能系统学报, CAAI Transactions on Intelligent Systems], V12, P770
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zajdel W, 2005, IEEE INT CONF ROBOT, P2081
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
NR 30
TC 10
Z9 10
U1 15
U2 167
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4649
EP 4667
DI 10.1007/s11042-020-10494-4
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000618948700012
DA 2024-07-18
ER

PT J
AU Zhang, XD
   Kusrini, K
AF Zhang, Xindi
   Kusrini, Kusrini
TI Autonomous long-range drone detection system for critical infrastructure
   safety
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drone detection; Deep-learning; Infrastructure security; Sensing
   equipment
ID TRACKING
AB The development of unmanned aerial vehicles has been identified as a potential source of a weapon for causing operational disruptions against critical infrastructures. To mitigate and neutralise the threat posed by the misuse of drones against malicious and terrorist activity, this paper presents a holistic design of a long-range autonomous drone detection platform. The novelty of the proposed system lies in the confluence between the design of hardware and software components to effective and efficient localisation of the intruder objects. The research presented in the paper proposes the design and validation of a situation awareness component which is interfaced with the hardware component for controlling the focal length of the camera. The continuous stream of media data obtained from the region of vulnerability is processed using the object detection that is built on region based fully connected neural network. The novelty of the proposed system relies on the processing of multi-threaded dual-media input streams that are evaluated to mitigate the latency of the system. Upon the successful detection of malicious drones, the system logs the occurrence of intruders that consists of both event description and the associated media evidence for the deployment of the mitigation strategy. The analytics platform that controls the signalling of the low-cost sensing equipment contains the NVIDIA GeForce GTX 1080 for detecting drones. The experimental testbeds developed for the validation of the proposed system has been constructed to include environments and situations that are commonly faced by critical infrastructure operators such as the area of protection, drone flight path, tradeoff between the angle of coverage against the distance of coverage. The validation of the proposed system has resulted in yielding a range of intruder drone detection by 250m with an accuracy of 95.5%.
C1 [Zhang, Xindi] Queen Mary Univ London, Sch Elect Engn & Comp Sci, Multimedia & Vis Grp, Mile End Rd, London E1 4NS, England.
   [Kusrini, Kusrini] Univ AMIKOM Yogyakarta, Jl Ringrd Utara Condong Catur Depok Sleman, Yogyakarta, Indonesia.
C3 University of London; Queen Mary University London
RP Zhang, XD (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, Multimedia & Vis Grp, Mile End Rd, London E1 4NS, England.
EM xindi.zhang@qmul.ac.uk; kusrini@amikom.ac.id
RI Kusrini, Kusrini/C-7787-2015; Zhang, Xindi/ISU-4775-2023; Zhang,
   Xindi/JCO-9907-2023
OI Kusrini, Kusrini/0000-0001-9573-3909; 
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brust MR, 2018, ARXIV180806900
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gökçe F, 2015, SENSORS-BASEL, V15, P23805, DOI 10.3390/s150923805
   Grinberg M., 2014, Flask Web Development: Developing Web Applications With Python
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu Y., 2015, ARXIV151207711, P2351
   Narkhede N., 2017, Kafka The Definitive Guide-Realtime data and stream processing at scale
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rozantsev A, 2017, IEEE T PATTERN ANAL, V39, P879, DOI 10.1109/TPAMI.2016.2564408
   Singh B, 2018, 32 C NEURAL INFORM P
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taha B, 2019, IEEE ACCESS, V7, P138669, DOI 10.1109/ACCESS.2019.2942944
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yoshihashi R, 2017, ARXIV170904666
   Zhang XD, 2019, LECT NOTES COMPUT SC, V11754, P713, DOI 10.1007/978-3-030-34995-0_65
NR 29
TC 9
Z9 10
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23723
EP 23743
DI 10.1007/s11042-020-10231-x
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000617417600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Banday, SA
   Pandit, MK
AF Banday, Shoaib Amin
   Pandit, Mohammad Khalid
TI Texture maps and chaotic maps framework for secure medical image
   transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image encryption; Logistic maps; Arnold cat map; Entropy
ID ENCRYPTION; SCHEME; RESOLUTION; EFFICIENT; ALGORITHM; SPACE
AB Telemedicine has evolved significantly for detection and diagnosis of diseases remotely, which means more frequent transmission of medical images over the network. The security of any medical image can be characterized as its integrity, confidentiality and authentication. It is these security vulnerabilities that limit the development of mobile healthcare applications, which intend to improve the efficiency of medical image communication. To address the vulnerabilities associated with medical images, we propose a texture edge map and multilevel chaotic map driven encryption framework for medical images. This technique utilizes texture maps generated by utilizing a bank of gabor filters along with multiple chaotic maps viz.: Sine, Cubic and Logistic maps for enhancing the key space, robustness and security of medical images over an insecure channel. The security, speed and reliability of the proposed technique for medical images are illustrated via experiments for key sensitivity, statistical and performance analysis. The proposed technique offers a large key space, pixel diffusion at an acceptable speed. Security analysis shows a high sensitive dependence of the encryption and decryption techniques to any subtle change in the secret key, the plain medical image and the encrypted image. Also, the proposed technique has a large enough key space to see off brute force attacks. Therefore, the proposed technique is a potential candidate for addressing security vulnerabilities of medical images over the communication networks.
C1 [Banday, Shoaib Amin; Pandit, Mohammad Khalid] Sch Engn & Technol IUST J&K India, Machine Learning Lab, Awantipora, India.
RP Banday, SA (corresponding author), Sch Engn & Technol IUST J&K India, Machine Learning Lab, Awantipora, India.
EM shoaibee.a@gmail.com
OI pandit, Mohammad khalid/0000-0002-3755-3245
CR Abdmouleh AKMK, 2013, P 2013 INT C SYST CO, P241
   Alassaf N, 2019, INT J E-HEALTH MED C, V10, P1, DOI 10.4018/IJEHMC.2019100101
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Ali S, 2020, IEEE ACCESS, V8, P148007, DOI 10.1109/ACCESS.2020.3014671
   Alvarez E, 1999, PHYS LETT A, V263, P373, DOI 10.1016/S0375-9601(99)00747-1
   Amin Banday S, 2020, 5 INT C NEXT GEN COM
   Ashtiyani M, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES: FROM THEORY TO APPLICATIONS, VOLS 1-5, P2633
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Belkhouche F, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2135792
   Brahimi Zahia, 2008, WSEAS Transactions on Circuits and Systems, V7, P718
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Farooqi N., 2019, LIFE SCI J, V16, P11
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Hu JK, 2009, J NETW COMPUT APPL, V32, P788, DOI 10.1016/j.jnca.2009.02.009
   Ji ZX, 2015, INFORM SCIENCES, V301, P285, DOI 10.1016/j.ins.2015.01.006
   Jung H, 2009, MAGN RESON MED, V61, P103, DOI 10.1002/mrm.21757
   Khan MK, 2008, NEUROCOMPUTING, V71, P3026, DOI 10.1016/j.neucom.2007.12.017
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Lin CF, 2009, MED BIOL ENG COMPUT, V47, P757, DOI 10.1007/s11517-009-0458-8
   Liu HJ, 2016, OPTIK, V127, P5812, DOI 10.1016/j.ijleo.2016.04.014
   Liu JL, 2006, PATTERN RECOGN, V39, P1509, DOI 10.1016/j.patcog.2006.02.013
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Materka A., 1998, TEXTURE ANAL METHODS
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mitra S, 2015, INFORM SCIENCES, V306, P111, DOI 10.1016/j.ins.2015.02.015
   Ou Y, 2007, LECT NOTES COMPUT SC, V4613, P62
   Panduranga HT, 2013, INT J ENG SCI TECH, V5
   Pandzic H., 2013, 2013 INT C OPT IM SE, P1, DOI [10.1109/PESMG.2013.6672719, DOI 10.1109/ICOISS.2013.6678417]
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Phophalia A, 2014, SIGNAL PROCESS, V103, P24, DOI 10.1016/j.sigpro.2014.01.029
   Puech W., 2005, EUSIPCO 05 EUR SIGN, P1
   Rao YVS, 2006, LECT NOTES COMPUT SC, V4332, P315
   Sarker MZH, 2005, P 9 IEEE INT MULT C, P1
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Singh Saurabh, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1625, DOI 10.1007/s12652-017-0494-4
   Som S, 2013, PROC TECH, V10, P663, DOI 10.1016/j.protcy.2013.12.408
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wong KW, 2002, PHYS LETT A, V298, P238, DOI 10.1016/S0375-9601(02)00431-0
   Wong WK, 2001, COMPUT PHYS COMMUN, V138, P234, DOI 10.1016/S0010-4655(01)00220-X
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhao TY, 2018, IEEE T IMAGE PROCESS, V27, P4740, DOI 10.1109/TIP.2018.2845118
   Zhou YC, 2009, IEEE ENG MED BIO, P3707, DOI 10.1109/IEMBS.2009.5334799
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
NR 57
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17667
EP 17683
DI 10.1007/s11042-021-10564-1
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616915300005
DA 2024-07-18
ER

PT J
AU Ma, B
   Hou, JC
   Wang, CP
   Wu, XM
   Shi, YQ
AF Ma, Bin
   Hou, Jin-Cheng
   Wang, Chun-Peng
   Wu, Xiao-Ming
   Shi, Yun-Qing
TI A reversible data hiding algorithm for audio files based on code
   division multiplexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Audio; Code division multiplexing (CDM);
   Capacity
ID PREDICTION
AB In this paper, a reversible data hiding algorithm for audio files based on code division multiplexing (CDM) is proposed. In the scheme, the orthogonal spreading sequences are employed to carry the embedding data, and the host audio file can also be recovered completely after the secret message has been extracted accurately. At the same time, according the orthogonal character of the spreading sequences, the secret message can be embedded into the audio files repeatedly, and most elements of the spreading sequences are mutually canceled in the process of multi-level data embedding, which maintains the audio file in good auditory even at high data embedding capacity. Moreover, only the receiver who holds the same spreading sequences, as the sender can restore the embedded data, which enhance the security of the proposed scheme. As shown in the experimental results, the CDM based reversible data hiding (RDH) algorithm for audio files can achieve higher data embedding capacity at the same audio distortion compared with those state-of-the-art audio RDH algorithms.
C1 [Ma, Bin; Hou, Jin-Cheng; Wang, Chun-Peng; Wu, Xiao-Ming] Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Shandong Prov Key Lab Comp Networks, Jinan 250300, Peoples R China.
   [Shi, Yun-Qing] New Jersey Inst Technol, Newark, NJ 07102 USA.
C3 Qilu University of Technology; New Jersey Institute of Technology
RP Ma, B (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Shandong Prov Key Lab Comp Networks, Jinan 250300, Peoples R China.
EM sddxmb@126.com
FU National Natural Science Foundation of China [61802212]
FX The research reported in this paper was partially supported by National
   Natural Science Foundation of China (nos. 61872203) and The National
   Natural Science Foundation of China (nos. 61802212).
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, P SPIE ELECT IMAGING
   Barton J. M., 1997, U.S. Patent, Patent No. 5646997
   Bobeica A, 2018, INT CONF SYST THEO, P810, DOI 10.1109/ICSTCC.2018.8540672
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   EBU Committee, SOUND QUAL ASS MAT R
   Echizen I, 2013, REVERSIBLE AUDIO INF
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Han S, 2009, IEICE T FUND ELECTR, VE92A, P2572, DOI 10.1587/transfun.E92.A.2572
   Jassim S A, 2020, MULTIMED TOOLS APPL, P1
   Kalker T, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P71, DOI 10.1109/ICDSP.2002.1027818
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ma B., 2016, IEEE T INF FOREN SEC, V11, P1, DOI DOI 10.1109/TIFS.2016.2606958
   Ma B, 2019, J REAL-TIME IMAGE PR, V16, P857, DOI 10.1007/s11554-019-00884-9
   Ma B, 2019, J REAL-TIME IMAGE PR, V16, P821, DOI 10.1007/s11554-019-00891-w
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Nishimura A., 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P318, DOI 10.1109/IIHMSP.2011.76
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang F, 2014, SCI WORLD J, DOI 10.1155/2014/656251
   WU XY, 2019, INT J DIGITAL CRIME, V11, P29
   Xiang SJ, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0101-9
   Xiang SJ, 2012, P 14 INT C, V7692, P224
   Xie XZ, 2020, MULTIMED TOOLS APPL, V79, P24329, DOI 10.1007/s11042-019-08402-6
   Xie XZ, 2019, IET IMAGE PROCESS, V13, P1411, DOI 10.1049/iet-ipr.2018.5333
   Yan DQ, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P249, DOI 10.1109/IIH-MSP.2008.27
   Yu H., 2020, IEEE Access
NR 35
TC 11
Z9 11
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17569
EP 17581
DI 10.1007/s11042-021-10532-9
EA FEB 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616158900004
DA 2024-07-18
ER

PT J
AU Darwish, SM
AF Darwish, Saad M.
TI Feature extraction of finger-vein patterns based on boosting
   evolutionary algorithm and its application for loT identity and access
   management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric finger vein identification; Optimal feature extraction;
   Niching genetic algorithm; Context based clearing procedure
ID AUTHENTICATION; RECOGNITION
AB With billions of devices being connected, how to make sure that our information stays secure is becoming a hot topic of IoT. Traditional approaches to personal authentication are inadequate and ineffective in the IoT era. Finger vein technology is the current biometric system that utilizes the vein structure for recognition. As such patterns are veiled under the skin surface, they have significant privacy protection and are therefore incredibly difficult to forge. Finger vein recognition has gained a great deal of publicity because earlier approaches experienced significant pitfalls, such as its inability to handle the imbalanced collection of finger veins samples and the detection of distinguishing features in low-quality images. Such disadvantages have triggered a lack of consistency of the optimization algorithm or have contributed to a decrease in its efficiency. The key objective of the research discussed in this paper is to examine the impact of the genetic algorithm in the selection of the optimum vector characteristics of the finger vein. This is done by incorporating a Niching model in the form of a Context-Based Clearing (CBC) procedure to increase the heterogeneity of the features within the features' vector, with the goal of minimizing the association between them. It also offers the idea of a reduction of the feature set to reduce duplication without reducing accuracy. The performance study of the proposed model is carried out through multiple tests and the findings indicate an overall increase of 6% in the accuracy relative to some of the state-of-the-art finger vein recognition systems present in the literature.
C1 [Darwish, Saad M.] Univ Alexandria, Dept Informat Technol, Inst Grad Studies & Res, 136 Horreya Ave,Shatby 21526,POB 832, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP Darwish, SM (corresponding author), Univ Alexandria, Dept Informat Technol, Inst Grad Studies & Res, 136 Horreya Ave,Shatby 21526,POB 832, Alexandria, Egypt.
EM saad.darwish@alexu.edu.eg
RI Darwish, Saad Mohamed/ISB-6375-2023
OI Darwish, Saad/0000-0003-2723-1549
CR Adeoye O. S., 2010, INT J COMPUT APPL, V9, P975
   [Anonymous], 2011, J GLOBAL RES COMPUT
   Banerjee A, 2018, MULTIMED TOOLS APPL, V77, P5857, DOI 10.1007/s11042-017-4501-8
   Beining Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1269, DOI 10.1109/ICPR.2010.316
   Bhargava N., 2013, INT J COMPUTER TREND, V4, P515
   Das R, 2019, IEEE T INF FOREN SEC, V14, P360, DOI 10.1109/TIFS.2018.2850320
   Ezhilmaran D, 2017, P IEEE REG 10 S TENS, P1
   Fayek MB, 2010, J ADV RES, V1, P301, DOI 10.1016/j.jare.2010.09.001
   Garg P., 2012, GLOB J COMPUT SCI TE, V12, P1
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   He CL, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P456, DOI 10.1109/ICCI-CC.2017.8109788
   Van HT, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P348, DOI 10.1109/KSE.2015.12
   Hsia CH, 2018, J IMAGING SCI TECHN, V62, DOI 10.2352/J.ImagingSci.Technol.2018.62.3.030402
   Hu N, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.163664
   Iqbal K, 2012, J COMPUT SYST SCI, V78, P1258, DOI 10.1016/j.jcss.2011.10.013
   Jalilian E, 2020, ADV COMPUT VIS PATT, P201, DOI 10.1007/978-3-030-27731-4_8
   Kaur S., 2017, INT J SCI ENG RES, V8, P936
   Khalil-Hani M., 2012, 2012 1st IEEE International Conference on Communications in China (ICCC 2012), P236, DOI 10.1109/ICCChina.2012.6356884
   Kono M, 2002, APPL OPTICS, V41, P7429, DOI 10.1364/AO.41.007429
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu X, 2020, IEEE T IND INFORM, V16, P5379, DOI 10.1109/TII.2019.2947435
   Liu X, 2019, IEEE INTERNET THINGS, V6, P5962, DOI 10.1109/JIOT.2018.2847731
   Liu Y, 2018, SOFT COMPUT, V22, P2257, DOI 10.1007/s00500-017-2487-9
   Liu Z, 2010, J NETW COMPUT APPL, V33, P275, DOI 10.1016/j.jnca.2009.12.006
   Lu Y, 2017, FUTURE GENER COMP SY, V77, P149, DOI 10.1016/j.future.2017.07.013
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Mohsin AH, 2020, IEEE ACCESS, V8, P9821, DOI 10.1109/ACCESS.2020.2964788
   Obaidat M.S., 2019, Biometric-Based Phys. Cybersecur. Syst., P477
   Parthiban K, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT), P143, DOI 10.1109/ICADIWT.2014.6814681
   Ragan R., 2014, P IEEE INT C EM RES, P1
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Shaheed K, 2018, INFORMATION, V9, DOI 10.3390/info9090213
   Shaikh S., 2016, Indian J. Sci. Technol, V9, P1, DOI [10.17485/ijst/2016/v9iS1/109279, DOI 10.17485/IJST/2016/V9IS1/109279]
   Sheikh Rahila H., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P314, DOI 10.1109/ICETET.2008.48
   Shinde S. R., 2017, INT RES J ENG TECHNO, V4, P1517
   Su J, 2017, J CRYST GROWTH, V468, P914, DOI 10.1016/j.jcrysgro.2016.10.061
   Syazana-Itqan K., 2016, Indian J. Sci. Technol, V9, P1
   Thakur S, 2019, INT C INV COMP TECHN, P138
   Unnikrishnan P, 2014, THESIS RMIT U AUSTR
   Veluchamy S, 2017, IET BIOMETRICS, V6, P232, DOI 10.1049/iet-bmt.2016.0112
   Vishi K, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P334, DOI 10.1109/IIH-MSP.2013.91
   Wang F, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010028
   Wang K., 2011, BOOK BIOMETRICS
   Wu JD, 2011, EXPERT SYST APPL, V38, P5423, DOI 10.1016/j.eswa.2010.10.013
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P623, DOI 10.1016/j.patrec.2011.11.002
   Yang JF, 2011, COMPUT HUM BEHAV, V27, P1565, DOI 10.1016/j.chb.2010.10.029
   Yang L, 2014, LECT NOTES COMPUT SC, V8833, P234, DOI 10.1007/978-3-319-12484-1_26
   Ye F, 2011, PROCEDIA ENGINEER, V16, DOI 10.1016/j.proeng.2011.08.1099
NR 55
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14829
EP 14851
DI 10.1007/s11042-021-10569-w
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612905100003
DA 2024-07-18
ER

PT J
AU Tsai, WL
AF Tsai, Wen-Lung
TI A cooperative mechanism for managing multimedia project documentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document context; Multimedia project; Object technology; Project
   documentation; Section-orientation
AB Documentation management is a crucial component of successful business-related projects, but it often involves significant effort in terms of time and cost. Initializing, writing, and revising project documents can be a monotonous and fragmented task, especially during rapid project development. However, the context among most project documentation and business administration is highly interconnected. Based on the relationships among project documentation, especially for multimedia projects, this study uses the concept of section-orientation and presents a cooperative mechanism that uses object technology to clarify project documentation and its context. This study also introduces a prototype object-based functional project documentation system and illustrates the mechanism through two case studies and data analysis. The purpose of this study is to present a definite expression of this context in functional project documents. The results are practically applicable for managing multimedia project documentation.
C1 [Tsai, Wen-Lung] Oriental Inst Technol, Dept Informat Management, 58,Sect 2,Sihchuan Rd, New Taipei 22061, Taiwan.
C3 Asia Eastern University of Science & Technology
RP Tsai, WL (corresponding author), Oriental Inst Technol, Dept Informat Management, 58,Sect 2,Sihchuan Rd, New Taipei 22061, Taiwan.
EM tswelu@gmail.com
CR Batova T, 2018, IEEE T PROF COMMUN, V61, P311, DOI 10.1109/TPC.2018.2823598
   Bjarnason E, 2016, INFORM SOFTWARE TECH, V70, P204, DOI 10.1016/j.infsof.2015.05.004
   Choi D, 2015, SOFTWARE PRACT EXPER, V45, P1073, DOI 10.1002/spe.2296
   CMMI Institute, 2018, CMMI for Development
   De Lucia A, 2010, SOFTWARE PRACT EXPER, V40, P1007, DOI 10.1002/spe.986
   Fourati M, 2020, MULTIMED TOOLS APPL, V79, P33519, DOI 10.1007/s11042-020-09589-9
   Guillaume-Joseph G., 2016, Improving software project outcomes through predictive analytics
   Hannay JE, 2007, IEEE T SOFTWARE ENG, V33, P87, DOI 10.1109/TSE.2007.12
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   Hussain ZI, 2019, INT J INFORM MANAGE, V48, P218, DOI 10.1016/j.ijinfomgt.2018.09.014
   IEEE Std, 2017, 122072017 IEEE IEEE
   IEEE Std, 2018, 185762018 IEEE IEEE
   Prasetyo HN, 2018, P 2018 INT C IND ENT, P109
   Rose J, 2007, INFORM SOFTWARE TECH, V49, P605, DOI 10.1016/j.infsof.2007.02.005
   Rosemann M, 2008, MIS QUART, V32, P1
   Salminen A, 2000, INFORM PROCESS MANAG, V36, P623, DOI 10.1016/S0306-4573(99)00070-9
   Singhal Amit, 2017, ACM SIGIR Forum, V51, P176, DOI 10.1145/3130348.3130365
   SPRAGUE RH, 1995, MIS QUART, V19, P29, DOI 10.2307/249710
   Tang, 2019, WEB BASED COLLABORAT
   The Standish Group, 2014, 3 QUART RES REP
   Tsai, 2011, INT J ELECT BUS MANA, V9, P3
   Tsai WL, 2017, IN C IND ENG ENG MAN, P735, DOI 10.1109/IEEM.2017.8289988
   Uysal Murat Pasa, 2016, International Journal of Computer Theory and Engineering, V8, P328, DOI 10.7763/IJCTE.2016.V8.1066
   Whyte J, 2019, PROJ MANAG J, V50, P177, DOI 10.1177/8756972818823304
   Whyte J, 2016, INT J PROJ MANAG, V34, P339, DOI 10.1016/j.ijproman.2015.02.006
   Wong WY, 2018, 2018 IEEE CONFERENCE ON SYSTEMS, PROCESS AND CONTROL (ICSPC), P123, DOI 10.1109/SPC.2018.8703978
NR 26
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35069
EP 35082
DI 10.1007/s11042-021-10521-y
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000610019400014
DA 2024-07-18
ER

PT J
AU Wei, J
   Yang, XY
   Dong, YZ
AF Wei, Jie
   Yang, Xinyu
   Dong, Yizhuo
TI User-generated video emotion recognition based on key frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User-generated video; Emotion recognition; Key frames; Hybrid fusion
ID FEATURES
AB Video is an important medium in communication and entertainment, and thus, an intelligent understanding of videos has attracted widespread interest in academic community. Video content diversity and sparse emotional expression are challenging for video emotion recognition, especially for user-generated video. In this paper, we propose a key frames extraction algorithm based on affective saliency estimation. By estimating the affective saliency value of video frames, key frames are extracted to avoid the influence of emotion-independent frames on the recognition result. Efficient deep visual features are extracted using pretrained models and traditional models Support Vector Machine (SVM), Random Forests (RF) and deep model Convolutional Neural Networks (CNN) are used to perform emotion recognition. Moreover, we propose a hybrid fusion mechanism that combines score fusion and Top-K decision fusion to further improve recognition accuracy. Extensive experiments are conducted on user-generated video datasets Ekman-6 and VideoEmotion-8, and the average recognition accuracy are 59.51% and 52.85% respectively. The experimental results show that the proposed method can improve the recognition performance and is superior to the current user-generated video emotion recognition methods.
C1 [Wei, Jie; Yang, Xinyu; Dong, Yizhuo] Xi An Jiao Tong Univ, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Yang, XY (corresponding author), Xi An Jiao Tong Univ, Xian, Peoples R China.
EM yxyphd@mail.xjtu.edu.cn
OI WEI, JIE/0000-0003-2068-2363
CR Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   [Anonymous], 2016, Proceedings of the 24th ACM international conference on Multimedia, DOI DOI 10.1145/2964284.2967196
   Baveye Y, 2013, INT CONF AFFECT, P13, DOI 10.1109/ACII.2013.9
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen T., 2014, DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dhall A, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2993148.2997638
   Doherty AidenR., 2008, INT C CONTENT BASED, P259
   Gao JR, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P78, DOI 10.1145/3078971.3079030
   Ge HW, 2019, MULTIMED TOOLS APPL, V78, P20533, DOI 10.1007/s11042-019-7404-z
   Güder M, 2018, MULTIMEDIA SYST, V24, P55, DOI 10.1007/s00530-017-0535-z
   Guo F, 2018, IEEE T CYBERNETICS, V48, P3159, DOI 10.1109/TCYB.2017.2761361
   Guo SM, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P341
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang YG, 2014, AAAI CONF ARTIF INTE, P73
   Li D, 2019, IEEE T MULTIMEDIA, V21, P416, DOI 10.1109/TMM.2018.2862341
   Liu CH, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P630, DOI 10.1145/3242969.3264989
   Liu J, 2018, 2018 1 AS C AFF, P2018
   Liu Y, 2018, IEEE T CIRC SYST VID, V28, P3044, DOI 10.1109/TCSVT.2017.2713409
   Liu Y, 2019, IEEE T CYBERNETICS, V49, P159, DOI 10.1109/TCYB.2017.2769097
   Lu C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P646, DOI 10.1145/3242969.3264992
   Ly ST, 2019, IEEE COMPUT SOC CONF, P2927, DOI 10.1109/CVPRW.2019.00353
   Mo SS, 2018, NEUROCOMPUTING, V291, P11, DOI 10.1016/j.neucom.2018.02.052
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Okubo M., 2019, INT C HUM COMP INT, P254
   Pan XZ, 2020, IET IMAGE PROCESS, V14, P176, DOI 10.1049/iet-ipr.2019.0293
   Pang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P619, DOI 10.1145/2671188.2749400
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   SAMADIANI N, 2019, INT C DAT SERV, P275
   Shao L, 2019, IEEE T CYBERN, VPP, P1, DOI [10.1109/TCYB.2019.2942105, DOI 10.1109/TCYB.2019.2942105]
   Shinohara Y, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE/ INTELLIGENCE AND APPLIED INFORMATICS (CSII 2018), P133, DOI 10.1109/CSII.2018.00030
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Singhal A, 2018, COGN SYST RES, V52, P917, DOI 10.1016/j.cogsys.2018.09.019
   Soltanian M, 2019, IEEE T MULTIMEDIA, V21, P157, DOI 10.1109/TMM.2018.2844101
   Subramanian R., 2017, AFFECT RECOGNITION A
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tripathi A, 2019, IEEE ACCESS, V7, P51185, DOI 10.1109/ACCESS.2019.2911235
   Tu GY, 2020, IEEE T MULTIMEDIA, V22, P148, DOI 10.1109/TMM.2019.2922129
   Tu ZG, 2017, PATTERN RECOGN, V72, P285, DOI 10.1016/j.patcog.2017.07.028
   Wang JW, 2018, 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII ASIA)
   Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173
   Wang WG, 2017, IEEE T IMAGE PROCESS, V26, P5645, DOI 10.1109/TIP.2017.2745098
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   WangS Wang W X, 2017, P 19 ACM INT C MULTI, P598
   Wei W, 2020, J MULTIMODAL USER IN, V14, P17, DOI 10.1007/s12193-019-00308-9
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Xu BH, 2018, IEEE T AFFECT COMPUT, V9, P255, DOI 10.1109/TAFFC.2016.2622690
   Xu BH, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P15, DOI 10.1145/2911996.2912006
   Xu BH, 2016, IEEE MULTIMEDIA, V23, P23, DOI 10.1109/MMUL.2016.18
   Xu JC, 2018, INT C PATT RECOG, P2833, DOI 10.1109/ICPR.2018.8545441
   Xu WR, 2017, IEEE T MULTIMEDIA, V19, P1494, DOI 10.1109/TMM.2017.2674622
   Yadati K, 2014, IEEE T MULTIMEDIA, V16, P15, DOI 10.1109/TMM.2013.2282128
   Yang JF, 2017, AAAI CONF ARTIF INTE, P224
   Zhalehpour S, 2016, SIGNAL IMAGE VIDEO P, V10, P827, DOI 10.1007/s11760-015-0822-0
   Zhang HM, 2018, IEEE T MULTIMEDIA, V20, P2824, DOI 10.1109/TMM.2018.2808760
   Zhang Q, 2013, J HUM KINET, V39, P5, DOI 10.2478/hukin-2013-0063
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
NR 59
TC 19
Z9 19
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14343
EP 14361
DI 10.1007/s11042-020-10203-1
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400003
DA 2024-07-18
ER

PT J
AU Singh, YB
   Goel, S
AF Singh, Youddha Beer
   Goel, Shivani
TI An efficient algorithm for recognition of emotions from speaker and
   language independent speech using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human emotion recognition; Spectrogram; DCNN; Learning rate
ID FEATURES; CLASSIFIER
AB Automatic emotion recognition from speech is a demanding and challenging problem. It is difficult to differentiate between the emotional states of humans. The major problem with this task is to extract the important features from the speech in case of hand-crafted features. The accuracy for emotion recognition can be increased using deep learning approaches which use high level features of speech signals. In this work, an algorithm is proposed using deep learning to extract the high-level features from raw data with high accuracy irrespective of language and speakers (male/females) of speech corpora. For this, the .wav files are converted into the RGB spectrograms (images) and normalized to size (224x224x3) for fine-tuning these for Deep Convolutional Neural Network (DCNN) to recognize emotions. DCNN model is trained in two stages. From stage-1 the optimal learning rate is identified using the Learning Rate (LR) range test and then the model is trained again with optimal learning rate in stage-2. Special stride is used for down-sampling the features with reduced model size. The emotions considered are happiness, sadness, anger, fear, disgust, boredom/surprise and neutral. The proposed algorithm is tested on three popular public speech corpora EMODB (German), EMOVO (Italian), and SAVEE (British English). The accuracy of emotion recognition reported is better as compared to the existing studies for different languages and speakers.
C1 [Singh, Youddha Beer; Goel, Shivani] Bennett Univ, Sch Engn & Appl Sci, Comp Sci & Engn Dept, Greater Noida 201310, India.
   [Singh, Youddha Beer] Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida, UP, India.
C3 Galgotias College of Engineering & Technology (GCET)
RP Singh, YB (corresponding author), Bennett Univ, Sch Engn & Appl Sci, Comp Sci & Engn Dept, Greater Noida 201310, India.; Singh, YB (corresponding author), Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida, UP, India.
EM youddhabeer.singh@bennett.edu.in; shivani.goel@bennett.edu.in
RI Singh, Youddha Beer Beer/CAJ-4542-2022
OI Singh, Youddha Beer Beer/0000-0002-3745-2823
CR Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], 2008, TELEHEALTH ASSISTIVE
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Bitouk D, 2010, SPEECH COMMUN, V52, P613, DOI 10.1016/j.specom.2010.02.010
   Bou-Ghazale SE, 2000, IEEE T SPEECH AUDI P, V8, P429, DOI 10.1109/89.848224
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Chauhan Arun, 2010, Proceedings of the 2010 IEEE Students' Technology Symposium (TechSym 2010), P255, DOI 10.1109/TECHSYM.2010.5469162
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Farrús M, 2009, IET SIGNAL PROCESS, V3, P247, DOI 10.1049/iet-spr.2008.0147
   Fayek, 2015 9 INT C SIGN PR, P1, DOI 10.1109/ICSPCS.2015.7391796
   Firoz Shah A., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P162, DOI 10.1109/ACT.2009.49
   Han K, 2014, INTERSPEECH, P223
   Haq S., 2011, MACHINE AUDITION PRI, P398, DOI DOI 10.4018/978-1-61520-919-4.CH017
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Jawarkar NP, 2007, IETE TECH REV, V24, P369
   Khanchandani KB, 2009, J SCI IND RES INDIA, V68, P367
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Koolagudi SG, 2010, SPEECH PROS 5 INT C
   KOOLAGUDI SG, 2010, 2010 INT C SIGN PROC, P1
   Koolagudi SG, 2018, INT J SPEECH TECHNOL, V21, P167, DOI 10.1007/s10772-018-9495-8
   Koolagudi SG, 2009, COMM COM INF SC, V40, P485, DOI 10.1007/978-3-642-03547-0_46
   Kwon O.-W., 2003, Interspeech, P125
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Motamed S, 2017, BIOL INSPIR COGN ARC, V19, P32, DOI 10.1016/j.bica.2016.12.002
   Neiberg D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P809
   Nwe TL, 2001, IEEE REGION 10 INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC TECHNOLOGY, VOLS 1 AND 2, P297, DOI 10.1109/TENCON.2001.949600
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Parry J, 2019, INTERSPEECH, P1656, DOI 10.21437/Interspeech.2019-2753
   Partila P., 2013, NOSTRADAMUS 2013 PRE, P221, DOI DOI 10.1007/978-3-319-00542-3_23
   Peipei Shen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P621, DOI 10.1109/EMEIT.2011.6023178
   Pervaiz A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082326
   Polzehl T, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P340
   Prasomphan S, 2015, INT CONF SYST SIGNAL, P73, DOI 10.1109/IWSSIP.2015.7314180
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   Razak AA, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P297
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sato N., 2007, Information and Media Technologies, V2, P835, DOI [10.5715/jnlp.14.4_83, DOI 10.11185/IMT.2.835]
   Singh Youddha Beer, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P298, DOI 10.1109/ICACCCN.2018.8748379
   Steidl S, 2010, EURASIP J AUDIO SPEE, DOI 10.1155/2010/783954
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   Tang H, 2009, IEEE INT CON MULTI, P294, DOI 10.1109/ICME.2009.5202493
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wahlster Wolfgang, 2013, Verbmobil: foundations of speech-to-speech translation
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Yu D., 2016, AUTOMATIC SPEECH REC, VVolume 1
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zheng WM, 2014, IEEE SIGNAL PROC LET, V21, P569, DOI 10.1109/LSP.2014.2308954
   Zhou J, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P53
NR 57
TC 6
Z9 6
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14001
EP 14018
DI 10.1007/s11042-020-10399-2
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609068600004
DA 2024-07-18
ER

PT J
AU Lingwal, S
   Bhatia, KK
   Tomer, MS
AF Lingwal, Surabhi
   Bhatia, Komal Kumar
   Tomer, Manjeet Singh
TI Image-based wheat grain classification using convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image processing; Convolutional neural network;
   Classification; Wheat crops
ID COMPUTER VISION; RICE; DISCRIMINATION; TEXTURE
AB India is among the largest cultivators and consumers of wheat grains leading to apparent demand for identifying the quality and varietal distribution of wheat to fulfill the specific requirements of food industries. Moreover, with the variations in prices of distinct varieties in different parts of the country, it becomes a vital need for the customers as well as for the cultivators to identify and classify the grains based upon specific end products, demand, and prices of individual variety. The growth of Machine Learning and Computer Vision in agriculture, facilitate the development of such techniques that can successfully identify the classes based on visual features and representation. In this paper, a model has been developed from scratch for the classification of fifteen different varieties of wheat consists of 15000 images based on their visual traits using Convolutional Neural Network. The model has been produced under a different set of hyper-parameters tuned to develop the best model that can classify the varieties of wheat grains with high accuracy and minimum loss. The performance of the different models are compared in terms of classification accuracy and categorical cross-entropy loss. The model which is found best, successfully classifies the wheat varieties with 94.88% training accuracy and 97.53% test accuracy while on the other side reduces loss to 15% for training and 8% for the test set. Hence, the developed model can be deployed for the classification of different grain varieties, plant diseases, plant varieties, and several other fields under agriculture.
C1 [Lingwal, Surabhi] Govind Ballabh Pant Inst Engn & Technol, Pauri Garhwal, Uttarakhand, India.
   [Bhatia, Komal Kumar; Tomer, Manjeet Singh] JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Lingwal, S (corresponding author), Govind Ballabh Pant Inst Engn & Technol, Pauri Garhwal, Uttarakhand, India.
EM surabhi.lingwal@gmail.com; komal_bhatia1@rediffmail.com;
   mstomer2000@yahoo.com
RI Singh, Manjeet/GPF-8211-2022; bhatia, komal/R-2289-2019
OI Singh, Manjeet/0000-0003-4738-8033; bhatia, komal/0000-0002-1388-1252
CR [Anonymous], 2017, PROPERTIES SOFTMAX F
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Bi L, 2017, VISUAL COMPUT, V33, P1061, DOI 10.1007/s00371-017-1379-4
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Cao ZH, 2020, VISUAL COMPUT, V36, P1619, DOI 10.1007/s00371-019-01763-x
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Cheng SL, 2019, VISUAL COMPUT, V35, P1255, DOI 10.1007/s00371-018-1583-x
   Fujita E, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P989, DOI [10.1109/ICMLA.2016.56, 10.1109/ICMLA.2016.0178]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P163
   Günes EO, 2014, INT CONF AGRO-GEOINF, P216
   Ioffe S, 2015, ARXIV150203167
   Kaya Y, 2014, VISUAL COMPUT, V30, P71, DOI 10.1007/s00371-013-0782-8
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo TY, 2016, COMPUT ELECTRON AGR, V127, P716, DOI 10.1016/j.compag.2016.07.020
   Kurtulmus F, 2015, EXPERT SYST APPL, V42, P1880, DOI 10.1016/j.eswa.2014.10.003
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Mique EL, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEM (ICISS 2018), P147, DOI 10.1145/3209914.3209945
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Pazoki AR, 2014, J ANIM PLANT SCI-PAK, V24, P336
   Petrellis N., 2017, P 21 PAN HELLENIC C, P1, DOI [10.1145/3139367.3139368, DOI 10.1145/3139367.3139368]
   Sabanci K, 2017, J SCI FOOD AGR, V97, P3994, DOI 10.1002/jsfa.8264
   Sabanci K, 2017, J SCI FOOD AGR, V97, P2588, DOI 10.1002/jsfa.8080
   Sharma S, 2020, VISUAL COMPUT, V36, P1755, DOI 10.1007/s00371-019-01768-6
   Sivakumar V., 2013, Forest Science and Practice, V15, P253, DOI 10.1007/s11632-013-0414-4
   Uthayakumaran S, 2005, CEREALS
   Wang J., 2018, Revised Selected Papers, P319
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zapotoczny P, 2014, INT J FOOD PROP, V17, P139, DOI 10.1080/10942912.2011.615085
   Zareiforoush H, 2015, FOOD ENG REV, V7, P321, DOI 10.1007/s12393-014-9101-z
NR 36
TC 21
Z9 21
U1 6
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35441
EP 35465
DI 10.1007/s11042-020-10174-3
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000607776300010
DA 2024-07-18
ER

PT J
AU Ferraz, CT
   Barcellos, W
   Pereira, O
   Borges, TTN
   Manzato, MG
   Gonzaga, A
   Saito, JH
AF Toledo Ferraz, Carolina
   Barcellos, William
   Pereira Junior, Osmando
   Trevisan Negri Borges, Tamiris
   Garcia Manzato, Marcelo
   Gonzaga, Adilson
   Hiroki Saito, Jose
TI A comparison among keyframe extraction techniques for CNN classification
   based on video periocular images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocular recognition; Convolutional neural network; Transfer learning;
   Feature extraction; Kennard-stone
ID SELECTION
AB Training and validation sets of labeled data are important components used in supervised learning to build a classification model. During training, most learning algorithms use all images from the given training set to estimate the model's parameters. Particularly for video classification, it is required a keyframe extraction technique in order to select representative frames for training, which commonly is based on simple heuristics such as low level features frame difference. As some learning algorithms are noise sensitive, it is important to carefully select frames for training so that the model's optimization is accomplished more accurately and faster. We propose in this paper to analyze four methodologies for selecting representative frames of a periocular video database. One of them is based on the thresholds calculation (T), the other is a modified Kennard-Stone (KS) model, the thir method is based on sum of absolute difference in LUV colorspace and the last one is random sampling. To evaluate the selected image sets we use two deep network methodologies: feature extraction (FE) and fine tuning (FT). The results show that with a reduced amount of training images we can achieve the same accuracy of the complete database using the modified KS refinement methodology and the FT evaluation method.
C1 [Toledo Ferraz, Carolina; Hiroki Saito, Jose] UNIFACCAMP, Comp Sci Program, Campo Limpo Paulista, SP, Brazil.
   [Barcellos, William; Gonzaga, Adilson] Univ Sao Paulo, Dept Elect Engn, Sao Carlos, SP, Brazil.
   [Pereira Junior, Osmando] Fed Inst Triangulo Mineiro IFTM, Dept Elect Engn, Patrocinio, MG, Brazil.
   [Trevisan Negri Borges, Tamiris] Fed Inst Sao Paulo IFSP, Dept Matemath & Educ, Araraquara, SP, Brazil.
   [Garcia Manzato, Marcelo] Univ Sao Paulo, Dept Comp Sci, Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo; Instituto Federal de Sao Paulo (IFSP);
   Universidade de Sao Paulo
RP Ferraz, CT (corresponding author), UNIFACCAMP, Comp Sci Program, Campo Limpo Paulista, SP, Brazil.
EM caroltoledoferraz@gmail.com; william.barcellos@gmail.com;
   osmando@iftm.edu.br; tamirisnegri@ifsp.edu.br; mmanzato@icmc.usp.br;
   agonzaga@sc.usp.br; saitojosehiroki@gmail.com
RI Manzato, Marcelo/F-1255-2011; Toledo Ferraz, Carolina/O-6559-2016
OI Toledo Ferraz, Carolina/0000-0002-0867-6350
FU Capes (Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior)
   [001]
FX The authors would like to thank NVidia for GPU donation. We would also
   like to thank Capes (Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior) for financial support, financing code -001.
CR Al-Obaydy WNI, 2020, MULTIMED TOOLS APPL, V79, P2897, DOI 10.1007/s11042-019-08414-2
   Alonso-Fernandez F, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P536, DOI 10.1109/SITIS.2018.00087
   Ambika DR, 2012, INT CONF MULTIMED, P180, DOI 10.1109/ICMCS.2012.6320240
   Angiulli F, 2010, IEEE T NEURAL NETWOR, V21, P351, DOI 10.1109/TNN.2009.2039227
   [Anonymous], 2018, ARXIV180906157
   [Anonymous], 2015, IEEE C COMP VISION P
   [Anonymous], 2018, 2018 9 INT C COMP CO
   Asha Paul M.K., 2018, Recent Pat. Comput. Sci, V11, P3, DOI DOI 10.2174/2213275911666180719111118
   Balcazar J., 2001, Proc. 12th Int. Conf. Algorithmic Learning Theory, P119
   Barrett StevenF., 2019, Microchip AVR Microcontroller Primer: Programming and Interfacing, P1
   Capin, 2007, KEY FRAME EXTRACTION
   Cervantes J, 2015, APPL SOFT COMPUT, V37, P787, DOI 10.1016/j.asoc.2015.08.048
   de Almeida MB, 2000, SIXTH BRAZILIAN SYMPOSIUM ON NEURAL NETWORKS, VOL 1, PROCEEDINGS, P162, DOI 10.1109/SBRN.2000.889732
   de Sousa, 2008, THESIS U FEDERAL VIC
   de Sousa LC, 2011, CIENC FLOREST, V21, P591, DOI 10.5902/198050983817
   DESOUZA JM, 2019, MULTIMED TOOLS APPL
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Donahue J, 2014, PR MACH LEARN RES, V32
   Ferraz CT, 2018, WEBMEDIA'18: PROCEEDINGS OF THE 24TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB, P265, DOI 10.1145/3243082.3267444
   Gawande U, 2020, RECENT TRENDS COMPUT RECENT TRENDS COMPUT
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He K., 2018, arXiv
   Jogin Manjunath, 2018, 2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), P2319, DOI 10.1109/RTEICT42901.2018.9012507
   KENNARD RW, 1969, TECHNOMETRICS, V11, P137, DOI 10.2307/1266770
   Morais CLM, 2019, BIOINFORMATICS, V35, P5257, DOI 10.1093/bioinformatics/btz421
   Muhammad, 2018, PATTERN RECOGN LETT
   Nalepa J, 2019, ARTIF INTELL REV, V52, P857, DOI 10.1007/s10462-017-9611-1
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Nigam I, 2015, INFORM FUSION, V26, P1, DOI 10.1016/j.inffus.2015.03.005
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouyang SZ, 2018, IOP CONF SER-MAT SCI, V359, DOI 10.1088/1757-899X/359/1/012010
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Park, 2019, SENSORS BASEL SWITZE, V19
   Proenca, 2016, PERIOCULAR RECOGNITI, V19
   Proenca H, 2017, IEEE C COMP VIS PATT
   Qi X, 2018, INT CONF BIOMETR, P132, DOI 10.1109/ICB2018.2018.00030
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saptoro A, 2012, CHEM PROD PROCESS MO, V7, DOI 10.1515/1934-2659.1645
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P1, DOI 10.1002/9780470175637
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Tran L, 2020, IEEE ACCESS, V8, P12364, DOI 10.1109/ACCESS.2020.2966142
   Verbiest N, 2016, APPL SOFT COMPUT, V38, P10, DOI 10.1016/j.asoc.2015.09.006
   Yang HS, 2019, KSII T INTERNET INF, V13, P3074, DOI 10.3837/tiis.2019.06.017
NR 45
TC 2
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12843
EP 12856
DI 10.1007/s11042-020-10384-9
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607504000007
DA 2024-07-18
ER

PT J
AU Srivastava, AK
   Pandey, D
   Agarwal, A
AF Srivastava, Atul Kumar
   Pandey, Dhiraj
   Agarwal, Alok
TI Extractive multi-document text summarization using dolphin swarm
   optimization approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dolphin swarm optimization; Multi-document summarization; Modified
   normalized Google distance; Word mover distance; Similarity;
   Non-redundancy
ID MAXIMUM COVERAGE
AB Nowadays, extracting the desired information from internet source is a challenging task because of a large amount of information available on the internet. So, we propose a new extractive based approach for multi-document text summarization to extract useful information from multi-document. Initially, the redundant contents in the document create a single text file from the multiple text file document. The content coverage and non-redundancy features are achieved by Word Mover Distance (WMD) and Modified Normalized Google Distance (M-NGD) (WM) Hybrid Weight Method based similarity approaches. For feature weight optimization, we use the Dolphin swarm optimization (DSO) which is a metaheuristic approach. The proposed approach is tested under python with multiling 2013 dataset and the performances have been evaluated with ROUGE and AutoSummENG metrics. The investigational outcomes show that the proposed technique works well and very much effective for multi-document text summarization.
C1 [Srivastava, Atul Kumar] Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
   [Srivastava, Atul Kumar] Amity Univ, Sect 125, Noida, India.
   [Pandey, Dhiraj] AKTU, JSS Acad Tech Educ, Dept Comp Sci & Engn, Noida, India.
   [Agarwal, Alok] Univ Petr & Energy Studies, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Amity University
   Noida; University of Petroleum & Energy Studies (UPES)
RP Srivastava, AK (corresponding author), Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.; Srivastava, AK (corresponding author), Amity Univ, Sect 125, Noida, India.
EM phd.atulkumarsrivasta008@gmail.com
RI Srivastava, Atul Kumar/JED-6550-2023; Pandey, Dhiraj/W-1065-2018
OI Pandey, Dhiraj/0000-0001-5969-6071; Aggarwal, Dr.
   Shalini/0000-0001-9172-3420; Srivastava, Atul Kumar/0000-0002-9085-2842;
   Aggarwal, Alok/0000-0002-4394-4488
CR Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Alguliev RM, 2013, EXPERT SYST APPL, V40, P1675, DOI 10.1016/j.eswa.2012.09.014
   Alguliev RM, 2011, EXPERT SYST APPL, V38, P14514, DOI 10.1016/j.eswa.2011.05.033
   [Anonymous], 2004, PRINCIPLES READABILI
   Baralis E, 2015, ACM T INFORM SYST, V34, DOI 10.1145/2809786
   Conroy J, 2011, TAC, P1
   Conroy J. M., 2004, P DOC UND C DUC 2004
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Ferilli S, 2018, COMM COM INF SC, V806, P57, DOI 10.1007/978-3-319-73165-0_6
   Giannakopoulos G, 2011, TAC, P65
   Giannakopoulos George., 2013, P MULTILING 2013 WOR, P20
   Gillick D, 2008, TAC, P335
   Golding JM, 1998, INTENTIONAL FORGETTING: INTERDISCIPLINARY APPROACHES, P59
   Gross O, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1023, DOI 10.1145/2600428.2609500
   Hailu TT, 2020, INFORMATION, V11, DOI 10.3390/info11020078
   Khan A, 2018, INT J PARALLEL PROG, V46, P992, DOI 10.1007/s10766-018-0560-3
   Larson RR, 2010, J AM SOC INF SCI TEC, V61, P852, DOI 10.1002/asi.21234
   Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150
   Marujo L, 2016, KNOWL-BASED SYST, V94, P33, DOI 10.1016/j.knosys.2015.11.005
   Patel D, 2019, EXPERT SYST APPL, V134, P167, DOI 10.1016/j.eswa.2019.05.045
   Rautray Rasmita, 2018, Applied Computing and Informatics, V14, P134, DOI 10.1016/j.aci.2017.05.003
   Rautray R, 2017, PHYSICA A, V477, P174, DOI 10.1016/j.physa.2017.02.056
   Rezaei A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P680, DOI 10.1109/KBEI.2019.8735084
   Roul RK, 2019, LECT NOTES COMPUT SC, V11319, P212, DOI 10.1007/978-3-030-05366-6_17
   Sahba R, 2018, WORLD AUTOMAT CONG, P6
   Sanchez-Gomez JM, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106231
   Sanchez-Gomez JM, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112904
   Sanchez-Gomez JM, 2019, J PARALLEL DISTR COM, V134, P166, DOI 10.1016/j.jpdc.2019.09.001
   Sanchez-Gomez JM, 2018, KNOWL-BASED SYST, V159, P1, DOI 10.1016/j.knosys.2017.11.029
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Tohalino JV, 2018, PHYSICA A, V503, P526, DOI 10.1016/j.physa.2018.03.013
   Toman M., 2006, The 1st International Conference on Multidisciplinary Information Sciences Technologies, V4, P354
   Uçkan T, 2020, EGYPT INFORM J, V21, P145, DOI 10.1016/j.eij.2019.12.002
   Valladares-Valdes E., 2019, INT WORKSH SOFT COMP, P57
   Verma P, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1082-4
   Verma P, 2019, EXPERT SYST APPL, V120, P43, DOI 10.1016/j.eswa.2018.11.022
   Yao KC, 2018, NEUROCOMPUTING, V284, P52, DOI 10.1016/j.neucom.2018.01.020
   Zamanian M., 2012, THEORY PRACTICE LANG, V2, P43, DOI DOI 10.4304/TPLS.2.1.43-53
   Zhan ZH, 2009, IEEE T SYST MAN CY B, V39, P1362, DOI 10.1109/TSMCB.2009.2015956
NR 39
TC 8
Z9 8
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11273
EP 11290
DI 10.1007/s11042-020-10176-1
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605548700024
DA 2024-07-18
ER

PT J
AU Tausif, M
   Jain, A
   Khan, E
   Hasan, M
AF Tausif, Mohd
   Jain, Abhinandan
   Khan, Ekram
   Hasan, Mohd
TI Memory-efficient architecture for FrWF-based DWT of high-resolution
   images for IoMT applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Visual sensor networks; High-resolution
   images; Image coders; Low memory architecture; Internet of multimedia
   things
ID DISCRETE WAVELET TRANSFORM; SPEED VLSI IMPLEMENTATION; LINE-BASED
   ARCHITECTURE; HIGH-PERFORMANCE; LOW-POWER; ALGORITHM; INTERNET; DESIGN;
   THINGS; COMPRESSION
AB This paper proposes a simple low memory architecture for computing discrete wavelet transform (DWT) of high-resolution (HR) images on low-cost memory-constrained sensor nodes used in visual sensor networks (VSN) or Internet of Multimedia Things (IoMT). The main feature of the proposed architecture is the novel data scanning technique that makes memory requirement independent of the image size. The proposed architecture needs only (30S) words of memory, where S is the number of parallel processing units and a critical path delay (CPD) equal to the delay of a multiplier (T-m). Furthermore, a multiplierless version of this architecture is also proposed which reduces the CPD to T-a<T-m (where T-a is the delay of an adder). In order to evaluate their effectiveness, the proposed architectures are coded in HDL and implemented on same FPGA board. Their performance is also compared with other state-of-the-art low memory DWT architectures. The experimental results show the superiority of the proposed architectures in terms of memory and CPD compared to existing DWT architectures. Moreover, the reduction in CPD to T-a indicates that the operating frequency can be scaled up by several factors and can be chosen depending upon the application. Compared to one of the best state-of-the-art DWT architecture, proposed multiplierless architecture (with S = 4) needs 57.37% less LUT's and 64.39% less flip-flops for HR image of dimension 2048 x 2048. Moreover, the proposed architecture needs no LUTRAM and DSP, whereas the existing architecture requires 3264 LUTRAM and 24 DSP's. Thus the proposed multiplierless architecture is superior to the existing state-of-the-art architecture and is suitable for IoMT/VSNs.
C1 [Tausif, Mohd] Univ Beira Interior, Fac Engn, Dept Informat, Covilha, Portugal.
   [Jain, Abhinandan] MIT, Mit Media Lab, Cambridge, MA USA.
   [Khan, Ekram; Hasan, Mohd] Aligarh Muslim Univ, ZH Coll Engg, Dept Elect Engg, Aligarh, Uttar Pradesh, India.
C3 Universidade da Beira Interior; Massachusetts Institute of Technology
   (MIT); Aligarh Muslim University
RP Tausif, M (corresponding author), Univ Beira Interior, Fac Engn, Dept Informat, Covilha, Portugal.
EM mohdtausif32@gmail.com; abyjain007@gmai.com; ekhan67@gmail.com;
   mohdhasan097@gmail.com
RI Hasan, Mohd/JDD-4950-2023
OI Hasan, Mohd/0000-0002-9067-867X; TAUSIF, MOHD/0000-0002-5341-7948
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Acharya T, 2006, J VLSI SIG PROC SYST, V42, P321, DOI 10.1007/s11266-006-4191-3
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Andra K, 2002, IEEE T SIGNAL PROCES, V50, P966, DOI 10.1109/78.992147
   Bao YL, 2001, IEEE T CIRC SYST VID, V11, P642, DOI 10.1109/76.920193
   Bhattar RK, 2002, SIGNAL PROCESS-IMAGE, V17, P441, DOI 10.1016/S0923-5965(02)00019-X
   Çelik T, 2008, COMPUT VIS IMAGE UND, V111, P229, DOI 10.1016/j.cviu.2007.12.001
   Cheng C, 2008, IEEE T SIGNAL PROCES, V56, P393, DOI 10.1109/TSP.2007.900754
   Chew LW, 2012, INT J SENS NETW, V11, P33, DOI 10.1504/IJSNET.2012.045033
   Chew LW, 2009, EURASIP J EMBED SYST, DOI 10.1155/2009/479281
   Chia WC, 2012, INT J SENS NETW, V11, P22, DOI 10.1504/IJSNET.2012.045037
   Chiu MY, 2003, SIPS 2003: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P177, DOI 10.1109/SIPS.2003.1235665
   Chrysafis C, 2000, IEEE T IMAGE PROCESS, V9, P378, DOI 10.1109/83.826776
   Cosman P, 1998, IEEE SIGNAL PROC LET, V5, P221, DOI 10.1109/97.712104
   Darji A, 2015, IET COMPUT DIGIT TEC, V9, P113, DOI 10.1049/iet-cdt.2013.0167
   Darji AD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-47
   Di Martino B, 2018, INTERNET THINGS-NETH, V1-2, P99, DOI 10.1016/j.iot.2018.08.008
   Dillen G, 2003, IEEE T CIRC SYST VID, V13, P944, DOI 10.1109/TCSVT.2003.816518
   Divakara SS, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S0219467820500175
   Gardezi SEI, 2019, INT BHURBAN C APPL S, P548, DOI 10.1109/IBCAST.2019.8667215
   Hsia CH, 2013, IEEE T CIRC SYST VID, V23, P671, DOI 10.1109/TCSVT.2012.2211953
   Hsia CH, 2009, IEEE T CIRC SYST VID, V19, P1202, DOI 10.1109/TCSVT.2009.2020259
   Hu CK, 2004, SIGNAL PROCESS, V84, P1689, DOI 10.1016/j.sigpro.2004.05.014
   Hu YS, 2013, IEEE T SIGNAL PROCES, V61, P4975, DOI 10.1109/TSP.2013.2274640
   Hu YS, 2013, IEEE T CIRCUITS-II, V60, P502, DOI 10.1109/TCSII.2013.2268335
   Huang CT, 2005, IEEE T CIRC SYST VID, V15, P910, DOI 10.1109/TCSVT.2005.848307
   Huang CT, 2005, IEEE T SIGNAL PROCES, V53, P1575, DOI 10.1109/TSP.2005.843704
   Huang CT, 2004, IEEE T SIGNAL PROCES, V52, P1080, DOI 10.1109/TSP.2004.823509
   Javed F, 2018, IEEE COMMUN SURV TUT, V20, P2062, DOI 10.1109/COMST.2018.2817685
   Jiang WQ, 2001, IEEE T CIRC SYST VID, V11, P651, DOI 10.1109/76.920194
   Kannan P, 2019, INT RES J ENG TECHNO
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kumar G., 2019, INT J INTELLIGENT EN, V12, P148, DOI [10.22266/ijies2019.0630.16, DOI 10.22266/IJIES2019.0630.16]
   Lai YK, 2009, IEEE T CONSUM ELECTR, V55, P400, DOI 10.1109/TCE.2009.5174400
   Lan XG, 2005, IEEE T CONSUM ELECTR, V51, P379, DOI 10.1109/TCE.2005.1467975
   Liao HY, 2004, IEEE T SIGNAL PROCES, V52, P1315, DOI 10.1109/TSP.2004.826175
   Lin J, 2017, IEEE INTERNET THINGS, V4, P1125, DOI 10.1109/JIOT.2017.2683200
   Madanayake A, 2015, IEEE CIRC SYST MAG, V15, P25, DOI 10.1109/MCAS.2014.2385553
   Mei KZ, 2007, IEEE T CIRC SYST VID, V17, P1065, DOI 10.1109/TCSVT.2007.903555
   Mohanty BK, 2012, IEEE T CIRCUITS-II, V59, P434, DOI 10.1109/TCSII.2012.2200169
   Mohanty BK, 2011, IEEE T SIGNAL PROCES, V59, P2072, DOI 10.1109/TSP.2011.2109953
   Mohanty BK, 2013, IEEE T CIRC SYST VID, V23, P258, DOI 10.1109/TCSVT.2012.2203745
   Oliver J, 2008, IEEE T CIRC SYST VID, V18, P237, DOI 10.1109/TCSVT.2007.913962
   Rafi M., 2017, INT J ADV TELECOMMUN, V6, P24, DOI DOI 10.11601/ijates.v6i1.202
   Rani S, 2017, IEEE INTERNET THINGS, V4, P832, DOI 10.1109/JIOT.2017.2671460
   Rein S, 2008, P 4 INT ICST MOB MUL
   Rein S, 2011, AD HOC NETW, V9, P482, DOI 10.1016/j.adhoc.2010.08.004
   Rein S, 2011, IEEE COMMUN SURV TUT, V13, P291, DOI 10.1109/SURV.2011.100110.00059
   Savic G, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S0218126619501184
   Seo YH, 2007, IEEE J SOLID-ST CIRC, V42, P431, DOI 10.1109/JSSC.2006.889368
   Shi GM, 2009, IEEE T CIRCUITS-II, V56, P290, DOI 10.1109/TCSII.2009.2015393
   Song J, 2009, IEEE T CIRCUITS-II, V56, P916, DOI 10.1109/TCSII.2009.2035257
   Tausif M, 2018, IEEE SENSOR, P117
   Tausif M, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P593, DOI 10.1109/UPCON.2017.8251116
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Tian X, 2011, IEEE T COMPUT, V60, P1207, DOI 10.1109/TC.2010.178
   VISHWANATH M, 1994, IEEE T SIGNAL PROCES, V42, P673, DOI 10.1109/78.277863
   Wei-Hsin Chang, 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P330, DOI 10.1109/ISCAS.2001.922239
   Wu BF, 2006, IEEE T CIRCUITS-II, V53, P304, DOI 10.1109/TCSII.2005.862042
   Wu BF, 2005, IEEE T CIRC SYST VID, V15, P1615, DOI 10.1109/TCSVT.2005.858610
   Xiong CY, 2007, IEEE T IMAGE PROCESS, V16, P607, DOI 10.1109/TIP.2007.891069
   Xiong CY, 2006, IEEE T CIRC SYST VID, V16, P309, DOI 10.1109/TCSVT.2005.860121
   Yang CH, 2007, IEICE T FUND ELECTR, VE90A, P1062, DOI 10.1093/ietfec/e90-a.5.1062
   Ye LN, 2007, IEEE DATA COMPR CONF, P213
   Ye LN, 2015, IEEE T CIRC SYST VID, V25, P1773, DOI 10.1109/TCSVT.2015.2400776
   Ye LN, 2011, OPT ENG, V50, DOI 10.1117/1.3541802
   Zeng Y, 2019, COMPUT SCI ENG, V21, P18, DOI 10.1109/MCSE.2018.2882328
   Zhang CJ, 2012, IEEE T CIRCUITS-I, V59, P1775, DOI 10.1109/TCSI.2011.2180432
   Zhang W, 2012, IEEE T CIRCUITS-II, V59, P158, DOI 10.1109/TCSII.2012.2184369
   Zhang YF, 2016, J VIS COMMUN IMAGE R, V38, P297, DOI 10.1016/j.jvcir.2016.03.014
NR 70
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11177
EP 11199
DI 10.1007/s11042-020-10258-0
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604816600001
DA 2024-07-18
ER

PT J
AU Jahangir, R
   Teh, YW
   Hanif, F
   Mujtaba, G
AF Jahangir, Rashid
   Teh, Ying Wah
   Hanif, Faiqa
   Mujtaba, Ghulam
TI Deep learning approaches for speech emotion recognition: state of the
   art and research challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SER; Deep learning; Survey; Acoustic features; Emotional speech
   databases
ID NEURAL-NETWORKS; BELIEF NETWORKS; CHINESE SPEECH; MODEL; FEATURES;
   IDENTIFICATION; ARCHITECTURES; EXPRESSION; RECURRENT; ALGORITHM
AB Speech emotion recognition (SER) systems identify emotions from the human voice in the areas of smart healthcare, driving a vehicle, call centers, automatic translation systems, and human-machine interaction. In the classical SER process, discriminative acoustic feature extraction is the most important and challenging step because discriminative features influence the classifier performance and decrease the computational time. Nonetheless, current handcrafted acoustic features suffer from limited capability and accuracy in constructing a SER system for real-time implementation. Therefore, to overcome the limitations of handcrafted features, in recent years, variety of deep learning techniques have been proposed and employed for automatic feature extraction in the field of emotion prediction from speech signals. However, to the best of our knowledge, there is no in-depth review study is available that critically appraises and summarizes the existing deep learning techniques with their strengths and weaknesses for SER. Hence, this study aims to present a comprehensive review of deep learning techniques, uniqueness, benefits and their limitations for SER. Moreover, this review study also presents speech processing techniques, performance measures and publicly available emotional speech databases. Furthermore, this review also discusses the significance of the findings of the primary studies. Finally, it also presents open research issues and challenges that need significant research efforts and enhancements in the field of SER systems.
C1 [Jahangir, Rashid; Teh, Ying Wah] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Informat Syst, Kuala Lumpur 50603, Malaysia.
   [Jahangir, Rashid; Hanif, Faiqa] COMSATS Univ Islamabad, Dept Comp Sci, Vehari Campus, Islamabad, Pakistan.
   [Mujtaba, Ghulam] Sukkur IBA Univ, Dept Comp Sci, Ctr Excellence Robot Artificial Intelligence & Bl, Sukkur, Pakistan.
C3 Universiti Malaya; COMSATS University Islamabad (CUI); Sukkur IBA
   University
RP Jahangir, R; Teh, YW (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Informat Syst, Kuala Lumpur 50603, Malaysia.; Jahangir, R (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Vehari Campus, Islamabad, Pakistan.
EM rashidjahangir@ciitvehari.edu.pk; tehyw@um.edu.my
RI Jahangir, Rashid/AAT-6804-2021; TEH, YING WAH/B-9938-2010; Mujtaba,
   Ghulam/AAW-4254-2021
OI JAHANGIR, RASHID/0000-0003-1129-6006
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Adam TB, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P447, DOI 10.1109/ICSIPA.2013.6708048
   Alghamdi R, 2016, INT J ADV COMPUT SC, V7, P39
   Alotaibi Y, 2016, IEEE INT SYMP SIGNAL, P11, DOI 10.1109/ISSPIT.2016.7886001
   [Anonymous], 1997, P 5 EUROPEAN C SPEEC, DOI DOI 10.21437/EUROSPEECH.1997-494
   [Anonymous], 2000, ISCA TUT RES WORKSH
   [Anonymous], 2017, ARXIV170108071
   [Anonymous], 2016, IJCAI
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   [Anonymous], 2009, Automatic Classification of Emotion-Related User States in Spontaneous Children's Speech
   Anoop V, 2018, ADV INTELL SYST, V628, P393, DOI 10.1007/978-981-10-5272-9_36
   Arshad H, 2020, MULTILEVEL PARADIGM
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Automation C, 2010, CASIA CHINESE EMOTIO
   Aytar Y, 2016, ADV NEUR IN, V29
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bargal SA, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433, DOI 10.1145/2993148.2997627
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bhattacharjee U., 2013, Int. J. Eng. Res. Technol., V2, P1
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Brownlee J., 2019, Machine Learning Mastery
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cairong Z, 2016, J ELECT COMPUTER ENG
   Chen LF, 2020, INFORM SCIENCES, V509, P150, DOI 10.1016/j.ins.2019.09.005
   Chen R, 2018, COMMUNICATION, P122
   Choudhary, 2018, SPEECH LANGUAGE PROC, P195, DOI DOI 10.1007/978-981-10-6626-9_22
   Chung Junyoung, 2014, ARXIV14123555
   Coetzee H. J., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P596, DOI 10.1109/ICASSP.1989.266497
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Cutajar M, 2013, IET SIGNAL PROCESS, V7, P25, DOI 10.1049/iet-spr.2012.0151
   Degirmenci A., 2014, Introduction to Hidden Markov Models
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   Deng J, 2018, IEEE-ACM T AUDIO SPE, V26, P31, DOI 10.1109/TASLP.2017.2759338
   Deng J, 2017, IEEE ACCESS, V5, P5235, DOI 10.1109/ACCESS.2017.2672722
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   Deng L, 2014, T SIGNAL INFORM PROC, P3
   Deriche M, 2017, ARAB J SCI ENG, V42, P5231, DOI 10.1007/s13369-017-2742-5
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Dong L, 2017, DESTECH TRANS ENG, P195
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Endah SN, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS), P189, DOI 10.1109/ICICOS.2017.8276360
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Etienne C., 2018, P WORKSH SPEECH MUS, P21, DOI DOI 10.21437/SMM.2018-5
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Eyben F., 2009, 3 INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349350
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Fonnegra RD, 2018, LECT NOTES COMPUT SC, V10714, P882, DOI 10.1007/978-3-319-76270-8_59
   France DJ, 2000, IEEE T BIO-MED ENG, V47, P829, DOI 10.1109/10.846676
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Ghosh S, 2016, INTERSPEECH, P3603, DOI 10.21437/Interspeech.2016-692
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Gjoreski M, AUTOMATIC RECOGNITIO
   Gretton A, 2009, NEURAL INF PROCESS S, P131
   Gulli A., 2017, Deep learning with Keras
   Gulzar T., 2014, International Journal of Computer Applications, V101, P22, DOI DOI 10.5120/17740-8271
   Hajarolasvadi N, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050479
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   HANSEN JHL, 1995, SPEECH COMMUN, V16, P391, DOI 10.1016/0167-6393(95)00007-B
   Haq S., 2011, Machine Audition: Principles, Algorithms and Systems, P398
   He KY, 2014, C IND ELECT APPL, P1810, DOI 10.1109/ICIEA.2014.6931461
   Heracleous P, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220386
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Huang C, 2014, MATH PROBLEMS ENG
   Huang Y., 2016, INT J SIMULATION SYS, V17, P28
   Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
   Huang YM, 2014, COMM COM INF SC, V484, P436
   Huang ZW, 2015, FRONT INFORM TECH EL, V16, P358, DOI 10.1631/FITEE.1400323
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Hussain N, 2020, DEEP NEURAL NETWORK
   Ide H., 2017, 2017 International Joint Conference on Neural Networks (IJCNN), P2684, DOI DOI 10.1109/IJCNN.2017.7966185
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jarchi D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092594
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jian YL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061434
   JIANG W, 2019, SENSORS BASEL, V19
   KAISER JF, 1990, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1990.115702
   Kerkeni L, 2017, SPEECH EMOTION RECOG
   Keyvanrad M. A., 2014, ARXIV PREPRINT ARXIV
   Khalid S, 2019, IET INTELL TRANSP SY, V13, P269, DOI 10.1049/iet-its.2018.5223
   Khan H, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12432-6
   Kingma D. P., 2014, arXiv
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Lalitha S, 2015, PROCEDIA COMPUT SCI, V70, P29, DOI 10.1016/j.procs.2015.10.020
   Latha CP, 2016, ELECTRON J COMPUT SC, V1, P92
   Laydrus NC, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P135, DOI 10.1109/ICDSP.2007.4288537
   Le D, 2015, INT CONF AFFECT, P146, DOI 10.1109/ACII.2015.7344564
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li C, 2015, NEUROCOMPUTING, V168, P119, DOI 10.1016/j.neucom.2015.06.008
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Lopez-Moreno I, 2016, COMPUT SPEECH LANG, V40, P46, DOI 10.1016/j.csl.2016.03.001
   Lykartsis A., 2016, RHYTHM DESCRIPTION M
   Lyons J., 2013, PYTHON SPEECH FEATUR
   Mannepalli K, 2017, ALEX ENG J, V56, P485, DOI 10.1016/j.aej.2016.09.002
   Mannepalli K, 2016, INT J SPEECH TECHNOL, V19, P779, DOI 10.1007/s10772-016-9368-y
   Mano LY, 2016, COMPUT COMMUN, V89-90, P178, DOI 10.1016/j.comcom.2016.03.010
   Manolov A, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P354, DOI 10.1109/TSP.2017.8076004
   Mao QR, 2017, SPEECH COMMUN, V93, P1, DOI 10.1016/j.specom.2017.06.006
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   McCormick C, 2014, DEEP LEARNING TUTORI
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   McLoughlin IV, 1997, DSP 97: 1997 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P591, DOI 10.1109/ICDSP.1997.628419
   Meftah AH, 2018, IEEE ACCESS, V6, P72845, DOI 10.1109/ACCESS.2018.2881096
   Mehmood A, 2020, PROSPEROUS HUMAN GAI
   Mehta D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020416
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mesnil G., 2011, ICML WORKSH UNS TRA, P97
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   MicroPyramid, 2011, MICROPYRAMID
   Milton A., 2013, International Journal of Computer Applications, V69, DOI [DOI 10.5120/11872-7667, 10.5120/11872-7667]
   Mishra AN, 2010, PROC SPIE, V7546, DOI 10.1117/12.856318
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Molchanov Dmitry, 2017, P 34 INT C MACH LEAR, P2498
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Mu Y, 2017, DESTECH T COMPUTER S
   Muda Lindasalwa, 2010, Journal of Computing, DOI DOI 10.48550/ARXIV.1003.4083
   Mukherjee H, 2020, IMAGE BASED FEATURES
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Naz I, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500556
   Neiberg D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P809
   Neumann M, 2017, INTERSPEECH, P1263, DOI 10.21437/Interspeech.2017-917
   Ng A., 2017, Improving deep neural networks: hyperparameter tuning, regularization and optimization
   Ho NH, 2020, IEEE ACCESS, V8, P61672, DOI 10.1109/ACCESS.2020.2984368
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Pannu HS, 2020, DEEP LEARNING BASED
   Papakostas M, 2017, GENEDIS 2016, pSpringer
   Papakostas M, 2017, COMPUTATION, V5, DOI 10.3390/computation5020026
   Partila Pavol, 2015, ScientificWorldJournal, V2015, P573068, DOI 10.1155/2015/573068
   Pavez E, 2012, SPEECH COMMUN, V54, P814, DOI 10.1016/j.specom.2012.02.002
   Peng Wenshu., 2019, IEEE INT CONF AUTOMA, P1, DOI [DOI 10.1109/FG.2019.8756541, DOI 10.1109/fg.2019.8756541]
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pires EJS, 2010, NONLINEAR DYNAM, V61, P295, DOI 10.1007/s11071-009-9649-y
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Prabhakar O. P., 2013, INT J ADV RES COMPUT, V3
   Preeti, 2020, SCI TECHNOL MANAG, P33
   Rabiner L. R., 1975, Theory and application of digital signal processing
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Raj RJS, 2020, IEEE ACCESS, V8, P58006, DOI 10.1109/ACCESS.2020.2981337
   Ralph Abbey TH, 2017, SAS GLOB FOR ORL FLO
   Rana R, GATED RECURRENT UNIT
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Ruder S., 2016, ARXIV
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salakhutdinov R., 2010, JMLR WORKSHOP C P, P693
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Schaul T, 2010, J MACH LEARN RES, V11, P743
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Schuller B, 2010, P INTERSPEECH 2010 J, P2794
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Sezgin C, 2015, SPEECH COMMUN, V67, P26, DOI 10.1016/j.specom.2014.09.002
   Sezgin MC, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-16
   Shaburov V, 2017, GOOGLE PATENTS
   Shahsavarani S, 2018, SPEECH EMOTION RECOG
   Shami MT, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P366, DOI 10.1109/ICME.2005.1521436
   Sharma M, 2019, MULTIMED TOOLS APPL, V78, P16195, DOI 10.1007/s11042-018-7030-1
   Sivanagaraja T, 2017, ASIAPAC SIGN INFO PR, P189, DOI 10.1109/APSIPA.2017.8282026
   Soong F., 1984, P IEEE INT C AC SPEE, V9, P37
   Srikanth M, 2018, ADV INTELL SYST COMP, V678, P328, DOI 10.1007/978-3-319-67934-1_29
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stolar Melissa N., 2017, 2017 11 INT C SIGN P, P1, DOI [10.1109/ICSPCS.2017.8270472, DOI 10.1109/ICSPCS.2017.8270472]
   Sugiyama Masashi, 2008, Advances in Neural Information Processing Systems, P1433
   Sun LH, 2018, INT J SPEECH TECHNOL, V21, P931, DOI 10.1007/s10772-018-9551-4
   Sun Z, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P425
   Sunitha Ram C, 2014, 2014 INT C INF COMM, DOI 10.1109/ICICES.2014.7034102
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Talal A, 2020, WOODH PUBL SER BIOM, P1, DOI 10.1016/B978-0-08-102834-6.00001-X
   Tang Yichuan, 2013, CoRR
   Tawari A, 2010, IEEE T MULTIMEDIA, V12, P502, DOI 10.1109/TMM.2010.2058095
   Teager Herbert M., 1983, Speech Science: Recent Advances, P73
   TEAGER HM, 1980, IEEE T ACOUST SPEECH, V28, P599, DOI 10.1109/TASSP.1980.1163453
   Team TTD, 2016, ARXIV160502688
   Tong DL, 2010, INT J MACH LEARN CYB, V1, P75, DOI 10.1007/s13042-010-0004-x
   Torres-Carrasquillo P., 2002, 7 INT C SPOK LANG PR
   Trevisan MA, 2001, PHYS REV E, V63, DOI 10.1103/PhysRevE.63.026216
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Ververidis D, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1501
   Vincent E, 2008, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.2008.4517558
   vlab.amrita.edu, 2019, NONST NAT SPEECH SIG
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang F, 2016, IEEE ANN INT CONF CY, P308, DOI 10.1109/CYBER.2016.7574841
   Weishan Zhang, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P1313, DOI 10.1109/GreenCom-iThings-CPSCom.2013.228
   Wen GH, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1945630
   Weninger F, 2015, J MACH LEARN RES, V16, P547
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Wöllmer M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2362
   Wong E, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P95, DOI 10.1109/ISIMP.2001.925340
   Xiao MJ, 2016, INT CON DISTR COMP S, P721, DOI 10.1109/ICDCS.2016.15
   Xie Y, 2019, IEICE T INF SYST, VE102D, P1426, DOI 10.1587/transinf.2019EDL8019
   Yadav Kavita S., 2013, INT J SCI ENG, Vl, P61
   Yeh JH, 2011, COMPUT HUM BEHAV, V27, P1545, DOI 10.1016/j.chb.2010.10.027
   Yu Z, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P338, DOI 10.1109/ASRU.2015.7404814
   Zaidan NA, 2016, CHAM ADV MACHINE LEA, P141
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang SQ, 2016, COMM COM INF SC, V663, P645, DOI 10.1007/978-981-10-3005-5_53
   Zhang T, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P524, DOI 10.1109/ChinaSIP.2015.7230458
   Zhang WS, 2017, SOFTWARE PRACT EXPER, V47, P1127, DOI 10.1002/spe.2487
   Zhang WS, 2016, LECT NOTES COMPUT SC, V9677, P49, DOI 10.1007/978-3-319-39601-9_5
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhao ZP, 2019, IEEE ACCESS, V7, P97515, DOI 10.1109/ACCESS.2019.2928625
   Zheng WQ, 2015, INT CONF AFFECT, P827, DOI 10.1109/ACII.2015.7344669
   Zhu LZ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071694
   Zou CR, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/7437860
NR 225
TC 38
Z9 39
U1 2
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23745
EP 23812
DI 10.1007/s11042-020-09874-7
EA JAN 2021
PG 68
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000604225300001
DA 2024-07-18
ER

PT J
AU Li, XW
   Zhao, L
   Chen, GL
   Zhou, W
   Zhang, HY
   Pan, ZG
   Dong, QD
   Ling, J
AF Li, Xianwei
   Zhao, Liang
   Chen, Guolong
   Zhou, Wei
   Zhang, Haiyang
   Pan, Zhenggao
   Dong, Quande
   Ling, Jun
TI Performance and power consumption tradeoff in multimedia cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia cloud; QoS; QoE; Resource allocation
ID PROFIT MAXIMIZATION; SERVICE
AB With the rapidly growing adoption of mobile devices, such as smartphones and tablets, the Internet multimedia traffic generated by mobile users has increased. An important problem involves providing users with satisfactory multimedia services. Multimedia cloud is emerging as a specific computing paradigm to resolve the aforementioned issue by providing quality of service (QoS) provisioning for multimedia services. Given the emergence of multimedia cloud services, studies of multi-platform multimedia information analysis are significantly supported. However, because the multimedia cloud includes limited resources, the allocation of resources to satisfy user requirements with respect to QoS guaranteed multimedia services is a challenging task. Additionally, the rapidly growing demand for multimedia services motivates cloud service providers (CSPs) to deploy a great number of servers in their data centers. However, the power consumption of the servers is a matter of increasing concern for CSPs. In this study, we investigate the problem of optimal resource allocation in a multimedia cloud by considering two server models, namely the constant-speed model and idle-speed model. Our objective involves achieving the tradeoff between response time and power consumption in the two server models. With respect to each server model, we formulate an optimization problem and solve it by employing the Lagrangian multiplier method. We present numerical results to verify the effectiveness of the proposed method. The numerical results indicate that our proposed resource allocation scheme achieves both minimal response time and power consumption when compared with the existing allocation schemes.
C1 [Li, Xianwei; Chen, Guolong; Zhou, Wei; Pan, Zhenggao; Dong, Quande; Ling, Jun] Suzhou Univ, Sch Informat Engn, Suzhou, Peoples R China.
   [Li, Xianwei] Waseda Univ, Global Informat & Telecommun Inst, Tokyo, Japan.
   [Zhao, Liang] Shenyang Aerosp Univ, Sch Comp Sci, Shenyang, Peoples R China.
   [Zhang, Haiyang] Suzhou Univ, Sch Environm & Geomat Engn, Suzhou, Peoples R China.
C3 Waseda University; Shenyang Aerospace University; Suzhou University
RP Li, XW (corresponding author), Suzhou Univ, Sch Informat Engn, Suzhou, Peoples R China.; Li, XW (corresponding author), Waseda Univ, Global Informat & Telecommun Inst, Tokyo, Japan.
EM lixianwei163@163.com
RI Zhao, Liang/AAD-2705-2020
OI Zhao, Liang/0000-0001-5829-6850
CR [Anonymous], 2016, Cisco visual networking index: Forecast and methodology 2010-2015
   [Anonymous], IEEE T CLOUD COMPUT
   Borgolte K, 2018, PROCEEDINGS OF THE 2018 APPLIED NETWORKING RESEARCH WORKSHOP (ANRW '18), P4, DOI 10.1145/3232755.3232859
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cao JW, 2013, IEEE T PARALL DISTR, V24, P1087, DOI 10.1109/TPDS.2012.203
   Chen LJ, 2015, IEEE J SEL AREA COMM, V33, P2567, DOI 10.1109/JSAC.2015.2482098
   Daniel D, 2017, CLUSTER COMPUT, V20, P525, DOI 10.1007/s10586-017-0778-7
   Do CT, 2016, J NETW COMPUT APPL, V69, P152, DOI 10.1016/j.jnca.2016.04.012
   Dou H, 2017, IEEE T SUST COMPUT, V2, P211, DOI 10.1109/TSUSC.2017.2711925
   Feng Y, 2014, IEEE T COMPUT, V63, P59, DOI 10.1109/TC.2013.153
   Grosu D, 2005, J PARALLEL DISTR COM, V65, P1022, DOI 10.1016/j.jpdc.2005.05.001
   Guo Y., IEEE T CLOUD COMPUT
   Hao SJ, 2016, IEEE MULTIMEDIA, V23, P34, DOI 10.1109/MMUL.2016.17
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Khazaei H, 2012, IEEE T PARALL DISTR, V23, P936, DOI 10.1109/TPDS.2011.199
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Mei J, 2015, IEEE T COMPUT, V64, P3064, DOI 10.1109/TC.2015.2401021
   Nan XM, 2011, IEEE INT WORKSH MULT
   Ran YY, 2017, IEEE T SERV COMPUT, V10, P190, DOI 10.1109/TSC.2015.2464212
   Shojafar  M., IEEE T CLOUD COMPUT
   Su Z, 2016, IEEE T MULTIMEDIA, V18, P1650, DOI 10.1109/TMM.2016.2566584
   Tang JH, 2014, IEEE T MULTIMEDIA, V16, P1434, DOI 10.1109/TMM.2014.2308726
   Tian Y, 2014, CLUSTER COMPUT, V17, P943, DOI 10.1007/s10586-013-0326-z
   Wang M, IEEE T CIRC SYST VID
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181
   Wei L, 2017, IEEE T CIRC SYST VID, V27, P49, DOI 10.1109/TCSVT.2016.2589621
   Zhu JM, 2013, IEEE INT CONF CLOUD, P589, DOI 10.1109/CLOUD.2013.59
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 31
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33381
EP 33396
DI 10.1007/s11042-018-6833-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000004
DA 2024-07-18
ER

PT J
AU Wang, YD
   Zhang, HF
   Zhang, Z
   Long, Y
AF Wang, Yinduo
   Zhang, Haofeng
   Zhang, Zheng
   Long, Yang
TI Asymmetric graph based zero shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-shot learning; Asymmetric graph; Orthogonal projection; Self
   reconstruction
ID RECOGNITION
AB Zero-shot learning (ZSL) now has gained a great deal of focus due to its ability of recognizing unseen categories by training with samples of only seen categories. Existing efforts have been devoted to learn a projection between semantic space and feature space, which has made a big progress in ZSL. However, simply establishing a projection often suffers from the visual semantic ambiguity problem and hubness problem. Specifically, visual patterns and semantic concepts often can not properly match each other, and lead to inaccurate recognition result. To this end, in this paper, we propose a novel ZSL model, namely Asymmetric Graph-based Zero Shot Learning (AGZSL), to simultaneously preserve class level semantic manifold and instance level visual manifold in a latent space. In addition, to make the model more discriminative, we also constrain the latent space to be orthogonal, which means that the projected visual features and semantic embeddings in the latent space are orthogonal when they belong to different categories. We test our approach on four benchmark datasets under both standard zero-shot setting and more realistic generalized zero-shot learning (GZSL) setting, and the results show that our AGZSL can significantly improve the final performance comparing to the state-of-the-art methods.
C1 [Wang, Yinduo; Zhang, Haofeng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Zhang, Zheng] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
   [Long, Yang] Newcastle Univ, Sch Comp, Open Lab, Newcastle Upon Tyne, Tyne & Wear, England.
C3 Nanjing University of Science & Technology; University of Queensland;
   Newcastle University - UK
RP Zhang, HF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
EM wangyd@njust.edu.cn; zhanghf@njust.edu.cn; darrenzz219@gmail.com;
   yang.long@ieee.org
RI Zhang, Zhang/JAX-2097-2023; Zhang, Zheng/M-6325-2014
OI Zhang, Zheng/0000-0003-1470-6998
FU MRC [MR/S003916/1, MR/S003916/2] Funding Source: UKRI
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2016, BMVC
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen X, 2016, INT GEOSCI REMOTE SE, P5169, DOI 10.1109/IGARSS.2016.7730347
   Deutsch S., 2017, Proceedings of the IEEE conference on computer vision and pattern recognition, P7112
   Ding ZM, 2019, IEEE T PATTERN ANAL, V41, P2861, DOI 10.1109/TPAMI.2018.2867870
   Donahue J, 2014, PR MACH LEARN RES, V32
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Ferrari V., 2008, Proc. of NIPS'08, P433
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Ji Z, 2017, INFORM SCIENCES, V378, P48, DOI 10.1016/j.ins.2016.10.025
   Jiang B, 2017, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2017.66
   Jiang HJ, 2018, LECT NOTES COMPUT SC, V11214, P121, DOI 10.1007/978-3-030-01249-6_8
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P109
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li JJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P663, DOI 10.1145/3240508.3240579
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li J, 2017, LECT NOTES COMPUT SC, V10538, P193, DOI 10.1007/978-3-319-68155-9_15
   Li JJ, 2017, IEEE T CIRC SYST VID, V27, P1700, DOI 10.1109/TCSVT.2016.2539541
   Long Y, 2017, IEEE WINT CONF APPL, P907, DOI 10.1109/WACV.2017.106
   Massei S, 2018, SIAM J MATRIX ANAL A, V39, P1564, DOI 10.1137/17M1157155
   Norouzi M., 2014, P INT C LEARN REPR
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Recht B, 2012, Advances in Neural Information Processing Systems, P1214
   Sermanet P., 2014, INT C LEARN REPR
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Verma VK, 2017, LECT NOTES ARTIF INT, V10535, P792, DOI 10.1007/978-3-319-71246-8_48
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Yan H, 2018, PATTERN RECOGN, V74, P434, DOI 10.1016/j.patcog.2017.09.035
   Ye QL, 2018, IEEE T CIRC SYST VID, V28, P114, DOI 10.1109/TCSVT.2016.2596158
   Zhang HF, 2019, MULTIMED TOOLS APPL, V78, P24147, DOI 10.1007/s11042-018-6842-3
   Zhang HF, 2019, NEUROCOMPUTING, V329, P12, DOI 10.1016/j.neucom.2018.10.043
   Zhang HF, 2019, INFORM SCIENCES, V470, P43, DOI 10.1016/j.ins.2018.08.048
   Zhang HF, 2019, IEEE T IMAGE PROCESS, V28, P506, DOI 10.1109/TIP.2018.2869696
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang Z, 2015, ZERO SHOT LEARNING V, P6034
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 57
TC 12
Z9 15
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33689
EP 33710
DI 10.1007/s11042-019-7689-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000019
DA 2024-07-18
ER

PT J
AU Khanh, TL
   Kim, SH
   Lee, G
   Yang, HJ
   Baek, ET
AF Khanh, Trinh Le Ba
   Kim, Soo-Hyung
   Lee, Gueesang
   Yang, Hyung-Jeong
   Baek, Eu-Tteum
TI Korean video dataset for emotion recognition in the wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Facial expression; Emotion dataset
AB Emotion recognition is one of the hottest fields in affective computing research. Recognizing emotions is an important task for facilitating communication between machines and humans. However, it is a very challenging task based on a lack of ethnically diverse databases. In particular, emotional expressions tend to be very dissimilar between Western and Eastern people. Therefore, diverse emotion databases are required for studying emotional expression. However, majority of the well-known emotion databases focus on Western people, which exhibit different characteristics compared to Eastern people. In this study, we constructed a novel emotion dataset containing more than 1200 video clips collected from Korean movies, called Korean Video Dataset for Emotion Recognition in the Wild (KVDERW). Which are similar to real-world conditions, with the goal of studying the emotions of Eastern people, particularly Korean people. Additionally, we developed a semi-automatic video emotion labelling tool that could be used to generate video clips and annotate the emotions in clips.
C1 [Khanh, Trinh Le Ba; Kim, Soo-Hyung; Lee, Gueesang; Yang, Hyung-Jeong; Baek, Eu-Tteum] Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju, South Korea.
C3 Chonnam National University
RP Yang, HJ (corresponding author), Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju, South Korea.
EM hjyang@jnu.ac.kr
RI Yang, Hyung-Jeong/GXV-4819-2022
OI Le Ba Khanh, Trinh/0000-0003-1688-9003
FU National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [NRF-2020R1A4A1019191]; MSIT(Ministry of Science and ICT), Korea, under
   ITRC(Information Technology Research Center) support program
   [IITP-2020-2016-0-00314]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIT).
   (NRF-2020R1A4A1019191). The authors also thank Ms Tran Thi Dung for
   participation in revising of the manuscript. This research was supported
   by the MSIT(Ministry of Science and ICT), Korea, under the
   ITRC(Information Technology Research Center) support
   program(IITP-2020-2016-0-00314) supervised by the IITP(Institute for
   Information & communications Technology Planning & Evaluation).
CR Avola D., 2020, IEEE T AFFECTIVE COM, DOI 10.1109/TAFFC.2020.3003816
   Benitez-Garcia G., 2017, J SIGNAL INFORM PROC, V8, P78
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P653
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Douglas-Cowie E., 2000, NEW EMOTION DATABASE, P3944
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Jack Rachael E, 2009, Curr Biol, V19, P1543, DOI 10.1016/j.cub.2009.07.051
   Kolakowska A, 2014, ADV INTELL SYST, V300, P51, DOI 10.1007/978-3-319-08491-6_5
   Li Shan, 2018, arXiv:1804.08348
   Lim N, 2016, INTEGR MED RES, V5, P105, DOI 10.1016/j.imr.2016.03.004
   MUSZYNSKI M, 2019, IEEE T AFFECTIVE COM
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Yu KM, 2013, PATTERN RECOGN, V46, P2144, DOI 10.1016/j.patcog.2013.01.032
   Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P1980, DOI 10.1109/CVPRW.2017.248
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P1067, DOI 10.1016/j.imavis.2014.09.005
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 21
TC 12
Z9 12
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9479
EP 9492
DI 10.1007/s11042-020-10106-1
EA NOV 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588276000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Sridhar, B
   Syambabu, V
AF Sridhar, B.
   Syambabu, V.
TI Security enhancement in video based on gatefold technique for copyright
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Copyright protection; Cross-layered embedding; Gate
   folding approach; Watermarking; Wavelet transform
ID WATERMARKING; ROBUST
AB Watermarking of multimedia gives more attention to the research society. This paper presents the non-blind watermarking technique on video; initially, a watermark is reshaped and grouped into odd and even row images. Next, the luminance band of the frame is shared into alternative pixel shares and it is concatenated. Further, gatefold operation is enabled on a concatenated luminance band. Now, single-level decomposition is imposed on the gatefold image and, the copyright marking process is enabled only on the medium level of frequency sub-bands. To enrich the robustness of the technique the marking fashion is in the upper diagonal layer region of wavelet sub-band. Next, an inverse wavelet is imposed to obtain the gate folded marked cover image. Further, the reverse process can be carried out to obtain the watermarked video frame. To prove authorship the cover and copyrighted image has subject to the same procedure and acquires the marked information. The main objective is to design and develop a gatefold based video authentication approaches with ownership information that can be used for copyright protection. Also increase the robustness, payload, and minimize the bit error rate.
C1 [Sridhar, B.; Syambabu, V.] MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
C3 MLR Institute of Technology
RP Sridhar, B (corresponding author), MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
EM sridharbece@gmail.com
RI Balakrishnan, Sridhar/AAA-4514-2021
OI Balakrishnan, Sridhar/0000-0002-3144-7468
CR Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Amiri MD, 2019, MULTIMEDIA SYST, V25, P273, DOI 10.1007/s00530-019-00604-0
   [Anonymous], 2003, Techniques and Applications of Digital Watermarking and Content Protection
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Bhatnagar G, 2012, SADHANA-ACAD P ENG S, V37, P371, DOI 10.1007/s12046-012-0081-5
   Busch C, 1999, IEEE COMPUT GRAPH, V19, P25, DOI 10.1109/38.736466
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Huang H.-Y., 2007, P MACH VIS APPL, P256
   Karpe KS, 2014, INT C EL COMM ENG IC
   Lee MJ, 2012, DIGIT SIGNAL PROCESS, V22, P190, DOI 10.1016/j.dsp.2011.08.001
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rajab Lama., 2009, EUR J SCI RES, V30, P389
   Sahu N, 2017, J VIS COMMUN IMAGE R, V45, P77, DOI 10.1016/j.jvcir.2017.02.013
   Sathya SPA, 2020, IET IMAGE PROCESS, V14, P366, DOI 10.1049/iet-ipr.2019.0341
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Sridhar B., 2018, Pattern Recognition and Image Analysis, V28, P537, DOI 10.1134/S1054661818030203
   Sridhar B, 2016, J COMMUN TECHNOL EL+, V61, P165, DOI 10.1134/S1064226916020042
   Vural C, 2015, SIGNAL IMAGE VIDEO P, V9, P1613, DOI 10.1007/s11760-014-0618-7
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
NR 23
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8241
EP 8256
DI 10.1007/s11042-020-09909-z
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000583128500001
DA 2024-07-18
ER

PT J
AU Katoch, S
   Chauhan, SS
   Kumar, V
AF Katoch, Sourabh
   Chauhan, Sumit Singh
   Kumar, Vijay
TI A review on genetic algorithm: past, present, and future
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Optimization; Metaheuristic; Genetic algorithm; Crossover; Mutation;
   Selection; Evolution
ID SUPPORT VECTOR REGRESSION; INVENTORY-ROUTING PROBLEM; COLOR IMAGE
   SEGMENTATION; MULTIOBJECTIVE OPTIMIZATION; SEARCH ALGORITHM; LOCAL
   SEARCH; DESIGN; NETWORK; MODEL; PERFORMANCE
AB In this paper, the analysis of recent advances in genetic algorithms is discussed. The genetic algorithms of great interest in research community are selected for analysis. This review will help the new and demanding researchers to provide the wider vision of genetic algorithms. The well-known algorithms and their implementation are presented with their pros and cons. The genetic operators and their usages are discussed with the aim of facilitating new researchers. The different research domains involved in genetic algorithms are covered. The future research directions in the area of genetic operators, fitness function and hybrid algorithms are discussed. This structured review will be helpful for research and graduate teaching.
C1 [Katoch, Sourabh; Chauhan, Sumit Singh; Kumar, Vijay] Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Kumar, V (corresponding author), Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur, India.
EM vijaykumarchahar@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989
CR Abbasi M, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-0157-4
   Abdelghany A, 2017, COMPUT OPER RES, V87, P20, DOI 10.1016/j.cor.2017.05.013
   Abdulal W., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P673, DOI 10.1109/CSNT.2011.145
   Abdullah J, 2010, INT J GRID DISTRIB, V3, P57
   Abo-Elnaga Y, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050767
   Afrouzy ZA, 2016, COMPUT IND ENG, V101, P440, DOI 10.1016/j.cie.2016.09.008
   Ahmed D, 2011, INT J ENDOCRINOL, V2011, DOI 10.1155/2011/530274
   Aiello G, 2012, EXPERT SYST APPL, V39, P10352, DOI 10.1016/j.eswa.2012.01.125
   Al-Oqaily AT, 2018, INT CONF COMP SCI, P103, DOI 10.1109/CSIT.2018.8486176
   Alaoui N, 2020, IET IMAGE PROCESS, V14, P289, DOI 10.1049/iet-ipr.2019.0566
   Alkhafaji B.J., 2020, Periodicals of Engineering and Natural Sciences, V8, P1106, DOI [10.21533/pen.v8i2.1351, DOI 10.21533/PEN.V8I2.1351]
   Alves MJ, 2007, COMPUT OPER RES, V34, P3458, DOI 10.1016/j.cor.2006.02.008
   [Anonymous], 2004, P 2004ACM S APPL COM
   [Anonymous], 2018, ADV CONDENS MATTER P, DOI DOI 10.1109/ISCAS.2018.8351098
   [Anonymous], 2000, TECH REP
   Arakaki RK, 2018, COMPUT OPER RES, V90, P221, DOI 10.1016/j.cor.2017.09.020
   Arkhipov DI, 2020, IEEE ACCESS, V8, P106506, DOI 10.1109/ACCESS.2020.2997812
   Azadeh A, 2017, COMPUT IND ENG, V104, P124, DOI 10.1016/j.cie.2016.12.019
   Baker James Edward, 2014, P 1 INT C GEN ALG TH, P101
   Bolboaca SD, 2010, NOT BOT HORTI AGROBO, V38, P51
   Bonabeau E., 1999, NATURAL ARTIFICIAL S
   Burchardt H, 2006, IEEE C EVOL COMPUTAT, P1816
   Burdsali B., 1997, ISFL'97. Second International ICSC Symposium on Fuzzy Logic and Applications, P217
   Burkowski F. J., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1574, DOI 10.1109/CEC.1999.782671
   Chaiyaratana N, 2000, IEEE C EVOL COMPUTAT, P22, DOI 10.1109/CEC.2000.870271
   Chen R, 2015, APPL SOFT COMPUT, V26, P435, DOI 10.1016/j.asoc.2014.10.022
   Cheng H, 2010, PROCEEDINGS OF THE ASME DYNAMIC SYSTEMS AND CONTROL CONFERENCE 2010, VOL 2, P563
   Cheng H, 2013, EXPERT SYST APPL, V40, P1381, DOI 10.1016/j.eswa.2012.08.050
   Cheng JR, 2022, INT J INTELL SYST, V37, P10100, DOI 10.1002/int.22310
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Chuang YC, 2016, APPL SOFT COMPUT, V38, P87, DOI 10.1016/j.asoc.2015.09.036
   Coello CAC, 2001, LECT NOTES COMPUT SC, V1993, P126
   Das AK, 2018, DIRECTION BASED EXPO
   Das KN, 2014, ADV COMPU INTELL ROB, P268, DOI 10.4018/978-1-4666-4936-1.ch010
   Dash SR, 2013, IEEE INT ADV COMPUT, P631
   Datta D, 2011, EUR J OPER RES, V213, P388, DOI 10.1016/j.ejor.2011.03.034
   de Ocampo ALP, 2017, I C HUMANOID NANOTEC
   de Paiva JL, 2016, APPL SOFT COMPUT, V46, P778, DOI 10.1016/j.asoc.2015.09.013
   Deb Kalyanmoy, 2014, International Journal of Artificial Intelligence and Soft Computing, V4, P1, DOI 10.1504/IJAISC.2014.059280
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 1995, Complex Systems, V9, P115
   Deep K, 2008, APPL MATH COMPUT, V203, P86, DOI 10.1016/j.amc.2008.04.021
   Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046
   Deep K, 2007, APPL MATH COMPUT, V188, P895, DOI 10.1016/j.amc.2006.10.047
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Di Fatta G, 2003, IEEE T SYST MAN CY C, V33, P313, DOI 10.1109/TSMCC.2003.818946
   Diabat A, 2016, J MANUF SYST, V38, P172, DOI 10.1016/j.jmsy.2015.04.011
   Díaz-Manríquez A, 2018, IEEE ACCESS, V6, P21552, DOI 10.1109/ACCESS.2018.2815992
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Ebrahimzadeh Reza, 2013, International Journal of Intelligent Systems and Applications, V5, P19, DOI 10.5815/ijisa.2013.05.03
   EkbataniFard G. Hossein, 2010, 2010 5th International Symposium on Wireless Pervasive Computing (ISWPC), P80, DOI 10.1109/ISWPC.2010.5483775
   El-Mihoub T. A., 2006, Engineering Letters, V13, P124
   Elmihoub T, 2004, ESM'2004: 18TH EUROPEAN SIMULATION MULTICONFERENCE, P154
   Emmerich MTM, 2018, NAT COMPUT, V17, P585, DOI 10.1007/s11047-018-9685-y
   ESHELMAN LJ, 1997, BIASES CROSSOVER LAN
   Espinoza FP, 2003, LECT NOTES COMPUT SC, V2723, P922
   Farahani RZ, 2008, INT J PROD ECON, V111, P229, DOI 10.1016/j.ijpe.2006.11.028
   FONSECA CM, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P416
   Fox B., 1991, FDN GENETIC ALGORITH, P284, DOI DOI 10.1016/B978-0-08-050684-5.50021-5
   Freisleben B., 1996, Parallel Problem Solving from Nature - PPSN IV. International Conference on Evolutionary Computation - The 4th International Conference on Parallel Problem Solving from Nature. Proceedings, P890, DOI 10.1007/3-540-61723-X_1052
   Friend DH, 2008, CONSUM COMM NETWORK, P993, DOI 10.1109/ccnc08.2007.228
   Fuertes G, 2019, CHAOTIC GENETIC ALGO
   Ghaheri Ali, 2015, Oman Med J, V30, P406, DOI 10.5001/omj.2015.82
   Ghosh S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106692
   Ghoshal AK, 2019, INT CONF COMMUN SYST, P130, DOI [10.1109/COMSNETS.2019.8711127, 10.1109/comsnets.2019.8711127]
   Gogna A, 2012, INT J MET, V2
   Goldberg D. E., 1985, P 1 INT C GEN ALG TH, P154
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Guido R, 2017, COMPUT OPER RES, V87, P270, DOI 10.1016/j.cor.2016.11.009
   HajiRassouliha A, 2013, INT CONF IMAG VIS, P352, DOI 10.1109/IVCNZ.2013.6727067
   Harada T, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3400031
   Harik GR, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P258
   Hassanat A, 2019, INFORMATION, V10, DOI 10.3390/info10120390
   He J, 2012, INT J SENS NETW, V11, P166, DOI 10.1504/IJSNET.2012.046331
   Hedar AR, 2003, ADV SOFT COMP, P135
   Helal MHS, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATION AND ENGINEERING (IEEE-ICICE 2017), P535, DOI 10.1109/ICICE.2017.8478917
   Hiassat A, 2017, J MANUF SYST, V42, P93, DOI 10.1016/j.jmsy.2016.10.004
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Hong TP, 2014, EXPERT SYST APPL, V41, P655, DOI 10.1016/j.eswa.2013.07.090
   Hong WC, 2011, APPL SOFT COMPUT, V11, P1881, DOI 10.1016/j.asoc.2010.06.003
   Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37
   Hu C, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1757
   Hussain A, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/7430125
   Ishibuchi H, 1998, IEEE T SYST MAN CY C, V28, P392, DOI 10.1109/5326.704576
   Jafari A, 2020, IEEE ACCESS, V8, P2417, DOI 10.1109/ACCESS.2019.2962153
   Jaszkiewicz A, 2002, EUR J OPER RES, V137, P50, DOI 10.1016/S0377-2217(01)00104-7
   Javidi M, 2015, INT ARAB J INF TECHN, V12, P163
   Jebari K., 2013, International Journal of Emerging Sciences, V3, P333, DOI DOI 10.14355/ijes.2013.0305.05
   Jiang MY, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P235, DOI 10.1109/ICACI.2018.8377612
   Jiang SC, 2017, EXPERT SYST APPL, V82, P216, DOI 10.1016/j.eswa.2017.04.017
   Kaluri R., 2016, Int. J. Intell. Eng. Syst, V9, P225, DOI [10.22266/ijies2016.1231.24, DOI 10.22266/IJIES2016.1231.24]
   Kandavanam G, 2010, LECT NOTES COMPUT SC, V5975, P49, DOI 10.1007/978-3-642-14156-0_5
   Kannan S, 2020, SIGNAL IMAGE VIDEO P, V14, P877, DOI 10.1007/s11760-019-01619-w
   Katz P, 2001, SPIE NEWSROOM, P201
   KAUR G, 2018, SENSORS IMAGE PROCES, P255, DOI DOI 10.1007/978-981-10-6614-6_26
   Kaur M, 2018, IMAGING SCI J, V66, P453, DOI 10.1080/13682199.2018.1505327
   Kaur M, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418501328
   Kaur M, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501154
   Kavitha AR, 2016, IMAGING SCI J, V64, P285, DOI 10.1080/13682199.2016.1178412
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan A, 2019, SIGNAL IMAGE VIDEO P, V13, P833, DOI 10.1007/s11760-019-01419-2
   Kia R, 2014, J MANUF SYST, V33, P218, DOI 10.1016/j.jmsy.2013.12.005
   Kim EY, 2006, PATTERN RECOGN LETT, V27, P1252, DOI 10.1016/j.patrec.2005.07.023
   Kim EY, 2005, PATTERN RECOGN, V38, P59, DOI 10.1016/j.patcog.2004.06.004
   Kita H., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1581, DOI 10.1109/CEC.1999.782672
   Kobayashi H., 2004, Systems and Computers in Japan, V35, P37, DOI 10.1002/scj.10350
   Konak A., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1817, DOI 10.1109/CEC.1999.785495
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Krishnan N, 2013, LECT NOTES COMPUTER, V8284
   Kumar A., 2013, Int. J. Adv. Res. Eng, V2, P1
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Kumar V, 2017, ADV ENG SOFTW, V112, P231, DOI 10.1016/j.advengsoft.2017.05.008
   Kumar V, 2014, J COMPUT SCI-NETH, V5, P144, DOI 10.1016/j.jocs.2013.12.001
   Kurdi M, 2016, COMPUT OPER RES, V67, P132, DOI 10.1016/j.cor.2015.10.005
   Larrañaga P, 1999, ARTIF INTELL REV, V13, P129, DOI 10.1023/A:1006529012972
   Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827
   Lee CKH, 2018, ENG APPL ARTIF INTEL, V76, P1, DOI 10.1016/j.engappai.2018.08.011
   Lee CY, 2003, IEEE T SYST MAN CY B, V33, P138, DOI 10.1109/TSMCB.2003.808184
   Lee JY, 2007, PROCEEDINGS OF SICE ANNUAL CONFERENCE, VOLS 1-8, P2685
   Lee Y, 2001, IEEE T MED IMAGING, V20, P595, DOI 10.1109/42.932744
   Leng LT, 1999, THESIS U ESSEX
   Li B, 2015, ACM COMPUTING SURVEY
   Lim Siew Mooi, 2017, International Journal of Machine Learning and Computing, V7, P9, DOI 10.18178/ijmlc.2017.7.1.611
   Lima SJD, 2018, LECT NOTES COMPUT SC, V10835, P174, DOI 10.1007/978-3-319-91641-5_15
   Liu DH, 2019, J COMPUT METHODS SCI, V19, pS131, DOI 10.3233/JCM-191019
   Liu ZY, 2013, TRANSPORT RES C-EMER, V31, P83, DOI 10.1016/j.trc.2013.02.012
   Lorenzo B, 2013, IEEE T MOBILE COMPUT, V12, P2274, DOI 10.1109/TMC.2012.204
   LUCASIUS CB, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P170
   Luo B, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS, P580, DOI 10.1109/ICNC.2008.532
   Maghawry A, 2020, INT J COMPUT INT SYS, V13, P223, DOI 10.2991/ijcis.d.200214.001
   Manzoni L, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100646
   Mazinani M, 2013, INT J ADV MANUF TECH, V65, P929, DOI 10.1007/s00170-012-4229-6
   Mehboob U, 2016, SOFT COMPUT, V20, P2467, DOI 10.1007/s00500-016-2070-9
   Michalewicz Z, 1996, EVOL COMPUT, V4, P1, DOI 10.1162/evco.1996.4.1.1
   Michalewicz Zbigniew, 1992, GENETIC ALGORITHMS D, DOI [DOI 10.1007/978-3-662-02830-8, 10.1007/978-3-662-02830-8]
   Mishra R, 2017, ADV KNOWL ACQUISITIO, P230, DOI 10.4018/978-1-5225-2375-8.ch009
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Mudaliar DN, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P127, DOI 10.1109/ICSIPR.2013.6497974
   Murata Tadahiko., 2002, PROC 4 ASIAN FUZZY S, P538
   Neto JC, 2006, COMPUT ELECTRON AGR, V51, P66, DOI 10.1016/j.compag.2005.11.002
   Ono I., 1997, P 7 INT C GENETIC AL, P246
   Pachepsky Y, 1998, GEODERMA, V85, P213, DOI 10.1016/S0016-7061(98)00021-4
   Palomo-Romero JM, 2017, EXPERT SYST APPL, V68, P151, DOI 10.1016/j.eswa.2016.10.004
   PANDIAN S, 2009, ADV LOGISTIC SYSTEMS, V3, P63
   Park YB, 2016, EXPERT SYST APPL, V53, P149, DOI 10.1016/j.eswa.2016.01.041
   Patel R, 2012, DECOMPOSITION BASED
   Pattanaik Jagat Kishore, 2018, Journal of Electrical Systems and Information Technology, V5, P349, DOI 10.1016/j.jesit.2018.03.002
   PAYNE AWR, 1993, J MOL GRAPHICS, V11, P74, DOI 10.1016/0263-7855(93)87001-L
   Peerlinck A, 2019, IEEE C EVOL COMPUTAT, P1838, DOI [10.1109/CEC.2019.8790267, 10.1109/cec.2019.8790267]
   Pilat M.L., 2002, Ant Algorithms. ANTS 2002, P282
   Pinagapany S, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P239, DOI 10.1109/COMSWA.2008.4554416
   Pinel F, 2013, J PARALLEL DISTR COM, V73, P101, DOI 10.1016/j.jpdc.2012.02.018
   Pinto G, 2009, COMPUT IND ENG, V57, P1131, DOI 10.1016/j.cie.2009.05.003
   Piszcz A, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P953
   Porta J, 2013, COMPUT ENVIRON URBAN, V37, P45, DOI 10.1016/j.compenvurbsys.2012.05.003
   Ha QM, 2020, J HEURISTICS, V26, P219, DOI 10.1007/s10732-019-09431-y
   Rafsanjani Marjan Kuchaki, 2020, International Journal of Advanced Intelligence Paradigms, V16, P157
   Palencia AER, 2012, INT J PROD ECON, V140, P431, DOI 10.1016/j.ijpe.2012.06.026
   Rathi R, 2018, ARAB J SCI ENG, V43, P4215, DOI 10.1007/s13369-017-2838-y
   Rathi R., 2018, International Journal of Fuzzy Systems Applications, V7, P74, DOI 10.4018/IJFSA.2018010106
   Rathi R, 2020, COMP STUDY GENETIC A
   Ray SS, 2004, INT C PATT RECOG, P497, DOI 10.1109/ICPR.2004.1334276
   Richter JN, 2002, INT C ART NEUR NETW
   Riedl A, 2002, 2002 IEEE WORKSHOP ON IP OPERATIONS AND MANAGEMENT, P166, DOI 10.1109/IPOM.2002.1045774
   Ripon KSN, 2011, EVOL SYST-GER, V2, P119, DOI 10.1007/s12530-010-9022-x
   Roberge V, 2014, IEEE T POWER ELECTR, V29, P5087, DOI 10.1109/TPEL.2014.2311737
   Ronald S, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P43, DOI 10.1109/ICEC.1997.592265
   Roy A, 2002, IEEE VTS VEH TECHNOL, P1160, DOI 10.1109/VTC.2002.1002796
   Sadrzadeh A, 2012, COMPUT IND ENG, V62, P1055, DOI 10.1016/j.cie.2011.12.033
   Sahingoz OK, 2014, J INTELL ROBOT SYST, V74, P499, DOI 10.1007/s10846-013-9968-6
   Saini N, 2017, International Journal Of Engineering And Computer Science, V6, P23261, DOI [DOI 10.18535/IJECS/V6I12.04, 10.18535/ijecs/v6i12.04]
   Sari M, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/6154025
   Scully T, 2009, KNOWL-BASED SYST, V22, P529, DOI 10.1016/j.knosys.2008.10.008
   Sermpinis G, 2015, EUR J OPER RES, V247, P831, DOI 10.1016/j.ejor.2015.06.052
   Shabankareh SG, 2019, 2019 5 IR C SIGN PRO, P1
   Sharma N, 2020, EVALUATION ACCIDENTA, DOI 10.2139/ssrn.3563084
   Shayeghi A, 2015, PHYS CHEM CHEM PHYS, V17, P2104, DOI 10.1039/c4cp04323e
   Shi GY, 1996, IEEE DECIS CONTR P, P4395, DOI 10.1109/CDC.1996.577484
   Shi JM, 2017, APPL MATH MODEL, V45, P14, DOI 10.1016/j.apm.2016.11.004
   Shukla AK, 2019, INT J COMPUT INTELL, V18, DOI 10.1142/S1469026819500202
   Singh Amarjeet, 2015, International Journal of Intelligent Systems and Applications, V7, P1, DOI 10.5815/ijisa.2015.12.01
   Sivanandam S., 2008, Introduction to genetic algorithms, DOI [10.1007/978-3-540-73190-0_7, DOI 10.1007/978-3-540-73190-0]
   Soleimani H, 2017, COMPUT IND ENG, V109, P191, DOI 10.1016/j.cie.2017.04.038
   Soleimani H, 2015, APPL MATH MODEL, V39, P3990, DOI 10.1016/j.apm.2014.12.016
   Soon GK, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P493, DOI 10.1109/ICCSCE.2013.6720015
   SRINIVAS N, 1995, Evolutionary computation., V2, P221, DOI [DOI 10.1162/EVCO.1994.2.3.221, 10.1162/evco.1994.2.3.221]
   Subbaraj P, 2011, APPL SOFT COMPUT, V11, P83, DOI 10.1016/j.asoc.2009.10.019
   Tahir M, 2022, NEURAL COMPUT APPL, V34, P11453, DOI 10.1007/s00521-020-05347-y
   Tam V., 2006, Journal of Communications, V1, P1, DOI 10.4304/jcm.1.4.1-10
   Tan K. C., 1995, First International Conference on `Genetic Algorithms in Engineering Systems: Innovations and Applications' GALESIA (Conf. Publ. No.414), P164
   Tang L, 2000, T ASAE, V43, P1019, DOI 10.13031/2013.2970
   Tang PH, 2013, APPL SOFT COMPUT, V13, P600, DOI 10.1016/j.asoc.2012.08.035
   TIONG SK, 2012, TRENDS APPL SCI RES, V7, P785, DOI DOI 10.3923/tasr.2012.785.791
   Toutouh J, 2017, SOFT COMPUT, V21, P1949, DOI 10.1007/s00500-015-1891-2
   Umbarkar A. J., 2015, ICTACT Journal on Soft Computing, V6, P1083
   Verma D, 2020, ADV INTELL SYST COMP, V1064, P135, DOI 10.1007/978-981-15-0339-9_12
   Viswanatha SDK, 2009, INT J COMPUT ELECT E, V1
   Vitayasak S, 2016, INT J PROD EC
   [王福林 Wang Fulin], 2016, [东北农业大学学报, Journal of Northeast Agricultural University], V47, P72
   Wang JL, 2019, J NANOMATER, V2019, DOI 10.1155/2019/6923701
   Wang JQ, 2016, APPL SOFT COMPUT, V43, P415, DOI 10.1016/j.asoc.2016.02.021
   Wang JR, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P1064, DOI 10.1109/WARTIA.2014.6976460
   Wang L, 2014, WORLD C ENG ASS MAN
   Wang N, 2014, MULTIMED TOOLS APPL, V71, P1411, DOI 10.1007/s11042-012-1278-7
   Wen Z, 2017, IEEE INTERNET COMPUT, V21, P16, DOI 10.1109/MIC.2017.36
   Wright A. H., 1991, FDN GENETIC ALGORITH, P205, DOI DOI 10.1016/B978-0-08-050684-5.50016-1
   Wu XD, 2007, EUR J OPER RES, V181, P156, DOI 10.1016/j.ejor.2006.05.035
   Yang CF, 2014, ENERG BUILDINGS, V76, P92, DOI 10.1016/j.enbuild.2014.02.053
   Yang SX, 2010, IEEE T SYST MAN CY C, V40, P52, DOI 10.1109/TSMCC.2009.2023676
   Yu F, 2014, APPL ENERG, V134, P102, DOI 10.1016/j.apenergy.2014.07.104
   Yuce B, 2017, COMPUT IND ENG, V113, P842, DOI 10.1016/j.cie.2017.07.018
   Yun SY, 2009, EXPERT SYST APPL, V36, P7552, DOI 10.1016/j.eswa.2008.09.064
   Zhai R, 2020, J PHYS C SER, V1550, P1
   Zhang QG, 2008, I C WIREL COMM NETW, P3539
   Zhang R, 2015, APPL SOFT COMPUT, V37, P521, DOI 10.1016/j.asoc.2015.08.051
   Zhang XY, 2016, IEEE T EVOLUT COMPUT, V20, P695, DOI 10.1109/TEVC.2015.2511142
   Zhao H, 2009, FOURTH INTERNATIONAL CONFERENCE ON COOPERATION AND PROMOTION OF INFORMATION RESOURCES IN SCIENCE AND TECHNOLOGY (COINFO 2009), P387, DOI 10.1109/COINFO.2009.30
   Zhenhua Y., 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P823, DOI 10.1109/ISDEA.2010.234
NR 221
TC 1633
Z9 1721
U1 450
U2 2275
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 8091
EP 8126
DI 10.1007/s11042-020-10139-6
EA OCT 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583128600001
PM 33162782
OA Bronze, Green Published
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Khan, RA
   Lone, SA
AF Khan, Riaz A.
   Lone, Sajaad A.
TI A comprehensive study of document security system, open issues and
   challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Physical document security; Anti-counterfeiting; Impersonation; Privacy;
   Biometrics; RFID; QR codes
ID WATERMARKING ALGORITHM; SCHEME; RECOGNITION; DCT; PROTECTION;
   BIOMETRICS; FRAUD; FACE
AB The privacy and security of identity documents like Passports, PAN cards, Driving License as well as other important personal documents like academic degree certificates are now at an all-time high, given how easy and cheap the new technologies make it to produce forged documents which not just carry threat to an individual's respect in society or career aspirations but can also prove to be life threatening if they are placed in the wrong hands. Thus, it is very important to have mechanisms that prevent or rather make it computationally unfeasible to forge these important documents. In this paper, we present an extensive review of techniques aimed at making tamper resistant physical documents, published across last two decades. We provide an in-depth classification of the means used for securing documents in the existing literature, discuss their limitations, open areas and future insights to address the open issues and challenges.
C1 [Khan, Riaz A.; Lone, Sajaad A.] Islamic Univ Sci & Technol IUST, Dept Comp Sci & Engn, Kashmir 192122, J&K, India.
RP Khan, RA (corresponding author), Islamic Univ Sci & Technol IUST, Dept Comp Sci & Engn, Kashmir 192122, J&K, India.
EM riaz.khan@islamicuniversity.edu.in
RI Khan, Riaz/ABG-7173-2020
OI lone, sajaad/0000-0002-7089-1991; Khan, Riaz/0000-0002-3355-4099
FU Islamic University of Science and Technology; Kashmir - TEQIP - III
FX This work is fully supported and funded by Islamic University of Science
   and Technology; Kashmir under Seed Grant Project sponsored by TEQIP -
   III.
CR Abid M, 2010, THERMOPHYSICS 2010, P9
   Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ahmed A, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P252, DOI 10.1109/DAS.2014.26
   Ahmed H. A., 2017, International Journal of Applied Engineering Research, V12, P9728
   Akinyele AO, 2018, AM J ELECT COMPUT EN, V2, P16
   Ambadiyil Sajan, 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P722, DOI 10.1109/SCOPES.2016.7955534
   Ambadiyil S, 2016, PROCEEDINGS OF THE 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL & ELECTRONICS, INFORMATION, COMMUNICATION & BIO INFORMATICS (IEEE AEEICB-2016), P558, DOI 10.1109/AEEICB.2016.7538353
   Ambadiyil S, 2015, PROCEDIA COMPUT SCI, V46, P507, DOI 10.1016/j.procs.2015.02.075
   [Anonymous], 2019, HLTH SAF ASP FOOD, DOI DOI 10.1007/978-3-030-24903-8
   [Anonymous], 2012, J GLOBAL RES COMPUTE
   [Anonymous], 2008, PROC IEEE REGION 10, DOI DOI 10.1109/TENCON.2008.4766581
   [Anonymous], 2019, IEEE T DEPENDABLE SE
   Araki K., 1998, Public Key Cryptography. First International Workshop on Practice and Theory in Public Key Cryptography, PKC'98. Proceedings, P29, DOI 10.1007/BFb0054012
   Ayeswarya S, 2019, INT J BIOMETRICS, V11, P67, DOI 10.1504/IJBM.2019.10016811
   Baran B., 2001, Proceedings of the 34th Annual Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.2001.927273
   Blue J, 2017, 2017 28 IR SIGN SYST, P1
   Carlos-Roca L.R., 2018, International Joint Conference on Neural Networks (IJCNN), P1, DOI DOI 10.1109/IJCNN.2018.8489113
   Chandramathi S, 2010, INT J COMPUT INTELL, V976, P976
   Cheddad A, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, VOLS 1 AND 2, P945
   Chin-Ho Chung, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P522, DOI 10.1109/IIH-MSP.2009.119
   Choudhury ZH, 2019, BIOMETRICS PASSPORT, DOI [10.31219/osf.io/wrbdp, DOI 10.31219/OSF.IO/WRBDP]
   Choudhury ZH, 2019, J APPL SEC RES, P1
   Dargan S, 2019, COMPREHENSIVE SURVEY, P113114
   Dass P, 2016, PROCEDIA COMPUT SCI, V78, P100, DOI 10.1016/j.procs.2016.02.017
   Dessimoz D, 2007, FORENSIC SCI INT, V167, P154, DOI 10.1016/j.forsciint.2006.06.037
   Dhagat Rashi, 2016, 2016 S COL DAT AN NE, P1
   Eldefrawy MH, 2012, INT CONF INTERNET, P74
   Espejel-Trujillo A, 2012, PROC TECH, V3, P241, DOI 10.1016/j.protcy.2012.03.026
   Finance UK, 2019, COMPUT FRAUD SECUR, V2019, P4, DOI [10.1016/S1361-3723(19)30037-5, DOI 10.1016/S1361-3723(19)30037-5]
   Fu ZX, 2019, MEASUREMENT, V141, P267, DOI 10.1016/j.measurement.2019.03.080
   Garain Utpal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P718, DOI 10.1109/ICDAR.2009.234
   Gariup M, 2019, INT J CRIT INFR PROT, V24, P100, DOI 10.1016/j.ijcip.2018.10.005
   Ghoshal N, 2013, P INT C FRONT INT CO, P631
   Guillen E, 2012, P WORLD C ENG COMP S, P1
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hebbes L, 2011, HAISA, P86
   Jagadiswary D, 2016, PROCEDIA COMPUT SCI, V85, P109, DOI 10.1016/j.procs.2016.05.187
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Kalamsyah SA, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), P435, DOI 10.1109/ICoICT.2018.8528771
   Katz J, 2010, DIGITAL SIGNATURES, P1, DOI 10.1007/978-0-387-27712-7
   Kejariwal A, 2003, IEEE POTENTIALS, V22, P37, DOI 10.1109/MP.2003.1238692
   Kessler Gary C., 1998, HDB LOCAL AREA NETWO
   Khaledi Hiwa, 2005, 2005 12 IEEE INT C E, P1
   Kirovski D, 2004, ISSE 2004 - SECURING ELECTRONIC BUSINESS PROCESSES, P160
   Kumar P, 2016, OPTIK, V127, P2341, DOI 10.1016/j.ijleo.2015.11.188
   Kwon TY, 2004, LECT NOTES COMPUT SC, V3043, P728
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lewis O, 2019, 2019 SOUTHEASTCON, P1
   Li CM, 2015, IEEE ICC, P7400, DOI 10.1109/ICC.2015.7249509
   Li RS, 2019, ANAL CHEM, V91, P11185, DOI 10.1021/acs.analchem.9b01936
   Lindoso A, 2007, LECT NOTES COMPUT SC, V4642, P713
   Mahbour R, 2008, MULTIMEDIA TECHNOLOG
   McAteer I, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020034
   Mikkilineni AK, 2006, NIP 22: 22ND INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P444
   Mushtaq S., 2014, International Journal of Advanced Science and Technology, V73, P15, DOI DOI 10.14257/IJAST.2014.73.02
   Mushtaq S, 2014, 2014 INNOVATIVE APPLICATIONS OF COMPUTATIONAL INTELLIGENCE ON POWER, ENERGY AND CONTROLS WITH THEIR IMPACT ON HUMANITY (CIPECH), P92, DOI 10.1109/CIPECH.2014.7019062
   Natgunanathan I, 2018, MULTIMED TOOLS APPL, V77, P6753, DOI 10.1007/s11042-017-4596-y
   Nizamuddin N, 2019, COMPUT ELECTR ENG, V76, P183, DOI 10.1016/j.compeleceng.2019.03.014
   Owayjan M, 2015, New Trends in Networking, Computing, E-learning, Systems Sciences, and Engineering, P343
   Paret D, 2005, RFID CONTACTLESS SMA, P91
   Pavesic N, 2006, STUD CLASS DATA ANAL, P630, DOI 10.1007/3-540-31314-1_77
   Perry B, 2000, P SOC PHOTO-OPT INS, V3973, P80, DOI 10.1117/12.382214
   Picard J, 2004, PROC SPIE, V5306, P416, DOI 10.1117/12.525446
   Pieprzyk J., 1993, DESIGN HASHING ALGOR
   Prasanna GA, 2016, INT RES J ENG TECHNO, V3
   Putro PAW, 2019, 2019 INTERNATIONAL CONFERENCE ON INFORMATICS, MULTIMEDIA, CYBER AND INFORMATION SYSTEM (ICIMCIS), P157, DOI [10.1109/icimcis48181.2019.8985190, 10.1109/ICIMCIS48181.2019.8985190]
   Querini M, 2012, FED CONF COMPUT SCI, P755
   Rajeswari M, 2016, INT J ENG RES TECHNO, V4, P2016
   Rao TS, 2013, ADV INTELL SYST, V182, P425
   Rehman SU, 2014, J COMPUT SYST SCI, V80, P591, DOI 10.1016/j.jcss.2013.06.013
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Rudner M, 2008, STUD CONFL TERROR, V31, P95, DOI 10.1080/10576100701812803
   Saho NJG, 2019, 2019 INT C SMART APP, P1
   Saini K., 2016, EGYPT J FORENSIC SCI, V6, P317, DOI DOI 10.1016/J.EJFS.2015.03.001
   Saini R., 2014, P INT J ADV SCI TECH, V2, P1
   Seth B, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4108
   Sharma MA, 2011, INT J COMP SCI TELEC, V2, P58
   Shrivastava A, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944593
   Singhal A., 2015, Int. J. Comput. Appl, V120, P38, DOI [10.5120/21315-4303, DOI 10.5120/21315-4303]
   Subramanya Sr, 2001, IEEE POTENTIALS, V20, P19
   Suhail MA, 2003, IEEE T INSTRUM MEAS, V52, P1640, DOI 10.1109/TIM.2003.817155
   Thirumalai C, 2020, COMPUT COMMUN, V150, P634, DOI 10.1016/j.comcom.2019.12.015
   Thongkor K., 2012, P 2012 9 INT C EL EN, V1618, P1
   WG I, 2019, FINAL DOCUMENT
   Wiersma J, 2007, U.S. patent, Patent No. [11/485,705, 11485705]
   Winter C., 2019, P 20 INT S POW EL EE, P1, DOI [10.1109/PEE.2019.8923546, DOI 10.1109/PEE.2019.8923546]
   Wong KS, 2012, 2012 THIRD FTRA INTERNATIONAL CONFERENCE ON MOBILE, UBIQUITOUS, AND INTELLIGENT COMPUTING (MUSIC), P120, DOI 10.1109/MUSIC.2012.28
   Xu ZJ, 2011, PROCEDIA ENVIRON SCI, V10, P1129, DOI 10.1016/j.proenv.2011.09.180
   Yahya Z., 2017, P 2017 INT C E COMM, P82
   Yang CL, 2014, C IND ELECT APPL, P1441, DOI 10.1109/ICIEA.2014.6931395
   Zulfiqar M.D., 2019, P INT C UK CHIN EM T, P1
NR 96
TC 7
Z9 7
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7039
EP 7061
DI 10.1007/s11042-020-10061-x
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583495900003
DA 2024-07-18
ER

PT J
AU Filali, J
   Zghal, HB
   Martinet, J
AF Filali, Jalila
   Zghal, Hajer Baazaoui
   Martinet, Jean
TI OntoAnnClass: ontology-based image annotation driven by classification
   using HMAX features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Ontologies; Classification; HMAX features; BoVW model
ID OBJECT RECOGNITION
AB Several approaches have been proposed in the area of Automatic Image Annotation (AIA) in order to exploit the relationships between words that are extracted from image categories, and to automatically generate annotation words for a given image. Other methods exploit ontologies, where the annotation keywords were derived from ontology to improve image annotation. In this paper, we propose an ontology-based image annotation driven by classification using HMAX features. The idea is (1) to train visual-feature-classifiers and to build an ontology that can finely represent the semantic information associated with training images, and (2) to combine classifier outputs and ontology for image annotation. To annotate images, we define a membership value of words in images. In particular, we propose to evaluate the membership value based on the confidence value of classifiers and the semantic similarity between words. The membership value depends on the word relationships found in the ontology that serve to select annotation words. The obtained experimental results show that the exploitation of both classifier outputs and ontology by evaluating our proposed membership value enables an improvement of image annotation.
C1 [Filali, Jalila; Zghal, Hajer Baazaoui] Univ Manouba, RIADI Lab, ENSI, Manouba, Tunisia.
   [Zghal, Hajer Baazaoui] CY Univ, ENSEA, CNRS, ETIS,UMR 8051, F-59000 Cergy, France.
   [Martinet, Jean] Univ Cote Azur, I3S, CNRS, Polytech Nice Sophia Campus SophiaTech, Sophia Antipolis, France.
C3 Universite de la Manouba; CY Cergy Paris Universite; Centre National de
   la Recherche Scientifique (CNRS); Centre National de la Recherche
   Scientifique (CNRS); Universite Cote d'Azur
RP Filali, J (corresponding author), Univ Manouba, RIADI Lab, ENSI, Manouba, Tunisia.
EM jalila.filali@ensi-uma.tn; hajer.baazaoui@ensea.fr;
   jean.martinet@univ-cotedazur.fr
OI Baazaoui, Hajer/0000-0002-2151-7397
CR [Anonymous], 2015, INT J HYBRID INFORM
   [Anonymous], 2015, INT J DATABASE THEOR
   [Anonymous], 2012, P 21 ACM INT C INFOR
   [Anonymous], 2015, CLEF WORKING NOTES
   [Anonymous], 2015, ARXIV150202772
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen Yu, 2013, Evid Based Complement Alternat Med, V2013, P245958, DOI 10.1155/2013/245958
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dutt A, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P443, DOI 10.1145/3078971.3079042
   Filali J, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420400029
   Filali J, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P124, DOI 10.5220/0007444101240134
   Filali J, 2017, IEEE INT CON INF VIS, P182, DOI 10.1109/iV.2017.27
   Han YH, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P251, DOI 10.1145/2671188.2749290
   He XT, 2017, AAAI CONF ARTIF INTE, P4075
   Lei J, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P240, DOI 10.1109/CRV.2017.21
   Li YL, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00123
   Ma YC, 2019, MULTIMED TOOLS APPL, V78, P3767, DOI 10.1007/s11042-018-6038-x
   Niu YL, 2019, IEEE T IMAGE PROCESS, V28, P1720, DOI 10.1109/TIP.2018.2881928
   Olszewska JI, 2013, INT J ADV COMPUT SC, V4, P201
   Reshma IA, 2014, 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY AND APPLICATION (ICAICTA), P226, DOI 10.1109/ICAICTA.2014.7005945
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Rinaldi AM, 2014, IEEE INT CONGR BIG, P242, DOI 10.1109/BigData.Congress.2014.43
   Ristin M, 2015, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2015.7298619
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sun CJ, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P518, DOI 10.1109/MVA.2015.7153244
   Sun FM, 2016, MULTIMED TOOLS APPL, V75, P1427, DOI 10.1007/s11042-014-2141-9
   Thériault C, 2013, IEEE T IMAGE PROCESS, V22, P764, DOI 10.1109/TIP.2012.2222900
   Theriault C, 2011, IEEE IMAGE PROC, P1261, DOI 10.1109/ICIP.2011.6115663
   Tsai D, 2011, IEEE I CONF COMP VIS, P611, DOI 10.1109/ICCV.2011.6126295
   Wang C, 2015, IMAGE VISION COMPUT, V38, P65, DOI 10.1016/j.imavis.2014.10.013
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Wu DM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113240
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Zarka M, 1391, REGIMVID IMAGECLEF 2
   Zhang HZ, 2016, NEUROCOMPUTING, V218, P242, DOI 10.1016/j.neucom.2016.08.051
   Zhenzhen Wei, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P434, DOI 10.1109/ICIG.2013.93
   Zou FH, 2016, MULTIMED TOOLS APPL, V75, P12627, DOI 10.1007/s11042-014-2423-2
NR 37
TC 0
Z9 0
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6823
EP 6851
DI 10.1007/s11042-020-09864-9
EA OCT 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581569800005
DA 2024-07-18
ER

PT J
AU Wang, XP
   Liu, XX
   Guo, J
   Zheng, JX
   Xu, PF
   Xiao, Y
   Liu, BY
AF Wang, Xiaopei
   Liu, Xiaoxia
   Guo, Jun
   Zheng, Jiaxiang
   Xu, Pengfei
   Xiao, Yun
   Liu, Baoying
TI A deep person re-identification model with multi visual-semantic
   information embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Edge contour clue; Multiple visual-semantic
   information embedding; Convolution neural networks
AB The local features of different body parts have been widely used to learn more discriminative representation for person re-identification, which act as either extra visual semantic information or auxiliary means to deal with the issue of misalignment and background bias. However, the existing person re-identification works mainly focuses on the common impact of multiple body parts while failing to explicitly explore the influence of body edge contour. As the edge contour is one of the most significant visual-semantic clues for object detection and person identification in the blurred scene, this paper intentionally explores the effect of edge contour clues on person re-identification and proposes a deep learning framework with multi visual-semantic information embedding, including body parts and edge contour. Meanwhile, we conceive a practical strategy which can effectively fuse the different body part features and reduce the dimensionality of features. Extensive experimental results on four benchmark data sets show that our model has achieved competitive accuracy compared to the state-of-the-art models.
C1 [Wang, Xiaopei; Liu, Xiaoxia; Guo, Jun; Zheng, Jiaxiang; Xu, Pengfei; Xiao, Yun] Northwest Univ, Dept Comp Sci, Xian, Peoples R China.
   [Liu, Baoying] Shaanxi Int Joint Res Ctr Battery Free Internet T, Xian, Peoples R China.
C3 Northwest University Xi'an
RP Guo, J (corresponding author), Northwest Univ, Dept Comp Sci, Xian, Peoples R China.
EM wangxiaopei@stumail.nwu.edu.cn; xiaoxia@nwu.edu.cn; guojun@nwu.edu.cn;
   zhengjiaxiang@stumail.nwu.edu.cn; pfxu@nwu.edu.cn; yxiao@nwu.edu.cn;
   paola.liu@nwu.edu.cn
RI Liu, Jing/IQX-0664-2023; QI, LIU/IQR-4870-2023; LIU, YU/HTR-1607-2023;
   Guo, Jun/AAB-9166-2022; Li, Fan/JRY-4017-2023; Lu,
   Xiaomei/IUQ-2139-2023; liu, xiao/HMD-7454-2023; Li, Li/IAQ-0885-2023;
   Li, Shuyao/JRY-8603-2023; yang, liu/HTN-9175-2023; li,
   sixuan/KGR-3943-2024; sun, huan/JEO-7152-2023; liu, xiao/HKE-9880-2023;
   cheng, shu/IZE-4788-2023; liang, YU/IYT-4334-2023
OI Guo, Jun/0000-0001-6944-0731; liang, YU/0009-0007-3922-3454
FU National Science Foundation of China [62072372, 61972315, 61973250,
   61902318]; Key Research and Development Program of Shaanxi [2019GY-012,
   2018SF-369]; Shaanxi Science and Technology Innovation Team Support
   Project [2018TD-026]
FX This work is financially supported in part by the National Science
   Foundation of China under Grant No.62072372, No.61972315, No.61973250,
   No.61902318, and Key Research and Development Program of Shaanxi
   (Program No.2019GY-012, No.2018SF-369). We are also grateful to the
   Shaanxi Science and Technology Innovation Team Support Project under
   grant agreement 2018TD-026.
CR [Anonymous], 2016, arXiv preprint arXiv:1611.05244
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen WH, 2017, AAAI CONF ARTIF INTE, P3988
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Chu HF, 2019, MULTIMED TOOLS APPL, V78, P27067, DOI 10.1007/s11042-017-4817-4
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   Fan X, 2019, LECT NOTES COMPUT SC, V11362, P19, DOI 10.1007/978-3-030-20890-5_2
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hayat T, 2003, MATH PROBL ENG, P1, DOI 10.1155/S1024123X03308014
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang X, 2020, NMS PEPRESENTATIVE R
   Hwang J. J., 2015, ARXIV150401989
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   Qi L., 2018, ARXIV180403864
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Watson G, 2020, MULTIMED TOOLS APPL, V79, P6463, DOI 10.1007/s11042-019-08499-9
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou QQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1041
NR 44
TC 0
Z9 1
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6853
EP 6870
DI 10.1007/s11042-020-09957-5
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581569800006
DA 2024-07-18
ER

PT J
AU Huang, W
   Luo, MY
   Zhang, P
   Zha, YF
AF Huang, Wei
   Luo, Mingyuan
   Zhang, Peng
   Zha, Yufei
TI Full-scaled deep metric learning for pedestrian re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Metric learning; Deep learning
ID SELECTION
AB The pedestrian re-identification problem (i.e., re-id) is essential and pre-requisite in multi-camera video surveillance studies, provided the fact that pedestrian targets need to be accurately re-identified across a network of multiple cameras with non-overlapping fields of views before other post-hoc high-level utilizations (i.e., tracking, behaviors analyses, activities monitoring, etc.) can be carried out. Driven by recent developments in deep learning techniques, the important re-id problem is often tackled via either deep discriminant learning or deep generative learning techniques. However, most contemporary deep learning-based models with tremendously deep structures are not easy to be trained because of the notorious vanishings gradient problem. In this study, a novel full-scaled deep discriminant learning model is proposed. The novelty of the full-scale model is significant, as three crucial concepts in designing a deep learning model, including depth, width, and cardinality, are all taken into consideration, simultaneously. Therefore, the new model needs not to be tremendously deep but is more convenient to be trained. Moreover, based on the new model, a novel deep metric learning method is proposed to further solve the important re-id problem. Technically, two algorithms either based on the conventional SGD (stochastic gradient descent) or an alternative more efficient PGD (proximal gradient descent) are both derived. For experimental analyses, the newly introduced full-scaled deep metric learning method has been comprehensively compared with dozens of popular re-id methods proposed from either deep learning or shallow learning perspectives. Several well-known public re-id datasets have been incorporated and rigorous statistical analyses have been carried out to compare all methods regarding their re-id performance. The superiority of the novel full-scaled deep metric learning method has been substantiated, from the statistical point of view.
C1 [Huang, Wei] Nanchang Univ, Sch Informat Engn, Dept Comp Sci, Nanchang 330022, Jiangxi, Peoples R China.
   [Huang, Wei] Nanchang Univ, Informatizat Off, Nanchang 330022, Jiangxi, Peoples R China.
   [Luo, Mingyuan] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Guangdong Prov Key Lab Biomed Measurements & Ultr, Shenzhen 518061, Peoples R China.
   [Zhang, Peng; Zha, Yufei] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Xian 710072, Peoples R China.
C3 Nanchang University; Nanchang University; Shenzhen University;
   Northwestern Polytechnical University
RP Huang, W (corresponding author), Nanchang Univ, Sch Informat Engn, Dept Comp Sci, Nanchang 330022, Jiangxi, Peoples R China.; Huang, W (corresponding author), Nanchang Univ, Informatizat Off, Nanchang 330022, Jiangxi, Peoples R China.
EM n060101@e.ntu.edu.sg; lmy0217@126.com; zh0036ng@nwpu.edu.cn;
   zhayufei@126.com
RI Zhang, Penghui/HGB-7353-2022; Li, Chun/KBC-9591-2024
OI Zhang, Penghui/0000-0002-9518-7079; Huang, Wei/0000-0002-0541-8612
FU National Natural Science Foundation of China [61862043, 61971352];
   Natural Science Foundation of Jiangxi Province [S2020RCDT2K0033];
   Natural Science Foundation of Shaanxi Province [2018JM6015]
FX This work was partially supported by grants 61862043 and 61971352
   approved by National Natural Science Foundation of China, grant
   S2020RCDT2K0033 approved by Natural Science Foundation of Jiangxi
   Province, and grant 2018JM6015 approved by Natural Science Foundation of
   Shaanxi Province. The source code of the new method has been made public
   through the following URL: https://github.com/Lmy0217/FDML.
CR Abu-El-Haija Sami, 2016, arXiv
   An L, 2016, NEUROCOMPUTING, V182, P247, DOI 10.1016/j.neucom.2015.12.029
   [Anonymous], 2016, HUMAN REIDENTIFICATI
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2017, Dual path networks
   [Anonymous], 2016, Adv. NeuralInf. Process. Syst.
   Arjovsky M., 2017, ARXIV170107875
   Bar-Hillel A, 2002, P COMP VIS PATT REC
   Bolettieri P, 2009, COPHIR TEST COLLECTI
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196
   Camps O, 2017, IEEE T CIRC SYST VID, V27, P540, DOI 10.1109/TCSVT.2016.2556538
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng W, 2018, P INT C COMP VIS
   Duan YQ, 2020, IEEE T IMAGE PROCESS, V29, P2037, DOI 10.1109/TIP.2019.2948472
   Durugkar Ishan, 2016, ARXIV161101673
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang W, 2018, NEUROCOMPUTING, V272, P520, DOI 10.1016/j.neucom.2017.07.019
   Gao HH, 2020, IEEE INTERNET THINGS, V7, P4532, DOI 10.1109/JIOT.2019.2956827
   Gao WJ, 2019, COMPUT INTELL-US, V35, P496, DOI 10.1111/coin.12202
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Ghahramani Z, 2004, LECT NOTES ARTIF INT, V3176, P72
   Goldberger J., 2004, Advances in Neural Information Processing Systems, V17
   Gong C, 2015, P COMP VIS PATT REC
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guo FJ, 2017, IEEE INFOCOM SER, DOI 10.1109/TCYB.2017.2761361
   Guo M, 2017, DUKEMTMC4REID LARGE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoi S, 2006, P COMP VIS PATT REC
   Howard AL., 1977, Bull. Amer. Math. Soc. (N.S.), V1, P521
   Hu JL, 2016, IEEE T CIRC SYST VID, V26, P2056, DOI 10.1109/TCSVT.2015.2477936
   Hu JL, 2016, IEEE T IMAGE PROCESS, V25, P5576, DOI 10.1109/TIP.2016.2612827
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huiskes MJ, 2010, P INT C MULT INF RET
   Karanam Srikrishna, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P33, DOI 10.1109/CVPRW.2015.7301392
   Karras T, 2018, P INT C LEARN REPR I
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P760, DOI 10.1007/978-3-030-01246-5_45
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FH, 2018, IEEE T IMAGE PROCESS, V27, P2777, DOI 10.1109/TIP.2018.2813161
   Liu H, 2015, NEUROCOMPUTING, V151, P1283, DOI 10.1016/j.neucom.2014.11.002
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, INT C LEARN REPR
   Peng P, 2016, P COMP VIS PATT REC
   Radford A., 2015, ARXIV
   Rice J. A., 2006, MATH STAT DATA ANAL
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour Sara, 2017, Advances in Neural Information Processing Systems, P3856
   Shamoyan R, 2009, ARMEN J MATH, V2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Suh Y, 2019, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2019.00742
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang J, 2017, IEEE T CIRC SYST VID, V27, P513, DOI 10.1109/TCSVT.2016.2586851
   Wang Xinshao, 2019, PROC CVPR IEEE, P5207, DOI DOI 10.1109/CVPR.2019.00535
   Weinberger K.Q., 2006, Advances in neural information processing systems, P1473
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Wu ZY, 2015, IEEE T PATTERN ANAL, V37, P1095, DOI 10.1109/TPAMI.2014.2360373
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang L., 2006, Michigan State Universiy
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang ZM, 2017, IEEE T CIRC SYST VID, V27, P499, DOI 10.1109/TCSVT.2016.2596159
   Zheng AH, 2020, IEEE T SYST MAN CY-S, V50, P149, DOI 10.1109/TSMC.2017.2784356
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zheng WZ, 2019, PROC CVPR IEEE, P72, DOI 10.1109/CVPR.2019.00016
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 87
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5945
EP 5975
DI 10.1007/s11042-020-09997-x
EA OCT 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800008
DA 2024-07-18
ER

PT J
AU Zhang, ZJ
   Pan, X
   He, K
   Cheng, L
   Yang, CC
   Chen, RQ
AF Zhang, Zejun
   Pan, Xiong
   He, Kai
   Cheng, Li
   Yang, Changcai
   Chen, Riqing
TI SAR image segmentation with parallel region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic Aperture Radar (SAR) images segmentation;
   Multi-scale-multi-direction (MSMD) ratio edge detector; Parallel region
   merging strategy
ID MARKOV RANDOM-FIELD; DETECTOR; MODEL
AB In this paper, a parallel region merging strategy is proposed for partitioning Synthetic Aperture Radar (SAR) images into several disjoint regions, based on the region adjacency graph (RAG) of an initial partition and the nearest neighbor graph (NNG) produced from the RAG. Developed from the multi-direction ratio edge detector, a multi-scale-multi-direction (MSMD) one is used to extract edge strength map (ESM) of an initial SAR image, feeded into watershed transform to generate an initial partition result of the initial SAR image. Considering local image properties, which makes the generated NNG center around bi-node circles situated in interiors of homogeneous regions, many of which are independently located in different homogeneous regions, the predication of the parallelizability for bi-node circles is proposed to make the proposed parallel region merging strategy. The proposed parallel merging strategy simultaneously merges bi-node circles far away from boundaries of regions, characterized by the length of path from a node to the bi-node circle in the NNG. The performance of the proposed parallel merging strategy is analyzed theoretically and experimentally, and our experiments show that the proposed method outweighs other compared methods.
C1 [Zhang, Zejun] Zhejiang Normal Univ, Coll Phys & Elect Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.
   [Pan, Xiong; He, Kai] Fujian Agr & Forestry Univ, Fujian Prov Univ, Key Lab Smart Agr & Forestry, Fuzhou 350002, Peoples R China.
   [Pan, Xiong; He, Kai; Yang, Changcai; Chen, Riqing] Fujian Agr & Forestry Univ, Digital Fujian Inst Big Data Agr & Forestry, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
   [Cheng, Li] Fujian Agr & Forestry Univ, Jinshan Coll, Fuzhou 350002, Peoples R China.
C3 Zhejiang Normal University; Fuzhou University; Fujian Agriculture &
   Forestry University; Fujian Agriculture & Forestry University; Fujian
   Agriculture & Forestry University
RP Zhang, ZJ (corresponding author), Zhejiang Normal Univ, Coll Phys & Elect Informat Engn, Jinhua 321004, Zhejiang, Peoples R China.
EM zjzhang_fafu@163.com
RI Zhang, Zejun/IRZ-3618-2023
CR Akyilmaz E, 2018, IEEE GEOSCIENCE REMO
   [Anonymous], 2016, P INT C LEARN REPR
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Calderero F, 2010, IEEE T IMAGE PROCESS, V19, P1567, DOI 10.1109/TIP.2010.2043008
   Carvalho EA, 2010, DIGIT SIGNAL PROCESS, V20, P1365, DOI 10.1016/j.dsp.2009.10.014
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   COOK R., 1994, P SOC PHOTO-OPT INS, V2316, P92, DOI DOI 10.1117/12.197529
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Eppstein D, 1997, DISCRETE COMPUT GEOM, V17, P263, DOI 10.1007/PL00009293
   Fan S, 2020, IEEE GEOSCIENCE REMO
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fjortoft R, 1998, IEEE T GEOSCI REMOTE, V36, P793, DOI 10.1109/36.673672
   Galland F, 2003, IEEE T IMAGE PROCESS, V12, P995, DOI 10.1109/TIP.2003.816005
   Gao L, 2016, 30 AAAI C ART INT
   Gao L, 2018, COARSE TO FINE IMAGE, P719
   Gemme L, 2018, IEEE T GEOSCI REMOTE, V56, P2633, DOI 10.1109/TGRS.2017.2769710
   Grunwald P. D., 2007, The Minimum Description Length Principle
   Haris K, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P338, DOI 10.1109/ICIP.1998.727211
   Komodakis N, 2015, IEEE T PATTERN ANAL, V37, P1425, DOI 10.1109/TPAMI.2014.2368990
   Lang FK, 2014, IEEE GEOSCI REMOTE S, V11, P509, DOI 10.1109/LGRS.2013.2271040
   Lei P, 2020, IEEE GEOSCIENCE REMO
   Li BN, 2016, IEEE ACCESS, V4, P4777, DOI 10.1109/ACCESS.2016.2590440
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Li W, 1999, INT J REMOTE SENS, V20, P3377, DOI 10.1080/014311699211390
   Liu ZW, 2018, IEEE T PATTERN ANAL, V40, P1814, DOI 10.1109/TPAMI.2017.2737535
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Y, 2020, IEEE T COGNITIVE DEV
   Luo SY, 2018, IEEE T IMAGE PROCESS, V27, P2560, DOI 10.1109/TIP.2018.2806201
   Marques RCP, 2012, IEEE T PATTERN ANAL, V34, P2046, DOI 10.1109/TPAMI.2011.274
   Nie XL, 2015, IEEE T IMAGE PROCESS, V24, P1209, DOI 10.1109/TIP.2015.2396292
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Oliver CJ, 1996, IEE P-RADAR SON NAV, V143, P31, DOI 10.1049/ip-rsn:19960219
   Pan X, 2017, IEEE T VIS COMPUT GR, V23, P2342, DOI 10.1109/TVCG.2016.2621763
   Panagiotakis C, 2011, IEEE T IMAGE PROCESS, V20, P2276, DOI 10.1109/TIP.2011.2114893
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Picco M, 2011, IEEE GEOSCI REMOTE S, V8, P350, DOI 10.1109/LGRS.2010.2073678
   Shui PL, 2014, IEEE T GEOSCI REMOTE, V52, P6434, DOI 10.1109/TGRS.2013.2296561
   Smits PC, 1997, IEEE T GEOSCI REMOTE, V35, P844, DOI 10.1109/36.602527
   TOUZI R, 1988, IEEE T GEOSCI REMOTE, V26, P764, DOI 10.1109/36.7708
   Wang F, 2017, IEEE T GEOSCI REMOTE, V55, P537, DOI 10.1109/TGRS.2016.2611060
   Xia GS, 2016, IEEE T GEOSCI REMOTE, V54, P1860, DOI 10.1109/TGRS.2015.2490078
   Yang JY, 2015, IEEE T CYBERNETICS, V45, P913, DOI 10.1109/TCYB.2014.2340032
   Yu H, 2013, IEEE T GEOSCI REMOTE, V51, P995, DOI 10.1109/TGRS.2012.2203604
   Yu QY, 2008, IEEE T PATTERN ANAL, V30, P2126, DOI 10.1109/TPAMI.2008.15
NR 46
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5701
EP 5721
DI 10.1007/s11042-020-09920-4
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577990600001
DA 2024-07-18
ER

PT J
AU Ali, M
   Asghar, MZ
   Baloch, A
AF Ali, Mushtaq
   Asghar, Muhammad Zubair
   Baloch, Amanullah
TI An efficient approach for sub-image separation from large-scale
   multi-panel images using dynamic programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic programming; Multi-panel image; Image segmentation; Image
   classification; Figure mining; Image retrieval system
ID RETRIEVAL
AB Multi-panel images are increasingly used in research and medical domains for describing complicated situations like results' comparison in paper; or case depiction of a patient by combining all his medical images into a consolidated image. However, the content based image retrieval (CBIR) systems face the issue of performance decline in terms of poor retrieval accuracy because the individual sub-images of the multi-panel images cannot be accessed during the searching process. Representing multi-panel images in the form of sub-images is a necessary step for improving the retrieval accuracy of CBIR systems. The state-of-the-art multi-panel image segmentation approaches use recursive approach for sub-image separation, which detects the location of the sub-lines of a line in the multi-panel image appearing in its sub-images repeatedly. This characteristic of the available approaches makes the CBIR incapable to provide the intended results to the end users in real time. In this work, a line detection-based method using dynamic programming is proposed for sub-image separation, which detects the position of every line in the multi-panel image only once, instead of several times as in the case of state-of-art approaches. We evaluated the proposed method on a subset of the imageCLEFmed 2013 dataset, containing 1050 images belonging to different groups. The experimental results depict the effectiveness of the proposed method in term of generating the results quickly without losing the accuracy as compare to the state-of-the-art approaches.
C1 [Ali, Mushtaq; Baloch, Amanullah] Hazara Univ, Dept IT, Dhodial, Pakistan.
   [Asghar, Muhammad Zubair] Gomal Univ, Inst Comp & Informat Technol, Dera Ismail Khan, Pakistan.
C3 Hazara University; Gomal University
RP Ali, M (corresponding author), Hazara Univ, Dept IT, Dhodial, Pakistan.
EM mushtaqyaqubi@hotmail.com
RI Asghar, Muhammad Zubair/M-6411-2015
OI Asghar, Muhammad Zubair/0000-0003-3320-2074
CR Ali M, 2018, MULTIMED TOOLS APPL, V77, P20271, DOI 10.1007/s11042-017-5453-8
   [Anonymous], 1979, NOBUYUKI OTSU
   Antani S, 2008, P SPIE, VXV, P28
   Apostolova E, 2013, J AM SOC INF SCI TEC, V64, P893, DOI 10.1002/asi.22810
   Archip N, 2005, ULTRASOUND MED BIOL, V31, P1485, DOI 10.1016/j.ultrasmedbio.2005.07.005
   Aucar JA, 2007, AM J SURG, V194, P734, DOI 10.1016/j.amjsurg.2007.08.036
   Bai Xiaodong, 2011, 7 INT S MULT IM PROC
   Brown CN, 1996, ENG SCI ED J, V5
   Cheng B, 2011, P SPIE EL IM SCI TEC
   Chhatkuli A, 2013, PROC SPIE, V8674, DOI 10.1117/12.2007897
   Cooper MS, 2004, METHOD CELL BIOL, V77, P439
   Cramer Kalpathy, 2011, WORKING NOTES CLEF 2
   De Herrera A.G.S., 2013, CLEF Working Notes
   de Herrera Alba Garcia Seco, 2013, CLEF WORKING NOTES 2
   Demner-Fushman D, 2007, 7 IEEE INT C DAT MIN
   Demner-Fushman D, 2009, INT J MED INFORM, V78, pE59, DOI 10.1016/j.ijmedinf.2009.05.003
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P757, DOI 10.1109/TCSVT.2004.828348
   Doulamis ND, 2014, IEEE T COMPUT, V63, P461, DOI 10.1109/TC.2012.222
   Eggel I, 2010, P 10 INT C CROSS LAN
   Gou SP, 2012, IEEE GEOSCIENCE REMO, V9
   Hersh W, 2008, J DIGIT IMAGING
   Ihde J, 2010, ADV TECHNOL EARTH SC, P277, DOI 10.1007/978-3-642-10228-8_22
   Jhanwar N, 2004, IMAGE VISION COMPUTI
   Jordan Michael I, 2002, ADV NEURAL INFORM PR
   Kalpathy-Cramer J, 2008, QUERY ANAL IMPROVE M
   Kalpathy-Cramer J, 2007, STUD HEALTH TECHNOL, V129, P1334
   Li PY, 2018, BIOINFORMATICS, V34, P1192, DOI 10.1093/bioinformatics/btx611
   Lopez LD, 2012, BIOINF BIOM BIBM 201, P1
   Müller H, 2009, LECT NOTES COMPUT SC, V5706, P512, DOI 10.1007/978-3-642-04447-2_63
   Muller H., 2012, WORKING NOTES CLEF 2
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 2002, IEEE T CIRCUITS VIDE, P644
   SHIN KG, 1991, IEEE T ROBOTIC AUTOM, V7, P333, DOI 10.1109/70.88142
   Sreedevi S, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P29, DOI 10.1109/MVIP.2012.6428753
   Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184, DOI 10.1136/jamia.1997.0040184
   Taschwer Mario, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P162, DOI 10.1007/978-3-319-27671-7_14
   Tsutsui Satoshi, 2017, COMPUTER VISION PATT
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   W-Y Ma, 1999, HDB MULTIMEDIA COMPU
   Zhang YH, 1997, PROCEEDINGS OF THE 1997 IEEE INTERNATIONAL CONFERENCE ON CONTROL APPLICATIONS, P429, DOI 10.1109/CCA.1997.627618
   Zheng Xin, 2004, P 12 ANN ACM INT C M
NR 41
TC 3
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5449
EP 5471
DI 10.1007/s11042-020-09950-y
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577469600003
DA 2024-07-18
ER

PT J
AU Soliman, NF
   Khalil, MI
   Algarni, AD
   Ismail, S
   Marzouk, R
   El-Shafai, W
AF Soliman, Naglaa F.
   Khalil, M. I.
   Algarni, Abeer D.
   Ismail, Sahar
   Marzouk, Radwa
   El-Shafai, Walid
TI Efficient HEVC steganography approach based on audio compression and
   encryption in QFFT domain for secure multimedia communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion mathematics; HEVC steganography; QFFT; Random projection;
   Legendre sequence; DCT; DWT
ID VIDEO STEGANOGRAPHY; IMAGE STEGANOGRAPHY; ALGORITHM; FEATURES; SCHEME
AB High-Efficiency Video Coding (HEVC) is the most recent video codec standard. It is substantial to analyze the HEVC steganography process due to its practical and academic significance. Thus, a secure HEVC steganography approach is introduced in this paper to study the possibility of hiding an encrypted secret audio message within a cover compressed video frame in a secure and complicated manner. In the preliminary stage, the secret audio message is compressed utilizing the Discrete Cosine Transform (DCT) to achieve a high capacity performance for the HEVC steganography process. After that, the suggested approach implies two-cascaded encryption layers to encrypt the compressed secret message before embedding it within a cover HEVC frame. In the first encryption layer, a novel encryption technique based on random projection and Legendre sequence in the Discrete Wavelet Transform (DWT) domain is introduced to cipher the compressed secret audio message. In the second encryption layer, the yielded encrypted audio message is represented in a form of quaternion numbers using the Quaternion Fast Fourier Transform (QFFT) technique. Each cover HEVC frame is also represented in a quaternion form. In the suggested approach, some straightforward quaternion mathematical operations are employed on the encrypted secret message and the cover HEVC frames to represent them in a quaternion form in the frequency domain, then the encrypted secret audio message is hidden within the cover HEVC frame. At the receiver, the secret message can be retrieved and extracted from the cover HEVC frame utilizing the same methodology of the employed quaternion mathematical operations. The major contributions of the suggested HEVC steganography scheme are: (1) it allows hiding of massive amount of secret information within cover video frames, and (2) it has higher robustness against multimedia attacks and steganalysis contrasted to the conventional and literature schemes. Furthermore, the proposed approach is evaluated utilizing different assessment metrics like Feature Similarity Index Measure (FSIM), Peak Signal-to-Noise Ratio (PSNR), correlation coefficient, and Structural Similarity Index Measure (SSIM) to evaluate the efficiency of the stego HEVC frames compared to the original ones. The achieved outcomes demonstrate that the suggested steganography scheme is straightforward to implement, more secure, and robust in the presence of steganalysis multimedia attacks compared to the literature approaches.
C1 [Soliman, Naglaa F.; Algarni, Abeer D.; Ismail, Sahar; Marzouk, Radwa] Princess Nourah Bint Abdulrahman Univ, Fac Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Soliman, Naglaa F.] Zagazig Univ, Dept Elect & Commun, Fac Engn, Zagazig, Egypt.
   [Khalil, M. I.] Atom Energy Author, Reactor Phys Dept, NRC, Cairo, Egypt.
   [Ismail, Sahar] Benha Univ, Dept Elect Engn, Fac Engn Shoubra, Cairo, Egypt.
   [Marzouk, Radwa] Cairo Univ, Dept Math, Fac Sci, Giza 12613, Egypt.
   [El-Shafai, Walid] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Princess Nourah bint Abdulrahman University; Egyptian Knowledge Bank
   (EKB); Zagazig University; Egyptian Knowledge Bank (EKB); Egyptian
   Atomic Energy Authority (EAEA); New & Renewable Energy Authority (NREA);
   National Research Centre (NRC); Egyptian Knowledge Bank (EKB); Benha
   University; Egyptian Knowledge Bank (EKB); Cairo University; Egyptian
   Knowledge Bank (EKB); Menofia University
RP El-Shafai, W (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM nagla.soliman@yahoo.com; magdi_nrc@hotmail.com; a_dalqarni@pnu.edu.sa;
   saismail@pnu.edu.sa; rmmarzouk@pnu.edu.sa;
   walid.elshafai@el-eng.menofia.edu.eg
RI Soliman, Naglaa/HJY-8292-2023; El-Shafai, Walid/AAG-4796-2021; Algarni,
   Abeer/HIZ-6134-2022; Marzouk, Radwa/GRR-4559-2022
OI El-Shafai, Walid/0000-0001-7509-2120; Marzouk,
   Radwa/0000-0001-6527-9856; Soliman, Naglaa/0000-0001-7322-1857
FU Dean of Scientific Research at princess Nourah bint Abdulrahman
   University [39/S/250]
FX This research was funded by the Dean of Scientific Research at princess
   Nourah bint Abdulrahman University. Grant No. (39/S/250). And the
   authors would like to thank this support.
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Alyousuf F. Q. A., 2020, B ELECT ENG INFORMAT, V9, P573
   [Anonymous], 2014, HEVC Reference Software HM 13.0
   Bahrami Z, 2018, MULTIMED TOOLS APPL, V77, P327, DOI 10.1007/s11042-016-4226-0
   Balu S, 2019, CLUSTER COMPUT, V22, P4057
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Golomb S. W., 1967, SHIFT REGISTER SEQUE
   Gugjoo MB, 2020, RECENT PATENTS INFLA, V14, P3, DOI 10.2174/1872213X14666200130100236
   Hamilton William Rowan, 1844, P ROYAL IRISH ACAD, V2, P4
   Hashemzadeh M, 2018, COMPUT ELECTR ENG, V68, P14, DOI 10.1016/j.compeleceng.2018.03.046
   Hitzer E, 2016, ADV APPL CLIFFORD AL, V26, P969, DOI 10.1007/s00006-015-0620-3
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kaur H, 2015, PROCEDIA COMPUT SCI, V54, P661, DOI 10.1016/j.procs.2015.06.077
   Khalil M. I., 2018, International Journal of Communication Networks and Information Security, V10, P425
   Khalil MI, 2017, INT J INF TECHNOL SE, V9, P3
   Khalil MI., 2012, Int. J. Image Graph. Signal Process, V2, P9, DOI [10.5815/ijigsp.2012.02.02, DOI 10.5815/IJIGSP.2012.02.02]
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Konyar MZ, 2020, SIGNAL IMAGE VIDEO P, P1
   Kumar M., 2014, INT J SCI TECHNOLOGY, V3, P226
   Liu SY, 2020, COGN SYST RES, V59, P207, DOI 10.1016/j.cogsys.2019.09.008
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Liu ZH, 2017, MULTIMED TOOLS APPL, V76, P12481, DOI 10.1007/s11042-016-3664-z
   Liu Z, 2020, IEEE ACCESS, V8, P22275, DOI 10.1109/ACCESS.2020.2968740
   Manisha S, 2019, MULTIDIM SYST SIGN P, V30, P529, DOI 10.1007/s11045-018-0568-2
   Mansouri J, 2009, INT J IMAG SYST TECH, V19, P306, DOI 10.1002/ima.20207
   Mareen H, 2018, IEEE T CONSUM ELECTR, V64, P250, DOI 10.1109/TCE.2018.2852258
   Matousek J, 2008, RANDOM STRUCT ALGOR, V33, P142, DOI 10.1002/rsa.20218
   Mihara T, 2015, PHYS LETT A, V379, P952, DOI 10.1016/j.physleta.2015.01.038
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   Nabil M, 2017, ARXIV171003163
   Noda H, 2004, IEEE IMAGE PROC, P2147
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Rakhmawati L, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0462-3
   Ramalingam M, 2015, APPL SOFT COMPUT, V34, P744, DOI 10.1016/j.asoc.2015.05.040
   Rawat CS, 2013, INT ARAB J INF TECHN, V10, P553
   Galiano DR, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106541
   Sadat ES, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040244
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Sheela SJ, 2017, HINDAWI J COMPUTER N, V2017, P12
   Soliman NF, 2017, INT J SPEECH TECHNOL, V20, P977, DOI 10.1007/s10772-017-9435-z
   Soria-Lorente A, 2017, SECURE STEGANOGRAPHI
   Sushmitha MC, 2017, IEEE ICCE, P72, DOI 10.1109/ICCE-ASIA.2017.8307831
   Suterio V, 2019, IFMBE PROC, V70, P319, DOI 10.1007/978-981-13-2517-5_49
   Tan DW, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P1409, DOI [10.1109/ITNEC.2019.8729476, 10.1109/itnec.2019.8729476]
   Wang J, 2019, IEEE ACCESS, V7, P119393
   Wang J., 2009, P RAD C, P1
   Wang QY, 2014, IEICE T FUND ELECTR, VE97A, P1627, DOI 10.1587/transfun.E97.A.1627
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhu WJ, 2018, 2018 19TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P233, DOI 10.1109/ICEPT.2018.8480804
NR 54
TC 41
Z9 43
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4789
EP 4823
DI 10.1007/s11042-020-09881-8
EA OCT 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574100800001
DA 2024-07-18
ER

PT J
AU Byun, SW
   Lee, SP
AF Byun, Sung-Woo
   Lee, Seok-Pil
TI Human emotion recognition based on the weighted integration method using
   image sequences and acoustic features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Acoustic feature; Facial expression; Model
   integration
ID FACIAL EXPRESSION RECOGNITION; SPEECH; COMMUNICATION
AB People generally perceive other people's emotions based on speech and facial expressions, so it can be helpful to use speech signals and facial images simultaneously. However, because the characteristics of speech and image data are different, combining the two inputs is still a challenging issue in the area of emotion-recognition research. In this paper, we propose a method to recognize emotions by synchronizing speech signals and image sequences. We design three deep networks. One of the networks is trained using image sequences, which focus on facial expression changes. Facial landmarks are also input to another network to reflect facial motion. The speech signals are first converted to acoustic features, which are used for the input of the other network, synchronizing the image sequence. These three networks are combined using a novel integration method to boost the performance of emotion recognition. A test comparing accuracy is conducted to verify the proposed method. The results demonstrated that the proposed method exhibits more accurate performance than previous studies.
C1 [Byun, Sung-Woo] Sangmyung Univ, Grad Sch, Dept Comp Sci, Seoul, South Korea.
   [Lee, Seok-Pil] Sangmyung Univ, Dept Elect Engn, Seoul, South Korea.
C3 Sangmyung University; Sangmyung University
RP Lee, SP (corresponding author), Sangmyung Univ, Dept Elect Engn, Seoul, South Korea.
EM 123234566@naver.com; esprit@smu.ac.kr
OI Lee, Seok-Pil/0000-0003-2520-6681
CR Abu Shaqra F, 2019, PROCEDIA COMPUT SCI, V151, P37, DOI 10.1016/j.procs.2019.04.009
   Bjorn S, 2013, INTERSPEECH 2013 COM
   Domínguez-Jiménez JA, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101646
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Gao XJ, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9149379
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Happy S. L., 2012, P 4 INT C INT HUM CO, P1
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   He J, 2019, KSII T INTERNET INF, V13, P5546, DOI 10.3837/tiis.2019.11.015
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Iliou T, 2009, ICDT: 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL TELECOMMUNICATIONS, P121, DOI 10.1109/ICDT.2009.30
   Jeong M, 2018, IEEE T CIRC SYST VID, V28, P2753, DOI 10.1109/TCSVT.2017.2769096
   Jeong MH, 2016, 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016), DOI 10.1145/2996913.2996984
   Jia XB, 2020, KSII T INTERNET INF, V14, P924, DOI 10.3837/tiis.2020.03.001
   Joseph Redmon, 2015, ARXIV150602640
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kao YH, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1814
   Kaulard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032321
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   KO BC, 2018, SENSORS BASEL, V18
   Lee C., 2014, J.Acoust.Soc.Am, V135, P2422
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Lotfian R, 2019, IEEE-ACM T AUDIO SPE, V27, P815, DOI 10.1109/TASLP.2019.2898816
   Luengo I., 2005, INTERSPEECH 2005, P493
   Ma YX, 2019, INFORM FUSION, V46, P184, DOI 10.1016/j.inffus.2018.06.003
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Song P, 2020, IEEE T AFFECT COMPUT, V11, P373, DOI 10.1109/TAFFC.2018.2800046
   Sun N, 2019, PATTERN RECOGN LETT, V119, P49, DOI 10.1016/j.patrec.2017.10.022
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Wang XS, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115831
   Wu CH, 2009, AFFECTIVE INFORMATION PROCESSING, P93, DOI 10.1007/978-1-84800-306-4_6
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zamil AAA, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P281, DOI [10.1109/ICREST.2019.8644168, 10.1109/icrest.2019.8644168]
   Zhang HP, 2020, PATTERN RECOGN LETT, V131, P128, DOI 10.1016/j.patrec.2019.12.013
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 47
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35871
EP 35885
DI 10.1007/s11042-020-09842-1
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000570841100007
OA hybrid
DA 2024-07-18
ER

PT J
AU Dai, Y
AF Dai, Ying
TI Sample-specific repetitive learning for photo aesthetic auto-assessment
   and highlight elements analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo aesthetic auto-assessment; Imbalanced learning; Repetitive
   self-revised learning; Dropping out sample; CNN
ID CLASSIFICATION
AB Aesthetic assessment is subjective, and the distribution of the aesthetic grades is over-concentrated in the middle levels. In order to realize the auto-assessment of photo aesthetics, we focus on using repetitive self-revised learning (RSRL) to retrain the convolutional neural network (CNN)-based aesthetics prediction network repetitively by the transfer learning, so as to improve the performance of imbalanced learning caused by the overconcentration distribution of aesthetic scores utilized as learning data. As RSRL, the network is trained repetitively by dropping out the low likelihood photo samples at the middle levels of aesthetics from the training data set based on the previously trained network. Further, the two retained networks are used in extracting aesthetic highlight elements of the photos to analyze the relation of the photo composition with the aesthetic assessment. The objective and subjective experimental results show that the CNN-based RSRL is effective for improving the performances of the imbalanced scores prediction network for the photos aesthetic auto-assessment.
C1 [Dai, Ying] Iwate Prefectural Univ, Takizawa, Japan.
C3 Iwate Prefectural University
RP Dai, Y (corresponding author), Iwate Prefectural Univ, Takizawa, Japan.
EM dai@iwate-pu.ac.jp
RI Dai, Ying/AFF-6820-2022
OI Dai, Ying/0000-0002-6987-8212
CR Dong Z, 2015, NEUROCOMPUTING, V168, P308, DOI 10.1016/j.neucom.2015.05.095
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Johnson CG, 2019, COMPLEXITY, DOI 10.1155/2019/3495962
   Kao YY, 2016, SIGNAL PROCESS-IMAGE, V47, P500, DOI 10.1016/j.image.2016.05.004
   Lemarchand F, 2018, PATTERN RECOGN LETT, V112, P9, DOI 10.1016/j.patrec.2018.05.016
   Mavridaki E, 2015, 2015 IEEE INT C IM P
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Tan YL, 2017, NEUROCOMPUTING, V228, P165, DOI 10.1016/j.neucom.2016.08.098
   Yubin, ARXIV161000838V2
   Zhang C, 2018, SIGNAL PROCESS-IMAGE, V67, P12, DOI 10.1016/j.image.2018.05.006
   Zhao MQ, 2016, SIGNAL PROCESS-IMAGE, V47, P511, DOI 10.1016/j.image.2016.05.009
NR 12
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1387
EP 1402
DI 10.1007/s11042-020-09426-z
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871600002
DA 2024-07-18
ER

PT J
AU Gong, LH
   Tian, C
   Zou, WP
   Zhou, NR
AF Gong, Li-Hua
   Tian, Cheng
   Zou, Wei-Ping
   Zhou, Nan-Run
TI Robust and imperceptible watermarking scheme based on Canny edge
   detection and SVD in the contourlet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robustness; Imperceptibility; Digital watermarking; Canny edge
   detection; Singular value decomposition; Contourlet transform
ID IMAGE WATERMARKING; DIGITAL WATERMARKING; TRANSFORM; DCT; HYBRID
AB To enhance the invisibility and the robustness of the watermarking algorithm, a robust and imperceptible watermarking scheme is presented by combining Canny edge detection, contourlet transform with singular value decomposition. The host image is firstly decomposed by the contourlet transform. Then the low frequency sub-band obtained by contourlet transform is partitioned into 4x4 non-overlapping blocks and the singular value decomposition is carried out for the specific blocks selected by the Canny edge detection. Finally, the watermark is embedded into the coefficient of matrix U. The embedded watermark could be recovered blindly in the watermark extraction stage. And the robustness and the imperceptibility are efficiently guaranteed with an optimal thresholdkselected by the least-square curve fitting. Experimental results demonstrate that the proposed watermarking scheme is superior in terms of imperceptibility and robustness against common attacks.
C1 [Gong, Li-Hua; Tian, Cheng; Zou, Wei-Ping; Zhou, Nan-Run] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Zou, Wei-Ping] Univ Poitiers, XLIM UMR CNRS 7252, Poitiers, France.
C3 Nanchang University; Universite de Poitiers; Centre National de la
   Recherche Scientifique (CNRS)
RP Zhou, NR (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM znr21@163.com
RI tian, cheng/KJM-4052-2024; Zhou, Nanrun/HGC-4650-2022
OI ZHOU, Nanrun/0000-0002-5080-2189
FU National Natural Science Foundation of China [61861029, 61462061]; Major
   Academic Discipline and Technical Leader of Jiangxi Province
   [20162BCB22011]; Natural Science Foundation of Jiangxi Province
   [2017BAB202002]; Cultivation Plan of Applied Research of Jiangxi
   Province [20181BBE58022]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61861029 and 61462061), the Major Academic Discipline
   and Technical Leader of Jiangxi Province (Grant No. 20162BCB22011), the
   Natural Science Foundation of Jiangxi Province (Grant No.
   2017BAB202002), and the Cultivation Plan of Applied Research of Jiangxi
   Province (Grant No. 20181BBE58022).
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bi HB, 2010, INT CONF SIGN PROCES, P881, DOI 10.1109/ICOSP.2010.5656038
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Miyake S, 2016, QUANTUM INF PROCESS, V15, P1849, DOI 10.1007/s11128-016-1260-9
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Pereira S, 2001, SIGNAL PROCESS, V81, P1251, DOI 10.1016/S0165-1684(01)00042-1
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Xu ZG, 2017, IEEE SIGNAL PROC LET, V24, P1068, DOI 10.1109/LSP.2017.2710144
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 34
TC 37
Z9 38
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 439
EP 461
DI 10.1007/s11042-020-09677-w
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600010
DA 2024-07-18
ER

PT J
AU Tang, PJ
   Xia, JW
   Tan, YN
   Tan, B
AF Tang, Pengjie
   Xia, Jiewu
   Tan, Yunlan
   Tan, Bin
TI Double-channel language feature mining based model for video description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double-channel; Language feature; Video description; LSTM; Deep fusion
AB Video description is to translate video to natural language. Many recent effective models for the task are developed with the popular deep convolutional neural networks and recurrent neural networks. However, the abstractness and representation ability of visual motion feature and language feature are usually ignored in most of popular methods. In this work, a framework based on double-channel language feature mining is proposed, where deep transformation layer (DTL) is employed in both of the stages of motion feature extraction and language modeling, to increase the number of feature transformation and enhance the power of representation and generalization of the features. In addition, the early deep sequential fusion strategy is introduced into the model with element-wise product for feature fusing. Moreover, for more comprehensive information, the late deep sequential fusion strategy is also employed, and the output probabilities from the modules with DTL and without DTL are fused with weight average for further improving accuracy and semantics of generated sentence. Multiple experiments and ablation study are conducted on two public datasets including Youtube2Text and MSR-VTT2016, and competitive results compared to the other popular methods are achieved. Especially on CIDEr metric, the performance reaches to 82.5 and 45.9 on the two datasets respectively, demonstrating the effectiveness of the proposed model.
C1 [Tang, Pengjie; Xia, Jiewu; Tan, Yunlan; Tan, Bin] Jinggangshan Univ, Coll Elect & Informat Engn, Jian 343009, Jiangxi, Peoples R China.
   [Tang, Pengjie; Xia, Jiewu; Tan, Yunlan; Tan, Bin] Jiangxi Engn Lab IoT Technol Crop Growth, Jian 343009, Jiangxi, Peoples R China.
C3 Jinggangshan University
RP Xia, JW (corresponding author), Jinggangshan Univ, Coll Elect & Informat Engn, Jian 343009, Jiangxi, Peoples R China.; Xia, JW (corresponding author), Jiangxi Engn Lab IoT Technol Crop Growth, Jian 343009, Jiangxi, Peoples R China.
EM tangpengjie@jgsu.edu.cn; jwxia@126.com; tanyunlan@163.com;
   tanbin@163.com
FU Research Foundation of Art Planning of Jiangxi Province [YG2017283];
   Bidding Project for the Foundation of Colleges Key Research on
   Humanities and Social Science of Jiangxi Province [JD17082]; Doctoral
   Scientific Research Foundation of Jinggangshang University [JZB1923,
   JZB1807]; National Natural Science Foundation of P. R. China [61762052]
FX Research Foundation of Art Planning of Jiangxi Province (No. YG2017283);
   Bidding Project for the Foundation of Colleges Key Research on
   Humanities and Social Science of Jiangxi Province (No. JD17082); The
   Doctoral Scientific Research Foundation of Jinggangshang University (No.
   JZB1923, JZB1807); National Natural Science Foundation of P. R. China
   (No. 61762052).
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   [Anonymous], 2016, PROC 24 ACM INT C MU, DOI [DOI 10.1145/2964284.2984065, 10.1145/2964284.2984065]
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   [Anonymous], 2016, ARXIV161107837
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Ballas Nicolas, 2015, Comput. Sci
   Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chen H, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P606, DOI 10.1109/ITME.2018.00139
   Chen H, 2018, AAAI CONF ARTIF INTE, P6706
   Chen JW, 2019, AAAI CONF ARTIF INTE, P8167
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Ding GG, 2019, COGN COMPUT, V11, P763, DOI 10.1007/s12559-018-9581-x
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1082, DOI 10.1145/2964284.2984064
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Iashin V, 2020, ARXIV200508271V1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krishnamoorthy N., 2013, P AAAI C ART INT, P541
   Li W, 2018, PATTERN RECOGN LETT, V105, P23, DOI 10.1016/j.patrec.2017.10.012
   Lin Chin-Yew, 2004, P 42 ANN M AOC COMP, P605, DOI [DOI 10.3115/.1218955.1219032, DOI 10.3115/1218955.1219032]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shaw D, 2011, IMPACT OF THE ECONOMIC CRISIS ON EAST ASIA: POLICY RESPONSES FROM FOUR ECONOMIES, P190
   Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548
   Shetty R., 2016, P 24 ACM INT C MULTI, P1073
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang PJ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3303083
   Tang PJ, 2018, NEUROCOMPUTING, V312, P154, DOI 10.1016/j.neucom.2018.05.086
   Tang PJ, 2017, NEUROCOMPUTING, V225, P188, DOI 10.1016/j.neucom.2016.11.023
   Thomason J., 2014, COLING, P1218
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Venugopalan S., 2015, P ANN C N AM CHAPT A, P1494, DOI 10.3115/v1/N15-1173
   Venugopalan S., 2016, EMNLP, P1961
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wei SK, 2010, IEEE T KNOWL DATA EN, V22, P1191, DOI 10.1109/TKDE.2009.145
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu H., 2015, WORKSH CLOS LOOP VIS
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu Y, 2018, 2018 IEEE RESEARCH AND APPLICATIONS OF PHOTONICS IN DEFENSE CONFERENCE (RAPID), P367
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
NR 60
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33193
EP 33213
DI 10.1007/s11042-020-09674-z
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000008
DA 2024-07-18
ER

PT J
AU Saman, G
   Gohar, N
   Noor, S
   Shahnaz, A
   Idress, S
   Jehan, N
   Rashid, R
   Khattak, SS
AF Saman, Gule
   Gohar, Neelam
   Noor, Salma
   Shahnaz, Ambreen
   Idress, Shakira
   Jehan, Neelam
   Rashid, Reena
   Khattak, Sheema Shuja
TI Automatic detection and severity classification of diabetic retinopathy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Morphological operations; Exudates;
   Microaneurysms; Support vector machine; Classification; Decision making
ID RETINAL IMAGES; FUNDUS IMAGES; IDENTIFICATION; VALIDATION; ALGORITHM
AB Diabetic retinopathy (DR) is a leading cause of preventable blindness caused by damaged blood vessels in the eye, if not treated early on. The aim of this research work was to develop a method for the automatic detection of Diabetic Retinopathy and proposing a model for deciding the progression/severity using fundus images. The method was developed so that DR can be detected in an effective and efficient manner before causing damage to the eye, without the presence of an ophthalmologist. The manual screening requires the presence of an ophthalmologist and the resource of time. Detecting exudates is important for the diagnosis of DR. The approach adopted was two-fold: i. extracting features of interest from the images i.e. the blood vessels, optic disc (OD), exudates and microaneurysms by using morphological operations and ii. classifying its progression/severity as either mild or moderate by using the support vector machine (SVM) classifier for helping Ophthalmologists. The performance of the proposed method has been assessed by an ophthalmologist and approved. This paper contributes towards the field of automatic detection of anomalous structures and their severity.
C1 [Saman, Gule; Gohar, Neelam; Noor, Salma; Shahnaz, Ambreen; Idress, Shakira; Jehan, Neelam; Rashid, Reena; Khattak, Sheema Shuja] Shaheed Benazir Bhutto Women Univ Peshawar, Dept Comp Sci, Peshawar, KP, Pakistan.
RP Saman, G (corresponding author), Shaheed Benazir Bhutto Women Univ Peshawar, Dept Comp Sci, Peshawar, KP, Pakistan.
EM gulesaman@sbbwu.edu.pk; neelam.gohar@sbbwu.edu.pk;
   dr.salmanoor@sbbwu.edu.pk; ambreen.shahnaz@sbbwu.edu.pk;
   shakira_idrees@yahoo.com; jehan.neelam@yahoo.com; rena.rashid@yahoo.com;
   khattak.sheema@sbbwu.edu.pk
CR Akram UM, 2012, J MED SYST, V36, P3151, DOI 10.1007/s10916-011-9802-2
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   [Anonymous], 2010, INT J COMPUTER SCI E
   Aquino A, 2010, IEEE T MED IMAGING, V29, P1860, DOI 10.1109/TMI.2010.2053042
   Centers for Disease Control Prevention, 2011, National Diabetes Fact Sheet: National Estimates and General Information on Diabetes and Prediabetes in the United States
   Dehghani A, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-19
   DIARETDB1, 2016, STAND DIAB RET DAT C
   Doshi D, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P261, DOI 10.1109/CAST.2016.7914977
   El Abbadi NK., 2013, INT J COMPUT SCI ISS, V10, P237
   Fleming AD, 2007, PHYS MED BIOL, V52, P7385, DOI 10.1088/0031-9155/52/24/012
   Gandhi M, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P873, DOI 10.1109/iccsp.2013.6577181
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Jose J., 2014, INT J ENG COMPUT SCI, V3, P8583
   Kande GB, 2010, J DIGIT IMAGING, V23, P430, DOI 10.1007/s10278-009-9246-0
   LI H, 2003, NULL, P394
   Nayak J, 2008, J MED SYST, V32, P107, DOI 10.1007/s10916-007-9113-9
   Oktoeberza KZW, 2015, COMM COM INF SC, V516, P348, DOI 10.1007/978-3-662-46742-8_32
   Priya R, 2012, INT J COMPUT APPL, V41
   Raja DSS, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/419279
   Sanchez Clara I, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4453
   Sinthanayothin C, 2002, DIABETIC MED, V19, P105, DOI 10.1046/j.1464-5491.2002.00613.x
   SOPHARAK A., 2008, International Conference on Embedded Systems and Intelligent Technology, P139, DOI DOI 10.1109/CBMS.2012.6266341
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Tripathi S., 2013, INT J ENG TECHNOLOGY, V5, P2024
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Yanoff M, 2012, GOLDMAN CECIL MED
   Zhu YL, 2012, PHYSCS PROC, V25, P601, DOI 10.1016/j.phpro.2012.03.132
NR 30
TC 9
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31803
EP 31817
DI 10.1007/s11042-020-09118-8
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360200008
DA 2024-07-18
ER

PT J
AU Cheng, GF
   Wang, CH
   Xu, C
AF Cheng, Guangfeng
   Wang, Chunhua
   Xu, Cong
TI A novel hyper-chaotic image encryption scheme based on quantum genetic
   algorithm and compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper-chaotic system; Image encryption; Quantum genetic algorithm (QGA);
   Compressive sensing (CS)
ID SYSTEM; CRYPTANALYSIS; PERMUTATION
AB Over the last few years, lots of chaotic image encryption schemes have been proposed. However, most of the schemes are permutation-diffusion architectures which still have some shortcomings, such as weak key streams, small key spaces, small information entropy, and so on. To eliminate the above weaknesses, in this paper, we propose a hyper-chaotic image encryption scheme based on quantum genetic algorithm (QGA) and compressive sensing (CS), which is a new image encryption scheme and has not been proposed so far. Firstly, QGA can update the population with the quantum rotation gate, which can enhance the randomness of the population and avoid falling into local optimum. Then compressive sensing technology is used to reduce data storage and speed up the encryption and decryption process. Moreover, we utilize the SHA-512 hash function of the plain image to calculate the initial values of the hyper-chaotic system, which is capable of enhancing the relationships between encryption schemes and plain images. The simulation experiments and security analysis reveal that the proposed scheme is more efficient in resisting statistical attack and plaintext attack and shows better performance in peak signal-to-noise ratio (PSNR) and information entropy compared with other image encryption schemes based on chaos theory.
C1 [Cheng, Guangfeng; Wang, Chunhua] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Wang, CH (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM wch1227164@hnu.edu.cn
RI Wang, Chunhua/HCH-5464-2022
OI Wang, Chunhua/0000-0001-6522-9795
FU Major Research Plan of the National Natural Science Foundation of China
   [91964108]; National Natural Science Foundation of China [61971185];
   Open Fund Project of Key Laboratory in Hunan Universities [18 K010]
FX This work is supported by the Major Research Plan of the National
   Natural Science Foundation of China (No.91964108), the National Natural
   Science Foundation of China (No.61971185) and the Open Fund Project of
   Key Laboratory in Hunan Universities (No.18 K010).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Cai ST, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040282
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Devaraj P, 2016, NONLINEAR DYNAM, V86, P927, DOI 10.1007/s11071-016-2934-7
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Han KH, 2000, IEEE C EVOL COMPUTAT, P1354, DOI 10.1109/CEC.2000.870809
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kayalvizhi S, 2020, MULTIMED TOOLS APPL, V79, P3957, DOI 10.1007/s11042-019-7642-0
   Li M, 2018, IEEE ACCESS, V6, P47102, DOI 10.1109/ACCESS.2018.2867111
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Lin HR, 2020, APPL MATH COMPUT, V369, DOI 10.1016/j.amc.2019.124840
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Niu YJ, 2010, COMMUN NONLINEAR SCI, V15, P3518, DOI 10.1016/j.cnsns.2009.12.005
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Pashakolaee PG, 2018, MULTIMED TOOLS APPL, V77, P20385, DOI 10.1007/s11042-017-5461-8
   Schmitz R, 2001, J FRANKLIN I, V338, P429, DOI 10.1016/S0016-0032(00)00087-9
   Wang L, 2001, P SOC PHOTO-OPT INS, V4550, P115, DOI 10.1117/12.441434
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Xiao D, 2017, OPT LASER TECHNOL, V91, P212, DOI 10.1016/j.optlastec.2016.12.024
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang S, 2016, MULTIMED TOOLS APPL, V75, P17157, DOI 10.1007/s11042-015-2982-x
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang X, 2019, IEEE ACCESS, V7, P16336, DOI 10.1109/ACCESS.2019.2894853
   Zhang XP, 2017, MULTIMED TOOLS APPL, V76, P15641, DOI 10.1007/s11042-016-3861-9
   Zhao Q, 2019, CHAOS, V29, DOI 10.1063/1.5081076
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhu CX, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090399
NR 41
TC 70
Z9 75
U1 6
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29243
EP 29263
DI 10.1007/s11042-020-09542-w
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559626400001
DA 2024-07-18
ER

PT J
AU Yin, YF
   Cheng, H
   Liu, H
AF Yin, Yunfei
   Cheng, Hui
   Liu, Huan
TI Flue gas layer feature segmentation based on multi-channel pixel
   adaptive
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flue gas layer segmentation; Multi-scale Aggregate Channel features;
   Pixel block feature matching
ID SMOKE DETECTION
AB It is very difficult to accurately separate the smoke contour in fire video. Because the scene of a fire is complex and changeable, and there are often many interference factors, such as continuously changing light and fast switching scenes, it is difficult to accurately guarantee the separation of smoke contours. In this paper, an aggregate channel feature algorithm that combines color, saturation and texture is designed, and a fast pixel block feature matching method is used to build the background model. In order to overcome the error caused by scene switching, a dynamic threshold control method based on the background switching speed is proposed, which eliminates the interference caused by the dynamic background update, and effectively extracts the foreground smoke pixels and smoke contour map. The experimental results show that the algorithm can accurately extract the smoke layer contour map, and compared with the traditional foreground extraction algorithms, the algorithm is faster and more accurate.
C1 [Yin, Yunfei; Cheng, Hui; Liu, Huan] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
C3 Chongqing University
RP Yin, YF (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
EM yinyunfei@cqu.edu.cn; hcheng@cqu.edu.cn; 932956197@qq.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Awad A. I., 2016, STUDIES COMPUTATIONA
   Baik S. W., 2020, DEEP LEARNING COMPUT, P63
   Barnich O, 2009, VIBE POWERFUL RANDOM
   Cao XF, 2014, FIRE SCI TECHNOL, V33, P670
   Celik Turgay, 2015, EUR SIGN PROC C
   Ghaeminia MH, 2019, SIGNAL IMAGE VIDEO P, V13, P43, DOI 10.1007/s11760-018-1326-5
   Han JianDong, 2017, J COMPUT APPL
   Hofmann M, 2012, 2012 IEEE COMP SOC C
   Hu Yan, 2014, Computer Engineering and Applications, V50, P180, DOI 10.3778/j.issn.1002-8331.1211-0362
   Jia Y, 2016, FIRE TECHNOL, V52, P1271, DOI 10.1007/s10694-014-0453-y
   Mégret O, 2000, FIRE SAFETY J, V34, P393, DOI 10.1016/S0379-7112(00)00010-2
   Muhammad K, 2020, IEEE T IND INFORM, V16, P1067, DOI 10.1109/TII.2019.2915592
   Ojala T, PATTERN RECOGNITION
   Palanisamy G, 2019, SIGNAL IMAGE VIDEO P, V13, P719, DOI 10.1007/s11760-018-1401-y
   Pan C., 2015, J JIANGSU U SCI TECH, V29, P52
   Qureshi WS, 2016, FIRE TECHNOL, V52, P1293, DOI 10.1007/s10694-015-0489-7
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Sun Li, 2016, VIDEO SMOKE DETECTIO
   Toreyin B.U, 2005, EUR SIGN PROC C
   Wang Tao, 2011, Computer Engineering, V37, P186, DOI 10.3969/j.issn.1000-3428.2011.23.063
   Wen ZB, 2016, THESIS
   Wojek C, 2012, IEEE T PATTERN ANAL
   Yan Hu, 2012, COMPUT SIMULAT, V29, P170
   Yuan FN, 2020, IEEE T IMAGE PROCESS, V29, P2301, DOI 10.1109/TIP.2019.2946126
   Yuan FN, 2016, INFORM SCIENCES, V372, P225, DOI 10.1016/j.ins.2016.08.040
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Zhou BL, 2016, SHIP SCI TECHNOL, V38, P111
NR 28
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29069
EP 29085
DI 10.1007/s11042-020-09466-5
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557123500003
DA 2024-07-18
ER

PT J
AU Elboushaki, A
   Hannane, R
   Afdel, K
   Koutti, L
AF Elboushaki, Abdessamad
   Hannane, Rachida
   Afdel, Karim
   Koutti, Lahcen
TI Improving articulated hand pose detection for static finger sign
   recognition in RGB-D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand pose estimation; Finger sign recognition; Per-pixel classification;
   Random decision forest; Density based spatial clustering; RGB-D
   information
ID GESTURE RECOGNITION; ROBUST APPROACH; DEPTH; REGRESSION; SYSTEM;
   CLASSIFICATION; HISTOGRAM; POSTURE
AB With the emergence of consumer RGB-D sensors, discriminative modeling has been shown to perform well in estimating human body pose. However, articulated hand pose estimation remains a challenging problem, mostly due to its high flexibility, occlusions, noisy data, and small area of the fingertips. In this paper, we present an efficient discriminative-based scheme to improve the performance of hand pose estimation from a single depth image. The proposed scheme is inspired by decision forest-based framework, but with several well-motivated modifications. Specifically, we propose a method to estimate 2D in-plane orientation of the hand, which is then utilized to enforce the depth comparison features and make them invariant to in-plane rotation. Subsequently, we investigate the use of random decision forests (RDF) and mean shift algorithm to predict a primary version of hand parts and joint locations. Based on this primary prediction, an adaptive spatial clustering method is applied to correct the misclassified regions, and to deliver the final estimation of hand pose. Along with the proposed scheme, we further develop a new set of highly-distinctive features for static finger sign recognition by utilizing the estimated hand pose configurations and RGB information. The proposed features are straightforward and can effectively capture different aspects of hand pose, such as links from each joint to the closest joints and orientation of each hand part. Extensive experiments on several challenging datasets demonstrate that our approach, compared to decision forest-based methods, is able to provide more precise estimation of hand poses (with up to 21% improvement in joint localization accuracy), and can efficiently recognize more complex static finger signs (93.85% mean recognition accuracy on a challenging 34-finger sign dataset). Our approach is also robust to illumination, inter-hand occlusion, scale, and rotation variance.
C1 [Elboushaki, Abdessamad] Sidi Mohammed Ben Abdellah Univ, Natl Sch Appl Sci, Fes 30000, Morocco.
   [Hannane, Rachida; Afdel, Karim; Koutti, Lahcen] Ibn Zohr Univ, Fac Sci, Lab Comp Syst & Vis, Agadir 80000, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Ibn Zohr University of
   Agadir
RP Elboushaki, A (corresponding author), Sidi Mohammed Ben Abdellah Univ, Natl Sch Appl Sci, Fes 30000, Morocco.
EM abdessamad.elboushaki@gmail.com; rachida.hannane@edu.uiz.ac.ma;
   k.afdel@uiz.ac.ma; l.koutti@uiz.ac.ma
RI Karim, AFDEL/AAC-7992-2019; KOUTTI, Larsen/GWR-2429-2022
OI Karim, AFDEL/0000-0002-0828-2116; KOUTTI, Lahcen/0000-0002-4274-3414
FU Centre National pour la Recherche Scientifique et Technique (CNRST) -
   Moroccan government [14UIZ2015]
FX The authors would like to thank the associate editors and the anonymous
   reviewers for their valuable and insightful comments and suggestions,
   which have contributed a lot towards improving the contents and
   presentation of this article. This work was supported by "Centre
   National pour la Recherche Scientifique et Technique (CNRST)" funded by
   Moroccan government under the Grant no: 14UIZ2015.
CR Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   [Anonymous], 2016, ARXIV160406195
   [Anonymous], 2011, IEEE C COMP VIS PATT
   [Anonymous], 2015, Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.241
   Bhuyan MK, 2015, J VISUAL LANG COMPUT, V28, P39, DOI 10.1016/j.jvlc.2014.12.001
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen XL, 2018, NEUROCOMPUTING, V315, P18, DOI 10.1016/j.neucom.2018.05.018
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   Choi C, 2015, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2015.269
   Choi D, 2019, IEEE ACCESS, V7, P96035, DOI 10.1109/ACCESS.2019.2929310
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Elboushaki A, 2017, PATTERN RECOGN, V64, P168, DOI 10.1016/j.patcog.2016.11.004
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Estrela BNS, 2013, VISAO COMP WORKSH WV
   Ferreira PM, 2019, MULTIMED TOOLS APPL, V78, P10035, DOI 10.1007/s11042-018-6565-5
   Fleishman Shachar, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P28, DOI 10.1109/CVPRW.2015.7301345
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Hou GD, 2015, IEEE SYS MAN CYBERN, P1738, DOI 10.1109/SMC.2015.305
   Hu ZZ, 2018, ADV ENG SOFTW, V115, P1, DOI 10.1016/j.advengsoft.2017.08.007
   Ji P, 2017, J INTELL ROBOT SYST, V87, P583, DOI 10.1007/s10846-016-0440-2
   Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61
   Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391
   Kirac F, 2014, PATTERN RECOGN LETT, V50, P91, DOI 10.1016/j.patrec.2013.09.003
   Krejov Philip, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163141
   Krejov P, 2017, COMPUT VIS IMAGE UND, V155, P124, DOI 10.1016/j.cviu.2016.11.005
   Kuznetsova A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P83, DOI 10.1109/ICCVW.2013.18
   Li PY, 2015, IEEE I CONF COMP VIS, P819, DOI 10.1109/ICCV.2015.100
   Li YT, 2014, PATTERN RECOGN, V47, P80, DOI 10.1016/j.patcog.2013.05.028
   Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Makris Alexandros, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2015.7301343
   Malik J, 2019, COMPUT GRAPH-UK, V85, P85, DOI 10.1016/j.cag.2019.10.002
   Media and Communication Lab China, HUST AM SIGN LANG
   Mirehi N, 2019, MULTIMED TOOLS APPL, V78, P13361, DOI 10.1007/s11042-019-7269-1
   Modanwal G, 2016, PATTERN RECOGN, V57, P50, DOI 10.1016/j.patcog.2016.03.026
   Nai WZ, 2017, PATTERN RECOGN, V65, P1, DOI 10.1016/j.patcog.2016.11.022
   Oberweger M., 2015, 20 COMP VIS WINT WOR
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379
   Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483
   Otiniano Rodriguez K., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P1, DOI 10.1109/SIBGRAPI.2013.10
   Ozturk O, 2015, APPL INTELL, V43, P786, DOI 10.1007/s10489-015-0680-z
   Paulo SF, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103316
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Poier G, 2015, ARXIV151008039
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Qian C., 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145
   Remelli E, 2017, IEEE I CONF COMP VIS, P2554, DOI 10.1109/ICCV.2017.277
   Ren YY, 2018, IEEE T CIRC SYST VID, V28, P364, DOI 10.1109/TCSVT.2016.2608837
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941
   Suau X, 2014, IMAGE VISION COMPUT, V32, P522, DOI 10.1016/j.imavis.2014.04.015
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Supancic JS, 2015, IEEE I CONF COMP VIS, P1868, DOI 10.1109/ICCV.2015.217
   Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700
   Tang DH, 2015, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2015.380
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664
   Tkach A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130830
   Tkach A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980226
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Wan CD, 2016, LECT NOTES COMPUT SC, V9907, P554, DOI 10.1007/978-3-319-46487-9_34
   Xie B, 2018, J ENG-JOE, P1515, DOI 10.1049/joe.2018.8327
   Xu C, 2016, INT J COMPUT VISION, V116, P21, DOI 10.1007/s11263-015-0826-9
   Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429
   Yanyi Zhang, 2017, 2017 16th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN). Proceedings, P299, DOI 10.1145/3055031.3055058
   Yao Y, 2012, INT J ANTENN PROPAG, V2012, DOI 10.1155/2012/890705
   Ye Q, 2016, LECT NOTES COMPUT SC, V9912, P346, DOI 10.1007/978-3-319-46484-8_21
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhou X., 2016, IJCAI, P2421
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 79
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28925
EP 28969
DI 10.1007/s11042-020-09370-y
EA AUG 2020
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557124000002
DA 2024-07-18
ER

PT J
AU Tariq, U
   Aldaej, A
AF Tariq, Usman
   Aldaej, Abdulaziz
TI Advancing an in-memory computing for a multi-accent real-time voice
   frequency recognition modeling: a comprehensive study of models &
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Computational intelligence; Evolutionary computing;
   NN-search
AB In this age of pervasive computing, numerous scientific accomplishments, such as artificial intelligence and machine learning [ML], have conveyed exciting uprisings to human civilization, which highlights the prospect to shape superior tools and solutions to aid to discourse some of the world's utmost persistent challenges. Coding of English-dialectal dialogue recognition that has numerous datasets turn into a worthy preparatory point. Due to the nature of established records, there is an enormous sum of auditory features that can instantaneously distress the communication signals. These aspects comprise orator transformations, channel spins, contextual and reverberant noise, etc. In the initial step of communication anticipation, input dialog frequencies are administered by a front-end to offer a torrent of audio feature trajectories or interpretations. In projected scheme, the mined reflection classification is served into a decoder to distinguish the furthermost probable term disarray. The aural model signifies the auditory understanding of function by which a reflection categorization can be plotted to a system of sub-word divisions. This study has engrossed on revision and adaptive preparation of auditory models.
C1 [Tariq, Usman; Aldaej, Abdulaziz] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Informat Syst, Al Kharj, Saudi Arabia.
C3 Prince Sattam Bin Abdulaziz University
RP Tariq, U (corresponding author), Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Informat Syst, Al Kharj, Saudi Arabia.
EM u.tariq@psau.edu.sa
RI Tariq, Usman/AAE-8037-2022; Aldaej, Abdulaziz/GSM-7715-2022; Tariq,
   Usman/AAF-8954-2020; Aldaej, Abdulaziz/GRJ-9569-2022; Aldaej,
   Abdulaziz/AAF-7734-2021; Tariq, Usman/GZL-9946-2022
OI Tariq, Usman/0000-0001-7672-1187; Aldaej, Abdulaziz/0000-0003-2504-4387;
   Aldaej, Abdulaziz/0000-0003-2504-4387; 
FU Deanship of Scientific Research at Prince Sattam Bin Abdulaziz
   University [2019/01/9857]
FX The authors would like to acknowledge the support of the Deanship of
   Scientific Research at Prince Sattam Bin Abdulaziz University under the
   research project # 2019/01/9857.
CR Audhkhasi K, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4759, DOI 10.1109/ICASSP.2018.8461935
   Baby D, 2019, INT CONF ACOUST SPEE, P106, DOI [10.1109/icassp.2019.8683799, 10.1109/ICASSP.2019.8683799]
   Chowdary SJS, 2019, SENTIMENT ANAL MOVIE
   Czerwinski D, 2018, 2018 CONFERENCE ON ELECTROTECHNOLOGY: PROCESSES, MODELS, CONTROL AND COMPUTER SCIENCE (EPMCCS)
   Deng L., 2018, DEEP LEARNING NATURA, P1
   Deng L, 2018, IEEE SIGNAL PROC MAG, V35, P180, DOI 10.1109/MSP.2017.2762725
   Fernandes V, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART), P200, DOI 10.1109/SYSMART.2018.8746939
   Fujita Y, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P416, DOI 10.1109/ASRU.2015.7404825
   Genesys Telecommunications Laboratories Inc, 2019, U.S. Patent Application, Patent No. [16/272,130, 16272130]
   Gideon J, 2021, IEEE T AFFECT COMPUT, V12, P1055, DOI [10.1109/TAFFC.2019.2916092, 10.1109/taffc.2019.2916092]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   IBM Cognitive, 2016, CONN COGN WORLD
   International Business Machines Corp, 2019, U.S. Patent Application, Patent No. [16/251,831, 16251831]
   Kim T, 2019, U.S. patent application, Patent No. [16/138,506, 16138506]
   Kirov C, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1868
   Laaridh I, 2018, PERCEPTUAL AUTOMATIC
   Li K, 2018, SPEECH COMMUN, V96, P28, DOI 10.1016/j.specom.2017.11.003
   Li YC, 2019, INTERSPEECH, P2803, DOI 10.21437/Interspeech.2019-2594
   Liu WW, 2018, IEEE ACCESS, V6, P48030, DOI 10.1109/ACCESS.2018.2867804
   Meyer J. A. E., 2019, THESIS
   Novoa J, 2018, COMPUT SPEECH LANG, V47, P30, DOI 10.1016/j.csl.2017.06.005
   Ozturel A, 2019, P 14 INT C FINITE ST, P65
   Pang Z, 2015, ARXIV150907211
   Qaisar SM, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON EVENT-BASED CONTROL, COMMUNICATION, AND SIGNAL PROCESSING (EBCCSP), DOI 10.1109/ebccsp.2019.8836903
   Tran HD, 2016, 2016 IEEE INT UNPUB
   Withanage P, 2018, IEEE REG 10 HUMANIT
   Wu FY, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013973
   Xiong W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5934, DOI 10.1109/ICASSP.2018.8461870
   Zhuang Y, 2015, SP201507 SHANGH JIAO
NR 29
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27705
EP 27720
DI 10.1007/s11042-020-09355-x
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000553718200003
DA 2024-07-18
ER

PT J
AU Cao, QJ
   Shi, ZF
   Wang, R
   Wang, PM
   Yao, SY
AF Cao, Qingjie
   Shi, Zaifeng
   Wang, Rong
   Wang, Pumeng
   Yao, Suying
TI A brightness-preserving two-dimensional histogram equalization method
   based on two-level segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Two-dimensional histogram; Histogram equalization;
   Brightness-preserving; Two-level segmentation
ID IMAGE-CONTRAST ENHANCEMENT
AB Histogram equalization (HE) is a classical enhancement method for image processing. However, conventional HE techniques have poor performance in terms of preserving the brightness and natural appearance of images, meaning they typically fail to produce satisfactory results. A novel two-dimensional HE method with two-level segmentation for refining image brightness is proposed in this paper. Additionally, a modified two-dimensional histogram is generated to determine the locations of main segmentation points based on neighborhood matrices. The weights of the absolute brightness differences between low and high local contrast regions in this two-dimensional histogram are adjustable. After separating images into two main areas based on main segmentation points, multiple sub-segmentation points are selected based on a novel criterion derived from the maximum value distribution of the double histograms. Experimental results for various test images demonstrate that the proposed method achieves excellent performance in terms of brightness preservation and image contrast enhancement.
C1 [Cao, Qingjie; Shi, Zaifeng; Wang, Rong; Wang, Pumeng; Yao, Suying] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
   [Cao, Qingjie] Tianjin Normal Univ, Sch Math Sci, Tianjin, Peoples R China.
   [Shi, Zaifeng] Tianjin Key Lab Imaging & Sensing Microelect Tech, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin Normal University
RP Shi, ZF (corresponding author), Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.; Shi, ZF (corresponding author), Tianjin Key Lab Imaging & Sensing Microelect Tech, Tianjin, Peoples R China.
EM qingjiecao@tjnu.edu.cn; shizaifeng@tju.edu.cn; rongw@tju.edu.cn;
   wpm212121@tju.edu.cn; syyao@tju.edu.cn
OI Shi, Zaifeng/0000-0002-3851-5697; rong, wang/0000-0003-2977-3325
FU National Natural Science Foundation of China [61674115]; Natural Science
   Foundation of Tianjin, China [17JCYBJC15900]
FX This paper was supported by the National Natural Science Foundation of
   China (No. 61674115) and the Natural Science Foundation of Tianjin,
   China (No.17JCYBJC15900).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   [Anonymous], 2012, Journal of Information Hiding and Multimedia Signal Processing
   Arriaga-Garcia EF, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.053009
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2290, DOI 10.1109/TIP.2006.875204
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Hoseini P, 2013, DIGIT SIGNAL PROCESS, V23, P879, DOI 10.1016/j.dsp.2012.12.011
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kumar SP, 2013, IMAGING SCI J, V61, P447, DOI 10.1179/1743131X12Y.0000000031
   Kumarbarode M, 2015, INT J COMPUT VISION, V110, P32, DOI [10.5120/19380-1086, DOI 10.5120/19380-1086]
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Menotti D, 2007, IEEE T CONSUM ELECTR, V53, P1186, DOI 10.1109/TCE.2007.4341603
   Muslim HSM, 2019, COMPUT MATH ORGAN TH, V25, P108, DOI 10.1007/s10588-018-9274-8
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Sengee N, 2010, IEEE T CONSUM ELECTR, V56, P2727, DOI 10.1109/TCE.2010.5681162
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao Z, 2016, 2016 8 INT C WIR COM, DOI 10.1109/WCSP.2016.7752466
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 28
TC 7
Z9 7
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27091
EP 27114
DI 10.1007/s11042-020-09265-y
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551000800001
DA 2024-07-18
ER

PT J
AU Bernardi, A
   Gadia, D
   Maggiorini, D
   Palazzi, CE
   Ripamonti, LA
AF Bernardi, Alessio
   Gadia, Davide
   Maggiorini, Dario
   Palazzi, Claudio Enrico
   Ripamonti, Laura Anna
TI Procedural generation of materials for real-time rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Procedural content generation; Computer graphics; Layered material;
   Genetic algorithm; Real-time rendering
AB The use of Procedural Content Generation techniques in the production of Video Games has seen a large diffusion in these last years. Regarding the procedural generation of Computer Graphics content, several works have been proposed about the automatic construction of complex models and environments, or about the instancing of several copies of a reference model, each with peculiar differences to introduce variety. However, very few works have proposed techniques for the procedural production of complex materials to be assigned to these generated models. In this paper, we present a method for the automatic generation of realistic layered materials based on the application of a Genetic Algorithm. We show that, with the proposed approach, is possible to generate several instances of a target material (e.g., a car paint, or a rusty metal), maintaining a desired level of closeness to the overall characteristics of the simulated interaction between the light and the surface, but introducing also a controlled amount of differences in the final reproduction of the perceived appearance.
C1 [Bernardi, Alessio; Gadia, Davide; Maggiorini, Dario; Ripamonti, Laura Anna] Univ Milan, Dept Comp Sci, Via Celoria 18, I-20133 Milan, Italy.
   [Palazzi, Claudio Enrico] Univ Padoa, Dept Math, Via Trieste 63, I-35131 Padua, Italy.
C3 University of Milan
RP Gadia, D (corresponding author), Univ Milan, Dept Comp Sci, Via Celoria 18, I-20133 Milan, Italy.
EM alessio.bernardi@studenti.unimi.it; gadia@di.unimi.it;
   dario@di.unimi.it; cpalazzi@math.unipd.it; ripamonti@di.unimi.it
RI Ripamonti, Laura Anna/GQH-8599-2022; Gadia, Davide/P-6309-2016
OI Gadia, Davide/0000-0003-4491-9150; Maggiorini, Dario/0000-0002-7460-2966
CR Agliata F, 2019, 20TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND SIMULATION (GAME-ON 2019), P45
   Andrade G., 2005, Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems, P1111, DOI DOI 10.1145/1082473.1082648
   [Anonymous], 2018, Real-Time Rendering, Fourth Edition, DOI DOI 10.1201/B22086
   [Anonymous], 2016, PHYS BASED RENDERING
   [Anonymous], 2019, VULKAN API HOMEPAGE
   Ashlock D., 2016, PROCEDURAL CONTENT G, P159, DOI 10.1007/978-3-319-42716-4_9
   Baldwin Alexander, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P25, DOI 10.1109/CIG.2017.8080411
   Belcour L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201289
   Bernardi A, 2019, 20TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND SIMULATION (GAME-ON 2019), P29
   Botta M., 2012, 2012 IEEE Conference on Computational Intelligence and Games (CIG 2012), P108, DOI 10.1109/CIG.2012.6374145
   Brady A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601193
   Byun S, 2006, 2006 10TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P953
   Chen GN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360702
   Compton P, 2006, BCS CONF SERIES, P109, DOI 10.1007/1-84628-224-1_9
   de Carvalho Leonardo Filipe Batista Silva, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P526, DOI 10.1109/ICICISYS.2010.5658282
   De Francesco A, 2019, CEUR WORKSHOP PROC
   Ebert D.S., 2003, TEXTURING MODELING, V3rd
   Frade M, 2012, SOFT COMPUT, V16, P1893, DOI 10.1007/s00500-012-0863-z
   GRANT IP, 1969, PROC R SOC LON SER-A, V313, P183, DOI 10.1098/rspa.1969.0187
   Guarneri A, 2013, 12 EUROPEAN C ARTIFI, P585, DOI 10.7551/978-0-262-31709-2-ch084
   Hastings EJ, 2009, IEEE T COMP INTEL AI, V1, P245, DOI 10.1109/TCIAIG.2009.2038365
   Krecklau L, 2011, COMPUT GRAPH FORUM, V30, P335, DOI 10.1111/j.1467-8659.2011.01864.x
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Masia B., 2009, P 2009 SPRING C COMP
   Mazza C., 2017, PROCEEDING 12 BIANNU, P22
   Mora AM, 2010, LECT NOTES COMPUT SC, V6024, P171, DOI 10.1007/978-3-642-12239-2_18
   Missura O, 2009, LECT NOTES ARTIF INT, V5808, P197, DOI 10.1007/978-3-642-04747-3_17
   Mokrzycki W. S., 2011, Machine Graphics & Vision, V20, P383
   Mora A. M., 2010, 2010 IEEE Information Theory Workshop (ITW 2010), P241, DOI 10.1109/ITW.2010.5593347
   Mourato F, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Norton D, 2017, CEUR WORKSHOP PROC
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Pena JM, 2014, 2014 IEEE C COMP INT, P1
   Piergigli D., 2019, P 2019 IEEE C GAM LO, P1, DOI DOI 10.1109/CIG.2019.8848061
   Prusinkiewicz P., 2004, The Algorithmic Beauty of Plants
   Ripamonti L.A., 2017, P IEEE DIG ENT NETW
   Ripamonti LA, 2017, MULTIMED TOOLS APPL, V76, P5001, DOI 10.1007/s11042-016-3636-3
   Rizzi A, 2013, COLOR IMAGING 18 DIS
   Scalabrin M., 2016, P IS TS STER DISPL A, V5, P1
   Schwarz M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766956
   Sitthi-amorn P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024186
   Snodgrass Sam, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P280, DOI 10.1109/CIG.2017.8080447
   Togelius J, 2007, P IEEE S COMP INT GA
   Walter B., 2007, EUROGRAPHICS C RENDE
   Weber J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P119, DOI 10.1145/218380.218427
   Yannakakis GN, 2009, IEEE T COMP INTEL AI, V1, P121, DOI 10.1109/TCIAIG.2009.2024533
NR 47
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 12969
EP 12990
DI 10.1007/s11042-020-09141-9
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000548791400003
OA Bronze
DA 2024-07-18
ER

PT J
AU Stuner, B
   Chatelain, C
   Paquet, T
AF Stuner, Bruno
   Chatelain, Clement
   Paquet, Thierry
TI Handwriting recognition using cohort of LSTM and lexicon verification
   with extremely large lexicon
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cohort; LSTM; Handwriting recognition
ID NUMERICAL FIELD EXTRACTION; NEURAL-NETWORK; WORD RECOGNITION;
   CLASSIFICATION; ONLINE
AB In this article, a handwriting recognition model whose complexity does not depend on the lexicon size is proposed. It is an alternative to lexicon-driven decoding, based on alexicon verificationprocess that allows to deal with millions of words, without any time consuming decoding stage. This lexicon verification is included in a cascade framework that uses complementary LSTM RNN classifiers. An original and very efficient method to obtain hundreds of complementary LSTM RNN extracted from a single training, calledcohort, is proposed. The proposed approach achieves new state-of-the art performance on the Rimes and IAM datasets, and provides 90% of accuracy on the Rimes dataset when dealing with a gigantic lexicon record of 3 millions of words. The last contribution extends the idea of cohort and lexicon verification in a ROVER combination for handwriting line recognition, and achieves state-of-the-art results on the Rimes dataset.
C1 [Stuner, Bruno; Chatelain, Clement; Paquet, Thierry] Normandie Univ, UNIROUEN, INSA Rouen, LITIS, F-76000 Rouen, France.
C3 Universite Le Havre Normandie; Universite de Rouen Normandie
RP Stuner, B (corresponding author), Normandie Univ, UNIROUEN, INSA Rouen, LITIS, F-76000 Rouen, France.
EM bruno.stuner@gmail.com
RI chatelain, clement/AAC-7383-2022
OI chatelain, clement/0000-0001-8377-0630
CR [Anonymous], 2008, Advances in Neural Information Processing Systems
   Bharath A, 2012, IEEE T PATTERN ANAL, V34, P670, DOI 10.1109/TPAMI.2011.234
   Bideault G, 2015, DOCUMENT RECOGNITION
   Bluche T, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P161, DOI 10.1109/DAS.2014.40
   Brakensiek A, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P357, DOI 10.1109/IWFHR.2002.1030936
   Chatelain C, 2006, LECT NOTES COMPUT SC, V3872, P564
   Chatelain C, 2006, INT C PATT RECOG, P224
   Chelba C., ARXIV13123005
   Choromanska A, 2015, JMLR WORKSH CONF PRO, V38, P192
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   El Abed Haikal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1388, DOI 10.1109/ICDAR.2009.284
   El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288
   Fiscus JG, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P347, DOI 10.1109/ASRU.1997.659110
   FISSORE L, 1988, SPEECH COMMUN, V7, P355, DOI 10.1016/0167-6393(88)90051-9
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves Alex., RNNLIB: A recurrent neural network library for sequence learning problems "
   Grosicki Emmanuele, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1398, DOI 10.1109/ICDAR.2009.184
   Hamdani M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P111, DOI 10.1109/DAS.2014.61
   Hamdani M, 2013, PROC INT CONF DOC, P280, DOI 10.1109/ICDAR.2013.63
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Koerich AL, 2003, PATTERN ANAL APPL, V6, P97, DOI 10.1007/s10044-002-0169-3
   Kozielski M, 2013, INT CONF ACOUST SPEE, P8257, DOI 10.1109/ICASSP.2013.6639275
   Madhvanath S, 2001, PATTERN RECOGN, V34, P37, DOI 10.1016/S0031-3203(99)00201-0
   Madhvanath S, 1996, P SOC PHOTO-OPT INS, V2660, P224, DOI 10.1117/12.234704
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Menasri F, 2012, DOCUMENT RECOGNITION, p82970Y
   Mioulet L., 2015, PROC SPIE THE INT SO
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Poznanski A, 2016, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2016.253
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Senior A, 1996, ADV NEUR IN, V8, P743
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shridhar M, 1997, PROC INT CONF DOC, P861, DOI 10.1109/ICDAR.1997.620634
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Zamora-Martínez F, 2014, PATTERN RECOGN, V47, P1642, DOI 10.1016/j.patcog.2013.10.020
   Zhang BL, 2013, IEEE T INTELL TRANSP, V14, P322, DOI 10.1109/TITS.2012.2213814
   Zhang P, 2007, PATTERN RECOGN, V40, P3415, DOI 10.1016/j.patcog.2007.03.022
NR 47
TC 15
Z9 17
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34407
EP 34427
DI 10.1007/s11042-020-09198-6
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000546532400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Min, J
   Ahn, J
   Ahn, S
   Choi, H
   Ahn, S
AF Min, Jihyun
   Ahn, Jaehong
   Ahn, Sohyun
   Choi, Heesu
   Ahn, Sangdoo
TI Digital imaging methods for painting analysis: the application of RTI
   and 3D scanning to the study of brushstrokes and paintings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brushstroke; Painting analysis; Reflectance transformation imaging; 3D
   scanning
ID DOCUMENTATION
AB This work presents digital imaging technology as a tool for studying artists' brushstroke patterns and painting techniques. Digital imaging analysis performed using reflectance transformation imaging (RTI) and three-dimensional (3D) scanning was used to observe the morphological textures of brushstrokes formed on the painted surface; this provided a "digital fingerprint" to indicate an individual artist's specific characteristics. A model specimen was produced to examine the relationship between paint and painting tools. For painting tools, twelve types of brushes were chosen from the artist's studio. The results revealed distinctive features among the different types of brushes. The model specimen was then further compared with the artist's works and a replicated painting was also produced for comparison with one of the original works. The overall result provided information about similar patterns corresponding to the types of brushes the artist used for the model specimen and paintings. Distinctive painting pattern features were detected in the replica, although it was painted using the same material and type of brush.
C1 [Min, Jihyun; Ahn, Sohyun; Choi, Heesu; Ahn, Sangdoo] Chung Ang Univ, Dept Sci Cultural Properties, Seoul 06974, South Korea.
   [Ahn, Jaehong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea.
   [Ahn, Sangdoo] Chung Ang Univ, Dept Chem, Seoul 06974, South Korea.
C3 Chung Ang University; Korea Advanced Institute of Science & Technology
   (KAIST); Chung Ang University
RP Ahn, S (corresponding author), Chung Ang Univ, Dept Sci Cultural Properties, Seoul 06974, South Korea.; Ahn, S (corresponding author), Chung Ang Univ, Dept Chem, Seoul 06974, South Korea.
EM sangdoo@cau.ac.kr
RI Ahn, Sangdoo/A-4615-2009; Li, Mengqi/AAG-6804-2021
OI Ahn, Sangdoo/0000-0003-3803-9210
FU Art Appraisal & Authentication Infrastructure Project through the
   Ministry of Culture, Sports and Tourism; Korea Arts Management Service
   (KAMS); National Research Foundation of Korea grant - Korean government
   (Ministry of Science ITC & Future Planning) [2017R1C1B1012808]
FX This work was supported by the Art Appraisal & Authentication
   Infrastructure Project through the Ministry of Culture, Sports and
   Tourism, the Korea Arts Management Service (KAMS) (KAMS-2018), and the
   National Research Foundation of Korea grant, which was funded by the
   Korean government (Ministry of Science ITC & Future Planning)
   (No.2017R1C1B1012808).
CR Akca D., 2007, OPTICAL 3 D MEASUREM, V2, P50, DOI DOI 10.3929/ETHZ-A-005748653
   Artal-Isbrand P, 2011, MRS ONLINE P LIB ARC, V1319, DOI [10.1557/opl.2011.793, DOI 10.1557/OPL.2011.793]
   Boute R, 2018, IOP CONF SER-MAT SCI, V364, DOI 10.1088/1757-899X/364/1/012060
   Breuckmann B, 2009, MAKING HIST INTERACT, P42
   Breuckmann B, 2011, EUR SIGNAL PR CONF, P1249
   Clarricoates R, 2019, J INST CONSERV, V42, P135, DOI 10.1080/19455224.2019.1605919
   Earl G, 2010, J ARCHAEOL SCI, V37, P2040, DOI 10.1016/j.jas.2010.03.009
   Fontana R, 2003, P SOC PHOTO-OPT INS, V5146, P88, DOI 10.1117/12.501247
   Jaehong Ahn, 2013, 2013 Digital Heritage International Congress (DigitalHeritage). Federating the 19th Int'I VSMM, 10th Eurographics GCH, & 2nd UNESCO Memory of the World Conferences, plus special sessions from CAA, Arqueologico 2.0, Space2Place, ICOMOS ICIP & CIPA, EU projects, et al. Proceedings, P387
   Kotoula Eleni., 2013, E CONSERVATION, P74
   Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320
   Manfredi M, 2014, SENSORS-BASEL, V14, P12271, DOI 10.3390/s140712271
   Ono S, ICOM 200 18 TRIENN C
   Padfield J, 2005, 14 TRIENN M HAG 12 1, V1, P1
   Tamayo SNM, 2013, INT J CONSERV SCI, V4, P535
NR 15
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25427
EP 25439
DI 10.1007/s11042-020-09263-0
EA JUL 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545796600002
DA 2024-07-18
ER

PT J
AU Al-Zu'bi, S
   Hawashin, B
   Mughaid, A
   Baker, T
AF Al-Zu'bi, Shadi
   Hawashin, Bilal
   Mughaid, Ala
   Baker, Thar
TI Efficient 3D medical image segmentation algorithm over a secured
   multimedia network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Hidden Markov Model (HMM); Computer aided diagnosis;
   Multimedia networking security; Distributed systems
ID CT; SYSTEM
AB Image segmentation has proved its importance and plays an important role in various domains such as health systems and satellite-oriented military applications. In this context, accuracy, image quality, and execution time deem to be the major issues to always consider. Although many techniques have been applied, and their experimental results have shown appealing achievements for 2D images in real-time environments, however, there is a lack of works about 3D image segmentation despite its importance in improving segmentation accuracy. Specifically, HMM was used in this domain. However, it suffers from the time complexity, which was updated using different accelerators. As it is important to have efficient 3D image segmentation, we propose in this paper a novel system for partitioning the 3D segmentation process across several distributed machines. The concepts behind distributed multimedia network segmentation were employed to accelerate the segmentation computational time of training Hidden Markov Model (HMMs). Furthermore, a secure transmission has been considered in this distributed environment and various bidirectional multimedia security algorithms have been applied. The contribution of this work lies in providing an efficient and secure algorithm for 3D image segmentation. Through a number of extensive experiments, it was proved that our proposed system is of comparable efficiency to the state of art methods in terms of segmentation accuracy, security and execution time.
C1 [Al-Zu'bi, Shadi; Hawashin, Bilal] Al Zaytoonah Univ Jordan, Fac Sci & IT, Amman, Jordan.
   [Mughaid, Ala] Hashemite Univ, Comp Sci Dept, Zarqa, Jordan.
   [Baker, Thar] Liverpool John Moores Univ, Liverpool, Merseyside, England.
C3 Al-Zaytoonah University of Jordan; Hashemite University; Liverpool John
   Moores University
RP Al-Zu'bi, S (corresponding author), Al Zaytoonah Univ Jordan, Fac Sci & IT, Amman, Jordan.
EM smalzubi@zuj.edu.jo; b.hawashin@zuj.edu.jo; ala.mughaid@hu.edu.jo;
   t.baker@ljmu.ac.uk
RI Baker, Thar/H-6073-2019; alzubi, shadi/W-4507-2018
OI Baker, Thar/0000-0002-5166-4873; Hawashin, Bilal/0000-0002-4913-6940;
   alzubi, shadi/0000-0003-4173-2323; Mughaid, Ala/0000-0002-1298-6933
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al Zu'bi S, 2010, PROCEEDINGS OF THE 2010 IEEE ASIA PACIFIC CONFERENCE ON CIRCUIT AND SYSTEM (APCCAS), P604, DOI 10.1109/APCCAS.2010.5774847
   Al-Zu'bi S, 2017, PROCEDIA COMPUT SCI, V113, P531, DOI 10.1016/j.procs.2017.08.318
   AlZu'bi S., 2018, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-020-08676-1
   AlZu'bi S, 2018, CONCURR COMP-PRACT E
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZubi S., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P287, DOI 10.1109/IEEEGCC.2011.5752537
   AlZubi S., 2011, THESIS
   AlZubi S., 2012, 2012 INT C INN INF T, P156
   AlZubi S, 2011, INT J BIOMED IMAGING, V2011, DOI 10.1155/2011/136034
   [Anonymous], 2006, THESIS
   [Anonymous], 2018, 2018 IEEE INT ULTR S
   [Anonymous], 2017, MAT BASEL
   [Anonymous], 2011, 2011 IEEE INT WORKSH
   [Anonymous], 1999, THESIS
   [Anonymous], 2009, Image processing and mathematical morphology fundamentals and applications
   Badura P, 2011, ECTA 2011/FCTA 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON FUZZY COMPUTATION THEORY AND APPLICATIONS, P486, DOI 10.5220/0003670904860492
   Bezdek James C., 1981, PATTERN RECOGN
   Computerized Imaging Reference Systems I, 2013, TRIPL MOD 3D ABD PHA
   García-Vázquez V, 2017, Z MED PHYS, V27, P218, DOI 10.1016/j.zemedi.2016.07.002
   Gek Hong Sim, 2011, 2011 International Conference on Information Networking (ICOIN), P86, DOI 10.1109/ICOIN.2011.5723139
   Guo ZH, 2018, I S BIOMED IMAGING, P1230, DOI 10.1109/ISBI.2018.8363793
   Happ PN, 2015, INT GEOSCI REMOTE SE, P4352, DOI 10.1109/IGARSS.2015.7326790
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Hussein WA, 2017, 2017 IEEE 13TH MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P136, DOI 10.1109/MICC.2017.8311747
   (IEC) IEC (NEMA) NEMA, 2001, NEM STAND PUBL, Vnu2
   Jararweh Y., 2011, 2011 IEEE JORD C APP, P1, DOI DOI 10.1109/AEECT.2011.6132516
   Jung C, 2018, J REAL-TIME IMAGE PR, V14, P501, DOI 10.1007/s11554-015-0513-7
   Kostrzewa M, 2015, EUR J RADIOL, V84, P1970, DOI 10.1016/j.ejrad.2015.06.028
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2016, NEUROCOMPUTING, V173, P501, DOI 10.1016/j.neucom.2015.06.041
   Liu W, 2016, IEEE MULTIMEDIA, V23, P75, DOI 10.1109/MMUL.2016.39
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Osher Stanley, 2002, LEVEL SET METHODS DY
   Otake Y, 2012, IEEE T MED IMAGING, V31, P948, DOI 10.1109/TMI.2011.2176555
   Peng HC, 2000, IEEE C EVOL COMPUTAT, P272, DOI 10.1109/CEC.2000.870306
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Sleman AA, 2019, 2019 IEEE INT C IM S, P1
   Sun YR, 2020, IEEE ACCESS, V8, P26457, DOI 10.1109/ACCESS.2020.2971542
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   von Berg J, 2004, INT CONGR SER, V1268, P492, DOI 10.1016/j.ics.2004.03.171
   Wieclawek W, 2015, COMPUT MED IMAG GRAP, V43, P122, DOI 10.1016/j.compmedimag.2015.01.003
   Wieclawek W, 2008, ADV INTEL SOFT COMPU, V47, P93
   Wieclawek W, 2007, P ANN INT IEEE EMBS, P5645, DOI 10.1109/IEMBS.2007.4353627
   Won HJ, 2017, DIAGN INTERV RADIOL, V23, P233, DOI 10.5152/dir.2017.16422
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zarychta P, 2012, LECT N BIOINFORMAT, V7339, P93
   Zhang L., 2020, IEEE T MED IMAGING
   Zhang XX, 2015, IEEE ACM INT SYMP, P777, DOI 10.1109/CCGrid.2015.108
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
   Zhou J, 2011, PHYS MED BIOL, V56, P6739, DOI 10.1088/0031-9155/56/20/015
NR 52
TC 33
Z9 33
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16887
EP 16905
DI 10.1007/s11042-020-09160-6
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000542142900002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ghazvini, M
   Mirzadi, M
   Parvar, N
AF Ghazvini, Mahdieh
   Mirzadi, Mojdeh
   Parvar, Negin
TI A modified method for image encryption based on chaotic map and genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Security; Genetic algorithm
ID SYSTEM
AB The security of digital data has been attending more than past, spatially image data security. In this study, a hybrid image encryption method has been proposed based on genetic algorithm and chaos. Encryption process consists of three main steps: confusion phase, diffusion phase, and improvement phase using a genetic algorithm. At first, Chen's chaotic map is used in the confusion phase to generate a scrambled image by shuffling plain-image pixels, and in the diffusion step, Logistic-Sine map alters those pixels gray-level values. It produces some of encrypted images which were considered as the initial population for the genetic algorithm. Then, by using the genetic algorithm, the encrypted images are optimized as much as possible. Finally, the best encrypted image is the final cipher image. The experimental results and several security analyses show that the proposed modified method provides an efficient scheme for image encryption and good robustness against frequent statistical and security attacks.
C1 [Ghazvini, Mahdieh; Mirzadi, Mojdeh] Shahid Bahonar Univ Kerman, Dept Comp Engn, Fac Engn, Kerman, Iran.
   [Parvar, Negin] Islamic Azad Univ, Kerman Branch, Dept Comp Engn, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK); Islamic Azad University
RP Ghazvini, M (corresponding author), Shahid Bahonar Univ Kerman, Dept Comp Engn, Fac Engn, Kerman, Iran.
EM mghazvini@uk.ac.ir; m.mirzadi@gmail.com; n_parvar@yahoo.com
RI Ghazvini, Mahdieh/AAC-1630-2022
OI Ghazvini, Mahdieh/0000-0002-3647-2101
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Attaullah, 2020, WIRELESS PERS COMMUN, V110, P1429, DOI 10.1007/s11277-019-06793-1
   Badoni P, 2016, J EXP BIOL AGRIC SCI, V4, P7, DOI 10.18006/2015.4(1).07.15
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Boloorchi M, 2017, CAN CON EL COMP EN
   Çavusoglu Ü, 2019, CLUSTER COMPUT, V22, P1211, DOI 10.1007/s10586-018-02895-w
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fadhel S., 2017, B ELECT ENG INFORM, V6, P99, DOI [10.11591/eei.v6i1.599, DOI 10.11591/EEI.V6I1.599]
   Flores-Vergara A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030268
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gayathri J., 2016, International Journal of Information and Computer Security, V8, P347
   Hu HP, 2013, COMPUT PHYS COMMUN, V184, P765, DOI 10.1016/j.cpc.2012.11.017
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Lü JH, 2002, INT J BIFURCAT CHAOS, V12, P659, DOI 10.1142/S0218127402004620
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Nepomuceno EG, 2019, CHAOS, V29, DOI 10.1063/1.5099261
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Noshadian S, 2018, MULTIMED TOOLS APPL, P1
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Song W, 2020, INFORM SCI
   Takkar P, 2017, IMAGE ENCRYPTION APP
   Tewani R., 2020, ADV DATA SCI SECURIT, P363
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang M, 2019, P 2 INT ACM WORKSH S
   Zhang QY, 2019, IET IMAGE PROCESS, V13, P2905, DOI 10.1049/iet-ipr.2019.0667
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 37
TC 41
Z9 42
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26927
EP 26950
DI 10.1007/s11042-020-09058-3
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000541402000005
DA 2024-07-18
ER

PT J
AU Hardalac, F
   Yasar, H
   Akyel, A
   Kutbay, U
AF Hardalac, Firat
   Yasar, Huseyin
   Akyel, Anil
   Kutbay, Ugurhan
TI A novel comparative study using multi-resolution transforms and
   convolutional neural network (CNN) for contactless palm print
   verification and identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contactless palm print verification and identification; Discrete cosine
   transform; Discrete wavelet transform; Contourlet transform; Ripplet-I
   transform; Principal component analysis; Local binary pattern;
   Artificial neural network; Euclidean distance; Support vector machine;
   Convolutional neural network
ID WAVELET; EXTRACTION; RIPPLET; IMAGES; FUSION
AB Palm print scanning is a widespread method for biometric identity detection which has some advantages over other methods including its simplicity and relatively lower cost. In this study, a novel methods for biometric verification and identification by contactless palm scanning technique is proposed. In the study, Ripplet-I Transform (R-IT) which is a generalized form of Curvelet Transform (CuT), have been used in addition to multi-resolution transforms which were previously used in the literature as palm print verification and identification methods such as Discrete Cosine Transform (DCT), Discrete Wavelet Transform (DWT), Contourlet Transform (CoT). In addition, Principal Component Analysis (PCA) and Local Binary Pattern (LBP) have been utilized to increase the algorithm diversity. In order to investigate the effect of classification methods on the study results and the processing times, Artificial Neural Network (ANN), Euclidean Distance (ED) and Support Vector Machine (SVM) have been used separately for matching in the verification part of study. The performance of Convolutional Neural Network (CNN) as a classifier has also been examined. Verification and identification algorithms proposed in the study have been tested using palm print images of Hong Kong Polytechnic University Contact-free 3D/2D Hand Images Database (Version 1.0). The studies, that were carried out under two main sections yielded interesting results. At the end of the study, AUC (Area Under the ROC Curve) values ranging from 0.550 (Equal Error Rate (EER)= 0.4594) to 0.9875 (EER= 0.0336) were obtained for palm print verification. The highest AUC value without using LBP was obtained as 0.9563 (EER= 0.1096) using R-IT/CuT+DCT+CNN. Study results were showed that CNN is more successful than other classifiers without using LBP. It also has pointed out that the R-IT/CuT provides better results than the DWT and CoT. Using LBP in algorithms has increased success for ED, SVM and ANN. However, it has reduced overall for CNN. The highest AUC value (0.9875 and EER= 0.0336) was provided by the LBP+DWT+ED algorithm for palm print verification. The highest Identification Rate (IR) was achieved by using the LBP+CoT+ED algorithm with 84.444% for for palm print identification.
C1 [Hardalac, Firat; Akyel, Anil; Kutbay, Ugurhan] Gazi Univ, Dept Elect & Elect Engn, Ankara, Turkey.
   [Yasar, Huseyin] Minist Hlth Republ Turkey, Elect & Elect Engn, Ankara, Turkey.
C3 Gazi University; Ministry of Health - Turkey
RP Yasar, H (corresponding author), Minist Hlth Republ Turkey, Elect & Elect Engn, Ankara, Turkey.
EM firat@gazi.edu.tr; mirhendise@gmail.com; anilakyel@gazi.edu.tr;
   ukutbay@gazi.edu.tr
RI Akyel, Anol/ABD-5456-2021; Akyel, Anıl/ABD-6397-2021; Yaşar,
   Hüseyin/GLV-6400-2022; KUTBAY, Ugurhan/AAP-8534-2020
OI Akyel, Anıl/0000-0001-7393-526X; Yaşar, Hüseyin/0000-0002-7583-980X;
   KUTBAY, Ugurhan/0000-0003-2167-9107
CR Ahmad MI, 2014, INT CONF SYST SIGNAL, P79
   Alsubari A, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P748, DOI 10.1109/NGCT.2016.7877510
   [Anonymous], 2019, SP TECHNOL TEXT MIN
   [Anonymous], P INT C COMP GRAPH I
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Ceylan M, 2016, TURK J ELECTR ENG CO, V24, P3212, DOI 10.3906/elk-1408-157
   Chen GY, 2010, PATTERN RECOGN, V43, P579, DOI 10.1016/j.patcog.2009.08.020
   Chen XH, 2009, INT J IMAG SYST TECH, V19, P350, DOI 10.1002/ima.20212
   Choge HK, 2009, LECT NOTES COMPUT SC, V5863, P639, DOI 10.1007/978-3-642-10677-4_73
   Cummins H., 1961, FINGER PRINTS PALMS
   Dale MP, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P221, DOI 10.1109/ICAPR.2009.76
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   DEWAN S, 2003, ELEMENTARY WATSON SC
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Galton F., 1965, FINGERPRINTS
   *HONG KONG POL U, 2011, HONG KONG POL U CONT
   Imtiaz Hafiz, 2010, 2010 International Conference on Communication Control and Computing Technologies, P657, DOI 10.1109/ICCCCT.2010.5670758
   IMTIAZ H, 2014, INT C EL ENG INF COM, P1
   Imtiaz H, 2013, DIGIT SIGNAL PROCESS, V23, P244, DOI 10.1016/j.dsp.2012.06.016
   Isnanto R.R., 2017, 2 INT C ONINFORMATIC, V12, P1
   Jaswal G, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P210, DOI 10.1109/ICSPCom.2015.7150649
   Jiwen Lu, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P2096, DOI 10.1109/ICOSP.2008.4697558
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   KISKU DR, 2011, MOBILE MULTIMEDIA IM, V8063
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng R, 2010, GREAT WEALTH, POOR HEALTH: CONTEMPORARY ISSUES IN EATING AND LIVING, P1
   MASOOD H, 2008, INT S BIOM SEC TECHN, P1
   Murukesh C, 2018, INT J SMART SENS INT, V11, DOI 10.21307/ijssis-2018-006
   *NSTC SUBC BIOM, 2009, PALM PRINT REC
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pan X, 2008, INT CONF SIGN PROCES, P2109
   PATIL JJ, 2015, INT C EN SYST APPL, P1
   Prasad SM, 2011, SECUR COMMUN NETW, V4, P577, DOI 10.1002/sec.234
   RIOSSANCHEZ B, 2017, INT CARN C SEC TECHN, P1
   Sanyal N, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P236, DOI 10.1109/CALCON.2017.8280731
   Sanyal N, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P455, DOI 10.1109/ReTIS.2015.7232922
   Saranraj S, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P490, DOI 10.1109/WiSPNET.2016.7566183
   SEMWAL VB, 2014, ROBOT AUTON SYST, V21
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   SHASHIKALA KP, 2012, PALMPRINT IDENTIFICA, P105
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Tamrakar D., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P20, DOI 10.1109/CICN.2010.15
   Thepade SD, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1232
   Thilagavathi T., 2015, INDIAN J SCI TECHNOL, V8, P147
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VAPNIK VN, 1964, AUTOMAT REM CONTR+, V25, P103
   Varshney V, 2014, IEEE INT SYMP SIGNAL, P7, DOI 10.1109/ISSPIT.2014.7300555
   Vu PF, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2982, DOI 10.1109/ICMLC.2008.4620918
   Wang XC, 2011, PROCEDIA ENGINEER, V23, DOI 10.1016/j.proeng.2011.11.2506
   Wu XQ, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1253, DOI 10.1109/ICMLC.2002.1167403
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Yan-Xia Wang, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1130, DOI 10.1109/ICMLC.2012.6359513
   Yasar H, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P745, DOI 10.1109/SIU.2016.7495847
   Zhang SW, 2008, LECT NOTES COMPUT SC, V5227, P1101, DOI 10.1007/978-3-540-85984-0_132
NR 61
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22929
EP 22963
DI 10.1007/s11042-020-09005-2
EA JUN 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000537042100001
DA 2024-07-18
ER

PT J
AU Kim, H
   Kim, H
   Hwang, E
AF Kim, Hyungjoon
   Kim, Hyeonwoo
   Hwang, Eenjun
TI Real-time shape tracking of facial landmarks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial landmarks; Real-time tracking; SegNet; Point tracker; Virtual
   makeup
AB Detection of facial landmarks and accurate tracking of their shape are essential in real-time applications such as virtual makeup, where users can see the makeup's effect by moving their face in diverse directions. Typical face tracking techniques detect facial landmarks and track them using a point tracker such as the Kanade-Lucas-Tomasi (KLT) point tracker. Typically, 5 or 64 points are used for tracking a face. Even though these points are enough to track the approximate locations of facial landmarks, they are not sufficient to track the exact shape of facial landmarks. In this paper, we propose a method that can track the exact shape of facial landmarks in real-time by combining a deep learning technique and a point tracker. We detect facial landmarks accurately using SegNet, which performs semantic segmentation based on deep learning. Edge points of detected landmarks are tracked using the KLT point tracker. In spite of its popularity, the KLT point tracker suffers from the point loss problem. We solve this problem by executing SegNet periodically to recalculate the shape of facial landmarks. That is, by combining the two techniques, we can avoid the computational overhead of SegNet and the point loss problem of the KLT point tracker, which leads to accurate real-time shape tracking. We performed several experiments to evaluate the performance of our method and report some of the results herein.
C1 [Kim, Hyungjoon; Kim, Hyeonwoo; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM hyungjun89@korea.ac.kr; guihon12@korea.ac.kr; ehwang04@korea.ac.kr
OI Kim, Hyungjoon/0000-0003-4580-489X
CR [Anonymous], 2018 INT C PLATF TEC
   [Anonymous], 2016, DEST V 08 SOFTWARE L
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Belaroussi R, 2005, P 9 IAPR C MACH VIS, P290
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Geonzalez RC, 2008, DIGITAL IMAGE PROCES
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim H, 2018, EVID-BASED COMPL ALT, V2018, DOI 10.1155/2018/1073509
   Kim K-S, 2007, INT C COMP SCI ITS A
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Park J, 2018, INT CONF CLOUD COMP, P181, DOI 10.1109/CloudCom2018.2018.00044
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaik Z, 2007, APPL IM PATT REC WOR
   Soille, 2013, MORPHOLOGICAL IMAGE
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wettum YC, 2017, THESIS
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 28
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15945
EP 15963
DI 10.1007/s11042-018-6814-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600009
DA 2024-07-18
ER

PT J
AU Shakeel, PM
   Desa, MI
   Burhanuddin, MA
AF Shakeel, P. Mohamed
   Desa, Mohamad Ishak
   Burhanuddin, M. A.
TI Improved watershed histogram thresholding with probabilistic neural
   networks for lung cancer diagnosis for CBMIR systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Neural networks; Watershed histogram;
   Feature extraction and segmentation
AB The past few decades have witnessed a steep increase in image data analysis for lung cancer, leading to huge repositories in the area of research in the medical sector. Content Based medical Image Retrieval (CBMIR) methods for lung cancer have been tried with the objective of facilitating access to image data. Many research works have been developed in content based medical image retrieval. But the techniques have the drawback of low efficiency and high computation cost. Image segmentation, extraction and classification methods of various kinds was taken upusing traditional methodswhich involves extraction of a specific region of interest and given to medical experts for diagnosis. The extracted region of interest region provides information useful for the for diagnosis of the disease. But the segmentation methods have some limitations such as flat valleys, noise sensitive and computational expensive which lead to reduction in the entire system performance. This is addressed by animproved watershed histogram thresholding using the probabilistic neural networks (IWHT-PNN) approach. The algorithm introduced outperforms the existing techniques improving the segmentation ratio and recognition accuracy of lung cancer which can be validated using experimental analysis.
C1 [Shakeel, P. Mohamed; Desa, Mohamad Ishak; Burhanuddin, M. A.] Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Melaka, Malaysia.
C3 Universiti Teknologi Malaysia; University Teknikal Malaysia Melaka
RP Shakeel, PM (corresponding author), Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Melaka, Malaysia.
EM shakeelji@ieee.org
RI Mohamed Shakeel, Pethuraj/P-4135-2019
CR Abdillah B, 2017, J PHYS CONF SER, V893, DOI 10.1088/1742-6596/893/1/012063
   Al-Tarawneh M.S., 2012, Leonardo Electron J Practices And Technol, V11, P147
   [Anonymous], 2018, 2018 ISTAFRICA WEEK
   Caverly TJ, 2018, ANN INTERN MED, V169, P1, DOI [10.7326/M17-2561, 10.7326/m17-2561]
   Dahab D., 2012, INT J IMAGE PROCESSI, V1, P1
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   El-Melegy MT, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-21
   El-Regaily SA, 2018, CURR MED IMAGING, V14, P3, DOI 10.2174/1573405613666170602123329
   Gaikwad A., 2016, Int. Res. J. Eng. Technol. (IRJET)
   Ghosh S, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P114, DOI 10.1109/ISBI.2012.6235497
   Gomathi P, 2020, MULTIMED TOOLS APPL, V79, P10609, DOI 10.1007/s11042-019-7301-5
   Huang WY, 2018, EPIDEMIOLOGY, V29, P126, DOI [10.1097/ede.0000000000000746, 10.1097/EDE.0000000000000746]
   Masri M, 2018, CURR PULMONOL REP, V7, P79, DOI 10.1007/s13665-018-0204-5
   Robichaux JP, 2018, NAT MED, V24, P638, DOI 10.1038/s41591-018-0007-9
   Schmid U, 2018, CANCER CHEMOTH PHARM, V81, P89, DOI 10.1007/s00280-017-3452-0
   Sene A, 2018, COGN TECHNOL WORK, V20, P245, DOI 10.1007/s10111-018-0466-2
   Shakeel PM, 2020, HEALTH TECHNOL-GER, V10, P157, DOI 10.1007/s12553-018-0279-6
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Smith A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202291
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Tanner NT, 2019, CHEST, V155, P236, DOI 10.1016/j.chest.2018.07.046
   Tiwari S, 2018, INT J INF SYST MODEL, V9, DOI 10.4018/IJISMD.2018100101
   Wang XQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010194
   Wei GH, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0874-5
   Xu J, 2020, J MATERN-FETAL NEO M, V33, P687, DOI 10.1080/14767058.2018.1497595
   Yang Tiejun, 2018, MATEC Web of Conferences, V232, DOI 10.1051/matecconf/201823203011
NR 27
TC 22
Z9 22
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17115
EP 17133
DI 10.1007/s11042-019-7662-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600073
DA 2024-07-18
ER

PT J
AU Zhang, YT
   Lu, WP
   Ou, WH
   Zhang, GQ
   Zhang, X
   Cheng, JY
   Zhang, WY
AF Zhang, Yuteng
   Lu, Wenpeng
   Ou, Weihua
   Zhang, Guoqiang
   Zhang, Xu
   Cheng, Jinyong
   Zhang, Weiyu
TI Chinese medical question answer selection via hybrid models based on CNN
   and GRU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Question answer selection; Chinese medical field; Question answering
   system; Convolutional neural network; Gated recurrent unit
ID RANKING
AB Question answer selection in the Chinese medical field is very challenging since it requires effective text representations to capture the complex semantic relationships between Chinese questions and answers. Recent approaches on deep learning, e.g., CNN and RNN, have shown their potential in improving the selection quality. However, these existing methods can only capture a part or one-side of semantic relationships while ignoring the other rich and sophisticated ones, leading to limited performance improvement. In this paper, a series of neural network models are proposed to address Chinese medical question answer selection issue. In order to model the complex relationships between questions and answers, we develop both single and hybrid models with CNN and GRU to combine the merits of different neural network architectures. This is different from existing works that can onpy capture partial relationships by utilizing a single network structure. Extensive experimental results on cMedQA dataset demonstrate that the proposed hybrid models, especially BiGRU-CNN, significantly outperform the state-of-the-art methods. The source codes of our models are available in the GitHub ().
C1 [Zhang, Yuteng; Lu, Wenpeng; Zhang, Xu; Cheng, Jinyong; Zhang, Weiyu] QiLu Univ Technol, Sch Comp Sci & Technol, Shandong Acad Sci, Jinan, Peoples R China.
   [Ou, Weihua] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Peoples R China.
   [Zhang, Guoqiang] Univ Technol Sydney, Ctr Audio Acoust & Vibrat, Sydney, NSW, Australia.
C3 Qilu University of Technology; Guizhou Normal University; University of
   Technology Sydney
RP Lu, WP (corresponding author), QiLu Univ Technol, Sch Comp Sci & Technol, Shandong Acad Sci, Jinan, Peoples R China.
EM zhangyuteng1029@163.com; lwp@qlu.edu.cn; ouweihuahust@gmail.com;
   guoqiang.zhang@uts.edu.au
RI Ou, Weihua/T-9156-2019
OI Ou, Weihua/0000-0001-5241-7703; Lu, Wenpeng/0000-0002-1840-3540
CR [Anonymous], 2012, P 2 ACM SIGHIT INT H
   [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], 2015, COMPUT SCI
   Athenikos SofiaJ., 2009, SAC '09 Proceedings of the 2009 ACM symposium on Applied Computing, P847
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cai LH, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P934, DOI 10.1109/WCICA.2016.7578491
   Cairns Brian L, 2011, AMIA Annu Symp Proc, V2011, P171
   Chao L, 2016, THESIS
   Cho K., 2014, ARXIV14061078
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Heilman Michael, 2010, Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, P1011
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu BT, 2014, ADV NEUR IN, V27
   Jain S, 2014, ADV INTELL SYST, V236, P1225, DOI 10.1007/978-81-322-1602-5_128
   LeCun Y., 2006, PREDICTING STRUCTURE, V1
   Li S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P138
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu WS, 2018, CORP SOC RESP ENV MA, V25, P844, DOI 10.1002/csr.1501
   Lu WP, 2018, IEICE T INF SYST, VE101D, P225, DOI 10.1587/transinf.2017EDP7090
   Lu WP, 2012, PRZ ELEKTROTECHNICZN, V88, P82
   Moschitti A, 2011, INFORM PROCESS MANAG, V47, P825, DOI 10.1016/j.ipm.2010.06.002
   Qiu XP, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1305
   Quan Z, 2018, WORLD WIDE WEB, V22, P1
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Shi GB, 2018, DESTECH TRANS ENVIR
   Tan Ming, 2015, Lstm-based deep learning models for non-factoid answer selection
   Toba H, 2014, INFORM SCIENCES, V261, P101, DOI 10.1016/j.ins.2013.10.030
   Tymoshenko K., 2016, 2016 C N AM CHAPTER, P1268
   Wang J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P139, DOI 10.1109/SOLI.2016.7551676
   Wang SJ, 2020, IEEE T SYST MAN CY-S, V50, P935, DOI 10.1109/TSMC.2017.2768547
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   Xiang LY, 2018, IEEE ACCESS, V6, P64131, DOI 10.1109/ACCESS.2018.2878273
   Xu X, 2018, INT PSYCHOGERIATR, V30, P1355, DOI 10.1017/S1041610217002952
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Yao Xuchen, 2013, ACL, P858
   Yen SJ, 2013, INFORM SCIENCES, V224, P77, DOI 10.1016/j.ins.2012.10.014
   Yu H, 2007, J BIOMED INFORM, V40, P236, DOI 10.1016/j.jbi.2007.03.002
   Yuan L, 2017, P 1 WORKSH SENS CONC, P31
   Zhang MS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1326
   Zhang S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7080767
   Zhou Q, 2016, PATTERN RECOGN, V59, P312, DOI 10.1016/j.patcog.2016.03.023
NR 45
TC 60
Z9 67
U1 5
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14751
EP 14776
DI 10.1007/s11042-019-7240-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900025
DA 2024-07-18
ER

PT J
AU Zhao, HH
   Rosin, PL
   Lai, YK
   Zheng, JH
   Wang, YN
AF Zhao, Hui-Huang
   Rosin, Paul L.
   Lai, Yu-Kun
   Zheng, Jin-Hua
   Wang, Yao-Nan
TI Adaptive gradient-based block compressive sensing with sparsity for
   noisy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block Compressive Sensing (CS); Adaptive; Convex optimization; Sparsity
ID SIGNAL RECOVERY; RECONSTRUCTION; ALGORITHM; PURSUIT
AB This paper develops a novel adaptive gradient-based block compressive sensing (AGbBCS_SP) methodology for noisy image compression and reconstruction. The AGbBCS_SP approach splits an image into blocks by maximizing their sparsity, and reconstructs images by solving a convex optimization problem. In block compressive sensing, the commonly used square block shapes cannot always produce the best results. The main contribution of our paper is to provide an adaptive method for block shape selection, improving noisy image reconstruction performance. The proposed algorithm can adaptively achieve better results by using the sparsity of pixels to adaptively select block shape. Experimental results with different image sets demonstrate that our AGbBCS_SP method is able to achieve better performance, in terms of peak signal to noise ratio (PSNR) and computational cost, than several classical algorithms.
C1 [Zhao, Hui-Huang] Hunan Prov Key Lab Intelligent Informat Proc & Ap, Hengyang, Hunan, Peoples R China.
   [Zhao, Hui-Huang; Zheng, Jin-Hua] Hengyang Normal Univ, Coll Comp Sci & Technol, Hengyang, Peoples R China.
   [Rosin, Paul L.; Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff, Wales.
   [Wang, Yao-Nan] Hunan Univ, Coll Elect & Informat Engn, Changsha, Peoples R China.
C3 Hengyang Normal University; Cardiff University; Hunan University
RP Zhao, HH (corresponding author), Hunan Prov Key Lab Intelligent Informat Proc & Ap, Hengyang, Hunan, Peoples R China.; Zhao, HH (corresponding author), Hengyang Normal Univ, Coll Comp Sci & Technol, Hengyang, Peoples R China.
EM happyday.huihuang@gmail.com; RosinPL@cardiff.ac.uk; LaiY4@cardiff.ac.uk;
   jhzheng@xtu.edu.cn; yaonan@hnu.cn
RI Lai, Yu-Kun/D-2343-2010; 金华, 郑/GWM-7529-2022
CR [Anonymous], 2011, ARXIV11040262
   [Anonymous], 2016, DISCRETE DYNAM NAT S
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bi DJ, 2016, DIGIT SIGNAL PROCESS, V50, P171, DOI 10.1016/j.dsp.2015.12.014
   Bigot J, 2016, IEEE T INFORM THEORY, V62, P2125, DOI 10.1109/TIT.2016.2524628
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Bo CJ, 2015, OPTIK, V126, P5806, DOI 10.1016/j.ijleo.2015.08.211
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Davenport MA, 2013, IEEE T INFORM THEORY, V59, P6820, DOI 10.1109/TIT.2013.2273491
   Deswal S., 2016, INT J SIGNAL PROCESS, V9, P293
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Eldar YC, 2010, IEEE T SIGNAL PROCES, V58, P3042, DOI 10.1109/TSP.2010.2044837
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gilbert A. C., 2012, 2012 Information Theory and Applications Workshop (ITA), P382, DOI 10.1109/ITA.2012.6181772
   Huggins PS, 2007, IEEE T SIGNAL PROCES, V55, P3760, DOI 10.1109/TSP.2007.894287
   Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Li F, 2016, IEEE T CIRC SYST VID, V26, P1697, DOI 10.1109/TCSVT.2015.2469171
   Li SC, 2013, IEEE T IND INFORM, V9, P2177, DOI 10.1109/TII.2012.2189222
   Liu H., 2015, J APPL REMOTE SENS, V9
   Lu H, 2018, FUTURE GENERATION CO
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu W, 2010, INT CONF ACOUST SPEE, P3926, DOI 10.1109/ICASSP.2010.5495799
   Melli SA, 2016, NUCL INSTRUM METH A, V806, P307, DOI 10.1016/j.nima.2015.10.013
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2012, EUR SIGNAL PR CONF, P1424
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D, 2009, FOUND COMPUT MATH, V9, P317, DOI 10.1007/s10208-008-9031-3
   Parikh N, 2016, MAGN RESON IMAGING, V34, P694, DOI 10.1016/j.mri.2015.12.033
   Qaisar S, 2013, J COMMUN NETW-S KOR, V15, P443, DOI 10.1109/JCN.2013.000083
   Qin ZJ, 2017, IEEE T COMMUN, V65, P1464, DOI 10.1109/TCOMM.2016.2623606
   Ren XZ, 2016, IEEJ T ELECTR ELECTR, V11, P140, DOI 10.1002/tee.22199
   Safavi SH, 2017, IET SIGNAL PROCESS, V11, P36, DOI 10.1049/iet-spr.2016.0176
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Unde AS, 2017, J VIS COMMUN IMAGE R, V44, P187, DOI 10.1016/j.jvcir.2017.01.028
   Wang J, 2016, IEEE T SIGNAL PROCES, V64, P1076, DOI 10.1109/TSP.2015.2498132
   Xu J, 2016, IEICE T INF SYST, VE99D, P1702, DOI 10.1587/transinf.2015EDL8230
   Xu TG, 2017, IEEE INT INTERC TECH
   YOU H., 2015, P 38 AUSTR COMP SCI, V27, P30
   Zhang ZL, 2013, IEEE T BIO-MED ENG, V60, P300, DOI 10.1109/TBME.2012.2226175
   Zhao C, 2017, IEEE T CIRC SYST VID, V27, P1182, DOI 10.1109/TCSVT.2016.2527181
   Zhao H.H., 2018, INT S ARTIFICIAL INT, P389
   Zhao HH, 2016, SOLDER SURF MT TECH, V28, P114, DOI 10.1108/SSMT-09-2014-0017
   Zhao HH, 2014, SOLDER SURF MT TECH, V26, P129, DOI 10.1108/SSMT-09-2013-0024
   Zhao WD, 2018, IEEE T MULTIMEDIA, V20, P866, DOI 10.1109/TMM.2017.2760100
NR 55
TC 7
Z9 7
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14825
EP 14847
DI 10.1007/s11042-019-7647-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900029
DA 2024-07-18
ER

PT J
AU Zhao, XF
   Lin, SX
   Chen, XF
   Ou, CC
   Liao, CP
AF Zhao, Xiaofang
   Lin, Shengxin
   Chen, Xuefang
   Ou, Chaochao
   Liao, Chunping
TI Application of face image detection based on deep learning in privacy
   security of intelligent cloud platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MTCNN; Personal image; Intelligent cloud platform; Data encryption;
   Chaotic logical diagrams
AB The application of deep learning-based face detection in the privacy and security of intelligent cloud platforms is studied, in order to resolve the risk of private photo leakage on such platforms. Five key feature points of human faces (two eyes, two noses and two corners of mouth) are sought using the multitask cascaded convolution network (MTCNN). The algorithm utilizes the intrinsic links among Proposal Network (P-Net), Refine Network (R-Net) and Output Network (O-Net) to improve their face detection performances substantially. Since many existing data encryption methods, such as DES, RSA and AES, are applicable only to test data instead of digital images, the encryption of eigenvalues is achieved with a combination of chaotic logic diagrams and RC4 stream ciphers. Meanwhile, the MTCNN-generated face coordinates and user passwords are hash-converted and double-encrypted using hash table. The results show that the face detection accuracy of MTCNN reaches 95.04%, and that the image encryption method is suitable for network transmission. The chaotic logic diagrams increase the security of S-box initialization in the RC4 algorithm. The hash structure accelerates the file reading, whereas the hash conversion improves the security of critical data. In conclusion, the proposed encryption scheme is computationally fast and highly secure.
C1 [Zhao, Xiaofang; Lin, Shengxin; Liao, Chunping] Dong Guan Univ Technol, Coll Elect Engn & Intelligentizat, Dong Guan 523808, Peoples R China.
   [Chen, Xuefang; Ou, Chaochao] Dong Guan Univ Technol, Coll Comp & Network Secur, Dong Guan 523808, Peoples R China.
   [Ou, Chaochao] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518061, Peoples R China.
C3 Dongguan University of Technology; Dongguan University of Technology;
   Shenzhen University
RP Chen, XF (corresponding author), Dong Guan Univ Technol, Coll Comp & Network Secur, Dong Guan 523808, Peoples R China.
EM 654650052@qq.com
CR [Anonymous], 2001, PROC CVPR IEEE
   [Anonymous], MACHINE INTELLIGENCE
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], FACE RECOGNITION TEC
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], MAJLESI J MULTIMEDIA
   [Anonymous], ISUAL FRONTENDWARS V
   [Anonymous], 2016, 4 INT C MACH MAT INF
   [Anonymous], TEMPLATE MATCHING BA
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Ginting Riah Ukur, 2013, 2013 International Conference on Information Technology and Electrical Engineering (ICITEE), P101, DOI 10.1109/ICITEED.2013.6676220
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Wang QZ, 2019, IEEE ACCESS, V7, P3918, DOI 10.1109/ACCESS.2018.2889782
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Zhang C, 2014, IEEE WINT CONF APPL, P1036, DOI 10.1109/WACV.2014.6835990
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 20
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16707
EP 16718
DI 10.1007/s11042-019-08014-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600050
DA 2024-07-18
ER

PT J
AU Boudra, S
   Yahiaoui, I
   Behloul, A
AF Boudra, Safia
   Yahiaoui, Itheri
   Behloul, Ali
TI A set of statistical radial binary patterns for tree species
   identification based on bark images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant identification; Bark texture; Distribution description; Radial
   Binary Pattern; SRBP; ISRBP
ID TEXTURE CLASSIFICATION; RECOGNITION; DESCRIPTOR; LBP
AB This paper deals with bark texture representation at high scale-space levels for tree species identification. The proposed approach, named, a set of statistical radial binary patterns (sSRBP), is based on the combination of a novel scale-space sampling and an LBP-like radial encoding in the distribution level. This method aims at capturing and encoding large bark structure information. The multi-scale neighborhood is formed by a set of concentric ring-shaped scale levels, in each of which the intensity distribution is represented by statistical features that provide a compact and information-preserving representation of the neighborhood. Then, the gradual distribution variation over scale levels is encoded by a macro pattern code. For each bark sample, five statistical descriptors are obtained and contribute to enhancing the texture representativeness and discriminative power. We evaluated the performances of the proposed approach on four different bark datasets and found that the novel scale-space sampling significantly improves the bark structure representation leading to enhanced performances and outperforming competitive state-of-the-art LBP-like methods. Furthermore, experiments on the color representation of bark samples improve the performances on challenging bark datasets. Moreover, comparative study between the handcrafted sSRBP texture descriptor and convolutional neural network features shows interesting generalization results on the very large BarkNet dataset.
C1 [Boudra, Safia; Behloul, Ali] Univ Batna 2, LaSTIC, Batna 05000, Algeria.
   [Yahiaoui, Itheri] Univ Reims, CReSTIC, F-51100 Reims, France.
C3 University of Batna 2; Universite de Reims Champagne-Ardenne
RP Boudra, S (corresponding author), Univ Batna 2, LaSTIC, Batna 05000, Algeria.; Yahiaoui, I (corresponding author), Univ Reims, CReSTIC, F-51100 Reims, France.
EM safia.boudra@gmail.com; itheri.yahiaoui@univ-reims.fr;
   ali.behloul@gmail.com
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 2015, COMP INT LA CCI 2015
   [Anonymous], 2008, REAL LIF IM WORKSH E
   [Anonymous], 2013, P 3 ACM C INT C MULT
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8_9
   Bertrand S, 2017, VISAPP 2017
   Boudra S., 2018, P INT C CONT BAS MUL, P1, DOI [10.1109/CBMI.2018.8516536, DOI 10.1109/CBMI.2018.8516536]
   Boudra S, 2017, LECT NOTES COMPUT SC, V10617, P101, DOI 10.1007/978-3-319-70353-4_9
   Boudra S, 2015, LECT NOTES COMPUT SC, V9386, P764, DOI 10.1007/978-3-319-25903-1_66
   Carpentier M, 2018, IEEE INT C INT ROBOT, P1075, DOI 10.1109/IROS.2018.8593514
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chi ZR, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1035
   Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55
   Fiel Stefan., 2011, 16th Computer Vision Winter Workshop, Citeseer, P1
   Godet J, 2012, GUIDE ECORCES ARBRES
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang ZK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P946, DOI 10.1109/ICIA.2006.305863
   Huang ZK, 2006, LECT NOTES COMPUT SC, V4233, P80
   Huang ZK, 2006, LECT NOTES COMPUT SC, V4113, P1121, DOI 10.1007/11816157_138
   Jing JF, 2013, J TEXT I, V104, P18, DOI 10.1080/00405000.2012.692940
   Lakmann R., 1998, BARKTEX BENCHMARK DA
   Le-Viet T, 2019, 10 INT C SIGN PROC S, V11071, P110710
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Liu L, 2012, PATTERN RECOGN, V45, P2405, DOI 10.1016/j.patcog.2011.10.027
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Mäenpää T, 2003, LECT NOTES COMPUT SC, V2749, P885
   Mirmehdi Majid., 2008, Handbook of Texture Analysis
   Mouine S, 2013, IEEE IMAGE PROC, P1466, DOI 10.1109/ICIP.2013.6738301
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Mzoughi O, 2016, MULTIMED TOOLS APPL, V75, P1615, DOI 10.1007/s11042-015-2603-8
   Mzoughi O, 2013, IEEE IMAGE PROC, P3967, DOI 10.1109/ICIP.2013.6738817
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nilsback M.E., 2009, IMAGE VISION COMPUT
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Porebski A, 2014, MULTIMED TOOLS APPL, V70, P543, DOI 10.1007/s11042-013-1418-8
   Porebski A, 2012, PATTERN ANAL APPL
   Qi XB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.40
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Ratajczak R, 2019, INT C COMP VIS THEOR
   Reme V, 2019, PATTERN RECOGNITION
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Sixta T., 2011, THESIS
   Sulc M, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0265-4
   Sulc M, 2013, INT CONF IMAG VIS, P82, DOI 10.1109/IVCNZ.2013.6726996
   Svab M., 2014, THESIS
   Nguyen TP, 2016, NEUROCOMPUTING, V173, P1565, DOI 10.1016/j.neucom.2015.09.029
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Vargas JG, 2014, DIFFERENTIAL GEOMETRY FOR PHYSICISTS AND MATHEMATICIANS: MOVING FRAMES AND DIFFERENTIAL FORMS: FROM EUCLID PAST RIEMANN, P85
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wan YY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P482, DOI 10.1109/ISIMP.2004.1434106
   Wang K, 2017, PATTERN RECOGN, V67, P213, DOI 10.1016/j.patcog.2017.01.034
   Wojtech M., 2011, Bark: A Field Guide to Trees of the Northeast
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 64
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22373
EP 22404
DI 10.1007/s11042-020-08874-x
EA MAY 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000534441900003
DA 2024-07-18
ER

PT J
AU Vibhute, AD
   Kale, K
   Gaikwad, S
   Dhumal, RK
   Nagne, AD
   Varpe, AB
   Nalawade, DB
   Mehrotra, SC
AF Vibhute, Amol D.
   Kale, Karbhari, V
   Gaikwad, Sandeep, V
   Dhumal, Rajesh K.
   Nagne, Ajay D.
   Varpe, Amarsinh B.
   Nalawade, Dhananjay B.
   Mehrotra, Suresh C.
TI Classification of complex environments using pixel level fusion of
   satellite data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel level fusion; Color normalized spectral sharpening (CNSS);
   Dimensionality reduction; Minimum noise fraction; Maximum likelihood
   classifier; Supervised classification
ID IMAGE CLASSIFICATION; HYPERSPECTRAL DATA; DECISION FUSION; LIDAR DATA;
   LAND; EXTRACTION
AB The present study reports classification and analysis of composite land features using fusion images obtained by fusing two original hyperspectral and multispectral datasets. The high spatial-spectral resolution, multi-instrument and multi-period satellite images were used for fusion. Three pixel level fusion based techniques, Color Normalized Spectral Sharpening (CNSS), Principal Component Spectral Sharpening Transform (PCSST) and Gram-Schmidt Transform (GST), were implemented on the datasets. Performance evaluations of three fusion algorithms were done using classification results. The Support Vector Machine (SVM) and Gaussian Maximum Likelihood Classification (MLC) were used for classification using five types of images, viz. hyperspectral, multispectral and three fused images. Number of classes considered was eight. Sufficient number of ground field data for each class has also been acquired which was needed for supervise based classification. The accuracy was improved from 74.44 to 97.65% when the fused images were considered with SVM classifier. Similarly, the results were improved from 69.25 to 94.61% with original and fused data using MLC classifier. The fusion image technique was found to be superior to the single original image and the SVM is better than the MLC method.
C1 [Vibhute, Amol D.; Dhumal, Rajesh K.] Punyashlok Ahilyadevi Holkar Solapur Univ, Sch Computat Sci, Solapur 413255, MS, India.
   [Kale, Karbhari, V; Gaikwad, Sandeep, V; Varpe, Amarsinh B.; Nalawade, Dhananjay B.; Mehrotra, Suresh C.] Dr Babasaheb Ambedkar Marathwada Univ, Dept Comp Sci & IT, Aurangabad 431004, MS, India.
   [Nagne, Ajay D.] MGM, Dr GY Pathrikar Coll Comp Sci & Informat Technol, Aurangabad, MS, India.
C3 Solapur University; Dr. Babasaheb Ambedkar Marathwada University (BAMU)
RP Vibhute, AD (corresponding author), Punyashlok Ahilyadevi Holkar Solapur Univ, Sch Computat Sci, Solapur 413255, MS, India.
EM amolvibhute2011@gmail.com; dhumal19@gmail.com; ajay.nagne@gmail.com;
   varpeamarsinh@gmail.com; dhananjay.bamu@gmail.com;
   mehrotra.suresh15j@gmail.com
RI Dhumal, Rajesh K./AGE-9678-2022; Nalawade, Dhananjay/AAO-4440-2020;
   Gaikwad, Sandeep Vasant/AAD-4263-2019; Vibhute, Amol
   Dattatraya/U-8498-2019; Varpe, Amarsinh/JZT-8632-2024; Nagne,
   Ajay/IYK-0474-2023; Kale, Karbhari/D-4006-2017
OI Dhumal, Rajesh K./0000-0002-7008-7442; Nalawade,
   Dhananjay/0000-0002-1777-5828; Gaikwad, Sandeep
   Vasant/0000-0002-1099-2360; Vibhute, Amol
   Dattatraya/0000-0002-3605-7450; Mehrotra, Suresh/0000-0002-6683-656X;
   Kale, Karbhari/0000-0002-2582-3770; Nagne, Ajay/0000-0002-9652-5631
FU UGC [3-42/2009, 4-15/2015/DRS-II]
FX The authors would like to thanks to the United States Geological Survey
   (USGS) for providing EO-1 Hyperion Data for this study. The authors
   would also like to thanks to UGC for providing BSR fellowship and lab
   facilities under UGC SAP (II) DRS Phase-I F.No.-3-42/2009, Phase-II
   4-15/2015/DRS-II for this study. The authors would like to thank the
   Editor-in-Chief, the Associate Editor, managing and handling editors of
   MTAP and anonymous reviewers for their valuable suggestions and
   comments, which improved the quality of this manuscript.
CR Abbasi B, 2015, INT ARCH PHOTOGRAMM, V41, P1, DOI 10.5194/isprsarchives-XL-1-W5-1-2015
   Andrejchenko V, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060624
   [Anonymous], 2015, MATH PROB ENG
   Ashraf S, 2012, APPL GEOGR, V32, P619, DOI 10.1016/j.apgeog.2011.07.010
   Basaeed E, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P227
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625
   Chouinard P, 2006, INT GEOSCI REMOTE SE, P2313, DOI 10.1109/IGARSS.2006.598
   Dalponte M, 2008, IEEE T GEOSCI REMOTE, V46, P1416, DOI 10.1109/TGRS.2008.916480
   Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441
   DHUMAL RK, 2019, LECT NOTES ELECT ENG, V521
   Ehlers M, 2010, INT J IMAGE DATA FUS, V1, P25, DOI 10.1080/19479830903561985
   Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034
   Gao J., 2008, DIGITAL ANAL REMOTEL
   Heras DB, 2014, INT J REMOTE SENS, V35, P401, DOI 10.1080/01431161.2013.869633
   Kosaka N, 2005, INT GEOSCI REMOTE SE, P2980
   Kumar U, 2015, INT ARCH PHOTOGRAMM, V47, P51, DOI 10.5194/isprsarchives-XL-7-W4-51-2015
   Lillesand T., 2015, Remote sensing and image interpretation
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Luo GC, 2016, CAN J REMOTE SENS, V42, P106, DOI 10.1080/07038992.2016.1160772
   Man QX, 2015, INT J REMOTE SENS, V36, P1618, DOI 10.1080/01431161.2015.1015657
   Petropoulos GP, 2012, EXPERT SYST APPL, V39, P3800, DOI 10.1016/j.eswa.2011.09.083
   Rajput UK, 2017, J INDIAN SOC REMOTE, V45, P709, DOI 10.1007/s12524-016-0615-0
   Richards J. A., 2013, Remote Sensing Digital Image Analysis: An Introduction, V5th, DOI 10.1007/3-540-29711-1
   Saravanan S, 2019, COASTAL ZONE MANAGEMENT: GLOBAL PERSPECTIVES, REGIONAL PROCESSES, LOCAL ISSUES, P471, DOI 10.1016/B978-0-12-814350-6.00020-3
   Su May Hsu, 2003, Lincoln Laboratory Journal, V14, P145
   Sun JB, 2013, MATH COMPUT MODEL, V58, P573, DOI 10.1016/j.mcm.2011.10.063
   Swatantran A, 2011, REMOTE SENS ENVIRON, V115, P2917, DOI 10.1016/j.rse.2010.08.027
   Tsagaris V, 2005, INT J REMOTE SENS, V26, P3241, DOI 10.1080/01431160500127609
   Vibhute AD, 2015, INT C MAN MACHINE IN
   VIBHUTE AD, 2018, RECENT TRENDS IMAGE, V1035
   Vibhute AD, 2016, ADV INTELL SYST, V380, P413, DOI 10.1007/978-81-322-2523-2_40
   Widjaja E, 2008, INT J ONCOL, V32, P653
   YIQIANG G, 2010, MATH COMPUT MODEL, V51, P1408, DOI DOI 10.1016/j.mcm.2009.10.023
   Zhu XF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060734
   Zoleikani R, 2017, J INDIAN SOC REMOTE, V45, P25, DOI 10.1007/s12524-016-0573-6
NR 36
TC 5
Z9 5
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34737
EP 34769
DI 10.1007/s11042-020-08978-4
EA MAY 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000534196400002
DA 2024-07-18
ER

PT J
AU Bouchakwa, M
   Ayadi, Y
   Amous, I
AF Bouchakwa, Mariam
   Ayadi, Yassine
   Amous, Ikram
TI A review on visual content-based and users' tags-based image annotation:
   methods and techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Image annotation; Image segmentation; Feature extraction; Machine
   learning; Deep learning; Semantic measure
ID TEXTURE SEGMENTATION; NEURAL-NETWORK; PARTICLE SWARM; RETRIEVAL; COLOR;
   REPRESENTATION; CLASSIFICATION; RESOLUTION; FEATURES; MODELS
AB In the current era of digital communication, the use of images is growing exponentially since they are one of the best ways of expressing, sharing and memorizing knowledge. In fact, images can be used in various real-world applications, like biology, medical diagnosis, space research, remote sensing, etc. However, finding the most relevant images that meet the users' needs is a challenging task, especially when the search is performed over gigantic amounts of images. This has led to the emergence of several image retrieval studies during the past two decades. Typically, research studies in this area were focused on the Content-based Image Retrieval (CBIR). However, extensive research have proved that there is a 'semantic gap' between the visual information captured by the imaging devices and the image semantics understandable by humans. As an alternative, researchers' efforts have been oriented towards the Text-based Image Retrieval (TBIR). Indeed, TBIR is a typical method that helps bridge the issue of 'semantic gap' between the low-level image features and the high-level image semantics. Its policy consists in associating textual descriptions with the images, which constitute the focus of the research queries later on. In this paper, we analyze various image annotation methods, namely: Visual Content-based and Users' Tags-based Image Annotation Methods. In particular, we focus on the visual content-based image annotation techniques since they are one of the dynamic research fields nowadays.
C1 [Bouchakwa, Mariam; Ayadi, Yassine; Amous, Ikram] Univ Sfax, MIRACL Lab, Technopole Sfax,POB 242, Sfax 3031, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Centre de Recherche en Numerique de Sfax
   (CRNS)
RP Bouchakwa, M (corresponding author), Univ Sfax, MIRACL Lab, Technopole Sfax,POB 242, Sfax 3031, Tunisia.
EM mariam.bouchekwa@gmail.com; ayadi.yassine@gmail.com;
   Ikram.amous@enetcom.usf.tn
OI Amous, Ikram/0000-0002-5893-9833
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Abioui H, 2018, LECT NOTES COMPUT SC, V10884, P129, DOI 10.1007/978-3-319-94211-7_15
   Abo-Zahhad M, 2014, J signal inf process, V5, P123
   Adebayo S, 2016, J BIOMED SEMANT, V7, DOI 10.1186/s13326-016-0072-2
   Ahmed KZ, 2008, PROCEEDINGS OF ICECE 2008, VOLS 1 AND 2, P195, DOI 10.1109/ICECE.2008.4769199
   AJALA FA, 2012, J INF ENG APPL, V2, P21
   AKBULUT Y, 2017, SYMMETRY BASEL, V9
   Alham N. K., 2011, 2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2011), P2655, DOI 10.1109/FSKD.2011.6020072
   Anees VM, 2012, ANNU IEEE IND CONF, P920
   ANEJA J, 2017, P 27 IEEE C COMP VIS, P5561
   Angelina S., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P970, DOI 10.1109/ICCEET.2012.6203833
   Anjna E.A., 2017, INT J ADV RES COMPUT, V8
   [Anonymous], 2015, INT J HYBRID INFORM
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], INT J IMAGE PROCESSI
   [Anonymous], 2014, INT C IND INF SYST I
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], [No title captured]
   [Anonymous], 2010, Int. J. Comput. Appl.
   [Anonymous], P ACM MULT
   Appels R, 2014, FUNCT INTEGR GENOMIC, V14, P1, DOI 10.1007/s10142-014-0364-5
   Arellano G, 2010, LECT NOTES ARTIF INT, V6437, P278, DOI 10.1007/978-3-642-16761-4_25
   ARUN K, 2013, DATA MINING TECHNIQU, P114
   Atlam H.F., 2017, Int. J. Comput. Appl., V164, P23
   AYADI Y, 2013, INT J ENG TECHNOLOGY, V13, P80
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belkhatir M, 2009, MULTIMED TOOLS APPL, V43, P1, DOI 10.1007/s11042-008-0254-8
   Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970
   Bergeaud F, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA53
   Bhatt Himanshu S., 2010, 2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1, DOI DOI 10.1109/BTAS.2010.5634507
   BHENDE P, 2013, INT J COMPUT ENG RES, V3, P10
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   BOBADE KB, 2014, INT J SCI RES ENG TE, V3, P713
   Bouchakwa M., 2016, Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media, MoMM'16, P35
   Bouchakwa M, 2019, I C COMP SYST APPLIC, P1, DOI [DOI 10.1109/aiccsa47632.2019.9035278, 10.1109/AICCSA47632.2019.9035278]
   Bouchakwa M, 2017, VISION 2020: SUSTAINABLE ECONOMIC DEVELOPMENT, INNOVATION MANAGEMENT, AND GLOBAL GROWTH, VOLS I-IX, 2017, P2307
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   CANNON RL, 1986, IEEE T GEOSCI REMOTE, V24, P400, DOI 10.1109/TGRS.1986.289598
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chathurani NWUD, 2015, INT CONF IND INF SYS, P158, DOI 10.1109/ICIINFS.2015.7399003
   CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen X., 2011, P 19 ACM INT C MULT, P263
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Cheng QM, 2018, PATTERN RECOGN, V79, P242, DOI 10.1016/j.patcog.2018.02.017
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Cooper L, 2013, PLANT CELL PHYSIOL, V54, pE1, DOI 10.1093/pcp/pcs163
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Cusano C, 2004, PROC SPIE, V5304, P330
   Dai B, 2017, IEEE I CONF COMP VIS, P2989, DOI 10.1109/ICCV.2017.323
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595
   Dharani T., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P485, DOI 10.1109/ICPRIME.2013.6496719
   DIMITRIU Ileana., 2010, Compromiso social y Traduccion/Interpretacion. Translation/Interpreting and Social Activism, P1
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   FAN J, 2004, P 27 ANN INT ACM SIG, P361
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Figueiredo CA, 2016, DEBATES, P1
   Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Gao Yan-Yu, 2010, Acta Automatica Sinica, V36, P960, DOI 10.3724/SP.J.1004.2010.00960
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Ghahabi O, 2018, COMPUT SPEECH LANG, V47, P16, DOI 10.1016/j.csl.2017.06.007
   GHOSHAL A, 2005, P 28 ANN INT ACM SIG, P544
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   Göksu Ö, 2018, SIG PROCESS COMMUN
   Gong TX, 2010, PROC INT C TOOLS ART, DOI 10.1109/ICTAI.2010.35
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Gu JX, 2017, IEEE I CONF COMP VIS, P1231, DOI 10.1109/ICCV.2017.138
   Guha Sudipto., 1998, SIGMOD 1998 P ACM SI, P73, DOI DOI 10.1145/276305.276312
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Gupta R., 2017, INDIAN J SCI TECHNOL, V10, DOI [10.17485/ijst/2017/v10i31/113894, DOI 10.17485/ijst/2017/v10i4/108963]
   Halaschek-Wiener C., 2005, Proceedings of the 4th international semantic web conference, P6
   Hambali H.A., 2017, J TELECOMMUN ELECT C, V9, P43
   Han YT, 2005, IEEE IMAGE PROC, P377
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   Hastings S, 2005, J AM MED INFORM ASSN, V12, P286, DOI 10.1197/jamia.M1698
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He XJ, 2005, LECT NOTES ARTIF INT, V3614, P727
   Hermanto A, 2015, 2015 INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH), P132, DOI 10.1109/ICSITech.2015.7407791
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   HOLLINK L, 2003, SEMANTIC ANNOTATION, P8
   HOLLINK L, 2004, P 4 INT WORKSH KNOWL, P31
   Horvat M, 2013, INT J KNOWL-BASED IN, V17, P157, DOI 10.3233/KES-130269
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Im D H, 2013, P INF SCI APPL ICISA, P1
   Im DH, 2015, MULTIMED TOOLS APPL, V74, P2273, DOI 10.1007/s11042-014-1855-z
   Islam MM, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1521, DOI 10.1109/ICME.2008.4607736
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jau-Ling Shih, 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P88
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jeong JW, 2013, MULTIMED TOOLS APPL, V62, P451, DOI 10.1007/s11042-011-0903-1
   Ji Q, 2017, KSII T INTERNET INF, V11, P4476, DOI 10.3837/tiis.2017.09.016
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   JIAWEI H, DATA MINING CONCEPTS, P383
   JIN J, 2015, ARXIV150606272
   Jin YB, 2005, P ANN INT IEEE EMBS, P7068, DOI 10.1109/IEMBS.2005.1616134
   JING F, 2003, P INT C IM VID RETR, P206
   Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kalafi EY, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1376-z
   Kamdi Shilpa., 2012, International Journal of Computer Technology and Electronics Engineering (IJCTEE), V2
   Kao ST, 2009, BIOMED CIRC SYST C, P68
   Karoui I, 2010, IEEE T IMAGE PROCESS, V19, P3146, DOI 10.1109/TIP.2010.2071290
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kaya Y, 2014, VISUAL COMPUT, V30, P71, DOI 10.1007/s00371-013-0782-8
   KENDALL A, 2015, ABS151102680 CORR
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan A, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P293, DOI 10.1109/ICCWAMTIP.2014.7073411
   KIROS JR, 2014, P 28 WORKSH NEUR INF
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KSIBI A, 2012, P 10 INT WORKSH CONT, P1
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Kumar K, 2010, NAT C ADV INF SEC NC, P1
   KUMAR SS, 2014, INT J ADV RES SCI EN, V3, P108
   Kuroda K, 2002, NEUROCOMPUTING, V43, P259, DOI 10.1016/S0925-2312(01)00344-7
   KURTZ C, 2014, P 14 C KNOWL EXTR MA, P609
   Kwitt R, 2012, MED IMAGE ANAL, V16, P1415, DOI 10.1016/j.media.2012.04.010
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Lavrenko V., 2003, NIPS
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leacock C, 1998, LANG SPEECH & COMMUN, P265
   LEI Y, 2010, P 10 AS C COMP VIS A, P115
   Levine MartinD., 1985, VISION MAN MACHINE
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li DF, 2013, ADV APPL MATH MECH, V5, P55, DOI 10.4208/aamm.10-m1072
   Li S, 2011, P 15 C COMP NAT LANG, P220
   Li T, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2856058
   Li Yandong, 2016, Journal of Computer Applications, V36, P2508, DOI 10.11772/j.issn.1001-9081.2016.09.2508
   Lin BR, 2006, TENCON IEEE REGION, P520
   Lin D, 1998, P 15 INT C MACH LEAR, V98, P296
   Lingutla NT, 2014, J BIOMED SEMANT, V5, DOI 10.1186/2041-1480-5-50
   Liu J, 2010, INT CONF COMPUT AUTO, P491, DOI 10.1109/ICCAE.2010.5451908
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2015, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2015.7298920
   Liu Y., 2004, Proceedings of Pacific Rim Conference on Multimedia, P931
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Long FH, 2003, SIG COM TEC, P1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Low WC, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P116, DOI 10.1109/MMDBMS.1998.709521
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   MacArthur SD, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P68, DOI 10.1109/IVL.2000.853842
   MAGESH N, 2011, INT J COMPUTER APPL, V1, P12
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Mao Junhua., 2014, Explain images with multimodal recurrent neural networks
   Marée R, 2005, PROC CVPR IEEE, P34
   Materka A, 1998, TEXTURE ANAL METHODS, P9
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Mayhew MB, 2016, IEEE IMAGE PROC, P2266, DOI 10.1109/ICIP.2016.7532762
   Mezaris V, 2004, EURASIP J APPL SIG P, V2004, P886, DOI 10.1155/S1110865704401188
   Mezaris V, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P511
   MITRAN M, 2013, P 10 C OP RES AR INF, P65
   Miyamori H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P320, DOI 10.1109/AFGR.2000.840653
   Mori Y, 2003, SENSOR MATER, V15, P1
   Muda Zurina, 2009, 2009 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2009), P173, DOI 10.1109/ICSIPA.2009.5478621
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   NAIK D, 2014, INT J COMPUTER SCI I, V5, P3289
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   NANDA PK, 1998, P IND C COMP VIS GRA, P15
   Natsev A, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P395, DOI 10.1145/304181.304217
   Nguyen TV, 2018, INT J COMPUT VISION, V126, P86, DOI 10.1007/s11263-017-1042-6
   Niles I., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P2, DOI 10.1145/505168.505170
   OBEROI A, 2012, IJCSI INT J COMPUTER, V9, P300
   Ojha U., 2017, 2017 8th International Conference on Computing, Communication and Networking Technologies (ICCCNT), P1, DOI DOI 10.1109/ICCCNT.2017.8204031
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva D, 2017, INTEL SYST REF LIBR, V117, P1, DOI 10.1007/978-3-319-48550-8
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   PANDA S, 2016, INT J COMPUT MATH, V5, P73
   Park SB, 2004, PATTERN RECOGN LETT, V25, P287, DOI 10.1016/j.patrec.2003.10.015
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   PATIL MP, 2012, ADV COMPUTATIONAL RE, V4, P108
   PATIL MP, 2014, INT J COMPUT SCI APP, V11, P38
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Petridis K, 2006, LECT NOTES ARTIF INT, V4253, P633
   Pinheiro P.O., 2015, NEURIPS, P1990
   PREECE J, 2016, P 7 JOINT INT C BIOL
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Qian YG, 2015, REMOTE SENS-BASEL, V7, P153, DOI 10.3390/rs70100153
   QIU B, 2006, P WORKSH CROSS LANG, P690
   QUATTRONE G, 2012, P 23 INT C SOFTW ENG, P385
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   REN Z, 2017, PROC CVPR IEEE, P1151, DOI DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Rosenfeld A., 1980, DIGITAL PATTERN RECO, P135, DOI DOI 10.1007/978-3-642-67740-3_5
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Rui S, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P322
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sak H., 2014, CORR
   Sami M, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P790, DOI 10.1109/WICT.2012.6409182
   SENTHILKUMAR R, 2014, INT J ENG TECHNOLOGY, V1, P286
   Senthilkumaran N., 2016, COMPUT SCI ENG INT J, V6, P1, DOI [DOI 10.5121/CSEIJ.2016.6101, 10.5121/cseij.2016, DOI 10.5121/CSEIJ.2016]
   Serrano N, 2002, INT C PATT RECOG, P146, DOI 10.1109/ICPR.2002.1047420
   Sethi I., 2001, Proceedings of the SPIE Data Mining and Knowledge Discovery, V3, P279, DOI DOI 10.1117/12.421083
   Shen J, 2011, ACM MULTIMEDIA, P639, DOI DOI 10.1145/2072298.2072405
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shetty R, 2017, IEEE I CONF COMP VIS, P4155, DOI 10.1109/ICCV.2017.445
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi R, 2004, LECT NOTES COMPUT SC, V3115, P545
   Shimpi Sanjay., 2013, Elixir International Journal Elixir Comp. Sci. Engg, V56A, P13530
   SHITOLE A, 2014, INT J COMPUTER AIDED, V1, P21
   SHUKLA T, 2013, INT J COMPUTER APPL, V68, P17
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava HM, 2012, ELSEV INSIGHT, P479
   Stanchev P.L., 2003, INT J INF THEORIES A, V10, P363
   Steggink J, 2011, MULTIMEDIA SYST, V17, P367, DOI 10.1007/s00530-010-0220-y
   STUHRENBERG M, 2013, MARK C MONTR CAN BAL
   SUGANO Y, 2016, ARXIV160805203
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Sun CJ, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P518, DOI 10.1109/MVA.2015.7153244
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922
   Tallapragada V. S., 2016, INT J RES ENG TEC, V4, P83
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan WT, 2013, PR CHINAGRID, P103, DOI 10.1109/ChinaGrid.2013.22
   TANG JH, 2013, ACM T MULTIM COMPUT, V9
   Tang JH, 2013, SIGNAL PROCESS, V93, P2199, DOI 10.1016/j.sigpro.2012.05.003
   Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Torralba A, 2010, P IEEE, V98, P1467, DOI 10.1109/JPROC.2010.2050290
   Town C., 2000, CONTENT BASED IMAGE
   Tran K, 2016, IEEE COMPUT SOC CONF, P434, DOI 10.1109/CVPRW.2016.61
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Tsai CF, 2006, ACM T INFORM SYST, V24, P353, DOI 10.1145/1165774.1165777
   Tu M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P850
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   TYAGI V, 2017, CONTENT BASED IMAGE, P29, DOI DOI 10.1007/978-981-10-6759-4_2
   Ugarriza LG, 2009, IEEE T IMAGE PROCESS, V18, P2275, DOI 10.1109/TIP.2009.2025555
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Vega F, 2015, PROC SPIE, V9681, DOI 10.1117/12.2214324
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   VISA A, 1991, IEEE IJCNN, P1001, DOI 10.1109/IJCNN.1991.170529
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Wagstaff K., 2001, P 18 INT C MACH LEAR, P577, DOI DOI 10.1109/TPAMI.2002.1017616
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WANG JZ, 2002, P 10 ACM INT C MULT, P436
   WANG Q, 2018, ARXIV180509019
   Wang RG, 2017, J VIS COMMUN IMAGE R, V49, P213, DOI 10.1016/j.jvcir.2017.07.004
   Wang T, 2012, INT C PATT RECOG, P3304
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wei CW, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050488
   Wei YC, 2016, PATTERN RECOGN, V59, P234, DOI 10.1016/j.patcog.2016.01.015
   Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667
   Weston J., 2011, IJCAI, V3, P2764, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-460
   Wojnar A, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P130, DOI 10.1109/ISBI.2012.6235501
   Wong RCF, 2008, IEEE T PATTERN ANAL, V30, P1933, DOI 10.1109/TPAMI.2008.125
   Wong STC, 1999, IEEE COMMUN MAG, V37, P84, DOI 10.1109/35.739310
   Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968
   Xu H, 2009, PHIL MAG LETT, V89, P465, DOI 10.1080/09500830903019012
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu Z, 2014, SCI WORLD J, DOI 10.1155/2014/758089
   Xue J, 2013, INTERSPEECH, P2364
   Yang CB, 2005, IEEE IMAGE PROC, P641
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yang M., 2008, PATTERN RECOGN, P43, DOI DOI 10.5772/6237
   Yang Y, 2015, J VIS COMMUN IMAGE R, V33, P368, DOI 10.1016/j.jvcir.2015.10.006
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507
   Yin-Fu Huang, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P386, DOI 10.1109/PSIVT.2010.71
   You D, 2014, PROC SPIE, V9021, DOI 10.1117/12.2042526
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083
   ZHANG C, 2005, P 28 ANN INT ACM SIG, P51
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang H., 2004, 17 INT FLAIRS C, P17
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Zhao YF, 2009, EXPERT SYST APPL, V36, P9813, DOI 10.1016/j.eswa.2009.02.050
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhenzhen Wei, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P434, DOI 10.1109/ICIG.2013.93
   Zhu C, 2019, IEEE ENER CONV, P5084, DOI [10.1109/ECCE.2019.8912878, 10.1109/ecce.2019.8912878]
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Ziheng Jiang, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P906, DOI 10.1109/ISDA.2010.5687074
   ZNAIDIA A, 2011, P CLEF NOT PAP LABS
   ZOMAHOUN DE, 2013, INT J SIGNAL IMAGE P, V4, P71
NR 341
TC 8
Z9 8
U1 10
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21679
EP 21741
DI 10.1007/s11042-020-08862-1
EA MAY 2020
PG 63
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531216800003
DA 2024-07-18
ER

PT J
AU Tian, D
   Lu, ZM
   Chen, X
   Ma, LH
AF Tian, Dong
   Lu, Zhe-Ming
   Chen, Xiao
   Ma, Long-Hua
TI An attentional spatial temporal graph convolutional network with
   co-occurrence feature learning for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Spatial-temporal graph convolutional networks
   (ST-GCN); Multi-task framework; Attentional branch network;
   Co-occurrence feature learning
AB Action recognition plays a central role in intelligent surveillance system, game-control, human-computer interaction, and so on. In this work, we design a multi-task framework that improves the recent Spatial-Temporal Graph Convolutional Networks (ST-GCN) for skeleton-based action recognition by introducing the attention mechanism and co-occurrence feature learning. Specifically, we use an attentional branch to pay more attention to more discriminating features and aggregates co-occurrence features from all joints globally in another branch. Additionally, our multi-task framework exploits the inherent correlation between branches to further enhance the classification accuracy and convergence speed. Experiments have been carried out on NTURGB+D and Kinetics human action dataset. The results clearly show that the accuracy of the proposed multi-task framework are distinguishably higher than ST-GCN and other mainstream methods for 3D action recognition.
C1 [Tian, Dong; Lu, Zhe-Ming; Chen, Xiao] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.
   [Ma, Long-Hua] Zhejiang Univ, Sch Informat Sci & Engn, Ningbo Inst Technol, Ningbo 315100, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.
EM zheminglu@zju.edu.cn
CR [Anonymous], 2016, INT C MACH LEARN
   [Anonymous], ARXIV160400239
   [Anonymous], AAAI C ART INT AAAI
   [Anonymous], 2012, ICCV
   [Anonymous], 2018, ARXIV180603536
   [Anonymous], 2013, ABS13124659 CORR
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], 2018, ARXIV180103226
   [Anonymous], 2017, ABS170310106 CORR
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Gu J., 2016, ARXIV161207086
   Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Jie H, 2017, IEEE T PATTERN ANAL
   Kay W., 2017, CORR ABS170506950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Li C., 2018, ARXIV180406055
   Li C, 2017, IEEE INT CONF MULTI
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Lu GL, 2016, MULTIMED TOOLS APPL, V75, P3479, DOI 10.1007/s11042-015-2448-1
   Ma ZC, 2018, MULTIMED TOOLS APPL, V77, P32275, DOI 10.1007/s11042-018-6260-6
   Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P77, DOI 10.1109/TCSVT.2014.2333151
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun B, 2018, MULTIMED TOOLS APPL, P1
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang L, 2016, MATEC WEB CONF, V63, DOI 10.1051/matecconf/20166302016
   Weston J, 2014, ARXIV14103916
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y
   Yu YL, 2010, IEEE T SYST MAN CY B, V40, P1398, DOI 10.1109/TSMCB.2009.2038895
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
NR 44
TC 10
Z9 10
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12679
EP 12697
DI 10.1007/s11042-020-08611-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400063
DA 2024-07-18
ER

PT J
AU Moridvaisi, H
   Razzazi, F
   Pourmina, MA
   Dousti, M
AF Moridvaisi, Hooman
   Razzazi, Farbod
   Pourmina, Mohammad Ali
   Dousti, Massoud
TI An extended KCF tracking algorithm based on TLD structure in low frame
   rate videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low frame rate video processing; Abrupt motion; Large appearance
   changes; Tracking-learning-detection; Kernelized correlation filter
ID CORRELATION FILTER; OBJECT TRACKING; ROBUST
AB The KCF (Kernelized Correlation Filter) algorithm achieved a good performance on target tracking challenges. However, it still has some defects and problems of false tracking in low frame rate (LFR) scenarios, target scale variation, occlusion and out of view target, that exists in the correlation filter based methods. In this paper, we overcome the shortcomings of KCF tracking algorithm based on Tracking-Learning-Detection (TLD) framework. The proposed algorithm trained two classifiers simultaneously, based on semi supervised co-training learning algorithm. Then, we comparatively evaluate the proposed method on TB-100 datasets by other trackers. The experimental results demonstrate that the precision and robustness of the improved tracking algorithm is higher than traditional KCF, TLD and the other top state-of-the-art tracking algorithms in LFR videos.
C1 [Moridvaisi, Hooman; Razzazi, Farbod; Pourmina, Mohammad Ali; Dousti, Massoud] Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University
RP Razzazi, F (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Sci & Res Branch, Tehran, Iran.
EM razzazi@srbiau.ac.ir
RI Razzazi, Farbod/AAO-8522-2021; dousti, massoud/ABA-5354-2021; Pourmina,
   Mohammad Ali/AAO-6632-2021; Pourmina, Mohammad Ali/JAN-9517-2023;
   Dousti, Massoud/AAU-1765-2021
OI Pourmina, Mohammad Ali/0000-0001-6884-0266; Dousti,
   Massoud/0000-0003-2884-7062; Razzazi, Farbod/0000-0003-4970-8117
CR [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Boroujeni HS, 2012, COMM COM INF SC, V295, P143
   Cai CT, 2018, CHIN CONTR CONF, P2674, DOI 10.23919/ChiCC.2018.8483083
   Carneiro G, 2011, IEEE I CONF COMP VIS, P1700, DOI 10.1109/ICCV.2011.6126433
   CHUANG MC, 2014, P IEEE INT C IM PROC
   DAI W, 2016, 2 WORKSH ADV RES TEC
   Di Caterina G., 2011, 8 IEEE INT C ADV VID
   Di Wu, 2018, MATEC Web of Conferences, V232, DOI 10.1051/matecconf/201823203016
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   GODEC M, 2012, P IEE INT C COMP VIS
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu JH, 2017, CHIN CONT DECIS CONF, P6096, DOI 10.1109/CCDC.2017.7978266
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2017, ELECTRON LETT, V53, P1358, DOI 10.1049/el.2017.2129
   Lee G, 2017, EXPERT SYST APPL, V80, P46, DOI 10.1016/j.eswa.2017.03.023
   LI T, 2016, INT SOC OPTICS PHOTO, V1003
   Liu P, 2017, PROC INT C TOOLS ART, P559, DOI 10.1109/ICTAI.2017.00090
   Liu YJ, 2019, IEEE T SYST MAN CY-S, V49, P2318, DOI 10.1109/TSMC.2018.2815560
   Lu YL, 2018, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION ENGINEERING (RAE 2018) AND INTERNATIONAL CONFERENCE ON ADVANCED MECHANICAL AND ELECTRICAL ENGINEERING (AMEE 2018), P60, DOI 10.1145/3303714.3303747
   MIAO F, 2017, ELECT DES ENG, V7
   Mo ZP, 2018, INT J INNOV COMPUT I, V14, P1239, DOI 10.24507/ijicic.14.04.1239
   Ni JJ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/6931020
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   PALANIAPPAN K, 2010, INF FUS FUSION 13 C
   PANG Y, 2013, P SPIE
   Pei MX, 2016, CHIN CONTR CONF, P4009, DOI 10.1109/ChiCC.2016.7553979
   Siqueira DL, 2016, IEEE LAT AM T, V14, P1966, DOI 10.1109/TLA.2016.7483541
   Wu W, 2018, PROC SPIE, V10608, DOI 10.1117/12.2282345
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Xu Q, 2017, INT J FOOD ENG, V13, DOI 10.1515/ijfe-2016-0247
   Xu T, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P2051, DOI 10.1109/ICInfA.2016.7832157
   Yu L., 2016, J SIGN PROCESS IMAGE, V9, P431
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang Song, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P387, DOI 10.1109/ICEMI.2017.8265827
   Zhang XQ, 2015, INT J COMPUT VISION, V115, P279, DOI 10.1007/s11263-015-0819-8
   Zhang YH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P199, DOI 10.1109/ICMA.2016.7558560
   Zhao LL, 2017, AIP CONF PROC, V1839, DOI 10.1063/1.4982579
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 40
TC 6
Z9 7
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20995
EP 21012
DI 10.1007/s11042-020-08867-w
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529585600002
DA 2024-07-18
ER

PT J
AU Arabaci, MA
   Özkan, F
   Surer, E
   Jancovic, P
   Temizel, A
AF Arabaci, Mehmet Ali
   Ozkan, Fatih
   Surer, Elif
   Jancovic, Peter
   Temizel, Alptekin
TI Multi-modal egocentric activity recognition using multi-kernel learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Egocentric; First-person vision; Activity recognition; Multi-kernel
   learning; Multi-modality
ID SPEAKER; FUSION; KERNEL; DEPTH
AB Existing methods for egocentric activity recognition are mostly based on extracting motion characteristics from videos. On the other hand, ubiquity of wearable sensors allow acquisition of information from different sources. Although the increase in sensor diversity brings out the need for adaptive fusion, most of the studies use pre-determined weights for each source. In addition, there are a limited number of studies making use of optical, audio and wearable sensors. In this work, we propose a new framework that adaptively weighs the visual, audio and sensor features in relation to their discriminative abilities. For that purpose, multi-kernel learning (MKL) is used to fuse multi-modal features where the feature and kernel selection/weighing and recognition tasks are performed concurrently. Audio-visual information is used in association with the data acquired from wearable sensors since they hold information on different aspects of activities and help building better models. The proposed framework can be used with different modalities to improve the recognition accuracy and easily be extended with additional sensors. The results show that using multi-modal features with MKL outperforms the existing methods.
C1 [Arabaci, Mehmet Ali; Ozkan, Fatih; Surer, Elif; Temizel, Alptekin] Middle East Tech Univ METU, Grad Sch Informat, Ankara 06800, Turkey.
   [Jancovic, Peter; Temizel, Alptekin] Univ Birmingham, Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.
C3 Middle East Technical University; University of Birmingham
RP Arabaci, MA (corresponding author), Middle East Tech Univ METU, Grad Sch Informat, Ankara 06800, Turkey.
EM mehmet.arabaci@metu.edu.tr; fatih.ozkan@metu.edu.tr; elifs@metu.edu.tr;
   p.jancovic@bham.ac.uk; atemizel@metu.edu.tr
RI Arabacı, Mehmet Ali/GYJ-2329-2022; Surer, Elif/I-5157-2015; Temizel,
   Alptekin/D-1315-2010
OI Arabacı, Mehmet Ali/0000-0002-5433-5864; Surer,
   Elif/0000-0002-0738-6669; Temizel, Alptekin/0000-0001-6082-2573
FU Scientific and Technological Research Council of Turkey under TUBITAK
   [BIDEB-2219, 1059B191500048]
FX This work was partly supported by The Scientific and Technological
   Research Council of Turkey under TUBITAK BIDEB-2219 grant no
   1059B191500048.
CR Abebe G, 2017, IEEE INT CONF COMP V, P1392, DOI 10.1109/ICCVW.2017.165
   Abebe G, 2017, NEUROCOMPUTING, V267, P362, DOI 10.1016/j.neucom.2017.06.015
   Abebe G, 2016, COMPUT VIS IMAGE UND, V149, P229, DOI 10.1016/j.cviu.2015.10.015
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   ALSHEIKH MA, 2016, IEEE NETWORK, V30, P22, DOI DOI 10.1109/MNET.2016.7474340
   [Anonymous], 2005, BEHAV RECOGNITION VI
   [Anonymous], P 4 ACM WORKSH WEAR
   [Anonymous], 2016 IEEE Winter Conf. Appl. Comput. Vision, DOI [DOI 10.1109/WACV.2016.7477708, 10.1109/WACV.2016.7477708]
   Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965
   Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Bambach S, 2017, IEEE INT CONF COMP V, P2773, DOI 10.1109/ICCVW.2017.326
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Bhattacharya S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS)
   Bottou L., 2007, Large scale kernel machines, V3, P301
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Campbell WM, 2006, INT CONF ACOUST SPEE, P97
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen M, 2011, INT CONF CLOUD COMPU, P316, DOI 10.1109/CCIS.2011.6045082
   Clarkson B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P69, DOI 10.1109/ISWC.2000.888467
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   FITZGERALD RW, 1994, REMOTE SENS ENVIRON, V47, P362, DOI 10.1016/0034-4257(94)90103-1
   Gartner T., 2003, SIGKDD Explor., V5, P49, DOI DOI 10.1145/959242.959248
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622
   Incel OD, 2015, SENSORS-BASEL, V15, P25474, DOI 10.3390/s151025474
   Iwashita Y, 2014, INT C PATT RECOG, P4310, DOI 10.1109/ICPR.2014.739
   Kang T, 2016, INT WINT WORKSH BR
   Kwon H, 2018, PATTERN RECOGN LETT, V112, P161, DOI 10.1016/j.patrec.2018.07.011
   Lan ZY, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.220
   Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li XC, 2004, ZOOTAXA, P1
   Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625
   Liu L, 2016, 30 AAAI C ART INT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209
   Morales J, 2017, BIOCYBERN BIOMED ENG, V37, P388, DOI 10.1016/j.bbe.2017.04.004
   Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433
   Ni BB, 2012, INT CONF ACOUST SPEE, P1405, DOI 10.1109/ICASSP.2012.6287947
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Özkan F, 2017, EUR SIGNAL PR CONF, P1050, DOI 10.23919/EUSIPCO.2017.8081368
   Pansiot J, 2007, IFMBE PROC, V13, P208
   Peleg S., 2014, CVPR, P2537, DOI DOI 10.1109/CVPR.2014.325
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Peters J, 2017, ADAPT COMPUT MACH LE
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Safavi S, 2018, COMPUT SPEECH LANG, V50, P141, DOI 10.1016/j.csl.2018.01.001
   Sathyanarayana A, 2016, JMIR MHEALTH UHEALTH, V4, DOI 10.2196/mhealth.6562
   SCHAPIRE RE, 1999, J JAPANESE SOC ARTIF, P1401
   Song H, 2017, INT CONF ACOUST SPEE, P2292, DOI 10.1109/ICASSP.2017.7952565
   Song SB, 2016, INT CONF ACOUST SPEE, P2717, DOI 10.1109/ICASSP.2016.7472171
   Song SB, 2015, LECT NOTES COMPUT SC, V9010, P445, DOI 10.1007/978-3-319-16634-6_33
   Sudhakaran S, 2017, IEEE INT CONF COMP V, P2339, DOI 10.1109/ICCVW.2017.276
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LK, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020189
   Wang Xinxi., 2012, Proceedings of the 20th ACM international conference on Multimedia, P99, DOI [DOI 10.1145/2393347.2393368, 10.1145/2393347.2393368]
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Xia H, 2013, IEEE T KNOWL DATA EN, V25, P1574, DOI 10.1109/TKDE.2012.89
   Yao R, 2018, PATTERN RECOGN, V78, P252, DOI 10.1016/j.patcog.2017.12.024
   Yi WL, 2009, INT J HUM ROBOT, V6, P337, DOI 10.1142/S0219843609001863
   Yilmaz T, 2010, SENSORS-BASEL, V10, P10837, DOI 10.3390/s101210837
   Young S., 2006, The HTK Book (v3. 4)
   Yu Guan, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090076
NR 71
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16299
EP 16328
DI 10.1007/s11042-020-08789-7
EA APR 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000529123600001
DA 2024-07-18
ER

PT J
AU Guan, BL
   Lin, SJ
   Wang, RM
   Zhou, F
   Luo, XN
   Zheng, YC
AF Guan, Boliang
   Lin, Shujin
   Wang, Ruomei
   Zhou, Fan
   Luo, Xiaonan
   Zheng, Yongchuan
TI Voxel-based quadrilateral mesh generation from point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud; Voxelization; Quad mesh generation; Vertex-to-point mapping
ID SURFACE RECONSTRUCTION
AB In recent years point cloud has been used more and more widely in CAD and computer graphics communities due to the availability of fast and accurate laser scan devices. Many works focus on reconstructing a triangle mesh from a point cloud but few consider the quadrangulate of a point cloud directly. In this paper, a novel method which is able to achieve quad mesh models directly from a point cloud is proposed. The main idea is to use voxel as the intermediate medium between point cloud and grid to generate voxel model, then by mapping vertices of a voxel model outer surface to points to construct quad meshes. Furthermore, quad meshes are refinement through point remapping and meshes regularization to obtain high quality meshes. The experimental results show that our method can efficiently and flexible generate quad mesh based on point cloud directly with better quality and different scales. Especially, this method is much more suitable to tasks expecting less computation time and less manual interaction in rapid prototyping and reverse engineering.
C1 [Guan, Boliang; Wang, Ruomei; Zhou, Fan; Zheng, Yongchuan] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.
   [Guan, Boliang; Lin, Shujin; Wang, Ruomei; Zhou, Fan; Zheng, Yongchuan] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Guangzhou, Peoples R China.
   [Lin, Shujin] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Sch Informat & Commun, Guilin, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen University;
   Guilin University of Electronic Technology
RP Lin, SJ (corresponding author), Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Guangzhou, Peoples R China.; Lin, SJ (corresponding author), Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.
EM guanbl3@mail2.sysu.edu.cn; linshjin@mail.sysu.edu.cn
RI Zhou, fan/KIL-4066-2024
FU National Natural Science Foundation of China [61672547, 61902088];
   Natural Science Foundation of Guangdong [2019A1515011953];
   Innovation-driven Development Special Fund Project of Guangxi
   [AA18118039]; Guangzhou science and technology project [201902010056]
FX This work was supported by the National Natural Science Foundation of
   China(No. 61672547, No. 61902088), the Natural Science Foundation of
   Guangdong(No. 2019A1515011953), the Innovation-driven Development
   Special Fund Project of Guangxi(No. AA18118039), and the Guangzhou
   science and technology project(No. 201902010056).
CR [Anonymous], 2008, MESHLAB OPEN SOURCE, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Ben Eckart,, 2016, PROC CVPR IEEE, P5497, DOI 10.1109/CVPR.2016.593
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Boltcheva D, 2017, COMPUT AIDED DESIGN, V90, P123, DOI 10.1016/j.cad.2017.05.011
   Bommes D, 2013, COMPUT GRAPH FORUM, V32, P51, DOI 10.1111/cgf.12014
   Botsch M, 2001, COMPUT GRAPH FORUM, V20, pC402, DOI 10.1111/1467-8659.00533
   Bukenberger DR, 2018, COMPUT GRAPH FORUM, V37, P135, DOI 10.1111/cgf.13497
   Campen M, 2017, COMPUT GRAPH FORUM, V36, P567, DOI 10.1111/cgf.13153
   Cheng SW, 2017, ACM T ALGORITHMS, V13, DOI 10.1145/3039242
   Chu PM, 2018, MULTIMED TOOLS APPL, V77, P29991, DOI 10.1007/s11042-017-5089-8
   Cohen RA, 2016, IEEE IMAGE PROC, P1374, DOI 10.1109/ICIP.2016.7532583
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   de Queiroz RL, 2017, IEEE T IMAGE PROCESS, V26, P3886, DOI 10.1109/TIP.2017.2707807
   DeCarlo D., 2003, SUGGESTIVE CONTOUR G
   Diamanti O, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766906
   Gross Markus, 2007, ACM SIGGRAPH 2007 PA
   Guo YH, 2018, COMPUT AIDED DESIGN, V104, P27, DOI 10.1016/j.cad.2018.04.005
   He Y, 2009, COMPUT GRAPH-UK, V33, P369, DOI 10.1016/j.cag.2009.03.024
   Hu ZZ, 2017, MULTIMED TOOLS APPL, V76, P24343, DOI 10.1007/s11042-016-4192-6
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Knöppel F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462005
   Kovacs D, 2010, 14 ACM S SOL PHYS MO
   Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P137
   Li E, 2011, COMPUT GRAPH-UK, V35, P992, DOI 10.1016/j.cag.2011.05.003
   Li E, 2011, COMPUT GRAPH-UK, V35, P452, DOI 10.1016/j.cag.2011.03.021
   Lin JC, 2008, LECT NOTES COMPUT SC, V4975, P3
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pang XF, 2014, GRAPH MODELS, V76, P86, DOI 10.1016/j.gmod.2013.11.004
   Panozzo D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601179
   Peng CH, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024175
   Schertler N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073635
   Song W, 2015, MULTIMED TOOLS APPL, V74, P3459, DOI 10.1007/s11042-013-1669-4
   Tarini M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024176
   Wang H, 2009, IEEE T VIS COMPUT GR, V15, P572, DOI 10.1109/TVCG.2009.13
   Wang HY, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P397
   Wang WD, 2019, MULTIMED TOOLS APPL, V78, P8737, DOI 10.1007/s11042-018-6244-6
   Xia J., 2011, S INTERACTIVE 3D GRA, P151
   Xiong SY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661263
   Yoo DJ, 2011, COMPUT AIDED DESIGN, V43, P934, DOI 10.1016/j.cad.2011.03.002
   Yoshihara H, 2012, COMPUT AIDED GEOM D, V29, P422, DOI 10.1016/j.cagd.2012.03.007
   Zhang MY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778855
   Zhong SK, 2019, COMPUT AIDED GEOM D, V71, P43, DOI 10.1016/j.cagd.2019.04.011
NR 45
TC 9
Z9 9
U1 4
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20561
EP 20578
DI 10.1007/s11042-020-08923-5
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528819200001
DA 2024-07-18
ER

PT J
AU Yu, HF
   Li, XB
   Lou, Q
   Lei, CB
   Liu, ZX
AF Yu, Haifeng
   Li, Xinbin
   Lou, Qian
   Lei, Chengbo
   Liu, Zhixin
TI Underwater image enhancement based on DCP and depth transmission map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image enhancement; Homomorphic filtering; Double transmission
   map; Dual-image wavelet fusion; Contrast enhancement
AB Seeing that the light in the water is affected by absorption and scattering, underwater image will suffer degradation including low contrast, low visibility and color deviation. Therefore, the key issue of underwater image enhancement is to improve the visibility and the contrast of underwater images. In this paper, we proposed an underwater image dehazing algorithm combining three main steps of homomorphic filtering, double transmission map and dual-image wavelet fusion. First at all, we removed the color deviation in the underwater image by homomorphic filtering. Then, we obtained the enhanced image by depth map which calculate the difference between the light and dark channels. Finally, the dual-image wavelet fusion technique is used to combine the enhanced image obtained by the depth map with the enhanced image obtained by the dark channel. In addition, we obtained the contrast enhanced image which use Contrast-Limited Adaptive Histogram Equalization (CLAHE) method. Through simulation experiments, the proposed method has better visual effects and better effect on entropy, average gradient and underwater color image quality evaluation (UCIQE) compared with other popular methods.
C1 [Yu, Haifeng; Li, Xinbin; Lou, Qian; Lei, Chengbo; Liu, Zhixin] Yanshan Univ, Inst Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP Li, XB (corresponding author), Yanshan Univ, Inst Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM yhf5170@163.com; lixb@ysu.edu.cn; lq13583226492@163.com;
   c740759816h@163.com; lzxauto@ysu.edu.cn
RI Liu, Zhixin/AAO-1419-2020
FU Natural Science Foundation of China [61873224]
FX The authors thank the financial support of the Natural Science
   Foundation of China under Grant No.61571387 and Natural Science
   Foundation of China under Grant No.61873224.
CR Ahn J, 2017, J MAR SCI TECH-JAPAN, V22, P758, DOI 10.1007/s00773-017-0442-1
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghani ASA, 2018, OCEAN ENG, V162, P224, DOI 10.1016/j.oceaneng.2018.05.027
   Ghani ASA, 2014, INT J NAV ARCH OCEAN, V6, P840, DOI 10.2478/IJNAOE-2013-0217
   He DM, 2004, OPT LASER ENG, V41, P217, DOI 10.1016/S0143-8166(02)00138-0
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Kahanov Y, 2001, INT J NAUT ARCHAEOL, V30, P257
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Ouyang B, 2013, IEEE J OCEANIC ENG, V38, P566, DOI 10.1109/JOE.2012.2229066
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Qiao X, 2019, MEASUREMENT, V133, P444, DOI 10.1016/j.measurement.2018.10.039
   Tian H, 2018, OPT LASER TECHNOL, V108, P515, DOI 10.1016/j.optlastec.2018.07.057
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhong Zhang, 2011, 2011 International Conference on Multimedia Technology, P254
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 23
TC 27
Z9 31
U1 4
U2 69
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20373
EP 20390
DI 10.1007/s11042-020-08701-3
EA APR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000527485500004
DA 2024-07-18
ER

PT J
AU Al-Turjman, F
   Alturjman, S
AF Al-Turjman, Fadi
   Alturjman, Sinem
TI 5G/IoT-enabled UAVs for multimedia delivery in industry-oriented
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things (IoT); Delay; IIoT; Multipath routing
ID PARTICLE SWARM OPTIMIZATION; SENSOR; WSN
AB Industrial Internet of Things (IIoTs) is the fast growing network of interconnected things that collect and exchange data using embedded sensors planted everywhere. It is an interconnection of several things through a diverse communication system capable of monitoring, collecting, exchanging, analysing, and delivering valuable and challenging amount of information. Given their ability to be operated autonomously, their high mobility, and their communication and processing power, Unmanned Aerial Vehicles (UAVs) are expected to be involved in numerous IIoT-related applications, where multimedia and video streaming plays a key role. Our main interest is the multimedia routing in IIoT and its facilities during and/or after operational hours. For recovering, constructing and selecting k-disjoint paths, capable of putting up with failure of the parameters but satisfying the quality of service, we introduce an industry-oriented Canonical Particle Swarm (CPS) optimization data delivery framework. During communication with the UAV, multi-swarm strategy is used to determine the optimal direction while performing a multipath routing. Authenticity of the proposed approach has been tested and results show that, compared to the ordinary Canonical Particle Multi-path Swarm (CPMS) optimization and Fully Multi-path Particle Swarm (FMPS) optimization, the proposed method is better.
C1 [Al-Turjman, Fadi; Alturjman, Sinem] Antalya Bilim Univ, Dept Comp Engn, Antalya, Turkey.
C3 Antalya Bilim University
RP Al-Turjman, F (corresponding author), Antalya Bilim Univ, Dept Comp Engn, Antalya, Turkey.
EM fadi.alturjman@antalya.edu.tr; sinem.alturjman@antalya.edu.tr
RI Al-Turjman, Fadi/C-7891-2019; Al-Turjman, Fadi/L-2998-2019
OI Al-Turjman, Fadi/0000-0001-6375-4123; Al-Turjman,
   Fadi/0000-0001-5418-873X
CR Adnan MA, 2014, SENSORS-BASEL, V14, P299, DOI 10.3390/s140100299
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Ai-Turjman F, 2019, FUTURE GENER COMP SY, V92, P1103, DOI 10.1016/j.future.2017.03.014
   Al-Nidawi Y, 2016, IEEE SENS J, V16, P1412, DOI 10.1109/JSEN.2015.2500502
   Al-Turjman F, 2018, IEEE T IND INFORM, V14, P2736, DOI 10.1109/TII.2018.2808190
   Al-Turjman F, 2018, COMPUT COMMUN, V121, P33, DOI 10.1016/j.comcom.2018.02.012
   Al-Turjman F, 2017, PERVASIVE MOB COMPUT, V42, P299, DOI 10.1016/j.pmcj.2017.05.001
   Al-Turjman FM, 2017, ANN TELECOMMUN, V72, P3, DOI 10.1007/s12243-016-0533-8
   Al-Turjman FM, 2015, AD HOC NETW, V24, P172, DOI 10.1016/j.adhoc.2014.08.017
   [Anonymous], 2010, QUALITY
   Chi QP, 2014, IEEE T IND INFORM, V10, P1417, DOI 10.1109/TII.2014.2306798
   Dhir M. B. K., 2016, GLOBAL J COMPUTER SC, V15, P3
   Jiang SS, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/871596
   Karschnia B, 2017, IND INTERNET THINGS
   Lim WH, 2014, APPL SOFT COMPUT, V24, P623, DOI 10.1016/j.asoc.2014.08.013
   Pant M, 2007, IEEE C EVOL COMPUTAT, P3294, DOI 10.1109/CEC.2007.4424896
   Petrov V., 2017, ARXIV170300541
   Radwan A, 2017, MOBILE CACHING ENABL
   Radwan Ayman, 2015, ENERGY EFFICIENT SMA
   Shieh HL, 2011, APPL MATH COMPUT, V218, P4365, DOI 10.1016/j.amc.2011.10.012
   Singh GT, 2016, IEEE INTERNET THINGS, V3, P572, DOI 10.1109/JIOT.2015.2504487
   Spanò E, 2016, IEEE SENS J, V16, P5452, DOI 10.1109/JSEN.2016.2564995
   Vis JK, 2015, PARTICLE SWARM OPTIM
   Wu CH, 2007, LECT NOTES COMPUT SC, V4459, P78
   Zhou YC, 2016, INT J SENS NETW, V20, P37, DOI 10.1504/IJSNET.2016.074280
NR 25
TC 61
Z9 61
U1 1
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8627
EP 8648
DI 10.1007/s11042-018-6288-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600015
DA 2024-07-18
ER

PT J
AU Huang, WD
   Qian, C
   Cui, Y
AF Huang, Weidong
   Qian, Chen
   Cui, Yang
TI Study on multimedia network Weibo situational awareness model and
   emotional algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information theory; E-info; Emotion; Situational awareness; Weibo
AB With the development of 4G networks and the popularity of mobile terminals, the public's way of expressing emotions and expressing opinions has been transferred from traditional information media to multimedia Internet platforms, which has promoted the dissemination of public information on multimedia networks into public view. The public through the APP software, smart phones, various types of mobile terminals portable, and quickly participate in the network public opinion information carried by Weibo, WeChat, forum and other media. This trend can be represented by various attributes, and those with objectivity and irrefutability provide the strongest evidence of the reality of an event. At present, scholars at home and abroad mostly use the quantitative characteristics of online public opinion texts as the basis for calculation to judge the situation and emotions of online public opinion. In this paper, information theory is introduced to the field of public opinion analysis, and S-info is defined and extended to E-info; the sum of E-info of an event shows the event trend, representing the emotional intensity and tendency and their changes over time. Based on this, a Weibo situational perception model is constructed. The dictionary method is used to calculate the emotion of the text, and is then combined with the Weibo situational perception model to analyze the sentimental trend. The model is used on a dataset of 1,448,188 Weibos, and the events were separately statistically analyzed. The sum of the E-info are collected and compared with the number of Weibos. From the comparison, key time points and emotional burst points of the event can be picked up clearly, revealing the novel characteristics of this model. Duplications and advertisements can be filtered out and the reality can be revealed, uncovering the objective and irrefutable attributes.
C1 [Huang, Weidong; Qian, Chen; Cui, Yang] Nanjing Univ Posts & Telecommun, Sch Econ & Management, Nanjing 210046, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Huang, WD (corresponding author), Nanjing Univ Posts & Telecommun, Sch Econ & Management, Nanjing 210046, Peoples R China.
EM huangwd@njupt.edu.cn
RI qian, chen/HSG-9475-2023
CR Alsumaitl B, 2008, P 8 IEEE INT C DAT M, P3
   [Anonymous], 2017, NATL TAIWAN U SEMANT
   [Anonymous], 2017, CNKI SENTIMENT ANAL
   [Anonymous], 1948, BSTJ
   Dan P, 2009, MODERN INFORM, V29, P4
   El-Din Doaa Mohey, 2016, SURVEY SENTIMENT ANA, DOI [10.1016/j.jksues.2016.04.002, DOI 10.1016/J.JKSUES.2016.04.002(2016.4.18)]
   Fuji C, 2014, J INFORM, P97
   [何炎祥 He Yanxiang], 2017, [计算机学报, Chinese Journal of Computers], V40, P773
   Jing Z, 2013, RES HOT SPOT DETECTI
   Kang W, 2018, INFORM SCI, V36, P113
   Liu Kan, 2011, Computer Engineering and Applications, V47, P170, DOI 10.3778/j.issn.1002-8331.2011.36.047
   Longfei L., 2015, J CHIN INF PROCESS, V29, P159
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Tao C, 2013, J INFORM, P7
   Wenjing L, 2009, INFORM SCI, V27, P986
   Xiaobo T, 2016, LIB INFORM SERVICE, V60, P121
   Xu Linhong, 2008, Journal of the China Society for Scientific and Technical Information, V27, P180
   Xu YM, 2017, RES QUANTE EC TECHNO, V034, P94
   You D.D., 2016, J INTELL-BASEL, V35, P156
   Zhang Hong, 2007, Computer Engineering and Applications, V43, P159
NR 20
TC 3
Z9 3
U1 4
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10383
EP 10403
DI 10.1007/s11042-019-07779-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600035
DA 2024-07-18
ER

PT J
AU Jaswanth, BRB
   Prasad, VVKDV
   Kamaraju, M
AF Jaswanth, Rohith Bala B.
   Prasad, V. V. K. D. V.
   Kamaraju, M.
TI RETRACTED: Design of Three Stage Cascaded Low Power CMOS Operational
   Trans Conductance Amplifier (OTA) for ECG Applications (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Transconductance; Potential difference; Low power; ECG applications
ID FILTER
AB The primary test incorporates intensifying the weak signal within the noisy environment. The OTA configuration is all around used to evacuate the glint commotion. The execution of the ECG enhancer can be enhanced by three-arrange operational transconductance amplifiers (OTAs) utilizing nanometer CMOS advancements with doping input transistor measuring, device coordinating and filtration process. This three phase configuration has a few favorable circumstances, for example, current part, source degeneration to expand the linearity of the device.
C1 [Jaswanth, Rohith Bala B.; Prasad, V. V. K. D. V.; Kamaraju, M.] Gudlavalleru Engn Coll, Gudlavalleru, India.
RP Jaswanth, BRB (corresponding author), Gudlavalleru Engn Coll, Gudlavalleru, India.
EM rjaswanth76@gmail.com; varrevkdvp@rediffmail.com; madduraju@yahoo.com
RI Varaprasad, VVKD/T-2816-2018; Maddu, Kamaraju/AAT-8153-2020; Tata,
   Subhashini/AAW-8547-2021; B, Rohith Bala Jaswanth/ABD-7644-2020
OI Varaprasad, VVKD/0000-0001-9554-3814; Maddu,
   Kamaraju/0000-0002-8212-5960; Tata, Subhashini/0000-0003-2717-9912; B,
   Rohith Bala Jaswanth/0000-0002-9754-6063
CR Azcona C, 2013, IEEE T CIRCUITS-I, V60, P2333, DOI 10.1109/TCSI.2013.2244432
   AzIz F. I. B. A., 2013, MOD APPL SCI, V7, P70
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Chatterjee S, 2005, IEEE J SOLID-ST CIRC, V40, P2373, DOI 10.1109/JSSC.2005.856280
   Jyoti J, 2015, INT J COMPUT APPL, V122, P14
   Lee SM, 2009, SERV BUS, V3, P1, DOI 10.1007/s11628-008-0051-5
   Menon M, 2010, INT C REC TRENDS INF
   Mohieldin N, 2003, IEEE J SOLID STATE C, V38
   Raj N, 2010, CYBER J MULTIDISCIP
   Saavedra CE, 2008, IEEE T CIRC SYST, V55
   Saini P, 2012, INT J ADV COMPUT SC, V3, P161
   Singer M, 2013, INFECT DIS POVERTY, V2, DOI 10.1186/2049-9957-2-26
   Solís-Bustos S, 2000, IEEE T CIRCUITS-II, V47, P1391, DOI 10.1109/82.899631
   Wu C-K, 2007, IEEE T CIRC SYST 2, V54
   Zhu F, 2005, FEEDFORWARD REVERSED
NR 15
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9063
EP 9073
DI 10.1007/s11042-018-6873-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600036
DA 2024-07-18
ER

PT J
AU Liang, XY
AF Liang, Xinyu
TI On the crack evolution and failure form of concrete specimens based on
   minimum energy principle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concrete; CT test; Stress state; Failure area; Failure energy
ID STRENGTH; MODEL
AB By subjecting concrete specimens to pressure and tension under different loading conditions, this paper studies the relationships of stress state with crack opening and development and failure forms of specimens. Based on the principle of conservation of energy, it explores the relationship between failure area, failure energy and strength. The numerical calculation and CT test results show that the stress state of concrete determines the failure form, that the failure form determines the failure area, that failure area determines the energy consumed by the failure and that the failure energy determines the strength of the specimen, regardless of how the specimen is loaded.
C1 [Liang, Xinyu] Xian Technol Univ, Sch Civil Engn & Architecture, Xian, Peoples R China.
C3 Xi'an Technological University
RP Liang, XY (corresponding author), Xian Technol Univ, Sch Civil Engn & Architecture, Xian, Peoples R China.
EM key_xinyu@163.com
CR [Anonymous], J CHINA COAL SOC
   [Anonymous], 1917, J ASTM INT JAI
   BISCHOFF PH, 1991, MATER STRUCT, V24, P425, DOI 10.1007/BF02472016
   [陈樟福生 CHEN Zhangfusheng], 2008, [水利学报, Journal of Hydraulic Engineering], V39, P385
   Deng ZH, 2019, KSCE J CIV ENG, V23, P699, DOI 10.1007/s12205-018-0575-8
   Khaliq W, 2018, FIRE SAFETY J, V96, P203, DOI 10.1016/j.firesaf.2018.01.009
   Klepaczko JR, 2001, INT J IMPACT ENG, V25, P387, DOI 10.1016/S0734-743X(00)00050-6
   Liang XY, 2010, J HYDROELECTRIC ENG, V31, P35
   Ma H. F., 2004, J CHINA I WATER RES, V2, P124
   [马怀发 Ma Huaifa], 2005, [水利学报, Journal of Hydraulic Engineering], V36, P846
   Malvar LJ, 1998, ACI MATER J, V95, P735
   Morita M, 1989, 897127 ISABE, V89-7127, P1200
   OTTOSEN NS, 1977, J ENG MECH DIV-ASCE, V103, P527
   Tedesco JW, 1997, COMPUT STRUCT, V64, P1053, DOI 10.1016/S0045-7949(97)00018-7
   [田威 TIAN Wei], 2008, [水利学报, Journal of Hydraulic Engineering], V39, P889
   Vishalakshi KP, 2018, ENG FRACT MECH, V194, P52, DOI 10.1016/j.engfracmech.2018.02.029
   Xinyu L, 2015, MATER RES INNOV, V19, P1095, DOI 10.1179/1432891714Z.0000000001255
NR 17
TC 1
Z9 1
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10629
EP 10638
DI 10.1007/s11042-019-7616-2
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600049
DA 2024-07-18
ER

PT J
AU Singh, DN
   Hashmi, MF
   Sharma, SK
AF Singh, D. Narendhar
   Hashmi, Mohammad Farukh
   Sharma, Sudhir Kr.
TI Predictive analytics & modeling for modern health care system for
   cerebral palsy patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram (EEG); Independent component analysis (ICA);
   Principal component analysis (PCA); Support vector machine (SVM);
   Internet of things; Machine learning (ML); Fast Fourier transform (FFT)
ID EPILEPSY
AB The time-shifting elements and high between individual changeability make early forecast of a seizure express a difficult errand. Numerous examinations have demonstrated that EEG signals do have profitable data that if effectively broke down, could help in the expectation of seizures in epileptic patients before their event. A few numerical changes have been broke down for its connection with seizure beginning forecast and a progression of analyses were done to ensure their qualities. New calculations are exhibited to help elucidate, screen, and cross-approve the order of EEG signs to foresee the ictal (for example seizure) states, explicitly the preictal, interictal, and postictal states in the mind. These new strategies show promising outcomes in distinguishing the nearness of a preictal stage before the ictal state. Artificial Intelligence and Machine Learning are playing major role in Diagnosis and Predicting the diseases, EEG signal were recorded with 16 channel system from brain scalp and stored in system. From recorded database seizure levels were analyzed from each channel by articrafting with ICA and PCA algorithms and processed through Band pass filter to identify the Delta, Theta, Alpha and Beta levels. After collecting the brain signals from each channel they were bided with FFT to get the data in time domain series. A machine learning model is developed using python programming by sampling on obtained EEG data, sampled data is trained on to the system. Machine Learning algorithms were applied to the data to accuracy and predict the accuracy on developed model neural network is applied to identify the True-False values. The analyzed data is integrated with IOT framework to Diagnosis the Cerebral Palsy patient remotely. Remote monitoring system for the persons with Intellectual disabilities and update the health status to care takers time to time while they are at work. It's also reduces the patient work load by checking his details staying at home rather going to a hospital. If system identifies any changes in patient heart rate, brain signals, body temperature, the system alerts the doctor and respective relatives about patient's status over IOT and also stores the patient details in the cloud.
C1 [Singh, D. Narendhar; Sharma, Sudhir Kr.] Jaipur Natl Univ, Dept Elect & Commun Engn, Jaipur, Rajasthan, India.
   [Hashmi, Mohammad Farukh] Natl Inst Technol, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
C3 Jaipur National University; National Institute of Technology (NIT
   System); National Institute of Technology Warangal
RP Hashmi, MF (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
EM dnarendarsingh@gmail.com; mdfarukh@nitw.ac.in; sudhir.732000@gmail.com
RI D, NARENDAR SINGH/S-2856-2017; HASHMI, MOHAMMAD FARUKH/W-1428-2019;
   Sharma, Sudhir/ITT-7007-2023
OI D, NARENDAR SINGH/0000-0001-6951-9714; HASHMI, MOHAMMAD
   FARUKH/0000-0002-3808-9122; Sharma, Sudhir/0000-0001-6932-9160; Sharma,
   Sudhir Kumar/0000-0003-4838-8481
CR AlMotiri SH, 2016, 2016 IEEE 4TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD WORKSHOPS (FICLOUDW), P39, DOI 10.1109/W-FiCloud.2016.24
   [Anonymous], INT ENCY STAT SCI
   Castellaro C, 2002, NEUROPHYSIOL CLIN, V32, P193, DOI 10.1016/S0987-7053(02)00302-7
   Chatterjee P, 2015, INT CONF COMPUT INTE, P903, DOI 10.1109/CICN.2015.178
   CIZEK V, 1970, IEEE T ACOUST SPEECH, VAU18, P340, DOI 10.1109/TAU.1970.1162139
   COOLEY JW, 1987, MIKROCHIM ACTA, V3, P33
   Hughes JR, 2005, EPILEPSY BEHAV, V7, P531, DOI 10.1016/j.yebeh.2005.07.021
   Hughes JR, 2003, EPILEPSY BEHAV, V4, P793, DOI 10.1016/j.yebeh.2003.09.005
   IASEMIDIS L D, 1990, Brain Topography, V2, P187, DOI 10.1007/BF01140588
   Iasemidis LD, 2001, US patent, Patent No. [6304775 B1, 6304775]
   ISAKSSON A, 1981, P IEEE, V69, P451, DOI 10.1109/PROC.1981.11988
   Jacoby A, 2005, EPILEPSIA, V46, P1978, DOI 10.1111/j.1528-1167.2005.00345.x
   Junling Z, 2006, 2005 IEEE ENG MED BI, P7277
   Kay S. M., 1988, Modern Spectral Estimation: Theory and Application
   Kecman V., 2001, LEARNING SOFT COMPUT
   Kraniauskas P, 1994, IEEE SIGNAL PROC MAG, V11, P24, DOI 10.1109/79.273892
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Nhat VDM, 2005, ADV SOFT COMP, P311
   Pujari A.K., 2001, Data Mining Techniques
   Rghioui A, 2014, COLLOQ INF SCI TECH, P384, DOI 10.1109/CIST.2014.7016651
   Sahu S., 2016, 2016 INT C REC ADV I, P1, DOI DOI 10.1109/ICRAIE.2016.7939565
   Satija U, 2017, IEEE INTERNET THINGS, V4, P815, DOI 10.1109/JIOT.2017.2670022
   Shlens J., 2014, A tutorial on principal component analysis
   Sundaravadivel P, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P17, DOI [10.1109/iNIS.2016.016, 10.1109/iNIS.2016.9]
   Teive HAG, 2002, ARQ NEURO-PSIQUIAT, V60, P505, DOI 10.1590/S0004-282X2002000300033
   Tewary S, 2016, 2016 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Vapnik V.N., 2015, MEASURES COMPLEXITY, P11
   WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901
NR 28
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10285
EP 10307
DI 10.1007/s11042-019-07834-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600030
DA 2024-07-18
ER

PT J
AU Yu, HY
   Gao, LR
   Li, J
   Zhan, B
AF Yu, Haoyang
   Gao, Lianru
   Li, Jun
   Zhan, Bing
TI Subspace-based multitask learning framework for hyperspectral imagery
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Classification; Subspace projection; Support vector
   machine
ID SPECTRAL-SPATIAL CLASSIFICATION; SUPPORT VECTOR MACHINES; EXTRACTION;
   REPRESENTATION; OPTIMIZATION
AB Subspace-based models have been widely applied for hyperspectral imagery applications, especially for classification. The main principle of these methods is based on the fact that the original image can approximately lie on a lower-dimensional subspace. However, due to the existence of mixed samples, the subspace projection is unstable and affected by the selection of training samples, such that may lead to poor characterization and classification performances. In order to improve the robustness and characterization ability of the subspace-based classification models, this paper proposes a novel subspace-based multitask learning framework. In particular, the original image is first projected to the multiple subspaces in different branches. Then, the support vector machine (SVM) classifier is applied in each branch to deal with the projected data sets. With a consideration of integrating the spatial information, an extended step is provided including the process of a Markov Random Field (MRF) based on the result of SVM. Finally, the classification result is obtained by a decision fusion process. Experimental results on three real hyperspectral data sets demonstrate the improvements on classification performance of the proposed methods over other related methods.
C1 [Yu, Haoyang; Gao, Lianru; Zhan, Bing] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Yu, Haoyang; Zhan, Bing] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
   [Li, Jun] Sun Yat Sen Univ, Sch Geog & Planning, Guangdong Prov Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.
C3 Chinese Academy of Sciences; The Institute of Remote Sensing & Digital
   Earth, CAS; Chinese Academy of Sciences; University of Chinese Academy
   of Sciences, CAS; Sun Yat Sen University
RP Gao, LR (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
EM yuhy@radi.ac.cn; gaolr@radi.ac.cn; lijun48@mail.sysu.edu.cn;
   zb@radi.ac.cn
RI Gao, Lianru/JOZ-6951-2023; Yu, Haoyang/P-4934-2017
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2006, REMOTE SENSING DIGIT
   BOREL CC, 1994, REMOTE SENS ENVIRON, V47, P403, DOI 10.1016/0034-4257(94)90107-4
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Chang C. I., 2003, HYPERSPECTRAL IMAGIN
   Chang CI, 1998, IEEE T GEOSCI REMOTE, V36, P898, DOI 10.1109/36.673681
   Chen C, 2014, REMOTE SENS-BASEL, V6, P5795, DOI 10.3390/rs6065795
   Chen C, 2014, IEEE J-STARS, V7, P1047, DOI 10.1109/JSTARS.2013.2295610
   Du B, 2018, IEEE T IMAGE PROCESS, V27, P4219, DOI 10.1109/TIP.2018.2836324
   Du B, 2017, IEEE T MULTIMEDIA, V19, P67, DOI 10.1109/TMM.2016.2608780
   Du B, 2017, IEEE T CYBERNETICS, V47, P14, DOI 10.1109/TCYB.2015.2496974
   Farag AA, 2005, IEEE T GEOSCI REMOTE, V43, P1617, DOI 10.1109/TGRS.2005.849059
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Fjortoft R, 2003, IEEE T GEOSCI REMOTE, V41, P675, DOI 10.1109/TGRS.2003.809940
   Gao LR, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.042004
   Gao LR, 2015, IEEE GEOSCI REMOTE S, V12, P349, DOI 10.1109/LGRS.2014.2341044
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Jia X, 2008, IEEE GEOSCI REMOTE S, V5, P311, DOI 10.1109/LGRS.2008.916076
   Jiang JJ, 2018, IEEE T GEOSCI REMOTE, V56, P4581, DOI 10.1109/TGRS.2018.2828029
   Jiang JJ, 2017, IEEE GEOSCI REMOTE S, V14, P404, DOI 10.1109/LGRS.2016.2645708
   Jiang JJ, 2016, INT CONF ACOUST SPEE, P3346, DOI 10.1109/ICASSP.2016.7472297
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   KIRKPATRICK S, 1984, J STAT PHYS, V34, P975, DOI 10.1007/BF01009452
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Li J, 2010, IEEE T GEOSCI REMOTE, V48, P4085, DOI 10.1109/TGRS.2010.2060550
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Platt JC, 2000, ADV NEUR IN, P61
   Plaza A, 2004, IEEE T GEOSCI REMOTE, V42, P650, DOI 10.1109/TGRS.2003.820314
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177
   Watanabe S., 1967, Computer and Information Science, V2, P91
   Xie JY, 2013, INTELL DATA ANAL, V17, P649, DOI 10.3233/IDA-130598
   Yu HY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061695
   Yu HY, 2018, REMOTE SENS LETT, V9, P534, DOI 10.1080/2150704X.2018.1446565
   Yu HY, 2017, IEEE GEOSCI REMOTE S, V14, P2142, DOI 10.1109/LGRS.2017.2755061
   Yu HY, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040355
   Zhang B, 2011, IEEE GEOSCI REMOTE S, V8, P973, DOI 10.1109/LGRS.2011.2145353
   Zhong YF, 2014, IEEE J-STARS, V7, P1314, DOI 10.1109/JSTARS.2013.2290296
NR 40
TC 0
Z9 0
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8887
EP 8909
DI 10.1007/s11042-018-7010-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600027
DA 2024-07-18
ER

PT J
AU Khraief, C
   Benzarti, F
   Amiri, H
AF Khraief, Chadia
   Benzarti, Faouzi
   Amiri, Hamid
TI Elderly fall detection based on multi-stream deep convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Elderly people; Smart home; Video surveillance; Deep
   learning; Multi stream CNN; RGB-depth cameras; Kinect cameras; Optical
   flow; Motion of binary motion images; Data augmentation; Transfer
   learning
ID DETECTION SYSTEM; NEURAL-NETWORK
AB Fall is the biggest threat to seniors, with significant emotional, physical and financial implications. It is the major cause of serious injuries, disabilities, hospitalizations and even death especially for elderly people living alone. Timely detection could provide immediate medical service to the injured and avoid its harmful consequences. Great number of vision-based techniques has been proposed by installing cameras in several everyday environments. Recently, deep learning has revolutionized these techniques, mostly using convolutional neural networks (CNNs). In this paper, we propose weighted multi-stream deep convolutional neural networks that exploit the rich multimodal data provided by RGB-D cameras. Our method detects automatically fall events and sends a help request to the caregivers. Our contribution is three-fold. We build a new architecture composed of four separate CNN streams, one for each modality. The first modality is based on a single combined RGB and depth image to encode static appearance information. RGB image is used to capture color and texture and depth image deals with illumination variations. In contrast of the first feature that lacks the contextual information about previous and next frames, the second modality characterizes the human shape variations. After background subtraction and person recognition, human silhouette is extracted and stacked to define history of binary motion HBMI. The last two modalities are used to more discriminate the motion information. Stacked amplitude and oriented flow are used in addition to stacked optical flow field to describe respectively the velocity, the direction and the motion displacements. The main motivation behind the use of these multimodal data is to combine complementary information such as motion, shape, RGB and depth appearance to achieve more accurate detection than using only one modality. Our second contribution is the combination of the four streams to generate the final decision for fall detection. We evaluate early and late fusion strategies and we have defined the weight of each modality based on its overall system performance. Weighted score fusion is finally adopted based on our experiments. In the third contribution, transfer learning and data augmentation are applied to increase the amount of training data, avoid over fitting and improve the accuracy. Experiments have been conducted on publicly available standard datasets and demonstrate the effectiveness of the proposed method compared to existing methods.
C1 [Khraief, Chadia; Benzarti, Faouzi; Amiri, Hamid] Univ Tunis El Manar, Natl Engn Sch Tunis ENIT, SITI Lab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Khraief, C (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis ENIT, SITI Lab, Tunis, Tunisia.
EM chadiaKhraief@gmail.com; benzartif@yahoo.fr; hamidlamiri@gmail.com
RI Benzarti, Faouzi/AAJ-8072-2020
CR Adhikari K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P81, DOI 10.23919/MVA.2017.7986795
   Albawendi S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P529, DOI 10.1145/3197768.3201539
   Alhimale L, 2014, APPL SOFT COMPUT, V18, P59, DOI 10.1016/j.asoc.2014.01.024
   Allali G, 2017, ARCH GERONTOL GERIAT, V69, P15, DOI 10.1016/j.archger.2016.09.008
   [Anonymous], SIGNAL IMAGE VIDEO P
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Burns ER, 2016, J SAFETY RES, V58, P99, DOI 10.1016/j.jsr.2016.05.001
   Casilari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140929
   Charfi I, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041106
   Cippitelli E, 2017, IEEE SENS J, V17, P3585, DOI 10.1109/JSEN.2017.2697077
   Delahoz YS, 2014, SENSORS-BASEL, V14, P19806, DOI 10.3390/s141019806
   Dollar P., 2010, BMVC 2010, DOI DOI 10.5244/C.24.68
   Doulamis A, 2018, P 11 PETRA 18
   Espinosa R, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103520
   Fan YX, 2017, NEUROCOMPUTING, V260, P43, DOI 10.1016/j.neucom.2017.02.082
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gasparrini S, 2014, SENSORS-BASEL, V14, P2756, DOI 10.3390/s140202756
   Colque RVHM, 2015, SIBGRAPI, P126, DOI 10.1109/SIBGRAPI.2015.21
   Kepski M, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P640
   Kharrat O, 2017, NPG Neurol Psychiatr Geriatr, V97, P5
   Khraief C, 2018, 10 INT C MACH VIS IC
   Khraief C, 2017, 10 INT C MACH VIS IC, P91
   Kistler BM, 2018, PREV CHRONIC DIS, V15, DOI 10.5888/pcd15.170518
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lie WN, 2018, PROC INT WORKSH ADV
   Lin HY, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P285, DOI [10.1109/ICS.2016.0064, 10.1109/ICS.2016.63]
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Mauldin TR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103363
   Merrouche F, 2017, ACM PROCEEDINGS OF INTERNATIONAL CONFERENCE OF COMPUTING FOR ENGINEERING AND SCIENCE (ICCES'17), P29, DOI 10.1145/3129186.3129192
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Nizam Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072260
   Nizam Y, 2017, PROCEDIA COMPUT SCI, V105, P131, DOI 10.1016/j.procs.2017.01.191
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Pathak D., 2017, INT J INNOVATIVE RES, V5, P1468
   Rahman MM, 2017, IEEE INT CON MULTI, P991, DOI 10.1109/ICME.2017.8019538
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Roy N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189266
   Santos GL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071644
   Sehairi K., 2018, 2018 International Conference on Intelligent Systems and Computer Vision, P1, DOI 10.1109/ISACV.2018.8354084
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stevens JA, 2014, J AM GERIATR SOC, V62, P470, DOI 10.1111/jgs.12702
   Uddin MZ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072027
   Vielzeuf V., 2017, P 19 ACM INT C MULT, P569
   Wang K, 2016, IEEE INT C BIOINFORM, P1228, DOI 10.1109/BIBM.2016.7822694
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wei W, 2016, EUR MICROW INTEGRAT, P169
   Wortmann M, 2012, ALZHEIMERS RES THER, V4, DOI 10.1186/alzrt143
   Xu T, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8030418
   Yang XD, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P978, DOI 10.1145/2964284.2964297
   Yu M, 2012, IEEE T INF TECHNOL B, V16, P1274, DOI 10.1109/TITB.2012.2214786
   Yun YX, 2016, COMPUT VIS IMAGE UND, V148, P111, DOI 10.1016/j.cviu.2015.12.002
   Zerrouki N, 2018, MULTIMED TOOLS APPL, V77, P6405, DOI 10.1007/s11042-017-4549-5
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang Z, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769540
   Zhou X, 2018, PLAST RECON SURG-SER, P1, DOI 10.1007/978-981-10-3400-8_1
NR 60
TC 35
Z9 39
U1 3
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19537
EP 19560
DI 10.1007/s11042-020-08812-x
EA MAR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521787600001
DA 2024-07-18
ER

PT J
AU Alghamdi, A
   Hammad, M
   Ugail, H
   Abdel-Raheem, A
   Muhammad, K
   Khalifa, HS
   Abd El-Latif, AA
AF Alghamdi, Ahmed
   Hammad, Mohamed
   Ugail, Hassan
   Abdel-Raheem, Asmaa
   Muhammad, Khan
   Khalifa, Hany S.
   Abd El-Latif, Ahmed A.
TI Detection of myocardial infarction based on novel deep transfer learning
   methods for urban healthcare in smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Myocardial infarction; ECG; Convolution neural network
   (CNN); Smart cities
ID CONVOLUTIONAL NEURAL-NETWORK; AUTOMATED DETECTION; ECG; DIAGNOSIS;
   FUSION; LOCALIZATION; ENERGY
AB One of the common cardiac disorders is a cardiac attack called Myocardial infarction (MI), which occurs due to the blockage of one or more coronary arteries. Timely treatment of MI is important and slight delay results in severe consequences. Electrocardiogram (ECG) is the main diagnostic tool to monitor and reveal the MI signals. The complex nature of MI signals along with noise poses challenges to doctors for accurate and quick diagnosis. Manually studying large amounts of ECG data can be tedious and time-consuming. Therefore, there is a need for methods to automatically analyze the ECG data and make diagnosis. Number of studies has been presented to address MI detection, but most of these methods are computationally expensive and faces the problem of overfitting while dealing real data. In this paper, an effective computer-aided diagnosis (CAD) system is presented to detect MI signals using the convolution neural network (CNN) for urban healthcare in smart cities. Two types of transfer learning techniques are employed to retrain the pre-trained VGG-Net (Fine-tuning and VGG-Net as fixed feature extractor) and obtained two new networks VGG-MI1 and VGG-MI2. In the VGG-MI1 model, the last layer of the VGG-Net model is replaced with a specific layer according to our requirements and various functions are optimized to reduce overfitting. In the VGG-MI2 model, one layer of the VGG-Net model is selected as a feature descriptor of the ECG images to describe it with informative features. Considering the limited availability of dataset, ECG data is augmented which has increased the classification performance. A standard well-known database Physikalisch-Technische Bundesanstalt (PTB) Diagnostic ECG is used for the validation of the proposed framework. It is evident from experimental results that the proposed framework achieves a high accuracy surpasses the existing methods. In terms of accuracy, sensitivity, and specificity; VGG-MI1 achieved 99.02%, 98.76%, and 99.17%, respectively, while VGG-MI2 models achieved an accuracy of 99.22%, a sensitivity of 99.15%, and a specificity of 99.49%.
C1 [Alghamdi, Ahmed] Univ Jeddah, Dept Cybersecur, Coll Comp Sci & Engn, Jeddah, Saudi Arabia.
   [Hammad, Mohamed] Menoufia Univ, Fac Comp & Informat, Informat Technol Dept, Shibin Al Kawm, Egypt.
   [Ugail, Hassan] Univ Bradford, Ctr Visual Comp, Bradford BD7 1DP, W Yorkshire, England.
   [Abdel-Raheem, Asmaa] Menoufia Univ, Fac Med, Publ Hlth & Community Med Dept, Shibin Al Kawm, Egypt.
   [Muhammad, Khan] Sejong Univ, Dept Software, Intelligent Media Lab, Seoul, South Korea.
   [Khalifa, Hany S.] Misr Higher Inst Commerce & Comp, Comp Sci Dept, Mansoura, Egypt.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm, Egypt.
   [Abd El-Latif, Ahmed A.] Nile Univ, Sch Informat Technol & Comp Sci, Giza, Egypt.
   [Abd El-Latif, Ahmed A.] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
C3 University of Jeddah; Egyptian Knowledge Bank (EKB); Menofia University;
   University of Bradford; Egyptian Knowledge Bank (EKB); Menofia
   University; Sejong University; Egyptian Knowledge Bank (EKB); Menofia
   University; Egyptian Knowledge Bank (EKB); Nile University; Harbin
   Institute of Technology
RP Abd El-Latif, AA (corresponding author), Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm, Egypt.; Abd El-Latif, AA (corresponding author), Nile Univ, Sch Informat Technol & Comp Sci, Giza, Egypt.; Abd El-Latif, AA (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM a.rahiem@gmail.com
RI Khalifa, Hany S./AAO-3146-2021; Hammad, Mohamed/U-6169-2019; Muhammad,
   Khan/L-9059-2016; Khan, Muhammad/IXN-8470-2023; Abd El-Latif, Ahmed A.
   A./GRO-1613-2022
OI Khalifa, Hany S./0000-0001-9462-3409; Hammad,
   Mohamed/0000-0002-6506-3083; Muhammad, Khan/0000-0003-4055-7412; Abd
   El-Latif, Ahmed A. A./0000-0002-5068-2033; Muhammad,
   Khan/0000-0002-5302-1150
FU University of Jeddah, Jeddah, Saudi Arabia [UJ-02-018-ICGR]; DSR;
   TYSP-Talented Young Scientist Program (China); Menoufia University
   (Egypt)
FX This project was funded by University of Jeddah, Jeddah, Saudi Arabia
   (Project number: UJ-02-018-ICGR). The authors, therefore, gratefully
   acknowledge DSR technical and financial support. Also, Ahmed A. Abd
   El-Latif acknowledges support from TYSP-Talented Young Scientist Program
   (China) and Menoufia University (Egypt). Additionally, the authors
   warmly thank their families for their unconditional support.
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Acharya UR, 2016, KNOWL-BASED SYST, V99, P146, DOI 10.1016/j.knosys.2016.01.040
   Al-Kindi S. G., 2011, 2011 1st Middle East Conference on Biomedical Engineering (MECBME), P454, DOI 10.1109/MECBME.2011.5752162
   Aly AM, 2017, SSDBM 2017: 29TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, DOI 10.1145/3085504.3085523
   Amrani M, 2018, NEURAL COMPUT APPL, V30, P2047, DOI 10.1007/s00521-018-3616-9
   [Anonymous], COMPUT VIS PATTERN R
   Arif M, 2012, J MED SYST, V36, P279, DOI 10.1007/s10916-010-9474-3
   Bousseljot R., 1995, BIOMED TECH, V40, P317, DOI [10.1515/bmte.1995.40.s1.317, DOI 10.1515/BMTE.1995.40.S1.317, 10.1515/bmte.1995.40s1.317]
   BOUVRIE J, 2007, NOTES CONVOLUTIONAL
   Chang PC, 2012, APPL SOFT COMPUT, V12, P3165, DOI 10.1016/j.asoc.2012.06.004
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dohare AK, 2018, APPL SOFT COMPUT, V64, P138, DOI 10.1016/j.asoc.2017.12.001
   Duda R.O., 2001, PATTERN CLASSIFICATI, V2nd, P55
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hall J. E., 2016, GUYTON HALL TXB MED
   HAMMAD M, 2019, FUTUR GENER COMPUT S
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   Hammad M, 2018, MEASUREMENT, V125, P634, DOI 10.1016/j.measurement.2018.05.033
   Han C, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105138
   Han C, 2019, COMPUT METH PROG BIO, V175, P9, DOI 10.1016/j.cmpb.2019.03.012
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Janwe NJ, 2018, APPL INTELL, V48, P2047, DOI 10.1007/s10489-017-1033-x
   Jayachandran ES, 2010, J MED SYST, V34, P985, DOI 10.1007/s10916-009-9314-5
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   JUN TJ, 2018, ARXIV180406812V1
   KLIGFIELD P, 2018, J ELECTROCARDIOL, V51, P620, DOI DOI 10.1016/J.JELECTROCARD.2018.03.017
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19030092
   Liu B, 2015, COMPUT BIOL MED, V61, P178, DOI 10.1016/j.compbiomed.2014.08.010
   Liu WH, 2018, BIOMED SIGNAL PROCES, V45, P22, DOI 10.1016/j.bspc.2018.05.013
   *MATHWORKS, 2019, GET STARTED TRANSFER
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Oh SL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142870
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Paul JK, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103331
   PAWIAK P, 2018, EXPERT SYST APPL, V92, P334
   PAWIAK P, 2018, SWARM EVOL COMPUT, V39, P192
   Plawiak P, 2020, NEURAL COMPUT APPL, V32, P11137, DOI 10.1007/s00521-018-03980-2
   Protopapadakis E, 2019, APPL INTELL, V49, P2793, DOI 10.1007/s10489-018-01396-y
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Rajput JS, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16214068
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadhukhan D, 2018, IEEE T INSTRUM MEAS, V67, P2303, DOI 10.1109/TIM.2018.2816458
   Safdarian N., 2014, J. Biomed. Sci. Eng, V7, P818, DOI [DOI 10.4236/JBISE.2014.710081, 10.4236/jbise.2014.710081]
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharma LN, 2015, IEEE T BIO-MED ENG, V62, P1827, DOI 10.1109/TBME.2015.2405134
   Sharma M, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103446
   Sharma M, 2018, COMPUT BIOL MED, V102, P341, DOI 10.1016/j.compbiomed.2018.07.005
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STROM JB, 2019, J AM SOC ECHOCARDIOG
   SUN J, 2016, IEEE 2016 3 INT C IN
   Sun L, 2012, IEEE T BIO-MED ENG, V59, P3348, DOI 10.1109/TBME.2012.2213597
   Thygesen K, 2007, J AM COLL CARDIOL, V50, P2173, DOI [10.1161/CIRCULATIONAHA.107.187397, 10.1016/j.jacc.2007.09.011]
   Tsai DY, 2005, MEASUREMENT, V37, P284, DOI 10.1016/j.measurement.2004.11.015
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   VELASCO JM, 2017, IEEE C EV COMP CEC
   Wang ZH, 2020, COGN SYST RES, V59, P15, DOI 10.1016/j.cogsys.2019.09.001
   Wu J, 2017, DESTECH TRANS ECON, P306
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Zeng K, 2019, APPL INTELL, V49, P292, DOI 10.1007/s10489-018-1270-7
   2019, CARDIOVASCULAR DIS W
NR 63
TC 82
Z9 83
U1 5
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14913
EP 14934
DI 10.1007/s11042-020-08769-x
EA MAR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000521673400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Maka, T
AF Maka, Tomasz
TI Influence of adaptive thresholding on peaks detection in audio data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal analysis; Adaptive thresholding; Genetic algorithm
ID ALGORITHM
AB Many audio analysis systems employ peak picking procedure to produce the final decision. A typical scheme uses a thresholding function to minimise detection errors where its form depends on the structure of the input signal. The paper covers the problem of an adaptive thresholding function estimation. Using the genetic algorithm to optimise the components of the thresholding function we have determined the level of importance of individual local statistics on the final function representation. The proposed method has been used to tune the peak detection procedure to identify the change points in an audio signal. In the result of the heuristic configuration, the best accuracy of segment boundaries have been obtained for thresholding function built on top of two local statistics of the detection function and constant value. Finally, as an example, a comparison with the state-of-the-art scheme for audio segmentation was performed.
C1 [Maka, Tomasz] West Pomeranian Univ Technol, Fac Comp Sci & Informat Technol, Szczecin Zolnierska 52, PL-71210 Szczecin, Poland.
C3 West Pomeranian University of Technology
RP Maka, T (corresponding author), West Pomeranian Univ Technol, Fac Comp Sci & Informat Technol, Szczecin Zolnierska 52, PL-71210 Szczecin, Poland.
EM tmaka@wi.zut.edu.pl
RI Maka, Tomasz/G-4620-2016
OI Maka, Tomasz/0000-0001-5898-2201
CR Aboy M, 2005, IEEE T BIO-MED ENG, V52, P1662, DOI 10.1109/TBME.2005.855725
   [Anonymous], 2008, Springer Handbook of Speech Processing
   [Anonymous], 1998, P DARPA BROADC NEWS
   Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
   Bock S, 2013, 6 INT WORKSH MACH LE, P1
   Cettolo M, 2005, COMPUT SPEECH LANG, V19, P147, DOI 10.1016/j.csl.2004.05.008
   Cettolo M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P537
   Chan CF, 2010, EUR SIGNAL PR CONF, P1851
   Cheng S.-S., 2003, EUROSPEECH 2003, P945
   Dov D, 2017, IEEE-ACM T AUDIO SPE, V25, P1322, DOI 10.1109/TASLP.2017.2690568
   Fodor B, 2012, 10 ITG S SPEECH COMM, P1
   Ganchev T, 2011, SPRINGERBRIEF SPEECH, P1, DOI 10.1007/978-1-4419-8447-0
   Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478
   Kauppinen I, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P967, DOI 10.1109/ICDSP.2002.1028251
   Markel JD, 1976, LINEAR PREDICTION SP, V12
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Potamitis I, 2008, STUD COMPUT INTELL, V120, P41
   Rosao C., 2012, INT SOC MUSIC INFORM, P517
   Rosin PL, 1997, MACH VISION APPL, V9, P139, DOI 10.1007/s001380050036
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Scholkmann F, 2012, ALGORITHMS, V5, P588, DOI 10.3390/a5040588
   Shao Y, 2008, INT CONF ACOUST SPEE, P1589
   Siedenburg K., 2012, P 9 SOUND MUS COMP C, P426
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8
   Yan FX, 2005, PATTERN RECOGN LETT, V26, P1183, DOI 10.1016/j.patrec.2004.11.003
   Yang EC, 2016, CANCER CELL INT, V16, DOI [10.1186/s12935-016-0351-0, 10.1155/2016/7168797]
NR 27
TC 1
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19329
EP 19348
DI 10.1007/s11042-020-08780-2
EA MAR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521018900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Javeed, A
   Shah, TR
   Attaullah
AF Javeed, Adnan
   Shah, Tariq
   Attaullah
TI Design of an S-box using Rabinovich-Fabrikant system of differential
   equations perceiving third order nonlinearity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rabinovich-Fabrikant equations; Chaotic system; Nonlinear dynamics;
   Substitution box (S-box); Encryption
ID CHAOS; CONSTRUCTION; PERMUTATION
AB Chaos based cryptosystems are used to protect the vital information while communicating through different communication networks. In this article, Rabinovich-Fabrikant (RF) system of coupled ordinary differential equations perceiving third order nonlinearity generating rich chaotic and complex dynamics is utilized in cyber security. Initially, this system is used to generate random integers, then for the construction of chaotic substitution boxes these integer values are permuted for obtaining highly nonlinear chaotic Substitution box (S-box). The prime advantage of the proposed design is the construction of different cryptographically strong S-boxes, by slightly altering the initial conditions and parameters of the RF system of differential equations. An S-box constructed by utilizing this scheme is evaluated by the algebraic and statistical analyses already available in literature. The outcomes of analysis yielded promising statistics which ensure its importance in application of secure communications.
C1 [Javeed, Adnan; Shah, Tariq; Attaullah] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Javeed, A (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM ajaveed@math.qau.edu.pk
CR Ahmad M, 2018, WIRELESS PERS COMMUN, V101, P1715, DOI 10.1007/s11277-018-5787-1
   Attaullah, 2019, MULTIMED TOOLS APPL, V78, P31467, DOI 10.1007/s11042-019-07981-8
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Brown R, 1996, INT J BIFURCAT CHAOS, V6, P219, DOI 10.1142/S0218127496000023
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Dachselt F, 2001, IEEE T CIRCUITS-I, V48, P1498, DOI 10.1109/TCSI.2001.972857
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Danca MF, 2017, NONLINEAR DYNAM, V88, P791, DOI 10.1007/s11071-016-3276-1
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Hussain I, 2012, Z NATURFORSCH A, V67, P282, DOI 10.5560/ZNA.2012-0022
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   RABINOVICH MI, 1979, ZH EKSP TEOR FIZ+, V77, P617
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Ullah A, 2019, MULTIMED TOOLS APPL, V78, P32467, DOI 10.1007/s11042-019-07957-8
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 28
TC 25
Z9 25
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6649
EP 6660
DI 10.1007/s11042-019-08393-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900054
DA 2024-07-18
ER

PT J
AU Srivastava, V
   Biswas, B
AF Srivastava, Vishal
   Biswas, Bhaskar
TI A subspace regression and two phase label optimization for High
   Dimensional Image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image (HSI); Kernel graphcut; Subspace regression;
   Multiphase labelling
ID MULTINOMIAL LOGISTIC-REGRESSION; GRAPH CUTS; ENERGY MINIMIZATION;
   SEGMENTATION; ALGORITHMS; MOTION
AB This paper introduces a two-step algorithm which deals with spectral mixing issue as well as performs the empirical study of continuous labelling in HSI images for over segmentation within class labels. In step-1, we have applied a subspace regression followed by an alpha expansion method to obtain the classified HSI image. This method better classifies the HSI image by removing the spectral mixing problem, which is a well-known problem in HSI domain. The classified image of step-1 is directly used in step-2 to improve the classification result by label update optimization using the energy of clusters. The optimization process in step-2 has performed in two phases. In the first phase of step-2, we have updated the cluster centers by the minimization of cluster energy. This energy minimization has stopped until some stopping criteria have met. The energy minimization has resulted in improved cluster centers. In the second phase of step-2, the RBF kernel based image function has updated using improved cluster centres, obtained from the phase-1. Classification probabilistic result from step-1 and updated image function from step-2 has transformed into a spectral data-cost. Subsequently, the data-cost of step-1 and step-2 have fused with the linear decision fusion method. Finally, The graph-cut method has applied to the fused spectral data-cost(Dc) and a spatial smoothness cost(Sc). Fusion of data-costs has resulted in a significant improvement in accuracy.
C1 [Srivastava, Vishal; Biswas, Bhaskar] IIT BHU, Dept Comp Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Srivastava, V (corresponding author), IIT BHU, Dept Comp Engn, Varanasi, Uttar Pradesh, India.
EM vishalismdhanbad@gmail.com
OI srivastava, vishal/0000-0002-2064-5805
CR Arrieta C, 2017, BIOMED SIGNAL PROCES, V33, P88, DOI 10.1016/j.bspc.2016.11.002
   Bejinariu SI, 2016, INT CONF EXPO ELECTR, P10, DOI 10.1109/ICEPE.2016.7781293
   Ben Ayed I, 2006, IEEE T PATTERN ANAL, V28, P1493, DOI 10.1109/TPAMI.2006.191
   Ben Salah M, 2011, IEEE T IMAGE PROCESS, V20, P545, DOI 10.1109/TIP.2010.2066982
   Bioucas-Dias JM, 2008, IEEE T GEOSCI REMOTE, V46, P2435, DOI 10.1109/TGRS.2008.918089
   BOHNING D, 1992, ANN I STAT MATH, V44, P197, DOI 10.1007/bf00048682
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang H, 2007, IEEE IMAGE PROC, P241
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dai SF, 2015, NEUROCOMPUTING, V168, P799, DOI 10.1016/j.neucom.2015.05.044
   De Stefano C, 2002, INT C PATT RECOG, P192, DOI 10.1109/ICPR.2002.1048270
   Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Du QH, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.980
   El-Zehiry N, 2007, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P182
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Fukui K, 2014, SUBSPACE METHODS
   Jaroszewicz S., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431), P212
   Jia S, 2016, IEEE T GEOSCI REMOTE, V54, P88, DOI 10.1109/TGRS.2015.2450759
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Li J, 2011, IEEE T GEOSCI REMOTE, V49, P3947, DOI 10.1109/TGRS.2011.2128330
   Li J, 2010, IEEE T GEOSCI REMOTE, V48, P4085, DOI 10.1109/TGRS.2010.2060550
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   O-Duda R., 2001, PATTERN CLASSIFICATI
   POULSEN J., 2004, DISCRIMINANT FUNCTIO
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Schoenemann T, 2006, LECT NOTES COMPUT SC, V4174, P455
   Sun K, 2016, INT J REMOTE SENS, V37, P4874, DOI 10.1080/01431161.2016.1225173
   Sun WW, 2018, IEEE T GEOSCI REMOTE, V56, P3185, DOI 10.1109/TGRS.2018.2794443
   Sun WW, 2016, IEEE J-STARS, V9, P4374, DOI 10.1109/JSTARS.2016.2539981
   Thrun S., 2002, EXPLORING ARTIFICIAL, P1, DOI DOI 10.5555/779343.779345
   Veksler O, 1999, THESIS, paAI9939932
   Vu N., 2008, Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587450
   Watanabe S., 1973, SUBSPACE METHOD PATT
   Yang JM, 2010, IEEE T GEOSCI REMOTE, V48, P2840, DOI 10.1109/TGRS.2010.2043533
   Zeng X., 2006, EFFICIENTLY SOLVING
   Zheng Q, 2018, J VIS COMMUN IMAGE R, V55, P157, DOI 10.1016/j.jvcir.2018.06.005
   Zhong YF, 2018, IEEE GEOSC REM SEN M, V6, P46, DOI 10.1109/MGRS.2018.2867592
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhou SP, 2016, NEUROCOMPUTING, V186, P107, DOI 10.1016/j.neucom.2015.12.073
   ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909
NR 50
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5897
EP 5918
DI 10.1007/s11042-019-08477-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900021
DA 2024-07-18
ER

PT J
AU Pandey, A
   Pandey, M
   Singh, N
   Trivedi, A
AF Pandey, Anurag
   Pandey, Mayank
   Singh, Navjot
   Trivedi, Abha
TI KUMBH MELA: a case study for dense crowd counting and modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Convolutional neural network
ID MULTIPLE; HUMANS
AB Dense crowd counting and modeling at different gatherings has ignited a new flame in the visual surveillance research community. There is a high possibility of mishappenings in the form of stampede, mob fighting at these gatherings and the administration is helpless in these scenarios. There is a requirement of analyzing the crowd to prevent these dangerous situations. The proposed work is a case study of Kumbh Mela which models the crowd counting in densely populated images. In the proposed work, the orthographic projection of the crowd is captured using a camera attached to a drone, to reduce the effect of occlusion and scaling which, otherwise, may get introduce during image acquisition process. The captured data is fed to a Convolutional Neural Network for training the model to count head of persons present in the frame. The results obtained from the trained model are validated using geometry and imaging techniques. The proposed model has achieved a mean-absolute-error of 94.3 and a mean-squared-error of 104.6 which seems to outperform the existing state-of-the-art models with respect to the reported performance parameters. The proposed model can be used as a viable solution in applications related to modeling the crowd behavior.
C1 [Pandey, Anurag] HCL Technol Ltd, Engn & RnD Serv, Noida, India.
   [Pandey, Mayank; Singh, Navjot; Trivedi, Abha] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Singh, N (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
EM anurag.pandey@hcl.com; mayankpandey@mnnit.ac.in; navjot@mnnit.ac.in;
   abhson1711@gmail.com
RI Pandey, Mayank/AAD-8514-2021; Trivedi, Abha/HSG-7141-2023; Trivedi,
   Abha/AAV-5390-2021; Singh, Navjot/I-5444-2017
OI Trivedi, Abha/0000-0002-4641-8678; Singh, Navjot/0000-0003-0409-8482;
   Pandey, Mayank/0000-0001-6071-0571
FU Kumbh Mela Police, Kumbh Mela, Prayagraj, Uttar Pradesh
FX This work has been supported by the Kumbh Mela Police, Kumbh Mela,
   Prayagraj, Uttar Pradesh. We would like to specially acknowledge, Mr.
   K.P. Singh, DIG, Kumbh Mela, Prayagraj for allowing us to collect video
   data through drone cameras. We are also thankful to the reviewers for
   their constructive suggestions.
CR [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   [Anonymous], ARXIV161200220
   [Anonymous], 2017, IEEE T CIRC SYST VID
   [Anonymous], ARXIV170603686
   [Anonymous], 2007, CVPR07 IEEE C IEEE
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   CHEN K, 2013, PROC CVPR IEEE, P2467, DOI [DOI 10.1109/CVPR.2013.319, 10.1109/CVPR.2013.319]
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   FELZENSZWALB P, 2008, P IEEE C COMP VIS PA, P1
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Kong D, 2006, INT C PATT RECOG, P1187
   Kumagai S., 2017, arXiv preprint arXiv:1703.09393
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu L., 2019, NEUROCOMPUTING
   Miao YQ, 2019, PATTERN RECOGN LETT, V125, P113, DOI 10.1016/j.patrec.2019.04.012
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Oren Michael., 1997, PROC CVPR IEEE, P193, DOI DOI 10.1109/CVPR.1997.609319
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Xu B, 2018, IEEE ACM T COMPUT BI, V15, P1797, DOI 10.1109/TCBB.2016.2578337
   Xu M., 2019, Pattern Recognition Letters
   Yao H, 2017, ARXIV171009757
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang C, 2016, IEEE T MULTIMEDIA, V18, P1048, DOI 10.1109/TMM.2016.2542585
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
NR 47
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17837
EP 17858
DI 10.1007/s11042-020-08754-4
EA FEB 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516508200001
DA 2024-07-18
ER

PT J
AU Berlin, SJ
   John, M
AF Berlin, S. Jeba
   John, Mala
TI Particle swarm optimization with deep learning for human action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Human action recognition; Autoencoder; Deep learning
   network; Particle swarm optimization
ID FEATURE-SELECTION; CLASSIFICATION; MODEL
AB A novel method for human action recognition using a deep learning network with features optimized using particle swarm optimization is proposed. The binary histogram, Harris corner points and wavelet coefficients are the features extracted from the spatiotemporal volume of the video sequence. In order to reduce the computational complexity of the system, the feature space is reduced by particle swarm optimization technique with the multi-objective fitness function. Finally, the performance of the system is evaluated using deep learning neural network (DLNN). Two autoencoders are trained independently and the knowledge embedded in the autoencoders are transferred to the proposed DLNN for human action recognition. The proposed framework achieves an average recognition rate of 91% on UT interaction set 1, 88% on UT interaction set 2, 91% on SBU interaction dataset and 94% on Weizmann dataset.
C1 [Berlin, S. Jeba; John, Mala] Anna Univ, Madras Inst Technol, Dept Elect Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Madras Institute of Technology
RP Berlin, SJ (corresponding author), Anna Univ, Madras Inst Technol, Dept Elect Engn, Chennai, Tamil Nadu, India.
EM jebaberlin@gmail.com
RI JOHN, MALA/AAI-7508-2021
OI JOHN, MALA/0000-0001-5034-3405
FU DST INSPIRE Fellowship; DST, India
FX The first author is a recipient of DST INSPIRE Fellowship and wishes to
   thank DST, India for the same.
CR Abdelgawad H, 2014, J ADV TRANSPORT, V48, P507, DOI 10.1002/atr.1201
   Al-Berry MN, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P254, DOI 10.1109/HIS.2014.7086208
   Al-Berry MN, 2016, IET COMPUT VIS, V10, P153, DOI 10.1049/iet-cvi.2015.0087
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Berlin SJ, 2016, INT CARN CONF SECU, P143
   Cai JJ, 2016, IEEE IMAGE PROC, P4155, DOI 10.1109/ICIP.2016.7533142
   Cheng J, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2441634
   Chuang LY, 2011, EXPERT SYST APPL, V38, P12699, DOI 10.1016/j.eswa.2011.04.057
   Curtis S, 2013, VISUAL COMPUT, V29, P1277, DOI 10.1007/s00371-012-0769-x
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Han YM, 2018, PATTERN RECOGN LETT, V107, P83, DOI 10.1016/j.patrec.2017.08.015
   Hasan M, 2015, IEEE T MULTIMEDIA, V17, P1909, DOI 10.1109/TMM.2015.2477242
   Huang CL, 2008, APPL SOFT COMPUT, V8, P1381, DOI 10.1016/j.asoc.2007.10.007
   Imtiaz H, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P537, DOI 10.1109/ACPR.2013.143
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Ji XP, 2017, KNOWL-BASED SYST, V122, P64, DOI 10.1016/j.knosys.2017.01.035
   Ji YL, 2015, J VIS COMMUN IMAGE R, V33, P340, DOI 10.1016/j.jvcir.2015.10.001
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim S, 2015, VISUAL COMPUT, V31, P541, DOI 10.1007/s00371-014-0946-1
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P167, DOI 10.1109/TIP.2015.2498410
   Kumar SU, 2017, NEURAL COMPUT APPL, V28, P3239, DOI 10.1007/s00521-016-2236-5
   Li JJ, 2019, IEEE T IMAGE PROCESS, V28, P6103, DOI 10.1109/TIP.2019.2924174
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li NJ, 2014, INT C PATT RECOG, P2513, DOI 10.1109/ICPR.2014.434
   Li WB, 2015, IEEE I CONF COMP VIS, P4444, DOI 10.1109/ICCV.2015.505
   Liu C, 2011, IEEE T CIRC SYST VID, V21, P1203, DOI 10.1109/TCSVT.2011.2130270
   Liu MY, 2014, IEEE IMAGE PROC, P1460, DOI 10.1109/ICIP.2014.7025292
   Ma MH, 2016, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2016.209
   Nikouei SY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P125, DOI 10.1109/EDGE.2018.00025
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rapantzikos K., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P294, DOI DOI 10.1145/1282280.1282326
   Ryoo M., 2010, IEEE INT C PATT REC, P1
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Sener F, 2015, J VIS COMMUN IMAGE R, V32, P63, DOI 10.1016/j.jvcir.2015.07.016
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Shao L, 2011, NEUROCOMPUTING, V74, P962, DOI 10.1016/j.neucom.2010.11.013
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Siddiqi MH, 2014, SENSORS-BASEL, V14, P6370, DOI 10.3390/s140406370
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Huynh-The T, 2015, PROC INT CONF ADV, P117, DOI 10.1109/ATC.2015.7388302
   Tong M, 2020, NEURAL COMPUT APPL, V32, P5285, DOI 10.1007/s00521-019-04030-1
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Xue B, 2014, APPL SOFT COMPUT, V18, P261, DOI 10.1016/j.asoc.2013.09.018
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang JF, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P123, DOI 10.1109/FPT.2014.7082764
   Zhang Y, 2017, IEEE ACM T COMPUT BI, V14, P64, DOI 10.1109/TCBB.2015.2476796
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 60
TC 22
Z9 22
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17349
EP 17371
DI 10.1007/s11042-020-08704-0
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516318300001
DA 2024-07-18
ER

PT J
AU Vyas, R
   Kanumuri, T
   Sheoran, G
   Dubey, P
AF Vyas, Ritesh
   Kanumuri, Tirupathiraju
   Sheoran, Gyanendra
   Dubey, Pawan
TI Smartphone based iris recognition through optimized textural
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris biometrics; Mobile devices; Bit-transition codes; Optimization;
   Gabor filtering
ID EXTRACTION; SEGMENTATION; NETWORKS
AB Mobile devices have become ubiquitous nowadays and so is the need of secure access to these devices. Iris being the most reliable and hard-to-tamper biometric trait, can serve the aforementioned purpose. Iris recognition on mobile phones has become a significant and challenging task for the research community. With advancement in technology, it has now become feasible to use mobile devices' in-built cameras to unlock the device through the user's iris. This paper presents a convenient and efficient approach: optimal bit-transition codes (OBTC), for representing mobile iris images in a more distinctive manner. The approach is derived from the texture analysis property of 2D Gabor filters. Optimization of Gabor parameters is performed for iris images from two challenging mobile iris databases: MICHE I (which comprises of eye images acquired from three different smartphones: iPhone5, Galaxy S4 and Galaxy Tab2) and VISOB (which contains eye images acquired from iPhone5S, Samsung Note 4 and Oppo N1). After filtering, the image responses are converted to binary numbers and stored in concatenated vectors. Later, the concatenated vectors produce binary strings across the direction of concatenation and number of bit-transitions in these binary strings are encoded to form the complete feature vectors. A capacious experimentation is performed on the challenging MICHE I and VISOB iris databases. Comparison of the proposed approach with several state-of-the-art approaches clearly shows its expediency. More importantly, the proposed iris recognition approach performs at par with a commercial iris matcher, named VeriEye, which proves its usefulness.
C1 [Vyas, Ritesh] Bennett Univ, Sch Engn & Appl Sci, Greater Noida, UP, India.
   [Kanumuri, Tirupathiraju; Sheoran, Gyanendra; Dubey, Pawan] Natl Inst Technol Delhi, Delhi 110040, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi
RP Vyas, R (corresponding author), Bennett Univ, Sch Engn & Appl Sci, Greater Noida, UP, India.
EM ritesh.vyas157@gmail.com; ktraju@nitdelhi.ac.in;
   gsheoran@nitdelhi.ac.in; pawandubey@nitdelhi.ac.in
RI Vyas, Ritesh/AAF-9410-2020; Sheoran, Gyanendra/ADH-1043-2022; sheoran,
   gyanendra/AAD-3973-2022; dubey, pawan/HGU-6795-2022; Kanumuri,
   Tirupathiraju/V-5584-2019
OI Vyas, Ritesh/0000-0002-9739-2551; Sheoran,
   Gyanendra/0000-0002-9631-9707; dubey, pawan/0000-0002-5177-8715;
   Kanumuri, Tirupathiraju/0000-0002-0441-7642
CR Abate AF, 2017, PATTERN RECOGN LETT, V91, P37, DOI 10.1016/j.patrec.2017.02.002
   Ahuja K, 2017, PATTERN RECOGN LETT, V91, P17, DOI 10.1016/j.patrec.2017.04.002
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   Bansal A, 2016, SADHANA-ACAD P ENG S, V41, P507, DOI 10.1007/s12046-016-0492-9
   Barra S, 2015, PATTERN RECOGN LETT, V57, P66, DOI 10.1016/j.patrec.2014.10.011
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   De Marsico M, 2018, PATTERN RECOGN, V74, P286, DOI 10.1016/j.patcog.2017.08.028
   De Marsico M, 2017, PATTERN RECOGN LETT, V91, P3, DOI 10.1016/j.patrec.2016.12.013
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   ELREFAEI LA, 2017, TOOLS APPL, P1
   Galdi C, 2017, PATTERN RECOGN LETT, V91, P44, DOI 10.1016/j.patrec.2017.01.023
   Galdi C, 2016, PATTERN RECOGN LETT, V82, P144, DOI 10.1016/j.patrec.2015.09.009
   Haindl M, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P49, DOI 10.1109/SITIS.2014.48
   Haindl M, 2015, PATTERN RECOGN LETT, V57, P60, DOI 10.1016/j.patrec.2015.02.012
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jamaludin S, 2018, ARAB J SCI ENG, V43, P7219, DOI 10.1007/s13369-017-3051-8
   Jillela RR, 2015, PATTERN RECOGN LETT, V57, P4, DOI 10.1016/j.patrec.2014.09.014
   Kaur B, 2018, ARAB J SCI ENG, V43, P7209, DOI 10.1007/s13369-017-3057-2
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Masek L., 2003, THESIS CITESEER
   Miyazawa K, 2008, IEEE T PATTERN ANAL, V30, P1741, DOI 10.1109/TPAMI.2007.70833
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Poornima S, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414560102
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proenca H., 2007, First IEEE International Conference on Biometrics: Theory, Applications, and Systems, P1
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Radman A, 2017, DIGIT SIGNAL PROCESS, V64, P60, DOI 10.1016/j.dsp.2017.02.003
   Radman A, 2014, ARAB J SCI ENG, V39, P3039, DOI 10.1007/s13369-013-0924-3
   Raja KB, 2017, PATTERN RECOGN LETT, V91, P27, DOI 10.1016/j.patrec.2016.12.025
   RATTANI A, 2016, IEEE INT C IM PROC I
   Subban R, 2018, CLUSTER COMPUT, V21, P79, DOI 10.1007/s10586-017-0934-0
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vyas R, 2019, MULTIMED TOOLS APPL, V78, P5681, DOI 10.1007/s11042-018-5689-y
   Vyas R, 2016, 2016 1ST INDIA INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (IICIP)
   Wai Kin Kong, 2003, Pattern Recognition, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 40
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14127
EP 14146
DI 10.1007/s11042-019-08598-7
EA FEB 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000517446800001
DA 2024-07-18
ER

PT J
AU Sakhare, SV
   Dalal, U
AF Sakhare, Swati Vinod
   Dalal, Upena
TI High efficiency coding for surveillance videos based on selective based
   fast intra coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Early CU termination; PU splitting; Block-based intra prediction;
   Sample based angular prediction; Boundary region based SAP
ID DIAMOND SEARCH ALGORITHM
AB HEVC, the successor of popular H.264 video compression standard targets the new era of ultra high-resolution videos with higher frame rates. Lossless coding mode of high-efficiency video coding (HEVC) relies on efficient intra prediction methods for achieving higher compression. In this paper, we propose a method called selective based intra prediction (SBIP) which is a combination of Block based intra prediction (BP) and Boundary region based SAP (BRSAP) for surveillance videos. First, we calculate the threshold complexity for the block and based on the condition the CU early termination is done. Then, we calculate a prediction for each block by using the BP and BRSAP method separately. After calculating both the prediction based on some condition the final prediction of the block is performed which selects the best prediction for each pixel to reduce the residual energy thereby increasing the coding efficiency. At last, the transform, quantization, and entropy coding are performed to compress the input video signal. The experimental results are conducted for surveillance videos test sequences for 30 frames from each test sequence. The results are evaluated based on encoding time and peak signal to noise ratio (PSNR).
C1 [Sakhare, Swati Vinod] SVNIT, Surat 395007, Gujarat, India.
   [Dalal, Upena] SVNIT, Dept Elect & Commun Engn, Surat 395007, Gujarat, India.
C3 National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology; National Institute of Technology (NIT
   System); Sardar Vallabhbhai National Institute of Technology
RP Sakhare, SV (corresponding author), SVNIT, Surat 395007, Gujarat, India.
EM swativinods1181@gmail.com
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   [Anonymous], 2012, IEEE T CIRCUITS SYST
   [Anonymous], 2015, INT J COMPUT APPL, DOI DOI 10.5120/IJCA2015907589
   Ayele EA, 2012, INT J COMPUT APPL, V59
   Biswas T, 2015, FUTUR SCI OA, V1, DOI [10.4155/FSO.15.16, 10.4155/fso.15.16]
   Brahmasury Jain H, 2014, POLIBITS
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Frojdh P, 2013, ERICSSON REV
   Ghanbari M, 2003, IEE
   Hosseini E, 2019, MULTIMED TOOLS APPL, V78, P11607, DOI 10.1007/s11042-018-6713-y
   Hu N, 2015, IEEE T CIRC SYST VID, V25, P1521, DOI 10.1109/TCSVT.2015.2395772
   Jain AK, 1981, J IEEE T COMMUNICATI
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   KAPPAGANTULA S, 1985, IEEE T COMMUN, V33, P1011, DOI 10.1109/TCOM.1985.1096415
   Lainema J, 2011, IEEE
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Li W, 2017, SIGNAL IMAGE VIDEO P, V11, P1163, DOI 10.1007/s11760-017-1071-1
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   LIOU M, 1991, COMMUN ACM, V34, P59, DOI 10.1145/103085.103091
   Ma Y, 2018, MULTIMED TOOLS APPL, V77, P14907, DOI 10.1007/s11042-017-5074-2
   Marzuki I., 2016, J REAL TIME IMAGE PR
   Medhat A, 2016, J IET IMAGE PROCESSI, P1
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Shaw MQ, 2015, SIGNAL PROCESS-IMAGE, V39, P355, DOI 10.1016/j.image.2015.04.008
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V, 2012, IEEE T CIRCUITS SYST
   Wu LG, 1996, PROCEEDINGS OF '96 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE & ENGINEERING, P419
   Yang EH, 2014, IEEE T INFORM THEORY, V60, P1428, DOI 10.1109/TIT.2013.2296523
   Zhou M, JCTVCG093
   Zhou M, JCTVCH0083
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
   Zhu C, 2004, IEEE T CIRCUITS SYST, P1210
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 35
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14079
EP 14101
DI 10.1007/s11042-019-08426-y
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515999800002
DA 2024-07-18
ER

PT J
AU Shojaei, M
   Rezaei, M
AF Shojaei, Maryam
   Rezaei, Mehdi
TI FJND-based fuzzy rate control of scalable video for streaming
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FJND; Fuzzy; Perceptual quality; Rate control; Scalable video; Video
   streaming
ID OPTIMIZATION; MODEL; JND
AB A fuzzy rate controller with buffer constraint in combination with a perceptual quality controller is proposed for streaming applications of the AVC/H.264 scalable (SVC) video. The bit rate of each video layer is controlled separately by the fuzzy controller that adjusts the quantization parameter (QP) on a group of pictures (GOP) basis. The QPs of pictures are computed from the GOP QP by the well-known QP cascading technique. While the fuzzy controller provides the buffering constraint for each video layer, the quality controller tries to improve the perceptual quality of the compressed video based on the foveated just-noticeable distortion (FJND) model. The quality controller regulates the QP of each macroblock around the picture QP based on the visibility threshold of the FJND model. In these applications, the initial buffering allows slight variations of the bit rate leading to produce a variable bit rate (VBR) video bit stream with consistent quality. Experimental results show that the proposed algorithm effectively adapts to the buffer size, while strictly prevents buffer overflow and underflow. In addition, incorporating the perceptual quality controller into the fuzzy rate controller achieves higher perceptual quality at the same bit rate.
C1 [Shojaei, Maryam; Rezaei, Mehdi] Univ Sistan & Baluchestan, Dept Commun Engn, Zahedan, Iran.
C3 University of Sistan & Baluchestan
RP Rezaei, M (corresponding author), Univ Sistan & Baluchestan, Dept Commun Engn, Zahedan, Iran.
EM mehdi.rezaei@ece.usb.ac.ir
RI Rezaei, Mehdi/HPC-0221-2023
OI Rezaei, Mehdi/0000-0002-6918-9767
CR [Anonymous], 1997, VID COD TEST MOD TMN
   [Anonymous], JOINT SCALABLE VIDEO
   [Anonymous], 2001, JTC1SC29WG11 ISOIEC
   [Anonymous], [No title captured]
   Bakar G, 2019, IEEE T MULTIMEDIA, V21, P429, DOI 10.1109/TMM.2018.2856629
   Bjontegaard G., 2001, Document VCEG-M33
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Hu SD, 2012, IEEE T IND ELECTRON, V59, P1673, DOI 10.1109/TIE.2011.2157282
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   ITU-T, 2016, ITU T P SER REC, VP.913
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P116, DOI 10.1109/TCSVT.2007.903325
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Muller K, 2019, DIGITAL TRANSFORMATI
   Nihei K, 2018, IEEE GLOB COMM CONF
   Reichel J., 2007, JOINT SCALABLE VIDEO
   Rezaei M, 2008, IEEE T CIRC SYST VID, V18, P633, DOI 10.1109/TCSVT.2008.919108
   Rezaei M, 2017, MULTIMED TOOLS APPL, V76, P1439, DOI 10.1007/s11042-015-3110-7
   Ribas-Corbera J, 2003, IEEE T CIRC SYST VID, V13, P674, DOI 10.1109/TCSVT.2003.814965
   Samiee A., 2015, 4 IR JOINT C FUZZ IN, P1
   Sanz-Rodriguez S., 2009, PICT COD S PCS, P1
   Sanz-Rodríguez S, 2013, IEEE INT CONF MULTI
   Sanz-Rodríguez S, 2011, IEEE T CIRC SYST VID, V21, P1263, DOI 10.1109/TCSVT.2011.2143330
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Shojaei M., 2015, 4 IR JOINT C FUZZ IN, P1
   Sullivan G., 2003, JVTI049
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang L.-X., 1999, A Course in Fuzzy Systems and Control, P238
   Wang X, 2014, IEEE T IMAGE PROCESS, V23, P4010, DOI 10.1109/TIP.2014.2341951
   Yuan D, 2019, IEEE ACCESS, V7, P29014, DOI 10.1109/ACCESS.2019.2901342
NR 35
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13753
EP 13773
DI 10.1007/s11042-019-08563-4
EA FEB 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510371300001
DA 2024-07-18
ER

PT J
AU Jin, HX
   Fu, YY
   Yang, GL
   Zhu, XN
AF Jin, Huixia
   Fu, Yuanyuan
   Yang, Gelan
   Zhu, Xiaoning
TI An intelligent scheduling algorithm for resource management of cloud
   platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Task scheduling; Deep reinforcement learning; Deep Q
   networks; Distributed computing
AB Cloud-computing technologies and their application are becoming increasingly popular, which improves both enterprises' and individuals' working efficiency while at the same time greatly reducing users' cost. Besides, the scale of cloud platform and its application are rapidly expanding. Yet it's a challenging task to effectively utilize resource and guarantee quality of services to users. The quality of cloud task scheduling algorithm plays a key role in it. For one thing, traditional rule-based scheduling algorithms like FCFS and priority-based always focus on the algorithm itself instead of considering characteristics of Virtual Machines (VMs) and task, finally leading to poor operation effect. For another, one carefully selects a set of features based on sample data and employs machine-learning algorithms to train a scheduling policy. This method has the following deficiencies: quality of manually selected sample features directly affects that of the scheduling algorithm; many effective scheduling algorithms are based on a large number of labeled samples; however, it is very difficult to acquire these samples in reality; trained scheduling algorithms are often applicable only to specific environments and easy to be damaged. For the deficiencies of traditional scheduling algorithm and based on deep reinforcement learning (DRL) model, this paper presents a new-type model-free and end-to-end task scheduling agent which can interact with cloud environment and output the information of the virtual machine executing the task while inputting the original tasks of the cloud platform. The agent learns scheduling knowledge through the execution of tasks, and optimizes its scheduling policy. This algorithm completely solves the deficiencies of traditional scheduling algorithms like lower adaptability and flexibility, providing brand-new feasible solutions for task scheduling methods under cloud environments.
C1 [Jin, Huixia; Fu, Yuanyuan; Yang, Gelan] Hunan City Univ, Dept Informat Sci & Engn, Yiyang, Hunan, Peoples R China.
   [Zhu, Xiaoning] Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing, Peoples R China.
C3 Hunan City University; Beijing University of Posts & Telecommunications
RP Zhu, XN (corresponding author), Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing, Peoples R China.
EM Jinhuixia1980@163.com; glyang@mail.ustc.edu.cn; xiaoning158@bupt.edu.cn
RI Jin, Hui/GXG-2296-2022; Wang, Yiru/JMB-2281-2023
CR [Anonymous], 11 IEEE INT C HIGH P
   [Anonymous], 2016, MODEL FREE EPISODIC
   [Anonymous], IEEE INT PAR DISTR P
   [Anonymous], 2016, Technical report
   [Anonymous], 2013, LEARNING
   [Anonymous], 2016, Variational information maximizing exploration
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], INT J HIGH PERFORMAN
   [Anonymous], IEEE INT S PAR DISTR
   Armbrust M., CLOUDS BERKELEY VIEW
   Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Fang WW, 2015, INFORM SCIENCES, V301, P169, DOI 10.1016/j.ins.2014.12.059
   Galindo-Serrano A, 2014, WIREL NETW, V20, P441, DOI 10.1007/s11276-013-0609-6
   Germain-Renaud C, 2009, IEEE INTERNET COMPUT, V13, P9, DOI 10.1109/MIC.2009.137
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hosseinimotlagh S, 2015, J SUPERCOMPUT, V71, P45, DOI 10.1007/s11227-014-1276-9
   IBARRA OH, 1977, J ACM, V24, P280, DOI 10.1145/322003.322011
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lange S, 2010, IEEE IJCNN
   Li JY, 2012, J PARALLEL DISTR COM, V72, P666, DOI 10.1016/j.jpdc.2012.02.002
   Lin Long-Ji, 1993, P TECHN REP DTIC DOC
   Maguluri ST, 2012, IEEE INFOCOM SER, P702, DOI 10.1109/INFCOM.2012.6195815
   Mnih V, 2013, Ph.D. dissertation,
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Morozs N, 2016, IEEE T MOBILE COMPUT, V15, P817, DOI 10.1109/TMC.2015.2442529
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Riedmiller M, 2005, LECT NOTES ARTIF INT, V3720, P317, DOI 10.1007/11564096_32
   Rummery Gavin A, 1994, On-line Q-Learning Using Connectionist Systems, V37
   Sallans B, 2004, J MACH LEARN RES, V5, P1063
   Barreto ADS, 2008, ARTIF INTELL, V172, P454, DOI 10.1016/j.artint.2007.08.001
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   van Rooijen JC, 2014, MECHATRONICS, V24, P966, DOI 10.1016/j.mechatronics.2014.05.007
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wei QL, 2017, IEEE T CYBERNETICS, V47, P1224, DOI 10.1109/TCYB.2016.2542923
   Yang WK, 2016, NEUROCOMPUTING, V213, P183, DOI 10.1016/j.neucom.2015.11.134
NR 40
TC 9
Z9 10
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5335
EP 5353
DI 10.1007/s11042-018-6477-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500063
DA 2024-07-18
ER

PT J
AU Shu, Y
   Zhang, H
AF Shu, Yao
   Zhang, Heng
TI Multimodal information fusion based human movement recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Information integration technology; Overview
AB Emotion recognition has wide application prospect in multiple fields including psychological research, security monitoring and control, distance education and clinical medicine, the information source of which involves multiple original data statuses of humans in the recognition process. This paper briefly introduces several kinds of emotion recognition methods based on different data sources and information integration technology thus to provide certain theoretical background for the engineering technicians. And then it conducts classified introduction to the current situation of emotion recognition in the multi-source information integration field, explains and analyzes the problems existed in emotion recognition based on multi-source information integration, briefly expounds the application prospect of it in the emotion recognition field, and finally makes summary.
C1 [Shu, Yao; Zhang, Heng] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Shu, Y (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
EM yaoshuheng0@163.com
CR Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Chen YZ, 2016, OPT LETT, V41, P2306, DOI 10.1364/OL.41.002306
   Du XL, 2017, CELL PHYSIOL BIOCHEM, V43, P568, DOI 10.1159/000480529
   Fernandes SL, 2020, PATTERN RECOGN LETT, V139, P148, DOI 10.1016/j.patrec.2017.07.002
   Ghebrebrhan M, 2017, IEEE MICROW WIREL CO, V27, P989, DOI 10.1109/LMWC.2017.2750031
   Kurup P, 2017, INDIAN GEOTECH J, V47, P421, DOI 10.1007/s40098-016-0214-6
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Pan WS, 2013, APPL MATH INFORM SCI, V7, P675, DOI 10.12785/amis/070235
   Stephygraph LR, 2016, ADV INTELL SYST, V397, P537, DOI 10.1007/978-81-322-2671-0_52
   Stephygraph LR, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P596, DOI 10.1109/ICSTM.2015.7225484
   Zhang YY, 2016, BIOMATERIALS, V84, P230, DOI 10.1016/j.biomaterials.2015.12.028
   Zhao YJ, 2017, IEEE T INSTRUM MEAS, V66, P1789, DOI 10.1109/TIM.2017.2665983
   Zhao YJ, 2015, CIRC SYST SIGNAL PR, V34, P2667, DOI 10.1007/s00034-015-9989-4
NR 13
TC 3
Z9 3
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5043
EP 5052
DI 10.1007/s11042-018-6315-8
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500045
DA 2024-07-18
ER

PT J
AU Abidi, SMR
   Xu, YL
   Ni, JY
   Wang, XM
   Zhang, W
AF Abidi, Syed Muhammad Raza
   Xu, Yonglin
   Ni, Jianyue
   Wang, Xiangmeng
   Zhang, Wu
TI Popularity prediction of movies: from statistical modeling to machine
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie popularity; Machine learning; Movie success; Regression; IMDb;
   Supervised learning
ID BOX-OFFICE; SUCCESS; RECOMMENDATION; STARS; POWER
AB Film industries all over the world are producing several hundred movies rapidly and grabbing the attraction of people of all ages. Every movie producer is of keen interest in knowing which movies are either likely to hit or flop in the box office. So, the early prediction of the popularity of a movie is of the utmost importance to the film industry. In this study, we examine factors inside the hidden patterns which become movie popular. In past studies, machine learning techniques were implemented on blog articles, social networking, and social media to predict the success of a movie. Their works focused on which algorithms are better at predicting the success of a movie but less focused on data and attributes related to an ongoing movie and in various directions. In this paper, we inspect this perspective that might be related to the prediction of the results. Data collected from the publicly available Internet Movie Database (IMDb). We implemented five machine learning algorithms, i.e., Generalized Linear Model (GLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), and Gradient Boosted Tree (GBT) using Root Mean Squared Error (RMSE) as a performance metric and got the accuracy performances of GLM: 47.9%, DL: 51.1%, DT: 54.5%, RF: 50.0%, and GBT: 49.5%, respectively. We found that GLM is the high achieving accuracy regression classifier due to the lower value of RMSE, which is considered to be better.
C1 [Abidi, Syed Muhammad Raza; Xu, Yonglin; Ni, Jianyue; Wang, Xiangmeng; Zhang, Wu] Shanghai Univ, Sch Engn & Comp Sci, 99 Shangda Rd,Baoshan Campus, Shanghai 200444, Peoples R China.
   [Zhang, Wu] Shanghai Univ, Shanghai Inst Appl Math & Mech, 99 Shangda Rd,Baoshan Campus, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Abidi, SMR; Zhang, W (corresponding author), Shanghai Univ, Sch Engn & Comp Sci, 99 Shangda Rd,Baoshan Campus, Shanghai 200444, Peoples R China.; Zhang, W (corresponding author), Shanghai Univ, Shanghai Inst Appl Math & Mech, 99 Shangda Rd,Baoshan Campus, Shanghai 200444, Peoples R China.
EM razaabdi@live.com; wffzxyl@gmail.com; njy0612@163.com;
   xiangm_wang@163.com; wzhang@shu.edu.cn
RI Abidi, Syed Muhammad Raza/Q-4896-2019; Wang, Xiangmeng/KVB-2336-2024
OI Abidi, Syed Muhammad Raza/0000-0001-8808-0882; 
FU NATIONAL NATURAL SCIENCE FOUNDATION OF CHINA [91630206, 61572434];
   NATIONAL KEY R&D PROGRAM OF CHINA [2017YFB0701501]
FX The effort of this paper supported by "NATIONAL NATURAL SCIENCE
   FOUNDATION OF CHINA, grant number 91630206, and 61572434", and "THE
   NATIONAL KEY R&D PROGRAM OF CHINA, grant number 2017YFB0701501".
CR Aguiar E., 2014, P 4 INT C LEARNING A, P103, DOI 10.1145/2567574.2567589
   [Anonymous], 2009, STAT FDN DATA ANAL
   Asad KI, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P747, DOI 10.1109/ICIEV.2012.6317401
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Basuroy S, 2003, J MARKETING, V67, P103, DOI 10.1509/jmkg.67.4.103.18692
   Billsus D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P46
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chambers M, 2015, ADV ANAL METHODOLOGI, P324
   Çizmeci B, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P173, DOI 10.1109/UBMK.2018.8566661
   Cobos R., 2017, CEUR Workshop Proceedings, V1967, P74
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Elberse A, 2007, J MARKETING, V71, P102, DOI 10.1509/jmkg.71.4.102
   Eliashberg J, 2007, MANAGE SCI, V53, P881, DOI 10.1287/mnsc.1060.0668
   Gallaugher J, 2008, GALL COM, P1
   HAN JW, 2004, DATA MINING CONCEPTS
   Hastie T., 2009, The Elements of Statistical Learning
   Im D., 2011, Predicting Box-Office Success of Movies in the U . S . Market, P1
   Ishikawa M, 2007, PROCEEDING OF THE 2007 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WORKSHOPS, P129, DOI 10.1109/WI-IATW.2007.90
   Kabra R., 2011, Int J Comput Appl, V36, P8
   Kim Y, 2018, KSII T INTERNET INF, V12, P4090, DOI 10.3837/tiis.2018.08.030
   Latif MH, 2016, INT J COMPUT SCI NET, V16, P127
   Lee K, 2018, INFORM SYST FRONT, V20, P577, DOI 10.1007/s10796-016-9689-z
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li WT, 2016, IEEE IJCNN, P3130, DOI 10.1109/IJCNN.2016.7727598
   Li Y, 2005, EXPERT SYST APPL, V28, P67, DOI 10.1016/j.eswa.2004.08.013
   LITMAN BR, 1983, J POP CULT, V16, P159, DOI 10.1111/j.0022-3840.1983.1604_159.x
   Marovic M., 2011, 2011 Proceedings of 34th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO 20111), P1640
   Masih S, 2019, INT J ADV COMPUT SC, V10, P438
   Mayr A, 2014, EVOLUTION BOOSTING A, P1
   Mendez G, 2008, J ENG EDUC, V97, P57, DOI 10.1002/j.2168-9830.2008.tb00954.x
   Mestyán M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071226
   Nelson RA, 2012, J CULT ECON, V36, P141, DOI 10.1007/s10824-012-9159-5
   Ng VKY, 2019, COMMUN STAT-SIMUL C, V48, P2269, DOI 10.1080/03610918.2018.1440301
   Nithin V., 2014, International Journal of Data Mining Techniques and Applications, V3, P365
   Oghina Andrei, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P503, DOI 10.1007/978-3-642-28997-2_51
   POPESCUL A., 2001, P 17 C UNCERTAINTY A, P437
   Prag J., 1994, Journal of Cultural Economics, V18, P217, DOI 10.1007/BF01080227
   Prettenhofer P., 2014, Gradient boosted regression trees in scikit- learn
   Quader N, 2018, 3 INT C EL INF COMM, P1
   RapidMiner, 2016, RAPIDMINER DOC
   Rundel M.C., 2018, LINEAR REGRESSION MO
   Sarwar B., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P158, DOI 10.1145/352871.352887
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Simonoff J., 2000, Chance, V13, P15, DOI [DOI 10.1080/09332480.2000.10542216, 10.1080/09332480.2000.10542216]
   Smith MichaelR., 2014, Meta-Learning and Algorithm Selection, V2, DOI DOI 10.1145/2487575.2487629
   Son J, 2017, EXPERT SYST APPL, V89, P404, DOI 10.1016/j.eswa.2017.08.008
   Tang TY, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P79, DOI 10.1145/3195106.3195130
   van Kan GA, 2010, CLIN GERIATR MED, V26, P275, DOI 10.1016/j.cger.2010.02.002
   Vany A. de, 1999, Journal of Cultural Economics, V23, P285, DOI 10.1023/A:1007608125988
   Vu DH, 2015, APPL ENERG, V140, P385, DOI 10.1016/j.apenergy.2014.12.011
   Wang HF, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P110, DOI 10.1109/CCWC.2018.8301647
   Wilson DC, 2003, INT J PATTERN RECOGN, V17, P863, DOI 10.1142/S0218001403002678
   Xing WL, 2019, J EDUC COMPUT RES, V57, P547, DOI 10.1177/0735633118757015
   Yamagishi J, 2008, SPEECH COMMUN, V50, P405, DOI 10.1016/j.specom.2007.12.003
   Zhang L, 2009, EXPERT SYST APPL, V36, P6580, DOI 10.1016/j.eswa.2008.07.064
   Zhang WB, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P301
NR 58
TC 13
Z9 14
U1 4
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35583
EP 35617
DI 10.1007/s11042-019-08546-5
EA JAN 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000574100900001
DA 2024-07-18
ER

PT J
AU Lai, Y
   Tariq, M
AF Lai, Yu
   Tariq, Muhammad
TI Group enhancement for matching of multi-view image with overlap fuzzy
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view; Image; Overlap; Fuzzy feature; Group enhancement
ID INTELLIGENT SURVEILLANCE; TRACKING
AB When an object is affected by illumination and noise, traditional methods of image feature group enhancement are mismatched and the accuracy of feature group enhancement is poor. Therefore, a feature group enhancement method for three-dimensional images with overlap fuzzy based on Scale-invariant feature transform (SIFT) algorithm is proposed. Firstly, the scale space of multi-view images is constructed. Next, extreme points are detected and screened to determine the main direction of key points. An image SIFT that is used to describe a sub-feature vector to prevent noise and edge response is generated. Then, overlap fuzzy features of multi-view image are internally and externally normalized. Features are highlighted and the effects of illumination are eliminated by measuring the similarity. Finally, different weights are given to overlap fuzzy features of multi-view images to achieve matching and feature group enhancement. Experimental results show that the proposed method achieves the matching and feature group enhancement process under different illumination conditions and noise environment. Furthermore, the proposed method improves feature group enhancement efficiency and feature group enhancement accuracy.
C1 [Lai, Yu] Zhengzhou Inst Technol, Dept Informat Engn, Zhengzhou 450000, Peoples R China.
   [Tariq, Muhammad] Natl Univ Comp & Emerging Sci, Dept Elect Engn, Peshawar 25000, Pakistan.
C3 Henan University of Technology
RP Tariq, M (corresponding author), Natl Univ Comp & Emerging Sci, Dept Elect Engn, Peshawar 25000, Pakistan.
EM Tariq.khan@nu.edu.pk
RI Tariq, Muhammad/P-7695-2019
OI Tariq, Muhammad/0000-0003-1296-2058
CR Abbas Y, 2015, PLOS ONE, V10, P1
   [Anonymous], 2018, COMPLICAT NEUROSURG
   Bao Zhenhua, 2017, Journal of Computer Applications, V37, P1753, DOI 10.11772/j.issn.1001-9081.2017.06.1753
   Das D, 2017, OPT LASER TECHNOL, V87, P51, DOI 10.1016/j.optlastec.2016.07.016
   Dwivedi AD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020326
   Jaeglé L, 2017, J GEOPHYS RES-ATMOS, V122, P13436, DOI 10.1002/2017JD027656
   Keyes SD, 2017, MICROSC MICROANAL, V23, P538, DOI 10.1017/S1431927617000319
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2019, MOBILE NETW APPL, V24, P5, DOI 10.1007/s11036-018-1134-8
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Lu MY, 2018, IEEE ACCESS, V6, P33451, DOI 10.1109/ACCESS.2017.2779850
   Magudeeswaran V, 2017, INT J IMAG SYST TECH, V27, P153, DOI 10.1002/ima.22219
   Nisar S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/6172453
   Noor SSM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112644
   Padmavathy TV, 2021, MULTIMED TOOLS APPL, V80, P26997, DOI 10.1007/s11042-018-5951-3
   Palanisamy G, 2018, SIVIP, V13, P719
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Rehman YAU, 2016, IEEE SENS J, V16, P5942, DOI 10.1109/JSEN.2016.2574989
   Tan BY, 2018, BIOMED OPT EXPRESS, V9, P2394, DOI 10.1364/BOE.9.002394
   Yan Y, 2017, MULTIMEDIA SYST, V23, P41, DOI 10.1007/s00530-014-0419-4
   [赵猛 Zhao Meng], 2016, [数据采集与处理, Journal of Data Acquisition & Processing], V31, P577
NR 23
TC 1
Z9 2
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2069
EP 2084
DI 10.1007/s11042-019-08173-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2LE
UT WOS:000571393400001
DA 2024-07-18
ER

PT J
AU Zhang, JL
   Guo, MT
   Fan, JP
AF Zhang, Jiulong
   Guo, Mingtao
   Fan, Jianping
TI A novel generative adversarial net for calligraphic tablet images
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; GAN; Residual dense blocks; Calligraphic images
ID RECOGNITION; ONLINE
AB Chinese calligraphic images have important historical and artistic value, but natural weathering and man-made decay severely damage these works, thus image denoising is an important topic to be addressed. Traditional denoising methods still leave room for improvement. In this paper, image denoising is modeled as generation of clean image by using GAN (Goodfellow I et al. Advances in Neural Information Processing Systems 2672-2680, 2014) with an embedment of residual dense blocks (Zhang Y et al. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018) that was formerly used for super resolution reconstruction. Meanwhile, a new type of noise is defined to simulate the real noise, and is used for compensation of unpaired data in the training set for GAN. The new structure, used with some preprocessing and training methods, yield satisfactory results compared to known denoising methods.
C1 [Zhang, Jiulong; Guo, Mingtao] Xian Univ Technol, Inst Comp Sci & Engn, Xian, Peoples R China.
   [Zhang, Jiulong] Shaanxi Key Lab Network Comp & Secur Technol, Xian, Peoples R China.
   [Fan, Jianping] Univ N Carolina, Charlotte, NC USA.
C3 Xi'an University of Technology; University of North Carolina; University
   of North Carolina Charlotte
RP Zhang, JL (corresponding author), Xian Univ Technol, Inst Comp Sci & Engn, Xian, Peoples R China.; Zhang, JL (corresponding author), Shaanxi Key Lab Network Comp & Secur Technol, Xian, Peoples R China.
EM zjl@xaut.edu.cn
FU National Key Research and Development Plan [2017YFB1402103]; Xi'an
   science and technology bureau project [201805037YD15CG21(6)]; Beilin
   science and technology special project [GX1917]
FX This work is supported by the National Key Research and Development Plan
   (No.2017YFB1402103); Xi'an science and technology bureau project
   (201805037YD15CG21(6)); Beilin science and technology special project
   No. GX1917.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2016, P IEEE C COMPUTER VI
   [Anonymous], 2016, INSTANCE NORMALIZATI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   [Anonymous], 2013, P ICML
   Arjovsky M, 2017, arXiv preprint arXiv:1701.07875
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guemri K, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P279, DOI 10.1109/SOCPAR.2014.7008019
   Gulrajani Ishaan, 2017, P ADV NEUR INF PROC, P5767
   Ha Thai Nguyen, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P468, DOI 10.1109/ISSPA.2010.5605441
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140
   Kandemir C, 2015, DIGIT SIGNAL PROCESS, V46, P164, DOI 10.1016/j.dsp.2015.08.012
   Kingma D. P., 2014, arXiv
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182
   Liu H, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P574, DOI 10.1109/ICACI.2012.6463230
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Radford A., 2015, ARXIV151106434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen-Zheng Wang, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P271, DOI 10.1109/ICDAR.2001.953797
   Shi ZH, 2017, MULTIMED TOOLS APPL, V76, P14921, DOI 10.1007/s11042-016-4284-3
   Shi ZH, 2016, MULTIMED TOOLS APPL, V75, P12245, DOI 10.1007/s11042-016-3421-3
   Wang L., 2019, IEEE Transactions on Cybernetics
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang W, 2018, IEEE CONF COMPUT
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
NR 35
TC 13
Z9 15
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 119
EP 140
DI 10.1007/s11042-019-08052-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600006
DA 2024-07-18
ER

PT J
AU Quan, HL
   Feng, SH
   Lang, CY
   Chen, BF
AF Quan, Honglin
   Feng, Songhe
   Lang, Congyan
   Chen, Baifan
TI Improving person re-identification via attribute-identity representation
   and visual attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Saliency detection; Deep learning; Attribute
   representation
ID PEDESTRIAN RECOGNITION; SALIENCY DETECTION
AB Person re-identification, which aims to compare a person of interest as seen in a "probe" camera view to a "gallery" of candidates captured from a camera that does not overlap with the probe one, has increased significant attention in computer vision due to its application in surveillance and security. Various methods utilize the global information as the feature descriptors, which neglect the details in an image and may have a low accuracy of person re-identification and not much attention has been paid to suppressing the background information, which has an influence on person re-identification to some extent. Being aware of these problems, this paper concentrate on the appearance of a person by improving feature descriptors that shed light on a combination framework by fusing the attribute-identity discrimination network with the person discrimination network based on the visual attention mechanism. Experimental results on publicly available image benchmark data sets have demonstrated that the proposed combination framework can achieve competitive performances as compared with state-of-the-art algorithms in terms of accuracy and effectiveness.
C1 [Quan, Honglin; Feng, Songhe; Lang, Congyan] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Chen, Baifan] Cent South Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
C3 Beijing Jiaotong University; Central South University
RP Feng, SH (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM 16120408@bjtu.edu.cn; shfeng@bjtu.edu.cn; cylang@bjtu.edu.cn;
   chenbaifan@csu.edu.cn
FU National Natural Science Foundation of China [61872032]; Fundamental
   Research Funds for the Central universities [2019JBM020]; Key RAMP;D
   Program of Zhejiang Province [2019C01068]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61872032), in part by the Fundamental Research
   Funds for the Central universities (2019JBM020), in part by the Key R&D
   Program of Zhejiang Province (Nos. 2019C01068).
CR [Anonymous], 2017, ARXIV171107155
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hermans Alexander, 2017, ARXIV170307737
   Hu L, 2008, IEEE IMAGE PROC, P1348, DOI 10.1109/ICIP.2008.4712013
   Jain A, 2007, IRI 2007: PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P209, DOI 10.1109/IRI.2007.4296622
   Jian M, 2018, PATTERN RECOGN LETT, V12, P1
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu Y, 2012, INT CONF INTELL SYST, P884, DOI 10.1109/ISDA.2012.6416655
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Quan HL, 2017, IEEE ACCESS, V5, P23519, DOI 10.1109/ACCESS.2017.2764503
   Rahimpour A, 2017, IEEE IMAGE PROC, P4242, DOI 10.1109/ICIP.2017.8297082
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang CL, 2016, CHIN CONTR CONF, P3887, DOI 10.1109/ChiCC.2016.7553958
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, ARXIV 1701 08398
NR 56
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7259
EP 7278
DI 10.1007/s11042-019-08184-x
EA DEC 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000503664300003
DA 2024-07-18
ER

PT J
AU Fogli, D
   Arenghi, A
   Gentilin, F
AF Fogli, Daniela
   Arenghi, Alberto
   Gentilin, Fulvio
TI A universal design approach to wayfinding and navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Universal design; Urban accessibility; Architectural barrier; Mobile
   navigator; Software accessibility; User evaluation
ID MAPS
AB This paper investigates the problem of urban accessibility and proposes a system for the generation of accessible paths in an urban university campus. Universal Design has been adopted to explore the different perspectives of the involved stakeholders; an interdisciplinary team has iteractively developed a web application targeted at public administrators and two versions of a mobile app (one for Android and one for iOS) to be used by citizens. The mobile app is able to propose and guide users on paths that best fit their characteristics and preferences; for example, if a user declares some motor and/or visual impairement, the app proposes paths that avoid the architectural barriers related to such impairments. Not only pedestrian paths are considered in the system, but also routes for private cars or public transportation, and thus information about reserved parking lots and limited traffic zones are also managed. The app has been currently tailored to the campus of the University of Brescia, which is distributed in different districts of Brescia, a town in northern Italy; however, it can be easily scaled to other organizations or whole towns, since Google Maps and its APIs have been used as mapping service. Twenty five participants, including blind people and persons with motor disabilities, have been involved in the evaluation of the usability and accessibility of the two versions of the mobile app.
C1 [Fogli, Daniela] Univ Brescia, Dipartimento Ingn Informaz, Brescia, Italy.
   [Arenghi, Alberto; Gentilin, Fulvio] Univ Brescia, Dipartimento Ingn Civile Architettura Terr Ambien, Brescia, Italy.
C3 University of Brescia; University of Brescia
RP Fogli, D (corresponding author), Univ Brescia, Dipartimento Ingn Informaz, Brescia, Italy.
EM daniela.fogli@unibs.it; alberto.arenghi@unibs.it;
   fulvio.gentilin@unibs.it
OI FOGLI, Daniela/0000-0003-1479-2240
CR Aguiari D, 2018, CONSUM COMM NETWORK, DOI 10.18387/polibotanica.46.1
   Arenghi A, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P124, DOI 10.1145/3284869.3284900
   Arenghi A, 2016, STUD HEALTH TECHNOL, V229, P31, DOI 10.3233/978-1-61499-684-2-31
   Arondi S, 2002, P WORK C ADV VIS INT, P177
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cabitza F, 2014, J VISUAL LANG COMPUT, V25, P684, DOI 10.1016/j.jvlc.2014.10.014
   Comai S., 2018, MOBILE SOLUTIONS THE, P105
   Comai S., 2017, EAI ENDORSED T INTER, V3, P153050, DOI [10.4108/eai.31-8-2017.153050, DOI 10.4108/EAI.31-8-2017.153050]
   Comai S, 2017, L N INST COMP SCI SO, V195, P254, DOI 10.1007/978-3-319-61949-1_27
   Comai S, 2015, STUD HEALTH TECHNOL, V217, P325, DOI 10.3233/978-1-61499-566-1-325
   Depari A, 2018, 2018 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 AND IOT (METROIND4.0&IOT), P146, DOI 10.1109/METROI4.2018.8428343
   Fischer CT, 2017, ON THE WAY TO COLLABORATIVE PSYCHOLOGICAL ASSESSMENT: THE SELECTED WORKS OF CONSTANCE T. FISCHER, P61
   Fischer G, 2006, HUM COM INT, V9, P427
   Fogli Daniela, 2018, Smart Objects and Technologies for Social Good. Third International Conference, GOODTECHS 2017. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 233), P364, DOI 10.1007/978-3-319-76111-4_36
   Fogli D, 2014, UNIVERSAL ACCESS INF, V13, P205, DOI 10.1007/s10209-013-0291-6
   Fogli D, 2010, UNIVERSAL ACCESS INF, V9, P35, DOI 10.1007/s10209-009-0158-z
   Iwarsson S, 2003, DISABIL REHABIL, V25, P57, DOI 10.1080/0963828021000007969
   Karimi Hassan A., 2014, Annals of GIS, V20, P99, DOI 10.1080/19475683.2014.904438
   Karimi Hassan A., 2013, Web and Wireless Geographical Information Systems. 12th International Symposium, W2GIS 2013. Proceedings, P199, DOI 10.1007/978-3-642-37087-8_15
   Lauria A., 2012, PIANI ACCESSIBILITA
   Mehigan TJ, 2012, LECT NOTES COMPUT SC, V7383, P67, DOI 10.1007/978-3-642-31534-3_11
   Melis A, 2018, MOBILE NETW APPL, V23, P167, DOI 10.1007/s11036-017-0831-z
   Mirri Silvia, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P1119, DOI 10.1109/CCNC.2016.7444946
   Palazzi CE, 2010, IEEE INT CON MULTI, P1707, DOI 10.1109/ICME.2010.5583240
   Pittarello F, 2006, P WORK C ADV VIS INT, P364
   Prandi Catia, 2014, 2014 IEEE 11th Consumer Communications and Networking Conference (CCNC), P591, DOI 10.1109/CCNC.2014.6940491
   Prandi C, 2017, ACM T INTERNET TECHN, V18, DOI 10.1145/3133327
   Prandi C, 2017, MULTIMED TOOLS APPL, V76, P4951, DOI 10.1007/s11042-016-3780-9
   Reichheld FF, 2003, HARVARD BUS REV, V81, P46
   Rosson MB., 2001, Usability engineering: scenario-based development of human-computer interaction
   Shigeno Kelly., 2013, Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility, page, P24
   Story M. F., 1998, The universal design file: Designing for people of all ages and abilities
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Vescovo F, 1992, PAESAGGIO URBANO, V1/92
   Vitiello G, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P249, DOI 10.1145/3284869.3284908
NR 36
TC 7
Z9 7
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33577
EP 33601
DI 10.1007/s11042-019-08492-2
EA DEC 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000574620100001
DA 2024-07-18
ER

PT J
AU Bernacki, J
AF Bernacki, Jaroslaw
TI Digital camera identification based on analysis of optical defects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hardwaremetry; Camera recognition; Sensor identification; Photo response
   non uniformity; Distortion; Vignetting; Privacy; Digital forensics
ID VIGNETTING CORRECTION
AB In this paper we deal with the problem of digital camera identification by photographs. Identifying camera is possible by analyzing camera's sensor artifacts that occur during the process of photo processing. The problem of digital camera identification has been popular for a long time. Recently many effective and robust algorithms for solving this problem have been proposed. However, almost all solutions are based on state-of-the-art algorithm, proposed by Lukas et al. in 2006. Core of this algorithm is to calculate the so-called sensor pattern noise based on denoising images with wavelet-based denoising filter. Such technique is very efficient, but very time consuming. In this paper we consider tracing cameras by analyzing defects of their optical systems, like vignetting and lens distortion. We show that analysis of vignetting defect allows for recognizing brand of the camera. Lens distortion can be used to distinguish images from different cameras. Experimental evaluation was carried out on 60 devices (compact cameras and smartphones) for a total number of 12 051 images, with support of the Dresden Image Database. Proposed methods do not require denoising images with wavelet-based denoising filter what has a significant influence for speed of image processing, compared with state-of-the-art algorithm.
C1 [Bernacki, Jaroslaw] Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
C3 Technical University Czestochowa
RP Bernacki, J (corresponding author), Czestochowa Tech Univ, Al Armii Krajowej 36, PL-42200 Czestochowa, Poland.
EM jaroslaw.bernacki@outlook.com
OI Bernacki, Jaroslaw/0000-0002-4488-3488
CR [Anonymous], 2008, DRESDEN IMAGE DATABA
   Baar T., 2012, ABS12072641 CORR
   Bloy GJ, 2008, IEEE T PATTERN ANAL, V3, P30
   Chapman GH, 2015, ENHANCED CORRECTION
   Claus D, 2005, P 2005 IEEE COMP SOC
   de Villiers Jason P., 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V7266, DOI 10.1117/12.804771
   Deng ZH, 2011, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2011.6126225
   Fuentes L, 2015, LECT NOTES COMPUTER, V9095
   Galdi C, 2016, PATTERN RECOGN LETT, V82, P144, DOI 10.1016/j.patrec.2015.09.009
   Gloe T, 2012, LNCS T DATA HIDING M
   Goljan Miroslav, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7254, DOI 10.1117/12.805701
   Goljan M., 2014, P SOC PHOTO-OPT INS, P9028
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Goljan M, 2010, PROC SPIE, V7541, DOI 10.1117/12.838378
   Goljan M, 2009, LECT NOTES COMPUT SC, V5450, P454, DOI 10.1007/978-3-642-04438-0_38
   Hu Y., 2012, ADV MATER SCI ENG, V2012, P5
   Julliand Thibaut, 2016, IMAGE NOISE DIGITAL, V9569, P3
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Khan M., 2016, 2016 INT C DIG IM CO
   Kordecki A, 2016, P SPIE
   Kordecki A, 2016, SIGNAL IMAGE VIDEO P, V10, P1417, DOI 10.1007/s11760-016-0941-2
   Lee SY, 2016, US, Patent No. [20160189353 A1, 20160189353]
   Li H., 2005, P OMNIVISION 05 ICCV
   Li XH, 2014, IEEE GEOSCI REMOTE S, V11, P768, DOI 10.1109/LGRS.2013.2278626
   Lukas J, 2016, MATLAB IMPLEMENTATIO
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Park SW, 2001, PATTERN RECOGN, V34, P1199, DOI 10.1016/S0031-3203(00)00068-6
   Qiao T, 2018, IEEE ACCESS, V6, P78038, DOI 10.1109/ACCESS.2018.2884710
   Ray S., 2002, Applied Photographic Optics
   Schwarting M, 2016, 2015 ANNUAL GLOBAL ONLINE CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGY (GOCICT), P66, DOI 10.1109/GOCICT.2015.21
   Silva V.D., 2016, Electron. Imaging, V2016, P1
   Syga, 2017, P 14 INT JOINT C E B, V4, P343
   Taspinar S, 2016, IEEE IMAGE PROC, P156, DOI 10.1109/ICIP.2016.7532338
   Van Lanh T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P16
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Zeng H, 2017, IEEE T CYBERNETICS, V47, P1757, DOI 10.1109/TCYB.2016.2557802
   Zeng H, 2015, IEEE IMAGE PROC, P1687, DOI 10.1109/ICIP.2015.7351088
   Zheng YJ, 2013, IEEE T PATTERN ANAL, V35, P1480, DOI 10.1109/TPAMI.2012.210
   Zheng YJ, 2009, IEEE T PATTERN ANAL, V31, P2243, DOI 10.1109/TPAMI.2008.263
NR 40
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2945
EP 2963
DI 10.1007/s11042-019-08182-z
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500612000003
OA hybrid
DA 2024-07-18
ER

PT J
AU Gao, JC
   Han, B
   Yan, KD
AF Gao, Junchai
   Han, Bing
   Yan, Keding
TI Static object imaging features recognition algorithm in dynamic scene
   mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Monocular vision in dynamic scene; Static feature; Optical flow; 3D
   motion segmentation
ID MONOCULAR SLAM; MOTION; RANSAC
AB In dynamic scene monocular visual SLAM, it is important to recognize static object imaging features for mapping. The optical flow of noise and the object moving in the same orientations would have the same orientations of static feature for two frames image, that would disturb static feature point recognition. Because the translational motion optical flow orientations method judges with optical flow of single feature point and translational motion orientations, it is not reliable for static feature point recognition. Therefore, a 3D motion segmentation combined for static object imaging features recognition is proposed, which clusters the same optical flow of feature points in 3D motion subspace, including orientations and amplitude of translation and rotation. The simulation results show that the proposed static object imaging features recognition method improves the recognition correct rate and reliability of static features. So, it is effective for static object imaging features recognition in dynamic scene mapping.
C1 [Gao, Junchai; Yan, Keding] Xian Technol Univ, Sch Elect Informat Engn, Xian 710032, Shaanxi, Peoples R China.
   [Han, Bing] Xian Technol Univ, Ctr Informat Technol, Xian 710032, Shaanxi, Peoples R China.
C3 Xi'an Technological University; Xi'an Technological University
RP Gao, JC (corresponding author), Xian Technol Univ, Sch Elect Informat Engn, Xian 710032, Shaanxi, Peoples R China.
EM 527667658@qq.com
FU Shaanxi Province Key Research and Development program [2018GY-184];
   Program for Innovative Science and Research Team of Xi'an Technological
   University
FX This work was supported by Shaanxi Province Key Research and Development
   program (Program No. 2018GY-184), and supported by the Program for
   Innovative Science and Research Team of Xi'an Technological University.
CR Bideau P, 2016, LECT NOTES COMPUT SC, V9912, P433, DOI 10.1007/978-3-319-46484-8_26
   Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345
   Civera J, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3498, DOI 10.1109/IROS.2009.5354410
   Evans M., 2011, STAT DISTRIBUTIONS, P191
   Guangliang Chen, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P759, DOI 10.1109/ICCVW.2009.5457626
   Kundu A., 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1635, DOI 10.1109/ROBIO.2010.5723575
   Kundu A., 2010, Proceedings of the Seventh Indian Conference on Computer Vision, Graphics and Image Processing, P251
   Kundu A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4306, DOI 10.1109/IROS.2009.5354227
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Migliore D., 2009, ICRA Workshop on Safe navigation in open and dynamic environments: Application to autonomous vehicles, P12
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Namdev RK, 2012, IEEE INT CONF ROBOT, P4092, DOI 10.1109/ICRA.2012.6224800
   Narayana M, 2013, IEEE I CONF COMP VIS, P1577, DOI 10.1109/ICCV.2013.199
   Nistér D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y
   Perera LDL, 2004, IEEE INT CONF ROBOT, P860, DOI 10.1109/ROBOT.2004.1307257
   Rodríguez-Canosa GR, 2012, REMOTE SENS-BASEL, V4, P1090, DOI 10.3390/rs4041090
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781
   Xu W, 2012, ROBOT, V34, P64
   Yan JY, 2008, IEEE T PATTERN ANAL, V30, P865, DOI 10.1109/TPAMI.2007.70739
   Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94
NR 25
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33885
EP 33898
DI 10.1007/s11042-019-08148-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600058
DA 2024-07-18
ER

PT J
AU Li, Y
   Lv, ZH
   Zhao, JL
   Pan, ZK
AF Li, Yi
   Lv, Zhihan
   Zhao, Junli
   Pan, Zhenkuan
TI Improving performance of medical image fusion using histogram,
   dictionary learning and sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Histogram similarity; Sparse representation
ID WAVELET TRANSFORM
AB Medical image fusion has attracted much attention in recent years, which aims to fuse different medical images into a more informative and clearer one. The fused image is able to help doctors to diagnose diseases rapidly and effectively. Among numerous fusion methods, sparse-representation-based image fusion is a new concept that has emerged over the past several years. However, the high-frequency components of low-resolution and the high-frequency components of source images are obtained equally, and sparse coefficients are solved by a minimization problem. As a result, it ignores the correlation between high-frequency components of low-resolution and the high-frequency components of source images, and solutions to the L-0-norm minimization problem. To address these issues, we propose a new image fusion method based on histogram similarity and multi-view weighted sparse representation. By introducing a histogram similarity, different weights are assigned to the high-frequency components of low-resolution and the high-frequency components of source images to efficiently harness the complementary information. In addition, sparse coefficients solved by the L-1-norm minimization problem are more accurate. This technique is further incorporated into medical image fusion. Experimental results demonstrate that the proposed method achieves state-of-the-art performance in terms of both visual quality and quantitative evaluation metrics.
C1 [Li, Yi; Lv, Zhihan; Zhao, Junli] Qingdao Univ, Coll Data Sci Software Engn, Qingdao 266071, Shandong, Peoples R China.
   [Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
C3 Qingdao University; Qingdao University
RP Li, Y; Lv, ZH (corresponding author), Qingdao Univ, Coll Data Sci Software Engn, Qingdao 266071, Shandong, Peoples R China.
EM lyqgx@126.com; lvzhihan@gmail.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074; Zhao,
   Junli/0000-0002-2034-6426
FU National Natural Science Foundation of China [61702293]; Shandong
   Provincial Natural Science Foundation of China [ZR2017QF015]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61702293.This work was supported in
   part by the Shandong Provincial Natural Science Foundation of China
   under Grants ZR2017QF015.
CR Abdullah NNB, 2018, 2018 IEEE/ACM INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING IN HEALTHCARE SYSTEMS (SEHS), P10, DOI 10.1145/3194696.3194698
   [Anonymous], 2018, IEEE T CIRCUITS SYST
   Banerjee R, 2019, WIRELESS PERS COMMUN, V104, P57, DOI 10.1007/s11277-018-6008-7
   Bar-Sinai Y, 2018, B AM PHYS SOC, V54, P200
   Chen BD, 2018, IEEE T NEUR NET LEAR, V29, P731, DOI 10.1109/TNNLS.2016.2636160
   Chen S, 2018, 2018 2 IEEE ADV INF, P1034
   Chipman LJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC248
   Dai WR, 2018, IEEE T SIGNAL PROCES, V66, P603, DOI 10.1109/TSP.2017.2773427
   Daniel E, 2018, IEEE SENSORS J
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Ding F, 2018, INT J CONTROL AUTOM, V16, P630, DOI 10.1007/s12555-017-0001-x
   Ding Z, 2018, INT SOC OPTICS PHOTO, P10836
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Fu W, 2018, IEEE T GEOSCI REMOTE, V56, P1336, DOI 10.1109/TGRS.2017.2761893
   Gharbia R, 2018, FUTUR GENER COMPUT S, V54
   Hagargi P. A., 2018, BRAIN, V5
   Kumar KS, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1232, DOI 10.1109/ICICCT.2018.8473004
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Li J, 2019, COMPUTATIONAL INTELL
   Li ST, 2019, IMMUNOL INVEST, V48, P181, DOI [10.1080/08820139.2018.1529790, 10.1002/er.4275]
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liu S, 2019, IEEE T CIRCUITS SYST
   Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mancini M, 2018, IEEE ROBOT AUTOM LET, V3, P1490, DOI 10.1109/LRA.2018.2800083
   Massot A., 2018, CIRC SYST ISCAS 2018, P1
   Nguyen L, 2018, METHODS MOL BIOL, V1795, P1, DOI 10.1007/978-1-4939-7874-8_1
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Ra Prakash K., 2018, 2018 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia). Proceedings, P1177, DOI 10.1109/ISGT-Asia.2018.8467843
   Srinivasan A., 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1660, DOI 10.1109/ICECA.2018.8474806
   Wang M, 2019, J MOD OPTIC, V66, P77, DOI 10.1080/09500340.2018.1512668
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Y, 2018, IEEE T MED IMAGING, V37, P1067, DOI 10.1109/TMI.2017.2777870
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wen Y, 2019, IEEE T IMAGE PROCESS, V28, P994, DOI 10.1109/TIP.2018.2874285
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yang JL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1633, DOI 10.1109/ICASSP.2018.8462675
   Yazdi SV, 2018, PATTERN RECOGN LETT, V112, P1, DOI 10.1016/j.patrec.2018.05.017
   Ye QL, 2018, IEEE T NEUR NET LEAR, V29, P4494, DOI 10.1109/TNNLS.2017.2749428
   Yin H, 2018, IEEE T BIOMED ENG
   Yin HT, 2013, INFORM FUSION, V14, P229, DOI 10.1016/j.inffus.2012.01.008
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5113, DOI 10.1109/TIP.2018.2851390
   Zhao WD, 2018, IEEE T MULTIMEDIA, V20, P866, DOI 10.1109/TMM.2017.2760100
   Zhou T, 2018, IEEE T CYBERNETICS, V48, P2643, DOI 10.1109/TCYB.2017.2747998
NR 47
TC 8
Z9 8
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34459
EP 34482
DI 10.1007/s11042-019-08027-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800011
DA 2024-07-18
ER

PT J
AU Kushwaha, R
   Nain, N
AF Kushwaha, Riti
   Nain, Neeta
TI PUG-FB : Person-verification using geometric and Haralick features of
   footprint biometric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Footprint; Biometrics; Geometry feature; Dynamic time warp; Haralick
   features
ID IDENTIFICATION; RECOGNITION; IMAGES; EAR
AB This article demonstrates a study of biometric identification and verification system using foot geometry features. A footprint has three types of features which are sufficient to recognize a person uniquely. These features are categorized into geometric, texture, and minutiae. We have computed most widely used geometry features of the foot using length, width, area, major axis, and minor axis, to identify a person uniquely. Different variations of these features are computed by assigning weights to each feature emphasizing its importance. We have extracted the best variations among foot descriptors, and conclude that the province is the most contributing factor to identify a person foot uniquely. Foot contour features are further combined with foot descriptors to increase the accuracy. For texture, Gray level co-occurrence matrix based on Haralick features is computed with Support Vector Machine as the classifier. Foot biometrics can be used as an additional covert authentication measure where people remove shoes, such as holy places, airport security, swimming pools, wellness centers etc. It can also be used for newborn authentication and identification in hospitals. The method achieves GenuineAcceptRate(GAR) of 82% with the FalseAcceptRate(FAR) of 2.0%, and GAR of 85% with the FAR of 4.0% in case of combination sum rule. GenuineAcceptRate(GAR) has increased to 87.5% at FalseAcceptRate(FAR) of 2.0% including texture features as Gray level co-occurrence matrix.
C1 [Kushwaha, Riti; Nain, Neeta] Malaviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Kushwaha, R (corresponding author), Malaviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
EM riti.kushwaha07@gmail.com; nnain.cse@mnit.ac.in
RI Kushwaha, Riti/AAR-1690-2021
OI Kushwaha, Riti/0000-0003-0738-437X; Nain, Neeta/0000-0002-0550-0376
CR [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI DOI 10.17485/ijst/2016/v9i44/105167
   [Anonymous], 2004, Hand
   Barker SL, 1998, MED SCI LAW, V38, P341, DOI 10.1177/002580249803800411
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   CHORAS M, 2015, ENCY BIOMETRICS, P363
   Chu F, 2005, STUD FUZZ SOFT COMP, V177, P343
   Cutler R, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1589, DOI 10.1109/ICME.2000.871073
   Dietz HP, 2004, ULTRASOUND OBST GYN, V23, P615, DOI 10.1002/uog.1072
   Doyle S, 2008, I S BIOMED IMAGING, P496, DOI 10.1109/ISBI.2008.4541041
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hashem K.M., 2016, IJEM, V6, P22, DOI [10.5815/ijem.2016.04.03, DOI 10.5815/IJEM.2016.04.03]
   *ITU TEL, 1996, STAND SECT IT, P263
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jain A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P1, DOI 10.1109/ICICICT.2014.6781242
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706
   Kennedy RB, 1996, FORENSIC SCI INT, V82, P81, DOI 10.1016/0379-0738(96)01969-X
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Khokher R, 2015, MACROMOL SYMP, V347, P16, DOI 10.1002/masy.201400045
   Ko K., 2007, TECHNICAL REPORT, P3
   Kubanek M, 2006, BIOMETRICS, COMPUTER SECURITY SYSTEMS AND ARTIFICIAL INTELLIGENCE APPLICATIONS, P45, DOI 10.1007/978-0-387-36503-9_5
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   KUMAR VDA, 2013, INDIAN J COMPUTER SC, V3
   KUMAR VDA, 2012, INDIAN J BIOINFORMAT, V1, P28
   KUSHWAHA R, 2012, INT J CURRENT ENG TE, V2, P270
   Kushwaha R, 2018, IEEE INT ADV COMPUT, P196, DOI 10.1109/IADCC.2018.8692109
   Kushwaha R, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P164, DOI 10.1109/SITIS.2016.34
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Liu S., 2001, IT Professional, V3, P27, DOI 10.1109/6294.899930
   Moos S, 2017, INT J INTERACT DES M, V11, P1, DOI 10.1007/s12008-014-0244-1
   Muller M., 2007, Information retrieval for music and motion, P69, DOI [10.1007/978-3-540-74048-3_4, DOI 10.1007/978-3-540-74048-3_4]
   Nagwanshi K., 2012, INT J APPL INFORM SY, V3, P1
   Nakajima K, 2000, IEEE T BIO-MED ENG, V47, P1534, DOI 10.1109/10.880106
   Porebski A, 2008, 2008 FIRST INTERNATIONAL WORKSHOPS ON IMAGE PROCESSING THEORY, TOOLS AND APPLICATIONS (IPTA), P206
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Scholkopf B., 2002, Learning with Kernels
   Singh H, 2018, INT CONF COMPUT
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Sudiro S., 2012, International Research Journal of Modernization in Engineering Technology and Science, V2, P1, DOI DOI 10.56726/IRJMETS33396
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Uhl A, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2892674
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Weingaertner D, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P200
   Wickenheiser RA, 2002, J FORENSIC SCI, V47, P442
   Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067
   ZHANG X, 2017, SENSORS BASEL, V17
NR 51
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2671
EP 2701
DI 10.1007/s11042-019-08149-0
EA NOV 2019
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000499243900001
DA 2024-07-18
ER

PT J
AU Dey, A
   Ghosh, S
   Bhattacharya, S
   Chaki, N
AF Dey, Ayan
   Ghosh, Shibashis
   Bhattacharya, Sukriti
   Chaki, Nabendu
TI A robust software watermarking framework using shellcode
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software watermarking; Shellcode; Encryption; Hash functions
ID OBFUSCATION TECHNIQUES; PROTECTION
AB Watermarks have long been applied to ensure the authenticity of media contents. Computer software is an intellectual outcome in the digital domain. Therefore, it has to face all the common threats like illegal redistribution, copying, misuse through malicious modification. However, the majority of the existing software watermarking techniques are suffering from the limitations of existing robustness notions and lack of resilience from a variety of attacks. In this paper, we proposed a novel robust software watermarking scheme based on "shellcode". It is a small piece of code generally used as the payload in the exploitation of a software vulnerability. It consists of a list of carefully arranged machine instructions, executed through injecting into a running application. Shellcode serves as the backbone of our proposed watermarking scheme. It is used to achieve both covert communication (steganography), and deterrence (watermarking) process in the proposed watermarking technique. Such a combination gives more robustness and security to the whole process. In this paper, we introduce ShellMark as a proof of concept to illustrate the shellcode based software watermarking technique. We compared and tested ShellMark with already existing software watermarking techniques, and it showed that ShellMark is resilient to most of the well known watermarking attacks.
C1 [Dey, Ayan; Ghosh, Shibashis] Univ Calcutta, AK Choudhury Sch IT, Kolkata, India.
   [Bhattacharya, Sukriti] LIST, Environm Informat, Dept Environm Res & Innovat ERIN, Luxembourg, Luxembourg.
   [Chaki, Nabendu] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
C3 University of Calcutta; Luxembourg Institute of Science & Technology;
   University of Calcutta
RP Dey, A (corresponding author), Univ Calcutta, AK Choudhury Sch IT, Kolkata, India.
EM adakc_rs@caluniv.ac.in; shibashisghosh3@gmail.com;
   sukriti.bhattacharya@list.lu; nabendu@ieee.org
RI CHAKI, NABENDU/A-5869-2015; Bhattacharya, Sukriti/AAB-8018-2020
FU TCS Research Scholar Program; TEQIP Phase-III project
FX This study was funded by TCS Research Scholar Program (granted to Ayan
   Dey) and TEQIP Phase-III project (granted to the University of
   Calcutta).
CR Adnan G., 2010, Bahria University Journal of Information Communication Technology, V3, P68
   Ahmadoh E, 2015, UTILIZATION 2 DIACRI, V3
   Al-Nofaie S., 2016, J COMPUTER SCI COMPU, V6, P59, DOI [10.20967/jcscm.2016.03.004, DOI 10.20967/jcscm.2016.03.004]
   Al-Nofaie S., 2016, 3 INT C MATH SCI COM, P38
   Alanazi N, 2018, J RES ENG APPL SCI, V3, P11
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Aljuaid N, 2014, LECT NOTES INF THEOR, V2, P151
   Aljuaid N, 2014, P 2014 INT C ADV ENG, P12
   Almazrooie M, 2018, J KING SAUD U COMPUT
   Alrehily Ashwag, 2018, International Journal of Computer Network and Information Security, V10, P28, DOI 10.5815/ijcnis.2018.05.04
   [Anonymous], 2015, SEIZING OPPORTUNITY
   [Anonymous], 2010, INT J SIGNAL IMAGE P
   [Anonymous], 2010, 8 ANN BSA IDC GLOBAL
   [Anonymous], 2005, P 2005 ACM S APPL CO, DOI DOI 10.1145/1066677.1066753
   Behera CK, 2015, PROCEDIA COMPUT SCI, V70, P757, DOI 10.1016/j.procs.2015.10.114
   Chen Z, 2017, MARIT POLICY MANAG, V44, P537, DOI 10.1080/03088839.2017.1327726
   Collberg C., 1999, Conference Record of POPL '99. 26th ACM SIGPLAN-SIGACT. Symposium on Principles of Programming Languages, P311, DOI 10.1145/292540.292569
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Dey A, 2019, INT J CONTROL, V92, P1903, DOI 10.1080/00207179.2017.1418909
   Dey A, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P260, DOI 10.1145/3297001.3297036
   Djekic P, 2007, J STRATEGIC INF SYST, V16, P173, DOI 10.1016/j.jsis.2007.05.005
   Fratantonio Y, 2011, LECT NOTES COMPUT SC, V6961, P61, DOI 10.1007/978-3-642-23644-0_4
   Gupta G, 2006, LECT NOTES COMPUT SC, V4283, P282
   Gutub A, 2010, J EMERGING TECHNOLOG, V2, P2
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P48, DOI 10.4304/jetwi.2.1.48-55
   Gutub A. A. A., 2007, INT J COMPUT ELECT A, V1, P502, DOI DOI 10.5281/ZENODO.1061621
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Gutub AA, 2010, KUWAIT J SCI ENG, V37, P89
   Hamilton J, 2011, ELGAR FINANC LAW, P17
   Hosseinzadeh S, 2018, INFORM SOFTWARE TECH, V104, P72, DOI 10.1016/j.infsof.2018.07.007
   Khan F, 2007, MESSAGE CONCEALMENT
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Lim HI, 2008, IEICE T INF SYST, VE91D, P2323, DOI 10.1093/ietisy/e91-d.9.2323
   Lim HI, 2009, INFORM SOFTWARE TECH, V51, P1338, DOI 10.1016/j.infsof.2009.04.011
   Mishra A, 2008, J ARTICLE
   Pizzolante R, 2018, COMPUT SECUR, V74, P384, DOI 10.1016/j.cose.2017.06.003
   Sha ZL, 2009, THIRD INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING, P410, DOI 10.1109/WGEC.2009.18
   Shirali-Shahreza M, 2008, INFORM COMMUNICATION
   Sion R, 2002, LECT NOTES COMPUT SC, V2613, P130
   Stern JP, 2000, LECT NOTES COMPUT SC, V1768, P368
   Tamada H, 2005, IEICE T INF SYST, VE88D, P2148, DOI 10.1093/ietisy/e88-d.9.2148
   Tamada H, 2004, FUTURE SOFTWARE TECH, V20
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Willison R, 2008, P 41 HAW INT C SYST, P266
   Zhao Yong-Xia, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P271, DOI 10.1109/MMIT.2010.186
   Zhu W, 2005, LECT NOTES COMPUT SC, V3495, P454
   Zhu W, 2007, THESIS
NR 47
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2555
EP 2576
DI 10.1007/s11042-019-08372-9
EA NOV 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2UX
UT WOS:000502127000001
DA 2024-07-18
ER

PT J
AU Evangelin, LN
   Fred, AL
AF Evangelin, L. Nisha
   Fred, A. Lenin
TI Reduced Optimal Feature Based Biometric Authentication Using MALO-MKSVM
   Techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric authentication; Multimodal; Feature extraction;
   Classification; MALO
ID NEURAL-NETWORK; FINGERPRINT; VERIFICATION; FUSION
AB Biometric authentication is referred to as a realistic authentication which traits used is distinct, and quantifiable to recognize one individual. Depending on the level of security required, unimodal based authentication mechanisms are prone to numerous security attacks. In this paper, we propose a multimodal based biometric recognition framework which will improve the security level by using more than one type of biometric scanner. A new multimodal feature extraction technique has been proposed to reduce the features by utilizing Probabilistic Principal Component Analysis (PPCA) model by the way of choosing optimal features with the assistance of Modified Ant Lion Optimization (MALO). Finally, the recognized and non-recognized images are accomplished by the formation of a new classification model i.e. Multi Kernel Support Vector Machine (MKSVM). From this procedure, the result showed that a high recognition rate and also the most extreme accuracy accomplished in this work.
C1 [Evangelin, L. Nisha] Sathyabama Univ, Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Fred, A. Lenin] Mar Ephraem Coll Engn & Technol, Marthandam, India.
C3 Sathyabama Institute of Science & Technology
RP Evangelin, LN (corresponding author), Sathyabama Univ, Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM nishaevangelin0187@gmail.com
RI Fred, Lenin/AAU-9556-2021
OI FRED, A.LENIN/0000-0002-6551-4796
CR Bansal M, 2016, OPTIK, V127, P4808, DOI 10.1016/j.ijleo.2016.01.160
   Ben Tarif E, 2018, MULTIMED TOOLS APPL, V77, P2485, DOI 10.1007/s11042-016-4280-7
   Brocardo ML, 2015, J COMPUT SYST SCI, V81, P1429, DOI 10.1016/j.jcss.2014.12.019
   Chaurasia P, 2015, BEHAV SCI TERROR POL, V7, P210, DOI 10.1080/19434472.2015.1071420
   D'Urso P, 2005, FUZZY SET SYST, V150, P285, DOI 10.1016/j.fss.2004.03.024
   Dixon P, 2008, J LIBR ADM, V47, P141, DOI 10.1080/01930820802186480
   Eskandari M, 2015, COMPUT VIS IMAGE UND, V137, P63, DOI 10.1016/j.cviu.2015.02.011
   Evangelin LN, 2017, INT J COMPUT APPL T, V56, P219, DOI 10.1504/IJCAT.2017.088196
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Fridman L, 2015, COMPUT ELECTR ENG, V41, P142, DOI 10.1016/j.compeleceng.2014.10.018
   Kang JH, 2018, NEUROCOMPUTING, V287, P93, DOI 10.1016/j.neucom.2018.01.074
   Khellat-Kihel S, 2016, APPL SOFT COMPUT, V42, P439, DOI 10.1016/j.asoc.2016.02.008
   Khodadoust J, 2017, PATTERN RECOGN, V67, P110, DOI 10.1016/j.patcog.2017.01.022
   Lastra M, 2015, INFORM SCIENCES, V301, P195, DOI 10.1016/j.ins.2014.12.052
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Malarvizhi N, 2019, MULTIMED TOOLS APPL, P1
   Malegori C, 2016, J FOOD ENG, V185, P48, DOI 10.1016/j.jfoodeng.2016.04.001
   Malek O, 2015, NEUROCOMPUTING, V148, P294, DOI 10.1016/j.neucom.2014.06.074
   Mohanty AswiniKumar., 2011, International Journal of Engineering Research and Applications, V1, P687
   Mondal S, 2015, INFORM SCIENCES, V304, P28, DOI 10.1016/j.ins.2014.12.045
   Moos S, 2017, INT J INTERACT DES M, V11, P1, DOI 10.1007/s12008-014-0244-1
   Morales A, 2015, PATTERN RECOGN LETT, V68, P183, DOI 10.1016/j.patrec.2015.09.011
   Murillo-Escobar MA, 2015, EXPERT SYST APPL, V42, P8198, DOI 10.1016/j.eswa.2015.06.035
   Neha CK, 2018, J MULTIMEDIA TOOLS A, P1
   Nigam A, 2015, NEUROCOMPUTING, V151, P1120, DOI 10.1016/j.neucom.2014.03.083
   Om H, 2013, J DISCRET MATH SCI C, V16, P207, DOI 10.1080/09720529.2013.778459
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Ramu T, MULTIMEDIA TOOLS APP, P1
   Regouid M, 2019, MULTIMED TOOLS APPL, P1
   Sahoo SK, 2012, IETE TECH REV, V29, P54, DOI 10.4103/0256-4602.93139
   Subhashini KR, 2017, APPL SOFT COMPUT, V59, P153, DOI 10.1016/j.asoc.2017.05.007
   Tiong LCO, 2019, MULTIMED TOOLS APPL, P1
   Vezzetti E, 2012, ROBOT AUTON SYST, V60, P928, DOI 10.1016/j.robot.2012.01.003
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wang JS, 2013, TECHNOL ANAL STRATEG, V25, P1067, DOI 10.1080/09537325.2013.832747
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007
   Zhang N, 2009, IEEE IMAGE PROC, P3373, DOI 10.1109/ICIP.2009.5413878
NR 40
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31077
EP 31100
DI 10.1007/s11042-019-07918-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000005
DA 2024-07-18
ER

PT J
AU Karim, S
   Zhang, Y
   Yin, SL
   Laghari, AA
   Brohi, AA
AF Karim, Shahid
   Zhang, Ye
   Yin, Shoulin
   Laghari, Asif Ali
   Brohi, Ali Anwar
TI Impact of compressed and down-scaled training images on vehicle
   detection in remote sensing imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle detection; Machine learning; Compressed; Down-scaled; Regions;
   RCNN
ID FEATURE-EXTRACTION; CONVOLUTIONAL NETWORKS; OBJECT DETECTION;
   RECOGNITION
AB Vehicle detection in remote sensing imagery is a prominent issue over the last few years. In this application, the processing of optical remote sensing images becomes critical due to the complex environment, large size, occlusions and color variations. However, several approaches have been proposed to improve the training process but still, the efforts are moving towards optimal solutions. The training process is time-consuming and a large amount of memory is required to store those training images. Numerous traditional state-of-the-art approaches are suffering from problematic high computational time. In this paper, a new training methodology which is based on compressed and down-scaled images is implemented to reduce the training time. The training images are compressed at Quality Factor (QF) of 50 and down-scaled by scale factor of 0.5 to evaluate the performance for vehicle detection. The existing approaches of computer vision are taking advantage of high computational Graphical Processing Units (GPUs) to speed up the training process. The proposed framework is also a better way to reduce the computational time. To compare performance, we have trained the RCNN, Fast-RCNN, Faster-RCNN and Cascade detectors by using three types of training image sets and several experiments have been performed. More specifically, our approach makes the training faster than the training based on original images and training based on compressed images provides optimal results.
C1 [Karim, Shahid; Zhang, Ye; Yin, Shoulin] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Laghari, Asif Ali] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Brohi, Ali Anwar] Harbin Inst Technol, Sch Energy Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Harbin
   Institute of Technology
RP Karim, S (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM shahidhit@yahoo.com; zhye@hit.edu.cn; yslinhit@163.com;
   asifalilaghari@gmail.com; alianwar50@gmail.com
RI Yin, Shoulin/IZE-4876-2023; Zhang, Y J/HLG-1022-2023; Yin,
   Shoulin/AAQ-6430-2021; zhang, ye/HKN-5128-2023; Karim,
   Shahid/AAO-1087-2020; Laghari, Asif Ali/AAF-5893-2020
OI Yin, Shoulin/0000-0002-5367-1372; Karim, Shahid/0000-0001-9986-5052;
   Laghari, Asif Ali/0000-0001-5831-5943
FU National Natural Science Foundation of China [61471148]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61471148.
CR [Anonymous], 2014, BMVC
   Bak JH, 2017, INT C CONTR AUTOMAT, P1185, DOI 10.23919/ICCAS.2017.8204402
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Brubaker SC, 2006, LECT NOTES COMPUT SC, V3951, P325
   Campos V, 2017, INT C COMP SCI ICCS, P12
   Chen XY, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P181, DOI 10.1109/ACPR.2013.33
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   El-Bakry HM, 2006, VECTORS, V1, P4
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Han  S., 2015, ARXIV151000149
   Hassairi S, 2018, MULTIMED TOOLS APPL, V77, P5443, DOI 10.1007/s11042-017-4461-z
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu JG, 2016, COMM COM INF SC, V664, P122, DOI 10.1007/978-981-10-3476-3_15
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Huh JH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082693
   Ji CY, 1997, ADV NEUR IN, V9, P494
   Jia Z., 2011, Proceedings-International Joint Conference on Artificial Intelligence (IJCAI), V22, P2072
   Jiang J, 1999, SIGNAL PROCESS-IMAGE, V14, P737, DOI 10.1016/S0923-5965(98)00041-1
   Jin R, 2017, MULTIMED TOOLS APPL, V76, P5927, DOI 10.1007/s11042-015-2694-2
   Joliffe I T, 1992, Stat Methods Med Res, V1, P69, DOI 10.1177/096228029200100105
   Karim S, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042618
   Kato T, 2002, IEEE T INTELL TRANSP, V3, P252, DOI 10.1109/TITS.2002.804752
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebrun G, 2004, INT C PATT RECOG, P160, DOI 10.1109/ICPR.2004.1334035
   Leitloff J, 2010, IEEE T GEOSCI REMOTE, V48, P2795, DOI 10.1109/TGRS.2010.2043109
   Li M, 2008, IEEE ICC, P2900
   Liu JN, 2012, OPT COMMUN, V285, P2549, DOI 10.1016/j.optcom.2012.01.065
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maggiori E., 2017, CAN SEMANTIC LABELIN
   Marcus M, 2014, JPEG IMAGE COMPRESSI
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Naikal N, 2011, IEEE I CONF COMP VIS, P818, DOI 10.1109/ICCV.2011.6126321
   Niyomugabo C, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/5289413
   O'Hanen B., 2005, JPEG COMPRESSION
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Palubinskas G., 2008, IGARSS 2008 2008 IEE, VVolume 2, pII, DOI DOI 10.1109/IGARSS.2008.4779019
   Qu Shenquan, 2016, J IND INTELLIGENT IN, V4
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   SAMUEL AL, 1967, IBM J RES DEV, V11, P601, DOI 10.1147/rd.116.0601
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Sundaram N, 2012, MAKING COMPUTER VISI
   Tang TY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111170
   Taubman David., 2012, JPEG2000 Image Compression Fundamentals, Standards and Practice
   Tekalp A. M., 2015, Digital Video Processing, V2nd
   Teo CH, 2005, P 12 INT C NEUR INF, P17
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang L, 2016, NEUROCOMPUTING, V208, P325, DOI 10.1016/j.neucom.2016.03.082
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Yao SH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134242
   Zhang WF, 2007, PR IEEE COMP DESIGN, P10
   Zhu XX, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.80
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 77
TC 34
Z9 33
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32565
EP 32583
DI 10.1007/s11042-019-08033-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000066
DA 2024-07-18
ER

PT J
AU Zhang, HB
   Yi, YZ
   Wang, JS
   Cao, N
   Duan, Q
AF Zhang, Hongbin
   Yi, Yuzi
   Wang, Junshe
   Cao, Ning
   Duan, Qiang
TI Network attack prediction method based on threat intelligence for IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social internet of things; Internet of things; Support vector machine;
   Threat intelligence; Social networks; Malicious behavior
AB The Social Internet of Things (SIoT) is a combination of the Internet of Things (IoT) and social networks, which enables better service discovery and improves the user experience. The threat posed by the malicious behavior of social network accounts also affects the SIoT, this paper studies the analysis and prediction of malicious behavior for SIoT accounts, proposed a method for predicting malicious behavior of SIoT accounts based on threat intelligence. The method uses support vector machine (SVM) to obtain threat intelligence related to malicious behavior of target accounts, analyze contextual data in threat intelligence to predict the behavior of malicious accounts. By collecting and analyzing the data in a SIoT environment, verifies the malicious behavior prediction method of SIoT account proposed in this paper.
C1 [Zhang, Hongbin; Yi, Yuzi; Wang, Junshe] Hebei Univ Sci & Technol, Sch Informat Sci & Engn, Shijiazhuang, Hebei, Peoples R China.
   [Zhang, Hongbin] Hebei Normal Univ, Hebei Key Lab Network & Informat Secur, Shijiazhuang 050024, Hebei, Peoples R China.
   [Cao, Ning] Qingdao Binhai Univ, Coll Informat Engn, Qingdao 266555, Shandong, Peoples R China.
   [Duan, Qiang] Penn State Univ, Dept Informat Sci & Technol, 1600 Woodland Rd, Abington, PA 19001 USA.
C3 Hebei University of Science & Technology; Hebei Normal University;
   Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University
RP Yi, YZ (corresponding author), Hebei Univ Sci & Technol, Sch Informat Sci & Engn, Shijiazhuang, Hebei, Peoples R China.
EM yiyuzi03@163.com
RI Duan, Qiang/U-8262-2019
FU National Natural Science Foundation of China [61672206,61572170]; Hebei
   Province Science and Technology Support Program [17210104D]; Hebei
   Province Innovation Capacity Improvement Program Soft Science Research
   and Science Popularization Project [17K50702D]; College Science and
   Technology Research Project of Heibei Province [ZD2015099]
FX This research was supported by the National Natural Science Foundation
   of China (61672206,61572170), Hebei Province Science and Technology
   Support Program (17210104D), Hebei Province Innovation Capacity
   Improvement Program Soft Science Research and Science Popularization
   Project (17K50702D), College Science and Technology Research Project of
   Heibei Province (ZD2015099). Yuzi Yi is the corresponding author of this
   article.
CR Atzori L, 2011, IEEE COMMUN LETT, V15, P1193, DOI 10.1109/LCOMM.2011.090911.111340
   Bao-Tong M, 2018, SURVEY SIOT, P41
   Boshmaf Y, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P93
   Douceur JR, 2002, LECT NOTES COMPUT SC, V2429, P251, DOI 10.1007/3-540-45748-8_24
   Gao HY, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P681, DOI 10.1145/1866307.1866396
   Gartner, 2018, DEF THREAT INT
   Guinard Dominique, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P702, DOI 10.1109/PERCOMW.2010.5470524
   Guinard D., 2009, WEB THINGS WEB MASHU
   Gunther Specht EvaZangerle., 2014, P 29 ANN ACM S APPL, P587
   Guo R, 2014, LECT NOTES COMPUT SC, V8422, P531, DOI 10.1007/978-3-319-05813-9_38
   Liu WY, 2018, CMC-COMPUT MATER CON, V55, P71, DOI 10.3970/cmc.2018.055.071
   Tran N, 2011, IEEE INFOCOM SER, P3218, DOI 10.1109/INFCOM.2011.5935171
   Sain SR, 1996, The nature of statistical learning theory, DOI 10.2307/1271324
   Wang Y, 2013, IEEE GLOB CONF SIG, P241, DOI 10.1109/GlobalSIP.2013.6736860
   Wu CR, 2018, CMC-COMPUT MATER CON, V54, P269, DOI 10.3970/cmc.2018.054.269
NR 15
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30257
EP 30270
DI 10.1007/s11042-018-7005-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200035
DA 2024-07-18
ER

PT J
AU Fan, MQ
AF Fan, MingQuan
TI A source coding scheme for authenticating audio signal with capability
   of self-recovery and anti-synchronization counterfeiting attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio fragile watermarking; Self-recovery; Set partitioning in
   hierarchical trees (SPIHT); Chaos; Synchronization counterfeiting attack
ID FRAGILE WATERMARKING SCHEME; ALGORITHM
AB Authenticating the veracity and integrity of digital media content is the most important application of fragile watermarking technique. Recently, fragile watermarking schemes for digital audio signals are developed to not only detect the malicious falsification, but also recover the tampered audio content. However, they are fragile against synchronization counterfeiting attack, which greatly narrows the applicability of audio watermarking schemes. In this paper, a novel source coding scheme for authenticating audio signal based on set partitioning in hierarchical trees (SPIHT) encoding and chaotic dynamical system with capability of self-recovery and anti-synchronization counterfeiting attack is proposed. For self-recovery feature, the compressed version of audio signal generated by SPIHT source coding and protected against maliciously tampering by repeated coding is embedded into the original audio signal. Besides, for robustness against synchronization counterfeiting attack feature, based on the position and content of audio section, check bits are generated by Hash algorithm and chaotic sequence, and taken as part of fragile watermark. Simulation results show the self-embedding audio authentication scheme is recoverable with proper audio quality, and it has capability against synchronization counterfeiting attack.
C1 [Fan, MingQuan] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Fan, MQ (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
EM mqfan_sc@163.com
CR [Anonymous], 1996, DUAL RATE SPEECH COD
   [Anonymous], AUD DAT
   Fan MQ, 2013, INT J COMPUT MATH, V90, P2588, DOI 10.1080/00207160.2013.805752
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Fan MQ, 2012, MULTIMED TOOLS APPL, V51, P2255
   Ghobadi A, 2013, INT CONF ADV COMMUN, P1077
   Hwang MJ, 2018, IEEE T MULTIMEDIA, V20, P45, DOI 10.1109/TMM.2017.2721642
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Liu J. X., 2009, IEEE T SIGNAL PROCES, V31, P395
   Liu ZH, 2017, MULTIMED TOOLS APPL, V76, P12481, DOI 10.1007/s11042-016-3664-z
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Park CM, 2007, PATTERN RECOGN LETT, V28, P931, DOI 10.1016/j.patrec.2006.12.010
   Qian Q, 2016, MULTIMED TOOLS APPL, V75, P13431, DOI 10.1007/s11042-015-2801-4
   Renza D, 2018, EXPERT SYST APPL, V91, P211, DOI 10.1016/j.eswa.2017.09.003
   Rigoni R, 2016, INFORM SCIENCES, V328, P127, DOI 10.1016/j.ins.2015.08.040
   Sarreshtedari S, 2015, IEEE-ACM T AUDIO SPE, V23, P1917, DOI 10.1109/TASLP.2015.2456431
   Su ZP, 2017, MULTIMED TOOLS APPL, V76, P9363, DOI 10.1007/s11042-016-3539-3
   Tang X, 2015, CHINESE J ELECTRON, V24, P492, DOI 10.1049/cje.2015.07.009
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Xiang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P529, DOI 10.1109/TASLP.2017.2782487
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yoshitomi Y., 2011, Journal of Information Security, V2, P59
NR 22
TC 3
Z9 3
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1037
EP 1055
DI 10.1007/s11042-019-08095-x
EA OCT 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000490223600002
DA 2024-07-18
ER

PT J
AU Goyal, N
   Gupta, K
   Kumar, N
AF Goyal, Neha
   Gupta, Kapil
   Kumar, Nitin
TI Multiclass Twin Support Vector Machine for plant species identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant recognition; Image segmentation; Feature extraction; Multiclass
   classification; TWSVM
ID FEATURES
AB Automatic plant species identification is one of the recent and fascinating research area as plants are crucial element of ecosystem. Several plant species exist with significant importance but most of us are unaware of the diversity of plant species available on earth. Their utility to humans starts as oxygen provider, food source, and medicinal compounds essential for medicines that are difficult to develop in right proportions. Being the first living habitants of earth, they have roots far deeper in the ecosystem than any living being. Hence, it is utmost important to develop automatic plant species identification system in which the digital image of the plant is given as input and the label of the plant is determined by the system. In this paper, we have focused on three different aspects (i) Significance of threshold (ii) Feature descriptor that can best describe the leaf images and (iii) Proposed a novel classification method called Multi class Twin Support Vector Machine which in an extension of widely used Twin Support Vector Machine classifier. The performance of the proposed method is compared with SVM, Multi Birth SVM and Probabilistic Neural Network. It is observed that the proposed classifier outperforms all the aforementioned classifiers on publicly available datasets.
C1 [Goyal, Neha; Gupta, Kapil] NIT, Kurukshetra, Haryana, India.
   [Kumar, Nitin] NIT, Dept Comp Sci & Engn, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Uttarakhand
RP Goyal, N (corresponding author), NIT, Kurukshetra, Haryana, India.
EM neha.goya12309@gmail.com; navkapil@gmail.com; nitin@nituk.ac.in
RI Gupta, Kapil/AAN-8584-2020; Goyal, Neha/AFH-8800-2022; Goyal,
   Neha/AAF-3497-2022; Kumar, Nitin/AAT-9454-2020
OI Gupta, Kapil/0000-0003-0264-948X; Goyal, Neha/0000-0002-7016-4663
FU University Grant Commission, India
FX We acknowledge University Grant Commission, India for supporting this
   research by providing fellowship to one of the author, Ms. Neha Goyal.
   We are also thankful to the reviewers for their valuable and
   constructive comments and suggestions for the paper. Their inputs have
   helped us in strengthening the overall quality of the paper.
CR Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003
   Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Arun Priya C., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P428, DOI 10.1109/ICPRIME.2012.6208384
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen S, 2012, CROSS DISCIPLINARY B, P183
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007
   Chen S, 2014, IEEE T IMAGE PROCESS, V23, P1629, DOI 10.1109/TIP.2013.2294548
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, EUR C COMP VIS, P428
   Dallimer M, 2012, BIOSCIENCE, V62, P47, DOI 10.1525/bio.2012.62.1.9
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Hsiao JK, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P389, DOI 10.1109/SAI.2014.6918216
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Kalyoncu C, 2015, COMPUT VIS IMAGE UND, V133, P102, DOI 10.1016/j.cviu.2014.11.001
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Pham NH, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P134, DOI 10.1109/ComManTel.2013.6482379
   Pilgrim SE, 2008, ECOLOGICAL KNOWLEDGE
   Punyasena SW, 2014, APPL PLANT SCI, V2, DOI 10.3732/apps.1400071
   Robinson BS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156572
   ROSENFELD A, 1983, IEEE T SYST MAN CYB, V13, P231, DOI 10.1109/TSMC.1983.6313118
   Rzanny M, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0245-8
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038
   SEZAN MI, 1990, COMPUT VISION GRAPH, V49, P36, DOI 10.1016/0734-189X(90)90161-N
   Sourceforge, 2017, FLAV LEAF REC ALG PL
   Sun Y, 2017, COMPUT INTELL NEUROS, V2017
   Tomar D, 2015, KNOWL-BASED SYST, V81, P131, DOI 10.1016/j.knosys.2015.02.009
   Trias-Blasi A, 2015, NATURE, V521, P161, DOI 10.1038/521161c
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Wäldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yang ZX, 2013, NEURAL COMPUT APPL, V22, pS153, DOI 10.1007/s00521-012-1108-x
   Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7
NR 33
TC 7
Z9 8
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27785
EP 27808
DI 10.1007/s11042-019-7588-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000046
DA 2024-07-18
ER

PT J
AU Guo, JM
   Riyono, D
   Prasetyo, H
AF Guo, Jing-Ming
   Riyono, Dwi
   Prasetyo, Heri
TI Hyperchaos permutation on false-positive-free SVD-based image
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE False-positive-free; Hyperchaos; Image watermarking; Permutation
ID COLOR IMAGES; ROBUST; TRANSFORM; SYSTEM; SECURITY
AB This paper reports the effect of hyperchaos permutation on the False-Positive-Free (FPF) Singular Value Decomposition (SVD)-based image watermarking scheme. To further improve the security aspect, the watermark image is firstly processed using the hyperchaos permutation before being embedded into the host image. In this scheme, only principal component of watermark image is inserted into the transformed host image to avoid the false positive problem. As reported in the experimental results, the proposed method satisfies the imperceptibility and robustness aspects. At the same time, the proposed method can suffer from the false positive problem which often occurs in the former existing SVD-based image watermarking schemes.
C1 [Guo, Jing-Ming; Riyono, Dwi] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
   [Prasetyo, Heri] Univ Sebelas Maret UNS, Dept Informat, Surakarta, Indonesia.
C3 National Taiwan University of Science & Technology; Sebelas Maret
   University
RP Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jmguo@seed.net.tw; rion_rh@yahoo.com; heri.prasetyo@staff.uns.ac.id
RI Prasetyo, Heri/AAD-2388-2022
OI Prasetyo, Heri/0000-0002-1257-4832
CR Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   Bhatnagar G, 2015, MULTIMED TOOLS APPL, V74, P8421, DOI 10.1007/s11042-013-1681-8
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Bhatnagar G, 2012, AEU-INT J ELECTRON C, V66, P275, DOI 10.1016/j.aeue.2011.08.005
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   El-Shafai W, 2018, MULTIMED TOOLS APPL, V77, P30911, DOI 10.1007/s11042-018-6036-z
   Guo JM, 2016, J VIS COMMUN IMAGE R, V35, P193, DOI 10.1016/j.jvcir.2015.12.016
   Guo JM, 2015, IEEE T MULTIMEDIA, V17, P1576, DOI 10.1109/TMM.2015.2449234
   Guo JM, 2015, IEEE T INTELL TRANSP, V16, P1989, DOI 10.1109/TITS.2014.2386535
   Guo JM, 2014, AEU-INT J ELECTRON C, V68, P816, DOI 10.1016/j.aeue.2014.03.008
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Mardanpour M, 2016, AEU-INT J ELECTRON C, V70, P790, DOI 10.1016/j.aeue.2016.03.004
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Sathya SPA, 2018, WIRELESS PERS COMMUN, V102, P2011, DOI 10.1007/s11277-018-5252-1
   Singh P, 2018, INFORM SCIENCES, V422, P77, DOI 10.1016/j.ins.2017.08.077
   Singh P, 2017, SIGNAL PROCESS-IMAGE, V57, P46, DOI 10.1016/j.image.2017.04.012
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Yen E, 2010, EXPERT SYST APPL, V37, P4033, DOI 10.1016/j.eswa.2009.09.032
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 23
TC 13
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29229
EP 29270
DI 10.1007/s11042-018-6767-x
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700046
DA 2024-07-18
ER

PT J
AU Hwang, H
   Lee, EC
AF Hwang, Hyeonsang
   Lee, Eui Chul
TI Determining the parameters of emotion by analyzing environmental images
   captured by a mobile device
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile app; Life-logging; Visual parameter; Color; Spatial complexity;
   Emotion
AB This paper proposes a method to quantitatively extract human emotions by analyzing images of the surrounding environment captured by a smartphone camera in real time. In the field of psychology, it is known that visual elements such as colors and complexity affect human emotions. Based on this knowledge, we developed an application for the extraction of emotions in real time using the colors and spatial complexity of images obtained with Android smartphones. Among the color components of images, the hue component, which indicates the color, is extracted as the color element and the spatial complexity is extracted by quantitatively determining the high- and low-frequency components that are visible in the images. The corresponding two-dimensional emotion is identified by using two support vector regression modules. The results show that the root-mean-square error between the estimated emotion and the subjectively evaluated emotion is approximately 0.36 on the -1 to +1 axes plane.
C1 [Hwang, Hyeonsang] Sangmyung Univ, Dept Comp Sci, Hongjimun 2 Gil 20, Seoul 03016, South Korea.
   [Lee, Eui Chul] Sangmyung Univ, Dept Intelligent Engn Informat Human, Hongjimun 2 Gil 20, Seoul 03016, South Korea.
C3 Sangmyung University; Sangmyung University
RP Lee, EC (corresponding author), Sangmyung Univ, Dept Intelligent Engn Informat Human, Hongjimun 2 Gil 20, Seoul 03016, South Korea.
EM hyeonsang92@naver.com; eclee@smu.ac.kr
RI JO, YOUSUB/AAE-7592-2020
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government(MSIT) [2015-0-00312]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIT)
   (No. 2015-0-00312, The development of technology for social life logging
   based on analyzing social emotion and intelligence of convergence
   contents).
CR Bradley MM, 2007, PSYCHOPHYSIOLOGY, V44, P364, DOI 10.1111/j.1469-8986.2007.00520.x
   Caprani N, 2014, INT J MOB HUM COMPUT, V6, P15, DOI 10.4018/ijmhci.2014010102
   Corchs SE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157986
   Elliot AJ, 2014, ANNU REV PSYCHOL, V65, P95, DOI 10.1146/annurev-psych-010213-115035
   Freedman D, 1988, Sociol Methodol, V18, P37, DOI 10.2307/271044
   Gupta R, 2016, HUM-CENT COMPUT INFO, V6, DOI 10.1186/s13673-016-0062-5
   Hair JF., 1998, UPPER SADDLE RIVER, V5, P207
   Hyeonsang Hwang, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P37, DOI 10.1007/978-981-10-5041-1_7
   Kaya N., 2004, COLL STUD J, V38, P396
   Mafrur R, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0049-7
   Mann S., 2003, SURVEILL SOC, V1, P331, DOI 10.24908/ss.v1i3.3344
   MITCHELL AA, 1986, J CONSUM RES, V13, P12, DOI 10.1086/209044
   Park Min Woo, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P91, DOI 10.1007/978-981-10-5041-1_16
   임지원, 2015, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V5, P107, DOI 10.14257/AJMAHS.2015.10.22
   Park MW, 2015, ADV COMPUTER SCI UBI, P201
   Paro JAM, 2015, ANN PLAS SURG, V74, pS71, DOI 10.1097/SAP.0000000000000423
   Pieters R, 2010, J MARKETING, V74, P48, DOI 10.1509/jmkg.74.5.48
   Rao LK, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0044-z
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Sellen A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P81
   Wolf K, 2014, IEEE PERVAS COMPUT, V13, P8, DOI 10.1109/MPRV.2014.53
NR 21
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28375
EP 28389
DI 10.1007/s11042-017-5342-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700002
DA 2024-07-18
ER

PT J
AU Zhao, ZF
   Han, S
   Kim, J
AF Zhao, Zhanfang
   Han, SungKook
   Kim, JuRi
TI R2LD: Schema-based Graph Mapping of relational databases to Linked Open
   Data for multimedia resources data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDF; Linked Open Data; direct mapping; SPARQL; SQL; Multimedia resources
ID WEB
AB The Web of Data used to share and interchange the diverse data of heterogeneous types on the Web has been actively established. Ontology-based Linked Open Data (LOD) that allows computers to understand and process data semantics has emerged to extend the current Web of Documents. LOD is important for the modeling of multimedia resources since it provides an efficient way for unstructured data resources. This paper proposes a noble and practical schema-based mapping method to populate Linked Open Data sets from relational databases for multimedia resources. The proposed schema-based mapping R2LD realizes the seamless mapping for RDB-to-RDF by taking advantage of the compatible conceptual schema. The schema-based mapping can resolve the complicated mapping issues in RDB-to-RDF, such as primary and foreign key relationships. The mapping description is straightforward and flexible. It can define mapping information in the form of attribute-value pairs. Especially, the proposed mapping method is suitable for the unstructured multimedia resources. The schema-based mapping R2LD provides an efficient way to implement SPARQL endpoint into RDB and preserve the performance of SQL, which is vital to the dissemination of LOD.
C1 [Zhao, Zhanfang] Hebei GEO Univ, Coll Informat Engn, Shijiazhuang 050031, Hebei, Peoples R China.
   [Han, SungKook] WonKwang Univ, Coll Convergence & Liberal Arts, Iksan 54538, Jeonbuk, South Korea.
   [Kim, JuRi] WonKwang Univ, Coll Liberal Arts, Dept Comp Engn, Iksan 54538, Jeonbuk, South Korea.
C3 Hebei GEO University; Wonkwang University; Wonkwang University
RP Kim, J (corresponding author), WonKwang Univ, Coll Liberal Arts, Dept Comp Engn, Iksan 54538, Jeonbuk, South Korea.
EM cyanic@wku.ac.kr
FU Wonkwang university
FX This paper was supported by Wonkwang university in 2017.
CR [Anonymous], W3C RDB2RDF INCUBATO, V1, P113
   Bizer C, 2009, IEEE INTELL SYST, V24, P87, DOI 10.1109/MIS.2009.102
   Boris Villazon-Terrazas M. H, 2012, R2RML DIRECT MAPPING
   Chebotko A, 2009, DATA KNOWL ENG, V68, P973, DOI 10.1016/j.datak.2009.04.001
   Erling O., 2008, REQUIREMENTS RELATIO
   Heath  T., 2011, SYNTHESIS LECT SEMAN, DOI [10.2200/S00334ED1V01Y201102WBE001, DOI 10.2200/S00334ED1V01Y201102WBE001, 10.2200/s00334ed1v01y201102wbe001]
   Hert M., 2011, P 7 INT C SEMANTIC S, P25, DOI [10.1145/2063518.2063522, DOI 10.1145/2063518.2063522]
   Hu W, 2014, ISWC LECT NOTES COMP, DOI [10. 1007/978-3-319-11964-9_1, DOI 10.1007/978-3-319-11964-9_1]
   Lee TB, 1998, RELATIONAL DATABASES
   Michel F., 2014, THESIS
   Sahoo SS, 2009, W3C RDB2RDF INCUBATO, V1, P113
   Sequeda J., 2012, em Proceedings of the 3rd International Conference on Ontology Patterns, V929, P97
   Spanos DE, 2012, SEMANT WEB, V3, P169, DOI 10.3233/SW-2011-0055
   W3C, 2012, R2RML RDB RDF MAPPIN
   W3C, 2012, DIRECT MAPPING RELAT
   W3C, 2013, SPARQL 1.1 query language
   W3C, 2014, RDF 1 1 PRIME
   W3C, 2010, USE CASES REQUIREMEN
   W3C Recommendation, 2012, DIRECT MAPPING RELAT
   Yoshimura KS, 2016, D LIB MAGAZINE, V22, P7
NR 20
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28835
EP 28851
DI 10.1007/s11042-019-7281-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700027
OA hybrid
DA 2024-07-18
ER

PT J
AU Dagadu, JC
   Li, JP
   Addo, PC
AF Dagadu, Joshua C.
   Li, Jian-Ping
   Addo, Prince C.
TI An image cryptosystem based on pseudorandomly enhanced chaotic DNA and
   random permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Logistic map; DNA coding; Random permutation; SHA-256
ID ENCRYPTION METHOD; SEQUENCE OPERATION; LOGISTIC MAP; ALGORITHM;
   SUBSTITUTION
AB We propose an image encryption scheme based on pseudorandomly enhanced logistic map, random permutation and deoxyribonucleic acid coding in this paper. The scheme consists of two main phases: permutation and diffusion. Firstly, a random pixel permutation phase is carried out by a random permutation function to enhance the diffusion and statistical performance. Secondly, a DNA-based diffusion is performed via randomly selected DNA algebraic operations between the randomly permuted image matrix and a chaotic key matrix to produce the cipher image. Pseudorandomly enhanced logistic map is used to produce the key matrix while the direct logistic map is used to select DNA encoding/decoding rules and DNA algebraic operations. The chaos maps are driven by a SHA-256 hash value of the plain image. Experimental results based on several analyses including statistical, differential, key analyses, etc. show that the proposed scheme achieves robust encryption and provides sufficient resistance to various forms of attacks.
C1 [Dagadu, Joshua C.; Li, Jian-Ping; Addo, Prince C.] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Dagadu, Joshua C.] Univ Educ, Winneba, Ghana.
C3 University of Electronic Science & Technology of China
RP Dagadu, JC (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.; Dagadu, JC (corresponding author), Univ Educ, Winneba, Ghana.
EM joscaldag@yahoo.com
RI li, jianping/A-9544-2012
OI Addo, Prince/0000-0002-8105-7222; Li, Jian Ping/0000-0003-2192-1450
FU National Natural Science Foundation of China [61370073]; National High
   Technology Research and Development Program of China [2007AA01Z423];
   project of Science and Technology Department of Sichuan Province
FX This paper was supported by the National Natural Science Foundation of
   China (Grant No. 61370073), the National High Technology Research and
   Development Program of China (Grant No. 2007AA01Z423), the project of
   Science and Technology Department of Sichuan Province.
CR Al-Husainy MAF, 2012, INT J SECUR APPL, V6, P1
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Andrecut M, 1998, INT J MOD PHYS B, V12, P921, DOI 10.1142/S021797929800051X
   Askar SS, 2015, Math Probl Eng, V2015
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chakraborty S, 2016, INT J SECUR APPL, V10, P205, DOI 10.14257/ijsia.2016.10.2.19
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen SL, 2010, IEEE T CIRCUITS-II, V57, P996, DOI 10.1109/TCSII.2010.2083170
   El-Alfy ES. M., 2015, Advances in Intelligent Informatics
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   IEEE, 2019, 754-2019-IEEE Standard for Floating-Point Arithmetic, P1, DOI [10.1109/IEEESTD.2019.8766229, DOI 10.1109/IEEESTD.2019.8766229]
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mao Y, 2005, HDB GEOMETRIC COMPUT
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Norouzi B, 2017, OPTIK, V140, P946, DOI 10.1016/j.ijleo.2017.04.103
   Parvees MYM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0611-5
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Penard W, 2008, TECH REP
   PHATAK SC, 1995, PHYS REV E, V51, P3670, DOI 10.1103/PhysRevE.51.3670
   Prasanna S, 2000, P ECCAP, P99
   Praveenkumar P, 2017, MULTIMED TOOLS APPL, P1
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   WATSON JP, 1974, NATURE, V247, P74, DOI 10.1038/247074a0
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
NR 42
TC 16
Z9 16
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24979
EP 25000
DI 10.1007/s11042-019-7693-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900059
DA 2024-07-18
ER

PT J
AU Mohapatra, D
   Patra, MR
AF Mohapatra, Debasis
   Patra, Manas Ranjan
TI Anonymization of attributed social graph using anatomy based clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attributed social graph; Privacy preservation; Anonymization; Anatomy;
   Clustering
ID K-ANONYMITY; NETWORKS; PRIVACY; SELECTION; UTILITY
AB A social graph is a common way to publish a social network, but such publication poses privacy risks. In this paper, we use attributed social graph as a graph model to represent the original social network. Therefore, anonymization of descriptive as well as structural data is essential to meet the privacy requirement. Cluster based anonymization is one of the anonymization approaches that provides privacy preservation in social network publication. Though most of the previous work like SaNGreeA (SNG) and Sequential Clustering (SC) employ generalization based clustering, we propose an Anatomy based Clustering (AC) that retains the data originality since it doesn't suppress or generalize any value. Therefore, the proposed approach provides higher utility than the existing approaches. Consequently, the information loss in AC is found to be lower than SNG and SC. We propose a Modified Anatomy based Clustering (MAC) which ensures better preservation of ground-truth community than AC. The algorithms are tested on Attributed Networks (ANs) that are created by the proposed Network Generator algorithm. According to information loss and information gain based community preservation, MAC is found to be the best among the four algorithms i.e., SNG, SC, AC, and MAC.
C1 [Mohapatra, Debasis] Parala Maharaja Engn Coll, Dept CSE, Brahmapur 7671003, Odisha, India.
   [Patra, Manas Ranjan] Berhampur Univ, Dept Comp Sci, Brahmapur 760007, Odisha, India.
C3 Berhampur University
RP Mohapatra, D (corresponding author), Parala Maharaja Engn Coll, Dept CSE, Brahmapur 7671003, Odisha, India.
EM devdisha@gmail.com; mrpatra12@gmail.com
CR [Anonymous], 2008, PINKDD
   Babu KS, 2013, TRANS DATA PRIV, V6, P1
   Babu KS, 2013, COMPUT ELECTR ENG, V39, P1947, DOI 10.1016/j.compeleceng.2013.01.020
   Casas-Roma J, 2017, KNOWL INF SYST, V50, P447, DOI 10.1007/s10115-016-0947-7
   Chester S, 2011, ADBIS 2011 RES COMMU, V789, P107
   De Salve A, 2018, MOBILE NETW APPL, V23, P1715, DOI 10.1007/s11036-018-1067-2
   El Emam K, 2009, J AM MED INFORM ASSN, V16, P670, DOI 10.1197/jamia.M3144
   Fung Benjamin C. M., 2010, Introduction to Privacy-Preserving Data Publishing: Concepts and Techniques
   Goldberger J, 2010, TRANS DATA PRIV, V3, P149
   Han Jiawei, 2006, DATA MINING CONCEPTS, P402
   Kapron B, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P155, DOI 10.1109/ASONAM.2011.108
   Khoshgoftaar TM, 2006, TWELFTH ISSAT INTERNATIONAL CONFERENCE RELIABILITY AND QUALITY IN DESIGN, PROCEEDINGS, P139
   Largeron C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122777
   Lee H, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0499-0
   LeFevre K, 2005, INT C ACM SPEC INT G
   LeFevre K., 2006, P 22 INT C DAT ENG I, P25, DOI DOI 10.1109/ICDE.2006.101
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Li TC, 2012, IEEE T KNOWL DATA EN, V24, P561, DOI 10.1109/TKDE.2010.236
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Liu KQ, 2008, CONF REC ASILOMAR C, P93, DOI 10.1109/ACSSC.2008.5074369
   Liu K, 2009, CH CRC DATA MIN KNOW, P419
   Machanavajjhala A, 2007, ACM T KNOWL DISCOV D, V1, P1, DOI DOI 10.1145/1217299.1217302
   Mohapatra D, 2017, SOC NETW ANAL MIN, V7, DOI 10.1007/s13278-017-0470-1
   Mohapatra D, 2015, LECT NOTES COMPUT SC, V8956, P299, DOI 10.1007/978-3-319-14977-6_29
   Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Sweeney L, 1997, COMPUTATIONAL DISCLO
   Tassa T, 2013, IEEE T KNOWL DATA EN, V25, P311, DOI 10.1109/TKDE.2011.232
   Wong R.C., 2006, ACM SIGKDD INT C KNO
   Wu W., 2010, P 13 INT C EXT DAT T, P111
   Zheleva E, 2008, LECT NOTES COMPUT SC, V4890, P153
   Zhou B, 2008, PROC INT CONF DATA, P506, DOI 10.1109/ICDE.2008.4497459
NR 34
TC 8
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25455
EP 25486
DI 10.1007/s11042-019-07745-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700011
DA 2024-07-18
ER

PT J
AU Tian, YM
   Li, Q
   Wang, D
   Wan, B
AF Tian, Yumin
   Li, Qiang
   Wang, Di
   Wan, Bo
TI Robust joint learning network: improved deep representation learning for
   person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep learning; Representation learning; Joint
   learning
AB Existing person re-identification methods, which based on deep representation learning, mostly only focus on either global feature or local feature. This obviously ignores the joint advantages and the correlation between global and local features. In this paper, we test and verify the benefits of jointly learning local and global features in a network based on the Convolutional Neural Network (CNN). Specifically, we give distinct weights to global loss and local loss when considering their different influence on our research, then we innovatively combine two losses into one loss. Besides, we propose a novel and strong network to learn part-level features with unified partition. Experimental results on three person ReID data sets, show that our method outperforms existing deep learning methods.
C1 [Tian, Yumin; Li, Qiang; Wang, Di; Wan, Bo] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Wang, D (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM wangdi@xidian.edu.cn
RI LI, QI/IUM-8577-2023
FU National Natural Science Foundation of China [61702394, 61572385,
   61711530248]; Postdoctoral Science Foundation of China [2018T111021,
   2017M613082]; Science and Technology Project of Shaanxi Province
   [2016GY-033]; Shaanxi Key Research and Development Program
   [2017ZDXM-GY-002]; Aeronautical Science Foundation of China
   [20171981008]; Fundamental Research Funds for the Central Universities
   [JBX170313, XJS17063, JBF180301]
FX This paper was supported in part by the National Natural Science
   Foundation of China under Grant 61702394, Grant 61572385 and Grant
   61711530248, in part by the Postdoctoral Science Foundation of China
   under Grant 2018T111021 and Grant 2017M613082, in part by the Science
   and Technology Project of Shaanxi Province under Grant 2016GY-033, in
   part by the Shaanxi Key Research and Development Program under Grant
   2017ZDXM-GY-002, in part by the Aeronautical Science Foundation of China
   under Grant 20171981008, and in part by the Fundamental Research Funds
   for the Central Universities under Grant JBX170313, Grant XJS17063 and
   Grant JBF180301.
CR [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2016, CVPR
   [Anonymous], 2013, TPAMI
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, ARXIV
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], 2017, ICCV
   [Anonymous], P INT ACM SIGIR C
   [Anonymous], CVPR
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], CONSISTENT RE IDENTI
   [Anonymous], 2015, ARXIV151205300
   [Anonymous], 2017, ARXIV170700798
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, ECCV
   [Anonymous], 2016, ARXIV
   [Anonymous], 2016, ECCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, ECCV
   [Anonymous], 2016, EUR C COMP VIS WORKS
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, ICCV
   [Anonymous], 2016, arXiv preprint arXiv:1611.05244
   [Anonymous], 2008, ECCV
   [Anonymous], 2016, WACV
   [Anonymous], 2018, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, IJCAI
   [Anonymous], 2015, ICCV
   [Anonymous], 2016, NIPS
   [Anonymous], 2015, CVPR
   [Anonymous], 2014, CVPR
   [Anonymous], ABS160204433 CORR
   [Anonymous], 2017, EUROPEAN C COMPUTER
   [Anonymous], 2016, ECCV
   [Anonymous], CORR
   [Anonymous], 2017, ACM MULTIMEDIA
   [Anonymous], 2011, BMVC
   [Anonymous], 2016, COMPUTER VISION PATT
   [Anonymous], 2016, CORR
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen Y., 2017, INT C COMP VIS WORKS
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, CVPR, V2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsia CY, 2017, PROCEEDINGS OF THE 20TH PACIFIC BASIN NUCLEAR CONFERENCE, VOL 1, P571, DOI 10.1007/978-981-10-231-8_53
   Karanam S., 2016, ARXIV PREPRINT ARXIV
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Leibe B., 2017, ARXIV170307737CS
   Li J, 2018, IEEE Transactions on Cybernetics, V99, P12
   Li Z, 2017, IEEE Trans Knowl Data Eng, V99, p1 1
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu X., 2017, ICCV
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Martinel N, 2016, LECT NOTES COMPUT SC, V9908, P858, DOI 10.1007/978-3-319-46493-0_52
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Xiang T., 2017, ARXIV170500384
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu CC, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P420, DOI 10.1109/ICWS.2017.48
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zeng C, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1, DOI 10.1109/IAEAC.2017.8053964
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zheng L., 2017, IEEE T IMAGE PROCESS
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE PHOT SPEC CONF, P721, DOI 10.1109/PVSC.2017.8366628
NR 73
TC 11
Z9 12
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24187
EP 24203
DI 10.1007/s11042-018-6998-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900022
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, Z
   Zhang, LB
   Sun, FZ
   Wang, L
   Liu, SS
AF Wang, Zhen
   Zhang, Long-Bo
   Sun, Fu-Zhen
   Wang, Lei
   Liu, Shu-Shu
TI Relative similarity preserving bitwise weights generated by an adaptive
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary codes; Bitwise weights; Adaptive scheme; Relative similarity
   preserving
ID CODE RANKING; IMAGE SEARCH; BINARY; QUANTIZATION
AB Due to its high query speed and low storage cost, binary hashing has been widely used in approximate nearest neighbors (ANN) search. However, the binary bits are generally considered to be equal, which causes data points with different codes to share the same Hamming distance to the query sample. To solve the above distance measure ambiguity, bitwise weights methods were proposed. Unfortunately, in most of the existing methods, the bitwise weights and the binary codes are learnt separately in two stages, and their performances cannot be further improved. In this paper, to effectively address the above issues, we propose an adaptive mechanism that jointly generate the bitwise weights and the binary codes by preserving different types of similarity relationship. As a result, the binary codes are utilized to obtain the initial retrieval results, and they are further re-ranked by the weighted Hamming distance. This ANN search mechanism is termed AR-Rank in this paper. First, this joint mechanism allows the bitwise weights and the binary codes to be used as mutual feedback during the training stage, and they are well adapted to one other when the algorithm converges. Furthermore, the bitwise weights are required to preserve the relative similarity which is consistent with the nature of ANN search task. Thus, the data points can be accurately re-sorted based on the weighted Hamming distances. Evaluations on three datasets demonstrate that the proposed AR-Rank retrieval system outperforms nine state-of-the-art methods.
C1 [Wang, Zhen; Zhang, Long-Bo; Sun, Fu-Zhen; Wang, Lei; Liu, Shu-Shu] Shandong Univ Technol, Sch Comp Sci & Technol, Zibo, Peoples R China.
C3 Shandong University of Technology
RP Sun, FZ (corresponding author), Shandong Univ Technol, Sch Comp Sci & Technol, Zibo, Peoples R China.
EM zhwang@sdut.edu.cn; zhanglb@sdut.edu.cn; sunfuzhen@sdut.edu.cn;
   wanglei0511@sdut.edu.cn; lsszyt@sdut.edu.cn
RI Wang, Zhiqiang/AAO-7592-2021
FU National Natural Science Foundation of China [61841602]; Natural Science
   Foundation of Shandong Province of China [ZR2018PF005]; Doctoral
   Research Foundation of Shandong University of Technology [4041417009]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61841602), the Natural Science Foundation of Shandong
   Province of China (Grant No. ZR2018PF005) and the Doctoral Research
   Foundation of Shandong University of Technology (Grant No. 4041417009).
CR [Anonymous], 2012, Advances in neural information processing systems
   Cheng ZY, 2016, MULTIMEDIA SYST, V22, P509, DOI 10.1007/s00530-014-0432-7
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fu HY, 2016, MULTIMED TOOLS APPL, V75, P1391, DOI 10.1007/s11042-014-2087-y
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   He M, 2014, WINT SIMUL C PROC, P1005, DOI 10.1109/WSC.2014.7019960
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang Y, 2011, ASIAN LAW S, P1
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Liu W, 2012, P 2012 INT C MACH LE
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Silpa-Anan C., 2008, [39] C. Silpa-Anan and R. Hartley, "Optimized KD-trees for fast image descriptor matching", IEEE Conf. on Computer Vision and Pattern Recognition, 2008, pp. 1-8., P1, DOI [DOI 10.1109/CVPR.2008.4587638, 10.1109/CVPR.2008.4587638]
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Terasawa K, 2007, LECT NOTES COMPUT SC, V4619, P27
   Wang Jianfeng., 2013, ACM Multimedia, P133
   Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Xia Y, 2015, PROC CVPR IEEE, P3332, DOI 10.1109/CVPR.2015.7298954
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Zhang J, 2016, ARXIV161202541
   Zhang L, 2013, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2013.208
   Zhang X, 2012, PROC CVPR IEEE, P2058, DOI 10.1109/CVPR.2012.6247910
   Zhang X, 2016, CHIN CONTR CONF, P5223, DOI 10.1109/ChiCC.2016.7554167
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE PHOT SPEC CONF, P721, DOI 10.1109/PVSC.2017.8366628
NR 36
TC 0
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24453
EP 24472
DI 10.1007/s11042-018-6997-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900035
DA 2024-07-18
ER

PT J
AU You, XY
   Tian, F
   Tang, W
AF You, Xiangyu
   Tian, F.
   Tang, W.
TI Highly efficient facial blendshape animation with analytical dynamic
   deformations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial blendshapes; Physics-based facial animation; Dynamic
   deformations; Equation of motion; Analytical solutions
AB Adding physics to facial blendshape animation is an active research topic. Existing physics-based approaches of facial blendshape animation are numerical, so they require special knowledge and skills, additional preprocess, large computer capacity, and expensive calculations leading to low animation frame rates, and are not easy to learn, implement and use. To tackle these problems, we propose an analytical approach and develop a blending force-based framework for physics-based facial animation. The proposed approach introduces the equation of motion to consider inertial effects, damping effects and the resistance against deformations, combines them with source and target facial shapes to formulate the mathematical model of dynamic deformations, and develops a simple and efficient closed-form solution. The blending force-based framework incorporates the new proposed slider force-based, exponentiation force-based and random force-based methods built on the obtained closed form solution to achieve highly efficient facial animation. Compared with facial blendshape animation using geometric linear interpolation, the proposed approach is physics-based. It not only creates all the blended shapes generated by linear interpolation, but also a much larger superset of blended shapes. Unlike linear interpolation which can only generate blended shapes with a same deformation rate, the proposed approach can generate blended shapes with different deformation rates, resulting in special effects of acceleration and deceleration. Compared to existing physics-based approaches of facial blendshape animation which are numerical, the proposed approach is the first time to develop an analytical approach of physics-based facial blendshapes. It does not require any special knowledge and skills and is easy to learn, implement and use. More importantly, it can avoid the additional preprocess of numerical methods and create various physics-based facial blendshape animations highly efficiently. Moreover, it can be used to estimate physical parameters from real shapes and developed into an interactive and real-time physics-based shape manipulation tool.
C1 [You, Xiangyu; Tian, F.; Tang, W.] Bournemouth Univ, Fac Sci & Technol, Dept Creat Technol, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP You, XY (corresponding author), Bournemouth Univ, Fac Sci & Technol, Dept Creat Technol, Poole BH12 5BB, Dorset, England.
EM xyou@bournemouth.ac.uk
CR Akhter I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159523
   [Anonymous], SIGGRAPH 85 TUTORIAL
   Bächer M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185543
   Barrielle V, 2016, COMPUT GRAPH FORUM, V35, P341, DOI 10.1111/cgf.12836
   Hahn F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185568
   Ichim AE, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073664
   Keeve E, 1996, IEEE VISUAL, P21, DOI 10.1109/VISUAL.1996.567595
   Kim M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073685
   KOCH R.M., 1996, P SIGGRAPH, P421
   Kozlov Y, 2017, COMPUT GRAPH FORUM, V36, P75, DOI 10.1111/cgf.13108
   Lee YY, 1995, OREGON CONFERENCE MONOGRAPH 1995, VOL 7, FEBRUARY 1995, P55
   Lewis JP, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462019
   Liu XC, 2011, COMPUT GRAPH FORUM, V30, P1655, DOI 10.1111/j.1467-8659.2011.01852.x
   Ma W-G, 2011, P SIGGRAPH AS 2011
   Ma WC, 2012, COMPUT ANIMAT VIRT W, V23, P235, DOI 10.1002/cav.1441
   Mora H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164694
   Noh J-Y, 1999, USCTR99705, P1
   Park S, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION 2007, VOL 5, P1, DOI 10.1145/13606121360695
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   Seo J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024198
   Seol Y, 2012, VISUAL COMPUT, V28, P319, DOI 10.1007/s00371-011-0641-4
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Tu PH, 2004, J COMPUT SCI TECH-CH, V19, P618, DOI 10.1007/BF02945587
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Warburton M, 2015, COMPUT ANIMAT VIRT W, V26, P55, DOI 10.1002/cav.1565
   Waters K, 1993, CAMBRIDGE RES LAB TE, P1
NR 31
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25569
EP 25590
DI 10.1007/s11042-019-7671-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700015
DA 2024-07-18
ER

PT J
AU Zareapoor, M
   Yang, J
   Jain, DK
   Shamsolmoali, P
   Jain, N
   Kant, S
AF Zareapoor, Masoumeh
   Yang, Jie
   Jain, Deepak Kumar
   Shamsolmoali, Pourya
   Jain, Neha
   Kant, Surya
TI Deep semantic preserving hashing for large scale image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional auto-encoder; Image hashing; Image retrieval; Deep
   learning; Similarity search; Learning to hash
ID ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH; ALGORITHMS
AB Hashing approaches have got a great attention because of its efficient performance for large-scale images. This paper, aims to propose a deep hashing method which can combines stacked convolutional autoencoder with hashing learning, where the input image hierarchically maps to the low dimensional space. The proposed method DCAH contains encoder-decoder, and supervisory sub-network, that generates a low dimensional binary code in a layer-wised manner of the deep conventional neural network. To optimizing the hash algorithm, we added some extra relaxations constraint to the objective function. In our extensive experiments on ultra-high dimensional image datasets, our results demonstrate that the decoder structure can improve the hashing method to preserve the similarities in hashing codes; also, DCAH achieves the best performance comparing to other states of the art approaches.
C1 [Zareapoor, Masoumeh; Yang, Jie; Shamsolmoali, Pourya] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Jain, Deepak Kumar] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Jain, Neha] Jaypee Univ Engn & Technol, Guna, India.
   [Kant, Surya] India Inst Technol, Roorkee, Uttar Pradesh, India.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Roorkee
RP Zareapoor, M; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM mzarea222@gmail.com; jieyang@sjtu.edu.cn
RI Zareapoor, Dr. Masoumeh/AAE-6067-2019; Yang, Jie/JCD-9867-2023
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61603171]; 863 PlanChina [2015AA042308]
FX This research was supported by NSFC, China (No: 61603171) and 863
   PlanChina (No. 2015AA042308).
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Alvear-Sandoval RF, 2018, INFORM FUSION, V39, P41, DOI 10.1016/j.inffus.2017.03.008
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], ANAL BIOANAL CHEM
   [Anonymous], 2009, TR2009 U TOR
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], 2014, NIPS
   [Anonymous], 2016, P 29 C NEUR INF PROC
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], INT C LEARN REPR
   [Anonymous], ICIP C
   [Anonymous], 2016, ARXIV
   [Anonymous], 2009, NIPS
   [Anonymous], 2015, CVPR
   [Anonymous], 2016, AAAI
   Chollet F, 2015, KERAS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding KM, 2018, ALGORITHMS, V11, DOI 10.3390/a11010006
   Doersch C., 2016, CORR
   Dong Z, 2016, AAAI CONF ARTIF INTE, P3471
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu L, 2016, IEEE T NEUR NET LEAR, V27, P2526, DOI 10.1109/TNNLS.2015.2495345
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shao J, 2012, PATTERN RECOGN LETT, V33, P271, DOI 10.1016/j.patrec.2011.10.018
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang J, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717696506
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Xia R, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY (POWERCON), P1521, DOI 10.1109/POWERCON.2014.6993796
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Zareapoor M, 2018, PATTERN RECOGN LETT, V115, P4, DOI 10.1016/j.patrec.2017.09.018
NR 44
TC 10
Z9 10
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23831
EP 23846
DI 10.1007/s11042-018-5970-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900003
DA 2024-07-18
ER

PT J
AU Abbas, Q
   Celebi, ME
AF Abbas, Qaisar
   Celebi, M. Emre
TI DermoDeep-A classification of melanoma-nevus skin lesions using
   multi-feature fusion of visual features and deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Digital dermoscopy; Computer-aided diagnosis system;
   Perceptual-oriented color space; Multi-feature fusion; Color features;
   Deep learning; Deep neural networks; Recurrent neural networks
ID COMPUTER-AIDED DIAGNOSIS; COLOR-DIFFERENCE FORMULA; DERMOSCOPY IMAGES;
   DECISION-SUPPORT; SYSTEM; ALGORITHM; DERMATOSCOPY; ATTRIBUTES;
   CIEDE2000; TEXTURE
AB The Scientific community has been developing computer-aided detection systems (CADs) for automatic diagnosis of pigmented skin lesions (PSLs) for nearly 30 years. Several works have addressed this issue and obtained encouraging results, however, there has not been much focus on the pre-processing step, determining the relevance of the features considered and how they may be important indicators of a lesion's malignancy. To differentiate between nevus and melanoma skin lesions, the development of CAD system is a challenging task due to the use of inaccurate image processing techniques. In this paper, a new classification system is developed for PSLs known as DermoDeep through a fusion of multiple visual features and deep-neural-network approach. A new aggregation of visual features along with descriptors are extracted in a perceptual-oriented color space. Moreover, a new five-layer architecture based DermoDeep system is proposed. This DermoDeep system applied on 2800 region-of-interest (ROI) PSLs including 1400 nevus and 1400 malignant lesions. The classification accuracy of DermoDeep system is compared with the state-of-the-art methods and evaluated by the sensitivity (SE), specificity (SP) and area under the receiver operating characteristics (AUC) curve. The difference between AUC of DermoDeep is statistically significant compared to other techniques with AUC: 0.96 (p < 0.001), SE of 93% and SP of 95%. The obtained results demonstrate that the DermatDeep can be used to assist dermatologists during a screening process.
C1 [Abbas, Qaisar] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, FR 85, PO 5701, Riyadh 11432, Saudi Arabia.
   [Celebi, M. Emre] Univ Cent Arkansas, Dept Comp Sci, Conway, AR USA.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU); University of Central
   Arkansas
RP Abbas, Q (corresponding author), Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, FR 85, PO 5701, Riyadh 11432, Saudi Arabia.
EM qaisarabbasphd@gmail.com; ecelebi@uca.edu
RI Muhammad Abas, Qaisar Abbas/ABI-6501-2020; Abbas, Qaisar/AAC-9673-2021;
   Muhammad Abas, Qaisar Abbas/GPX-7906-2022; Celebi, M. Emre/G-2129-2012
OI Muhammad Abas, Qaisar Abbas/0000-0002-0361-1363; Muhammad Abas, Qaisar
   Abbas/0000-0002-0361-1363; Celebi, M. Emre/0000-0002-2721-6317
FU Al Imam Mohammad Ibn Saud Islamic University (IMSIU) [360905]
FX This study was funded by Al Imam Mohammad Ibn Saud Islamic University
   (IMSIU) (grant number 360905).
CR Abbas Q, 2016, COMPUTERS, V5, DOI 10.3390/computers5030013
   Abbas Q, 2013, SKIN RES TECHNOL, V19, pE93, DOI 10.1111/j.1600-0846.2012.00614.x
   Abbas Q, 2013, PATTERN RECOGN, V46, P86, DOI 10.1016/j.patcog.2012.07.027
   Al Aghbari Z, 2006, IMAGE VISION COMPUT, V24, P894, DOI 10.1016/j.imavis.2006.02.013
   Barata C, 2017, PATTERN RECOGN, V69, P270, DOI 10.1016/j.patcog.2017.04.023
   Barata C, 2016, COMPUT VIS IMAGE UND, V151, P124, DOI 10.1016/j.cviu.2015.09.011
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Barata C, 2012, IEEE T BIO-MED ENG, V59, P2744, DOI 10.1109/TBME.2012.2209423
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Blum A, 2004, BRIT J DERMATOL, V151, P1029, DOI 10.1111/j.1365-2133.2004.06210.x
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   Celebi ME, 2014, IEEE SYST J, V8, P980, DOI 10.1109/JSYST.2014.2313671
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Demyanov S, 2016, I S BIOMED IMAGING, P364, DOI 10.1109/ISBI.2016.7493284
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Dreiseitl S, 2005, ARTIF INTELL MED, V33, P25, DOI 10.1016/j.artmed.2004.07.007
   Ferris LK, 2015, J AM ACAD DERMATOL, V73, P769, DOI 10.1016/j.jaad.2015.07.028
   Fornaciali M, 2016, AUTOMATED MELANOMA S
   Garnavi R, 2012, IEEE T INF TECHNOL B, V16, P1239, DOI 10.1109/TITB.2012.2212282
   GRAVES A, 2013, CORR, DOI [DOI 10.1109/ICASSP.2013.6638947, 10.1109/ICASSP.2013.6638947. U R L, 10.1109/ICASSP.2013.6638947]
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu HJ, 2016, NEUROCOMPUTING, V181, P86, DOI 10.1016/j.neucom.2015.05.134
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   International Skin Imaging Collaboration, 2017, ISIC 2017 SKIN LESIO
   Ishihara Y, 2006, AM J DERMATOPATH, V28, P21, DOI 10.1097/01.dad.0000187931.05030.a0
   Iyatomi H, 2008, COMPUT MED IMAG GRAP, V32, P566, DOI 10.1016/j.compmedimag.2008.06.005
   Iyatomi H, 2008, J INVEST DERMATOL, V128, P2049, DOI 10.1038/jid.2008.28
   Jaworek-Korjakowska J, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8934242
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Keren G, 2016, IEEE IJCNN, P3412, DOI 10.1109/IJCNN.2016.7727636
   Lingala M, 2014, COMPUT MED IMAG GRAP, V38, P403, DOI 10.1016/j.compmedimag.2014.03.007
   Liu D, 2018, PATTERN RECOGNITION
   Liu LC, 2018, IEEE T IMAGE PROCESS, V27, P4345, DOI 10.1109/TIP.2018.2831454
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Liu MF, 2016, NEUROCOMPUTING, V208, P127, DOI 10.1016/j.neucom.2016.01.096
   LIU W, 2015, PROC CVPR IEEE, V2015, P3707
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Z, 2012, MED BIOL ENG COMPUT, V50, P503, DOI 10.1007/s11517-012-0895-7
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   Ma Z, 2017, EXPERT SYST APPL, V84, P92, DOI 10.1016/j.eswa.2017.05.003
   McDonald R, 1995, J SOC DYERS COLOUR, V111, P376
   Md F, 2005, COLOR APPEARANCE MOD, V82
   Melgosa M, 2004, J OPT SOC AM A, V21, P2269, DOI 10.1364/JOSAA.21.002269
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Mirzaalian H, 2016, MED IMAGE ANAL, V27, P84, DOI 10.1016/j.media.2015.03.001
   Mishra N.K., 2016, An Overview of Melanoma Detection in Dermoscopy Images Using Image Processing and Machine Learning
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Oliveira RB, 2016, EXPERT SYST APPL, V61, P53, DOI 10.1016/j.eswa.2016.05.017
   Pathan S, 2018, BIOMED SIGNAL PROCES, V39, P237, DOI 10.1016/j.bspc.2017.07.010
   Premaladha J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0460-2
   Rosendahl C, 2011, J AM ACAD DERMATOL, V64, P1068, DOI 10.1016/j.jaad.2010.03.039
   Ruiz D, 2011, EXPERT SYST APPL, V38, P15217, DOI 10.1016/j.eswa.2011.05.079
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sadeghi M, 2013, IEEE T MED IMAGING, V32, P849, DOI 10.1109/TMI.2013.2239307
   Sadri AR, 2017, IET IMAGE PROCESS, V11, P475, DOI 10.1049/iet-ipr.2016.0681
   Sáez A, 2014, IEEE T MED IMAGING, V33, P1137, DOI 10.1109/TMI.2014.2305769
   Schanda J, 2007, INT COMMISSION ILLUM
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shimizu K, 2015, IEEE T BIO-MED ENG, V62, P274, DOI 10.1109/TBME.2014.2348323
   Soyer HP, 2000, Interactive atlas of dermoscopy
   Stoecker WV, 2011, COMPUT MED IMAG GRAP, V35, P144, DOI 10.1016/j.compmedimag.2010.09.005
   Thomas S, 2013, INT CONF ACOUST SPEE, P6704, DOI 10.1109/ICASSP.2013.6638959
   Unlu E, 2014, J DERMATOL, V41, P598, DOI 10.1111/1346-8138.12491
   Wang B, 2018, LECT NOTES COMPUT SC, V11071, P759, DOI 10.1007/978-3-030-00934-2_84
   Yoshida T, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3439, DOI 10.1109/BigData.2016.7841005
   Zortea M, 2014, ARTIF INTELL MED, V60, P13, DOI 10.1016/j.artmed.2013.11.006
NR 70
TC 46
Z9 46
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23559
EP 23580
DI 10.1007/s11042-019-7652-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400060
DA 2024-07-18
ER

PT J
AU Dad, N
   En-nahnahi, N
   Ouatik, SE
AF Dad, Nisrine
   En-nahnahi, Noureddine
   Ouatik, Said El Alaoui
TI Quaternion Harmonic moments and extreme learning machine for color
   object recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion algebra; Color image feature extraction; Disc-Harmonic
   moments; Zernike moments; Spherical harmonics; Color object recognition;
   Back-propagation neural networks; Extreme learning machine
ID INVARIANT IMAGE RECOGNITION; FACE RECOGNITION; COMPUTATION; TRANSFORMS
AB The quaternary orthogonal moments have been widely used as color image descriptors owe to their remarkable color and shape information encapsulation capability. Their computation, however, depends on finding the optimal value of a unit pure quaternion parameter, which is done empirically and with no warranty of optimality. We propose a 2D color object recognition method that relies on the quaternion-valued parameter-free disc-harmonic moment invariants (QHMs) fed into the quaternion extreme learning machine (QELM). The role of this latter is to maintain the correlation between the four parts, real and imaginary, of the quaternary descriptor coefficients. Several datasets are used for recognition experiments. We draw the conclusion that: (1) our quaternion-valued QHMs invariants outperform other quaternary moments, (2) the quaternion-valued moment invariants give results better than the modulus-based moment invariants and (3) the QELM yields results better than the state-of-the-art classifiers.
C1 [Dad, Nisrine; En-nahnahi, Noureddine; Ouatik, Said El Alaoui] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Lab Informat & Modeling, PB 1796, Fes 30003, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Dad, N (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Lab Informat & Modeling, PB 1796, Fes 30003, Morocco.
EM nisrine.dad@usmba.ac.ma; noureddine.en-nahnahi@usmba.ac.ma;
   said.ouatikelalaoui@usmba.ac.ma
RI EN NAHNAHI, Noureddine/ABU-8379-2022
OI EN NAHNAHI, Noureddine/0000-0003-1641-1501; OUATIK EL ALAOUI,
   Said/0000-0003-1194-0578
CR [Anonymous], 3D MODEL RETRIEVAL S
   [Anonymous], 1996, DESCRIPTION LIBOR SP
   Arena P, 1997, NEURAL NETWORKS, V10, P335, DOI 10.1016/S0893-6080(96)00048-2
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Burel G, 1995, GRAPH MODEL IM PROC, V57, P400, DOI 10.1006/gmip.1995.1034
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen BJ, 2014, APPL MECH MATER, V446-447, P1034, DOI 10.4028/www.scientific.net/AMM.446-447.1034
   [陈北京 Chen Beijing], 2012, [自动化学报, Acta Automatica Sinica], V38, P1815
   Dad N, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), P131, DOI 10.1109/ISIVC.2016.7893975
   Dad N, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053026
   Dad N, 2014, I C COMP SYST APPLIC, P266, DOI 10.1109/AICCSA.2014.7073208
   De Brabanter K, 2010, LS-SVMlab toolbox user's guide: version 1.7
   de Chazal P, 2015, INT CONF ACOUST SPEE, P2165, DOI 10.1109/ICASSP.2015.7178354
   Deng WY, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P389, DOI 10.1109/CIDM.2009.4938676
   DILTS GA, 1985, J COMPUT PHYS, V57, P439, DOI 10.1016/0021-9991(85)90189-5
   Ding SF, 2017, NEURAL COMPUT APPL, V28, P1975, DOI 10.1007/s00521-015-2170-y
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Ennahnahi N, 2010, IET IMAGE PROCESS, V4, P120, DOI 10.1049/iet-ipr.2009.0318
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Flusser J, 2009, ORTHOGONAL MOMENTS, P165
   Gautam K, 2014, FACE RECOGNITION SYS, P87
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Gough W., 1984, European Journal of Physics, V5, P163, DOI 10.1088/0143-0807/5/3/008
   Hamilton W. R., 1844, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, V25, P10, DOI [DOI 10.1080/14786444408644923, 10.1080/14786444408644923]
   He B, 2014, COGN COMPUT, V6, P264, DOI 10.1007/s12559-013-9224-1
   Hosny KM, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023021
   Iosifidis A, 2015, PATTERN RECOGN LETT, V54, P11, DOI 10.1016/j.patrec.2014.12.003
   Jing J., 2011, THESIS
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Li YN, 2013, IEEE SIGNAL PROC LET, V20, P803, DOI 10.1109/LSP.2013.2267775
   Lopez-Gonzalez G, 2014, QUATERNION SUPPORT V, P722
   Mennesson J, 2010, IEEE IMAGE PROC, P2685, DOI 10.1109/ICIP.2010.5651939
   Minemoto T, 2017, SIGNAL PROCESS, V136, P59, DOI 10.1016/j.sigpro.2016.11.008
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nitta T, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2754
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Shao ZH, 2014, PATTERN RECOGN, V47, P603, DOI 10.1016/j.patcog.2013.08.016
   Shu HZ, 2000, GRAPH MODELS, V62, P237, DOI 10.1006/gmod.2000.0523
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0
   Wang XY, 2015, APPL MATH COMPUT, V256, P951, DOI 10.1016/j.amc.2015.01.075
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Xavier-de-Souza S, 2010, IEEE T SYST MAN CY B, V40, P320, DOI 10.1109/TSMCB.2009.2020435
   XIANGYANG W, 2015, OPT LASER TECHNOL, V66, P78, DOI DOI 10.1016/j.optlastec.2014.07.020
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zeng R, 2014, ELECTRON LETT, V50, P1929, DOI 10.1049/el.2014.2526
NR 50
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20935
EP 20959
DI 10.1007/s11042-019-7381-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400018
DA 2024-07-18
ER

PT J
AU Kamel, M
   Siuky, FN
   Yazdi, HS
AF Kamel, Mohammad
   Siuky, Farzaneh Namdar
   Yazdi, Hadi Sadoghi
TI Robust sentiment fusion on distribution of news
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Sentiment analysis; Fusion method; Neural
   network; News corpus; ISNA-set
AB In recent years, since technology has revolutionized human life, plenty of data and information are published on the Internet each day. These shared data contain sentiments (i.e., positive, neutral or negative) toward various topics. Hence, there is a growing need for some techniques and tools which make anticipations about the sentiment of documents. Some sentiment analysis tools extract sentiments for words or sentences separately; moreover, these tools might generate noisy results. Moreover, some documents may contain noisy sentences(not relevant sentences to the context of the document). Therefore, we present some fusion methods to fuse all separated sentiments to have a noise robust value as the whole document sentiment. The proposed robust sentiment analysis tool is called RSF. Initially, the sentiment of sentences are extracted by CoreNLP; afterward, due to the histogram of extracted sentence sentiments, documents are divided into two separated groups. The first group consists of documents which have one main concept and some noisy signals. On the other hand, the second group consists of documents with two main concepts. Afterward, the separated sentiments are fused by using non-linear and linear operator with different loss functions. Moreover, an approach is proposed to evaluate the different loss functions utilized in the fusion step. This approach is based on spaCy and neural network which calculate the train and test errors of different fusion methods to determine the most efficient loss function. Eventually, a news corpus of English news of ISNA is introduced in this paper.
C1 [Kamel, Mohammad; Siuky, Farzaneh Namdar; Yazdi, Hadi Sadoghi] Ferdowsi Univ Mashhad, Ctr Excellence Soft Comp & Intelligent Informat P, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Yazdi, HS (corresponding author), Ferdowsi Univ Mashhad, Ctr Excellence Soft Comp & Intelligent Informat P, Mashhad, Razavi Khorasan, Iran.
EM mohammad.kamel@mail.um.ac.ir; fa.namdarsiuky@mail.um.ac.ir;
   h-sadoghi@um.ac.ir
CR [Anonymous], 2008, Proceedings of ACL-08: HLT
   [Anonymous], 2006, P 5 INT C LANG RES E
   [Anonymous], 2012, SENTIMENT ANAL OPINI
   [Anonymous], 2012, MINING TEXT DATA
   Ashkezari-Toussi S, 2019, SIGNAL PROCESS, V158, P201, DOI 10.1016/j.sigpro.2019.01.004
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   BRAUNSTEIN SL, 1992, J PHYS A-MATH GEN, V25, P3813, DOI 10.1088/0305-4470/25/13/027
   Cai X, 2012, 2012 IEEE INT C COMP, DOI [10.1109/csae.2012.6272913, DOI 10.1109/CSAE.2012.6272913]
   Chatzakou D, 2015, IEEE INTERNET COMPUT, V19, P46, DOI 10.1109/MIC.2015.28
   Choi JD, 2015, ACL
   Dasarathy BV, 1997, P IEEE, V85, P24, DOI 10.1109/5.554206
   Deonna J, 2012, EMOTIONS PHILOS INTR, V69
   Duan X, 2016, P NEWS 2016 6 NAM EN
   Durrant-whyte H, DATA FUSION DECENTRA
   DURRANTWHYTE HF, 1988, INT J ROBOT RES, V7, P97, DOI 10.1177/027836498800700608
   Gan Q, 2001, IEEE T AERO ELEC SYS, V37, P273, DOI 10.1109/7.913685
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Greene D., 2006, P 23 INT C MACH LEAR, V148, P377
   Honnibal M., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1162, 10.18653/v1/d15-1162]
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Hussein DME, SURVEY SENTIMENT ANA, DOI [10. 1016/j. jksues. 2016. 04. 002, DOI 10.1016/J.JKSUES.2016.04.002]
   Intarapaiboon P, 2015, FRAMEWORK TEXT CLASS, DOI [10. 1007/978-3-662-47200-2_78, DOI 10.1007/978-3-662-47200-2_78]
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Kadhim A.I., 2014, Text Document Preprocessing and Dimension Reduction Techniques for Text Document Clustering, DOI [DOI 10.1109/ICAIET.2014.21, 10. 1109/ICAIET.2014.21]
   Liang H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0993-1
   Luo RC, 2002, IEEE SENS J, V2, P107, DOI 10.1109/JSEN.2002.1000251
   Manyika J., 1994, Ellis Horwood series in electrical and electronic engineering, Vfirst
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pradhan L, 2017, PROCEDIA TECHNOLOGY, V66, pS104
   Qin ZL, 2013, SCI TECHNOLOGY ENG
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, P318
   Serrano-Guerrero J, 2015, INFORM SCIENCES, V311, P18, DOI 10.1016/j.ins.2015.03.040
   Shaikh MAM, 2007, LECT NOTES COMPUT SC, V4738, P191
   Shopon Md, 2016, 2016 International Workshop on Computational Intelligence (IWCI), P64, DOI 10.1109/IWCI.2016.7860340
   Snyder B., 2007, proceedings of the Joint Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies, P300
   Socher R., RECURSIVE DEEP MODEL
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Song Jun-nan, 2018, Instrument Technique and Sensor, P1
   Sun X, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P903, DOI 10.1109/ICCIAS.2006.294269
   Sun X, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P928, DOI 10.1109/ICDMW.2014.101
   Takamura H., 2005, ANN ARBOR MI, P133, DOI DOI 10.3115/1219840.1219857
   Tellez ES, 2017, EXPERT SYST APPL, V81, P457, DOI 10.1016/j.eswa.2017.03.071
   Turney P.D., 2002, P 17 INT C MACHINE L, P1
   Vaseghi S.V., 2006, ADV DIGITAL SIGNAL P
   Vilares D, 2017, INFORM PROCESS MANAG, V53, P595, DOI 10.1016/j.ipm.2017.01.004
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Wei W, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P404
   Wiebe J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P1065
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Xiong Y, 2014, LECT NOTES COMPUT SC, V8485, P96, DOI 10.1007/978-3-319-08010-9_12
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
NR 52
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21917
EP 21942
DI 10.1007/s11042-019-7505-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400060
DA 2024-07-18
ER

PT J
AU Tiong, LCO
   Kim, ST
   Ro, YM
AF Tiong, Leslie Ching Ow
   Kim, Seong Tae
   Ro, Yong Man
TI Implementation of multimodal biometric recognition via multi-feature
   deep learning networks and feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep multimodal learning; Multimodal biometric recognition;
   Multi-feature fusion layers; Texture descriptor representations
ID FACE RECOGNITION
AB Although there is an abundance of current research on facial recognition, it still faces significant challenges that are related to variations in factors such as aging, poses, occlusions, resolution, and appearances. In this paper, we propose a Multi-feature Deep Learning Network (MDLN) architecture that uses modalities from the facial and periocular regions, with the addition of texture descriptors to improve recognition performance. Specifically, MDLN is designed as a feature-level fusion approach that correlates between the multimodal biometrics data and texture descriptor, which creates a new feature representation. Therefore, the proposed MLDN model provides more information via the feature representation to achieve better performance, while overcoming the limitations that persist in existing unimodal deep learning approaches. The proposed model has been evaluated on several public datasets and through our experiments, we proved that our proposed MDLN has improved biometric recognition performances under challenging conditions, including variations in illumination, appearances, and pose misalignments.
C1 [Tiong, Leslie Ching Ow; Kim, Seong Tae; Ro, Yong Man] Korea Adv Inst Sci & Technol, Image & Video Syst Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol, Image & Video Syst Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
EM ymro@kaist.ac.kr
RI Ro, Yong Man/ABF-6817-2020; Tiong, Leslie/AAC-8535-2021; ARSLAN,
   Okan/AAA-3232-2020; Kim, Seong Tae/N-8137-2019
OI Ro, Yong Man/0000-0001-5306-6853; Tiong, Leslie/0000-0003-3786-2117;
   Kim, Seong Tae/0000-0002-2132-6021
CR Ahmad MI, 2016, NEUROCOMPUTING, V177, P49, DOI 10.1016/j.neucom.2015.11.003
   Ahuja K, 2017, PATTERN RECOGN LETT, V91, P17, DOI 10.1016/j.patrec.2017.04.002
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], BBC NEWS
   [Anonymous], INT C COMP VIS WORKS
   [Anonymous], 2012, INT C MACH LEARN WOR
   [Anonymous], 2011, INT J COMPUT SCI ISS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, Int J Signal Process Image Process Pattern Recogn, DOI [DOI 10.14257/IJSIP.2015.8.11.29, 10.14257/ijsip.2015.8.11.29]
   [Anonymous], COMPUTER VISION USIN
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   Bharati MH, 2004, CHEMOMETR INTELL LAB, V72, P57, DOI 10.1016/j.chemolab.2004.02.005
   Cao Y, 2014, CANCER INFORM, V13, P125, DOI 10.4137/CIN.S14053
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Chen YR, 2016, EXPERT SYST APPL, V64, P93, DOI 10.1016/j.eswa.2016.07.009
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Delac K., 2006, International Conference on Systems, Signals and Image Processing, P95
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Fan CN, 2011, PATTERN RECOGN LETT, V32, P1468, DOI 10.1016/j.patrec.2011.03.023
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Goswami G, 2017, IEEE IJCNN, P2894, DOI 10.1109/IJCNN.2017.7966214
   Goswami G, 2016, INFORM FUSION, V32, P3, DOI 10.1016/j.inffus.2015.06.007
   Hayat M, 2017, INT J COMPUT VISION, V123, P479, DOI 10.1007/s11263-017-1000-3
   Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635
   Jagadiswary D, 2016, PROCEDIA COMPUT SCI, V85, P109, DOI 10.1016/j.procs.2016.05.187
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Kafai M, 2014, IEEE T INF FOREN SEC, V9, P2132, DOI 10.1109/TIFS.2014.2359548
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Karpathy A, 2014, ADV NEUR IN, V27
   Kasar MM, 2016, INT J SECUR APPL, V10, P81, DOI 10.14257/ijsia.2016.10.3.08
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Liu Y, 2018, MULTIMED TOOLS APPL, V77, P29407, DOI 10.1007/s11042-018-5691-4
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Martinez A. M., 1998, THE AR FACE DATABASE
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Mokhayeri F, 2015, IEEE IMAGE PROC, P4052, DOI 10.1109/ICIP.2015.7351567
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Nigam I, 2015, INFORM FUSION, V26, P1, DOI 10.1016/j.inffus.2015.03.005
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Raghavendra R, 2016, IEEE IMAGE PROC, P325, DOI 10.1109/ICIP.2016.7532372
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Shahamat H, 2014, J VIS COMMUN IMAGE R, V25, P970, DOI 10.1016/j.jvcir.2014.02.007
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Simonyan K., 2014, 14091556 ARXIV
   Struc V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/847680
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiong Leslie Ching Ow, 2017, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V20, P170
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Woodard D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P162, DOI DOI 10.1109/CVPRW.2010.5544621
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2013, NEURAL COMPUT APPL, V23, P1251, DOI 10.1007/s00521-012-1066-3
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
NR 61
TC 20
Z9 22
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22743
EP 22772
DI 10.1007/s11042-019-7618-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400026
DA 2024-07-18
ER

PT J
AU Wang, MY
   Yan, TW
   Luo, MY
   Huang, W
AF Wang, Mingyan
   Yan, Tianwei
   Luo, Mingyuan
   Huang, Wei
TI A novel deep residual network-based incomplete information competition
   strategy for four-players Mahjong games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incomplete information games; Chinese Mahjong; Deep learning; Residual
   networks
ID GO
AB The game theory is widely acknowledged to benefit a lot from recent advances in deep learning, and intelligent competition strategies have been proposed for both complete information games and incomplete information games in recent years. In this paper, the four-players Chinese Mahjong game, which is a typical incomplete information game, is emphasized, a low-level semantic pseudo image generated based on game related prior knowledge and a novel deep residual network-based competition strategy are introduced to play the Chines Mahjong game. Technically, the deep learning within this new competition strategy is realized by a series of "GoBlock", which is a new deep learning model structure introduced in this paper. Also, the "GoBlock" is further made up of several "Inception+" sub-structures, which is novel as well. Comprehensive experiments are conducted to reveal the superiority of this new competition strategy. A great number of the Chinese Mahjong game data have been collected from an online Chinese Mahjong company to construct the dataset in this study, and the newly proposed competition strategy has been compared with several shallow learning-based methods as well as deep learning-based methods. Both qualitative and quantitative analysis have been conducted based on outcomes obtained by all compared methods, and the superiority of the new competition strategy over others are suggested. Furthermore, an interesting competition among the new AI competition strategy and three real senior players are also introduced in this paper. The effectiveness and efficiency of the new competition strategy over real senior human players are also revealed by quantitative analysis based on four measures, from the statistical point of view. It is also necessary to point out that, this work is the first attempt to tackle the Mahjong game, which is a typical incomplete information game, from the deep learning perspective.
C1 [Wang, Mingyan; Yan, Tianwei; Luo, Mingyuan; Huang, Wei] Nanchang Univ, Sch Informat Engn, Dept Comp Sci, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University
RP Huang, W (corresponding author), Nanchang Univ, Sch Informat Engn, Dept Comp Sci, Nanchang, Jiangxi, Peoples R China.
EM n060101@e.ntu.edu.sg
RI wang, ming/HPC-6329-2023; wang, ming/ITV-5378-2023; wang,
   zhenhui/JMQ-0550-2023; Li, Zilong/JEZ-8642-2023; Wang,
   Xuezhen/IUN-6267-2023
FU National Natural Science Foundation of China [61862043]; Natural Science
   Foundation of Jiangxi Province [20161BAB212047];  [20181ACB20006]; 
   [20171ACB21017]
FX The authors would like to acknowledge the grant 61862043 approved by
   National Natural Science Foundation of China, key grants 20181ACB20006
   and 20171ACB21017 as well as grant 20161BAB212047 approved by Natural
   Science Foundation of Jiangxi Province for supporting this study.
CR [Anonymous], SCIENCE
   [Anonymous], 2017, P ADV NEUR INF PROC
   [Anonymous], 2017, INT C MACHINE LEARNI
   [Anonymous], IMAGE CAPTIONING DEE
   [Anonymous], 2017, ARXIV170701629
   [Anonymous], 2016, END TO END ATTENTION, DOI DOI 10.1109/ICASSP.2016.7472618
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   [Anonymous], 1987, Journal of the Japanese and International Economies, DOI [DOI 10.1016/0889-1583(87)90027-X, 10.1016/0889-1583(87)90027-X]
   Bansal T., 2017, arXiv
   Bowling M, 2015, SCIENCE, V347, P145, DOI 10.1126/science.1259433
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Drachen Anders., 2014, 2014 IEEE GAMES MEDI, P1, DOI DOI 10.1109/GEM.2014.7048109
   Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heinrich J., 2016, ARXIV160301121
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Kingma DP, 2013, ARXIV
   Kingma DP, 2018, 32 C NEURAL INFORM P
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Mason L, 2000, ADV NEUR IN, V12, P512
   Mizukami N, 2015, IEEE CONF COMPU INTE, P275, DOI 10.1109/CIG.2015.7317929
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Silver D, 2017, Mastering chess and shogi by self-play with a general reinforcement learning algorithm
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vinyals O., 2017, CoRR
   Von Neumann John, 1959, CONTRIBUTIONS THEORY, V4, P13
   Wang C., 2017, ARXIV PREPRINT ARXIV
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zambaldi V., 2018, Relational deep reinforcement learning
NR 43
TC 6
Z9 8
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23443
EP 23467
DI 10.1007/s11042-019-7682-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400055
DA 2024-07-18
ER

PT J
AU Dondi, P
   Lombardi, L
   Porta, M
   Rovetta, T
   Invernizzi, C
   Malagodi, M
AF Dondi, Piercarlo
   Lombardi, Luca
   Porta, Marco
   Rovetta, Tommaso
   Invernizzi, Claudia
   Malagodi, Marco
TI What do luthiers look at? An eye tracking study on the identification of
   meaningful areas in historical violins
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye-tracking; User study; Education; Multimedia presentation; Cultural
   heritage; Historical violins
ID LARGE POPULATIONS; PERFORMANCE; ATTENTION; MOVEMENTS; ART
AB Stylistic analysis of artworks is an important practice in the field of Cultural Heritage. Over time, significant stylistic characteristics have been identified for paintings and sculptures, but not for historical musical instruments. Even if various stylistic features of instruments are well known, their importance for attributing an instrument to its maker remains unclear. In this work, we propose a study carried out in relation to 34 luthiers' examinations recorded with an eye tracker. Our goal was to find which regions of a violin are most closely observed by experts during the attribution process. The retrieved data were used to create a multimedia presentation that shows a violin in the same way in which luthiers look at it. This application can be employed for knowledge dissemination (e.g,. inside museums) or as an educational tool for students of violin making schools. The experiments were carried out on a series of images of 17th-18th century historical violins kept at the Museo del Violino in Cremona (Italy).
C1 [Dondi, Piercarlo; Rovetta, Tommaso; Invernizzi, Claudia; Malagodi, Marco] Univ Pavia, CISRiC Arvedi Lab Noninvas Diagnost, Cremona, Italy.
   [Dondi, Piercarlo] Univ Pavia, Dept Civil Engn & Architecture, Pavia, Italy.
   [Lombardi, Luca; Porta, Marco] Univ Pavia, Dept Elect Comp & Biomed Engn, Pavia, Italy.
   [Invernizzi, Claudia] Univ Parma, Dept Math Phys & Comp Sci, Parma, Italy.
   [Malagodi, Marco] Univ Pavia, Dept Musicol & Cultural Heritage, Cremona, Italy.
C3 University of Pavia; University of Pavia; University of Pavia;
   University of Parma; University of Pavia
RP Dondi, P (corresponding author), Univ Pavia, CISRiC Arvedi Lab Noninvas Diagnost, Cremona, Italy.; Dondi, P (corresponding author), Univ Pavia, Dept Civil Engn & Architecture, Pavia, Italy.
EM piercarlo.dondi@unipv.it; luca.lombardi@unipv.it; marco.porta@unipv.it;
   tommaso.rovetta@unipv.it; claudia.invernizzi@unipv.it;
   marco.malagodi@unipv.it
RI Porta, Marco/ACW-5714-2022; rovetta, tommaso/P-6972-2016
OI rovetta, tommaso/0000-0002-9626-8380; Invernizzi,
   Claudia/0000-0001-5111-6589; Dondi, Piercarlo/0000-0002-0624-073X
CR [Anonymous], 1993, Usability Engineering
   [Anonymous], 2016, P 8 INT C GAM VIRT W, DOI DOI 10.1109/VS-GAMES.2016.7590371
   [Anonymous], FRONT PSHICOL
   [Anonymous], 2007, Eye tracking methodology: Theory and practice, DOI DOI 10.1007/978-3-319-57883-5
   [Anonymous], 2013, HDB HUMAN CENTRIC VI
   Armstrong T, 2012, CLIN PSYCHOL REV, V32, P704, DOI 10.1016/j.cpr.2012.09.004
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Bergstrom JCR, 2013, INT J HUM-COMPUT INT, V29, P541, DOI 10.1080/10447318.2012.728493
   BUQUET C, 1988, MED BIOL ENG COMPUT, V26, P277, DOI 10.1007/BF02447081
   Calandra DM, 2016, L N INF SYST ORGAN, V11, P161, DOI 10.1007/978-3-319-23784-8_13
   Cantoni V, 2016, COMPUTER SYSTEMS AND TECHNOLOGIES, COMPSYSTECH'16, P307, DOI 10.1145/2983468.2983499
   Cecotti H, 2016, IEEE T HUM-MACH SYST, V46, P601, DOI 10.1109/THMS.2016.2537749
   Cornelissen FW, 2002, BEHAV RES METH INS C, V34, P613, DOI 10.3758/BF03195489
   Damala A, 2012, INT SYM MIX AUGMENT
   Davanzo N, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206350
   DiPaola S, 2010, LEONARDO, V43, P145, DOI 10.1162/leon.2010.43.2.145
   Dondi P., 2017, ACTA IMEKO, V6, P29, DOI [10.21014/actaimeko.v6i3.455, DOI 10.21014/ACTAIMEKO.V6I3.455, 10.21014/acta_imeko.v6i3.455, DOI 10.21014/ACTA_IMEKO.V6I3.455]
   Dondi P, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3051472
   Dondi P, 2015, LECT NOTES COMPUT SC, V9281, P103, DOI 10.1007/978-3-319-23222-5_13
   Eghbal-Azar K, 2013, SOC SCI COMPUT REV, V31, P103, DOI 10.1177/0894439312453565
   Fan ZB, 2015, PR IEEE I C PROGR IN, P301, DOI 10.1109/PIC.2015.7489858
   Fiocco G, 2017, APPL SPECTROSC, V71, P2477, DOI 10.1177/0003702817715622
   Gartus A, 2015, ACTA PSYCHOL, V156, P64, DOI 10.1016/j.actpsy.2015.01.005
   Jalovec K., 1963, BEAUTIFUL ITALIAN VI
   Jalovec K, 1964, ITALIAN VIOLIN MAKER
   Liccione D, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00672
   Milekic S, 2010, P MUS WEB ARCH MUS I, P61
   Milekic S, 2003, P 7 ANN MUS WEB C, P57
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   Nielsen Jakob., 2009, EYETRACKING WEB USAB
   Ooms K, 2015, J EYE MOVEMENT RES, V8, DOI 10.16910/jemr.8.1.5
   Piper T, 1898, P MUSICAL ASS, P97
   Porta M, 2015, J ASSIST TECHNOL, V9, P48, DOI 10.1108/JAT-12-2013-0037
   Rovetta T, 2018, X-RAY SPECTROM, V47, P159, DOI 10.1002/xrs.2825
   Sylaiou S, 2013, P REN 2013 C REN DIG, P48
   Toyama T, 2011, P RETH TECHN MUS 201, P1
   Valuch C, 2015, MULTIMED TOOLS APPL, V74, P10161, DOI 10.1007/s11042-015-2806-z
   Vik P., 2013, REGRESSION ANOVA GEN
   Wang CC, 2019, MULTIMED TOOLS APPL, V78, P4813, DOI 10.1007/s11042-018-5754-6
   Wedel M., 2008, Review of Marketing Research, V4, P123, DOI 10.4324/9781351550932-5
   Wessel Daniel, 2007, WORKSH RES METH INF
   Wooding DS, 2002, BEHAV RES METH INS C, V34, P509, DOI 10.3758/BF03195480
   Wooding DS, 2002, BEHAV RES METH INS C, V34, P518, DOI 10.3758/BF03195481
NR 43
TC 5
Z9 5
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19115
EP 19139
DI 10.1007/s11042-019-7276-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800009
DA 2024-07-18
ER

PT J
AU Du, SL
   Ikenaga, T
AF Du, Songlin
   Ikenaga, Takeshi
TI Low-dimensional superpixel descriptor and its application in visual
   correspondence estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel descriptor; Low-dimensional feature; Visual correspondence
   estimation
ID IMAGE; FEATURES
AB Establishing local visual correspondence between video frames is an important and challenging problem in many vision based applications. Local keypoint detection and description based pixel-level matching is a typical way for visual correspondence estimation. Unlike traditional local keypoint descriptor based methods, this paper proposes a comprehensive yet low-dimensional local feature descriptor based on superpixels generated by over segmentation. The proposed local feature descriptor extracts shape feature, texture feature, and color feature from superpixels by orientated center-boundary distance (OCBD), gray-level co-occurrence matrix (GLCM), and saturation histogram (SHIST), respectively. The types of features are more comprehensive than existing descriptors which extract only one specific kind of feature. Experimental results on the widely used Middlebury optical flow dataset prove that the proposed superpixel descriptor achieves triple accuracy compared with the state-of-the-art ORB descriptor which has the same dimension of features with the proposed one. In addition, since the dimension of the proposed superpixel descriptor is low, it is convenient for matching and memory-efficient for hardware implementation.
C1 [Du, Songlin; Ikenaga, Takeshi] Waseda Univ, Grad Sch Informat Prod & Syst, Kitakyushu, Fukuoka 8080135, Japan.
C3 Waseda University
RP Du, SL (corresponding author), Waseda Univ, Grad Sch Informat Prod & Syst, Kitakyushu, Fukuoka 8080135, Japan.
EM dusonny@fuji.waseda.jp
FU KAKENHI [16K13006]; Waseda University Grant for Special Research
   Projects [2017B-261]
FX This work was supported by KAKENHI (16K13006) and Waseda University
   Grant for Special Research Projects (2017B-261).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Awad A.I., 2016, Image Feature Detectors and Descriptors: Foundations and Applications, V1st
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Daribo I, 2014, IEEE T IMAGE PROCESS, V23, P4696, DOI 10.1109/TIP.2014.2353817
   Du S, 2018, P INT S INT SIGN PRO, P287
   Fan B., 2015, LOCAL IMAGE DESCRIPT
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guo Y, 2010, INT CONF SIGN PROCES, P1198, DOI 10.1109/ICOSP.2010.5656102
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu WM, 2015, IEEE T PATTERN ANAL, V37, P816, DOI 10.1109/TPAMI.2014.2353628
   Ke Y, 2004, PROC CVPR IEEE, P506
   Khan N, 2015, MACH VISION APPL, V26, P819, DOI 10.1007/s00138-015-0689-7
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miao ZW, 2013, PATTERN RECOGN, V46, P2890, DOI 10.1016/j.patcog.2013.03.024
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schwartz WR, 2006, IEEE IMAGE PROC, P2449, DOI 10.1109/ICIP.2006.312772
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Yang P, 2016, NEUROCOMPUTING, V197, P212, DOI 10.1016/j.neucom.2016.02.061
NR 38
TC 3
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19457
EP 19472
DI 10.1007/s11042-019-7248-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800024
DA 2024-07-18
ER

PT J
AU Ferwerda, B
   Yang, E
   Schedl, M
   Tkalcic, M
AF Ferwerda, Bruce
   Yang, Emily
   Schedl, Markus
   Tkalcic, Marko
TI Personality and taxonomy preferences, and the influence of category
   choice on the user experience for music streaming services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality; Taxonomy; Music; Categorization; Overchoice; Choice
   overload; Music sophistication
ID PRODUCT ASSORTMENT; TIME PRESSURE; BEHAVIOR; VARIETY; EMOTION; NUMBER;
   SIZE; TOO; OVERLOAD; OPTIONS
AB Music streaming services increasingly incorporate different ways for users to browse for music. Next to the commonly used genre taxonomy, nowadays additional taxonomies, such as mood and activities, are often used. As additional taxonomies have shown to be able to distract the user in their search, we looked at how to predict taxonomy preferences in order to counteract this. Additionally, we looked at how the number of categories presented within a taxonomy influences the user experience. We conducted an online user study where participants interacted with an application called Tune-A-Find. We measured taxonomy choice (i.e., mood, activity, or genre), individual differences (e.g., personality traits and music expertise factors), and different user experience factors (i.e., choice difficulty and satisfaction, perceived system usefulness and quality) when presenting either 6- or 24-categories within the picked taxonomy. Among 297 participants, we found that personality traits are related to music taxonomy preferences. Furthermore, our findings show that the number of categories within a taxonomy influences the user experience in different ways and is moderated by music expertise. Our findings can support personalized user interfaces in music streaming services. By knowing the user's personality and expertise, the user interface can adapt to the user's preferred way of music browsing and thereby mitigate the problems that music listeners are facing while finding their way through the abundance of music choices online nowadays.
C1 [Ferwerda, Bruce] Jonkoping Univ, Dept Comp Sci & Informat, Jonkoping, Sweden.
   [Yang, Emily; Schedl, Markus] Johannes Kepler Univ Linz, Inst Computat Percept, Linz, Austria.
   [Tkalcic, Marko] Free Univ Bozen Bolzano, Fac Comp Sci, Bolzano, Italy.
C3 Jonkoping University; Johannes Kepler University Linz; Free University
   of Bozen-Bolzano
RP Ferwerda, B (corresponding author), Jonkoping Univ, Dept Comp Sci & Informat, Jonkoping, Sweden.
EM bruce.ferwerda@ju.se; emily@emzyne.net; markus.schedl@jku.at;
   marko.tkalcic@unibz.it
RI Tkalcic, Marko/L-9767-2016; Ferwerda, Bruce/B-8168-2017
OI Tkalcic, Marko/0000-0002-0831-5512; Ferwerda, Bruce/0000-0003-4344-9986
CR [Anonymous], 1976, BOLLINGEN SERIES, V20
   [Anonymous], 2009, P 5 WORKSHOP EMOTION
   [Anonymous], 2004, PARADOX CHOICE
   [Anonymous], 1995, Journal of Retailing and Consumer Services, DOI [DOI 10.1016/0969-6989(95)00038-0, 10.1016/0969-6989(95)00038-0]
   [Anonymous], 2017, P 1 WORKSH TEMP REAS
   ARNOLD SJ, 1983, J MARKETING RES, V20, P149, DOI 10.2307/3151681
   Back MD, 2010, PSYCHOL SCI, V21, P372, DOI 10.1177/0956797609360756
   Baumeister RF, 2007, PERS SOC PSYCHOL REV, V11, P167, DOI 10.1177/1088868307301033
   Bertin-Mahieux T., 2011, Machine audition: Principles, algorithms and systems, P334
   Boatwright P, 2001, J MARKETING, V65, P50, DOI 10.1509/jmkg.65.3.50.18330
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Borle S, 2005, MARKET SCI, V24, P616, DOI 10.1287/mksc.1050.0121
   Bown NJ, 2003, J BEHAV DECIS MAKING, V16, P297, DOI 10.1002/bdm.447
   Bravo MJ, 2006, PERCEPT PSYCHOPHYS, V68, P911, DOI 10.3758/BF03193354
   Burger J, 2010, PERSONALITY PSY 235
   Chernev A, 2003, J CONSUM RES, V30, P170, DOI 10.1086/376808
   Chernev A, 2003, J PERS SOC PSYCHOL, V85, P151, DOI 10.1037/0022-3514.85.1.151
   CRAIG CS, 1984, J RETAILING, V60, P5
   Delic A, 2018, CONF BUS INFORM, P79, DOI 10.1109/CBI.2018.00018
   Dhar R, 1999, J CONSUM RES, V25, P369, DOI 10.1086/209545
   Dhar R, 1996, J BEHAV DECIS MAKING, V9, P265, DOI 10.1002/(SICI)1099-0771(199612)9:4<265::AID-BDM231>3.0.CO;2-4
   Dhar R, 1997, J CONSUM RES, V24, P215, DOI 10.1086/209506
   Diehl K, 2010, J MARKETING RES, V47, P312, DOI 10.1509/jmkr.47.2.312
   DREZE X, 1994, J RETAILING, V70, P301, DOI 10.1016/0022-4359(94)90002-7
   EASTERBROOK JA, 1959, PSYCHOL REV, V66, P183, DOI 10.1037/h0047707
   Elahi M, 2013, IA ADV ARTIFICIAL IN, P2013
   Fasolo B, 2009, PSYCHOL MARKET, V26, P254, DOI 10.1002/mar.20272
   Ferwerda Bruce, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P850, DOI 10.1007/978-3-319-27671-7_71
   Ferwerda B., 2018, ARXIV180807314
   Ferwerda B, 2016, UMAP P
   Ferwerda B, 2014, P 2 WORKSH EM PERS P, P1613
   Ferwerda B, 2015, CHI 15 HUM FACT COMP
   Ferwerda B., 2018, P 23 INT INT US INT
   Ferwerda B, 2018, 26 C US MOD AD PERS
   Ferwerda B, 2015, PERSONALITY EMOTION
   Ferwerda B., 2016, P 2016 C US MOD AD P, P287
   Ferwerda B, 2015, P 1 WORKSH COLL INT
   Ferwerda B, 2016, P INT WORKSH MOD SOC
   Ferwerda B, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P285, DOI 10.1145/3079628.3079693
   Ferwerda B, 2016, LECT NOTES ARTIF INT, V9853, P254, DOI 10.1007/978-3-319-46131-1_29
   Ferwerda Bruce, 2016, INFLUENCE USERS PERS, P43
   Ferwerda Bruce, 2015, WORKSH EM PERS SYST, P7, DOI DOI 10.1145/2809643.2809644
   Ferwerda Bruce, 2016, THESIS
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Golbeck J, 2011, PRIVACY SECURITY RIS, P49
   Gosling SamuelD., 2007, PERSONALITY IMPRESSI
   Gourville JT, 2005, MARKET SCI, V24, P382, DOI 10.1287/mksc.1040.0109
   David MG, 2015, J RES PERS, V58, P154, DOI 10.1016/j.jrp.2015.06.002
   Gross JJ, 1998, J PERS SOC PSYCHOL, V170
   Haynes GA, 2009, PSYCHOL MARKET, V26, P204, DOI 10.1002/mar.20269
   Hsee CK, 1998, J CONSUM RES, V25, P175, DOI 10.1086/209534
   Hu R., 2009, Proceedings of the third ACM conference on Recommender systems, P221, DOI DOI 10.1145/1639714.1639753
   Hutchinson JMC, 2005, BIOL REV, V80, P73, DOI 10.1017/S1464793104006554
   Iyengar SS, 2006, PSYCHOL SCI, V17, P143, DOI 10.1111/j.1467-9280.2006.01677.x
   Iyengar SS, 2000, J PERS SOC PSYCHOL, V79, P995, DOI 10.1037//0022-3514.79.6.995
   Janiszewski C, 1998, J CONSUM RES, V25, P290, DOI 10.1086/209540
   John O.P., 1991, BIG 5 INVENTORY VERS, DOI DOI 10.1037/T07550-000
   Kahn BE, 2004, J CONSUM RES, V30, P519, DOI 10.1086/380286
   Kemp A.E., 1996, MUSICAL TEMPERAMENT
   Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453
   Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4
   Knoll N, 2006, EUR J PERSONALITY, V20, P217, DOI 10.1002/per.581
   Koelemeijer K, 1999, J RETAILING, V75, P319, DOI 10.1016/S0022-4359(99)00011-1
   Langner T, 2013, J BUS RES, V66, P924, DOI 10.1016/j.jbusres.2011.12.012
   Lay A, 2018, 23 INT INT US INT
   Leith KP, 1996, J PERS SOC PSYCHOL, V71, P1250, DOI 10.1037/0022-3514.71.6.1250
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   MAZURSKY D, 1986, J RETAILING, V62, P145
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mogilner C, 2008, J CONSUM RES, V35, P202, DOI 10.1086/588698
   Müllensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Oppewal H, 2005, INT J RES MARK, V22, P45, DOI 10.1016/j.ijresmar.2004.03.002
   Park G, 2014, AUTOMATIC PERSONALIT
   Perruchet P, 2006, MEM COGN
   Quercia D., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P180, DOI 10.1109/PASSAT/SocialCom.2011.26
   Rawlings D., 1997, Psychology of Music, V25, P120, DOI [DOI 10.1177/0305735697252003, 10.1177/0305735697252003]
   REDELMEIER DA, 1995, JAMA-J AM MED ASSOC, V273, P302, DOI 10.1001/jama.1995.03520280048038
   Rentfrow PJ, 2011, J PERS, V79, P223, DOI 10.1111/j.1467-6494.2010.00662.x
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   Reutskaja E, 2009, PSYCHOL MARKET, V26, P197, DOI 10.1002/mar.20268
   Ross C, 2009, COMPUT HUM BEHAV, V25, P578, DOI 10.1016/j.chb.2008.12.024
   Schedl M, 2017, MULT ISM IEEE INT S, P2017
   Schedl M, 2017, IEEE INT SYM MULTIM, P479, DOI 10.1109/ISM.2017.95
   Scheibehenne B, 2010, J CONSUM RES, V37, P409, DOI 10.1086/651235
   Scheibehenne B, 2009, PSYCHOL MARKET, V26, P229, DOI 10.1002/mar.20271
   Schwartz B, 2004, SCI AM, V290, P70, DOI 10.1038/scientificamerican0404-70
   Sethi-Iyengar S., 2004, PENSION DESIGN STRUC, P83, DOI DOI 10.1093/0199273391.003.0005
   Shah AM, 2007, PSYCHOL SCI, V18, P369, DOI 10.1111/j.1467-9280.2007.01906.x
   Skowron M, 2017, EUR C INF RETR
   Skowron M, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P107, DOI 10.1145/2872518.2889368
   Sloot LM, 2006, J MARKETING RES, V43, P536, DOI 10.1509/jmkr.43.4.536
   Tkalcic M., 2011, 1 INT WORKSHOP DECIS, V106, P106
   Tkalcic M, 2015, PERSONALITY CORRELAT, P1
   Tkalcic Marko, 2018, Personality, Emotions, and Group Dynamics
   van Herpen E, 2008, ADV CONSUM RES, V35, P82
   Yun JT, 2017, COMPUT HUM BEHAV, V74, P205, DOI 10.1016/j.chb.2017.04.038
NR 96
TC 15
Z9 15
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20157
EP 20190
DI 10.1007/s11042-019-7336-7
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800056
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Pezeshki, H
   Rastgarpour, M
   Sharifi, A
   Yazdani, S
AF Pezeshki, H.
   Rastgarpour, M.
   Sharifi, A.
   Yazdani, S.
TI Extraction of spiculated parts of mammogram tumors to improve accuracy
   of classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammographic mass classification; Breast cancer; Extraction of
   spiculated parts; Segmentation; Feature extraction
ID BREAST-CANCER; MASS CLASSIFICATION; DIGITAL MAMMOGRAPHY;
   FEATURE-SELECTION; SHAPE-ANALYSIS; PREDICTION; BENIGN; TRANSFORM;
   ALGORITHM; DIAGNOSIS
AB Spiculated parts of masses are significant features to classify tumors in digital mammography; however, segmentation, which is used to extract the shape and contour of a tumor, eliminates them. To address this problem, the current study proposes a novel algorithm for extraction of the spiculated pixels of a tumor that are of similar intensity along a line. It first applies the sums of the differences between the central pixel and neighboring pixels in different symmetric orthogonal directions. The minimum difference between two symmetric orthogonal directions specifies the similarity of pixels in one direction as denoting a spiculated part of the mass. These parts then are added to the segmented image to enhance the shape of tumor. The features of the tumor are extracted from the final segmented image to allow its classification as benign or malignant. Simulation results showed that the accuracy and the area under the ROC curve of the proposed method for mini-MIAS and DDSM databases were 91.37% and 93.22% and 0.9776 and 0.9752, respectively. This confirms the effectiveness of the proposed algorithm for extraction of the spiculated parts of a malignant tumor with the aim of increasing the classification accuracy.
C1 [Pezeshki, H.; Sharifi, A.] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Rastgarpour, M.] Islamic Azad Univ, Dept Comp Engn, Fac Engn, Saveh Branch, Saveh, Iran.
   [Yazdani, S.] Islamic Azad Univ, Dept Comp Engn, North Tehran Branch, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University
RP Rastgarpour, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Fac Engn, Saveh Branch, Saveh, Iran.
EM hamed.pezeshki@srbiau.ac.ir; m.rastgarpour@iau-saveh.ac.ir;
   a.sharifi@srbiau.ac.ir; s_yazdani@iau-tnb.ac.ir
RI Rastgarpour, Maryam/AAY-9451-2021; Yazdani, Samaneh/AAV-3195-2021;
   Sharifi, Arash/AAU-2023-2021; Pezeshki, Hamed/AAN-7840-2021
OI Rastgarpour, Maryam/0000-0002-7095-151X; Pezeshki,
   Hamed/0000-0003-1661-4261; Sharifi, Arash/0000-0002-2441-9477
CR [Anonymous], 2017, Facts and Figures
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2013, PATTERN RECOGN, DOI DOI 10.1007/978-1-4757-0450-1
   [Anonymous], CANC WHO FACT SHEETS
   [Anonymous], 2000, P 5 INT WORKSH DIG M
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Cheikhrouhou I., 2008, First Workshops on Image Processing Theory, Tools and Applications (IPTA), P1, DOI [10.1109/IPTA.2008.4743751, DOI 10.1109/IPTA.2008.4743751]
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Domínguez AR, 2009, PATTERN RECOGN, V42, P1138, DOI 10.1016/j.patcog.2008.08.006
   FEIG SA, 1995, RADIOL CLIN N AM, V33, P1205
   Forsyth D., 2011, Computer Vision: A Modern Approach
   FRANQUET T, 1993, RADIOGRAPHICS, V13, P841, DOI 10.1148/radiographics.13.4.8356272
   Görgel P, 2015, EXPERT SYST, V32, P155, DOI 10.1111/exsy.12073
   Guliato Denise, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P2791
   Huang CL, 2008, EXPERT SYST APPL, V34, P578, DOI 10.1016/j.eswa.2006.09.041
   Huo ZM, 2000, ACAD RADIOL, V7, P1077, DOI 10.1016/S1076-6332(00)80060-4
   Jalaja K., 2005, IGARSS 2005. IEEE International Geoscience and Remote Sensing Symposium
   Kashyap KL, 2015, IEEE CONF IMAGING SY, P131
   Kashyap KL, 2018, MULTIMED TOOLS APPL, V77, P9249, DOI 10.1007/s11042-017-4751-5
   Keller B, 2011, LECT NOTES COMPUT SC, V6893, P562, DOI 10.1007/978-3-642-23626-6_69
   Khan S, 2016, APPL SOFT COMPUT, V44, P267, DOI 10.1016/j.asoc.2016.04.012
   LAI SM, 1989, IEEE T MED IMAGING, V8, P377, DOI 10.1109/42.41491
   Liu XM, 2014, IEEE SYST J, V8, P910, DOI 10.1109/JSYST.2013.2286539
   Maitra IK, 2012, COMPUT METH PROG BIO, V107, P175, DOI 10.1016/j.cmpb.2011.05.007
   Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT
   Mohanty AK, 2013, NEURAL COMPUT APPL, V22, P1151, DOI 10.1007/s00521-012-0881-x
   Mohanty F, 2019, MULTIMED TOOLS APPL, V78, P12805, DOI 10.1007/s11042-018-5804-0
   Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092
   Nguyen TA, 2005, P ANN INT IEEE EMBS, P3210, DOI 10.1109/IEMBS.2005.1617159
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Rabidas R, 2017, IET COMPUT VIS, V11, P22, DOI 10.1049/iet-cvi.2016.0163
   Rouhi R, 2016, EXPERT SYST APPL, V46, P45, DOI 10.1016/j.eswa.2015.10.011
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Sahiner B, 1998, MED PHYS, V25, P516, DOI 10.1118/1.598228
   Sahiner B, 2001, MED PHYS, V28, P1455, DOI 10.1118/1.1381548
   Saki F, 2013, COMPUT BIOL MED, V43, P32, DOI 10.1016/j.compbiomed.2012.10.006
   Sampat MP, 2008, MED PHYS, V35, P2110, DOI 10.1118/1.2890080
   SICKLES EA, 1989, RADIOLOGY, V173, P297, DOI 10.1148/radiology.173.2.2678242
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Sundaram M., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P842, DOI 10.1109/ICSCCN.2011.6024667
   Vapnik V., 2013, The nature of statistical learning theory
   Vyborny CJ, 2000, RADIOLOGY, V215, P703, DOI 10.1148/radiology.215.3.r00jn38703
   Wang XW, 2011, MED ENG PHYS, V33, P934, DOI 10.1016/j.medengphy.2011.03.001
   Wang Y, 2014, NEUROCOMPUTING, V144, P107, DOI 10.1016/j.neucom.2013.11.050
   Wu WJ, 2012, COMPUT MED IMAG GRAP, V36, P627, DOI 10.1016/j.compmedimag.2012.07.004
   Xie WY, 2016, NEUROCOMPUTING, V173, P930, DOI 10.1016/j.neucom.2015.08.048
NR 47
TC 16
Z9 16
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19979
EP 20003
DI 10.1007/s11042-019-7185-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800048
DA 2024-07-18
ER

PT J
AU Xiao, XJ
   Qiang, ZL
   Zhao, JJ
   Qiang, Y
   Wang, P
   Han, P
AF Xiao, Xiaojiao
   Qiang, Zilin
   Zhao, Juanjuan
   Qiang, Yan
   Wang, Pan
   Han, Peng
TI A feature extraction method for lung nodules based on a multichannel
   principal component analysis network (PCANet)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung nodules; Spatial pyramid pooling (SPP); Feature extraction;
   Principal component analysis network (PCANet)
ID PULMONARY NODULES; CT IMAGES; CLASSIFICATION; REPRESENTATION; DIAGNOSIS;
   MATRIX
AB Feature extraction of lung nodules is very important in the diagnosis of lung cancer and is the premise of feature description, target matching, recognition and benign and malignant diagnosis. The main contribution of this work is the development of a new end-to-end feature extraction method that learns effective feature representation from images to effectively establish the direct relationship between multiple features and tissue features (that is, benign or malignant). The architecture consists of three seamlessly connected functional layers. RGB multichannel can automatically extract ROI sequence images involving lung parenchyma from the lung imaging sequence. The feature extraction layers, using Principal Component Analysis Network - random binary hash (PCANet-RBH), a) extract high-level semantic features of the R/G/B channel by cascading PCA and fuse the extracted normal color patterns, and b) generate multiple binary patterns via RBH to produce richer features with color information. The connected spatial pyramid pooling (SPP) layer can extract the location features of the lung nodules and map the feature matrix to the low-dimensional space and then establish a correspondence between the image features and the organizational identity. We validate the performance of the proposed method using the public dataset LIDC. The experimental results show that the fusion features extracted by our method have high and stable classification accuracy (accuracy:93.25 +/- 0.53, sensitivity:93.12 +/- 0.62 specificity:91.37 +/- 0.62), which is significantly better than the traditional algorithm for lung nodule feature extraction. Moreover, RGB-PCANet has a short training time, which can meet the requirements of real-time diagnosis of lung cancer. In general, the advantage of our framework is that it provides a better and more comprehensive method to establish a direct relationship between image high-level semantic features, color features, location features and tissue features, making it an attractive clinical diagnostic tool for lung cancer.
C1 [Xiao, Xiaojiao; Qiang, Zilin; Zhao, Juanjuan; Qiang, Yan; Wang, Pan; Han, Peng] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan, Shanxi, Peoples R China.
C3 Taiyuan University of Technology
RP Zhao, JJ (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan, Shanxi, Peoples R China.
EM 497039573@qq.com; 614339099@qq.com; zhaojuanjuan@tyut.edu.cn;
   qiangyan@tyut.edu.cn; 243830124@qq.com; 18734817739@163.com
FU National Natural Science Foundation of China [61572344]; State Key
   Laboratory of Virtual Reality Technology and Systems, Beihang University
   [BUAA-VR-17KF-15, VRLAB2018A07]; Shanxi Scholarship Council of China
   [2016-038]
FX This work was supported in part by the found of National Natural Science
   Foundation of China (61572344), in part by the open funding project of
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University (Grant No. BUAA-VR-17KF-15; VRLAB2018A07), in part by
   Research Project Supported by Shanxi Scholarship Council of China
   (2016-038).
CR [Anonymous], 2016, BIOINSPIRED COMPUTIN, DOI DOI 10.1007/978-981-10-3611-8_28
   [Anonymous], MED IMAGING COMPUTER
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cao SS, 2016, CONF REC ASILOMAR C, P117, DOI 10.1109/ACSSC.2016.7869006
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cheng CQ, 2015, INT ARCH PHOTOGRAMM, V47, P1, DOI 10.5194/isprsarchives-XL-7-W4-1-2015
   Chlaoua R, 2018, EVOLUTION SYSTEMS, V2, P1
   Dhara AK, 2016, J DIGIT IMAGING, V29, P466, DOI 10.1007/s10278-015-9857-6
   Han FF, 2015, J DIGIT IMAGING, V28, P99, DOI 10.1007/s10278-014-9718-8
   Han H, 2015, IEEE J BIOMED HEALTH, V19, P648, DOI 10.1109/JBHI.2014.2328870
   Hou CP, 2014, PATTERN RECOGN, V47, P454, DOI 10.1016/j.patcog.2013.07.002
   Hua KL, 2015, ONCOTARGETS THER, V8, P2015, DOI 10.2147/OTT.S80733
   Jiang M, 2015, MED IMAGE COMPUTING, V1, P558
   Kim B.-C., 2016, 2016 4th International Winter Conference on Brain-Computer Interface (BCI), V2, P1
   Kim YI, 2016, J PROTEOMICS, V148, P36, DOI 10.1016/j.jprot.2016.04.052
   Ko JP, 2001, RADIOLOGY, V218, P267, DOI 10.1148/radiology.218.1.r01ja39267
   Kobayashi T, 2014, INT J COMPUT VISION, V110, P308, DOI 10.1007/s11263-014-0709-5
   Kobayashi T, 2012, LECT NOTES COMPUT SC, V7573, P474, DOI 10.1007/978-3-642-33709-3_34
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Lakshmi SP, 2017, PPAR RES, V2017, DOI 10.1155/2017/8252796
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lin DT, 2005, COMPUT MED IMAG GRAP, V29, P447, DOI 10.1016/j.compmedimag.2005.04.001
   Mousa WAH, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P153, DOI 10.1109/ICIP.2002.1038927
   Osicka T, 2006, MED IMAGING
   Qiang Y, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12224
   Ramaswamy S, 2016, PULMONARY NODULE CLA
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shu-Tong L I, 2018, COMPUTER SCI
   Soltani T, 2015, IR IM INF C, P37
   Suzuki K, 2005, ACAD RADIOL, V12, P1333, DOI 10.1016/j.acra.2005.06.017
   Tarando SR, 2017, MED IMAGING 2016 COM
   Wang Z, 2008, IEEE T NEURAL NETWOR, V19, P758, DOI 10.1109/TNN.2007.911744
   Xu XW, 1997, MED PHYS, V24, P1395, DOI 10.1118/1.598028
   Yu D, 2018, MULTIMED TOOLS APPL, V4, P1
   Zaidi H, 2016, IEEE SIGNAL PROC MAG, V33, P67, DOI 10.1109/MSP.2015.2482225
   Zhao JJ, 2017, J COMPUT SCI TECH-CH, V32, P457, DOI 10.1007/s11390-017-1736-9
   Zhao JJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123694
   Zhao ZJ, 2017, CHIN AUTOM CONGR, P2099, DOI 10.1109/CAC.2017.8243118
NR 38
TC 2
Z9 2
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17317
EP 17335
DI 10.1007/s11042-018-7041-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200001
DA 2024-07-18
ER

PT J
AU Zam, A
   Khayyambashi, MR
   Bohlooli, A
AF Zam, Abdulaziz
   Khayyambashi, Mohammad Reza
   Bohlooli, Ali
TI Energy-aware strategy for collaborative target-detection in wireless
   multimedia sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy efficiency; Multi-scales pyramid construction; Target
   tracking-by-detection; Wireless multimedia sensor network
ID TRACKING
AB Energy-efficiency in visual surveillance is the most important issue for wireless multimedia sensor network (WMSN) due to its energy-constraints. This paper addresses the trade-off between detection-accuracy and power-consumption by presenting an energy-aware scheme for detecting moving target based on clustered WMSN. The contributions of this paper are as follows; 1- An adaptive clustering and nodes activation approach is proposed based on residual energy of detecting nodes and the location of the object at the camera's field of view (FoV). 2- An effective cooperative features-pyramid construction method for collaborative target identification with low communication cost. 3- An in-network collaboration mechanism for cooperative detection of the target is proposed. The performance of this scheme is evaluated using both standard datasets and personal recorded videos in terms of detection-accuracy and power-consumption. Compared with state-of-the-art methods, our proposed strategy greatly reduces energy-consumption and saves more than 65% of the network-energy. Detection-accuracy rate of our strategy is 11% better than other recent works. We have increased the Precision of classification up to 49% and 65% and the Recall of classification up to 53% and 71% for specific-target and object-type respectively. These results demonstrate the superiority of our scheme over the recent state-of-the-art works.
C1 [Zam, Abdulaziz; Bohlooli, Ali] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
   [Khayyambashi, Mohammad Reza] Univ Isfahan, Fac Comp Engn, Dept Comp Architecture, Esfahan, Iran.
C3 University of Isfahan; University of Isfahan
RP Bohlooli, A (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM bohlooli@eng.ui.ac.ir
RI Bohlooli, Ali/ABG-4510-2021
OI Bohlooli, Ali/0000-0003-2678-8281; zam, abdulaziz/0000-0002-9063-8862
CR Almalkawi IT, 2010, SENSORS, V10
   Ang K. H., 2005, IEEE T CONTR SYST T, V13, P4
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], [No title captured]
   Bay H., 2006, EUROPEAN CONFERENCE
   Bhuiyan MZA, 2015, IEEE T COMPUT, V64, P1968, DOI 10.1109/TC.2014.2346209
   Chen ZZ, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P276, DOI 10.1109/BigMM.2015.53
   Civelek M, 2017, IEEE SENSORS J, V17
   Dalal N, 2005, IEEE COMP SOC C COMP, P25
   Dao T, 2017, IEEE DISTR COMP SYST
   Demigha O, 2013, IEEE COMMUNICATION S, V15
   Ding ZJ, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2406336.2406340
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Elhoseny M, 2017, WIREL PERS COMMUN, V95
   Elhoseny M, 2016, SECURITY COMMUNICATI, V9, P13
   Elhoseny M, 2015, IEEE COMMUN LETT IEE, V19
   Elhoseny M, 2018, EXPERT SYST APPL, V92, P142, DOI 10.1016/j.eswa.2017.09.008
   Fang W, 2015, INT J WIRELESS INF N, V22
   Fayed S, 2016, MULTIMED TOOLS APPL, V75, P6347, DOI 10.1007/s11042-015-2575-8
   Fu PC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030639
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdi OA, 2016, WIREL COMMUN MOB COM, V16, P2663, DOI 10.1002/wcm.2715
   MATSUO S, 2013, IEEE COMMUNICATION L, V17, DOI DOI 10.1186/CC12493
   Najjar-Ghabel S, 2017, WIREL PERS COMMUN, V97
   Nikzad M, 2018, MULTIMED TOOLS APPL, V77, P19547, DOI 10.1007/s11042-017-5397-z
   Piccardi M., 2004, P IEEE INT C SYST MA
   Redondi A, 2013, MULT SIGN PROC MMSP
   Redondi AE, 2016, IEEE INFOCOM SER
   Shi K, 2015, ELSEVIER INFORM SCI, V292
   Souza EL, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2938639
   Taj M, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940281
   Ur Rehman YA, 2016, IEEE SENSORS J, V16
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang X, 2013, PATTERN RECOGN LETT, V34
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang Y, 2014, COMPUT ELECTR ENG, V40, P484, DOI 10.1016/j.compeleceng.2013.07.005
   Wu B, 2016, IEEE SENSORS J, V16
   Xiao S, 2018, MULTIMED TOOLS APPL, V77, P12003, DOI 10.1007/s11042-017-4846-z
   Xu Y, 2011, IEEE INT C MOB DAT M
   Yuan XH, 2017, J NETW SYST MANAG, V25, P21, DOI 10.1007/s10922-016-9379-7
NR 40
TC 13
Z9 13
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18921
EP 18941
DI 10.1007/s11042-019-7204-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200070
DA 2024-07-18
ER

PT J
AU Liu, HJ
   Wen, FT
   Kadir, A
AF Liu, Hongjun
   Wen, Fengtong
   Kadir, Abdurahman
TI Construction of a new 2D Chebyshev-Sine map and its application to color
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D Chebyshev-Sine map; One-time keys; Avalanche effect
ID PERMUTATION; SCHEME
AB A new 2D Chebyshev-Sine map with natural evaluation is proposed and its dynamical behavior is analyzed. To investigate its application in information security, a color image encryption algorithm is designed. One-time initial condition expressed as ordered quaternion is extracted from colored non Gaussian noise before each encryption process. The algorithm can achieve desired effect after two rounds by exclusive or (XOR) operation with avalanche effect. Simulation results demonstrated that the speed is fast, so the algorithm is suitable for image encryption over the Cloud.
C1 [Liu, Hongjun; Wen, Fengtong] Jinan Univ, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
   [Liu, Hongjun] Weifang Vocat Coll, Shandong Famous Teachers Workshop, Weifang 261041, Shandong, Peoples R China.
   [Kadir, Abdurahman] Xinjiang Univ Finance & Econ, Sch Engn & Comp Sci, Urumqi 830012, Peoples R China.
C3 University of Jinan; Xinjiang University of Finance & Economics
RP Liu, HJ (corresponding author), Jinan Univ, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.; Liu, HJ (corresponding author), Weifang Vocat Coll, Shandong Famous Teachers Workshop, Weifang 261041, Shandong, Peoples R China.
EM sms_liuhj@ujn.edu.cn
OI Liu, Hongjun/0000-0003-4991-6696
FU National Natural Science Foundation of China [61662073, 61363082];
   Natural Science Foundation of Shandong Province [ZR2018LF006]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61662073, 61363082), the Natural Science Foundation of
   Shandong Province (No: ZR2018LF006).
CR Abdallah E, 2007, INT C IM AN REC
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Arroyo D, 2008, CHAOS, V18, DOI 10.1063/1.2959102
   Banerjee S, 1998, PHYS REV LETT, V80, P3049, DOI 10.1103/PhysRevLett.80.3049
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Ben Hamza A, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY - PROCEEDINGS, P257
   Gao ZG, 2018, IET IMAGE PROCESS, V12, P472, DOI 10.1049/iet-ipr.2017.0383
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kurian AP, 2009, IEEE T CIRCUITS-I, V56, P820, DOI 10.1109/TCSI.2008.2002922
   LEcuyer P, 2013, TESTU01 SOFTWARE LIB
   Ling C, 1999, IEEE T SIGNAL PROCES, V47, P1424, DOI 10.1109/78.757236
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Luo C, 2014, J VIB CONTROL, V20, P1831, DOI 10.1177/1077546313476727
   Rozenbaum EB, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.086801
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 26
TC 49
Z9 50
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15997
EP 16010
DI 10.1007/s11042-018-6996-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500012
DA 2024-07-18
ER

PT J
AU Tian, XY
   Li, HF
   Deng, HX
AF Tian, Xiuyan
   Li, Haifang
   Deng, Hongxia
TI Object Tracking Algorithm based on Improved ContextModel in Combination
   with DetectionMechanismforSuspectedObjects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Occlusion detection; Early warning; Context
   information; Confidence degree; Spatio-temporal feature
ID VISUAL TRACKING
AB Built upon the methodology of spatio-temporal context, a simple yet robust object tracking method is proposed for solving the occlusion problems in this paper. This algorithm makes full use of the context information of the object and its local background to calculate the features, which maximumlly improve the occlusion predictive response and recapture accuracy. Firstly, an early warning mechanism is adopted to realize the occlusion detection. Once the object is fully occluded, the object position with accurate motion information saved in the early warning is predicted and memory tracking model is used to delete the suspected object region, which reduces the matching complexity. Finally, a confidence strategy for similarity measurement is adopted to capture the suspected object when the object appears, and the optimal confidence is introduced to get an adaptive update model. Many simulation experiments in benchmark videos show that our proposed algorithm achieves more favorable performance than these existing state-of-the-art algorithms.
C1 [Tian, Xiuyan; Li, Haifang; Deng, Hongxia] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030600, Shanxi, Peoples R China.
   [Tian, Xiuyan] Yuncheng Univ, Dept Econ & Management, Yuncheng 044000, Peoples R China.
C3 Taiyuan University of Technology; Yuncheng University
RP Tian, XY (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030600, Shanxi, Peoples R China.; Tian, XY (corresponding author), Yuncheng Univ, Dept Econ & Management, Yuncheng 044000, Peoples R China.
EM Tianxiuyan197901@foxmail.com; lihaifang@tyut.edu.cn;
   denghongxia@tyut.edu.cn
FU National Natural Science Foundation of Shanxi Province [2014021022-5];
   Technological Project of State Grid Corporation of China [5205301500]
FX This work was supported by the National Natural Science Foundation of
   Shanxi Province (No. 2014021022-5), and the Technological Project of
   State Grid Corporation of China (No. 5205301500). The authors thank
   Zhang Kaihua and Kalal for providing their results.
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen X, 2008, MACH VISION APPL, V19, P217, DOI 10.1007/s00138-007-0094-y
   CHOI J, 2015, J INFRARED MILLIMETE, V34, P11, DOI DOI 10.1007/S13131-015-0774-9
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jiang HL, 2016, NEUROCOMPUTING, V207, P189, DOI 10.1016/j.neucom.2016.03.074
   Kalal M, 2011, TRACKING LEARNING DE
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Liu L, 2016, 30 AAAI C ART INT
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Su Z, 2017, ACTA TRIBUNE CHINA, V38, P1140
   Tao XIE, 2017, JEIT, V40, P602
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wen LY, 2012, LECT NOTES COMPUT SC, V7575, P716, DOI 10.1007/978-3-642-33765-9_51
   Wu Y, 2017, MULTIMED TOOLS APPL, P1
   Yang C, 2016, INF TECHNOL, V38, P211
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2013, IEEE T CIRC SYST VID, V23, P1957, DOI 10.1109/TCSVT.2013.2269772
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang XL, 2015, IEEE T PATTERN ANAL, V37, P28, DOI 10.1109/TPAMI.2014.2343221
NR 27
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16907
EP 16922
DI 10.1007/s11042-018-7025-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500052
DA 2024-07-18
ER

PT J
AU Wang, HH
   Tu, CW
   Chiang, CK
AF Wang, Hui-Hung
   Tu, Chia-Wei
   Chiang, Chen-Kuo
TI Sparse representation for image classification via paired dictionary
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dictionary learning; Sparse coding; Visual recognition
ID DISCRIMINATIVE DICTIONARY; COUPLED DICTIONARY; FACE RECOGNITION; K-SVD;
   ALGORITHM
AB Sparse coding technique is usually applied for feature representation. To learn discriminative features for visual recognition, a dictionary learning method, called Paired Discriminative K-SVD (PD-KSVD), is presented in this paper. Firstly, to reduce the reconstruction error of positive class while increasing the errors of negative classes, the scheme inverted signal is applied to the negative training samples. Then, the class-specific sub-dictionaries are learned from pairs of positive and negative classes to jointly achieve high discrimination and low reconstruction errors for sparse coding. Multiple sub-dictionaries are concatenated with respect to the same negative class so that the non-zero sparse coefficients can be discriminatively distributed to improve classification accuracy. Last, sparse coefficients are solved via the concatenated sub-dictionaries and used to train the classifier. Compared to the existing dictionary learning methods, PD-KSVD method achieves superior performance in a variety of visual recognition tasks on several publicly available datasets.
C1 [Wang, Hui-Hung; Tu, Chia-Wei; Chiang, Chen-Kuo] Natl Chung Cheng Univ, CIRAS, Adv Inst Mfg High tech Innovat, 168,Sec 1,Univ Rd, Chiayi, Taiwan.
   [Wang, Hui-Hung; Tu, Chia-Wei; Chiang, Chen-Kuo] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, 168,Sec 1,Univ Rd, Chiayi, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University
RP Chiang, CK (corresponding author), Natl Chung Cheng Univ, CIRAS, Adv Inst Mfg High tech Innovat, 168,Sec 1,Univ Rd, Chiayi, Taiwan.; Chiang, CK (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, 168,Sec 1,Univ Rd, Chiayi, Taiwan.
EM huihung55@gmail.com; pc80927@gmail.com; ckchiang@cs.ccu.edu.tw
OI Chiang, Chen-Kuo/0000-0001-5276-1109
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], LEARNING CANONICAL C
   [Anonymous], 2013, P 2013 4 NATL C COMP, DOI DOI 10.1109/NCVPRIPG.2013.6776176
   [Anonymous], P 2016 ACM MULT C
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bao CL, 2013, IEEE I CONF COMP VIS, P3384, DOI 10.1109/ICCV.2013.420
   Ben Said A, 2017, I C COMP SYST APPLIC, P63, DOI 10.1109/AICCSA.2017.117
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7
   Engan K, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P1, DOI 10.1109/ISCAS.1999.779928
   Feng ZZ, 2013, PATTERN RECOGN, V46, P2134, DOI 10.1016/j.patcog.2013.01.016
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Gu SH, 2014, ADV NEUR IN, V27
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T KNOWL DATA EN, V29, P1186, DOI 10.1109/TKDE.2017.2669982
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Shen L, 2013, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2013.56
   Sun XX, 2018, IEEE IMAGE PROC, P346, DOI 10.1109/ICIP.2018.8451701
   Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760
   Toh SH, 2011, BMC GENOMICS, V12, DOI 10.1186/1471-2164-12-S3-S24
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
NR 39
TC 9
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16945
EP 16963
DI 10.1007/s11042-018-6888-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500054
DA 2024-07-18
ER

PT J
AU Ashiba, HI
   Mansour, HM
   Ahmed, HM
   Dessouky, MI
   El-Kordy, MF
   Zahran, O
   Abd El-Samie, FE
AF Ashiba, H. I.
   Mansour, H. M.
   Ahmed, H. M.
   Dessouky, M. I.
   El-Kordy, M. F.
   Zahran, O.
   Abd El-Samie, Fathi E.
TI Enhancement of IR images using histogram processing and the Undecimated
   additive wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Additive wavelet transform; IR images; Homomorphic image enhancement;
   CLAHE
AB This paper presents a fabulous enhancement approach for infrared (IR) images. This approach mixes the benefits of the undecimated Additive Wavelet Transform (AWT) with the homomorphic transform and Contrast Limited Adaptive Histogram Equalization (CLAHE). The basic idea of this approach depends on applying the CLAHE on the IR image. Then, the resultant image is decomposed into sub-bands using the AWT. The homomorphic enhancement is implemented on each sub-band, separately, up to the sixth sub-band. The homomorphic enhancement is applied on the IR image in the log domain by decomposing the image into illumination and reflectance components. The illumination is attenuated, while the reflectance is magnified. Applying this method on each sub-band gives more details in the IR image. The performance quality metrics for the suggested approach are entropy, average gradient, contrast, and Sobel edge magnitude. Simulation results reveal the success of the proposed approach in enhancing the quality of IR images.
C1 [Ashiba, H. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
   [Mansour, H. M.; Ahmed, H. M.] Banha Univ, Fac Shoubra Engn, Dept Elect & Elect Commun, Banha, Egypt.
   [Dessouky, M. I.; El-Kordy, M. F.; Zahran, O.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Benha University; Egyptian Knowledge Bank
   (EKB); Menofia University
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; ashiba, huda/GQI-4310-2022
OI Sayed, Fathi/0000-0001-8749-9518; Zahran, Osama/0000-0001-5334-5908; ,
   HM Abdelkader/0009-0005-7854-7545; ashiba, huda/0000-0002-4926-8919
CR [Anonymous], DIGITAL IMAGE PROCES
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Chan A. L., 2010, P SPIE DSS AUTOMATIC, V7696, P1
   Ehsaeyan E, 2016, IRANIAN J ELECT ELEC, V12
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Jae S., 1990, Two-dimensional signal and image processing
   Marshall S, 2006, ADV NONLINEAR SIGNAL
   Petrou ML., 1999, IMAGE PROCESSING FUN
   Qi W, 2016, INFRARED PHYS TECHN, V76, P684, DOI 10.1016/j.infrared.2016.04.038
   Qi YH, 2016, INFRARED PHYS TECHN, V76, P521, DOI 10.1016/j.infrared.2016.03.021
   Song Q, 2016, INFRARED PHYS TECHN, V77, P464, DOI 10.1016/j.infrared.2016.06.023
   Vincent O., 2009, A descriptive algorithm for sobel image edge detection
   Yang Z, 2017, 2017 IEEE 36 INT PER
   Zhang XH, 2017, DYES PIGMENTS, V138, P204, DOI 10.1016/j.dyepig.2016.11.022
   Zhu P, 2017, INFRARED PHYS TECHN, V81, P282, DOI 10.1016/j.infrared.2017.01.013
   Zhuqing J, 2011, THESIS
NR 17
TC 24
Z9 25
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11277
EP 11290
DI 10.1007/s11042-018-6545-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900009
DA 2024-07-18
ER

PT J
AU Dou, JF
   Qin, Q
   Tu, ZM
AF Dou, Jianfang
   Qin, Qin
   Tu, Zimei
TI Image fusion based on wavelet transform with genetic algorithms and
   human visual system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Genetic algorithms; Human Visual System; Multi-scale
   transform
ID PERFORMANCE; SCHEMES
AB A novel wavelet-based approach for multi-focus image fusion is presented, which is developed by taking into not only account the characteristics of human visual system (HVS) but also consider the optimization of image quality index to meet the human perception. After the multi-focus images to be fused are decomposed by the wavelet transform, different-fusion schemes for combining the coefficients are proposed: coefficients in low-frequency band are using the genetic algorithms to estimate the optimal weight according to the Edge-Association Index, and coefficients in high-frequency bands are weighted fusion by the texture masking of human visual system. To overcome the presence of noise and guarantee the homogeneity of the fused image, all the coefficients are subsequently performed by a window-based consistency verification process. The fused image is finally constructed by the inverse wavelet transform with all composite coefficients. To quantitatively evaluate and prove the performance of the proposed method, series of experiments and comparisons with some existing fusion methods are carried out in the paper. Experimental results on simulated and real images indicate that the proposed method is effective and can get satisfactory fusion results.
C1 [Dou, Jianfang; Qin, Qin; Tu, Zimei] Shanghai Polytech Univ, Sch Intelligent Mfg & Control Engn, Dept Automat & Mech & Elect Engn, Shanghai 201209, Peoples R China.
C3 Shanghai Polytechnic University
RP Dou, JF (corresponding author), Shanghai Polytech Univ, Sch Intelligent Mfg & Control Engn, Dept Automat & Mech & Elect Engn, Shanghai 201209, Peoples R China.
EM jfdou@sspu.edu.cn
RI Dou, Fang Jian/ABR-7700-2022; Zhuo, Xianglong/HNO-9030-2023; qin, qin
   x/GXG-6164-2022
FU Shanghai University Outstanding Teachers Cultivation Fund Program
   [A30DB1524011-21]; 2015 School Fund Project [A01GY15GX48]; Shanghai
   Second Polytechnic University Mechanical Engineering Key Disciplines
   [XXKZD1603]; Construction of University Enterprise Cooperation
   Automobile Electronic Joint Experiment Center [A11NH182016]
FX The authors would particularly like to thank the anonymous Reviewers for
   their helpful suggestions. This work was supported by the by Shanghai
   University Outstanding Teachers Cultivation Fund Program A30DB1524011-21
   and 2015 School Fund Project A01GY15GX48 and Shanghai Second Polytechnic
   University Mechanical Engineering Key Disciplines XXKZD1603 and the
   Construction of University Enterprise Cooperation Automobile Electronic
   Joint Experiment Center, Grant Number A11NH182016.
CR [Anonymous], 2018, ARXIV180607119
   BUCHSBAUM G, 1980, IEEE T BIO-MED ENG, V27, P237, DOI 10.1109/TBME.1980.326628
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chipman L. J., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P248, DOI 10.1109/ICIP.1995.537627
   Dong LM, 2015, NEUROCOMPUTING, V159, P268, DOI 10.1016/j.neucom.2015.01.050
   Dongmei Yan, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P291, DOI 10.1109/ICII.2001.982761
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Jing Z, 2007, IMAGE FUSION THEORY, P70
   Jing Z, 2018, NONCOOPERATIVE TARGE, P251
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu Gui-Xi, 2002, Acta Automatica Sinica, V28, P927
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Mumtaz A, 2010, GENETIC ALGORITHMS I
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Redondo R, 2009, INFORM FUSION, V10, P163, DOI 10.1016/j.inffus.2008.08.006
   Shivappa ST, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/478396
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Singh R, 2013, SCI WORLD J, DOI 10.1155/2013/521034
   Singh R, 2012, J MED IMAG HEALTH IN, V2, P168, DOI 10.1166/jmihi.2012.1080
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wang Y., 2000, Multisensor Image Fusion: Concept, Method and Applications
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1997, J OPT SOC AM A, V14, P2379, DOI 10.1364/JOSAA.14.002379
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 34
TC 13
Z9 14
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12491
EP 12517
DI 10.1007/s11042-018-6756-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900063
DA 2024-07-18
ER

PT J
AU Gennari, R
   Melonio, A
   Rizvi, M
AF Gennari, Rosella
   Melonio, Alessandra
   Rizvi, Mehdi
TI Turn taking with turn-talk in group: Actions and reflections with
   children and teachers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action research; Meta-design; Tangible; Conversation; Children; Teachers
ID SUPPORT
AB Conversations are structured by norms for turn taking. Turn taking is practiced in primary schools, starting from 8 years of age, when turn taking is used for managing group conversations. Being rather abstract for children to master, teachers use physical objects to convey turn taking. However, such physical objects tend not to be effective with children. Past research indicates that interactive tangible objects (briefly, tangibles) might help primary school classes master turn taking and positively affect their conversation behaviours. The research of this paper pursues this idea and shows how a meta-design approach, based on action research, can help design tangibles for conveying turn taking in group. The paper focuses on several actions with TurnTalk in the same primary school classroom with 9-10 years old children, and it shows how actions led to benefits for the class and designers.
C1 [Gennari, Rosella; Melonio, Alessandra; Rizvi, Mehdi] Free Univ Bozen Bolzano, Piazza Domenicani 3, Bolzano, Italy.
C3 Free University of Bozen-Bolzano
RP Gennari, R (corresponding author), Free Univ Bozen Bolzano, Piazza Domenicani 3, Bolzano, Italy.
EM gennari@inf.unibz.it; alessandra.melonio@unibz.it; SRizvi@unibz.it
RI Gennari, Rosella/AAX-1802-2021; Gennari, Rosella/HIR-3964-2022; Rizvi,
   Mehdi/AAV-6017-2021
OI Gennari, Rosella/0000-0003-0063-0996; Melonio,
   Alessandra/0000-0001-6655-1946; Rizvi, Mehdi/0000-0001-8386-5779
CR [Anonymous], 2004, CHI 04 EXTENDED ABST
   [Anonymous], 2016, WHAT IS ARDUINO
   [Anonymous], 1999, COMMUN ASSOC INF SYS
   [Anonymous], 2007, P 2007 40 ANN HAWAII
   Anthony L., 2013, P 12 INT C INTERACTI, P157, DOI [10.1145/2485760.2485775, DOI 10.1145/2485760.2485775]
   Bachour K, 2010, IEEE T LEARN TECHNOL, V3, P203, DOI 10.1109/TLT.2010.18
   Blatchford P, 2016, CHILD SCH, V2nd
   Brondino M, 2015, EMOTIONS INCLUSION C, P1
   Cabitza F., 2014, LNISO, P193, DOI DOI 10.1007/978-3-319-07040-7_
   Costabile MF, 2007, IEEE T SYST MAN CY A, V37, P1029, DOI 10.1109/TSMCA.2007.904776
   Di Mascio T, 2017, MULTIMED TOOLS APPL, V76, P4855, DOI 10.1007/s11042-016-3609-6
   Diaz P, 2015, ENG CREATIVE CODESIG
   DiMicco JM, 2007, HUM-COMPUT INTERACT, V22, P47
   Dodero G., 2014, CHI 14 EXTENDED ABST, P707
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Fogli Daniela, 2015, PHYS PROTOTYPING SOC, P217, DOI [10.1007/978-3-319-18425-8-_}19, DOI 10.1007/978-3-319-18425-8-_}19]
   Fosnot C.T., 2005, CONSTRUCTIVISM THEOR
   Fu C, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P609, DOI 10.1145/3024969.3025079
   Gennari Rosella, 2017, End-User Development. 6th International Symposium, IS-EUD 2017. Proceedings: LNCS 10303, P167, DOI 10.1007/978-3-319-58735-6_12
   Gennari R, 2017, INT J HUM-COMPUT ST, V101, P45, DOI 10.1016/j.ijhcs.2017.01.006
   Gennari R, 2016, LNCS
   Gennari R, 2018, EVOLVING TANGIBLES C, P368
   Gennari R, 2018, P 12 INT C TANG EMB
   Gennari R, 2017, PARTICIPATORY DESIGN, P167
   Gennari R, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206513
   Gennari R, 2017, MULTIMED TOOLS APPL, V76, P4925, DOI 10.1007/s11042-016-3543-7
   Gorjian B., 2015, J APPL LINGUISTICS L, V1, P14
   Hourcade Juan Pablo., Child Computer Interaction
   Ivankova N., 2015, MIXED METHODS APPL A
   Joshi Suhas Govind, 2016, Scandinavian Journal of Information Systems, V28, P3
   Kapp K.M., 2013, GAMIFICATION LEARNIN
   Kock N, 2018, ACTION RES
   Leonardi C, 2009, HUM-COMPUT INT-SPRIN, P187, DOI 10.1007/978-1-84882-054-8_17
   Malone T, 1988, APTITUDE LEARNING IN, V3, P229
   Maquil Valerie, 2015, HUMAN COMPUTER INTER, P79
   McCrindle C, 2011, PROCEEDINGS OF IDC 2011: THE 10TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2011), P181
   Melonio A., 2016, DESIGN TURNTALK SCAF, P278
   Nijholt A, 2006, AI SOC, V20, P202, DOI 10.1007/s00146-005-0016-3
   Ocumpaugh J., 2015, Monitoring protocol (bromp) training manual
   Olson IC, 2011, TEI 2011: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION, P29
   Piaget J., 1952, ORIGINS INTELLIGENCE
   Pianesi F, 2008, PERS UBIQUIT COMPUT, V12, P181, DOI 10.1007/s00779-007-0144-5
   Pollock P, 2011, J POLITICAL SCI ED
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Schiavo Gianluca, 2014, P 19 INT C INT US IN, P225, DOI DOI 10.1145/2557500.2557507
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Shaw F.W., 2010, P 12 ACM INT C ADJUN, P379
   Slovák P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2797, DOI 10.1145/2702123.2702385
   Slovák P, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2744195
   VYGOTSKII LS, 1930, MIND SOC
   Weiser M., 1994, UIST '94: Proceedings of the 7th Annual ACM Symposium on User Interface Software and Technology, P1, DOI [10.1145/192426.192428, DOI 10.1145/192426.192428]
   [No title captured]
   [No title captured]
NR 53
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13461
EP 13487
DI 10.1007/s11042-018-7090-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900039
DA 2024-07-18
ER

PT J
AU Kaur, G
   Kasana, SS
   Sharma, MK
AF Kaur, Gagandeep
   Kasana, Singara Singh
   Sharma, M. K.
TI An efficient watermarking scheme for enhanced high efficiency video
   coding/h.265
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding; DST; DCT; Video watermarking
ID ROBUST WATERMARKING; HEVC; FRAMEWORK
AB In this paper, an efficient drift free watermarking scheme is proposed for enhanced high efficiency video coding standard. This standard uses multiple transforms to efficiently de-correlate the residual error of intra luma block in an I frame. Some of these transforms are not symmetric, thus cannot be used directly for embedding watermark. In this scheme, symmetric transforms are used to embed watermark into selected luma transform blocks. The relationship between the magnitudes of a pair of transform coefficients of luma transform block is utilized to embed the watermark. This pair of coefficients is selected in such a way that error drift is not propagated to neighbouring blocks during intra prediction process of the standard. Embedded watermark can be extracted by decoding only non-zero quantized transform coefficients from the compressed bit stream which makes it useful for real time applications. Experimental results justify the efficiency of the proposed scheme with respect to the existing schemes in terms of imperceptibility, bit increase rate, robustness against re-compression, noise and temporal attacks.
C1 [Kaur, Gagandeep; Kasana, Singara Singh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Sharma, M. K.] Thapar Inst Engn & Technol, Sch Math, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Kaur, G (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM gagandeep.kaur@thapar.edu; singara@thapar.edu; mksharma@thapar.edu
RI kaur, Gagandeep/AAG-5779-2021
OI kaur, Gagandeep/0000-0002-1513-8446
FU Maulana Azad National Fellowship (MANF) under UGC
   [MANF-2014-15-SIK-PUN-32682]
FX This work is supported by Maulana Azad National Fellowship (MANF) under
   UGC with application number MANF-2014-15-SIK-PUN-32682.
CR Alattar AM, 2003, IEEE T CIRC SYST VID, V13, P787, DOI 10.1109/TCSVT.2003.815958
   An J, 2011, NON CE7 BOUNDARY DEP
   [Anonymous], 2016, INT J SOFTW ENG ITS, DOI DOI 10.14257/IJSEIA.2016.10.1.25
   [Anonymous], 2015, High Efficiency Video Coding: coding tools and specifications
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen JY, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P991, DOI 10.1109/BigData.2015.7363850
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dutta T, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3002178
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Gaj S., 2015, 5 NAT C COMP VIS PAT, P1
   GAJ S, 2017, COMPUTER, V13, P11, DOI DOI 10.1145/3009910
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Li L, 2015, J VIS COMMUN IMAGE R, V26, P1, DOI 10.1016/j.jvcir.2014.08.009
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P6459, DOI 10.1007/s11042-018-6320-y
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ogawa K, 2015, I SYMP CONSUM ELECTR, P102, DOI 10.1109/ICCE.2015.7066337
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Shanableh T, 2018, MULTIMED TOOLS APPL, V77, P8939, DOI 10.1007/s11042-017-4787-6
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhao X, 2016, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC.2016.9
NR 29
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12537
EP 12559
DI 10.1007/s11042-018-6791-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900065
DA 2024-07-18
ER

PT J
AU Ponuma, R
   Amutha, R
AF Ponuma, R.
   Amutha, R.
TI Encryption of image data using compressive sensing and chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Compressive sensing; Cryptography; Dimensionality
   reduction; Image compression-encryption
ID ALGORITHM; SECURITY
AB An image cryptosystem using chaotic compressive sensing is designed to achieve simultaneous compression - encryption. Compressive sensing requires a measurement matrix to compressively sample a sparse signal and to guarantee its recovery at the receiver. In this paper, a new one-dimensional chaotic map is proposed which is used to construct the chaotic measurement matrix. Performance analysis demonstrates that the proposed chaotic map is highly chaotic, ergodic, highly sensitive to the initial conditions and suitable for chaotic compressive sensing. The parameters of the chaotic system are used as the secret key in the construction of measurement matrix and also the masking matrix. The sparse representation of the image is obtained using discrete wavelet transform. The sparse coefficients are then compressively sampled and encrypted using the chaotic measurement matrix and masking matrix. A parallel compressive sensing framework is employed which greatly improves the efficiency of the proposed chaotic compressive sensing scheme. Simulation results shows that the proposed scheme has good security performance against various attacks and better reconstruction performance, when compared with the commonly used random measurement matrix.
C1 [Ponuma, R.; Amutha, R.] SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Ponuma, R (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM ponumar@ssn.edu.in
RI Amutha, R./AAB-9399-2020
CR [Anonymous], TPDS
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Badve O., 2016, Handbook of Research on Modern Cryptographic Solutions for Computer and Cyber Security, P479, DOI DOI 10.4018/978-1-5225-0105-3.CH020
   Bandeira AS, 2013, IEEE T INFORM THEORY, V59, P3448, DOI 10.1109/TIT.2013.2248414
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cambareri V, 2015, IEEE T INF FOREN SEC, V10, P2182, DOI 10.1109/TIFS.2015.2450676
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Deepak M, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P360, DOI 10.1109/CNSC.2014.6906665
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fay R, 2016, INT CONF INTERNET, P119, DOI 10.1109/ICITST.2016.7856681
   Fay R, 2016, INFORM PROCESS LETT, V116, P279, DOI 10.1016/j.ipl.2015.11.010
   Hu GQ, 2017, OPT LASER ENG, V98, P123, DOI 10.1016/j.optlaseng.2017.06.013
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Mahesh M, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1849, DOI 10.1109/ICCSP.2015.7322844
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Peng HP, 2017, IEEE T BIOMED CIRC S, V11, P558, DOI 10.1109/TBCAS.2017.2665659
   Phamila AVY, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0411
   Phamila YAV, 2013, INFORM PROCESS LETT, V113, P672, DOI 10.1016/j.ipl.2013.06.008
   Ponnaian D, 2017, OPTIK, V147, P263, DOI 10.1016/j.ijleo.2017.07.063
   Ponuma R, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P172, DOI 10.1109/WiSPNET.2016.7566114
   Pudi V, 2018, IEEE T CIRCUITS-II, V65, P371, DOI 10.1109/TCSII.2017.2715659
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yang ZY, 2015, IEEE T EMERG TOP COM, V3, P363, DOI 10.1109/TETC.2014.2372151
   Yaseen Q, 2018, MULTIMED TOOLS APPL, V77, P18249, DOI 10.1007/s11042-017-5288-3
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhang LY, 2016, IEEE T MULTIMEDIA, V18, P1720, DOI 10.1109/TMM.2016.2581593
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou Y., 2012, IEEE T CYBERNETICS, V45, P2001, DOI DOI 10.1109/TCYB.2014.2363168
NR 38
TC 29
Z9 30
U1 0
U2 73
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11857
EP 11881
DI 10.1007/s11042-018-6745-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900035
DA 2024-07-18
ER

PT J
AU Ratnakumar, R
   Nanda, SJ
AF Ratnakumar, Rahul
   Nanda, Satyasai Jagannath
TI A low complexity hardware architecture of K-means algorithm for
   real-time satellite image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; K-means clustering; Finite state machine; Moore
   machine; Reconfigurable
AB The Real time monitoring of forest area, coastal regions, sea, river basins, nation borders etc. helps in quick determination of devastations caused by natural or man-made catastrophes, which can lead to emergency situations. Real-time Segmentation of satellite images is essential to detect fire, floods, volcanoes, earthquakes etc. of a specific geographical zone. Effective determination of such calamities and taking proactive measures can save a lot of lives and natural resources. In this paper, an efficient FSM based architecture is proposed for performing segmentation of satellite Images procured from NASA's Operational Land Imager (OLI) on Landsat 8 and Landsat 5. The K-means clustering algorithm even after five decades of it's existence is quite effective and mostly used for big data applications, owing to its lower complexity. However, it's effective implementation has started only in the last couple of years. Here a FSM-based reconfigurable architecture is proposed for K-means algorithm taking into consideration the real-time segmentation of satellite Images. Compared to other architectures in the literature, the proposed one has reduced hardware usage, lower area, power consumption with a satisfactory clock frequency, most importantly it is reconfigurable and can be used with the on-board circuitry within satellites. The testing is carried out on eight latest satellite images of natural and human devastations, taken from NASA's OLI. The number of possible clusters within the geographical image is studied with the help of histogram analysis based on Otsu's thresholding method. The performance analysis is carried out by computing the Peak Signal to Noise (PSNR) and Mean Structural Similarity Index (M-SSIM) of the resultant clusters. It is observed that by increasing the number of clusters, the detailed classes were effectively segmented and the quality of clustering is ensured by the improvement in PSNR and M-SSIM values. Comparison of the obtained clusters with their true land features also yielded satisfactory results.
C1 [Ratnakumar, Rahul; Nanda, Satyasai Jagannath] Malaviya Natl Inst Technol, Dept Elect & Commun Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Ratnakumar, R (corresponding author), Malaviya Natl Inst Technol, Dept Elect & Commun Engn, Jaipur 302017, Rajasthan, India.
EM 2014rec9032@mnit.ac.in; sjnanda.ece@mnit.ac.in
RI Nanda, Satyasai Jagannath/N-5095-2017
OI Nanda, Satyasai Jagannath/0000-0002-4005-5589; Ratnakumar,
   Rahul/0000-0002-2079-9062
CR A Plaza QD, 2011, INT J HIGH PERFORM C, V4, P528
   [Anonymous], 2006, FUNDAMENTALS DIGITAL
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Borengasser M., 2007, Hyperspectral Remote Sensing: Principles and Applications
   Camps-Valls G., 2011, Recherches sur la Methode, V5, P1, DOI 10.2200/S00392ED1V01Y201107IVM012
   Chen TW, 2008, IEEE INT SYMP CIRC S, P2578, DOI 10.1109/ISCAS.2008.4541983
   Chen TW, 2011, IEEE T VLSI SYST, V19, P1336, DOI 10.1109/TVLSI.2010.2049669
   Chen TW, 2010, IEEE T VLSI SYST, V18, P957, DOI 10.1109/TVLSI.2009.2017543
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   da S AG, 2003, 16TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN, SBCCI 2003, PROCEEDINGS, P99
   González C, 2012, IEEE J-STARS, V5, P248, DOI 10.1109/JSTARS.2011.2171673
   González C, 2012, IEEE T GEOSCI REMOTE, V50, P374, DOI 10.1109/TGRS.2011.2171693
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Harris DL, 2003, P 13 IEEE S COMP AR, P18
   Hauck S, 1998, P IEEE, V86, P615, DOI 10.1109/5.663540
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hussain H. M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P475, DOI 10.1109/ReConFig.2011.49
   Hussain H. M., 2011, Proceedings of the 2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), P248, DOI 10.1109/AHS.2011.5963944
   Israel K, 2009, COMPUTER ARITHMETIC
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jigang W, 2010, IEEE T COMPUT, V59, P532, DOI 10.1109/TC.2009.173
   Kutty JSS, 2013, IEEE INT SYMP CIRC S, P1801, DOI 10.1109/ISCAS.2013.6572215
   Lavenier D, 2000, 003079118 LAUR LOS A, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nanda SJ, 2014, SWARM EVOL COMPUT, V16, P1, DOI 10.1016/j.swevo.2013.11.003
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Oberman SF, 1997, IEEE T COMPUT, V46, P833, DOI 10.1109/12.609274
   Plaza A, 2008, PARALLEL COMPUT, V34, P92, DOI 10.1016/j.parco.2007.12.005
   Plaza AJ, 2009, J REAL-TIME IMAGE PR, V4, P191, DOI 10.1007/s11554-009-0126-0
   Plaza Chang C-I, 2007, HIGH PERFORMANCE COM
   Ratnakumar R, 2016, INT SYM VLSI DES TES
   Richards J.A., 2006, Remote Sensing Digital Image Analysis, P359, DOI DOI 10.1007/3-540-29711-1_13
   Robertson J., 1958, Electronic Computers, IRE Transactions on, VEC-7, P218, DOI DOI 10.1109/TEC.1958.5222579
   Saegusa T, 2007, J REAL-TIME IMAGE PR, V2, P309, DOI 10.1007/s11554-007-0055-8
   Sinangil ME, 2012, IEEE IMAGE PROC, P1529, DOI 10.1109/ICIP.2012.6467163
   Sonka Milan., 2001, IMAGE PROCESSING ANA
   Tocher K.D., 1958, Q J MECH APPL MATH, V11, P364, DOI DOI 10.1093/QJMAM/11.3.364
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 43
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11949
EP 11981
DI 10.1007/s11042-018-6726-6
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900039
DA 2024-07-18
ER

PT J
AU Thanki, R
   Borra, S
AF Thanki, Rohit
   Borra, Surekha
TI Fragile watermarking for copyright authentication and tamper detection
   of medical images using compressive sensing (CS) based encryption and
   contourlet domain processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Contourlet transform (CT); Fragile; Medical image;
   Non-blind watermarking; Security
ID TRANSFORM; RECOVERY
AB With the rapid growth in communication and computing technologies, transmission of digital images and medical images over the Internet is on the rise. In such scenario, there is a special need to meet the security and privacy issues and challenges of an individual and Intellectual Property (IP) owners. It is highly important for an individual to keep his/her personal images against invalid manipulation by the impostors. Hence developments of authentication and tamper detection techniques are the need of the hour. In this paper, a new hybrid non-blind fragile watermarking technique is proposed for tamper detection of images and for securing the copyrights of sensitive images. A combination of Compressive Sensing (CS) theory, Discrete Wavelet Transform (DWT), and Non-Subsampled Contourlet Transform (NSCT) are employed to achieve security, high embedding capacity, and authenticity. In this technique, the requirements are achieved by inserting encrypted watermark in lower frequency contourlet coefficients of cover images. The experimental results prove that this proposed technique provides high security, high imperceptibility, authenticity and tamper detection of various common signal processing and geometrical attacks.
C1 [Thanki, Rohit] CU Shah Univ, Fac Technol & Engn, Wadhwan City, India.
   [Borra, Surekha] KS Inst Technol, Dept ECE, Bangalore, Karnataka, India.
RP Thanki, R (corresponding author), CU Shah Univ, Fac Technol & Engn, Wadhwan City, India.
EM rohitthanki9@gmail.com; borrasurekha@gmail.com
RI Borra, Surekha/AAD-5332-2022; Thanki, Dr. Rohit/Q-9029-2017
OI Borra, Surekha/0000-0002-1842-806X; Thanki, Dr.
   Rohit/0000-0002-0645-6266
CR [Anonymous], 1999, WILEY SER PROB STAT
   [Anonymous], 2015, THESIS
   [Anonymous], MED IMAGING ITS SECU
   Banerjee Shubhendu, 2015, International Journal of Image, Graphics and Signal Processing, V7, P1, DOI 10.5815/ijigsp.2015.03.01
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Barati M, 2015, INT C ULTRA MOD TELE, P1, DOI 10.1109/ICUMT.2015.7382395
   Borra S, 2017, FRONT ARTIF INTEL AP, V296, P450, DOI 10.3233/978-1-61499-785-6-450
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Carlin S, 2011, INT J AMBIENT COMPUT, V3, P14, DOI 10.4018/jaci.2011010102
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dey N, 2017, STUD COMPUT INTELL, V660, P345, DOI 10.1007/978-3-319-44790-2_16
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fridrich J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P792, DOI 10.1109/ICIP.1999.817228
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Kutter M., 1999, ELECT IMAGING 99 SEC, V3657, P1
   Nagesh P, 2009, INT CONF ACOUST SPEE, P1261, DOI 10.1109/ICASSP.2009.4959820
   Qian ZX, 2010, IEEE SIGNAL PROC LET, V17, P929, DOI 10.1109/LSP.2010.2072991
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Rajeswari P, 2017, STUD COMPUT INTELL, V660, P469, DOI 10.1007/978-3-319-44790-2_21
   Raval MS, 2003, TENCON IEEE REGION, P935
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Tchepnda C, 2009, INT J AMBIENT COMPUT, V1, P39, DOI 10.4018/jaci.2009010104
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki RM, 2018, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-319-73183-4
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Yan J., 2009, WAVELET MATRIX
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
NR 35
TC 30
Z9 30
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13905
EP 13924
DI 10.1007/s11042-018-6746-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900058
DA 2024-07-18
ER

PT J
AU Touati, R
   Messaoudi, I
   Oueslati, AE
   Lachiri, Z
AF Touati, Rabeb
   Messaoudi, Imen
   Oueslati, Afef Elloumi
   Lachiri, Zied
TI A combined support vector machine-FCGS classification based on the
   wavelet transform for Helitrons recognition in C.elegans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Helitrons; Repetitive DNA; Microsatellites; C; Elegans; FCGS(2)coding;
   SVM; Features; Continuous wavelet transform; Kernel tricks
ID ROLLING-CIRCLE TRANSPOSONS; IDENTIFICATION; PREDICTION; SIGNALS; DNA;
   RESIDUES; SEQUENCE; FEATURES; PLANT; SVM
AB The Helitrons, an important sub-class of the transposable elements (TEs) class II, have been revealed in diverse eukaryotic genomes. They are mobile elements with great impact on genomic evolution. Till today, there is no systematic classification model of helitrons; that's why we thought of creating an efficient automatic model to identify these sequences. This paper focuses on the discrimination between helitrons and non-helitrons using the Support Vector Machine (SVM). In this study, we use all the SVM kernels and the higher accuracy rates are obtained by reaching the optimal kernels-parameters (d, c and sigma). Further, we introduce two methods to represent the genomic sequences in the form of features to be considered later for the classification task: (i) the temporal and the spectral features extracted from the Frequency Chaos Game Signals order 2 (FCGS(2)) (ii) the features extracted from the Continuous Wavelet Transform (CWT) applied to the FCGS(2) signals. The dataset we used regards two types DNA classes in C.elegans: the helitrons and the repetitive DNA sequences that contain microsatellites and do not form helitrons. The classification results prove that the wavelet energy feature is more effective than the FCGS(2) features in the helitron's recognition system. The performance of our system achieves a high recognition rate (Globally accuracy rate) reaching the value of 92.27%.
C1 [Touati, Rabeb; Messaoudi, Imen; Oueslati, Afef Elloumi; Lachiri, Zied] Univ Tunis El Manar, Natl Sch Engineers Tunis ENIT, SITI Lab, BP 37, Tunis 1002, Tunisia.
   [Messaoudi, Imen] Univ Carthage, Ind Comp Dept, Higher Inst Informat Technol & Commun, Carthage, Tunisia.
   [Oueslati, Afef Elloumi] Univ Carthage, Dept Elect Engn, Natl Sch Engineers Cartage ENICarthage, Carthage, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Carthage; Universite de Carthage
RP Touati, R (corresponding author), Univ Tunis El Manar, Natl Sch Engineers Tunis ENIT, SITI Lab, BP 37, Tunis 1002, Tunisia.
EM Rabeb.touati.enit@gmail.com; imen.messaoudi@enit.rnu.tn;
   Afef.Elloumi@enit.rnu.tn; Zied.lachiri@enit.rnu.tn
RI Touati, Rabeb/AAX-9685-2020
OI Touati, Rabeb/0000-0001-5982-7123
CR Amin HU, 2015, AUSTRALAS PHYS ENG S, V38, P139, DOI 10.1007/s13246-015-0333-x
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2016, MOB GENET ELEMENTS
   [Anonymous], THESIS
   [Anonymous], MACHINE LEARNING
   [Anonymous], 2003, NEURAL COMPUT, DOI DOI 10.1111/J.1945-1474.2005.TB00541.X
   Barbaglia AM, 2012, GENETICS, V190, P965, DOI 10.1534/genetics.111.136176
   Breton M, 2018, J PRIM CARE COMMUNIT, V9, DOI 10.1177/2150132718795943
   Du CG, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-51
   Edgar RC, 2004, NUCLEIC ACIDS RES, V32, P1792, DOI 10.1093/nar/gkh340
   Eindhoven University of Technology MRJE, 2005, WAVELET THEORY APPL, V53
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   GROSSMANN A, 1984, SIAM J MATH ANAL, V15, P723, DOI 10.1137/0515056
   Gutschoven B., 2000, Proceedings of the Third International Conference on Information Fusion, V2, P3
   Hood ME, 2005, GENETICA, V124, P1, DOI 10.1007/s10709-004-6615-y
   Huang Y, 2017, GENE REP, V8, P30, DOI 10.1016/j.genrep.2017.05.002
   Jahankhani P, 2006, IEEE JOHN VINCENT ATANASOFF 2006 INTERNATIONAL SYMPOSIUM ON MODERN COMPUTING, PROCEEDINGS, P120, DOI 10.1109/JVA.2006.17
   Jurka J, 2005, CYTOGENET GENOME RES, V110, P462, DOI 10.1159/000084979
   Kapitonov VV, 2007, TRENDS GENET, V23, P521, DOI 10.1016/j.tig.2007.08.004
   Kapitonov VV, 2001, P NATL ACAD SCI USA, V98, P8714, DOI 10.1073/pnas.151269298
   Kaur B, 2017, MULTIMED TOOLS APPL, V76, P25581, DOI 10.1007/s11042-016-4232-2
   Kumar M, 2011, J MOL RECOGNIT, V24, P303, DOI 10.1002/jmr.1061
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Li LQ, 2017, J BIOINF COMPUT BIOL, V15, DOI 10.1142/S0219720016500256
   Mateos A, 2002, GENOME RES, V12, P1703, DOI 10.1101/gr.192502
   Mena-Chalco JP, 2008, IEEE ACM T COMPUT BI, V5, P198, DOI 10.1109/TCBB.2007.70259
   Messaoudi I, 2015, J MED IMAG HEALTH IN, V5, P1035, DOI 10.1166/jmihi.2015.1498
   Messaoudi I, 2014, IEEE ACM T COMPUT BI, V11, P863, DOI 10.1109/TCBB.2014.2315991
   Najmi AH, 1997, J HOPKINS APL TECH D, V18, P134
   Nigatu D, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1884-5
   Orhan U, 2011, EXPERT SYST APPL, V38, P13475, DOI 10.1016/j.eswa.2011.04.149
   Oueslati AE, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P864
   Oueslati AE, 2015, MED BIOL ENG COMPUT, V53, P1165, DOI 10.1007/s11517-015-1304-9
   Öz E, 2013, J INEQUAL APPL, DOI 10.1186/1029-242X-2013-85
   Poulter RTM, 2005, CYTOGENET GENOME RES, V110, P575, DOI 10.1159/000084991
   Poulter RTM, 2003, GENE, V313, P201, DOI 10.1016/S0378-1119(03)00679-6
   Pritham EJ, 2007, P NATL ACAD SCI USA, V104, P1895, DOI 10.1073/pnas.0609601104
   Schlötterer C, 2000, CHROMOSOMA, V109, P365, DOI 10.1007/s004120000089
   Schölkopf B, 2001, ADV NEUR IN, V13, P301
   Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570
   Song JN, 2018, J THEOR BIOL, V443, P125, DOI 10.1016/j.jtbi.2018.01.023
   Suo HB, 2008, EURASIP J AUDIO SPEE, DOI 10.1155/2008/674859
   Sweredoski M, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-467
   Takezaki N, 1996, GENETICS, V144, P389
   Thomas J, 2015, MICROBIOL SPECTR, V3, DOI 10.1128/microbiolspec.MDNA3-0049-2014
   Touati R, 2018, Bioinformatics, P127, DOI [10.5220/0006631001270134, DOI 10.5220/0006631001270134]
   Valli I, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00052
   Vapnik V., 2013, The nature of statistical learning theory
   Wicker T, 2007, NAT REV GENET, V8, P973, DOI 10.1038/nrg2165
   Xie D, 2005, NUCLEIC ACIDS RES, V33, pW105, DOI 10.1093/nar/gki359
   Xiong WW, 2014, P NATL ACAD SCI USA, V111, P10263, DOI 10.1073/pnas.1410068111
   Yang LX, 2009, P NATL ACAD SCI USA, V106, P12832, DOI 10.1073/pnas.0905563106
   Zhou QC, 2006, ZEBRAFISH, V3, P39, DOI 10.1089/zeb.2006.3.39
NR 54
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13047
EP 13066
DI 10.1007/s11042-018-6455-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900017
DA 2024-07-18
ER

PT J
AU Yin, XL
   Zhang, JD
   Wu, XG
   Huang, J
   Xu, YP
   Zhu, LY
AF Yin, Xuelong
   Zhang, Jindong
   Wu, Xinggang
   Huang, Ju
   Xu, Yanping
   Zhu, Linyao
TI An improved lane departure warning algorithm based on fusion of F-Kalman
   filter and F-TLC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LDWS; Fuzzy; Kalman filter; TLC
ID TIME; SYSTEM; TRACKING
AB In order to reduce the lane departure accident caused by driver's negligence, LDWS (lane departure warning system) has become increasingly popular and important. However, most researches proposed mainly focus on how to detect lane markings. In this paper, we propose an improved lane departure warning algorithm based on fusion of F-Kalman filter (kalman filter based on fuzzy logic) and F-TLC (time to lane crossing based on fuzzy logic). First of all, least square method is used to calculate the distance between vehicle and lane markings. Then the estimation of vehicle states in the future is generated by means of the traditional kalman filter. To better work for lateral offset estimation, a fuzzy model is adopted to change the size of covariance matrices, which is used to adjust the traditional kalman filter in time. Finally, we further put forward to utilize F-TLC to generate multi-grade alarm. Extensive experiments are conducted on different conditions. Experimental results indicate that our warning method works efficiently. The average time consumed for system in each frame is 20.0216ms. The proposed method possesses good robustness, and can be widely us\ed in LDWS.
C1 [Yin, Xuelong; Zhang, Jindong; Huang, Ju] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Jilin, Peoples R China.
   [Wu, Xinggang; Xu, Yanping; Zhu, Linyao] Jilin Univ, Coll Software, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Jilin, Peoples R China.
EM zhangjindong_100@163.com
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship for the academic year of 2017-2018; Jilin University
   [5157050847, 2017XYB252]
FX This work is supported by National Key Research and Development Program
   of China (2017YFB0102500), Natural Science Foundation of Jilin province
   (20170101133JC), Korea Foundation for Advanced Studies' International
   Scholar Exchange Fellowship for the academic year of 2017-2018, and
   Jilin University (5157050847, 2017XYB252).
CR Albousefi AA, 2017, J INTELL TRANSPORT S, V21, P41, DOI 10.1080/15472450.2016.1196141
   Ali A, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510971
   Ambarak JM, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P492, DOI 10.1109/ICIT.2017.7913281
   [Anonymous], 2015, IOSR JEEE, DOI DOI 10.9790/1676-1061112116
   [Anonymous], 2017, INTELLIGENT TRANSPOR
   [Anonymous], 2017, CHIN STAT YB
   [Anonymous], 2016, 2016 INT IMAGE PROCE, DOI DOI 10.1109/IPAS.2016.7880072
   [Anonymous], 2016 CYBERNETICS INF
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Cicchino JB, 2017, TRAFFIC INJ PREV, V18, P481, DOI 10.1080/15389588.2016.1247446
   Dahmani H, 2015, VEHICLE SYST DYN, V53, P1135, DOI 10.1080/00423114.2015.1026609
   Ding Y, 2017, MULTIMED TOOLS APPL, V76, P22979, DOI 10.1007/s11042-016-4184-6
   Dorj B, 2016, J SENSORS, V2016, DOI 10.1155/2016/4058093
   Gaikwad V, 2015, IEEE T INTELL TRANSP, V16, P910, DOI 10.1109/TITS.2014.2347400
   Glaser S, 2010, IEEE T VEH TECHNOL, V59, P2757, DOI 10.1109/TVT.2010.2049670
   GODTHELP H, 1984, HUM FACTORS, V26, P257, DOI 10.1177/001872088402600302
   Hsiao PY, 2009, IEEE T VEH TECHNOL, V58, P2089, DOI 10.1109/TVT.2008.2006618
   Ibarra-Bonilla MN, 2015, J INTELL FUZZY SYST, V29, P479, DOI 10.3233/IFS-141183
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim SY, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P361, DOI 10.1109/IVS.2003.1212937
   KOBAYASHI K, 1995, PROCEEDINGS OF THE 1995 AMERICAN CONTROL CONFERENCE, VOLS 1-6, P3086
   Lan M, 2009, 2009 12 INT IEEE C I, P1, DOI [10.1109/ITSC.2009.5309685, DOI 10.1109/ITSC.2009.5309685]
   Lee JW, 2002, COMPUT VIS IMAGE UND, V86, P52, DOI 10.1006/cviu.2002.0958
   Madrid N, 2016, FUZZY SET SYST, V291, P144, DOI 10.1016/j.fss.2015.09.009
   Mammar S, 2006, IEEE T INTELL TRANSP, V7, P226, DOI 10.1109/TITS.2006.874707
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Midya A, 2017, MULTIMED TOOLS APPL, V76, P23931, DOI 10.1007/s11042-016-4148-x
   Motwani A, 2016, P I MECH ENG M-J ENG, V230, P491, DOI 10.1177/1475090215596180
   Narote SP, 2018, PATTERN RECOGN, V73, P216, DOI 10.1016/j.patcog.2017.08.014
   Navarro J, 2017, APPL ERGON, V59, P123, DOI 10.1016/j.apergo.2016.08.010
   Pomerleau D., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P506, DOI 10.1109/IVS.1995.528333
   Salari E, 2013, MIDWEST SYMP CIRCUIT, P1278, DOI 10.1109/MWSCAS.2013.6674888
   Sandström M, 2017, ACCIDENT ANAL PREV, V99, P272, DOI 10.1016/j.aap.2016.12.003
   Son J, 2015, EXPERT SYST APPL, V42, P1816, DOI 10.1016/j.eswa.2014.10.024
   Sternlund S, 2017, TRAFFIC INJ PREV, V18, P225, DOI 10.1080/15389588.2016.1230672
   Tan DK, 2017, IEEE INTEL TRANSP SY, V9, P76, DOI 10.1109/MITS.2017.2743204
   Tapia-Espinoza R, 2013, SENSORS-BASEL, V13, P3270, DOI 10.3390/s130303270
   Tu C, 2013, IERI PROC, V4, P316, DOI 10.1016/j.ieri.2013.11.045
   Viswanath Prashanth, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P73, DOI 10.1109/ICCE.2016.7430527
   Wang JG, 2010, EXPERT SYST APPL, V37, P113, DOI 10.1016/j.eswa.2009.05.026
   Yoo JH, 2017, IEEE T INTELL TRANSP, V18, P3254, DOI 10.1109/TITS.2017.2679222
   Zhang JD, 2015, J INTELL FUZZY SYST, V29, P2779, DOI 10.3233/IFS-151982
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 43
TC 7
Z9 8
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12203
EP 12222
DI 10.1007/s11042-018-6762-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900051
DA 2024-07-18
ER

PT J
AU Alhamid, MF
AF Alhamid, Mohammed F.
TI Investigation of mammograms in the cloud for smart healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart healthcare; Breast cancer detection; Mammogram; Local binary
   pattern; Co-occurrence matrix
ID CLASSIFICATION; FEATURES; MASS; FRAMEWORK
AB In this paper, we propose a breast cancer monitoring system to be used as a part of smart healthcare. The breast cancer is one of the big reasons of death of young and elderly women, yet women often hesitate to go to the doctor due to the social and psychological barrier. A smart solution based on the cloud can facilitate the women to overcome this barrier. In the proposed system, mammograms can be obtained from the machine, and processed and analyzed in the cloud. In the system, we use a local binary pattern (LBP) and a co-occurrence matrix from the region of interest (where there is a possible mass) of the mammogram image. Several features are extracted from the LBP and the matrix to describe the mass. A support vector machine is used as a classifier. Experimental results show that the proposed system can achieve more than 98% accuracy while discriminating between normal and mass, and more than 87% accuracy while discriminating between benign and malignant.
C1 [Alhamid, Mohammed F.] King Saud Univ, CCIS, Software Engn Dept, Riyadh, Saudi Arabia.
C3 King Saud University
RP Alhamid, MF (corresponding author), King Saud Univ, CCIS, Software Engn Dept, Riyadh, Saudi Arabia.
EM mohalhamid@ksu.edu.sa
FU Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia [RG-1437-042]
FX The authors would like to extend their sincere appreciation to the
   Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia for funding this research group No. (RG-1437-042).
CR [Anonymous], TECH REP
   [Anonymous], TPAMI
   Braz G, 2009, COMPUT BIOL MED, V39, P1063, DOI 10.1016/j.compbiomed.2009.08.009
   Buciu I, 2011, BIOMED SIGNAL PROCES, V6, P370, DOI 10.1016/j.bspc.2010.10.003
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Costa DD, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-55
   Dimoulas CA, 2016, IEEE T MULTIMEDIA, V18, P1969, DOI 10.1109/TMM.2016.2594148
   Eltoukhy MM, 2010, COMPUT MED IMAG GRAP, V34, P269, DOI 10.1016/j.compmedimag.2009.11.002
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hossain MS, 2017, J PARALLEL DISTR COM, V103, P11, DOI 10.1016/j.jpdc.2016.10.005
   Hossain MS, 2016, IEEE ACCESS, V4, P7806, DOI 10.1109/ACCESS.2016.2626316
   Hossain MS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0627-x
   Hossain MS, 2017, IEEE SYST J, V11, P118, DOI 10.1109/JSYST.2015.2470644
   Hu L, 2015, IEEE WIREL COMMUN, V22, P67, DOI 10.1109/MWC.2015.7368826
   Lladó X, 2009, COMPUT MED IMAG GRAP, V33, P415, DOI 10.1016/j.compmedimag.2009.03.007
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moayedi F, 2010, COMPUT BIOL MED, V40, P373, DOI 10.1016/j.compbiomed.2009.12.006
   Muhammad G, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020267
   Muhammad G, 2017, IEEE COMMUN MAG, V55, P69, DOI 10.1109/MCOM.2017.1600425CM
   Muhammad G, 2015, CLUSTER COMPUT, V18, P795, DOI 10.1007/s10586-015-0439-7
   Muhammad G, 2012, INT J ARTIF INTELL T, V21, DOI 10.1142/S0218213012500194
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Reyad YA, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0100-7
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   de Oliveira FSS, 2015, COMPUT BIOL MED, V57, P42, DOI 10.1016/j.compbiomed.2014.11.016
   Solanas A, 2014, IEEE COMMUN MAG, V52, P74, DOI 10.1109/MCOM.2014.6871673
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Zhang L, 2016, J MED SYST, V40, DOI [10.1007/s10916-016-0480-y, 10.1007/s10916-016-0644-9]
   Zheng YF, 2010, ALGORITHMS, V3, P44, DOI 10.3390/a3010044
NR 31
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8997
EP 9009
DI 10.1007/s11042-017-5239-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800061
DA 2024-07-18
ER

PT J
AU Guo, CP
   Yang, W
   Huang, LS
AF Guo, ChuanPeng
   Yang, Wei
   Huang, Liusheng
TI An improved entropy-based approach to steganalysis of compressed speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Entropy; Compressed speech; Markov chain
ID STEGANOGRAPHY; VOICE; WATERMARKING
AB Compared with more and more steganography techniques motivated by abundant compressed speech, steganalysis is still a challenging task. Many existing studies are based on a single dimensional feature model and it is difficult to have a wide range of applicability. In this paper, a hybrid Markov model is proposed, which is based on the correlation of fixed codebook parameters in speech codec between pulses in a given track. And then, two detecting methods based on entropy are given. One is designed as a single-pulse position based entropy detection method (SPBE). The other is pulse-position pairs based entropy detection method (PPBE). Simultaneously, to solve the problem of inaccurate calculation of the entropy rate of finite length samples, corrected conditional entropy (CCE) is used as an estimate of the Markov chain entropy rate. Experiments show that CCE and entropy are highly complementary, and both can be employed as classification features to achieve better steganalysis results. Finally, the performance of the proposed detection methods is evaluated and compared with the existing detection methods. Results prove that the two methods proposed in this paper are suitable for online and real-time steganographic detection, especially for small-size samples.
C1 [Guo, ChuanPeng; Yang, Wei; Huang, Liusheng] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Yang, W (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
EM guocp@mail.ustc.edu.cn; qubit@ustc.edu.cn; lshuang@ustc.edu.cn
FU National Natural Science Foundation of China [61572456]; Natural Science
   Foundation of Jiangsu Province of China [BK20151241]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61572456), and the Natural Science Foundation of Jiangsu
   Province of China (No. BK20151241).
CR [Anonymous], 2012, CMU AUDIO DATABASES
   [Anonymous], 2017, SPEECH CODEC SPEECH
   [Anonymous], 2018, AMR SPEECH ENCODER D
   [Anonymous], 2013, COOL EDIT PRO 2 1
   Bo XA, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.375
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cover T. M., 2006, Elements of Information Theory, DOI DOI 10.1002/047174882X
   DING Q, 2010, 6TH INTERNATIONAL CO, V6, P1
   Dittmann J, 2005, P SOC PHOTO-OPT INS, V5681, P607, DOI 10.1117/12.586579
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   [高瞻瞻 Gao Zhanzhan], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P854
   Geiser B, 2008, INT CONF ACOUST SPEE, P4005, DOI 10.1109/ICASSP.2008.4518532
   Geiser B, 2007, INT CONF ACOUST SPEE, P533
   Gianvecchio S, 2011, IEEE T DEPEND SECURE, V8, P785, DOI 10.1109/TDSC.2010.46
   Huang YF, 2011, IET COMMUN, V5, P929, DOI 10.1049/iet-com.2010.0348
   Huang YF, 2017, SCI CHINA TECHNOL SC, V60, P1585, DOI 10.1007/s11431-016-0707-3
   Jagtap SK, 2015, PROCEDIA COMPUT SCI, V49, P253, DOI 10.1016/j.procs.2015.04.251
   Krätzer C, 2006, IEEE INT SYMP CIRC S, P2397
   Kraetzer C, 2007, PROC SPIE, V6505, DOI 10.1117/12.704040
   LI S, 2017, AUDIO SPEECH AND LAN, V25, P1011, DOI DOI 10.1109/TASLP.2017.2676356
   Li Song-Bin, 2013, Chinese Journal of Computers, V36, P1168, DOI 10.3724/SP.J.1016.2013.01168
   Liu J, 2016, J AMB INTEL HUM COMP, V7, P139, DOI 10.1007/s12652-015-0315-6
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297
   Liu P, 2017, MULTIMED TOOLS APPL, V76, P2837, DOI 10.1007/s11042-016-3257-x
   Lu ZM, 2005, IEICE T INF SYST, VE88D, P330, DOI 10.1093/ietisy/E88-D.2.330
   Mazurczyk W, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543587
   Miao HB, 2014, LECT NOTES COMPUT SC, V8389, P63, DOI 10.1007/978-3-662-43886-2_5
   Miao HB, 2012, COMPUT ELECTR ENG, V38, P1490, DOI 10.1016/j.compeleceng.2012.05.003
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Ren YZ, 2015, IEEE T INF FOREN SEC, V10, P1801, DOI 10.1109/TIFS.2015.2421322
   Takahashi T, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON SECURITY AND PRIVACY IN COMMUNICATION NETWORKS AND WORKSHOPS, P371, DOI 10.1109/SECCOM.2007.4550357
   Tian H, 2017, SIGNAL PROCESS, V134, P9, DOI 10.1016/j.sigpro.2016.11.013
   Tian H, 2015, SIGNAL PROCESS, V117, P33, DOI 10.1016/j.sigpro.2015.05.001
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu ZJ, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1970, DOI 10.1109/CompComm.2016.7925046
   Wu ZJ, 2015, CHINESE J ELECTRON, V24, P157, DOI 10.1049/cje.2015.01.026
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 38
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8513
EP 8534
DI 10.1007/s11042-018-6941-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800035
DA 2024-07-18
ER

PT J
AU Liu, L
   Xu, J
   Liu, Z
AF Liu, Liu
   Xu, Jin
   Liu, Zheng
TI Automatic extraction of coronary centerline based on model-mapped and
   inertia-guided minimum path from CTA images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coronary centerline; Prior model; Minimum path; CTA image
ID WHOLE HEART SEGMENTATION; PROPAGATION FRAMEWORK; LUMEN SEGMENTATION;
   QUANTIFICATION; REGISTRATION; ROBUST
AB It has been a challenging but significant research topic to extract the centerlines of the coronary arteries of the cardiac computed tomography angiography volume in clinical applications. A new method is proposed to full-automatically extract and recognize the centerlines of the major branches instead of manual interaction in this paper, which employs a new path tracking algorithm that combines direction features from atlases and inertia features from previous extracted centerline points, referred to as model-mapped and inertia-guided minimum path. This method first registers a pre-constructed coronary model that contains the right coronary artery, the left anterior descending artery, the left circumflex artery coronary artery to the target cardiac computed tomography, to provide initial reference positions and direction information of the coronary artery. After getting the reference regions based on the registration, the two ostia positions are detected automatically by the learning-based method, which is based on the probability boosting tree and 3D Haar features, in the region of interest of the cardiac computed tomography volume. The starting points are then as the ostia in the evolution of minimum path. Meanwhile, to boost the robustness of the evolution, the tracked path of the last step is used to generate the inertia-driven force. Finally, based on a new automatic endpoint detection algorithm, the longest centerline of a particular coronary branch can be extracted with the proposed method. We tested the robustness of our method in the Rotterdam Coronary Artery Algorithm Evaluation framework. The proposed method is fully automatic and obtains the optimal effect among the fully automatic methods in Rotterdam framework.
C1 [Liu, Liu; Xu, Jin] Nanjing Univ Posts & Telecommun, Nanjing, Jiangsu, Peoples R China.
   [Liu, Zheng] Nanjing Univ Chinese Med, Affiliated Hosp 3, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Chinese Medicine
RP Liu, L (corresponding author), Nanjing Univ Posts & Telecommun, Nanjing, Jiangsu, Peoples R China.
EM linue5466@gmail.com
FU NSFC of China [61503354, NY213110, NY214121]
FX This work was jointly supported by NSFC of China (61503354), and NPTSF
   (NY213110, NY214121).
CR Bauer C, 2008, MIDAS J, P1
   Boskamp T, 2004, RADIOGRAPHICS, V24, P287, DOI 10.1148/rg.241035073
   Castro C., 2008, The Midas Journal
   Deschamps T, 2000, EUR C COMP VIS, P543
   Dijkstra E. A., 1959, NUMER MATH, V1, P69
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   FRIMAN O, 2008, MICCAI WORKSH GRAND
   Gülsün MA, 2008, LECT NOTES COMPUT SC, V5241, P602, DOI 10.1007/978-3-540-85988-8_72
   Kirisli HA, 2010, MED PHYS, V37, P6279, DOI 10.1118/1.3512795
   Kitamura Y, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P234, DOI 10.1109/ISBI.2012.6235527
   Kitslaar P, 2008, MIDAS J
   Krissian Karl, 2008, MIDAS J, DOI 10.54294/b6ilok
   Li CM, 2005, PROC CVPR IEEE, P430
   Liu L, 2014, I S BIOMED IMAGING, P133, DOI 10.1109/ISBI.2014.6867827
   Liu L, 2013, LECT NOTES COMPUT SC, V8149, P542, DOI 10.1007/978-3-642-40811-3_68
   METZ C, 2008, MIDAS J
   Ning ZHU, 2013, IEEE C COMP VIS PATT, P23
   Schaap M, 2009, LECT NOTES COMPUT SC, V5636, P528, DOI 10.1007/978-3-642-02498-6_44
   Schaap M, 2009, MED IMAGE ANAL, V13, P701, DOI 10.1016/j.media.2009.06.003
   SZYMCZAK A, 2008, MIDAS J
   Tang H, 2012, MED IMAGE ANAL, V16, P1202, DOI 10.1016/j.media.2012.05.014
   Wang C, 2008, MIDAS J
   Yang GY, 2012, INT J CARDIOVAS IMAG, V28, P921, DOI 10.1007/s10554-011-9894-2
   Yefeng Zheng, 2012, Machine Learning in Medical Imaging. Third International Workshop (MLMI 2012). Held in Conjunction with MICCAI 2012. Revised Selected Papers, P10, DOI 10.1007/978-3-642-35428-1_2
   Zambal S, 2008, MIDAS J
   Zheng YF, 2008, IEEE T MED IMAGING, V27, P1668, DOI 10.1109/TMI.2008.2004421
   Zheng YF, 2013, LECT NOTES COMPUT SC, V8151, P74, DOI 10.1007/978-3-642-40760-4_10
   Zhu N, 2011, LECT NOTES COMPUT SC, V6893, P436, DOI 10.1007/978-3-642-23626-6_54
   Zhuang XH, 2016, MED IMAGE ANAL, V31, P77, DOI 10.1016/j.media.2016.02.006
   Zhuang XH, 2015, MED PHYS, V42, P3822, DOI 10.1118/1.4921366
   Zhuang XH, 2010, IEEE T MED IMAGING, V29, P1612, DOI 10.1109/TMI.2010.2047112
   Zhuang XH, 2008, LECT NOTES COMPUT SC, V5242, P425, DOI 10.1007/978-3-540-85990-1_51
NR 32
TC 1
Z9 1
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8767
EP 8782
DI 10.1007/s11042-018-6335-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY5JW
UT WOS:000468165200001
DA 2024-07-18
ER

PT J
AU Pham, TA
   Do, NT
AF The-Anh Pham
   Nang-Toan Do
TI Embedding hierarchical clustering in product quantization for feature
   indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Product quantization; Hierarchical clustering decomposition; Approximate
   nearest neighbor search
ID NEAREST-NEIGHBOR; ALGORITHMS
AB Effective indexing is a crucial need for large scale object matching and retrieval. In this work, a novel indexing scheme is presented, that exploits the advantages of hierarchical clustering and product quantization. First, the high dimensional feature space is decomposed into disjointed sub-spaces and the data belonging to each sub-space is separately represented by a hierarchical clustering tree. Second, each tree quantizes a distinct part of an input vector to the closest centroid of a leaf node and the distances for all the pairs of centroids are pre-computed and stored in a lookup table. Finally, searching for a given query is proceeded in parallel between the trees and is performed efficiently in the quantized space using the pre-computed lookup tables. The proposed method has been validated by a number of experiments, demonstrating significant improvements of search performance in comparison with other methods.
C1 [The-Anh Pham] HDU, Thanh Hoa City, Vietnam.
   [Nang-Toan Do] VNU, Inst Informat, Hanoi, Vietnam.
C3 Hong Duc University; Vietnam National University Hanoi
RP Pham, TA (corresponding author), HDU, Thanh Hoa City, Vietnam.
EM phamtheanh@hdu.edu.vn; dntoan@vnu.edu.vn
OI Pham, The-Anh/0000-0002-0674-8066
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2016.01]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2016.01.
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   Andoni Alexandr, 2014, P 25 ANN ACM SIAM S, P1018
   [Anonymous], 2014, Hashing for similarity search: A survey
   Babenko A, 2015, PROC CVPR IEEE, P4240, DOI 10.1109/CVPR.2015.7299052
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Cheng DY, 1984, PROC IEEE INT CONF A, P372
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   GE T, 2014, TPAMI, V36, P744, DOI DOI 10.1109/TPAMI.2013.240
   He J., 2010, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P1129
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Leibe B., 2006, P BRIT MACH VIS C 20, DOI [10.5244/C.20.81, DOI 10.5244/C.20.81]
   Liu T., 2004, INVESTIGATION PRACTI, P825
   Lv Q, 2007, P 33 INT C VER LARG, P950
   McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Panigrahy R, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1186, DOI 10.1145/1109557.1109688
   Popescu A, 2015, P 2015 WORKSH COMM O, P7, DOI [10.1145/2814815.2814819, DOI 10.1145/2814815.2814819]
   Silpa-Anan C., 2008, [39] C. Silpa-Anan and R. Hartley, "Optimized KD-trees for fast image descriptor matching", IEEE Conf. on Computer Vision and Pattern Recognition, 2008, pp. 1-8., P1, DOI [DOI 10.1109/CVPR.2008.4587638, 10.1109/CVPR.2008.4587638]
   Simonyan K., 2014, 14091556 ARXIV
   Pham TA, 2017, COMPUT VIS IMAGE UND, V154, P35, DOI 10.1016/j.cviu.2016.07.011
   Pham TA, 2015, PATTERN RECOGN LETT, V55, P42, DOI 10.1016/j.patrec.2014.08.006
   Pham TA, 2013, LECT NOTES COMPUT SC, V8156, P752
   ZHANG T, 2014, PROCEEDINGS OF THE 3, V31, P838
   Zhang T, 2015, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2015.7299085
NR 32
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9991
EP 10012
DI 10.1007/s11042-018-6626-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400023
DA 2024-07-18
ER

PT J
AU Badshah, AM
   Rahim, N
   Ullah, N
   Ahmad, J
   Muhammad, K
   Lee, MY
   Kwon, S
   Baik, SW
AF Badshah, Abdul Malik
   Rahim, Nasir
   Ullah, Noor
   Ahmad, Jamil
   Muhammad, Khan
   Lee, Mi Young
   Kwon, Soonil
   Baik, Sung Wook
TI Deep features-based speech emotion recognition for smart affective
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Convolutional neural network; Spectrogram;
   Rectangular kernels
ID SCHEMES; CLASSIFICATION
AB Emotion recognition from speech signals is an interesting research with several applications like smart healthcare, autonomous voice response systems, assessing situational seriousness by caller affective state analysis in emergency centers, and other smart affective services. In this paper, we present a study of speech emotion recognition based on the features extracted from spectrograms using a deep convolutional neural network (CNN) with rectangular kernels. Typically, CNNs have square shaped kernels and pooling operators at various layers, which are suited for 2D image data. However, in case of spectrograms, the information is encoded in a slightly different manner. Time is represented along the x-axis and y-axis shows frequency of the speech signal, whereas, the amplitude is indicated by the intensity value in the spectrogram at a particular position. To analyze speech through spectrograms, we propose rectangular kernels of varying shapes and sizes, along with max pooling in rectangular neighborhoods, to extract discriminative features. The proposed scheme effectively learns discriminative features from speech spectrograms and performs better than many state-of-the-art techniques when evaluated its performance on Emo-DB and Korean speech dataset.
C1 [Badshah, Abdul Malik; Rahim, Nasir; Ullah, Noor; Ahmad, Jamil; Muhammad, Khan; Lee, Mi Young; Kwon, Soonil; Baik, Sung Wook] Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
EM sbaik@sejong.ac.kr
RI Muhammad, Khan/L-9059-2016; Badshah, Abdul Mlik/HGU-0378-2022; Khan,
   Muhammad/IXN-8470-2023; Baik, Sung Wook/AAR-8236-2020; Ahmad,
   Jamil/H-6264-2019
OI Muhammad, Khan/0000-0003-4055-7412; Ahmad, Jamil/0000-0001-8407-5971;
   KWON, SOONIL/0000-0001-5451-8815; Baik, Sung Wook/0000-0002-6678-7788;
   Muhammad, Khan/0000-0002-5302-1150
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIT) [R0126-15-1119]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIT)
   (No. R0126-15-1119, Development of a solution for situation-awareness
   based on the analysis of speech and environmental sounds).
CR Abdelgawad H, 2014, J ADV TRANSPORT, V48, P507, DOI 10.1002/atr.1201
   Ahmad Jamil, 2016, 2016 International Conference on Platform Technology and Service (PlatCon). Proceedings, P1, DOI 10.1109/PlatCon.2016.7456788
   Ahmad J, 2018, MULTIMED TOOLS APPL, V77, P4883, DOI 10.1007/s11042-016-4041-7
   Aly SA, 2014, PROCEDIA COMPUT SCI, V32, P1141, DOI 10.1016/j.procs.2014.05.545
   [Anonymous], TMM
   [Anonymous], EUROSPEECH
   [Anonymous], TECHNOL
   [Anonymous], 2013, FEATURE LEARNING DEE
   [Anonymous], 2012, WIT Transactions on The Built Environment
   [Anonymous], 2010, 2010 IEEE 39 APPL IM, DOI DOI 10.1109/AIPR.2010.5759701
   [Anonymous], PLATFORM TECHNOLOGY
   [Anonymous], P INT C AFF COMP INT
   [Anonymous], BIG DATA
   [Anonymous], NVIDIA DIGITS
   [Anonymous], 2016, SOFT COMPUT
   [Anonymous], INF VIS
   [Anonymous], 2013, EMOTION RECOGNITION, DOI DOI 10.1007/978-1-4614-5143-3_4
   [Anonymous], INT J COMPUTER SCI E
   [Anonymous], TMM
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Curtis S, 2013, VISUAL COMPUT, V29, P1277, DOI 10.1007/s00371-012-0769-x
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692
   Dennis J, 2011, IEEE SIGNAL PROC LET, V18, P130, DOI 10.1109/LSP.2010.2100380
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   France DJ, 2000, IEEE T BIO-MED ENG, V47, P829, DOI 10.1109/10.846676
   Gharavian D, 2012, NEURAL COMPUT APPL, V21, P2115, DOI 10.1007/s00521-011-0643-1
   Haq S., 2009, INT C AUDITORY VISUA, P53
   Hu H., 2007, P INTERSPEECH, P2269
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaysi I, 2013, TRANSPORT RES REC, P111, DOI 10.3141/2350-13
   Khan MK, 2018, AUST J FORENSIC SCI, V50, P525, DOI 10.1080/00450618.2017.1296186
   Kim S, 2015, VISUAL COMPUT, V31, P541, DOI 10.1007/s00371-014-0946-1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lugger Marko, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1225
   Mao QR, 2010, INT J HUM ROBOT, V7, P245, DOI 10.1142/S0219843610002088
   Mao X, 2010, IEICE T INF SYST, VE93D, P2324, DOI 10.1587/transinf.E93.D.2324
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Nanda AJ, 2017, IEEE ACCESS, V5, P6471, DOI 10.1109/ACCESS.2017.2686438
   Pao TL, 2007, LECT NOTES COMPUT SC, V4681, P997
   Ramakrishnan S, 2013, TELECOMMUN SYST, V52, P1467, DOI 10.1007/s11235-011-9624-z
   Raman R, 2016, IEEE ACCESS, V4, P5788, DOI 10.1109/ACCESS.2016.2608844
   Rout JK, 2018, ELECTRON COMMER RES, V18, P181, DOI 10.1007/s10660-017-9257-8
   Schmidt EM, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P65, DOI 10.1109/ASPAA.2011.6082328
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   Sun R, 2011, LECT NOTES COMPUT SC, V6975, P425, DOI 10.1007/978-3-642-24571-8_54
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wöllmer M, 2012, INT CONF ACOUST SPEE, P4157, DOI 10.1109/ICASSP.2012.6288834
   Xu Z, 2017, IEEE T EMERG TOP COM, V5, P403, DOI 10.1109/TETC.2017.2684819
   Yun S, 2012, IEEE T AUDIO SPEECH, V20, P585, DOI 10.1109/TASL.2011.2162405
NR 54
TC 100
Z9 101
U1 3
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5571
EP 5589
DI 10.1007/s11042-017-5292-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100028
DA 2024-07-18
ER

PT J
AU Kaljahi, MA
   Palaiahnakote, S
   Anisi, MH
   Idris, MYI
   Blumenstein, M
   Khan, MK
AF Kaljahi, Maryam Asadzadeh
   Palaiahnakote, Shivakumara
   Anisi, Mohammad Hossein
   Idris, Mohd Yamani Idna
   Blumenstein, Michael
   Khan, Muhammad Khurram
TI A scene image classification technique for a ubiquitous visual
   surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ubiquitous visual surveillance; Edge strength; Sharpness; K-means
   clustering; Focused edges; Image classification; SVM classifier
ID NETWORKS
AB The concept of smart cities has quickly evolved to improve the quality of life and provide public safety. Smart cities mitigate harmful environmental impacts and offences and bring energy-efficiency, cost saving and mechanisms for better use of resources based on ubiquitous monitoring systems. However, existing visual ubiquitous monitoring systems have only been developed for a specific purpose. As a result, they cannot be used for different scenarios. To overcome this challenge, this paper presents a new ubiquitous visual surveillance mechanism based on classification of scene images. The proposed mechanism supports different applications including Soil, Flood, Air, Plant growth and Garbage monitoring. To classify the scene images of the monitoring systems, we introduce a new technique, which combines edge strength and sharpness to detect focused edge components for Canny and Sobel edges of the input images. For each focused edge component, a patch that merges nearest neighbor components in Canny and Sobel edge images is defined. For each patch, the contribution of the pixels in a cluster given by k-means clustering on edge strength and sharpness is estimated in terms of the percentage of pixels. The same percentage values are considered as a feature vector for classification with the help of a Support Vector Machine (SVM) classifier. Experimental results show that the proposed technique outperforms the state-of-the-art scene categorization methods. Our experimental results demonstrate that the SVM classifier performs better than rule and template-based methods.
C1 [Kaljahi, Maryam Asadzadeh; Palaiahnakote, Shivakumara; Idris, Mohd Yamani Idna] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Anisi, Mohammad Hossein] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
   [Blumenstein, Michael] Univ Technol Sydney, Sch Software, Sydney, NSW, Australia.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh 11451, Saudi Arabia.
C3 Universiti Malaya; University of Essex; University of Technology Sydney;
   King Saud University
RP Idris, MYI (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.; Anisi, MH (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
EM asadzadeh@um.edu.my; shiva@um.edu.my; m.anisi@essex.ac.uk;
   yamani@um.edu.my; michael.blumenstein@uts.edu.au; mkhurram@ksu.edu.sa
RI Idris, Mohd. Yamani Idna/GPP-2401-2022; Idris, Mohd. Yamani
   Idna/B-5232-2010; Anisi, Mohammad Hossein/L-3718-2016; Nusa,
   Nuhammad/JXY-5819-2024; Palaiahnakote, Shivakumara/B-6261-2013; KHAN,
   MUHAMMAD KHURRAM/E-4836-2014; Khan, Muhammad/IXN-8470-2023;
   Palaiahnakote, Shivakumara/ITU-6488-2023
OI Idris, Mohd. Yamani Idna/0000-0003-4894-0838; Anisi, Mohammad
   Hossein/0000-0001-8414-2708; KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533;
   
FU Faculty of Computer Science and Information Technology, University of
   Malaya [RP036B-15AET]; King Saud University [RGP-288]
FX This research work was supported by the Faculty of Computer Science and
   Information Technology, University of Malaya under a special allocation
   of Post Graduate Funding for the RP036B-15AET project. The authors also
   extend their appreciation to the Dean of Scientific Research at King
   Saud University for funding this work through Research Group Number
   (RGP-288). The authors convey special thanks to Sangheeta Roy, Faculty
   of Computer Science and Information Technology, University of Malaya for
   her help in implementing existing classification methods and conducting
   experiments for the comparative study.
CR Afsharinejad A, 2016, IEEE INTERNET THINGS, V3, P59, DOI 10.1109/JIOT.2015.2463685
   Bai S, 2017, EXPERT SYST APPL, V71, P279, DOI 10.1016/j.eswa.2016.10.038
   Balla-Arabé S, 2014, IEEE T GEOSCI REMOTE, V52, P5183, DOI 10.1109/TGRS.2013.2287239
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   D'Addabbo A, 2016, IEEE T GEOSCI REMOTE, V54, P3612, DOI 10.1109/TGRS.2016.2520487
   Davis TW, 2012, IEEE SENS J, V12, P1933, DOI 10.1109/JSEN.2011.2179933
   Dornaika F, 2016, EXPERT SYST APPL, V58, P130, DOI 10.1016/j.eswa.2016.03.024
   Du L, 2016, IEEE T CYBERNETICS, V46, P2156, DOI 10.1109/TCYB.2015.2466692
   Dunlop H, 2010, P CVPRW, P72
   El Bastawesy M, 2012, IEEE J-STARS, V5, P1564, DOI 10.1109/JSTARS.2012.2200456
   Guerrero JM, 2013, EXPERT SYST APPL, V40, P656, DOI 10.1016/j.eswa.2012.07.073
   Hastie T, 1998, ANN STAT, V26, P451
   Hayat M, 2016, IEEE T IMAGE PROCESS, P4289
   Jang SW, 2014, INT J DISTRIB SENSOR
   JIANG T, 2016, P INT C PATT REC, P387
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Liu JJ, 2016, COMPUT VIS IMAGE UND, V152, P79, DOI 10.1016/j.cviu.2015.10.012
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Longhi S., 2012, New Technologies, Mobility and Security (NTMS), 5th International Conference on, IEEE, P1
   LU X, IMAGE AND VISION COM, V29, P104, DOI DOI 10.1016/j.imavis.2010.08.001
   Messer H, 2014, IEEE SIG P MAG, P110
   Nirmala D E., 2013, Electronics, Computing and Communication Technologies (CONECCT), International Conference on, IEEE, P1
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Ohn-Bar E, 2017, PATTERN RECOGN, V64, P425, DOI 10.1016/j.patcog.2016.08.029
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rao VSH, 2012, IEEE T INF TECHNOL B, V16, P112, DOI 10.1109/TITB.2011.2171978
   Shaban KB, 2016, IEEE SENS J, V16, P2598, DOI 10.1109/JSEN.2016.2514378
   Sharma O, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P98, DOI [10.1109/iNIS.2016.13, 10.1109/iNIS.2016.033]
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Sun X, 2018, INFORM SCIENCES, V429, P37, DOI 10.1016/j.ins.2017.10.051
   Tian D, 2016, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2016.7532341
   Wu ZX, 2016, PROC CVPR IEEE, P3112, DOI 10.1109/CVPR.2016.339
   XIE L, 2016, IEEE TRANSACTIONS ON, V26, P1251, DOI DOI 10.1109/TCSVT.2015.2461978
   Yang D, 2016, IEEE T CIRC SYST VID, V26, P1363, DOI 10.1109/TCSVT.2015.2452780
   YI X, 1938, TIP, V25, P1626, DOI DOI 10.1109/TIP.2016.2528042
   Yuan L, 2015, NEUROCOMPUTING, V170, P213, DOI 10.1016/j.neucom.2014.05.095
   Zhang XD, 2013, IEEE SIGNAL PROC LET, V20, P319, DOI 10.1109/LSP.2013.2244081
   Zhou Q, 2016, PATTERN RECOGN, V59, P312, DOI 10.1016/j.patcog.2016.03.023
   ZHU J, 2016, TIP, V25, P150, DOI DOI 10.1109/TIP.2015.2498407
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 41
TC 10
Z9 11
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5791
EP 5818
DI 10.1007/s11042-018-6151-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100039
DA 2024-07-18
ER

PT J
AU Kim, MJ
   Yoo, C
   Ko, YW
AF Kim, Min-Ja
   Yoo, Chuck
   Ko, Young-Woong
TI Multimedia file forensics system exploiting file similarity search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia file forensics; File similarity search; Video fingerprint;
   media-aware information detection; fingerprint-based matching
AB With the fast increase of multimedia contents, efficient forensics investigation methods for multimedia files have been required. In multimedia files, the similarity means that the identical media (audio and video) data are existing among multimedia files. This paper proposes an efficient multimedia file forensics system based on file similarity search of video contents. The proposed system needs two key techniques. First is a media-aware information detection technique. The first critical step for the similarity search is to find the meaningful keyframes or key sequences in the shots through a multimedia file, in order to recognize altered files from the same source file. Second is a video fingerprint-based technique (VFB) for file similarity search. The byte for byte comparison is an inefficient similarity searching method for large files such as multimedia. The VFB technique is an efficient method to extract video features from the large multimedia files. It also provides an independent media-aware identification method for detecting alterations to the source video file (e.g., frame rates, resolutions, and formats, etc.). In this paper, we focus on two key challenges: to generate robust video fingerprints by finding meaningful boundaries of a multimedia file, and to measure video similarity by using fingerprint-based matching. Our evaluation shows that the proposed system is possible to apply to realistic multimedia file forensics tools.
C1 [Kim, Min-Ja; Yoo, Chuck] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Ko, Young-Woong] Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
C3 Korea University; Hallym University
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
EM mjkim@gmail.com; hxy@korea.ac.kr; yuko@hallym.ac.kr
RI Kim, Mi Jin/GXH-9639-2022; KIM, MINJI/IXD-7702-2023
OI ko, young woong/0000-0002-6292-0799
FU National Research Foundation of Korea(NRF) - Ministry of Science, ICT
   and future Planning [2014R1A2A1A11054160]; Leading Human Resource
   Training Program of Regional Neo industry through the National Research
   Foundation of Korea(NRF) - Ministry of Science, ICT and future Planning
   [2016H1D5A1910630]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT and future Planning (2014R1A2A1A11054160). And this
   research was supported by The Leading Human Resource Training Program of
   Regional Neo industry through the National Research Foundation of
   Korea(NRF) funded by the Ministry of Science, ICT and future Planning
   (2016H1D5A1910630)
CR Allamanche E., 2001, Ismir
   Anand A, 2016, IEEE ACM T NETWORK, V24, P1223, DOI 10.1109/TNET.2015.2413352
   [Anonymous], P 5 ACM MULT SYST C
   [Anonymous], 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on
   [Anonymous], 1999, THESIS
   [Anonymous], 2010, IMPLEMENTATION BENCH
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2007, NSDI
   Baber J., 2011, 17th DSP 2011 International Conference on Digital Signal Processing, Proceedings, P1
   Chasanis VT, 2009, IEEE T MULTIMEDIA, V11, P89, DOI 10.1109/TMM.2008.2008924
   Chen S, 2010, INT CONF ACOUST SPEE, P2378, DOI 10.1109/ICASSP.2010.5496165
   Coskun B, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P292, DOI 10.1109/SIU.2004.1338317
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Eshghi K, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 5TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES ( FAST '07), P123
   Forman George., 2005, KDD 05, P394
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gloe T, 2014, DIGIT INVEST, V11, pS68, DOI 10.1016/j.diin.2014.03.009
   Haitsma J, 2001, INDEX, V4, P117
   HotSync P, 2007, PALM DEV ONLINE DOCU
   Ko YW, 2013, IEICE T INF SYST, VE96D, P1544, DOI 10.1587/transinf.E96.D.1544
   Li J., 2010, J DIGITAL CONTENT TE, P202, DOI DOI 10.4156/JDCTA.VOL4.ISSUE3.20
   Mas J, 2003, TRECVID2003 2003 GAI
   MEUNIER P, 2002, ACTIVESYNC TCP IP 80, P145
   Muthitacharoen A., 2001, Operating Systems Review, V35, P174, DOI 10.1145/502059.502052
   OpenCv, OP SOURC COMP VIS
   pHash, OP SOURC PERC HASH L
   Quinlan S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FAST'02 CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P89
   Standaert FX, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, P89, DOI 10.1109/ITCC.2005.229
   Starobinski D, 2003, IEEE T MOBILE COMPUT, V2, P40, DOI 10.1109/TMC.2003.1195150
   Steinebach Martin, 2014, 2014 Ninth International Conference on Availability, Reliability and Security (ARES). Proceedings, P579, DOI 10.1109/ARES.2014.85
   Vukelic Bernard, 2014, 25th International Central European Conference on Information and Intelligent Systems (CECIIS), P286
   [徐旦 XU Dan], 2011, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V5, P38
   Yan H., 2008, ALGORITHMS LOW LATEN, P156
   Yang B, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P167
   You Lawrence., 2004, MSST, P227
NR 35
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5233
EP 5254
DI 10.1007/s11042-017-4969-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100009
DA 2024-07-18
ER

PT J
AU Kumar, CV
   Natarajan, V
   Nirmala, K
   Balasubramanian, T
   Rao, KR
   Krishnan, S
AF Kumar, C. Vinoth
   Natarajan, V.
   Nirmala, K.
   Balasubramanian, T.
   Rao, K. Ramnarayan
   Krishnan, S.
TI Encrypted separable reversible watermarking with authentication and
   error correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color Palette Image; Color Partitioning; Error Correcting Codes;
   Reversible Watermarking; SHA-256
ID HAMMING CODE; EXPANSION; IMAGES
AB Reversible Watermarking (RW) in encrypted images helps to reconstruct the original content and embedded data without distortion while protecting the owner's privacy. The security and integrity of embedded data is very much demanding. In this paper, an efficient RW method is proposed that recovers the embedded data from the marked encrypted color palette images in the presence of attacks. In this method, embeddable color-triples are constructed by employing color partitioning. Next, the cryptographic SHA-256 hash and Bose-Chaudhuri-Hocquenghem (BCH) are applied over the secret information to ensure the authenticity and integrity. The hash authenticated secret data is embedded into the encrypted color palette image. The secret data is extracted using the separable color partitioning method and authenticated with cryptographic hash function. The proposed method has higher embedding capacity when compared to other relative schemes. The BCH codes helps to recover the secret data and cover image in the presence of noise and attacks.
C1 [Kumar, C. Vinoth; Balasubramanian, T.; Rao, K. Ramnarayan; Krishnan, S.] SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Natarajan, V.] Anna Univ, Dept Instrumentat Engn, MIT Campus, Chennai, Tamil Nadu, India.
   [Nirmala, K.] SSN Coll Engn, Dept Biomed Engn, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering; Anna University; Anna University Chennai;
   SSN College of Engineering
RP Kumar, CV (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM vinothkumarc@ssn.edu.in; natraj@mitindia.edu; nirmalak@ssn.edu.in;
   balasubramaniant.9507@gmail.com; kotagiriramnarayan@gmail.com;
   skrish22195@gmail.com
RI K, Nirmala/HNO-8774-2023; C, Vinoth Kumar/JLR-7384-2023
OI K, Nirmala/0000-0003-0635-5892
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Caldelli R, 2010, INT J E-ADOPT, V2, P1, DOI 10.4018/jea.2010010101
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Feng J.B., 2006, IJ Network Security, V2, P161
   Fontaine C, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/274845
   Guruswami V, 1999, IEEE T INFORM THEORY, V45, P1757, DOI 10.1109/18.782097
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim C, 2011, LECT NOTES ARTIF INT, V6592, P372, DOI 10.1007/978-3-642-20042-7_38
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lien BK, 2015, ADV INTELL SYST, V329, P179, DOI 10.1007/978-3-319-12286-1_18
   Lin Cheng-Li., 2011, IEEE INT NANOELECTRO, P1
   Liu TI, 2008, C IND ELECT APPL, P1, DOI 10.1109/ICIEA.2008.4582469
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Prathap I, 2014, COMPUT ELECTR ENG, V40, P920, DOI 10.1016/j.compeleceng.2014.01.006
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Sabery M, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P585, DOI 10.1109/ICACTE.2008.177
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Xu S., 2010, INT J IMAGE GRAPH SI, V2, P61
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 36
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7005
EP 7027
DI 10.1007/s11042-018-6450-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700027
DA 2024-07-18
ER

PT J
AU Lee, JS
   Lee, SH
AF Lee, Jeong-Seob
   Lee, Sung-Hee
TI Automatic path generation for group dance performance using a genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Choreography; Dance floor pattern; Genetic algorithm
AB Designing dancers' paths in choreography, or a floor pattern, is one of the most highly creative tasks of choreographers. Aiming to assist this task, this paper presents a novel system that automatically generates a number of floor patterns for multiple dancers given a choreographer's high-level feature inputs. The proposed floor pattern model represents locomotor movements of dancers on stage. Through a dance literature survey, four major features, i.e., time, space, symmetry, and entropy, were selected as feature inputs and mathematically modeled. Our system uses a multi-objective genetic algorithm to achieve desired floor patterns given input features. It iterates from random floor patterns to the ones that satisfy users' preferences while exploring the space of floor pattern with selection, mutation, crossover methods that are developed to fit the genotype of our system. User tests confirmed that our system generates a wide range of floor patterns according to user-specified input conditions. In addition, an actual dance piece was choreographed with the proposed method, which validated the usefulness of the proposed system. The proposed system is the first that automatically generates floor patterns for multiple dancers.
C1 [Lee, Jeong-Seob; Lee, Sung-Hee] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, SH (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Daejeon, South Korea.
EM jslee85@kaist.ac.kr; sunghee.lee@kaist.ac.kr
RI Lee, Sung-Hee/I-4721-2013; Lee, Jeongseob/AAL-8199-2021
OI Lee, Jeongseob/0000-0001-5685-0686; Lee, Sung-Hee/0000-0001-6604-4709
FU Korea Advanced Institute of Science and Technology (KAIST); Daejeon
   Culture and Art Foundation
FX This research was supported by the Korea Advanced Institute of Science
   and Technology (KAIST) and Daejeon Culture and Art Foundation.
CR [Anonymous], 2007, Pedestrian and evacuation dynamics 2005, DOI DOI 10.1007/978-3-540-47064-9
   Antunes Rui Filipe, 2012, Evolutionary and Biologically Inspired Music, Sound, Art and Design. Proceedings of the First International Conference, EvoMUSART 2012, P1, DOI 10.1007/978-3-642-29142-5_1
   Aristidou A, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2755566
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Carlson K., 2011, P 2 INT C COMP CREAT
   COHOON JP, 1987, IEEE T COMPUT AID D, V6, P956, DOI 10.1109/TCAD.1987.1270337
   Copeland Roger., 2004, MERCE CUNNINGHAM MOD
   Cunningham M, 1985, DANCER DANCE M CUNNI
   den Heijer E., 2012, Evolutionary and Biologically Inspired Music, Sound, Art and Design. Proceedings of the First International Conference, EvoMUSART 2012, P60, DOI 10.1007/978-3-642-29142-5_6
   Eisenmann J, 2016, LEONARDO, V49, P246, DOI 10.1162/LEON_a_01102
   Fang ZM, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL I, PROCEEDINGS, P373, DOI 10.1109/AICI.2009.130
   Gentry S, 2003, IEEE SYS MAN CYBERN, P3432
   GENTRY S, 2003, P EUROHAPTICS, P481
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Henry Joseph., 2012, Proceedings of the 11th ACM SIGGRAPH / Eurographics conference on Computer Animation, EUROSCA'12, P193
   Humphrey D., 1987, The art of making dances
   Hutchinson Guest Ann, 2013, LABANOTATION
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Laban R., 1947, EFFORT
   Lapointe F.-J., 2005, 13th Annual ACM International Conference on Multimedia, P555, DOI 10.1145/1101149.1101276
   LaViers A, 2012, P AMER CONTR CONF, P4327
   LaViers A, 2011, IEEE ROBOT AUTOM MAG, V18, P87, DOI 10.1109/MRA.2011.942118
   LaViers A, 2011, ACM IEEE INT CONF CY, P13, DOI 10.1109/ICCPS.2011.10
   Lee M, 2013, MULTIMED TOOLS APPL, V62, P895, DOI 10.1007/s11042-012-1288-5
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Loke Lian, 2005, P 2 AUSTR C INT ENT, P113
   Lynne A, 1982, INTIMATE ACT CHOREOG
   Michalewicz Zbigniew, 1996, GENETIC ALGORITHMS D, P329
   Mitra N.J., 2004, P 2004 EUROGRAPHICSA, P22, DOI 10.1145/1057432.1057435
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Moon B, 2008, EASILY LEARNING GENE
   Oulasvirta Antti, 2013, P SIGCHI C HUM FACT, P1289
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sareni B., 1998, IEEE Transactions on Evolutionary Computation, V2, P97, DOI 10.1109/4235.735432
   Pires EJS, 2013, ENTROPY-SWITZ, V15, P5475, DOI 10.3390/e15125475
   Vircikova M, 2010, DANCE CHOREOGRAPHY D
   Woo KH, 2000, DANCE MUSIC MEET
NR 37
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7517
EP 7541
DI 10.1007/s11042-018-6493-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700049
DA 2024-07-18
ER

PT J
AU Petrangeli, S
   Pauwels, D
   van der Hooft, J
   Ziak, M
   Slowack, J
   Wauters, T
   De Turck, F
AF Petrangeli, Stefano
   Pauwels, Dries
   van der Hooft, Jeroen
   Ziak, Matus
   Slowack, Jurgen
   Wauters, Tim
   De Turck, Filip
TI A scalable WebRTC-based framework for remote video collaboration
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time communication; Remote video collaboration; WebRTC; Selective
   forwarding unit; Integer linear programming; Jitsi-videobridge
AB Remote video collaboration is common nowadays in conferencing, telehealth and remote teaching applications. To support these low-latency and interactive use cases, Real-Time Communication (RTC) solutions are generally used. WebRTC is an open-source project for real-time browser-based conferencing, developed with a peer-to-peer architecture in mind. In this peer-to-peer architecture, each sending peer needs to encode a separate, independent stream for each receiving peer participating in the remote session, which makes this approach expensive in terms of encoders and not able to scale well for a large number of users. This paper proposes a WebRTC-compliant framework to solve this scalability issue, without impacting the quality delivered to the remote peers. In the proposed framework, each sending peer is only equipped with a limited number of encoders, much smaller than and independent of the number of receiving peers. Consequently, each encoder transmits to a multitude of receivers at the same time, to improve scalability. A centralized node based on the Selective Forwarding Unit (SFU) principle, called conference controller, forwards the best stream to the receiving peers, based on their bandwidth conditions. Moreover, the conference controller dynamically recomputes the encoding bitrates of the sending peers, to maximize the quality delivered to the receiving peers. This approach allows to closely follow the long-term bandwidth variations of the receivers, even with a limited number of encoders at sender-side, and increase the delivered video quality. An integer linear programming formulation for the bitrate recomputation problem is presented, which can be optimally solved when the number of receivers is small. An approximate, scalable method is also proposed using the K-means clustering algorithm. The gains brought by the proposed framework have been confirmed in both simulation and emulation, through a testbed implementation using the Google Chrome browser and the open-source Jitsi-Videobridge software. Particularly, we focus on a remote collaboration scenario where the interaction among the remote participants is dominated by a single peer, as in a remote teaching scenario. When a single sending peer equipped with three encoders transmits to 28 receiving peers, the proposed framework improves the average received video bitrate up to 15%, compared to a static solution where the encoding bitrates do not change over time. Moreover, the dynamic bitrate recomputation is more efficient than a static association in terms of encoders used at sender-side. For the same configuration mentioned above, the same received bitrate is obtained in the static case using four encoders as in the dynamic case using three encoders.
C1 [Petrangeli, Stefano; Pauwels, Dries; van der Hooft, Jeroen; Wauters, Tim; De Turck, Filip] Univ Ghent, Dept Informat Technol, IMEC, IDLab, Technol Pk Zwijnaarde 15, B-9052 Ghent, Belgium.
   [Ziak, Matus] Tech Univ Kosice, Letna 9, Kosice 04200, Slovakia.
   [Slowack, Jurgen] Barco NV Technol Ctr, Beneluxpk 21, B-8500 Kortrijk, Belgium.
C3 IMEC; Ghent University; Technical University Kosice
RP Petrangeli, S (corresponding author), Univ Ghent, Dept Informat Technol, IMEC, IDLab, Technol Pk Zwijnaarde 15, B-9052 Ghent, Belgium.
EM petrange@adobe.com; dries.pauwels@ugent.be; jeroen.vanderhooft@ugent.be;
   matusziak303@gmail.com; jurgen.slowack@barco.com; tim.wauters@ugent.be;
   filip.deturck@ugent.be
OI Petrangeli, Stefano/0000-0002-5492-7747; De Turck,
   Filip/0000-0003-4824-1199
FU Agency for Innovation by Science and Technology in Flanders (VLAIO)
   [150223]
FX Jeroen van der Hooft is funded by grant of the Agency for Innovation by
   Science and Technology in Flanders (VLAIO). This research was performed
   partially within the imec PRO-FLOW project (150223).
CR Al Noor S, 2016, IEEE INT CONF CLOUD, P172, DOI [10.1109/CLOUD.2016.30, 10.1109/CLOUD.2016.0032]
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Alvestrand Harald., 2013, Rtcp message for receiver estimated maximum bitrate. draft-alvestrand-rmcat-remb-03_(work_in_progress)
   [Anonymous], INT C ADV MACH LEARN
   [Anonymous], P 7 INT C MULT SYST
   [Anonymous], COMPUTER AIDED ACUTE
   [Anonymous], 2015 INT C COMP INF
   [Anonymous], NETWORK
   [Anonymous], EFFICIENT SCHEMES PL
   [Anonymous], COMPUTERS ELECT ENG
   [Anonymous], P 1 WORKSH ALL WEB R
   [Anonymous], FUTURE GENER COMP SY
   [Anonymous], P 1 WORKSH ALL WEB R
   [Anonymous], 2013, IEEE INT PACK VID WO
   [Anonymous], ACM T MULTIM COMPUT
   Grozev Boris, 2017, IEEE Communications Standards Magazine, V1, P52, DOI 10.1109/MCOMSTD.2017.1700009
   Grozev B., 2015, P 25 ACM WORKSHOP NE, P19
   Guimaraes MD, 2018, MULTIMED TOOLS APPL, V77, P347, DOI 10.1007/s11042-016-4256-7
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Jang-Jaccard J, 2016, COMPUTING, V98, P169, DOI 10.1007/s00607-014-0429-2
   López L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1187, DOI 10.1145/2964284.2973798
   López-Fernández L, 2017, MULTIMED TOOLS APPL, V76, P14247, DOI 10.1007/s11042-016-3729-z
   Loreto S, 2017, IEEE COMMUN MAG, V55, P200, DOI 10.1109/MCOM.2017.1600283
   Ma LP, 2015, IEEE IMAGE PROC, P2209, DOI 10.1109/ICIP.2015.7351193
   Petrangeli S, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P533, DOI 10.1145/3204949.3208109
   Rodríguez P, 2016, COMPUT STAND INTER, V44, P234, DOI 10.1016/j.csi.2015.09.004
   Rodríguez P, 2014, 2014 INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD), P61, DOI 10.1109/FiCloud.2014.20
   Trnkoczy J, 2017, 2017 IEEE 2ND INTERNATIONAL WORKSHOPS ON FOUNDATIONS AND APPLICATIONS OF SELF* SYSTEMS (FAS*W), P219, DOI 10.1109/FAS-W.2017.151
   van der Hooft J, 2017, J NETW SYST MANAG, P1
   Wenzel M, 2016, INT C COMP SUPP COOP, P334, DOI 10.1109/CSCWD.2016.7566010
   Xhagjika V, 2017, IEEE ACM INT SYMP, P739, DOI 10.1109/CCGRID.2017.118
   Yang EZ, 2016, FRONT INFORM TECH EL, V17, P672, DOI 10.1631/FITEE.1601087
NR 33
TC 14
Z9 14
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7419
EP 7452
DI 10.1007/s11042-018-6460-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700045
OA Green Published
DA 2024-07-18
ER

PT J
AU Partheniadis, K
   Stavrakis, M
AF Partheniadis, Konstantinos
   Stavrakis, Modestos
TI Design and evaluation of a digital wearable ring and a smartphone
   application to help monitor and manage the effects of Raynaud's
   phenomenon
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Raynaud's phenomenon; Wearable health systems; Mhealth; Smart ring;
   Smartphone application; Evaluation; Design requirements
ID LEVEL LASER THERAPY; PERCEIVED USEFULNESS; DOUBLE-BLIND; ACCEPTANCE;
   DIAGNOSIS; DISEASE; DEVICES; STIGMA; EASE; CARE
AB This paper presents the iterative research, design and evaluation phases of a digital wearable health system for monitoring, managing and possibly assisting in preventing the effects of a chronic disease called Raynaud's Phenomenon (RP). The wearable health system is composed of three main parts, a physical product of a smart ring, the digital infrastructure of the physical computing subsystem (hardware and software) and an accompanying smartphone application. A set of design requirements that best describe the functionality and the characteristics of wearable health systems have been selected to derive a thorough study and evaluate the design prototype. We present these along with a set of guidelines for designing wearable health systems (device products and software at the application level) with focus on usability and user experience. The purpose is to evaluate, the prototype which is based on multiple sensor inputs that acquire simultaneously several biomedical and environmental signals, the interaction techniques used and the feedback mechanisms of the smart ring and the accompanying smartphone application for logging and monitoring the progress of RP.
C1 [Partheniadis, Konstantinos; Stavrakis, Modestos] Univ Aegean, Dept Prod & Syst Design Engn, Syros, Greece.
C3 University of Aegean
RP Stavrakis, M (corresponding author), Univ Aegean, Dept Prod & Syst Design Engn, Syros, Greece.
EM partheniadis.k@gmail.com; modestos@aegean.gr
RI Stavrakis, Modestos/Y-2264-2018
OI Stavrakis, Modestos/0000-0002-0694-6038
CR Al-Awami M, 2004, VASA-J VASCULAR DIS, V33, P25, DOI 10.1024/0301-1526.33.1.25
   Al-Awami M, 2001, VASA
   Al-Muhtadi J, 2019, HEALTH INFORM J, V25, P315, DOI 10.1177/1460458217706184
   Anderson ME, 2007, RHEUMATOLOGY, V46, P533, DOI 10.1093/rheumatology/kel330
   Andrews J, 1997, J Med Biogr, V5, P46
   [Anonymous], 2015, Interaction design: Beyond human-computer interaction
   [Anonymous], KICKSTARTER
   [Anonymous], NON TRADITIONAL REF
   [Anonymous], 2013, Lean UX: Applying Lean Principles to Improve User Experience
   Benyon D., 2010, DESIGNING INTERACTIV
   Bichard JA, 2007, LECT NOTES COMPUT SC, V4554, P622
   Block JA, 2001, LANCET, V357, P2042, DOI 10.1016/S0140-6736(00)05118-7
   Bodine K, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P57, DOI 10.1109/ISWC.2003.1241394
   Brown KM, 2001, J BEHAV MED, V24, P137, DOI 10.1023/A:1010758530555
   Chan M, 2012, ARTIF INTELL MED, V56, P137, DOI 10.1016/j.artmed.2012.09.003
   Chatterjee S, HLTH LIVING PERSUASI, DOI [10.1197/jamia.M2859, DOI 10.1197/JAMIA.M2859]
   Chiauzzi E, 2015, BMC MED, V13, DOI 10.1186/s12916-015-0319-2
   Chisnell D., 2008, Handbook of usability testing: How to plan, design, and conduct effective tests, V2nd
   Cho G., 2010, Smart clothing: technology and applications
   Cooper A., 2014, FACE ESSENTIALS INTE
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Delabrida Silva S. E., 2017, Examining developments and applications of wearable devices in modern society
   Dinsdale G., 2014, J VASC DIAGN, V2, P127, DOI DOI 10.2147/JVD.S52943
   Dow S, 2005, IEEE PERVAS COMPUT, V4, P18, DOI 10.1109/MPRV.2005.93
   Dunne LE, 2014, IEEE ENG MED BIO, P4159, DOI 10.1109/EMBC.2014.6944540
   Farrington C, 2016, LANCET DIABETES ENDO, V4, P566, DOI 10.1016/S2213-8587(16)00075-9
   Fensli R, 2008, COMM COM INF SC, V25, P402
   Finstad K, 2006, J USABILITY STUD, V1, P185
   Goodwin KimAlan Cooper., 2009, DESIGNING DIGITAL AG
   Herrick AL, 2012, NAT REV RHEUMATOL, V8, P469, DOI 10.1038/nrrheum.2012.96
   Hirschl M, 2004, J RHEUMATOL, V31, P2408
   Hirschl M, 2002, VASA-J VASCULAR DIS, V31, P91, DOI 10.1024/0301-1526.31.2.91
   Hirschl M, 2006, ARTHRITIS RHEUM-US, V54, P1974, DOI 10.1002/art.21912
   Holtzblatt K., 1997, CONTEXTUAL DESIGN DE
   Holtzblatt Karen, 2004, RAPID CONTEXTUAL DES
   Jean J, 2016, PORTABLE RAYNAUD MON
   Karahanolu Armaan, 2011, P 2011 C DESIGNING P
   Karavidas MK, 2006, APPL PSYCHOPHYS BIOF, V31, P203, DOI 10.1007/s10484-006-9018-2
   Kim Won-Serk, 2011, Laser Therapy, V20, P205
   Kim YW, 2017, P 3 INT C ITAP 2017, P53, DOI [10.1007/978-3-319, DOI 10.1007/978-3-319]
   Kirk S, 2014, IEEE CONSUM ELECTR M, V3, P45, DOI 10.1109/MCE.2014.2345996
   KLIPPEL JH, 1991, ARCH INTERN MED, V151, P2389, DOI 10.1001/archinte.151.12.2389
   Knight JF, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P65, DOI 10.1109/ISWC.2002.1167220
   Kurley M, 2016, HEATED GLOVE METHOD
   Li H, 2016, INT J MED INFORM, V88, P8, DOI 10.1016/j.ijmedinf.2015.12.010
   Li X, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001402
   Lupton D, 2013, SOC THEOR HEALTH, V11, P256, DOI 10.1057/sth.2013.10
   Lymberis A, 2003, ENG MED BIOL SOC ANN, P272
   MARCUS S, 1991, POSTGRAD MED, V89, P171
   Maricq H R, 1998, Vasc Med, V3, P109
   Merkel PA, 2002, ARTHRITIS RHEUM-US, V46, P2410, DOI 10.1002/art.10486
   NHLBI, 2009, HEART VASC DIS RAYN
   Norman D.A., 1986, USER CTR SYSTEM DESI, DOI 10.1201/b15703
   Oumnia K, 2017, SEMELLE CHAUFFANTE C
   Pantelopoulos A, 2010, IEEE T SYST MAN CY C, V40, P1, DOI 10.1109/TSMCC.2009.2032660
   Parette P, 2004, EDUC TRAIN DEV DISAB, V39, P217
   Park S, 2003, IEEE ENG MED BIOL, V22, P41, DOI 10.1109/MEMB.2003.1213625
   Patel MS, 2015, JAMA-J AM MED ASSOC, V313, P459, DOI 10.1001/jama.2014.14781
   Patel S, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-21
   Paul G, 2014, INT CONF ACOUST SPEE, DOI 10.1145/2659651.2659683
   Piwek L, 2016, PLOS MED, V13, DOI 10.1371/journal.pmed.1001953
   Rantakari J., 2016, P 7 AUGM HUM INT C 2, P1, DOI DOI 10.1145/2875194.2875231
   Rodgers M, 2013, NEW ENGL J MED, V368, P1344, DOI 10.1056/NEJMicm1209600
   Ruiz A, 2012, IS LOW LEVEL LASER T
   Schnall R, 2015, STUD HEALTH TECHNOL, V216, P467, DOI 10.3233/978-1-61499-564-7-467
   Smith MJ, 2015, METHODS APPARATUSES
   Stavrakis M, 2009, THESIS
   Taket A., 2000, PARTNERSHIP PARTICIP
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Vredenburg K., 2002, Proceedings of CHI'2002 Conference on Human Factors in Computing Systems Proceedings, P471
   Wechsung I., 2014, An evaluation framework for multimodal interaction
   Wigley F., 2005, Ambulatory surface skin temperature monitor
   Wigley FM, 2002, NEW ENGL J MED, V347, P1001, DOI 10.1056/NEJMcp013013
   Zhang Y, 2017, IEEE SYST J, V11, P88, DOI 10.1109/JSYST.2015.2460747
NR 74
TC 4
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3365
EP 3394
DI 10.1007/s11042-018-6514-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600039
DA 2024-07-18
ER

PT J
AU Tao, M
   Wei, WH
   Yuan, HQ
   Huang, SQ
AF Tao, Ming
   Wei, Wenhong
   Yuan, Huaqiang
   Huang, Shuqiang
TI Version-vector based video data online cloud backup in smart campus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video data; Version-vector; Cloud backup; Smart campus
ID INDEXING TECHNIQUES; PERFORMANCE; DEDUPLICATION; OPTIMIZATION;
   ENCRYPTION; ALGORITHM; SECURE
AB As a kind of popular multimedia service, the video business in smart campus is fully developed, and the data volume is experiencing a continuous tremendous growth. However, the video data storage also needs to cope with many security threats resulted from some uncertainly factors. Recently, data backup has been credited as an important method to address these issues. Yet, how to improve the efficiency of video data online backup remains a critical challenge. In the context of cloud computing, a version-vector based video data online backup system is proposed in this paper, which fully implements three important functions, e.g., backup, indexing and recovery. At the time of the client backuping the data to the server, the version vectors of files and data chunks are produced as metadata. Accordingly, only through exchanging a small amount of metadata between the data nodes, it can identify the redundant data such that breaking the limitations on file-level deduplication and data-chunk-level deduplication in the existing backup systems, and can further improve the performance of backup, indexing and recovery. The conducted experiments have been shown to demonstrate the efficiency.
C1 [Tao, Ming; Wei, Wenhong; Yuan, Huaqiang] Dongguan Univ Technol, Sch Comp Sci & Network Secur, Dongguan 523808, Peoples R China.
   [Huang, Shuqiang] Jinan Univ, Dept Optoelect Engn, Guangzhou 510632, Guangdong, Peoples R China.
C3 Dongguan University of Technology; Jinan University
RP Tao, M; Yuan, HQ (corresponding author), Dongguan Univ Technol, Sch Comp Sci & Network Secur, Dongguan 523808, Peoples R China.
EM ming.tao@mail.scut.edu.cn; weiwh@dgut.edu.cn; hyuan66@163.com;
   hsq@jnu.edu.cn
OI Tao, Ming/0000-0003-1175-5380
FU National Key R&D Program of China [2016YFD0400206]; National Natural
   Science Fund, China [61300198, 61572131, 61772233]; Guangdong University
   Scientific Innovation Project [2017KTSCX178]; outstanding young teacher
   training program of the Education Department of Guangdong Province
   [YQ2015158]; Guangdong Provincial Science & Technology Plan Projects
   [2016A010101035, 2016A010101034]
FX This work was supported in part by the National Key R&D Program of China
   (Grand No. 2016YFD0400206), the National Natural Science Fund, China
   (Grant Nos. 61300198 & 61572131 & 61772233); the Guangdong University
   Scientific Innovation Project (Grant No. 2017KTSCX178); the outstanding
   young teacher training program of the Education Department of Guangdong
   Province (Grant No. YQ2015158); Guangdong Provincial Science &
   Technology Plan Projects (Grant No. 2016A010101035 & 2016A010101034).
CR Alfalou A, 2015, OPT COMMUN, V338, P371, DOI 10.1016/j.optcom.2014.10.020
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], 2014, COMPUT NOW
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bouchrika I, 2016, MULTIMED TOOLS APPL, V75, P1201, DOI 10.1007/s11042-014-2364-9
   Chang V, 2016, FUTURE GENER COMP SY, V57, P56, DOI 10.1016/j.future.2015.10.003
   Chervenak AnnL., 1998, P JOINT NASA IEEE MA, P17
   Christen P, 2012, IEEE T KNOWL DATA EN, V24, P1537, DOI 10.1109/TKDE.2011.127
   Edstrom J, 2017, IEEE T BIG DATA, DOI [10. 1109/TBDATA20172750699, DOI 10.1109/TBDATA20172750699]
   Esposito C, 2016, IEEE T COMPUT, V65, P2348, DOI 10.1109/TC.2015.2389952
   Fu YJ, 2014, IEEE T PARALL DISTR, V25, P1155, DOI 10.1109/TPDS.2013.167
   Gani A, 2016, KNOWL INF SYST, V46, P241, DOI 10.1007/s10115-015-0830-y
   Gupta S., 2014, International Journal of Computer Applications, V104, P1, DOI [10.5120/18267-9305, DOI 10.5120/18267-9305]
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Levitin G, 2016, IEEE T DEPEND SECURE, V13, P644, DOI 10.1109/TDSC.2015.2413404
   Li B, 2019, INFORM SCIENCES, V479, P651, DOI 10.1016/j.ins.2018.02.019
   Li J, 2015, IEEE T COMPUT, V64, P3569, DOI 10.1109/TC.2015.2401017
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Mao B, 2016, IEEE T COMPUT, V65, P1775, DOI 10.1109/TC.2015.2455979
   Nakamura S, 2017, INT J RELIAB QUAL SA, V24, DOI 10.1142/S0218539317500152
   Neelaveni P, 2015, P INT C DISTR COMP I, P213
   Park D, 2017, J COMPUT SCI TECH-CH, V32, P26, DOI 10.1007/s11390-017-1680-8
   Paulo J, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2611778
   Shen J, 2018, J NETW COMPUT APPL, V106, P117, DOI 10.1016/j.jnca.2018.01.003
   Shin Y, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3017428
   Son Y, 2017, PROC INT CONF DATA, P285, DOI 10.1109/ICDE.2017.88
   Song CW, 2011, IEEE INT CONF TRUST, P812, DOI 10.1109/TrustCom.2011.107
   Tao M, 2017, FUTURE GENER COMP SY, V76, P528, DOI 10.1016/j.future.2016.11.012
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wang C, 2012, IEEE T SERV COMPUT, V5, P220, DOI 10.1109/TSC.2011.24
   Wang GP, 2014, EXPERT SYST APPL, V41, P2415, DOI 10.1016/j.eswa.2013.09.040
   Xia W, 2016, IEEE T COMPUT, V65, P1692, DOI 10.1109/TC.2015.2456015
   Xia W, 2015, IEEE T COMPUT, V64, P1162, DOI 10.1109/TC.2014.2308181
   Xiong YH, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON ADVANCED CLOUD AND BIG DATA (CBD 2016), P7, DOI [10.1109/CBD.2016.57, 10.1109/CBD.2016.012]
   Xu QQ, 2015, INT J PARALLEL PROG, V43, P316, DOI 10.1007/s10766-013-0280-7
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang PF, 2017, J SYST SOFTWARE, V128, P11, DOI 10.1016/j.jss.2017.02.039
NR 41
TC 2
Z9 2
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3435
EP 3456
DI 10.1007/s11042-018-6106-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600043
DA 2024-07-18
ER

PT J
AU Vassou, SA
   Anagnostopoulos, N
   Christodoulou, K
   Amanatiadis, A
   Chatzichristofis, SA
AF Vassou, S. A.
   Anagnostopoulos, N.
   Christodoulou, K.
   Amanatiadis, A.
   Chatzichristofis, S. A.
TI CoMo: a scale and rotation invariant compact composite moment-based
   descriptor for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Low level features; Compact composite
   descriptors
ID COLOR; FEATURES; REPRESENTATION
AB Low level features play a significant role in image retrieval. Image moments can effectively represent global information of image content while being invariant under translation, rotation, and scaling. This paper presents CoMo: a moment based composite and compact low-level descriptor that can be used effectively for image retrieval and robot vision tasks. The proposed descriptor is evaluated by employing the Bag-of-Visual-Words representation over various well-known benchmarking image databases. The findings from the experimental evaluation provide strong evidence of high and competitive retrieval performance against various state-of-the-art local descriptors.
C1 [Vassou, S. A.] Cyprus Univ Technol, Limassol, Cyprus.
   [Anagnostopoulos, N.] Microsoft, Prague, Czech Republic.
   [Christodoulou, K.; Chatzichristofis, S. A.] Neapolis Univ Pafos, Dept Informat Sci, Pafos, Cyprus.
   [Amanatiadis, A.] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
C3 Cyprus University of Technology; Democritus University of Thrace
RP Chatzichristofis, SA (corresponding author), Neapolis Univ Pafos, Dept Informat Sci, Pafos, Cyprus.
EM s.chatzichristofis@nup.ac.cy
RI Chatzichristofis, Savvas/AAA-2698-2020; Amanatiadis,
   Angelos/AAI-9496-2021; Christodoulou, Klitos/J-8249-2018
OI Chatzichristofis, Savvas/0000-0002-4657-4435; Amanatiadis,
   Angelos/0000-0002-1595-2683; Christodoulou, Klitos/0000-0003-3543-6405
CR [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   Aslan S, 2017, J VIS COMMUN IMAGE R, V49, P315, DOI 10.1016/j.jvcir.2017.09.009
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2013, IEEE T CYBERNETICS, V43, P192, DOI 10.1109/TSMCB.2012.2203300
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dong L, 2016, IEEE T MULTIMEDIA, V18, P714, DOI 10.1109/TMM.2016.2530399
   Eisa M, 2013, ARXIVABS13012542 COR
   Fond A, 2017, 16 IEEE INT S MIX AU
   Gholipour F, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P67, DOI 10.1109/IKT.2014.7030335
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   HARRIS CG, 1988, IMAGE VISION COMPUT, V6, P87, DOI 10.1016/0262-8856(88)90003-0
   Huang J, 2001, US Patent, Patent No. [6,246,790 12:1-16, 624679012]
   Iakovidou C, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0262-6
   Jain M., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1441
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Karakasis EG, 2015, PATTERN RECOGN LETT, V55, P22, DOI 10.1016/j.patrec.2015.01.005
   Kim NW, 2005, LECT NOTES COMPUT SC, V3568, P454
   Lei Z., 1999, P IEEE REG 10 C TENC, V1, P166
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Li XC, 2015, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR.2015.7299151
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lux M., 2016, 14 INT WORKSH CONT B, P1, DOI DOI 10.1109/CBMI.2016.7500248
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mikulík A, 2010, LECT NOTES COMPUT SC, V6313, P1
   Nister D., 2006, Proc. CVPR, V5
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papakostas GA, 2013, NEUROCOMPUTING, V99, P358, DOI 10.1016/j.neucom.2012.06.031
   Papakostas GA, 2009, INFORM SCIENCES, V179, P3619, DOI 10.1016/j.ins.2009.06.033
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Petscharnig S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095737
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Qi G.-J., 2007, PROC IEEE C COMPUT V, P1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reta C, 2017, MULTIMED TOOLS APPL, DOI [10. 1007/s11042-017-4708-8., DOI 10.1007/S11042-017-4708-]
   Rosten E., 2006, P 2006 9 EUR C COMP, P430, DOI DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shao H., 2003, ZUBUD ZURICH BUILD I, P6
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shyu CR, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P30, DOI 10.1109/IVL.1998.694482
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4
   Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007
   Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177
   Vassou SA, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095744
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Zhang SL, 2015, IEEE T PATTERN ANAL, V37, P2573, DOI 10.1109/TPAMI.2015.2417573
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
NR 63
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2765
EP 2788
DI 10.1007/s11042-018-5854-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600008
DA 2024-07-18
ER

PT J
AU Zhang, QX
   Gong, HX
   Zhang, XS
   Liang, C
   Tan, YA
AF Zhang, Quanxin
   Gong, Hanxiao
   Zhang, Xiaosong
   Liang, Chen
   Tan, Yu-an
TI A sensitive network jitter measurement for covert timing channels over
   interactive traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Jitter; RTCP; Covert timing channel; IPD
ID SECURE; PROTECTION; DEPLOYMENT; SIGNATURE; VOLTE
AB In order to reflect the network transmission quality, some network state feedback mechanisms are provided in the network protocol. In the RTP, the jitter of the packet transmission delay is fed back through the jitter field in the RTCP packet. This feedback value is a very important reference data when the covert timing channel is established. However, the sending frequency of the RTCP packet is low and the feedback value of the RTCP packet are only the jitter value of the last RTP packet associated with this RTCP packet when it is sent. Therefore, the jitter feedback mechanism in the existing RTCP protocol has the problem of lack of feedback on the network state during the period between two RTCP data packets. As a result, the feedback value is highly susceptible to extreme values, which prevents it from providing an accurate numerical reference for establishing covert channels. Therefore, in this paper, a buffer was established between the last RTCP packet and the current RTCP packet. And we choose to set the interval is n RTP packets and record the corresponding position jitter value in the buffer. The data in the buffer is averaged, and the mean value is weighted and averaged with the jitter value of the current RTCP packet as a new jitter feedback value. The effect of the extreme value on the feedback value is reduced, thereby it contribute to the improvement of the feedback energy for the state of the network. In addition, the bit error rate generated by establishing a simple covert timing channel for data transmission under different network conditions is compared with the change of two jitter feedback values. It is verified that there is a positive correlation between the feedback value of the new feedback mode and the error rate. through the comparison It is verified that the new feedback method can provide a more accurate reference for the establishment of covert channels.
C1 [Zhang, Quanxin; Gong, Hanxiao; Zhang, Xiaosong; Liang, Chen; Tan, Yu-an] Beijing Inst Technol, Sch Sci & Technol, Beijing 100081, Peoples R China.
   [Zhang, Xiaosong] Tangshan Univ, Dept Comp Sci & Technol, Tangshan 063000, Peoples R China.
C3 Beijing Institute of Technology; Tangshan University
RP Tan, YA (corresponding author), Beijing Inst Technol, Sch Sci & Technol, Beijing 100081, Peoples R China.
EM zhangqx@bit.edu.cn; 13718106764@163.com; zxs0224@163.com;
   1342313537@qq.com; tan2008@bit.edu.cn
RI Liang, Chen/HNP-5916-2023
FU National Natural Science Foundation of China [U1636213]
FX This paper was supported by the National Natural Science Foundation of
   China (No. U1636213).
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Andreadis A, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0695-0
   [Anonymous], P INT C MAL UNW SOFT
   Archibald R., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P970, DOI 10.1109/TrustCom.2012.21
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Biswas AK, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3023872
   Carle G, 1997, IEEE NETWORK, V11, P24, DOI 10.1109/65.642357
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen ZX, 2017, SOFT COMPUT, V21, P2035, DOI 10.1007/s00500-015-1902-3
   Denby L, 2007, TECHNOMETRICS, V49, P318, DOI 10.1198/004017007000000290
   Fu LF, 2017, J COMPUT ACOUST, V25, DOI 10.1142/S0218396X17500345
   Gianvecchio S, 2008, LECT NOTES COMPUT SC, V5230, P211, DOI 10.1007/978-3-540-87403-4_12
   Guan ZT, 2017, IEEE INTERNET THINGS, V4, P1934, DOI 10.1109/JIOT.2017.2690522
   Guan ZT, 2017, IEEE T IND INFORM, V13, P3216, DOI 10.1109/TII.2017.2706760
   Hastyo WJ, 2014, NMR BIOMED, V22, P191
   He B, 2017, IEEE COMMUN LETT, V21, P941, DOI 10.1109/LCOMM.2016.2647716
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Imputato P, 2018, SIMUL MODEL PRACT TH, V80, P1, DOI 10.1016/j.simpat.2017.09.008
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Jouihri Y, 2017, TELECOMMUN SYST, V64, P467, DOI 10.1007/s11235-016-0186-y
   Jung TJ, 2016, J REAL-TIME IMAGE PR, V12, P455, DOI 10.1007/s11554-015-0497-3
   Kumar R, 2006, J NONCRYST SOLIDS, V144, P247
   Li J, 2018, COMPUT SECUR, V72, P1, DOI 10.1016/j.cose.2017.08.007
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Liu Q, 2017, IEEE T PARALL DISTR, V28, P1417, DOI 10.1109/TPDS.2016.2615020
   Qi W, 2018, IEEE T MOBILE COMPUT, V17, P44, DOI 10.1109/TMC.2017.2696945
   Qiu Lili., 1985, NATL COMPUTER SECURI
   Rezaei F, 2017, IEEE T DEPEND SECURE, V14, P249, DOI 10.1109/TDSC.2017.2656078
   Schulzrinne H, 1995, INTERNET SERVICES EL, P21
   Schulzrinne H, 1996, IETF RFC, V2
   Serdar C., 2004, P 11 ACM C COMP COMM, P178, DOI [10.1145/1030083.1030108, DOI 10.1145/1030083.1030108]
   Shen J, 2018, J NETW COMPUT APPL, V106, P117, DOI 10.1016/j.jnca.2018.01.003
   Szpyrka M, 2013, COMPUT SCI, V6, P81
   Wang YH, 2016, INT J FUZZY SYST, V18, P424, DOI 10.1007/s40815-016-0175-z
   Wu ZY, 2015, IEEE ACM T NETWORK, V23, P603, DOI 10.1109/TNET.2014.2304439
   Xue Y, 2018, SOFT COMPUT, V22, P4445, DOI 10.1007/s00500-017-2651-2
   Zhang XS, 2018, MULTIMED TOOLS APPL, V77, P11137, DOI 10.1007/s11042-017-5363-9
   Zhang XS, 2017, CLUSTER COMPUT, V20, P2393, DOI 10.1007/s10586-016-0721-3
   Zhu HF, 2018, CHINESE J ELECTRON, V27, P297, DOI 10.1049/cje.2017.09.008
   Zhu HF, 2017, FUTURE GENER COMP SY, V73, P106, DOI 10.1016/j.future.2017.01.031
   Zhu RJ, 2017, INT J CRIT INFR PROT, V16, P26, DOI 10.1016/j.ijcip.2016.12.002
   Zkik K, 2017, INT J CLOUD APPL COM, V7, P62, DOI 10.4018/IJCAC.2017040105
NR 47
TC 30
Z9 30
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3493
EP 3509
DI 10.1007/s11042-018-6281-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600046
DA 2024-07-18
ER

PT J
AU Gnouma, M
   Ladjailia, A
   Ejbali, R
   Zaied, M
AF Gnouma, Mariem
   Ladjailia, Ammar
   Ejbali, Ridha
   Zaied, Mourad
TI Stacked sparse autoencoder and history of binary motion image for human
   activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Silhouette extraction; History of binary
   motion image; Deep learning
ID WAVELET NETWORK
AB The recognition of human actions in a video sequence still remains a challenging task in the computer vision community. Several techniques have been proposed until today such as silhouette detection, local space-time features and optical flow techniques. In this paper, a supervised way followed by an unsupervised learning using the principle of the auto-encoder is proposed to address the problem. We introduce a new foreground detection architecture based on information extracted from the Gaussian mixture model (GMM) incorporating with the uniform motion of Magnitude of Optical Flow (MOF). Thus, we use a fast dynamic frame skipping technique to avoid frames that contain irrelevant motion, making it possible to decrease the computational complexity of silhouette extraction. Furthermore a new technique of representations to construct an informative concept for human action recognition based on the superposition of human silhouettes is presented. We called this approach history of binary motion image (HBMI).Our method has been evaluated by a classification on the Ixmas, Weizmann, and KTH datasets, the Sparce Stacked Auto-encoder (SSAE), an instance of a deep learning strategy, is presented for efficient human activities detection and the Softmax (SMC) for the classification. The objective of this classifier in deep learning is the learning of function hierarchies with higher-level functions at lower-level functions of the hierarchy to provide an agile, robust and simple method. The results prove the efficiency of our proposed approach with respect to the irregularity in the performance of an action shape distortion, change of point of view as well as significant changes of scale.
C1 [Gnouma, Mariem; Ejbali, Ridha; Zaied, Mourad] Univ Gabes, Natl Sch Engineers Gabes, Res Team Intelligent Machines, Gabes, Tunisia.
   [Ladjailia, Ammar] Univ Souk Ahras, Fac Sci & Technol, Souk Ahras, Algeria.
   [Ladjailia, Ammar] Univ Annaba, Algeria Dept Comp Sci, Annaba, Algeria.
C3 Universite de Gabes; Universite de Souk Ahras Mohammed Cherif Messaadia;
   Universite Badji Mokhtar - Annaba
RP Gnouma, M (corresponding author), Univ Gabes, Natl Sch Engineers Gabes, Res Team Intelligent Machines, Gabes, Tunisia.
EM mariem21gnouma@gmail.com; l_ammardz@yahoo.fr; ridha_ejbali@ieee.org;
   mourad.zaied@ieee.org
RI Ladjailia, Ammar/ABD-6963-2020; Ejbali, Ridha/K-4234-2012
OI Ladjailia, Ammar/0000-0001-8364-1791; Ejbali, Ridha/0000-0002-8148-1621;
   gnouma, mariem/0000-0002-2357-6817
FU General Direction of scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Abdessamad J, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268766
   Abidine M., 2013, P 2013 INT C COMPUTE, DOI [10.1109/ICCMA.2013.6506158, DOI 10.1109/ICCMA.2013.6506158]
   Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 1981, 7 INT JOINT C ARTIFI
   Bellil W., 2004, SCS 04, P201
   Benezeth Y, 2010, ICVGIP
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick Aaron F., IEEE T PATTERN ANAL
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Chandrashekhar V, 2006, ACTION ENERGY IMAGES
   Chang Z, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/528190
   Chaudhry R, 2014, P C COMP VIS PATT RE, P471
   Chen CH, 2007, IEEE C EVOL COMPUTAT, P1
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Dobhal T, 2015, PROCEDIA COMPUT SCI, V58, P178, DOI 10.1016/j.procs.2015.08.050
   Ejbali R, 2018, MULTIMED TOOLS APPL, V77, P6149, DOI 10.1007/s11042-017-4523-2
   Ejbali R, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P88, DOI 10.1109/HIS.2013.6920461
   Ejbali R, 2010, KDIR 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND INFORMATION RETRIEVAL, P518
   ElAdel A, 2016, MACH VISION APPL, V27, P781, DOI 10.1007/s00138-016-0789-z
   Gnouma M, 2018, MULTIMED TOOLS APPL, P1
   Gnouma M, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268988
   Hassairi S., 2016, INT C DIG IM COMP TE, P1
   Hassairi S, 2015, 15 INT C INT SYST DE, DOI [10.1109/ISDA.2015.7489226, DOI 10.1109/ISDA.2015.7489226]
   Hassairi S, 2018, MULTIMED TOOLS APPL, V77, P5443, DOI 10.1007/s11042-017-4461-z
   Hassairi S, 2015, PROC INT C TOOLS ART, P265, DOI 10.1109/ICTAI.2015.49
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hwang JN, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P616, DOI 10.1109/MMSP.1998.739049
   Jalal A, 2012, IEEE T CONSUM ELECTR, V58, P863, DOI 10.1109/TCE.2012.6311329
   Jemai O, 2015, 7 INT C MACH VIS ICM, P944
   JIA K, 2008, IEEE C COMP VIS PATT
   Karthikeyan S, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Ke S, 2013, REV VIDEO BASED HUMA, DOI [10.3390/280computers2020088, DOI 10.3390/280C0MPUTERS2020088]
   Khatrouch M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2314834
   Ladjailia A, 2016, 4 INT C EL ENG ICEE, DOI [10.1109/INTEE.2015.7416792, DOI 10.1109/INTEE.2015.7416792]
   Ladjailia A., 2018, COMPUTER VISION CONC, P2042
   Li ZZW, 2008, IEEE T CIRCUITS SYST, P1499
   Liu H., 2017, HUMAN MOTION SENSING, P233, DOI DOI 10.1007/978-3-662-53692-6_11
   Maity S, 2016, ELSEVIER IETE J RES
   Mariem G., 2016, International Journal of Computer Theory and Engineering, V8, P398, DOI 10.7763/IJCTE.2016.V8.1078
   Qi J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114147
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Seo JJ, 2017, IMAGE VISION COMPUT, V58, P76, DOI 10.1016/j.imavis.2016.06.002
   Singh VK, 2011, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2011.6126232
   Sivagami M., 2017, International Journal of High Performance Computing and Networking, V10, P44
   Teyeb I, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P379, DOI 10.1109/IISA.2014.6878809
   Wang J, 2014, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-04561-0_2
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Willems TTG, P 10 EUR C COMP VIS
   Yu S, 2017, MULTIMED TOOLS APPL, V76, P13367, DOI 10.1007/s11042-016-3768-5
   Yu ZL, 2014, P AS C COMP VIS
   Zaied M, 2012, INT REV COMPUTERS SO, V7
   Zhen X, 2014, INFORM SCI
NR 54
TC 27
Z9 28
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2157
EP 2179
DI 10.1007/s11042-018-6273-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700039
DA 2024-07-18
ER

PT J
AU Ling, ZG
   Fan, GL
   Gong, JW
   Guo, SY
AF Ling, Zhigang
   Fan, Guoliang
   Gong, Jianwei
   Guo, Siyu
TI Learning deep transmission network for efficient image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Haze-relevant features; Convolutional neural networks;
   Deep transmission network
ID VISION; HAZE; RESTORATION; VISIBILITY; ALGORITHM; TRACKING
AB Single image dehazing algorithms are recently attracting more and more attention from many researchers because of their flexibility and practicality. However, most existing algorithms have some challenges in dealing with images captured under complex weather conditions because the often used assumptions cannot always reflect true structural information of natural images in those situations. In this paper, we develop a deep transmission network to estimate the transmission map for efficient image dehazing, which automatically explores and exploits underlying haze-relevant features from RGB color channels and a local patch jointly for robust transmission estimation. Moreover, due to the fact that transmission values are affected by light wavelengths, a three-channel transmission map is considered in the proposed network so that this network can discover and utilize the chromatic characteristics for transmission estimation. We also investigate different network structures and parameter settings to achieve different trade-offs between performance and speed, and find that three color channels and local spatial information are the most informative haze-relevant features. This could explain why haze relevant priors or assumptions are often related to three color channels in most existing methods. Experiment results demonstrate that the proposed algorithm outperforms state-of-the-art methods on both synthetic and real-world datasets.
C1 [Ling, Zhigang; Gong, Jianwei; Guo, Siyu] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
   [Ling, Zhigang] Natl Engn Lab Robot Visual Percept & Control Tech, Changsha, Hunan, Peoples R China.
   [Fan, Guoliang] Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.
C3 Hunan University; Oklahoma State University System; Oklahoma State
   University - Stillwater
RP Ling, ZG (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.; Ling, ZG (corresponding author), Natl Engn Lab Robot Visual Percept & Control Tech, Changsha, Hunan, Peoples R China.
EM zgling_hunan@126.com; guoliang.fan@okstate.edu; syguo75@163.com
RI Gong, Jianwei/I-1710-2013
FU National Natural Science Foundation of China [61471166, 61471167,
   61671204]; Natural Science Foundation of Hunan Province (CN) [14JJ2052]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61471166, 61471167 and 61671204) and Natural Science
   Foundation of Hunan Province (CN) (14JJ2052).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], PHYSICAE FREIBERGER
   [Anonymous], 1962, Elements of Infrared Technology: Generation, Transmission and Detection
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Danescu R, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2011.2178492
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gaikwad V, 2015, IEEE T INTELL TRANSP, V16, P910, DOI 10.1109/TITS.2014.2347400
   Grabner M, 2011, OPT EXPRESS, V19, P3379, DOI 10.1364/OE.19.003379
   Hao JY, 2013, IEEE T INTELL TRANSP, V14, P295, DOI 10.1109/TITS.2012.2212432
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Hautière N, 2010, IEEE T INTELL TRANSP, V11, P474, DOI 10.1109/TITS.2010.2046165
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Kim D, 2008, IEEE INT C MULT FUS
   Kopf J., 2008, ACM TRANS GRAPHICS, V27
   Lai YH, 2015, IEEE T CIRC SYST VID, V25, P1, DOI 10.1109/TCSVT.2014.2329381
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lu HP, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/348036
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2003, CONJUNCTION ICCV
   Nayar Shree K, 1999, 7 IEEE INT C COMP VI
   Oakley JP, 2007, IEEE T IMAGE PROCESS, V16, P511, DOI 10.1109/TIP.2006.887736
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Rong Z, 2014, OPTIK, V125, P3064, DOI 10.1016/j.ijleo.2013.12.077
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Tan HL, 2017, MULTIMED TOOLS APPL, V76, P23413, DOI 10.1007/s11042-016-4036-4
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tian B, 2014, IEEE T INTELL TRANSP, V15, P597, DOI 10.1109/TITS.2013.2283302
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu BF, 2013, IEEE T INTELL TRANSP, V14, P485, DOI 10.1109/TITS.2012.2208190
   Xu YW, 2012, IEEE T SYST MAN CY B, V42, P729, DOI 10.1109/TSMCB.2011.2175726
   Xu Z., 2009, 2009 INT C COMP INT, P1
   Zhou J, 2013, 2 INT S INSTR MEAS S
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 44
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 213
EP 236
DI 10.1007/s11042-018-5687-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500012
DA 2024-07-18
ER

PT J
AU Zhang, MM
   Lai, DL
   Liu, Z
   An, CZ
AF Zhang, Mengmeng
   Lai, Delun
   Liu, Zhi
   An, Changzhi
TI A novel adaptive fast partition algorithm based on CU complexity
   analysis in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Entropy; Texture contrast; Unit coding; Adaptive
ID MODE DECISION; SIZE DECISION; VIDEO; EFFICIENCY; SCHEME
AB High efficiency video coding (HEVC) is the latest video coding standard. Compared with H.264, the proposal of quad-tree structure not only improves the coding efficiency greatly but also increases complexity of coding. Therefore, this paper performed a fast-adaptive algorithm based on the complexity of images for intra prediction. Two values from micro and macro levels are considered for each coding unit block. We use entropy on the macroscopic level and texture contrast on the microscopic level. Relatively, large pictures always have more smooth blocks and there are more complex blocks in small pictures. To deal with this problem, this study uses adaptive process to make the values of entropy and texture contrast close to the ideal values of the current video, thereby making the division reasonable. Experimental results show that the proposed algorithm can reduce 34.6% coding time on average, with a loss of BjOntegaard delta rate of 0.8%.
C1 [Zhang, Mengmeng; Lai, Delun; Liu, Zhi] North China Univ Technol, Beijing, Peoples R China.
   [An, Changzhi] Beijing China Elect Intelligent Commun Technol Co, Beijing, Peoples R China.
C3 North China University of Technology
RP Zhang, MM (corresponding author), North China Univ Technol, Beijing, Peoples R China.
EM muchmeng@126.com; ldelun0928@sina.com; lzliu@ncut.edu.cn;
   changzhi.an@ceict.com.cn
FU National Natural Science Foundation of China [61370111]; Beijing
   Municipal Natural Science Foundation [4172020]; Great Wall Scholar
   Project of Beijing Municipal Education Commission [CITTCD20180304];
   Beijing Youth Talent Project [CITTCD 201504001]; Beijing Municipal
   Education Commission General Program [KM201610009003]
FX This work is supported by the National Natural Science Foundation of
   China (No.61370111), Beijing Municipal Natural Science Foundation
   (No.4172020), Great Wall Scholar Project of Beijing Municipal Education
   Commission (CIT&TCD20180304), Beijing Youth Talent Project (CIT&TCD
   201504001), and Beijing Municipal Education Commission General Program
   (KM201610009003).
CR [Anonymous], THEOR COMPUT SCI
   Bai HH, 2007, IEEE T CIRC SYST VID, V17, P912, DOI 10.1109/TCSVT.2007.898646
   Bai HH, 2014, IEEE T CIRC SYST VID, V24, P1390, DOI 10.1109/TCSVT.2014.2315770
   Chen Y, 2017, IEEE DATA COMPR CONF, P434, DOI 10.1109/DCC.2017.38
   Chen YQ, 2015, INT CONF MACH LEARN, P295, DOI 10.1109/ICMLC.2015.7340938
   Fang MY, 2017, IEEE DATA COMPR CONF, P439, DOI 10.1109/DCC.2017.94
   Han WJ, 2010, IEEE T CIRC SYST VID, V20, P1709, DOI 10.1109/TCSVT.2010.2092612
   Huang HM, 2016, IEEE I C NETW INFRAS, P347, DOI 10.1109/ICNIDC.2016.7974594
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kim YH, 2016, INT SOC DESIGN CONF, P331
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li F, 2017, MULTIMED TOOLS APPL, V76, P13107, DOI 10.1007/s11042-016-3737-z
   Liu XG, 2017, IEEE T CIRC SYST VID, V27, P1737, DOI 10.1109/TCSVT.2016.2556278
   Marpe D, 2010, IEEE T CIRC SYST VID, V20, P1676, DOI 10.1109/TCSVT.2010.2092615
   Pakdaman F, 2017, MULTIMED TOOLS APPL, V76, P9891, DOI 10.1007/s11042-016-3584-y
   Qin J, 2017, IEICE T FUND ELECTR, VE100A, P1274, DOI 10.1587/transfun.E100.A.1274
   Saldanha M, 2017, J REAL-TIME IMAGE PR, V13, P55, DOI 10.1007/s11554-016-0597-8
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   [王驰 Wang Chi], 2017, [计算机工程与应用, Computer Engineering and Application], V53, P206
   Wang XJ, 2017, IEEE INT SYM BROADB, P153
   Xiao W, 2018, IEEE T CIRC SYST VID, V28, P499, DOI 10.1109/TCSVT.2016.2612684
   Xie XY, 2017, INT CONF SYST INFORM, P1302, DOI 10.1109/ICSAI.2017.8248487
   Xiong L, 2016, AS PAC SIGN INF PROC, P1
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Ye J, 2018, FUTURE GENER COMP SY, V81, P433, DOI 10.1016/j.future.2017.09.030
   Zhang QW, 2017, MULTIDIM SYST SIGN P, V28, P1203, DOI 10.1007/s11045-016-0388-1
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhou JB, 2017, IEEE T VLSI SYST, V25, P714, DOI 10.1109/TVLSI.2016.2593581
   Zhu WJ, 2017, IEEE T BROADCAST, V63, P673, DOI 10.1109/TBC.2017.2711144
NR 29
TC 15
Z9 15
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1035
EP 1051
DI 10.1007/s11042-018-6105-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500058
DA 2024-07-18
ER

PT J
AU Li, WQ
   Li, Y
AF Li, Wei-qiang
   Li, Yan
TI A study on the collaborative management method of product design cycle
   knowledge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Product design; Knowledge management; Knowledge migration; Knowledge
   cooperation
ID LIFE-CYCLE; ENGINEERING DESIGN; CONCEPTUAL DESIGN; MODELING APPROACH;
   INFORMATION; FRAMEWORK; SYSTEMS; REPRESENTATION; PERFORMANCE;
   INTEGRATION
AB Because of the ever-increasing market competition and rapidly changing of customers' requirements, the innovation quality and design efficiency of knowledge-intensive product has become the key factors in business success. The traditional knowledge management method which is based on design reuse and the single categories of design knowledge cannot satisfy these demands any more. Therefore, in order to effectively support the innovative design process of enterprises, a design knowledge collaborative management method based on multi-knowledge migration is proposed. According to the characteristics and functions during the product design process, the design knowledge is divided into three categories, design principle knowledge, design domain knowledge and design object knowledge. By extracting the operation attributes, relation attributes and physical attributes of the design knowledge, a unified knowledge representation model is established for different design participants. The ontology concept and knowledge matrix are used to establish the association between various categories of design knowledge. Multifarious knowledge search methods include keyword, function, principle and natural semantics are proposed for different design participants in different design stages. They can not only realize the knowledge reuse in the same domain but also support the cross-domain knowledge migration among different domain. Finally, based on the system analysis modelling, a design knowledge collaborative platform is established for the design process of mechanical products. A case study is also presented to illustrate the implementation of the platform.
C1 [Li, Wei-qiang; Li, Yan] Sichuan Univ, Sch Mfg Sci & Engn, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Li, WQ (corresponding author), Sichuan Univ, Sch Mfg Sci & Engn, Chengdu 610065, Sichuan, Peoples R China.
EM Liwenqiang@scu.edu.cn
FU National Natural Science Foundation of China [51435011]; Science &
   Technology Ministry Innovation Method Program China [2017IM040100]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 51435011) and the Science & Technology Ministry
   Innovation Method Program China (Grant No. 2017IM040100).
CR Aitken J, 2003, INT J PROD ECON, V85, P127, DOI 10.1016/S0925-5273(03)00105-1
   Al-Hakim L, 2007, COMPUT AIDED DESIGN, V32, P867
   Barao A, 2017, INT J INFORM MANAGE, V37, P735, DOI 10.1016/j.ijinfomgt.2017.07.013
   Baxter D, 2007, RES ENG DES, V18, P37, DOI 10.1007/s00163-007-0028-8
   Brunetti G, 2000, COMPUT AIDED DESIGN, V32, P877, DOI 10.1016/S0010-4485(00)00076-2
   Chen YJ, 2009, EXPERT SYST APPL, V36, P2759, DOI 10.1016/j.eswa.2008.01.049
   Fan Y, 2006, COMPUT ENG, V32, P197
   Fensel D, 2002, COMPUTER, V35, P56, DOI 10.1109/MC.2002.1046975
   Goel AK, 2012, COMPUT AIDED DESIGN, V44, P879, DOI 10.1016/j.cad.2011.03.010
   Gu CC, 2012, J ENG DESIGN, V23, P577, DOI 10.1080/09544828.2011.629318
   Hicks BJ, 2002, INT J INFORM MANAGE, V22, P263, DOI 10.1016/S0268-4012(02)00012-9
   Huang SH, 2001, J INTELL MANUF, V12, P377, DOI 10.1023/A:1011271501713
   Lei C, 2008, J ZHEJIANG U ENG SCI, V42, P2037
   Li WQ, 2017, INFORM SYST, V67, P71, DOI 10.1016/j.is.2017.03.007
   Li Wen-qiang, 2009, Computer Integrated Manufacturing Systems, V15, P1062
   Lin Hui-ping, 2007, Computer Integrated Manufacturing Systems, V13, P663
   Lin W, 2012, J COMPUT AIDED DESIG, V11, P1020
   Liu J, 2009, PROCEEDINGS OF 2009 8TH INTERNATIONAL CONFERENCE ON RELIABILITY, MAINTAINABILITY AND SAFETY, VOLS I AND II, P690, DOI 10.1109/ICRMS.2009.5270101
   Lu SCY, 2000, IEEE INTERNET COMPUT, V4, P54, DOI 10.1109/4236.877486
   Mustapha SMFDS, 2018, EXPERT SYST APPL, V97, P244, DOI 10.1016/j.eswa.2017.12.033
   Peng GZ, 2017, ADV ENG INFORM, V33, P314, DOI 10.1016/j.aei.2016.12.007
   Relich M, 2018, NEUROCOMPUTING, V272, P40, DOI 10.1016/j.neucom.2017.05.092
   Seong D, 2012, PROD PLAN CONTROL, V23, P922, DOI 10.1080/09537287.2011.586651
   [沈斌 SHEN Bin], 2006, [计算机工程, Computer Engineering], V32, P186
   Suh S, 2005, J CLEAN PROD, V13, P687, DOI 10.1016/j.jclepro.2003.04.001
   Swart J, 2003, HUM RESOUR MANAG J, V16, P60
   Tai YM, 2017, J ENG TECHNOL MANAGE, V46, P67, DOI 10.1016/j.jengtecman.2017.06.001
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tsai WP, 2010, ACAD MANAGE J, V53, P441, DOI 10.5465/AMJ.2010.51459152
   Violante MG, 2017, INT J INTERACT DES M, V11, P191, DOI 10.1007/s12008-015-0266-3
   Wu JN, 2011, INT J KNOWL SYST SCI, V2, P1, DOI 10.4018/jkss.2011100101
   YinHong P, 2007, KBE TECHNOLOGY ITS A, P7
   Yu W, 2002, CHINESE J MECH ENG, V38, P145
   Zhang WY, 2002, INT J ADV MANUF TECH, V19, P454, DOI 10.1007/s001700200048
   Zhang YF, 2017, J CLEAN PROD, V159, P229, DOI 10.1016/j.jclepro.2017.04.172
   Zhao JY, 2014, COMPUT HUM BEHAV, V30, P567, DOI 10.1016/j.chb.2013.06.041
NR 36
TC 2
Z9 2
U1 1
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27877
EP 27894
DI 10.1007/s11042-018-6024-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500007
DA 2024-07-18
ER

PT J
AU Lv, XP
   Liao, XF
   Yang, B
AF Lv, Xiupin
   Liao, Xiaofeng
   Yang, Bo
TI A novel scheme for simultaneous image compression and encryption based
   on wavelet packet transform and multi-chaotic systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet packet transform; Compressive sensing; Image compression;
   Multi-chaotic systems; Image encryption
ID PERMUTATION; MAP
AB This paper presents a new scheme for simultaneous image compression and encryption. First, the approach of wavelet packet transform is used to decompose an image. Herein, the image is divided into four different types and self-adaptive approaches are designed to process the four signals. Second, a fleeting image encryption algorithm based on multi-chaotic systems is proposed to protect the security of the image. The above method not only balances the compression ratio and reconstruction quality, but also greatly improves the encryption speed and transmission security of the image. More importantly, the proposed scheme solves a long-standing contradiction that a signal should be first compressed or encrypted, which often appears in traditional image compression and encryption systems. Computer simulations and numerical analysis validate that the proposed scheme possesses superior security, high efficiency and promising practical value for images encryption and transmission.
C1 [Lv, Xiupin; Liao, Xiaofeng; Yang, Bo] Southwest Univ, Coll Elect & Informat Engn, Chongqing Key Lab Nonlinear Circuits & Intelligen, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Liao, XF (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing Key Lab Nonlinear Circuits & Intelligen, Chongqing 400715, Peoples R China.
EM xfliao@swu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023
FU National Key Research and Development Program of China [2016YFB0800601];
   Natural Science Foundation of China [61472331, 61772434]
FX The authors would like to thank the anonymous reviewers for valuable
   comments and suggestions. This work is supported by National Key
   Research and Development Program of China (Grant no. 2016YFB0800601),
   Natural Science Foundation of China (Grant no. 61472331, 61772434).
CR [Anonymous], 2016, CHAOTIC DIGITAL IMAG
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Drukarev A, 1997, P SOC PHOTO-OPT INS, V3024, P855, DOI 10.1117/12.263297
   Du M, 2012, COMM COM INF SC, V346, P570
   George SN, 2014, J OPT-INDIA, V43, P1, DOI 10.1007/s12596-013-0147-8
   Goirand E, 1994, WAVELET APPL CHEM EN, P275
   Goklani Hemant S., 2017, International Journal of Image, Graphics and Signal Processing, V9, P30, DOI 10.5815/ijigsp.2017.08.04
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hilton ML, 1997, IEEE T BIO-MED ENG, V44, P394, DOI 10.1109/10.568915
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang R, 2012, PARALLEL IMAGE ENCRY
   Huang X, 2014, IMAGE ENCRYPTION ALG
   Korhonen J, 2012, INT WORK QUAL MULTIM, P37, DOI 10.1109/QoMEX.2012.6263880
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Qureshi MA, 2016, MULTIMED TOOLS APPL, V75, P6737, DOI 10.1007/s11042-015-2590-9
   Shima H., 2009, Higher Mathematics for Physics and Engineering, P449
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 31
TC 32
Z9 32
U1 2
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28633
EP 28663
DI 10.1007/s11042-018-6013-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500035
DA 2024-07-18
ER

PT J
AU Zeng, W
   Wang, C
   Wang, QH
AF Zeng, Wei
   Wang, Cong
   Wang, Qinghui
TI Hand gesture recognition using Leap Motion via deterministic learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Deterministic learning; Leap Motion; Hand
   motion dynamics; RBF neural networks
ID MODEL; REPRESENTATION; RETRIEVAL; SYSTEM
AB With the development of multimedia technology, traditional interactive tools, such as mouse and keyboard, cannot satisfy users' requirements. Touchless interaction has received considerable attention in recent years with benefit of removing barriers of physical contact. Leap Motion is an interactive device which can be used to collect information of dynamic hand gestures, including coordinate, acceleration and direction of fingers. The aim of this study is to develop a new method for hand gesture recognition using jointly calibrated Leap Motion via deterministic learning. Hand gesture features representing hand motion dynamics, including spatial position and direction of fingers, are derived from Leap Motion. Hand motion dynamics underlying motion patterns of different gestures which represent Arabic numbers (0-9) and capital English alphabets (A-Z) are modeled by constant radial basis function (RBF) neural networks. Then, a bank of estimators is constructed by the constant RBF networks. By comparing the set of estimators with a test gesture pattern, a set of recognition errors are generated. The average L (1) norms of the errors are taken as the recognition measure according to the smallest error principle. Finally, experiments are carried out to demonstrate the high recognition performance of the proposed method. By using the 2-fold, 10-fold and leave-one-person-out cross-validation styles, the correct recognition rates for the Arabic numbers are reported to be 94.2%, 95.1% and 90.2%, respectively, for the English alphabets are reported to be 89.2%, 92.9% and 86.4%, respectively.
C1 [Zeng, Wei; Wang, Qinghui] Longyan Univ, Sch Mech & Elect Engn, Longyan 364012, Peoples R China.
   [Wang, Cong] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 Longyan University; South China University of Technology
RP Zeng, W (corresponding author), Longyan Univ, Sch Mech & Elect Engn, Longyan 364012, Peoples R China.
EM zw0597@126.com
RI Zeng, Wei/AFO-2103-2022
OI Zeng, Wei/0000-0002-8353-8265
FU National Natural Science Foundation of China [61773194, 61304084];
   Program for New Century Excellent Talents in Fujian Province University;
   Science and Technology Project of Longyan City [2017LY69]
FX This work was supported by the National Natural Science Foundation of
   China (Grant nos. 61773194, 61304084), by the Program for New Century
   Excellent Talents in Fujian Province University, and by the Science and
   Technology Project of Longyan City (Grant no. 2017LY69).
CR [Anonymous], 2012, P 27 C IMAGE VISION
   Beh J, 2014, PATTERN RECOGN, V47, P1586, DOI 10.1016/j.patcog.2013.11.010
   Beh J, 2014, PATTERN RECOGN LETT, V36, P144, DOI 10.1016/j.patrec.2013.10.007
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Du GL, 2016, IEEE T IND INFORM, V12, P694, DOI 10.1109/TII.2016.2526674
   Elmezain M, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P1170
   Farrell JA, 1998, IEEE T NEURAL NETWOR, V9, P1008, DOI 10.1109/72.712182
   GORINEVSKY D, 1995, IEEE T NEURAL NETWOR, V6, P1237, DOI 10.1109/72.410365
   Hafiz AR, 2015, NEURAL PROCESS LETT, V42, P649, DOI 10.1007/s11063-014-9379-0
   HAKEN H, 1985, BIOL CYBERN, V51, P347, DOI 10.1007/BF00336922
   Herekar Rachana R., 2014, IOSR J COMPUTER ENG, V16, P75
   Hettig J, 2017, INT J COMPUT ASS RAD, V12, P1643, DOI 10.1007/s11548-017-1523-7
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Ju ZJ, 2014, IEEE-ASME T MECH, V19, P456, DOI 10.1109/TMECH.2013.2240312
   Kane L, 2016, PROCEDIA COMPUT SCI, V84, P6, DOI 10.1016/j.procs.2016.04.059
   Katahira R, 2015, PROCEDIA COMPUT SCI, V60, P1595, DOI 10.1016/j.procs.2015.08.269
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Kundu S., 2017, Int. J. Adv. Res.Comput. Sci. Softw. Eng., V7, P156
   Lamberti L, 2012, EXPERT SYST APPL, V39, P10489, DOI 10.1016/j.eswa.2012.02.081
   Lin WY, 2013, PATTERN RECOGN, V46, P662, DOI 10.1016/j.patcog.2012.09.014
   Liu N, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P648
   Liu NJ, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P100
   Lu GL, 2016, MULTIMED TOOLS APPL, V75, P3479, DOI 10.1007/s11042-015-2448-1
   Lu W, 2016, IEEE SIGNAL PROC LET, V23, P1188, DOI 10.1109/LSP.2016.2590470
   Maqueda AI, 2015, COMPUT VIS IMAGE UND, V141, P126, DOI 10.1016/j.cviu.2015.07.009
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Mohandes M, 2014, PROC IEEE INT SYMP, P960, DOI 10.1109/ISIE.2014.6864742
   Park J, 1991, NEURAL COMPUT, V3, P246, DOI 10.1162/neco.1991.3.2.246
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sahoo MK, 2015, COMPUTATIONAL INTELL, V2
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Shen JC, 2016, VISUAL COMPUT, V32, P359, DOI 10.1007/s00371-016-1209-0
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Tekin Bugra, 2016, P 27 BRIT MACHINE VI
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Vafadar M, 2015, MULTIMED TOOLS APPL, V74, P7515, DOI 10.1007/s11042-014-1989-z
   Wang C, 2006, IEEE T NEURAL NETWOR, V17, P130, DOI 10.1109/TNN.2005.860843
   Wang C., 2009, Deterministic learning theory for identification, recognition, and control
   Wang C, 2007, IEEE T NEURAL NETWOR, V18, P617, DOI 10.1109/TNN.2006.889496
   Wang C, 2009, INT J BIFURCAT CHAOS, V19, P1307, DOI 10.1142/S0218127409023640
   Wang M, 2016, MEASUREMENT, V94, P734, DOI 10.1016/j.measurement.2016.09.018
   Wang QQ, 2014, INT CONF INFO SCI, P598, DOI 10.1109/ICIST.2014.6920549
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xu YR, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P437, DOI 10.1109/ICInfA.2014.6932695
   Xue YX, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7040358
   Yang C, 2017, PATTERN RECOGN LETT, V99, P39, DOI 10.1016/j.patrec.2017.05.016
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Zaiti IA, 2015, PERS UBIQUIT COMPUT, V19, P821, DOI 10.1007/s00779-015-0863-y
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 57
TC 33
Z9 36
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28185
EP 28206
DI 10.1007/s11042-018-5998-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500018
DA 2024-07-18
ER

PT J
AU Esmael, AA
   dos Santos, JA
   Torres, RD
AF Esmael, Agnaldo Aparecido
   dos Santos, Jefersson Alex
   Torres, Ricardo da Silva
TI On the ensemble of multiscale object-based classifiers for aerial
   images: a comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object-based classification; Multiscale segmentation; Multiclass
   classification; Multiscale; Classifier ensemble; Comparative study;
   Boosting; Majority voting
ID REMOTE-SENSING IMAGES; CLASSIFICATION; MULTICLASS; SEGMENTATION;
   TEXTURE; SCALE; COLOR
AB Remote sensing images (RSIs) are increasingly used as data source to produce maps used in several applications. Modern sensors launched into space from the end of the 1990s have been producing high spatial resolution RSIs. The use of classification methods based on regions, called as Geographic Object-Based Image Analysis (GEOBIA), has been demonstrated to be more appropriate to deal with this kind of image. However, finding the appropriate segmentation scale, which is not a trivial task, is crucial for the success of a GEOBIA method. In this paper, we perform a comparative study involving seven methods for RSI multiclass classification that combine different features extracted from different scales: M1-OvA, M2-OvO, M3-AdaMH, M4-Samme, M5-MV, M5-WMV, and M6-Cascade. The first four methods are boosting-based techniques and the last three are based on the majority vote approach. The effectiveness of the proposed methods was evaluated by analyzing the results of experiments conducted in three RSIs datasets. The methods were compared with the baseline SVM with Kernel RBF by measuring the overall accuracy, the Kappa Index, and the accuracy per class. The results show that all the proposed methods are effective for RSI classification.
C1 [Esmael, Agnaldo Aparecido; Torres, Ricardo da Silva] Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1251, BR-13083852 Campinas, SP, Brazil.
   [dos Santos, Jefersson Alex] Univ Fed Minas Gerais, Dept Comp Sci, Av Antonio Carlos 6627 Predio ICEx, BR-31270010 Pampulha Belo Horizonte, MG, Brazil.
C3 Universidade Estadual de Campinas; Universidade Federal de Minas Gerais
RP Torres, RD (corresponding author), Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1251, BR-13083852 Campinas, SP, Brazil.
EM rtorres@ic.unicamp.br
RI dos Santos, Jefersson/HKW-4282-2023; Torres, Ricardo da S./C-4526-2012
OI dos Santos, Jefersson/0000-0002-8889-1586; 
FU CNPq [312167/2015-6, 307560/2016-3]; FAPESP [2014/12236-1, 2015/24494-8,
   2016/50250-1, 2017/20945-0]; FAPESP-Microsoft Virtual Institute
   [2014/50715-9, 2013/50155-0, 2013/50169-1]; CAPES
   [88881.145912/2017-01]; FAPEMIG [APQ-00449-17]; Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [14/12236-1, 13/50155-0,
   17/20945-0, 16/50250-1, 14/50715-9] Funding Source: FAPESP
FX This work was financed by CNPq (grants #312167/2015-6, and
   #307560/2016-3), FAPESP (grants #2014/12236-1, #2015/24494-8,
   #2016/50250-1, and #2017/20945-0), FAPESP-Microsoft Virtual Institute
   (grants #2014/50715-9, #2013/50155-0, and #2013/50169-1), CAPES (grant #
   88881.145912/2017-01), and FAPEMIG (APQ-00449-17).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], P 8 INT S MATH MORPH
   [Anonymous], 2013, The return of adaboost.mh: multi-class hamming trees
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Bovolo F, 2010, IEEE T IMAGE PROCESS, V19, P2983, DOI 10.1109/TIP.2010.2051632
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Cunningham P, 2000, LECT NOTES ARTIF INT, V1810, P109
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   dos Santos JA, 2013, IEEE J-STARS, V6, P2020, DOI 10.1109/JSTARS.2012.2237013
   dos Santos JA, 2012, IEEE T GEOSCI REMOTE, V50, P3764, DOI 10.1109/TGRS.2012.2186582
   Du PJ, 2012, SENSORS-BASEL, V12, P4764, DOI 10.3390/s120404764
   Elmqvist B, 2008, INT J REMOTE SENS, V29, P7129, DOI 10.1080/01431160802238419
   Faria Fabio A., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P16, DOI 10.1109/SIBGRAPI.2013.12
   Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2
   Gianinetto M, 2014, EUR J REMOTE SENS, V47, P229, DOI 10.5721/EuJRS20144715
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Huo LZ, 2015, IEEE GEOSCI REMOTE S, V12, P150, DOI 10.1109/LGRS.2014.2329713
   Im J, 2014, SCALE ISSUES IN REMOTE SENSING, P197
   Johnson BA, 2013, REMOTE SENS LETT, V4, P131, DOI 10.1080/2150704X.2012.705440
   Kavzoglu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.035016
   Kim M, 2010, PHOTOGRAMM ENG REM S, V76, P137, DOI 10.14358/PERS.76.2.137
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li XX, 2014, REMOTE SENS-BASEL, V6, P11372, DOI 10.3390/rs61111372
   Lin YD, 2017, MULTIMED TOOLS APPL, V76, P14461, DOI 10.1007/s11042-016-3857-5
   Liu DS, 2010, REMOTE SENS LETT, V1, P187, DOI 10.1080/01431161003743173
   Luo YM, 2016, MULTIMED TOOLS APPL, V75, P9707, DOI 10.1007/s11042-015-2906-9
   Nogueira K, 2016, INT C PATT RECOG, P3566, DOI 10.1109/ICPR.2016.7900187
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Nogueira K, 2015, LECT NOTES COMPUT SC, V9423, P67, DOI 10.1007/978-3-319-25751-8_9
   Novack T, 2011, REMOTE SENS-BASEL, V3, P2263, DOI 10.3390/rs3102263
   Paisitkriangkrai S, 2014, IEEE T NEUR NET LEAR, V25, P764, DOI 10.1109/TNNLS.2013.2281214
   Pasolli E, 2014, IEEE T GEOSCI REMOTE, V52, P2217, DOI 10.1109/TGRS.2013.2258676
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Rocha A, 2014, IEEE T NEUR NET LEAR, V25, P289, DOI 10.1109/TNNLS.2013.2274735
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Schapire RE, 1999, INT JOINT C ART INT, P1401
   Suo AN, 2016, MULTIMED TOOLS APPL, V75, P12061, DOI 10.1007/s11042-016-3334-1
   Trias-Sanz R, 2008, ISPRS J PHOTOGRAMM, V63, P156, DOI 10.1016/j.isprsjprs.2007.08.005
   Tuia D, 2009, IEEE T GEOSCI REMOTE, V47, P2218, DOI 10.1109/TGRS.2008.2010404
   Tzotsos A., 2008, LECT NOTES GEOINFORM, P663, DOI DOI 10.1007/978-3-540-77058-9_36
   Tzotsos A, 2014, SCALE ISSUES IN REMOTE SENSING, P170
   Vargas JE, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P173, DOI 10.1109/SIBGRAPI.2014.49
   Wang L, 2010, DATA PROCESSING AND QUANTITATIVE ECONOMY MODELING, P1
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Zhang A., 2017, MULTIMED TOOLS APPL, P1
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 51
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24565
EP 24592
DI 10.1007/s11042-018-6023-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400001
DA 2024-07-18
ER

PT J
AU Gnouma, M
   Ejbali, R
   Zaied, M
AF Gnouma, Mariem
   Ejbali, Ridha
   Zaied, Mourad
TI Abnormal events' detection in crowded scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Anomaly detection; Crowd analysis; Tracking; Motion
   estimation
ID ANOMALY DETECTION; VIDEOS
AB In this paper, two new methods are developed in order to detect and track unexpected events in scenes. The process of detecting people may face some difficulties due to poor contrast, noise and the small size of the defects. For this purpose,the perfect knowledge of the geometry of these defects is an essential step in assessing the quality of detection. First, we collected statistical models of the element for each individual for time tracking of different people using the technique of Gaussian mixture model (GMM). Then we improved this method to detect and track the crowd(IGMM). Thereafter, we adopted two methods: the differential method of Lucas and Kanade(LK) and the method of optical flow estimation of Horn Schunck(HS) for optical flow representation. Then, we proposed a novel descriptor, named the Distribution of Magnitude of Optical Flow (DMOF) for anomalous events' detection in the surveillance video. This descriptor represents an algorithm whose aim is to accelerate the action of abnormal events' detection based on a local adjustment of the velocity field by manipulating the light intensity.
C1 [Gnouma, Mariem; Ejbali, Ridha; Zaied, Mourad] Univ Gabes, Natl Sch Engn Gabes, Res Team Intelligent Machines, Gabes, Tunisia.
C3 Universite de Gabes
RP Gnouma, M (corresponding author), Univ Gabes, Natl Sch Engn Gabes, Res Team Intelligent Machines, Gabes, Tunisia.
EM mariem.gnouma.tn@ieee.org
RI Ejbali, Ridha/K-4234-2012
OI Ejbali, Ridha/0000-0002-8148-1621; gnouma, mariem/0000-0002-2357-6817
FU General Direction of scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2013, IEEE INT C COMP VIS
   Benezeth Y, 2009, PROC CVPR IEEE, P2450
   Benezeth Y, 2011, PATTERN RECOGN LETT, V32, P423, DOI 10.1016/j.patrec.2010.10.008
   Biswas S, 2017, MACH VISION APPL, V28, P35, DOI 10.1007/s00138-016-0800-8
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Cao TA, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1709, DOI 10.1109/ROBIO.2009.5420408
   Chaturvedi P., 2013, INT J ADV COMPUTER R, V3, P866
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Direkoglu C, 2017, 14 IEEE INT C ADV VI
   Direkoglu C., 2017, 2017 14 IEEE INT C A, P1
   Drews P, 2010, 13 C INF FUS FUSION, P18
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Hauhan AK, 2013, INT J ADV RES COMPUT, V3
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu M, 2008, INT C PATT RECOG, P9
   Hu Y, 2013, IEEE COMPUT SOC CONF, P767, DOI 10.1109/CVPRW.2013.115
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kaviani R, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P586, DOI 10.1109/ICCKE.2014.6993441
   Khatrouch M, 2017, 10 INT C MACH VIS VI
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Kratz L, 2010, PROC CVPR IEEE, P693, DOI 10.1109/CVPR.2010.5540149
   Li A, 2017, MULTIMED TOOLS APPL, V76, P26249, DOI 10.1007/s11042-016-4115-6
   Li JF, 2010, PROCEEDINGS OF THE 4TH INTERNATIONAL YELLOW RIVER FORUM ON ECOLOGICAL CIVILIZATION AND RIVER ETHICS, VOL III, P293
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu X, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P306
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mariem G., 2016, International Journal of Computer Theory and Engineering, V8, P398, DOI 10.7763/IJCTE.2016.V8.1078
   Marques JS, 2003, IEEE COMP SOC C COMP, V9
   Marzat J, 2008, INRIA ESTIMATION TEM
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mousse AM, 2016, RECONNAISSANCE DACTI
   Nam Y, 2014, MULTIMED TOOLS APPL, V72, P3001, DOI 10.1007/s11042-013-1593-7
   Perez-Rua Juan-Manuel., 2017, Frontiers in ICT, V4, P10
   Rao A., 2014, IEEE Aerospace Conference Proceedings, P1, DOI DOI 10.1109/DICTA.2014.7008100
   Rodrigues de Almeida Igor, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P63, DOI 10.1109/SIBGRAPI.2013.18
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Ryan D., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P230, DOI 10.1109/AVSS.2011.6027327
   Santosh DHH., 2013, INT J SOFT COMPUTING, V3, P114
   Shah AJ, 2016, THESIS
   Shi YJ, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061608
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Tu P, 2008, LECT NOTES COMPUT SC, V5305, P691, DOI 10.1007/978-3-540-88693-8_51
   Tziakos I., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P519, DOI 10.1109/AVSS.2010.70
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Wang J, 2016, COMPUT VIS IMAGE UND, V144, P177, DOI 10.1016/j.cviu.2015.08.010
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Wu S, 2014, IEEE T CIRC SYST VID, V24, P85, DOI 10.1109/TCSVT.2013.2276151
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453
NR 55
TC 18
Z9 18
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24843
EP 24864
DI 10.1007/s11042-018-5701-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400012
DA 2024-07-18
ER

PT J
AU Helmy, M
   El-Rabaie, EM
   Eldokany, I
   Abd El-Samie, FE
AF Helmy, Mai
   El-Rabaie, El-Sayed M.
   Eldokany, Ibrahim M.
   Abd El-Samie, Fathi E.
TI Chaotic encryption with different modes of operation based on Rubik's
   cube for efficient wireless communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orthogonal Frequency Division Multiplexing (OFDM); Rubik's cube; Chaotic
   Bakermap; RC6; Rayleigh fading
ID CARRIER FREQUENCY OFFSET; OFDM
AB A novel image encryption algorithm based on the Rubik's cube scrambling is proposed in this paper to achieve simultaneous encryption of a group of images. This proposed encryption algorithm begins with chaotic Baker map permutation with a selected mode of operation or RC6 algorithm as a first step for encrypting the images, separately. After that, the obtained encrypted images are further encrypted in a second stage with Rubik's cube. Chaotic or RC6 encrypted images are used as the faces of the Rubik's cube. From the concepts of image encryption, the RC6 algorithm adds a degree of diffusion, while chaotic Baker map adds a degree of permutation. The Rubik's cube algorithm adds more permutation to the encrypted images, simultaneously. The simulation results demonstrate that the proposed encryption algorithm is efficient, and it exhibits strong robustness and security. The encrypted images are further transmitted over a wireless channel with Orthogonal Frequency Division Multiplexing (OFDM) system, and decrypted at the receiver side. Evaluation of the quality of the decrypted images at the receiver side reveals good performance.
C1 [Helmy, Mai; El-Rabaie, El-Sayed M.; Eldokany, Ibrahim M.; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Helmy, M (corresponding author), Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
EM mai_hil@yahoo.com; srabie1@yahoo.com; dokany_2006@hotmail.com;
   fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; EL-Rabaie,
   El-Sayed/0000-0001-6854-5881
CR Abraham L, 2013, INT J RES ENG TECHNO, V2
   Abraham L, 2013, INT J SCI TECHNOL RE, V2, P80
   Andre J M., 2007, Philosophica. Filosofia e Espaco Publico, P113
   [Anonymous], THESIS
   [Anonymous], ELEMENTRAY CRYPTOGRA, P29
   Bergman C, 2005, EUROPEAN MANAGEMENT, P1
   Ebrahim M., 2013, International Journal of Computer Applications, V61, P12
   Eldokany I, 2015, WIRELESS PERS COMMUN, V84, P475, DOI 10.1007/s11277-015-2645-2
   Elkamchouchi H., 2005, P 22 NAT RAD SCI C N, pC11
   Fishawy NFE., 2007, INT J NETWORK SECUR, V5, P241
   Hashim AT, 2010, IJCCCE, V10, P12
   Joyner WD, 1996, MATH RUBIKS CUBE, P1
   Lawrey E, 1997, THESIS
   Lawrey E., THESIS
   Li SJ, 2002, PROC SPIE, V4666, P149, DOI 10.1117/12.458527
   Li SJ, 2001, PHYS LETT A, V290, P127, DOI 10.1016/S0375-9601(01)00612-0
   Mohamed AB, 2011, 8 INT MULT C SOUSS T
   Ramia F, 2006, 646 ECE GMU
   Sirisha M., 2014, International Journal of Application or Innovation in Engineering & Management, V3, P273
   Swiss encryption technology, MEDICRYPT MOD OP, P1
   Tan P, 2005, GLOB TELECOMM CONF, P1429
   Verma H.K., 2012, International Journal of Computer Applications, V42, P1
NR 22
TC 9
Z9 9
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27337
EP 27361
DI 10.1007/s11042-018-5923-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500049
DA 2024-07-18
ER

PT J
AU Hu, HT
   Chang, JR
AF Hu, Hwai-Tsu
   Chang, Jieh-Ren
TI Dual image watermarking by exploiting the properties of selected DCT
   coefficients with JND modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual image watermarking; Discrete cosine transform; Partly sign-altered
   mean; Just noticeable distortion; Contrast masking
ID WAVELET-BASED WATERMARKING; INTERBLOCK PREDICTION; ROBUST; VISIBILITY;
   DWT
AB The distinctive properties of partly sign-altered (PSA) coefficients in discrete cosine transform (DCT) domain are explored to achieve effective dual blind image watermarking. A host image is divided into non-overlapped blocks, each of which is then converted to a DCT representation separately. For each block, low-frequency DCT coefficients are selected for dual binary watermarking. The first binary bit is applied to the mean value of the PSA coefficients. Our formulation takes into account of human psychovisual characteristics. A stair-like quantization function is designed to not only regulate embedding strength but accommodate extra embedding for blocks with high contrast masking. In case second watermarking is requested, we tactically adjust the standard deviation of the PSA coefficients while keeping the PSA mean intact. The embedding strengths with respect to the involved parameters in the first and second watermarking are analytically examined. Experiment results indicate that the proposed scheme is capable of achieving excellent robustness at a peak signal-to-noise ratio (PSNR) around 38.7 dB. In particular, the exploitation of just noticeable distortion helps to enhance the robustness of the first watermark without causing noticeable quality degradation. The secondary watermark is embedded at the cost of approximately 1 dB PSNR. Yet the resultant performance is comparable with other compared methods in terms of bit error rates.
C1 [Hu, Hwai-Tsu; Chang, Jieh-Ren] Natl Ilan Univ, Dept Elect Engn, Yilan 26041, Taiwan.
C3 National Ilan University
RP Hu, HT (corresponding author), Natl Ilan Univ, Dept Elect Engn, Yilan 26041, Taiwan.
EM hthu@mail.niu.edu.tw
FU Ministry of Science and Technology, Taiwan, ROC [MOST
   104-2221-E-197-023, MOST 105-2221-E-197-019]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, ROC, under Grants MOST 104-2221-E-197-023 & MOST
   105-2221-E-197-019.
CR AHUMADA AJ, 1992, P SOC PHOTO-OPT INS, V1666, P365
   [Anonymous], COMP COMM NETW 2008
   [Anonymous], MORGAN KAUFMANN SERI
   [Anonymous], 1968, MATH PHYS MONOGRAPH
   Bae SH, 2013, IEEE SIGNAL PROC LET, V20, P893, DOI 10.1109/LSP.2013.2272193
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Ghazy RA, 2014, OPTIK, V125, P6299, DOI 10.1016/j.ijleo.2014.08.012
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Shen H, 2012, COMPUT ELECTR ENG, V38, P1310, DOI 10.1016/j.compeleceng.2011.11.012
   Shi H, 2016, MULTIMED TOOLS APPL, V75, P465, DOI 10.1007/s11042-014-2301-y
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Tao P., 2006, J Multimed, V1, P36, DOI 10.4304/jmm.1.6.36-45
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wan WB, 2016, MULTIMED TOOLS APPL, V75, P13481, DOI 10.1007/s11042-015-2853-5
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Zhang GN, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2294
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
   Zheng D, 2006, CAN CON EL COMP EN, P2017
NR 46
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26965
EP 26990
DI 10.1007/s11042-018-5900-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500033
DA 2024-07-18
ER

PT J
AU Juarez-Sandoval, OU
   Cedillo-Hernandez, M
   Nakano-Miyatake, M
   Cedillo-Hernandez, A
   Perez-Meana, H
AF Ulises Juarez-Sandoval, Oswaldo
   Cedillo-Hernandez, Manuel
   Nakano-Miyatake, Mariko
   Cedillo-Hernandez, Antonio
   Perez-Meana, Hector
TI Digital image ownership authentication via camouflaged unseen-visible
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Image-processing; Information security; Unseen-visible
   watermarking; Ownership authentication
ID ROBUST; DELIVERY
AB In recent years, end users can easily capture digital images using several devices, such as smartphones, mobile devices and digital imaging cameras, allowing such images to be easily copied, manipulated, transmitted or format converted without any restrictions. This fact suggests the necessity to develop digital tools, such as digital watermarking, to solve the issues associated with copyright protection and ownership authentication of digital images. To claim the ownership of a digital image, we propose a camouflaged, unseen-visible watermarking technique based on luminance and texture properties in conjunction with an image enhancement criterion. The proposed method has some advantages over invisible and visible watermarking methodologies in terms of readability and imperceptibility of the watermark, respectively. The experimental results demonstrate that the proposed scheme is effective and applicable for digital images on a variety of topics, including natural scenes and man-made objects, both indoors and outdoors. A comparison with previously reported methods based on unseen-visible watermarking techniques is also provided.
C1 [Ulises Juarez-Sandoval, Oswaldo; Cedillo-Hernandez, Manuel; Nakano-Miyatake, Mariko; Cedillo-Hernandez, Antonio; Perez-Meana, Hector] Inst Politecn Nacl, SEPI ESIME Culhuacan, Ave Santa Ana 1000, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Cedillo-Hernandez, M (corresponding author), Inst Politecn Nacl, SEPI ESIME Culhuacan, Ave Santa Ana 1000, Mexico City, DF, Mexico.
EM mcedilloh@ipn.mx
RI Perez-Meana, Hector/N-1624-2019; Nakano, Mariko/N-4075-2019;
   Cedillo-Hernandez, Antonio/IYJ-5019-2023; Cedillo-Hernandez,
   Manuel/R-2154-2018
OI Perez-Meana, Hector/0000-0002-7786-2050; Cedillo-Hernandez,
   Manuel/0000-0002-9149-9841; Cedillo-Hernandez,
   Antonio/0000-0003-3420-6851; Juarez-Sandoval, Oswaldo
   Ulises/0000-0002-0330-8161
FU Instituto Politecnico Nacional (IPN); Consejo Nacional de Ciencia y
   Tecnologia de Mexico (CONACYT)
FX Authors thank the Instituto Politecnico Nacional (IPN) as well as the
   Consejo Nacional de Ciencia y Tecnologia de Mexico (CONACYT) by the
   support provided during the realization of this research.
CR AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Barker C., 2017, AGE NETFLIX CRITICAL
   Barni M., 2004, WATERMARKING SYSTEMS, P23, DOI [10.1201/9780203913512, DOI 10.1201/9780203913512]
   Bas P., 2016, SpringerBriefs in Electrical and Computer Engineering, P13, DOI [10.1007/978-981-10-0506-0, DOI 10.1007/978-981-10-0506-0]
   Cedillo-Hernandez A, 2016, IEICE T INF SYST, VE99D, P1541, DOI 10.1587/transinf.2015EDP7412
   Cedillo-Hernandez M, 2017, RADIOENGINEERING, V26, P536, DOI 10.13164/re.2017.0536
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Chang HA, 2007, IEEE T CIRC SYST VID, V17, P964, DOI 10.1109/TCSVT.2007.897471
   Chareyron G., 2010, Advanced Techniques in Multimedia Watermarking: Image, Video and Audio Ap-plications, P36, DOI [10.4018/978-1-61520-903-3.ch003, DOI 10.4018/978-1-61520-903-3.CH003]
   Chrysochos E, 2014, SIGNAL IMAGE VIDEO P, V8, P843, DOI 10.1007/s11760-012-0307-3
   Chuang SC, 2007, IEEE IMAGE PROC, P1389
   Cox I, 2002, DIGITAL WATERMARKING, P11
   DANGNGUYEN DT, 2015, RAISE RAW IMAGES DAT, P219
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Huang CH, 2009, IEEE T INF FOREN SEC, V4, P193, DOI 10.1109/TIFS.2009.2020778
   Huang JW, 1998, ELECTRON LETT, V34, P748, DOI 10.1049/el:19980545
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lee ML, 2016, MULTIMED TOOLS APPL, V75, P16173, DOI 10.1007/s11042-015-2925-6
   Lin PY, 2014, J SYST SOFTWARE, V95, P194, DOI 10.1016/j.jss.2014.04.038
   Lin PY, 2013, IMAGE VISION COMPUT, V31, P311, DOI 10.1016/j.imavis.2013.02.002
   Lin YH, 2012, INT CONF ACOUST SPEE, P1801, DOI 10.1109/ICASSP.2012.6288250
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Pei SC, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P140, DOI 10.1109/GCCE.2014.7031132
   Pei SC, 2015, IEEE T MULTIMEDIA, V17, P128, DOI 10.1109/TMM.2014.2368255
   Pham VQ, 2008, IEICE T INF SYST, VE91D, P2027, DOI 10.1093/ietisy/e91-d.7.2027
   Santoyo-Garcia H, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/7903198
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu PP, 2013, PROC SPIE, V8917, DOI 10.1117/12.2031136
   Yu Tian-he, 2008, Infrared Laser Engineering, V37, P951
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 40
TC 12
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26601
EP 26634
DI 10.1007/s11042-018-5881-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500018
DA 2024-07-18
ER

PT J
AU Zhang, FJ
   Lu, W
   Liu, HM
   Xue, F
AF Zhang, Fengjun
   Lu, Wei
   Liu, Hongmei
   Xue, Fei
TI Natural image deblurring based on <i>L</i>0-regularization and kernel
   shape optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind motion deblurring; L0-regularization; Alternate iteration; Kernel
   shape optimization
AB The goal of blind image deblurring is to estimate the blur kernel and restore the sharp latent image based on an input blur image. This paper proposes a novel blind image deblurring algorithm based on L0-regularization and kernel shape optimization. Firstly, the proposed objective function of the optimization model is formulated with L0-norm terms of the gradient and intensity of kernels, which results to good sparsity and less noise in the obtained kernel. Then, the coarse-to-fine iterative framework is adopted to estimate reliable salient image structures implicitly, which can reduce computation and accelerate convergence. Finally, the kernel shape is optimized by weighting method, which enables the obtained kernel closer to the ground-truth. Experimental results on public bench mark datasets demonstrate that restored images are clear with less ring-artifacts.
C1 [Zhang, Fengjun; Lu, Wei; Liu, Hongmei; Xue, Fei] Sun Yat Sen Univ, Sch Data & Comp Sci, Data & Comp Sci Guangdong Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Xue, F (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Data & Comp Sci Guangdong Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China.
EM zhangfengjun@163.com; luwei3@mail.sysu.edu.cn; isslhm@mail.sysu.edu.cn;
   xuefeicn@qq.com
FU National Natural Science Foundation of China [U1736118]; Natural Science
   Foundation of Guangdong [2016A030313350]; Special Funds for Science and
   Technology Development of Guangdong [2016KZ010103]; Key Project of
   Scientific Research Plan of Guangzhou [201804020068]; Fundamental
   Research Funds for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Hu Z, 2015, INT J COMPUT VISION, V115, P345, DOI 10.1007/s11263-015-0821-1
   Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4
   Pan JS, 2013, SIGNAL PROCESS-IMAGE, V28, P1156, DOI 10.1016/j.image.2013.05.001
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   Roth S, 2005, PROC CVPR IEEE, P860
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Simoncelli EP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P431, DOI 10.1016/B978-012119792-6/50089-9
   Sun SJ, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.3.033019
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
NR 30
TC 22
Z9 24
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26239
EP 26257
DI 10.1007/s11042-018-5847-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500004
DA 2024-07-18
ER

PT J
AU Gao, ZF
   Zhang, HY
   Wang, DF
   Guo, M
   Liu, HF
   Zhuang, L
   Shi, PC
AF Gao, Zhifan
   Zhang, Heye
   Wang, Defeng
   Guo, Min
   Liu, Huafeng
   Zhuang, Ling
   Shi, Pengcheng
TI Robust recovery of myocardial kinematics using dual H<sub>∞</sub>
   criteria
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiac motion analysis; Multiframe estimation; State space
   representation; H-infinity filter; Robust estimation
ID 3D OBJECT RETRIEVAL; TAGGED MR-IMAGES; NONRIGID MOTION; BIOMECHANICAL
   MODELS; PHASE-CONTRAST; WALL-MOTION; HUMAN-HEART; DEFORMATION; TRACKING;
   QUANTIFICATION
AB Accurate estimation of myocardial motion can help to better understand the pathophysiological processes of ischemic heart diseases. However, because of partial and noisy image-derived measurements on the cardiac kinematics, the performance of model-based motion estimation relies heavily on the assumption of noise distribution on the measurement data. While existing studies of model-based motion estimation have often adopted the criteria (e.g. least square error) based on fixed model constraints from mathematical or mechanical nature, we present a robust estimation framework with an adaptive biomechanical model constraint using dual criteria for the first time. Comparing to the minimization of average gaussian error in criteria, our criteria aims to minimize the maximum error without regarding the noise distribution. In this work, our dual estimation framework consists of two iterative filters: One filter for the kinematics estimation and another one for the elasticity estimation. At each time step, heart kinematics is estimated with sub-optimal fixed material parameters, followed by an elasticity property recovering given these sub-optimal kinematic state estimates. Such coupled estimation processes are iteratively repeated as necessary until convergence. We evaluate the performance of dual estimation framework on synthetic data, cine image sequences, and human image sequence. Our dual estimation framework shows a higher tolerance of noise than the conventional extended Kalman filter. The results obtained by both synthetic data of varying noises and magnetic resonance image sequences demonstrate the accuracy and robustness of the proposed strategy.
C1 [Gao, Zhifan; Zhang, Heye] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Wang, Defeng] Chinese Univ Hong Kong, Dept Imaging & Intervent Radiol, Hong Kong, Hong Kong, Peoples R China.
   [Guo, Min; Liu, Huafeng] Zhejiang Univ, Dept Opt Engn, Hangzhou, Zhejiang, Peoples R China.
   [Zhuang, Ling] Northwestern Lake forest Hosp, Dept Radiat Oncol, Lake Forest, IL 60045 USA.
   [Shi, Pengcheng] Rochester Inst Technol, B Thomas Golisano Coll Comp & Informat Sci, Rochester, NY 14623 USA.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese University of Hong Kong; Zhejiang University; Rochester
   Institute of Technology
RP Zhang, HY (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.; Liu, HF (corresponding author), Zhejiang Univ, Dept Opt Engn, Hangzhou, Zhejiang, Peoples R China.
EM hy.zhang@siat.ac.cn; liuhf@zju.edu.cn
RI Zhang, Heye/JPK-4651-2023; Guo, Min/HNC-3856-2023; Gao,
   Zhifan/O-9082-2019; Guo, Min/ABH-3471-2020
OI Zhang, Heye/0000-0001-7334-3037; Guo, Min/0000-0002-2093-8771; Gao,
   Zhifan/0000-0002-1576-4439; 
FU National Key Research and Development Program of China [2016YFC1300302];
   Natural Science Foundation of China [61427807, 61525106, 61771464];
   Science Technology and Innovation Committee of Shenzhen for Research
   Projects [SGLH20150213143207911, JCYJ20151030151431727]
FX This work was supported by National Key Research and Development Program
   of China (2016YFC1300302), Natural Science Foundation of China (No.
   61427807, 61525106, 61771464), and Science Technology and Innovation
   Committee of Shenzhen for Research Projects (SGLH20150213143207911,
   JCYJ20151030151431727).
CR Abd-Elmoniem KZ, 2008, MED IMAGE ANAL, V12, P778, DOI 10.1016/j.media.2008.03.008
   AXEL L, 1989, RADIOLOGY, V171, P841, DOI 10.1148/radiology.171.3.2717762
   Bathe K J, 1976, NUMERICAL METHODS FI
   Benayoun S, 1998, INT J COMPUT VISION, V26, P25, DOI 10.1023/A:1007932523504
   Britton OJ, 2013, P NATL ACAD SCI USA, V110, pE2098, DOI 10.1073/pnas.1304382110
   Burger M, 2013, SIAM J SCI COMPUT, V35, pB132, DOI 10.1137/110835955
   Cheng TM, 2008, IEEE T BIO-MED ENG, V55, P2499, DOI 10.1109/TBME.2008.2001131
   Chiang P, 2013, MAGN RESON MED, V69, P1297, DOI 10.1002/mrm.24359
   Cochet H, 2013, J NUCL MED, V54, P556, DOI 10.2967/jnumed.112.110577
   Cox MAJ, 2006, J BIOMECH ENG-T ASME, V128, P428, DOI 10.1115/1.2187040
   Declerck J, 2000, PHYS MED BIOL, V45, P1611, DOI 10.1088/0031-9155/45/6/315
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Denney T. S.  Jr., 1994, Proceedings of the IEEE Workshop on Biomedical Image Analysis (Cat. No.94TH0624-7), P51, DOI 10.1109/BIA.1994.315866
   DIDINSKY G, 1995, AUTOMATICA, V31, P1227, DOI 10.1016/0005-1098(95)00073-6
   Gao H, 2014, PHYS MED BIOL, V59, P3637, DOI 10.1088/0031-9155/59/13/3637
   Gao ZF, 2017, MED IMAGE ANAL, V37, P1, DOI 10.1016/j.media.2017.01.004
   Gilliam AD, 2009, IEEE T INF TECHNOL B, V13, P226, DOI 10.1109/TITB.2008.2009221
   Glad T., 2000, CONTROL THEORY
   Glass L., 1991, THEORY OF HEART
   Gopal S, 2013, SPIE MED IMAGING
   Halmos PR, 1978, BOUNDED INTEGRAL OPE
   Hameeteman K, 2013, PHYS MED BIOL, V58, P1605, DOI 10.1088/0031-9155/58/5/1605
   Han LH, 2012, PHYS MED BIOL, V57, P455, DOI 10.1088/0031-9155/57/2/455
   Honarvar M, 2012, PHYS MED BIOL, V57, P5909, DOI 10.1088/0031-9155/57/19/5909
   Jahanzad Z, 2015, PHYS MED BIOL, V60, P4015, DOI 10.1088/0031-9155/60/10/4015
   JANZ RF, 1974, J BIOMECH, V7, P509, DOI 10.1016/0021-9290(74)90085-2
   Kerwin WS, 1999, IEEE T SIGNAL PROCES, V47, P2942, DOI 10.1109/78.796430
   Klein GJ, 2000, IEEE T NUCL SCI, V47, P1000, DOI 10.1109/23.856538
   Liu HF, 2004, LECT NOTES COMPUT SC, V3216, P34
   Liu HF, 2012, MED PHYS, V39, P475, DOI 10.1118/1.3673066
   Liu HF, 2009, IEEE T BIO-MED ENG, V56, P378, DOI 10.1109/TBME.2008.2006012
   Marchesseau S, 2013, MED IMAGE ANAL, V17, P816, DOI 10.1016/j.media.2013.04.012
   McEachen JC, 2000, IEEE T IMAGE PROCESS, V9, P651, DOI 10.1109/83.841941
   McEachen JC, 1997, IEEE T MED IMAGING, V16, P270, DOI 10.1109/42.585761
   Metaxas DN, 2002, IEEE T PATTERN ANAL, V24, P1310, DOI 10.1109/TPAMI.2002.1039203
   Meyer C, 2014, MAGN RESON MATER PHY, V27, P211, DOI 10.1007/s10334-013-0405-4
   Meyer FG, 1996, IEEE T MED IMAGING, V15, P453, DOI 10.1109/42.511749
   Moireau P, 2008, COMPUT METHOD APPL M, V197, P659, DOI 10.1016/j.cma.2007.08.021
   Moireau P, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/3/035010
   Nash MP, 1998, THESIS
   OBrien RT, 2003, IFAC P, V36, P127
   Ozturk C, 2000, PHYS MED BIOL, V45, P1683, DOI 10.1088/0031-9155/45/6/319
   Papademetris X, 2002, IEEE T MED IMAGING, V21, P786, DOI 10.1109/TMI.2002.801163
   Pavarino E, 2013, INT J BIOMED IMAGING, V2013, P1
   PELC N J, 1991, Magnetic Resonance Quarterly, V7, P229
   Perreard IM, 2010, PHYS MED BIOL, V55, P6801, DOI 10.1088/0031-9155/55/22/013
   Sermesant A, 2006, IEEE T MED IMAGING, V25, P612, DOI 10.1109/TMI.2006.872746
   Sermesant M, 2005, LECT NOTES COMPUT SC, V3504, P325
   Shen XM, 1999, IEEE T SPEECH AUDI P, V7, P391, DOI 10.1109/89.771261
   Shi PC, 1999, INT J COMPUT VISION, V35, P87, DOI 10.1023/A:1008163112590
   Shi PC, 2003, MED IMAGE ANAL, V7, P445, DOI 10.1016/S1361-8415(03)00066-5
   Simon D., 2006, OPTIMAL STATE ESTIMA, DOI [10.1002/0470045345, DOI 10.1002/0470045345.CH11]
   Tavakoli V, 2013, COMPUT VIS IMAGE UND, V117, P966, DOI 10.1016/j.cviu.2012.11.017
   Taylor JR, CLASSICAL MECH
   Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007
   Vaccarella A, 2013, IEEE T INSTRUM MEAS, V62, P2067, DOI 10.1109/TIM.2013.2248304
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wong A, 2003, IEEE WORKSH VAR GEOM, P193
   Young AA, 2013, ANNU REV BIOMED ENG, V15, P433, DOI 10.1146/annurev-bioeng-071812-152346
   YOUNG AA, 1995, IEEE T MED IMAGING, V14, P413, DOI 10.1109/42.414605
   ZERHOUNI EA, 1988, RADIOLOGY, V169, P59, DOI 10.1148/radiology.169.1.3420283
   Zhang ZJ, 2013, LECT NOTES COMPUT SC, V7945, P474, DOI 10.1007/978-3-642-38899-6_56
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhu YD, 1999, IEEE T MED IMAGING, V18, P557, DOI 10.1109/42.790456
NR 65
TC 13
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 23043
EP 23071
DI 10.1007/s11042-017-5395-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500068
DA 2024-07-18
ER

PT J
AU Liu, YG
   Yu, JZ
   Han, YH
AF Liu, Yongge
   Yu, Jianzhuang
   Han, Yahong
TI Understanding the effective receptive field in semantic image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Effective receptive field; Dilated convolution
AB Deep convolutional neural networks trained with strong pixel-level supervision have recently significantly boosted the performance in semantic image segmentation. The receptive field is a crucial issue in such visual tasks, as the output must capture enough information about large objects to make a better decision. In DCNNs, the theoretical receptive field size could be very large, but the effective receptive field may be quite small. The latter is an really important factor in performance. In this work, we defined a method of measuring effective receptive field. We observed that stacking layers with large receptive field can increase the size of receptive field and increase the density of receptive field. Based on the observation, we designed a Dense Global Context Module, which makes the effective receptive field coverage larger and density higher. With the Dense Global Context Module, segmentation model reduces a large number of parameters while the performance has been substantially improved. Massive experiments proved that our Dense Global Context Module exhibits very excellent performance on the PASCAL VOC2012 and PASCAL CONTEXT data set.
C1 [Liu, Yongge] Anyang Normal Univ, Sch Comp & Informat Engn, Anyang, Peoples R China.
   [Yu, Jianzhuang; Han, Yahong] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Liu, Yongge] Anyang Normal Univ, Henan Key Lab Oracle Bone Inscript Informat Proc, Anyang, Peoples R China.
   [Liu, Yongge] Collaborat Innovat Ctr Int Disseminat Chinese Lan, Zhengzhou, Henan, Peoples R China.
C3 Anyang Normal University; Tianjin University; Anyang Normal University
RP Han, YH (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
EM liuyongge@aynu.edu.cn; jzyu@tju.edu.cn; yahong@tju.edu.cn
FU Major Projects by the National Social Science Fund of China [16ZH017A3];
   Program for Changjiang Scholars and Innovative Research Team in
   University (PCSIRT); NSFC [U1509206, 61472276]
FX Prof. Liu is supported by the Major Projects entrusted by the National
   Social Science Fund of China (Under Grant 16ZH017A3) and Program for
   Changjiang Scholars and Innovative Research Team in University (PCSIRT)
   granted by Ministry of Education, China. Dr. Han is supported by the
   NSFC (Under Grant U1509206,61472276)
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   [Anonymous], 2016, ARXIV161108323
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Baehrens D, 2010, J MACH LEARN RES, V11, P1803
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Ghiasi G., 2016, CORR
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin G., 2016, RefineNet: Multi-path refinement networks for high-resolution semantic segmentation
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J.L., 2014, Advances in neural information processing systems, V27, P1601
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo WJ, 2016, ADV NEUR IN, V29
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oquab M., 2015, PROC CVPR IEEE, P685
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14
   Simonyan K., 2013, arXiv preprint arXiv:1312.6034
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Yu F., 2015, ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B., 2014, CORR, V1412, P6856
NR 38
TC 40
Z9 48
U1 4
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22159
EP 22171
DI 10.1007/s11042-018-5704-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500022
DA 2024-07-18
ER

PT J
AU Tan, M
   Yu, J
   Huang, QM
   Wu, WC
AF Tan, Min
   Yu, Jun
   Huang, Qingming
   Wu, Weichen
TI Click data guided query modeling with click propagation and sparse
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recognition; Click data; Sparse coding; Query modeling; Graph
   based model
ID FEATURES
AB We address the problem of fine-grained image recognition using user click data, wherein each image is represented as a semantical query-click feature vector. Usually, the query set obtained from search engines is large-scale and redundant, making the click feature be high-dimensional and sparse. We propose a novel query modeling approach to merge semantically similar queries, and construct a compact click feature with the merged queries. To deal with the sparsity and in-consistency in click feature, we design a graph based propagation approach to predict the zero-clicks, ensuring similar images have similar clicks for each query. Afterwards, using the propagated click feature, we formulate the query merging problem as a sparse coding based recognition task. In addition, the hot queries are utilized to construct the dictionary. We evaluate our method for fine-grained image recognition on the public Clickture-Dog dataset. It is shown that, the propagated click feature performs much better than the original one. In the query merging procedure, sparse coding performs better than traditional K-mean algorithm. Also, the "hot queries" outperform K-SVD in dictionary learning.
C1 [Tan, Min; Yu, Jun; Wu, Weichen] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China.
C3 Hangzhou Dianzi University; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Yu, J (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
EM tanmin@hdu.edu.cn; yujun@hdu.edu.cn; qmhuang@ucas.ac.cn; jxwwc@qq.com
FU National Natural Science Foundation of China [61602136, 61622205,
   61472110]; Zhejiang Provincial Natural Science Foundation of China
   [LR15F020002]
FX This work was partly supported by National Natural Science Foundation of
   China (No. 61602136, No.61622205, No. 61472110), and Zhejiang Provincial
   Natural Science Foundation of China under Grant LR15F020002.
CR [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Chang YJ., 2018, Mater. Chem. Phys, V210, P111, DOI [DOI 10.1016/J.MATCHEMPHYS.2017.09.057, 10.1016/j.matchemphys.2017.09.057]
   Chun IY, 2016, IEEE INT CONF MULTI
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Datta D, 2017, MULTIMED TOOLS APPL, V76, P1
   Feng L., 2016, IEEE T PATTERN ANAL, V38, P1
   Hua X.-S., 2013, Proceedings of the 21st ACM International Conference on Multimedia, Oct. 21-25, ACM, P243
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Nie L, 2011, ACM SIGIR C RES DEV, P605
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan M, 2012, INTELLIGENT SCI INTE
   Tan M, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P118, DOI 10.1145/3007669.3007730
   Tan M, 2016, IEEE T INTELL TRANSP, V17, P1415, DOI 10.1109/TITS.2015.2506182
   Tan M, 2016, NEUROCOMPUTING, V181, P96, DOI 10.1016/j.neucom.2015.04.123
   Tan M, 2014, NEUROCOMPUTING, V139, P56, DOI 10.1016/j.neucom.2013.09.054
   Tsung-Yu Lin AR, 2015, IEEE INT C COMP VIS
   Wang R., 2017, IEEE T NEURAL NETWOR, V99, P1
   Yan CX, 2018, MULTIMED TOOLS APPL, V77, P3553, DOI 10.1007/s11042-017-5202-z
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang J., 2016, P ACM INT C MULT, P1415
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
   Zheng G, 2017, IEEE INT C MULT EXP
NR 33
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22145
EP 22158
DI 10.1007/s11042-018-5703-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500021
DA 2024-07-18
ER

PT J
AU Becker, S
   Hübner, W
   Arens, M
AF Becker, Stefan
   Hubner, Wolfgang
   Arens, Michael
TI State estimation for tracking in image space with a de- and re-coupled
   IMM filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interacting multiple models; Filtering; Visual tracking; Object
   tracking; Bayes filter
ID TARGET TRACKING; MULTIPLE
AB Estimating the motion state of objects is a central component of most visual tracking pipelines. Visual tracking relies on observations in scale space generated by an appearance model. Under real-life conditions, it is obvious to assume that the dynamic of a tracked object changes over time. A popular solution for considering such varying system characteristics is the Interacting Multiple Model (IMM) filter. Usually, the motion of objects is modeled using position, velocity, and acceleration. Although it seems obvious that different image space dimensions can be combined in one overall system state, this naive approach may fail under various circumstances. Toward this end, we demonstrate the benefit of decoupling the state estimate of an IMM filter in case of relying solely on the output of a visual tracker. Further, a state re-coupling scheme is introduced which helps to better deal with the corresponding measurement uncertainties of such a tracking pipeline. The proposed decoupled and re-coupled IMM filters are evaluated on publicly available datasets.
C1 [Becker, Stefan; Hubner, Wolfgang; Arens, Michael] Fraunhofer IOSB, Gutleuthausstr 1, D-76275 Ettlingen, Germany.
C3 Fraunhofer Gesellschaft; Fraunhofer Optronics, System Technologies &
   Image Exploitation Ettlingen
RP Becker, S (corresponding author), Fraunhofer IOSB, Gutleuthausstr 1, D-76275 Ettlingen, Germany.
EM stefan.becker@iosb.fraunhofer.de; wolfgang.huebner@iosb.fraunhofer.de;
   michael.arens@iosb.fraunhofer.de
RI Becker, Stefan/AAH-9794-2020; Hübner, Wolfgang/ADH-2549-2022
OI Becker, Stefan/0000-0001-7367-2519; Hübner, Wolfgang/0000-0001-5634-6324
CR [Anonymous], 2008, BIOMED ENG
   [Anonymous], P AIAA GUID NAV CONT
   [Anonymous], 2008, THESIS
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bar-Shalom Y, 2001, ESTIMATION APPL TRAC
   Becker S, 2016, LECT NOTES COMPUT SC, V9680, P3, DOI 10.1007/978-3-319-33618-3_1
   Blackman S., 1999, Design and analysis of modern tracking systems
   BLOM HAP, 1988, IEEE T AUTOMAT CONTR, V33, P780, DOI 10.1109/9.1299
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Cehovin L, 2014, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2014.6836055
   Cooper D.C., 1987, ELECT POWER, V33, P407
   Cordts M, 2015, CVPR WORKSH FUT DAT
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kieritz H, 2016, C ADV VID SIGN BAS S
   LEAL-TAIXE L, 2017, ARXIV170402781CS
   Li XR, 2005, IEEE T AERO ELEC SYS, V41, P1255, DOI 10.1109/TAES.2005.1561886
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mazor E, 1998, IEEE T AERO ELEC SYS, V34, P103, DOI 10.1109/7.640267
   Milan A, 2017, AAAI C ART INT
   Milan A., 2016, ARXIV160300831
   Ondrúska P, 2016, AAAI CONF ARTIF INTE, P3361
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Spinello D, 2010, IEEE T AUTOMAT CONTR, V55, P1358, DOI 10.1109/TAC.2010.2042006
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   VOT, 2014, VIS OBJ TRACK CHALL
   Wang H, 1999, IEEE T AERO ELEC SYS, V35, P255, DOI 10.1109/7.745696
   Yeddanapudi M, 1997, P IEEE, V85, P80, DOI 10.1109/5.554210
NR 29
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20207
EP 20226
DI 10.1007/s11042-017-5324-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500058
DA 2024-07-18
ER

PT J
AU Harakawa, R
   Ogawa, T
   Haseyama, M
AF Harakawa, Ryosuke
   Ogawa, Takahiro
   Haseyama, Miki
TI Tracking topic evolution via salient keyword matching with consideration
   of semantic broadness for Web video discovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web video; Video retrieval; Topic evolution; Tracking algorithm; Network
   analysis
ID HIERARCHICAL STRUCTURE; EVENT DETECTION; RETRIEVAL; DATABASE
AB A method to track topic evolution via salient keyword matching with consideration of semantic broadness for Web video discovery is presented in this paper. The proposed method enables users to understand the evolution of topics over time for discovering Web videos in which they are interested. A framework that enables extraction and tracking of the hierarchical structure, which contains Web video groups with various degrees of semantic broadness, is newly derived as follows: Based on network analysis using multimodal features, i.e., features of video contents and metadata, our method extracts the hierarchical structure and salient keywords that represent contents of each Web video group. Moreover, salient keyword matching, which is newly developed by considering salient keyword distribution, semantic broadness of each Web video group and initial topic relevance, is applied to each hierarchical structure obtained in different time stamps. Unlike methods in previous works, by considering the semantic broadness as well as the salient keyword distribution, our method can overcome the problem of the desired semantic broadness of topics being different depending on each user. Also, the initial topic relevance enables correction of the gap from an initial topic at the start of tracking. Consequently, it becomes feasible to track the evolution of topics over time for finding Web videos in which the users are interested. Experimental results for real-world datasets containing YouTube videos verify the effectiveness of the proposed method.
C1 [Harakawa, Ryosuke; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Hokkaido University
RP Harakawa, R (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
EM harakawa@lmd.ist.hokudai.ac.jp; ogawa@lmd.ist.hokudai.ac.jp;
   miki@ist.hokudai.ac.jp
RI Haseyama, Miki/A-6163-2012
OI Ogawa, Takahiro/0000-0001-5332-8112
FU JSPS KAKENHI [JP16J02042, JP17H01744]; Grants-in-Aid for Scientific
   Research [16J02042] Funding Source: KAKEN
FX This work was partly supported by JSPS KAKENHI Grant Numbers JP16J02042
   and JP17H01744.
CR [Anonymous], 2012, P 27 ANN ACM S APPL
   [Anonymous], 1991, P VDB
   [Anonymous], 2009, MCG WEBV BENCHMARK D
   [Anonymous], 2015, P 6 ACM MULTIMEDIA S
   [Anonymous], BIOCH J
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Botafogo R. A., 1991, Third ACM Conference on Hypertext Proceedings, P63, DOI 10.1145/122974.122981
   Cao J, 2016, MULTIMED TOOLS APPL, V75, P1543, DOI 10.1007/s11042-014-2245-2
   Cao J, 2016, NEUROCOMPUTING, V172, P53, DOI 10.1016/j.neucom.2014.10.103
   Cao J, 2011, IEEE T CIRC SYST VID, V21, P1835, DOI 10.1109/TCSVT.2011.2148470
   Chen T., 2012, P 20 ACM INT C MULT, P781
   Chen XJ, 2016, MULTIMED TOOLS APPL, V75, P15079, DOI 10.1007/s11042-015-2514-8
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Fang Q, 2016, IEEE T MULTIMEDIA, V18, P702, DOI 10.1109/TMM.2016.2527602
   Feng BL, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P721
   Gantz J., 2012, The Digital Universe in 2020: Big Data, Bigger Digital Shadows, and Biggest Growth in the Far East, V2012, P1
   Gargi U., 2011, PROC 5 INT C WEBLOGS, P486
   Geetha P., 2008, Journal of Computer Sciences, V4, P474, DOI 10.3844/jcssp.2008.474.486
   Hanjalic A, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490827
   Harakawa R, 2017, IEEE ACCESS, V5, P16963, DOI 10.1109/ACCESS.2017.2741098
   Harakawa R, 2016, IEEE GLOB CONF SIG, P1238, DOI 10.1109/GlobalSIP.2016.7906039
   Harakawa R, 2016, MULTIMED TOOLS APPL, V75, P17059, DOI 10.1007/s11042-015-2976-8
   Harakawa R, 2015, IEEE IMAGE PROC, P1021, DOI 10.1109/ICIP.2015.7350954
   Haseyama M, 2013, ITE TRANS MEDIA TECH, V1, P2, DOI 10.3169/mta.1.2
   Hatakeyama Y, 2009, IEICE T FUND ELECTR, VE92A, P1961, DOI 10.1587/transfun.E92.A.1961
   Hindle A, 2011, WORLD WIDE WEB, V14, P53, DOI 10.1007/s11280-010-0097-x
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huang J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P602, DOI 10.1109/ICCV.1998.710779
   Jhuo IH, 2014, INT C PATT RECOG, P666, DOI 10.1109/ICPR.2014.125
   Jiang L, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P311, DOI 10.1145/2872518.2888599
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Kofler C, 2014, IEEE T MULTIMEDIA, V16, P1421, DOI 10.1109/TMM.2014.2315777
   Le Quoc V., 2014, P INT C MACH LEARN I
   Li GR, 2016, MULTIMEDIA SYST, V22, P115, DOI 10.1007/s00530-014-0402-0
   Liu L., 2008, P 17 INT C WORLD WID, P1009
   Lu Z, 2017, MULTIMED TOOLS APPL, V76, P10855, DOI 10.1007/s11042-016-3877-1
   Ma ZG, 2013, PROC CVPR IEEE, P2627, DOI 10.1109/CVPR.2013.339
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mazloom M., 2013, Proceedings of the ACM Multimedia Conference, MM'13, P609
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814
   Ngo C.W., 2001, Proc. ACM Multimedia, P51, DOI DOI 10.1145/500141.500151
   Ngo CW, 2002, IEEE T MULTIMEDIA, V4, P446, DOI 10.1109/TMM.2002.802022
   Reed C, 2011, P INT WORKSH MULT DA
   Sang JT, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037687
   Shao J., 2010, P INT C MULT, P915
   Shao J, 2012, PATTERN RECOGN LETT, V33, P410, DOI 10.1016/j.patrec.2011.07.026
   Taskiran C, 2004, IEEE T MULTIMEDIA, V6, P103, DOI 10.1109/TMM.2003.819783
   Turner V, 2014, IDC IVIEW
   van der Vaart A.W., 1998, ASYMPTOTIC STAT, DOI 10.1017/CBO9780511802256
   Wu J, 2012, IEEE T MULTIMEDIA, V14, P291, DOI 10.1109/TMM.2011.2174969
   Xie L, 2011, P 19 ACM INT C MULT, P53, DOI DOI 10.1145/2072298.2072307
   Zhang XM, 2012, WORLD WIDE WEB, V15, P233, DOI 10.1007/s11280-011-0132-6
NR 56
TC 3
Z9 3
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20297
EP 20324
DI 10.1007/s11042-017-5404-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300002
DA 2024-07-18
ER

PT J
AU Liu, LT
   Lu, YL
   Yan, XH
   Wang, HX
AF Liu, Lintao
   Lu, Yuliang
   Yan, Xuehu
   Wang, Huaixi
TI Greyscale-images-oriented progressive secret sharing based on the linear
   congruence equation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Progressive secret sharing; Greyscale image; Linear
   congruence; Simple computations
ID THRESHOLD VISUAL CRYPTOGRAPHY; STEGANOGRAPHY; IMPROVEMENTS; SCHEMES
AB Secret image sharing (SIS) can be applied to protect a secret image when the secret is transmitted in public channels. However, classic SIS schemes, e.g., visual secret sharing (VSS) and Shamir's polynomial-based scheme, are not suitable for progressive encryption of greyscale images, because they will lead to many problems, such as "All-orNothing", lossy recovery, complex computations and so on. Based on the linear congruence equation, three novel progressive secret sharing (PSS) schemes are proposed to overcome these problems: (k, k) threshold LCSS and (k, n) threshold LCPSS aim to achieve general threshold progressive secret sharing with simple computations. Furthermore, extended LCPSS (ELCPSS) is developed to generate meaningful shadow images, which enable simple management and misleading the enemy. Both theoretical proofs and experimental results are given to demonstrate the validity of the proposed scheme.
C1 [Liu, Lintao; Lu, Yuliang; Yan, Xuehu; Wang, Huaixi] Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
C3 National University of Defense Technology - China
RP Liu, LT; Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
EM liuta1989@163.com; publictiger@126.com
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720; Lu,
   Yuliang/0000-0002-8502-9907
FU National Natural Science Foundation of China [61602491]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Number: 61602491).
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen SK, 2009, OPT ENG, V48, DOI 10.1117/1.3262345
   Chen SK, 2005, PATTERN RECOGN, V38, P2466, DOI 10.1016/j.patcog.2005.04.002
   Cheng TF, 2017, MULTIMED TOOLS APPL, V76, P9337, DOI 10.1007/s11042-016-3535-7
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   Fang WP, 2014, NON EXPANDING FRIEND, P155
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Huang CP, 2010, J SYST SOFTWARE, V83, P517, DOI 10.1016/j.jss.2009.10.012
   Kumar S., 2013, INT J COMPUTER APPL, V83, P1, DOI [10.5120/14457-2741, DOI 10.5120/14457-2741]
   Lee SS, 2002, ETRI J, V24, P373, DOI 10.4218/etrij.02.0102.0505
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Tuyls P, 2004, LECT NOTES COMPUT SC, V2802, P271
   Viet DQ, 2004, LECT NOTES COMPUT SC, V2964, P353
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Xuehu Yan, 2018, Journal of Real-Time Image Processing, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan X, 2014, LNCS, V9, P68, DOI DOI 10.1007/978-3-642-55046-1
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yang B, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P471
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
NR 39
TC 11
Z9 12
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20569
EP 20596
DI 10.1007/s11042-017-5435-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300012
DA 2024-07-18
ER

PT J
AU Nguyen, XS
   Mouaddib, AI
   Nguyen, TP
   Jeanpierre, L
AF Nguyen, Xuan Son
   Mouaddib, Abdel-Illah
   Thanh Phuong Nguyen
   Jeanpierre, Laurent
TI Action recognition in depth videos using hierarchical gaussian
   descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Covariance descriptor; Gaussian descriptor;
   Riemannian manifold; Lie group; Symmetric positive definite matrices;
   Comparative space transform
ID LOCAL BINARY PATTERNS; OBJECT AFFORDANCES; CLASSIFICATION; TEXTURE;
   FUSION; SPACE
AB In this paper, we propose a new approach based on distribution descriptors for action recognition in depth videos. Our local features are computed from binary patterns which incorporate the shape and motion cues for effective action recognition. Given pixel-level features, our approach estimates video local statistics in a hierarchical manner, where the distribution of pixel-level features and that of frame-level descriptors are modeled using single Gaussians. In this way, our approach constructs video descriptors directly from low-level features without resorting to codebook learning required by Bag-of-features (BoF) based approaches. In order to capture the spatial geometry and temporal order of a video, we use a spatio-temporal pyramid representation for each video. Our approach is validated on six benchmark datasets, i.e. MSRAction3D, MSRGesture3D, DHA, SKIG, UTD-MHAD and CAD-120. The experimental results show that our approach gives good performance on all the datasets. In particular, it achieves state-of-the-art accuracies on DHA, SKIG and UTD-MHAD datasets.
C1 [Nguyen, Xuan Son; Mouaddib, Abdel-Illah; Jeanpierre, Laurent] Univ Caen Basse Normandie, CNRS, GREYC, UMR 6072, F-14000 Caen, France.
   [Thanh Phuong Nguyen] Aix Marseille Univ, CNRS, ENSAM, LSIS,UMR 7296, F-13397 Marseille, France.
   [Thanh Phuong Nguyen] Univ Toulon & Var, CNRS, LSIS, UMR 7296, F-83957 La Garde, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de Caen
   Normandie; Centre National de la Recherche Scientifique (CNRS);
   Aix-Marseille Universite; Arts et Metiers Institute of Technology;
   Universite de Toulon; Centre National de la Recherche Scientifique
   (CNRS); Aix-Marseille Universite
RP Nguyen, XS (corresponding author), Univ Caen Basse Normandie, CNRS, GREYC, UMR 6072, F-14000 Caen, France.
EM xuan-son.nguyen@unicaen.fr; abdel-illah.mouaddib@unicaen.fr;
   thanh-phuong.nguyen@univ-tln.fr; laurent.jeanpierre@unicaen.fr
RI Nguyen, Thanh Phuong/AAA-2769-2019
OI Nguyen, Thanh Phuong/0000-0002-5646-8505; Jeanpierre,
   Laurent/0000-0002-2082-5451
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Altun K, 2010, LECT NOTES COMPUT SC, V6219, P38, DOI 10.1007/978-3-642-14715-9_5
   Chaaraoui AA, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P91, DOI 10.1109/ICCVW.2013.19
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Bilinski P, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2140
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cavazza J, 2016, INT C PATT RECOG, P408, DOI 10.1109/ICPR.2016.7899668
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen C, 2014, IEEE ENG MED BIO, P4983, DOI 10.1109/EMBC.2014.6944743
   Cirujeda Pol, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P657, DOI 10.1109/3DV.2014.10
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622
   Huang Z., 2017, CVPR
   Hussein, 2013, INT JOINT C ART INT
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Lee I, 2017, CVPR
   Li PH, 2017, IEEE T PATTERN ANAL, V39, P803, DOI 10.1109/TPAMI.2016.2560816
   Li PH, 2012, LECT NOTES COMPUT SC, V7574, P469, DOI 10.1007/978-3-642-33712-3_34
   Li Q, 2009, SIXTH INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P138, DOI [10.1109/P3644.45, 10.1109/BSN.2009.46]
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu C., 2017, Pku-mmd: A large scale benchmark for continuous multi-modal human action understanding
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Liu L., 2013, 23 INT JOINT C ART I
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu MY, 2018, IEEE T CIRC SYST VID, V28, P1824, DOI 10.1109/TCSVT.2017.2655521
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Lovric M, 2000, J MULTIVARIATE ANAL, V74, P36, DOI 10.1006/jmva.1999.1853
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mici L, 2017, ARXIV171001916
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H., 2017, ICCV
   Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167
   Rezazadegan F, 2017, ARXIV170104925
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi Z., 2017, CVPR
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519
   Wang P, 2017, ICCV WORKSHOP
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang QL, 2016, PATTERN RECOGN, V59, P63, DOI 10.1016/j.patcog.2016.03.004
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yi Y, 2018, VISUAL COMPUT, V34, P391, DOI 10.1007/s00371-016-1345-6
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925
   Yuan CF, 2010, LECT NOTES COMPUT SC, V5994, P343
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 86
TC 9
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21617
EP 21652
DI 10.1007/s11042-017-5593-x
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300057
DA 2024-07-18
ER

PT J
AU Ponuma, R
   Amutha, R
AF Ponuma, R.
   Amutha, R.
TI Compressive sensing based image compression-encryption using Novel
   1D-Chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ChaoticMap; Compressed Sensing; Compression; Encryption; Security
ID CHAOTIC SYSTEM; MEASUREMENT MATRIX
AB Compressive sensing based encryption achieves simultaneous compression-encryption by utilizing a low complex sampling process, which is computationally secure. In this paper, a new novel 1D-chaotic map is proposed that is used to construct an incoherence rotated chaotic measurement matrix. The chaotic property of the proposed map is experimentally analysed. The linear measurements obtained are confused and diffused using the chaotic sequence generated using the proposed map. The chaos based measurement matrix construction results in reduced data storage and bandwidth requirements. As it needs to store only the parameters required to generate the chaotic sequence. Also, the sensitivity of the chaos to the parameters makes the data transmission secure. The secret key used in the encryption process is dependent on both the input data and the parameter used to generate the chaotic map. Hence the proposed scheme can resist chosen plaintext attack. The key space of the proposed scheme is large enough to thwart statistical attacks. Experimental results and the security analysis verifies the security and effectiveness of the proposed compression-encryption scheme.
C1 [Ponuma, R.; Amutha, R.] SSN Coll Engn, Dept Elect & Commun Engineeting, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Ponuma, R (corresponding author), SSN Coll Engn, Dept Elect & Commun Engineeting, Chennai, Tamil Nadu, India.
EM ponumar@ssn.edu.in
RI Amutha, R./AAB-9399-2020
CR [Anonymous], M ASS COMP LING
   [Anonymous], MULTIMED TOOLS APPL
   Bandeira AS, 2013, IEEE T INFORM THEORY, V59, P3448, DOI 10.1109/TIT.2013.2248414
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cambareri V, 2015, IEEE T INF FOREN SEC, V10, P2182, DOI 10.1109/TIFS.2015.2450676
   Cambareri V, 2015, IEEE T SIGNAL PROCES, V63, P2183, DOI 10.1109/TSP.2015.2407315
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Deepak M, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P360, DOI 10.1109/CNSC.2014.6906665
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fay R, 2016, INFORM PROCESS LETT, V116, P279, DOI 10.1016/j.ipl.2015.11.010
   Gordon W.B., 1996, MATH MAG, V69, P118
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Jiang J, 2015, OPTIK, V126, P882, DOI 10.1016/j.ijleo.2015.02.053
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu ET, 2012, IEEE T INFORM THEORY, V58, P2040, DOI 10.1109/TIT.2011.2177632
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1
   Phamila AVY, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0411
   Phamila YAV, 2013, INFORM PROCESS LETT, V113, P672, DOI 10.1016/j.ipl.2013.06.008
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Rong Huang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P105, DOI 10.1109/IIHMSP.2011.53
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Yao SH, 2017, MULTIMED TOOLS APPL, V76, P17699, DOI 10.1007/s11042-015-2953-2
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Yuan XL, 2016, IEEE T MULTIMEDIA, V18, P2002, DOI 10.1109/TMM.2016.2602758
   Yuen CH, 2011, APPL SOFT COMPUT, V11, P5092, DOI 10.1016/j.asoc.2011.05.050
   Zhang LY, 2016, IEEE T MULTIMEDIA, V18, P1720, DOI 10.1109/TMM.2016.2581593
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 48
TC 83
Z9 86
U1 2
U2 88
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19209
EP 19234
DI 10.1007/s11042-017-5378-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500015
DA 2024-07-18
ER

PT J
AU Mansourian, L
   Abdullah, MT
   Abdullah, LN
   Azman, A
   Mustaffa, MR
AF Mansourian, Leila
   Abdullah, Muhamad Taufik
   Abdullah, Lili Nurliyana
   Azman, Azreen
   Mustaffa, Mas Rina
TI An effective fusion model for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency map; PHOW MSDSIFT feature; Bag of visual words model (BoVW);
   Dominant color description (DCD); Image retrieval; Pyramidal histogram
   of visual words (PHOW)
ID SALIENT OBJECT DETECTION; ANNOTATION; FEATURES
AB In the past decade, the popular Bag of Visual Words approach has been applied to many computer vision tasks, including image classification, video search, robot localization, and texture recognition. Unfortunately, most approaches use intensity features and discard color information, an important characteristic of any image that is motivated by human vision. Besides, if background colors are higher than foreground ones, Dominant Color Descriptor (DCD) retrieves images that contain similar background colors correctly. On the other hand, just color feature extraction is not sufficient for similar objects with different color descriptors (e.g. white dog vs. black dog). To solve these problems, a new Salient DCD (SDCD) color descriptor is proposed to extract foreground color and add semantic information into DCD based on the color distances and salient object extraction methods. Besides, a new fusion model is presented to fuse SDCD histogram and PHOW MSDSIFT histogram. Performance evaluation on several datasets proves that the new approach outperforms other existing, state-of-the-art methods.
C1 [Mansourian, Leila; Abdullah, Muhamad Taufik; Abdullah, Lili Nurliyana; Azman, Azreen; Mustaffa, Mas Rina] Univ Putra Malaysia UPM, Fac Comp Sci & Informat Technol, Dept Multimedia, Serdang 43400, Selangor Darul, Malaysia.
C3 Universiti Putra Malaysia
RP Mansourian, L (corresponding author), Univ Putra Malaysia UPM, Fac Comp Sci & Informat Technol, Dept Multimedia, Serdang 43400, Selangor Darul, Malaysia.
EM l_mansourian@yahoo.com; mta@upm.edu.my; liyana@upm.edu.my;
   azreenazman@upm.edu.my; masrina@upm.edu.my
RI Abdullah, Lili Nurliyana/AAC-6423-2020; MUSTAFFA, MAS RINA/B-1763-2017
OI Abdullah, Lili Nurliyana/0000-0001-8704-2390; Abdullah, Muhamad
   Taufik/0000-0001-5124-8098; Mansourian, Leila/0000-0001-6949-7156;
   MUSTAFFA, MAS RINA/0000-0001-5088-2871
FU Malaysian Ministry of Higher Education under the Fundamental Research
   Grant Scheme (FRGS)
FX This article was kindly supported by the Malaysian Ministry of Higher
   Education under the Fundamental Research Grant Scheme (FRGS).
CR [Anonymous], INT J COMPUT SCI ISS
   [Anonymous], WEAKLY SUPERVISED LE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2014, INT J CONTROL AUTOM
   [Anonymous], SIVIP
   [Anonymous], 2001, JTC1SC29WG11N391 ISO
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], FUSING COLOR SHAPE B
   [Anonymous], COGSCI ANN M COGNITI
   [Anonymous], P 9 EUR C COMP VIS 1
   [Anonymous], LOCAL LEARNING IMPRO
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], J COMPUTER SCI, DOI DOI 10.3844/JCSSP.2023.20.56
   [Anonymous], 3 INT C IM GRAPH ICI
   [Anonymous], WHAT IS SALIENT OBJE
   [Anonymous], 2006, OBJECT DETECTION LOC
   [Anonymous], FAST METHOD DOMINANT
   [Anonymous], SVM KNN DISCRIMINATI
   [Anonymous], LOCALITY CONSTRAINED
   [Anonymous], LOCAL FEATURES OBJEC
   [Anonymous], SALIENT OBJECT DETEC
   [Anonymous], CALTECH 256 OBJECT C
   [Anonymous], RES J APPL SCI ENG T
   [Anonymous], 2011, Proceedings of the British Machine Vision Conference
   Bannour H, 2014, MULTIMED TOOLS APPL, V72, P2107, DOI 10.1007/s11042-013-1491-z
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chen JZ, 2015, PATTERN ANAL APPL, V18, P441, DOI 10.1007/s10044-014-0427-1
   Chiang CC, 2013, COMPUT STAND INTER, V35, P50, DOI 10.1016/j.csi.2012.05.002
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng Y., 1999, P IEEE INT S CIRC SY, V4, P21, DOI DOI 10.1109/ISCAS.1999.779933
   Dey V, 2010, INT ARCH PHOTOGRAMM, V38, P31
   Fakhari A, 2013, APPL SOFT COMPUT, V13, P1292, DOI 10.1016/j.asoc.2012.10.019
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Islam Md Monirul, 2008, 2008 Digital Image Computing: Techniques and Applications, P191, DOI 10.1109/DICTA.2008.17
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim J, 2011, PROC CVPR IEEE, P1553, DOI 10.1109/CVPR.2011.5995526
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Lampert C.H., 2008, 2008 IEEE C COMPUTER, P1
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee CH, 2011, EXPERT SYST APPL, V38, P13792, DOI 10.1016/j.eswa.2011.04.182
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Mansourian L, 2016, KSII T INTERNET INF, V10, P769, DOI 10.3837/tiis.2016.02.018
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   O'Hara S, 2011, INT J SEMANT WEB INF, V7, P1, DOI 10.4018/jswis.2011010101
   Rassem T. H., 2011, 2011 Proceedings of IEEE International Conference on Imaging Systems and Techniques (IST 2011), P290, DOI 10.1109/IST.2011.5962197
   Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vigo David A. Rojas, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1549, DOI 10.1109/ICPR.2010.383
   Wang H., 2013, INT C MACHINE LEARNI, P352
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhang DS, 2013, J VIS COMMUN IMAGE R, V24, P1087, DOI 10.1016/j.jvcir.2013.07.004
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 66
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16131
EP 16154
DI 10.1007/s11042-017-5192-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300007
DA 2024-07-18
ER

PT J
AU Babahenini, D
   Gruson, A
   Babahenini, MC
   Bouatouch, K
AF Babahenini, Djihane
   Gruson, Adrien
   Babahenini, Mohamed Chaouki
   Bouatouch, Kadi
TI Efficient inverse transform methods for VPL selection in global
   illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visibility; Indirect lighting; Voxelization; Inverse transform methods;
   Virtual point light
ID SHADOW MAPS
AB In computer graphics, designing efficient Global Illumination methods is a hot research topic. These methods consist in computing the light distribution inside a 3D scene. There exist several global illumination-based rendering methods, but one popular approach is based on Virtual Point Light (VPL). It is a two-step approach. First, the algorithm generates VPLs that act as secondary light sources (indirect illumination). Second, the radiance of a pixel is computed by summing the contributions of a small set of VPLs (rather than all the VPLs) selected randomly. The most active issues rely on how to select a small set of VPLs that contribute more to the final image. In this paper, we propose two new VPL selection methods using the inverse transform method. To provide realistic images, we propose a Multiple Importance Sampling technique combining an inverse transform method with a gathering approach. The obtained results demonstrate the effectiveness of our methods in terms of image quality and rendering time.
C1 [Babahenini, Djihane; Babahenini, Mohamed Chaouki] Univ Mohamed Khider, Dept Comp Sci, LESIA, BP 145, Biskra 07000, Algeria.
   [Gruson, Adrien] Univ Tokyo, Dept Creat Informat, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
   [Bouatouch, Kadi] Univ Rennes 1, IRISA, F-35000 Rennes, France.
C3 Universite Mohamed Khider Biskra; University of Tokyo; Universite de
   Rennes
RP Babahenini, D (corresponding author), Univ Mohamed Khider, Dept Comp Sci, LESIA, BP 145, Biskra 07000, Algeria.
EM babaheninidjihene@gmail.com; adrien.gruson@gmail.com;
   chaouki.babahenini@gmail.com; kadi.bouatouch@irisa.fr
RI BABAHENINI, Mohamed Chaouki/F-1427-2017; Gruson, Adrien/AAB-6971-2021
OI BABAHENINI, Mohamed Chaouki/0000-0001-7972-8026; 
CR Agarwal S, 2003, ACM T GRAPHIC, V22, P605, DOI 10.1145/882262.882314
   [Anonymous], 2009, VIS MOD VIS WORKSH
   [Anonymous], 1997, ROBUST MONTE CARLO M
   [Anonymous], P SIGGRAPH AS 2015 P
   [Anonymous], 1978, P 5 ANN C COMPUTER G, P270
   Arvo J., 1990, SIGGRAPH, V24, P63, DOI DOI 10.1145/97880.97886
   Barák T, 2013, COMPUT GRAPH FORUM, V32, P87, DOI 10.1111/cgf.12154
   Brabec S, 2002, SHADOW MAPPING HEMIS
   Crassin C., 2009, P 2009 S INT 3D GRAP, P15, DOI [10.1145/1507149.1507152, DOI 10.1145/1507149.1507152]
   Crassin C, 2012, OPENGL INSIGHTS, P303
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   Dammertz H, 2010, COMPUT GRAPH FORUM, V29, P2504, DOI 10.1111/J.1467-8659.2010.01786.X
   Dutre P, 2003, COMPUTER GRAPHICS, P6
   Gascuel JD, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P107
   Georgiev I, 2010, P EUROGRAPHICS, V4
   Gilks W., 2005, Markov Chain Monte Carlo
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   Hasan M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618489
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Hedman P, 2016, SEQUENTIAL MONTE CAR
   Heidrich W., 1998, P ACM SIGGRAPH EUROG, P39
   Hu W, 2014, VISUAL COMPUT, V30, P697, DOI 10.1007/s00371-014-0968-8
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   Lafortune EP, 1993, BI DIRECTIONAL PATH
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   McGuire M., 2011, Computer Graphics Archive
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Nabata K, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.13040
   Novak J., 2011, S INTERACTIVE 3D GRA, P119
   Olsson O, 2015, IEEE T VIS COMPUT GR, V21, P701, DOI 10.1109/TVCG.2015.2418772
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Ritschel T, 2012, COMPUT GRAPH FORUM, V31, P160, DOI 10.1111/j.1467-8659.2012.02093.x
   Ritschel T, 2011, COMPUT GRAPH FORUM, V30, P2258, DOI 10.1111/j.1467-8659.2011.01998.x
   Ritschel Tobias, 2008, ACM Transactions on Graphics, DOI DOI 10.1145/1409060.1409082
   Segovia B, 2007, THESIS, P1
   Simon F, 2015, COMPUT GRAPH FORUM, V34, P575, DOI 10.1111/cgf.12585
   Thiedemann Sinje., 2011, Symposium on Interactive 3D Graphics and Games, I3D '11, P103
   Walter B, 2005, ACM T GRAPHIC, V24, P1098, DOI 10.1145/1073204.1073318
   Walter B, 2006, ACM T GRAPHIC, V25, P1081, DOI 10.1145/1141911.1141997
NR 40
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13571
EP 13595
DI 10.1007/s11042-017-4976-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900023
DA 2024-07-18
ER

PT J
AU Banitalebi-Dehkordi, M
   Banitalebi-Dehkordi, A
   Abouei, J
   Plataniotis, KN
AF Banitalebi-Dehkordi, Mehdi
   Banitalebi-Dehkordi, Amin
   Abouei, Jamshid
   Plataniotis, Konstantinos N.
TI Face recognition using a new compressive sensing-based feature
   extraction method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Feature extraction; Neural networks; SRC
   classifier; FFT
ID ONE TRAINING IMAGE; REPRESENTATION; EIGENFACES; SIGNALS
AB This paper proposes a novel face recognition algorithm that utilizes a sparse Fast Fourier Transform (FFT)-based feature extraction method. In our algorithm, we use Compressive Sampling (CS) theory two times. First, in the feature extraction process for extracting the feature vectors from a face images, and second, in the classification process where the CS reconstruction is used for selecting true classes. As a result, a significant reduction in the dimensionality of the signals is achieved. Extensive and comparative experiments have been conducted to evaluate the performance of the proposed scheme. The experiment results show that the combined Compressive Sensing and Sparse Representation Classification (SRC) achieves a high recognition accuracy, while maintaining a reasonable computational complexity.
C1 [Banitalebi-Dehkordi, Mehdi] Yazd Univ, SPRL, Yazd, Iran.
   [Abouei, Jamshid] Yazd Univ, Dept Elect Engn, Yazd, Iran.
   [Banitalebi-Dehkordi, Amin] Univ British Columbia, Digital Media Lab, Vancouver, BC, Canada.
   [Plataniotis, Konstantinos N.] Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Plataniotis, Konstantinos N.] Univ Toronto, Multimedia Lab, Toronto, ON, Canada.
C3 University of Yazd; University of Yazd; University of British Columbia;
   University of Toronto; University of Toronto
RP Banitalebi-Dehkordi, A (corresponding author), Univ British Columbia, Digital Media Lab, Vancouver, BC, Canada.
EM dehkordi@ece.ubc.ca
RI Abouei, Jamshid/A-4959-2010; Abouei, Jamshid/AAN-7300-2020; Plataniotis,
   Konstantinos/E-8471-2014
OI Abouei, Jamshid/0000-0002-2608-6100; Plataniotis,
   Konstantinos/0000-0003-3647-5473
CR [Anonymous], 2016, Advances in Face Detection and Facial Image Analysis
   Banitalebi A, 2010, 3 INT C IM SIGN PROC
   Banitalebi-Dehkordi M, 2014, J SIGNAL PROCESS SYS, V74, P273, DOI 10.1007/s11265-013-0797-4
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen D-Y, 2012, P IEEE INT S INT SIG, P157
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Daugman J, 1997, IEEE T PATTERN ANAL, V19, P675, DOI 10.1109/34.598225
   Dehkordi MB, 2013, DIGIT SIGNAL PROCESS, V23, P1239, DOI 10.1016/j.dsp.2013.01.008
   Ebrahimpour-Komleh H, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P359, DOI 10.1109/ISSPA.2001.949852
   Every MR, 2008, IEEE T AUDIO SPEECH, V16, P267, DOI 10.1109/TASL.2007.908128
   Gao YS, 2005, PATTERN RECOGN, V38, P1009, DOI 10.1016/j.patcog.2004.12.006
   Hennings-Yeomans P., 2008, P IEEE INT C BIOM TH, P56, DOI [10.1109/btas.2008.46993212-s2.0-67549097153, DOI 10.1109/BTAS.2008.46993212-S2.0-67549097153]
   Huang G, 2013, LABELED FACES WILD, P1
   Huang J, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P120
   Jung HC, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P272
   Kadosh KC, 2010, J COGNITIVE NEUROSCI, V22, P903, DOI 10.1162/jocn.2009.21224
   Kepenekci B., 2002, P IEEE INT C IM PROC, P373, DOI [10.1109/ICIP.2002.1038017, DOI 10.1109/ICIP.2002.1038017]
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Le HS, 2004, INT C PATT RECOG, P318, DOI 10.1109/ICPR.2004.1334116
   Learned-Miller E, 2008, P FAC REAL LIF IM WO, P5
   Lee K, 2003, IEEE T PATTERN ANAL, V27, P684
   Liang SF, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P1460, DOI 10.1109/IMCCC.2012.342
   Lu JW, 2003, PATTERN RECOGN LETT, V24, P3079, DOI 10.1016/S0167-8655(03)00167-3
   Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162
   Martinez A. M., 1998, THE AR FACE DATABASE
   Nagesh P, 2009, PROC CVPR IEEE, P1518, DOI 10.1109/CVPRW.2009.5206657
   Paulin F., 2011, INT J COMPUT SCI ENG, V3, P327
   Shaheed MH, 2004, IEEE SYS MAN CYBERN, P5985
   Sheel S., 2007, Second International Conference on Industrial and Information Systems - 2007, P307, DOI 10.1109/ICIINFS.2007.4579193
   Sreenivas TV, 2009, INT CONF ACOUST SPEE, P4125, DOI 10.1109/ICASSP.2009.4960536
   Struc V, 2012, PHD PRETTY HELPFUL D
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817
   Tao D, 2017, IEEE T CIRC SYST VID, V27
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wakin M, 2009, COMPRESSIVE SENSING, P4125
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yap X, 2010, INT CONF ACOUST SPEE, P2490, DOI 10.1109/ICASSP.2010.5494897
   Zhang YB, 2006, IMAGE VISION COMPUT, V24, P626, DOI 10.1016/j.imavis.2005.08.004
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou E., 2015, arXiv preprint arXiv:1501.04690
NR 49
TC 4
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14007
EP 14027
DI 10.1007/s11042-017-5007-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900040
DA 2024-07-18
ER

PT J
AU El Khoury, J
   Le Moan, S
   Thomas, JB
   Mansouri, A
AF El Khoury, Jessica
   Le Moan, Steven
   Thomas, Jean-Baptiste
   Mansouri, Alamin
TI Color and sharpness assessment of single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image dehazing; Color; Sharpness; Image quality assessment;
   Objective assessment; Psychometric experiment
ID QUALITY ASSESSMENT; DIFFERENCE PREDICTION; ENHANCEMENT; VISION
AB Image dehazing is the process of enhancing a color image of a natural scene that contains an undesirable veil of fog for visualization or as a pre-processing step for computer vision systems. In this work, we investigate the performances of eleven state-of-the-art image quality metrics in evaluating dehazed images, and discuss challenges in designing an efficient dehazing evaluation metric. This is done through a composite study based on the agreement between subjective and objective evaluations. Accordingly, we evaluate five state-of-the-art dehazing algorithms. We use two semi-indoor scenes, degraded with several levels of fog. One important aspect of these scenes is that the fog-free images are available and can therefore serve as ground-truth data for dehazing methods evaluation. This study shows that the best working dehazing method depends on the density of fog. There seems to be a clear distinction between what people perceive as good quality in terms of color restoration and in terms of sharpness restoration. Most metrics show limitations in providing proper quality prediction of dehazing. According to the introduction and analysis, a contribution of this work is to point out the flaws in the evaluation and development of dehazing methods. Our observations might be considered when designing efficient methods and metrics dedicated to image dehazing.
C1 [El Khoury, Jessica; Thomas, Jean-Baptiste; Mansouri, Alamin] Univ Bourgogne Franche Comte, Lab LE2I, Dijon, France.
   [Le Moan, Steven] NTNU Gjovik, Norwegian Colour & Visual Comp Lab, Gjovik, Norway.
C3 Universite de Bourgogne; Norwegian University of Science & Technology
   (NTNU)
RP El Khoury, J (corresponding author), Univ Bourgogne Franche Comte, Lab LE2I, Dijon, France.
EM jessica.el-khoury@u-bourgogne.fr; steven.lemoan@hig.no;
   jean-baptiste.thomas@u-bourgogne.fr; alamin.mansouri@u-bourgogne.fr
RI THOMAS, Jean-Baptiste/AAF-7684-2020
FU Open Food System project; National Research Council of Norway; Vitagora;
   Cap Digital; Imaginove; Aquimer; Microtechnique; Agrimip; French State;
   Franche-Comte Region as part of The Investments for the Future Programme
FX The authors thank the Open Food System project as well as the National
   Research Council of Norway for funding. Open Food System is a research
   project supported by Vitagora, Cap Digital, Imaginove, Aquimer,
   Microtechnique and Agrimip, funded by the French State and the
   Franche-Comte Region as part of The Investments for the Future Programme
   managed by Bpifrance, www.openfoodsystem.fr.
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Anitharani M, 2013, IOSR J ENG, V3, P10
   [Anonymous], 1993, BT50012 ITUR
   [Anonymous], 2013, ISRN SIGNAL PROCESS, DOI [DOI 10.1155/2013/905685, 10.1155/2013/905685]
   [Anonymous], IEEE INT C IM PROC
   Brown L, 2005, J STAT PLAN INFER, V130, P359, DOI 10.1016/j.jspi.2003.09.039
   Chen ZY, 2014, PROC CVPR IEEE, P3003, DOI 10.1109/CVPR.2014.384
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   El Khoury J, 2015, AIC 2015, V2015
   El Khoury J, 2016, LECT NOTES COMPUT SC, V9680, P109, DOI 10.1007/978-3-319-33618-3_12
   El Khoury J, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P606, DOI 10.1109/SITIS.2014.78
   Fang S, 2011, CHIN CONT DECIS CONF, P610, DOI 10.1109/CCDC.2011.5968254
   Fleyeh H., 2005, 10th EWGT Meeting and 16th Mini-EURO Conference, P644
   Galdran A, 2015, APPL OPTICS, V27, P25
   Galdran A, 2015, LECT NOTES COMPUT SC, V8927, P259, DOI 10.1007/978-3-319-16199-0_18
   Guo F, 2014, J CENT SOUTH UNIV, V21, P272, DOI 10.1007/s11771-014-1938-z
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Koschmieder H., 1925, Theorie der horizontalen Sichtweite: Kontrast und Sichtweite
   Le Moan S., 2015, IMAGE QUALITY SYSTEM, V9396, P9096
   Le Moan S, 2014, IEEE T IMAGE PROCESS, V23, P2058, DOI 10.1109/TIP.2014.2311373
   Lissner I, 2013, IEEE T IMAGE PROCESS, V22, P435, DOI 10.1109/TIP.2012.2216279
   Liu SL, 2015, INT CONF INFO SCI, P345, DOI 10.1109/ICIST.2015.7288994
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Luthen J., 2017, Electron. Imaging, V29, P79, DOI DOI 10.2352/ISSN.2470-1173.2017.12.IQSP-229
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Ngo KV, 2015, IS T SPIE ELECT IMAG
   Pang J, 2011, IMPROVED SINGLE IMAG
   Pettersson N., 2013, GPU ACCELERATED REAL
   Pierre F, 2015, GRETSI
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Sahu C, 2014, INT J ADV RES COMPUT, V3, P7057
   Sathya R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1119, DOI 10.1109/ECS.2015.7124757
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   SHEN W, 2017, J NETW INTELL, V2, P139
   Song YC, 2017, J PHYS CONF SER, V844, DOI 10.1088/1742-6596/844/1/012045
   Sun W, 2013, OPTIK, V124, P4770, DOI 10.1016/j.ijleo.2013.01.097
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Ullah E., 2013, 2013 5th International Conference on Modelling, Identification and Control (ICMIC), P245
   Wang LX, 2015, CHINESE J ELECTRON, V24, P573, DOI 10.1049/cje.2015.07.023
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Ximvei Liu, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P118
   Xu Z., 2009, 2009 INT C COMP INT, P1
   Yan Wang, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P789, DOI 10.1109/ICICISYS.2010.5658614
   Yendrikhovskij SN, 1998, P SOC PHOTO-OPT INS, V3299, P274, DOI 10.1117/12.320117
   Zhang H., 2013, J COMPUTLNF SYST, V9, P1623
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu Q., 2014, P BMVC
NR 61
TC 22
Z9 22
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15409
EP 15430
DI 10.1007/s11042-017-5122-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200043
DA 2024-07-18
ER

PT J
AU Li, CL
   Zhong, F
   Zhang, Q
   Qin, XY
AF Li, Chenglong
   Zhong, Fan
   Zhang, Qian
   Qin, Xueying
TI Accurate and fast 3D head pose estimation with noisy RGBD images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head pose estimation; Depth feature points; Point cloud matching;
   Outlier filtering; Kinect
AB Head pose estimation plays an essential role in many high-level face analysis tasks. However, accurate and robust pose estimation with existing approaches remains challenging. In this paper, we propose a novel method for accurate three-dimensional (3D) head pose estimation with noisy depth maps and high-resolution color images that are typically produced by popular RGBD cameras such as the Microsoft Kinect. Our method combines the advantages of the high-resolution RGB image with the 3D information of the depth image. For better accuracy and robustness, features are first detected using only the color image, and then the 3D feature points used for matching are obtained by combining depth information. The outliers are then filtered with depth information using rules proposed for depth consistency, normal consistency, and re-projection consistency, which effectively eliminate the influence of depth noise. The pose parameters are then iteratively optimized using the Extended LM (Levenberg-Marquardt) method. Finally, a Kalman filter is used to smooth the parameters. To evaluate our method, we built a database of more than 10K RGBD images with ground-truth poses recorded using motion capture. Both qualitative and quantitative evaluations show that our method produces notably smaller errors than previous methods.
C1 [Li, Chenglong; Zhong, Fan; Zhang, Qian; Qin, Xueying] Shandong Univ, Sch Comp Sci & Technol, 1500 Shunhua Rd, Jinan, Shandong, Peoples R China.
C3 Shandong University
RP Zhong, F (corresponding author), Shandong Univ, Sch Comp Sci & Technol, 1500 Shunhua Rd, Jinan, Shandong, Peoples R China.
EM lcl19880926@163.com; zhongfan@sdu.edu.cn
RI Qin, Xueying/AAM-8775-2021
OI Qin, Xueying/0000-0003-0057-295X
FU 863 program of China [2015AA016405]; NSF of China [61572290, 61672326];
   Fundamental Research Funds of Shandong University [2015JC051]
FX The authors gratefully acknowledge the editor and anonymous reviewers
   for their comments to help us to improve our paper, and also thank for
   their enormous help in revising this paper. This work is supported by
   863 program of China (No. 2015AA016405), and NSF of China (Nos.
   61572290, 61672326), and The Fundamental Research Funds of Shandong
   University (No. 2015JC051).
CR [Anonymous], 2011, ACM transactions on graphics (TOG), DOI DOI 10.1145/1964921.1964972
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.458
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Liang GY, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P632
   Liu XB, 2016, IEEE IMAGE PROC, P1289, DOI 10.1109/ICIP.2016.7532566
   Martin Manuel, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P641, DOI 10.1109/3DV.2014.54
   Meyer G. P., 2015, INT C COMP VIS
   Mian A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P735
   Milborrow S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P380
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Niese Robert, 2007, Journal of Multimedia, V2, P1, DOI 10.4304/jmm.2.5.1-12
   Osadchy M, 2007, ADV NEURAL INFORM PR, P1017
   Padeleris P., 2012, COMPUTER VISION PATT, P42
   Papazov C, 2015, PROC CVPR IEEE, P4722, DOI 10.1109/CVPR.2015.7299104
   Rekik Ahmed, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P223
   Saeed A, 2015, IEEE IMAGE PROC, P1752, DOI 10.1109/ICIP.2015.7351101
   Seemann E, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P626, DOI 10.1109/AFGR.2004.1301603
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Storer Markus, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P192, DOI 10.1109/ICCVW.2009.5457701
   Sun Y, 2008, INT C PATT RECOG, P104
   Tulyakov S, 2014, INT C PATT RECOG, P2263, DOI 10.1109/ICPR.2014.393
   Vatahska T, 2007, IEEE-RAS INT C HUMAN, P330, DOI 10.1109/ICHR.2007.4813889
   Viola P., 2007, ADV NEURAL INFORM PR, V18, P1417
   Whitehill J., 2008, P IEEE C AUT FACT GE, P1
   Yang RG, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P255, DOI 10.1109/AFGR.2002.1004163
   Yao J, 2004, PROC CVPR IEEE, P414
   Zabulis X, 2009, P BRIT MACH VIS C
NR 33
TC 11
Z9 12
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14605
EP 14624
DI 10.1007/s11042-017-5050-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200006
DA 2024-07-18
ER

PT J
AU Luo, YM
   Zhao, L
   Liu, PZ
   Huang, DT
AF Luo, Yanmin
   Zhao, Liang
   Liu, Peizhong
   Huang, Detian
TI Fire smoke detection algorithm based on motion characteristic and
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background dynamic update; Dark channel prior; Convolutional neural
   networks; Smoke detection
ID PARALLEL FRAMEWORK; VIDEO FIRE; HEVC; IMAGE
AB It is a challenging task to recognize smoke from visual scenes due to large variations in the feature of color, texture, shapes, etc. The current detection algorithms are mainly based on single feature or fusion of multiple static features of smoke, which leads to low detection accuracy. To solve this problem, this paper proposes a smoke detection algorithm based on the motion characteristics of smoke and the convolutional neural networks (CNN). Firstly, a moving object detection algorithm based on background dynamic update and dark channel priori is proposed to detect the suspected smoke regions. Then, the features of suspected region is extracted automatically by CNN, on that the smoke identification is performed. Compared to previous work, our algorithm improves the detection accuracy, which can reach 99% in the testing sets. For the problem that the region of smoke is relatively small in the early stage of smoke generation, the strategy of implicit enlarging the suspected regions is proposed, which improves the timeliness of smoke detection. In addition a fine-tuning method is proposed to solve the problem of scarce of data in the training network. Also, the algorithm has good smoke detection performance by testing under various video scenes.
C1 [Luo, Yanmin; Zhao, Liang] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Luo, Yanmin] Huaqiao Univ, Coll Mech Engn & Automat, Xiamen 361021, Peoples R China.
   [Liu, Peizhong; Huang, Detian] Huaqiao Univ, Coll Engn, Quanzhou 362021, Fujian, Peoples R China.
C3 Huaqiao University; Huaqiao University; Huaqiao University
RP Luo, YM (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.; Luo, YM (corresponding author), Huaqiao Univ, Coll Mech Engn & Automat, Xiamen 361021, Peoples R China.
EM lym@hqu.edu.cn
FU Talent project of Huaqiao University [14BS215]; Quanzhou scientific and
   technological planning projects of Fujian, China [2015Z40, 2015Z120]
FX This work was supported by the Talent project of Huaqiao University (No.
   14BS215) and Quanzhou scientific and technological planning projects of
   Fujian, China (2015Z40, 2015Z120).
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], J ELECT INF TECHNOL
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chenebert A, 2011, IEEE IMAGE PROC, P1741, DOI 10.1109/ICIP.2011.6115796
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Fujiwara N, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P659
   Hongda Tian, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P532, DOI 10.1109/ICME.2012.72
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   [罗胜 Luo Sheng], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P1225
   Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001
   Kolesov I, 2010, IEEE IMAGE PROC, P761, DOI 10.1109/ICIP.2010.5652119
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Luo S, 2015, FIRE SAFETY J, V75, P23, DOI 10.1016/j.firesaf.2015.04.002
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tao CY, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P150, DOI [10.1109/ICIICII.2016.68, 10.1109/ICIICII.2016.0045]
   Tian H, 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/VETECF.2011.6092963
   Toreyin BU, 2015, P 13 EUR SIGN PROC C, P1
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yu CY, 2010, FIRE TECHNOL, V46, P651, DOI 10.1007/s10694-009-0110-z
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   [赵亮 Zhao Liang], 2017, [计算机应用研究, Application Research of Computers], V34, P957
NR 31
TC 81
Z9 90
U1 2
U2 105
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15075
EP 15092
DI 10.1007/s11042-017-5090-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200028
DA 2024-07-18
ER

PT J
AU Nogueira, J
   Guardalben, L
   Cardoso, B
   Sargento, S
AF Nogueira, Joao
   Guardalben, Lucas
   Cardoso, Bernardo
   Sargento, Susana
TI Catch-up TV forecasting: enabling next-generation over-the-top
   multimedia TV services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Catch-up TV; IPTV; OTT; Multimedia; Forecasting
ID SELECTION; MODELS
AB Due to recent developments in Over-The-Top (OTT) technologies, Pay-TV operators have begun a migration process of managed IP Television (IPTV) services to more appealing OTT approaches. In these scenarios, being able to predict when and what resources will be necessary at any given point is crucial to a high-quality, efficient, and cost-effective operation, especially when dealing with the dynamic and resource-intensive requirements of IPTV multimedia services. To evaluate the advantages of demand forecasting for efficient Catch-up TV delivery on OTT scenarios, this research work explores several classes of machine learning models regarding their accuracy, computational requirement trade-offs, and deployability. The training process relies on a dataset comprised of Catch-up TV usage logs acquired from an IPTV operator's live production service containing over 1 million subscribers. A predictive and dynamic resource provisioning approach is proposed and evaluated in terms of bandwidth and storage savings. Results demonstrate that forecasting Catch-up TV demand is practical, suitable for integration in OTT solutions, and useful in improving efficiency, with benefits to operators and consumers. Significant savings in bandwidth and storage are shown to be achievable, enabling green and cost-effective resource usage.
C1 [Nogueira, Joao; Cardoso, Bernardo] Altice Labs SA, Aveiro, Portugal.
   [Nogueira, Joao; Guardalben, Lucas] Univ Aveiro, Aveiro, Portugal.
   [Sargento, Susana] Univ Aveiro, Habillitat, Aveiro, Portugal.
   [Guardalben, Lucas; Sargento, Susana] Inst Telecomunicacoes, Aveiro, Portugal.
   [Sargento, Susana] Inst Telecomunicacoes, Network Architectures & Protocols NAP Grp, Aveiro, Portugal.
C3 Altice Portugal; Universidade de Aveiro; Universidade de Aveiro;
   Universidade de Aveiro; Universidade de Aveiro
RP Nogueira, J (corresponding author), Altice Labs SA, Aveiro, Portugal.; Nogueira, J (corresponding author), Univ Aveiro, Aveiro, Portugal.
EM joaonogueira@ua.pt; guardalben@ua.pt; bernardo@alticelabs.com;
   susana@ua.pt
RI Sargento, Susana I. B. M/A-5586-2012; Nogueira, Joao/B-6543-2014
OI Cardoso, Bernardo/0000-0002-1210-5665; Nogueira,
   Joao/0000-0002-5748-833X
FU UltraTV (Portugal 2020) [POCI-01-0247-FEDER-017738]; FCT/MEC; FEDER -
   PT2020 partnership agreement [UID/EEA/50008/2013]
FX This research was funded by UltraTV (Portugal 2020
   POCI-01-0247-FEDER-017738), by FCT/MEC through national funds, and when
   applicable co-funded by FEDER - PT2020 partnership agreement under the
   project UID/EEA/50008/2013 OT2Delivery (Over-the-top Multimedia Content
   Delivery for Next Generation Mobile Networks).
CR Aguado A, 2016, J LIGHTWAVE TECHNOL, V34, P1933, DOI 10.1109/JLT.2016.2522823
   ANACOM, 2015, TECH REP
   Bahrpeyma F, 2015, COMPUTING, V97, P1209, DOI 10.1007/s00607-015-0455-8
   Beauvisage Thomas, 2012, P 21 INT C COMP WORL, P461, DOI [10.1145/2187980.2188077, DOI 10.1145/2187980.2188077]
   Burden Frank., 2009, Bayesian regularization of neural networks. Artificial Neural Networks: Methods and Applications, P23, DOI DOI 10.1007/978-1-60327-101-13
   Caruana Rich, 2004, P 21 INT C MACH LEAR, DOI [10.1145/1015330.1015432, DOI 10.1145/1015330.1015432]
   Dhotre I. A., 2009, OPERATING SYSTEMS
   Famaey J, 2013, J NETW COMPUT APPL, V36, P219, DOI 10.1016/j.jnca.2012.08.014
   Harstead E, 2015, IEEE COMMUN MAG, V53, P199, DOI 10.1109/MCOM.2015.7060505
   Hyndman R.J., 2015, forecast: forecasting functions for time series and linear models
   Hyndman RJ, 2006, FORESIGHT INT J APPL, V4, P43
   John G.H., 1994, P 11 INT C MACH LEAR, P121
   Karatzoglou A, 2015, KERNLAB
   Karsoliya S., 2012, "Int. J. Eng. Trends Technol., V3, P714
   Kephart JO, 2003, COMPUTER, V36, P41, DOI 10.1109/MC.2003.1160055
   Kryftis Y, 2016, IEEE WIREL COMMUN, V23, P14, DOI 10.1109/MWC.2016.7422401
   Kuhn M., 2013, APPL PREDICTIVE MODE, DOI [DOI 10.1007/978-1-4614-6849-3, 10.1007/978-1-4614-6849-3]
   Kuhn M., 2015, CARET
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Liaw A, 2015, RANDOMFOREST
   Mercian A, 2015, IEEE COMMUN SURV TUT, V18, P1, DOI [10.1109/COMST.2016.2586999, DOI 10.1109/COMST.2016.2586999]
   Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499
   Nam H, 2015, IEEE WCNC, P2185, DOI 10.1109/WCNC.2015.7127806
   Nencioni Gianfranco, 2013, P 22 INT C WORLD WID, P965
   Nielsen, 2014, DIG CONS
   Nogueira J, 2016, 21 IEEE S COMP COMM, P6
   Nogueira J, 2017, MULTIMEDIA SYST, V23, P563, DOI 10.1007/s00530-016-0516-7
   Pathan M, 2008, LECT NOTES ELECTR EN, V9, P33
   R Foundation for Statistical Computing, 2016, R PROJECT STAT COMPU
   Ranjan R, 2015, IEEE INTERNET COMPUT, V19, P46, DOI 10.1109/MIC.2015.20
   Ripley B, 2015, CLASS
   Rodriguez PP, 2015, BRNN BAYESIAN REGULA
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Szlek J, 2015, FSCARET
   Tofallis C, 2015, J OPER RES SOC, V66, P1352, DOI 10.1057/jors.2014.103
   Vanattenhoven J., 2015, P ACM INT C INT EXP, P73, DOI [DOI 10.1145/2745197.2745208, 10.1145/2745197.2745208]
   Weingärtner R, 2015, J NETW COMPUT APPL, V47, P99, DOI 10.1016/j.jnca.2014.09.018
   Wirth R., 2000, Proceedings of the Fourth International Conference on the Practical Application of Knowledge Discovery and Data Mining, P29
   Yeo IK, 2000, BIOMETRIKA, V87, P954, DOI 10.1093/biomet/87.4.954
NR 39
TC 6
Z9 6
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14527
EP 14555
DI 10.1007/s11042-017-5043-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200003
DA 2024-07-18
ER

PT J
AU Song, XB
   Zheng, JM
   Zhong, F
   Qin, XY
AF Song, Xibin
   Zheng, Jianmin
   Zhong, Fan
   Qin, Xueying
TI Modeling deviations of rgb-d cameras for accurate depth map and color
   image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D cameras; Camera calibration; Registration; Deviations; Computer
   vision
ID CALIBRATION; KINECT
AB A fundamental step to employ RGB-D cameras is to register color and depth images, whose misalignment may be caused by differences of camera poses and parameters, depth noises, etc. Previous methods mainly devote to more accurate camera calibration, which can only deal with misalignment that are parameterized with camera projection model. Other misalignment, which we call deviations, are more difficult to be measured and modeled. In this paper, we propose a method to model and remove RGB-D camera deviations. First, a specially-designed checkerboard with hollow squares is utilized to measure deviations and camera parameters, it takes advantage of the regularity of corner arrangements and can achieve high accuracy even with noisy depth inputs. Second, we propose a general deviation model to deal with irregular deviations that can not be handled by RGB-D camera projection model. Third, we introduce a registration method that incorporates the estimated deviation model to well register color and depth information. As demonstrated in the experiments, comparing with manufacturer's calibration and some state-of-the-art algorithms, our approach produces significant better accuracy.
C1 [Song, Xibin; Zhong, Fan; Qin, Xueying] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
   [Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
C3 Shandong University; Nanyang Technological University
RP Qin, XY (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
EM song.sducg@gmail.com; ASJMZheng@ntu.edu.sg; zhongfan@sdu.edu.cn;
   qxy@sdu.edu.cn
RI Qin, Xueying/AAM-8775-2021; Zheng, Jianmin/A-3717-2011; Song,
   Xibin/AAF-8629-2019
OI Qin, Xueying/0000-0003-0057-295X; Zheng, Jianmin/0000-0002-5062-6226; 
FU 863 program of China [2015AA016405]; NSF of China [61672326, 61572290];
   Shandong Science and Technology Development Plan [2013G0020601]
FX 863 program of China (No. 2015AA016405), NSF of China (Nos. 61672326,
   61572290), and Shandong Science and Technology Development Plan (No.
   2013G0020601).
CR [Anonymous], 2011, 2011 IEEE WORKSHOP A
   Basso F, 2017, ARXIV170105748
   Basso F, 2014, IEEE INT CONF ROBOT, P6244, DOI 10.1109/ICRA.2014.6907780
   Bradski G., 2008, LEARNING OPENCV
   Burrus N., 2011, KINECT CALIBRATION
   Canessa A, 2014, J VIS COMMUN IMAGE R, V25, P227, DOI 10.1016/j.jvcir.2013.02.011
   Chow JCK, 2013, IEEE ACCESS, V1, P465, DOI 10.1109/ACCESS.2013.2271860
   De Boor C, 1978, A Pratical Guide to Splines, V27
   Fleet DJ, 2014, COMPUTER VISION, V8693
   Frank B, 2010, P IEEE INT C ROB AUT
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Fuchs S., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587828
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Gwang-Soo Hong, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P484, DOI 10.1109/ICCE.2016.7430699
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579
   Henry P., 2010, International Symposium on Experimental Robotics, V20, P22
   Herrera D, 2011, LECT NOTES COMPUT SC, V6855, P437, DOI 10.1007/978-3-642-23678-5_52
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Hickson S, 2014, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2014.51
   Hong GS, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/326029
   Hung M., 2013, SIGN INF PROC ASS AN, P1, DOI DOI 10.2139/SSRN.2206877
   Jebari I, 2012, PROCEDIA ENGINEER, V41, P1307, DOI 10.1016/j.proeng.2012.07.315
   Jung J, 2015, IEEE T PATTERN ANAL, V37, P1501, DOI 10.1109/TPAMI.2014.2363827
   Jung J, 2011, IEEE INT C INT ROBOT, P3290, DOI 10.1109/IROS.2011.6048877
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Konolige K, 2010, IEEE INT CONF ROBOT, P148, DOI 10.1109/ROBOT.2010.5509796
   Kramer J., 2012, HACKING THE KINECT, V268
   Kurt Konolige PM, TECHNICAL DESCRIPTIO
   Lachat E, 2015, REMOTE SENS-BASEL, V7, P13070, DOI 10.3390/rs71013070
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6
   Matsuo K, 2015, IEEE C COMP VIS PATT
   Mikhelson IV, 2014, J VIS COMMUN IMAGE R, V25, P218, DOI 10.1016/j.jvcir.2013.03.010
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nguyen CV, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P524, DOI 10.1109/3DIMPVT.2012.84
   Ramey A, 2011, ACMIEEE INT CONF HUM, P229, DOI 10.1145/1957656.1957745
   Raposo C, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P342, DOI 10.1109/3DV.2013.52
   Scaramuzza D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4170, DOI 10.1109/iros.2007.4399276
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   Shao L, 2013, IEEE T CYBERNETICS, V43, P1314, DOI 10.1109/TCYB.2013.2276144
   Shapiro L., 2002, STOCKMAN G COMPUTER
   Shaw John R., 2004, QUICKFILL EFFICIENT
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Song XB, 2014, VISUAL COMPUT, V30, P855, DOI 10.1007/s00371-014-0965-y
   Staranowicz A., 2013, PACIFIC RIM S IMAGE, P265
   Staranowicz AN, 2015, COMPUT VIS IMAGE UND, V137, P102, DOI 10.1016/j.cviu.2015.03.013
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Vandevenn L, 2004, SAMPLE IMPLEMENTATIO
   Wang YK, 2014, VISUAL COMPUT, V30, P1157, DOI 10.1007/s00371-013-0896-z
   Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131
   Zhang Cha., 2014, Computer Vision and Machine Learning with RGB-D Sensors, P47
   Zhang Q. L., 2004, 2004 IEEERSJ INT C I, P2301
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 57
TC 10
Z9 10
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14951
EP 14977
DI 10.1007/s11042-017-5081-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200023
DA 2024-07-18
ER

PT J
AU Zhu, HQ
   Xie, QY
AF Zhu, Hongqing
   Xie, Qunyi
TI Content-based image retrieval using student's <i>t</i>-mixture model and
   constrained multiview nonnegative matrix factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imageretrieval; Student's t-mixture model; nonnegative matrix
   factorization; sparse constraint; Markov random field; multiview
ID REPRESENTATION; SELECTION
AB The expensive and time-consuming effort required for archiving images is the main motive for developing an effective retrieval system. This paper addresses a competitive scheme for Content-Based Image Retrieval (CBIR) based on a constrained multiview Nonnegative Matrix Factorization (NMF) that has the ability to generate a sparse representation. The scheme blends multiple visual features, which can together reflect the content of images in terms of similarity metrics and the Frobenius norm. Then, the proposed method constructs a similarity-preserving matrix factorization via an improved NMF, where the structural constraint, L (1/2)-sparse constraint and farness-preserving constraint are integrated into the objective function of conventional NMF. In this way, the structure and content of high-dimensional feature data source can be preserved in low-dimensional space. Another critical part of the proposed system is to establish Student's t-Mixture Model (SMM) based on a Markov Random Field (MRF), which can best manipulate the clustering of sparse representations according to the statistical properties of the image features. With this method, the task of image retrieval of the whole dataset is reduced to a nearest-neighbour search in a specific category containing the query image. Convergence of the proposed update rule, investigated in this study, is also verified by numerical simulations. Lastly, we conduct experiments on public datasets to compare the performance of the proposed algorithm with existing works in terms of Precision and Recall Rates. The encouraging results indicate the effectiveness of the proposed technique.
C1 [Zhu, Hongqing; Xie, Qunyi] East China Univ Sci & Technol, Sch Informat Sci & Engn, 130 Mei Long Rd, Shanghai 200237, Peoples R China.
C3 East China University of Science & Technology
RP Zhu, HQ (corresponding author), East China Univ Sci & Technol, Sch Informat Sci & Engn, 130 Mei Long Rd, Shanghai 200237, Peoples R China.
EM hqzhu@ecust.edu.cn
FU National Nature Science Foundation of China [61371150]
FX The authors would like to thank the anonymous reviewers and the
   associate editor for their insightful comments that significantly
   improved the quality of this paper, This work was supported by the
   National Nature Science Foundation of China under Grant 61371150.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Amin T, 2007, IEEE T MULTIMEDIA, V9, P1416, DOI 10.1109/TMM.2007.906587
   An L, 2016, NEUROCOMPUTING, V172, P215, DOI 10.1016/j.neucom.2014.09.098
   Babaee M, 2016, NEUROCOMPUTING, V173, P212, DOI 10.1016/j.neucom.2014.12.124
   Babaee M, 2014, IEEE IMAGE PROC, P3023, DOI 10.1109/ICIP.2014.7025611
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cheng SF, 2012, EXPERT SYST APPL, V39, P8467, DOI 10.1016/j.eswa.2012.01.172
   Cox Michael AA Cox TrevorF., 2010, Multidimensional scaling
   Cui SY, 2015, INT GEOSCI REMOTE SE, P3719, DOI 10.1109/IGARSS.2015.7326631
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Feng LN, 2016, IEEE T PATTERN ANAL, V38, P785, DOI 10.1109/TPAMI.2015.2469281
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Gertheiss J, 2009, CHEMOMETR INTELL LAB, V99, P30, DOI 10.1016/j.chemolab.2009.07.004
   Gillis N, 2015, IEEE T GEOSCI REMOTE, V53, P2066, DOI 10.1109/TGRS.2014.2352857
   Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Hyvarinen A, 2001, NEURAL COMPUT SUR, V4, P60
   Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Liu J., 2013, P 2013 SIAM INT C DA, P252, DOI DOI 10.1137/1.9781611972832.28
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luszczkiewicz-Piatek M, 2013, INT SYMP IMAGE SIG, P130
   Marakakis A, 2009, IET IMAGE PROCESS, V3, P10, DOI 10.1049/iet-ipr:20080012
   Mittal Ajay, 2013, International Journal of Computer Theory and Engineering, V5, P81, DOI 10.7763/IJCTE.2013.V5.651
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Qi SY, 2016, SIGNAL PROCESS-IMAGE, V41, P101, DOI 10.1016/j.image.2015.12.004
   Qian YT, 2011, IEEE T GEOSCI REMOTE, V49, P4282, DOI 10.1109/TGRS.2011.2144605
   Rajabi R, 2015, IEEE GEOSCI REMOTE S, V12, P38, DOI 10.1109/LGRS.2014.2325874
   Nguyen TM, 2014, IEEE T CYBERNETICS, V44, P857, DOI 10.1109/TCYB.2013.2273714
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Wang WH, 2016, IEEE J-STARS, V9, P681, DOI 10.1109/JSTARS.2015.2508448
   Wang Z, 2016, SIGNAL PROCESS, V120, P691, DOI 10.1016/j.sigpro.2014.11.015
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Yang SY, 2015, IEEE J-STARS, V8, P2696, DOI 10.1109/JSTARS.2015.2417574
   Yang WH, 2012, INT C PATT RECOG, P979
   Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9
NR 45
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14207
EP 14239
DI 10.1007/s11042-017-5026-x
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900049
DA 2024-07-18
ER

PT J
AU Ruan, ZC
   Miao, YT
   Pan, L
   Xiang, Y
   Zhang, J
AF Ruan, Zichan
   Miao, Yuantian
   Pan, Lei
   Xiang, Yang
   Zhang, Jun
TI Big network traffic data visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visualization; Network traffic; Multidimensional data; MDS; PCA
ID CLASSIFICATION
AB Visualization is an important tool for capturing the network activities. Effective visualization allows people to gain insights into the data information and discovery of communication patterns of network flows. Such information may be difficult for human to perceive its relationships due to its numeric nature such as time, packet size, inter-packet time, and many other statistical features. Many existing work fail to provide an effective visualization method for big network traffic data. This work proposes a novel and effective method for visualizing network traffic data with statistical features of high dimensions. We combine Principal Component Analysis (PCA) and Mutidimensional Scaling (MDS) to effectively reduce dimensionality and use colormap for enhance visual quality for human beings. We obtain high quality images on a real-world network traffic dataset named 'ISP'. Comparing with the popular t-SNE method, our visualization method is more flexible and scalable for plotting network traffic data which may require to preserve multi-dimensional information and relationship. Our plots also demonstrate the capability of handling a large amount of data. Using our method, the readers will be able to visualize their network traffic data as an alternative method of t-SNE.
C1 [Ruan, Zichan; Miao, Yuantian; Pan, Lei] Deakin Univ, Sch Informat Technol, Geelong, Vic 3220, Australia.
   [Xiang, Yang] Swinburne Univ Technol, Digital Res, Innovat Capabil Platform, John St, Hawthorn, Vic 3122, Australia.
   [Zhang, Jun] Swinburne Univ Technol, Sch Software & Elect Engn, John St, Hawthorn, Vic 3122, Australia.
C3 Deakin University; Swinburne University of Technology; Swinburne
   University of Technology
RP Ruan, ZC (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3220, Australia.
EM zichanr@deakin.edu.au; myuanti@deakin.edu.au; l.pan@deakin.edu.au;
   yxiang@swin.edu.au; junzhang@swin.edu.au
RI Xiang, Yang/D-1280-2009; Pan, Lei/ITT-0556-2023; Pan, Lei/ADH-0321-2022;
   Xiang, Yang/M-3527-2019; yang, xiang/HKN-0533-2023; Miao,
   Yuantian/CAG-3009-2022
OI Xiang, Yang/0000-0001-5252-0831; Pan, Lei/0000-0002-4691-8330; Pan,
   Lei/0000-0002-4691-8330; Xiang, Yang/0000-0001-5252-0831; Miao,
   Yuantian/0000-0002-7333-0305
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   [Anonymous], 1999, Proceedings of the Section on Statistical Graphics, American Statistical Association
   Ashby F. G., 2014, Multidimensional Models of Perception and Cognition
   Boothe R.G., 2001, Perception of the Visual Environment, V1
   Borg I., 2005, MODERN MULTIDIMENSIO, DOI DOI 10.18637/JSS.V014.B04
   Braun L, 2014, COMPUTING, V96, P15, DOI 10.1007/s00607-013-0286-4
   Brewer C.A, 2013, ColorBrewer 2.0
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Dzemyda Gintautas., 2013, Methods and applications series: Springer optimization and its applications, V75, P122
   Elbaham M, 2016, INT CONF NETW SER, P277, DOI 10.1109/CNSM.2016.7818432
   Erl T., 2016, Big data fundamentals: Concepts, drivers & techniques
   Feng ZL, 2018, NEUROCOMPUTING, V273, P395, DOI 10.1016/j.neucom.2017.07.043
   Fisher D.F., 2017, EYE MOVEMENTS COGNIT, V8
   Glatz E, 2014, COMPUTING, V96, P27, DOI 10.1007/s00607-013-0282-8
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Harrison L, 2012, IEEE NETWORK, V26, P6, DOI 10.1109/MNET.2012.6375887
   Harrower M.A., 2011, MAP READER THEORIES, P261, DOI DOI 10.1002/9780470979587.CH34
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Kim Y, 2006, IEEE T VIS COMPUT GR, V12, P925, DOI 10.1109/TVCG.2006.174
   Kumano Y, 2014, INT CONF COMPUT NETW, P136, DOI 10.1109/ICCNC.2014.6785319
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Marsland S, 2009, CH CRC MACH LEARN PA, P1
   Munsell AlbertHenry., 1915, ATLAS MUNSELL COLOR
   Neyman J., 1937, Phil Trans R Soc Lond a, V236, P333, DOI [DOI 10.1098/RSTA.1937.0005, 10.1098/rsta.1937.0005]
   Promrit N, 2015, INT CON ADV INFO NET, P358, DOI 10.1109/AINA.2015.207
   Robbins N.B., 2012, Creating more effective graphs
   Shiravi H, 2012, IEEE T VIS COMPUT GR, V18, P1313, DOI 10.1109/TVCG.2011.144
   Snellen Herman., 1873, Probebuchstaben zur bestimmung der sehscharfe, V1
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Staheli Diane., 2014, Proceedings of the Eleventh Workshop on Visualization for Cyber Security. VizSec'14, P49, DOI DOI 10.1145/2671491.2671492
   Stone M., 2016, FIELD GUIDE DIGITAL, DOI DOI 10.1201/B12887
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang Y, 2014, IEEE T PARALL DISTR, V25, P2932, DOI 10.1109/TPDS.2013.307
   Ward M. O., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P326, DOI 10.1109/VISUAL.1994.346302
   Ware C., 2020, INFORM VISUALIZATION
   Xiao L, 2006, IEEE CONF VIS ANAL, P107
   Zhang J, 2015, IEEE ACM T NETWORK, V23, P1257, DOI 10.1109/TNET.2014.2320577
   Zhang J, 2013, IEEE T INF FOREN SEC, V8, P5, DOI 10.1109/TIFS.2012.2223675
   Zhang J, 2013, IEEE T PARALL DISTR, V24, P104, DOI 10.1109/TPDS.2012.98
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 46
TC 5
Z9 5
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11459
EP 11487
DI 10.1007/s11042-017-5495-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900059
DA 2024-07-18
ER

PT J
AU Wang, M
   Qu, WB
   Chen, WY
AF Wang, Mei
   Qu, Wubing
   Chen, Wen-Yuan
TI Hybrid sensing and encoding using pad phone for home robot control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BCI; Feature extraction; Recognition; Robot; Control
ID BRAIN-COMPUTER INTERFACE; BCI
AB For the patients with limb disorder to control the home robot movement, the human intention sensing and encoding are the two important tasks. This paper focuses on a new augmented reality brain computer interface (ARBCI) of the stable state visual evoked potential (SSVEP), the human intention recognition algorithms using SSVEP and Electra-hologram (EOG) respectively, and the encoding design of the human intentions. Firstly, the new ARBCI is developed which includes the SSVEP collector and a specific environment augmented reality stimulator of the symbols of the robot operations. Furthermore, the robot control instructions are encoded. Secondly, the sliding window superposition-average algorithm (SWSA) is proposed for human intention recognition on the basis of SSVEP. The stimulation frequency feature from the augmented reality stimulator is extracted by using SWSA to control the power supply and the robot speed. Thirdly, the intentional blinking EOG threshold is defined according to the experiments. Then, a fusion recognition (FR) algorithm of amplitude and sampling tune is developed on the basis of EOG, which is for the home robot direction controls. It is experimentally proved that the ARBCI improves the eye comfort compared with that of the original BCI stimulator. Besides, the SWSA can save 4 s to sensing a SSVEP intention meanwhile keep the same recognition accuracy compared with the traditional superposition-average method. In addition, the human intention sensing accuracy can reach 100% by using ARBCI and SWSA and the FR if the sensing time is adequate. A EOG intention sensing time is about 0.5 s by using the FR algorithm.
C1 [Wang, Mei; Qu, Wubing] Xian Univ Sci & Technol, Coll Elect & Control Engn, Xian 710054, Shaanxi, Peoples R China.
   [Chen, Wen-Yuan] Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung, Taiwan.
C3 Xi'an University of Science & Technology; National Chin-Yi University of
   Technology
RP Chen, WY (corresponding author), Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung, Taiwan.
EM cwy@ncut.edu.tw
FU Natural Science Foundation of China [51405381]; Key Scientific and
   Technological Project of Shaanxi Province [2016GY-040]; Science
   Foundation of Xi'an University of Science and Technology
   [104-6319900001]
FX This research was sponsored by the Natural Science Foundation of China
   (51405381), Key Scientific and Technological Project of Shaanxi Province
   (2016GY-040), and the Science Foundation of Xi'an University of Science
   and Technology (104-6319900001).
CR Al Gizi AJH, 2015, APPL SOFT COMPUT, V28, P226, DOI 10.1016/j.asoc.2014.10.046
   Bi LZ, 2014, IEEE T INTELL TRANSP, V15, P959, DOI 10.1109/TITS.2013.2291402
   Bi LZ, 2013, IEEE T INTELL TRANSP, V14, P1996, DOI 10.1109/TITS.2013.2266135
   Chae Y, 2012, IEEE T ROBOT, V28, P1131, DOI 10.1109/TRO.2012.2201310
   Diez PF, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-39
   Friedman D, 2010, HUM-COMPUT INTER-US, V25, P67, DOI 10.1080/07370020903586688
   Jung  Y., 2016, MULTIMED TOOLS APPL, P1
   Kim J. H., 2012, ROBOT INTELL TECHNOL, P375
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Ma JX, 2015, IEEE T BIO-MED ENG, V62, P876, DOI 10.1109/TBME.2014.2369483
   Masataka Y, 2014, ROBOT BIOMIM, V1, P22
   Pan JH, 2013, COGN NEURODYNAMICS, V7, P523, DOI 10.1007/s11571-013-9253-1
   Shih Chung C, 2014, LECT NOTES ELECT ENG, V345, P475
   Volosyak I, 2011, IEEE T NEUR SYS REH, V19, P232, DOI 10.1109/TNSRE.2011.2121919
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6495, DOI 10.1007/s11042-016-3275-8
   Zolotukhin YN, 2011, OPTOELECTRON INSTRUM, V47, P141, DOI 10.3103/S8756699011020051
NR 19
TC 7
Z9 7
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10773
EP 10786
DI 10.1007/s11042-017-4871-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900023
DA 2024-07-18
ER

PT J
AU Shanableh, T
AF Shanableh, Tamer
TI Altering split decisions of coding units for message embedding in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video coding; HEVC; Data hiding; Pattern recognition
ID VIDEO; WATERMARKING; H.264/AVC
AB This paper proposes a novel message embedding solution based on modifying the split decisions of HEVC videos. The encoder starts by computing a mapping between the split decisions of a Coding Unit (CU) and its features variables. This results in model weights that can be used to predict the split decisions. Message embedding is then carried out as a function of the predicted and true split decisions per CU. If the message bit to embed is '1' and the predicted and the true split decisions are different then the true split decision is modified to be identical to the predicted flag. Otherwise if the message bit is '0' and the predicted and the true split decisions are identical, then the true split flag is modified to become different than the predicted flag. We apply this embedding concept at two CU coding levels; 32x32 and 16x16. To extract a message, the decoder starts by regenerating the model weights which are then used to predict split decisions and compare them against the true decisions received in the bit stream. Identical decisions indicate a message bit of '1' and non-identical split decisions indicate a message bit of '0'. In the experimental results we examine the prediction accuracy, the effect of the proposed solutions on message payload, the number of modified split decisions and the corresponding impact on video quality. Comparison with an existing solution reveals that the proposed solution is superior in terms in message payload whilst resulting in reduced video distortions.
C1 [Shanableh, Tamer] Amer Univ Sharjah, Comp Sci, ShrjahPO Box 2666, Sharjah, U Arab Emirates.
C3 American University of Sharjah
RP Shanableh, T (corresponding author), Amer Univ Sharjah, Comp Sci, ShrjahPO Box 2666, Sharjah, U Arab Emirates.
EM tshanableh@aus.edu
RI Shanableh, Tamer/AAC-7893-2021
OI Shanableh, Tamer/0000-0002-7651-3094
CR Cao Y, 2015, IEEE COMMUN LETT, V19, P203, DOI 10.1109/LCOMM.2014.2387160
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Emmanuel S, 2007, P DIG EC SYST TECHN, P21
   Heindel A., 2016, PICT COD SYMP
   Hu Y, 2007, IEEE INT C MULT EXP, V2007, P1231
   Hung KW, 2014, IEEE T CIRC SYST VID, V24, P2018, DOI 10.1109/TCSVT.2014.2329352
   Jiaji W, 2014, SENSORS TRANSDUCERS, V177, P230
   Kapotas SK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P277, DOI 10.1109/ICME.2008.4607425
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim I.-K., 2013, 15 M GEN CH 23 OCT 1
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Shanableh T, 2012, SIGNAL PROCESS-IMAGE, V27, P1025, DOI 10.1016/j.image.2012.06.003
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Tasdemir K, 2016, IEEE T IMAGE PROCESS, V25, P3316, DOI 10.1109/TIP.2016.2567073
   Tew Yiqi, 2014, IEEE INT C IM PROC I
   Tian LH, 2011, SIGNAL PROCESS-IMAGE, V26, P427, DOI 10.1016/j.image.2011.06.001
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yilmaz A, 2008, SIGNAL PROCESS-IMAGE, V23, P298, DOI 10.1016/j.image.2008.03.003
   Zheng X, 2016, KSII T INTERNET INF, V10, P3286, DOI 10.3837/tiis.2016.07.023
NR 25
TC 16
Z9 18
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8939
EP 8953
DI 10.1007/s11042-017-4787-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800051
DA 2024-07-18
ER

PT J
AU Zheng, S
   Chen, J
   Kuo, YH
AF Zheng, Shuai
   Chen, Jian
   Kuo, Yonghong
TI An improved distributed compressed video sensing scheme in
   reconstruction algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed compressed video sensing; Iterative termination decision;
   Weights prediction; Position-based cross reconstruction
ID RECOVERY
AB Under the new video application scene of resource-constrained coding side such as wireless sensor networks, compressed sensing technique provides the possibility to solve the high-complexity problem of encoder because of its highly efficient compression encoding performance. Distributed compressed video sensing system provides a solution to satisfy the requirements of low encoder complexity and high coding efficiency in the new scene. This paper proposes a new distributed compressed video sensing scheme, which effectively improves the reconstruction quality of non-key frames. An auxiliary iterative termination decision algorithm is proposed to improve the performance of key frames initial reconstruction. An adaptive weights prediction algorithm is put forward to reduce the overall complexity. Besides, this paper proposes a position-based cross reconstruction algorithm to improve the decoded quality of the middle non-key frames in the group of pictures. The simulation results show that the proposed scheme effectively improves the overall performance of the distributed compressed video sensing system especially for high motion sequences.
C1 [Zheng, Shuai; Chen, Jian; Kuo, Yonghong] Xidian Univ, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Chen, J (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
EM zhs_xd@163.com; jianchen@mail.xidian.edu.cn; yhkuo@mail.xidian.edu.cn
RI KUO, Yong-Hong/M-9078-2015; Zheng, Shuai/AAH-5647-2020
FU National Natural Science Foundation of China [61540046]; "111" project
   [B08038]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61540046) and the "111" project (Grant No. B08038).
CR [Anonymous], 2003, 449610 ISOIEC MPEG4A
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chang K, 2014, MULTIMEDIA SYST, V20, P363, DOI 10.1007/s00530-014-0354-4
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen J, 2016, CIRCUITS SYSTEMS SIG, P1
   Chen J, 2015, MULTIMED TOOLS APPL, V74, P2085, DOI 10.1007/s11042-013-1743-y
   Chen ScottShaobing., 2001, SIAM Journal on Scientific Computing, V20, P33
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Kang LW, 2009, INT CONF ACOUST SPEE, P1169, DOI 10.1109/ICASSP.2009.4959797
   Kuo Y, 2015, MULTIDIMENSIONAL SYS, P1
   Kuo YH, 2013, ELECTRON LETT, V49, P991, DOI 10.1049/el.2013.0345
   Li CB, 2013, COMPUT OPTIM APPL, V56, P507, DOI 10.1007/s10589-013-9576-1
   Li Chengbo., 2009, Tval3: Tv minimization by augmented lagrangian and alternating direction algorithm
   Liu Z., 2009, ELECT DEVICES M IEDM, P1, DOI DOI 10.1109/WICOM.2009.5302548
   Ma S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587391
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Roohi S, 2013, IRAN CONF MACH, P53, DOI 10.1109/IranianMVIP.2013.6779949
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tramel EW, 2011, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC.2011.26
   Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   Xiao YH, 2012, INVERSE PROBL IMAG, V6, P547, DOI 10.3934/ipi.2012.6.547
   Zhang J, 2013, IEEE INT SYMP CIRC S, P2836
   Zhang XQ, 2010, INVERSE PROBL IMAG, V4, P191, DOI 10.3934/ipi.2010.4.191
NR 33
TC 6
Z9 9
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8711
EP 8728
DI 10.1007/s11042-017-4765-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800042
DA 2024-07-18
ER

PT J
AU Borjian, N
   Kabir, E
   Seyedin, S
   Masehian, E
AF Borjian, Nastaran
   Kabir, Ehsanollah
   Seyedin, Sanaz
   Masehian, Ellips
TI A query-by-example music retrieval system using feature and decision
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music information retrieval; Query-by-example; Feature fusion; Decision
   fusion
AB An attractive topic of Music Information Retrieval (MIR) is focused on query-by-example (QBE), which receives a user-provided query and aims to find the target song from an associated music dataset. In this paper, we use feature and decision fusion techniques to develop a two-stage accurate and rapid QBE based MIR system. For this purpose, a proposed diverse ensemble of recognizers automatically recognizes the genre of the query in first stage. This diversity is yielded through feature extraction over different frequency bands followed by feature fusion to train the recognizers, and then a decision fusion technique fuses the individual results obtained by members of ensemble. Second stage measures similarity between query and other contents of dataset having the same genre with the query to find the target song. To accomplish this, a distance measure that here is Kullback-Leibler divergence is utilized. In this stage, a genre-adaptive feature extraction method is proposed, and features are also fused by a feature fusion technique. The effectiveness of the feature and decision fusion techniques in our two-stage system (genre recognition; song retrieval) is evaluated experimentally that shows a significant improvement in terms of accuracy and retrieval time in comparison with a system for which those techniques are not applied.
C1 [Borjian, Nastaran; Kabir, Ehsanollah] Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
   [Seyedin, Sanaz] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Masehian, Ellips] Tarbiat Modares Univ, Fac Engn, Tehran, Iran.
C3 Tarbiat Modares University; Amirkabir University of Technology; Tarbiat
   Modares University
RP Borjian, N (corresponding author), Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
EM nastaran.borjian@modares.ac.ir; kabir@modares.ac.ir; sseyedin@aut.ac.ir;
   masehian@modares.ac.ir
RI Seyedin, Sanaz/AAP-3846-2020; kabir, ehsanollah/D-1708-2010
OI kabir, ehsanollah/0000-0002-5610-7611; Seyedin,
   Sanaz/0000-0002-3626-7589; Masehian, Ellips/0000-0003-4869-1237
CR [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], P COMP MUS MOD RETR
   [Anonymous], PROC 10 INT C DIG AU
   [Anonymous], J SIGNAL PROCESS SYS
   [Anonymous], QUERY BY EXAMP UNPUB
   [Anonymous], MUSIC PHYS ENG COURI
   [Anonymous], GTZAN GENRE COLLECTI
   [Anonymous], 1 INT WORLD WID WEB
   [Anonymous], 12 INT SOC MUS INF R
   [Anonymous], 2013, WORLD SCI
   [Anonymous], P 6 INT C MUS INF RE
   [Anonymous], OPEN MUSIC ENCY
   [Anonymous], FREE DATABASE
   [Anonymous], NEUROS
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Chathuranga D., 2012, 2012 Fourth International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2012), P237, DOI 10.1109/CIMSim.2012.47
   Cox IJ., 2007, DIGITAL WATERMARKING
   Duda R., 1973, Pattern Classification and Scene Analysis
   Helén M, 2010, EURASIP J AUDIO SPEE, DOI 10.1155/2010/179303
   Itoyama K, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/172961
   Kaminskas M, 2012, COMPUT SCI REV, V6, P89, DOI 10.1016/j.cosrev.2012.04.002
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Mayer Rudolf, 2008, P 16 ACM INT C MULT, P159, DOI [10.1145/1459359.1459382, DOI 10.1145/1459359.1459382]
   McKinney M.F., 2003, Proc. ISMIR, V3, P151
   Meng A, 2007, IEEE T AUDIO SPEECH, V15, P1654, DOI 10.1109/TASL.2007.899293
   Ponti M. P.  Jr., 2011, 2011 24th SIBGRAPI Conference on Graphics, Patterns and Images: Tutorials, P1, DOI 10.1109/SIBGRAPI-T.2011.9
   Porter F., 2013, STAT ANAL TECHNIQUES
   Rizo D, 2011, J NEW MUSIC RES, V40, P313, DOI 10.1080/09298215.2011.615407
   Shen JL, 2006, IEEE T MULTIMEDIA, V8, P1179, DOI 10.1109/TMM.2006.884618
   Silla CN, 2008, IEEE INT SYM MULTIM, P39, DOI 10.1109/ISM.2008.54
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang L, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 5, PROCEEDINGS, P580, DOI 10.1109/ICNC.2008.815
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
   Zwicker E., 2013, PSYCHOACOUSTICS FACT
NR 34
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6165
EP 6189
DI 10.1007/s11042-017-4524-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800048
DA 2024-07-18
ER

PT J
AU Ghasemzadeh, H
   Arjmandi, MK
AF Ghasemzadeh, Hamzeh
   Arjmandi, Meisam K.
TI Optimum solution and evaluation of rectangular jigsaw puzzles based on
   branch and bound method and combinatorial accuracy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rectangular jigsaw puzzle; Branch and bound (B&B); Minimum weight
   arborescence; Edmond algorithm; Performance criteria; Mean opinion score
   (MOS)
AB Automatic solution of rectangular jigsaw puzzles can be broken down into two separate steps of calculating pairwise compatibility metrics and jigsaw assembling algorithm. This work discriminates between two different sources of errors, each corresponding to one of these two steps. In this regard, type I error is defined as the imperfection of the used compatibility metric, and type II error is reserved to measure the imperfection of jigsaw assembling algorithm. Differentiating between these two types of error allows us to tweak and optimize different parts of the algorithm to achieve the best performance. Based upon these defined terms, this study argues that current jigsaw assembling algorithms mainly rely on either greedy methods or metaheuristic algorithms, which may impose a considerable amount of type II error to the final solution. This paper demonstrates that a powerful and perfect (i.e., type II error-free) jigsaw assembling algorithm is achievable by combining branch and bound technique with graph theory. This perfect jigsaw assembling algorithm is then utilized to measure the performances of various compatibility metrics and color models. The superiority of red-green-blue (RGB) color model and Mahalanobis gradient compatibility (MGC) metric in solving rectangular jigsaw puzzles is shown by providing conclusive evidence. Additionally, a mean opinion score (MOS) test is conducted to examine the accuracy of the existing metrics. According to the results from MOS test, we argue that the existing performance criteria are not concise and accurate; thus, a new accuracy metric is proposed on the basis of comparing different sub-blocks of solutions. Finally, the efficiency of jigsaw assembling algorithm is measured by proposing a new performance criterion.
C1 [Ghasemzadeh, Hamzeh; Arjmandi, Meisam K.] Michigan State Univ, Dept Commun Sci & Disorders, E Lansing, MI 48824 USA.
   [Ghasemzadeh, Hamzeh] Michigan State Univ, Dept Computat Math Sci & Engn, E Lansing, MI 48824 USA.
C3 Michigan State University; Michigan State University
RP Ghasemzadeh, H (corresponding author), Michigan State Univ, Dept Commun Sci & Disorders, E Lansing, MI 48824 USA.; Ghasemzadeh, H (corresponding author), Michigan State Univ, Dept Computat Math Sci & Engn, E Lansing, MI 48824 USA.
EM hamzeh_g62@yahoo.com
RI Arjmandi, Meisam/IUO-5484-2023; ghasemzadeh, hamzeh/P-1424-2018
OI Arjmandi, Meisam/0000-0002-4368-9106; ghasemzadeh,
   hamzeh/0000-0001-5395-1908
CR Abdi H., 2007, Encyclopedia of measurement and statistics, P508, DOI DOI 10.4135/9781412952644.N239
   Adler J, 2010, CYTOM PART A, V77A, P733, DOI 10.1002/cyto.a.20896
   [Anonymous], 2012, Methodology for the subjective assessment of the quality of television pictures
   [Anonymous], MOBILE COMPUTING IEE
   [Anonymous], COMPUTATIONAL METHOD
   Arjmandi MK, 2011, J VOICE, V25, pE275, DOI 10.1016/j.jvoice.2010.08.003
   Brown BJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360683
   CHO TS, 2010, PROC CVPR IEEE, P183, DOI DOI 10.1109/CVPR.2010.5540212
   CHU YJ, 1965, SCI SINICA, V14, P1396
   Chun-Wei Tsai, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P1698, DOI 10.1109/ICMLC.2012.6359630
   Chung MG, 1998, ICSP '98: 1998 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PROCEEDINGS, VOLS I AND II, P877, DOI 10.1109/ICOSP.1998.770751
   Clausen J, 1999, Branch and bound algorithms-principles and examples, P1
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Farn EJ, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3067, DOI 10.1109/ICMLC.2008.4620935
   Farn EJ, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3073979
   Fournier J-C, 2010, GRAPHS THEORY APPL E, V72
   FREEMAN H, 1964, IEEE T COMPUT, VEC13, P118, DOI 10.1109/PGEC.1964.263781
   Gallagher AC, 2012, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2012.6247699
   Ghasemzadeh H, 2017, ISC INT J I IN PRESS
   Ghasemzadeh H, 2016, DIGIT SIGNAL PROCESS, V51, P133, DOI 10.1016/j.dsp.2015.12.015
   Ghasemzadeh H, 2015, 2015 SIGNAL PROCESSING AND INTELLIGENT SYSTEMS CONFERENCE (SPIS), P143, DOI 10.1109/SPIS.2015.7422329
   Ghasemzadeh H, 2015, BIOMED SIGNAL PROCES, V22, P135, DOI 10.1016/j.bspc.2015.07.002
   Ghasemzadeh H, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P194, DOI 10.1109/ICCKE.2014.6993428
   Koller D, 2006, B COMMISSIONE ARCHEO, P2
   Lin HY, 2012, EXPERT SYST APPL, V39, P3324, DOI 10.1016/j.eswa.2011.09.019
   Logeswaran L, 2014, P BRIT MACH VIS C BM
   Makridis M, 2010, IEEE T SYST MAN CY B, V40, P789, DOI 10.1109/TSMCB.2009.2029868
   Murakami T, 2008, INT C PATT RECOG, P518
   Olmos A, 2011, MCGILL CALIBRATED CO
   Pomeranz D, 2011, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2011.5995331
   Russell S., 1995, Prentice Hall series in artificial intelligence, V25, P27
   Sagiroglu MS, 2010, TOP, V18, P321, DOI 10.1007/s11750-010-0156-6
   Sholomon D, 2016, GENET PROGRAM EVOL M, P1
   Son K, 2016, PROC CVPR IEEE, P1193, DOI 10.1109/CVPR.2016.134
   Toyama F, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1047477
   Weiss-Cohen M, 2006, International Conference on Computational Intelligence for Modelling, Control & Automation Jointly with International Conference on Intelligent Agents, Web Technologies & Internet Commerce, Vol 2, Proceedings, P379
   YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z
NR 37
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6837
EP 6861
DI 10.1007/s11042-017-4601-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700018
DA 2024-07-18
ER

PT J
AU He, XL
   Jiang, H
   Song, Y
AF He, Xiaoli
   Jiang, Hong
   Song, Yu
TI Spectrum access strategy for cognitive wireless networks sensing part of
   channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive wireless network; Channel optimization; Spectrum sensing;
   Optimal algorithm; Channel throughput
ID RADIO NETWORKS; ALGORITHM
AB To effectively balance contradiction between sensing time of access channel and total throughput of channel in secondary user system of cognitive wireless network, a kind of spectrum access strategy sensing part of channels is proposed. The Thesis, based on algorithm proposed through single secondary user carrying out transmission on multiple channels of master user at the same time, takes total throughout of channel as objective function; on one hand, it is related to transmission rate, on the other hand, it is related to selection of sensing time and sensing channel. The algorithm assumes secondary user detects channel through perception in order and chooses certain suitable channel by using optimum stopping theory to perceive. It avoids sensing all channels, meanwhile, the throughput is greater. Through comparison with simulation analysis of HC-MAC (Hardware-constrained Cognitive MAC) algorithm, the algorithm avoids sensing all channels and lowers expenditure, meanwhile, the throughput is greater, which make it obtain obvious advantage on performance.
C1 [He, Xiaoli; Jiang, Hong; Song, Yu] South West Univ Sci & Technol, Sch Informat Engn, 59 Middle Sect Fucheng Dist, Mianyang City, Sichuan, Peoples R China.
   [He, Xiaoli; Jiang, Hong; Song, Yu] Sichuan Univ Sci & Engn, Sch Comp Sci, Zigong, Peoples R China.
C3 Southwest University of Science & Technology - China; Sichuan University
   of Science & Engineering
RP He, XL (corresponding author), South West Univ Sci & Technol, Sch Informat Engn, 59 Middle Sect Fucheng Dist, Mianyang City, Sichuan, Peoples R China.; He, XL (corresponding author), Sichuan Univ Sci & Engn, Sch Comp Sci, Zigong, Peoples R China.
EM hexiaolils1@hotmail.com
FU National Natural Science Foundation of China [61379005]; Key base of
   tourism and scientific research of Sichuan Provincial Tourism
   Administration [ZHZ16-02, ZHY15-04]; Key Laboratory of Higher Education
   of Sichuan Province for Enterprise Informationalization and Internet of
   Things [2014WYY03, 2014WYY02]; Artificial Intelligence Key Laboratory of
   Sichuan Province [2014RYY02]
FX This work is supported in part by National Natural Science Foundation of
   China(No. 61379005), 2016 Key base of tourism and scientific research of
   Sichuan Provincial Tourism Administration(NO. ZHZ16-02), 2014 Key
   Laboratory of Higher Education of Sichuan Province for Enterprise
   Informationalization and Internet of Things(No. 2014WYY03), 2014
   Artificial Intelligence Key Laboratory of Sichuan Province(No.
   2014RYY02), 2015 Key base of tourism and scientific research of Sichuan
   Provincial Tourism Administration(NO. ZHY15-04), and 2014 Key Laboratory
   of Higher Education of Sichuan Province for Enterprise
   Informationalization and Internet of Things (No. 2014WYY02).
CR [Anonymous], BIOMED RES INT, DOI DOI 10.1371/J0URNAL.PPAT.1005243
   Cao XH, 2015, IEEE T WIREL COMMUN, V14, P2058, DOI 10.1109/TWC.2014.2379642
   Cheng N, 2014, IEEE T VEH TECHNOL, V63, P237, DOI 10.1109/TVT.2013.2274201
   Derakhshani M, 2014, IEEE T VEH TECHNOL, V63, P3715, DOI 10.1109/TVT.2014.2309120
   Gupta N., 2016, IEEE T COGN COMMUN, V2, P370, DOI [10.1109/TCCN.2016.2621750, DOI 10.1109/TCCN.2016.2621750]
   Hess A., 2016, IEEE Transactions on Cognitive Communications and Networking., V2, P381
   Jiang DD, 2015, COMPUT NETW, V84, P1, DOI 10.1016/j.comnet.2015.04.003
   Jondral F. K., 2005, EURASIP Journal on Wireless Communications and Networking, V2005, P275, DOI 10.1155/WCN.2005.275
   Li F, 2015, WIREL NETW, V21, P161, DOI 10.1007/s11276-014-0775-1
   Syed AR, 2016, IEEE ACCESS, V4, P6304, DOI 10.1109/ACCESS.2016.2613122
   Tan XB, 2014, IET COMMUN, V8, P689, DOI 10.1049/iet-com.2013.0696
   Wang HX, 2016, IEEE J SEL AREA COMM, V34, P2866, DOI 10.1109/JSAC.2016.2615262
   Yang C, 2014, NEUROCOMPUTING, V125, P33, DOI 10.1016/j.neucom.2012.07.041
   Zhang L, 2016, WIRELESS PERS COMMUN, V87, P1383, DOI 10.1007/s11277-015-3067-x
   Zhang N, 2014, IEEE J SEL AREA COMM, V32, P516, DOI 10.1109/JSAC.2014.1403004
   Zhang WJ, 2015, WIREL COMMUN MOB COM, V15, P100, DOI 10.1002/wcm.2319
   Zhang YL, 2014, KSII T INTERNET INF, V8, P2675, DOI 10.3837/tiis.2014.08.006
   Zhao Y, 2014, IEICE T COMMUN, VE97B, P334, DOI 10.1587/transcom.E97.B.334
NR 18
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7703
EP 7716
DI 10.1007/s11042-017-4671-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700057
DA 2024-07-18
ER

PT J
AU Hu, CY
   Hu, BJ
   Tu, WQ
   Xiong, YH
AF Hu, Chunyun
   Hu, Binjie
   Tu, Wanqing
   Xiong, Yunhui
TI A low-complexity and efficient encoder rate control solution for
   distributed residual video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed residual video coding (DRVC); Encoder rate control (ERC);
   Encoder block mode decision (EBMD); Low-complexity encoder;
   Pseudo-random sequence scrambling
ID SIDE INFORMATION; MODE SELECTION; ALGORITHM
AB Existing encoder rate control (ERC) solutions have two technical limitations that prevent them from being widely used in real-world applications. One is that encoder side information (ESI) is required to be generated which increases the complexity at the encoder. The other is that rate estimation is performed at bit plane level which incurs computation overheads and latency when many bit planes exist. To achieve a low-complexity encoder, we propose a new ERC solution that combines an efficient encoder block mode decision (EBMD) for the distributed residual video coding (DRVC). The main contributions of this paper are as follows: 1) ESI is not required as our ERC is based on the analysis of the statistical characteristics of the decoder side information (DSI); 2) a simple EBMD is introduced which only employs the values of residual pixels at the encoder to classify blocks into Intra mode, Skip mode, and WZ mode; 3) an ERC solution using pseudo-random sequence scrambling is proposed to estimate rates for all WZ blocks at frame level instead of at bit plane level, i.e., only one rate is estimated; and 4) a quantization-index estimation algorithm (QIEA) is proposed to solve the problem of rate underestimation. The simulation results show that the proposed solution is not only low complex but also efficient in both the block mode decision and the rate estimation. Also, as compared to DISCOVER system and the state-of-the-art ERC solution, our solution demonstrates a competitive rate-distortion(RD)performance. Due to maintain the low-complexity nature of the encoder and have good RD performance, we believe that our ERC solution is promising in practice.
C1 [Hu, Chunyun] South China Agr Univ, Coll Elect & Engn, Guangzhou, Guangdong, Peoples R China.
   [Hu, Chunyun; Hu, Binjie] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Tu, Wanqing] Robert Gordon Univ, Sch Comp Sci & Digital Media, Aberdeen, Scotland.
   [Xiong, Yunhui] South China Univ Technol, Sch Math, Guangzhou, Guangdong, Peoples R China.
C3 South China Agricultural University; South China University of
   Technology; Robert Gordon University; South China University of
   Technology
RP Xiong, YH (corresponding author), South China Univ Technol, Sch Math, Guangzhou, Guangdong, Peoples R China.
EM hcy2182@scau.edu.cn; eebjiehu@scut.edu.cn; w.tu@rgu.ac.uk;
   yhxiong@scut.edu.cn
OI Tu, Wanqing/0000-0002-0849-6392
FU Ministry of Industry and Information Technology of Things special fund
   [[2014]351]; SRF for ROCS, SEM; National Natural Science Foundation of
   China [61302055]; EPSRC [EP/J017159/2] Funding Source: UKRI
FX This work is supported by the Ministry of Industry and Information
   Technology of Things special fund([2014]351), the National Natural
   Science Foundation of China (No.61302055), and the Project sponsored by
   SRF for ROCS, SEM.
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Aaron A, 2002, CONF REC ASILOMAR C, P240
   Aaron A., 2006, P INT PICT COD S APR, P1
   Ascenso J, 2009, IEEE INT CON MULTI, P101, DOI 10.1109/ICME.2009.5202446
   Brites Catarina, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P5
   Brites C, 2011, IEEE T CIRC SYST VID, V21, P1278, DOI 10.1109/TCSVT.2011.2147210
   Chiang JC, 2010, BLOCK BASED DISTRIBU
   Clerckx T, 2007, 14 IEEE INT C IM PRO, V6, DOI 10.1109/ICIP.2007.4379610
   Du B, 2009, ENCODER RATE CONTROL
   HoangVan X, 2012, IEEE T BROADCAST, V58, P209, DOI 10.1109/TBC.2012.2187611
   Huchet G., 2010, P IEEE INT S BROADB, P1, DOI DOI 10.1109/ISBMSB.2010.5463126
   Luong HV, 2014, IEEE T IMAGE PROCESS, V23, P2804, DOI 10.1109/TIP.2014.2320364
   Ji W, 2014, IEEE T CIRC SYST VID, V24, P141, DOI 10.1109/TCSVT.2013.2276535
   Liu LM, 2008, IEEE IMAGE PROC, P1136
   Liu WH, 2013, IET WIREL SENS SYST, V3, P205, DOI 10.1049/iet-wss.2012.0115
   Morbée M, 2007, INT CONF ACOUST SPEE, P521
   Morbée M, 2007, LECT NOTES COMPUT SC, V4678, P663
   Natário L, 2006, LECT NOTES COMPUT SC, V3893, P16
   Qiu GF, 2013, INT CONF DIGIT SIG
   Sheng T, 2010, MULTIMEDIA SYST, V16, P127, DOI 10.1007/s00530-009-0179-8
   Skorupa J, 2012, IEEE T CIRC SYST VID, V22, P530, DOI 10.1109/TCSVT.2011.2168289
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tagliasacchi M, 2006, 2006 IEEE INT C AC S, V2
   [唐振华 Tang Zhenhua], 2015, [电子学报, Acta Electronica Sinica], V43, P365
   Wang Y, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1089
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yang HP, 2015, 2015 28TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P111, DOI 10.1109/SOCC.2015.7406923
   Zhang Deng-yin, 2014, Journal of China Universities of Posts and Telecommunications, V21, P109, DOI 10.1016/S1005-8885(14)60276-4
   Zhang YS, 2011, IEEE T CIRC SYST VID, V21, P1100, DOI 10.1109/TCSVT.2011.2133830
NR 29
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5713
EP 5735
DI 10.1007/s11042-017-4484-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800026
DA 2024-07-18
ER

PT J
AU Simic, N
   Peric, ZH
   Savic, MS
AF Simic, Nikola
   Peric, Zoran H.
   Savic, Milan S.
TI Image coding algorithm based on Hadamard transform and simple vector
   quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Hadamard transform; Vector quantization; Scalar
   quantization
ID MANY-CORE PROCESSORS; LOSSLESS COMPRESSION; PARALLEL FRAMEWORK; MRI
   IMAGES; PREDICTION; HEVC
AB Transform coding is commonly used in image processing algorithms to provide high compression ratios, often at the expense of processing time and simplicity of the system. We have recently proposed a pixel value prediction scheme in order to exploit adjacent pixel correlation, providing a low-complexity model for image coding. However, the proposed model was unable to reach high compression ratios retaining high quality of reconstructed image at the same time. In this paper we propose a new segmentation algorithm which further utilizes adjacent pixel correlation, provides higher compression ratios and it is based on application of Hadamard transform coding. Additional compression is provided by using vector quantization for a low number of quantization levels and by simplifying generalized Lloyd's algorithm where the special attention is paid to determination of optimal partitions for vector quantization, making a fixed quantizer. The proposed method is quite simple and experimental results show that it ensures better or similar rate-distortion ratio for very low bit-rates, comparing to the other similar methods that are based on wavelet or curvelet transform coding and support or core vector machine application. Furthermore, the proposed method requires very low processing time since the proposed quantizers are fixed, much less than the required time for the aforementioned methods that we compare with as well as much less than the time required for fractal image coding. In the end, the appropriate discussion is provided comparing the results with a scheme based on linear prediction and dual-mode quantization.
C1 [Simic, Nikola; Peric, Zoran H.] Univ Nis, Fac Elect Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.
   [Savic, Milan S.] Univ Pristina, Fac Nat Sci & Math, Ive Lole Ribara 29, Kosovska Mitrovica 38220, Serbia.
C3 University of Nis; Universiteti i Prishtines
RP Simic, N (corresponding author), Univ Nis, Fac Elect Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.
EM simicnikola90@gmail.com; zoran.peric@elfak.ni.ac.rs;
   malimuzicar@gmail.com
RI Simic, Nikola/ACU-2326-2022
OI Simic, Nikola/0000-0002-0748-4672; Peric, Zoran/0000-0002-8267-9541;
   Savic, Milan/0000-0002-7692-001X
FU Serbian Ministry of Education, Science and Technological Development
   [TR32035]; Serbian Ministry of Education and Science through
   Mathematical Institute of Serbian Academy of Sciences and Arts
   [III44006]
FX This work is supported by Serbian Ministry of Education and Science
   through Mathematical Institute of Serbian Academy of Sciences and Arts
   (Project III44006) and by Serbian Ministry of Education, Science and
   Technological Development (Project TR32035).
CR [Anonymous], 2006, Introduction to Data Compression
   Anusuya V, 2014, J DIGIT IMAGING, V27, P594, DOI 10.1007/s10278-014-9697-9
   Berrouche Y, 2014, AEU-INT J ELECTRON C, V68, P976, DOI 10.1016/j.aeue.2014.04.021
   Chiranjeevi K, 2018, AIN SHAMS ENG J, V9, P1417, DOI 10.1016/j.asej.2016.09.009
   Djordjevic IB, 2013, PHOTONICS J IEEE, V5
   Gersho A., 2003, Vector Quantization and Signal Compression
   Haykin S. S., 2009, NEURAL NETWORKS LEAR
   Horng MH, 2012, EXPERT SYST APPL, V39, P1078, DOI 10.1016/j.eswa.2011.07.108
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Jovanovic AZ, 2011, INFORM SCIENCES, V181, P3043, DOI 10.1016/j.ins.2011.03.012
   Karimi N, 2015, MULTIMED TOOLS APPL, V74, P11007, DOI 10.1007/s11042-014-2214-9
   Kekre H. B., 2010, INT J COMPUT SCI INF, V7, P159
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Li YC, 2013, OPTIK, V124, P4859, DOI 10.1016/j.ijleo.2013.02.027
   Li YC, 2010, EXPERT SYST APPL, V37, P3063, DOI 10.1016/j.eswa.2009.09.024
   Li ZY, 2015, VISUAL COMPUT, V31, P1633, DOI 10.1007/s00371-014-1044-0
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Pakdaman Z, 2017, MULTIMED TOOLS APPL, V76, P8517, DOI 10.1007/s11042-016-3490-3
   Raman R, 2018, MULTIMED TOOLS APPL, V77, P741, DOI 10.1007/s11042-016-4234-0
   Rebollo-Monedero D, 2013, INFORM SCIENCES, V222, P185, DOI 10.1016/j.ins.2012.08.022
   Savic MS, 2015, EXPERT SYST APPL, V42, P7285, DOI 10.1016/j.eswa.2015.05.037
   Savic MS, 2012, INFORMATICA-LITHUAN, V23, P125
   Sim HM, 2014, EXPERT SYST APPL, V41, P5390, DOI 10.1016/j.eswa.2014.02.051
   Song XY, 2016, J DIGIT IMAGING, V29, P706, DOI 10.1007/s10278-016-9892-y
   Sun J, 2014, OPTIK, V125, P2356, DOI 10.1016/j.ijleo.2013.10.068
   Wang XY, 2014, NONLINEAR DYNAM, V75, P439, DOI 10.1007/s11071-013-1076-4
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 30
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6033
EP 6049
DI 10.1007/s11042-017-4513-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800041
DA 2024-07-18
ER

PT J
AU Tong, M
   Tian, WJ
   Wang, HY
   Wang, F
AF Tong, Ming
   Tian, Weijuan
   Wang, Houyi
   Wang, Fan
TI A compact discriminant hierarchical clustering approach for action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Hierarchical clustering; Discriminant constraint;
   Support Vector Machines; Mid-level semantics; Cluster analysis
ID MOTION; REPRESENTATION; TRANSFORM; LOCATION; FEATURES; VECTOR; PARTS
AB In order to improve the accuracy of action recognition, a compact discriminant hierarchical clustering approach and an action recognition new framework are respectively proposed. Firstly, on the bases of low-level features 3D Self-Correlation Histogram of Oriented Gradient in Trajectory (3D_SCHOGT) and 3D Self-Correlation Histogram of Oriented Optical Flow in Trajectory (3D_SCHOOFT), the mid-level semantics possessing purity, representativeness and discriminativeness simultaneously are obtained using the proposed compact discriminant hierarchical clustering approach, in which removal of singularities, quantitative evaluations of purity, representativeness and discriminativeness, as well as additive constraint of information entropies for clusters are conducted respectively to assure the better purity, representativeness and discriminativeness. Secondly, by introducing category constraint, a discriminant classification model of Category Constraint Latent Support Vector Machines (CC-LSVM) is proposed, which enhances the discriminative ability of classifier. Finally, to further improve the accuracy of action recognition, a new framework is proposed, which introduces low-level features, mid-level semantics and mid-level semantic self-correlation features into the proposed CC-LSVM classifier in a weighted association way, makes full use of category information of actions, and mines the correlations between multi-semantic features and action categories. Consequently, the action recognition accuracy is improved. The accuracies on Weizmann, KTH, UCF-Sports and YouTube datasets are 100%, 98.83%, 98.67% and 90.73% respectively, which outperform all those in contrastive methods. Experiments demonstrate the effectiveness of proposed compact discriminant hierarchical clustering approach and new framework.
C1 [Tong, Ming; Tian, Weijuan; Wang, Houyi; Wang, Fan] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Tong, M (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM mtong@xidian.edu.cn; stayrealtian501@163.com; wanghouyi_why@163.com;
   zhixiaotianzhuo@163.com
RI Tian, Weijuan/ABC-3902-2021
FU National Natural Science Foundation of China [61072110]; Science and
   Technology Overall Innovation Project of Shaanxi Province
   [2013KTZB03-03-03]; Industrial Research Project of Shaanxi Province
   [2015GY011]; International Cooperation Project of Shaanxi Province
   [2015KW-004, 2016KW-042]
FX This work was supported by National Natural Science Foundation of China
   [No. 61072110]; Science and Technology Overall Innovation Project of
   Shaanxi Province [2013KTZB03-03-03]; Industrial Research Project of
   Shaanxi Province [2015GY011]; International Cooperation Project of
   Shaanxi Province [2015KW-004]; International Cooperation Project of
   Shaanxi Province [2016KW-042].
CR [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], THESIS
   [Anonymous], P IND C COMP VIS GRA
   [Anonymous], BMVC
   Bajcsy P, 1998, IEEE T PATTERN ANAL, V20, P1011, DOI 10.1109/34.713365
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Byrne J, 2015, PROC CVPR IEEE, P502, DOI 10.1109/CVPR.2015.7298648
   Cao XQ, 2015, IEEE T FUZZY SYST, V23, P1581, DOI 10.1109/TFUZZ.2014.2370678
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chatzis SP, 2015, IEEE I CONF COMP VIS, P2803, DOI 10.1109/ICCV.2015.321
   Cho J, 2014, PATTERN RECOGN, V47, P1813, DOI 10.1016/j.patcog.2013.12.004
   Das S, 2008, IEEE T SYST MAN CY A, V38, P218, DOI 10.1109/TSMCA.2007.909595
   Derpanis KG, 2013, IEEE T PATTERN ANAL, V35, P527, DOI 10.1109/TPAMI.2012.141
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Goudelis G, 2013, PATTERN RECOGN, V46, P3238, DOI 10.1016/j.patcog.2013.06.006
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hsu YP, 2016, PATTERN RECOGN, V60, P215, DOI 10.1016/j.patcog.2016.05.010
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Lan T, 2015, IEEE I CONF COMP VIS, P4552, DOI 10.1109/ICCV.2015.517
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li LJ, 2016, ADV COMPUT VIS PATT, P41, DOI 10.1007/978-3-319-25781-5_3
   Liu JE, 2012, COMPUT VIS IMAGE UND, V116, P361, DOI 10.1016/j.cviu.2011.08.010
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu L, 2014, PATTERN RECOGN, V47, P3819, DOI 10.1016/j.patcog.2014.07.006
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Narayan S, 2014, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2014.337
   Nasiri JA, 2014, SIGNAL PROCESS, V104, P248, DOI [10.1016/j.sigpro.2014.04.010, 10.1016/j.sigpro.2014.04,010]
   Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P77, DOI 10.1109/TCSVT.2014.2333151
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Pei LS, 2015, MULTIMED TOOLS APPL, V74, P10801, DOI 10.1007/s11042-014-2207-8
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Rodriguez M., 2008, P IEEE C COMPUTER VI
   Sapienza M, 2014, INT J COMPUT VISION, V110, P30, DOI 10.1007/s11263-013-0662-8
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang HR, 2014, IEEE T IMAGE PROCESS, V23, P570, DOI 10.1109/TIP.2013.2292550
   Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Wang X, 2016, IEEE IMAGE PROC, P236, DOI 10.1109/ICIP.2016.7532354
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Xinggang Wang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P829, DOI 10.1007/978-3-319-27671-7_69
   Yang XD, 2014, LECT NOTES COMPUT SC, V8690, P727, DOI 10.1007/978-3-319-10605-2_47
   Yang YH, 2016, SIGNAL PROCESS, V124, P36, DOI 10.1016/j.sigpro.2015.10.035
   Yi Y, 2016, PATTERN RECOGN, V53, P148, DOI 10.1016/j.patcog.2015.11.022
   Yi Y, 2013, SIGNAL PROCESS, V93, P2932, DOI 10.1016/j.sigpro.2013.05.002
   Yu H, 2014, INT J APPROX REASON, V55, P101, DOI 10.1016/j.ijar.2013.03.018
   Yuan CF, 2013, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2013.99
   Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhou W, 2014, SIGNAL PROCESS-IMAGE, V29, P546, DOI 10.1016/j.image.2014.01.012
   Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442
NR 68
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7539
EP 7564
DI 10.1007/s11042-017-4660-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700051
DA 2024-07-18
ER

PT J
AU Wang, FH
   Ma, YH
   Jin, YJ
   Jiang, Y
   Wang, YY
AF Wang, Fenghua
   Ma, Yuhui
   Jin, Yanjuan
   Jiang, Ying
   Wang, Yunye
TI RETRACTED: Discovering Graphical Visual Features for Abnormal Semantic
   Event Detection (Retracted article. See vol. 79, pg. 6917, 2020)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Feature selection; manifold; unsupervised; graph clustering; abnormal
   detection
ID KERNEL
AB Intrusion detection systems play an important role in numerous industrial applications, such as network security and abnormal event detection. They effectively protect our critical computer systems or networks against the network attackers. Anomaly detection is an effective detection method, which can find patterns that do not meet a desired behavior. Mainstream anomaly detection system (ADS) typically depend on data mining techniques. That is, they recognize abnormal patterns and exceptions from a set of network data. Nevertheless, supervised or semi-supervised data mining techniques rely on data label information. This setup may be infeasible in real-world applications, especially when the network data is large-scale. To solve these problems, we propose a novel unsupervised and manifold-based feature selection algorithm, associated with a graph density search mechanism for detecting abnormal network behaviors. First, toward a succinct set of features to describe each network pattern, we realize that these pattern can be optimally described on manifold. Thus, a Laplacian score feature selection is developed to discover a set of descriptive features for each pattern, wherein the patterns' locality relationships are well preserved. Second, based on the refined features, a graph clustering method for network anomaly detection is proposed, by incorporating the patterns' distance and density properties simultaneously. Comprehensive experimental results show that our method can achieve higher detection accuracy as well as a significant efficiency improvement.
C1 [Wang, Fenghua; Ma, Yuhui; Jiang, Ying; Wang, Yunye] State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
   [Jin, Yanjuan] Hangzhou Dayou Sci & Technol Dev Co Ltd, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Wang, FH (corresponding author), State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
EM wang_fenghua@zj.sgcc.com; ma_yuhui@zj.sgcc.com; Jin_yanjuan@zj.sgcc.com;
   Jiang_ying@zj.sgcc.com; wang_yunye@zj.sgcc.com
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   BARBARA D., 2002, Applications of Data Mining in Computer Security
   Camacho J, 2014, IEEE CONF COMPUT, P500, DOI 10.1109/INFCOMW.2014.6849282
   Cao B, 2007, INT C MACH LEARN, P745
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Davis J. V., 2007, ICML, P209
   Duda RO, 1986, PATTERN CLASSIFICATI
   Egilmez HE, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853764
   Eskin E, 2002, APPL DATA MINING COM, P77, DOI [DOI 10.1007/978-1-4615-0953-04, DOI 10.1007/978-1-4615-0953-0_4]
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fukunaga K, 1990, INTRO STAT PATTERN R, P101
   Heady R., 1990, The Architecture of a Network Level Intrusion Detection System (No. LASUB93219)
   Hu W, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P712
   Huang SY, 2013, 2013 43 ANN IEEE IFI, P1, DOI DOI 10.1109/DSN.2013.6575338
   Jiang W, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 2, P326, DOI 10.1109/ISISE.2008.17
   Leibe B, 2003, PROC CVPR IEEE, P409
   Liu X, 2014, IEEE T NEUR IN PRESS
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Luo Y. B., 2013, FL LPVG APPROACH ANO
   Patcha A, 2007, COMPUT NETW, V51, P3448, DOI 10.1016/j.comnet.2007.02.001
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Roesch M, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRTEENTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XIII), P229
   Tenenbaum JB, 1998, NEURAL INFORM PROCES, P745
   Tong XJ, 2009, COMPUT PHYS COMMUN, V180, P1795, DOI 10.1016/j.cpc.2009.05.004
   Wang G, 2014, INT C MULT EXP ICME
   Xia YJ, 2015, NEUROCOMPUTING, V151, P700, DOI 10.1016/j.neucom.2014.05.091
   Xu L, 1993, INT C MACH LEARN, P745
   Yin Y, 2014, ACM T MULTI IN PRESS
   Zhang J, 2006, IEEE ICC, P2388
   Zhang L, 2014, ACM ICMR
   Zhang L, 2014, INF SCI, V254, P41
   Zhang L., 2013, IEEE T IP, V21, P803
   Zhang L, 2014, ACM MULTIME IN PRESS
   Zhang L, 2014, MULTIMEDIA SYSTEM, V12, P102
   Zhang L, 2014, IEEE T NEUR IN PRESS
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P40, DOI 10.1109/TMM.2014.2370257
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2012, INT C PATT RECOG, P2813
   Zhang LM, 2014, MULTIMEDIA SYST, V20, P659, DOI 10.1007/s00530-013-0317-1
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang Y, 2014, ACM T MULTIMEDIA COM
   Zhou Q., 2006, P 2006 INT C PRIVACY, V380, P67
NR 57
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3245
EP 3260
DI 10.1007/s11042-017-5057-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600018
DA 2024-07-18
ER

PT J
AU Wang, L
   Gong, XQ
   Zhang, YQ
   Xu, PF
   Chen, XJ
   Fang, DY
   Zheng, X
   Guo, J
AF Wang, Lei
   Gong, Xiaoqing
   Zhang, Yongqin
   Xu, Pengfei
   Chen, Xiaojiang
   Fang, Dingyi
   Zheng, Xia
   Guo, Jun
TI Artistic features extraction from chinese calligraphy works via regional
   guided filter with reference image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artistic features extraction; Chinese calligraphy; Reference images;
   Guided filter; Regional guided filter; Spirit
AB Chinese calligraphy is a unique visual art, and and is one of the material basis of China's traditional cultural heritage. However, time had caused the old calligraphy works to weathering and damages, so it is necessary to utilize advanced technologies to protect those works. One of those technologies is digital imaging, and the obtained images by digital imaging can preserve the visual information of calligraphy works better, furthermore, they can be used in further researches. While the basic works for those researches are to extract the artistic features which include two elements, i.e., form and spirit. However, most of the existing methods only extract the form and ignore the characters' spirit, especially they are insensitive to the slight variation in complex ink strokes. To solve these problems, this paper proposes an extraction method based on regional guided flter (RGF) with reference images, which is generated by KNN matting and used as the input image for RGF. Since RGF is sensitive to the slight variation of ink, so the detailed information of the inside of strokes can be detected better. Besides, unlike the past works, which filter the whole strokes, RGF filters the inside of strokes and edges in different windows respectively, which results in that the edges are preserved accurately. Results from a deployment of several famous Chinese calligraphy works demonstrate that our method can extract more accurate and complete form and spirit with lower error rate.
C1 [Wang, Lei; Gong, Xiaoqing; Zhang, Yongqin; Xu, Pengfei; Chen, Xiaojiang; Fang, Dingyi; Guo, Jun] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
   [Zheng, Xia] Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou, Zhejiang, Peoples R China.
C3 Northwest University Xi'an; Zhejiang University
RP Guo, J (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.; Zheng, X (corresponding author), Zhejiang Univ, Dept Culture Heritage & Museol, Hangzhou, Zhejiang, Peoples R China.
EM zhengxia@zju.edu.cn; guojun@nwu.edu.cn
FU National Natural Science Foundation of China [61202198]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016 JQ6068]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61202198), and Natural Science Basic Research Plan in
   Shaanxi Province of China (Grant No. 2016 JQ6068). The authors also
   gratefully acknowledge the helpful comments and suggestions of the
   reviewers.
CR [Anonymous], NEUROCOMPUTING
   [Anonymous], P 3 INT C MULT TECHN
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], CESKOSLOVENSK PEDIAT
   [Anonymous], INT J INF TECHNOL CO
   Cardoso A, 2013, NEUROCOMPUTING, V99, P575, DOI 10.1016/j.neucom.2012.07.027
   Chang X, 2016, IEEE T CYBERN, P1
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760
   Draper NormanRichard., 1966, APPL REGRESSION ANAL, V3
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Li W, 2014, NEUROCOMPUTING, V135, P299, DOI 10.1016/j.neucom.2013.12.013
   Lu WM, 2011, J ZHEJIANG U-SCI C, V12, P873, DOI 10.1631/jzus.C1100005
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Tan J, 2012, NEUROCOMPUTING, V89, P213, DOI 10.1016/j.neucom.2012.02.026
   Wen J, 2012, NEUROCOMPUTING, V86, P45, DOI 10.1016/j.neucom.2011.12.035
   Wong STS, 2006, IEEE IMAGE PROC, P397, DOI 10.1109/ICIP.2006.312477
   Yan-fei Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1670, DOI 10.1109/ICPR.2010.413
   YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1
   Zhang X., 2011, P 2011 WORKSHOP HIST, P37
   Zhang Yiquan., 2017, A deep Convolutional Neural Network for topology optimization with strong generalization ability
   Zheng X., 2015, MULTIMED TOOLS APPL, P1
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
   Zhuang Y, 2010, LECT NOTES COMPUT SC, V6184, P544, DOI 10.1007/978-3-642-14246-8_53
   Zhuang YT, 2009, J VIS COMMUN IMAGE R, V20, P84, DOI 10.1016/j.jvcir.2008.11.007
NR 31
TC 5
Z9 5
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 2973
EP 2990
DI 10.1007/s11042-017-4688-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600004
DA 2024-07-18
ER

PT J
AU Yan, JH
   Zhang, HX
   Sun, JD
   Wang, Q
   Guo, PL
   Meng, LL
   Wan, WB
   Dong, X
AF Yan, Jihong
   Zhang, Huaxiang
   Sun, Jiande
   Wang, Qiang
   Guo, Peilian
   Meng, Lili
   Wan, Wenbo
   Dong, Xiao
TI Joint graph regularization based modality-dependent cross-media
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Correlation analysis; Joint graph regularization
ID CANONICAL CORRELATION-ANALYSIS; MODEL
AB Cross-media retrieval returns heterogeneous multimedia data of the same semantics for a query object, and the key problem for cross-media retrieval is how to deal with the correlations of heterogeneous multimedia data. Many works focus on mapping different modal data into an isomorphic space, so the similarities between different modal data can be measured. Inspired by this idea, we propose a joint graph regularization based modality-dependent cross-media retrieval approach (JGRMDCR), which takes into account the one-to-one correspondence between different modal data pairs, the inter-modality similarities and the intra-modality similarities. Meanwhile, according to the modality of the query object, this method learns different projection matrices for different retrieval tasks. Experimental results on benchmark datasets show that the proposed approach outperforms the other state-of-the-art algorithms.
C1 [Yan, Jihong; Zhang, Huaxiang; Sun, Jiande; Wang, Qiang; Guo, Peilian; Meng, Lili; Wan, Wenbo; Dong, Xiao] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang; Sun, Jiande; Wang, Qiang; Guo, Peilian; Meng, Lili; Wan, Wenbo] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhang, HX; Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Zhang, HX; Sun, JD (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@163.com; jiandesun@hotmail.com
RI meng, li/GVT-2063-2022; meng, li/HTQ-7341-2023
FU National Natural Science Foundation of China [61373081, 61572298,
   61402268, 61401260, 61601268]; Key Research and Development Foundation
   of Shandong Province [2016GGX101009]; Natural Science Foundation of
   Shandong China [BS2014DX006, ZR2014FM012]; NVIDIA Corporation
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61373081, 61572298, 61402268, 61401260,
   61601268), the Key Research and Development Foundation of Shandong
   Province (No. 2016GGX101009) and the Natural Science Foundation of
   Shandong China (No. BS2014DX006, ZR2014FM012). We also gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   TITAN X GPU used for this research.
CR André B, 2012, IEEE T MED IMAGING, V31, P1276, DOI 10.1109/TMI.2012.2188301
   [Anonymous], 2003, P ACM INT C MULT ACM
   [Anonymous], 2015, P SIAM C DAT MIN
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Haiduc S, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P842, DOI 10.1109/ICSE.2013.6606630
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hong Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P759, DOI 10.1007/978-3-642-34778-8_71
   Hu PF, 2014, PATTERN RECOGN, V47, P1138, DOI 10.1016/j.patcog.2013.06.010
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lin WX, 2012, LECT NOTES COMPUT SC, V7131, P740
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Peng Y, 2015, IEEE T CIRC SYST VID, V26, P1
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rasiwasia N, 2014, CLUSTER CANONICAL CO, P823
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shehata S, 2013, KNOWL INF SYST, V35, P411, DOI 10.1007/s10115-012-0504-y
   Singha M, 2012, SIGNAL IMAGE PROCESS, V3, P271
   Song W, 2015, LECT NOTES ARTIF INT, V9362, P229, DOI 10.1007/978-3-319-25207-0_20
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Virtanen S., 2011, P 28 INT C INT C MAC, P457, DOI DOI 10.5555/3104482.3104540
   Vitola CPJ, 2013, S SIGN IM ART VIS, P1
   Wang Y, 2017, IEEE T INTELL TRANSP, V18, P2443, DOI 10.1109/TITS.2016.2644725
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang H, 2013, NEUROCOMPUTING, V119, P10, DOI 10.1016/j.neucom.2012.03.033
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
NR 34
TC 21
Z9 22
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3009
EP 3027
DI 10.1007/s11042-017-4918-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600006
DA 2024-07-18
ER

PT J
AU Zear, A
   Singh, AK
   Kumar, P
AF Zear, Aditi
   Singh, Amit Kumar
   Kumar, Pardeep
TI A proposed secure multiple watermarking technique based on DWT, DCT and
   SVD for application in medicine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; Discrete wavelet transforms; Discrete cosine transform;
   Singular value decomposition; Back propagation neural network;
   Healthcare
ID DISCRETE WAVELET TRANSFORM; DIFFERENTIAL EVOLUTION ALGORITHM;
   SINGULAR-VALUE DECOMPOSITION; IMAGE WATERMARKING; FRAGILE WATERMARKING;
   SCHEME; DOMAIN; NETWORKS; MASKING; ROBUST
AB In this paper, an algorithm for multiple watermarking based on discrete wavelet transforms (DWT), discrete cosine transform (DCT) and singular value decomposition (SVD) has been proposed for healthcare applications. For identity authentication purpose, the proposed method uses three watermarks in the form of medical Lump image watermark, the doctor signature/identification code and diagnostic information of the patient as the text watermarks. In order to improve the robustness performance of the image watermark, Back Propagation Neural Network (BPNN) is applied to the extracted image watermark to reduce the noise effects on the watermarked image. The security of the image watermark is also enhanced by using Arnold transform before embedding into the cover. Further, the symptom and signature text watermarks are also encoded by lossless arithmetic compression technique and Hamming error correction code respectively. The compressed and encoded text watermark is then embedded into the cover image. Experimental results are obtained by varying the gain factor, different sizes of text watermarks and the different cover image modalities. The results are provided to illustrate that the proposed method is able to withstand a different of signal processing attacks and has been found to be giving excellent performance for robustness, imperceptibility, capacity and security simultaneously. The robustness performance of the method is also compared with other reported techniques. Finally, the visual quality of the watermarked image is evaluated by the subjective method also. This shows that the visual quality of the watermarked images is acceptable for diagnosis at different gain factors. Therefore the proposed method may find potential application in prevention of patient identity theft in healthcare applications.
C1 [Zear, Aditi; Singh, Amit Kumar; Kumar, Pardeep] Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
C3 Jaypee University of Information Technology
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM aditizear93@gmail.com; amit_245singh@yahoo.com;
   pardeepkumarkhokhar@gmail.com
RI ; Singh, Amit Kumar/D-1300-2015
OI Kumar, Pardeep/0000-0001-5303-7219; Singh, Amit
   Kumar/0000-0001-7359-2068
CR Agbaje M, 2015, P INF SCI IT ED C IN, P1
   Ahmad R, 2008, IEEE VTS VEH TECHNOL, P1
   Ahmed KA, 2009, CURRENT TRENDS INFOR, P1
   Ahmidi N, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P709, DOI 10.1109/ITCC.2004.1286738
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   [Anonymous], BIOL CYBERN
   [Anonymous], DIGITAL IMAGE WATERM
   Aslantas V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P241, DOI 10.1109/ICME.2008.4607416
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Elmisery A. M., 2015, INT J DISTRIB SENS N, V2015, P1
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Mei SC, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2430
   Mohananthini N., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P100
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Niu YY, 2016, LECT NOTES ELECTR EN, V369, P303, DOI 10.1007/978-981-10-0072-0_39
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Parashar P., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P111, DOI DOI 10.14257/IJSIP.2014.7.6.10
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Priya R., 2014, Journal of Theoretical and Applied Information Technology, V65, P103
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qun-ting Yang, 2010, 2010 International Conference on Intelligent Computing and Integrated Systems (ICISS 2010), P71, DOI 10.1109/ICISS.2010.5655017
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, P318
   SINGH AK, 2016, HDB RES MODERN CRYPT, P246, DOI DOI 10.4018/978-1-5225-0105-3.CH011
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh R., 2015, INT J RES, V2, P1087
   Terry M, 2009, TELEMED J E-HEALTH, V15, P928, DOI 10.1089/tmj.2009.9932
   Vafaei M., 2013, World Appl. Sci. J, V22, P1572
   Wei ZC, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1117, DOI 10.1109/ICME.2006.262731
   Yen CT, 2016, MULTIMED TOOLS APPL, V75, P9745, DOI 10.1007/s11042-015-2718-y
   Zeng B, 1999, SIGNAL PROCESS, V79, P205, DOI 10.1016/S0165-1684(99)00094-8
NR 50
TC 175
Z9 179
U1 4
U2 136
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4863
EP 4882
DI 10.1007/s11042-016-3862-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500044
DA 2024-07-18
ER

PT J
AU Zhang, MW
   Gao, CQ
   Li, Q
   Wang, L
   Zhang, JY
AF Zhang, Minwen
   Gao, Chenqiang
   Li, Qiang
   Wang, Lan
   Zhang, Jiayao
TI Action detection based on tracklets with the two-stream CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action detection; Action classification; Object tracking
ID HISTOGRAMS; SALIENCY
AB Different from action recognition which just needs to assign correct labels to video clips, action detection aims to recognize and localize the action from an unknown video. While action recognition has made a good progress, action detection still remains a challenging task. Inspired by the success of object detection and action recognition based on the powerful Convolutional Neural Network (CNN), in this paper, a novel action detection method is proposed by embedding multiple object tracking into the action detection process. Firstly, we fine-tune the off-the-shelf faster-RCNN model to detect people in frames. Then, a simple tracking-by-detection algorithm is adopted to obtain tracklets for keeping temporal consistency. After that, we apply a temporal multi-scale sliding window strategy to each tracklet to generate the action proposal. Finally, the action proposal is further fed into a fully connected neural network to complete the classification task. Here, features of the action proposal are obtained by the two-stream CNN. Experiment results reveal that our method outperforms the state-of-the-art methods on J-HMDB and UCF sports action detection datasets.
C1 [Zhang, Minwen; Gao, Chenqiang; Li, Qiang; Wang, Lan; Zhang, Jiayao] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Zhang, MW (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
EM minwen.zhang@outlook.com
FU National Natural Science Foundation of China [61571071]; Wenfeng
   innovation and start-up project of Chongqing University of Posts and
   Telecommunications [WF201404]; Research Innovation Program for
   Postgraduate of Chongqing l [CYS17222]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61571071), Wenfeng innovation and start-up project of
   Chongqing University of Posts and Telecommunications (No. WF201404), the
   Research Innovation Program for Postgraduate of Chongqing (No.
   CYS17222). The authors also thank NVIDIA corporation for the donation of
   GeForce GTX TITAN X GPU.
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], P ACM INT C MULT RET
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gao CQ, 2016, NEUROCOMPUTING, V212, P36, DOI 10.1016/j.neucom.2016.05.094
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2010, IEEE EUROPEAN C COMP, V6553, P219
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rodriguez M. D., 2008, 2008 IEEE C COMPUTER, P1
   Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, PROC CVPR IEEE, P2708, DOI 10.1109/CVPR.2016.296
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yan Y, 2014, INT C PATT RECOG, P3493, DOI 10.1109/ICPR.2014.601
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 53
TC 14
Z9 16
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3303
EP 3316
DI 10.1007/s11042-017-5116-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600022
DA 2024-07-18
ER

PT J
AU Hoda, M
   Hoda, Y
   Hafidh, B
   El Saddik, A
AF Hoda, Mohamad
   Hoda, Yehya
   Hafidh, Basim
   El Saddik, Abdulmotaleb
TI Predicting muscle forces measurements from kinematics data using kinect
   in stroke rehabilitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Least-squares regression; Stroke rehabilitation; Kinect; Virtual reality
AB Muscle strength is mostly measured by wearable devices. However, wearing such devices is a tedious, unpleasant, and sometimes impossible task for stroke patients. In this paper, a mathematical model is proposed to estimate the strength of the upper limb muscles of a stroke patient by using Microsoft Kinect sensor. A prototype exergame is designed and developed to mimic real post-stroke rehabilitation exercises. Least-square regression matrix is used to find the relation between the kinematics of the upper limb and the strength of the corresponding muscles. Kinect sensor is used along with a force sensing resistors (FSR) glove and two straps to collect both, real-time upper limb joints data and the strength of muscles of the subjects while they are performing the exercises. The prototype of this system is tested on five stroke patients and eight healthy subjects. Results show that there is no statistically significant difference between the measured and the estimated values of the upper-limb muscles of the stroke patients. Thus, the proposed method is useful in estimating the strength of the muscles of stroke patient without the need to wear any devices.
C1 [Hoda, Mohamad; Hafidh, Basim; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, 800 King Edward, Ottawa, ON K1N 6N5, Canada.
   [Hoda, Yehya] Perpuim Care Polyclin, Doha, Qatar.
C3 University of Ottawa
RP Hoda, M (corresponding author), Univ Ottawa, Multimedia Commun Res Lab, 800 King Edward, Ottawa, ON K1N 6N5, Canada.
EM mhoda053@uottawa.ca; yehyahuda@hotmail.com; bhafi014@uottawa.ca;
   elsaddik@uottawa.ca
RI Hoda, Mohamad/AAW-6453-2020; /D-4159-2009
OI Hoda, Mohamad/0000-0003-3486-2648; /0000-0002-7690-8547
CR Amirabdollahian F, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-4
   [Anonymous], P 3 2015 WORKSH ICTS
   [Anonymous], REHABILITATION GRASP
   [Anonymous], IEEE T INSTRUMENTATI
   [Anonymous], WORLD HAPT C WORLD H
   [Anonymous], 2010, IBM SPSS STAT WIND V
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], MOBILE INFORM SYSTEM
   [Anonymous], 2013, P 2013 IEEE 13 INT C
   Cirstea MC, 2000, BRAIN, V123, P940, DOI 10.1093/brain/123.5.940
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   COHEN DB, 1994, AM J SPORT MED, V22, P746, DOI 10.1177/036354659402200604
   Ghatnekar O, 2013, HEALTH QUAL LIFE OUT, V11, DOI 10.1186/1477-7525-11-34
   Pham HT, 2015, MULTIMED TOOLS APPL, V74, P1125, DOI 10.1007/s11042-014-2103-2
   HOAGLIN DC, 1978, AM STAT, V32, P17, DOI 10.2307/2683469
   Hogan N., 1982, Proceedings of the 1982 American Control Conference, P522
   Kaiser V, 2012, STROKE, V43, P2735, DOI 10.1161/STROKEAHA.112.665489
   Krebs H.I., 2012, Am. J. Phys. Med. Rehabil, V91, P290, DOI [10.1097/PHM.0b013e31826bcd80, DOI 10.1097/PHM.0B013E31826BCD80]
   Lv ZH, 2016, NEUROCOMPUTING, V208, P290, DOI 10.1016/j.neucom.2015.12.128
   Lv ZH, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0475-8
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   LYLE RC, 1981, INT J REHABIL RES, V4, P483, DOI 10.1097/00004356-198112000-00001
   Nathan D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127113
   Obdrzálek S, 2012, IEEE ENG MED BIO, P1188, DOI 10.1109/EMBC.2012.6346149
   PEDEGANA LR, 1982, AM J SPORT MED, V10, P352, DOI 10.1177/036354658201000606
   Perry JC, 2007, IEEE-ASME T MECH, V12, P408, DOI 10.1109/TMECH.2007.901934
   Rahman MA, 2015, MULTIMED TOOLS APPL, V74, P5463, DOI 10.1007/s11042-014-1864-y
   Ramos-Murguialday A, 2013, ANN NEUROL, V74, P100, DOI 10.1002/ana.23879
   Stewart JC, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-27
   Su CH., 2015, Multimedia Tools Appl, V75, P1
   Takatsuru Y, 2013, J NEUROSCI, V33, P4683, DOI 10.1523/JNEUROSCI.2657-12.2013
   Tanaka K., 2012, Loading...The Journal of the Canadian Game Studies Association, V6, P69
   Webster D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-108
   Woldag H, 2002, J NEUROL, V249, P518, DOI 10.1007/s004150200058
   Xiao ZG, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-2
   Xu GZ, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/51035
   Ziai A, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-56
NR 37
TC 6
Z9 6
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1885
EP 1903
DI 10.1007/s11042-016-4274-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400019
DA 2024-07-18
ER

PT J
AU Huang, XL
   Ye, GD
AF Huang, Xiaoling
   Ye, Guodong
TI An image encryption algorithm based on irregular wave representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Irregular wave; Image encryption; 2D Logistic map; Security
ID SCHEME; MATRIX; CRYPTANALYSIS; OPERATION
AB For a gray image, every row (column) can be seen as an irregular wave. Activated by the architecture of permutation-diffusion based image encryption scheme, a chaotic image encryption algorithm is proposed to change the representation of irregular waves in the plain-image. To reduce the high correlation, permutation for both rows and columns is taken in the first stage. Due to the transposition of pixels in row/column, wave shapes will be changed according to the pseudo-random sequences generated from chaotic map. Specifically, pixels in each wave (row or column) are divided into two groups by energy (a bigger one and a smaller one). Then different groups are employed to manipulate the production of chaotic sequence. As a result, the chosen-plaintext and known-plaintext attacks will be difficult due to the plain-image dependent keystream. In the second stage, wave-by-wave diffusion in column is carried out such that any tiny change in the plain-image spreads out uniformly to the whole cipher-image. The keystream used in diffusion is designed again dependent on the permuted image obtained from the first stage. In this way, the security of the proposed algorithm can be further strengthened compared with some existing algorithms. Related security analyses also show that our method can satisfy common requirements of secure communication for daily images.
C1 [Huang, Xiaoling; Ye, Guodong] Guangdong Ocean Univ, Fac Math & Comp Sci, Zhanjiang 524088, Peoples R China.
   [Ye, Guodong] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Guangdong Ocean University; Zhejiang University
RP Ye, GD (corresponding author), Guangdong Ocean Univ, Fac Math & Comp Sci, Zhanjiang 524088, Peoples R China.; Ye, GD (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
EM guodongye@hotmail.com
RI Ye, Guodong/B-3322-2017
FU National Natural Science Foundations of China [61602124, 11526057,
   11301091]; Natural Science Foundations of Guangdong Province of China
   [2016A030310333, 2015A030313614, 2015A030313620]; Science & Technology
   Planning Projects of Zhanjiang City of China [2015B01098, 2015B01051];
   Program for Scientific Research Start-up Funds of Guangdong Ocean
   University of China; Special Funding Program for Excellent Young
   Scholars of Guangdong Ocean University
FX The work described in this paper was fully supported by the National
   Natural Science Foundations of China (No. 61602124, No. 11526057, No.
   11301091), the Natural Science Foundations of Guangdong Province of
   China (No. 2016A030310333, No. 2015A030313614, No. 2015A030313620), the
   Science & Technology Planning Projects of Zhanjiang City of China (No.
   2015B01098, No. 2015B01051), the Program for Scientific Research
   Start-up Funds of Guangdong Ocean University of China, and the Special
   Funding Program for Excellent Young Scholars of Guangdong Ocean
   University.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   CHIOU GH, 1989, IEEE T SOFTWARE ENG, V15, P929, DOI 10.1109/32.31350
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Özkaynak F, 2012, OPT COMMUN, V285, P4946, DOI 10.1016/j.optcom.2012.07.106
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Rostami MJ, 2016, IETE J RES, V62, P179, DOI 10.1080/03772063.2015.1081414
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2013, NONLINEAR DYNAM, V73, P795, DOI 10.1007/s11071-013-0832-9
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Yang YG, 2015, SCI REP-UK, V5, DOI 10.1038/srep07784
   Ye GD, 2014, APPL SOFT COMPUT, V22, P351, DOI 10.1016/j.asoc.2014.05.025
   Ye GD, 2010, FUND INFORM, V101, P321, DOI 10.3233/FI-2010-291
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 38
TC 22
Z9 22
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2611
EP 2628
DI 10.1007/s11042-017-4455-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400048
DA 2024-07-18
ER

PT J
AU Lei, T
   Zhang, YN
   Wang, Y
   Guo, Z
   Liu, SG
AF Lei, Tao
   Zhang, Yanning
   Wang, Yi
   Guo, Zhe
   Liu, Shigang
TI Adaptive Unsymmetrical Trim-Based Morphological Filter for High-Density
   Impulse Noise Removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector median filter (VMF); Morphological filter; color image
   processing; high-density impulse noise removal
ID THEORETICAL FOUNDATIONS; SWITCHING FILTER; VECTOR; REDUCTION
AB The modified decision-based unsymmetrical trimmed median filter (MDBUTMF), which is an efficient tool for restoring images corrupted with high-density impulse noise, is only effective for certain types of images. This is because the size of the selected window is fixed and some of the center pixels are replaced by a mean value of pixels in the window. To address these issues, this paper proposes an adaptive unsymmetrical trim-based morphological filter. Firstly, a strict extremum estimation approach is used, in order to decide whether the pixel to be processed belongs to a monochrome or non-monochrome area. Then, the center pixel is replaced by a median value of pixels in a window for the monochrome area. Secondly, a relaxed extremum estimation approach is used to control the size of structuring elements. Then an adaptive structuring element is obtained and the center pixel is replaced by the output of constrained morphological operators, i.e., the minimum or maximum of pixels in a trimmed structuring element. Our experimental results show that the proposed filter is more robust and practical than the MDBUTMF. Moreover, the proposed filter provides a preferable performance compared to the existing median filters and vector median filters for high-density impulse noise removal.
C1 [Lei, Tao] Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
   [Lei, Tao; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Wang, Yi; Guo, Zhe] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Liu, Shigang] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Shaanxi, Peoples R China.
C3 Shaanxi University of Science & Technology; Northwestern Polytechnical
   University; Northwestern Polytechnical University; Shaanxi Normal
   University
RP Lei, T (corresponding author), Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.; Lei, T (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM leitaoly@163.com
RI wang, yi/KBB-3614-2024; WU, SHAN/KGM-5484-2024
OI Wang, Yi/0000-0002-7743-1779
FU National Natural Science Foundation of China [61461025, 61672333,
   61402371, 61402274, 61202314]; Key Science and Technology Program of
   Shaanxi Province [2016GY-081]; Natural Science Basic Research Plan in
   Shaanxi Province of China [2015JM6317]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61461025, 61672333, 61402371, 61402274, 61202314), the
   Key Science and Technology Program of Shaanxi Province (Grant No.
   2016GY-081), and Natural Science Basic Research Plan in Shaanxi Province
   of China (Grant No. 2015JM6317).
CR Angulo J, 2013, SIAM J IMAGING SCI, V6, P1790, DOI 10.1137/110844258
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bins J, 2013, J MATH IMAGING VIS, V45, P293, DOI 10.1007/s10851-012-0354-y
   Bouaynaya N, 2008, IEEE T PATTERN ANAL, V30, P823, DOI 10.1109/TPAMI.2007.70754
   Bouaynaya N, 2008, IEEE T PATTERN ANAL, V30, P837, DOI 10.1109/TPAMI.2007.70756
   Bouaynaya N, 2012, IEEE T PATTERN ANAL, V34, P805, DOI 10.1109/TPAMI.2011.244
   Camarena JG, 2010, PATTERN RECOGN LETT, V31, P1842, DOI 10.1016/j.patrec.2010.01.008
   Celebi ME, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2991415
   Chen Y, 2016, IEEE T CIRC SYST VID, DOI [10.1109/TCSVT.2615444, DOI 10.1109/TCSVT.2615444]
   Chen Y, 2011, EUR J RADIOL, V80, pE42, DOI 10.1016/j.ejrad.2010.07.003
   Chen YK, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0109464, 10.1371/journal.pone.0086159, 10.1371/journal.pone.0096386, 10.1371/journal.pone.0109012, 10.1371/journal.pone.0094614]
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Geng X, 2012, SIGNAL PROCESS, V92, P150, DOI 10.1016/j.sigpro.2011.06.015
   Han WY, 1997, ELECTRON LETT, V33, P124, DOI 10.1049/el:19970106
   Jin LH, 2007, SIGNAL PROCESS, V87, P1345, DOI 10.1016/j.sigpro.2006.11.008
   Lei T, 2011, IET IMAGE PROCESS, V5, P1, DOI 10.1049/iet-ipr.2010.0135
   Liu S, 2011, IET IMAGE PROCESS, V5, P541, DOI 10.1049/iet-ipr.2009.0408
   Lucat L, 2002, SIGNAL PROCESS-IMAGE, V17, P509, DOI 10.1016/S0923-5965(02)00023-1
   Lukac R, 2004, EURASIP J APPL SIG P, V2004, P1870, DOI 10.1155/S1110865704312126
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Ma ZH, 2006, IEEE T IMAGE PROCESS, V15, P2324, DOI 10.1109/TIP.2006.877066
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   Nasimudeen A, 2012, SIGNAL IMAGE VIDEO P, V6, P613, DOI 10.1007/s11760-010-0189-1
   Pyatykh S, 2014, J VIS COMMUN IMAGE R, V25, P748, DOI 10.1016/j.jvcir.2014.02.001
   Ramamoorthy K., 2014, INT J COMP SCI MOBIL, V3, P97
   Ray N, 2005, IEEE T IMAGE PROCESS, V14, P1736, DOI 10.1109/TIP.2005.857251
   Salembier P, 2009, IEEE SIGNAL PROC MAG, V26, P136, DOI 10.1109/MSP.2009.934154
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2015, J REAL-TIME IMAGE PR, V10, P289, DOI 10.1007/s11554-012-0307-0
   Smolka B, 2010, PATTERN RECOGN LETT, V31, P484, DOI 10.1016/j.patrec.2009.09.012
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Wang GH, 2014, SIGNAL PROCESS, V102, P216, DOI 10.1016/j.sigpro.2014.03.027
   Wang W, 2011, IEEE SIGNAL PROC LET, V18, P551, DOI 10.1109/LSP.2011.2162583
   Xu JT, 2014, SIGNAL PROCESS, V98, P359, DOI 10.1016/j.sigpro.2013.11.035
NR 35
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 689
EP 711
DI 10.1007/s11042-016-4298-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400029
DA 2024-07-18
ER

PT J
AU Rashedi, E
   Nezamabadi-Pour, H
AF Rashedi, Esmat
   Nezamabadi-pour, Hossein
TI A hierarchical algorithm for vehicle license plate localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate localization; Cascade classifiers; Hierarchical algorithm;
   Texture features; Integral image
ID EFFICIENT METHOD; OBJECT DETECTION; RECOGNITION; LOCATION; IMAGES
AB Traffic car images suffer immensely from various degrading factors that make it hard to localize license plates. Each license plate localization (LPL) method has its own advantages and disadvantages to extract plates in the images under different circumstances. To have the benefits of different methods, our proposed solution is to employ a combination of four methods including a method based on cascade classifiers and local binary pattern (LBP) features, an edge-based method, a color-based method, and a contrast-based method. Considering the computational complexity, the methods are ordered on the basis of their chances for success. The order of the methods and the parameters are set experimentally in different conditions: day, night, and twilight. Furthermore, to find the plates rapidly, an algorithm is proposed to refine regions of interest (ROIs) and remove unwanted regions. The algorithm is applied in a real automated transport system for plate identification/recognition and tested with 4000 vehicle images taken from a three-lane dual carriageway with a central barrier in the different illumination situations with six cameras. The results are promising in a large database of moving car images. The car license plates have been correctly extracted in 3938 input images (98.45%). The results show that the proposed system is robust for moving cars in outdoor and under different illumination conditions.
C1 [Rashedi, Esmat] Grad Univ Adv technol, Dept Elect Engn, POB 76315-117, Kerman, Iran.
   [Nezamabadi-pour, Hossein] Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
C3 Graduate University of Advanced Technology; Shahid Bahonar University of
   Kerman (SBUK)
RP Rashedi, E (corresponding author), Grad Univ Adv technol, Dept Elect Engn, POB 76315-117, Kerman, Iran.
EM e.rashedi@kgut.ac.ir; nezam@uk.ac.ir
RI Rashedi, Esmat/AAZ-7069-2020; Nezamabadi-pour, Hossein/AAB-4009-2019
OI Nezamabadi-pour, Hossein/0000-0002-3350-7348; Rashedi,
   Esmat/0000-0002-2539-5817
CR Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   Al-Hmouz R, 2010, MACH VISION APPL, V21, P319, DOI 10.1007/s00138-008-0164-9
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   [Anonymous], IEEE T EVOL COMPUT
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Boggavarapu LNP, 2011, ADV INTEL SOFT COMPU, V95, P685
   Caner H, 2008, IEEE T VEH TECHNOL, V57, P2675, DOI 10.1109/TVT.2008.915524
   Chen ZX, 2009, IEEE T VEH TECHNOL, V58, P3781, DOI 10.1109/TVT.2009.2013139
   Dawei Du, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P347, DOI 10.1007/978-3-642-34778-8_32
   Deb K, 2012, PROC TECH, V4, P812, DOI 10.1016/j.protcy.2012.05.133
   Deb K, 2009, LECT NOTES ARTIF INT, V5579, P66, DOI 10.1007/978-3-642-02568-6_7
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Farajian N, 2014, 2014 INTERNATIONAL CONGRESS ON TECHNOLOGY, COMMUNICATION AND KNOWLEDGE (ICTCK)
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gou C, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P217, DOI 10.1109/SOLI.2014.6960724
   Guo JM, 2008, IEEE T VEH TECHNOL, V57, P1417, DOI 10.1109/TVT.2007.909284
   Jiao JB, 2009, PATTERN RECOGN, V42, P358, DOI 10.1016/j.patcog.2008.08.016
   Kim KI, 2002, LECT NOTES COMPUT SC, V2388, P293
   Kim KL, 2005, STUD FUZZ SOFT COMP, V177, P297
   Lalimi MA, 2013, COMPUT ELECTR ENG, V39, P834, DOI 10.1016/j.compeleceng.2012.09.015
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lienhart R, 2002, ICIP 2002
   Öztürk F, 2012, PROC TECH, V1, P124, DOI 10.1016/j.protcy.2012.02.024
   Salahshoor M, 2014, 2014 IRANIAN CONFERENCE ON INTELLIGENT SYSTEMS (ICIS)
   Sedighi A, 2011, EXPERT SYST APPL, V38, P13497, DOI 10.1016/j.eswa.2011.02.030
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang RM, 2014, OPTIK, V125, P2283, DOI 10.1016/j.ijleo.2013.10.126
   Wang YR, 2011, EXPERT SYST APPL, V38, P3142, DOI 10.1016/j.eswa.2010.08.106
   Yao ZJ, 2014, INFORM FUSION, V18, P78, DOI 10.1016/j.inffus.2013.05.008
   Yu SY, 2015, PATTERN RECOGN, V48, P114, DOI 10.1016/j.patcog.2014.07.027
   Zahedi M, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.164
   Zheng LH, 2013, J COMPUT SYST SCI, V79, P245, DOI 10.1016/j.jcss.2012.05.006
   Zunino R, 2000, IEEE T IND ELECTRON, V47, P159, DOI 10.1109/41.824138
NR 34
TC 12
Z9 14
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2771
EP 2790
DI 10.1007/s11042-017-4429-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400054
DA 2024-07-18
ER

PT J
AU Saeed, A
   Al-Hamadi, A
   Neumann, H
AF Saeed, Anwar
   Al-Hamadi, Ayoub
   Neumann, Heiko
TI Facial point localization via neural networks in a cascade regression
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial point detection; Face detection; Histogram of gradients; Cascade
   regression
ID FACE DETECTION; SELECTION
AB Facial point detection gains an increasing importance in computer vision as it plays a vital role in several applications such as facial expression recognition and human behavior analysis. In this work, we propose an approach to locate 49 facial points via neural networks in a cascade regression fashion. The localization process starts by detecting the face, followed by a face cropping refinement task and lastly arriving at the facial point location through five cascades of regressors. In particular, we perform a guided initialization using holistic features extracted from the entire face patch. Then, the points location is refined in the next four cascades using local features extracted from patches enclosing the prior estimates of the points. The generalization capability was improved by performing feature selection at each cascade. By evaluating our approach on samples gathered from four challenging databases, we achieved a location average error for each point ranging between 0.72 % and 1.57 % of the face width. The proposed approach was further evaluated according to the 300-w challenge, where we achieved competitive results to those obtained by state-of-the-art approaches and commercial software packages. Moreover, our approach showed better generalization capability. Finally, we validated the proposed enhancements by studying the impact of several factors on the point localization accuracy.
C1 [Saeed, Anwar; Al-Hamadi, Ayoub] Otto von Guericke Univ, Inst Informat Technol & Commun IIKT, Magdeburg, Germany.
   [Neumann, Heiko] Univ Ulm, Inst Neural Informat Proc, Ulm, Germany.
C3 Otto von Guericke University; Ulm University
RP Saeed, A (corresponding author), Otto von Guericke Univ, Inst Informat Technol & Commun IIKT, Magdeburg, Germany.
EM anwar.saeed@ovgu.de
FU German Research Foundation (DFG)
FX This work is part of the project done within the Transregional
   Collaborative Research Centre SFB/TRR 62 Companion-Technology for
   Cognitive Technical Systems funded by the German Research Foundation
   (DFG).
CR ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1
   [Anonymous], 2004, P ICPR INT WORKSH VI
   [Anonymous], 2014, ADV HUMAN COMPUTER I
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 13 INT C MACH LEARN
   [Anonymous], LUX FAC VER 6 1
   [Anonymous], FAC MATL SDK DEM
   [Anonymous], BRIT MACH VIS C BMVC
   Baltrusaitis T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P909, DOI 10.1109/FG.2011.5771372
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Barbu A, 2017, IEEE T PATTERN ANAL, V39, P272, DOI 10.1109/TPAMI.2016.2544315
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hall M.A., 1999, P 17 INT C MACHINE L, P359
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P8821, DOI 10.1007/s11042-013-1565-y
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Long N, 2011, J ANIM BREED GENET, V128, P247, DOI 10.1111/j.1439-0388.2011.00917.x
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Milborrow S., The MUCT Landmarked Face Database
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499
   Saeed A, 2015, SENSORS-BASEL, V15, P20945, DOI 10.3390/s150920945
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Smith BM, 2014, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2014.225
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P1067, DOI 10.1016/j.imavis.2014.09.005
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 45
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2261
EP 2283
DI 10.1007/s11042-016-4261-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400034
DA 2024-07-18
ER

PT J
AU Taschwer, M
   Marques, O
AF Taschwer, Mario
   Marques, Oge
TI Automatic separation of compound figures in scientific articles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multipanel figure separation; Document image understanding
ID IMAGE RETRIEVAL; CLASSIFICATION; PERFORMANCE; TEXT
AB Content-based analysis and retrieval of digital images found in scientific articles is often hindered by images consisting of multiple subfigures (compound figures). We address this problem by proposing a method (ComFig) to automatically classify and separate compound figures, which consists of two main steps: (i) a supervised compound figure classifier (ComFig classifier) discriminates between compound and non-compound figures using task-specific image features; and (ii) an image processing algorithm is applied to predicted compound images to perform compound figure separation (ComFig separation). The proposed ComFig classifier is shown to achieve state-of-the-art classification performance on a published dataset. Our ComFig separation algorithm shows superior separation accuracy on two different datasets compared to other known automatic approaches. Finally, we propose a method to evaluate the effectiveness of the ComFig chain combining classifier and separation algorithm, and use it to optimize the misclassification loss of the ComFig classifier for maximal effectiveness in the chain.
C1 [Taschwer, Mario] Klagenfurt Univ AAU, ITEC, Univ Str 65-67, A-9020 Klagenfurt, Austria.
   [Marques, Oge] Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Marques, O (corresponding author), Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM mario.taschwer@aau.at; omarques@fau.edu
CR [Anonymous], CLEF 2015 WORKING NO
   [Anonymous], CLEF 2015 WORKING NO
   [Anonymous], CLEF 2015 WORKING NO
   [Anonymous], CLEF 2013 WORKING NO
   [Anonymous], CLEF 2015 WORKING NO
   [Anonymous], CLEF 2013 WORKING NO
   [Anonymous], CLEF 2013 WORKING NO
   Apostolova E, 2013, J AM SOC INF SCI TEC, V64, P893, DOI 10.1002/asi.22810
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bishop C., 2006, Pattern Recognition and Machine Learning, P38
   Caruana R., 2006, ACM INT C P SER, P161, DOI DOI 10.1145/1143844.1143865
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chen N, 2007, INT J DOC ANAL RECOG, V10, P1, DOI 10.1007/s10032-006-0020-2
   Chhatkuli A, 2013, PROC SPIE, V8674, DOI 10.1117/12.2007897
   Hastie T., 2009, ELEMENTS STAT LEARNI, P485, DOI DOI 10.1007/978-0-387-84858-7_7
   Kalpathy-Cramer J, 2015, COMPUT MED IMAG GRAP, V39, P55, DOI 10.1016/j.compmedimag.2014.03.004
   Kou G, 2012, INT J INF TECH DECIS, V11, P197, DOI 10.1142/S0219622012500095
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Mitchell T.M., 1997, MACH LEARN, P128
   Murphy RF, 2001, 2ND ANNUAL IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS, P119, DOI 10.1109/BIBE.2001.974420
   Qian YT, 2008, BIOINFORMATICS, V24, P569, DOI 10.1093/bioinformatics/btm561
   Shatkay H, 2006, BIOINFORMATICS, V22, pE446, DOI 10.1093/bioinformatics/btl235
   Simpson MS, 2015, COMPUT MED IMAG GRAP, V39, P3, DOI 10.1016/j.compmedimag.2014.06.006
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smith-Miles KA, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456656
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taschwer Mario, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P162, DOI 10.1007/978-3-319-27671-7_14
   Yuan XH, 2014, INT J DATA MIN BIOIN, V9, P22, DOI 10.1504/IJDMB.2014.057779
NR 29
TC 5
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 519
EP 548
DI 10.1007/s11042-016-4237-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400022
DA 2024-07-18
ER

PT J
AU Khan, M
   Din, S
   Gohar, M
   Ahmad, A
   Cuomo, S
   Piccialli, F
   Jeon, G
AF Khan, Murad
   Din, Sadia
   Gohar, Moneeb
   Ahmad, Awais
   Cuomo, Salvatore
   Piccialli, Francesco
   Jeon, Gwanggil
TI Enabling multimedia aware vertical handover Management in Internet of
   Things based heterogeneous wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous wireless networks; Vertical handover management; IoT;
   Handover triggering; Network selection; Artificial bee Colony
ID SCHEME; OPTIMIZATION; SELECTION
AB Enabling seamless connectivity in Internet of Things (IoT) based heterogeneous wireless networks and pervasive use of smartphones in daily life require high data speed and always-best-connected services. However, providing vertical handover management in heterogeneous wireless networks is a difficult and challenging task. Moreover, various issues are present in the current vertical handover management schemes such as inappropriate handover triggering, high handover delay, wrong network selection, etc. In order to address the aforementioned issues, we propose a generic vertical handover management scheme. Our research is twofold; firstly, the Mobile Node (MN) dynamically checks the data rate required by the applications running on the MN's device. If the data rate drops below a predefined threshold, the MN initiates the handover. Secondly, the network selection is performed by considering various parameters such as end-to-end delay, jitter, Bit Error Rate, and packet loss. The Artificial Bee Colony (ABC) optimization algorithm uses the above parameters to select the target network with minimum handover delay and time. The proposed scheme is compared with the Simple Additive Weighting (SAW), Weighted Product Method (WPM), Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS), and Fuzzy TOPSIS in context of energy consumption, throughput, average MN's stay time in a network, handover delay, and handover time. The experimental results show that the proposed vertical handover management scheme outperforms the existing schemes used for similar purpose.
C1 [Khan, Murad] Sarhad Univ Sci & Informat Technol, Dept Comp Sci, Peshawar, Kpk, Pakistan.
   [Din, Sadia] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Gohar, Moneeb] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Ahmad, Awais] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan, South Korea.
   [Cuomo, Salvatore; Piccialli, Francesco] Univ Naples Federico II, Dept Math & Applicat, Naples, Italy.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
C3 Kyungpook National University; Yeungnam University; University of Naples
   Federico II; Incheon National University
RP Ahmad, A (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan, South Korea.; Jeon, G (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
EM murad.csit@suit.edu.pk; research.2486@gmail.com; moneebgohar@gmail.com;
   aahmmad.marwat@gmail.com; salvatore.cuomo@unina.it;
   francesco.piccialli@unina.it; gjeon@inu.ac.kr
RI Cuomo, Salvatore/Q-1365-2016; Khan, Murad/AAB-6060-2019; Piccialli,
   Francesco/ABC-2457-2020; Ahmad, Awais/AAA-4504-2019
OI Cuomo, Salvatore/0000-0003-4128-2588; Khan, Murad/0000-0001-9905-8904;
   Piccialli, Francesco/0000-0002-5179-2496; Din, Sadia/0000-0003-0921-4462
FU NRF - Korean Government [2015R1D1A1A01058171]
FX This work was supported by the NRF Grant funded by the Korean Government
   (2015R1D1A1A01058171)
CR Abduljalil FM, 2007, IEEE COMMUN SURV TUT, V9, P14, DOI 10.1109/COMST.2007.358969
   Alnas M, 2009, HANDOFF MECH MOBILE
   [Anonymous], IEEE COMMUNICATIONS
   [Anonymous], INT C ADV TECHN COMM
   Ashoka B, 2011, 12 INT C PAR DISTR C
   Buiati F, 2010, IEEE COMMUN LETT, V14, P1020, DOI 10.1109/LCOMM.2010.092310.100711
   Fallon E, 2013, IEEE T BROADCAST, V59, P96, DOI 10.1109/TBC.2012.2219232
   Ganz F, 2013, IEEE SENS J, V13, P3793, DOI 10.1109/JSEN.2013.2271562
   Gustafsson E, 2003, IEEE WIREL COMMUN, V10, P49, DOI 10.1109/MWC.2003.1182111
   Herwono I, 2005, 11 EUR NEXT GEN C WI
   Ismail A, 2011, 2011 INT C MOB IT CO
   Jadhav S, 2012, IEEE 26 INT C ADV IN
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Khan MQ, 2012, IEEE S COMP COMM ISC
   Khan M, 2015, WIRELESS PERS COMMUN, V85, P2273, DOI 10.1007/s11277-015-2904-2
   Khan M, 2015, IETE TECH REV, V32, P402, DOI 10.1080/02564602.2015.1020890
   Khan M, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/173068
   Khan M, 2014, IETE TECH REV, V31, P353, DOI 10.1080/02564602.2014.959077
   Kuhnert M, 2014, IEEE VTS VEH TECHNOL
   Lahby M, 2013, 8 INT C INT SYST THE
   Lee W, 2011, IEEE T VEH TECHNOL, V60, P2389, DOI 10.1109/TVT.2011.2140386
   Li M, 2007, P 2 ACM WORKSH PERF
   Li X, 2013, 6 INT C IM SIGN PROC
   Luo LJ, 2013, CHINA COMMUN, V10, P50, DOI 10.1109/CC.2013.6723878
   Maaloul S, 2013, 27 INT C ADV INF NET
   Mahardhika G., 2015, J COMPUT NETW COMMUN, V1, P1
   Mei J, 2011, 6 INT ICST C COMM NE
   Neves P, 2009, GLOBECOM WORKSH 2009, DOI [10.1109/GLOCOMW.2009.5360720, DOI 10.1109/GLOCOMW.2009.5360720]
   Nguyen-Vuong QT, 2008, COMPUT NETW, V52, P3358, DOI 10.1016/j.comnet.2008.09.002
   Pack S, 2007, IEEE COMMUN SURV TUT, V9, P2, DOI 10.1109/COMST.2007.358968
   Paul AAA, 2015, MOBILE INFORM SYSTEM, V14
   Pyun JY, 2008, IEEE T CONSUM ELECTR, V54, P71, DOI 10.1109/TCE.2008.4470026
   Rakovic V, 2010, INT C ULTR MOD TEL C
   TalebiFard P, 2011, IEEE C COMP COMM WOR
   Teodorovic D, 2006, NEUREL
   Valdez F, 2014, EXPERT SYST APPL, V41, P6459, DOI 10.1016/j.eswa.2014.04.015
NR 36
TC 25
Z9 25
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25919
EP 25941
DI 10.1007/s11042-017-4736-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500021
DA 2024-07-18
ER

PT J
AU Lin, GS
   Tuan, NM
   Chen, WJ
AF Lin, Guo-Shiang
   Nguyen-Minh Tuan
   Chen, Wen-Jan
TI Detecting region of interest for cadastral images in Taiwan
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive thresholding; Region of interest; Skew correction; Noise
   reduction
ID SCHEME
AB In the paper, we proposed a coarse-to-fine scheme to automatically detect the regions of interest (ROIs) for digitized cadastral images in Taiwan. To consider some issues such as the skew effect, image quality, and noise in digitized cadastral images, the proposed scheme is composed of four parts: pre-processing, skew correction, noise reduction, and ROI localization. In the pre-processing, each cadastral image is normalized and the prior knowledge is used to find the candidate region of the ROI. To reduce the impact of noise and poor contrast on line detection, an adaptive thresholding is adopted. To decrease the skew effect, the detected horizontal and vertical lines are analyzed to estimate the skew angle. After skew correction, an adaptive noise reduction algorithm is devised to reduce the effect of marginal, artificial, and random noise. The coordinates of the candidate region in the de-skew image with high resolution can be found and then the ROI boundary can be located correctly in the fine detection. Experimental results demonstrate that the proposed scheme can effectively and correctly localize ROIs in digitized cadastral images.
C1 [Lin, Guo-Shiang; Nguyen-Minh Tuan; Chen, Wen-Jan] Da Yeh Univ, Dept Comp Sci & Informat Engn, Changhua, Taiwan.
C3 Da Yeh University
RP Lin, GS (corresponding author), Da Yeh Univ, Dept Comp Sci & Informat Engn, Changhua, Taiwan.
EM khlin@mail.dyu.edu.tw; tuannguyenminh@gmail.com; cwj@mail.dyu.edu.tw
CR Alaei A, 2016, J PATTERN RECOGNIT R, V11, P1, DOI 10.13176/11.635
   Chou CH, 2007, PATTERN RECOGN, V40, P443, DOI 10.1016/j.patcog.2005.10.030
   Farahmand A, 2013, INT MULT C ENG COMP, V1, P5
   Hull J.J., 1998, Document Analysis Systems II, P40, DOI [DOI 10.1142/9789812797704_0003, 10.1142/9789812797704_0003]
   Lin GS, 2016, MULTIMED TOOLS APPL, V75, P9903, DOI 10.1007/s11042-015-2777-0
   Lin GS, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500074
   Lin GS, 2011, IEEE T CIRC SYST VID, V21, P421, DOI 10.1109/TCSVT.2011.2125370
   Lin GS, 2009, INT J PATTERN RECOGN, V23, P1179, DOI 10.1142/S0218001409007521
   Lin H, 2007, 2007 INTERNATIONAL CONFERENCE ON INTEGRATION OF KNOWLEDGE INTENSIVE MULTI-AGENT SYSTEMS, P306, DOI 10.1109/KIMAS.2007.369827
   Rezaei SB, 2013, P INT MULT C ENG COM
   Sonka M., 2008, IMAGE PROCESSING ANA
   Zhou Q, 2005, MULTIMED TOOLS APPL, V27, P251, DOI 10.1007/s11042-005-2577-z
NR 12
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25369
EP 25389
DI 10.1007/s11042-017-4504-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300045
DA 2024-07-18
ER

PT J
AU Pang, JB
   Huang, J
   Zhang, WG
   Huang, QM
   Yin, BC
AF Pang, Junbiao
   Huang, Jing
   Zhang, Weigang
   Huang, Qingming
   Yin, Baocai
TI Justify role of Similarity Diffusion Process in cross-media topic
   ranking: an empirical evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised ranking; Poisson noise; Gaussian noise; Similarity
   Diffusion Process; Deconvolution
AB Recently top performing cross-media topic detection employs Similarity Diffusion Process (SDP) to rank the interestingness of topics from a large number of candidates. SDP models the polysemous phenomenon from short and less-constrained user-generated data by assuming the similarities between two multi-media data should be divided into intersected topics. The noise in SDP plays an important role to explain the generation of the similarity. However, it is unclear what kind of noise is more appropriate for different modalities in cross media: SDP under different noises should has the lower false positives when topics are successfully detected. In this paper, we provide an in depth analysis of two types of noises (Poisson and Gaussian) for this task. In the evaluation, we observe that the combination of Poisson noise and topic sizes performs best while Gaussian noise has a faster optimization speed than that of Poisson one.
C1 [Pang, Junbiao; Huang, Jing; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
   [Zhang, Weigang] Univ Chinese Acad Sci, Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhang, Weigang; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Huang, Qingming; Yin, Baocai] Dalian Univ Technol, Dalian 116024, Peoples R China.
C3 Beijing University of Technology; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Dalian University of
   Technology
RP Pang, JB (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
EM junbiao_pang@bjut.edu.cn; jing.huang@vipl.ict.ac.cn; wgzhang@hit.edu.cn;
   qmhuang@ucas.ac.cn; ybc@dlut.edu.cn
RI Zhang, Weigang/GZA-9095-2022
OI pang, Junbiao/0000-0001-8153-7229; Zhang, Weigang/0000-0003-0042-7074
FU Natural Science Foundation of China [61672069, 61332016, 61620106009,
   61472387, U1636214, 61650202]; Key Research Program of Frontier Sciences
   [CAS: QYZDJ-SSW-SYS013]; China Postdoctoral Science Foundation; Beijing
   Post-Doctoral Research Foundation; Beijing Municipal Commission of
   Education [KM201610005034]; Funding Project for Academic Human Resources
   Development in Institutions of Higher Learning Under the Jurisdiction of
   Beijing Municipality (PHR)
FX This work was supported in part by Natural Science Foundation of China
   under Grant 61672069, Grant 61332016, Grant 61620106009, Grant 61472387,
   Grant U1636214, and Grant 61650202, in part by Key Research Program of
   Frontier Sciences under Grant CAS: QYZDJ-SSW-SYS013, in part by China
   Postdoctoral Science Foundation, by Beijing Post-Doctoral Research
   Foundation, by Beijing Municipal Commission of Education under Grant
   KM201610005034, and by the Funding Project for Academic Human Resources
   Development in Institutions of Higher Learning Under the Jurisdiction of
   Beijing Municipality (PHR).
CR Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao J, 2011, IEEE T CIRC SYST VID, V21, P1835, DOI 10.1109/TCSVT.2011.2148470
   Cheung SCS, 2003, IEEE T CIRC SYST VID, V13, P59, DOI 10.1109/TCSVT.2002.808080
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32
   Jia F, 2014, INT C MULT EXP, P1
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Aiello LM, 2013, IEEE T MULTIMEDIA, V15, P1268, DOI 10.1109/TMM.2013.2265080
   Nesterov Y., 1983, SOV MATH DOKL, V27, P372
   Pang JB, 2016, IEEE T MULTIMEDIA, V18, P2482, DOI 10.1109/TMM.2016.2598439
   Pang JB, 2015, IEEE T MULTIMEDIA, V17, P843, DOI 10.1109/TMM.2015.2425143
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   PUTTHIVIDHYA D, 2010, PROC CVPR IEEE, P3408, DOI DOI 10.1109/CVPR.2010.5540000
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   Wu X, 2007, P INT C ACM MULT, P168
   Zhang YD, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/705238
NR 19
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25145
EP 25157
DI 10.1007/s11042-017-5037-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300032
DA 2024-07-18
ER

PT J
AU Wang, CC
   Li, GL
AF Wang, Chuen-Ching
   Li, Gwo-Long
TI Hardware-friendly advanced motion vector prediction method and its
   architecture design for high efficiency video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Video coding; Motion estimation; HDTV
AB High efficiency video coding (HEVC) has been standardized as a means of meeting the coding requirements of 4 K (3840 x 2160) video. However, HEVC has a high computational complexity and a challenging hardware implementation. As a result, 4 K video applications are still limited. Consequently, the present study proposes a hardware-friendly advanced motion vector prediction (AMVP) method for HEVC which avoids the data dependency problem during the hardware pipeline operation. In the proposed method, the motion vector relationship between the largest coding unit (LCU) and the smaller coding units (CUs) and prediction units (PUs) is observed first. Based on the observation results, a linear model is constructed to estimate the motion vectors of the CUs and PUs from the motion vector of the LCU. It is shown that the proposed prediction method improves the hardware coding throughput by at least 53.8% compared to a traditional AMVP hardware realization, and increases the BD-rate by no more than 0.99% on average. To reduce the hardware implementation costs, a coefficient approximation and control signal sharing technique are also proposed in this paper to realize the proposed linear model. In addition, since the motion vectors of the small CUs and PUs are estimated in advance, a data pre-fetch technique can be employed to further increase the hardware-coding throughput. The experimental results show that the proposed AMVP design has a gate count of just 10 k.
C1 [Wang, Chuen-Ching] Kao Yuan Univ, Dept Informat Technol, Kaohsiung, Taiwan.
   [Li, Gwo-Long] Ind Technol Res Inst, Dept Video Coding Core Technol, Hsinchu, Taiwan.
C3 Industrial Technology Research Institute - Taiwan
RP Wang, CC (corresponding author), Kao Yuan Univ, Dept Informat Technol, Kaohsiung, Taiwan.
EM t90261@cc.kyu.edu.tw; gwolong@gmail.com
FU Ministry of Science Technology, Taiwan [MOST 102-2221-E-244 -017-]
FX The authors gratefully acknowledge the financial support provided to
   this study by the Ministry of Science Technology, Taiwan. (MOST
   102-2221-E-244 -017-).
CR Advanced Video Coding for Generic Audio-visual Services, 2010, H264 ITUT
   Amish F, 2016, J SYST ARCHITECT, V64, P133, DOI 10.1016/j.sysarc.2015.10.002
   Bossen F., 2013, JCTVCM1010
   Bossen F., 2012, JCTVCJ1100
   Chen WW, 2015, I SYMP CONSUM ELECTR, P56, DOI 10.1109/ICCE.2015.7066316
   Fan C, 2015, MULTIMED TOOLS APPL, V74, P1
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   High Efficiency Video Coding, 2013, H265 ITUT
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee S., 2016, IEEE INT C CONS EL B
   Li F, 2016, MULTIMED TOOLS APPL, V75, P1
   Mert AC, 2016, IEEE ICCE
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Sugio T., 2011, JCTVCF470
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   Yuan Y, 2012, IEEE T CIRC SYST VID, V22, P1707, DOI 10.1109/TCSVT.2012.2223037
   Zhong GY, 2015, MULTIMED TOOLS APPL, V74, P11023, DOI 10.1007/s11042-014-2216-7
NR 20
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25285
EP 25296
DI 10.1007/s11042-017-4500-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300041
DA 2024-07-18
ER

PT J
AU Wu, W
   Yang, XM
   Li, H
   Liu, K
   Jian, LH
   Zhou, ZL
AF Wu, Wei
   Yang, Xiaomin
   Li, Hong
   Liu, Kai
   Jian, Lihua
   Zhou, Zhili
TI A novel scheme for infrared image enhancement by using weighted least
   squares filter and fuzzy plateau histogram equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared image; Fuzzy histogram; Plateau histogram equalization;
   Weighted least squares filter; Non-local means filter
ID CONTRAST ENHANCEMENT; ALGORITHM
AB High-quality thermal infrared (IR) images are always preferred in numerous real-world applications. However, acquired IR images, which have low contrast and signal-to-noise ratio (SNR) among other characteristics, have inferior quality because of various factors. To improve the quality of IR images, three main aspects must be addressed: global contrast, local contrast, and noise of IR images. Most of the existing methods focus only on some of these issues. In this paper, we propose a novel scheme to solve the three issues. First, an edge-preserving filter called weighted least squares filter is adopted to decompose an IR image into a low-frequency (LF) component and a sequence of high-frequency (HF) components. We propose a fuzzy plateau histogram equalization for the LF component to improve global contrast. A strategy is exploited to alter the coefficients of the HF components to enhance local contrast. The primitive result is synthesized with the enhanced LF and HF components. To suppress the noise in the primitive result, nonlocal means filter is applied to derive the final result. Numerous experiments are conducted. Experimental results demonstrate that the proposed scheme exhibits the best performance compared with the other methods.
C1 [Wu, Wei; Yang, Xiaomin; Li, Hong; Jian, Lihua] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Liu, Kai] Sichuan Univ, Coll Elect & Engn Informat, Chengdu 610064, Sichuan, Peoples R China.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan University; Nanjing University of
   Information Science & Technology; Nanjing University of Information
   Science & Technology; Sichuan University
RP Yang, XM (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM wuwei@scu.edu.cn; arielyang@scu.edu.cn; 1033782076@qq.com;
   kailiu@scu.edu.cn; 540345294@qq.com; zhou_zhili@163.com
RI LI, RUIJIAN/GYJ-0470-2022; Liu, Kai/IST-6808-2023; yang,
   xiao/HJI-7815-2023; xu, chen/JNE-5010-2023; zhen, wang/KBA-3844-2024
OI Wu, Wei/0000-0001-5769-9340
FU National Natural Science Foundation of China [61271330, 61473198];
   Priority Academic Program Development of Jiangsu Higer Education
   Institutions (PAPD) Fund; Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology (CICAEET) Fund
FX The research is sponsored by the National Natural Science Foundation of
   China (No. 61271330, No. 61473198), also is supported by the Priority
   Academic Program Development of Jiangsu Higer Education Institutions
   (PAPD) Fund, Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology (CICAEET) Fund.
CR [Anonymous], 2007, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2007.383003
   [Anonymous], 2011 THERM IM GUID I
   Bai XZ, 2011, INFRARED PHYS TECHN, V54, P61, DOI 10.1016/j.infrared.2010.12.001
   Bharathi SA, 2012, COMM COM INF SC, V270, P665
   Budzan Sebastian, 2015, Measurement Automation Monitoring, V61, P187
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gan W, 2015, INFRARED PHYS TECHN, V72, P37, DOI 10.1016/j.infrared.2015.07.003
   Highnam R, 1995, WORKSH PHYS BAS MOD, P410
   Hossain MF, 2010, COMM COM INF SC, V77, P74
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Kara AO, 2011, INFRARED PHYS TECHN, V54, P382, DOI 10.1016/j.infrared.2011.05.003
   Karali AO, 2010, J OPT SOC AM A, V27, P509, DOI 10.1364/JOSAA.27.000509
   Lai R, 2010, OPT COMMUN, V283, P4283, DOI 10.1016/j.optcom.2010.06.072
   Li HH, 2015, PATTERN RECOGN LETT, V51, P23, DOI 10.1016/j.patrec.2014.07.021
   Li Y, 2007, P ANN INT IEEE EMBS, P3315, DOI 10.1109/IEMBS.2007.4353039
   Li Y, 2014, NEUROCOMPUTING, V134, P70, DOI 10.1016/j.neucom.2013.03.068
   Li Y, 2008, IEEE ENG MED BIO, P2189, DOI 10.1109/IEMBS.2008.4649629
   Lin CL, 2011, INFRARED PHYS TECHN, V54, P84, DOI 10.1016/j.infrared.2011.01.001
   Maini R., 2010, A comprehensive review of image compression techniques, P8
   Ni C, 2008, SIGNAL PROCESS, V88, P1606, DOI 10.1016/j.sigpro.2007.12.016
   Pace T, 2008, P SPIE INT SOC OPTIC, P6978
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Qidwai U, 2008, IEEE T IMAGE PROCESS, V17, P1274, DOI 10.1109/TIP.2008.925377
   Rahman ZU, 2002, P SPIE INT SOC OPTIC, P4736
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Shao ML, 2006, PROC SPIE, V6150, DOI 10.1117/12.676901
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh S. S., 2012, INT J COMPUTER APPL, V47, P39
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Vickers VE, 1996, OPT ENG, V35, P1921, DOI 10.1117/1.601006
   Wang BJ, 2006, INFRARED PHYS TECHN, V48, P77, DOI 10.1016/j.infrared.2005.04.008
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yu TH, 2009, CHIN OPT LETT, V7, P206, DOI 10.3788/COL20090703.0206
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Yuan LT, 2015, PATTERN RECOGN LETT, V54, P103, DOI 10.1016/j.patrec.2014.09.011
   Zhao JF, 2014, OPTIK, V125, P4039, DOI 10.1016/j.ijleo.2014.01.117
   Zhao JF, 2014, INFRARED PHYS TECHN, V62, P86, DOI 10.1016/j.infrared.2013.11.008
   Zhao WD, 2014, INFRARED PHYS TECHN, V66, P152, DOI 10.1016/j.infrared.2014.05.018
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zia-Ur R, 1999, IS TS C CEL ALL IM, P426
NR 44
TC 6
Z9 10
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24789
EP 24817
DI 10.1007/s11042-017-4643-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300012
DA 2024-07-18
ER

PT J
AU Bui, TH
   Park, SB
AF Bui, Thanh-Hieu
   Park, Seong-Bae
TI Point of interest mining with proper semantic annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE POI mining; Clustering; Semantic annotation; Geo-tagged photo
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; GEO-TAGGED PHOTOS;
   SOCIAL MEDIA; LOCATIONS; SYSTEM
AB Mining geo-tagged social photo media has received large amounts of attention from researchers recently. Points of interest (POI) mining from a collection of geo-tagged photos is one of these problems. POI mining refers to the processes of pattern recognition (namely clustering), extraction and semantic annotation. However, based on unsupervised clustering methods, many POIs might not be mined. Additionally, there is a great challenge for the proper semantic annotation to data clusters after clustering. In practice, there are many applications which require the accuracy of semantic annotation and high quality of pattern recognition such as POI recommendation. In this paper, we study POI mining from a collection of geo-tagged photos in combination with proper semantic annotation by using additional POI information from high coverage external POI databases. We propose a novel POI mining framework by using two-level clustering, random walk and constrained clustering. In random walk clustering step, we separate a large-scale collection of geo-tagged photos into many clusters. In the constrained clustering step, we continue to divide the clusters that include many POIs into many sub-clusters, where the geo-tagged photos in a sub-cluster associate with a particular POI. Experimental results on two datasets of geo-tagged Flickr photos of two cities in California, USA have shown that the proposed method substantially outperforms existing approaches that are adapted to handle the problem.
C1 [Bui, Thanh-Hieu; Park, Seong-Bae] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
C3 Kyungpook National University
RP Park, SB (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM bthieu@sejong.knu.ac.kr; sbpark@sejong.knu.ac.kr
RI Bui, Thanh-Hieu/IZQ-2903-2023
FU Institute for Information & Communications Technology Promotion (IITP) -
   Korea government (MSIP) [R0101-16-0054]
FX This work was supported by Institute for Information & Communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP)
   (No. R0101-16-0054, WiseKB: Big data based self-evolving knowledge base
   and reasoning platform).
CR [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], 2001, P 18 INT C MACH LEAR
   [Anonymous], 2010, INT C EXH COMP GEOSP
   [Anonymous], 2008, Proceedings of the 25th international conference on Machine learning
   [Anonymous], 2001, International Conf. on Foundations of Software Technology and Theoretical Computer Science, DOI DOI 10.1007/3-540-45294-X_3
   [Anonymous], MATRIX COMPUTATIONS
   BASU S, 2004, KDD
   Bermingham L, 2014, PROCEDIA COMPUT SCI, V29, P379, DOI 10.1016/j.procs.2014.05.034
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fuchs G., 2015, SIGSPATIAL SPECIAL, V7, P27
   Han J, 2015, PERVASIVE MOB COMPUT, V18, P4, DOI 10.1016/j.pmcj.2014.08.002
   Hu YJ, 2015, COMPUT ENVIRON URBAN, V54, P240, DOI 10.1016/j.compenvurbsys.2015.09.001
   Vu HQ, 2015, TOURISM MANAGE, V46, P222, DOI 10.1016/j.tourman.2014.07.003
   Ji RR, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037688
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Kou NM, 2015, GEOINFORMATICA, V19, P693, DOI 10.1007/s10707-015-0226-x
   Krueger R, 2015, IEEE T VIS COMPUT GR, V21, P903, DOI 10.1109/TVCG.2014.2371856
   Kunze C, 2015, COMPUT ENVIRON URBAN, V53, P4, DOI 10.1016/j.compenvurbsys.2015.04.002
   Lacerda Y.A., 2012, Proceedings_of_the_18th_Brazilian_Symposium on_Multimedia_and_the_Web, WebMedia'12, P281
   Laptev Dmitry, 2014, P 22 ACM SIGSPATIAL, P113
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Lee I, 2014, EXPERT SYST APPL, V41, P397, DOI 10.1016/j.eswa.2013.07.065
   Lim K.H., 2015, P 2015 ACM SIGMOD PH, P33, DOI DOI 10.1145/2744680.2744693
   Majid A, 2015, DATA KNOWL ENG, V95, P66, DOI 10.1016/j.datak.2014.11.001
   Majid A, 2013, INT J GEOGR INF SCI, V27, P662, DOI 10.1080/13658816.2012.696649
   Maraziotis IA, 2012, PATTERN RECOGN, V45, P637, DOI 10.1016/j.patcog.2011.05.007
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   O'Hare N, 2013, INFORM RETRIEVAL, V16, P30, DOI 10.1007/s10791-012-9195-y
   Popescu A, 2008, P JCDL 2008 PITTSB P
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Rattenbury T, 2007, P 16 INT C WORLD WID, P1287
   Sedgewick R., 2011, Algorithm
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Spyrou E, 2016, NEUROCOMPUTING, V172, P114, DOI 10.1016/j.neucom.2014.12.104
   Tang W, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P707
   Thomee B, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2854004
   Tipping M., 2001, Artificial intelligence and statistics, P129
   Wei-Chao Chen, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P1248, DOI 10.1109/ACSSC.2009.5469962
   Wen YT, 2014, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2014.66
   Weyand T, 2015, COMPUT VIS IMAGE UND, V135, P1, DOI 10.1016/j.cviu.2015.02.002
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang YY, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P883
   Yin Y., 2015, P ACM T MULTIMEDIA C, V11, P29
   Zhang JM, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P355, DOI 10.1145/2671188.2749353
   Zheng YT, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168770
   Zhou XL, 2015, COMPUT ENVIRON URBAN, V54, P144, DOI 10.1016/j.compenvurbsys.2015.07.006
NR 56
TC 7
Z9 7
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23435
EP 23457
DI 10.1007/s11042-016-4114-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700014
DA 2024-07-18
ER

PT J
AU Robitza, W
   Ahmad, A
   Kara, PA
   Atzori, L
   Martini, MG
   Raake, A
   Sun, LF
AF Robitza, Werner
   Ahmad, Arslan
   Kara, Peter A.
   Atzori, Luigi
   Martini, Maria G.
   Raake, Alexander
   Sun, Lingfen
TI Challenges of future multimedia QoE monitoring for internet service
   providers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telecommunications; Network monitoring; Quality of experience; Quality
   of service; Service monitoring; Encryption; Service defined networks;
   Network function virtualization
ID QUALITY
AB The ever-increasing network traffic and user expectations at reduced cost make the delivery of high Quality of Experience (QoE) for multimedia services more vital than ever in the eyes of Internet Service Providers (ISPs). Real-time quality monitoring, with a focus on the user, has become essential as the first step in cost-effective provisioning of high quality services. With the recent changes in the perception of user privacy, the rising level of application-layer encryption and the introduction and deployment of virtualized networks, QoE monitoring solutions need to be adapted to the fast changing Internet landscape. In this contribution, we provide an overview of state-of-the-art quality monitoring models and probing technologies, and highlight the major challenges ISPs have to face when they want to ensure high service quality for their customers.
C1 [Robitza, Werner] Deutsch Telekom AG, Telekom Innovat Labs, Ernst Reuter Pl 7, D-10587 Berlin, Germany.
   [Ahmad, Arslan; Atzori, Luigi] Univ Cagliari, Dept Elect & Elect Engn, Via Univ 40, I-09124 Cagliari, Italy.
   [Kara, Peter A.; Martini, Maria G.] Kingston Univ, WMN Res Grp, Penrhyn Rd, Kingston Upon Thames KT1 2EE, Surrey, England.
   [Raake, Alexander] TU Ilmenau, Audiovisual Technol Grp, D-98693 Ilmenau, Germany.
   [Sun, Lingfen] Univ Plymouth, Sch Comp Elect & Math, Plymouth PL4 8AA, Devon, England.
C3 Deutsche Telekom AG; University of Cagliari; Kingston University;
   Technische Universitat Ilmenau; University of Plymouth
RP Robitza, W (corresponding author), Deutsch Telekom AG, Telekom Innovat Labs, Ernst Reuter Pl 7, D-10587 Berlin, Germany.
EM werner.robitza@gmail.com; arslan.ahmad@diee.unica.it;
   p.kara@kingston.ac.uk; l.atzori@ieee.org; m.martini@kingston.ac.uk;
   alexander.raake@tu-ilmenau.de; l.sun@plymouth.ac.uk
RI Martini, Maria/AAC-8754-2022; Ahmad, Arslan/W-4581-2019
OI Ahmad, Arslan/0000-0002-3979-5870
FU European Union's Horizon 2020 research and innovation program under the
   Marie Sklodowska-Curie grant, Network QoE-Net [643072]
FX The work on this paper was funded from the European Union's Horizon 2020
   research and innovation program under the Marie Sklodowska-Curie grant
   agreement No 643072, Network QoE-Net.
CR Aaron A, 2015, IEEE IMAGE PROC, P1732, DOI 10.1109/ICIP.2015.7351097
   Ahmad A., 2017, PROC IEEE INT C COMM, P1
   Ahmad A, 2017, IFIP IEEE I IN PRESS
   Ahmad A, 2016, COMPUT NETW, V110, P168, DOI 10.1016/j.comnet.2016.09.022
   [Anonymous], 2014, P 15 WORKSH MOB COMP
   [Anonymous], 2013, Int. J. Distributed Parallel Syst.
   Bajpai V, 2015, IEEE COMMUN SURV TUT, V17, P1313, DOI 10.1109/COMST.2015.2418435
   Barakovic S., 2013, J COMPUTER NETWORKS
   Bruschi R, 2016, 2016 INT TEL C
   Carey T, 2016, US Patent, Patent No. 20160020962
   Casas Pedro, 2013, Performance Evaluation Review, V41, P44
   Chen QA, 2014, PROCEEDINGS OF THE 2014 ACM INTERNET MEASUREMENT CONFERENCE (IMC'14), P151, DOI 10.1145/2663716.2663726
   Chen Y., 2014, IEEE COMMUN SURV TUT, VPP, P1
   Dimopoulos G., 2016, P 2016 INT MEAS C SA, P513, DOI DOI 10.1145/2987443.2987459
   Feng H, 2014, IEEE IMTC P, P267, DOI 10.1109/I2MTC.2014.6860750
   Francesco DP, 2016, 34 CHIN CONTR C
   Frank B, 2013, ACM SIGCOMM COMP COM, V43, P35
   Gharakheili HH, 2016, ACM SIGCOMM COMP COM, V46, P64, DOI 10.1145/2875951.2875962
   Han B, 2015, IEEE COMMUN MAG, V53, P90, DOI 10.1109/MCOM.2015.7045396
   Hofstede R, 2014, IEEE COMMUN SURV TUT, V16, P2037, DOI 10.1109/COMST.2014.2321898
   Hossfeld T, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P1274, DOI 10.1109/INM.2015.7140480
   Kasbekar M, 2015, MAN RAD NETW ENCR WO
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Le Callet P., 2013, QUALINET WHITE PAPER
   Manzalini A, 2013, IEEE COMMUN MAG, V51, P63, DOI 10.1109/MCOM.2013.6553679
   Marsden C.T., 2017, NETWORK NEUTRALITY P
   Mijumbi R, 2016, IEEE COMMUN SURV TUT, V18, P236, DOI 10.1109/COMST.2015.2477041
   Moreira A, 2011, WINT SIMUL C PROC, P3178, DOI 10.1109/WSC.2011.6148016
   Orsolic I, 2016, IEEE GLOBE WORK
   Passarella A, 2012, COMPUT COMMUN, V35, P1, DOI 10.1016/j.comcom.2011.10.005
   Perkis A, 2014, T-LAB SER TELECOMMUN, P97, DOI 10.1007/978-3-319-02681-7_7
   Raake A, 2011, IEEE SIGNAL PROC MAG, V28, P68, DOI 10.1109/MSP.2011.942472
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   Schatz R., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P358, DOI 10.1109/IMIS.2012.12
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Skorin-Kapov Lea, 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P662
   Thomas E., 2015, ENHANCING MPEG DASH
   Varela M, 2015, IEEE INT CONF COMM, P1741, DOI 10.1109/ICCW.2015.7247432
   Wamser F, 2015, 2015 EUROPEAN CONFERENCE ON NETWORKS AND COMMUNICATIONS (EUCNC), P239, DOI 10.1109/EuCNC.2015.7194076
   Wichtlhuber M, 2015, IEEE T NETW SERV MAN, V12, P48, DOI 10.1109/TNSM.2015.2404792
   Yeh CL, 2014, 20 ITS BIENN C RIO D
NR 41
TC 21
Z9 21
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22243
EP 22266
DI 10.1007/s11042-017-4870-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200021
OA Green Published, hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Takehara, D
   Harakawa, R
   Ogawa, T
   Haseyama, M
AF Takehara, Daichi
   Harakawa, Ryosuke
   Ogawa, Takahiro
   Haseyama, Miki
TI Extracting hierarchical structure of content groups from different
   social media platforms using multiple social metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media platform; Cross-platform application; Hierarchical
   structure; YouTube; Wikipedia
ID CROSS-MEDIA
AB A novel scheme for retrieving users' desired contents, i.e., contents with topics in which users are interested, from multiple social media platforms is presented in this paper. In existing retrieval schemes, users first select a particular platform and then input a query into the search engine. If users do not specify suitable platforms for their information needs and do not input suitable queries corresponding to the desired contents, it becomes difficult for users to retrieve the desired contents. The proposed scheme extracts the hierarchical structure of content groups (sets of contents with similar topics) from different social media platforms, and it thus becomes feasible to retrieve desired contents even if users do not specify suitable platforms and do not input suitable queries. This paper has two contributions: (1) A new feature extraction method, Locality Preserving Canonical Correlation Analysis with multiple social metadata (LPCCA-MSM) that can detect content groups without the boundaries of different social media platforms is presented in this paper. LPCCA-MSM uses multiple social metadata as auxiliary information unlike conventional methods that only use content-based information such as textual or visual features. (2) The proposed novel retrieval scheme can realize hierarchical content structuralization from different social media platforms. The extracted hierarchical structure shows various abstraction levels of content groups and their hierarchical relationships, which can help users select topics related to the input query. To the best of our knowledge, an intensive study on such an application has not been conducted; therefore, this paper has strong novelty. To verify the effectiveness of the above contributions, extensive experiments for real-world datasets containing YouTube videos and Wikipedia articles were conducted.
C1 [Takehara, Daichi; Harakawa, Ryosuke; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Hokkaido University
RP Takehara, D (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
EM takehara@lmd.ist.hokudai.ac.jp; harakawa@lmd.ist.hokudai.ac.jp;
   ogawa@lmd.ist.hokudai.ac.jp; miki@ist.hokudai.ac.jp
RI Haseyama, Miki/A-6163-2012
OI Ogawa, Takahiro/0000-0001-5332-8112
FU JSPS KAKENHI [JP25280036, JP24120002]; Grants-in-Aid for Scientific
   Research [16J02042] Funding Source: KAKEN
FX This work was partly supported by JSPS KAKENHI Grant Numbers JP25280036,
   JP24120002.
CR Amigó E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8
   [Anonymous], 2012, P 27 ANN ACM S APPL
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], 2013, 31 INT C MACH LEARN
   [Anonymous], J STAT MECH
   [Anonymous], CONVERGENCE INT J RE
   [Anonymous], 2013, P 5 INT C INT MULT C
   [Anonymous], 2014, Abstr.Appl. Anal.
   [Anonymous], BIOCH J
   [Anonymous], 2012, P 29 INT C MACH LEAR
   [Anonymous], 2013, Dynamics On and Of Complex Networks
   Bao BK, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2730889
   Cao J, 2016, NEUROCOMPUTING, V172, P53, DOI 10.1016/j.neucom.2014.10.103
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chu LY, 2016, IEEE T CIRC SYST VID, V26, P556, DOI 10.1109/TCSVT.2014.2347551
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Fang Q, 2016, IEEE T MULTIMEDIA, V18, P702, DOI 10.1109/TMM.2016.2527602
   Ferragina P, 2008, SOFTWARE PRACT EXPER, V38, P189, DOI 10.1002/spe.829
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gao K, 2012, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2012.6248059
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Harakawa R, 2016, MULTIMED TOOLS APPL, V75, P17059, DOI 10.1007/s11042-015-2976-8
   Haseyama M, 2013, ITE TRANS MEDIA TECH, V1, P2, DOI 10.3169/mta.1.2
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hindle A, 2011, WORLD WIDE WEB, V14, P53, DOI 10.1007/s11280-010-0097-x
   Hong Richang, 2011, ACM Transactions on Multimedia Computing, Communications and Applications, V7, DOI 10.1145/2043612.2043613
   Hong RC, 2013, SIGNAL PROCESS, V93, P2361, DOI 10.1016/j.sigpro.2012.06.028
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hua-Jun Zeng, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P210
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Min WQ, 2015, IEEE T MULTIMEDIA, V17, P1787, DOI 10.1109/TMM.2015.2463226
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2016, MULTIMED TOOLS APPL, V75, P12521, DOI 10.1007/s11042-014-2339-x
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Que XY, 2015, INT PARALL DISTRIB P, P28, DOI 10.1109/IPDPS.2015.59
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Steinbach M., 2000, KDD WORKSH TEXT MIN, P525
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Takehara D, 2016, IEEE IMAGE PROC, P479, DOI 10.1109/ICIP.2016.7532403
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang WG, 2015, NEUROCOMPUTING, V169, P169, DOI 10.1016/j.neucom.2015.02.083
   Zhang Y.-D., 2013, MATH PROBL ENG, P1, DOI DOI 10.1155/2013/716952
   Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P515, DOI 10.1145/584792.584877
   Zhou XP, 2016, IEEE T KNOWL DATA EN, V28, P411, DOI 10.1109/TKDE.2015.2485222
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 48
TC 5
Z9 5
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20249
EP 20272
DI 10.1007/s11042-017-4717-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500053
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Xu, DQ
   Wang, XY
   Sun, G
   Li, HM
AF Xu, Dongqing
   Wang, Xiuyou
   Sun, Gang
   Li, Huaimin
TI Towards a novel image denoising method with edge-preserving sparse
   representation based on laplacian of B-spline edge-detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laplacian of B-spline; Image denoising; Sparse presentation; Edge
   preservation
ID REGULARIZATION
AB To address the edge structure preservation problem in sparse representation image denoising, a Laplacian of B-spline (LOBS) edge detection operator was brought out, which solves the problem of singleness of existing edge-detection operators under noise environment and lack of robustness to noise to some extent. Based on LOBS operator, a novel sparse-based edge preservation image denoising method (ESRIDM) was proposed. It determines edge region by computing gradient with LOBS operator. The non-edge region was denoised normally, while noise in edge region can be filtered by setting appropriate threshold. Simulation experiment compared with Laplacian-of-Gaussian (LOG) operator and Canny operator shows that the LOBS edge-detection operator has better robustness and lost less edge. Denoising experiments on general images and video monitoring images show that this novel method can achieve better denoising effect in subjective vision.
C1 [Xu, Dongqing; Wang, Xiuyou; Sun, Gang; Li, Huaimin] Fuyang Teachers Univ, Sch Comp & Informat Engn, Fuyang 236037, Anhui, Peoples R China.
   [Xu, Dongqing] Xinjiang Agr Univ, Sch Hydraul & Civil Engn, Urumqi 830000, Xinjiang, Peoples R China.
   [Wang, Xiuyou] Anhui Univ, Sch Comp Sci & Technol, Hefei 561099, Anhui, Peoples R China.
C3 Xinjiang Agricultural University; Anhui University
RP Xu, DQ (corresponding author), Fuyang Teachers Univ, Sch Comp & Informat Engn, Fuyang 236037, Anhui, Peoples R China.; Xu, DQ (corresponding author), Xinjiang Agr Univ, Sch Hydraul & Civil Engn, Urumqi 830000, Xinjiang, Peoples R China.
EM dongqingmtap@163.com
FU Anhui Province Science Foundation of China [KJ2012A214, 2015KJ012,
   2015FSKJ08, 2013WLGH01ZD, KJ2013B192]
FX This work is supported by the project of Anhui Province Science
   Foundation of China with No. KJ2012A214 entitled "Dynamical behaviour
   and control of memristor-based chaotic and hyperchaotic systems", the
   project of Anhui Province Science Foundation of China with No. 2015KJ012
   entitled "Inpainting system model of thangka damaged region", the
   project of Anhui Province Science Foundation of China with No.
   2015FSKJ08 entitled "Thangka semantic annotation based on interesting
   region", the project of Anhui Province Science Foundation of China with
   No. 2013WLGH01ZD entitled "Construction of regional logistics
   information platform based on cloud computing", and the project of Anhui
   Province Science Foundation of China with No. KJ2013B192 entitled
   "Finger vein image quality evaluation and its application".
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Chen BJ, 2014, IET IMAGE PROCESS, V8, P591, DOI 10.1049/iet-ipr.2013.0521
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Hong SW, 2000, IEE P-VIS IMAGE SIGN, V147, P16, DOI 10.1049/ip-vis:20000311
   Jiang LX, 2010, P 2 INTT C COMP AUT, V4, P476
   Li F, 2009, P 2 INT C IM SIGN PR, DOI [10.1109/CISP.2009.5303579, DOI 10.1109/CISP.2009.5303579]
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu X, 2014, 2014 Fifth International Conference on Intelligent Systems Design and Engineering Applications (ISDEA), P533, DOI 10.1109/ISDEA.2014.126
   Lo CY, 2013, PHOTOGRAMM REC, V28, P7, DOI 10.1111/j.1477-9730.2012.00703.x
   Mandal S, 2013, IEEE IMAGE PROC, P967, DOI 10.1109/ICIP.2013.6738200
   Setayesh M, 2012, P IEEE C EV COMP, P10
   Setayesh M, 2013, INFORM SCIENCES, V246, P28, DOI 10.1016/j.ins.2013.05.031
   Vaiter S, 2013, IEEE T INFORM THEORY, V59, P2001, DOI 10.1109/TIT.2012.2233859
   Wan SA, 2008, C IND ELECT APPL, P999, DOI 10.1109/ICIEA.2008.4582665
   Wang GB, 2015, IEEE T MED IMAGING, V34, P930, DOI 10.1109/TMI.2014.2371392
   Zhang J, 2007, P 8 ACIS INT C ART I, V3, P259
   Zhang XM, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P275
   Zhao D- P, 2015, OPT TECH, V41, P380
   Zheng Z., 2015, Applied Mathematics Information Sciences, P3169, DOI DOI 10.12785/AMIS/090646
   [朱晓临 Zhu Xiaolin], 2012, [图学学报, Journal of Graphics], V33, P72
NR 25
TC 7
Z9 11
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17839
EP 17854
DI 10.1007/s11042-015-3097-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800014
DA 2024-07-18
ER

PT J
AU dos Santos, JM
   de Moura, ES
   da Silva, AS
   Torres, RD
AF dos Santos, Joyce Miranda
   de Moura, Edleno Silva
   da Silva, Altigran Soares
   Torres, Ricardo da Silva
TI Color and texture applied to a signature-based bag of visual words
   method for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval (CBIR); Image descriptor; Indexing;
   Textual signature; Visual word
ID DESCRIPTORS
AB This article addresses the problem of representation, indexing and retrieval of images through the signature-based bag of visual words (S-BoVW) paradigm, which maps features extracted from image blocks into a set of words without the need of clustering processes. Here, we propose the first ever method based on the S-BoVW paradigm that considers information of texture to generate textual signatures of image blocks. We also propose a strategy that represents image blocks with words which are generated based on both color as well as texture information. The textual representation generated by this strategy allows the application of traditional text retrieval and ranking techniques to compute the similarity between images. We have performed experiments with distinct similarity functions and weighting schemes, comparing the proposed strategy to the well-known cluster-based bag of visual words (C-BoVW) and S-BoVW methods proposed previously. Our results show that the proposed strategy for representing images is a competitive alternative for image retrieval, and overcomes the baselines in many scenarios.
C1 [dos Santos, Joyce Miranda; de Moura, Edleno Silva; da Silva, Altigran Soares] Univ Fed Amazonas, Inst Comp, Ave Gen Rodrigo Otavio 3000, BR-69077000 Manaus, AM, Brazil.
   [dos Santos, Joyce Miranda] Fed Inst Educ Sci & Technol Amazonas, Ave Sete Setembro 1975, BR-69020120 Manaus, AM, Brazil.
   [Torres, Ricardo da Silva] Univ Estadual Campinas, Inst Comp, Ave Albert Einstein 400, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Federal de Amazonas; Instituto Federal do Amazonas (IFAM);
   Universidade Estadual de Campinas
RP dos Santos, JM (corresponding author), Univ Fed Amazonas, Inst Comp, Ave Gen Rodrigo Otavio 3000, BR-69077000 Manaus, AM, Brazil.; dos Santos, JM (corresponding author), Fed Inst Educ Sci & Technol Amazonas, Ave Sete Setembro 1975, BR-69020120 Manaus, AM, Brazil.
EM mds.joyce@gmail.com
RI da Silva, Altigran/JCO-8664-2023; Torres, Ricardo da S./C-4526-2012
OI da Silva, Altigran/0000-0002-8992-495X; Miranda dos Santos,
   Joyce/0000-0002-4624-3441
FU CNPq fellowship; CAPES; E-vox/FAPEAM; FAPESP [2010/52113-5,
   2013/50169-1, 2013/50155-0]; Fundacao de Amparo a Pesquisa do Estado de
   Sao Paulo (FAPESP) [13/50155-0, 10/52113-5] Funding Source: FAPESP
FX Authors thank CAPES, E-vox/FAPEAM, FAPESP, (grants #2010/52113-5,
   #2013/50169-1, and #2013/50155-0) and CNPq fellowship grants (Edleno S.
   de Moura, Altigran S. da Silva and Ricardo Torres) for the financial
   support.
CR [Anonymous], 1983, INTRO MODERN INFORM
   [Anonymous], J INFORM DATA MANAGE
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   dos Santos JM, 2015, PATTERN RECOGN LETT, V65, P1, DOI 10.1016/j.patrec.2015.06.023
   Douze M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P687, DOI 10.1145/2647868.2654892
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Nister David, 2006, CVPR
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Saraiva PC, 2016, MULTIMODAL QUERY EXP
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Takala V, 2005, IMAGE ANAL, P13
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vidal MLA, 2012, INT C PATT RECOG, P1960
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
NR 30
TC 14
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16855
EP 16872
DI 10.1007/s11042-016-3955-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100037
DA 2024-07-18
ER

PT J
AU Liao, L
   Huang, YH
   Liu, XM
AF Liao Lang
   Huang Yonghong
   Liu Xingming
TI Study on the mining method for specific fault data of multimedia sensor
   networks in cloud computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia sensor networks; Specific fault data; Mining; Decision tree
   method; In cloud computing environment
AB When traditional methods are used to mine specific fault data of multimedia sensor networks in cloud computing environment, the related specific fault features are just simply extracted from the database, and the dynamic changes of specific data fault characteristics in the database are ignored, also, the mining performance of specific fault data is reduced, there exist many other limitations. A mining method for specific fault data of multimedia sensor networks in cloud computing environment based on decision tree method is proposed, after pretreatments like interference filtration, data integration and data reduction are applied to multimedia data, the decision tree method is introduced to generate fault discrimination tree, according to the characteristics of specific fault data to acquire refined discrimination rules, and complete fault classification, so as to realize the mining for specific fault data. The experimental results show that the proposed method has very high accuracy and efficiency of the mining, and requires low energy consumption, also has strong adaptability.
C1 [Liao Lang; Liu Xingming] Shenzhen Inst Informat Technol, Dept Comp Sci, Shenzhen 518172, Peoples R China.
   [Huang Yonghong] Chongqing Univ Posts & Telecommun, Chongqing 400065, Peoples R China.
C3 Shenzhen Institute of Information Technology; Chongqing University of
   Posts & Telecommunications
RP Huang, YH (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing 400065, Peoples R China.
EM huangyonghong5643@163.com
RI liu, jianyang/JXL-6273-2024
FU Guangdong province natural science foundation project [2015 a030310511]
FX Support by: Guangdong province natural science foundation project, the
   project number: 2015 a030310511.
CR Abaei G, 2015, KNOWL-BASED SYST, V74, P28, DOI 10.1016/j.knosys.2014.10.017
   Abdi A, 2015, TECTONOPHYSICS, V649, P130, DOI 10.1016/j.tecto.2015.03.004
   Ahmed E, 2015, WIREL NETW, V21, P1193, DOI 10.1007/s11276-014-0843-6
   Al-Ariki HDE, 2016, WIREL NETW
   Audet P, 2015, CAN J FOREST RES, V45, P364, DOI 10.1139/cjfr-2014-0330
   Bhatt R, 2015, WIREL NETW, P1
   Bissig T, 2015, ORE GEOL REV, V65, P327, DOI 10.1016/j.oregeorev.2014.09.027
   Botros NS, 2015, ORE GEOL REV, V70, P173, DOI 10.1016/j.oregeorev.2015.04.014
   Burns EM, 2016, HEALTH AFFAIR, V35, P415, DOI 10.1377/hlthaff.2015.0788
   Karapetrou S, 2016, ENG STRUCT, V112, P114, DOI 10.1016/j.engstruct.2016.01.009
   Khan SH, 2015, PATTERN RECOGN, V48, P458, DOI 10.1016/j.patcog.2014.08.024
   Lee C, 2016, WIREL NETW, V22, P69, DOI 10.1007/s11276-015-0953-9
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Monaro RM, 2015, IEEE T POWER DELIVER, V30, P1487, DOI 10.1109/TPWRD.2014.2372007
   Moss S, 2016, INT J CLIN PRACT, V70, P312, DOI 10.1111/ijcp.12784
   Naoi M, 2015, TECTONOPHYSICS, V649, P100, DOI 10.1016/j.tecto.2015.02.025
   Newswise, 2015, LITIGATING RIGHTS CH, P827
   Pavel AB, 2016, BMC SYST BIOL, V10, P1, DOI DOI 10.1186/S12918-016-0260-9)
   Re DL, 2016, J APPL GEOPHYS, V124, P148
   Sang J, 2015, LANCET, V378, P1917
   Tosun S, 2015, IEEE T COMPUT AID D, V34, P1
   Tsao L, 2016, ERGONOMICS, P1
   Wu F, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/293271
   Yang CS, 2015, APPL INTELL, V43, P913, DOI 10.1007/s10489-015-0674-x
   Yousefpour A., 2015, WIREL NETW, P1
   Zhang Y, 2015, ENVIRON EARTH SCI, V74, P1
   Zimek A, 2015, MACH LEARN, V98, P121, DOI 10.1007/s10994-013-5334-y
NR 28
TC 0
Z9 0
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17113
EP 17128
DI 10.1007/s11042-016-3671-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500013
DA 2024-07-18
ER

PT J
AU Valderas, P
   Torres, V
   Mansanet, I
   Pelechano, V
AF Valderas, Pedro
   Torres, Victoria
   Mansanet, Ignacio
   Pelechano, Vicente
TI A mobile-based solution for supporting end-users in the composition of
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE End-user development; Service composition; Processmodelling; Mobile
   development
AB Currently, technologies and applications evolve to create eco-systems made up of a myriad of heterogeneous and distributed services that are accessible anytime and anywhere. Even though these services can be used individually, it is their coordinated and combined usage what provide an added value to end-users. In addition, user's wide adoption of mobile devices for daily activities have fostered a shift in the role played by end-users towards Internet data and services. However, existing solutions to service composition are not targeted to ordinary end-users. More easy-to-use tools have to be offered to end-users to make sure that they are successfully accepted and used by them. To this end, the work presented in this paper supports end-users in the creation of service compositions by using mobile devices. We present a Domain Specific Visual Language (DSVL) for end-users that allows them to create service compositions. A tool specifically designed for mobile devices supports this DSVL.
C1 [Valderas, Pedro; Torres, Victoria; Mansanet, Ignacio; Pelechano, Vicente] Univ Politecn Valencia, Pros Res Ctr, Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Valderas, P (corresponding author), Univ Politecn Valencia, Pros Res Ctr, Valencia, Spain.
EM pvalderas@pros.upv.es; vtorres@pros.upv.es; imansanet@pros.upv.es;
   pele@pros.upv.es
RI Pelechano, Vicente/S-4344-2016; Valderas, Pedro/X-3605-2018; Torres,
   Victoria/B-3828-2017
OI Pelechano, Vicente/0000-0003-1090-230X; Valderas,
   Pedro/0000-0002-4156-0675; Torres, Victoria/0000-0002-2039-2174
FU MINECO under the project SMART ADAPT [TIN2013-42981-P]; ERDF
FX This work has been developed with the support of MINECO under the
   project SMART ADAPT TIN2013-42981-P and co-financed with ERDF.
CR [Anonymous], 2000, Software Cost Estimation with COCOMO II
   Athreya B, 2012, S VIS LANG HUM CEN C, P75, DOI 10.1109/VLHCC.2012.6344486
   Atoma, 2015, AT TOUCH MAG
   Ayora C, 2013, LECT NOTES BUS INF P, V147, P246
   BPDM, 2014, BUSINESS PROCESS DEF, Vii
   Casati F, 1998, THESIS
   Couper MP, 2004, SOC SCI COMPUT REV, V22, P111, DOI 10.1177/0894439303256555
   Cuccurullo Stefania, 2011, End-User Development. Proceedings Third International Symposium, IS-EUD 2011, P289, DOI 10.1007/978-3-642-21530-8_28
   Dadam P, 2009, COMPUT SCI-RES DEV, V23, P81, DOI 10.1007/s00450-009-0068-6
   Danado J, 2014, J VISUAL LANG COMPUT, V25, P297, DOI 10.1016/j.jvlc.2014.03.005
   Danado J, 2010, LECT NOTES COMPUT SC, V6369, P118
   Dey AK, 2006, LECT NOTES COMPUT SC, V3968, P254
   Engestrom Y., 1999, PERSPECTIVES ACTIVIT, DOI DOI 10.1017/CBO9780511812774
   Galitz WO, 2002, DESIGN PRINCIPLES TE
   Gil M, 2013, SCI COMPUT PROGRAM, V78, P1987, DOI 10.1016/j.scico.2013.03.002
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Haines W, 2010, ACM WORKSH US CENTR, P42
   Häkkilä J, 2005, LECT NOTES COMPUT SC, V3585, P927, DOI 10.1007/11555261_73
   ICIS, 2015, INT COMP INT SERV SU
   Larman C, 2003, COMPUTER, V36, P47, DOI 10.1109/MC.2003.1204375
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Liberman H, 2006, END USER DEV EMERGIN, V9, P427
   Lucci G, 2014, LECT NOTES COMPUT SC, V8742, P182, DOI 10.1007/978-3-662-44811-3_11
   Mansanet I, 2014, 10 JORN CIENC ING SE, P25
   Mansanet I, 2015, 11 JORN CIENC ING SE
   Neil T., 2014, Mobile design pattern gallery: UI patterns for smartphone apps
   Nielsen J., 2020, 10 Usability Heuristics for User Interface Design
   Renger M, 2008, LECT NOTES BUS INF P, V10, P61
   Repenning A, 2006, HUM COM INT, V9, P51
   Runeson P, 2009, EMPIR SOFTW ENG, V14, P131, DOI 10.1007/s10664-008-9102-8
   SEGAL J, 2005, ACM SIGSOFT SOFTWARE, V30, P1
   Serral E, 2013, COMPUT J, V56, P87, DOI 10.1093/comjnl/bxs019
   Tasker, 2015, TASK TOT AUT ANDR
   Uden L, 2008, INFORM RES, V13
   Valderas P, 2006, INT J WEB ENG TECHN, V3, P4
   van Deursen A, 2000, ACM SIGPLAN NOTICES, V35, P26, DOI 10.1145/352029.352035
   Weber B, 2008, DATA KNOWL ENG, V66, P438, DOI 10.1016/j.datak.2008.05.001
   Welie M., 2000, 2000 PATT LANG PROGR, P13
   Yu J, 2012, DATA KNOWL ENG, V72, P202, DOI 10.1016/j.datak.2011.10.005
NR 39
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16315
EP 16345
DI 10.1007/s11042-016-3910-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100012
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, CY
   Kong, XW
   Li, C
AF Wang Cai-yin
   Kong Xiang-wei
   Li Chao
TI Process color watermarking: the use of visual masking and dot gain
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Process color; CMYK color space; Visual mask; Dot
   gain; Fidelity printing
ID PRINT-SCAN; SCHEME; IMAGES; ROTATION; ROBUST
AB Subtractive-Color-Reproduction is the fundamental mechanism in 4-color process printing, which employs CMYK (cyan, magenta, yellow and black) dots for color reproduction. Watermarks embedded in RGB images are distorted when the image is transformed from what to process color for printing usage. Based on the feature of CMYK color space and human visual system, this paper presents a robust CMYK watermarking algorithm for printing images, which embeds an informative watermark and a structure template signal in DCT domain of the Yellow information channel and DFT domain of the black information channel respectively. The embedded template enables robustness against geometric distortions in the print-scanning process. Another spatial visual mask is proposed to reshape the embedded energy after it is inverted to the spatial domain, which significantly improves the color fidelity and the image quality. In addition, a dot gain compensation model is put forward for color correction. A series of proof tests have been carried out on an offset press, which show that the watermark preserves the fidelity of the image and can be extracted with a high quality; moreover, a remarkable fidelity of color and tones on printed copies is well preserved.
C1 [Wang Cai-yin; Kong Xiang-wei] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.
   [Wang Cai-yin; Li Chao] Dalian Polytech Univ, Sch Light Ind & Chem Engn, Dalian 116034, Liaoning, Peoples R China.
C3 Dalian University of Technology; Dalian Polytechnic University
RP Wang, CY (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.; Wang, CY (corresponding author), Dalian Polytech Univ, Sch Light Ind & Chem Engn, Dalian 116034, Liaoning, Peoples R China.
EM wcyvivien@126.com; kongxw@dlut.edu.cn; dlpulc@gmail.com
RI Kong, Xiangwei/IWL-9350-2023
CR Agarwal H., 2014, MULTIMED TOOLS APPL, V74, P1
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Cao P, 2013, CN, CN, Patent No. [102184428 B, 102184428]
   Chang Chin-chen, 2002, Journal of China Institute of Communications, V23, P9
   Chen PY, 2015, IMAGING SCI J, V63, P273, DOI 10.1179/1743131X15Y.0000000010
   Ford A., 1998, COLOUR SPACE CONVERS
   Fu MS, 2003, SIGNAL PROCESS, V83, P2171, DOI 10.1016/S0165-1684(03)00173-7
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4117, DOI 10.1109/TIP.2012.2198221
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kaur Blossom., 2011, International Journal of Advances in Engineering Technology, V1, P72
   Lefebvre F, 2001, MULT SIGN PROC 2001, P511
   Li Xin-Wei, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P675, DOI 10.1109/ICGEC.2010.172
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu H, 2012, P SOC PHOTO-OPT INS, V8303
   Makbol NM, 2014, I S INTELL SIG PROC, P48, DOI 10.1109/ISPACS.2014.7024423
   Namedanian M, 2013, J IMAGING SCI TECHN, V57, DOI 10.2352/J.ImagingSci.Technol.2013.57.2.020504
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Pramila A, 2008, LECT NOTES COMPUT SC, V5041, P279
   Rani A, 2016, MULTIMED TOOLS APPL, V75, P1027, DOI 10.1007/s11042-014-2344-0
   Reed A M, 2002, ELECT IMAGING 2002, P222
   Rentzeperis I, 2015, J VISION, V15, DOI 10.1167/15.9.13
   Solanki K, 2004, IEEE IMAGE PROC, P39
   Tokar T, 2007, P 17 INT C RAD, P1
   Wang C, 2010, P 17 IEEE INT C IM P, P26
   [王彩印 Wang Caiyin], 2014, [光电子·激光, Journal of Optoelectronics·Laser], V25, P2186
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei B, 2014, J TAIYUAN NORMAL U N, V13, P63
   Weige L, 2011, ACTA OPT SINICA, V31
   Yong X, 2014, CYBER ENABLED DISTRI, P286
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
   Zhu X, 2008, P 19 INT C PATT REC
   [No title captured]
NR 35
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16291
EP 16314
DI 10.1007/s11042-016-3909-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100011
DA 2024-07-18
ER

PT J
AU Xu, CH
   Zhu, J
   Huang, J
   Li, ZX
   Fung, GPC
AF Xu, Chuanhua
   Zhu, Jia
   Huang, Jin
   Li, Zhixu
   Fung, Gabriel Pui Cheong
TI A health management tool based smart phone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Health management; Classification; Smart phone
ID FEATURES
AB Nowadays smart phones are becoming more and more popular with the development of mobile technology. Phones are made more stronger and take more data related with user and it is also easier to collect information from smart phones than before. In the article, the tool we proposed aims to achieve the ability to predict and prevent complex diseases by mining multiple type of data that is collected by smart phones. It provides patients with health recommendations based on their daily diets and physiological information using Multimodal data based Health Recommendations module. In turn, users can interact with the smart phones to gain suggestions from historical results. The paper introduces the following: (i) Collecting users' physiological information to provide disease prediction; (ii) Analyzing diet images to obtain users' eating habits; (iii) Health recommendations based on the results of (i) and (ii).
C1 [Xu, Chuanhua; Zhu, Jia; Huang, Jin] South China Normal Univ, Comp Sci, 55 West ZhongShan Ave, Guangzhou, Guangdong, Peoples R China.
   [Li, Zhixu] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
   [Fung, Gabriel Pui Cheong] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
C3 South China Normal University; Soochow University - China; Chinese
   University of Hong Kong
RP Zhu, J; Huang, J (corresponding author), South China Normal Univ, Comp Sci, 55 West ZhongShan Ave, Guangzhou, Guangdong, Peoples R China.
EM jzhu@m.scnu.edu.cn; huangjin@m.scnu.edu.cn
RI Zhou, Xiangfeng/KDO-8724-2024; Zhou, Xiaofang/C-6169-2013
OI Zhou, Xiaofang/0000-0001-6343-1455; Zhu, Jia/0000-0002-5959-390X
FU Natural Science Foundation of Guangdong Province, China
   [2015A030310509]; National Science Foundation of China [61370229,
   61272067, 61303049, 61402313]; S&T Projects of Guangdong Province
   [2015A030401087, 2015B010110002, 2016A030303055, 2016B030305004,
   2016B010109008]
FX This work was supported by the Natural Science Foundation of Guangdong
   Province, China (No. 2015A030310509), the National Science Foundation of
   China (61370229, 61272067, 61303049, 61402313), and the S&T Projects of
   Guangdong Province (2015A030401087, 2015B010110002, No. 2016A030303055,
   No. 2016B030305004, 2016B010109008).
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   [Anonymous], IEEE T KNOWLEDGE DAT
   [Anonymous], CONTEXT BASED RECOMM
   [Anonymous], 2015, ICLR
   [Anonymous], 2012, P SIGGRAPH ASIA 2012
   [Anonymous], 2007, P AAAI C ART INT
   [Anonymous], ACM INT JOINT C PERV
   [Anonymous], 2015, P IEEE INT C MULT EX
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], UBS NOVEL NEWS RECOM
   [Anonymous], CNN BASED FOOD IMAGE
   [Anonymous], FAST FOOD RECOGNITIO
   [Anonymous], DEEP LEARNING NEURAL
   [Anonymous], DIAGNOSIS HEART DIS
   [Anonymous], 2007, COLLABORATIVE FILTER
   [Anonymous], 2014, 2014 INT C LEARNING
   Bosch M, 2011, IEEE IMAGE PROC, P1789, DOI 10.1109/ICIP.2011.6115809
   Bossard L., 2014, FOOD 101 MINING DISC, P446
   Cheplygina Veronika, 2013, Multiple Classifier Systems. 11th International Workshop, MCS 2013. Proceedings, P13, DOI 10.1007/978-3-642-38067-9_2
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hoashi H., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P296, DOI 10.1109/ISM.2010.51
   Kagaya H, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1085, DOI 10.1145/2647868.2654970
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li JQ, 2015, COMPUT IND, V69, P81, DOI 10.1016/j.compind.2014.09.004
   Liu C., 2016, DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided Dietary Assessment
   Liu FY, 2015, PATTERN RECOGN, V48, P2983, DOI 10.1016/j.patcog.2015.04.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pouladzadeh P, 2015, LECT NOTES COMPUT SC, V9281, P441, DOI 10.1007/978-3-319-23222-5_54
   Pouladzadeh P, 2014, IEEE T INSTRUM MEAS, V63, P1947, DOI 10.1109/TIM.2014.2303533
   Wang JG, 2015, NEUROCOMPUTING, V167, P195, DOI 10.1016/j.neucom.2015.04.076
   XiaoYan Shi, 2008, 2008 International Seminar on Business and Information Management (ISBIM 2008), P264, DOI 10.1109/ISBIM.2008.191
   Zhao ZD, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P478, DOI 10.1109/WKDD.2010.54
   Zheng K, 2012, VLDB J, P1
   Zhu J, 2014, SCIENTOMETRICS, V98, P2255, DOI 10.1007/s11192-013-1151-0
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 40
TC 1
Z9 1
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17541
EP 17558
DI 10.1007/s11042-016-4220-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500037
DA 2024-07-18
ER

PT J
AU Fang, SC
   Xie, HT
   Chen, ZN
   Zhu, SA
   Gu, XY
   Gao, XY
AF Fang, Shancheng
   Xie, Hongtao
   Chen, Zhineng
   Zhu, Shiai
   Gu, Xiaoyan
   Gao, Xingyu
TI Detecting Uyghur text in complex background images with convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Uyghur; Text detection; Text localization; Convolutional neural network
ID LINE DETECTION; RECOGNITION; LOCALIZATION; DATASET
AB Uyghur text detection is crucial to a variety of real-world applications, while little researches put their attention on it. In this paper, we develop an effective and efficient region-based convolutional neural network for Uyghur text detection in complex background images. The characteristics of the network include: (1) Three region proposal networks are used to improve the recall, which simultaneously utilize feature maps from different convolutional layers. (2) The overall architecture of our network is in the form of fully convolutional network, and global average pooling is applied to replace the fully connected layers in the classification and bounding box regression layers. (3) To fully utilize the baseline information, Uyghur text lines are detected directly by the network in an end-to-end fashion. Experiment results on benchmark dataset show that our method achieves an F-measure of 0.83 and detection time of 0.6 s for each image in a single K20c GPU, which is much faster than the state-of-the-art methods while keeps competitive accuracy.
C1 [Fang, Shancheng; Xie, Hongtao; Gu, Xiaoyan] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing, Peoples R China.
   [Fang, Shancheng; Xie, Hongtao; Gu, Xiaoyan] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Chen, Zhineng] Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China.
   [Zhu, Shiai] Univ Ottawa, Ottawa, ON, Canada.
   [Gao, Xingyu] Chinese Acad Sci, Inst Software, Lab Parallel Software & Computat Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS;
   University of Ottawa; Chinese Academy of Sciences; Institute of
   Software, CAS
RP Xie, HT (corresponding author), Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing, Peoples R China.; Xie, HT (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
EM xiehongtao@iie.ac.cn
RI chen, zhineng/AAD-6723-2020; Gao, Xingyu/AAL-3288-2021
OI Gao, Xingyu/0000-0002-4660-8092
FU National Nature Science Foundation of China [61303171, 61303175];
   "trategic Priority Research Program" of the Chinese Academy of Sciences
   [XDA06031000]
FX This work is supported by the National Nature Science Foundation of
   China (61303171,61303175), the "trategic Priority Research Program" of
   the Chinese Academy of Sciences (XDA06031000).
CR Ahmad AMA, 2012, ADV INTEL SOFT COMPU, V145, P261
   [Anonymous], 2015, CORR
   [Anonymous], CORR
   [Anonymous], ICMR
   [Anonymous], 2015 INT C COMM INF
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, Deep Residual Learning for Image Recognition
   [Anonymous], 2013, ARXIV PREPRINT ARXIV, DOI [DOI 10.48550/ARXIV.1312.6229, 10.48550/arXiv.1312.6229]
   Bai JF, 2014, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2014.7025518
   Bai JF, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853823
   Ben Halima M, 2010, LECT NOTES COMPUT SC, V6298, P648, DOI 10.1007/978-3-642-15696-0_60
   Chen ZY, 2015, IEEE DATA MINING, P71, DOI 10.1109/ICDM.2015.156
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jianjun Chen, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P406, DOI 10.1007/978-3-319-48896-7_40
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Lin M., 2013, P 2 INT C LEARNING R
   Moradi M, 2010, 2010 6 IR C MACH VIS, P1
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shivakumara P, 2014, MULTIMED TOOLS APPL, V72, P515, DOI 10.1007/s11042-013-1385-0
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Xie HT, 2013, J VIS COMMUN IMAGE R, V24, P635, DOI 10.1016/j.jvcir.2013.04.012
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yousfi S, 2015, PROC INT CONF DOC, P1221, DOI 10.1109/ICDAR.2015.7333958
   Yuan J, 2015, MULTIMED TOOLS APPL, V74, P859, DOI 10.1007/s11042-013-1702-7
   Zayene O, 2015, PROC INT CONF DOC, P996, DOI 10.1109/ICDAR.2015.7333911
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P297, DOI 10.1145/2964284.2967230
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
NR 53
TC 12
Z9 12
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15083
EP 15103
DI 10.1007/s11042-017-4538-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400030
DA 2024-07-18
ER

PT J
AU Liu, SS
   Wang, AH
   Wang, HD
   Li, SY
   Li, ML
   Liang, J
AF Liu, Shanshan
   Wang, Anhong
   Wang, Haidong
   Li, Suyue
   Li, Meiling
   Liang, Jie
TI Adaptive residual-based distributed compressed sensing for soft video
   multicasting over wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless video multicasting; Adaptive residual distributed compressed
   sensing; Optimal power allocation
AB Recently, multicasting of video signals has become a useful technology in wireless networks, in which the main challenge is to scalably serve multiple receivers that have different channel characteristics. In this paper, we propose an adaptive residual-based distributed compressed-sensing scheme for soft video multicast (ARDCS-cast). At the encoder, we first adaptively determine if a block in a non-reference frame should be measured directly or predictively during compressed-sensing. The resulting adaptive measurements from non-reference frames are then packeted together with the measurements of the reference frames. We further derive the optimal power allocation scheme for the measurements from each frame within each packet. The packets are then transmitted over the wireless channel. At the decoder, the receivers with different channel characteristics obtain different numbers of packets and reconstruct videos with different quality. Experimental results show that the proposed ARDCS-cast is more effective than the state-of-the-art SoftCast-2D, SoftCast-3D and DCS-cast schemes in both unicast and multicast scenarios.
C1 [Liu, Shanshan; Wang, Anhong; Wang, Haidong; Li, Suyue; Li, Meiling] Taiyuan Univ Sci & Technol, Inst Digital Multimedia & Commun, Taiyuan 030024, Peoples R China.
   [Liang, Jie] Simon Fraser Univ, Sch Engn Sci, Burnaby, BC, Canada.
C3 Taiyuan University of Science & Technology; Simon Fraser University
RP Wang, AH (corresponding author), Taiyuan Univ Sci & Technol, Inst Digital Multimedia & Commun, Taiyuan 030024, Peoples R China.
EM wah_ty@163.com; jiel@sfu.ca
RI Liu, shanshan/AAT-3465-2020
OI Liang, Jie/0000-0003-3003-4343
FU National Natural Science Foundation of China [61272262, 61210006];
   Shanxi Scholarship Council of China [2014-056]; Program for New Century
   Excellent Talent in Universities [NCET-12-1037]; International
   Cooperative Program of Shanxi Province [2015081015]; Scientific and
   Technological project of Shanxi Province [2015031003-2]; National
   Science Foundation for Young Scientists of Shanxi Province, China
   [2014021021-2]; The Program of "One hundred Talented People" of Shanxi
   Province
FX This work has been supported in part by National Natural Science
   Foundation of China (No. 61272262 and No. 61210006), The Program of "One
   hundred Talented People" of Shanxi Province, Research Project Supported
   by Shanxi Scholarship Council of China (2014-056), Program for New
   Century Excellent Talent in Universities (NCET-12-1037), International
   Cooperative Program of Shanxi Province (No. 2015081015), Scientific and
   Technological project of Shanxi Province (2015031003-2), and National
   Science Foundation for Young Scientists of Shanxi Province, China
   (2014021021-2)
CR [Anonymous], 2015, EURASIP J ADV SIGNAL
   [Anonymous], PREPRINT
   [Anonymous], SOFTCAST ONE VIDEO S
   Bougher B., 2015, LEADING EDGE, V34, P1256
   Carmi AY, 2014, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-642-38398-4_1
   Do TT, 2009, IEEE IMAGE PROC, P1393, DOI 10.1109/ICIP.2009.5414631
   Edward A, 2016, IEEE VEH TECHNOL MAG, V11, P79
   Etoh M, 2005, P IEEE, V93, P111, DOI 10.1109/JPROC.2004.839605
   Fan C, 2015, MULTIMED TOOLS APPL, P1
   Fan X., 2015, CIRC SYST VIDEO TECH, V25, P1
   Fan XP, 2013, IEEE T CIRC SYST VID, V23, P1040, DOI 10.1109/TCSVT.2013.2249019
   Fan XM, 2012, IEEE NUCL SCI CONF R, P1
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Garrido-Cantos R, 2016, MULTIMED TOOLS APPL, V75, P497, DOI 10.1007/s11042-014-2302-x
   Hanzo L., 2001, WIRELESS VIDEO COMMU
   Jakubczak S., 2011, PROC MOBICOM, P289
   Jakubczak S, 2010, ACM SIGCOMM COMP COM, V40, P449, DOI 10.1145/1851275.1851257
   Lee J, 2015, WIREL NETW, V21, P115, DOI 10.1007/s11276-014-0773-3
   Li CB, 2011, 2011 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P2077, DOI 10.1109/WCNC.2011.5779474
   Liang J, 2016, SIGNAL PROCESS, V126, P96, DOI 10.1016/j.sigpro.2015.10.026
   Liu XL, 2014, SIGNAL PROCESS-IMAGE, V29, P361, DOI 10.1016/j.image.2014.01.005
   Lorenz DA, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2689662
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Pudlewski S, 2012, IEEE T MOBILE COMPUT, V11, P1
   Reimers UH, 2006, P IEEE, V94, P173, DOI 10.1109/JPROC.2005.861004
   Schenkel M B, 2010, P SPIE INT SOC OPT E, V7744
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang AH, 2014, SIGNAL PROCESS-IMAGE, V29, P599, DOI 10.1016/j.image.2014.03.002
   Xiang S, 2011, COMM IEEE INT C IEEE, P1
   Xiong RQ, 2016, IEEE T IMAGE PROCESS, V25, P1820, DOI 10.1109/TIP.2016.2535288
   Xiong Ruiyin, 2014, G CAST GRADIENT BASE, P133
   Yu L, 2014, IEEE T CIRC SYST VID, V24, P331, DOI 10.1109/TCSVT.2013.2273675
NR 33
TC 3
Z9 3
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15587
EP 15606
DI 10.1007/s11042-016-3859-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900017
DA 2024-07-18
ER

PT J
AU Xiong, Y
   Zhang, YF
   Wang, DL
   Feng, S
AF Xiong, Yu
   Zhang, Yifei
   Wang, Daling
   Feng, Shi
TI Picture or it didn't happen: catch the truth for events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event truth detection; Event visual summary; Cross-modal retrieval;
   Multi-modal data fusion
ID FRAMEWORK
AB Pictures spreading on the Internet are essential for the authenticity of events. Each day, huge amounts of data are published on social media, and many of them are bound with a picture in order to increase their readability and reliability. On social media, the bound pictures often have little relevance to their context. The thing changes when it comes to events in our daily lives. The events on social media are often bound with the spot shooting. People are more willing to believe the events described by these pictures. Nevertheless, it is nightmare to plow through millions of pictures which contain enormous noises and redundancies on social media. Moreover, in order to attract readers, the dishonest often mislead the public, by spreading sensational sham news with specious pictures. This behave severely destroys the honesty in our society. In this paper, we visualize an event from its bound pictures, based on the consistency between picture and event. First, we extract high reliable pictures for the event, by analyzing the consistency on temporal and textual dimensions. Second, the consistency of pictures is optimized in a related picture graph, in order to push up representative pictures of an event. The experiments on a real dataset verify the effectiveness of our method in most cases, comparing to several up-to-date methods.
C1 [Xiong, Yu; Zhang, Yifei; Wang, Daling; Feng, Shi] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Peoples R China.
   [Zhang, Yifei; Wang, Daling; Feng, Shi] Northeastern Univ, Minist Educ, Key Lab Med Image Comp, Shenyang 110819, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Xiong, Y (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Peoples R China.
EM xiongyu@research.neu.edu.cn; zhangyifei@cse.neu.edu.cn;
   wangdaling@cse.neu.edu.cn; fengshi@cse.neu.edu.cn
RI Zhang, Yifei/GRO-3001-2022
FU National Natural Science Foundation of China [61402091, 61370074];
   Fundamental Research Funds for the Central Universities of China
   [N140404012]
FX The project is supported by National Natural Science Foundation of China
   (61402091, 61370074), the Fundamental Research Funds for the Central
   Universities of China under Grant N140404012.
CR Alqadah F., 2011, Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, P795
   [Anonymous], 2010, P ACM SIGMOD INT C M
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], 2014, PROC VLDB ENDOW
   Bertini M., 2005, PROC 7 ACM SIGMM INT, P89
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao Y, 2014, MULTIMED TOOLS APPL, V74, P11
   Cao YP, 2015, MULTIMED TOOLS APPL, V74, P11499, DOI 10.1007/s11042-014-2247-0
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Dao MS, 2014, MULTIMED TOOLS APPL, V70, P25, DOI 10.1007/s11042-012-1153-6
   Dekel T, 2013, IEEE I CONF COMP VIS, P977, DOI 10.1109/ICCV.2013.125
   Gozali JP, 2012, IEEE INT CONF MULTI, P25, DOI 10.1109/ICMEW.2012.12
   Hsieh LC, 2014, J VIS COMMUN IMAGE R, V25, P384, DOI 10.1016/j.jvcir.2013.12.010
   Hua X.-S., 2013, Proceedings of the 21st ACM International Conference on Multimedia, Oct. 21-25, ACM, P243
   JIN Feng, 2013, THESIS
   Kaneko T, 2016, NEUROCOMPUTING, V172, P143, DOI 10.1016/j.neucom.2015.02.081
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Luo J., 2008, ACM International Conference on Multimedia, P1071, DOI DOI 10.1145/1459359.1459574MULTIMEDIA-MM'PLACE
   McParlane P.J., 2014, P 23 ACM INT C INF K, P1459
   Rafailidis D, 2013, PATTERN RECOGN, V46, P3358, DOI 10.1016/j.patcog.2013.05.023
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rosani A, 2015, IEEE T MULTIMEDIA, V17, P1359, DOI 10.1109/TMM.2015.2441003
   Ruocco M, 2014, MULTIMED TOOLS APPL, V70, P55, DOI 10.1007/s11042-012-1087-z
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun Y., 2012, P 5 ACM INT C WEB SE, P663, DOI DOI 10.1145/2124295.2124373
   Sun Y, 2012, PROC VLDB ENDOW, V5, P394, DOI 10.14778/2140436.2140437
   Wang C, 2013, IEEE DATA MINING, P767, DOI 10.1109/ICDM.2013.53
   Wang Y., 2012, Proceedings of the 20th ACM International Conference on Multimedia, P865, DOI [DOI 10.1145/2393347.239633216, 10.1145/2393347.239633216]
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wu F, 2005, LECT NOTES COMPUT SC, V3767, P993
   Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214
   Xiong Y, 2014, LECT NOTES COMPUT SC, V8485, P96, DOI 10.1007/978-3-319-08010-9_12
   Yang FB, 2016, NEUROCOMPUTING, V172, P159, DOI 10.1016/j.neucom.2014.08.104
   Yang Y, 2010, PATTERN RECOGN, V43, P2927, DOI 10.1016/j.patcog.2010.02.015
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Zhang H, 2006, LECT NOTES COMPUT SC, V4261, P979
   Zhao Xun., 2013, SEMANTIC WEB WEB SCI, P55, DOI [10.1007/978-1-4614-6880-6_5, DOI 10.1007/978-1-4614-6880-6_5]
NR 38
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15681
EP 15706
DI 10.1007/s11042-016-3864-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900021
DA 2024-07-18
ER

PT J
AU Zhong, JL
   Gan, YF
   Young, J
   Huang, L
   Lin, PY
AF Zhong, Junliu
   Gan, Yanfen
   Young, Janson
   Huang, Lian
   Lin, Peiyu
TI A new block-based method for copy move forgery detection under image
   geometric transforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy move forgery detection; Block-based method; Discrete radial
   harmonic Fourier moments; Image geometrical distortions
AB Copy move forgery detection (CMFD) is one of the most active subtopic in forgery scheme. The methods of CMFD are divided into to block-based method and keypoint-based method in general. Compared with keypoint-based method, block-based method can detect undetectable detail without morphology segmentation. But many block-based methods detect the plain copy-move forgeries only. They have been incompetent to detect the post-processing operations such as various geometrical distortions, and then fail to detect the forgery regions accurately. Therefore, this paper presents an improved block-based efficient method for CMFD. Firstly, after pre-processing, an auxiliary overlapped circular block is presented to divide the forged image into overlapped circular blocks. The local and inner image feature is extracted by the Discrete Radial Harmonic Fourier Moments (DRHFMs) with the overlapped circular block from the suspicious image. Then, the similar feature vectors of blocks are searched by 2 Nearest Neighbors (2NN) test. Euclidean distance and correlation coefficient is employed to filter these features and then remove the false matches. Morphologic operation is employed to delete the isolated pixels. A series of experiments are done to analyze the performance for CMFD. Experimental results show that the new DRHFMs can obtain outstanding performance even under image geometrical distortions.
C1 [Zhong, Junliu; Huang, Lian; Lin, Peiyu] Guangdong Mech & Elect Coll, Sch Informat Engn, Guangzhou 510550, Guangdong, Peoples R China.
   [Gan, Yanfen] Guangdong Univ Foreign Studies, South China Business Coll, Sch Informat Sci & Technol, Guangzhou 510545, Guangdong, Peoples R China.
   [Young, Janson] Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Foreign Studies; Guangdong University of
   Technology
RP Gan, YF (corresponding author), Guangdong Univ Foreign Studies, South China Business Coll, Sch Informat Sci & Technol, Guangzhou 510545, Guangdong, Peoples R China.
EM Junliuzhong@foxmail.com; Fannygyf@foxmail.com; Jansonyoung@foxmail.com;
   Ramram@126.com; PeiyuLin633@163.com
FU Guangzhou philosophy and social science "Thirteen Five" project- Digital
   image forgery cause public opinion incident prevention countermeasures
   and technical research based on internet information security
   [2016gzqn23]
FX This work is supported by the 2016 Guangzhou philosophy and social
   science "Thirteen Five" project- Digital image forgery cause public
   opinion incident prevention countermeasures and technical research based
   on internet information security (No. 2016gzqn23).
CR Amerini I, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-18
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2011, 19 IR C EL ENG
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Debbarma S., 2014, 2014 International Conference on Informatics, Electronics Vision, P1
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gan YF, 2016, NONLINEAR DYNAM, V84, P341, DOI 10.1007/s11071-015-2524-0
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Kashyap A, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P396, DOI 10.1109/ICSPCom.2013.6719820
   Popescu AC, 2004, 2004515 DARTM COLL D
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   [秦娟 Qin Juan], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P919
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Serra G, 2014, SIFT BASED FORENSIC
   Huynh-Kha T, 2015, PROC INT CONF ADV, P44, DOI 10.1109/ATC.2015.7388368
   Ustubioglu B, 2015, 2015 38TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P540, DOI 10.1109/TSP.2015.7296321
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zheng J., 2016, MULTIMED TOOLS APPL, V76, P1, DOI [10.1007/s11042-016-3988, DOI 10.1007/S11042-016-3988]
   Zhong JL, 2016, CHAOS SOLITON FRACT, V89, P115, DOI 10.1016/j.chaos.2015.10.010
NR 23
TC 46
Z9 47
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14887
EP 14903
DI 10.1007/s11042-016-4201-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400019
DA 2024-07-18
ER

PT J
AU Li, J
   Yang, XY
   Liao, X
   Pan, F
   Zhang, MQ
AF Li, Jun
   Yang, Xiaoyuan
   Liao, Xin
   Pan, Feng
   Zhang, Minqing
TI A game-theoretic method for designing distortion function in spatial
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Distortion function; Game theory; Strategic adaptivity
ID STEGANALYSIS
AB Most modern secure image steganographic schemes define distortion functions for constraining the embedding changes to those parts of the image that are difficult to model such as textured or noisy regions. However, thus arguments disregard Kerckhoffs' principle: the warden also knows the adaptivity criterion as well and may be able reproduce or estimate it. This paper proposes a new idea that the embedding distortion is designed based on game theory. We present a two-player zero-sum game between steganographer and attacker related to the security of practical steganography, and there exists a unique mixed strategy Nash equilibrium. The distortion function is first achieved from the original method S-UNIWARD (Spatial-UNIversal Wavelet Relative Distortion), and then we readjust the distortion function according to the above Nash equilibrium. The new distortion not only ensures the embedding changes focus on textured region but also correlates to the Kerckhoffs' principle. Experiment results show that the statistical security of the proposed method is improved by approximately 6.2 % with the features of modern rich models.
C1 [Li, Jun; Yang, Xiaoyuan; Zhang, Minqing] Engn Univ Chinese Peoples Armed Police Force, Elect Dept, Key Lab Cryptog & Informat Secur Chinese Peoples, Xian 710086, Peoples R China.
   [Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Jun; Pan, Feng] Engn Univ Chinese Peoples Armed Police Force, Inst Network & Informat Secur, Xian 710086, Peoples R China.
   [Liao, Xin] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
C3 Hunan University; Chinese Academy of Sciences; Institute of Software,
   CAS
RP Li, J (corresponding author), Engn Univ Chinese Peoples Armed Police Force, Elect Dept, Key Lab Cryptog & Informat Secur Chinese Peoples, Xian 710086, Peoples R China.; Liao, X (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.; Li, J (corresponding author), Engn Univ Chinese Peoples Armed Police Force, Inst Network & Informat Secur, Xian 710086, Peoples R China.; Liao, X (corresponding author), Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
EM lijun9250lj@163.com; xinliao@hnu.edu.cn
RI , lj/ADC-2026-2022; Liao, Xin/X-2736-2018; Liao, Xin/ITT-1021-2023
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [61379152, 61402162]; Hunan
   Provincial Natural Science Foundation of China [14JJ7024]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20130161120004]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61379152, No. 61402162), Hunan Provincial Natural
   Science Foundation of China (Grant No. 14JJ7024), and Specialized
   Research Fund for the Doctoral Program of Higher Education (Grant No.
   20130161120004).
CR [Anonymous], 2015, P SPIE MEDIA WATER H
   [Anonymous], P EL IM SEC STEG WAT
   [Anonymous], P SPIE INT SOC OPTIC
   [Anonymous], 2012, Decision and Game Theory for Security (GameSec)
   [Anonymous], 1883, J SCI MILITAIRES
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], P SPIE INT SOC OPTIC
   Benjamin J., 2013, P 21 EUR SIGN PROC C, P1
   Böhme R, 2009, LECT NOTES COMPUT SC, V5806, P15, DOI 10.1007/978-3-642-04431-1_2
   Bohme R., 2010, Advanced Statistical Steganalysis
   Cayre F, 2008, IEEE T INF FOREN SEC, V3, P1, DOI 10.1109/TIFS.2007.916006
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Ettinger JM, 1998, LECT NOTES COMPUT SC, V1525, P319
   Filler T, 2010, IEEE INT WORKS INFOR
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J., 2009, INFORM HIDING
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Niu Ke, 2015, Journal of Xidian University, V42, P165, DOI 10.3969/j.issn.1001-2400.2015.04.027
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Schottle Pascal, 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P125, DOI 10.1007/978-3-642-36373-3_9
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
NR 33
TC 5
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12417
EP 12431
DI 10.1007/s11042-016-3632-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200011
DA 2024-07-18
ER

PT J
AU Zeng, KH
   Dong, MC
AF Zeng, Kehan
   Dong, Mingchui
TI Signal-to-noise ratio estimation based on Haar wavelet for
   cardiovascular bio-signals in web-based e-healthcare system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiovascular bio-signals; White noise; Haar wavelet; SNR estimation;
   Monte Carlo test
ID AIDED SNR ESTIMATION; OFDM SIGNALS; SEPARATION
AB The law of energy distribution of white noise (WN) in Haar wavelet decomposition levels (WDLs) of cardiovascular bio-signals including Phonocardiogram (PCG), Electrocardiogram (ECG), and Sphygmogram (SPG) is analyzed statistically. The analytical results indicate that for WN signals, energy proportion of the 2nd WDL to the 1st WDL is 0.5 approximately, which is verified by Monte Carlo test. For PCG, ECG and SPG signals, when sampling frequency is 4 kHz for PCG, 400 Hz for ECG, and 160 Hz for SPG, energies of the 1st WDL and 2nd WDLs are almost the same; this is validated by theoretical analysis and practical observation on collected datasets. Based on the wavelet energy distribution laws of WN and cardiovascular bio-signals, equations are created to estimate energy of WN, energy of bio-signals, and SNR. Experimental results show that the proposed SNR estimation method for cardiovascular bio-signals mixed with WN has the normalized mean square error of less than 0.1 in all cases considered.
C1 [Zeng, Kehan; Dong, Mingchui] Univ Macau, Dept Elect & Comp Engn, Ave Univ, Taipa, Macau, Peoples R China.
   [Zeng, Kehan] Huizhou Univ, Dept Comp Sci, Huizhou 516007, Peoples R China.
C3 University of Macau; Huizhou University
RP Zeng, KH (corresponding author), Univ Macau, Dept Elect & Comp Engn, Ave Univ, Taipa, Macau, Peoples R China.
EM kehanzeng1980@gmail.com
FU Research Committee of University of Macau [MYRG2014-00060-FST]; Science
   and Technology Development Fund (FDCT) of Macau S.A.R [016/2012/A1]
FX This work was supported in part by the Research Committee of University
   of Macau under Grant No. MYRG2014-00060-FST, and in part by the Science
   and Technology Development Fund (FDCT) of Macau S.A.R under Grant No.
   016/2012/A1.
CR Ali A, 2013, MULTIMED TOOLS APPL, V66, P201, DOI 10.1007/s11042-011-0791-4
   [Anonymous], 2010, NEUROCOMPUTING
   Cui T, 2006, IEEE COMMUN LETT, V10, P25, DOI 10.1109/LCOMM.2006.1576558
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   Jin SH, 2008, MULTIMED TOOLS APPL, V36, P285, DOI 10.1007/s11042-007-0148-1
   Kabir MA, 2012, BIOMED SIGNAL PROCES, V7, P481, DOI 10.1016/j.bspc.2011.11.003
   Karagiannis A, 2011, IEEE T INF TECHNOL B, V15, P11, DOI 10.1109/TITB.2010.2091648
   Lee YH, 2013, MULTIMED TOOLS APPL, V63, P45, DOI 10.1007/s11042-012-1031-2
   Lei WK, 2012, COMPUT METH PROG BIO, V108, P1199, DOI 10.1016/j.cmpb.2012.06.003
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   Lourenco A, 2014, MULTIMED TOOLS APPL, V70, P433, DOI 10.1007/s11042-013-1397-9
   Masood S, 2013, MULTIMED TOOLS APPL, V63, P93, DOI 10.1007/s11042-012-1015-2
   Messer SR, 2001, MICROELECTR J, V32, P931, DOI 10.1016/S0026-2692(01)00095-7
   Paul AS, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P2249
   Pauluzzi DR, 2000, IEEE T COMMUN, V48, P1681, DOI 10.1109/26.871393
   Vázquez RR, 2012, BIOMED SIGNAL PROCES, V7, P389, DOI 10.1016/j.bspc.2011.06.005
   Sastry KS, 2013, WIRELESS PERS COMMUN, V70, P165, DOI 10.1007/s11277-012-0686-3
   Socheleau FX, 2008, IEEE COMMUN LETT, V12, P813, DOI 10.1109/LCOMM.2008.081134
   Suchetha M, 2013, BIOMED SIGNAL PROCES, V8, P575, DOI 10.1016/j.bspc.2013.05.001
   Sur A, 2014, MULTIMED TOOLS APPL, V68, P805, DOI 10.1007/s11042-012-1078-0
   Tang H, 2010, IEEE T BIO-MED ENG, V57, P2438, DOI 10.1109/TBME.2010.2051225
   Tsalaile T, 2007, P 15 INT C EUSIPCO P, P1231
   Valentina A, 2012, IEEE TECHNOL BIOMED, V59, P219
   Zeng KH, 2014, CIRC SYST SIGNAL PR, V33, P2987, DOI 10.1007/s00034-014-9784-7
   Zia MK, 2011, IEEE ENG MED BIO, P5880, DOI 10.1109/IEMBS.2011.6091454
NR 25
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11739
EP 11749
DI 10.1007/s11042-015-2544-2
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000034
DA 2024-07-18
ER

PT J
AU Choi, JA
   Ho, YS
AF Choi, Jung-Ah
   Ho, Yo-Sung
TI High throughput entropy decoder design for H.265/HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.265/high efficiency video coding (HEVC); Throughput improvement;
   Complexity estimation; Linear regression; Entropy coding; CABAC
AB The H.265/high efficiency video coding (HEVC) standard employs context-based adaptive binary arithmetic coding (CABAC) as a single entropy coding method. Despite the high coding efficiency of CABAC, its context modeling process limits the throughput and prevents effective parallelization, particularly at the decoder. In this paper, we design a new joint rate distortion-decoding complexity (RDDC) cost function to improve the throughput performance at the H.265/HEVC decoder side. The proposed RDDC cost function includes the complexity term based on a newly designed complexity model using the linear regression. Experimental results show that the proposed method reduces the number of context-coded bins up to 19.8 % without significant coding loss.
C1 [Choi, Jung-Ah; Ho, Yo-Sung] GIST, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Choi, JA; Ho, YS (corresponding author), GIST, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
EM jachoi@gist.ac.kr; hoyo@gist.ac.kr
RI Choi, Jung Ah/J-5693-2012
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [2011-0030079]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (2011-0030079).
CR Bjontegaard G., 2008, VCEGAI11
   Bossen F, 2012, 10 JCT VC M
   Bross B, 2012, 10 JCT VC M
   Chen J, 2012, 8 JCT VC M
   Choi JA, 2015, SIGNAL IMAGE VIDEO P, V9, P1067, DOI 10.1007/s11760-013-0542-2
   Ho Y, 2012, P INT C EMB SYST INT
   Huang C, 2013, P 2013 IE INT SOL ST
   Kim S, 2012, 8 JCT VC M
   Lainema J, 2012, 8 JCT VC M
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Nguyen T, 2012, 8 JCT VC M
   Sze V, 2012, IEEE J SOLID-ST CIRC, V47, P8, DOI 10.1109/JSSC.2011.2169310
NR 12
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9877
EP 9890
DI 10.1007/s11042-016-3583-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300034
DA 2024-07-18
ER

PT J
AU Mousavi, SM
   Naghsh, A
   Manaf, AA
   Abu-Bakar, SAR
AF Mousavi, Seyed Mojtaba
   Naghsh, Alireza
   Manaf, Azizah A.
   Abu-Bakar, S. A. R.
TI A robust medical image watermarking against salt and pepper noise for
   brain MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain MRI image; Robust medical watermarking; Salt and pepper noise;
   Authentication; Electronic patient record; DICOM
ID AUTHENTICATION; RECOVERY; SCHEME
AB The ever-growing numbers of medical digital images and the need to share them among specialists and hospitals for better and more accurate diagnosis require that patients' privacy be protected. During the transmission of medical images between hospitals or specialists through the network, the main priority is to protect a patient's documents against any act of tampering by unauthorised individuals. Because of this, there is a need for medical image authentication scheme to enable proper diagnosis on patient. In addition, medical images are also susceptible to salt and pepper impulse noise through the transmission in communication channels. This noise may also be intentionally used by the invaders to corrupt the embedded watermarks inside the medical images. A common drawback of existing watermarking methods is their weakness against salt and pepper noise. The research carried out in this work addresses the issue of designing a new watermarking method that can withstand high density of salt and pepper noise for brain MRI images. For this purpose, combination of a spatial domain watermarking method, channel coding and noise filtering schemes are used. The region of non-interest (RONI) of MRI images from five different databases are used as embedding area and electronic patient record (EPR) is considered as embedded data. The quality of watermarked image is evaluated using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM), and the accuracy of the extracted watermark is assessed in terms of Bit Error Rate (BER).
C1 [Mousavi, Seyed Mojtaba; Manaf, Azizah A.] Univ Teknol Malaysia, Adv Informat Sch, Menara Razak, Jalan Sultan Yahya Petra, Kuala Lumpur 5410, Malaysia.
   [Naghsh, Alireza] Islamic Azad Univ, Najafabad Branch, Dept Elect Engn, Najafabad, Isfahan, Iran.
   [Abu-Bakar, S. A. R.] Univ Teknol Malaysia, Dept Elect & Comp Engn, Fac Elect Engn, Comp Vis Video & Image Proc CvviP Res Lab, Skudai 81310, Johor, Malaysia.
C3 Universiti Teknologi Malaysia; Islamic Azad University; Universiti
   Teknologi Malaysia
RP Manaf, AA (corresponding author), Univ Teknol Malaysia, Adv Informat Sch, Menara Razak, Jalan Sultan Yahya Petra, Kuala Lumpur 5410, Malaysia.
EM azizaham.kl@utm.my
RI Mousavi, Seyed Mojtaba/J-4314-2014; Manaf, Azizah Abdul/Q-4838-2019;
   naghsh, alireza/AAO-2400-2021
OI naghsh, alireza/0000-0002-0842-0419
FU Universiti Teknologi Malaysia (UTM); Universiti Teknologi Malaysia
   [R.K130000.7838.4F643]
FX The authors would like to thank Universiti Teknologi Malaysia (UTM) for
   their educational and financial support. This work is conducted at
   Advanced Informatics School (AIS) and funded by Universiti Teknologi
   Malaysia (Grant no. R.K130000.7838.4F643).
CR Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Anithadevi D, 2015, J BIOMED ENG MED IMA, V2
   [Anonymous], INT J SIGNAL IMAGE P
   Arab F, 2016, MULTIMED TOOLS APPL, V75, P10855, DOI 10.1007/s11042-015-2800-5
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Bi N, 2007, IEEE T IMAGE PROCESS, V16, P1956, DOI 10.1109/TIP.2007.901206
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Colin RR, 2008, IEICE T INF SYST, VE91D, P862, DOI 10.1093/ietisy/e91-d.3.862
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Feng X, 2012, 9 INT C FUZZ SYST KN
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Jabade V.S., 2011, International Journal of Computer Applications, V31, P28
   Khalid Shamsul Kamal Ahmad, 2013, The Second International Conference on Informatics Engineering & Information Science (ICIEIS2013), P96
   Khalili M, 2012, ABS12064256 CORR
   Li-Qun K, 2009, 1 INT C INF SCI ENG, P1047, DOI [10.1109/ICISE.2009.60, DOI 10.1109/ICISE.2009.60]
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Mousavi SM, 2015, J DIGIT IMAGING, V28, P417, DOI 10.1007/s10278-015-9770-z
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   MUHAREMAGIC E, 2006, MULTIMEDIA WATERMARK, P91
   Pan W, 2010, LECT NOTES COMPUT SC, V5939, P153
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Ramamurthy N, 2012, INT J COMPUT SCI NET, V1, P13
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Reddy V, 2015, INT J BIOSCI BIOTECH, V7, P55, DOI 10.14257/ijbsbt.2015.7.6.07
   Shahidan M., 2012, THESIS
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Sumalatha R, 2015, INT C EL EL SIGN COM, P1, DOI 10.1109/EESCO.2015.7254039
   Zamani M, 2015, TELECOMMUN SYST, V59, P291, DOI 10.1007/s11235-014-9936-x
NR 29
TC 37
Z9 40
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10313
EP 10342
DI 10.1007/s11042-016-3622-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300055
DA 2024-07-18
ER

PT J
AU Altaf, M
   Khan, FA
   Qadri, N
   Ghanbari, M
   Dudley, SE
AF Altaf, Muhammad
   Khan, Farman Ali
   Qadri, Nadia
   Ghanbari, Mohammed
   Dudley, Sandra E.
TI Adaptive robust video broadcast via satellite
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video broadcast; Error resiliency; H.264/AVC; Raptor codes
ID TRANSMISSION; H.264/AVC
AB With increasing demand for multimedia content over channels with limited bandwidth and heavy packet losses, higher coding efficiency and stronger error resiliency is required more than ever before. Both the coding efficiency and error resiliency are two opposing processes that require appropriate balancing. On the source encoding side the video encoder H.264/AVC can provide higher compression with strong error resiliency, while on the channel error correction coding side the raptor code has proven its effectiveness, with only modest overhead required for the recovery of lost data. This paper compares the efficiency and overhead of both the raptor codes and the error resiliency techniques of video standards so that both can be balanced for better compression and quality. The result is also improved by confining the robust stream to the period of poor channel conditions by adaptively switching between the video streams using switching frames introduced in H.264/AVC. In this case the video stream is initially transmitted without error resiliency assuming the channel to be completely error free, and then the robustness is increased based on the channel conditions and/or user demand. The results showed that although switching can increase the peak signal to noise ratio in the presence of losses but at the same time its excessive repetition can be irritating to the viewers. Therefore to evaluate the perceptual quality of the video streams and to find the optimum number of switching during a session, these streams were scored by different viewers for quality of enhancement. The results of the proposed scheme show an increase of 3 to 4 dB in peak signal to noise ratio with acceptable quality of enhancement.
C1 [Altaf, Muhammad; Qadri, Nadia] COMSATS Inst Informat Technol, Dept Elect Engn, Wah, Pakistan.
   [Khan, Farman Ali] COMSATS Inst Informat Technol, Attock, Pakistan.
   [Ghanbari, Mohammed] Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
   [Dudley, Sandra E.] London South Bank Univ, Sch Engn, London, England.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI);
   University of Tehran; London South Bank University
RP Altaf, M (corresponding author), COMSATS Inst Informat Technol, Dept Elect Engn, Wah, Pakistan.
EM mohammadaltaf@gmail.com; farmanmarwat@ciit-attock.edu.pk;
   nadianqadri@googlemail.com; ghan@essex.ac.uk; dudleyms@lsbu.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Altaf,
   Muhammad/0000-0001-5016-9478; Dudley-McEvoy, Sandra/0000-0002-6431-5357
CR Ahmad S, 2011, IEEE T MULTIMEDIA, V13, P92, DOI 10.1109/TMM.2010.2093511
   Alphand O, 2005, P IEEE GLOBC 2005
   Altaf M, 2011, J MOB MULTIMEDIA JMM, V7, P216
   [Anonymous], 2004, 302304 ETSI EN
   [Anonymous], 2005, WHY DIG FOUNT RAPT C
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], 2007, 26346 3GPP TS
   Bernardini R., 2005, Proceedings. DCC 2006. Data Compression Conference
   Byers JW, 2002, IEEE J SEL AREA COMM, V20, P1528, DOI 10.1109/JSAC.2002.803996
   Cataldi P, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P263
   Chatziparaskevas P, 2011, INT J SATELL COMM N, V29, P163, DOI 10.1002/sat.959
   Choi BS, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON UBIQUITOUS AND FUTURE NETWORKS, P137, DOI 10.1109/ICUFN.2009.5174300
   Donner A, 2002, 20 AIAA INT COMM SAT
   Gardikis G, 2009, INT J DIGIT MULTIMED, V2009, DOI 10.1155/2009/879290
   Gotta A, 2008, 2008 INTERNATIONAL WORKSHOP ON SATELLITE AND SPACE COMMUNICATIONS, CONFERENCE PROCEEDINGS, P234, DOI 10.1109/IWSSC.2008.4656797
   Hellge C, 2011, IEEE T MULTIMEDIA, V13, P551, DOI 10.1109/TMM.2011.2129499
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   Kumar S, 2003, ELSEVIER J VIS COMMU, V17, P1
   Kushwaha H, 2008, P IEEE, V96, P155, DOI 10.1109/JPROC.2007.909917
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Luby M, 2007, IEEE T BROADCAST, V53, P235, DOI 10.1109/TBC.2007.891703
   Neale J, 2001, IEEE COMMUN MAG, V39, P192, DOI 10.1109/35.910607
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Pandya A. U, 2013, INT J RES ENG TECHNO, V2, P601
   Schierl T, 2006, IEEE WIREL COMMUN, V13, P96, DOI 10.1109/WC-M.2006.250365
   Shokrollahi A., 2004, P IEEE INT S INF THE
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Skinnemoen H, 2004, IEEE J SEL AREA COMM, V22, P508, DOI 10.1109/JSAC.2004.823430
   Skinnemoen H, 2013, INT J SATELL
   Soldani C, 2006, P INT C DIG TEL
   Son N, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P385, DOI 10.1109/CIT.2008.Workshops.106
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Stockhammer T., 2007, MULTIMEDIA IP WIRELE, P13, DOI DOI 10.1016/B978-012088480-3/50003-5
   Thomos N, ARXIV12114014CSIT
   VARS V, 2001, SGI6 ITUT
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
NR 36
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7785
EP 7801
DI 10.1007/s11042-016-3426-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Go, K
   Kim, M
   Kang, S
   Yoon, Y
AF Go, Kyungmin
   Kim, Myungchul
   Kang, Sungwon
   Yoon, Yohaan
TI A systematic reallocation and prioritization scheme for error-resilient
   transmission of video packets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video packets; Packetreallocation; Prioritized transmission; Quality of
   Service; Wi-Fi
ID H.264/AVC; PRIORITY; TRANSPORT
AB This paper proposes a novel video transmission scheme that provides error-resilient transmission of encoded video on a per-packet basis over wireless networks. In conventional schemes, the error-resilient transmission of encoded video has been conducted using the unit of a video frame or data partition. However, in order to provide higher error-resilient transmission for significant video data that critically impacts the decoding when it is lost, the unit of prioritized video transmission should be more fine-grained. Moreover, the transmission overhead incurred by the application of the prioritized video transmission should be further minimized. In order to overcome these limitations, this paper proposes a scheme that identifies and reallocates significant video data within the unit of inter-frame dependency, which is a hierarchical relationship between video frames, in order to enhance the compression efficiency such as a group of pictures. Consequently, the encoded video is transmitted with different transmission priorities on a per-packet basis depending on the packet's significance for decoding. The evaluation results with standard definition and high definition videos demonstrate that the proposed scheme has significant performance enhancements over the conventional video frame prioritization scheme in terms of transmission overhead, transmitted video data utilization, peak signal-to-noise ratio, and subject quality test.
C1 [Go, Kyungmin; Kim, Myungchul; Kang, Sungwon; Yoon, Yohaan] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, M (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
EM mck@kaist.ac.kr
RI Kim, Myungchul/C-1730-2011
OI Go, Kyungmin/0000-0002-8410-5971
FU National Research Foundation of Korea - Korean Government
   [NRF-2012R1A2A2A01008244]
FX This work was supported by the National Research Foundation of Korea
   Grant funded by the Korean Government (NRF-2012R1A2A2A01008244).
CR [Anonymous], 2011, P 21 INT WORKSH NETW, DOI DOI 10.1145/1989240.1989248
   [Anonymous], 2005, 8021E IEEE 11
   [Anonymous], P ACM MMSYS 14 MAT
   [Anonymous], 8021D IEEE
   [Anonymous], 2014, High Efficiency Video Coding. Coding Tools and Specification
   [Anonymous], EURASIP J WIRELESS C
   [Anonymous], 2300912012 ISOIEC
   [Anonymous], 2014, Cisco visual networking index: Global mobile data traffic forecast update
   Baccaglini E, 2014, INT J COMMUN SYST, V27, P3822, DOI 10.1002/dac.2578
   Dong YN, 2015, WIRELESS PERS COMMUN, V82, P215, DOI 10.1007/s11277-014-2204-2
   Feng NN, 2015, J SIGNAL PROCESS SYS, V78, P115, DOI 10.1007/s11265-013-0826-3
   Greengrass J, 2009, IEEE INTERNET COMPUT, V13, P74, DOI 10.1109/MIC.2009.40
   Haghani E, 2009, IEEE T MULTIMEDIA, V11, P1140, DOI 10.1109/TMM.2009.2026099
   Huo YK, 2015, IEEE COMMUN SURV TUT, V17, P1166, DOI 10.1109/COMST.2015.2392378
   ITU, 2008, Rec. ITU-T P.910
   Kambhatla K.K. R., 2015, Springer Multimedia Tools Applications - Appeared Online, P1
   Ke C., 2015, SILICON NANOWIRES FA, P1, DOI [10.1007/978-3-319-18293-3, DOI 10.1007/978-3-319-18293-3]
   Lai CF, 2011, MULTIMEDIA SYST, V17, P299, DOI 10.1007/s00530-010-0211-z
   Lee J, 2009, IEEE COMMUN MAG, V47, P111, DOI 10.1109/MCOM.2009.4907416
   Nazir S, 2014, SPRINGER MULTIMED TO, P1
   Richardson Iain E, 2011, The H. 264 advanced video compression standard
   Schierl T, 2009, IEEE WIREL COMMUN, V16, P64, DOI 10.1109/MWC.2009.5300304
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Siebert P, 2009, IEEE T BROADCAST, V55, P407, DOI 10.1109/TBC.2008.2012019
   Souryal MR, 2006, IEEE WCNC, P1402
   Srinivasan SK, 2010, IEEE T BROADCAST, V56, P281, DOI 10.1109/TBC.2010.2049610
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian X., 2011, REV CAVLC ARITHMETIC, P29
   Wang HD, 2014, MULTIMED TOOLS APPL, V69, P621, DOI 10.1007/s11042-012-1131-z
   Wiegand T, 2012, SPRINGER SCI BUS MED, V636
   Wiegand T, 2011, IEEE SPECTRUM, V48, P50, DOI 10.1109/MSPEC.2011.5995902
   Yao XW, 2014, ACM SIGCOMM COMP COM, V44, P6
   Yaser PF, 2008, EURASIP J WIREL COMM, V11
   Zeadally S, 2011, IEEE SYST J, V5, P518, DOI 10.1109/JSYST.2011.2165601
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 36
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6755
EP 6783
DI 10.1007/s11042-016-3351-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400030
DA 2024-07-18
ER

PT J
AU Minemura, K
   Wong, K
   Qi, XJ
   Tanaka, K
AF Minemura, Kazuki
   Wong, KokSheik
   Qi, Xiaojun
   Tanaka, Kiyoshi
TI A scrambling framework for block transform compressed image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scrambling; block transform; sketch attack; JPEG
ID VIDEO ENCRYPTION ALGORITHMS; WATERMARKING
AB In this work, we propose a scrambling framework for block transform compressed image. First, three attacks are proposed to sketch the outline of the original image directly from its scrambled counterpart by exploiting information deduced from the transformed components. Based on the proposed sketch attacks, a scrambling framework aiming to minimize the bitstream size overhead and prevent the leakage of visual information is put forward. In particular, the DC components are manipulated within each non-overlapping region to achieve the scrambling while simultaneously reducing the bitstream size overhead. The non-DC components are shuffled and substituted to generate a completely distorted image while preventing information leakage. The ideas are implemented in JPEG to verify its performance and compare to that of the conventional JPEG based scrambling methods. Results indicate that the proposed methods exhibit stable performance in terms of the bitstream size overhead when using different quality factors, and it is able to withstand the proposed sketch attacks as well as the classical cryptographic attacks.
C1 [Minemura, Kazuki; Wong, KokSheik] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Qi, Xiaojun] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
   [Tanaka, Kiyoshi] Shinshu Univ, Fac Engn, Nagano, Japan.
C3 Universiti Malaya; Utah System of Higher Education; Utah State
   University; Shinshu University
RP Wong, K (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM kazuki.minemura@siswa.um.edu.my; koksheik@um.edu.my; Xiaojun.Qi@usu.edu;
   ktanaka@shinshu-u.ac.jp
RI Wong, KokSheik/B-9796-2011
OI Wong, KokSheik/0000-0002-4893-2291
FU University Malaya [RG050-11ICT]
FX This work was supported by the University Malaya Research Grant (account
   number RG050-11ICT) under the purview of ICT & Computational Science
   Research Cluster, UM Research.
CR [Anonymous], 1994, Standard No. ISO/IEC 10918-1:1994
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   AYOUB F, 1984, IEE PROC-F, V131, P684, DOI 10.1049/ip-f-1.1984.0103
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   ISO/IEC, 2003, 14496102003 ISOIEC
   ISO/IEC, 2000, 1381822000 ISOIEC
   ISO/IEC, 1993, 1117231993 ISOIEC
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li WH, 2007, INT J COMPUT MATH, V84, P1367, DOI 10.1080/00207160701294376
   Lian SG, 2004, IEEE INFOR VIS, P217, DOI 10.1109/IV.2004.1320147
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Niu XA, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P308, DOI 10.1109/IIH-MSP.2008.207
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Pazarci M, 2002, IEEE T CONSUM ELECTR, V48, P345, DOI 10.1109/TCE.2002.1010141
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Subramanyam AV, 2014, MULTIMED TOOLS APPL, V71, P1311, DOI 10.1007/s11042-012-1272-0
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Takayama M, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1035
   Takayama M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1349, DOI 10.1109/ICME.2006.262789
   Tang Z, 2014, MULTIMED TOOLS APPL, P1, DOI 10.1007/s11042-014-1861-1
   The Independent JPEG Group's, 2012, IND JPEG GROUPS JPEG
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong K, 2010, 2010 4 INT S COMM CO, P1
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 34
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6709
EP 6729
DI 10.1007/s11042-016-3338-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400028
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Li, XF
   Feng, YC
AF Zhang, Xiaoli
   Li, Xiongfei
   Feng, Yuncong
TI Image fusion based on simultaneous empirical wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Empirical wavelet transforms; Data driven; Simultaneous
   image decomposition
ID INFORMATION
AB In this paper, a new multi-scale image fusion algorithm for multi-sensor images is proposed based on Empirical Wavelet Transform (EWT). Different from traditional wavelet transform, the wavelets of EWT are not fixed, but the ones generated according to the processed signals themselves, which ensures that these wavelets are optimal for processed signals. In order to make EWT can be used in image fusion, Simultaneous Empirical Wavelet Transform (SEWT) for 1D and 2D signals are proposed, by which different signals can be projected into the same wavelet set generated according to all the signals. The fusion algorithm constructed on the 2D SEWT contains three steps: source images are decomposed into a coarse layer and a detail layer first; then, the algorithm fuses detail layers using maximum absolute values, and fuses coarse layers using the maximum global contrast selection; finally, coefficients in all the fused layers are combined to obtain the final fused image using 2D inverse SEWT. Experiments on various images are conducted to examine the performance of the proposed algorithm. The experimental results have shown that the fused images obtained by the proposed algorithm achieve satisfying visual perception; meanwhile, the algorithm is superior to other traditional algorithms in terms of objective measures.
C1 [Zhang, Xiaoli; Li, Xiongfei; Feng, Yuncong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engineer, Minist Educ, Changchun 130012, Peoples R China.
   [Zhang, Xiaoli; Li, Xiongfei; Feng, Yuncong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Li, XF (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engineer, Minist Educ, Changchun 130012, Peoples R China.; Li, XF (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM xiongfei@jlu.edu.cn
RI Zhang, Xiaoli/ABC-2210-2021
FU Projects in the National Science & Technology Pillar Program, China
   [2012BAH48F02]; National Science Foundation of China [61272209];
   Technology Development Plan of Jilin Province [201105017]; Agreement of
   Science & Technology Development Project, Jilin Province [20150101014JC]
FX The authors would like to express our gratitude to the editors and
   anonymous reviewers for their comments and suggestions. The work was
   supported by Projects in the National Science & Technology Pillar
   Program, China (2012BAH48F02), National Science Foundation of China
   (Grant No. 61272209), Technology Development Plan of Jilin Province
   (201105017), and Agreement of Science & Technology Development Project,
   Jilin Province (No. 20150101014JC).
CR Chen T, 2005, INT GEOSCI REMOTE SE, P1150
   Geng P, MULTIMED TOOLS APPL, P1
   Gilles J, 2014, SIAM J IMAGING SCI, V7, P157, DOI 10.1137/130923774
   Gilles J, 2013, IEEE T SIGNAL PROCES, V61, P3999, DOI 10.1109/TSP.2013.2265222
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hariharan H, 2006, J PATTERN RECOGNIT R, V1, P16, DOI 10.13176/11.6
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li TJ, 2011, INFORM FUSION, V12, P85, DOI 10.1016/j.inffus.2010.03.007
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Loeckx D, 2010, IEEE T MED IMAGING, V29, P19, DOI 10.1109/TMI.2009.2021843
   Looney D, 2009, IEEE T SIGNAL PROCES, V57, P1626, DOI 10.1109/TSP.2008.2011836
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Petrovic V, 2005, OPT ENG, V44, DOI 10.1117/1.2009764
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Shao ZF, 2012, APPL OPTICS, V51, P1910, DOI 10.1364/AO.51.001910
   Sin AMK, 2005, IEEE T IMAGE PROCESS, V14, P241, DOI 10.1109/TIP.2004.840690
   Toet A, 2003, DISPLAYS, V24, P25, DOI 10.1016/S0141-9382(02)00069-0
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yang SY, 2010, INFORM FUSION, V11, P78, DOI 10.1016/j.inffus.2009.05.001
NR 23
TC 21
Z9 23
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8175
EP 8193
DI 10.1007/s11042-016-3453-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800026
DA 2024-07-18
ER

PT J
AU Kim, BH
   Kim, KC
   Hong, SE
   Oh, SY
AF Kim, Bong-Hyun
   Kim, Ki-Chan
   Hong, Sung-Eon
   Oh, Sang-Young
TI Development of cyber information security education and training system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Cyber security education; Training web server;
   Monitoring and reporting server; Virtual security web server
ID PROTECTION; MANAGEMENT
AB Due to recent expansion of internet, use of personal internet banking and E-commerce is rapidly increasing. Additionally, services and marketing in corporations, government and banks are rapidly increasing mostly at the internet shopping malls and web sites. Accordingly, there are increasing number of cyber attacks like intelligent and high-tech APT attack, cyber intrusion access and digitalized information. However, countermeasures, operation exercise and security education about these security accidents are not executed properly. Therefore, this study is to develop cyber information security training system based on the internet. Additionally, in order to deal with security accidents caused by malicious emails and attaching files that frequently occur at public institutions and private companies, information security education is tried to be executed targeting affiliated employees and education and training subjects using the system. Through this, security accidents caused by malicious emails could be prevented in advance and economic loss could be minimized by preventing information loss or paralysis state in computer system.
C1 [Kim, Bong-Hyun] Acad Ind Convergence Res, 1362 Wolpyeong Dong, Daejeon Metropolitan, South Korea.
   [Kim, Ki-Chan] Hanbat Natl Univ, Dept Elect Engn, 125 Dongseodaero, Daejeon Si, South Korea.
   [Hong, Sung-Eon] Cheongju Univ, Dept Land Management, Cheongwon Gu, Chungcheongbuk, South Korea.
   [Oh, Sang-Young] Youngdong Univ, Dept Business Adm, 310 Daehak Ro,Youngdong Eup, Chungcheongbuk Do, South Korea.
C3 Cheongju University
RP Oh, SY (corresponding author), Youngdong Univ, Dept Business Adm, 310 Daehak Ro,Youngdong Eup, Chungcheongbuk Do, South Korea.
EM culture@yd.ac.kr
RI Kim, Bong-Hyun/GWM-5912-2022
OI Kim, Bong-Hyun/0000-0002-7514-1268
CR [Anonymous], 2000, Security, V37, P43
   Barnett SF, 1996, P IEEE S SECUR PRIV, P26, DOI 10.1109/SECPRI.1996.502666
   Brancheau JC, 1996, MIS QUART, V20, P225, DOI 10.2307/249479
   Denning D. E., 1986, Proceedings of the 1986 IEEE Symposium on Security and Privacy (Cat. No.86CH2292-1), P118
   Dutta A, 2008, SYST DYNAM REV, V24, P349, DOI 10.1002/sdr.405
   HARRISON MA, 1976, COMMUN ACM, V19, P461, DOI 10.1145/360303.360333
   Jeong Tae-Seog, 2012, [Journal of Digital Convergence, 디지털융복합연구], V10, P1
   Kim Sang-Hoon, 2011, [The Journal of Society for e-Business Studies, 한국전자거래학회지], V16, P33
   LOCH KD, 1992, MIS QUART, V16, P173, DOI 10.2307/249574
   National Cyber Safety Center, 2013, J KOREAN INFORM SECU, V23, P9
   Park JaeYong, 2012, [Management & Information Systems Review, 경영과 정보연구], V31, P149
   Rhee HS, 2009, COMPUT SECUR, V28, P816, DOI 10.1016/j.cose.2009.05.008
   SALTZER JH, 1975, P IEEE, V63, P1278, DOI 10.1109/PROC.1975.9939
   Shin SJ, 2013, YOUR INNOVATION SECU
   Straub DW, 1998, MIS QUART, V22, P441, DOI 10.2307/249551
   Yang DI, 2013, INFORM SECURITY INTR
NR 16
TC 16
Z9 24
U1 1
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6051
EP 6064
DI 10.1007/s11042-016-3495-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500064
DA 2024-07-18
ER

EF