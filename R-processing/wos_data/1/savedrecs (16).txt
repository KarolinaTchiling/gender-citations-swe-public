FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Kim, Y
   Bok, K
   Son, I
   Park, J
   Lee, B
   Yoo, J
AF Kim, Yongmin
   Bok, Kyoungsoo
   Son, Ingook
   Park, Junho
   Lee, Byoungyup
   Yoo, Jaesoo
TI Positioning sensor nodes and smart devices for multimedia data
   transmission in wireless sensor and mobile P2P networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Positioning; Hole detection; Multimedia data transmission; Mobile P2P
   network; Wireless sensor network
ID HOP LOCALIZATION ALGORITHM; MANAGEMENT
AB In recent, studies on multimedia data transmission have been progressing in a wireless sensor network that consist of a large number of sensor nodes and a mobile P2P network that consists of a large of number of smart devices such as smart phones and wearable devices. When multimedia data such as image, audio, and video are transmitted, it is important to figure out the positions of a sensor nodes and a smart device in the networks. However, existing positioning schemes do not consider network holes that can occur in real application areas, thereby causing many errors during positioning. In this paper, we propose a new positioning scheme considering holes in wireless sensor and mobile P2P network environments. In the proposed scheme, holes are detected based on neighboring node density when holes exist in a network, and the position of a sensor node or a smart device is estimated by conducting distance correction based on the cumulative number of hole-boundary nodes. Through the proposed scheme, highly accurate sensor positioning can be performed even in circumstances where holes are present over a network. To verify the good performance of the proposed scheme, a performance evaluation is conducted by comparing it with existing schemes. It is shown through experiments that the proposed positioning scheme transmits multimedia data to the destination node without data loss when the holes in the network exist.
C1 [Kim, Yongmin] Chonnam Natl Univ, Dept Elect Commerce, Gwangju, South Korea.
   [Bok, Kyoungsoo; Yoo, Jaesoo] Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
   [Son, Ingook] KT DS Co Ltd, Seoul, South Korea.
   [Park, Junho] Agcy Def Dev, Daejeon, South Korea.
   [Lee, Byoungyup] Paichai Univ, Dept Cyber Secur, Daejeon, South Korea.
C3 Chonnam National University; Chungbuk National University; Agency of
   Defense Development (ADD), Republic of Korea; Pai Chai University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM ymkim@chonnam.ac.kr; ksbok@chungbuk.ac.kr; ikson@chungbuk.ac.kr;
   jhpark@chungbuk.ac.kr; bylee@pcu.ac.kr; yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) [IITP-2016-H8501-16-1013];
   MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   C-ITRC(Convergence Information Technology Research Center)
   [IITP-2016-H8601-16-1008]; National Research Foundation of Korea(NRF) -
   Ministry of Education [2014R1A1A2055778]; Korea Government(MSIP)
   [2016R1A2B3007527]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2016-H8501-16-1013) supervised by the
   IITP(Institute for Information & communication Technology Promotion), by
   the MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   C-ITRC(Convergence Information Technology Research Center)
   (IITP-2016-H8601-16-1008) supervised by the IITP(Institute for
   Information & communications Technology Promotion), and by the National
   Research Foundation of Korea(NRF) funded by the Ministry of
   Education(No. 2014R1A1A2055778) and the Korea Government(MSIP)(No.
   2016R1A2B3007527).
CR Aassie A. A, 2005, P WORKSH POS NAV COM, P224
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422
   Ammari HM, 2015, AD HOC SENS WIREL NE, V25, P1
   Bazzi A, 2016, AD HOC NETW, V36, P409, DOI 10.1016/j.adhoc.2015.06.005
   Bok KS, 2012, KSII T INTERNET INF, V6, P815, DOI 10.3837/tiis.2012.03.003
   Bulusu N, 2000, IEEE PERS COMMUN, V7, P28, DOI 10.1109/98.878533
   Chatzimilioudis Georgios., 2010, Proceedings of the Ninth ACM International Workshop on Data Engineering for Wireless and Mobile Access, MobiDE '10, P33
   Chen HY, 2008, C IND ELECT APPL, P1557, DOI 10.1109/ICIEA.2008.4582780
   Chen HY, 2008, IEICE T FUND ELECTR, VE91A, P2232, DOI 10.1093/ietfec/e91-a.8.2232
   Cheng L, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/962523
   Covino Federico, 2009, Journal of Mobile Multimedia, V5, P203
   Escolar S, 2014, PERS UBIQUIT COMPUT, V18, P449, DOI 10.1007/s00779-013-0663-1
   Estrin D, 2001, INT CONF ACOUST SPEE, P2033, DOI 10.1109/ICASSP.2001.940390
   Go S, 2014, IEICE T COMMUN, VE97B, P2560, DOI 10.1587/transcom.E97.B.2560
   Gunay FB, 2014, SIG PROCESS COMMUN, P1431, DOI 10.1109/SIU.2014.6830508
   Gustafsson F, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P553
   Guzzo N, 2014, L N INST COMP SCI SO, V140, P98, DOI 10.1007/978-3-319-13329-4_9
   Han GJ, 2013, TELECOMMUN SYST, V52, P2419, DOI 10.1007/s11235-011-9564-7
   He T., 2003, PROC 9 ANN INT C MOB, P81, DOI DOI 10.1145/938985.938995
   Hu Y, 2013, TELECOMMUN SYST, V53, P13, DOI 10.1007/s11235-013-9671-8
   Huang PH, 2011, SENSORS-BASEL, V11, P4358, DOI 10.3390/s110404358
   Huang Xiaolong, 2014, Journal of Networks, V9, P168, DOI 10.4304/jnw.9.1.168-175
   Li XY, 2015, J HEURISTICS, V21, P177, DOI 10.1007/s10732-014-9257-y
   Mahmood MA, 2015, COMPUT NETW, V79, P166, DOI 10.1016/j.comnet.2014.12.016
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Niculescu D, 2003, TELECOMMUN SYST, V22, P267, DOI 10.1023/A:1023403323460
   Parker R, 2007, IEEE T VEH TECHNOL, V56, P3371, DOI 10.1109/TVT.2007.907687
   Raheel MS, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPLICATIONS, SERVICES AND TECHNOLOGIES (NGMAST 2015), P311, DOI 10.1109/NGMAST.2015.64
   Rong Peng, 2006, 2006 3rd Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks (IEEE Cat. No. 06EX1523), P374
   Shah B, 2014, INT CON ADV INFO NET, P421, DOI 10.1109/AINA.2014.52
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Cao TM, 2014, AD HOC NETW, V20, P16, DOI 10.1016/j.adhoc.2014.03.002
   Wu M, 2016, INFORM SCIENCES, V329, P800, DOI 10.1016/j.ins.2015.10.004
   Yaghoubi F, 2014, IEEE COMMUN LETT, V18, P973, DOI 10.1109/LCOMM.2014.2320939
   Zeng Degui, 2014, Journal of Networks, V9, P1229, DOI 10.4304/jnw.9.5.1229-1236
   Zhu CS, 2014, WIREL COMMUN MOB COM, V14, P19, DOI 10.1002/wcm.1219
NR 37
TC 6
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17193
EP 17211
DI 10.1007/s11042-016-3794-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500018
DA 2024-07-18
ER

PT J
AU Li, YG
   Zhang, SC
   Cheng, DB
   He, W
   Wen, GQ
   Xie, Q
AF Li, Yonggang
   Zhang, Shichao
   Cheng, Debo
   He, Wei
   Wen, Guoqiu
   Xie, Qing
TI Spectral clustering based on hypergraph and self-re-presentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spectral clustering; Hypergraph; Row-sparse; Self-representation;
   Hypergraph Laplacian
AB Traditional spectral clustering methods cluster data samples with pairwise relationships usually illustrated as graphs. However, the relationships among the data in real life are much more complex than pairwise. Merely representing the complex relationships into pairwise will result in loss of information which is helpful for improving clustering results. Moreover, the data in real life are often with noise and outliers. Therefore, to solve the problems mentioned above, we introduce hypergraph to fully consider the complex relationships of the data and use the self-representation based row sparse a"" (2,1)-norm to weaken the effect of the noise. The main contribution of this work is to integrate self-representation and hypergraph together and extend graph based spectral clustering to hypergraph. After that, we propose the spectral hypergraph clustering method named Spectral Clustering based on Hypergraph and Self-representation (HGSR). Finally, we put forward an efficient optimal method to solve the proposed problem. Experiment results showed that our method prominently outperforms the graph based methods.
C1 [Li, Yonggang; Zhang, Shichao; Cheng, Debo; He, Wei; Wen, Guoqiu] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Xie, Qing] Wuhan Univ Technol, Wuhan 430070, Hubei, Peoples R China.
C3 Guangxi Normal University; Wuhan University of Technology
RP Zhang, SC (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM nhmlj@QQ.com; mtlyg2@sina.com; chengdebo8936@qq.com; risehnhew@163.com;
   wenguoqiu2008@163.com; felixxq@whut.edu.cn
RI Zhang, Shichao/JXW-9650-2024; Cheng, Debo/T-9106-2019; Cheng,
   Debo/Y-5226-2019; Zhang, Shichao/AAA-7608-2020
OI Cheng, Debo/0000-0002-0383-1462; Li, Yonggang/0000-0001-7867-9795
FU China "1000-Plan" National Distinguished Professorship; National Natural
   Science Foundation of China [61263035, 61573270, 61602353, 61672177];
   China 973 Program [2013CB329404]; China Key Research Program
   [2016YFB1000905]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011]; China Postdoctoral Science Foundation
   [2015M570837]; Guangxi Higher Institutions' Program of Introducing 100
   High-Level Overseas Talents; Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing; Guangxi
   "Bagui" Teams for Innovation and Research; Innovation Project of Guangxi
   Graduate Education [YCSZ2016046, YCSZ2016045]; project "Application and
   Research of Big Data Fusion in Inter-City Traffic Integration of The
   Xijiang River - Pearl River Economic Belt (da shu jv rong he zai xijiang
   zhujiang jing ji dai cheng ji jiao tong yi ti hua zhong de ying yong yu
   yan jiu)"
FX This work was supported in part by the China "1000-Plan" National
   Distinguished Professorship; the National Natural Science Foundation of
   China (Grant Nos: 61263035, 61573270, 61602353, and 61672177), the China
   973 Program (Grant no: 2013CB329404); the China Key Research Program
   (Grant no: 2016YFB1000905); the Guangxi Natural Science Foundation
   (Grant no: 2015GXNSFCB139011); the China Postdoctoral Science Foundation
   (Grant No: 2015M570837); the Guangxi Higher Institutions' Program of
   Introducing 100 High-Level Overseas Talents; the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; and the Guangxi "Bagui" Teams for Innovation and
   Research; Innovation Project of Guangxi Graduate Education under grant
   YCSZ2016046 and YCSZ2016045 and the project "Application and Research of
   Big Data Fusion in Inter-City Traffic Integration of The Xijiang River -
   Pearl River Economic Belt (da shu jv rong he zai xijiang zhujiang jing
   ji dai cheng ji jiao tong yi ti hua zhong de ying yong yu yan jiu)".
CR Agarwal S, 2005, PROC CVPR IEEE, P838
   [Anonymous], 2000, IEEE T PATTERN ANAL
   [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 1988, Technometrics, DOI DOI 10.2307/1268876
   [Anonymous], 2007, P AAAI C ART INT
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   [Anonymous], 2007, C-J CARBON RES
   Bulò SR, 2013, IEEE T PATTERN ANAL, V35, P1312, DOI 10.1109/TPAMI.2012.226
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   FIEDLER M, 1973, CZECH MATH J, V23, P298
   Franjoine Mary Rose, 2003, Pediatr Phys Ther, V15, P114, DOI 10.1097/01.PEP.0000068117.48023.18
   HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   LANCASTER P, 1970, SIAM REV, V12, P544, DOI 10.1137/1012104
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Purkait P, 2014, LECT NOTES COMPUT SC, V8692, P672, DOI 10.1007/978-3-319-10593-2_44
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Zass Ron., 2008, CVPR
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhao F, 2010, NEUROCOMPUTING, V73, P1704, DOI 10.1016/j.neucom.2009.12.029
   Zheng ZW, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P810
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650
   Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
   Zykov A. A., 1974, Russ. Math. Surv., V29, P89, DOI [10.1070/RM1974v029n06ABEH001303, DOI 10.1070/RM1974V029N06ABEH001303]
NR 42
TC 8
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17559
EP 17576
DI 10.1007/s11042-016-4131-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500038
DA 2024-07-18
ER

PT J
AU Stojanovic, B
   Marques, O
   Neskovic, A
AF Stojanovic, Branka
   Marques, Oge
   Neskovic, Aleksandar
TI Latent overlapped fingerprint separation: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Overlapped fingerprints; Latent fingerprints; Fingerprint separation;
   Fingerprint verification; Fingerprint matching
ID MODEL; SEGMENTATION; ENHANCEMENT; COMPUTATION; EXTRACTION; ROBUST; FIELD
AB Fingerprint matching is a widely used process to aid in crime scene investigation, where fingerprint fragments are often found on objects and surfaces. In such cases, the lifted fingerprints (called latents) are usually of poor quality and often appear overlapped and against a noisy background. These aspects make latent fingerprint - especially overlapped latent fingerprints - segmentation and enhancement (for subsequent matching) a difficult problem, for which several solutions have been proposed during the past few years. This paper presents an overview of contemporary techniques for overlapped fingerprint separation in the context of latent overlapped fingerprint matching. In addition to explaining the main concepts and surveying the literature in the field, it highlights the importance of the overlapped fingerprint segmentation (ROI extraction) process, a step for which there are no automatic techniques yet.
C1 [Stojanovic, Branka; Neskovic, Aleksandar] Univ Belgrade, Sch Elect Engn, 73 Kralja Aleksandra Blvd, Belgrade 11120, Serbia.
   [Stojanovic, Branka] Vlatacom Inst Ltd Belgrade, 5 Milutina Milankovica Blvd, Belgrade 11070, Serbia.
   [Marques, Oge] Florida Atlantic Univ, Boca Raton, FL 33431 USA.
C3 University of Belgrade; State University System of Florida; Florida
   Atlantic University
RP Marques, O (corresponding author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.
EM branka.stojanovic@vlatacom.com; omarques@fau.edu; neshko@etf.rs
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [1464537] Funding Source: National Science Foundation
CR [Anonymous], 2011, 4 INT C IM CRIM DET
   [Anonymous], 2013, P IEEE 6 INT C BIOM
   [Anonymous], 2011, P INT JOINT C BIOM
   [Anonymous], 2012, STANDARD DOCUMENTATI
   [Anonymous], 1987, OPTIMAL ORIENTATION
   [Anonymous], FVC2002 2 INT FINGER
   [Anonymous], 2004, INDEPENDENT COMPONEN
   Ashbaugh D.R., 1999, CRC SER PR CRIM, DOI 10.1201/9781420048810
   Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618
   Chen FL, 2011, IEEE T INF FOREN SEC, V6, P346, DOI 10.1109/TIFS.2011.2114345
   Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036
   Choi H., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P303, DOI 10.1109/BTAS.2012.6374593
   Dass SC, 2004, IEEE T IMAGE PROCESS, V13, P1358, DOI 10.1109/TIP.2004.834659
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Dror IE, 2006, FORENSIC SCI INT, V156, P74, DOI 10.1016/j.forsciint.2005.10.017
   Dror IE, 2005, APPL COGNITIVE PSYCH, V19, P799, DOI 10.1002/acp.1130
   Dror IE., 2006, J FORENSIC IDENTIFIC, V56, P600, DOI DOI 10.1016/S1355-0306(98)72118-5
   Dror IE, 2011, FORENSIC SCI INT, V208, P10, DOI 10.1016/j.forsciint.2010.10.013
   Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155
   Feng JJ, 2012, IEEE T INF FOREN SEC, V7, P1498, DOI 10.1109/TIFS.2012.2204254
   Fraser-Mackenzie PAF, 2013, SCI JUSTICE, V53, P144, DOI 10.1016/j.scijus.2012.12.002
   Garris M.D., 2000, TENPRINT IMAGES
   Gu JW, 2006, IEEE T IMAGE PROCESS, V15, P1952, DOI 10.1109/TIP.2006.873443
   Hall LJ, 2008, FORENSIC SCI INT, V181, P36, DOI 10.1016/j.forsciint.2008.08.008
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Huckemann S, 2008, IEEE T PATTERN ANAL, V30, P1507, DOI 10.1109/TPAMI.2007.70826
   I. Management Association, 2011, MACH LEARN CONC METH
   Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242
   Jiangyang Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P189, DOI 10.1109/ICB.2012.6199807
   Kamei T, 2004, AUTOMATIC FINGERPRINT RECOGNITION SYSTEMS, P113, DOI 10.1007/0-387-21685-5_6
   Karimi-Ashtiani S, 2008, IEEE IMAGE PROC, P1492, DOI 10.1109/ICIP.2008.4712049
   KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0
   Langenburg Glenn., 2009, J FORENSIC IDENTIFIC, V59, P219
   Lee KC, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P41, DOI 10.1109/BSYM.2008.4655521
   Liu M, 2005, EURASIP J ADV SIG PR, V2005, P1
   Lo PZ, 2006, US Patent App, Patent No. [11/456,622, 11456622]
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Marques ACPB, 2005, NEURAL NETWORK FINGE, P6
   OGORMAN L, 1989, PATTERN RECOGN, V22, P29, DOI 10.1016/0031-3203(89)90035-6
   Oliveira MA, 2008, PATTERN RECOGN, V41, P367, DOI 10.1016/j.patcog.2007.05.019
   PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691
   Pelillo M., 1993, Advances in Artificial Intelligence. Third Congress of the Italian Association for Artificial Intelligence, AI*IA '93. Proceedings, P230
   RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   Sankaran A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P377, DOI 10.1109/BTAS.2012.6374604
   Sankaran A., 2011, Biometrics (IJCB), 2011 International Joint Conference On, P1, DOI [10.1109/IJCB.2011.6117525, DOI 10.1109/IJCB.2011.6117525]
   Sankaran A, 2014, IEEE ACCESS, V2, P982, DOI 10.1109/ACCESS.2014.2349879
   SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I
   Singh M, 2008, PROC SPIE, V6982, DOI 10.1117/12.777541
   Stojanovic B, 2017, MULTIMED TOOLS APPL, V76, P12775, DOI 10.1007/s11042-016-3696-4
   Stojanovic B, 2015, 2015 23RD TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P484, DOI 10.1109/TELFOR.2015.7377512
   Stojanovic B, 2014, 2014 22ND TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P505, DOI 10.1109/TELFOR.2014.7034457
   Van Tilborg Henk C. A., 2014, Encyclopedia of cryptography and security
   Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P72, DOI 10.1109/TPAMI.2010.73
   Wertheim K., 2006, Journal of Forensic Identification, V56, P55, DOI DOI 10.1016/J.FOODQUAL.2007.12.003
   Yadav RN, 2006, SOFT COMPUT, V10, P257, DOI 10.1007/s00500-005-0479-7
   Yoon S., 2011, Proceedings of International Joint Conference on Biometrics, P1, DOI DOI 10.1109/IJCB.2011.6117482
   Yoon Soweon, 2010, SPIE DEFENSE SECURIT
   Zhang JY, 2012, IEEE IMAGE PROC, P1145, DOI 10.1109/ICIP.2012.6467067
   Zhang N, 2014, INT C PATT RECOG, P678, DOI 10.1109/ICPR.2014.127
   Zhang N, 2014, IEEE T INF FOREN SEC, V9, P1547, DOI 10.1109/TIFS.2014.2340573
   Zhao QJ, 2012, IEEE T INF FOREN SEC, V7, P904, DOI 10.1109/TIFS.2012.2187281
   Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608
NR 65
TC 13
Z9 13
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16263
EP 16290
DI 10.1007/s11042-016-3908-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100010
DA 2024-07-18
ER

PT J
AU Qin, LJ
   Wang, T
AF Qin, Lijuan
   Wang, Ting
TI Design and research of automobile anti-collision warning system based on
   monocular vision sensor with license plate cooperative target
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automobile anti-collision warning system; Monocular vision sensor;
   License plate cooperative target; Positioning
ID POSE
AB At present, detection method for the target vehicle based on monocular vision sensor uses the whole vehicle as targets. The automobile anti-collision tec-hnology proposed in this paper adopts monocular vision sensor for automobile measurement based on vehicle license plate cooperative target. Monocular vision sensor has advantages of good real-time performance and low cost. The technique can improve the detection capability of vehicle collision avoidance warning systems. In addition to the target vehicle positioning, it can also realize attitude determination. This technology eliminates the limits of road surface roughness and fluctuation. This paper designs the realization scheme of collision warning system based on monocular vision sensor from the automobile license plate cooperative target. Technology roadmap of automobile collision warning system is given. In this paper, license plate frame location is as the research background. The paper presents an analytic solution of positioning method for the license plate frame image. The method uses four vertex characteristics of license plate frame image to locate. Positioning speed of the method is fast. And it has a unique solution. This method can be used to positioning for the license plate frame. Simulation experiment is done for the collision warning location. The simulation results show that this method can locate the position for license plate frame image. License plate is regular shape, uniform, with identity recognition function markers on the automobile body. In the previous research on automotive collision warning and intelligent vehicle, we have not seen the research methods similar to the method introduced in this paper. The research enriches automobile anticollision technology and theory of intelligent vehicle technology. It can also provide an auxiliary method for navigation and obstacle avoidance research for unmanned vehicle. It has certain scientific significance. Vehicle collision warning system can help the driver judgment, prompting warning, improving driving safety, and has broad application prospects.
C1 [Qin, Lijuan] Shenyang Ligong Univ, Sch Informat Sci & Engn, Shenyang, Peoples R China.
   [Qin, Lijuan; Wang, Ting] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Peoples R China.
C3 Shenyang Ligong University; Chinese Academy of Sciences; Shenyang
   Institute of Automation, CAS
RP Qin, LJ (corresponding author), Shenyang Ligong Univ, Sch Informat Sci & Engn, Shenyang, Peoples R China.; Qin, LJ (corresponding author), Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Peoples R China.
EM qinglijuan1865@163.com
RI Jiang, Yu/JEZ-9814-2023
FU National Natural Science Foundation Project of P. R. China [61203163,
   61373089]; State Key Laboratory of Robotics Fund of P. R. China
   [2013-O06]
FX The research work of this paper was supported by National Natural
   Science Foundation Project of P. R. China (Grant No. 61203163, Grant No.
   61373089). The research work of this paper was supported by Project of
   State Key Laboratory of Robotics Fund of P. R. China (2013-O06).
CR Alireza A.F, 2009, IMAGE VISION COMPUT, V27, P81
   [Anonymous], INT J MULTIMEDIA UBI
   Christy S, 1999, COMPUT VIS IMAGE UND, V73, P137, DOI 10.1006/cviu.1998.0717
   Ding Weili, 2008, Chinese Journal of Scientific Instrument, V29, P1965
   Feng C.R., 2013, THESIS CHINA U GEOSC, P1
   [付强 Fu Qiang], 2015, [空军工程大学学报. 自然科学版, Journal of Air Force Engineering University. Natural Science Edition], V16, P5
   Gilly D., 2013, INT J COMPUT APPL, V61, P34
   Graefe V, 1996, INT VEH S 96 TOK JAP, P363
   Gu BY, 2006, THESIS, P1
   Guo R, 2014, MANUF AUTOM, V36, P154
   Guo Y, 2011, J COMPUT, V34, P748
   Han L., 2014, OPTOELECTRON TECHNOL, V34, P78
   Hong C, 2010, THESIS, P1
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Hu TH, 2004, THESIS, P10
   Hu Zhan-Yi, 2001, Acta Automatica Sinica, V27, P770
   Jia YH, 2010, THESIS, P1
   Li B., 2001, THESIS, P32
   Li XY, 2015, MACH TOOLS HYDRAUL, V43, P35
   Lu ED, 2002, J NANJING U SCI TE S, VS1, P104
   Ma HX, 2012, J COMPUT APPL SOFTW, V29, P253
   Ni K, 2011, J TV TECHNOL, V35, P96
   Patel C., 2013, Int. J. Comput. Appl, V69, P21, DOI [10.5120/11871-7665, DOI 10.5120/11871-7665]
   Peng Yu-song, 2013, Computer Engineering and Design, V34, P1630
   PHONG TQ, 1995, INT J COMPUT VISION, V15, P225, DOI 10.1007/BF01451742
   Qin L. J., 2013, INT J ADV COMPUT TEC, V5, P515
   Qin L J, 2009, RANSACTIONS SHENYANG, V28, P66
   Shahbahrami Asadollah, 2011, INT J DIGITAL INFORM, V1, P247
   Srinivasa N, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P626
   Su Wei, 2012, Computer Engineering, V38, P166, DOI 10.3969/j.issn.1000-3428.2012.15.046
   Sun B, 2010, SICHUAN ORDNANCE J, V31, P85
   Sun F. M., 2006, ACTA AUTOMAT SIN, V32, P746
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Tang X.Z., 2012, GEOSPATIAL INFORM, V10, P100
   Tang YJ, 2014, J CHANGCHUN U SCI TE, V37, P95
   TAO LM, 2001, CHINESE SCI BULL, V46, P178
   Tian T, 2009, J COMPUT APPL SOFTW, V26, P79
   Wang JX, 2003, MICROCOMPUTER DEV, V13, P7
   Wang K., 2015, J OPT, V35, P237
   [王萍 WANG Ping], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P1173
   Wang Yan, 2009, Computer Engineering and Applications, V45, P80, DOI 10.3778/j.issn.1002-8331.2009.08.024
   [魏伟波 WEI Weibo], 2008, [计算机仿真, Computer Simulation], V25, P210
   Wu Fu-Chao, 2003, Journal of Software, V14, P703
   Xiong Juntao, 2015, Journal of System Simulation, V27, P836
   Xu Jun-yong, 2008, Robot, V30, P289
   Xu Song, 2010, Chinese Journal of Scientific Instrument, V31, P546
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Zhang C.C., 2011, THESIS DALIAN U TECH, P3
   [张玲玲 ZHANG Lingling], 2008, [建筑材料学报, Journal of Building Materials], V11, P732
   Zhao LS, 2012, COMPUT TECHNOL DEV, V22, P6
   Zhao Quan-you, 2008, Journal of Computer Applications, V28, P448, DOI 10.3724/SP.J.1087.2008.00448
   Zhao Y., 2009, J NW POLYTECHNICAL U, V27, P47
   Zheng QX, 2013, THESIS, P1
   Zhou Xin, 2003, Robot, V25, P289
   Zhou Xin, 2003, Chinese Journal of Computers, V26, P1696
   Zhu Chengjun, 2008, Journal of Beijing University of Aeronautics and Astronautics, V34, P541
NR 57
TC 10
Z9 10
U1 0
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14815
EP 14828
DI 10.1007/s11042-016-4042-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400015
DA 2024-07-18
ER

PT J
AU López-Fernández, L
   Garcia, B
   Gallego, M
   Gortázar, F
AF Lopez-Fernandez, Luis
   Garcia, Boni
   Gallego, Micael
   Gortazar, Francisco
TI Designing and evaluating the usability of an API for real-time
   multimedia services in the Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media server; Real-time multimedia communications; Application
   Programming Interfaces; WebRTC; Multimedia processing; Multimedia tools
   and applications; Cognitive dimensions of notations
ID COEFFICIENT ALPHA; ARCHITECTURE; STANDARD
AB In the last few years, multimedia technologies in general, and Real-Time multimedia Communications (RTC) in particular, are becoming mainstream among WWW and smartphone developers, who have an increasing interest in richer media capabilities for creating their applications. The engineering literature proposing novel algorithms, protocols and architectures for managing and processing multimedia information is currently overwhelming. However, most of these results do not arrive to applications due to the lack of simple and usable APIs. Interestingly, in this context in which APIs are the critical ingredient for reaching wide developer audiences, the scientific literature about multimedia APIs and their usability is scarce. In this paper we try to contribute to fill this gap by proposing the RTC Media API: a novel type of API designed with the aim of making simple for developers the use of latest trends in RTC multimedia including WebRTC, Video Content Analysis or Augmented Reality. We provide a specification of such API and discuss how it satisfies a set of design requirements including programming-language agnosticism, adaptation to cloud environments, support to multisensory multimedia, etc. After that, we describe an implementation of such an API that has been created in the context of the Kurento open source software project, and present a study evaluating the API usability performed in a group of more than 40 professional developers distributed worldwide. In the light of the obtained results, we conclude that the usability of the API is adequate across the main development activities (i.e. API learning, code creation and code maintenance), with an average usability score of 3.39 over 5 in a Likert scale, and that this result is robust with respect to developers' profiles, cultures, professional experiences and preferred programming languages.
C1 [Lopez-Fernandez, Luis; Garcia, Boni; Gallego, Micael; Gortazar, Francisco] Univ Rey Juan Carlos, Camino Molino S-N, Fuenlabrada 28943, Spain.
C3 Universidad Rey Juan Carlos
RP López-Fernández, L (corresponding author), Univ Rey Juan Carlos, Camino Molino S-N, Fuenlabrada 28943, Spain.
EM luis.lopez@urjc.es
RI Gortázar, Francisco/H-8219-2015; García, Boni/AAB-1990-2020; Gallego,
   Micael/I-1390-2015; García, Boni/ABE-9435-2020
OI Gortázar, Francisco/0000-0002-2183-0869; García,
   Boni/0000-0003-1808-8410; Gallego, Micael/0000-0002-2875-7342
FU European Commission [FI-WARE FP7-2011-ICT-FI GA-285248, FI-CORE
   FP7-2014-ICT-FI GA-632893, NUBOMEDIA FP7-ICT-2013-1.6 GA-610576];
   Spanish Ministerio de Educacion [TIN2013-41819-R]; Regional Government
   of Madrid (CM) - FSE [S2013/ICE-2894]; FEDER
FX This work has been supported by the European Commission under projects
   FI-WARE FP7-2011-ICT-FI GA-285248, FI-CORE FP7-2014-ICT-FI GA-632893 and
   NUBOMEDIA FP7-ICT-2013-1.6 GA-610576; by Spanish Ministerio de Educacion
   under project Reactive Media (TIN2013-41819-R); and by the Regional
   Government of Madrid (CM) under project Cloud4BigData (S2013/ICE-2894)
   co-funded by FSE & FEDER.
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Afonso L.M., 2012, Proceedings of the Psychology of Programming Interest Group, P8
   Ajanki A, 2011, VIRTUAL REAL-LONDON, V15, P161, DOI 10.1007/s10055-010-0183-5
   Allen I Elaine, 2007, QUAL PROG, V40, P64, DOI DOI 10.1111/J.1365-2929.2004.02012.X
   Alvestrand H, 2015, TRANSPORTS IN PRESS
   Andreasen F, 2003, 3435 RFC
   Andreessen Marc., 2011, Why Software Is Eating The World
   [Anonymous], 2012, WebRTC: APIs and RTCWEB protocols of the HTML5 real-time web
   Bainomugisha E, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501666
   Bajaj V, 2004, JAIN MEGACO API SPEC
   Bauer M, 2010, INT NEXT GEN NETW IC, P1
   Becke M, 2013, IEEE COMMUN MAG, V51, P34, DOI 10.1109/MCOM.2013.6495758
   Bertoa MF, 2006, J SYST SOFTWARE, V79, P427, DOI 10.1016/j.jss.2005.06.026
   Blackwell AF, 2001, LECT NOTES ARTIF INT, V2117, P325
   Blackwell AF, 2000, P 12 ANN M PSYCH PRO, P137
   Bloch J., 2006, 21 ACM SIGPLAN S OBJ, P506, DOI DOI 10.1145/1176617.1176622
   Bray Tim., 1998, EXTENSIBLE MARKUP LA
   Carroll JM, 2012, PERCEIVED SELF EFFIC, P42
   Catherine M.Ramya., 2013, International Journal of Advanced Research in Computer Engineering Technology (IJARCET), V2, P304
   Clarke S., 2001, P WORKSHOP PSYCHOL P, P275
   CORTINA JM, 1993, J APPL PSYCHOL, V78, P98, DOI 10.1037/0021-9010.78.1.98
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Downing SM, 2003, MED EDUC, V37, P830, DOI 10.1046/j.1365-2923.2003.01594.x
   Duala-Ekoko E, 2012, PROC INT CONF SOFTW, P266, DOI 10.1109/ICSE.2012.6227187
   Eckert C., 2000, Des. Stud., V21, P523, DOI [10.1016/S0142-694X(00)00022-3, DOI 10.1016/S0142-694X(00)00022-3]
   Ellis B, 2007, PROC INT CONF SOFTW, P302
   Ericson T, 2009, MEDIA SERVER CONTROL
   Farooq U, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P207
   Ferry D, 2004, JAIN SLEE API SPECIF
   FIWARE Consortium, 2015, FUT INT COR PLATF
   Fraternali P, 1999, ACM COMPUT SURV, V31, P227, DOI 10.1145/331499.331502
   Gamma Erich., 1994, DESIGN PATTERNS
   Ganassali S., 2008, Survey Research Methods, V2, P21, DOI DOI 10.18148/SRM/2008.V2I1.598
   Gouveia F, 2009, P 5 INT ICST MOB MUL, P51
   Green TRG, 2006, J VISUAL LANG COMPUT, V17, P328, DOI 10.1016/j.jvlc.2006.04.004
   Green T. R. G., 1989, People and Computers V. Proceedings of the Fifth Conference of the British Computer Society Human-Computer Interaction Specialist Group, P443
   Gualdi G, 2008, IEEE T MULTIMEDIA, V10, P1142, DOI 10.1109/TMM.2008.2001378
   Handley M, 2006, 4566 RFC
   Henning M., 2007, ACM Queue, V5, P25, DOI 10.1145/1255421.1255422
   Hovemeyer D, 2005, THESIS
   Internet Engineering Task Force, 2015, REAL TIM COMM WEB BR
   Ivov E, 2014, SESSION INI IN PRESS
   Jennings C, 2015, NEGOTIATING IN PRESS
   Kambona Kennedy., P 7 WORKSHOP DYNAMIC, DOI DOI 10.1145/2489798.2489802
   Koukoulidis V, 2006, MULTIMED TOOLS APPL, V28, P203, DOI 10.1007/s11042-006-6143-0
   Kristensen A, 2003, 116 JSR
   Laursen A., 1994, SIGMOD Record, V23, P470, DOI 10.1145/191843.191933
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Melanchuk T, 2009, 5567 RFC
   Moody DL, 2009, IEEE T SOFTWARE ENG, V35, P756, DOI 10.1109/TSE.2009.67
   O'Doherty P, 2003, 32 JSR
   Ott J, 2006, 4585 RFC
   Park S, 2009, IEEE T CONSUM ELECTR, V55, P126, DOI 10.1109/TCE.2009.4814424
   Perkins C, 2010, 5761 RFC
   Piccioni Marco, 2013, 2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), P5, DOI 10.1109/ESEM.2013.14
   Pickard A., 2012, RES METHODS INFORM
   Prusty N, 2015, LEARNING ECMASCRIPT
   Reddy Martin., 2011, API Design for C++
   Roccetti M, 2001, MULTIMED TOOLS APPL, V14, P23, DOI 10.1023/A:1011303506685
   ROSENBERG J., 2010, Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal for Offer/Answer Protocols
   Rosenberg J, 2002, 3261 REP
   Saint-Andre P., 2011, 6120 RFC
   Saleem A, 2010, 5707 RFC
   Schulzrinne H, 1999, IEEE NETWORK, V13, P18, DOI 10.1109/65.767133
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H, 2003, 3551 RFC
   Schulzrinne H., 1998, 2326 RFC
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Tang XY, 2002, PROC INT CONF PARAL, P287, DOI 10.1109/ICPP.2002.1040884
   Tay Y.H., 2019, P IAWA IUFRO INT S U
   Taylor T, 2000, IEEE COMMUN MAG, V38, P124, DOI 10.1109/35.874979
   Thom GA, 1996, IEEE COMMUN MAG, V34, P52, DOI 10.1109/35.556487
   Tilkov S, 2010, IEEE INTERNET COMPUT, V14, P80, DOI 10.1109/MIC.2010.145
   Van Dyke J, 2007, 4722 RFC
   Vaquero LM, 2009, ACM SIGCOMM COMP COM, V39, P50, DOI 10.1145/1496091.1496100
   VOGEL A, 1995, IEEE MULTIMEDIA, V2, P10, DOI 10.1109/93.388195
   Wagner B, 2010, EFFECTIVE C COVERS
   Westerlund M, 2015, USING SIMULCAST RTP
   Westerlund M, 2016, RTP INTERNET DRAFT T
   Willmott S, 2013, WINNING API EC
   World Wide Web Consortium, 2015, WEBRTC STATS
   World Wide Web Consortium, 2011, WEB REAL TIM COMM WO
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 85
TC 8
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14247
EP 14304
DI 10.1007/s11042-016-3729-z
PG 58
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800027
DA 2024-07-18
ER

PT J
AU Niu, LL
   Zhou, WC
   Wang, DD
   He, DJ
   Zhang, HH
   Song, HB
AF Niu, Leilei
   Zhou, Weicong
   Wang, Dandan
   He, Dongjian
   Zhang, Haihui
   Song, Huaibo
TI Extracting the symmetry axes of partially occluded single apples in
   natural scene using convex hull theory and shape context algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Occluded apple; Symmetric axis extraction; Shape context; Convex hull
   theory; K-means clustering algorithm; Threshold method
AB Accurate identification of apples partially occluded by branches and leaves is an urgent and key issue for a picking robot. The objective of this study was to detect the symmetry axes of partially occluded single apples accurately using the convex hull theory and Shape Context algorithm. Firstly, apple regions were obtained by using K-means clustering algorithm. Secondly, image pre-processing steps such as image binarization, hole filling, area opening and edge detection were applied. Thirdly, false contours were removed based on the convex hull theory to enhance the accuracy and stability of this method. Finally, the point matching relationship of each two contours and the two best symmetrical contours were found by using the Shape Context algorithm and Hungarian algorithm. Then the symmetry axes of apples were extracted using the matching point pairs. Least squares ellipses fitting algorithm and moment of inertia algorithm were used to compare with the presented algorithm. The angle difference between extracted symmetry axis and ideal symmetry axis for every method was computed, and the execution time of program as well. Ninety partially occluded single apple images were tested. The experimental results showed that the average angle error of the Shape Context algorithm were 7.72A degrees, 37.5 % of the ellipses fitting algorithm and 31.3 % of the inertia moment algorithm. And its average execution time is 1.86 s, 103 % of the ellipses fitting algorithm and 106 % of the inertia moment algorithm. In conclusion, it was feasible to use the proposed method to extract the symmetry axes of partially occluded apples.
C1 [Niu, Leilei; Zhou, Weicong; Wang, Dandan; He, Dongjian; Zhang, Haihui; Song, Huaibo] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China
RP Song, HB (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
EM songhuaibo@nwsuaf.edu.cn
RI SONG, Huaibo/GXM-9402-2022
FU National High Technology Research and Development Program of China (863
   Program) [2013AA10230402]; Natural Science Basic Research Plan in
   Shaanxi Province of China [2014JQ3094]
FX This work is supported by the National High Technology Research and
   Development Program of China (863 Program) (No.2013AA10230402), Natural
   Science Basic Research Plan in Shaanxi Province of China (No.
   2014JQ3094). The authors would like to thank all the authors cited in
   this article and anonymous referees for their helpful comments and
   suggestions.
CR [Anonymous], COMPUT SCI
   [Anonymous], IN ADVANCES IN NEURA
   [Anonymous], ELECT DES ENG
   [Anonymous], 2013, J AGR MECH RES, DOI [10.13427/j.cnki.njyi.2013.09.016, DOI 10.13427/J.CNKI.NJYI.2013.09.016]
   [Anonymous], MICROPROCESSORS
   Bohg J, 2010, ROBOT AUTON SYST, V58, P362, DOI 10.1016/j.robot.2009.10.003
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gu BaoXing Gu BaoXing, 2012, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V43, P153
   Kai Li, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P852, DOI 10.1109/ICCSE.2011.6028771
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Li CanCan Li CanCan, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P157
   Li Zhen Li Zhen, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P147
   Lin T.C., 2007, International Journal of Computer Sciences and Engineering Systems, V1, P253
   Liu Z, 2012, NEUROCOMPUTING, V83, P47, DOI 10.1016/j.neucom.2011.11.012
   Ma LL, 2013, CHIN CONTR CONF, P3906
   Mehta SS, 2014, COMPUT ELECTRON AGR, V102, P146, DOI 10.1016/j.compag.2014.01.003
   Premachandran V, 2013, PATTERN RECOGN, V46, P2092, DOI 10.1016/j.patcog.2013.01.030
   Rakun J, 2011, COMPUT ELECTRON AGR, V76, P80, DOI 10.1016/j.compag.2011.01.007
   Shi Si-qi, 2011, Systems Engineering and Electronics, V33, P913, DOI 10.3969/j.issn.1001-506X.2011.04.40
   Song HuaiBo Song HuaiBo, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P174
   Wachs JP, 2010, PRECIS AGRIC, V11, P717, DOI 10.1007/s11119-010-9198-x
   Wang DD, 2015, SPAN J AGRIC RES, V13, DOI 10.5424/sjar/2015131-6181
   WHITTAKER AD, 1987, T ASAE, V30, P591
   Xie ZhongHong Xie ZhongHong, 2010, Transactions of the Chinese Society of Agricultural Engineering, V26, P157
   Xun Yi, 2007, Journal of Jiangsu University Natural Science Edition, V28, P461
   Yuanyuan Zhang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P256
   [张显全 ZHANG XianQuan], 2006, [计算机科学, Computer Science], V33, P218
   Zhao J., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P263
   Zhiyong Wang, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P650, DOI 10.1109/DICTA.2011.115
   [周启海 ZHOU QiHai], 2007, [计算机科学, Computer Science], V34, P216
NR 30
TC 7
Z9 9
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14075
EP 14089
DI 10.1007/s11042-016-3781-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800019
DA 2024-07-18
ER

PT J
AU Biernacki, A
AF Biernacki, Arkadiusz
TI Analysis and modelling of traffic produced by adaptive HTTP-based video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia service management; Performance management; Stochastic
   processes; IP networks
ID ARTIFICIAL NEURAL-NETWORKS
AB The increase of HTTP-based video popularity causes that broadband and Internet service providers' links transmit mainly multimedia content. Network planning, traffic engineering or congestion control requires an understanding of the statistical properties of network traffic; therefore, it is desirable to investigate the characteristic of traffic traces generated by systems which employ adaptive bit-rate streaming. Our first contribution is an investigation of traffic originating from 120 client-server pairs, situated in an emulated content distribution network, and multiplexed onto a single network link. We show that the structure of the traffic is distinct from the structure generated by the first and second generation of HTTP video systems, and furthermore, not similar to the structure of general Internet traffic. The obtained traffic exhibits negative and positive correlations, anti-persistence, and its distribution function is skewed to the right. Our second contribution is an approximation of the traffic by ARIMA/FARIMA processes blue and artificial neural networks. As we show, the obtained traffic models are able to enhance the performance of an adaptive streaming algorithm.
C1 [Biernacki, Arkadiusz] Silesian Tech Univ, Inst Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Biernacki, A (corresponding author), Silesian Tech Univ, Inst Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
EM arkadiusz.biernacki@polsl.pl
CR Abhari A, 2010, MULTIMED TOOLS APPL, V46, P91, DOI 10.1007/s11042-009-0309-5
   Adebiyi AA, 2014, J APPL MATH, DOI 10.1155/2014/614342
   Alcock S, 2011, ACM SIGCOMM COMP COM, V41, P25, DOI 10.1145/1971162.1971166
   [Anonymous], 2008, INT J INTERACTIVE MO, DOI DOI 10.3991/IJIM.V3I1.284
   [Anonymous], 2019, R LANG ENV STAT COMP
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], J INDIAN I SCI
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], CONDMAT0105269 ARXIV
   [Anonymous], COMP FORECASTING APP
   [Anonymous], TCPDUMP PUBLIC REPOS
   [Anonymous], 2015, ELEKTRON ELEKTROTECH
   [Anonymous], VOICE VIDEO DATA COM
   [Anonymous], 2014, FORECASTING PRINCIPL
   [Anonymous], P NOSSDAV
   [Anonymous], RMETRICS
   [Anonymous], FEDCSIS POSITION PAP
   [Anonymous], ELEKT IR ELEKTROTECH
   [Anonymous], 1981, DETECTING STRANGE AT, DOI [DOI 10.1007/BFB0091924, 10.1007/BFb0091924]
   [Anonymous], ARXIVHEPTH150302955
   [Anonymous], 2015, HOTMOBILE
   [Anonymous], COMPUT NETW
   [Anonymous], 2016, CISC VIS NETW IND GL
   [Anonymous], BAHRIA U J INFORM CO
   [Anonymous], MULTIFRACTAL BASED N
   Biernacki A, 2007, INNOVATIVE ALGORITHMS AND TECHNIQUES IN AUTOMATION, INDUSTRIAL ELECTRONICS AND TELECOMMUNICATIONS, P55, DOI 10.1007/978-1-4020-6266-7_11
   Botta A, 2012, COMPUT NETW, V56, P3531, DOI 10.1016/j.comnet.2012.02.019
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Cortez P, 2012, EXPERT SYST, V29, P143, DOI 10.1111/j.1468-0394.2010.00568.x
   Cowpertwait PSP, 2009, USE R, P1, DOI 10.1007/978-0-387-88698-5_1
   Falk M., 2012, A First Course on Time Series Analysis: Examples with SAS
   Famaey J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P419
   Hemminger Stephen., 2005, LINUX C, P18
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Kantz H., 2004, NONLINEAR TIME SERIE, Vsecond, DOI DOI 10.1017/CBO9780511755798
   Khashei M, 2012, EXPERT SYST APPL, V39, P4344, DOI 10.1016/j.eswa.2011.09.157
   Khashei M, 2009, NEUROCOMPUTING, V72, P956, DOI 10.1016/j.neucom.2008.04.017
   Lazaris A, 2010, COMPUT COMMUN, V33, P1235, DOI 10.1016/j.comcom.2010.03.014
   Lederer S., 2012, P 3 MULT SYST C, P89
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liebeherr J, 2012, IEEE T INFORM THEORY, V58, P1010, DOI 10.1109/TIT.2011.2173713
   Liu Y, 2015, INT J GENOMICS, V2015, DOI [10.1155/2015/429469, 10.1155/2015/761063]
   Martin J, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P230, DOI 10.1109/CCNC.2013.6488451
   Miguel MLF, 2012, IEEE IFIP NETW OPER, P1082, DOI 10.1109/NOMS.2012.6212033
   Mirzaei MM, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P741, DOI 10.1109/ICCKE.2014.6993452
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ni PP, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P103
   Ramos-Munoz JJ, 2014, IEEE WIREL COMMUN, V21, P18, DOI 10.1109/MWC.2014.6757893
   Rao Ashwin., 2011, CONEXT
   Rhodes C., 1997, Computers & Chemical Engineering, V21, pS1149, DOI 10.1016/S0098-1354(97)00204-4
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Satoda K., 2012, GLOBECOM 2012 - 2012 IEEE Global Communications Conference, P1944, DOI 10.1109/GLOCOM.2012.6503400
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Taqqu M., 1986, Dependence in Probability and Statistics, P73
   Valipour M, 2013, J HYDROL, V476, P433, DOI 10.1016/j.jhydrol.2012.11.017
   Venables WN., 2002, MODERN APPL STAT S
   Villa Bjorn J., 2013, International Journal of Computer and Communication Engineering, V2, P460, DOI 10.7763/IJCCE.2013.V2.227
   Willinger W, 1997, IEEE ACM T NETWORK, V5, P71, DOI 10.1109/90.554723
   Yadav RK, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-15
   Zhani Mohamed Faten, 2009, Journal of Networks, V4, P855, DOI 10.4304/jnw.4.9.855-865
   Zink M, 2003, LECT NOTES COMPUT SC, V2707, P137
NR 62
TC 9
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12347
EP 12368
DI 10.1007/s11042-016-3623-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200008
OA hybrid
DA 2024-07-18
ER

PT J
AU Huang, RH
   Sato, A
   Tamura, T
   Ma, JH
   Yen, NY
AF Huang, Runhe
   Sato, Atsushi
   Tamura, Toshihiro
   Ma, Jianhua
   Yen, Neil. Y.
TI Towards next-generation business intelligence: an integrated framework
   based on DME and KID fusion engine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Business intelligence; Fusion techniques; Consumer behavior model;
   Personalization; Service provision; Cyber-I
AB Advances in information technology prompt a tremendous usage growth of the Internet. Online activities, such as e-commerce, social interaction, etc., have drawn increasing attentions in regard to the provision of personalized services which require best and comprehensive understanding of users. As an approach, this study outlines a general framework based on human (or consumer) contexts for the discovery and creation of business intelligence. Three major portions are discussed. First, the collection of human contexts, including activity logs in both cyber and physical worlds, is modeled. Second, data analysis was performed via proposed mining algorithms that concern potential fusion at different levels according to situations and ultimate purposes. Third, sustenance of developed model is then concentrated. An open platform was developed to support the evolutionary process of human models, and to allow contributions (e.g., data sharing, accessing, etc.) from third parties.
C1 [Huang, Runhe; Sato, Atsushi; Tamura, Toshihiro; Ma, Jianhua] Hosei Univ, Fac Comp & Informat Sci, Tokyo, Japan.
   [Yen, Neil. Y.] Univ Aizu, Sch Comp Sci & Engn, Fukushima, Japan.
C3 Hosei University; University of Aizu
RP Huang, RH (corresponding author), Hosei Univ, Fac Comp & Informat Sci, Tokyo, Japan.
EM rhuang@hosei.ac.jp; atsushi.sato.3r@stu.hosei.ac.jp;
   toshihiro.tamura.3k@stu.hosei.ac.jp; jianhua@hosei.ac.jp;
   neilyyen@u-aizu.ac.jp
FU Japan Society for the Promotion of Science [25330270]; Grants-in-Aid for
   Scientific Research [25330270] Funding Source: KAKEN
FX The work is partially supported by the Japan Society for the Promotion
   of Science Grants-in-Aid for Scientific Research (No. 25330270).
CR [Anonymous], J PSYCHOL MARKETING
   [Anonymous], 2013, J SUPERCOMPUT, DOI DOI 10.1007/s11227-010-0518-8
   [Anonymous], 1994, P INT C VERY LARGE D
   [Anonymous], 2009, P 18 INT C WORLD WID
   Cao B., 2007, P 24 INT C MACHINE L, P121, DOI DOI 10.1145/1273496.1273512
   Chandramouli B, 2012, PROC INT CONF DATA, P90, DOI 10.1109/ICDE.2012.55
   Cook RD, 1982, Sociological methodology, DOI 10.2307/270724
   Ewaryst T, 2009, INTERNET TECHNICAL D, P255
   Folstad A, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-18
   Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261
   Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P357, DOI 10.1109/ANZIIS.1994.396988
   Ibrahim N, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-1
   Jolliffe I. T., 1986, PRINCIPAL COMPONENT, P487, DOI DOI 10.1007/B98835
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X
   Li WH, 2005, LECT NOTES COMPUT SC, V3687, P344
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Ma JH, 2011, IEEE INTELL SYST, V26, P30, DOI 10.1109/MIS.2011.55
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mehrabian A, 1996, AUST J PSYCHOL, V48, P86, DOI 10.1080/00049539608259510
   Milenova BL, 2005, 2005 7TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), VOLS 1 AND 2, P638
   Nakada H., 2012, 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom). Proceedings, P618, DOI 10.1109/CloudCom.2012.6427499
   Narang A., 2012, 2012 IEEE 12th International Conference on Data Mining (ICDM 2012), P549, DOI 10.1109/ICDM.2012.128
   Ortony A., 1988, COGNITIVE STRUCTURE
   Smirnov A, 2003, COMPUT INFORM, V22, P105
   Wang TZ, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P706
   Wang XP, 2007, I C WIREL COMM NETW, P3549
   Xiao Yi Yu, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P406, DOI 10.1109/IIHMSP.2010.104
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang J, 2002, PATTERN RECOGN, V35, P295, DOI 10.1016/S0031-3203(01)00152-2
   Yang S., 2012, LNCS IN PRESS
   Zhang YX, 2011, COMPUT COMMUN, V34, P1539, DOI 10.1016/j.comcom.2010.06.024
NR 35
TC 5
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11509
EP 11530
DI 10.1007/s11042-014-2387-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000023
DA 2024-07-18
ER

PT J
AU Manafifard, M
   Ebadi, H
   Moghaddam, HA
AF Manafifard, M.
   Ebadi, H.
   Moghaddam, H. Abrishami
TI Multi-player detection in soccer broadcast videos using a blob-guided
   particle swarm optimization method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blob-guided PSO; multi-player detection; soccer; sub-swarm
ID PLAYER DETECTION; TRACKING; SEGMENTATION
AB Soccer is the most popular sport around the world, and automatic processing of soccer images is a precious alternative to the manual solutions regarding the explosive growth of soccer videos. A new multi-player detection algorithm in far view frames as an initial step to a wide range of applications, such as player tracking, is addressed in this paper. In the proposed detector, a two-step blob detection (grass-based blob detection followed by an edge-based blob detection) is combined with an efficient search mechanism based on particle swarm optimization (PSO) by assigning sub-swarms to each detected blob. Then, a sub-swarm is initialized and tripled to search for three models corresponding to two teams and the referee. Therefore, the most player-like regions in detected blobs are simultaneously searched by all sub-swarms flying through the solution space, thus expanding the scope of single player detection to multi-player detection. Experimental results demonstrate the efficiency and robustness of the algorithm.
C1 [Manafifard, M.; Ebadi, H.] KN Toosi Univ Technol, Dept Photogrammetry & Remote Sensing, Valieasr St, Tehran, Iran.
   [Moghaddam, H. Abrishami] KN Toosi Univ Technol, Dept Elect Engn, Seyedkhandan St, Tehran, Iran.
C3 K. N. Toosi University of Technology; K. N. Toosi University of
   Technology
RP Manafifard, M (corresponding author), KN Toosi Univ Technol, Dept Photogrammetry & Remote Sensing, Valieasr St, Tehran, Iran.
EM mmanafifard@mail.kntu.ac.ir
RI Abrishami Moghaddam, Hamid/AAW-9288-2021
OI Ebadi, Hamid/0000-0002-7017-1927; Manafifard,
   Mehrtash/0000-0003-0722-8617
CR [Anonymous], 2013, PROC VIS COMMUN IMAG
   [Anonymous], 1 JOINT IEEE INT WOR
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Beetz M, 2006, 5 INT JOINT C AUT AG
   Bilal M, 2016, MULTIMED TOOLS APPL, V75, P6533, DOI 10.1007/s11042-015-2587-4
   Chen CY, 2016, MULTIMED TOOLS APPL, V75, P9949, DOI 10.1007/s11042-015-2776-1
   Choi K, 2011, PATTERN RECOGN LETT, V32, P1274, DOI 10.1016/j.patrec.2011.03.009
   D'Orazio T, 2009, IEEE T CIRC SYST VID, V19, P1804, DOI 10.1109/TCSVT.2009.2026817
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Du YJ, 2016, MULTIMED TOOLS APPL, V75, P987, DOI 10.1007/s11042-014-2338-y
   Duh D.J., 2013, Intelligent Technologies and Engineering Systems, P123
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Heydari M, 2012, INT CONF ROBOT ARTIF, P195, DOI 10.1109/ICRAI.2012.6413398
   Huang Y, 2007, LECT NOTES COMPUT SC, V4577, P416
   Inamoto N, 2007, IEEE T MULTIMEDIA, V9, P1155, DOI 10.1109/TMM.2007.902832
   Iwase S, 2003, PROC SPIE, V5150, P283, DOI 10.1117/12.502967
   Jiang S, 2004, 12 ANN ACM INT C MUL
   John V, 2010, IMAGE VISION COMPUT, V28, P1530, DOI 10.1016/j.imavis.2010.03.008
   Joo SW, 2007, IEEE T IMAGE PROCESS, V16, P2849, DOI 10.1109/TIP.2007.906254
   Junior BM, 2004, ACM 2 INT WORKSH VID
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Kim H, 2003, P IM VIS COMP PALM N, P159
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Mackowiak S, 2013, INT J ELECTRON TELEC, V59, P75, DOI 10.2478/eletel-2013-0009
   Mackowiak S, 2010, INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS (ICSES '10): CONFERENCE PROCEEDINGS, P119
   Manafifard M, 2015, SCI IRAN, V22, P1031
   Martín R, 2014, MULTIMED TOOLS APPL, V73, P1617, DOI 10.1007/s11042-013-1659-6
   Laborda MAM, 2012, J REAL-TIME IMAGE PR, V7, P267, DOI 10.1007/s11554-011-0194-9
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Nuñez JR, 2008, INT CONF SYST SIGNAL, P279, DOI 10.1109/IWSSIP.2008.4604421
   Orazio TD, 2009, 6 IEEE INT C ADV VID, P559, DOI 10.1109/AVSS.2009.69
   Pallavi V, 2008, IEEE T MULTIMEDIA, V10, P794, DOI 10.1109/TMM.2008.922869
   Saini S, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/704861
   Schlipsing M, 2017, J REAL-TIME IMAGE PR, V13, P345, DOI 10.1007/s11554-014-0406-1
   Sha F, 2015, IEEE C EVOL COMPUTAT, P2737, DOI 10.1109/CEC.2015.7257228
   Sullivan J, 2006, LECT NOTES COMPUT SC, V3953, P619, DOI 10.1007/11744078_48
   Sun L, 2009, INT CONF ACOUST SPEE, P1237, DOI 10.1109/ICASSP.2009.4959814
   Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   Yao A, 2010, LECT NOTES COMPUT SC, V6376, P151
   Yoon HS, 2002, ETRI J, V24, P443, DOI 10.4218/etrij.02.0102.0005
   Zhang XQ, 2010, IEEE T CIRC SYST VID, V20, P1590, DOI 10.1109/TCSVT.2010.2087455
   Zheng Y, 2009, INT J INTELL SYST TE, V7, P3266
NR 48
TC 13
Z9 14
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12251
EP 12280
DI 10.1007/s11042-016-3625-6
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200005
DA 2024-07-18
ER

PT J
AU Wang, CC
AF Wang, Chun-Chia
TI Factors influencing the adoption of online group-buying in virtual
   community
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online group-buying; Perceived interactivity; Perceived risk;
   Initiator's trust; Word-of-mouth
ID WORD-OF-MOUTH; PERCEIVED RISK; TRUST; SERVICES; PURCHASE; INTERACTIVITY;
   ANTECEDENTS; INFORMATION; FRIENDSHIPS; TECHNOLOGY
AB In the past few years, virtual communities have greatly changed and influenced the way Internet users interact and exchange ideas. It not only offers amusement and enriches social relationship, but also changes people's daily habits. In the case of online retailing, the emergence of online group-buying is regarded as one of the popular and burgeoning shopping models. This works through an initiator who issues the group-buying message to members with the same demand for a specific product. In this way, it can enhance the bargaining power with the producer through bulk-buying to achieve the goal of price-cutting. In this study, we proposed a conceptual model to discuss constructs which influence online group-buying behaviors. These constructs include perceived interactivity, initiator's trust, perceived risk, word-of-mouth, and group-buying behavior intention. In the sample part, 134 valid participants with online-purchasing experiences were collected through online survey method. The conceptual model was conducted by structural equation modeling (SEM) method through SmartPLS 2.0 software to test the hypotheses proposed in this study. The results indicated that (1) perceived interactivity positively influenced the initiator's trust, (2) initiator's trust positively influenced group-buying behavior, (3) initiator's trust influence the perceived risk negatively; (4) word-of-mouth positively impacted group-buying behavior; and (5) perceived risk negatively impact on group-buying behavior. Overall, the results showed a good fit for the proposed model and provided the fine predictive and explanatory power on group-buying behavior of a virtual community.
C1 [Wang, Chun-Chia] Taipei City Univ Sci & Technol, Dept Informat Management, Taipei, Taiwan.
RP Wang, CC (corresponding author), Taipei City Univ Sci & Technol, Dept Informat Management, Taipei, Taiwan.
EM toshihitowang@gmail.com
CR [Anonymous], 2006, Academy of Marketing Studies Journal
   [Anonymous], 1998, MIS Quarterly
   ARNDT J, 1967, J MARKETING RES, V4, P291, DOI 10.1177/002224376700400308
   BERNDT TJ, 1986, DEV PSYCHOL, V22, P640, DOI 10.1037/0012-1649.22.5.640
   Berthon P, 1996, J ADVERTISING RES, V36, P43
   Bigley GA, 1998, ACAD MANAGE REV, V23, P405, DOI 10.2307/259286
   Black W., 1998, Multivariate data analysis: With readings
   Blair MM, 2001, U PENN LAW REV, V149, P1735, DOI 10.2307/3312898
   Bove LL, 2000, INT J SERV IND MANAG, V11, P491, DOI 10.1108/09564230010360191
   BROWN JJ, 1987, J CONSUM RES, V14, P350, DOI 10.1086/209118
   Buttle F.A., 1998, J. Strateg. Mark., V6, P241, DOI DOI 10.1080/096525498346658
   Chang YS, 2013, J ELECTRON COMMER RE, V14, P149
   Chen J, 2009, INT J ELECTRON COMM, V14, P147, DOI 10.2753/JEC1086-4415140105
   Chen Q., 2005, Journal of Interactive Advertising, V5, P19, DOI DOI 10.1080/15252019.2005.10722098
   Cheng HH, 2013, INT J INFORM MANAGE, V33, P185, DOI 10.1016/j.ijinfomgt.2012.09.003
   Cheng SY, 2012, ONLINE INFORM REV, V36, P698, DOI 10.1108/14684521211275984
   Chu KM, 2013, J ELECTRON COMMER RE, V14, P124
   CROSBY LA, 1990, J MARKETING, V54, P68, DOI 10.2307/1251817
   Cunningham SM., 1967, RISK TAKING INFORM H
   Diamantopoulos A, 2001, J MARKETING RES, V38, P269, DOI 10.1509/jmkr.38.2.269.18845
   Dirks KT, 2000, J APPL PSYCHOL, V85, P1004, DOI 10.1037//0021-9010.85.6.1004
   DODDS WB, 1991, J MARKETING RES, V28, P307, DOI 10.2307/3172866
   Doney PM, 1997, J MARKETING, V61, P35, DOI 10.2307/1251829
   Fan TY, 2013, J SCI TECHNOLOGY HUM, V17, P73
   Featherman MS, 2003, INT J HUM-COMPUT ST, V59, P451, DOI 10.1016/S1071-5819(03)00111-3
   Fishbein M., 1980, UNDERSTANDING ATTITU
   Fishbein Martin., 1975, Attitude, Intention and Behavior: An Introduction to Theory and Research
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gefen D, 2003, MIS QUART, V27, P51, DOI 10.2307/30036519
   Ghose S, 1998, J ADVERTISING RES, V38, P29
   Godes D, 2005, MARKET LETT, V16, P415, DOI 10.1007/s11002-005-5902-4
   Gupta A, 2004, INT J ELECTRON COMM, V8, P131, DOI 10.1080/10864415.2004.11044302
   Haffer R, 2008, TOTAL QUAL MANAG BUS, V19, P763, DOI 10.1080/14783360802159428
   Hawes JonM., 1989, J PERS SELL SALES M, V9, P1
   Haytko DL, 2004, J ACAD MARKET SCI, V32, P312, DOI 10.1177/0092070304264989
   Hennig-Thurau T, 2004, J INTERACT MARK, V18, P38, DOI 10.1002/dir.10073
   HERR PM, 1991, J CONSUM RES, V17, P454, DOI 10.1086/208570
   Hulland J, 1999, STRATEGIC MANAGE J, V20, P195, DOI 10.1002/(SICI)1097-0266(199902)20:2<195::AID-SMJ13>3.3.CO;2-Z
   Jarvenpaa S. L., 1996, International Journal of Electronic Commerce, V1, P59
   Jarvenpaa S. L., 2000, Information Technology & Management, V1, P45, DOI 10.1023/A:1019104520776
   Jing RZ, 2014, AER ADV ENG RES, V5, P1419
   Johnson JD, 1998, PREV MED, V27, pS71, DOI 10.1006/pmed.1998.0248
   Jung TS, 1999, CONSUMER BEHAV
   Kauffman R.J., 2002, Handbook of Electronic Commerce in Business and Society, P99
   Kim D., 2003, J ELECTRON COMMER RE, V4, P49
   Kini A, 1998, P ANN HICSS, P51, DOI 10.1109/HICSS.1998.655251
   Kotler Philip, 2006, Marketing Management, VTwelfth
   Lai H, 2003, P 1 WORKSH KNOWL EC, P51
   Lee MKO, 2007, J AM SOC INF SCI TEC, V58, P2066, DOI 10.1002/asi.20670
   Leeraphong A., 2013, J EC BUSINESS MANAGE, V1, P314
   Liaw G.-F., 2011, J INT MANAGEMENT STU, V6, P1
   Luhmann N., 2018, TRUST POWER
   Martin O., 2010, J MARKETING TRENDS, V1, P25
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   McKnight DH, 2001, INT J ELECTRON COMM, V6, P35, DOI 10.1080/10864415.2001.11044235
   Mudambi SM, 2010, MIS QUART, V34, P185
   MURSTEIN BI, 1977, J MARRIAGE FAM, V39, P543, DOI 10.2307/350908
   Park DH, 2008, ELECTRON COMMER R A, V7, P399, DOI 10.1016/j.elerap.2007.12.001
   Pavlou PA, 2004, INFORM SYST RES, V15, P37, DOI 10.1287/isre.1040.0015
   Pentina I, 2008, J ELECTRON COMMER RE, V9, P114
   PETER JP, 1976, J MARKETING RES, V13, P184, DOI 10.2307/3150856
   Pi SM, 2011, AFR J BUS MANAGE, V5, P7120
   Price LL, 1999, J MARKETING, V63, P38, DOI 10.2307/1251973
   Rezabakhsh B, 2006, J CONSUM POLICY, V29, P3, DOI 10.1007/s10603-005-3307-7
   Richins ML, 1984, ADV CONSUMER RES, VXI
   Ringle C.M., 2005, SmartPLS 2.0
   Shemwell D.J., 1994, INT J SERV IND MANAG, V5, P57, DOI DOI 10.1108/09564239410064089
   SILVER A, 1990, AM J SOCIOL, V95, P1474, DOI 10.1086/229461
   SMITH RE, 1993, J MARKETING RES, V30, P204, DOI 10.2307/3172828
   Song JH, 2008, J MARKETING, V72, P99, DOI 10.1509/jmkg.72.2.99
   Sorebo O, 2009, COMPUT EDUC, V53, P1177, DOI 10.1016/j.compedu.2009.06.001
   Teo TSH, 2007, OMEGA-INT J MANAGE S, V35, P22, DOI 10.1016/j.omega.2005.02.001
   Tong X, 2010, INT J RETAIL DISTRIB, V38, P742, DOI 10.1108/09590551011076524
   Tsvetovat M., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P263, DOI 10.1145/336595.337479
   Urbach N., 2010, J INFORM TECHNOLOGY, V11, P2
   van der Heijden H, 2003, EUR J INFORM SYST, V12, P41, DOI 10.1057/palgrave.ejis.3000445
   Wasko MM, 2005, MIS QUART, V29, P35, DOI 10.2307/25148667
   Wu JJ, 2005, IND MANAGE DATA SYST, V105, P937, DOI 10.1108/02635570510616120
   Yadav MS, 2014, J MARKETING, V78, P20, DOI 10.1509/jm.12.0020
NR 79
TC 6
Z9 7
U1 11
U2 148
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11751
EP 11768
DI 10.1007/s11042-017-4470-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000035
DA 2024-07-18
ER

PT J
AU Zhou, XK
   Jin, Q
AF Zhou, Xiaokang
   Jin, Qun
TI A heuristic approach to discovering user correlations from organized
   social stream data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social data; Stream metaphor; Social network analysis; User correlation
   discovery; Information seeking
AB Recently, with the widespread popularity of SNS (Social Network Service), such as Twitter, Facebook, people are increasingly accustomed to sharing feeling, experience and knowledge with each other on Internet. The high accessibility of these web sites has allowed the information to be spread across the social media more quickly and widely, which leads to more and more populations being engaged into this so-called social stream environment. All these make the organization of user relationships become increasingly important and necessary. In this study, we try to discover the potential and dynamical user correlations using those organized social streams in accordance with users' current interests and needs, in order to assist the collaborative information seeking process. We develop a heuristic approach to build a Dynamically Socialized User Networking (DSUN) model, and define a set of measures (such as interest degree, and popularity degree) and concepts (such as complementary tie, weak tie, and strong tie), to discover and represent users' current profiling and dynamical correlations. The corresponding algorithms are developed respectively. Finally, the architecture of the functional modules is presented, and the experiment results are demonstrated and discussed based on an application of the proposed model.
C1 [Zhou, Xiaokang; Jin, Qun] Waseda Univ, Grad Sch Human Sci, 2-579-15 Mikajima, Tokorozawa, Saitama, Japan.
C3 Waseda University
RP Jin, Q (corresponding author), Waseda Univ, Grad Sch Human Sci, 2-579-15 Mikajima, Tokorozawa, Saitama, Japan.
EM xkzhou@ruri.waseda.jp; jin@waseda.jp
RI Bennis, Mehdi/ABE-5838-2020
OI Bennis, Mehdi/0000-0003-0261-0171
FU Waseda University [2012B-215, 2013A-6395, 2013B-207, 2014K-6214]
FX The work has been partly supported by 2012, 2013 and 2014 Waseda
   University Grants for Special Research Project No. 2012B-215, No.
   2013A-6395, No. 2013B-207, and No. 2014K-6214.
CR Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   [Anonymous], 2003, P 29 INT C VER LARG
   [Anonymous], 2013, PROC 16 INT C EXTEND
   Bickmore Timothy, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P390, DOI 10.1007/978-3-642-33197-8_40
   Black A, 2012, PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON SUPPORTING GROUP WORK, P229
   Byun C., 2012, P 14 INT C INFORM IN, P196
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chen H, 2010, 2 INT S MULT EM NETW
   Cogan P, 2012, Proceedings of the First ACM International Workshop on Hot Topics on Interdisciplinary Social Networks Research, P25, DOI 10.1145/2392622.2392626
   Ed H, 2009, COMPUTER, V42, P42
   Gaber MM, 2005, SIGMOD REC, V34, P18, DOI 10.1145/1083784.1083789
   Gama Sandra, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P319, DOI 10.1007/978-3-642-33197-8_33
   Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387
   Guha S, 2000, P ANN S FOUND COMP S
   Gupta Chetan, 2009, 2009 IEEE Conference on Commerce and Enterprise Computing, P33, DOI 10.1109/CEC.2009.74
   Han JW, 2005, DISTRIB PARALLEL DAT, V18, P173, DOI 10.1007/s10619-005-3296-1
   Hashemi S, 2009, IEEE T KNOWL DATA EN, V21, P624, DOI 10.1109/TKDE.2008.181
   Hu B, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P368, DOI 10.1109/ASONAM.2012.67
   Huang J, 2010, P CASCON 10 2010 C C, P199
   Hyoseop Shin, 2008, Wl 2008. 2008 IEEE/WIC/ACM International Conference on Web Intelligence. IAT 2008. 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology. Wl-IAT Workshop 2008 2008 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology Workshops, P105, DOI 10.1109/WIIAT.2008.391
   Johnson KA, 2011, LEARN MEDIA TECHNOL, V36, P21, DOI 10.1080/17439884.2010.534798
   Junco R, 2011, J COMPUT ASSIST LEAR, V27, P119, DOI 10.1111/j.1365-2729.2010.00387.x
   Kendall L., 2011, CHI'11 Extended Abstracts on Human Factors in Computing Systems, P1555
   Leroy Vincent, 2010, P 16 INT C KNOWL DIS, P393
   Leskovec J., 2008, P 17 INT C WORLD WID, DOI 10.1145/1367497.1367620
   Li R, 2012, PROC VLDB ENDOW, V5, P1603
   Masud MM, 2008, ACM T MANAG INF SYST, V2
   Mitzlaff F., 2010, Proceedings of the 21st ACM conference on Hypertext and hypermedia, P265
   Musselle Chris, 2012, Artificial Immune Systems. Proceedings of the 11th International Conference, ICARIS 2012, P246, DOI 10.1007/978-3-642-33757-4_19
   ORDONEZ C, 2003, P 8 ACM SIGMOD WORKS, P12, DOI DOI 10.1145/882082.882087
   Pervin N, 2013, ACM TRANS MANAG INF, V3, DOI 10.1145/2407740.2407743
   Rogati M., 2010, Proceedings of the 19th international conference on World wide web, P981, DOI DOI 10.1145/1772690.1772790
   Signorini A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019467
   Wang X., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM'11, P1031
   Xiaokang Zhou, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P53, DOI 10.1007/978-3-642-35236-2_6
   Xiaokang Zhou, 2011, Advances in Web-Based Learning - ICWL 2011. Proceedings 10th International Conference, P219, DOI 10.1007/978-3-642-25813-8_23
   Yang C., 2012, ICEC, P41, DOI [10.1145/2346536.2346544, DOI 10.1145/2346536.2346544]
   Zhou XK, 2011, ACM ICUIMC 2011 5 IN
NR 38
TC 24
Z9 24
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11487
EP 11507
DI 10.1007/s11042-014-2153-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000022
DA 2024-07-18
ER

PT J
AU Chen, L
   Hu, RM
   Han, Z
   Li, Q
   Lu, Z
AF Chen, Liang
   Hu, Ruimin
   Han, Zhen
   Li, Qing
   Lu, Zheng
TI Face super resolution based on parent patch prior for VLQ scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face super resolution; Parent patch prior; Surrounding pixel; VLQ
   degradation; Consistency enhancement
ID SUPERRESOLUTION; HALLUCINATION; RECONSTRUCTION; LIMITS
AB Face Super Resolution (FSR) is to infer High Resolution (HR) facial images from given Low Resolution (LR) ones with the assistance of LR and HR training pairs. Among existing methods, Neighbor Embedding(NE) FSR methods are superior in visual and objective quality than holistic based methods. These NE methods are based on the consistency assumption that the neighbors in HR/LR space form similar local geometry. But when LR images are in Very Low Quality (VLQ), the LR patches are seriously contaminated that even two distinct patches form similar appearance, which means that the consistency assumption is not well held anymore. To solve this problem, in this paper we use the target patch as well as the surrounding pixels, which we call parent patch, to represent the target patch. By incorporating the peripheral information, the parent patch is much more robust to noise in the LR and HR consistency learning. The effectiveness of proposed method is verified both quantitatively and qualitatively. In this paper, we also discuss the boundary and the paradox of the multi-scaled parent patch prior in NE based FSR framework.
C1 [Chen, Liang; Hu, Ruimin; Han, Zhen] Wuhan Univ, State Key Lab Software Engn, Sch Comp, Wuhan, Peoples R China.
   [Chen, Liang; Hu, Ruimin; Han, Zhen] Collaborat Innovat Ctr Geospatial Technol, Wuhan, Peoples R China.
   [Chen, Liang; Hu, Ruimin; Han, Zhen] Wuhan Univ, NERCMS, Comp Sch, Wuhan, Peoples R China.
   [Chen, Liang; Li, Qing; Lu, Zheng] City Univ Hong Kong, MERC, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Wuhan University; Wuhan University; City University of Hong Kong
RP Hu, RM (corresponding author), Wuhan Univ, State Key Lab Software Engn, Sch Comp, Wuhan, Peoples R China.; Hu, RM (corresponding author), Collaborat Innovat Ctr Geospatial Technol, Wuhan, Peoples R China.; Hu, RM (corresponding author), Wuhan Univ, NERCMS, Comp Sch, Wuhan, Peoples R China.
EM hurm1964@gmail.com
RI Lu, Zheng/B-1537-2009
OI Lu, Zheng/0000-0003-4098-2486
FU National High Technology Research and Development Program of China (863
   Program) [2015AA016306]; National Nature Science Foundation of China
   [61231015, 61172173, 61303114, U1404618, 61501413, 61502354]; Internet
   of Things Development Funding Project of Ministry of industry [25];
   Technology Research Program of Ministry of Public Security
   [2014JSYJA016]; China Postdoctoral Science Foundation funded project
   [2013M530350, 2014M562058]; Specialized Research Fund for the Doctoral
   Program of Higher Education [20130141120024]; Fundamental Research Funds
   for the Central Universities [2042014kf0025]; EU [PIRSES-GA-2013-612652]
FX The research is supported by the National High Technology Research and
   Development Program of China (863 Program No. 2015AA016306); the
   National Nature Science Foundation of China (No. 61231015, 61172173,
   61303114, U1404618, 61501413, 61502354); the Internet of Things
   Development Funding Project of Ministry of industry in 2013(No. 25); the
   Technology Research Program of Ministry of Public Security (No.
   2014JSYJA016); the China Postdoctoral Science Foundation funded project
   (2013M530350, 2014M562058); the Specialized Research Fund for the
   Doctoral Program of Higher Education (No. 20130141120024); the
   Fundamental Research Funds for the Central Universities(2042014kf0025).
   This work was partly supported by the EU FP7 QUICK project under Grant
   Agreement No. PIRSES-GA-2013-612652. The authors would like to thank Dr.
   Junjun Jiang for his important contribution in this paper.
CR Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dai XY, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2414181
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Huang H, 2011, IEEE T CIRC SYST VID, V21, P1363, DOI 10.1109/TCSVT.2011.2163461
   Jiang J, FACIAL IMAGE HALLUCI
   Jiang J, 2015, CDMMA COUPLED DISCRI
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jiang JJ, 2014, SIGNAL PROCESS, V103, P168, DOI 10.1016/j.sigpro.2014.02.014
   Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121
   Lan C, 2010, P INT C MULT, P883
   Li B, 2009, IEEE SIGNAL PROC LET, V16, P957, DOI 10.1109/LSP.2009.2027657
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu SF, 2014, IEEE IMAGE PROC, P4032, DOI 10.1109/ICIP.2014.7025819
   Ma X, 2009, IEEE INT CON MULTI, P290, DOI 10.1109/ICME.2009.5202492
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Peng C, 2015, MULTIPLE REPRESENTAT
   Shao L, 2008, IEEE T IMAGE PROCESS, V17, P1772, DOI 10.1109/TIP.2008.2002162
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Su K., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Sun J, 2003, PROC CVPR IEEE, P729
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang NN, 2013, PATTERN RECOGN LETT, V34, P77, DOI 10.1016/j.patrec.2012.04.005
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2014, IEEE T CIRC SYST VID, V24, P802, DOI 10.1109/TCSVT.2013.2290574
   Xiaohui Dong, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P183, DOI 10.1007/978-3-319-13168-9_19
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Yang J, 2008, IEEE IMAGE PROC, P1264, DOI 10.1109/ICIP.2008.4711992
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 36
TC 8
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10231
EP 10254
DI 10.1007/s11042-016-3611-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300052
DA 2024-07-18
ER

PT J
AU Fan, JY
   Zhou, SB
   Siddique, MA
AF Fan, Jiyun
   Zhou, Shangbo
   Siddique, Muhammad Abubakar
TI Fuzzy color distribution chart -based shot boundary detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; FCDC; SIFT feature; Gradual transition; Abrupt
   transition
ID VIDEO; HISTOGRAM; REPRESENTATION; SCHEME
AB Shot boundary detection is an important research topic in the field of video processing technology, which has a wide range of applications in video indexing, pattern recognition, video summarization, video classification, video retrieval, etc. Shot boundary detection includes both abrupt (cut) and gradual transition detection. In this paper, a new method is proposed for extracting the feature from frames of a video. We name the proposed method as fuzzy color distribution chart (FCDC). FCDC can be used to describe the spatial distribution of colors and avoid the influences of noise, slight illumination and insertions such as words and logos. Based on the FCDC, a new algorithm is put forward for shot boundary detection, which can distinguish the gradual transition if there are quickly moving objects in the frames. Our proposed algorithm can be employed to suppress some defects of shot boundary detection that cannot be solved completely, and the experimental results show that the improved algorithm can detect the shot boundary more accurately than some existing researches.
C1 [Fan, Jiyun; Zhou, Shangbo; Siddique, Muhammad Abubakar] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
   [Fan, Jiyun; Zhou, Shangbo] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
C3 Chongqing University; Chongqing University
RP Zhou, SB (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.; Zhou, SB (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM shbzhou@cqu.edu.cn
RI Siddique, Muhammad Abubakar/AAO-9279-2021
OI Siddique, Muhammad Abubakar/0000-0001-9721-3034
FU Fundamental Science and Frontier Technology Research of Chongqing CSTC
   [cstc2015jcyjBX0124]
FX This work was supported by the major project of Fundamental Science and
   Frontier Technology Research of Chongqing CSTC (Grant No.
   cstc2015jcyjBX0124)
CR Adjeroh D, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/859371
   [Anonymous], COMP COMM NETW TECHN
   [Anonymous], P WWW
   Baber J., 2011, 17th DSP 2011 International Conference on Digital Signal Processing, Proceedings, P1
   Birinci M, 2014, SIGNAL PROCESS-IMAGE, V29, P410, DOI 10.1016/j.image.2013.12.003
   Boccignone G, 2005, IEEE T CIRC SYST VID, V15, P365, DOI 10.1109/TCSVT.2004.842603
   Cerneková Z, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2812528
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Gao GY, 2014, J COMPUT SCI TECH-CH, V29, P155, DOI 10.1007/s11390-014-1418-9
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Heng WJ, 2001, J VIS COMMUN IMAGE R, V12, P217, DOI 10.1006/jvci.2001.0457
   Jadon RS, 2001, PATTERN RECOGN LETT, V22, P1359, DOI 10.1016/S0167-8655(01)00041-1
   Jiang XH, 2013, NEUROCOMPUTING, V116, P102, DOI 10.1016/j.neucom.2011.11.037
   Kang HB, 1997, TENCON IEEE REGION, P195, DOI 10.1109/TENCON.1997.647290
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Li XQ, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P484, DOI 10.1109/IFITA.2009.233
   Li YN, 2009, IET IMAGE PROCESS, V3, P121, DOI 10.1049/iet-ipr.2007.0193
   Lo CC, 2001, COMPUT STAND INTER, V23, P429, DOI 10.1016/S0920-5489(01)00085-X
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei T, 2009, VISUAL COMPUT, V25, P39, DOI 10.1007/s00371-008-0282-4
   Mishra R, 2013, IEEE INT ADV COMPUT, P1201
   Priya GGL, 2012, PROC TECH, V1, P247, DOI 10.1016/j.protcy.2012.10.030
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Tang Lin-Xie., 2009, Proceedings of the 17th ACM international conference on Multimedia, P351
   Yoo HW, 2006, MULTIMED TOOLS APPL, V28, P283, DOI 10.1007/s11042-006-7715-8
   Zhang L, 2014, VISUAL COMPUT, V30, P1123, DOI 10.1007/s00371-013-0882-5
NR 27
TC 11
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10169
EP 10190
DI 10.1007/s11042-016-3604-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300049
DA 2024-07-18
ER

PT J
AU Kanrar, S
   Mandal, PK
AF Kanrar, Soumen
   Mandal, Prasenjit Kumar
TI E-health monitoring system enhancement with Gaussian mixture model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android; Database server; Frontline SMS; GPS; GMM; Healthcare system;
   Vital parameters
AB In order to enhance the healthcare system, we have designed and developed a system prototype which remotely monitors patient's vital parameters by using mobile based android application. Proposed E-health care system collects patient's biological and personal information with the corresponding vital parameters and stores this Meta data information into the health care database servers. The distributed servers are connected with GSP system. So the extracted information from the server is directly feed to the doctor's mobile device as well as to the patient's mobile devices in a presentable format. This system also uses Frontline SMS as an SMS service which is used to send SMS to the doctor's mobile device automatically, when any one of the patient's vital parameter goes out of normal range. In this paper, we present the GMM (Gaussian mixture model) based on extracted features of the patient information and assign it to the specialized doctor. In this work, we have shown that by GMM based algorithm efficiently balances the patient load to the doctor. This novel approach enhances the E-health monitoring system for normal situations as well as in the case of Natural disaster. The proposed load balancing approach gives relief to the patient for unnecessary long delay to receive medical advice. The presented result in this work shown that, the doctors from all category and specialization are loaded rationally and uniformly. According to our knowledge GMM based approach is the new additional component to enhance the E-health care system.
C1 [Kanrar, Soumen; Mandal, Prasenjit Kumar] Vehere Interact Pvt Ltd, Kolkata, W Bengal, India.
RP Kanrar, S (corresponding author), Vehere Interact Pvt Ltd, Kolkata, W Bengal, India.
EM soumen.kanrar@veheretech.com; prasenjit.mandal@vehere.com
RI Kanrar, Soumen/N-3113-2019
OI Kanrar, Soumen/0000-0002-0331-4932
CR [Anonymous], 16 IEEE S COMP BAS M
   [Anonymous], INT J SCI ENG RES
   [Anonymous], J GEN INTERN MED
   [Anonymous], MICR ESCIENCE WORKSH
   [Anonymous], 2014, P INT ACM SIGIR WORK
   [Anonymous], ANN IEEE IND C INDIC
   [Anonymous], IEEE S IND EMB SYST
   [Anonymous], INT J DISTRIBUTED PA
   [Anonymous], C MOB COMP APPL SERV
   [Anonymous], IEEE CONS COMM NETW
   [Anonymous], ACM SIGHIT INT HLTH
   [Anonymous], 2010 IE EMBS C BIOM
   [Anonymous], C MOB COMP APPL SERV
   [Anonymous], BODYNETS
   Bakshi A., 2011, 2011 IEEE 13th International Conference on e-Health Networking, Applications and Services (Healthcom 2011), P9, DOI 10.1109/HEALTH.2011.6026797
   Chan V, 2008, IET COMMUN, V2, P223, DOI 10.1049/iet-com:20060646
   Creswell J. W., 2013, RES DESIGN QUALITATI
   Jiang JH, 2006, 2006 3RD IEEE/EMBS INTERNATIONAL SUMMER SCHOOL ON MEDICAL DEVICES AND BIOSENSORS, P109, DOI 10.1109/ISSMDBS.2006.360110
   Kanrar S, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P95, DOI 10.1145/2818567.2818585
   Kanrar S, 2016, ADV INTELL SYST, V404, P97
   Kanrar S, 2015, ADV INTELL SYST, V339, P21, DOI 10.1007/978-81-322-2250-7_3
   Li JH, 2010, P ANN HICSS, P2367, DOI 10.1109/HICSS.2010.274
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Sposaro F., 2010, 32 ANN INT C IEEE EM
   Sposaro F, 2009, IEEE ENG MED BIO, P6119, DOI 10.1109/IEMBS.2009.5334912
   Suh MK, 2012, MOBILE NETW APPL, V17, P163, DOI 10.1007/s11036-011-0331-5
   Suh MK, 2011, J MED SYST, V35, P1165, DOI 10.1007/s10916-011-9733-y
   Tachakra S, 2003, TELEMED J E-HEALTH, V9, P247, DOI 10.1089/153056203322502632
   Wac K, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P212, DOI 10.1109/HEALTH.2008.4600138
   Wu WH, 2008, ARTIF INTELL MED, V42, P137, DOI 10.1016/j.artmed.2007.11.006
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 40
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10801
EP 10823
DI 10.1007/s11042-016-3509-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400028
DA 2024-07-18
ER

PT J
AU Zhang, H
   Li, F
   Li, N
AF Zhang, Hong
   Li, Fan
   Li, Na
TI Compressed-domain-based no-reference video quality assessment model
   considering fast motion and scene change
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality assessment; QoE; No-reference; Scene change; Fast motion;
   Compressed domain
ID PACKET-LOSS VISIBILITY; PSNR
AB Due to the variability of wireless channel state, video quality monitoring became very important for guaranteeing users' Quality of Experience (QoE). QoE presents the overall perceptual quality of service from the subjective users' perspective. However, because of diverse characteristics of video content, Human Visual System (HVS) cannot give the same attention to whole scene simultaneously when facing video sequence. In this paper, we proposed a video quality assessment model by considering the influence of fast motion and scene change. The motion change contribution factor and scene change contribution factor are defined to quantify the characteristics of video content, which is closely related to the users' QoE. Based on G.1070, our proposed model considers the influential factors of loss nature of video coding, variability of practical network and video features. Also, the proposed model owns low computational complexity due to the compressed domain approach for the estimation of the model parameters. Therefore, the video quality is assessed without fully decoding the video stream. The performance of our proposed model has been compared with five existing models and the results also shown that our model has high prediction accuracy closing to human perception.
C1 [Zhang, Hong; Li, Fan; Li, Na] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM lifan@mail.xjtu.edu.cn
FU National Science Foundation of China [61372091]; Fundamental Research
   Funds for the Central Universities
FX This research work was supported in part by National Science Foundation
   of China 61372091, and the Fundamental Research Funds for the Central
   Universities.
CR [Anonymous], G1070 ITUT
   [Anonymous], 2000, EE392J
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   De Vriendt J, 2014, BELL LABS TECH J, V18, P45, DOI 10.1002/bltj.21645
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   Ichigaya A, 2008, IEEE T CIRC SYST VID, V18, P817, DOI 10.1109/TCSVT.2008.920658
   Joskowicz J., 2009, 5th International Latin American Networking Conference, LANC 2009, September 24, 2009 - September 25, 2009, P87, DOI [10.1145/1636682.1636697, DOI 10.1145/1636682.1636697]
   Joskowicz J., 2010, IEEE INT WORKSH TECH, P1, DOI DOI 10.1109/CQR.2010.5619912
   Ju Y, 2014, MULTIMED TOOLS APPL, V72, P1093, DOI 10.1007/s11042-013-1413-0
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kim HJ, 2014, MULTIMED TOOLS APPL, V72, P2163, DOI 10.1007/s11042-013-1507-8
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Li F, 2012, IEEE T VEH TECHNOL, V61, P2753, DOI 10.1109/TVT.2012.2195511
   Lin TL, 2010, IEEE T IMAGE PROCESS, V19, P722, DOI 10.1109/TIP.2009.2038834
   Masry M, 2006, IEEE T CIRC SYST VID, V16, P260, DOI 10.1109/TCSVT.2005.861946
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Porikli F, 2011, IEEE SIGNAL PROC MAG, V28, P164, DOI 10.1109/MSP.2011.942341
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2007, INT CONF ACOUST SPEE, P869
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Singh S., 2012, IEEE International Conference on Communications (ICC 2012), P7071, DOI 10.1109/ICC.2012.6364806
   Sogaard J, 2015, IEEE T CIRC SYST VID, V25, P1637, DOI 10.1109/TCSVT.2015.2397207
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Yang FZ, 2012, IEEE J-STSP, V6, P672, DOI 10.1109/JSTSP.2012.2207705
   Zhang XH, 2008, J VIS COMMUN IMAGE R, V19, P30, DOI 10.1016/j.jvcir.2007.06.001
NR 29
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9485
EP 9502
DI 10.1007/s11042-016-3558-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300017
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Sun, ZR
   Tang, ZJ
   Yu, CQ
   Wang, XY
AF Zhang, Xianquan
   Sun, Zerui
   Tang, Zhenjun
   Yu, Chunqiang
   Wang, Xiaoyun
TI High capacity data hiding based on interpolated image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpolated image; Data hiding; Parabolic interpolation; Embedding
   capacity
ID DIFFERENCE EXPANSION; REVERSIBLE WATERMARKING; HISTOGRAM-MODIFICATION;
   ALGORITHM
AB We investigate the use of parabolic interpolation in data hiding and propose a novel data hiding algorithm with high capacity based on interpolated image. Specifically, the proposed algorithm creates an interpolated image from input image by parabolic interpolation, and embeds secret bits into interpolated pixels in terms of the relation between the interpolated value and the mean value. Ten standard benchmark images are taken as test images for validating efficiency of our algorithm. The results illustrate that our algorithm has better performances than some popular data hiding methods in embedding capacity and visual quality with respect to PSNR and SSIM.
C1 [Zhang, Xianquan; Sun, Zerui; Tang, Zhenjun; Yu, Chunqiang] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Zhang, Xianquan; Sun, Zerui; Tang, Zhenjun] Guangxi Normal Univ, Dept Comp Sci, 15 Yucai Rd, Guilin 541004, Peoples R China.
   [Zhang, Xianquan; Yu, Chunqiang] Guilin Univ Elect Technol, Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
   [Zhang, Xianquan; Sun, Zerui] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
   [Wang, Xiaoyun] Yangtze Normal Univ, Coll Math & Comp Sci, Chongqing 408100, Peoples R China.
C3 Guangxi Normal University; Guangxi Normal University; Guilin University
   of Electronic Technology; Guilin University of Electronic Technology;
   Yangtze Normal University
RP Zhang, XQ (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Zhang, XQ (corresponding author), Guangxi Normal Univ, Dept Comp Sci, 15 Yucai Rd, Guilin 541004, Peoples R China.; Zhang, XQ (corresponding author), Guilin Univ Elect Technol, Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.; Zhang, XQ (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
EM zxq6622@163.com
RI Li, June/JEF-1173-2023; wang, xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61562007, 61363034,
   61300109]; Guangxi Natural Science Foundation [2015GXNSFDA139040];
   Guangxi "Bagui Scholar" Teams for Innovation and Research; Project of
   the Guangxi Key Lab of Multi-source Information Mining Security
   [13-A-03-01, 14-A-02-02, 15-A-02-02]; Project of the Guangxi Experiment
   Center of Information Science [20130204]; Guangxi Key Laboratory of
   Trusted Software [kx201327]; Scientific and Technological Research
   Projects of Guangxi Education Administration [YB2014048]; Guangxi Higher
   School Key Lab of Cloud Computing and Complex System [15202]; Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing
FX This work was partially supported by the National Natural Science
   Foundation of China (61562007, 61363034, 61300109), the Guangxi Natural
   Science Foundation (2015GXNSFDA139040), the Guangxi "Bagui Scholar"
   Teams for Innovation and Research, the Project of the Guangxi Key Lab of
   Multi-source Information Mining & Security (13-A-03-01, 14-A-02-02,
   15-A-02-02), the Project of the Guangxi Experiment Center of Information
   Science (20130204), the Guangxi Key Laboratory of Trusted Software
   (kx201327), the Scientific and Technological Research Projects of
   Guangxi Education Administration (YB2014048), the Guangxi Higher School
   Key Lab of Cloud Computing and Complex System (15202), and the Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing. The authors would like to express sincere
   thanks for the anonymous reviewers' insightful comments and valuable
   suggestions.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 1, MAIN CONFERENCE, P506, DOI 10.1109/EUC.2008.20
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2002, LOSSLESS DATA EMBEDD, P572, DOI [10.1117/12.465317, DOI 10.1117/12.465317]
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2008, IMAGE VISION COMPUT, V26, P1148, DOI 10.1016/j.imavis.2007.12.005
   Wang WJ, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P387, DOI 10.1109/IIH-MSP.2013.103
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang XQ, 2012, SIGNAL PROCESS, V92, P1691, DOI 10.1016/j.sigpro.2012.01.004
NR 23
TC 48
Z9 52
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9195
EP 9218
DI 10.1007/s11042-016-3521-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300004
DA 2024-07-18
ER

PT J
AU Etezadifar, P
   Farsi, H
AF Etezadifar, Pouriya
   Farsi, Hassan
TI Scalable video summarization via sparse dictionary learning and
   selection simultaneously
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Dictionary learning; Key frames; Scene analysis;
   Video analysis; Sparse coding
ID PARALLEL FRAMEWORK; REPRESENTATION; REGRESSION; SKEWNESS; SCENE; MODEL
AB Every day, a huge amount of video data is generated worldwide and processing this kind of data requires powerful resources in terms of time, manpower, and hardware. Therefore, to help quickly understand the content of video data, video summarization methods have been proposed. Recently, sparse formulation-based methods have been found to be able to summarize a large amount of video compared to other methods. In this paper, we propose a new method in which video summarization is performed as training and selection sparse dictionary problem simultaneously. It is shown that the proposed method is able to improve the summarization of a large amount of video data compared to other methods. Finally, the performance of the proposed method is compared to state-of-the-art methods using standard data sets, in which the key frames are manually tagged. The obtained results demonstrate that the proposed method improves video summarization compared to other methods.
C1 [Etezadifar, Pouriya; Farsi, Hassan] Univ Birjand, Fac Elect & Comp Engn, Birjand, Iran.
C3 University of Birjand
RP Farsi, H (corresponding author), Univ Birjand, Fac Elect & Comp Engn, Birjand, Iran.
EM hfarsi@birjand.ac.ir
RI Farsi, hassan/AAF-5297-2021
CR [Anonymous], 2001, HPL2001191
   [Anonymous], 2007, GRADIENT METHODS MIN
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   ARNOLD BC, 1995, AM STAT, V49, P34, DOI 10.2307/2684808
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chen F, 2007, P INT WORKSH TRECVID
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Chen F, 2011, IEEE T CIRC SYST VID, V21, P193, DOI 10.1109/TCSVT.2011.2106271
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Doulamis ND, 2000, IEEE T CIRC SYST VID, V10, P501, DOI 10.1109/76.844996
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Ejaz N, 2012, INT J INNOV COMPUT I, V8, P4219
   Elad M, 2010, SPARSE REDUNDANT REP, P200
   Ferman AM, 1997, P SOC PHOTO-OPT INS, V3024, P953, DOI 10.1117/12.263307
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gallager R. G., 1968, INFORM THEORY RELIAB
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GROENEVELD RA, 1984, STATISTICIAN, V33, P391, DOI 10.2307/2987742
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Hanjalic R, 1996, 1 INT WORKSH IM DAT, P67
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kim HH, 2010, J AM SOC INF SCI TEC, V61, P927, DOI 10.1002/asi.21317
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Loui Alexander., 2007, MIR 07, P245
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Massimiliano A, 2006, THESIS
   MIKOLAJCZYK K, 2003, P BRIT MACH VIS C NO
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Priya GGL, 2014, ECOL INFORM, V23, P107, DOI 10.1016/j.ecoinf.2013.09.003
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   RAYNER JCW, 1995, COMMUN STAT-THEOR M, V24, P593, DOI 10.1080/03610929508831509
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsai DM, 2009, IEEE T IMAGE PROCESS, V18, P158, DOI 10.1109/TIP.2008.2007558
   Wu J, 2009, P IRO
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu JX, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4763, DOI 10.1109/IROS.2009.5354164
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xu M, 2004, IEEE IMAGE PROC, P2909
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 56
TC 11
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7947
EP 7971
DI 10.1007/s11042-016-3433-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800016
DA 2024-07-18
ER

PT J
AU Faraoun, KM
AF Faraoun, Kamel Mohamed
TI Design of a new efficient and secure multi-secret images sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-secrets sharing; Images sharing; Cryptographic construction;
   Provable security
AB We propose a new (n,n) multi-secret images sharing scheme that provides high level of provable security with fast sharing and reconstruction procedures. It uses simple Boolean operations conjointly with a secure stream cipher and a cryptographic hash function in order to enable an efficient sharing of n secret images among a set of n different participants. This approach overcomes the security weakness detected in existing similar schemes, and provides additional advantages such as high sensitivity to alterations and ability to share heterogeneous images having diverse resolutions. Obtained experimental results show the effectiveness and robustness of the method compared to existing schemes, particularly its ability to ensure higher security level with competitive computational performances.
C1 [Faraoun, Kamel Mohamed] Djilalli Liabbes Univ, Dept Comp Sci, Sidi Bel Abbes, Algeria.
RP Faraoun, KM (corresponding author), Djilalli Liabbes Univ, Dept Comp Sci, Sidi Bel Abbes, Algeria.
EM kamel_mh@yahoo.fr
CR Bernstein DJ, 2008, LECT NOTES COMPUT SC, V4986, P84
   Chang CC, 2005, 11th International Conference on Parallel and Distributed Systems Workshops, Vol II, Proceedings,, P300
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Chen CC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P515
   Chen CC, 2008, J INF SCI ENG, V24, P1567
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen CC, 2008, FUND INFORM, V86, P447
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Dai W, 2009, CRYPTO 5 6 0 BENCHMA
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Fips N, 2001, TECHNICAL REPORT
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Jin J, 2012, OPT LASER TECHNOL, V44, P538, DOI 10.1016/j.optlastec.2011.08.023
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lin SJ, 2010, J VIS COMMUN IMAGE R, V21, P900, DOI 10.1016/j.jvcir.2010.08.006
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1332, DOI 10.1109/APSCC.2008.223
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Tso HK, 2008, OPT ENG, V47, DOI 10.1117/1.2955502
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
NR 25
TC 13
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6247
EP 6261
DI 10.1007/s11042-016-3317-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400009
DA 2024-07-18
ER

PT J
AU Gudigar, A
   Chokkadi, S
   Raghavendra, U
   Acharya, UR
AF Gudigar, Anjan
   Chokkadi, Shreesha
   Raghavendra, U.
   Acharya, U. Rajendra
TI Multiple thresholding and subspace based approach for detection and
   recognition of traffic sign
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advanced driver assistance system; Computer vision; Multiple thresholds;
   Support vector machine; Traffic sign recognition
AB Automatic detection and recognition of traffic sign has been a topic of great interest in advanced driver assistance system. It enhances vehicle and driver safety by providing the condition and state of the road to the drivers. However, visual occlusion and ambiguities in the real-world scenario make the traffic sign recognition a challenging task. This paper presents an Automatic Traffic Sign Detection and Recognition (ATSDR) system, involving three modules: segmentation, detection, and recognition. Region of Interest (ROI) is extracted using multiple thresholding schemes with a novel environmental selection strategy. Then, the traffic sign detection is carried out using correlation computation between log-polar mapped inner regions and the reference template. Finally, recognition is performed using Support Vector Machine (SVM) classifier. Our proposed system achieved a recognition accuracy of 98.3 % and the experimental results demonstrates the robustness of traffic sign detection and recognition in real-world scenario.
C1 [Gudigar, Anjan; Chokkadi, Shreesha; Raghavendra, U.] Manipal Univ, Manipal Inst Technol, Dept Instrumentat & Control Engn, Manipal 576104, Karnataka, India.
   [Acharya, U. Rajendra] SIM Univ, Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore.
   [Acharya, U. Rajendra] Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
C3 Manipal Academy of Higher Education (MAHE); Singapore University of
   Social Sciences (SUSS); Universiti Malaya
RP Gudigar, A (corresponding author), Manipal Univ, Manipal Inst Technol, Dept Instrumentat & Control Engn, Manipal 576104, Karnataka, India.
EM anjan.gudigar@manipal.edu
RI Acharya, Rajendra U/E-3791-2010; Chokkadi, Shreesha/AAT-3001-2021;
   Raghavendra, U/G-8634-2015
OI Acharya, Rajendra U/0000-0003-2689-8552; Chokkadi,
   Shreesha/0000-0001-5966-1119; 
NR 0
TC 21
Z9 21
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6973
EP 6991
DI 10.1007/s11042-016-3321-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400039
DA 2024-07-18
ER

PT J
AU Huang, YH
   Chang, CC
   Chen, YH
AF Huang, Ying-Hsuan
   Chang, Ching-Chun
   Chen, Yi-Hui
TI Hybrid secret hiding schemes based on absolute moment block truncation
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Absolute moment block truncation coding (AMBTC); Data hiding; Visual
   quality
ID DATA EMBEDDING SCHEME; IMAGES; STEGANOGRAPHY
AB This paper presents two secret hiding schemes based on absolute moment block truncation coding (AMBTC). One is for embedding secrets into complex blocks and the other one is for smooth blocks. As for the smooth blocks, the small variation of the block is adopted to define the embedding rule to minimize the distortion after data embedding. As for the complex blocks, the large variation of the block is used to embed more secrets while maintaining good visual quality. In the experiments, when compared to Ou and Sun's scheme, the positive data is to confirm the higher capacity while preserving better visual quality.
C1 [Huang, Ying-Hsuan] Natl Chung Shan Inst Sci & Technol, Aeronaut Res Lab, Taichung 407, Taiwan.
   [Chang, Ching-Chun] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   [Chen, Yi-Hui] Asia Univ, Dept M Commerce & Multimedia Applicat, Taichung 413, Taiwan.
   [Chen, Yi-Hui] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung 404, Taiwan.
C3 University of Warwick; Asia University Taiwan; China Medical University
   Taiwan; China Medical University Hospital - Taiwan
RP Huang, YH (corresponding author), Natl Chung Shan Inst Sci & Technol, Aeronaut Res Lab, Taichung 407, Taiwan.
EM chenyh134@gmail.com
RI Chang, Ching-Chun/AGG-3857-2022; Chang, Ching-Chun/JAN-6210-2023
FU Ministry of Science and Technology in Taiwan [MOST 104-2221-E-468-005]
FX Many thanks for the support by Ministry of Science and Technology in
   Taiwan under Grant number MOST 104-2221-E-468-005. Our gratitude also
   goes to Michael Burton, Asia University.
CR Alturki F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958548
   Balasubramanian C, 2013, MULTIMED TOOLS APPL, P1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2009, SOFT COMPUT, V13, P321, DOI 10.1007/s00500-008-0332-x
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chen B, 1999, IMAGE VISION COMPUT, V17, P913, DOI 10.1016/S0262-8856(98)00165-6
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Guo JM, 2010, IEEE INT SYMP CIRC S, P2634, DOI 10.1109/ISCAS.2010.5537082
   Guo JM, 2010, IEEE T COMMUN, V58, P1667, DOI 10.1109/TCOMM.2010.06.090303
   Hashad AI, 2005, Enabling Technologies for the New Knowledge Society, P255
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin C.C., 2014, J INF HIDING MULTIME, V5, P124
   Lin CC, 2009, INT J INNOV COMPUT I, V5, P4283
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Munteanu A, 1999, IEEE Trans Inf Technol Biomed, V3, P176, DOI 10.1109/4233.788579
   Omoomi M, 2011, MULTIMED TOOLS APPL, V54, P201, DOI 10.1007/s11042-010-0517-z
   Ou D, 2014, MULTIMED TOOLS APPL, P1
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Shi YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P269, DOI 10.1109/ICME.2005.1521412
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Walker JamesS., 1996, Fast Fourier Transform
   Yang H. R., 2013, MULTIMED TOOLS APPL, P1
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
NR 33
TC 32
Z9 32
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6159
EP 6174
DI 10.1007/s11042-015-3208-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400004
DA 2024-07-18
ER

PT J
AU Shaheen, S
   Akram, MU
   Khanum, A
   Khan, SA
   Javed, MY
AF Shaheen, Saima
   Akram, M. Usman
   Khanum, Aasia
   Khan, Shoab A.
   Javed, M. Younas
TI A cross layer error control scheme for efficient WLAN multimedia
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unequal error protection; Scalability; IEEE WLAN; Multimedia quality;
   Resolution; Error checksum
ID WIRELESS NETWORKS; VIDEO; TRANSMISSION; INTERNET
AB Efficient streaming of bandwidth intensive and delay sensitive multimedia contents over error prone wireless links has proven to be one of the most challenging problems of the current era of digital communication. However, applying Unequal Error Protection (UEP) strategies at application layer and avoiding unnecessary packet discard at MAC layer yield valuable outcomes and can be incorporated to address the challenge. In this article, we have proposed the idea of discriminating classified video streaming calls from the data packeting over an IEEE WLAN link through bit demarcation in network packet headers, where remarkable concept of UDP-Lite deployed at the transport layer further assists in UEP implementation of the inevitable video parts later on MAC layer. In this way, error computation at various network levels are evaluated and disabled in order to attain increased throughput characterized by the higher number of packets available for decoding, enhanced multimedia visual quality due to gap elimination (appears as a consequence of some frame loss), efficient utilization of link bandwidth with no re-transmissions and reduced delays with least error checksum computations and packet re-transmissions. Promising experimental outcomes have been shown in tabular and graphical forms, particularly represented through subjective assessment of the reconstructed video clips with an emphasis on viewer QoE (Quality of Experience).
C1 [Shaheen, Saima; Akram, M. Usman; Khan, Shoab A.; Javed, M. Younas] Natl Univ Sci & Technol, Dept Comp Engn, Islamabad, Pakistan.
   [Khanum, Aasia; Javed, M. Younas] Forman Christian Coll, Dept Comp Sci, Lahore, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Akram, MU (corresponding author), Natl Univ Sci & Technol, Dept Comp Engn, Islamabad, Pakistan.
EM usmakram@gmail.com
RI Khanum, Aasia/AAR-4434-2021; Akram, Muhammad Usman/AAD-7343-2020
OI Khanum, Aasia/0000-0002-2522-7637; Akram, Muhammad
   Usman/0000-0002-6208-7231
CR Abukharis S, MPEG 2 STREAMING IEE
   Ahmed T, 2005, IEEE J SEL AREA COMM, V23, P385, DOI 10.1109/JSAC.2004.839425
   Andreopoulos Y, 2006, IEEE J SEL AREA COMM, V24, P2104, DOI 10.1109/JSAC.2006.881614
   [Anonymous], 2003, P MSWIM 03 SEP
   [Anonymous], 1998, RFC 2474
   Argyriou A, 2008, IEEE T MULTIMEDIA, V10, P691, DOI 10.1109/TMM.2008.922776
   Fu B, 2014, IEEE COMMUN SURV TUT, V16, P110, DOI 10.1109/SURV.2013.081313.00231
   Jain B.N., 1993, OPEN SYSTEMS INTERCO
   Johnson SJ, 2006, INSTRUCTIONS SCH ELE
   Khan A., 2011, THESIS
   Knee M, 2002, MPEG VIDEO, P1
   Larzon L.-A., 1999, 1999 IEEE International Workshop on Mobile Multimedia Communications (MoMuC'99) (Cat. No.99EX384), P187, DOI 10.1109/MOMUC.1999.819488
   Malladi R, 2002, COMMUN ACM, V45, P144
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Moid Azfar, 2009, Journal of Computer Systems, Networks, and Communications, DOI 10.1155/2009/682813
   Shaheen Saima, 2015, 2015 International Conference on Computer, Communications and Control Technology (I4CT), P570, DOI 10.1109/I4CT.2015.7219643
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Vatolin D., 2009, Msu video quality measurement tool," ed
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Xiao Y, 2011, IEEE SYST J, V5, P474, DOI 10.1109/JSYST.2011.2165596
   Zheng HT, 2001, IEEE T MULTIMEDIA, V3, P356, DOI 10.1109/6046.944478
   [No title captured]
NR 22
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6663
EP 6682
DI 10.1007/s11042-016-3308-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400026
DA 2024-07-18
ER

PT J
AU Azfar, A
   Choo, KKR
   Liu, L
AF Azfar, Abdullah
   Choo, Kim-Kwang Raymond
   Liu, Lin
TI Forensic taxonomy of android productivity apps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensic science; Digital forensics; Forensic taxonomy; Mobile app
   forensics; Mobile forensics; Productivity app taxonomy
AB Android productivity apps have provided the facility of having a constantly accessible and productive workforce to the information and work capabilities needed by the users. With hundreds of productivity apps available in the Android app market, it is necessary to develop a taxonomy for the forensic investigators and the end users to allow them to know what personal data remnants are available from the productivity apps. In this paper, 30 popular Android productivity apps were examined. A logical extraction of the Android phone was collected by using a well-known mobile forensic tool-XRY to extract various information of forensic interest such as user email ID and list of tasks. Based on the findings, a two dimensional taxonomy of the forensic artefacts of the productivity apps is proposed with the app categories in one dimension and the classes of artefacts in the other dimension. The artefacts identified in the study of the apps are summarised using the taxonomy. In addition, a comparison with the existing forensic taxonomies of different categories of Android apps is provided to facilitate timely collection and analysis of evidentiary materials from mobile devices.
C1 [Azfar, Abdullah; Choo, Kim-Kwang Raymond] Univ South Australia, Informat Assurance Res Grp, Adelaide, SA, Australia.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.
   [Choo, Kim-Kwang Raymond] China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
   [Liu, Lin] Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
C3 University of South Australia; University of Texas System; University of
   Texas at San Antonio (UTSA); China University of Geosciences; University
   of South Australia
RP Choo, KKR (corresponding author), Univ South Australia, Informat Assurance Res Grp, Adelaide, SA, Australia.; Choo, KKR (corresponding author), Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.; Choo, KKR (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
EM abdullah.azfar@mymail.unisa.edu.au; Raymond.Choo@fulbrightmail.org;
   Lin.Liu@unisa.edu.au
RI Choo, Kim-Kwang Raymond/A-3634-2009; Liu, Lin/ABD-1224-2020
OI Choo, Kim-Kwang Raymond/0000-0001-9208-5336; Liu,
   Lin/0000-0003-2843-5738
CR Al Mutawa N, 2012, DIGIT INVEST, V9, pS24, DOI 10.1016/j.diin.2012.05.007
   Azfar A, 2015, AMCIS 2015 PROCEEDINGS
   Azfar A, 2016, J FORENSIC SCI, V61, P1337, DOI 10.1111/1556-4029.13164
   Bancora M, 2015, 2ND ACM INTERNATIONAL CONFERENCE ON MOBILE SOFTWARE ENGINEERING AND SYSTEMS MOBILESOFT 2015, P174, DOI 10.1109/MobileSoft.2015.51
   Barmpatsalou K, 2013, DIGIT INVEST, V10, P323, DOI 10.1016/j.diin.2013.10.003
   Casey E, 2009, J FORENSIC SCI, V54, P1353, DOI 10.1111/j.1556-4029.2009.01150.x
   Chu H.C., 2012, Information Technology Convergence, Secure and Trust Computing, and Data Management, P171, DOI DOI 10.1007/978-94-007-5083-8_22
   Chu HC, 2013, ELECTRON COMMER RES, V13, P399, DOI 10.1007/s10660-013-9116-1
   Furini M, 2015, MULTIMED TOOLS APPL, V74, P9795, DOI 10.1007/s11042-014-2151-7
   Gao F, 2013, ADV INTEL SYS RES, V68, P278
   Geyer F, 2012, C DES INT SYST DIS 2
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Husain MI, 2010, L N INST COMP SCI SO, V31, P9
   Immanuel F, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P1094, DOI 10.1109/Trustcom.2015.488
   Keith MJ, 2014, P 47 HAW INT C SYST
   La Polla M, 2013, IEEE COMMUN SURV TUT, V15, P446, DOI 10.1109/SURV.2012.013012.00028
   Leung S, 2014, MOBILE CRM HAS CHANG
   Levinson Alex., 2011, System Sciences (HICSS), 2011 44th Hawaii International Conference on, P1
   Luo XF, 2011, IEEE T AUTOM SCI ENG, V8, P482, DOI 10.1109/TASE.2010.2094608
   Martini B, 2014, IEEE INT CONF TRUST, P935, DOI 10.1109/TrustCom.2014.124
   Martini B, 2013, DIGIT INVEST, V10, P287, DOI 10.1016/j.diin.2013.08.005
   Patrick Leahy Center for Digital Investigation (LCDI), 2015, RETR DAT ANDR OS DEV
   Plachkinova M, 2015, P ANN HICSS, P3187, DOI 10.1109/HICSS.2015.385
   Quick D, 2014, J NETW COMPUT APPL, V40, P179, DOI 10.1016/j.jnca.2013.09.016
   Quick D, 2013, FUTURE GENER COMP SY, V29, P1378, DOI 10.1016/j.future.2013.02.001
   Quick D, 2013, DIGIT INVEST, V10, P3, DOI 10.1016/j.diin.2013.02.003
   Reber C, 2015, OUT FUTURE WUNDERSLI
   Research I, 2015, SMARTPHONE MARKET SH
   Song CW, 2015, MULTIMED TOOLS APPL, V74, P9007, DOI 10.1007/s11042-013-1725-0
   Strauss K, 2014, ANY DOS LIFE PLANNER
   Strietelmeier J, 2015, GOOGLE KEEP NOTE LIS
   Wang Z. M., 2014, J NONLINEAR FUNCT AN, DOI DOI 10.1007/978-3-319-01796-9_
   Xu Z, 2020, IEEE T CLOUD COMPUT, V8, P387, DOI 10.1109/TCC.2016.2517638
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
NR 34
TC 16
Z9 17
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3313
EP 3341
DI 10.1007/s11042-016-3718-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200009
DA 2024-07-18
ER

PT J
AU Cobârzan, C
   Schoeffmann, K
   Bailer, W
   Hürst, W
   Blazek, A
   Lokoc, J
   Vrochidis, S
   Barthel, KU
   Rossetto, L
AF Cobarzan, Claudiu
   Schoeffmann, Klaus
   Bailer, Werner
   Hurst, Wolfgang
   Blazek, Adam
   Lokoc, Jakub
   Vrochidis, Stefanos
   Barthel, Kai Uwe
   Rossetto, Luca
TI Interactive video search tools: a detailed analysis of the video browser
   showdown 2015
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exploratory search; Video browsing; Video retrieval
ID RETRIEVAL; USER
AB Interactive video retrieval tools developed over the past few years are emerging as powerful alternatives to automatic retrieval approaches by giving the user more control as well as more responsibilities. Current research tries to identify the best combinations of image, audio and text features that combined with innovative UI design maximize the tools performance. We present the last installment of the Video Browser Showdown 2015 which was held in conjunction with the International Conference on MultiMedia Modeling 2015 (MMM 2015) and has the stated aim of pushing for a better integration of the user into the search process. The setup of the competition including the used dataset and the presented tasks as well as the participating tools will be introduced. The performance of those tools will be thoroughly presented and analyzed. Interesting highlights will be marked and some predictions regarding the research focus within the field for the near future will be made.
C1 [Cobarzan, Claudiu] Klagenfurt Univ, Next Generat Video Browsing Project, Univ Str 65-67, A-9020 Klagenfurt, Austria.
   [Schoeffmann, Klaus] Klagenfurt Univ, Distributed Multimedia Syst Res Grp, Inst Informat Technol ITEC, Univ Str 65-67, A-9020 Klagenfurt, Austria.
   [Bailer, Werner] Joanneum Res Forsch Gesell mbH, DIGITAL Inst Informat & Commun Technol, Steyrergasse 17, A-8010 Graz, Austria.
   [Hurst, Wolfgang] Univ Utrecht, Informat & Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
   [Blazek, Adam; Lokoc, Jakub] Charles Univ Prague, Fac Math & Phys, Dept Software Engn, SIRET Res Grp, Malostransk Nam 25, Prague 11800, Czech Republic.
   [Vrochidis, Stefanos] Inst Informat Technol, Ctr Res & Technol Hellas, 6th Klm Charilaou Thermi Rd, Thessaloniki 57001, Greece.
   [Barthel, Kai Uwe] Hsch Tech & Wirtschaft, Int Studiengang Medieninformat, Wilhelminenhofstr 75a, D-12459 Berlin, Germany.
   [Rossetto, Luca] Univ Basel, Dept Math & Comp Sci, Spiegelgasse 1, CH-4051 Basel, Switzerland.
C3 University of Klagenfurt; University of Klagenfurt; Utrecht University;
   Charles University Prague; Centre for Research & Technology Hellas;
   University of Basel
RP Cobârzan, C (corresponding author), Klagenfurt Univ, Next Generat Video Browsing Project, Univ Str 65-67, A-9020 Klagenfurt, Austria.; Schoeffmann, K (corresponding author), Klagenfurt Univ, Distributed Multimedia Syst Res Grp, Inst Informat Technol ITEC, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM claudiu@itec.uni-klu.ac.at; ks@itec.uni-klu.ac.at;
   werner.bailer@joanneum.at; huerst@uu.nl; blazekada@gmail.com;
   lokoc@ksi.mff.cuni.cz; stefanos@iti.gr; barthel@fhtw-berlin.de;
   luca.rossetto@unibas.ch
RI Cobarzan, Claudiu/AAO-5231-2021; Cobarzan, Claudiu/C-4822-2011;
   Rossetto, Luca/AAI-8684-2020; Lokoc, Jakub/P-1216-2017
OI Cobarzan, Claudiu/0000-0002-5132-3251; Rossetto,
   Luca/0000-0002-5389-9465; Lokoc, Jakub/0000-0002-3558-4144; Bailer,
   Werner/0000-0003-2442-4900; Vrochidis, Stefanos/0000-0002-2505-9178
FU University of Klagenfurt; Federal Ministry for Transport, Innovation and
   Technology (bmvit); Austrian Science Fund (FWF) [TRP 273-N15]; European
   Regional Development Fund; Carinthian Economic Promotion Fund (KWF);
   Lakeside Labs GmbH, Klagenfurt, Austria; European Union [610370];
   Charles University Grant Agency [1134316]
FX Open access funding provided by University of Klagenfurt.; This work was
   funded by the Federal Ministry for Transport, Innovation and Technology
   (bmvit) and Austrian Science Fund (FWF): TRP 273-N15 and the European
   Regional Development Fund and the Carinthian Economic Promotion Fund
   (KWF), supported by Lakeside Labs GmbH, Klagenfurt, Austria.; The
   research leading to these results has received funding from the European
   Union's Seventh Framework Programme (FP7/2007-2013) under grant
   agreement no. 610370, ICoSOLE ("Immersive Coverage of Spatially
   Outspread Live Events", http://www.icosole.eu).; This research has been
   supported by Charles University Grant Agency project 1134316.
CR Adams B, 2012, IEEE INT CONF MULTI, P127, DOI 10.1109/ICMEW.2012.29
   [Anonymous], MMM
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], 2013, ADV MULTIMEDIA MODEL
   [Anonymous], UNDERSTANDING VIDEO
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2010, P ACM C MULTIMEDIA S
   [Anonymous], P MEDIAEVAL WORKSH
   [Anonymous], P 6 ACM INT C IM VID
   [Anonymous], P MULT MOD C
   [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], ICMR 11
   Blazek Adam, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P243, DOI 10.1007/978-3-319-14442-9_22
   Blazek A, 2014, LECT NOTES COMPUT SC, V8821, P25, DOI 10.1007/978-3-319-11988-5_3
   Christel MG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1032
   Cob arzan, 2014, IEEE INT C MULTIMEDI, P1
   Cobarzan Claudiu, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P266, DOI 10.1007/978-3-319-14442-9_26
   Cobarzan Claudiu, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P109, DOI 10.1007/978-3-319-04114-8_10
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Del Fabro M, 2012, LECT NOTES COMPUT SC, V7131, P639
   Giangreco I, 2014, IEEE INT CONGR BIG, P406, DOI 10.1109/BigData.Congress.2014.66
   Hopfgartner F, 2007, INT WORK CONTENT MUL, P328, DOI 10.1109/CBMI.2007.385430
   Hu MC, 2015, IEEE T CYBERNETICS, V45, P742, DOI 10.1109/TCYB.2014.2335540
   Huber J., 2010, 18th ACM International Conference on Multimedia (MM'10), P341, DOI DOI 10.1145/1873951
   Hudelist Marco A., 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P272, DOI 10.1007/978-3-319-14442-9_27
   Hudelist MA, 2013, IEEE INT SYM MULTIM, P1, DOI 10.1109/ISM.2013.11
   Hürst W, 2008, IEEE MULTIMEDIA, V15, P76, DOI 10.1109/MMUL.2008.66
   Hurst Wolfgang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P261, DOI 10.1007/978-3-319-14442-9_25
   Hurst Wolfgang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P123, DOI 10.1007/978-3-319-14442-9_11
   Hürst W, 2011, LECT NOTES COMPUT SC, V6524, P230
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Lin Yan-Ching, 2012, P 20 ACM INT NARA JA, P1261, DOI [10.1145/2393347.2396432, DOI 10.1145/2393347.2396432]
   Lokoc Jakub, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P415, DOI 10.1007/978-3-319-04117-9_49
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Rossetto L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P18, DOI 10.1109/ISM.2014.38
   Rubner Y., 2001, Perceptual metrics for image database navigation
   Schoeffmann K., 2010, SPIE Reviews, V1, P018004, DOI DOI 10.1117/6.0000005
   Schoeffmann K., 2015, ACM Computing Surveys (CSUR), V48, P14, DOI DOI 10.1145/2808796
   Schoeffmann K, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1321, DOI 10.1145/2733373.2807417
   Schoeffmann K, 2014, INT J MULTIMED INF R, V3, P113, DOI 10.1007/s13735-013-0050-8
   Schoeffmann K, 2014, IEEE MULTIMEDIA, V21, P8, DOI 10.1109/MMUL.2014.56
   Schoeffmann K, 2009, INT WORK CONTENT MUL, P243, DOI 10.1109/CBMI.2009.40
   Thanh Duc Ngo, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P278, DOI 10.1007/978-3-319-14442-9_28
   Thanh Duc Ngo, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P419, DOI 10.1007/978-3-319-04117-9_50
   Worring M, 2012, IEEE MULTIMEDIA, V19, P6, DOI 10.1109/MMUL.2012.53
   Zhenxing Zhang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P282, DOI 10.1007/978-3-319-14442-9_29
NR 48
TC 46
Z9 47
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5539
EP 5571
DI 10.1007/s11042-016-3661-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500039
PM 32226277
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU De Marsico, M
   Mecca, A
AF De Marsico, Maria
   Mecca, Alessio
TI Biometric walk recognizer Gait recognition by a single smartphone
   accelerometer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Gait recognition; Accelerometer; Mobile devices
AB This paper presents an approach to gait recognition based on a single consumer accelerometer, built in most present mobile devices. It does not propose a completely novel algorithm, but rather investigates better ways to exploit the Dynamic Time Warping (DTW), which is still one of the most used at present in literature. To this aim, the paper presents both a new segmentation algorithm to split the gait signal into cycles/steps, and investigates the best way to use the possibly segmented signal for recognition. Summarizing, the first contribution of the present work is the proposal of a new segmentation algorithm for the gait signal, which does not require any pre-processing, either interpolation or noise reduction, to enhance the original signal, and its comparison with two other state-of-the-art step segmentation algorithms. The second contribution is related to the extensive tests performed with the five different investigated matching methods. The tests are carried out exploiting all compared segmentation algorithms and three different datasets, collected using different sensors: the originally exploited BWR dataset, that includes walk templates from 30 volunteers, and two huge datasets used for this kind of testing, namely the ZJU-gaitacc and the OU-ISIR Inertial Sensor Database. Tests have been performed in both verification mode, either single-template or multiple-template, and identification mode, both closed and open set. The latter is rarely found in literature though representing the most frequently predictable applicative setting. It is worth underlining that the final goal is to allow using low-cost, built-in sensors that nowadays equip most smartphones. The best result in closed set identification, which is the identification mode usually reported in literature, is achieved using the most constrained method, i.e., limiting the walks in the gallery and in the probe to have a similar number of steps. It reaches approximate to 93 % of Recognition Rate (RR) on ZJU-gaitacc dataset. The best result obtained with methods exploiting segmentation to overcome the mentioned limitation reaches approximate to 83 % of Recognition Rate (RR) on the same dataset, using our proposed algorithm. The best results in verification is achieved using multiple templates per user, again without segmentation, with an Equal Error Rate (EER) of 0.09, while the best results with segmentation is achieved again with our algorithm and is and EER of 0.10. This is a very good result for a soft biometrics as gait if often considered. As expected, open set identification achieves lower performance.
C1 [De Marsico, Maria; Mecca, Alessio] Sapienza Univ Rome, Dept Comp Sci, Rome, Italy.
C3 Sapienza University Rome
RP Mecca, A (corresponding author), Sapienza Univ Rome, Dept Comp Sci, Rome, Italy.
EM demarsico@di.uniroma1.it; mecca@di.uniroma1.it
RI De Marsico, Maria/K-6684-2015; MECCA, Alessio/GPW-6569-2022
OI De Marsico, Maria/0000-0002-1391-8502; MECCA,
   Alessio/0000-0002-1370-8759
CR De Marsico M, 2015, LECT NOTES COMPUT SC, V9281, P19, DOI 10.1007/978-3-319-23222-5_3
   Derawi Mohammad O., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P312, DOI 10.1109/IIHMSP.2010.84
   Gafurov Davrondzhon, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P836, DOI 10.1109/WAINA.2010.145
   Gafurov D., 2007, ANN NORW COMP SCI CO, P19
   Gafurov D, 2006, J COMPUT, V1, P51, DOI 10.4304/jcp.1.7.51-59
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Juefei-Xu F., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P8, DOI 10.1109/BTAS.2012.6374552
   Lee TKM, 2014, MULTIMED TOOLS APPL, V72, P2833, DOI 10.1007/s11042-013-1574-x
   Liu Rong, 2007, 2007 1st International Conference on Bioinformatics and Biomedical Engineering, P543
   Muller M., 2007, Information retrieval for music and motion, P69, DOI [10.1007/978-3-540-74048-3_4, DOI 10.1007/978-3-540-74048-3_4]
   Nickel C., 2011, 2011 Proceedings of IEEE 7th International Colloquium on Signal Processing & its Applications (CSPA 2011), P58, DOI 10.1109/CSPA.2011.5759842
   Pan G, 2009, ELECTRON LETT, V45, P1117, DOI 10.1049/el.2009.2301
   Rong L, 2007, C IND ELECT APPL, P2654
   Sprager S, 2015, SENSORS-BASEL, V15, P22089, DOI 10.3390/s150922089
   Ngo TT, 2014, PATTERN RECOGN, V47, P228, DOI 10.1016/j.patcog.2013.06.028
   Trung NgoThanh., 2011, BIOMETRICS IJCB 2011, P1
   Ngo TT, 2014, IEICE T INF SYST, VE97D, P541, DOI 10.1587/transinf.E97.D.541
   Zhang YT, 2015, IEEE T CYBERNETICS, V45, P1864, DOI 10.1109/TCYB.2014.2361287
   Zhong Y., 2014, 7 IET INT C POWER EL, P1
NR 19
TC 10
Z9 10
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4713
EP 4745
DI 10.1007/s11042-016-3654-1
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jeyhoon, M
   Asgari, M
   Ehsan, L
   Jalilzadeh, SZ
AF Jeyhoon, Mahdi
   Asgari, Mohammad
   Ehsan, Lili
   Jalilzadeh, Seyedeh Zahra
TI Blind audio watermarking algorithm based on DCT, linear regression and
   standard deviation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; DCT coefficients; Blind; Linear regression; Standard
   deviation
ID SPREAD-SPECTRUM; MULTIMEDIA
AB This paper proposes a blind audio watermarking algorithm to embed data and extract them by changing the Discrete Cosine Transform (DCT) coefficients. The key idea is to divide the selected frequency band of DCT into short frames and change the samples of each frame based on the watermark bits that are embedded in. The proposed idea uses linear regression and standard deviation to extract watermark bits. The experimental results show that the method has a high capacity about 3000 bps data payload, without significant perceptual distortion. Moreover, this idea provides robustness against common signal processing attacks such as Additive White Gaussian Noise, Resampling, Re-quantizing and Echo.
C1 [Jeyhoon, Mahdi; Asgari, Mohammad; Ehsan, Lili] Islamic Republ Iran Broadcasting Univ, Broadcast Engn Fac, Tehran, Iran.
   [Jalilzadeh, Seyedeh Zahra] Islamic Republ Iran Broadcasting, Tehran, Iran.
RP Jeyhoon, M (corresponding author), Islamic Republ Iran Broadcasting Univ, Broadcast Engn Fac, Tehran, Iran.
EM jeihoun_mahdi@yahoo.com; m.asgari@iribu.ac.ir; l-ehsan@iribu.ac.ir;
   jalilzadeh@irib.ir
CR Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   [Anonymous], 2009, Cambridge University Press, DOI DOI 10.1017/CBO9780511815867
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cvejic N, 2004, SIGNAL PROCESS, V84, P207, DOI 10.1016/j.sigpro.2003.10.016
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Fallahpour M, 2009, IEICE ELECTRON EXPR, V6, P1057, DOI 10.1587/elex.6.1057
   Jain P, 2012, INT J COMPUTATIONAL, V15, P2230
   Johnson N. F., 2001, J ELECTRON IMAGING, V10, P825, DOI DOI 10.1117/1.1388610
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Ko BS, 2005, IEEE T MULTIMEDIA, V7, P212, DOI 10.1109/TMM.2005.843366
   Malik H, 2008, IET INFORM SECUR, V2, P129, DOI 10.1049/iet-ifs:20070145
   Neubauer C, 2000, AUDIO ENG SOC CONVEN, P108
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Trivedi NK, 2014, INT CONF COMM SYST, P805, DOI 10.1109/CSNT.2014.167
   Zhang Z, 2012, INT J DIGIT CONTENT, V6
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
NR 21
TC 13
Z9 13
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3343
EP 3359
DI 10.1007/s11042-016-3934-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200010
DA 2024-07-18
ER

PT J
AU Lee, RC
   Park, KR
   Kim, JM
   Jeong, HY
AF Lee, Rae-Chun
   Park, Koo-Rack
   Kim, Jin-Mook
   Jeong, Hwa-Young
TI A study on the impact of the software developer's social exclusion on
   the quality information system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social exclusion; Information systems quality; Software development;
   Developers
ID MENTAL-HEALTH; EMPLOYMENT; UNEMPLOYMENT
AB Competition in the modern IT market has become fiercer thus making the forms of employment in IT companies more diversified. Accordingly, the number of full time jobs and related companies also greatly reduced. Thus to relative increase of non-regular workers, job insecurity and poor working conditions likely result to experience social exclusion. Consecutively, suffering from social exclusion of non-regular workers likely result to increase in experiencing economic difficulties. These problems pose require high degree of concentration in the information systems development because of resulting factors such as weakening of information system developers' focus, thus this is taken as an active issue of interest. However, any discussion on the status of IT workers in Korea that is related to social exclusion and its impact on the quality of information systems is rare. As a result, this study aims to empirically examine the relationship between the quality of information systems and its IT professionals' social exclusion. According to the survey conducted, IT professionals' social exclusion factors showed a significant effect on the quality of information system.
C1 [Lee, Rae-Chun; Park, Koo-Rack] Kongju Natl Univ, Div Comp Sci & Engn, Cheonan Daero 1223-24, Cheonan Si 330717, Chungnam, South Korea.
   [Kim, Jin-Mook] Sunmoon Univ, Div Informat Technol Educ, 70 Sunmoon Ro 221beon Gil, Asan 336708, Chungnam, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 24 Kyungheedae Ro, Seoul, South Korea.
C3 Kongju National University; Sun Moon University; Kyung Hee University
RP Kim, JM (corresponding author), Sunmoon Univ, Div Informat Technol Educ, 70 Sunmoon Ro 221beon Gil, Asan 336708, Chungnam, South Korea.
EM raechun@nate.com; ecgrpark@kongju.ac.kr; calf0425@sunmoon.ac.kr;
   hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], LABOUR REV
   Artazcoz L, 2004, AM J PUBLIC HEALTH, V94, P82, DOI 10.2105/AJPH.94.1.82
   Benach J, 2000, AM J PUBLIC HEALTH, V90, P1316, DOI 10.2105/AJPH.90.8.1316
   Bilsker D, 2006, CAN J PSYCHIAT, V51, P61, DOI 10.1177/070674370605100201
   Cho HY, 1996, J INF MANAG, V13, P143
   CLEMONS EK, 1991, COMMUN ACM, V34, P22, DOI 10.1145/99977.99985
   DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60
   General Services Administration, 1997, PERF BAS MAN 8 STEPS
   Hamilton JS, 1980, SURVEY DATA PROCESSI
   Leino-Arjas P, 1999, BRIT MED J, V319, P600, DOI 10.1136/bmj.319.7210.600
   Nätti J, 2009, EUR J PUBLIC HEALTH, V19, P150, DOI 10.1093/eurpub/ckp002
   Noh-buyngil, 2011, KOREAN J SOC WELF, V63, P113
   Percy-Smith Janie., 2000, Policy Responses to Social Exclusion: Towards Inclusion?, P1
   Rodriguez E, 2002, SOC SCI MED, V55, P963, DOI 10.1016/S0277-9536(01)00234-9
   Smithson S, 1998, EUR J INFORM SYST, V7, P158, DOI 10.1057/palgrave.ejis.3000304
   Social Exclusion Unit, 2004, DRIV SOC EXCL REV LI
   Virtanen M, 2005, INT J EPIDEMIOL, V34, P610, DOI 10.1093/ije/dyi024
NR 17
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6003
EP 6014
DI 10.1007/s11042-015-2842-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500061
DA 2024-07-18
ER

PT J
AU Niu, DM
   Rui, LL
   Huang, HQ
   Qiu, XS
AF Niu, Danmei
   Rui, Lanlan
   Huang, Haoqiu
   Qiu, Xuesong
TI A service recovery method based on trust evaluation in mobile social
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia content; Service recovery; Trust evaluation; Mobile social
   network
ID MULTIMEDIA SERVICE; MIDDLEWARE; ALGORITHM
AB Mobile social network makes users create and share multimedia contents freely and conveniently. However, some nodes in mobile social network have malicious behavior, such as discarding or tampering packet. These factors will cause service interruptions in the process of providing multimedia contents for the user. When the service interruption happens, how to choose the more reliable backup device, reduce interruption number, increase the packet transmission efficiency and improve user's experience of sharing multimedia contents is the object of this paper. We propose a service recovery method based on trust evaluation which adopts Dempster-Shafer (D-S) evidence theory. The service requester calculates the direct trust degree and the recommended trust degree of the backup devices, then uses the evidence combination rule to calculate the comprehensive trust degree. The backup device with the highest trust value will be seclected to recover the service. The simulation results show that this method effectively improves the packet delivery ratio, reduces the service execution time and provides users with more stable multimedia contents.
C1 [Niu, Danmei; Rui, Lanlan; Huang, Haoqiu; Qiu, Xuesong] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Niu, Danmei] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Henan University of
   Science & Technology
RP Niu, DM (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Niu, DM (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
EM niudanmei@163.com; llrui@bupt.edu.cn; francesco@bupt.edu.cn;
   xsqiu@bupt.edu.cn
FU National Natural Science Foundation of China [61302078, 61372108,
   61370220]; Program for Innovative Research Team (in Science and
   Technology) in University of Henan Province Grant [15IRTSTHN010]
FX The work is supported by National Natural Science Foundation of China
   (61302078, 61372108, 61370220), Program for Innovative Research Team (in
   Science and Technology) in University of Henan Province Grant
   (15IRTSTHN010).
CR Aivaloglou E, 2010, WIREL NETW, V16, P1493, DOI 10.1007/s11276-009-0216-8
   Amgoth Tarachand, 2014, International Journal of Information and Communication Technology, V6, P272, DOI 10.1504/IJICT.2014.063216
   [Anonymous], PARALLEL DISTRIBUTED
   Batra PK, 2016, WIREL NETW, V22, P49, DOI 10.1007/s11276-015-0951-y
   Bellavista P, 2013, PERVASIVE MOB COMPUT, V9, P437, DOI 10.1016/j.pmcj.2013.03.001
   Boix E.G., 2011, P 2011 ACM S APPL CO, P425, DOI [10.1145/1982185.1982277, DOI 10.1145/1982185.1982277]
   Chen Q, 2008, IEEE INT WORK MED ME, P1
   Chen W, 2008, IEEE ICC, P5576, DOI 10.1109/ICC.2008.1045
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Dooms S, 2014, MULTIMED TOOLS APPL, V72, P281, DOI 10.1007/s11042-012-1347-y
   Fenye Bao, 2012, IEEE Transactions on Network and Service Management, V9, P169, DOI 10.1109/TCOMM.2012.031912.110179
   Johnson D.B., 1996, Mobile Computing, DOI DOI 10.1007/978-0-585-29603-65
   Kalavathy GM, 2012, MULTIMED TOOLS APPL, V57, P633, DOI 10.1007/s11042-010-0664-2
   Li L, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING, P482, DOI 10.1109/SCC.2009.70
   Li X, 2014, INT J INFORM MANAGE, V34, P319, DOI 10.1016/j.ijinfomgt.2013.11.007
   Lili Sun, 2011, Proceedings of the 2011 International Conference on Cloud and Service Computing (CSC 2011), P60, DOI 10.1109/CSC.2011.6138553
   Paul A, 2014, MULTIMED TOOLS APPL, V71, P235, DOI 10.1007/s11042-013-1490-0
   Rong Hu, 2011, 2011 Proceedings of 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid 2011), P566, DOI 10.1109/CCGrid.2011.31
   Ruocco M, 2014, MULTIMED TOOLS APPL, V70, P55, DOI 10.1007/s11042-012-1087-z
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   Wang Yong, 2009, Chinese Journal of Computers, V92, P1668, DOI 10.3724/SP.J.1016.2009.01668
   Xia H, 2013, AD HOC NETW, V11, P2096, DOI 10.1016/j.adhoc.2012.02.009
   Yang Kai, 2011, Journal on Communications, V32, P89
   Yang K, 2010, MOBILE NETW APPL, V15, P488, DOI 10.1007/s11036-009-0189-y
   Yang ZM, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.56
   Zeng LZ, 2004, IEEE T SOFTWARE ENG, V30, P311, DOI 10.1109/TSE.2004.11
   Zhang K, 2014, IEEE COMMUN MAG, V52, P58, DOI 10.1109/MCOM.2014.6766086
   Zhang Z. Y., 2012, INT J DIGIT CONTENT, V6, P245, DOI DOI 10.4156/JDCTA.V0L6.ISSUE9.31
   Zhang ZY, 2013, SOC NETW ANAL MIN, V3, P969, DOI 10.1007/s13278-012-0078-4
NR 29
TC 9
Z9 10
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3255
EP 3277
DI 10.1007/s11042-016-3963-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200006
DA 2024-07-18
ER

PT J
AU Priyanka
   Maheshkar, S
AF Priyanka
   Maheshkar, Sushila
TI Region-based hybrid medical image watermarking for secure telemedicine
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telemdicine; Medical image; Image watermarking; Data hiding; Integer
   wavelet transform (IWT); Singular value decomposition (SVD); Electronic
   patient record (EPR)
ID MULTIPLE WATERMARKING; ROBUST; SCHEME; SYSTEM
AB In this paper we propose a novel region based hybrid medical image watermarking (MIW) scheme to ensure authenticity, integrity and confidentiality of medical images. In this scheme a digital medical image is partitioned into region of interest (ROI) and the region of non interest (RONI). To detect and localize ROI tampering with high accuracy pixel wise positional and relational bits are calculated. Positional bit is calculated with respect to MSBs, row and column of the pixel. Relational bit shows the relation between MSBs. Two original LSBs of each ROI pixel are replace by their corresponding positional and relational bits. Original LSBs of ROI pixels are concatenated and embedded in RONI for ROI recovery in the case of tampering. Multiple watermarks i. e. electronic patient record (EPR), hospitals logo and LSBs of ROI are embedded simultaneously as a robust watermark in RONI using IWT-SVD hybrid transform. The proposed scheme is blind and free from false positive detection. Various experiments have been carried out on different medical imaging modalities to evaluate the performance of the proposed scheme in terms of imperceptibility, robustness, tamper detection, localization, recovery and computation time. ROI tampering is detected and recovered with high accuracy. Thus, the proposed scheme is effective in telemedicine applications.
C1 [Priyanka; Maheshkar, Sushila] Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Maheshkar, S (corresponding author), Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
EM priyankasingh401@gmail.com; sushila_maheshkar@yahoo.com
RI Maheshkar, Sushila/KPY-5418-2024; Maheshkar, Sushila/V-7269-2019
OI Maheshkar, Sushila/0000-0003-3879-2800; 
CR Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   [Anonymous], J DIGITAL IMAGING
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], COMP STUDY MED IMAGI
   [Anonymous], 2012, INT J COMPUT COMMUN, DOI 10.5281/zenodo.1331913
   [Anonymous], MULTIMEDIA TOOLS APP
   Ansari IA, 2015, INT J MACH LEARN CYB, P1
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Bouslimi D, 2016, SIGNAL PROCESS-IMAGE, V47, P160, DOI 10.1016/j.image.2016.05.021
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CC, 2007, LECT NOTES COMPUT SC, V4614, P82
   Cox I. J., 2002, Digital Watermarking
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Davie B, 2001, IEEE INTERNET COMPUT, V5, P42, DOI 10.1109/4236.935176
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Hajjaji M.A., 2011, International Journal of Computer Science Issues
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Kumar B, 2011, WORLD ACAD SCI ENG T, V79, P2011
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Naseem MT., 2013, J BASIC APPL SCI RES, V3, P488
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Parah SA, 2015, MULTIMED TOOLS APPL, P1
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh AK, 2016, MULTIMED TOOLS APPL, P1
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Thabit R, 2015, MULTIMED TOOLS APPL, P1
   Wakatani A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2043, DOI 10.1109/HICSS.2002.994129
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
NR 42
TC 47
Z9 49
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3617
EP 3647
DI 10.1007/s11042-016-3913-1
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200022
DA 2024-07-18
ER

PT J
AU Thakkar, FN
   Srivastava, VK
AF Thakkar, Falgun N.
   Srivastava, Vinay Kumar
TI A blind medical image watermarking: DWT-SVD based robust and secure
   approach for telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking; Image and text watermarking; Medical image security;
   Electronic patient record (EPR); Error correcting code
ID MULTIPLE WATERMARKING; PROTECTION; SCHEME
AB In this paper, a blind image watermarking scheme based on discrete wavelet transform (DWT) and singular value decomposition (SVD) is proposed. In this scheme, DWT is applied on ROI (region of interest) of the medical image to get different frequency subbands of its wavelet decomposition. On the low frequency subband LL of the ROI, blockSVD is applied to get different singular matrices. A pair of elements with similar values is identified from the left singular value matrix of these selected blocks. The values of these pairs are modified using certain threshold to embed a bit of watermark content. Appropriate threshold is chosen to achieve the imperceptibility and robustness of medical image and watermark contents respectively. For authentication and identification of original medical image, one watermark image (logo) and other text watermark have been used. The watermark image provides authentication whereas the text data represents electronic patient record (EPR) for identification. At receiving end, blind recovery of both watermark contents is performed by a similar comparison scheme used during the embedding process. The proposed algorithm is applied on various groups of medical images like X-ray, CT scan and mammography. This scheme offers better visibility of watermarked image and recovery of watermark content due to DWT-SVD combination. Moreover, use of Hamming error correcting code (ECC) on EPR text bits reduces the BER and thus provides better recovery of EPR. The performance of proposed algorithm with EPR data coding by Hamming code is compared with the BCH error correcting code and it is found that later one perform better. A result analysis shows that imperceptibility of watermarked image is better as PSNR is above 43 dB and WPSNR is above 52 dB for all set of images. In addition, robustness of the scheme is better than existing scheme for similar set of medical images in terms of normalized correlation coefficient (NCC) and bit-error-rate (BER). An analysis is also carried out to verify the performance of the proposed scheme for different size of watermark contents (image and EPR data). It is observed from analysis that the proposed scheme is also appropriate for watermarking of color image. Using proposed scheme, watermark contents are extracted successfully under various noise attacks like JPEG compression, filtering, Gaussian noise, Salt and pepper noise, cropping, filtering and rotation. Performance comparison of proposed scheme with existing schemes shows proposed scheme has better robustness against different types of attacks. Moreover, the proposed scheme is also robust under set of benchmark attacks known as checkmark attacks.
C1 [Thakkar, Falgun N.; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Allahabad 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Thakkar, FN (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Allahabad 211004, Uttar Pradesh, India.
EM falgungcet@gmail.com; vinay@mannit.ac.in
RI Srivastava, Vinay Kumar/AAL-2501-2021; Thakkar, Falgun/AAR-1995-2020
OI Srivastava, Vinay Kumar/0000-0002-7993-0993; 
CR [Anonymous], INT J COMPUT APPL
   [Anonymous], ENGINEERING
   Bansal R, 2012, INF SECUR J, V21, P88, DOI 10.1080/19393555.2011.642066
   Inamdar VS, 2014, SADHANA-ACAD P ENG S, V39, P3, DOI 10.1007/s12046-013-0208-3
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kumar B., 2011, J INF SECUR, V2, P91, DOI DOI 10.4236/JIS.2011.22009
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Liu GY, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/406349
   Memon NA, 2011, INT J COMPUT MATH, V88, P2057, DOI 10.1080/00207160.2010.543677
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Paunwala M, 2014, MACH VISION APPL, V25, P263, DOI 10.1007/s00138-013-0533-x
   PEREIRA S, 2001, LECT NOTES COMPUTER, V2137, P340
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 30
TC 119
Z9 121
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3669
EP 3697
DI 10.1007/s11042-016-3928-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200024
DA 2024-07-18
ER

PT J
AU Wojciechowski, A
   Al-Musawi, R
AF Wojciechowski, Adam
   Al-Musawi, Raed
TI Assisstive technology application for enhancing social and language
   skills of young children with autism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Assisstive technology; Autism; Mobile system; Multimedia; Experimental
   validation
ID SPECTRUM; VOCABULARY
AB In this paper we present an assistive system designed for supporting young children affected by autism in their process of learning pronunciation and meaning of new words. The system is built-up of a mobile application and objects identifiers which in our case were Estimote Beacon sensors. The system requires active participation of a parent who selects words to learn, records pronunciation of object names, selects illustrations, and activates and turns off the application. The entire process is designed to extend parents' care and to support autistic children with an instant repetition of pronounced object's names when those items are met during playing or moving around the house. An experimental part of our project consists of a report where we compare collected results of two autistic children using our application installed on a smart watch and on a smart phone. In both reported cases autistic children made a visible progress in speed of learning new words when compared to an equivalent period of time without assistive application support.
C1 [Wojciechowski, Adam; Al-Musawi, Raed] Poznan Univ Tech, Inst Comp Sci, Piotrowo 2, PL-60965 Poznan, Poland.
C3 Poznan University of Technology
RP Wojciechowski, A (corresponding author), Poznan Univ Tech, Inst Comp Sci, Piotrowo 2, PL-60965 Poznan, Poland.
EM Adam.Wojciechowski@put.poznan.pl; almusawiraed@gmail.com
RI de Jager, Aimee/AAL-1264-2021; Wojciechowski, Adam/M-2531-2014
CR [Anonymous], ARE SMART PHONES SPR
   Bailey J.S., 2002, Research methods in applied behavior analysis
   Billstedt E, 2005, J AUTISM DEV DISORD, V35, P351, DOI 10.1007/s10803-005-3302-5
   Bosseler A, 2003, J AUTISM DEV DISORD, V33, P653, DOI 10.1023/B:JADD.0000006002.82367.4f
   Coleman-Martin M.B., 2005, FOCUS AUTISM OTHER D, V20, P80, DOI DOI 10.1177/10883576050200020401
   Dolui K, 2013, 2013 INTERNATIONAL COMPUTER SCIENCE AND ENGINEERING CONFERENCE (ICSEC), P91, DOI 10.1109/ICSEC.2013.6694759
   Eaves LC, 2008, J AUTISM DEV DISORD, V38, P739, DOI 10.1007/s10803-007-0441-x
   Farr W, 2010, AUTISM, V14, P237, DOI 10.1177/1362361310363280
   Fuster GG, 2015, BIG DATA SMART DEVIC
   Grandin T., 1996, My experiences with visual thinking sensory problems and communication difficulties
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Handleman J.S., 2000, PRESCHOOL ED PROGRAM, V2nd
   Hayes GR, 2010, PERS UBIQUIT COMPUT, V14, P663, DOI 10.1007/s00779-010-0294-8
   Hourcade JP, 2012, PERS UBIQUIT COMPUT, V16, P157, DOI 10.1007/s00779-011-0383-3
   Howlin P, 2004, J CHILD PSYCHOL PSYC, V45, P212, DOI 10.1111/j.1469-7610.2004.00215.x
   Johnson CP, 2007, PEDIATRICS, V120, P1183, DOI 10.1542/peds.2007-2361
   Kabadayi A, 2014, CROAT J EDUC, V16, P43
   Kanner L, 1943, NERV CHILD, V2, P217
   Madsen M., 2008, Int. ACM SIGACCESS Conf. Comput. and Accessibility, P19
   Mills R. D., 2012, THESIS
   Moore M, 2000, J AUTISM DEV DISORD, V30, P359, DOI 10.1023/A:1005535602064
   Myers SM, 2007, PEDIATRICS, V120, P1162, DOI 10.1542/peds.2007-2362
   Niwa T, 2014, 2014 IIAI 3RD INTERNATIONAL CONFERENCE ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2014), P913, DOI 10.1109/IIAI-AAI.2014.180
   Piper Anne Marie, 2006, 20 ANN C COMP SUPP C, P1, DOI DOI 10.1145/1180875.1180877
   Reichle J, 2011, J BEHAV EDUC, V20, P77, DOI 10.1007/s10864-011-9121-1
   Whalen C., 2006, Journal of Speech and Language Pathology and Applied Behavior Analysis, V1, P11
   Zakari HM, 2014, LECT NOTES COMPUT SC, V8778, P93, DOI 10.1007/978-3-319-11623-5_9
NR 27
TC 19
Z9 22
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5419
EP 5439
DI 10.1007/s11042-016-3995-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500033
DA 2024-07-18
ER

PT J
AU Xu, GQ
   Zhang, GX
   Xu, C
   Liu, B
   Li, MQ
   Ren, Y
   Li, XH
   Feng, ZY
   Zhang, DG
AF Xu, Guangquan
   Zhang, Gaoxu
   Xu, Chao
   Liu, Bin
   Li, Mingquan
   Ren, Yan
   Li, Xiaohong
   Feng, Zhiyong
   Zhang, Degan
TI A multi-attribute rating based trust model: improving the personalized
   trust modeling framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-attribute rating; Trustmodel; Multimedia recommendation service;
   Malicious attack
ID REPUTATION; MANAGEMENT; SYSTEM
AB Recently, trust models have contributed much to the success of online multimedia recommendation service. However, most of them only consider the case of binary ratings and ignore the attributes of ratings, which will limit their universal applicability. To address this problem, we propose a multi-attribute rating based trust model to improve the Zhang's Personalized trust modeling framework, an existing framework for trust modeling by using binary ratings in multi-agent electronic marketplaces. In our approach, it does not restrict users to using a single attribute rating; it allows a rating to be a certain value between 0 and 1 rather than only 0 or 1; it can improve assessment accuracy by calculating the similarity of common ratings between recommenders and users; and it considers the certainty of ratings to deal with the sudden change of partner's behaviours. Finally, experimental results show that, our approach can effectively model the trustworthiness of recommenders and providers, and it can also resist several malicious attacks.
C1 [Xu, Guangquan; Zhang, Gaoxu; Liu, Bin; Ren, Yan; Li, Xiaohong; Feng, Zhiyong] Tianjin Univ, Sch Comp Software, Inst Software & Informat Secur Engn, Tianjin, Peoples R China.
   [Xu, Chao] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
   [Li, Mingquan] SpaceStar Technol Co Ltd, Xian, Peoples R China.
   [Zhang, Degan] Tianjin Univ Technol, Key Lab Comp Vision & Syst, Minist Educ, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University; Tianjin University of Technology
RP Xu, GQ (corresponding author), Tianjin Univ, Sch Comp Software, Inst Software & Informat Secur Engn, Tianjin, Peoples R China.
EM losin@tju.edu.cn
RI li, xiao/GSN-6181-2022; liang, liang/IAO-8518-2023; Gulliver,
   Aaron/K-7925-2012; li, xiaofeng/GXF-9442-2022; Ren, Yanxiong/S-6389-2017
CR [Anonymous], 2003, P 12 INT C WORLD WID
   [Anonymous], 2004, P 7 INT WORKSH TRUST
   [Anonymous], 2002, P 15 BLED EL COMM C
   Dellarocas C., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P150, DOI 10.1145/352871.352889
   Guo G., 2013, P 23 INT JOINT C ART, P2619, DOI DOI 10.5555/2540128.2540506
   Hang CW, 2012, IEEE COMPUT, V46, P78
   Huynh TD, 2006, AUTON AGENT MULTI-AG, V13, P119, DOI 10.1007/s10458-005-6825-4
   Josang A, 2007, DECIS SUPPORT SYST, V43, P618, DOI 10.1016/j.dss.2005.05.019
   Liang Z, 2005, P 38 HAW INT C SYST, p201b
   Liu SY, 2014, COMPUT INTELL-US, V30, P316, DOI 10.1111/j.1467-8640.2012.00464.x
   Sabater J, 2005, ARTIF INTELL REV, V24, P33, DOI 10.1007/s10462-004-0041-5
   Schmidt S, 2007, APPL SOFT COMPUT, V7, P492, DOI 10.1016/j.asoc.2006.11.002
   Song SS, 2005, IEEE INTERNET COMPUT, V9, P24, DOI 10.1109/MIC.2005.136
   Teacy W.T. L., 2005, AAMAS 05 P 4 INT JOI, P997
   Thirunarayan K, 2014, FUTURE GENER COMP SY, V31, P182, DOI 10.1016/j.future.2013.05.006
   Tian CQ, 2011, FUTURE GENER COMP SY, V27, P1135, DOI 10.1016/j.future.2011.03.006
   Wang YH, 2010, ACM T AUTON ADAP SYS, V5, DOI 10.1145/1867713.1867715
   Wang YH, 2011, J ARTIF INTELL RES, V40, P221, DOI 10.1613/jair.3108
   Wang YH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1551
   Xu GQ, 2007, INT J ELECTRON COMM, V12, P93, DOI 10.2753/JEC1086-4415120104
   Zhang J., 2007, AAAI, P1495
   Zhang J., 2006, P AAMAS WORKSH TRUST
   Zhang J, 2008, ELECTRON COMMER R A, V7, P330, DOI 10.1016/j.elerap.2008.03.001
   Zhang J, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2438653.2438659
   Zhang J, 2008, ANN CONF PRIV SECUR, P189, DOI 10.1109/PST.2008.16
   Zhou RF, 2007, IEEE T PARALL DISTR, V18, P460, DOI 10.1109/TPDS.2007.1015
NR 26
TC 1
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5833
EP 5849
DI 10.1007/s11042-015-2539-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500051
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Singh, SK
   Chakraborty, P
AF Chakraborty, Soumendu
   Singh, Satish Kumar
   Chakraborty, Pavan
TI Local directional gradient pattern: a local descriptor for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local pattern descriptors; Local derivative pattern; Local vector
   pattern; Local directional gradient pattern; Face recognition
ID INVARIANT TEXTURE CLASSIFICATION; FEATURE DISTRIBUTIONS; BINARY
   PATTERNS; ILLUMINATION; EIGENFACES; POSE
AB In this paper a local pattern descriptor in high order derivative space is proposed for face recognition. The proposed local directional gradient pattern (LDGP) is a 1D local micropattern computed by encoding the relationships between higher order derivatives of the reference pixel in four distinct directions. The proposed descriptor identifies relationship between the high order derivatives of the referenced pixel in four different directions to compute the micropattern which corresponds to the local feature. Proposed descriptor considerably reduces the length of the micropattern which consequently reduces the extraction time and matching time while maintaining the recognition rate. Results of the extensive experiments conducted on benchmark databases AT&T, Extended Yale B and CMU-PIE show that the proposed descriptor significantly reduces the extraction as well as matching time while the recognition rate of the descriptor is almost similar to existing state of the art methods. Moreover the proposed descriptor is more resistant against the AWGN compared to the other state of the art descriptors used for face recognition problems.
C1 [Chakraborty, Soumendu; Singh, Satish Kumar; Chakraborty, Pavan] Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Chakraborty, S (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
EM soum.uit@gmail.com; sk.singh@iiita.ac.in; Pavan@iiita.ac.in
RI Chakraborty, Soumendu/ABA-2031-2020; Singh, Dr Satish
   Kumar/JMP-6186-2023; singh, satish/U-7158-2018; Chakraborty,
   Pavan/Y-5495-2019
OI Chakraborty, Soumendu/0000-0002-8778-8229; Singh, Dr Satish
   Kumar/0000-0003-1991-7727; singh, satish/0000-0002-8536-4991;
   Chakraborty, Pavan/0000-0002-9260-1131
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2 IEEE WORKSH APPL C
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Choi JY, 2011, IEEE T IMAGE PROCESS, V20, P1425, DOI 10.1109/TIP.2010.2093906
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P826, DOI 10.1109/TIFS.2014.2309851
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Kim HI, 2016, MULTIMED TOOLS APPL, V75, P6887, DOI 10.1007/s11042-015-2616-3
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Shen FM, 2016, MULTIMED TOOLS APPL, V75, P12535, DOI 10.1007/s11042-014-2340-4
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 22
TC 60
Z9 61
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1201
EP 1216
DI 10.1007/s11042-015-3111-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000053
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ioannidou, A
   Apostolidis, E
   Collyda, C
   Mezaris, V
AF Ioannidou, Anastasia
   Apostolidis, Evlampios
   Collyda, Chrysa
   Mezaris, Vasileios
TI A web-based tool for fast instance-level labeling of videos and the
   creation of spatiotemporal media fragments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Instance-level video labeling; Object re-detection; BRISK descriptor;
   Locality Sensitive Hashing
ID NEAREST-NEIGHBOR; ALGORITHMS; FEATURES; SIFT
AB This paper presents a web-based interactive tool for time-efficient instance-level spatiotemporal labeling of videos, based on the re-detection of manually selected objects of interest that appear in them. The developed tool allows the user to select a number of instances of the object that will be used for annotating the video via detecting and spatially demarcating it in the video frames, and provide a short description about the selected object. These instances are given as input to the object re-detection module of the tool, which detects and spatially demarcates re-occurrences of the object in the video frames. The video segments that contain detected instances of the given object can be then considered as object-related media fragments, being annotated with the user-provided information about the object. A key component for building such a tool is the development of an algorithm that performs the re-detection of the object throughout the video frames. For this, the first part of this work presents our study on different approaches for object re-detection and the finally developed one, which combines the recently proposed BRISK descriptors with a descriptor matching strategy that relies on the LSH algorithm. Following, the second part of this work is dedicated to the description of the implemented tool, introducing the supported functionalities and demonstrating its use for object-specific labeling of videos. A set of experiments and a user study regarding the efficiency of the introduced object re-detection method and the performance of the developed tool indicate that the proposed framework can be used for accurate and time-efficient instance-based annotation of videos, and the creation of object-related spatiotemporal media fragments.
C1 [Ioannidou, Anastasia; Apostolidis, Evlampios; Collyda, Chrysa; Mezaris, Vasileios] Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Apostolidis, E (corresponding author), Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
EM ioananas@iti.gr; apostolid@iti.gr; ckol@iti.gr; bmezaris@iti.gr
OI Apostolidis, Evlampios/0000-0001-5376-7158
FU European Commission [FP7-600826 ForgetIT, FP7-287911 LinkedTV]
FX This work was supported by the European Commission under contract
   FP7-600826 ForgetIT and FP7-287911 LinkedTV.
CR Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], ABS1205 CORR
   [Anonymous], 2004, P 20 ACM S COMP
   [Anonymous], 2013, EXAMINATION HYBRID I
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], IEEE WINT C APPL COM
   [Anonymous], COMPUTER ENG TECHNOL
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 1999, INTEL CORPORATION MI
   [Anonymous], 2013, 18 INT C DIG SIGN PR
   [Anonymous], BATTLE 3 DESCRIPTORS
   Apostolidis Evlampios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6583, DOI 10.1109/ICASSP.2014.6854873
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Chiu LC, 2013, IEEE T IMAGE PROCESS, V22, P3158, DOI 10.1109/TIP.2013.2259841
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Donglei Yang, 2011, Advanced Parallel Processing Technologies. Proceedings 9th International Symposium, APPT 2011, P98, DOI 10.1007/978-3-642-24151-2_8
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fleury M, 2004, J PARALLEL DISTR COM, V64, P520, DOI 10.1016/j.jpdc.2004.03.003
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Harris C., 1988, ALVEY VISION C, P147151
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Joly Alexis., 2008, PROCEEDING 16 ACM IN, P209
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kato Kimikazu, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P769, DOI 10.1109/CCGRID.2010.47
   Ke Y., 2004, PCA SIFT MORE DISTIN
   Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Miksik O, 2012, INT C PATT RECOG, P2681
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Pan J., 2011, Proceedings of the 19th ACM SIGSPATIAL Interna- tional Conference on Advances in Geographic Information Systems, P211
   Romberg S., 2013, Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, P113
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Silpa- Anan C., 2008, IEEE C COMPUTER VISI, P1
   Sismanis Nikos., 2012, HIGH PERFORMANCE EXT, P1
   Ta DN, 2009, PROC CVPR IEEE, P2929
   Tomasi C, 1991, DETECTION TRACKING P
   Warn S., 2009, IEEE INT C CLUSTER C
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Zhang N, 2009, LECT NOTES COMPUT SC, V5754, P287, DOI 10.1007/978-3-642-04070-2_33
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 56
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1735
EP 1774
DI 10.1007/s11042-015-3125-0
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000007
DA 2024-07-18
ER

PT J
AU Jain, P
   Tyagi, V
AF Jain, Paras
   Tyagi, Vipin
TI An adaptive edge-preserving image denoising technique using patch-based
   weighted-SVD filtering in wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet transform; Singular value decomposition (SVD); Edge detection;
   Adaptive filtering
ID SHRINKAGE; ALGORITHM
AB Image denoising has always been one of the standard problems in image processing and computer vision. It is always recommendable for a denoising method to preserve important image features, such as edges, corners, etc., during its execution. Image denoising methods based on wavelet transforms have been shown their excellence in providing an efficient edge-preserving image denoising, because they provide a suitable basis for separating noisy signal from the image signal. This paper presents a novel edge-preserving image denoising technique based on wavelet transforms. The wavelet domain representation of the noisy image is obtained through its multi-level decomposition into wavelet coefficients by applying a discrete wavelet transform. A patch-based weighted-SVD filtering technique is used to effectively reduce noise while preserving important features of the original image. Experimental results, compared to other approaches, demonstrate that the proposed method achieves very impressive gain in denoising performance.
C1 [Jain, Paras] Jaypee Univ Engn & Technol, Guna 473226, MP, India.
   [Tyagi, Vipin] Jaypee Univ Engn & Technol, CSE, Guna 473226, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, CSE, Guna 473226, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Jain, Dr. Paras/Y-5329-2018; Tyagi, Vipin/I-2451-2013
OI Jain, Dr. Paras/0000-0003-2990-3556; Tyagi, Vipin/0000-0003-4994-3686
CR [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 1983, MATRIX COMPUTATION
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], INT J INTELL TECHNOL
   Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942
   Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chipman HA, 1997, J AM STAT ASSOC, V92, P1413, DOI 10.2307/2965411
   Choi H, 2004, IEEE SIGNAL PROC LET, V11, P717, DOI 10.1109/LSP.2004.833493
   da Silva RD, 2013, PATTERN ANAL APPL, V16, P567, DOI 10.1007/s10044-012-0266-x
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Gao HY, 1997, STAT SINICA, V7, P855
   Gao HY, 1998, J COMPUT GRAPH STAT, V7, P469
   Hou ZJ, 2003, PATTERN RECOGN, V36, P1747, DOI 10.1016/S0031-3203(02)00323-0
   Jain P., 2013, IETE J. Educ, V54, P108, DOI DOI 10.1080/09747338.2013.10876113
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Jain P, 2015, VISUAL COMPUT, V31, P657, DOI 10.1007/s00371-014-0993-7
   Jain P, 2015, INFORM SCIENCES, V294, P164, DOI 10.1016/j.ins.2014.09.060
   KONSTANTINIDES K, 1988, IEEE T ACOUST SPEECH, V36, P757, DOI 10.1109/29.1585
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725
   Nason GP, 1996, J ROY STAT SOC B MET, V58, P463
   Nason Guy P, 1995, Wavelets and Statistics, P281, DOI [DOI 10.1007/978-1-4612-2544-7_17, 10.1007/978-1-4612-2544-7_17]
   Orchard J, 2008, IEEE IMAGE PROC, P1732, DOI 10.1109/ICIP.2008.4712109
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Qiu TS, 2013, IEEE T IMAGE PROCESS, V22, P80, DOI 10.1109/TIP.2012.2214052
   Rudin L. I., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), P31, DOI 10.1109/ICIP.1994.413269
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Shao L, HEURISTIC OPTIMIZATI, P1
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   VANDERVEEN AJ, 1993, P IEEE, V81, P1277, DOI 10.1109/5.237536
   Vidakovic B, 1998, J AM STAT ASSOC, V93, P173, DOI 10.2307/2669614
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weyrich N, 1998, IEEE T IMAGE PROCESS, V7, P82, DOI 10.1109/83.650852
   Wongsawat Y, 2005, IEEE INT SYMP CIRC S, P5990, DOI 10.1109/ISCAS.2005.1466004
   [No title captured]
NR 45
TC 17
Z9 17
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1659
EP 1679
DI 10.1007/s11042-015-3154-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000003
DA 2024-07-18
ER

PT J
AU Maheswari, SU
   Hemanth, DJ
AF Maheswari, S. Uma
   Hemanth, D. Jude
TI Performance enhanced image steganography systems using transforms and
   optimization techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contourlet transform; Frequency domain steganography; Fresnelet
   transform; Genetic Algorithm; Particle Swarm Optimization
ID HIDING SCHEME; WATERMARKING
AB Image steganography is the art of hiding highly sensitive information onto the cover image. An ideal approach to image steganography must satisfy two factors: high quality of stego image and high embedding capacity. Conventionally, transform based techniques are widely preferred for these applications. The commonly used transforms for steganography applications are Discrete Cosine Transform (DCT), Discrete Wavelet Transform (DWT) etc. In this work, frequency domain transforms such as Fresnelet Transform (FT) and Contourlet Transform (CT) are used for the data hiding process. The secret data is normally hidden in the coefficients of these transforms. However, data hiding in transform coefficients yield less accurate results since the coefficients used for data hiding are selected randomly. Hence, in this work, optimization techniques such as Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) are used for improving the performance of the steganography system. GA and PSO are used to find the best coefficients in order to hide the Quick Response (QR) coded secret data. This approach yields an average PSNR of 52.56 dB and an embedding capacity of 902,136 bits. These experimental results validate the practical feasibility of the proposed methodology for security applications.
C1 [Maheswari, S. Uma; Hemanth, D. Jude] Karunya Univ, ECE Dept, Coimbatore, Tamil Nadu, India.
C3 Karunya Institute of Technology & Sciences
RP Hemanth, DJ (corresponding author), Karunya Univ, ECE Dept, Coimbatore, Tamil Nadu, India.
EM uma.success53@gmail.com; jude_hemanth@rediffmail.com
RI Karunya, Librarian/HHS-3630-2022
OI Karunya, Librarian/0009-0006-0726-2507; HEMANTH,
   JUDE/0000-0002-6091-1880
CR Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   Bajaj R, 2010, LNCS, V6466, P237
   Bedi P, 2013, COMPUT ELECTR ENG, V39, P640, DOI 10.1016/j.compeleceng.2012.12.021
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   El-Emam NN, 2013, J SYST SOFTWARE, V86, P1465, DOI 10.1016/j.jss.2012.12.006
   Gerami P, 2012, INT J COMPUT APPL, V55, P975, DOI [10.5120/8727-2602, DOI 10.5120/8727-2602]
   Goldberg DE, 1992, OPTIMIZATION MACHINE
   Gonzalez R.C., 2005, Digital image processing
   Hemalatha S, 2013, COMPUTER NETWORKS CO, V131, P613
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Liebling M, 2003, IEEE T IMAGE PROCESS, V12, P29, DOI 10.1109/TIP.2002.806243
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Nazeer M, 2013, INT J ADV COMPUT SC, V4, P131
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Sajedi H, 2010, INT J INF SECUR, V9, P337, DOI 10.1007/s10207-010-0112-3
   Sajedi H, 2009, INT J INF SECUR, V8, P433, DOI 10.1007/s10207-009-0089-y
   Sharma V, 2005, INT J COMPUT INTELL, V3, P1
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Yeh HL, 2013, AEU-INT J ELECTRON C, V67, P808, DOI 10.1016/j.aeue.2013.04.003
NR 26
TC 21
Z9 21
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 415
EP 436
DI 10.1007/s11042-015-3035-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000019
DA 2024-07-18
ER

PT J
AU Wang, ZQ
   Huang, H
AF Wang, Zhongqiang
   Huang, Hua
TI Pixel-wise video stabilization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel-wise video stabilization; Dense motion field; Motion smoothing;
   Image completion
AB In this paper, we present a novel video stabilization method with a pixel-wise motion model. In order to avoid distortion introduced by traditional feature points based motion models, we focus on constructing a more accurate model to capture the motion in videos. By taking advantage of dense optical flow, we can obtain the dense motion field between adjacent frames and set up a pixel-wise motion model which is accurate enough. Our method first estimates dense motion field between adjacent frames. A PatchMatch based dense motion field estimation algorithm is proposed. This algorithm is specially designed for similar video frames rather than arbitrary images to reach higher speed and better performance. Then, a simple and fast smoothing algorithm is performed to make the jittered motion stabilized. After that, we warp input frames using a weighted average algorithm to construct the output frames. Some pixels in output frames may be still empty after the warping step, so in the last step, these empty pixels are filled using a patch based image completion algorithm. We test our method on many challenging videos and demonstrate the accuracy of our model and the effectiveness of our method.
C1 [Wang, Zhongqiang] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
   [Huang, Hua] Beijing Inst Technol, Sch Comp Sci, Beijing Key Lab Intelligent Informat Technol, Beijing, Peoples R China.
C3 Xi'an Jiaotong University; Beijing Institute of Technology
RP Huang, H (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Key Lab Intelligent Informat Technol, Beijing, Peoples R China.
EM wangzhongqiang@stu.xjtu.edu.cn; huahuang@bit.edu.cn
RI Huang, Hua/M-9684-2013
OI Huang, Hua/0000-0003-2587-1702
FU National Natural Science Foundation of China [61133008, 61202180]
FX We would like to thank the anonymous reviewers for their helpful
   advices. We also thank the participants in our user study. This work is
   supported by the National Natural Science Foundation of China under
   Project No. 61133008 and No. 61202180.
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chen ZY, 2013, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2013.316
   Chouvatut V, 2013, MULTIMED TOOLS APPL, V63, P569, DOI 10.1007/s11042-011-0925-8
   Furht B., 1996, MOTION ESTIMATION AL
   Gleicher ML, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404882
   Goldstein A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231824
   Grundmann M, 2011, 2011 IEEE C COMP VIS, DOI [10.1109/CVPR.2011.5995525, DOI 10.1109/CVPR.2011.5995525]
   He K, 2012, 2012 IEEE C COMP VIS, DOI [10.1109/CVPR.2012.6247665, DOI 10.1109/CVPR.2012.6247665]
   Irani M, 1994, 1994 IEEE COMP SOC C, DOI [10.1109/CVPR.1994.323866, DOI 10.1109/CVPR.1994.323866]
   Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421
   Lee KY, 2009, 2009 IEEE 12 INT C C, DOI [10.Westwater R/ICCV.2009.5459297, DOI 10.1109/ICCV.2009.5459297]
   Litvin A, 2003, S EL IM IM VID COMM, DOI [10.1117/12.476436, DOI 10.1117/12.476436]
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu S, 2012, P CVPR, P8995, DOI [10.1109/CVPR.2012.6247662, DOI 10.1109/CVPR.2012.6247662]
   Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242
   Matsushita Y, 2005, PROC CVPR IEEE, P50
   Morimoto C, 1998, 1998 IEEE INT C AC S, V5, DOI [10.1109/ICASSP.1998.678102, DOI 10.1109/ICASSP.1998.678102]
   Morimoto C., 1996, P CVPR
   Okade M, 2014, MULTIMED TOOLS APPL, V68, P947, DOI 10.1007/s11042-012-1095-z
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Wang ZQ, 2013, COMPUT GRAPH FORUM, V32, P265, DOI 10.1111/cgf.12234
   Zhang GF, 2009, VISUAL COMPUT, V25, P997, DOI 10.1007/s00371-009-0310-z
   Zhou ZH, 2013, PROC CVPR IEEE, P2299, DOI 10.1109/CVPR.2013.298
NR 29
TC 4
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15939
EP 15954
DI 10.1007/s11042-015-2907-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700047
DA 2024-07-18
ER

PT J
AU Yang, JC
   Zhou, JX
   Fan, DY
   Lv, HB
AF Yang, Jiachen
   Zhou, Jianxiong
   Fan, Dayong
   Lv, Haibin
TI Design of intelligent recognition system based on gait recognition
   technology in smart transportation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart transportation; Automatic fare collection; Gait recognition;
   Infrared sensor
AB With the rapid development of urban smart transportation, automatic fare collection system becomes more and more important. The related device based on recognition system in the smart transportation is a key equipment of automatic fare ticket system. It is part of the automatic fare collection system and passenger interface. Because of the complexity of the passenger traffic, how the intelligent recognition system can identify the passengers is a formidable challenge. In this paper, we design a sort of intelligent recognition system based on the simplified human gait recognition algorithm. Firstly, we analyze and study the existing identification system. After that we propose the improved and optimized algorithm and design layout of the sensors. And then, according to the motion including action, event and behavior, we propose a simplified method using infrared sensor based on XYT human gait recognition model. This system can effectively reduce the recognition system's judgment and computation time, and improve the accuracy of judgment. Therefore, the proposed system has a certain application value.
C1 [Yang, Jiachen; Zhou, Jianxiong; Fan, Dayong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Lv, Haibin] State Ocean Adm, Qingdao Huanhai Marine Engn Prospecting Inst, Qingdao, Peoples R China.
C3 Tianjin University
RP Zhou, JX (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM zhoujx@tju.edu.cn
RI Fan, Dayong/G-4654-2013; Lv, Haibin/AAX-7696-2020; Yang,
   Jiachen/ABH-5032-2020
OI Lv, Haibin/0000-0003-1059-4765; Yang, Jiachen/0000-0003-2558-552X
FU National Natural Science Foundation of China [61471260, 61271324];
   Program for New Century Excellent Talents in University [NCET-12-0400]
FX This research is partially supported by the National Natural Science
   Foundation of China (No. 61471260 and No. 61271324) and Program for New
   Century Excellent Talents in University (NCET-12-0400).
CR Amriki KA, 2014, MULTIMED TOOLS APPL, V71, P1051, DOI 10.1007/s11042-012-1247-1
   [Anonymous], ARXIV150406359
   [Anonymous], TELECOMMUNICATION SY
   Bae JN, 2015, IEEE T IND ELECTRON, V62, P3091, DOI 10.1109/TIE.2014.2379218
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Fernández-Isabel A, 2015, SENSORS-BASEL, V15, P14116, DOI 10.3390/s150614116
   Fu C, 2015, MULTIMEDIA TOOLS APP
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Hancke GP, 2013, SENSORS-BASEL, V13, P393, DOI 10.3390/s130100393
   Jegadeeshwaran R, 2015, MECH SYST SIGNAL PR, V52-53, P436, DOI 10.1016/j.ymssp.2014.08.007
   Jiang D, 2015, J COMMUNICATIONS NET
   Lee H, 2008, EURASIP J IMAGE VIDE, V2008, P380
   Lee H, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/380867
   Li X, 2015, MULTIMEDIA TOOLS APP
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061249
   Ma LY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070716
   McMullan A, 2012, TRANSPORT RES REC, P154, DOI 10.3141/2274-17
   Isern-Deyà AP, 2013, COMPUT J, V56, P1198, DOI 10.1093/comjnl/bxs033
   Shin DK, 2013, MULTIMED TOOLS APPL, P1
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Sun YS, 2012, TRANSPORT RES REC, P58, DOI 10.3141/2275-07
   Wang W, 2014, J URBAN PLANNING DEV
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2014, J CLIN MONIT COMPUT, V28, P363, DOI 10.1007/s10877-013-9541-7
   Yang JC, 2014, APPL OPTICS, V53, P2145, DOI 10.1364/AO.53.002145
NR 26
TC 7
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17501
EP 17514
DI 10.1007/s11042-016-3313-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600035
DA 2024-07-18
ER

PT J
AU Jiang, DD
   Yuan, Z
   Zhang, P
   Miao, L
   Zhu, T
AF Jiang, Dingde
   Yuan, Zhen
   Zhang, Peng
   Miao, Lei
   Zhu, Ting
TI A traffic anomaly detection approach in communication networks for
   applications of multimedia medical devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Empirical mode decomposition; Spectral
   kurtosis; Anomaly detection; Network traffic
ID WAVELET PACKET; LOW-POWER; DECOMPOSITION; INTERNET; CLOUD; EMD
AB Anomalous or unnormal multimedia medical devices are to yield anomaly network traffic and affect the diagnosis about medical issues. How to find anomaly network traffic is significantly important for normal applications of multimedia medical devices. This paper studies traffic anomaly detection problem in large-scale communication networks with multimedia medical devices. We employ empirical mode decomposition method and wavelet packet transform to propose an accurate detection method to capture it. Firstly, we use the wavelet packet transform to pre-treat network traffic. Network traffic is decomposed into multiple narrowband signals exhibiting more detailed features of network traffic. Secondly, the empirical mode decomposition method is utilized to divide these narrowband signals into the intrinsic mode function at different scales, in time and time-frequency domains. We calculate the spectral kurtosis value of the intrinsic mode function at these different scales to remove false components of the empirical mode decomposition. As a result, we can obtain new time and time-frequency signals which highlight the hidden nature of anomaly network traffic. Thirdly, we perform the reconstruction of empirical mode decompositions and wavelet packet transforms for the above time and time-frequency signals to attain a series of new time signals. Then we can find and diagnose abnormal network traffic. Simulation results show that our method is effective and promising.
C1 [Jiang, Dingde; Yuan, Zhen; Zhang, Peng] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Peoples R China.
   [Miao, Lei] Middle Tennessee State Univ, Dept Engn Technol, Murfreesboro, TN 37132 USA.
   [Zhu, Ting] SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13905 USA.
C3 Northeastern University - China; Middle Tennessee State University;
   State University of New York (SUNY) System; State University of New York
   (SUNY) Binghamton
RP Jiang, DD (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Peoples R China.
EM jiangdingde@ise.neu.edu.cn
RI Yuan, zhen/HLW-3443-2023; YUAN, ZG/JEF-2123-2023
FU National Natural Science Foundation of China [61571104, 61071124];
   General Project of Scientific Research of the Education Department of
   Liaoning Province [L20150174]; Program for New Century Excellent Talents
   in University [NCET-11-0075]; Fundamental Research Funds for the Central
   Universities [N150402003, N120804004, N130504003]; State Scholarship
   Fund [201208210013]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61571104, 61071124), the General Project of
   Scientific Research of the Education Department of Liaoning Province
   (No. L20150174), the Program for New Century Excellent Talents in
   University (No. NCET-11-0075), the Fundamental Research Funds for the
   Central Universities (Nos. N150402003, N120804004, N130504003), and the
   State Scholarship Fund (201208210013). The authors wish to thank the
   reviewers for their helpful comments.
CR Ahmad A, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P286, DOI 10.1109/BigMM.2015.48
   Akgül T, 2011, IEEE T INSTRUM MEAS, V60, P1358, DOI 10.1109/TIM.2010.2084711
   Anand A, 2009, PERF E R SI, V37, P37
   [Anonymous], P INF
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], IEEE T DEPENDABLE SE
   [Anonymous], CHAOS SOLITON FRACT
   [Anonymous], B SCI TECHNOL
   [Anonymous], ARXIV14030157
   Barford P, 2002, IMW 2002: PROCEEDINGS OF THE SECOND INTERNET MEASUREMENT WORKSHOP, P71, DOI 10.1145/637201.637210
   Bayram I, 2008, IEEE T SIGNAL PROCES, V56, P2298, DOI 10.1109/TSP.2007.916129
   Celenk M, 2010, IEEE T INF FOREN SEC, V5, P288, DOI 10.1109/TIFS.2010.2041808
   Chandola V, 2012, IEEE T KNOWL DATA EN, V24, P823, DOI 10.1109/TKDE.2010.235
   Cheng J, 2013, ADV MATER RES-SWITZ, V798-799, P411, DOI 10.4028/www.scientific.net/AMR.798-799.411
   Chhabra P, 2008, IEEE INFOCOM SER, P2378
   Dingde Jiang, 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P993, DOI 10.1109/CIS.2011.222
   Dingde Jiang, 2010, 2010 International Conference on Computational Problem-Solving (ICCP 2010), P94
   Guan XH, 2010, IEEE T INF FOREN SEC, V5, P905, DOI 10.1109/TIFS.2010.2066970
   Guo CX, 2015, DISCRETE CONT DYN-S, V8, P1139, DOI 10.3934/dcdss.2015.8.1139
   Han JM, 2013, PROCEEDINGS OF 2013 CHINA INTERNATIONAL CONFERENCE ON INSURANCE AND RISK MANAGEMENT, P1
   Hu XY, 2012, IEEE T SIGNAL PROCES, V60, P1075, DOI 10.1109/TSP.2011.2179650
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang SY, 2013, 2013 43 ANN IEEE IFI, P1, DOI DOI 10.1109/DSN.2013.6575338
   Ji HF, 2011, IEEE T INSTRUM MEAS, V60, P1917, DOI 10.1109/TIM.2011.2108073
   Jiang DD, 2015, T EMERG TELECOMMUN T, V26, P308, DOI 10.1002/ett.2619
   Jiang DD, 2014, AEU-INT J ELECTRON C, V68, P915, DOI 10.1016/j.aeue.2014.04.011
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2012, CHINESE J ELECTRON, V21, P705
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2009, IEEE COMMUN LETT, V13, P52, DOI 10.1109/LCOMM.2008.081271
   Lakhina A, 2004, ACM SIGCOMM COMP COM, V34, P219, DOI 10.1145/1030194.1015492
   Lazarou GY, 2009, IEEE ACM T NETWORK, V17, P1672, DOI 10.1109/TNET.2008.2010494
   Lian SG, 2015, TELECOMMUN SYST, V59, P289, DOI 10.1007/s11235-014-9935-y
   Lin PJ, 2011, INT J COMMUN SYST, V24, P325, DOI 10.1002/dac.1157
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu Dajiang., 2013, DESIGN AUTOMATION C, P1
   Liu D, 2014, IEEE INT CONF TRUST, P823, DOI 10.1109/TrustCom.2014.109
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Marnerides AK, 2014, COMPUT NETW, V73, P224, DOI 10.1016/j.comnet.2014.08.007
   Millioz F, 2011, IEEE T SIGNAL PROCES, V59, P515, DOI 10.1109/TSP.2010.2081986
   Novakov S, 2013, IEEE INT CONF HIGH, P185, DOI 10.1109/HPSR.2013.6602310
   Qin T, 2011, J NETW COMPUT APPL, V34, P1732, DOI 10.1016/j.jnca.2011.06.006
   Roy DB, 2014, 2014 APPLICATIONS AND INNOVATIONS IN MOBILE COMPUTING (AIMOC), P186, DOI 10.1109/AIMOC.2014.6785539
   Sheng G, 2015, COMM COM INF SC, V557, P280, DOI 10.1007/978-3-662-48683-2_25
   Spognardi A, 2014, COMM COM INF SC, V455, P192, DOI 10.1007/978-3-662-44791-8_12
   Sun T, 2014, INT SYMP PARAL ARCH, P148, DOI 10.1109/PAAP.2014.62
   Tavallaee M, 2010, IEEE T SYST MAN CY C, V40, P516, DOI 10.1109/TSMCC.2010.2048428
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Thatte G, 2011, IEEE ACM T NETWORK, V19, P512, DOI 10.1109/TNET.2010.2070845
   Vishwanath A, 2011, IEEE ACM T NETWORK, V19, P933, DOI 10.1109/TNET.2010.2091721
   Wald R, 2014, IEEE INT C BIOINF BI, P362, DOI 10.1109/BIBE.2014.69
   Wang XN, 2012, INT J COMMUN SYST, V25, P1513, DOI 10.1002/dac.1318
   Wang Y, 2015, PROC 27 INT C SCI ST, P1
   Won Y, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P636
   Xiong W, 2014, INFORM SCIENCES, V258, P403, DOI 10.1016/j.ins.2013.04.009
   Xu LJ, 2005, IEEE T SIGNAL PROCES, V53, P222, DOI 10.1109/TSP.2004.838954
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Yang TH, 2017, MULTIMED TOOLS APPL, V76, P19411, DOI 10.1007/s11042-015-3139-7
   Yu W, 2010, IEEE T PARALL DISTR, V21, P1501, DOI 10.1109/TPDS.2009.161
   Zhang Su, 2015, INT C NETW SYST SEC, P405
   Zhang XL, 2015, LECT NOTES COMPUT SC, V9492, P647, DOI 10.1007/978-3-319-26561-2_76
   Zhou HB, 2014, IEEE T INTELL TRANSP, V15, P2644, DOI 10.1109/TITS.2014.2321293
NR 65
TC 17
Z9 19
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14281
EP 14305
DI 10.1007/s11042-016-3402-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500017
DA 2024-07-18
ER

PT J
AU Cho, SW
   Cha, M
   Sohn, KA
AF Cho, Seung Woo
   Cha, MoonSu
   Sohn, Kyung-Ah
TI Topic category analysis on twitter via cross-media strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Category classification; Twitter; Short-text classification; Topic
   analysis; SNS; Cross-media
AB The growing popularity of social media provides a huge volume of social data including Tweets. These collections of social data can be potentially useful, but the extent of meaningful data in these collections has not been sufficiently researched, especially in South Korea Twitter data. In general, the South Korea Twitter data has been researched as a source of political media. Nonetheless, previous research on South Korea Twitter data has not adequately covered what kind of trend Twitter represents in terms of major topic categories such as politics, economics, or sports. In this paper, we present a cross-media approach to define the nature of South Korea Tweets by inferring the topic category distribution through short-text categorization. We select newspapers as cross-media, examine the categorization of news articles from major newspapers, and then train our classifier based on the features from each topic category. In addition, for grafting news topics onto South Korea Tweets, we propose a word clustering and filtering approach to exclude those words that do not provide semantic content for the topic categories. Based on the proposed procedures, we analyze the South Korea Tweets to determine the primary topic category focus of Twitter users. We observe the special behaviors of the South Korea Twitter users based on various parameters such as date, time slot, and day of the week. Because our research includes a macroscopic analysis of Twitter data using a cross-media strategy, our research can provide useful resources for other social media analysis as well.
C1 [Cho, Seung Woo; Cha, MoonSu; Sohn, Kyung-Ah] Ajou Univ, Dept Informat & Comp Engn, Suwon, South Korea.
C3 Ajou University
RP Sohn, KA (corresponding author), Ajou Univ, Dept Informat & Comp Engn, Suwon, South Korea.
EM sksmsspdj@ajou.ac.kr; ckanstnzja@ajou.ac.kr; kasohn@ajou.ac.kr
RI Sohn, Kyung-Ah/AAD-8788-2021
OI Sohn, Kyung-Ah/0000-0001-8941-1188
FU National Research Foundation (NRF) of Korea - Ministry of Science, ICT,
   and Future Planning (MSIP) [2014R1A1A3051169]; Ministry of Education
   [2012R1A1A2042792]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation (NRF) of Korea funded by the
   Ministry of Science, ICT, and Future Planning (MSIP) (2014R1A1A3051169),
   and by the Ministry of Education (2012R1A1A2042792).
CR AlSumait L, 2008, IEEE DATA MINING, P3, DOI 10.1109/ICDM.2008.140
   [Anonymous], 2011, P 22 INT JOINT C ART, DOI [DOI 10.5591/978-1-57735-516-8/IJCAI11-298, 10.5591/978-1-57735-516-8/IJCAI11-298]
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Blei DavidMeir., 2004, Probabilistic Models of Text and Images
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BROOKS G, 1992, SIGPLAN NOTICES, V27, P1, DOI [10.13334/j.0258-8013.pcsee.213043, 10.1145/143103.143108]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheong M., 2009, Proceedings of the 2nd ACM Workshop on Social Web Search and Mining, P1, DOI [10.1145/1651437.1651439, DOI 10.1145/1651437.1651439]
   Cho Sung-Yeon, 2014, Infect Chemother, V46, P1, DOI 10.3947/ic.2014.46.1.1
   Ge Song, 2014, Journal of Multimedia, V9, P635, DOI 10.4304/jmm.9.5.635-643
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hong L., 2010, P 1 WORKSH SOC MED A, P80, DOI [10.1145/1964858.1964870, DOI 10.1145/1964858.1964870]
   Hsu C.L., 2013, Journal of Contemporary Eastern Asia, V12, P65, DOI DOI 10.17477/JCEA.2013.12.1.065
   Joachims T, 1996, DTIC DOCUMENT
   Lau J. H., 2012, P INT C COMP LING, P1519
   Lee KH, 2011, ACTA HORTIC, V900, P251, DOI 10.1109/ICDMW.2011.171
   Lu R, 2012, TREND ANAL NEWS TOPI
   Mathioudakis M., 2010, P 2010 ACM SIGMOD IN, P1155
   McCallum A.K., 2002, MALLET MACHINE LEARN
   Phan Xuan-Hieu, 2008, P 17 INT C WORLD WID, P91
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Yoon HY, 2014, QUAL QUANT, V48, P409, DOI 10.1007/s11135-012-9777-1
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
NR 25
TC 4
Z9 5
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12879
EP 12899
DI 10.1007/s11042-015-2866-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700034
DA 2024-07-18
ER

PT J
AU Liu, CJ
   Chen, TT
   Ding, XM
   Zou, HL
   Tong, Y
AF Liu, Chanjuan
   Chen, Tongtong
   Ding, Xinmiao
   Zou, Hailin
   Tong, Yan
TI A multi-instance multi-label learning algorithm based on instance
   correlations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-instance multi-label learning; Multi-label classification;
   Instance correlations; Multiple-kernel fusion
ID CATEGORIZATION
AB Existing multi-instance multi-label learning algorithms generally assume that instances in a bag are independent of each other, which is difficult to be guaranteed in practical applications. A novel multi-instance multi-label learning algorithm is proposed by modeling instance correlations in each bag. First, instance correlations are introduced in multi-instance multi-label learning by constructing graphs. Then, different kernel matrices are derived from kernel functions based on graphs at different scales, which are employed to train Multiple Kernel Support Vector Machine (MKSVM) classifiers. Experimental results on different datasets show that the proposed method significantly improves the accuracy of the multi-label classification compared with the state-of-the-art methods.
C1 [Liu, Chanjuan; Chen, Tongtong; Zou, Hailin] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
   [Liu, Chanjuan; Tong, Yan] Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
   [Ding, Xinmiao] Shandong Inst Business & Technol, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
C3 Ludong University; University of South Carolina System; University of
   South Carolina Columbia; Shandong Technology & Business University
RP Liu, CJ (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.; Liu, CJ (corresponding author), Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
EM luckycj80@sina.com; zhl_8655@sina.com
FU National Science Foundation of China [61170161, 61300155, 61303086];
   Shandong Province Scholarship Council, Ph.D. Programs Foundation of
   Ludong University [LY2014033]
FX This work is supported by the National Science Foundation of China (No.
   61170161, No. 61300155, No. 61303086), Shandong Province Scholarship
   Council, Ph.D. Programs Foundation of Ludong University (No. LY2014033).
CR Andrews S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P943
   Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], P 24 NEUR INF PROC S
   [Anonymous], 2006, P 23 INT C MACH LEAR, DOI [10.1145/1143844.1143933, DOI 10.1145/1143844.1143933]
   [Anonymous], 1997, ICML
   [Anonymous], THESIS
   [Anonymous], 2000, International Conference on Machine Learning (ICML)
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Bing Li, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P370, DOI 10.1109/ICDM.2011.43
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Briggs Forrest, 2012, P 18 ACM SIGKDD INT, P534
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Chowdhury M, 2015, MULTIMED TOOLS APPL, V74, P11595, DOI 10.1007/s11042-014-2252-3
   Deselaers T., 2010, ICML, P287
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Feng SH, 2014, SIGNAL PROCESS, V94, P595, DOI 10.1016/j.sigpro.2013.07.028
   Fu ZY, 2011, IEEE T PATTERN ANAL, V33, P958, DOI 10.1109/TPAMI.2010.155
   Fung G., 2007, Advances in Neural Information Processing Systems, V19, P425
   Gartner T., 2002, P 9 INT C MACH LEARN, P179
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Hu CP, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2441051
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Huang SJ, 2014, AAAI CONF ARTIF INTE, P1868
   Huang YG, 2014, MULTIMED TOOLS APPL, V73, P1963, DOI 10.1007/s11042-013-1685-4
   Indyk W, 2013, MULTIMED TOOLS APPL, V65, P63, DOI 10.1007/s11042-012-1149-2
   Jorgensen Z, 2008, J MACHINE LEARNING R, V8, P993
   Li Y.-F., 2012, P 26 AAAI C ART INT, P1012
   Liu Guoqing, 2012, AS C MACH LEARN PMLR, P253
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Maron O, 1998, ADV NEUR IN, V10, P570
   Neal L, 2011, INT CONF ACOUST SPEE, P2012
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Ruffo G., 2000, LEARNING SINGLE MULT
   Salton G., 1989, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer
   Settles B, 2008, ADV NEURAL INFORM PR, V21, P1289
   Wang Changhu., 2008, ACM MIR, P156
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Wu JS, 2014, IEEE ACM T COMPUT BI, V11, P891, DOI 10.1109/TCBB.2014.2323058
   Xu X, 2004, LECT NOTES ARTIF INT, V3056, P272
   Xu X.-S., 2011, P 19 ACM INT C MULT, P1153, DOI [10.1145/2072298.2071962, DOI 10.1145/2072298.2071962]
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Yang S.-H., 2009, P ADV NEURAL INFORM, P2143
   Yang S.-J., 2013, Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, P1862
   Zha Z.-J., 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587384
   Zhang C., 2008, ADV NEURAL INFORM PR, V20, P1681
   Zhang M. L., 2007, P 2007 AAAI C ARTIFI, P669
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2010, PROC INT C TOOLS ART, P207, DOI 10.1109/ICTAI.2010.102
   Zhang Q, 2002, ADV NEUR IN, V14, P1073
   Zhang Qi, 2002, International Conference on Machine Learning (ICML), P682
   Zhang SQ, 2013, MULTIMED TOOLS APPL, V63, P615, DOI 10.1007/s11042-011-0887-x
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
   Zhou ZH, 2005, APPL INTELL, V22, P135, DOI 10.1007/s10489-005-5602-z
   Zhou ZH., 2007, ICML '07, V227, P1167
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
   Zhou Zhi-Hua, 2009, PROC ANN INT C MACH, V382, P1249
NR 59
TC 2
Z9 2
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12263
EP 12284
DI 10.1007/s11042-016-3494-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200037
DA 2024-07-18
ER

PT J
AU Liu, CZ
   Kavakli, M
AF Liu, Charles Z.
   Kavakli, Manolya
TI Extensions of principle component analysis with applications on vision
   based computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Principle component analysis; Karhunen-Loeve transform; Extended PCA;
   Subspace training; Eigenspace; Image compression; Visual tracking; Image
   recognition; Super-resolution image reconstruction
ID FACE RECOGNITION; HAUSDORFF DISTANCE; OBJECT TRACKING; SUPERRESOLUTION;
   SYSTEM; NAVIGATION; ARCHITECTURE; COMPRESSION; PCA; IMPLEMENTATION
AB This paper mainly focuses on the principle component analysis (PCA) and its applications on vision based computing. The underlying mechanism of PCA given and several significant factors, involved with subspace training are discussed theoretically in detail including principle components energy, residuals assessment, and decomposition computation. The typical extensions, including probabilistic PCA (PPCA), kernel PCA (KPCA), multi-dimensional PCA and robust PCA (RPCA), have been presented with critical analysis on both mechanisms and computations. Combining with the studies on, such as, image compression, visual tracking, image recognition and super-resolution image reconstruction, PCA and its extensions applied to computer vision are critically reviewed and evaluated on the targeted issues in each application as well as the role they played at specific tasks to the characteristics, cost and suitable situations of each PCA based vision processing technique.
C1 [Liu, Charles Z.; Kavakli, Manolya] Macquarie Univ, Dept Comp, VISOR, Fac Sci & Engn, Sydney, NSW 2109, Australia.
C3 Macquarie University
RP Liu, CZ (corresponding author), Macquarie Univ, Dept Comp, VISOR, Fac Sci & Engn, Sydney, NSW 2109, Australia.
EM charles.liu@mq.edu.au; manolya.kavakli@mq.edu.au
RI Liu, Charles/AAT-6099-2021
OI Kavakli, Manolya/0000-0003-3241-6839
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   An L, 2013, IEEE J EM SEL TOP C, V3, P155, DOI 10.1109/JETCAS.2013.2256752
   [Anonymous], FACE RECOGNITION
   [Anonymous], 2003, PROC CVPR IEEE
   [Anonymous], 2007, 2007 BIOMETRICS S
   [Anonymous], 2005, Proc._Neural_Information_Processing_System
   Anthony D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P339, DOI 10.1109/IJCNN.1990.137591
   Arias-Estrada M, 2002, LECT NOTES COMPUT SC, V2438, P710
   ATALLAH MJ, 1983, INFORM PROCESS LETT, V17, P207, DOI 10.1016/0020-0190(83)90042-X
   Bae CS, 2003, IEEE T CONSUM ELECTR, V49, P1129, DOI 10.1109/TCE.2003.1261207
   Bahl P, 2012, P 3 ACM WORKSH MOB C, P21, DOI DOI 10.1145/2307849.2307856
   Belimpasakis P, 2011, IEEE T CONSUM ELECTR, V57, P139, DOI 10.1109/TCE.2011.5735494
   Bravo I, 2010, SENSORS-BASEL, V10, P9232, DOI 10.3390/s101009232
   Butterworth S., 1930, Wireless Eng, V7, P536
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Capel D, 2001, PROC CVPR IEEE, P627
   Castañeda B, 2004, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2004.1333730
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chen C., 2010, HDB PATTERN RECOGNIT
   Chen KY, 2011, INTEGR TRANSF SPEC F, V22, P861, DOI 10.1080/10652469.2010.541158
   Cho J., 2009, FPGA 09, P103
   Cho Y, 2010, IEEE T CONSUM ELECTR, V56, P1997, DOI 10.1109/TCE.2010.5606357
   Clausen C, 2000, PATTERN RECOGN, V33, P1555, DOI 10.1016/S0031-3203(99)00126-0
   Cruz-Mota J, 2013, IEEE T CIRC SYST VID, V23, P898, DOI 10.1109/TCSVT.2013.2249374
   Dai F, 2015, AUTOMAT CONSTR, V50, P29, DOI 10.1016/j.autcon.2014.10.005
   Davis M., 2005, 13th Annual ACM International Conference on Multimedia, P483, DOI 10.1145/1101149.1101257
   De Cristóforis P, 2015, PATTERN RECOGN LETT, V53, P118, DOI 10.1016/j.patrec.2014.10.010
   De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Du Q, 2013, IEEE J SEL TOP QUANT, V7, P2237
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Eerenberg O, 2014, IEEE T CONSUM ELECTR, V60, P681, DOI 10.1109/TCE.2014.7027343
   Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893
   Elad M, 1999, IEEE T PATTERN ANAL, V21, P817, DOI 10.1109/34.790425
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Gai JD, 2011, IEEE T IMAGE PROCESS, V20, P186, DOI 10.1109/TIP.2010.2060343
   Gaidhane V, 2010, INT C ADV REC TECHN, P978
   Glösmann P, 2005, NONLINEAR DYNAM, V41, P111, DOI 10.1007/s11071-005-2794-z
   Gorur P, 2014, IEEE T CIRC SYST VID, V24, P1156, DOI 10.1109/TCSVT.2014.2319611
   Han DH, 2004, IEEE IJCNN, P2159
   Hong HM, 2014, AQUACULT ENG, V63, P62, DOI 10.1016/j.aquaeng.2014.10.003
   Hossain MS, 2014, MULTIMED TOOLS APPL, V73, P169, DOI 10.1007/s11042-012-1312-9
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Huang YS, 2011, MULTIMED TOOLS APPL, V54, P527, DOI 10.1007/s11042-010-0550-y
   Hung KW, 2012, INT CONF ACOUST SPEE, P1269, DOI 10.1109/ICASSP.2012.6288120
   Hyvarinen L., 1970, MATH MODELING IND PR, P82
   Indelman V, 2012, ROBOT AUTON SYST, V60, P822, DOI 10.1016/j.robot.2012.02.003
   Jalal A, 2012, IEEE T CONSUM ELECTR, V58, P863, DOI 10.1109/TCE.2012.6311329
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Kasai H, 2013, IEEE T CONSUM ELECTR, V59, P343, DOI 10.1109/TCE.2013.6531116
   Khan AA, 2015, LECT NOTES GEOINF CA, P175, DOI 10.1007/978-3-319-12181-9_11
   Kim JO, 2005, LECT NOTES COMPUT SC, V3480, P638
   Kim J, 2008, IEEE T CONSUM ELECTR, V54, P954, DOI 10.1109/TCE.2008.4637573
   Kim K.I., 2004, STAT LEARNING COMPUT, P135
   Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351, DOI 10.1109/TPAMI.2005.181
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Kim Y, 2010, IEEE T CONSUM ELECTR, V56, P1480, DOI 10.1109/TCE.2010.5606286
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Kwon Y, 2014, ROBOT CIM-INT MANUF, V30, P451, DOI 10.1016/j.rcim.2014.02.004
   Lalonde M, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P481, DOI 10.1109/CRV.2007.54
   Lee SH, 2012, IEEE T CONSUM ELECTR, V58, P963, DOI 10.1109/TCE.2012.6311343
   Lei L, 2014, IEEE T CONSUM ELECTR, V60, P702, DOI 10.1109/TCE.2014.7027346
   Lim S H., 2014, How Instagram can be used as a tool in social networking marketing, P1
   Liu Y, 2014, OPT LASER ENG, V55, P243, DOI 10.1016/j.optlaseng.2013.11.013
   Lopez S, 2009, IEEE T CONSUM ELECTR, V55, P2264, DOI 10.1109/TCE.2009.5373797
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Marcellin M. W., 2002, JPEG2000 IMAGE COMPR, V1
   Maugey T, 2013, IEEE T IMAGE PROCESS, V22, P3459, DOI 10.1109/TIP.2013.2270183
   Mehta SS, 2014, COMPUT ELECTRON AGR, V102, P146, DOI 10.1016/j.compag.2014.01.003
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786, DOI 10.1109/ICCV.1995.466858
   Mohammed AA, 2011, PATTERN RECOGN, V44, P2588, DOI 10.1016/j.patcog.2011.03.013
   MOORE BC, 1981, IEEE T AUTOMAT CONTR, V26, P17, DOI 10.1109/TAC.1981.1102568
   NEUVO Y, 1984, IEEE T ACOUST SPEECH, V32, P563, DOI 10.1109/TASSP.1984.1164348
   Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891
   Nickels K, 2010, ROBOT AUTON SYST, V58, P121, DOI 10.1016/j.robot.2009.07.029
   Ohmer Julius., 2005, DICTA 05, P78
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Rahman MT, 2008, IEEE T CONSUM ELECTR, V54, P1506, DOI 10.1109/TCE.2008.4711194
   Roelofs G., 1999, PNG: the definitive guide
   Ross D, 2004, LECT NOTES COMPUT SC, V3022, P470
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   ROTE G, 1991, INFORM PROCESS LETT, V38, P123, DOI 10.1016/0020-0190(91)90233-8
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sazdovski V, 2015, AEROSP SCI TECHNOL, V40, P33, DOI 10.1016/j.ast.2014.09.019
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shen Y, 2009, IEEE T CONSUM ELECTR, V55, P1714, DOI 10.1109/TCE.2009.5278047
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Soyata T, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P59, DOI 10.1109/ISCC.2012.6249269
   STEWART GW, 1993, SIAM REV, V35, P551, DOI 10.1137/1035134
   Storn R, 1996, IEEE C EVOL COMPUTAT, P268, DOI 10.1109/ICEC.1996.542373
   Su X, 2015, MULTIMED TOOLS APPL, P1
   Szydzik T, 2011, IEEE T CONSUM ELECTR, V57, P664, DOI 10.1109/TCE.2011.5955206
   Takyar U, 2014, IEEE SIGNAL PROC LET, V21, P22, DOI 10.1109/LSP.2013.2288014
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Tsuzuki G, 2002, IEEE T MICROW THEORY, V50, P2924, DOI 10.1109/TMTT.2002.805154
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   VANLOAN CF, 1976, SIAM J NUMER ANAL, V13, P76, DOI 10.1137/0713009
   Vasilescu MAO, 2002, LECT NOTES COMPUT SC, V2350, P447
   Verstockt S, 2014, MULTIMED TOOLS APPL, V69, P313, DOI 10.1007/s11042-012-0991-6
   Visakhasart S, 2009, ICDIP 2009: INTERNATIONAL CONFERENCE ON DIGITAL IMAGE PROCESSING, PROCEEDINGS, P152, DOI 10.1109/ICDIP.2009.48
   Vo DT, 2011, IEEE T CONSUM ELECTR, V57, P187, DOI 10.1109/TCE.2011.5735501
   Vongbunyong S, 2015, ROBOT CIM-INT MANUF, V34, P79, DOI 10.1016/j.rcim.2014.11.003
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang DS, 2010, IEEE T CONSUM ELECTR, V56, P799, DOI 10.1109/TCE.2010.5506004
   Wiggins RH, 2001, RADIOGRAPHICS, V21, P789, DOI 10.1148/radiographics.21.3.g01ma25789
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   XU L, 1995, IEEE T NEURAL NETWOR, V6, P131, DOI 10.1109/72.363442
   Yamada K, 2002, IEEE T CONSUM ELECTR, V48, P143, DOI 10.1109/TCE.2002.1010104
   Yan T, 2013, INT J COMPUT VISION, V102, P293, DOI 10.1007/s11263-012-0593-9
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang L, 2015, COMPUT MED IMAG GRAP, V40, P205, DOI 10.1016/j.compmedimag.2014.09.003
   Yuan Y, 2014, IEEE T CIRC SYST VID, V24, P1898, DOI 10.1109/TCSVT.2014.2319632
   Yun WH, 2007, IEEE T CONSUM ELECTR, V53, P1731, DOI 10.1109/TCE.2007.4429277
   Zhang DQ, 2006, PATTERN RECOGN, V39, P140, DOI 10.1016/j.patcog.2005.08.002
   Zhang HY, 2012, SIGNAL PROCESS, V92, P2082, DOI 10.1016/j.sigpro.2012.01.020
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P769, DOI 10.1109/TIP.2013.2294549
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   [No title captured]
NR 128
TC 3
Z9 4
U1 3
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10113
EP 10151
DI 10.1007/s11042-015-3025-3
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800002
DA 2024-07-18
ER

PT J
AU Urueña, M
   Machník, P
   Niemiec, M
   Stoianov, N
AF Uruena, Manuel
   Machnik, Petr
   Niemiec, Marcin
   Stoianov, Nikolai
TI Security architecture for law enforcement agencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Law Enforcement Agency (LEA); Security architecture; Police; ICT
   systems; Security
AB In order to carry out their duty to serve and protect, law enforcement agencies (LEAs) must deploy new tools and applications to keep up with the pace of evolving technologies. However, police information and communication technology (ICT) systems have stringent security requirements that may delay the deployment of these new applications, since necessary security measures must be implemented first. This paper presents an integrated security architecture for LEAs that is able to provide common security services to novel and legacy ICT applications, while fulfilling the high security requirements of police forces. By reusing the security services provided by this architecture, new systems do not have to implement custom security mechanisms themselves, and can be easily integrated into existing police ICT infrastructures. The proposed LEA security architecture features state-of-the-art technologies, such as encrypted communications at network and application levels, or multi-factor authentication based on certificates stored in smart cards.
C1 [Uruena, Manuel] Univ Carlos III Madrid, Dept Telemat Engn, Avda Univ 30, Madrid 28911, Spain.
   [Machnik, Petr] VSB Tech Univ Ostrava, Dept Telecommun, 17 Listopadu 15, Ostrava 70833, Czech Republic.
   [Niemiec, Marcin] AGH Univ Sci & Technol, Mickiewicza 30, PL-30059 Krakow, Poland.
   [Stoianov, Nikolai] Tech Univ Sofia, INDECT Project Team, 8 Kliment Ohridski St, Sofia 1000, Bulgaria.
C3 Universidad Carlos III de Madrid; Technical University of Ostrava; AGH
   University of Krakow; Technical University Sofia
RP Niemiec, M (corresponding author), AGH Univ Sci & Technol, Mickiewicza 30, PL-30059 Krakow, Poland.
EM muruenya@it.uc3m.es; petr.machnik@vsb.cz; niemiec@kt.agh.edu.pl;
   nkl_stnv@tu-sofia.bg
RI santana, elysmara S D/P-2636-2016; Urueña, Manuel/J-3189-2012; Stoianov,
   Nikolai/AAA-3724-2019; Niemiec, Marcin/D-1271-2011; Machnik,
   Petr/G-5341-2017
OI Urueña, Manuel/0000-0001-7834-5998; Stoianov,
   Nikolai/0000-0002-4953-4172; Niemiec, Marcin/0000-0002-3909-9592;
   Machnik, Petr/0000-0003-0021-9777
FU EU [218086]; European Structural Funds [CZ.1.07/2.3.00/20.0217]; state
   budget of the Czech Republic
FX This research has been partially funded by the EU project INDECT
   (Intelligent information system supporting observation, searching and
   detection for security of citizens in urban environment) - grant
   agreement number: 218086, and the project No. CZ.1.07/2.3.00/20.0217
   (The Development of Excellence of the Telecommunication Research Team in
   Relation to International Cooperation) within the frame of the operation
   programme "Education for competitiveness" financed by the European
   Structural Funds and from the state budget of the Czech Republic.
CR Adams C, 2002, UNDERSTANDING PKI CO
   [Anonymous], 2011, ADV ELECTR ELECTRON
   Apostolopoulos G, 1999, IEEE INFOCOM SER, P717, DOI 10.1109/INFCOM.1999.751458
   Coarfa C, 2006, ACM T COMPUT SYST, V24, P39, DOI 10.1145/1124153.1124155
   Failner M, 2009, BEGINNING OPENVPN 2
   Guerrero-Zapata M., 2006, SECURE AD HOC ON DEM
   INDECT Consortium, 2013, D8 7 DEF MECH PROC S
   Kleppe H, 2011, TECHNICAL REPORT
   Marina MK, 2001, 9 INT C NETW PROT, P11
   Niemiec M, 2012, IEEE GLOB TEL C GLOB
   Niemiec M, 2011, IEEE MULTIMEDIA COMM
   Niemiec M, 2012, IV INTERNATIONAL CONGRESS ON ULTRA MODERN TELECOMMUNICATIONS AND CONTROL SYSTEMS 2012 (ICUMT), P474, DOI 10.1109/ICUMT.2012.6459712
   Niemiec M, 2012, COMM COM INF SC, V287, P252
   Stoianov N, 2012, COMM COM INF SC, V287, P304
   Uruena Manuel., 2010, IEEE MULTIMEDIA COMM
NR 15
TC 0
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10709
EP 10732
DI 10.1007/s11042-014-2386-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800030
OA hybrid
DA 2024-07-18
ER

PT J
AU Cao, DL
   Ji, RR
   Lin, DZ
   Li, SZ
AF Cao, Donglin
   Ji, Rongrong
   Lin, Dazhen
   Li, Shaozi
TI Visual sentiment topic model based microblog image sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sentiment topic model; Visual sentiment ontology; Sentiment
   analysis
AB With a growing number of images being used to express opinions in Microblog, text based sentiment analysis is not enough to understand the sentiments of users. To obtain the sentiments implied in Microblog images, we propose a Visual Sentiment Topic Model (VSTM) which gathers images in the same Microblog topic to enhance the visual sentiment analysis results. First, we obtain the visual sentiment features by using Visual Sentiment Ontology (VSO); then, we build a Visual Sentiment Topic Model by using all images in the same topic; finally, we choose better visual sentiment features according to the visual sentiment features distribution in a topic. The best advantage of our approach is that the discriminative visual sentiment ontology features are selected according to the sentiment topic model. The experiment results show that the performance of our approach is better than VSO based model.
C1 [Cao, Donglin; Ji, Rongrong; Lin, Dazhen; Li, Shaozi] Xiamen Univ, Dept Cognit Sci, Xiamen 361005, Peoples R China.
   [Cao, Donglin; Ji, Rongrong; Lin, Dazhen; Li, Shaozi] Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Ji, RR (corresponding author), Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China.
EM another@xmu.edu.cn; rrji@xmu.edu.cn; dzlin@xmu.edu.cn; szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU National Nature Science Foundation of China [61402386, 61305061,
   61202143]; Nature Science Foundation of Fujian Province [2014 J01249,
   2011 J01367]; Doctoral Program Foundation of Institutions of Higher
   Education of China [20090121110032]; Shenzhen Science and Technology
   Research Foundation [JC200903180630A]; Special Fund for Developing
   Shenzhen's Strategic Emerging Industries [JCYJ20120614164600201]
FX This work was supported by National Nature Science Foundation of China
   (No.61402386, No. 61305061 and No. 61202143), the Nature Science
   Foundation of Fujian Province (No. 2014 J01249 and No. 2011 J01367),
   Doctoral Program Foundation of Institutions of Higher Education of China
   (No.20090121110032), Shenzhen Science and Technology Research Foundation
   (No.JC200903180630A) and Special Fund for Developing Shenzhen's
   Strategic Emerging Industries (No. JCYJ20120614164600201).
CR [Anonymous], 2012, PROC 20 ACM INT C MU
   [Anonymous], 2012, P 20 ACM INT C MULT
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Chen Bi, 2010, P AAAI C ART INT AAA
   Datta R., 2006, Studying Aesthetics in Photographic Images Using a Computational Approach, P288
   Feldman Ronen, 2011, P 23 IAAI C ART INT
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Yue, 2014, ACM C MULT RETR
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Groh Georg, 2011, P 5 INT AAAI C WEBL
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jiang Long, 2011, P 49 ANN M ASS COMP, P151
   Joshi Mahesh, 2010, P N AM CHAPT ASS COM
   Li B, 2012, P 20 ACM INT C MULT, P1365
   Li Bing, 2012, CONTEXT AWARE AFFECT, P721
   Liu J., 2007, P 2007 JOINT C EMP M, P334
   Liu Xianming, 2010, ICIMCS10
   Lu Xin, 2012, Proc ACM Int Conf Multimed, V2012, P229, DOI 10.1145/2393347.2393384
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   McGlohon M., 2010, P 4 INT C WEBL SOC M
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Tumasjan Andranik, 2010, ROC INT C WEBL SOC M
   Wilson T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P761
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Yano T., 2010, P INT AAAI C WEB SOC, V4
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Yanulevskaya V, 2012, P 20 ACM INT C MULT, P349, DOI [10.1145/2393347.2393399, DOI 10.1145/2393347.2393399]
   ZHAO SC, 2014, IEEE INT CON MULTI, pNI255
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhao Sicheng, 2013, INT C MULT MOD
   Zhao Sicheng, 2011, VIDEO INDEXING RECOM, P1473
   Zhou Lanjun., 2011, EMNLP, P162
NR 36
TC 24
Z9 25
U1 12
U2 111
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8955
EP 8968
DI 10.1007/s11042-014-2337-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500008
DA 2024-07-18
ER

PT J
AU de Boer, M
   Schutte, K
   Kraaij, W
AF de Boer, Maaike
   Schutte, Klamer
   Kraaij, Wessel
TI Knowledge based query expansion in complex multimedia event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video event classification; Information retrieval; Knowledge bases;
   Zero-shot retrieval; Semantic analysis
ID RETRIEVAL; ONTOLOGY; VIDEO
AB A common approach in content based video information retrieval is to perform automatic shot annotation with semantic labels using pre-trained classifiers. The visual vocabulary of state-of-the-art automatic annotation systems is limited to a few thousand concepts, which creates a semantic gap between the semantic labels and the natural language query. One of the methods to bridge this semantic gap is to expand the original user query using knowledge bases. Both common knowledge bases such as Wikipedia and expert knowledge bases such as a manually created ontology can be used to bridge the semantic gap. Expert knowledge bases have highest performance, but are only available in closed domains. Only in closed domains all necessary information, including structure and disambiguation, can be made available in a knowledge base. Common knowledge bases are often used in open domain, because it covers a lot of general information. In this research, query expansion using common knowledge bases ConceptNet and Wikipedia is compared to an expert description of the topic applied to content-based information retrieval of complex events. We run experiments on the Test Set of TRECVID MED 2014. Results show that 1) Query Expansion can improve performance compared to using no query expansion in the case that the main noun of the query could not be matched to a concept detector; 2) Query expansion using expert knowledge is not necessarily better than query expansion using common knowledge; 3) ConceptNet performs slightly better than Wikipedia; 4) Late fusion can slightly improve performance. To conclude, query expansion has potential in complex event detection.
C1 [de Boer, Maaike; Schutte, Klamer] TNO, Oude Waalsdorperweg 63, NL-2597 AK The Hague, Netherlands.
   [de Boer, Maaike; Kraaij, Wessel] Radboud Univ Nijmegen, Toernooiveld 200, NL-6525 EC Nijmegen, Netherlands.
   [Kraaij, Wessel] TNO, Anna van Buerenpl 1, NL-2595 DA The Hague, Netherlands.
C3 Netherlands Organization Applied Science Research; Radboud University
   Nijmegen; Netherlands Organization Applied Science Research
RP de Boer, M (corresponding author), TNO, Oude Waalsdorperweg 63, NL-2597 AK The Hague, Netherlands.; de Boer, M (corresponding author), Radboud Univ Nijmegen, Toernooiveld 200, NL-6525 EC Nijmegen, Netherlands.
EM maaike.deboer@tno.nl; klamer.schutte@tno.nl; wessel.kraaij@tno.nl
RI Kraaij, Wessel/S-2071-2016
OI Kraaij, Wessel/0000-0001-7797-619X
FU technology program Adaptive Multi Sensor Networks (AMSN); ERP Making
   Sense of Big Data (MSoBD)
FX We would like to thank the VIREO team from the City University of Hong
   Kong for the application of their concept detectors on the TRECVID MED
   2014 data sets and both the technology program Adaptive Multi Sensor
   Networks (AMSN) and the ERP Making Sense of Big Data (MSoBD) for their
   financial support.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P TRECVID 2013
   [Anonymous], 2014, INT J COMPUT VISION
   Baeza-Yates R, 2008, LECT NOTES COMPUT SC, V5039, P4
   Bagdanov AD, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P713, DOI 10.1109/ICSC.2007.30
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bodner RC, 1996, KNOWLEDGE BASED APPR, P146
   Bouma H, 2013, P TRECVID 2013
   Burgess JeanJoshua Green., 2013, YOUTUBE ONLINE VIDEO
   Caputo B., 2014, INFORM ACCESS EVALUA, P192
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   CHEN JW, 2014, P INT C MULT RETR AC, P1, DOI DOI 10.1145/2578726.2578729
   de Boer M, 2013, ICT OPEN, P39
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Georis B., 2004, Intelligent Distributed Surveillance Systems (IDSS-04), P46
   Grenon P, 2004, STUD HEALTH TECHNOL, V102, P20
   Habibian A, 2013, P 3 ACM C INT C MULT, P89, DOI DOI 10.1145/2461466.2461482
   Hare JS, 2006, ELECT IMAGING 2006
   Hassan S., 2011, Proceedings of the 25th AAAI Conference on Artificial Intelligence, (AAAI 2011), P884
   Hauptmann A.G., 2004, PROC 12 ANN ACM INT, P668
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Hoque E, 2013, J AMB INTEL HUM COMP, V4, P389, DOI 10.1007/s12652-011-0094-7
   Jiang Yu-Gang., 2012, IJMIR, P1
   Kotov A., 2012, P WSDM, DOI DOI 10.1145/2124295.2124344
   Leong CW, 2011, LECT NOTES COMPUT SC, V6941, P137, DOI 10.1007/978-3-642-23708-9_16
   Liu X., 2002, Master thesis
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mascardi V., 2007, WOA 2007, V2007, P55
   Mazloom M., 2013, Proceedings of the ACM Multimedia Conference, MM'13, P609
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Milne D, 2013, ARTIF INTELL, V194, P222, DOI 10.1016/j.artint.2012.06.007
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Natarajan P, 2011, NIST TRECVID WORKSH, V62
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   Ngo CW, 2014, P TRECVID 2014
   Over P, 2004, IEEE MULTIMEDIA, V11, P80, DOI 10.1109/MMUL.2004.1289045
   Patil PB, 2011, J APPL COMPUT SCI MA, V10, P4047
   Pedersen Ted., 2004, DEMONSTRATION PAPERS, P38
   Sheth A., 2005, International Journal on Semantic Web and Information Systems, V1, P1, DOI 10.4018/jswis.2005010101
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2010, COMPUTER, V43, P76, DOI 10.1109/MC.2010.183
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   Tu K, 2014, IEEE MULTIMEDIA, V21, P42, DOI 10.1109/MMUL.2014.29
   van der Zon R, 2014, THESIS
   Vatant B., 2012, Geonames ontology
   von Ahn L., 2006, Knowledge Creation Diffusion Utilization, V1, P75
   Voss J., 2005, P 10 INT C INT SOC S
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
NR 50
TC 16
Z9 17
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9025
EP 9043
DI 10.1007/s11042-015-2757-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500012
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sebillo, M
   Vitiello, G
   Paolino, L
   Ginige, A
AF Sebillo, Monica
   Vitiello, Giuliana
   Paolino, Luca
   Ginige, Athula
TI Training emergency responders through augmented reality mobile
   interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emergency management; Mobile interfaces; AR-based training applications;
   Information sharing; Situation awareness
ID MANAGEMENT
AB In the domain of emergency management, in addition to the constant technical skill-upgrade required by the nature of the humanitarian context, the importance of an appropriate training is widely recognized. In particular, giving responders information technology skills so that they are well prepared to address health, security and managerial concerns represents a key factor by which the goal of an efficient and effective humanitarian emergency response can be pursued. In this paper we propose the adoption of augmented reality mobile interfaces to enhance the training efficacy for on-site crisis preparedness activities. The system we propose originated from the idea to allow trainees to exploit Augmented Reality (AR) interaction and become quickly familiar with the mobile technology adopted today in emergency response activities.
C1 [Sebillo, Monica; Vitiello, Giuliana] Univ Salerno, Dept Comp Sci DI, I-84084 Fisciano, SA, Italy.
   [Paolino, Luca] Univ Western Sydney, Sydney, NSW, Australia.
   [Ginige, Athula] Link Campus Univ, Rome, Italy.
C3 University of Salerno; Western Sydney University
RP Vitiello, G (corresponding author), Univ Salerno, Dept Comp Sci DI, I-84084 Fisciano, SA, Italy.
EM msebillo@unisa.it; gvitiello@unisa.it; l.paolino@unilink.it;
   a.ginige@uws.edu.au
RI Vitiello, Giuliana/AAU-9132-2020; Ginige, Athula/AAV-2129-2020
OI Vitiello, Giuliana/0000-0001-7130-996X; Ginige,
   Athula/0000-0002-7445-588X
CR Aedo Banuls, 2011, P 8 INT C INF SYST C, P1
   Banuls V, 2014, P 11 INT ISCRAM C, P597
   Carver L, 2007, COMMUN ACM, V50, P33, DOI 10.1145/1226736.1226761
   De Chiara D, 2010, LECT NOTES COMPUT SC, V6298, P583, DOI 10.1007/978-3-642-15696-0_54
   Drabek TE, 2003, MONOGRAPH, V61
   Ginige A, 2014, COMPUT SUPP COOP W J, V23, P547, DOI 10.1007/s10606-014-9207-0
   Jackson BA, 2004, NATL I OCCUPATIONAL, V3
   Jennex M., 2004, Journal of Information Technology Theory and Application (JITTA), V6, P85
   Johnson WL, 1998, PRESENCE-VIRTUAL AUG, V7, P523, DOI 10.1162/105474698565929
   Paolino L, 2010, J LOCAT BASED SERV, V4, P222, DOI 10.1080/17489725.2010.537282
   Paolino L, 2009, LECT NOTES COMPUT SC, V5879, P1156, DOI 10.1007/978-3-642-10467-1_116
   Paolino L, 2008, J LOCAT BASED SERV, V2, P236, DOI 10.1080/17489720802487949
   PETAK WJ, 1985, PUBLIC ADMIN REV, V45, P3, DOI 10.2307/3134992
   Toups ZO, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/2063231.2063237
NR 14
TC 25
Z9 27
U1 4
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9609
EP 9622
DI 10.1007/s11042-015-2955-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500006
DA 2024-07-18
ER

PT J
AU Agilandeeswari, L
   Ganesan, K
AF Agilandeeswari, L.
   Ganesan, K.
TI A robust color video watermarking scheme based on hybrid embedding
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Proof of ownership; Digital watermarking;
   Imperceptibility; Robustness; Payload; CT; DWT; SVD; Arnold transform;
   Eigen vector; Covariance matrix; Non-motion frame; Scrambling
ID IMAGE WATERMARKING; COPYRIGHT PROTECTION; DIGITAL IMAGES; DCT; TRANSFORM
AB The advancements in network technologies and processing of multimedia contents have provided the way for the distribution and sharing of multimedia contents through networks. This in turn has increased the demand for protecting the multimedia contents in terms of authentication, proof of ownership, copy control etc., which can be achieved by means of what is called digital watermarking. The challenges in watermarking techniques are how to achieve the imperceptibility, robustness and payload simultaneously. This paper presents a new bit plane sliced, scrambled color image watermark embedded on the color cover video using hybrid transforms such as Contourlet Transform (CT), Discrete Wavelet Transform (DWT) and Singular Value Decomposition (SVD) transformations with good imperceptibility, high robustness and at an information rate of (N - number of motion frames) / 24 images per second of the video, where N is the total number of frames in the video. In order to achieve a good level of imperceptibility, we perform the following: First, we slice the color watermark image into 24 slices using the bit plane slicing mechanism. Subsequently, the so called Arnold transformation key is used to scramble those slices, to achieve first-level of security. Thus, an authenticated receiver with an appropriate key alone can descramble the received slices. Second, we embed those scrambled slices on one of the DWT mid-frequency coefficients (LH band) of successive 1-level CT non-motion frames of color cover video. The non-motion frames are identified using the histogram difference based shot boundary detection algorithm. Third, in order to the provide second-level of security, we generate a random eigen vector from the color watermark image, using co-variance matrix and maximum eigen value and then embed it on another DWT mid-frequency coefficients (HL band). Thus, embedding only the slices (not an entire image) will improve the level of imperceptibility. The mid-frequency embedding location can withstand against all low pass and high pass filtering attacks; thereby it increases the level of robustness. Thus, the proposed system is suitable for authentication. Finally, as far as payload is concerned, we need only 24 non-motion frames for embedding our watermark on to the cover video. Hence the remaining frames can be utilized for embedding other color images. Our simulation results prove that the proposed system provides trustworthy performance against various notable image processing attacks, multiple attacks, geometrical attacks, and temporal attacks.
C1 [Agilandeeswari, L.; Ganesan, K.] VIT Univ, SITE, Vellore 632014, Tamil Nadu, India.
   [Ganesan, K.] VIT Univ, TIFAC CORE Automot Infotron, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Agilandeeswari, L (corresponding author), VIT Univ, SITE, Vellore 632014, Tamil Nadu, India.
EM mail2agi05@gmail.com; kganesan@vit.ac.in
RI L, Agilandeeswari/P-8997-2016; L, A/HZI-4043-2023; L, A/GYV-6221-2022
OI L, Agilandeeswari/0000-0001-6147-9535; 
CR Acharya UR, 2001, IEEE T INF TECHNOL B, V5, P320, DOI 10.1109/4233.966107
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P7211, DOI 10.1007/s11042-015-2642-1
   Agilandeeswari L, 2013, SPRINGER SERIES, P366
   Agilandeeswari L, 2013, INT J SECUR APPL, V7, P145
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   BarniM Bartolini F, 2000, P 10 INT PACK VID WO
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Briassouli A, 2004, IEEE T CIRC SYST VID, V14, P1308, DOI 10.1109/TCSVT.2004.836753
   Checcacci N, 2000, IEEE WCNC, P1530, DOI 10.1109/WCNC.2000.904862
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Delaigle JF, 1998, SIGNAL PROCESS, V66, P319, DOI 10.1016/S0165-1684(98)00013-9
   Deng C, 2010, SIGNAL PROCESS, V90, P3256, DOI 10.1016/j.sigpro.2010.05.032
   Dharwadkar NV, 2009, J COMPUT, V1, P1
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Ganesan K, 2014, EUR PHYS J-SPEC TOP, V223, P1611, DOI 10.1140/epjst/e2014-02123-1
   Gonzalez RC, 2012, Digital image process- ing
   Hao PW, 2000, INT C PATT RECOG, P224
   Hong I, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P1946, DOI 10.1109/ISIE.2001.932010
   Huang JW, 2002, IEEE T CIRC SYST VID, V12, P916, DOI 10.1109/TCSVT.2002.804897
   Jiwu Huang, 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P239, DOI 10.1109/ISCAS.2001.922029
   Karybali IG, 2006, IEEE T INF FOREN SEC, V1, P256, DOI 10.1109/TIFS.2006.873652
   Kundur D, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P544, DOI 10.1109/ICIP.1997.647970
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Li LD, 2009, LECT NOTES COMPUT SC, V5450, P88, DOI 10.1007/978-3-642-04438-0_8
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Memon N., 2001, IEEE P, V3, P1019
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Nikolaidis N, 1996, INT CONF ACOUST SPEE, P2168, DOI 10.1109/ICASSP.1996.545849
   Niu X, 2000, P IEEE DIG SIGN PROC
   Peterson G., 1997, ARNOLDS CAT MAP, V45, P1
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Phadikar A, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P888, DOI 10.1109/IADCC.2009.4809133
   Radwan Nisreen I., 2012, P ICCSEA, P765
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Serdean CV, 2002, PROCEEDINGS VIPROMCOM-2002, P263, DOI 10.1109/VIPROM.2002.1026666
   Shekhwat RS, 2012, STUD C ENG SYST SCES, P1
   Song H, 2009, IEICE T INF SYST, VE92D, P2171, DOI 10.1587/transinf.E92.D.2171
   Su K, 2002, PROC SPIE, V4675, P491, DOI 10.1117/12.465307
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   Thomos N, 2006, IEEE IMAGE PROC, P5, DOI 10.1109/ICIP.2006.313197
   Vassaux B, 2002, PROCEEDINGS VIPROMCOM-2002, P239, DOI 10.1109/VIPROM.2002.1026662
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Zhang LJ, 2000, IEEE VTS VEH TECHNOL, P1198, DOI 10.1109/VETECF.2000.886291
NR 55
TC 45
Z9 48
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8745
EP 8780
DI 10.1007/s11042-015-2789-9
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300028
DA 2024-07-18
ER

PT J
AU Fini, MR
   Zargari, F
AF Fini, Mohammadreza Ramezanpour
   Zargari, Farzad
TI Two stage fast mode decision algorithm for intra prediction in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Intra coding; Fast mode decision; HEVC standard
ID SIZE
AB High efficiency video coding (HEVC) standard, introduced by the joint collaborative team on video coding (JCT-VC), is the newest international standard for video compression. This standard provides more compression and better video quality, compared with the previous standards such as H.264/AVC. The higher compression efficiency in HEVC is achieved at the cost of increasing the computational load. Intra prediction unit is among the high computational stages in the HEVC encoder. There are proposed 35 intra prediction modes in HEVC, to improve the compression efficiency. To reduce the computational load of intra prediction, HEVC uses a preprocessing step, called Rough Mode Decision (RMD). A number of best prediction modes are selected by the RMD stage and then, using Rate Distortion Optimization (RDO) process, the encoder selects the best prediction mode among them. In this paper a two stage algorithm is proposed for fast intra mode decision in HEVC encoder, in the first stage of our proposed algorithm the number of the tested modes in RMD is reduced from 35 to 19. In the second stage, the number of the tested modes in the RDO process is reduced as well. In order to evaluate the performance of the proposed method two encoding profiles, main and main10 were used in the experiments. Experimental results indicate that the proposed method achieves 14.4 and 7.2 % reduction in the encoding time compared with the HEVC reference software in all intra-main and all intra-main10 configurations, respectively. Meanwhile, it imposes minimum reduction in the coding efficiency among the compared methods.
C1 [Fini, Mohammadreza Ramezanpour] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Zargari, Farzad] Res Inst ICT, Dept Informat Technol, Tehran, Iran.
C3 Islamic Azad University
RP Zargari, F (corresponding author), Res Inst ICT, Dept Informat Technol, Tehran, Iran.
EM mr.ramezanpoor@srbiau.ac.ir; zargari@itrc.ac.ir
RI Ramezanpour, Mohammadreza/AAD-6944-2021
OI Ramezanpour, Mohammadreza/0000-0002-1588-0982
CR [Anonymous], 2013, TELKOMNIKA
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], 12 M GEN
   [Anonymous], 2012, P 20 INT C SOFTW TEL
   [Anonymous], 2013, Common test conditions and software reference configuration
   [Anonymous], 17 M VAL
   Bjontegaard G, 2001, 13 VCEG M33 M AUST
   da Silva TL, 2012, EUR SIGNAL PR CONF, P1214
   Fini MR, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P839, DOI 10.1109/ISTEL.2014.7000820
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Kumar V, 2014, IEEE INT ADV COMPUT, P504, DOI 10.1109/IAdCC.2014.6779376
   Kuo YH, 2014, MULTIMED TOOLS APPL, V72, P1803, DOI 10.1007/s11042-013-1480-2
   Lim K, 2012, IEEE T CONSUM ELECTR, V58, P654, DOI 10.1109/TCE.2012.6227473
   Lin HY, 2010, IEEE T CIRC SYST VID, V20, P894, DOI 10.1109/TCSVT.2010.2046059
   Pejman H, 2012, IEEE T CONSUM ELECTR, V58, P1345
   Piao Y, 2010, 3 M GUANGZH
   Quan D, 2010, IEEE T CONSUM ELECTR, V56, P1049, DOI 10.1109/TCE.2010.5506038
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Ting YC, 2014, IEEE INT SYMP CIRC S, P1929, DOI 10.1109/ISCAS.2014.6865538
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
NR 28
TC 15
Z9 16
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7541
EP 7558
DI 10.1007/s11042-015-2675-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600004
DA 2024-07-18
ER

PT J
AU Chung, M
AF Chung, MyoungBeom
TI Effective near advertisement transmission method for smart-devices using
   inaudible high-frequencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High frequency; Near advertisement; Smart device; Inaudible frequency;
   Signal processing; Advertisement transmission method
AB In this paper, we proposed the effective short-distance transmission of advertisements for smart-devices using high-frequencies that are not audible to humans. The existing methods, such as QR codes and NFC tags, for advertisement transmission are problematic, since a specific action is required of the user to obtain the advertising information. Furthermore, only a very near distance is used for advertisement data detection in this case. Alternatively, because the proposed method uses inaudible trigger signals and analyzes the signals using an internal speaker in a smart-device, it can mitigate the above-mentioned challenges of the existing methods. It does not require a specific action of the user to obtain the advertising information and it can be used at a short distance. To evaluate the efficacy of the proposed method, we developed trigger signals, which used the proposed method, for sending and receiving applications. We subsequently tested the developed applications in various situations and at various distances. The success rate of the proposed method was approximately 97 %. We also conducted a survey about user convenience; when they used the proposed method or the QR code, we knew that the proposed method was more useful and convenient than the QR code. Therefore, the proposed method is an effective technique for supplying short-distance advertising information to smart-device users.
C1 [Chung, MyoungBeom] Sungkyul Univ, Div Comp Engn, Anyang 430742, Gyeonggi, South Korea.
C3 Sungkyul University
RP Chung, M (corresponding author), Sungkyul Univ, Div Comp Engn, Anyang 430742, Gyeonggi, South Korea.
EM nzin@ssu.ac.kr
FU Ministry of Education [NRF-2013R1A1A2061478]
FX This research was supported in part by Ministry of Education, under
   Basic Science Research Program(NRF-2013R1A1A2061478), respectively.
CR [Anonymous], EFFECTS QR CODES ADV
   [Anonymous], QR CODE PLUS VIRAL V
   [Anonymous], P 2013 ACM C PERV UB
   [Anonymous], ADVERTISING AGE
   [Anonymous], TAPMEDIA
   [Anonymous], P FH SCI DAY
   [Anonymous], NFC TIMES
   [Anonymous], TAPMEDIA
   [Anonymous], CNET
   [Anonymous], 703MEDIA
   [Anonymous], P 6 INT C ADV HUM OR
   [Anonymous], 2009, The Economist
   Baik S, 2012, MULTIMED TOOLS APPL, V58, P427, DOI 10.1007/s11042-010-0686-9
   Bihler Pascal., 2011, Procedia Computer Science, V5, P586, DOI DOI 10.1016/J.PROCS.2011.07.076
   Canadi M, 2010, INFORMATION AND COMMUNICATION TECHNOLOGIES IN TOURISM 2010, P137, DOI 10.1007/978-3-211-99407-8_12
   Chung MB, 2015, MULTIMED TOOLS APPL, V74, P5955, DOI 10.1007/s11042-014-1901-x
   Chung MB, 2012, ADV INTEL SOFT COMPU, V143, P737
   Filonenko Viacheslav, 2012, Web and Wireless Geographical Information Systems. Proceedings 11th International Symposium, W2GIS 2012, P33, DOI 10.1007/978-3-642-29247-7_4
   Filonenko V., 2010, P INT IND POS IND NA, P1, DOI DOI 10.1109/IPIN.2010.5648235
   김진복, 2012, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V22, P327
   Narang S., 2012, International Journal of Mobile Marketing, P52
   Saminger C, 2013, ELEKTROTECH INFORMAT, V130, P218, DOI 10.1007/s00502-013-0154-0
   Sanchez-Silos Juan J., 2012, Proceedings of the 2012 4th International Workshop on Near Field Communication (NFC), P45, DOI 10.1109/NFC.2012.12
NR 23
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5871
EP 5886
DI 10.1007/s11042-015-2553-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600024
DA 2024-07-18
ER

PT J
AU Huang, W
   Zeng, SR
   Li, J
   Chen, G
AF Huang, Wei
   Zeng, Shuru
   Li, Jing
   Chen, Guang
TI A new image-based immersive tool for dementia diagnosis using pairwise
   ranking and learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-based immersive tool; Dementia disease; Pairwise ranking; Learning
ID ALZHEIMERS-DISEASE
AB Dementia disease is globally acknowledged as one of the most severe non-communicable diseases nowadays. Identifying different stages of dementia disease is significant in its later treatment for delaying the onset and progression of the disease. Among diverse types of tools utilized in dementia disease diagnosis, brain scanning is generally accepted as an effective and affordable way at present. There are several kinds of medical images incorporated in contemporary dementia studies, and magnetic resonance images receives vast popularity. In this study, arterial spin labeling, an emerging perfusion functional-magnetic resonance imaging technique, is adopted in a newly proposed image-based immersive tool for dementia disease diagnosis. Novel pairwise ranking and learning techniques based on a new continuous and differentiable surrogated Kendall-Tau rank correlation coefficient is proposed to realize the immersive tool. Extensive experiments based on a database composed of images acquired from 350 demented patients are carried out with several popular pattern recognition diagnosis tools being compared. Their results undergo rigorous and comprehensive statistical analysis, and the superiority of the newly proposed image-based immersive tool in dementia disease diagnosis has been demonstrated.
C1 [Huang, Wei; Zeng, Shuru; Li, Jing] Nanchang Univ, Sch Informat Engn, Nanchang, Peoples R China.
   [Chen, Guang] Xian Commun Inst, Xian, Peoples R China.
C3 Nanchang University
RP Huang, W (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang, Peoples R China.
EM huangwei@ncu.edu.cn; floraru@163.com; jing.li.2003@gmail.com;
   chenguang322@gmail.com
FU National Natural Science Foundation of China [61403182, 61363046];
   Scientific Research Foundation for Returned Overseas Chinese Scholars,
   Ministry of Education, China [[2014]1685]; Jiangxi Provincial Department
   of Science and Technology, China [20153BCB23029]
FX The authors would like to acknowledge Grants 61403182 and 61363046
   approved by the National Natural Science Foundation of China, Grant
   [2014]1685 approved by the Scientific Research Foundation for Returned
   Overseas Chinese Scholars, Ministry of Education, China, as well as the
   2015 Provincial Young Scientist Program 20153BCB23029 approved by the
   Jiangxi Provincial Department of Science and Technology, China.
CR Asllani I, 2008, MAGN RESON MED, V60, P1362, DOI 10.1002/mrm.21670
   BRANTZAWADZKI M, 1992, RADIOLOGY, V182, P769, DOI 10.1148/radiology.182.3.1535892
   Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381
   Burges C., 2005, ICML, P89
   Chu W., 2005, P INT C MACH LEARN N, P145
   Crammer K, 2002, ADV NEUR IN, V14, P641
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916
   Galton CJ, 2001, NEUROLOGY, V57, P216, DOI 10.1212/WNL.57.2.216
   Gold G, 2005, STROKE, V36, P1184, DOI 10.1161/01.STR.0000166052.89772.b5
   Harrington Edward F, 2003, INT C MACH LEARN ICM, P250
   Herbrich R, 2000, ADV NEUR IN, P115
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Laakso MP, 1996, NEUROLOGY, V46, P678, DOI 10.1212/WNL.46.3.678
   Mahendra B, 1987, DEMENTIA, V1, P189
   Malpass K., 2012, NATURE REV NEUROLOGY, V8, P847
   Mioshi E, 2006, INT J GERIATR PSYCH, V21, P1078, DOI 10.1002/gps.1610
   Musiek ES, 2012, ALZHEIMERS DEMENT, V8, P51, DOI 10.1016/j.jalz.2011.06.003
   Rice JA., 2007, MATH STAT DATA ANAL
   Shashua A., 2002, NIPS, P937
   un, World population prospects
   who, TOP 10 CAUS DEATH, DOI DOI 11/44679/INDEX.HTM
NR 24
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5359
EP 5376
DI 10.1007/s11042-015-2826-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700030
DA 2024-07-18
ER

PT J
AU Gramatikov, S
   Jaureguizar, F
AF Gramatikov, Sasho
   Jaureguizar, Fernando
TI Modelling and analysis of non-cooperative peer-assisted VoD streaming in
   managed networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-assisted streaming; VoD; Stochastic model; Failures; Performance
AB The growing popularity of the Video on Demand service in the Internet Protocol Television environments and the demand for increased quality of the offered videos are becoming a serious threat for the service providers because the high amounts of video traffic are causing congestion in the delivery networks. One of the most acceptable approaches to solve this issue is the peer-assisted streaming, where the peers participate in the streaming process in order to alleviate the load on the streaming servers and in the core of the network. Although the reliability of the Peer-to-Peer service is considerably improved in the managed networks because of the control that the operators have over the clients' Set-Top Boxes, the failures of the peers still cannot be completely eliminated. The operator can take advantage of the streaming and storage resources of the clients and use them for peer-assisted streaming only while they are watching a video, but not after they finish the streaming session because they may turn off their receiving devices until the next session. In this chapter, we address the issue of the failures of the peers in such environments and their influence on the traffic requested from the servers for providing uninterrupted video experience. For that purpose, we propose a precise mathematical tool for modelling a peer-assisted system for Video on Demand streaming in managed networks with non-cooperative peers, which may decide not to share their resources while they are not active. This tool calculates the performance of the system taking into consideration large variety of system parameters, including the failure probability and the time the peers spend until they decide to turn on the STB and join the network. As the results from the simulations verify the correctness of the mathematical model, we use it to analyse how the failures of the peers are affecting the system's performance for different system parameters.
C1 [Gramatikov, Sasho] Univ Ss Cyril & Methodius, Fac Comp Sci & Engn, Skopje 1000, North Macedonia.
   [Jaureguizar, Fernando] Univ Politecn Madrid, ETSI Telecomunicac, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
C3 Saints Cyril & Methodius University of Skopje; Universidad Politecnica
   de Madrid
RP Gramatikov, S (corresponding author), Univ Ss Cyril & Methodius, Fac Comp Sci & Engn, Skopje 1000, North Macedonia.
EM sasho.gramatikov@finki.ukim.mk; fjn@gti.ssr.upm.es
RI Jaureguizar, Fernando/T-7959-2018; Jaureguizar Nuñez,
   Fernando/ITV-1191-2023
OI Jaureguizar, Fernando/0000-0001-6449-5151; 
FU Faculty of Computer Science and Engineering at the "Ss. Cyril and
   Methodius" University
FX This work was partially financed by the Faculty of Computer Science and
   Engineering at the "Ss. Cyril and Methodius" University.
CR [Anonymous], 2013, 2013 IEEE INT C MULT
   Borst S, 2009, BELL LABS TECH J, V14, P113, DOI [10.1002/bltj.20391, 10.1145/1639562.1639591]
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Brosh E, 2009, ARCHITECTURE, P1
   Cha M, 2008, P 7 INT C PEER TO PE, P1
   Chen Y, 2007, P ACM NOSSDAV
   Chen YF, 2009, CAPACITY PROFIT OPTI, V15
   Chen YFR, 2010, MULTIMEDIA SYST, V16, P199, DOI 10.1007/s00530-010-0184-y
   Chesire M, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 3RD USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P1
   Cisco Systems, 2013, CISC VIS NETW IND FO
   Ciullo D, 2014, IEEE T PARALL DISTR, V25, P1852, DOI 10.1109/TPDS.2013.300
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Dyaberi JM, 2010, P 1 ANN ACM SIGMM C, P59
   Fan B, 2006, IEEE ICC, P915
   Gramatikov S, 2013, COMPUT NETW, V57, P2058, DOI 10.1016/j.comnet.2013.04.006
   Guo L, 2006, IEEE T KNOWL DATA EN, V18, P669, DOI 10.1109/TKDE.2006.79
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Jayasundara C, 2011, P IEEE GLOB 2011, P1
   Kerpez K, 2010, INT J DIGITAL MULTIM, P1
   Kleinrock L., 1975, Queuing Systems; Theory, V1
   Korosi A, 2009, P IWQOS, P1
   Krogfoss B, 2008, BELL LABS TECH J, V13, P13, DOI 10.1002/bltj.20320
   Kumar R, 2007, IEEE INFOCOM SER, P919, DOI 10.1109/INFCOM.2007.112
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Lu Y, 2005, ISADS 2005: INTERNATIONAL SYMPOSIUM ON AUTONOMOUS DECENTRALIZED SYSTEMS,PROCEEDINGS, P707, DOI 10.1109/ISADS.2005.1452174
   Lu Y, 2008, IEEE INT SYM MULTIM, P364, DOI 10.1109/ISM.2008.30
   Munoz-Gea J. P., 2012, MULTIMED TOOLS APPL, V59, P1
   Peng Z., 2010, 2010 IEEE INT C MAN, P1
   Qiu DY, 2004, ACM SIGCOMM COMP COM, V34, P367, DOI 10.1145/1030194.1015508
   Ramachandran KK, 2005, IEEE INFOCOM SER, P2159
   Rimac I, 2008, IEEE INT CONF PEER, P321, DOI 10.1109/P2P.2008.41
   Tu Y.C., 2005, ACM TOMCCAP, V1, P354
   Varga A., 2008, An Overview of the Omnet++ Simulation Environment, P1
   Varga A., 2013, INET FRAMEWORK
   Yang MK, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P557
   Zhou YP, 2011, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2011.5935322
NR 37
TC 3
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4321
EP 4348
DI 10.1007/s11042-015-2477-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700008
DA 2024-07-18
ER

PT J
AU Wang, YT
   Zhou, YF
   Liu, D
   Tang, Z
AF Wang, Yongtao
   Zhou, Yafeng
   Liu, Dong
   Tang, Zhi
TI Comic storyboard extraction via edge segment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Comic storyboard extraction; Quadrangle detection; Edge segment
   detection; Line segment detection
ID DETECTOR
AB Comic storyboard extraction aims to decompose the comic image into several storyboards (or frames), which is the key technique to produce the digital comic documents suitable for mobile reading. Previous methods fail either to detect overlapped storyboards or to produce storyboards without blank margins. To tackle these problems, we propose a novel comic storyboard extraction method based on edge segment analysis. First, we extract edge segments (i.e. contiguous chains of Canny edge points) from the input comic image; second, we detect line segments within each obtained edge segment with a top-down scheme; third, we detect storyboards through line segments combination and storyboard validation, and perform post-processing to handle some special cases. We test the proposed method on two datasets comprising 2237 comic pages from 11 printed comic series. Experimental results demonstrate that the proposed method achieves satisfactory results and outperformed the existing methods on the storyboard and page level.
C1 [Wang, Yongtao; Zhou, Yafeng; Liu, Dong; Tang, Zhi] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
C3 Peking University
RP Wang, YT (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM wyt@pku.edu.cn
RI ZHOU, YUN/ISA-9160-2023; ZHOU, yf/IAO-5497-2023
OI ZHOU, YUN/0009-0003-5061-8730; 
FU National Natural Science Foundation of China [61300061]; Beijing Natural
   Science Foundation [4132033]
FX This work is supported by National Natural Science Foundation of China
   under Grant 61300061, and Beijing Natural Science Foundation under Grant
   4132033.
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Anh Khoi Ngo Ho, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P424, DOI 10.1109/DAS.2012.66
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2009, INT J HUMAN COMPUTER
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan CH, 2007, LECT NOTES COMPUT SC, V4810, P775
   Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236
   Han EJ, 2009, J ZHEJIANG UNIV-SC A, V10, P800, DOI 10.1631/jzus.A0820842
   ISHII D, 2010, WORKSH PICT COD IM P, V2010, P124
   Li LY, 2014, MULTIMED TOOLS APPL, V69, P171, DOI 10.1007/s11042-012-1241-7
   Liu D, 2014, DRR 2014
   Liu D, 2014, PROC SPIE, V9069, DOI 10.1117/12.2050864
   Rigaud C., 2011, LECT NOTES COMPUTER, P129, DOI DOI 10.1007/978-3-642-36824-0
   Tanaka T, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2885
   Tolle H., 2010, INT J UBIQUITOUS COM, V1, P1
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Yamada M, 2004, IEICE T INF SYST, VE87D, P1370
NR 17
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2637
EP 2654
DI 10.1007/s11042-015-2680-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000015
DA 2024-07-18
ER

PT J
AU Wang, ZC
   Chen, YF
   Zhu, ZW
   Zhao, WD
AF Wang, Zhicheng
   Chen, Yufei
   Zhu, Zewei
   Zhao, Weidong
TI An automatic panoramic image mosaic method based on graph model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic mosaic; 360 degree-panoramic image generation; Weighted
   shortest path algorithm; Graph model
AB Image mosaic plays an important role in the fields of computer vision, robot navigation and virtual reality, and has become an active research field in recent years. There is a problem that the error will be accumulated and amplified in the case of aligning multi-images. This paper analyzes the looping path problem causing error accumulation, and introduces a multi-image stitching method based on graph model. We name the algorithm Weighted Shortest Path Algorithm, by which images can be stitched automatically. Matching Mean Square Error is introduced as the weight of edges on the graph, which is intuitive and easy to compute. Furthermore, the optimized Dijkstra algorithm is applied to speed up the path finding algorithm. Experiments show that the proposed algorithm causes less Matching Mean Square Error and obtains more stable results than other similar methods. Moreover, we extended our model to 360 A degrees panoramic image generation, and the quality of the stitched panorama is quite good.
C1 [Wang, Zhicheng; Chen, Yufei; Zhu, Zewei; Zhao, Weidong] Tongji Univ, Res Ctr CAD, Shanghai 200092, Peoples R China.
   [Wang, Zhicheng; Chen, Yufei; Zhu, Zewei; Zhao, Weidong] Tongji Univ, Minist Educ, Engn Res Ctr Enterprise Digital Technol, Shanghai 200092, Peoples R China.
C3 Tongji University; Tongji University
RP Chen, YF (corresponding author), Tongji Univ, Res Ctr CAD, Shanghai 200092, Peoples R China.; Chen, YF (corresponding author), Tongji Univ, Minist Educ, Engn Res Ctr Enterprise Digital Technol, Shanghai 200092, Peoples R China.
EM april337@163.com
RI ZHANG, Zhiyong/AAG-3281-2021
OI ZHANG, Zhiyong/0000-0003-3061-7768
FU National Natural Science Foundation of China [61103070]; Shanghai
   Science, Technology Project [13111103100, 12dz1125400]; Science and
   Technology Commission of Shanghai Municipality of China [13111103100,
   12dz1125400]; Young Excellent Talents in Tongji University [2013KJ008]
FX This work was supported by National Natural Science Foundation of China
   (No. 61103070), Shanghai Science, Technology Project (No. 13111103100,
   12dz1125400), the Research Program of Science and Technology Commission
   of Shanghai Municipality of China (Grant No. 12dz1125400, 13111103100),
   and Young Excellent Talents in Tongji University (2013KJ008).
CR [Anonymous], 2014, INT J COMPUT SCI MOB
   [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Geng N., 2012, TELKOMNIKA Indonesian Journal of Electrical Engineering, V10, P2183, DOI [DOI 10.11591/TELKOMNIKA.V10I8.1658, 10.11591/telkomnika.v10i8.1658]
   Gonalez MC, 1998, P BRIT MACH C, DOI [10.5244/C.12.38, DOI 10.5244/C.12.38]
   Hu WC, 2007, P 2007 INT C ADV INF
   Kalayeh HM, 2013, US Patent, Patent No. [8,600,193 B2, 8600193]
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nikolaidis N, 2005, LECT NOTES COMPUT SC, V3746, P716
   Reichmann M, 2009, REALVIZ STITCHER 4 0
   Sakharkar MVS, 2013, INT J COMPUT SCI APP, V6
   Szeliski R, 1997, P 24 ANN C COMP GRAP, P251
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tan YF, 2014, INT CONF ADV COMMUN, P1118, DOI 10.1109/ICACT.2014.6779133
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   [杨小辉 Yang Xiaohui], 2013, [计算机工程, Computer Engineering], V39, P241
   Yi-Li Z, 2013, 2 INT C ADV COMP SCI
   Yongxi G, 2009, J IMAGE GRAPH, V6, P1178
   Zhou H, 2006, LECT NOTES COMPUT SC, V4319, P1206
NR 24
TC 42
Z9 47
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2725
EP 2740
DI 10.1007/s11042-015-2619-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000021
DA 2024-07-18
ER

PT J
AU Epitropou, V
   Bassoukos, T
   Karatzas, K
   Karppinen, A
   Wanner, L
   Vrochidis, S
   Kompatsiaris, I
   Kukkonen, J
AF Epitropou, Victor
   Bassoukos, Tassos
   Karatzas, Kostas
   Karppinen, Ari
   Wanner, Leo
   Vrochidis, Stefanos
   Kompatsiaris, Ioannis
   Kukkonen, Jaakko
TI Environmental data extraction from heatmaps using the AirMerge system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heatmaps; Data retrieval; Air quality; Image processing; Web services;
   GIS
AB The AirMerge platform was designed and constructed to increase the availability and improve the interoperability of heatmap-based environmental data on the Internet. This platform allows data from multiple heterogeneous chemical weather data sources to be continuously collected and archived in a unified repository; all the data in this repository have a common data format and access scheme. In this paper, we address the technical structure and applicability of the AirMerge platform. The platform facilitates personalized information services, and can be used as an environmental information node for other web-based information systems. The results demonstrate the feasibility of this approach and its potential for being applied also in other areas, in which image-based environmental information retrieval will be needed.
C1 [Epitropou, Victor; Bassoukos, Tassos] Aristotle Univ Thessaloniki, Dept Mech Engn, Thessaloniki 54124, Greece.
   [Karppinen, Ari; Kukkonen, Jaakko] Finnish Meteorol Inst, FIN-00101 Helsinki, Finland.
   [Wanner, Leo] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Catalonia, Spain.
   [Wanner, Leo] Catalan Inst Res & Adv Studies ICREA, Barcelona, Catalonia, Spain.
   [Vrochidis, Stefanos; Kompatsiaris, Ioannis] Inst Informat Technol, Ctr Res & Technol Hellas, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki; Finnish Meteorological Institute;
   Pompeu Fabra University; ICREA; Centre for Research & Technology Hellas
RP Epitropou, V (corresponding author), Aristotle Univ Thessaloniki, Dept Mech Engn, Thessaloniki 54124, Greece.
EM vepitrop@isag.meng.auth.gr; abas@isag.meng.auth.gr; kkara@eng.auth.gr;
   ari.karppinen@fmi.fi; leo.wanner@upf.edu; stefanos@iti.gr; ikom@iti.gr;
   jaakko.kukkonen@fmi.fi
RI Karatzas, Kostas/C-1517-2010; Kompatsiaris, Ioannis/P-8594-2015;
   Karppinen, Ari T/J-9860-2013
OI Karatzas, Kostas/0000-0002-1033-5985; Kompatsiaris,
   Ioannis/0000-0001-6447-9020; Wanner, Leo/0000-0002-9446-3748; Karppinen,
   Ari/0000-0003-4592-5640; Vrochidis, Stefanos/0000-0002-2505-9178
FU FMI; PESCaDO; IKY Fellowships of Excellence for Postgraduate Studies in
   Greece-Siemens Program; ICREA Funding Source: Custom
FX AirMerge was developed in the frame of COST Action ES0602, and was
   financially supported by the FMI during the years 2010-2012 and
   co-funded by the PESCaDO project during 2012-2013. This publication was
   supported by the "IKY Fellowships of Excellence for Postgraduate Studies
   in Greece-Siemens Program" at the time of writing.
CR Aalto A., 2012, SCALABILITY COMPLEX
   [Anonymous], 2012, P MAED ACM
   Armenakis C, 2014, P 20 ISPRS C IST, P605
   Balk T, 2011, ATMOS ENVIRON, V45, P6917, DOI 10.1016/j.atmosenv.2010.09.058
   Bassoukos A, 2013, AIRMERGE REMOTE API
   de Smet P, 2013, 20139 EUR TOP CTR AI
   Epitropou Victor, 2012, International Journal of Artificial Intelligence, V9, P152
   Epitropou V, 2012, 8 INT C AIR QUAL SCI, P19
   Epitropou V, 2012, FUSION ENV INFORM DE
   Epitropou V., 2010, P GI FOR S EXH APPL, P58
   European Earth Observation Programme, 2012, PASODOBLE PROJ MYAIR
   European Environment Agency, 2014, AIRBASE EUR AIR QUAL
   Galmarini S, 2013, ATMOS CHEM PHYS, V13, P7153, DOI 10.5194/acp-13-7153-2013
   Karatzas K., 2009, COST ACTION ES0602 Q
   Karatzas Kostas, 2012, P239, DOI 10.1007/978-94-007-1359-8_40
   Khan FH, 2010, INT J COMPUT SCI
   Kukkonen J, 2012, ATMOS CHEM PHYS, V12, P1, DOI 10.5194/acp-12-1-2012
   Moumtzidou A, 2014, ECOL INFORM, V23, P69, DOI 10.1016/j.ecoinf.2013.08.003
   Open Geospatial Consortium, 2013, OGC BEST PRACT US WE
   OSGeo Foundation, 2014, GEOTOOLS INF
   Potempski S, 2009, ATMOS CHEM PHYS, V9, P9471, DOI 10.5194/acp-9-9471-2009
   Riga M, 2014, P 4 INT C WEB INT MI, p[59, 1]
   Snyder J, 1989, 1453 USGS PUBL WAR
   Snyder J, 1987, 1395 USGS PUBL WAR
   Sofiev M, 2006, ATMOS ENVIRON, V40, P674, DOI 10.1016/j.atmosenv.2005.09.069
   Verstraete MM, 2013, INVERSE METHODS GLOB, V1, P125
   Vrochidis S, 2012, IFIP ADV INFORM COMM, P361
   Wanner L., 2012, IFIP ADV INFORM COMM, V382, P351
NR 28
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1589
EP 1613
DI 10.1007/s11042-015-2604-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600015
DA 2024-07-18
ER

PT J
AU Shaukat, U
   Anwar, Z
AF Shaukat, Usman
   Anwar, Zahid
TI A fast and scalable technique for constructing multicast routing trees
   with optimized quality of service using a firefly based genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-objective optimization; Multiple QoS constraints; Multicast
   routing; Genetic algorithm
ID NETWORKS
AB We are seeing an explosive proliferation of multimedia content made available on the Internet. Multimedia applications have a multipartite nature where content has to be disseminated to multiple parties using group communication. Overheads involved in distributing the content through unicast can be overcome by using multicast mode of transmission. Many multimedia applications such as audio-video news streams, stock quotes, live conferences and online gaming require strict Quality-of-service (QoS) guarantees. Optimizing a multicast tree for multiple QoS constraints is a multi-objective NP-hard optimization problem. In this work we propose an optimization that uses modified Genetic Algorithm (GA), a branch of evolutionary computation, to determine near-optimal multicast trees to satisfy multiple QoS constraints such as bandwidth, delay and packet loss. Our modification uses the Firefly effect to reduce the convergence time as well the premature convergence of the GA. Our simulation results show that our proposed algorithm is capable of finding a set of near-optimal multicast trees in computationally feasible time within a few iterations and is much faster than other optimization techniques proposed in research literature. Moreover we show that the protocol is scalable and exhibits a linear increase in processing overhead with the increase in group size.
C1 [Shaukat, Usman; Anwar, Zahid] Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Sect H-12, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Anwar, Z (corresponding author), Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Sect H-12, Islamabad, Pakistan.
EM osman.shaukat@seecs.edu.pk; zahid.anwar@seecs.edu.pk
CR [Anonymous], MULTICAST COMMUNICAT
   Baddi Y, 2014, J MOB MULTIMED, V9, P253
   Banerjea A, 1998, SIGCOMM
   Banerjee N, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-10, CONFERENCE RECORD, P2588, DOI 10.1109/ICC.2001.936617
   Bentley PJ, 1998, SOFT COMPUTING IN ENGINEERING DESIGN AND MANUFACTURING, P231
   Carlberg K., 1997, Computer Communication Review, V27, P5, DOI 10.1145/251007.251008
   Chen YL, 2010, LECT NOTES COMPUT SC, V6382, P211, DOI 10.1007/978-3-642-16493-4_22
   Chuang JCI, 2001, TELECOMMUN SYST, V17, P281, DOI 10.1023/A:1016695006342
   De Rango F, 2007, COMPUT COMMUN, V30, P3126, DOI 10.1016/j.comcom.2007.05.058
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deering SE, 1989, TECHNICAL REPORT
   Feng G, 2006, COMPUT COMMUN, V29, P1811, DOI 10.1016/j.comcom.2005.10.014
   Gavish S, 2003, IEEE T COMMUN, V31, P1154
   Gessel IM, 2006, ELECTRON J COMB, V11
   Guerin R, 1997, IEEE GLOB TEL C GLOB
   Guérin RA, 1999, IEEE ACM T NETWORK, V7, P350, DOI 10.1109/90.779203
   Kompella VP, 1993, IEEE ACM T NETWORK, V1, P286, DOI 10.1109/90.234851
   Koyama A, 2005, 11TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL I, PROCEEDINGS, P655
   Lee DL, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, CONFERENCE PROCEEDINGS, P1290, DOI 10.1109/ICC.2002.997057
   Li X, 2014, CHINA COMMUN, V11, P90, DOI 10.1109/CC.2014.6821741
   Mala C, 2006, COMPUT COMMUN, V29, P3306, DOI 10.1016/j.comcom.2006.05.011
   Oliveira GMB, 2009, IEEE C EVOL COMPUTAT, P182, DOI 10.1109/CEC.2009.4982946
   Patel MK, 2014, AIN SHAMS ENG J, V5, P113, DOI 10.1016/j.asej.2013.07.005
   Peng Cheng, 2009, Frontiers of Electrical and Electronic Engineering in China, V4, P43, DOI 10.1007/s11460-008-0027-1
   Araújo AFR, 2010, APPL INTELL, V32, P330, DOI 10.1007/s10489-008-0148-5
   Riley G.F., 2003, P ACM SIGCOMM WORKSH, P5, DOI [10.1145/944773.944775, DOI 10.1145/944773.944775]
   Roy A, 2004, WIREL NETW, V10, P271, DOI 10.1023/B:WINE.0000023861.10684.f1
   Sahoo S. P., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P17, DOI 10.1109/CSNT.2011.11
   Schulzrinne H, 2003, TECHNICAL REPORT
   Souza A. B., 2013, 2013 International Conference on Information Networking (ICOIN), P101, DOI 10.1109/ICOIN.2013.6496359
   Taomin S, 2006, INT C COMM TECHN P, P1
   Vijayalakshmi K, 2008, COMPUT COMMUN, V31, P3984, DOI 10.1016/j.comcom.2008.08.005
   Vogel R, 1996, IEEE J SEL AREAS COM
   Wang B, 2000, IEEE NETWORK, V14, P22, DOI 10.1109/65.819168
   Wang H, 2010, COMPUT COMMUN, V33, P35, DOI 10.1016/j.comcom.2009.07.015
   Wang XW, 2007, LECT NOTES ARTIF INT, V4456, P115
   Wang XW, 2003, LECT NOTES COMPUT SC, V2834, P404
   Wang Z, 1996, IEEE J SEL AREA COMM, V14, P1228, DOI 10.1109/49.536364
   Yang X. S., 2008, Nature-Inspired Metaheuristic Algorithms, DOI DOI 10.1001/JAMA.1994.03520100096046
   Yen YS, 2008, COMPUT COMMUN, V31, P858, DOI 10.1016/j.comcom.2007.10.033
   Yuan J, 2013, INT SYM COMPUT INTEL, P160, DOI 10.1109/ISCID.2013.47
   Zegura EW, 2000, GT ITM MODELING TOPO
   Zhang QF, 1999, IEEE T EVOLUT COMPUT, V3, P53, DOI 10.1109/4235.752920
NR 43
TC 6
Z9 6
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2275
EP 2301
DI 10.1007/s11042-014-2405-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000025
DA 2024-07-18
ER

PT J
AU Wang, YL
   Guo, P
   Duan, FQ
AF Wang, Yuanlong
   Guo, Ping
   Duan, Fuqing
TI A fast ray tracing algorithm based on a hybrid structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer graphics; Ray tracing; Hybrid structure; Parallel computing;
   CUDA
ID CONSTRUCTION; PARALLEL
AB This paper proposes a new group-based accelerating structure called hybrid structure for the ray tracing of dynamic scenes, whose main advantage is that we can choose a suitable local accelerating structure for each object in the scene. In the hybrid structure, the objects in the scene are organized into a hierarchical bounding volume structure by surface area heuristic (SAH) cost model with each object group node including only one object, and a local accelerating structure is constructed for each object. For a hybrid structure, a scene is divided into static part and dynamic part by the movement, and only dynamic part is updated in each frame. In addition, we design an efficient storage format according to the graphics processing unit (GPU) storage characteristics, which makes it easy to realize the parallel ray tracing on GPU. Experimental results show that the hybrid structure is efficient to deal with the dynamic scene including different kinds of objects, and it can be easily integrated into parallel application systems.
C1 [Wang, Yuanlong; Guo, Ping; Duan, Fuqing] Beijing Normal Univ, Image Proc & Pattern Recognit Lab, Beijing 100875, Peoples R China.
   [Wang, Yuanlong] Shanxi Univ, Taiyuan 030006, Shanxi, Peoples R China.
C3 Beijing Normal University; Shanxi University
RP Guo, P (corresponding author), Beijing Normal Univ, Image Proc & Pattern Recognit Lab, Beijing 100875, Peoples R China.
EM ylwang@mail.bnu.edu.cn; pguo@ieee.org
RI Guo, Peng/GWC-0572-2022; GUO, Ping/AAG-2160-2019; guo,
   peng/AAG-4052-2019; GUO, Ping/A-3482-2015; Guo, Peng/IZQ-0331-2023
OI GUO, Ping/0000-0002-7122-1084; GUO, Ping/0000-0002-7122-1084; 
FU National Natural Science Foundation of China [61375045]; Beijing Natural
   Science Foundation [4142030]
FX The research work described in this paper was fully supported by the
   grants from the National Natural Science Foundation of China (Project
   no. 61375045) and Beijing Natural Science Foundation (Project no.
   4142030). Prof. Ping Guo is the author to whom all correspondence should
   be addressed.
CR [Anonymous], P GRAPH INT
   [Anonymous], P SIGGRAPH 08 LOS AN
   Bikker J, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P1
   Cadet G, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P63, DOI 10.1109/RT.2007.4342592
   Fan Wen-Shan, 2009, Chinese Journal of Computers, V32, P185, DOI 10.3724/SP.J.1016.2009.00185
   FUJIMOTO A, 1986, IEEE COMPUT GRAPH, V6, P16, DOI 10.1109/MCG.1986.276715
   Garanzha K, 2009, COMPUT GRAPH FORUM, V28, P1199, DOI 10.1111/j.1467-8659.2009.01497.x
   GOLDSMITH J, 1987, IEEE COMPUT GRAPH, V7, P14, DOI 10.1109/MCG.1987.276983
   [过洁 GUO Jie], 2011, [电子学报, Acta Electronica Sinica], V39, P1811
   Guo P, 2012, IEEE SYS MAN CYBERN, P2259, DOI 10.1109/ICSMC.2012.6378077
   Hapala M, 2011, COMPUT GRAPH FORUM, V30, P199, DOI 10.1111/j.1467-8659.2010.01844.x
   Havran V., 2001, THESIS
   Hou QM, 2011, IEEE T VIS COMPUT GR, V17, P466, DOI 10.1109/TVCG.2010.88
   Hunt W, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P81
   Ize T., 2007, P EUR S PAR GRAPH VI, P101
   Kalojanov J, 2009, P HIGH PERF GRAPH, P1
   Kang YS, 2011, J SYST ARCHITECT, V10, P1
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P579, DOI 10.1145/1141911.1141926
   Lext J., 2001, EUR 2001 SHORT PRES, P311
   Li Jing, 2009, Chinese Journal of Computers, V32, P1172, DOI 10.3724/SP.J.1016.2009.01172
   Morley RK, 2006, PROC GRAPH INTERF, P179
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Popov S, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P89
   Shevtsov M, 2007, P GRAPH COMP
   Shevtsov M, 2007, COMPUT GRAPH FORUM, V26, P395, DOI 10.1111/j.1467-8659.2007.01062.x
   Wachter C., 2006, Proceedings of the Eurographics Symposium on Rendering, P139, DOI DOI 10.2312/EGWR/EGSR06/139-149
   Wald I, 2008, COMPUT GRAPH-UK, V32, P3, DOI 10.1016/j.cag.2007.11.004
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Wu Zhefeng, 2011, P ACM SIGGRAPH S HIG, P71, DOI DOI 10.1145/2018323.2018335
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 30
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1883
EP 1898
DI 10.1007/s11042-014-2378-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000007
DA 2024-07-18
ER

PT J
AU Du, YJ
   Lu, XB
   Chen, L
   Zeng, WL
AF Du, Yijun
   Lu, Xiaobo
   Chen, Lin
   Zeng, Weili
TI An interval type-2 T-S fuzzy classification system based on PSO and SVM
   for gender recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interval type-2 T-S fuzzy system; Support vector machine; Fuzzy ISODATA;
   Particle swarm optimization
ID NEURAL-NETWORK; GENETIC ALGORITHMS; LOGIC SYSTEMS; OPTIMIZATION;
   EVOLUTION; ORDER; FACE; SETS
AB In this paper, an interval type-2 Takagi-Sugeno fuzzy classification system (IT2T-SFCS) learned by particle swarm optimization (PSO) and support vector machine (SVM) for antecedent and consequent parameters optimization is proposed. The IT2T-SFCS is constructed by fuzzy if-then rules whose antecedents are interval type-2 fuzzy sets and consequents are linear state equations. The antecedents of IT2T-SFCS use the fuzzy iterative self-organizing data analysis technique (ISODATA) and PSO to learn and calculate the optimal centers and the uncertain widths of the Gaussian membership functions. Consequent parameters in IT2T-SFCS are learned through SVM for the purpose of achieving higher generalization ability. The proposed IT2T-SFCS is able to directly handle uncertainties, minimize the effects of uncertainties and get the better generalization performance, which inherits the benefits of interval type-2 T-S fuzzy system and SVM. For demonstration, IT2T-SFCS is used as a classifier in gender recognition. The experimental results show that the performance of the proposed IT2T-SFCS is superior to that of the previous mainstream classifiers.
C1 [Du, Yijun; Lu, Xiaobo; Chen, Lin; Zeng, Weili] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Du, Yijun; Lu, Xiaobo; Chen, Lin; Zeng, Weili] Southeast Univ, Minist Educ, Key Lab Measurement & Control CSE, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control CSE, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
OI Zeng, Weili/0000-0002-5266-2423
FU National Natural Science Foundation of China [61374194, 61403081]; China
   Postdoctoral Science Foundation Founded Project [2013 M540405]; Natural
   Science Foundation of Jiangsu Province [BK20140638]; Special Program of
   China Postdoctoral Science Foundation [2014T70454]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61374194), the National Natural Science Foundation of China
   (No. 61403081), China Postdoctoral Science Foundation Founded Project
   (No. 2013 M540405), the Natural Science Foundation of Jiangsu Province
   (No. BK20140638), and Special Program of China Postdoctoral Science
   Foundation (No. 2014T70454).
CR Bartlett P, 1999, ADVANCES IN KERNEL METHODS, P43
   Belhumeur P. N., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P45
   Biglarbegian M, 2010, IEEE T SYST MAN CY B, V40, P798, DOI 10.1109/TSMCB.2009.2029986
   Birge B, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P182, DOI 10.1109/SIS.2003.1202265
   García JC, 2011, ADV INTEL SOFT COMPU, V91, P257
   Castillo O, 2008, STUD FUZZ SOFT COMP, V223, P187
   Castillo O., 2012, STUD FUZZINESS SOFT, V27, P173
   Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843
   Chiang JH, 2004, IEEE T FUZZY SYST, V12, P1, DOI 10.1109/TFUZZ.2003.817839
   Chih-Chung C, 2011, ACM T INTELL SYST TE, V2
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Eberhart R. C., 1998, Evolutionary Programming VII. 7th International Conference, EP98. Proceedings, P611, DOI 10.1007/BFb0040812
   Garibaldi JM, 2007, IEEE T FUZZY SYST, V15, P16, DOI 10.1109/TFUZZ.2006.889755
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Juang CF, 2002, IEEE T FUZZY SYST, V10, P155, DOI 10.1109/91.995118
   Juang CF, 1998, IEEE T FUZZY SYST, V6, P12, DOI 10.1109/91.660805
   Juang CF, 2007, IEEE T SYST MAN CY A, V37, P1077, DOI 10.1109/TSMCA.2007.904579
   Juang CF, 2007, IEEE T FUZZY SYST, V15, P998, DOI 10.1109/TFUZZ.2007.894980
   Juang CF, 2012, IEEE T IND ELECTRON, V59, P3309, DOI 10.1109/TIE.2011.2159949
   Karnik NN, 1999, IEEE T FUZZY SYST, V7, P643, DOI 10.1109/91.811231
   Karnik NN, 2001, FUZZY SET SYST, V122, P327, DOI 10.1016/S0165-0114(00)00079-8
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kim J, 2002, IEEE DECIS CONTR P, P1349, DOI 10.1109/CDC.2002.1184703
   KOSKO B, 1994, IEEE T COMPUT, V43, P1329, DOI 10.1109/12.324566
   Liang QL, 2000, IEEE T FUZZY SYST, V8, P535, DOI 10.1109/91.873577
   Lin CT, 2006, IEEE T FUZZY SYST, V14, P31, DOI 10.1109/TFUZZ.2005.861604
   LIN CT, 2004, P IEEE S CIRC SYST, P724
   Liu QJ, 2012, NEUROCOMPUTING, V85, P29, DOI 10.1016/j.neucom.2012.01.005
   Masood S, 2013, MULTIMED TOOLS APPL, V63, P93, DOI 10.1007/s11042-012-1015-2
   Melin P, 2013, FUZZINESS STUD FUZZI, V299, P435
   Mendel JM, 2006, IEEE T FUZZY SYST, V14, P808, DOI 10.1109/TFUZZ.2006.879986
   Mendel JM, 2007, INFORM SCIENCES, V177, P84, DOI 10.1016/j.ins.2006.05.003
   Mendel JM, 2009, INFORM SCIENCES, V179, P3418, DOI 10.1016/j.ins.2009.05.008
   Mendel JM, 2000, SIGNAL PROCESS, V80, P913, DOI 10.1016/S0165-1684(00)00011-6
   Muni DP, 2012, FUZZY INF ENG, V4, P29, DOI 10.1007/s12543-012-0099-8
   Naim S, 2014, SOFT COMPUT, V18, P1305, DOI 10.1007/s00500-013-1145-0
   Own CM, 2009, APPL INTELL, V31, P283, DOI 10.1007/s10489-008-0126-y
   Pankaj DS, 2011, COMM COM INF SC, V203, P53
   Patel PB, 2012, COMM COM INF SC, V311, P21
   Qilian Liang, 1999, FUZZ-IEEE'99. 1999 IEEE International Fuzzy Systems. Conference Proceedings (Cat. No.99CH36315), P1534, DOI 10.1109/FUZZY.1999.790132
   Rai P., 2012, Advances in Computer Science, Engineering Applications, P51, DOI [DOI 10.1007/978-3-642-30157-56, 10.1007/978-3-642-30157-56]
   Ren Q, 2012, INT J ADV MANUF TECH, V63, P1057, DOI 10.1007/s00170-012-3956-z
   Roh SB, 2010, FUZZY SET SYST, V161, P1803, DOI 10.1016/j.fss.2009.10.014
   Sánchez D, 2014, STUD COMPUT INTELL, V547, P19, DOI 10.1007/978-3-319-05170-3_2
   Smiatacz M, 2013, ADV INTELL SYST, V226, P187, DOI 10.1007/978-3-319-00969-8_18
   Sun Z, 2014, INT J ELEC POWER, V62, P19, DOI 10.1016/j.ijepes.2014.04.022
   Vapnik V., 1999, NATURE STAT LEARNING
   Zeng J, 2006, IEEE T FUZZY SYST, V14, P454, DOI 10.1109/TFUZZ.2006.876366
   Zhao LA, 2010, COMM COM INF SC, V98, P230
   Zhou WH, 2013, ADV INTELL SYST, V180, P583
NR 50
TC 13
Z9 13
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 987
EP 1007
DI 10.1007/s11042-014-2338-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700014
DA 2024-07-18
ER

PT J
AU Jia, XB
   Huang, HY
   Sun, YF
   Yuan, JM
   Powers, DMW
AF Jia, Xibin
   Huang, Haiyong
   Sun, Yanfeng
   Yuan, Jianming
   Powers, David M. W.
TI A novel edge detection approach using a fusion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge detection; Fusion; Most probable distribution; Voting count
   scorematrix; Difference score matrix
ID ENHANCEMENT
AB Edge detection is a long standing but still challenging problem. Although there are many effective edge detectors, none of them can obtain ideal edges in every situation. To make the results robust for any image, we propose a new edge detection algorithm based on a two-level fusion model that combines several typical edge detectors together with new proposed edge estimation strategies. At the first level, we select three typical but diverse edge detectors. The edge score is calculated for every pixel in the image based on a consensus measurement by counting positive voting number of approaches. Then results are combined at the second level using the Hadamard product with two additional edge estimations proposed in the paper, based on edge spatial characteristics, where one is binary matrix of the most probable edge distribution and the other is a score matrix based on calculating differences between maxima and minima neighboring intensity change at each point. Comprehensive experiments are conducted on two image databases, and three evaluation methods are employed to measure the performance, viz. F1-measure, ROC and PFOM. Experiments results show that our proposed method outperforms the three standard baseline edge detectors and shows better results than a state-of-the-art method.
C1 [Jia, Xibin; Huang, Haiyong; Sun, Yanfeng; Yuan, Jianming; Powers, David M. W.] Beijing Univ Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
   [Powers, David M. W.] Flinders Univ South Australia, Sch Comp Sci Engn & Math, Adelaide, SA, Australia.
C3 Beijing University of Technology; Flinders University South Australia
RP Jia, XB (corresponding author), Beijing Univ Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
EM jiaxibin@bjut.edu.cn; haiyong_huang@emails.bjut.edu.cn;
   yfsun@bjut.edu.cn; letsrocking@emails.bjut.edu.cn;
   david.powers@flinders.edu.au
RI jia, xibin/AAE-6620-2022; sun, huan/JEO-7152-2023; Powers,
   David/A-7698-2011
OI Powers, David/0000-0001-5998-2262
FU Chinese Natural Science Foundation [61070117, 61171169]; Beijing Natural
   Science Foundation [4122004, 4132013]; Importation and Development of
   High-Caliber Talents Project of Beijing Municipal Institutions
FX We appreciate the support of the Chinese Natural Science Foundation
   under Grant No. 61070117, No. 61171169 and the Beijing Natural Science
   Foundation under Grant No. 4122004, No. 4132013 and the Importation and
   Development of High-Caliber Talents Project of Beijing Municipal
   Institutions.
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fernández-García NL, 2008, IMAGE VISION COMPUT, V26, P496, DOI 10.1016/j.imavis.2007.06.009
   Gao W, 3 IEEE INT C COMP SC, P67
   JULESZ B, 1959, AT&T TECH J, V38, P1001, DOI 10.1002/j.1538-7305.1959.tb01586.x
   Laligant O, 2007, IEEE SIGNAL PROC LET, V14, P185, DOI 10.1109/LSP.2006.884030
   Laligant O, 2010, IEEE T PATTERN ANAL, V32, P242, DOI 10.1109/TPAMI.2008.282
   Lewis T.W., 2004, P 27 AUSTRALASIAN C, V26, P305
   Luo RC, 2002, IEEE SENS J, V2, P107, DOI 10.1109/JSEN.2002.1000251
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Mathworks, 2002, IM PROC TOOLB US MAT
   Melgani F, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2194767
   Novak CL., 1987, P DARPA IMAGE UNDERS, V1, P35
   Ou Y, 2011, PROCEDIA ENG, V15, P2439
   Powers DMW, 2013, 10 INT C INF CONTR A
   Powers DMW, 2012, SPRING C ENG TECHN S
   Prewitt J.M.S., 1970, OBJECT ENHANCEMENT E
   Ren J, 2010, IET IMAGE PROCESS, V4, P294, DOI 10.1049/iet-ipr.2009.0071
   Roberts LG, 1963, TR315 MIT LEX LINC L
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sobel I, 1970, AIM121 STANF U CAL D
   Swets J.A., 1995, SIGNAL DETECTION THE
   Yitzhaky Y, 2003, IEEE T PATTERN ANAL, V25, P1027, DOI 10.1109/TPAMI.2003.1217608
NR 27
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1099
EP 1133
DI 10.1007/s11042-014-2359-6
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700019
DA 2024-07-18
ER

PT J
AU Agarwal, H
   Atrey, PK
   Raman, B
AF Agarwal, Himanshu
   Atrey, Pradeep K.
   Raman, Balasubramanian
TI Image watermarking in real oriented wavelet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking scheme; Non-blind watermarking scheme; Quotient
   remainder theorem; Real oriented wavelet transform; Dual tree complex
   wavelet transform
ID AUTHENTICATION
AB In this paper, we propose blind and non-blind watermarking schemes in the real oriented wavelet transform (ROWT) domain. The ROWT, which is a member of the dual tree complex wavelet transform (DTCWT) family, is chosen as a watermarking domain since the DTCWT has recently emerged as an important new image processing tool. Existing watermarking schemes based on the DTCWT usually lack high embedding capacity. This is mainly due to the fact that the left inverse and the right inverse of the DTCWT (including the ROWT) are not equal. We have observed a relation when the ROWT follows its left inverse, and have used this relation to develop two watermarking schemes in the ROWT domain. Experimental results show that the proposed ROWT based watermarking schemes not only have a much higher capacity than the existing DTCWT based watermarking schemes, but are also robust to various image modification operations such as cropping, Gaussian filter, Gaussian noise, and salt and pepper noise.
C1 [Agarwal, Himanshu] Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
   [Atrey, Pradeep K.] SUNY Albany, Dept Comp Sci, Coll Comp & Informat, Albany, NY 12222 USA.
   [Raman, Balasubramanian] Indian Inst Technol, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; State University of New York (SUNY) System;
   State University of New York (SUNY) Albany; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Roorkee
RP Agarwal, H (corresponding author), Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM him11dma@iitr.ac.in; pkatrey@gmail.com; balarfma@iitr.ac.in
RI Agarwal, Himanshu/D-2825-2017
OI Agarwal, Himanshu/0000-0002-9950-7447
FU University Grants Commission (UGC) of New Delhi, India; Canadian Bureau
   for International Education under Canadian Commonwealth Scholarship
   Program
FX One of the authors, Himanshu Agarwal, acknowledges the University Grants
   Commission (UGC) of New Delhi, India for granting him a scholarship
   under the JRF scheme for his research. He also acknowledges the grant
   from the Canadian Bureau for International Education under the Canadian
   Commonwealth Scholarship Program.
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P6897, DOI 10.1007/s11042-014-1934-1
   [Anonymous], INT C IM PROC IEEE V
   [Anonymous], P INT C AC SPEECH SI
   [Anonymous], ACOUST SPEECH SIG PR
   [Anonymous], 2 D DUAL TREE WAVELE
   [Anonymous], P INT C IM PROC VANC
   [Anonymous], P WORKSH MULT SEC
   [Anonymous], IEEE 2 WORKSH MULT S
   [Anonymous], P 7 IND C COMP VIS G
   [Anonymous], P INT C IM PROC IEEE
   [Anonymous], P INT C IM PROC IEEE
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V52, P621, DOI 10.1007/s11042-009-0433-2
   Coria LE, 2008, IEEE T INF FOREN SEC, V3, P466, DOI 10.1109/TIFS.2008.927421
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Khan A, 2012, INFORM SCIENCES, V216, P155, DOI 10.1016/j.ins.2012.06.014
   Kim WG, 2009, SIGNAL PROCESS, V89, P2385, DOI 10.1016/j.sigpro.2009.04.014
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   Korus P, 2012, MULTIMED TOOLS APPL, P1
   Kumar S, 2013, INT J WAVELETS MULTI, V11, DOI 10.1142/S0219691313500045
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lin TC, 2009, INFORM SCIENCES, V179, P3349, DOI 10.1016/j.ins.2009.05.022
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Magarey J, 1998, IEEE T SIGNAL PROCES, V46, P1069, DOI 10.1109/78.668557
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mohanty SP, 2009, J SYST ARCHITECT, V55, P468, DOI 10.1016/j.sysarc.2009.09.005
   Mohanty SP, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1029, DOI 10.1109/ICME.2000.871535
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shi X, 2013, INFORM SCIENCES, V240, P173, DOI 10.1016/j.ins.2013.03.031
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Suhail MA, 2003, INFORM SCIENCES, V151, P93, DOI 10.1016/S0020-0255(02)00291-8
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Yang HJ, 2011, LECT NOTES COMPUT SC, V6730, P18, DOI 10.1007/978-3-642-24556-5_2
NR 44
TC 14
Z9 14
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10883
EP 10921
DI 10.1007/s11042-014-2212-y
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700034
DA 2024-07-18
ER

PT J
AU Dawood, H
   Dawood, H
   Guo, P
AF Dawood, Hassan
   Dawood, Hussain
   Guo, Ping
TI Removal of random-valued impulse noise by local statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Impulse noise; Random-valued impulse noise; Local similarity; Local
   statistics; Optimal direction
ID MEDIAN FILTERS; REDUCTION METHOD
AB In this paper, a new method for the identification and removal of random-valued impulse noise (RVIN) from images is proposed. We propose to identify the central pixel of the current sliding window as a noisy or noise free pixel based on the similar local statistics of the current window. Our proposed RVIN identifier works in an iterative way. Pixel identified as a noisy pixel is replaced by proposed minimum difference similar value in an optimal directions. The performance of the proposed method is evaluated on different test images and compared with state-of-the-art methods. Experimental results show that the proposed method cannot only identify the impulse noise efficiently, but can also preserve the detailed information of an image.
C1 [Dawood, Hassan; Dawood, Hussain; Guo, Ping] Beijing Normal Univ, Lab Image Proc & Pattern Recognit, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Guo, P (corresponding author), Beijing Normal Univ, Lab Image Proc & Pattern Recognit, Beijing 100875, Peoples R China.
EM hasandawod@yahoo.com; hussaindawood2002@yahoo.com; pguo@ieee.org
RI Guo, Peng/IZQ-0331-2023; GUO, Ping/A-3482-2015; guo, peng/AAG-4052-2019;
   Guo, Peng/GWC-0572-2022; GUO, Ping/AAG-2160-2019; Dawood,
   Hassan/AAZ-8114-2021; Dawood, Hussain/G-7453-2017
OI GUO, Ping/0000-0002-7122-1084; GUO, Ping/0000-0002-7122-1084; Dawood,
   Hassan/0000-0003-1355-6457; Dawood, Hussain/0000-0003-2653-9541
FU Natural Science Foundation of China [61375045]; Beijing Natural Science
   Foundation [4142030]
FX The research work described in this paper was fully supported by the
   grants from the Natural Science Foundation of China (Project No.
   61375045) and Beijing Natural Science Foundation(4142030). Prof. Ping
   Guo is the author to whom all correspondence should be addressed.
CR Akkoul S, 2010, IEEE SIGNAL PROC LET, V17, P587, DOI 10.1109/LSP.2010.2048646
   Caiquan JLX, 2008, J HUAZHONG U SCI TEC, V005, P8
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE T CIRCUITS-II, V48, P784, DOI 10.1109/82.959870
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Masood S., 2013, MULTIMED TOOLS APPL, P1
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Russo F, 1996, IEEE SIGNAL PROC LET, V3, P168, DOI 10.1109/97.503279
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Turkmen Ilke, 2013, AEU INT J ELECT COMM
   Wan Y, 2010, IEEE SIGNAL PROC LET, V17, P485, DOI 10.1109/LSP.2010.2044848
NR 18
TC 23
Z9 23
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11485
EP 11498
DI 10.1007/s11042-014-2246-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600023
DA 2024-07-18
ER

PT J
AU Pei, LS
   Ye, M
   Xu, P
   Li, T
AF Pei, Lishen
   Ye, Mao
   Xu, Pei
   Li, Tao
TI Fast multi-class action recognition by querying inverted index tables
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Inverted index table; State binary tree;
   Shape-motion feature
ID SHAPE
AB A fast inverted index based algorithm is proposed for multi-class action recognition. This approach represents an action as a sequence of action states. Here, the action states are cluster centers of the extracted shape-motion features. At first, we compute the shape-motion features of a tracked actor. Secondly, a state binary tree is built by hierarchically clustering the extracted features. Then the training videos are represented as sequences of action states by searching the state binary tree. Based on the labeled state sequences, we create a state inverted index table and a state transition inverted index table. During testing, after representing a new action video as a state sequence, the state and state transition scores are computed by querying the inverted index tables. With the weight trained by the validation set, we get an action class score vector. The recognized action class label is the index of the maximum component of the score vector. Our key contribution is that we propose a fast multi-class action recognition approach based on two inverted index tables. Experiments on several challenging data sets confirm the performance of this approach.
C1 [Pei, Lishen; Ye, Mao; Xu, Pei; Li, Tao] Univ Elect Sci & Technol China, Minist Educ, Key Lab NeuroInformat, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Ye, M (corresponding author), Univ Elect Sci & Technol China, Minist Educ, Key Lab NeuroInformat, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
EM pls.cvlab@gmail.com; cvlab.uestc@gmail.com; xupei268@gmail.com;
   cvlablitao@gmail.com
RI Ye, Mao/K-3012-2019
OI Ye, Mao/0000-0001-9253-1332; Ye, Mao/0000-0003-4760-8702
FU National Natural Science Foundation of China [61375038]
FX This work was supported in part by the National Natural Science
   Foundation of China (61375038).
CR Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   [Anonymous], 2007, PROC IEEE C COMPUT V
   [Anonymous], 2003, NONLINEAR PROGRAMMIN
   [Anonymous], 1987, FIELD MANUAL FM, P21
   [Anonymous], 2005, PRACTICAL MATH OPTIM
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2008, P IEEE INT C COMP VI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587730
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bocker Alexander., 2004, Hierarchical k-means clustering. Manual
   Chen B, 2010, IEEE INT WORKSH NEUR
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Elgammal A, 2003, PROC CVPR IEEE, P571
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Mikolajczyk K., 2008, IEEE C COMP VIS PATT
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Nister David, 2006, CVPR
   Pei L., 2013, IEEE INT C IM PROC
   Pei LS, 2014, MULTIMED TOOLS APPL, V72, P1751, DOI 10.1007/s11042-013-1478-9
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Reddy KK, 2009, IEEE I CONF COMP VIS, P1010, DOI 10.1109/ICCV.2009.5459374
   Rodriguez M., 2008, IEEE INT C COMP VIS, P3361
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Wang B, 2012, MACH VISION APPL, V9, P905
   Wang Y, 2007, LECT NOTES COMPUT SC, V4814, P240
   Weinland D., 2008, CVPR, P1
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zou WY, 2012, IEEE C NEUR INF PROC
NR 38
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10801
EP 10822
DI 10.1007/s11042-014-2207-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700030
DA 2024-07-18
ER

PT J
AU Wang, F
   Chang, CC
   Lyu, WL
AF Wang, Feng
   Chang, Chin-Chen
   Lyu, Wan-Li
TI The credit card visual authentication scheme based on
   <i>GF</i>(2<SUP>8</SUP>) field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Credit card; Authentication; One-time credit card transaction number;
   Image processing technique; Binary field; QR decomposition
AB Recently, with the popular use of the credit cards, credit card fraud has become a severe problem. Merchants suffer great losses from credit card fraud. In this paper, we focus on "chip and signature" card, propose a credit card visual authentication scheme to resist lost and stolen card attack and protect the benefits of merchants. Inspired from the QR decomposition, we introduce image processing techniques to credit card transactions at POS terminals in order to ensure that the payer is the real cardholder, which gives an approach for credit card authentication. Our proposed scheme combines a one-time credit card transaction number and image processing techniques without changing the cardholders' transaction habit. We use a hash function to generate a one-time credit card transaction number with the shared secret only known to the cardholder and the bank, and a mathematical method of GF(2(8)) to solve the image problem, which will provide a math tool on image research. Analysis and comparison show that our scheme is secure in practical applications.
C1 [Wang, Feng] Fujian Univ Technol, Dept Math & Phys, Fuzhou 350108, Fujian, Peoples R China.
   [Chang, Chin-Chen; Lyu, Wan-Li] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Lyu, Wan-Li] Anhui Univ, Sch Comp Sci & Technol, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei 230039, Peoples R China.
C3 Fujian University of Technology; Feng Chia University; Asia University
   Taiwan; Anhui University
RP Wang, F (corresponding author), Fujian Univ Technol, Dept Math & Phys, Fuzhou 350108, Fujian, Peoples R China.
EM w.h.feng@163.com; alan3c@gmail.com; lwl@ahu.edu.cn
RI Chang, Ching-Chun/JAN-6210-2023
CR [Anonymous], 2001, FEDERAL INFORM PROCE, V180-2
   [Anonymous], REP CARD FRAUD
   [Anonymous], 2001, FEDERAL INFORM PROCE, V197
   Bhatla T.P., 2003, CARDS BUSINESS REV
   EMVCo, 2011, EMV INT CIRC CARD SP
   Hankerson Darrel, 2006, Guide to Elliptic Curve Cryptography
   Li CT, 2013, IET INFORM SECUR, V7, P3, DOI 10.1049/iet-ifs.2012.0058
   Li XH, 2000, IEEE T SIGNAL PROCES, V48, P60
   Li YJ, 2005, ELECTRON COMMER R A, V4, P413, DOI 10.1016/j.elerap.2005.06.002
   Lu S., 1999, MASCOTS '99. Proceedings of the Seventh International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems, P358, DOI 10.1109/MASCOT.1999.805074
   Mao W., 2004, Modern cryptography theory and practice
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Pashalidis A, 2004, LECT NOTES COMPUT SC, V3093, P205
   Rubin AD, 2002, LECT NOTES COMPUT SC, V2339, P196
   SHAMIR A, 2001, P FIN CRYPT, P232
   Strang, 2009, Introduction to linear algebra
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Sullivan R.J., 2013, Economic Review, P59
   Watson EJ., 1962, MATH COMPUT, V16, P368
   Weaver AC, 2006, COMPUTER, V39, P88, DOI 10.1109/MC.2006.138
NR 20
TC 1
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11451
EP 11465
DI 10.1007/s11042-014-2238-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600021
DA 2024-07-18
ER

PT J
AU Wang, XY
   Hou, CP
   Pu, LZ
   Hou, YH
AF Wang, Xiaoyan
   Hou, Chunping
   Pu, Liangzhou
   Hou, Yonghong
TI A depth estimating method from a single image using FoE CRF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Field of experts (FoE); Conditional random field (CRF); Non-stationary
   spatially variance; Minimum mean square error (MMSE)
AB A high-order conditional random field (CRF) for depth estimation from a single image is proposed in this paper. Instead of formulating the problem with the Guassian or Laplacian CRF modeling techniques, which cannot exploit the full potential offered by the probabilistic modeling, this paper proposes a depth estimation CRF model with field of experts (FoE) as the prior. The minimum mean square error (MMSE) criteria is used to infer depth. Moreover, it is assumed that the variance of depth estimation error varies spatially in depth estimation model. This allows the proposed method to enjoy the benefits offered by the flexible prior and have the advantages of making use of the non-stationary variance probability model. Experimental results indicate that the proposed method outperforms state-of-the-art approaches in terms of RMSE-error and log10-error.
C1 [Wang, Xiaoyan; Hou, Chunping; Pu, Liangzhou; Hou, Yonghong] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Wang, XY (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM wangxytju@163.com
RI hou, yonghong/N-9255-2013
FU National Natural Science Foundation of China [60932007]; National 863
   Programm [2012AA03A301]; Ph.D. Programs Foundation of Ministry of
   Education of China [20110032110029]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 60932007, by National 863 Programm (No. 2012AA03A301),
   and by Ph.D. Programs Foundation of Ministry of Education of China (No.
   20110032110029).
CR [Anonymous], 2010, IEEE C EVOLUTIONARY, DOI DOI 10.1109/CEC.2010.5585957
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   Batra D., 2012, P IEEE C COMP VIS PA
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Huang JG, 2000, PROC CVPR IEEE, P324, DOI 10.1109/CVPR.2000.855836
   Karsch K, 2012, P 12 EUR C COMP VIS
   LAFFERTY J, 2001, INT C MACH LEARN ICM
   Li C, 2011, P ADV NEUR INF PROC
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Ranipa K, 2011, P IEEE MACH LEARN SI
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Sakuragi K, 2010, P INT C SIGN PROC
   Saxena A., 2005, P ADV NEURAL INFORM
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Tosic I, 2011, IEEE J-STSP, V5, P941, DOI 10.1109/JSTSP.2011.2158063
   Zhang HC, 2012, IEEE T IMAGE PROCESS, V21, P4054, DOI 10.1109/TIP.2012.2199330
NR 20
TC 9
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9491
EP 9506
DI 10.1007/s11042-014-2130-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200020
DA 2024-07-18
ER

PT J
AU Antón, P
   Maña, A
   Muñoz, A
   Koshutanski, H
AF Anton, Pablo
   Mana, Antonio
   Munoz, Antonio
   Koshutanski, Hristo
TI An immersive view approach by secure interactive multimedia
   proof-of-concept implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual window; Immersive view; Multimedia security; Ambient assisted
   living
AB Live media streaming is a field that recently has had a great impact in the scientific community, especially in the case of interactive media streaming. In this paper we propose a reference architecture conceptualizing an immersive view effect by considering heterogeneous tracking devices and enriched movement control over heterogeneous stream image sources. A proof-of-concept prototype implementation of the reference architecture is presented, called Live Interactive FramE (LIFE), illustrating the potential and value of the immersive view concept. Our work is part of the DESEOS research project that aims at applying an Ambient Assisted Living paradigm to a targeted scenario of hospitalised children. The main goal of LIFE is reducing stress and isolation during hospitalisation by enabling an immersive view of school activities via live media streaming. Functional and security aspects of LIFE are presented along with details of implementation and performance evaluation. Conclusions of experiments show that LIFE enables practical secure media streaming solution with optimal video quality settings.
C1 [Anton, Pablo; Mana, Antonio; Munoz, Antonio; Koshutanski, Hristo] ETSI Informat, Malaga 29071, Spain.
RP Antón, P (corresponding author), ETSI Informat, Campus Teatinos, Malaga 29071, Spain.
EM panton@lcc.uma.es; amg@lcc.uma.es; amunoz@lcc.uma.es; hristo@lcc.uma.es
RI Maña Gómez, Antonio/R-4661-2019; Muñoz, Antonio/AAG-7997-2020
OI Maña Gómez, Antonio/0000-0001-5291-6174; Muñoz,
   Antonio/0000-0002-6751-0625; Koshutanski, Hristo/0000-0002-0660-0635
FU DESEOS Dispositivos Electronicos Seguros para la Educacion, Ocio y
   Socializacion - government of Andalucia [TIC-4257]
FX This work is supported by the project DESEOS (TIC-4257) Dispositivos
   Electronicos Seguros para la Educacion, Ocio y Socializacion (meaning
   "secure electronic devices for education, entertainment and
   socialization") funded by the government of Andalucia.
CR Amos B, 1978, P C REM SYST TECHN U
   [Anonymous], INFLUENCIA I CRECIMI
   Antón P, 2011, LECT NOTES COMPUT SC, V6693, P92, DOI 10.1007/978-3-642-21303-8_13
   Antón P, 2012, J AMB INTEL HUM COMP, V3, P177, DOI 10.1007/s12652-010-0039-6
   APTEKER RT, 1995, IEEE MULTIMEDIA, V2, P32, DOI 10.1109/93.410510
   Baugher M., 2004, SECURE REAL TIME TRA
   Chen W, 2010, J APPL SCI ENG, V13, P215
   Clarke MM, 1982, P HUM FACT ERG SOC A, V26, P763
   Costa R, 2009, ADV SOFT COMP, V51, P86
   Dowden DC, 1998, BELL LABS TECH J, V3, P3, DOI 10.1002/bltj.2125
   Gaver W. W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P257
   Gheorghe G, 2011, PEER PEER NETW APPL, V4, P75, DOI 10.1007/s12083-010-0070-6
   Giles Jim., 2010, New Scientist, V208, P22, DOI DOI 10.1016/S0262-4079(10)62989-2
   Hanke S, 2011, ADV TECHNOL SOC CH, P127, DOI 10.1007/978-3-642-18167-2_10
   INGEBRETSEN M, 2010, IEEE INTELL SYST, V25, P4
   Kuhn DR, 2001, TECHNICAL REPORT
   Lee JC, 2008, IEEE PERVAS COMPUT, V7, P39, DOI 10.1109/MPRV.2008.53
   Li YM, 2010, IEEE IMAGE PROC, P4325, DOI 10.1109/ICIP.2010.5652437
   Liao RT, 2007, IITA 2007: WORKSHOP ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, PROCEEDINGS, P95, DOI 10.1109/IITA.2007.9
   Locklin Maryanne, 2005, Pediatr Nurs, V31, P474
   Marples D, 2001, IEEE COMMUN MAG, V39, P110, DOI 10.1109/35.968820
   Overbeeke CJ, 1988, THESIS TU DELFT
   Rosenberg J., 2002, TECHNICAL REPORT
   Schulzrinne H., 2003, RFC 3550, DOI 10.17487/RFC3550
   Schulzrinne H., 1998, 2326 RFC
   Tazari MR, 2010, HANDBOOK OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS, P1171, DOI 10.1007/978-0-387-93808-0_43
   Dinh T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3786, DOI 10.1109/IROS.2009.5353915
   Widener P, 2003, 19TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P396, DOI 10.1109/CSAC.2003.1254344
   Yingjie G, 2013, TECHNICAL REPORT
NR 29
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8401
EP 8420
DI 10.1007/s11042-013-1682-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600010
DA 2024-07-18
ER

PT J
AU Li, J
   Zhang, MM
   Pan, ZG
   Wang, SB
   Yan, Z
AF Li Jun
   Zhang Mingmin
   Pan Zhigeng
   Wang Shengbo
   Yan Zheng
TI Creating real body model of dressed human based on fat extent of body
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D body scanning; Shape estimation; Morphing; Quadratic programming
ID HUMAN BODIES; SHAPE; SCANS; POSE
AB The paper presents a method to estimate real body shape of dressed human. In the method we build a function to describe the fat extent of every vertex on the body. The fat extent is relative to the slim body template and the fat body template. Using the fat function and two templates a synthesizing model is created. The 3D scans of dressed human obtained by kinects are used to calculate the fat extents of feature rings on the bodies, and the results are used as the control points to build the fat function. We construct two databases corresponding to the persons wearing winter clothes and summer clothes respectively. The two databases consist of the fat extents of the feature rings on the naked bodies and on the 3D scans of dressed human. According the current season and the corresponding database, considering the proportional relations about these feature rings' fat extents as restrictions, the real body of dressed human can be estimated with quadratic programming. The experiments demonstrate the availability of our method.
C1 [Li Jun; Zhang Mingmin] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Pan Zhigeng; Wang Shengbo; Yan Zheng] Hangzhou Normal Univ, Int Serv Coll, Hangzhou 310036, Zhejiang, Peoples R China.
   [Li Jun] Com & Games Technol Co Ltd, Hangzhou High Tech R&D Ctr Jilin VIXO Animat, Hangzhou 310012, Zhejiang, Peoples R China.
C3 Zhejiang University; Hangzhou Normal University
RP Li, J (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM lijunchiron@163.com
RI zhang, mm/IWV-4201-2023; Zhang, Miao/JXY-8985-2024
FU NSFC [61173124, 61170318, 61332017]; national project [2013BAH24F00]
FX The authors acknowledge the supports from NSFC (Grant No. 61173124 and
   61170318), key project of NSFC (Grant No. 61332017) and the national
   project (Grant No. 2013BAH24F00).
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2007, IEEE C COMPUTER VISI
   Balan AO, 2008, LECT NOTES COMPUT SC, V5303, P15, DOI 10.1007/978-3-540-88688-4_2
   Chang W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966405
   Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x
   Cui Yan, 2011, ACM SIGGRAPH 2011 NE, P57
   Furukawa T, 2000, LECT NOTES ARTIF INT, V1834, P159
   Guan P, 2009, IEEE I CONF COMP VIS, P1381, DOI 10.1109/iccv.2009.5459300
   Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x
   Hasler N, 2007, LECT NOTES COMPUT SC, V4418, P200
   Hasler N, 2010, PROC CVPR IEEE, P1823, DOI 10.1109/CVPR.2010.5539853
   Hasler N, 2009, COMPUT GRAPH-UK, V33, P211, DOI 10.1016/j.cag.2009.03.026
   Liao M, 2009, IEEE I CONF COMP VIS, P167, DOI 10.1109/ICCV.2009.5459161
   Magnenat-Thalmann N, 2004, J COMPUT SCI TECH-CH, V19, P575, DOI 10.1007/BF02945583
   Magnenat-Thalmann N, 2008, LECT NOTES COMPUT SC, V5277, P63
   Seo H, 2003, EUROGRAPHICS SIGGRAP, V2003, P120
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863
NR 21
TC 3
Z9 3
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6951
EP 6966
DI 10.1007/s11042-014-1947-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800017
DA 2024-07-18
ER

PT J
AU Aihara, K
   Aoki, T
AF Aihara, Kazuaki
   Aoki, Terumasa
TI Motion dense sampling and component clustering for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; YouTube detaset; Bag-of-features; Interest point
   detection; Clustering
ID HISTOGRAMS
AB In this paper, we propose Motion Dense Sampling (MDS) for action recognition, which detects very informative interest points from video frames. MDS has three advantages compared to other existing methods. The first advantage is that MDS detects only interest points which belong to action regions of all regions of a video frame. The second one is that it can detect the constant number of points even when the size of action region in an image drastically changes. The Third one is that MDS enables to describe scale invariant features by computing sampling scale for each frame based on the size of action regions. Thus, our method detects much more informative interest points from videos unlike other methods. We also propose Category Clustering and Component Clustering, which generate the very effective codebook for action recognition. Experimental results show a significant improvement over existing methods on YouTube dataset. Our method achieves 87.5 % accuracy for video classification by using only one descriptor.
C1 [Aihara, Kazuaki] Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, Sendai, Miyagi 9800845, Japan.
   [Aoki, Terumasa] Tohoku Univ, New Ind Creat Hatchery Ctr, Aoba Ku, Sendai, Miyagi 9800845, Japan.
C3 Tohoku University; Tohoku University
RP Aihara, K (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-6-10 Aramaki, Sendai, Miyagi 9800845, Japan.
EM aihara@riec.tohoku.ac.jp; aoki@riec.tohoku.ac.jp
CR [Anonymous], BMVC
   [Anonymous], 2006, ECCV
   [Anonymous], 2008, P 2008 IEEE C COMP V
   [Anonymous], 2005, CVPR
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Guha S., 1998, CURE, P73, DOI DOI 10.1145/276305.276312
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Nagendar G., 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P479, DOI 10.1007/978-3-642-37431-9_37
NR 21
TC 6
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6303
EP 6321
DI 10.1007/s11042-014-2112-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700012
OA hybrid
DA 2024-07-18
ER

PT J
AU Fu, ZY
   Zhang, P
   Huang, W
   Wang, L
   Emmanuel, S
   Chen, G
AF Fu, Zhaoyang
   Zhang, Peng
   Huang, Wei
   Wang, Liang
   Emmanuel, Sabu
   Chen, Guang
TI Empirical mode decomposition based blind audio watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind audio watermarking; Multiple watermarks; Empirical mode
   decomposition (EMD); Psychoacoustic model; Analysis filterbank
   decomposition
ID SPECTRUM
AB Multiparty-multilevel digital rights management of audio requires blind detection of multiple watermarks. The proposed audio watermarking method offers copyright protection based on analysis filterbank decomposition, psychoacoustic model and empirical mode decomposition (EMD). The novel blind audio watermarking algorithm embeds the watermark bits in the final residue of the subbands in the transform domain. The watermarking system performance is optimized by selecting appropriate segment length for applying EMD process and by selecting the number of subbands for watermark embedding. Experimental results show that the proposed scheme is robust against various common signal processing manipulations while multiple watermark messages can be embedded.
C1 [Fu, Zhaoyang] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   [Zhang, Peng] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Huang, Wei] Nanchang Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
   [Wang, Liang; Emmanuel, Sabu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Chen, Guang] Xian Commun Inst, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Nanchang University; Nanyang Technological University
RP Zhang, P (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM fuzy@nwpu.edu.cn; zh0036ng@nwpu.edu.cn; huangwei@ncu.edu.cn;
   mail.liang.wang@gmail.com; asemmanuel@ntu.edu.sg; chenguang322@gmail.com
RI Emmanuel, Sabu/A-3690-2011; zhang, yueqi/JXM-4287-2024; Fu,
   ZHAOYANG/JVY-7184-2024; Zhang, Penghui/HGB-7353-2022
OI Zhang, Penghui/0000-0002-9518-7079
FU National Natural Science Foundation of China [61301194, 61363046];
   Ministry of Education, China [20126102120055]
FX This work is supported by the national grants No. 61301194 and No.
   61363046 approved by the National Natural Science Foundation of China,
   as well as the doctoral program of High Education of China No.
   20126102120055 approved by the Ministry of Education, China.
CR [Anonymous], 2008, DIGITAL AUDIO WATERM
   [Anonymous], 111723 ISOIEC IS
   Arnold M, 2001, FIRST INTERNATIONAL CONFERENCE ON WEB DELIVERING OF MUSIC, PROCEEDINGS, P4, DOI 10.1109/WDM.2001.990152
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bi N, 2007, IEEE T IMAGE PROCESS, V16, P1956, DOI 10.1109/TIP.2007.901206
   Cheng S, 2002, INT CONF ACOUST SPEE, P3728
   Chou W, 2003, PATTERN RECOGNITION IN SPEECH AND LANGUAGE PROCESSING, P1
   Cox I. J., 2002, Digital Watermarking
   Cox IJ., 2007, DIGITAL WATERMARKING
   Cvejic N, 2004, SIGNAL PROCESS, V84, P207, DOI 10.1016/j.sigpro.2003.10.016
   Cvejic N, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P227, DOI 10.1109/ASPAA.2001.969584
   Cvejic N, 2004, ALGORITHM AUDIO WATE
   El Hamdouni N, 2010, 4 INT S COMM CONTR S, P1
   El Hamdouni N, 2013, MULTIMED TOOLS APPL, V64, P809, DOI 10.1007/s11042-012-0988-1
   Gold B., 1999, SPEECH AUDIO SIGNAL
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Haykin S., 1998, Digital communication
   He X, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P393
   He X., 2008, WATERMARKING AUDIO K
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang W, 2010, J SIGNAL PROCESS SYS, V59, P143, DOI 10.1007/s11265-008-0294-3
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Liang H, 2005, COMPUT NEUROSCI TREN, V65-66, P805
   Liu Z, 2003, IEEE T CIRC SYST VID, V13, P801, DOI 10.1109/TCSVT.2003.815960
   Pressnitzer D., 2004, Auditory Signal Processing: Physiology, Psychoacoustics, and Models
   Seok JW, 2001, ELECTRON LETT, V37, P60, DOI 10.1049/el:20010029
   Shih F.Y., 2008, Digital Watermarking and Steganography: Fundamentals and Techniques
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Thomas T, 2009, IEEE T INF FOREN SEC, V4, P758, DOI 10.1109/TIFS.2009.2033229
   Wang L, 2010, P IEEE INT C MULT EX
   Wang Y, 2007, P SPIE SECURITY STEG
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Yang H, 2010, MULTIMEDIA TOOLS APP
   Zaman A. N. K., 2010, 2010 Fifth International Conference on Digital Information Management (ICDIM 2010), P1, DOI 10.1109/ICDIM.2010.5664669
NR 37
TC 2
Z9 2
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 6019
EP 6040
DI 10.1007/s11042-014-1905-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100032
DA 2024-07-18
ER

PT J
AU Hardy, S
   Dutz, T
   Wiemeyer, J
   Göbel, S
   Steinmetz, R
AF Hardy, Sandro
   Dutz, Tim
   Wiemeyer, Josef
   Goebel, Stefan
   Steinmetz, Ralf
TI Framework for personalized and adaptive game-based training programs in
   health sport
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious Games; Health; Exergames; Training; Personalization; Adaptation;
   Sensors
ID EXERCISE
AB This paper describes an interdisciplinary approach towards a framework for personalized, game-based training programs for elderly and handicapped people. Adaptation and personalization are proposed as a way to increase the physiological training effects of game-based training programs (exergames). Hereby, the diversity of users and a broad range of physiological handicaps are considered. The framework is based on scientific training programs enhanced by technical methods and concepts for personalized exergames. This includes an authoring environment (StoryTec) which supports game designers and domain experts (sport scientists, medical doctors, therapists, etc.) in the development process and the (personalized) configuration of such exergames. Two prototypically implemented applications (ErgoActive and BalanceFit) demonstrate the usability and adaptation of the underlying training and game concepts for different user groups and provide indicators of the effectiveness and efficiency of the generic framework for particular user groups. For instance, ErgoActive is applicable for people of all ages and both trained and untrained users by being able to provide personalized training levels to improve endurance. Similarly, BalanceFit is useful both for wheelchair and walking frame users in order to maintain and possibly even increase their balance, strength and muscular coordination.
C1 [Hardy, Sandro; Dutz, Tim; Goebel, Stefan; Steinmetz, Ralf] Tech Univ Darmstadt, Multimedia Commun Lab KOM, D-64283 Darmstadt, Germany.
   [Wiemeyer, Josef] Tech Univ Darmstadt, Inst Sport Sci, D-64289 Darmstadt, Germany.
C3 Technical University of Darmstadt; Technical University of Darmstadt
RP Hardy, S (corresponding author), Tech Univ Darmstadt, Multimedia Commun Lab KOM, Rundeturmstr 10, D-64283 Darmstadt, Germany.
EM sandro.hardy@kom.tu-darmstadt.de
RI Steinmetz, Patrick R. H./AAD-4093-2022
OI Steinmetz, Ralf/0000-0002-6839-9359; Wiemeyer, Josef/0000-0003-2958-7653
FU German Ministry of Education and Research; Wilhelmine-Thoss-Foundation
FX The authoring tool StoryTec used for this research has been extended by
   a template for exergames in the research project Motivotion60+ funded by
   the German Ministry of Education and Research. BalanceFit has been
   developed in cooperation with the Hessian Telemedia Technology and
   Competence Center and has been supported by the
   Wilhelmine-Thoss-Foundation.
CR [Anonymous], 2012, INT J COMPUT SCI SPO
   [Anonymous], 2009, Global recommendations on physical activity for health
   Baranowski T, 2008, AM J PREV MED, V34, P74, DOI 10.1016/j.amepre.2007.09.027
   Borg G, 1998, BORGS PERCIVED EXERT
   Bos J, 2006, HDB GESUNDHEITSSPORT
   Brehm W, 2005, FITNESS GESUNDHEITST, P37
   Brumels KA., 2008, CLIN KINESIOL, V62, P26
   Gobel S, 2011, P ECGBL 2011 5 EUR C
   Gobel Stefan., 2010, International Multimedia Conference. Association for Computing Machinery, P1663, DOI [DOI 10.1145/1873951.1874316, 10.1145/1873951.1874316]
   Haskell WL, 2007, MED SCI SPORT EXER, V39, P1423, DOI [10.1249/mss.0b013e3180616b27, 10.1161/CIRCULATIONAHA.107.185649]
   Heitkamp H-C, 2003, SPORT TRAININGSSTEUE, P161
   Jung Y., 2009, Proceedings of the Sixth Australasian Conference on Interactive Entertainment, p5:1, DOI DOI 10.1145/1746050.1746055
   Kato PM, 2008, PEDIATRICS, V122, pE305, DOI 10.1542/peds.2007-3134
   Kliem K., 2010, INT J COMPUTER SCI S, V9, P80
   Korn O., 2013, Serious Games Virtual Worlds Educ. Prof. Dev. Healthc, P258
   Lambert EV, 2005, BRIT J SPORT MED, V39, P52, DOI 10.1136/bjsm.2003.011247
   Mehm F., 2009, P 1 INT OPEN WORKSHO, V1, P113
   Mehm F, 2010, P 5 INT C FDN DIG GA, P271, DOI DOI 10.1145/1822348.1822390
   Memh F., 2011, P 19 ACM INT C MULT, P807, DOI DOI 10.1145/2072298.2072469
   Nacke L, 2009, BLEKINGE I TECHNOLOG, P1653
   Opper E, 2006, ZIELGRUPPENSPEZIFISC, P154
   Pfeifer K, 2005, QUALITATSMANAGEMENT, P21
   Robergs R., 2002, J Exerc Physiol Online, V5, P1, DOI DOI 10.1097/00005768-200205001-00429
   Roth K, 1998, METHODEN IM SPORT
   Sinclair J., 2009, proceedings of the sixth australasian conference on interactive entertainment, P1, DOI [DOI 10.1145/1746050.1746061, 10.1145/1746050.1746061]
   Sinclair J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P289
   Stolovitch HD, 1980, ED TECHNOLOGY
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Sygusch R, 2005, DEUT Z SPORTMED, V56, P318
   Tanaka H, 2001, J AM COLL CARDIOL, V37, P153, DOI 10.1016/S0735-1097(00)01054-8
   Weineck J, 2000, Optimales training
NR 31
TC 35
Z9 35
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5289
EP 5311
DI 10.1007/s11042-014-2009-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900020
DA 2024-07-18
ER

PT J
AU Khalil, M
   Adib, A
AF Khalil, Mohammed
   Adib, Abdellah
TI Informed audio watermarking based on adaptive carrier modulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Informed audio watermarking; Adaptive carrier modulation; Frequency
   selection; Error correcting code; Psychoacoustic
ID ALGORITHM
AB Generally audio watermarking schemes based on spread spectrum modulations (SSM) are the most widely used because they show desirable performance in terms of watermark inaudibility and robustness. However, an analysis about performance of carrier modulations (CM) have not been provided sufficiently in the literature. In this paper, we propose a new informed audio watermarking system based on carrier modulations. This system makes the watermark imperceptible by exploiting the audio masking characteristics of the Human Auditory System (HAS) with an adaptation of the carrier modulated signal parameters. The algorithm takes advantage of a new strategy to select the best watermark parameters in order to conciliate inaudibility and detection of the embedded message. Moreover, error-correcting coding is applied to the watermark to increase its robustness against various disturbances. In order to demonstrate the effectiveness of the proposed scheme compared to existing spread spectrum ones, simulations under various conditions are conducted. They testify good transparency of the watermark, high detection reliability and a great resistance against many perturbations for different types of audio signals.
C1 [Khalil, Mohammed; Adib, Abdellah] LIM II FSTM, Mohammadia 20650, Morocco.
RP Khalil, M (corresponding author), LIM II FSTM, BP 146, Mohammadia 20650, Morocco.
EM medkhalil87@gmail.com; adib@fstm.ac.ma
RI ADIB, Abdellah/HTQ-2801-2023
OI ADIB, Abdellah/0000-0002-0670-7221; Khalil, Mohammed/0000-0002-4211-1011
CR [Anonymous], 2001, Communication Systems
   Baras C, 2006, IEEE T AUDIO SPEECH, V14, P1772, DOI 10.1109/TASL.2006.879808
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   Cvejic N, 2004, SIGNAL PROCESS, V84, P207, DOI 10.1016/j.sigpro.2003.10.016
   Cvejic N, 2007, DIGITAL AUDIO WATERM
   Cvejic N, 2002, EUR SIGN PROC C
   Cvejic N, 2001, IEEE WORKSH APPL SIG
   Derrien O, 2000, ANN TELECOMMUN, V55, P442
   El Hamdouni N, 2011, J MULTIMED TOOLS APP
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   International Telecommunication Union, 2001, METH OBJ MEAS PERC A
   Kalantari NK, 2009, IEEE T AUDIO SPEECH
   Khalil Mohammed, 2012, Image and Signal Processing. Proceedings 5th International Conference, ICISP 2012, P282, DOI 10.1007/978-3-642-31254-0_32
   Khalil M, 2013, GRETSI IN PRESS
   Khalil M, 2013, EUSIPCO IN PRESS
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   KIROVSKI D, 2002, IEEE T SIGNAL PROCES
   Kondo K., 2012, INT C INT INF HID MU
   Kumar SK, 2007, SIGNAL PROCESS, V87, P61, DOI 10.1016/j.sigpro.2006.04.005
   LARBI S, 2004, IEEE INT C AC SPEECH
   Latif A, 2013, J INF HIDING MULTIME, V4
   Li L, 2013, J INF HIDING MULTIME, V4
   Li W, 2006, IEEE T MULTIMED, V8
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Mahdavi S, 2010, P ICEE
   Miller ML, 2004, IEEE T IMAGE PROCESS, V13, P792, DOI 10.1109/TIP.2003.821551
   Moore B. C. J., 1997, INTRO PSYCHOL HEARIN
   OZAWA K, 1993, J ACOUST SOC AM, V93, P1007, DOI 10.1121/1.405548
   Pinel J., 2010, 20 INT C AC ICA 2010
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Seok J, 2002, ETRI J, V24, P181, DOI 10.4218/etrij.02.0102.0301
   Yee HH, 2009, AUDIO WATERMARKING E
   Zwicker E., 1999, PSYCHOACOUSTICS FACT, V2nd, DOI DOI 10.1007/978-3-662-09562-1
NR 38
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5973
EP 5993
DI 10.1007/s11042-014-1902-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100030
DA 2024-07-18
ER

PT J
AU Lu, L
   Zhan, YJ
   Jiang, Q
   Cai, QL
AF Lu, Lu
   Zhan, Yi-Ju
   Jiang, Qing
   Cai, Qing-ling
TI A method for action recognition based on pose and interest points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Interest points; Particle filter; Pose estimation
AB In recent years, action recognition has become a hot research topic in the image processing area. Some studies have shown that based on supervised learning, spatial-temporal interest points which are extracted from videos demonstrate good performance in human action recognition. In this paper, we define the attributes of human pose, and associate human pose with interest points for human action recognition. We find that interest points can be used as samplers of the particle filter method, and improve the precision of pose estimation. Human pose can be used to detect outliers in interest points, and improve the precision of action recognition. Location and density of interest points associated with human pose can also improve the precision of action recognition. Experiment results on the publicly available "Weizmann", "KTH" and "UIUC" dataset demonstrate that our method outperforms the state-of-the-art methods.
C1 [Lu, Lu; Zhan, Yi-Ju; Jiang, Qing; Cai, Qing-ling] Sun Yat Sen Univ, Sch Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Lu] GuangDong Univ Business Studies, Sch Math, Guangzhou 510320, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Guangdong University of Finance & Economics
RP Zhan, YJ (corresponding author), Sun Yat Sen Univ, Sch Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM zyjsysu@126.com
RI Jiang, Qing/JXM-6827-2024
OI Jiang, Qing/0000-0002-2552-9686
CR [Anonymous], 2008, P IEEE COMP SOC C CO
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Chakraborty B, 2011, IEEE I CONF COMP VIS, P1776, DOI 10.1109/ICCV.2011.6126443
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   DEFREITAS N, 2001, SMC PRACTICE
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Ferrari V, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2009.5206495
   Foley J.D., 1990, Computer graphics: Principles and practice
   Hess R, 2009, PROC CVPR IEEE, P240, DOI 10.1109/CVPRW.2009.5206801
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liu J., 2008, P IEEE C COMP VIS PA, DOI [10.1109/cvpr.2008.4587723, DOI 10.1109/CVPR.2008.4587723]
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Tran D, 2010, P EUR C COMP VIS, V5302, P548
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60
NR 22
TC 0
Z9 0
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 6091
EP 6109
DI 10.1007/s11042-014-1910-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100035
DA 2024-07-18
ER

PT J
AU Zhan, YZ
   Sun, JY
   Niu, DJ
   Mao, QR
   Fan, JP
AF Zhan, Yongzhao
   Sun, Jiayao
   Niu, Dejiao
   Mao, Qirong
   Fan, Jianping
TI A semi-supervised incremental learning method based on adaptive
   probabilistic hypergraph for video semantic detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive probabilistic hypergraph; Semi-supervised learning; Incremental
   learning; Video semantic detection
AB Semantic categorization for the complex videos is an ambiguous task. The semi-supervised learning method based on hypergraph model can achieve multi-semantics labels, but a hypergraph model is sensitive to the radius parameter when it is constructed and the number of vertices belonging to a hyperedge is fixed. In this paper, a semi-supervised incremental learning method based on adaptive probabilistic hypergraph for video semantic detection is presented. In the probabilistic hypergraph modeling, a formula is presented as a measurement to adaptively decide whether a vertex is belonged to a hyperedge or not. The model has high robustness and can overcome the defect of fixed number of vertices belonging to the same hyperedge in the traditional probabilistic hypergraph model. In the semi-supervised incremental learning process, a threshold is defined, which is used to judge whether unlabeled sample can be added into the modeling, in order that the model learning result for unlabeled samples has high certainty. The experimental results show that our method can improve the model generalization ability and utilize the unlabeled samples effectively. In the aspects of recall rate and precision rate for semantic video concept detection from complex videos, our proposed method outperforms the compared methods.
C1 [Zhan, Yongzhao; Sun, Jiayao; Niu, Dejiao; Mao, Qirong] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
   [Fan, Jianping] UNC Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 Jiangsu University; University of North Carolina; University of North
   Carolina Charlotte
RP Zhan, YZ (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
EM yzzhan@ujs.edu.cn; sunjiayao_99@163.com; djniu@ujs.edu.cn;
   mao_qr@ujs.edu.cn; jfan@uncc.edn
RI sun, jiayao/KHU-2565-2024
FU National Natural Science Foundation of China [61170126]
FX This work is supported by the National Natural Science Foundation of
   China No. 61170126.
CR Ayers D, 2001, IMAGE VISION COMPUT, V19, P833, DOI 10.1016/S0262-8856(01)00047-6
   Chen G, 2009, PROC CVPR IEEE, P1658, DOI 10.1109/CVPRW.2009.5206813
   Chien JT, 2008, IEEE T AUDIO SPEECH, V16, P198, DOI 10.1109/TASL.2007.909452
   Chou TC, 2008, IEEE T KNOWL DATA EN, V20, P289, DOI 10.1109/TKDE.2007.190702
   Duan XH, 2013, IEEE T MULTIMEDIA, V15, P167, DOI 10.1109/TMM.2012.2225029
   El-Ghazal A, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P318, DOI 10.1109/ISM.2009.97
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Guo PF, 2010, INT CONF BIOMED, P2990, DOI 10.1109/BMEI.2010.5639829
   Haishan Liu, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P398, DOI 10.1109/ICDM.2011.12
   Han YH, 2010, J ZHEJIANG U-SCI C, V11, P525, DOI 10.1631/jzus.C0910453
   Huang YC, 2011, IEEE T PATTERN ANAL, V33, P1266, DOI 10.1109/TPAMI.2011.25
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Li XH, 2011, COMPUT HUM BEHAV, V27, P1571, DOI 10.1016/j.chb.2010.11.002
   Lin L, 2009, PATTERN RECOGN LETT, V30, P180, DOI 10.1016/j.patrec.2008.02.023
   Liu QS, 2011, PATTERN RECOGN, V44, P2255, DOI 10.1016/j.patcog.2010.07.014
   Liu Yan Liu Yan, 2011, Asian Agricultural Research, V3, P8
   Meng T, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P144, DOI 10.1109/IRI.2012.6303003
   Perse M, 2009, COMPUT VIS IMAGE UND, V113, P612, DOI 10.1016/j.cviu.2008.03.001
   Ren Mei, 2012, Journal of Computer Applications, V32, P3014, DOI 10.3724/SP.J.1087.2012.03014
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Wang YY, 2012, IEEE T NEUR NET LEAR, V23, P689, DOI 10.1109/TNNLS.2012.2186825
   Yi-Ding Wang, 2011, Proceedings of the 2011 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR 2011), P214, DOI 10.1109/ICWAPR.2011.6014480
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zha ZJ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1321, DOI 10.1109/ICME.2008.4607686
   Zou YX, 2011, MULTIMED TOOLS APPL, V52, P133, DOI 10.1007/s11042-010-0466-6
NR 25
TC 4
Z9 6
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5513
EP 5531
DI 10.1007/s11042-014-1866-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100007
DA 2024-07-18
ER

PT J
AU Hsieh, CW
   Liu, HC
   Chen, CY
   Chou, YH
   Tiu, CM
   Hsu, YC
   Chan, DY
AF Hsieh, Chi-Wen
   Liu, Hsiao-Chuan
   Chen, Chih-Yen
   Chou, Yi-Hong
   Tiu, Chui-Mei
   Hsu, Ying-Che
   Chan, Din-Yuen
TI An investigation of pixel resonance phenomenon in color imaging: the
   multiple interpretations of people with color vision deficiency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple interpretations; Color vision deficiency; Ishihara
   pseudoisochromatic test plates; Monte Carlo; Randomwalk; Stochastic
   resonance; Pixel resonance
AB Multiple interpretations of behavior in human vision lead us to a dissimilar comprehension. The perceivable vision of normal people and dichromats were simulated by confusion lines and co-punctal points on the CIE chromaticity diagram to interpret the concept of multiple interpretations. In addition, the new principle of pixel resonance (PR) was proposed to aid dichromats in recognizing the correct objects from a variegated background. In this study, the principle of PR, which is mainly derived from the stochastic resonance (SR) theory, was slightly introduced as the opening of the research. A Monte Carlo simulation of random walks is a common method used to achieve the SR conception by simulating an experiment of the photon casting process. This process is analogous to how people prioritize and understand certain parts of a scene or an image. The concept of PR applied to intensity imaging was introduced in Section 2. Next, an extension of the theory of PR conception was applied to color imaging in Section 3. In addition, we proposed a creative method to simulate an Ishihara pseudoisochromatic test plate using three procedures: circle pattern construction, color sampling and luminance placement. The visual simulations of dichromats and normal people were realized by confusion lines and co-punctal points to obtain multiple interpretations. Finally, the PR phenomenon on the simulated Ishihara pseudoisochromatic test plates was discussed. The results of the current study showed that the PR phenomenon for the perceivable vision of normal people and tritanopes, but not for protanopes and deuteranopes, can be meaningfully observed. In conclusion, the application of PR presents meaningful results for tritanopes. This research can be applied to clinics to assist people with color vision deficiency in recognizing the correct number.
C1 [Hsieh, Chi-Wen; Chan, Din-Yuen] Natl Chia Yi Univ, Dept Elect Engn, Chiayi 60004, Taiwan.
   [Liu, Hsiao-Chuan] Natl Taiwan Univ, Inst Biomed Engn, Taipei 100, Taiwan.
   [Liu, Hsiao-Chuan; Chou, Yi-Hong; Tiu, Chui-Mei] Taipei Vet Gen Hosp, Dept Radiol, Taipei 112, Taiwan.
   [Chen, Chih-Yen] Natl Appl Res Labs, Instrument Technol Res Ctr, Hsinchu 300, Taiwan.
   [Chou, Yi-Hong; Tiu, Chui-Mei] Natl Yang Ming Univ, Sch Med, Taipei 112, Taiwan.
   [Tiu, Chui-Mei] Lotung Poh Ai Hosp, Luodong Township 265, Yilan County, Taiwan.
   [Tiu, Chui-Mei] Ching Chyuan Hosp, Taichung 428, Taiwan.
   [Hsu, Ying-Che] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 30013, Taiwan.
C3 National Chiayi University; National Taiwan University; Taipei Veterans
   General Hospital; National Applied Research Laboratories - Taiwan;
   National Yang Ming Chiao Tung University; National Tsing Hua University
RP Chen, CY (corresponding author), Natl Appl Res Labs, Instrument Technol Res Ctr, 20 R&D Rd 6,Hsinchu Sci Pk, Hsinchu 300, Taiwan.
EM chiwen@mail.ncyu.edu.tw; tcliu0615@gmail.com; chihyenorama@gmail.com;
   yhchou@vghtpe.gov.tw; cmtiu@vghtpe.gov.tw; ychsu@mx.nthu.edu.tw;
   dychan@mail.ncyu.edu.tw
CR Anishchenko VS., 2007, Nonlinear Dynamics of Chaotic and Stochastic Systems
   [Anonymous], J MOD OPT
   [Anonymous], SIMULATION MONTE CAR
   Attarchi MS, 2010, NEUROTOXICOL TERATOL, V32, P558, DOI 10.1016/j.ntt.2010.05.003
   Biedeman I, 1987, PSYCHOL REV, V94, P5
   Birch J, 1997, OPHTHAL PHYSL OPT, V17, P403, DOI 10.1111/j.1475-1313.1997.tb00072.x
   Brettel H, 1997, J OPT SOC AM A, V14, P2647, DOI 10.1364/JOSAA.14.002647
   Cheng CM, 1994, ADV STUD CHIN LANG P, V20, P183
   Dai HP, 2010, J EXP PSYCHOL HUMAN, V36, P976, DOI 10.1037/a0017171
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hammersley J.M., 1975, Monte Carlo Methods
   Hsieh CW, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P59, DOI 10.1109/MUE.2009.22
   Judd DB., 1975, Color in business, science, and industry /
   Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713
   Lee DY, 2003, COLOR RES APPL, V28, P267, DOI 10.1002/col.10161
   Logvinenko AD, 2011, J VISION, V11, DOI 10.1167/11.8.6
   Noudoost B, 2010, CURR OPIN NEUROBIOL, V9, P353
   Peelen MV, 2009, NATURE, V460, P94, DOI 10.1038/nature08103
   Pitt FHG, 1944, PROC R SOC SER B-BIO, V132, P101, DOI 10.1098/rspb.1944.0006
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Szirmay-Kalos L., 2000, MONTE CARLO METHODS
   Truchetet F, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2957606
   Verghese P, 2001, NEURON, V31, P523, DOI 10.1016/S0896-6273(01)00392-0
   Vienot F, 2000, P SPIE SAN JOS, P199
   WRIGHT WD, 1952, J OPT SOC AM, V42, P509, DOI 10.1364/JOSA.42.000509
   Zjakic I, 2011, MEASUREMENT, V44, P1441, DOI 10.1016/j.measurement.2011.05.016
NR 26
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4487
EP 4505
DI 10.1007/s11042-013-1818-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400002
DA 2024-07-18
ER

PT J
AU Xu, WJ
   Zhao, CD
   Chiang, HP
   Huang, LF
   Huang, YM
AF Xu, Wei-Jian
   Zhao, Cai-Dan
   Chiang, Hua-Pei
   Huang, Lianfen
   Huang, Yueh-Min
TI The RR-PEVQ algorithm research based on active area detection for big
   data applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality evaluaiton; RR-PEVQ; Active area detection; Big data
AB The reduced-reference video quality evaluation method uses only partial reference video information to evaluate the quality of deteriorated videos. This method can evaluate the quality of a video in real-time because less transmission bandwidth is required. Because the video active area attracts significant human eye attention, any deterioration in the active area will directly affect video evaluation results. Given the advantage of reduced reference model in VQM (Video Qualify Metric), this paper proposes a reduced reference evaluation model named RR-PEVQ (Reduced Reference Perceptual Evaluation of Video Quality) for weighting the active video area. According to the experimental results, the RR-PEVQ evaluation score is similar to that of the full reference PEVQ and the proposed method's practicability is greatly improved for big data purposes.
C1 [Xu, Wei-Jian; Zhao, Cai-Dan; Huang, Lianfen] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Fujian, Peoples R China.
   [Xu, Wei-Jian] Jimei Univ, Sch Informat & Engn, Xiamen 361005, Fujian, Peoples R China.
   [Chiang, Hua-Pei; Huang, Yueh-Min] Natl Cheng Kung Univ, Dept Engn Sci, Tainan 70101, Taiwan.
C3 Xiamen University; Jimei University; National Cheng Kung University
RP Zhao, CD (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Fujian, Peoples R China.
EM xwjxwj@jmu.edu.cn; zcd@xmu.edu.cn; vchiang@fareastone.com.tw;
   lfhuang@xmu.edu.cn; huang@mail.ncku.edu.tw
RI Xu, Wei-Jian/ABA-4972-2021; Huang, Yueh-Min/B-4563-2009
OI Xu, Wei-Jian/0000-0003-1818-0284; 
FU National Natural Science Foundation of China [61172097]; Natural Science
   Foundation of Fujian [2012J01424]; NCETFJ; Fundamental Research Funds
   for the Central Universities [2012121028]; NSFC [61271242, 61001072];
   Natural Science Foundation of Fujian Province of China [2010J01347]; SRF
   for ROCS, SEM; Comba fund
FX The work presented in this paper was partially supported by 2011
   National Natural Science Foundation of China (Grant number 61172097),
   2012 Natural Science Foundation of Fujian (Grant number 2012J01424),
   NCETFJ, Fundamental Research Funds for the Central Universities
   (2012121028), and NSFC (61271242,61001072), Natural Science Foundation
   of Fujian Province of China (No.2010J01347), SRF for ROCS, SEM.; This
   research is supported by the Comba fund.
CR Brunnstrom K, 2009, IEEE SIGNAL P MAG
   Bughin J., 2010, McKinsey Quarterly, V56, P1, DOI DOI 10.1109/MC.2012.358
   Chen WM, 2011, IET IMAGE PROCESS, V5, P349, DOI 10.1049/iet-ipr.2009.0362
   Cheng RS, 2012, J SUPERCOMPUT, V62, P68, DOI 10.1007/s11227-011-0624-2
   Feng C, 2010, ANTICOUNTERFEITING S, P359
   Gao Xin-Bo, 2010, QUALITY ASSESSMENT M
   Hsu TH, 2011, J INTERNET TECHNOL, V12, P813
   Ma G, 2008, COMPUT ENG DES, V29, P7
   Meng F, 2007, 2007 IE INT C MULT E
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Wu TY, 2012, COMPUT COMMUN, V35, P1809, DOI 10.1016/j.comcom.2012.06.015
   Zhou LA, 2010, COMPUT COMMUN, V33, P1615, DOI 10.1016/j.comcom.2010.05.002
NR 12
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3507
EP 3520
DI 10.1007/s11042-014-1903-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000018
DA 2024-07-18
ER

PT J
AU Jung, I
   Ryu, W
   Kim, J
AF Jung, Ilgu
   Ryu, Won
   Kim, Jinsul
TI An efficient mobility management scheme for convergence mobile media
   multicast services in NGN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convergence; Mobile media service; Mobility management; Multicast;
   Handover
ID IMPLEMENTATION; DESIGN
AB This paper proposes mobility management architecture and scheme for network-based convergence mobile media multicast service, called Access Independent Mobile Service - with Mobile Multicast (AIMS-MM), which provides fast and seamless multicast service handover mechanism among heterogeneous wireless access networks with the minimum modifications on terminal devices. The proposed scheme applies a method to fast re-join the relevant multicast stream by enabling the AIMS-MM system to collect multicast group information through multicast group information handler located in the multicast router and providing related information to the router upon terminal handover. The advantage of the proposed method can provide an efficient seamless multicast service with fast connecting when they handover each other among heterogeneous wireless access networks with the proposed mobility management scheme. Also, the proposed scheme can provides the reliability and resource efficiency in the wireless area via exclusion of signaling in the wireless area. Through numerical analysis and the test-bed implementation, we have shown the superiority and practicality of the proposed scheme convergence mobile media multicast services in NGN. Experimental results show that the proposed method with AIMS-MM improve QoS with reducing delay time when comparing with MIP-BT-opt, HMIP-BT-opt, PMIP, etc., methods in terms of multicast service handover and etc.
C1 [Jung, Ilgu] ETRI, Broadcasting & Telecommun Media Lab, Dept Broadcasting Media Cloud Res, Taejon 305700, South Korea.
   [Ryu, Won] ETRI, Broadcasting & Telecommun Media Lab, Taejon 305700, South Korea.
   [Kim, Jinsul] Chonnam Natl Univ, Sch Elect & Comp Engn, Kwangju 500757, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Electronics & Telecommunications Research Institute - Korea (ETRI);
   Chonnam National University
RP Kim, J (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, 300 Yongbong Dong, Kwangju 500757, South Korea.
EM ilkoo@etri.re.kr; wlyu@etri.re.kr; jsworld@jnu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education, Science and Technology
   [NRF-2013R1A1A2013740]; MSIP (Ministry of Science, ICT&Future Planning),
   Korea, under the ITRC (Information Technology Research Center) support
   program [NIPA-2014-H0301-14-1014]
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology(NRF-2013R1A1A2013740) and also
   supported partially by the MSIP (Ministry of Science, ICT&Future
   Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2014-H0301-14-1014) supervised by the NIPA
   (National IT Industry Promotion Agency)
CR [Anonymous], RFC4429 IETF
   [Anonymous], 2010, GLOB MOB FOR 2014
   [Anonymous], RFC5213 IETF
   Banerjee K, 2011, INT J ELECT COMPUT S, V11
   Cisco, 2010, CISC VIS NETW IND GL
   Guan J, 2010, IEEE CCNC 2010
   Guan J, 2009, IEEE ICCTA OCT 2009
   Guan JF, 2009, IC NIDC 2009 NOV 200
   Guan JF, 2009, COMPUT COMMUN, V32, P552, DOI 10.1016/j.comcom.2008.07.011
   Johnson D., 2004, RFC3775 IETF, DOI IETF
   Kim Y-T, 2009, IEEE CCNC 2009
   Kong KS, 2008, IEEE ICC, P5838, DOI 10.1109/ICC.2008.1092
   Koodli R., 2009, RFC5568 IETF
   Kwon DH, 2008, COMPUT COMMUN, V31, P2162, DOI 10.1016/j.comcom.2008.02.008
   Lee KH, 2013, TELECOMMUN SYST, V52, P1989, DOI 10.1007/s11235-011-9479-3
   Ravindran R, 2012, INT WORKSH NETW FUT, P5584
   Schmidt T, 2011, RFC6224 IETF
   Soliman H, 2008, RFC5380 IETF
NR 18
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2201
EP 2217
DI 10.1007/s11042-014-1996-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200002
DA 2024-07-18
ER

PT J
AU Liu, XA
   Sun, C
   Yang, LT
AF Liu, Xingang
   Sun, Chao
   Yang, Laurence T.
TI DCT-based objective quality assessment metric of 2D/3D image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality assessment; DCT coding; Stereoscopic image; Human Visual System
   (HVS); Region of Interest (ROI)
ID VIDEO
AB With the increasing growth of multimedia applications over the networking in recent years, users have put forward much higher requirements for multimedia quality of experience (QoE) than before. One of the representative requirements is the image quality. Therefore, the image quality assessment ranging from two-dimension (2D) image to three-dimension (3D) image has been getting much attention. In this paper, an efficient objective image quality assessment metric in block-based discrete cosine transform (DCT) coding is proposed. The metric incorporates properties of human visual system (HVS) to improve its validity and reliability in evaluating the quality of stereoscopic image. This is fulfilled by calculating the local pixel-based distortions in frequency domain, combining the simplified models of local visibility properties embodied in frequency domain, which consist of region of interest (ROI) mechanism (visual sensitivity), contrast sensitivity function (CSF) and contrast masking effect. The performance of the proposed metric is compared with other currently state-of-the-art objective image quality assessment metrics. The experimental results have demonstrated that the proposed metric is highly consistent with the subjective test scores. Moreover, the performance of the metric is also confirmed with the popular IRCCyN/IVC database. Therefore, the proposed metric is promising in term of the practical efficiency and reliability for real-life multimedia applications.
C1 [Liu, Xingang; Sun, Chao] Univ Elect Sci & Technol China, Sch Elect Engn, High Tech Zone, Xiyuan Rd 2006, Chengdu 611731, Sichuan, Peoples R China.
   [Yang, Laurence T.] St Francis Xavier Univ, Antigonish, NS B2G 2W5, Canada.
C3 University of Electronic Science & Technology of China; Saint Francis
   Xavier University - Canada
RP Liu, XA (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, High Tech Zone, Xiyuan Rd 2006, Chengdu 611731, Sichuan, Peoples R China.
EM hanksliu@uestc.edu.cn; ch_sun@126.com; ltyang@ieee.org
RI Laurence T. Yang, FCAE/AAA-1898-2019
OI Laurence T. Yang, FCAE/0000-0002-7986-4244
FU Fundamental Research Funds for the Central Universities [ZYGX2012J028];
   China Postdoctoral Science Foundation [2013M530396.]
FX The work was supported by Fundamental Research Funds for the Central
   Universities on the grant ZYGX2012J028, and also supported by the China
   Postdoctoral Science Foundation funded Project on the grant 2013M530396.
CR [Anonymous], P INT WORKSH VID PRO
   [Anonymous], 2007, INT WORKSH VID PROC
   [Anonymous], 2005, SUBJECTIVE QUALITY A
   [Anonymous], THESIS CLARENDON OXF
   [Anonymous], P SPIE ELECT IMAGING
   [Anonymous], 2006, Digital Video Image Quality and Perceptual Coding
   [Anonymous], P SPIE
   [Anonymous], IEEE INT C IM PROC H
   [Anonymous], 2012, P IEEE INT S BROADB
   [Anonymous], 2006, P 2 INT WORKSH VID P
   Arican Z, 2009, PROC SPIE, V7443, DOI 10.1117/12.829381
   Boev A, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218
   Brandao T, 2008, SIGNAL PROCESS, V88, P822, DOI 10.1016/j.sigpro.2007.09.017
   Donghyun Kim, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7237, DOI 10.1117/12.806898
   Jin L., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2521, DOI 10.1109/ICIP.2011.6116175
   Joveluro P, 2010, 3DTV CONF
   Kwangsung Ha, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2525, DOI 10.1109/ICIP.2011.6116176
   Liyuan Xing, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P373, DOI 10.1109/MMSP.2010.5662049
   Ma L, 2013, SIGNAL PROCESS-IMAGE, V28, P884, DOI 10.1016/j.image.2012.08.001
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Park PK, 2008, ELECTRON LETT, V44, P102, DOI 10.1049/el:20082082
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Sazzad ZMP, 2009, INT WORK QUAL MULTIM, P180, DOI 10.1109/QOMEX.2009.5246956
   Seo J, 2012, CIRC SYST SIGNAL PR, V31, P1089, DOI 10.1007/s00034-011-9369-7
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Smolic A, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P389
   Solomon J. A., 1994, Proceedings DCC '94. Data Compression Conference (Cat. No.94TH0626-2), P361, DOI 10.1109/DCC.1994.305944
   Tsung PK, 2010, IEEE COMMUN MAG, V48, P76, DOI 10.1109/MCOM.2010.5439080
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yang J.-C., 2009, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video, P1
   Zhongjie Zhu, 2009, WSEAS Transactions on Signal Processing, V5, P241
NR 36
TC 8
Z9 9
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2803
EP 2820
DI 10.1007/s11042-013-1698-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300013
DA 2024-07-18
ER

PT J
AU Ch, SA
   Uddin, N
   Sher, M
   Ghani, A
   Naqvi, H
   Irshad, A
AF Ch, Shehzad Ashraf
   Uddin, Nizam
   Sher, Muhammad
   Ghani, Anwar
   Naqvi, Husnain
   Irshad, Azeem
TI An efficient signcryption scheme with forward secrecy and public
   verifiability based on hyper elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperelliptic curve cryptosystem; Lightweight cryptography; ECC; HECC;
   Signcryption; Public verifiability; Authentication; Forward secrecy
ID AUTHENTICATION
AB The need for Lightweight cryptography is on the rise as transition has been made from wired to wireless network. Wireless systems inherently are insecure and resource (power) constrained, to deal with these constraints, many techniques for symmetric and asymmetric cryptography are defined. One such important developement is Signcryption to achieve message confidentiality, integrity, sender and message authentication, non repudiation, forward secrecy as well as unforgeability, and public verifiability. Since Signcryption combines the signature and encryption therefore the cost is very less in comparison to those schemes based on the signature then encryption. Many signcryption schemes have been proposed based on El-Gamal, RSA and ECC till today. This paper highlights limitations of the existing ECC based schemes using signcryption. These limitations include some missing security aspects as well as high computation power requirement, more communication overhead incurred and large memory requirements. Further it proposes an efficient lightweight signcryption scheme based on HECC which fulfills all the security requirements. The scheme reduced significant amounts of computation, communication costs and message size as compared to existing signcryption schemes making it the good candidate for environments suffer from the resource limitation problems.
C1 [Ch, Shehzad Ashraf; Sher, Muhammad; Ghani, Anwar; Naqvi, Husnain; Irshad, Azeem] Int Islamic Univ, Islamabad, Pakistan.
   [Uddin, Nizam] Hazara Univ, Mansehra, Pakistan.
C3 International Islamic University, Pakistan; Hazara University
RP Ch, SA (corresponding author), Int Islamic Univ, Islamabad, Pakistan.
EM shahzad@iiu.edu.pk; sahibzadanizam@yahoo.com; m.sher@iiu.edu.pk;
   anwar.ghani@iiu.edu.pk; husnain.naqvi@iiu.edu.pk; irshadazeem2@gmail.com
RI Ramzan, Muhammad Sher/N-6832-2019; Chaudhry, Shehzad/Y-3430-2019; Uddin,
   Nizam/AAX-7298-2020; Irshad, Azeem/E-7400-2010; Ghani,
   Anwar/Q-1973-2019; Ramzan, Muhammad/ABG-2396-2020
OI Ramzan, Muhammad Sher/0000-0001-6752-0033; Chaudhry,
   Shehzad/0000-0002-9321-6956; Uddin, Nizam/0000-0002-5853-2849; Irshad,
   Azeem/0000-0002-1366-2834; Ghani, Anwar/0000-0001-7474-0405; 
CR [Anonymous], 2012, INT J DIGIT CONTENT
   [Anonymous], J CONVERG
   [Anonymous], 2013, IT CONVERGENCE SECUR
   [Anonymous], 2013, IT CONVERGENCE SECUR, DOI DOI 10.1007/978-94-007-5860-5_18
   [Anonymous], 2010, ARXIV10051856
   [Anonymous], THESIS
   [Anonymous], 2011, 2011 7 INT C EMERGIN
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Bao F., 1998, Public Key Cryptography. First International Workshop on Practice and Theory in Public Key Cryptography, PKC'98. Proceedings, P55, DOI 10.1007/BFb0054014
   Choi Hyun-jun, 2011, Journal of Information and Communication Convergence Engineering, V9, P271
   Diffie W., 1992, Designs, Codes and Cryptography, V2, P107, DOI 10.1007/BF00124891
   Gamage C, 1999, LECT NOTES COMPUT SC, V1560, P69
   Ganesan R, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P293, DOI 10.1109/ARTCom.2009.123
   Ganesan Ramachandran., 2010, IJ Network Security, V11, P121
   Hwang RJ, 2005, APPL MATH COMPUT, V167, P870, DOI 10.1016/j.amc.2004.06.124
   Irshad A, 2013, MULTIMEDIA TOOLS APP, P1
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Johnson D., 2001, International Journal of Information Security, V1, P36, DOI 10.1007/s102070100002
   Koblitz N., 1989, Journal of Cryptology, V1, P139, DOI 10.1007/BF02252872
   Mehmood Z., 2012, 2012 Second International Conference on Digital Information Processing and Communications (ICDIPC), P164, DOI 10.1109/ICDIPC.2012.6257295
   Nizamuddin N., 2011, 2011 High Capacity Optical Networks and Enabling Technologies (HONET), P244, DOI 10.1109/HONET.2011.6149826
   Nizamudin Sher M., 2012, INFORM SYSTEMS TECHN, P135
   Son B, 2013, MULTIMED TOOLS APPL, V63, P181, DOI 10.1007/s11042-011-0956-1
   Varalakshmi LM, 2013, MULTIMED TOOLS APPL, V64, P717, DOI 10.1007/s11042-011-0963-2
   YOU Lin, 2010, The Journal of China Universities of Posts and Telecommunications, V17, P100
   Zhang Z, 2014, MULTIMEDIA TOOLS APP, P1
   Zheng YL, 1997, LECT NOTES COMPUT SC, V1294, P165
   Zheng YL, 1998, INFORM PROCESS LETT, V68, P227, DOI 10.1016/S0020-0190(98)00167-7
NR 28
TC 36
Z9 37
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1711
EP 1723
DI 10.1007/s11042-014-2283-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900012
DA 2024-07-18
ER

PT J
AU Wang, SF
   Wang, ZY
   Ji, Q
AF Wang, Shangfei
   Wang, Zhaoyu
   Ji, Qiang
TI Multiple emotional tagging of multimedia data by exploiting dependencies
   among emotions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple emotional tagging; Multimedia; Bayesian network; Multi-label
   classification
ID MULTILABEL CLASSIFICATION; CONTENT REPRESENTATION; RETRIEVAL; MUSIC;
   VIDEO; AESTHETICS; IMAGES
AB Digital multimedia may elicit a mixture of human emotions. Most current emotional tagging research typically tags the multimedia data with a single emotion, ignoring the phenomenon of multi-emotion coexistence. To address this problem, we propose a novel multi-emotion tagging approach by explicitly modeling the dependencies among emotions. First, several audio or visual features are extracted from the multimedia data. Second, four traditional multi-label learning methods: Binary Relevance, Random k label sets, Binary Relevance k Nearest Neighbours and Multi-Label k Nearest Neighbours, are used as the classifiers to obtain the measurements of emotional tags. Then, a Bayesian network is automatically constructed to capture the relationships among emotional tags. Finally, the Bayesian network is used to infer the data's multi-emotion tags by combining the measurements obtained from those traditional methods with the dependencies among emotions. Experiments on two multi-label media data sets demonstrate the superiority of our approach to the existing methods.
C1 [Wang, Shangfei; Wang, Zhaoyu] Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Rensselaer Polytechnic Institute
RP Wang, SF (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
EM sfwang@ustc.edu.cn; wazhy@mail.ustc.edu.cn; qji@ecse.rpi.edu
RI wang, zhaoyu/IQT-3451-2023
FU NSFC [61175037, 61228304]; Special Innovation Project on Speech of Anhui
   Province [11010202192]; Anhui Science and Technology Agency
   [1106c0805008]; Fundamental Research Funds for the Central Universities;
   US National Science Foundation [1205664]; Direct For Computer & Info
   Scie & Enginr; Division Of Computer and Network Systems [1205664]
   Funding Source: National Science Foundation
FX This paper is supported by the NSFC (61175037, 61228304), Special
   Innovation Project on Speech of Anhui Province (11010202192), Project
   from Anhui Science and Technology Agency(1106c0805008) and the
   Fundamental Research Funds for the Central Universities. We also
   acknowledge partial support from the US National Science Foundation
   under grant # 1205664.
CR [Anonymous], 2001, P 9 ACM INT C MULT
   [Anonymous], 2003, Proceedings of the International Symposium on Music Information Retrieval
   [Anonymous], P 9 JOINT C INF SCI
   [Anonymous], 2008, P 14 ACM SIGKDD INT
   [Anonymous], 2005, Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM'05, DOI [DOI 10.1145/1099554.1099591, 10.1145/1099554.1099591]
   [Anonymous], 1997, ser. Studies in emotion and social interaction, 2nd series
   Arifin S, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P147, DOI 10.1109/ICSC.2007.22
   Bhattacharya S., 2010, P 18 ACM INT C MULTI, P271
   Bischoff K., 2009, ISMIR, P657
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   de Campos CP, 2011, J MACH LEARN RES, V12, P663
   Eerola T., 2009, P 10 INT SOC MUS INF, P621
   Feng Y., 2003, P 26 ANN INT ACM SIG, P375, DOI [DOI 10.1145/860500.860508, 10.1145/860435, DOI 10.1145/860435]
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hevner K, 1935, PSYCHOL REV, V42, P186, DOI 10.1037/h0054832
   Huang S. J., 2012, P 18 ACM SIGKDD INT, P525, DOI DOI 10.1145/2339530.2339615
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Kang HB, 2003, LECT NOTES COMPUT SC, V2911, P243
   Kim EY, 2005, LECT NOTES ARTIF INT, V3613, P1077
   Kim YoungmooE., 2010, Proceedings of the 11th International Society for Music Information Retrieval Conference (ISMIR 2010), P255
   Lazarus R.S., 1991, EMOTION ADAPTATION
   Li DG, 2001, PATTERN RECOGN LETT, V22, P533, DOI 10.1016/S0167-8655(00)00119-7
   Liu D., 2003, P ISMIR, P81
   MacDorman KF, 2007, J NEW MUSIC RES, V36, P281, DOI 10.1080/09298210801927846
   Marcelino R, 2011, MULTIMED TOOLS APPL, V61, P21
   Myint EEP, 2010, 2 INT C SIGN PROC SY, V1, P290
   Nack F., 2001, IEEE Multimedia, V8, P10, DOI 10.1109/93.959093
   Oliveira Eva, 2011, P 9 EUR C INT TV VID, P105
   Pearl J., 1988, PROBABILISTIC REASON
   PHILIPPOT P, 1993, COGNITION EMOTION, V7, P171, DOI 10.1080/02699939308409183
   Read J, 2009, LECT NOTES ARTIF INT, V5782, P254, DOI 10.1007/978-3-642-04174-7_17
   Sanden Chris., 2011, Proceedings of the International Society for Music Information Retrieval Conference, P717
   Santos Araken M., 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3, P218
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Schuller B, 2010, EURASIP J AUDIO SPEE, DOI 10.1155/2010/735854
   Shibata T., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P247, DOI 10.1109/ICSMC.1999.816558
   SMITH CA, 1989, J PERS SOC PSYCHOL, V56, P339, DOI 10.1037/0022-3514.56.3.339
   Sorower Mohammad S., 2010, A Literature Survey on Algorithms for Multi-Label Learning
   Spyromitros E, 2008, LECT NOTES ARTIF INT, V5138, P401, DOI 10.1007/978-3-540-87881-0_40
   Sun K, 2007, LECT NOTES COMPUT SC, V4738, P594
   Trohidis K, 2011, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2011-426793
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Tsoumakas G, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P667, DOI 10.1007/978-0-387-09823-4_34
   Wang CW, 2007, LECT NOTES COMPUT SC, V4351, P606
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang SF, 2011, KANSEI ENGINEERING AND SOFT COMPUTING: THEORY AND PRACTICE, P126, DOI 10.4018/978-1-61692-797-4.ch007
   Wang WN, 2008, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2008.4711705
   Wang Z, 2013, IEEE INT C AUT FAC G
   Watanapa SC, 2008, IEICE T INF SYST, VE91D, P1562, DOI 10.1093/ietisy/e91-d.5.1562
   Wei CY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P831, DOI 10.1109/ICME.2004.1394329
   Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667
   Winoto P, 2010, EXPERT SYST APPL, V37, P6086, DOI 10.1016/j.eswa.2010.02.117
   Wu TL, 2008, LECT NOTES COMPUT SC, V4903, P487
   Xu M, 2013, SIGNAL PROCESS, V93, P2140, DOI 10.1016/j.sigpro.2012.06.026
   Xu M, 2010, LECT NOTES COMPUT SC, V6298, P43, DOI 10.1007/978-3-642-15696-0_5
   Yang YL, 2012, ADV EDUC RES, V3, P40
   Yang YH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P208
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yoo HW, 2007, MULTIMED TOOLS APPL, V34, P317, DOI 10.1007/s11042-007-0109-8
   Zhang M.-L., 2010, P 16 ACM SIGKDD INT, P999, DOI DOI 10.1145/1835804.1835930
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
   Zhang SL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1369, DOI 10.1109/ICME.2008.4607698
NR 67
TC 16
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1863
EP 1883
DI 10.1007/s11042-013-1722-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500008
DA 2024-07-18
ER

PT J
AU Wang, XR
   Du, JP
   Wu, SZ
   Li, X
   Xin, HM
   Zhang, Y
   Li, F
AF Wang, Xiaoru
   Du, Junping
   Wu, Shuzhe
   Li, Xu
   Xin, Haiming
   Zhang, Yu
   Li, Fu
TI High-level semantic image annotation based on hot Internet topics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abstract semantics; Complex graph; High-level semantics; Hot Internet
   topic; Hypergraph; Image annotation
ID RETRIEVAL; FEATURES; MODEL
AB Images are complex multimedia data that contain rich semantic information. Currently, most of image annotation algorithms are only annotating the object semantics of images. There are still many challenges on high-level semantic image annotation. The major issues are the lack of effective modeling method for the high-level semantics of images and the lack of efficient dynamic update mechanism for the training set. To address these issues, we propose a high-level semantic annotation method based on hot Internet topics in this paper. There are two independent sub tasks in our method: dynamic update of the training set based on hot Internet topics and search-based image annotation. In the first sub task, we propose to model the abstract semantics of images based on three relationships: image-to-image similarity relationship, topic-to-topic co-occurrence relationship, and image-to-topic relevance relationship. Through the complex graph clustering, the hot Internet topics are extracted for images with consistent visual and semantic contents. Then the dynamic update mechanism will update the original training set with the new topics and images. It avoids the huge computing cost in traditional update methods and does not need to re-calculate the whole mapping relationship between the semantic concepts and visual features. In the second sub task, given a query image, it first searches for similar candidates in the annotated training set via visual features. Then the hypergraph modeling and spectral clustering are exploited to filter out the images with irrelevant semantics. The keywords will be extracted for annotation from the remaining images according to an annotation probability. Extensive experiments have been conducted and the results demonstrate that our algorithm could achieve better annotation performance than the state-of-the-art algorithms. And the update mechanism could extend the training set efficiently so that the coverage of the semantics in the training set wouldn't be obsolete.
C1 [Wang, Xiaoru; Du, Junping; Wu, Shuzhe; Li, Xu; Xin, Haiming; Zhang, Yu] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
   [Li, Fu] Portland State Univ, Dept Elect & Comp Engn, Portland, OR 97207 USA.
C3 Beijing University of Posts & Telecommunications; Portland State
   University
RP Wang, XR (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM wxr@bupt.edu.cn
FU National Basic Research Program of China (973 Program) [2012CB821206];
   National Natural Science Foundation of China [91024001, 61070142];
   Beijing Natural Science Foundation [4111002]; Fundamental Research Funds
   for the Central Universities [2013RC0306]
FX This research study was supported by the National Basic Research Program
   of China (973 Program) (2012CB821206), the National Natural Science
   Foundation of China (No. 91024001, No. 61070142), the Beijing Natural
   Science Foundation (No. 4111002), and the Fundamental Research Funds for
   the Central Universities (No. 2013RC0306).
CR [Anonymous], 2006, Book Annosearch: Image auto-annotation by search, DOI DOI 10.1109/CVPR.2006.58
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], P 8 ACM SIGMM INT WO, DOI DOI 10.1145/1178677.1178714
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Cusano C, 2004, PROC SPIE, V5304, P330
   Dai Wenyuan., 2009, ANN C NEURAL INFORM, P353
   DESCHACHT K, 2007, P 45 ANN M ASS COMP, P1000
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Eakins JP, 1996, AUTOMATIC IMAGE CONT, P123
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Kang F, 2005, MPROC SIAM C DAT MIN, P21
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Liu JJ, 2007, PROCEEDINGS OF THE 2007 CHINESE CONTROL AND DECISION CONFERENCE, P605, DOI 10.1145/1291233.1291380
   Long Bo., 2008, AAAI, P659
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Saenko Kate., 2009, Advances in Neural Information Processing Systems, P1393
   Shapiro L.G., 2003, Computer Vision, Vsecond
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Tsikrika T, 2011, MULTIMED TOOLS APPL, V55, P27, DOI 10.1007/s11042-010-0584-1
   Wang JZ, 2008, IEEE T PATTERN ANAL, V30, P1873, DOI 10.1109/TPAMI.2008.231
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Wu F, 2010, J COMPUT SCI TECH-CH, V25, P750, DOI [10.1007/s11390-010-9362-9, 10.1007/s11390-010-1058-7]
   Xia DY, 2008, LECT NOTES COMPUT SC, V5353, P842
   Xiang Y, 2010, PROC CVPR IEEE, P3368, DOI 10.1109/CVPR.2010.5540015
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Zhang XM, 2013, MULTIMED TOOLS APPL, V62, P601, DOI 10.1007/s11042-011-0863-5
   Zhu X., 2007, AAAI, V7, P1590, DOI 10.5555/1619797.1619900
NR 39
TC 6
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2055
EP 2084
DI 10.1007/s11042-013-1742-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500017
OA hybrid
DA 2024-07-18
ER

PT J
AU Mehrdad, V
   Ebrahimnezhad, H
AF Mehrdad, Vahid
   Ebrahimnezhad, Hossein
TI 3D model retrieval based on linear prediction coding in cylindrical and
   spherical projections using SVM-OSS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Linear prediction coding; Shape descriptor;
   Cylindrical and spherical projections
ID SIMILARITY SEARCH; SKELETONIZATION; CLASSIFICATION; ENGINE
AB This paper presents a 3D model descriptor based on the linear prediction coding (LPC) coefficients to retrieve 3D objects. In this method, the 3D object is projected on the lateral surface of a cylinder parallel to one of its principal axes and centered at the centroid of the object. To improve efficiency, cylindrical projection is performed on three cylinders parallel to principal axes. Besides, the object is projected on a sphere centered at the centroid of the 3D object. The surface of object is converted to two-dimensional shapes as a result of performing the projections which preserves the geometric features of the object. Then, LPC coefficients are extracted from the two-dimensional projected shapes. These coefficients estimate the parameters of correlated signal, efficiently. Since the cylindrical and spherical projections of the 3D model are correlated surfaces, LPC coefficients describe the surfaces as well. The rotation normalization is performed employing the principal component analysis. Furthermore, the retrieval performance is enhanced employing SVM-OSS similarity measure which efficiently compares two model feature vectors. We implement an experimental comparison on PSB database of 3D models in order to demonstrate the performance of the proposed descriptor. Experimental results show the effectiveness of the proposed descriptor compared to current methods.
C1 [Mehrdad, Vahid; Ebrahimnezhad, Hossein] Sahand Univ Technol, Fac Elect Engn, Comp Vision Res lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Fac Elect Engn, Comp Vision Res lab, Tabriz, Iran.
EM v_mehrdad@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ebrahimnezhad,
   Hossein/ACP-2704-2022
OI ebrahimnezhad, hossein/0000-0003-4071-2750; 
CR Alizadeh F, 2012, CBMI, P1, DOI DOI 10.1109/CBMI.2012.6269797
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2008, REAL LIF IM WORKSH E
   [Anonymous], ASIAN J INF TECHNOL
   [Anonymous], 2008, EUR WORKSH 3D OBJ RE
   [Anonymous], 2007, GRAPHICS VISUALIZATI
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Atmosukarto I, 2010, PATTERN RECOGN, V43, P1502, DOI 10.1016/j.patcog.2009.11.004
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chen Ziyang, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P2991, DOI 10.1109/iCECE.2010.729
   Chuang JH, 2000, IEEE T PATTERN ANAL, V22, P1241
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Faloutsos C., 1996, SEARCHING MULTIMEDIA, V3
   FANG WH, 1994, IEEE T SIGNAL PROCES, V42, P628
   Ferencz A., 2005, BUILDING CLASSIFICAT
   Ferencz Andras., 2005, Advances in Neural Information Processing Systems, V17, P425
   Frejlichowski D, 2011, LECT NOTES COMPUT SC, V6688, P457, DOI 10.1007/978-3-642-21227-7_43
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Haykin S., 2003, Adaptive filter theory (ISE)
   Hua S., 2011, COMMUNICATION SYSTEM, P163
   Jain A., 1989, Fundamentals of Digital Image Processing, V3
   Jain Vidit., 2006, British Machine Vision Conference, P357
   KAZHDAN M, 2004, THESIS PRINCETON U
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Keim DA, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P419, DOI 10.1145/304181.304219
   Kuo CT, 2007, PATTERN RECOGN, V40, P742, DOI 10.1016/j.patcog.2006.06.006
   Laga H, 2007, INT J SHAPE MODELING, V13, P51
   Lau R. W. H., 2002, World Wide Web, V5, P193, DOI 10.1023/A:1020984612969
   Lin TY, 2007, LECT NOTES ARTIF INT, V4482, P256
   Liu Y, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P86
   Löffler J, 2000, IEEE INFOR VIS, P82, DOI 10.1109/IV.2000.859741
   Manzanera A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P337, DOI 10.1109/ICCV.1999.791239
   Mohamed W, 2012, VISUAL COMPUT, V28, P305, DOI 10.1007/s00371-011-0640-5
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Nowak E, 2007, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2007.382969
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Pan XA, 2011, PATTERN RECOGN LETT, V32, P787, DOI 10.1016/j.patrec.2011.01.003
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Paquet E., 1998, Multimedia Information Analysis and Retrieval. IAPR International Workshop, MINAR'98. Proceedings, P20, DOI 10.1007/BFb0016486
   Petrou M. M., 2010, Image processing: the fundamentals
   Rabiner L.R., 1979, Digital Processing of Speech Signals, V19
   RANGANATH S, 1985, IEEE T ACOUST SPEECH, V33, P280, DOI 10.1109/TASSP.1985.1164523
   Riesenhuber Maximilian., 2000, COMPUTATIONAL MODELS
   Shih J L, 2012, J INF TECHNOL APPL, V6, P31
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   SHIH JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI DOI 10.1007/S11042-008-0256-6
   Shilane P., 2004, P INT C SHAPE MODELI, DOI DOI 10.1109/SMI.2004.1314504
   Tam GKL, 2007, IEEE T VIS COMPUT GR, V13, P470, DOI 10.1109/TVCG.2007.1011
   Veltkamp RC, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P188, DOI 10.1109/SMA.2001.923389
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
   Zhou Y, 1999, IEEE T VIS COMPUT GR, V5, P196, DOI 10.1109/2945.795212
   Zou K. S., 2012, MULTIMED TOOLS APPL, P1
NR 56
TC 0
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1511
EP 1535
DI 10.1007/s11042-014-2055-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300018
DA 2024-07-18
ER

PT J
AU Xia, ZQ
   Shen, Y
   Feng, XY
   Peng, JY
   Fan, JP
AF Xia, Zhaoqiang
   Shen, Yi
   Feng, Xiaoyi
   Peng, Jinye
   Fan, Jianping
TI Automatic tag-to-region assignment via multiple instance learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tag-to-region assignment; Multiple instance learning; Instance
   identification; AP clustering
ID IMAGE ANNOTATION; RETRIEVAL
AB Translating image tags at the image level to regions (i.e., tag-to-region assignment), which could play an important role in leveraging loosely-labeled training images for object classifier training, has become a popular research topic in the multimedia research community. In this paper, a novel two-stage multiple instance learning algorithm is presented for automatic tag-to-region assignment. The regions are generated by performing multiple-scale image segmentation and the instances with unique semantics are selected out from those regions by a random walk process. The affinity propagation (AP) clustering technique and Hausdorff distance are performed on the instances to identify the most positive instance and utilize it to initialize the maximum searching of Diverse Density likelihood in the first stage. In the second stage, the most contributive instance, which is chosen from each bag, is treated as the key instance for simplifying the computing procedure of Diverse Density likelihood. At last, an automatic method is proposed to discriminate the boundary between positive instances and negative instances. Our experiments on three well-known image sets have provided positive results.
C1 [Xia, Zhaoqiang; Feng, Xiaoyi; Peng, Jinye] Northwestern Polytech Univ, Xian 710072, Peoples R China.
   [Shen, Yi; Fan, Jianping] Univ N Carolina, Charlotte, NC 28223 USA.
C3 Northwestern Polytechnical University; University of North Carolina;
   University of North Carolina Charlotte
RP Xia, ZQ (corresponding author), Northwestern Polytech Univ, Xian 710072, Peoples R China.
EM xiazhaoqiang@gmail.com; yshen9@uncc.edu; fengxiao@nwpu.edu.cn;
   jinyepeng@nwpu.edu.cn; jfan@uncc.edu
RI Xia, Zhaoqiang/AAC-4021-2019; Peng, Jin/HZH-6965-2023; Shen,
   Yi/B-1433-2010
OI Xia, Zhaoqiang/0000-0003-0630-3339; Shen, Yi/0000-0003-0063-1200
FU doctorate foundation of Northwestern Polytechnical University
   [CX201113]; Doctoral Program of Higher Education of China
   [20106102110028, 20116102110027]; National Science Foundation of China
   [61075014, 61272285]
FX The authors would like to thank Jonathan Fortune for language polish.
   This work is partly supported by the doctorate foundation of
   Northwestern Polytechnical University (No: CX201113), Doctoral Program
   of Higher Education of China (Grant No. 20106102110028 and
   20116102110027) and National Science Foundation of China (under Grant
   No. 61075014 and 61272285).
CR Andrews S., 2002, NIPS, P577
   [Anonymous], 2000, International Conference on Machine Learning (ICML)
   [Anonymous], 2009, PROC 17 ACM INT C MU
   [Anonymous], CVPR 2007 SHORT COUR
   Bunescu R.C., 2007, P 24 INT C MACH LEAR, P105, DOI [10.1145/1273496.1273510, DOI 10.1145/1273496.1273510]
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023
   Cusano C, 2004, PROC SPIE, V5304, P330
   Deng Y, 1999, IEEE COMP SOC C COMP, V2
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Fan JP, 2010, PROC CVPR IEEE, P802, DOI 10.1109/CVPR.2010.5540135
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu D., 2010, Proceedings of ACM International Conference on Multimedea, P25
   Liu D, 2011, MULTIMED TOOLS APPL, V51, P723, DOI 10.1007/s11042-010-0647-3
   Liu S, 2012, IEEE T MULTIMEDIA, V14, P361, DOI 10.1109/TMM.2011.2174780
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Maron O, 1998, ADV NEUR IN, V10, P570
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Qi G.-J., 2007, PROC IEEE C COMPUT V, P1
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Shengli Yuan, 2010, Proceedings 2010 IEEE Global Communications Conference (GLOBECOM 2010), DOI 10.1109/GLOCOM.2010.5683786
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418
   Vijayanarasimhan S., 2008, Proc. CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587632
   Viola P., 2006, Proceedings of Advances in Neural Information Processing Systems, V18, P1417
   Wang D, 2006, LECT NOTES COMPUT SC, V4212, P473
   Yang KY, 2011, IEEE T MULTIMEDIA, V13, P662, DOI 10.1109/TMM.2011.2147777
   Zha Z.-J., 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587384
   Zhang ML, 2009, APPL INTELL, V31, P47, DOI 10.1007/s10489-007-0111-x
   Zhang Q, 2002, ADV NEUR IN, V14, P1073
NR 36
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 979
EP 1002
DI 10.1007/s11042-013-1707-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400015
DA 2024-07-18
ER

PT J
AU Borowiak, A
   Reiter, U
AF Borowiak, Adam
   Reiter, Ulrich
TI Quality evaluation of long duration AV content-an extended analysis
   using a novel assessment methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subjective audiovisual quality evaluation; Data analysis; Quality of
   experience (QoE); Long duration assessment; Audio quality; Video quality
AB This paper is an extension of our previous work describing a novel methodology for quality assessment of long duration audiovisual content. In this article we focus on data analysis of results obtained from two experiments conducted using the new methodology. In the first study, we found that the time dimension does not influence participants' expectations with respect to perceived video quality and that a possible increase or decrease in acceptable quality level is rather directly related to the presented material itself. Moreover, we found that participants are less sensitive to quality changes when the process is controlled externally than when they are in charge of the quality adjustment. A second experiment (study 2) was performed to evaluate the effect of simultaneous quality changes in the two modalities (audio and video) which confirmed the previous results.
C1 [Borowiak, Adam; Reiter, Ulrich] Norwegian Univ Sci & Technol NTNU, Trondheim, Norge, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Borowiak, A (corresponding author), Norwegian Univ Sci & Technol NTNU, Trondheim, Norge, Norway.
EM adam.borowiak@iet.ntnu.no
RI Reiter, Ulrich/C-7238-2014
FU Research Council of Norway [193034/S10]
FX This work was performed within the PERCEVAL project, funded by The
   Research Council of Norway under project number 193034/S10.
CR Adler H.E, 1966, Elemente der Psychophysik Elements of psychophysics, V1
   Alpert T, 1997, ISOIECJTCISC29WG11MP
   [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], 2006, EURASIP J APPL SIGNA
   Bech S., 2006, PERCEPTUAL AUDIO EVA
   Borowiak A, 2012, 9 ANN IEEE CONS COMM, P353
   Borowiak A, 2014, J SIGNAL PROCESS SYS, V74, P79, DOI 10.1007/s11265-013-0777-8
   Chen KT, 2009, MATH COMPUT SCI ENG, P491, DOI 10.1145/1631272.1631339
   Ghinea G, 2003, BRIT J EDUC TECHNOL, V34, P393, DOI 10.1111/1467-8535.00337
   HAMBERG R, 1995, J OPT SOC AM A, V12, P2573, DOI 10.1364/JOSAA.12.002573
   ITU- T Rec, 1998, ITUTRECP911 INT TEL
   ITU- T Rec, 1999, ITUTRECP910 INT TEL
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Reiter U, 2010, P 129 CONV AUD ENG S
   Rossi PE, 2001, J AM STAT ASSOC, V96, P20, DOI 10.1198/016214501750332668
   Wang H, 2010, P 2010 I E 17 INT C
   Watson A., 1998, Proceedings ACM Multimedia 98, P55, DOI 10.1145/290747.290755
   Winkler S, 2003, PROC SPIE, V5150, P593, DOI 10.1117/12.509910
   ZAJONC RB, 1980, AM PSYCHOL, V35, P151, DOI 10.1037/0003-066X.35.2.151
NR 19
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 367
EP 380
DI 10.1007/s11042-014-1920-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300004
DA 2024-07-18
ER

PT J
AU Kang, JH
   Kang, SJ
   Kim, S
AF Kang, Ji Hun
   Kang, Shin Jin
   Kim, SooKyun
TI Line recognition algorithm for 3D polygonal model using a parallel
   computing platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature detection; Line recognition; 3D model; Parallel computing
   platform; GPGPU
AB Line recognition-based rendering technique has been used effectively for shape transmission of 3D polygon model. Line recognition is defined by multifarious forms and characteristics of lines, and has been a fundamental key point in expressing shape of 3D polygon model in non-photorealistic rendering technique. Line recognition, however, requires a long period of calculation time and thus, various methods have been studied to accelerate the speed of the operation. This paper presents a new method that will accelerate the overall operation compared to the standard CPU-based method of extracting ink line. The new method will enhance the efficiency of the calculation speed by applying the parallel processing technique CUDA (Compute Unified Device Architecture) to the complex processes that consume a lot of time such as implicit surface calculation and feature point extraction. The overall performance will be tested and verified through various types of experiments with 3D polygon model.
C1 [Kang, Ji Hun] Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
   [Kang, Shin Jin] Hongik Univ, Sch Games, Sejong, South Korea.
   [Kim, SooKyun] Paichai Univ, Dept Game Engn, Taejon, South Korea.
C3 Korea University; Hongik University; Pai Chai University
RP Kim, S (corresponding author), Paichai Univ, Dept Game Engn, Taejon, South Korea.
EM kimsk@pcu.ac.kr
OI Kim, Soo Kyun/0000-0001-6071-8231
CR [Anonymous], 2011, NVIDIA CUDA C PROGR
   Hwu Wen-meiW., 2010, Programming Massively Parallel Processors ~ A Hands-on Approach
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kang Shin Jin, 2011, J FUTURE GAME TECHNO, V1, P9
   Kim SK, 2006, COMPUT AIDED DESIGN, V38, P172, DOI 10.1016/j.cad.2005.10.003
   Lee Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239469
   nVidia, 2011, CUDA API REF MAN
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Sanders J., 2010, CUDA by Example, V1st
NR 9
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 259
EP 270
DI 10.1007/s11042-013-1758-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300017
DA 2024-07-18
ER

PT J
AU Lu, GY
   Sebe, N
   Xu, CF
   Kambhamettu, C
AF Lu, Guoyu
   Sebe, Nicu
   Xu, Congfu
   Kambhamettu, Chandra
TI Memory efficient large-scale image-based localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-based localization; Large scale imagery; SIFT; Hamming descriptor;
   Dimensionality reduction
ID REPRESENTATION; FEATURES; 3D
AB Local features have been widely used in the area of image-based localization. However, large-scale 2D-to-3D matching problems still involve massive memory consumption, which is mainly caused by the high dimensionality of the features (e.g. 128 dimensions of SIFT feature). This paper introduces a new method that decreases local features' high dimensionality for reducing memory capacity and accelerating the descriptor matching process. With this new method, all descriptors are projected into a lower dimensional space through the new learned matrices that are able to reduce the curse of dimensionality in the large scale image-based localization. The low dimensional descriptors are then mapped into a Hamming space for further reducing the memory requirement. This study also proposes an image-based localization pipeline based on the new learned Hamming descriptors. The new learned descriptor and the localization pipeline are applied to two challenging datasets. The experimental results show that the proposed method achieves extraordinary image registration performance compared with the published results from state-of-the-art methods.
C1 [Lu, Guoyu; Kambhamettu, Chandra] Univ Delaware, Video Image Modeling & Synth Lab, Newark, DE 19711 USA.
   [Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
   [Xu, Congfu] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
C3 University of Delaware; University of Trento; Zhejiang University
RP Lu, GY (corresponding author), Univ Delaware, Video Image Modeling & Synth Lab, Newark, DE 19711 USA.
EM luguoyu@udel.edu; sebe@disi.unitn.it; xucongfu@cs.zju.edu.cn;
   chandrak@udel.edu
RI Sebe, Niculae/KEC-2000-2024
OI Sebe, Niculae/0000-0002-6597-7248; Lu, Guoyu/0000-0002-2685-5563
FU European Master in Informatics program; RWTH Aachen University;
   University of Trento; University of Delaware
FX This work has been financially supported by European Master in
   Informatics program, RWTH Aachen University, University of Trento and
   the PhD program of University of Delaware. The authors are grateful to
   Torsten Sattler and Leif Kobbelt from RWTH Aachen University for their
   great help to make this work accomplished.
CR [Anonymous], 2009, NIPS
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2009, NEURIPS
   [Anonymous], 2011, 2011 17 KOREA JAPAN
   [Anonymous], 2013, 23 INT JOINT C ART I
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beltran Arturo., 2013, Multimedia Tools and Applications (MTA), P1
   Broder A. Z., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P327, DOI 10.1145/276698.276781
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577
   Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   Heath K, 2010, PROC CVPR IEEE, P3432, DOI 10.1109/CVPR.2010.5539991
   Hua G, 2007, P 2007 IEEE 11 INT C, P1
   Irschara A., 2009, PROC IEEE C COMPUT V, P2599
   Jacobs Nathan, 2011, IEEE Winter Conference on Applications of Computer Vision (WACV), P132
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Leonard J. J., 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Philbin J, 2010, LECT NOTES COMPUT SC, V6313, P677
   POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155
   Robertson D., 2004, BRITICH MACHINE VISI, P819
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Schindler G., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Shao H, 2003, LECT NOTES COMPUT SC, V2728, P71
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Steinhoff U, 2007, LECT NOTES COMPUT SC, V4794, P124
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Wang H., 2007, IEEE C COMPUTER VISI, P1
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Weiss Y., 2008, PROC ADV NEURAL INFO, V21, P1753
   Wendel A., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5792, DOI 10.1109/ICRA.2011.5980317
   Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839
   Xiao JX, 2008, LECT NOTES COMPUT SC, V5304, P725, DOI 10.1007/978-3-540-88690-7_54
   Xuan KF, 2011, MULTIMED TOOLS APPL, V53, P459, DOI 10.1007/s11042-010-0498-y
   Yagnik J, 2011, IEEE I CONF COMP VIS, P2431, DOI 10.1109/ICCV.2011.6126527
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yu S., 2013, P 2013 IEEE C COMP V
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
NR 57
TC 10
Z9 10
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 479
EP 503
DI 10.1007/s11042-014-1977-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300010
DA 2024-07-18
ER

PT J
AU Mao, Y
   Peng, J
   Guo, Y
   Huang, DZ
   Lee, MH
AF Mao, Yun
   Peng, Jun
   Guo, Ying
   Huang, Dazu
   Lee, Moon Ho
TI On high-rate full-diversity space-time-frequency code with partial
   interference cancelation group decoding for frequency-selective channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maximum likelihood decoding; Partial interference cancelation decoding;
   Full-diversity; Frequency-selective channels; Wireless networks
ID BLOCK-CODES; OFDM
AB An explicit design of a linear dispersive space-time-frequency (STF) code is investigated with a design criterion achieving a high rate for frequency-selective channels when the partial interference cancelation (PIC) group decoding is implemented at receiver. With an appropriate grouping scheme, the proposed STF code is shown to obtain a similar diversity gain as that of the maximum likelihood (ML) decoding, namely the full-dimensional sphere decoding, but with a low complexity. It seems as an intermediate decoding approach between the ML decoding and the zero-forcing (ZF) decoding. The present grouping design criterion for the PIC group decoding that provides full diversity with orthogonal-frequency-division multiplexing (OFDM) is also an intermediate condition between the loosest ML full rank criterion of codewords and the strongest ZF linear independence of column vectors of the equivalent frequency-selective channel matrix. Simulation results show that the proposed PIC group decoding scheme can well address the rate-performance-complexity tradeoff of the multiple-input multiple-output orthogonal-frequency-division multiplexing (MIMO-OFDM) wireless communication system.
C1 [Mao, Yun; Peng, Jun; Guo, Ying] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Peoples R China.
   [Huang, Dazu] Hunan Univ Finance & Econ, Dept Informat Management, Changsha 410205, Hunan, Peoples R China.
   [Lee, Moon Ho] Chonbuk Natl Univ, Inst Informat & Commun Engn, Chonju 561756, South Korea.
C3 Central South University; Hunan University of Finance & Economics;
   Jeonbuk National University
RP Huang, DZ (corresponding author), Hunan Univ Finance & Econ, Dept Informat Management, Changsha 410205, Hunan, Peoples R China.
EM yingguo@csu.edu.cn; dazuhuang@126.com; moonho@chonbuk.ac.kr
FU National Natural Science Foundation of China [61071096, 61272495]; World
   Class University, Korea [R32-2012-000-20014-0 NRF]; Science and
   technology program of Hunan Province in China [2012TZ2017]; Education
   Science Twelfth Five Plan Project of Hunan Province in China
   [XJK011BGD050]; bilateral cooperation of the science foundation between
   China and Korea [NSFC-NRF 61111140391]
FX This work was supported by the National Natural Science Foundation of
   China (61071096, 61272495), World Class University R32-2012-000-20014-0
   NRF, Korea, and partly by the Science and technology program of Hunan
   Province in China (2012TZ2017), the Education Science Twelfth Five Plan
   Project of Hunan Province in China (XJK011BGD050), and the bilateral
   cooperation of the science foundation between China and Korea (NSFC-NRF
   61111140391).
CR Alamouti SM, 1998, IEEE J SEL AREA COMM, V16, P1451, DOI 10.1109/49.730453
   Gong Y, 2001, GLOB TELECOMM CONF, P519, DOI 10.1109/GLOCOM.2001.965171
   Guo XY, 2009, IEEE T INFORM THEORY, V55, P4366, DOI 10.1109/TIT.2009.2027502
   Heath RW, 2002, IEEE T SIGNAL PROCES, V50, P2429, DOI 10.1109/TSP.2002.803325
   Jafarkhani H, 2001, IEEE T COMMUN, V49, P1, DOI 10.1109/26.898239
   Shang Y, 2008, IEEE T INFORM THEORY, V54, P4528, DOI 10.1109/TIT.2008.928986
   Shang Y, 2007, GLOB TELECOMM CONF, P2927
   Su WF, 2005, IEEE T INFORM THEORY, V51, P229, DOI 10.1109/TIT.2004.839496
   Su WF, 2005, IEEE T WIREL COMMUN, V4, P1847, DOI 10.1109/TWC.2005.850323
   Zhang JK, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY (ISIT), VOLS 1 AND 2, P1942
   Zhang W, 2007, IEEE T COMMUN, V55, P25, DOI 10.1109/TCOMM.2006.885058
   Zhang W, 2007, IEEE WIREL COMMUN, V14, P32, DOI 10.1109/MWC.2007.386610
NR 12
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 43
EP 61
DI 10.1007/s11042-013-1446-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300004
DA 2024-07-18
ER

PT J
AU Song, XH
   Jiang, SQ
   Wang, SH
   Li, L
   Huang, QM
AF Song, Xinghang
   Jiang, Shuqiang
   Wang, Shuhui
   Li, Liang
   Huang, Qingming
TI Polysemious visual representation based on feature aggregation for large
   scale image applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Polysemious representation; Feature aggregation; Max pooling; Large
   scale
ID CLASSIFICATION; ANNOTATION; SCENE; WEB
AB Multiple image features and multiple semantic concepts from the images have intrinsic and complex relations. These relations influence the effectiveness of image semantic analysis methods, especially on the large scale problems. In this paper, a framework of generating polysemious image representation through three levels of feature aggregation is proposed. In the codebook level aggregation, visual dictionaries are learned for each feature type, and each image feature can be reconstructed with this dictionary. In the semantic level aggregation, the multiple concept distributions are learned with each feature codebook by using the improved local anchor embedding. Then the polysemious representation for for single feature type can be established after this level. In the multiple feature level aggregation, final image polysemious representation is obtained through multiple feature fusion with a weighted pooling approach. Through the proposed framework, multiple feature fusion and multiple semantic descriptions are both achieved in an integrated way. Experimental evaluations on large scale image dataset validate the effectiveness of the proposed method.
C1 [Song, Xinghang; Jiang, Shuqiang; Wang, Shuhui] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Li, Liang; Huang, Qingming] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Song, XH (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, 6 Kexueyuan South Rd Zhongguancun, Beijing, Peoples R China.
EM xinhang.song@vipl.ict.ac.cn; shuqiang.jiang@vipl.ict.ac.cn;
   shuhui.wang@vipl.ict.ac.cn; liang.li@vipl.ict.ac.cn; qmhuang@jdl.ac.cn
OI Li, Liang/0000-0002-1943-8219
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61322212, 61025011,
   61332016, 61303160]; Key Technologies R&D Program of China
   [2012BAH18B02]; National Hi-Tech Development Program (863 Program) of
   China [2014AA015202]
FX This work was supported in part by National Basic Research Program of
   China (973 Program):2012CB316400, in part by National Natural Science
   Foundation of China: 61322212, 61025011, 61332016, 61303160 in part by
   the Key Technologies R&D Program of China:2012BAH18B02 and in part by in
   part by National Hi-Tech Development Program (863 Program) of China:
   2014AA015202.
CR [Anonymous], 2011, CVPR
   [Anonymous], 2011, CVPR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], ECCV
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], ICCV
   Binder A, 2011, INT J COMPUT VISION, P1
   Bo L., 2010, ADV NEURAL INFORM PR, V23, P244
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Cao Liujuan., 2012, CVPR
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Feng Jiashi., 2012, ECCV
   Gehler Peter., 2009, ICCV
   Hwang S.J., 2011, CVPR
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li L.-j., 2010, NIPS
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Liu, 2010, P 27 INT C MACH LEAR, P679, DOI DOI 10.1007/s11263-007-0090-8
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451
   Rasiwasia N, 2012, IEEE T PATTERN ANAL, V34, P902, DOI 10.1109/TPAMI.2011.175
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tang JH, 2012, IEEE T IMAGE PROCESS, V21, P2354, DOI 10.1109/TIP.2011.2180916
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Wang H., 2010, AAAI
   Wang Jiang., 2011, CVPR
   Wang S., 2012, In CVPR
   Wei S, 2013, IEEE T CYBERN
   Wei SK, 2011, IEEE T CIRC SYST VID, V21, P15, DOI 10.1109/TCSVT.2011.2105554
   Wei SK, 2010, IEEE T KNOWL DATA EN, V22, P1191, DOI 10.1109/TKDE.2009.145
   Wu F, 2010, ACM MULTIMEDIA
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
NR 42
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 595
EP 611
DI 10.1007/s11042-014-1975-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300016
DA 2024-07-18
ER

PT J
AU Yi, YG
   Zhang, BX
   Kong, J
   Wang, JZ
AF Yi, Yugen
   Zhang, Baoxue
   Kong, Jun
   Wang, Jianzhong
TI An improved locality sensitive discriminant analysis approach for
   feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Outliers; ILSDA; Face image recognition
ID NONLINEAR DIMENSIONALITY REDUCTION; FACE-RECOGNITION
AB Recently, Locality Sensitive Discriminant Analysis (LSDA) has been proposed as an efficient feature extraction approach. By analyzing the local manifold structure of high-dimensional data, LSDA can obtain a subspace in which the nearby points with the same label are close to each other while the nearby points with different labels are far apart. However, because LSDA only takes the local information into consideration, it may fail to deal with the data set which contains some outliers. In order to address this limitation, a new algorithm called Improved Locality Sensitive Discriminant Analysis (ILSDA) is proposed in this paper. By integrating the intra-class scatter matrix into our algorithm, ILSDA can not only preserve the local discriminant neighborhood structure of the data, but also pull the outlier samples more close to their class centers, which makes it outperform the original LSDA and some other state of the art algorithms. Extensive experimental results on several publicly available image datasets show the feasibility and effectiveness of our proposed approach.
C1 [Yi, Yugen; Kong, Jun] NE Normal Univ, Coll Comp Sci & Informat Technol, Changchun, Peoples R China.
   [Kong, Jun] NE Normal Univ, Key Lab Intelligent Informat Proc Jilin Univ, Changchun, Peoples R China.
   [Yi, Yugen; Zhang, Baoxue] NE Normal Univ, Sch Math & Stat, Changchun, Peoples R China.
   [Wang, Jianzhong] NE Normal Univ, Natl Engn Lab Druggable Gene & Prot Screening, Changchun, Peoples R China.
C3 Northeast Normal University - China; Northeast Normal University -
   China; Northeast Normal University - China; Northeast Normal University
   - China
RP Kong, J (corresponding author), NE Normal Univ, Coll Comp Sci & Informat Technol, Changchun, Peoples R China.
EM kongjun@nenu.edu.cn; wangjz019@nenu.edu.cn
RI Zhang, Bao/B-3926-2012
OI Yi, Yugen/0000-0002-1049-5022; Yi, Yugen/0000-0001-9828-0319
FU Jilin Provincial Science & Technology Department [201115003, 20111804];
   Fundamental Research Funds for the Central Universities [11QNJJ005];
   Science Foundation for Post-doctor of Jilin Province [2011274]; Program
   for New Century Excellent Talents in University [NCET-09-0284]; National
   Natural Science Foundation of China [11271064]
FX This work is supported by Fund of Jilin Provincial Science & Technology
   Department (No. 201115003, 20111804), Fundamental Research Funds for the
   Central Universities (No. 11QNJJ005), the Science Foundation for
   Post-doctor of Jilin Province (No. 2011274), Program for New Century
   Excellent Talents in University (NCET-09-0284), and the National Natural
   Science Foundation of China (No. 11271064).
CR Belkin M, 2002, ADV NEUR IN, V14, P585
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   CAI D, 2007, P 2007 INT JOINT C A
   CAI D, 2007, P AAAI C ART INT
   Chen HT, 2005, PROC CVPR IEEE, P846
   Chin TJ, 2008, IEEE T PATTERN ANAL, V30, P1547, DOI 10.1109/TPAMI.2007.70813
   Fu Y., 2005, LOCALLY LINEAR EMBED
   Gao QX, 2012, PATTERN RECOGN, V45, P3717, DOI 10.1016/j.patcog.2012.03.024
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017
   Hastie T., 2009, ELEMENTS STAT LEARNI
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu HF, 2008, PATTERN RECOGN, V41, P2045, DOI 10.1016/j.patcog.2007.10.029
   Hua Q, 2012, NEUROCOMPUTING, V86, P150, DOI 10.1016/j.neucom.2012.01.031
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li B, 2008, PATTERN RECOGN, V41, P3287, DOI 10.1016/j.patcog.2008.05.014
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ., 2004, The facial recognition technology (feret) database
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wan M, 2011, IET COMPUT VIS, V5, P301, DOI 10.1049/iet-cvi.2011.0028
   Wang JZ, 2010, IMAGE VISION COMPUT, V28, P1624, DOI 10.1016/j.imavis.2010.05.001
   Wang Y, 2010, PATTERN RECOGN, V43, P1008, DOI 10.1016/j.patcog.2009.08.009
   Wong WK, 2012, PATTERN RECOGN, V45, P186, DOI 10.1016/j.patcog.2011.05.014
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang HG, 2010, MACH VISION APPL, V21, P577, DOI 10.1007/s00138-009-0213-z
   Zhang TH, 2007, NEUROCOMPUTING, V70, P1547, DOI 10.1016/j.neucom.2006.11.007
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhao HT, 2006, PATTERN RECOGN, V39, P1546, DOI 10.1016/j.patcog.2006.02.023
NR 34
TC 13
Z9 15
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 85
EP 104
DI 10.1007/s11042-013-1429-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300006
DA 2024-07-18
ER

PT J
AU Martin-Dorta, N
   Sanchez-Berriel, I
   Bravo, M
   Hernandez, J
   Saorin, JL
   Contero, M
AF Martin-Dorta, Norena
   Sanchez-Berriel, Isabel
   Bravo, Miguel
   Hernandez, Juan
   Luis Saorin, Jose
   Contero, Manuel
TI Virtual Blocks: a serious game for spatial ability improvement on mobile
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial abilities; Mobile gaming; Multimedia applications; Education and
   training
ID GENDER-DIFFERENCES; EXPERIENCE; COMPUTER
AB This paper presents a novel spatial instruction system for improving spatial abilities of engineering students. A 3D mobile game application called Virtual Blocks has been designed to provide a 3D virtual environment to build models with cubes that help students to perform visualization tasks to promote the development of their spatial ability during a short remedial course. A validation study with 26 freshman engineering students at La Laguna University (Spain) has concluded that the training had a measurable and positive impact on students' spatial ability. In addition, the results obtained using a satisfaction questionnaire show that Virtual Blocks is considered an easy to use and stimulating application.
C1 [Martin-Dorta, Norena; Sanchez-Berriel, Isabel; Bravo, Miguel; Hernandez, Juan; Luis Saorin, Jose] Univ La Laguna, Dehaes Res Grp, Tenerife, Spain.
   [Contero, Manuel] Univ Politecn Valencia, Inst Bioingn & Tecnol Orientada Ser Humano, E-46071 Valencia, Spain.
C3 Universidad de la Laguna; Universitat Politecnica de Valencia
RP Martin-Dorta, N (corresponding author), Univ La Laguna, Dehaes Res Grp, Tenerife, Spain.
EM nmartin@ull.edu.es; isanchez@ull.es; alu2218@etsii.ull.es;
   alu2644@etsii.ull.es; jlsaorin@ull.es; mcontero@labdesign.i3bh.es
RI Hernández, José/JKI-8418-2023; luis, José/Z-5533-2019; Hernandez, Juan
   C./C-1621-2018; Contero, Manuel/F-4276-2010; Sánchez-Berriel,
   Isabel/ABE-9843-2021; Martín-Dorta, Norena/E-5215-2012
OI Hernández, José/0009-0006-6689-6980; luis, José/0000-0003-3240-3317;
   Hernandez, Juan C./0000-0002-9200-5698; Contero,
   Manuel/0000-0002-6081-9988; Martín-Dorta, Norena/0000-0002-5704-5133;
   Sanchez-Berriel, Isabel/0000-0003-3279-9438
FU (Spanish) National Program for Studies and Analysis project "Evaluation
   and development of competencies associated to the spatial ability in the
   new engineering undergraduate courses" [EA2009-0025]; (Spanish) National
   Science Project "Enhancing Spatial REasoning and VIsual Cognition with
   advanced technological tools (ESREVIC)" [TIN2010-21296-C02-02]
FX This work has been partially supported by the (Spanish) National Program
   for Studies and Analysis project "Evaluation and development of
   competencies associated to the spatial ability in the new engineering
   undergraduate courses" (Ref. EA2009-0025) and the (Spanish) National
   Science Project "Enhancing Spatial REasoning and VIsual Cognition with
   advanced technological tools (ESREVIC)" (Ref TIN2010-21296-C02-02)
CR [Anonymous], 2000, Sex differences in cognitive abilities
   Baartmans B.G., 1996, Introduction to 3-D spatial visualization
   Clements D. H., 1992, Handbook of research on mathematics teaching and learning, P420
   Cohen J., 1988, STAT POWER ANAL BEHA
   DeLisi R, 1996, COMPUT HUM BEHAV, V12, P351, DOI 10.1016/0747-5632(96)00013-1
   Deno J.A., 1995, Engineering Design Graphics Journal, V59, P5
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   FRENCH JW, 1951, PSYCHOMETRIC MONOGRA, V5
   Guilford JP, 1947, 5 AAF
   Hofele C, 2007, MOBILE 3D GRAPHICS L
   Kajiya J. T., 1989, Computer Graphics, V23, P271, DOI 10.1145/74334.74361
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   Martin-Dorta N., 2010, 2010 10 IEEE INT C A, P6
   Martin-Dorta N, 2011, EDUC TECHNOL SOC, V14, P163
   Martín-Dorta N, 2008, J ENG EDUC, V97, P505, DOI 10.1002/j.2168-9830.2008.tb00996.x
   MCGEE MG, 1979, PSYCHOL BULL, V86, P889, DOI 10.1037/0033-2909.86.5.889
   Noguera JM, 2011, COMPUT GEOSCI-UK, V37, P1218, DOI 10.1016/j.cageo.2010.08.007
   Okagaki L., 1994, Journal of Applied Developmental Psychology, V15, P33, DOI DOI 10.1016/0193-3973(94)90005-1
   Pulli Kari., 2007, Mobile 3D Graphics: with OpenGL ES and M3G
   Quaiser-Pohl C, 2006, PERS INDIV DIFFER, V40, P609, DOI 10.1016/j.paid.2005.07.015
   Smith I.M., 1964, Spatial ability, its educational and social significance
   Sorby S.A., 2007, Australian Journal of Engineering Education, V13, P1, DOI [DOI 10.1080/22054952.2007.11463998, https://doi.org/10.1080/22054952.2007.11463998]
   Terlecki MS, 2008, APPL COGNITIVE PSYCH, V22, P996, DOI 10.1002/acp.1420
   Terlecki MS, 2005, SEX ROLES, V53, P433, DOI 10.1007/s11199-005-6765-0
   Thurstone L.L., 1941, PSYCHOMETRIC MONOGRA
   Thurstone LL, 1950, 59 IL U CHIC PSYCH L
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   Zimmerman WS, 1954, EDUC PSYCHOL MEAS, V14, P396, DOI 10.1177/001316445401400220
NR 28
TC 10
Z9 14
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1575
EP 1595
DI 10.1007/s11042-013-1652-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200021
DA 2024-07-18
ER

PT J
AU Su, XP
   Peng, JY
   Feng, XY
   Wu, J
   Fan, JP
   Cui, L
AF Su, Xueping
   Peng, Jinye
   Feng, Xiaoyi
   Wu, Jun
   Fan, Jianping
   Cui, Li
TI Cross-modality based celebrity face naming for news image collections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affinity propagation cluster; Cross-modality; Face classification; Rank
   aggregation
ID PEOPLE; NAMES
AB For automatically mining the underlying relationships between different famous persons in daily news, for example, building a news person based network with the faces as icons to facilitate face-based person finding, we need a tool to automatically label faces in new images with their real names. This paper studies the problem of linking names with faces from large-scale news images with captions. In our previous work, we proposed a method called Person-based Subset Clustering which is mainly based on face clustering for all face images derived from the same name. The location where a name appears in a caption, as well as the visual structural information within a news image provided informative cues such as who are really in the associated image. By combining the domain knowledge from the captions and the corresponding image we propose a novel cross-modality approach to further improve the performance of linking names with faces. The experiments are performed on the data sets including approximately half a million news images from Yahoo! news, and the results show that the proposed method achieves significant improvement over the clustering-only methods.
C1 [Su, Xueping; Peng, Jinye; Feng, Xiaoyi; Wu, Jun; Fan, Jianping; Cui, Li] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Su, XP (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM yifeichongtian1201@163.com; jinyepeng@nwpu.edu.cn; fengxiao@nwpu.edu.cn;
   junwu@nwpu.edu.cn; jfan@uncc.edu; l.cui@nwpu.edu.cn
RI Peng, Jin/HZH-6965-2023
FU doctorate foundation of Northwestern Polytechnical University
   [CX201114]; Ministry of Education Fund for Doctoral Students Newcomer
   Awards of China; National Natural Science Foundation of China [61075014,
   61272285, 61103062]; Research Fund for the Doctoral Program of Higher
   Education [20106102110028, 20116102110027, 20116102120031,
   20126101110022]; Science and technology project of Shaanxi Province
   [2013K06-29]; NPU Basic Research Foundation [JC201249]
FX This work is supported by the doctorate foundation of Northwestern
   Polytechnical University under CX201114, Ministry of Education Fund for
   Doctoral Students Newcomer Awards of China, National Natural Science
   Foundation of China under Grant 61075014, 61272285, 61103062, The
   Research Fund for the Doctoral Program of Higher Education under Grant
   20106102110028, 20116102110027, 20116102120031, 20126101110022, The
   Science and technology project of Shaanxi Province under Grant
   2013K06-29, and NPU Basic Research Foundation under Grant JC201249.
CR [Anonymous], P EUR C COMP VIS E 2
   Berg TL, 2004, PROC CVPR IEEE, P848
   Cunningham H, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P168
   Forsyth, 2005, ADV NEURAL INFORM PR, V17, P137
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Guillaumin M., 2008, Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, P1
   Guillaumin M, 2010, LECT NOTES COMPUT SC, V6311, P634, DOI 10.1007/978-3-642-15549-9_46
   Le DD, 2008, IEEE DATA MINING, P383, DOI 10.1109/ICDM.2008.47
   Mensink T, 2008, LECT NOTES COMPUT SC, V5303, P86, DOI 10.1007/978-3-540-88688-4_7
   Ozkan D, 2010, PATTERN RECOGN, V43, P1717, DOI 10.1016/j.patcog.2009.10.015
   Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Pham PT, 2010, IEEE MULTIMEDIA, V18, P44
   Poppe R, 2012, PATTERN RECOGN, V45, P2335, DOI 10.1016/j.patcog.2011.12.018
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang J, 2004, LECT NOTES COMPUT SC, V3115, P270
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 17
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1643
EP 1661
DI 10.1007/s11042-013-1578-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200024
DA 2024-07-18
ER

PT J
AU Aissaoui, A
   Martinet, J
   Djeraba, C
AF Aissaoui, Amel
   Martinet, Jean
   Djeraba, Chaabane
TI Rapid and accurate face depth estimation in passive stereo systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth estimation; Stereo matching; Active Shape Model; Face analysis
ID 3D SHAPE; RECOGNITION; RECONSTRUCTION
AB In this paper, we introduce a novel approach for face depth estimation in a passive stereo vision system. Our approach is based on rapid generation of facial disparity maps, requiring neither expensive devices nor generic face models. It consists in incorporating face properties into the disparity estimation process to enhance the 3D face reconstruction. We propose a model-based method that is independent from the specific stereo algorithm used. Our method is a two-step process. First, an algorithm based on the Active Shape Model (ASM) is proposed to acquire a disparity model specific to the face concerned. Second, using this model as a guidance, the dense disparity is calculated and the depth map is estimated. Besides, an original post-processing algorithm is proposed in order to detect holes and spikes in the generated depth maps caused by wrong matches and uncertainties. It is based on the smoothness property of the face and a local and global analysis of the image. Experimental results are presented to demonstrate the reconstruction accuracy and the speed of the proposed method.
C1 [Aissaoui, Amel; Martinet, Jean; Djeraba, Chaabane] Lab Informat Fondamentale Lille, F-59650 Villeneuve Dascq, France.
C3 Universite de Lille
RP Aissaoui, A (corresponding author), Lab Informat Fondamentale Lille, 50 Halley Ave, F-59650 Villeneuve Dascq, France.
EM amel.aissaoui@lifl.fr; jean.martinet@lifl.fr; chabane.djeraba@lifl.fr
RI Djeraba, Chaabane/AAC-6311-2020; Djeraba, Chaabane/ABI-8490-2020
OI Djeraba, Chaabane/0000-0003-4579-9592
CR Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Chow CK, 2009, INT J COMPUT VISION, V85, P58, DOI 10.1007/s11263-009-0240-2
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CRYER JE, 1995, PATTERN RECOGN, V28, P1033, DOI 10.1016/0031-3203(94)00183-M
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Fortuna J, 2010, INT J COMPUT VISION, V88, P404, DOI 10.1007/s11263-009-0313-2
   Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]
   Hirschmüller H, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P141, DOI 10.1109/SMBV.2001.988772
   Huang D, 2011, LECT NOTES COMPUT SC, V6523, P206
   Huang Y., 2006, BMVC, P879
   Jongmoo Choi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3959, DOI 10.1109/ICPR.2010.963
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Koo HS, 2008, PATTERN RECOGN LETT, V29, P712, DOI 10.1016/j.patrec.2007.11.018
   Le V, 2010, IEEE IMAGE PROC, P4265, DOI 10.1109/ICIP.2010.5651875
   Lengagne R, 2000, IMAGE VISION COMPUT, V18, P337, DOI 10.1016/S0262-8856(99)00058-X
   Lin WY, 2014, MULTIMED TOOLS APPL, V68, P877, DOI 10.1007/s11042-012-1092-2
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Park U., 2006, Third Canadian Conference on Computer and Robot Vision (CRV'06), P41, DOI DOI 10.1109/CRV.2006.1
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Sun ZL, 2013, IEEE T IMAGE PROCESS, V22, P17, DOI 10.1109/TIP.2012.2204269
   Sun ZL, 2011, IEEE T INF FOREN SEC, V6, P360, DOI 10.1109/TIFS.2011.2118207
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Wang SF, 2011, IEEE T PATTERN ANAL, V33, P2115, DOI 10.1109/TPAMI.2011.88
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Xiao J, 2004, PROC CVPR IEEE, P535
   Yan P, 2007, COMPUT VIS IMAGE UND, V107, P195, DOI 10.1016/j.cviu.2006.11.001
   ZHENG Y, 2007, IEEE INT C IM PROC I, P65, DOI DOI 10.1109/ICIP.2007.4379247
NR 32
TC 6
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2413
EP 2438
DI 10.1007/s11042-013-1556-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300017
DA 2024-07-18
ER

PT J
AU Wang, C
   Wang, YH
   Zhang, ZX
   Wang, YD
AF Wang, Chao
   Wang, Yunhong
   Zhang, Zhaoxiang
   Wang, Yiding
TI Incremental learning patch-based bag of facial words representation for
   face recognition in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video analysis; Face recognition; Biometrics; Incremental learning; Bag
   of words
ID SETS
AB Video-based face recognition is a fundamental topic in image processing and video analysis, and presents various challenges and opportunities. In this paper, we introduce an incremental learning approach to video-based face recognition which efficiently exploits the spatiotemporal information in videos. Face image sequences are incrementally clustered based on their descriptors, and the representative face images of each cluster are picked out. The incremental algorithm of creating facial visual words is applied to construct a codebook using the descriptors of the representative face images. Continuously, with the quantization of the facial visual words, each descriptor extracted from patches is converted into codes, and codes from each region are pooled together into a histogram. The representation of the face image is generated by concatenating the histograms from all regions, which is employed to perform the categorization. In the online recognition, a similarity score matrix and a voting algorithm are employed to judge a face video's identity. Recognition is performed online while face video sequence is continuous and the proposed method gives nearly realtime feedback. The proposed method achieves a 100 % verification rate on the Honda/UCSD database and 82 % on the YouTube datebase. Experimental results demonstrate the effectiveness and flexibility of the proposed method.
C1 [Wang, Chao; Wang, Yunhong; Zhang, Zhaoxiang] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Lab Intelligent Recognit & Image Proc, Beijing 100191, Peoples R China.
   [Wang, Yiding] North China Univ Technol, Sch Informat Engn, Beijing, Peoples R China.
C3 Beihang University; North China University of Technology
RP Zhang, ZX (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Lab Intelligent Recognit & Image Proc, Beijing 100191, Peoples R China.
EM zxzhang@buaa.edu.cn
RI Wang, Yiru/JMB-2281-2023; Wang, Yijun/GXW-1763-2022; wang,
   yan/GSE-6489-2022; wang, yixuan/GXW-2866-2022; Wang,
   yanru/JAX-5241-2023; wang, yi/GVT-8516-2022; Wang, Yixuan/GZK-6559-2022;
   xu, chen/JNE-5010-2023
FU National Basic Research Program of China [2010CB327902]; National
   Natural Science Foundation of China [61005016, 61061130560]; National
   High-tech R&D Program of China [2011AA010502]; Open Projects Program of
   National Laboratory of Pattern Recognition; Fundamental Research Funds
   for the Central Universities
FX This work is funded by the National Basic Research Program of China (No.
   2010CB327902), the National Natural Science Foundation of China (No.
   61005016, No. 61061130560), the National High-tech R&D Program of China
   (2011AA010502), the Open Projects Program of National Laboratory of
   Pattern Recognition, and the Fundamental Research Funds for the Central
   Universities.
CR Aggarwal G, 2004, INT C PATT RECOG, P175, DOI 10.1109/ICPR.2004.1333732
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], P ICME
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Collins RT, 2003, PROC CVPR IEEE, P234
   Cui Z, 2012, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2012.6247982
   Fan W, 2005, LECT NOTES COMPUT SC, V3546, P122
   Fischer M, 2011, MULTIMED TOOLS APPL, V55, P83, DOI 10.1007/s11042-010-0603-2
   Gkalelis N, 2013, IEEE T NEUR NET LEAR, V24, P8, DOI 10.1109/TNNLS.2012.2216545
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hadid A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P813, DOI 10.1109/AFGR.2004.1301634
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Huang KS, 2002, INT C PATT RECOG, P213, DOI 10.1109/ICPR.2002.1047435
   Kim M., 2008, P CVPR, P1
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee KC, 2005, COMPUT VIS IMAGE UND, V99, P303, DOI 10.1016/j.cviu.2005.02.002
   Lee KC, 2003, PROC CVPR IEEE, P313
   Liu L., 2007, Computer Vision and Pattern Recognition, P1
   Liu XM, 2003, PROC CVPR IEEE, P340
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matta F, 2006, LECT NOTES COMPUT SC, V4069, P326
   Matta F, 2009, J VISUAL LANG COMPUT, V20, P180, DOI 10.1016/j.jvlc.2009.01.002
   Mian A, 2011, PATTERN RECOGN, V44, P1068, DOI 10.1016/j.patcog.2010.12.001
   Phillips P.J., 2003, Face Recognition Vendor Test (FRVT) 2002: Evaluation Report
   Poh N, 2010, IEEE T INF FOREN SEC, V5, P781, DOI 10.1109/TIFS.2010.2077627
   Schneider JW, 2007, J AM SOC INF SCI TEC, V58, P1586, DOI 10.1002/asi.20643
   Schwarze T, 2013, MULTIMED TOOLS APPL, V63, P501, DOI 10.1007/s11042-011-0834-x
   Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yilmazturk MC, 2013, MULTIMED TOOLS APPL, V63, P591, DOI 10.1007/s11042-011-0884-0
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zisheng Li, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1285, DOI 10.1109/ICPR.2010.320
NR 37
TC 2
Z9 3
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2439
EP 2467
DI 10.1007/s11042-013-1562-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300018
DA 2024-07-18
ER

PT J
AU Dooms, S
   De Pessemier, T
   Verslype, D
   Nelis, J
   De Meulenaere, J
   Van den Broeck, W
   Martens, L
   Develder, C
AF Dooms, Simon
   De Pessemier, Toon
   Verslype, Dieter
   Nelis, Jelle
   De Meulenaere, Jonas
   Van den Broeck, Wendy
   Martens, Luc
   Develder, Chris
TI OMUS: an optimized multimedia service for the home environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Information systems; Graphical user interfaces; DLNA;
   Recommender systems; Algorithms
ID UPNP; IMPLEMENTATION
AB Media content in home environments is often scattered across multiple devices in the home network. As both the available multimedia devices in the home (e.g., smartphones, tablets, laptops, game consoles, etc.) and the available content (video and audio) is increasing, interconnecting desired content with available devices is becoming harder and home users are experiencing difficulties in selecting interesting content for their current context. In this paper, we start with an analysis of the home environment by means of a user study. Information handling problems are identified and requirements for a home information system formulated. To meet these requirements we propose the OMUS home information system which includes an optimized content aggregation framework, a hybrid group-based contextual recommender system, and an overall web-based user interface making both content and recommendations available for all devices across the home network. For the group recommendations we introduced distinct weights for each user and showed that by varying the weights, the coverage (i.e., items that can be returned by the recommender) considerably increases. Also the addition of genre filter functionality was proven to further boost the coverage. The OMUS system was evaluated by means of focus groups and by qualitative and quantitative performance assessment of individual parts of the system. The modularity of internal components and limited imposed hardware requirements implies flexibility as to how the OMUS system can be deployed (ranging from e.g., embedded in hardware devices or more software services based).
C1 [Dooms, Simon; De Pessemier, Toon; Martens, Luc] Univ Ghent, iMinds, WiCa, B-9050 Ghent, Belgium.
   [Verslype, Dieter; Nelis, Jelle; Develder, Chris] Univ Ghent, iMinds, IBCN, B-9050 Ghent, Belgium.
   [De Meulenaere, Jonas; Van den Broeck, Wendy] VUB, iMinds, SMIT, B-1050 Brussels, Belgium.
C3 Ghent University; IMEC; Ghent University; IMEC; Vrije Universiteit
   Brussel; IMEC
RP Dooms, S (corresponding author), Univ Ghent, iMinds, WiCa, G Crommenlaan 8 Box 201, B-9050 Ghent, Belgium.
EM simon.dooms@intec.ugent.be; toon.depessemier@intec.ugent.be;
   dieter.verslype@intec.ugent.be; jelle.nelis@intec.ugent.be;
   jdemeule@vub.ac.be; wendy.van.den.broeck@vub.ac.be;
   luc.martens@intec.ugent.be; chris.develder@intec.ugent.be
RI Develder, Chris/S-6359-2019; Van den Broeck, Wendy/ADN-2431-2022; Van
   den Broeck, Wendy/JAC-6551-2023
OI Develder, Chris/0000-0003-2707-4176; Van den Broeck,
   Wendy/0000-0002-4765-6125; Van den Broeck, Wendy/0000-0002-4765-6125
FU iMinds/OMUS project; Agency for Innovation by Science and Technology
   (IWT Vlaanderen); Research Foundation-Flanders (FWO-VL); FWO-Vl
FX This work was supported by the iMinds/OMUS project. The described
   research activities were funded by a PhD grant to Simon Dooms of the
   Agency for Innovation by Science and Technology (IWT Vlaanderen), and a
   PhD grant to Toon De Pessemier of the Research Foundation-Flanders
   (FWO-VL). C. Develder was supported (in part) as post-doctoral fellow of
   FWO-Vl.
CR Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Bellandi V., 2012, 2012 6 IEEE INT C DI, P1
   Bellogin Alejandro, 2010, International Workshop on Information Heterogeneity and Fusion in Recommender Systems, P1
   Bennett J, 2007, P KDD CUP WORKSH, P3
   Berkovsky J., 2010, P 4 ACM C REC SYST, P111
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Brewka L, 2011, IEEE T CONSUM ELECTR, V57, P1670, DOI 10.1109/TCE.2011.6131140
   BURKE R, 2000, ENCY LIB INF SYS S32, V69
   Cho SY, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P98, DOI 10.1109/ICCE.2002.1013943
   De Pessemier T, 2012, P 6 ACM C REC SYST R
   Develder C, 2012, TELECOMMUN SYST, V49, P129, DOI 10.1007/s11235-010-9358-3
   Dooms S, 2011, UCERSTI WORKSH US CE
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Guedes ALV, 2008, CONSUM COMM NETWORK, P1257, DOI 10.1109/ccnc08.2007.297
   Jameson A., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P596
   JERONIMO M., 2003, UPNP DESIGN EXAMPLE
   Kang DO, 2005, IEEE ICCE, P405
   Kawamoto E., 2009, CONS COMM NETW C 200, P1
   Kim DS, 2002, IEEE T CONSUM ELECTR, V48, P963, DOI 10.1109/TCE.2003.1196427
   Kim J, 2007, IEEE INT SYMP ELECTR, P170, DOI 10.1109/ISEE.2007.369388
   Lee H, 2007, IEEE T CONSUM ELECTR, V53, P1419, DOI 10.1109/TCE.2007.4429232
   Masthoff J, 2004, USER MODEL USER-ADAP, V14, P37, DOI 10.1023/B:USER.0000010138.79319.fd
   McCarthy J. F., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P363, DOI 10.1145/289444.289511
   Mobasher B., 2007, KUNSTL INTELL SPEC I, V3, P41
   Nelis J, 2012, P 37 IEEE C LOC COMP
   Nelis J, 2011, C LOCAL COMPUT NETW, P203, DOI 10.1109/LCN.2011.6115189
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Purcell K., 2010, STATE ONLINE VIDEO
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Sales Thiago, 2008, Second International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies 2008, P206, DOI 10.1109/UBICOMM.2008.87
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Van den Broeck W, 2011, THESIS VRIJE U BRUSS
NR 32
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 281
EP 311
DI 10.1007/s11042-012-1347-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800014
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, KW
   Chen, SY
   Su, SZ
   Duh, DJ
   Zhang, HB
   Li, SZ
AF Li, Kuo-Wei
   Chen, Shu-Yuan
   Su, Songzhi
   Duh, Der-Jyh
   Zhang, Hongbo
   Li, Shaozi
TI Logo detection with extendibility and discrimination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logo detection; Logo recognition; Edge-based histogram of oriented
   gradient; Affine scale invariant feature transform; Multi-scale sliding
   window scanning
ID SHAPE
AB Logos are specially designed marks that identify goods, services, and organizations using distinguished characters, graphs, signals, and colors. Identifying logos can facilitate scene understanding, intelligent navigation, and object recognition. Although numerous logo recognition methods have been proposed for printed logos, a few methods have been specifically designed for logos in photos. Furthermore, most recognition methods use codebook-based approaches for the logos in photos. A codebook-based method is concerned with the generation of visual words for all the logo models. When new logos are added, the codebook reconstruction is required if effectiveness is a crucial factor. Moreover, logo detection in natural scenes is difficult because of perspective tilt and non-rigid deformation. Therefore, this study develops an extendable, but discriminating, model-based logo detection method. The proposed logo detection method is based on a support vector machine (SVM) using edge-based histograms of oriented gradient (HOGE) as features through multi-scale sliding window scanning. Thereafter, anti-distortion affine scale invariant feature transform (ASIFT) is used for logo verification with constraints on the ASIFT matching pairs and neighbors. The experimental results using the public Flickr-Logo database confirm that the proposed method has a higher retrieval and precision accuracy compared to existing model-based methods.
C1 [Li, Kuo-Wei; Chen, Shu-Yuan] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
   [Su, Songzhi; Zhang, Hongbo; Li, Shaozi] Xiamen Univ, Sch Informat Sci & Technol, Xiamen, Fujian, Peoples R China.
   [Su, Songzhi; Zhang, Hongbo; Li, Shaozi] Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen, Fujian, Peoples R China.
   [Duh, Der-Jyh] Chien Hsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
C3 Yuan Ze University; Xiamen University; Xiamen University; Chien Hsin
   University of Science & Technology
RP Chen, SY (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
EM cschen@saturn.yzu.edu.tw; ssz@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU National Science Council of Taiwan [NSC-101-2221-E-155-060]; National
   Nature Science Foundation of China [61202143]
FX This work was supported by the National Science Council of Taiwan under
   Grant NSC-101-2221-E-155-060 and National Nature Science Foundation of
   China under Grant 61202143.
CR [Anonymous], P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   Arafat SY, 2010, P INT C DIG INF MAN
   Bagdanov AD, 2007, P ACM MULT INF RETR
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang C-C, LIBSVM BINARY SUPPOR
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chu WT, 2012, P INT C AC SPEECH SO
   Chum O, 2009, P IEEE INT C COMP VI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Joly A, 2009, P INT C ACM MULT
   Kleban J, 2008, P INT IEEE MULT EXN
   Lampert C., 2009, P INT C COMP VIS
   Liu RJ, 2010, PATTERN RECOGN, V43, P1907, DOI 10.1016/j.patcog.2009.11.022
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2006, IEEE T IMAGE PROCESS, V15, P1443, DOI 10.1109/TIP.2006.871081
   Meng J, 2010, P INT C ACM MULT
   Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54
   Pham A, 2011, P INT C DOC AN REC
   Pham TD, 2003, PATTERN RECOGN, V36, P3023, DOI 10.1016/S0031-3203(03)00125-0
   Phan R, 2010, COMPUT VIS IMAGE UND, V114, P66, DOI 10.1016/j.cviu.2009.07.004
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Revaud J, 2012, P INT C ACM MULT
   Romberg S, 2011, P INT C ACM MULT RET
   Roy PP, 2011, PATTERN RECOGN, V44, P1282, DOI 10.1016/j.patcog.2010.12.004
   Thomee B, 2010, P INT C ACM MULT
   Wei CH, 2009, PATTERN RECOGN, V42, P386, DOI 10.1016/j.patcog.2008.08.019
   Xu P, 2010, P INT C AC SPEECH SI
   Xu W, 2011, IEEE SIGNAL PROC LET, V18, P509, DOI 10.1109/LSP.2011.2161287
   Yu G., 2011, ASIFT ALGORITHM FULL
   Zhang HB, MULTIMEDIA TOOLS APP
NR 32
TC 13
Z9 13
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1285
EP 1310
DI 10.1007/s11042-013-1449-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300013
DA 2024-07-18
ER

PT J
AU Shivakumara, P
   Dutta, A
   Tan, CL
   Pal, U
AF Shivakumara, Palaiahnakote
   Dutta, Anjan
   Tan, Chew Lim
   Pal, Umapada
TI Multi-oriented scene text detection in video based on wavelet and angle
   projection boundary growing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet-median-moments; Text symmetry; Text frame classification; Text
   representatives; Angle projection boundary growing; Multi-oriented video
   text detection
ID IMAGES; FEATURES
AB In this paper, we address two complex issues: 1) Text frame classification and 2) Multi-oriented text detection in video text frame. We first divide a video frame into 16 blocks and propose a combination of wavelet and median-moments with k-means clustering at the block level to identify probable text blocks. For each probable text block, the method applies the same combination of feature with k-means clustering over a sliding window running through the blocks to identify potential text candidates. We introduce a new idea of symmetry on text candidates in each block based on the observation that pixel distribution in text exhibits a symmetric pattern. The method integrates all blocks containing text candidates in the frame and then all text candidates are mapped on to a Sobel edge map of the original frame to obtain text representatives. To tackle the multi-orientation problem, we present a new method called Angle Projection Boundary Growing (APBG) which is an iterative algorithm and works based on a nearest neighbor concept. APBG is then applied on the text representatives to fix the bounding box for multi-oriented text lines in the video frame. Directional information is used to eliminate false positives. Experimental results on a variety of datasets such as non-horizontal, horizontal, publicly available data (Hua's data) and ICDAR-03 competition data (camera images) show that the proposed method outperforms existing methods proposed for video and the state of the art methods for scene text as well.
C1 [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Informat Technol, Multimedia Unit, Kuala Lumpur, Malaysia.
   [Dutta, Anjan; Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 Universiti Malaya; Indian Statistical Institute; Indian Statistical
   Institute Kolkata; National University of Singapore
RP Shivakumara, P (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Informat Technol, Multimedia Unit, Kuala Lumpur, Malaysia.
EM hudempsk@yahoo.com; tancl@comp.nus.edu.sg; umapada@isical.ac.in
RI Palaiahnakote, Shivakumara/B-6261-2013; Pal, Umapada/AAC-4930-2022;
   Palaiahnakote, Shivakumara/ITU-6488-2023; Dutta, Anjan/R-5063-2016
OI Dutta, Anjan/0000-0002-1667-2245
FU National University of Singapore; Indian Statistical Institute, Kolkata,
   India; A*STAR [092 101 0051, R252-000-402-305]
FX This work is done jointly by National University of Singapore and Indian
   Statistical Institute, Kolkata, India. This research is supported in
   part by the A*STAR grant 092 101 0051 (WBS no. R252-000-402-305). We
   thank the anonymous reviewers for their valuable comments and
   suggestions that improve the quality of the work. Our special thanks to
   Prof. Andy Ming-Ham Yip, Department of Mathematics, National University
   of Singapore for his helpful discussion and comments on wavelet
   operations and other mathematical details.
CR Cai M, 2002, IEEE IMAGE PROC, P117
   Chen DT, 2004, SIGNAL PROCESS-IMAGE, V19, P205, DOI 10.1016/S0923-5965(03)00075-4
   Crandall D, 2001, PROC INT CONF DOC, P865, DOI 10.1109/ICDAR.2001.953910
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Guo JL, 2011, LECT NOTES COMPUT SC, V6524, P337
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Liu CM, 2005, PROC INT CONF DOC, P610
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Mariano VY, 2000, INT C PATT RECOG, P539, DOI 10.1109/ICPR.2000.902976
   Minetto R, 2010, IEEE IMAGE PROC, P3861, DOI 10.1109/ICIP.2010.5651761
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Phan T.Q., 2012, Proceedings of ACM MM'12, ACM, P765
   Sharma N., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P74, DOI 10.1109/DAS.2012.6
   Sharma N., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P63, DOI 10.1109/DAS.2012.72
   Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129
   Shivakumara P, 2011, PATTERN RECOGN, V44, P1671, DOI 10.1016/j.patcog.2011.02.008
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Shivakumara P, 2010, IEEE T CIRC SYST VID, V20, P1520, DOI 10.1109/TCSVT.2010.2077772
   Wang X, 2009, ICTON: 2009 11TH INTERNATIONAL CONFERENCE ON TRANSPARENT OPTICAL NETWORKS, VOLS 1 AND 2, P366, DOI 10.1007/978-3-642-00602-9_26
   Wong EK, 2003, PATTERN RECOGN, V36, P1397, DOI 10.1016/S0031-3203(02)00230-3
   WU W, 2004, P 12 ANN ACM INT C M, P852
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Zhang D., 2002, ACM Multimedia, P315
   Zhang J, 2008, P ICPR
   Zhang J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P5, DOI 10.1109/DAS.2008.49
   Zhou JC, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P119, DOI 10.1109/ICMV.2007.4469284
NR 32
TC 11
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 515
EP 539
DI 10.1007/s11042-013-1385-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800024
DA 2024-07-18
ER

PT J
AU Bin, SQ
   Xia, YS
AF Bin, Shi Quan
   Xia, You Sheng
TI Fast multi-channel image reconstruction using a novel two-dimensional
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiframe low-resolution images; Super-resolution; Double
   regularization term; Two-dimensional algorithm
ID SUPERRESOLUTION; RESOLUTION
AB Recently, two 2D algorithms for super resolution image reconstruction based on a matrix observation model were presented. They can greatly reduce computational cost and storage requirement but are suitable for the cases of face images or no warping operator. In this paper, for wide applications we propose a novel 2D algorithm to reconstruct a high-resolution image from multiple warped and degraded low-resolution images. The proposed 2D algorithm minimizes a new cost function with two regularization terms where one is the Laplacian regularization term for robustness to noise and another is learning term for more high frequency information. Simulation results show that the proposed 2D algorithm can obtain better results in terms of both PSNR and visual quality than the two existing 2D algorithms.
C1 [Bin, Shi Quan; Xia, You Sheng] Fuzhou Univ, Dept Software Engn, Fuzhou 350002, Peoples R China.
C3 Fuzhou University
RP Xia, YS (corresponding author), Fuzhou Univ, Dept Software Engn, Fuzhou 350002, Peoples R China.
EM ysxia2001@yahoo.com
RI bin, shi/KHU-4238-2024; xia, youshen/F-5813-2015
FU National Natural Science Foundation of China [61179037, 60875085]
FX The authors thank the editor and reviewers for their encouragement and
   valued comments, which helped in improving the quality of the paper.
   This work is supported by the National Natural Science Foundation of
   China under Grant No. 61179037 and 60875085.
CR [Anonymous], EURASIP J APPL SIGNA
   [Anonymous], INT C IMAGE SIGNAL P
   [Anonymous], LAB IMAGE SIGNAL ANA
   [Anonymous], 2010, J HARBIN I TECHNOL
   [Anonymous], INT J IMAGING SYST T
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Hardie R, 2007, IEEE T IMAGE PROCESS, V16, P2953, DOI 10.1109/TIP.2007.909416
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Kumar BGV, 2010, IET IMAGE PROCESS, V4, P61, DOI 10.1049/iet-ipr.2009.0072
   OZKAN MK, 1994, IEEE T IMAGE PROCESS, V3, P450, DOI 10.1109/83.298398
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Robinson MD, 2010, IEEE T IMAGE PROCESS, V19, P2669, DOI 10.1109/TIP.2010.2050107
   Stephenson TA, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/31062
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
NR 21
TC 17
Z9 17
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 2015
EP 2028
DI 10.1007/s11042-013-1371-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000047
DA 2024-07-18
ER

PT J
AU Wang, XK
   Wang, PJ
   Zhang, P
   Xu, SZ
   Yang, HZ
AF Wang, Xinkai
   Wang, Pengjun
   Zhang, Peng
   Xu, Shuzheng
   Yang, Huazhong
TI A blind audio watermarking algorithm by logarithmic quantization index
   modulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logarithmic quantization index modulation (LQIM); mu-Law companding;
   Vector norm; Discrete wavelet transform (DWT); Chaotic sequence
ID ROBUST AUDIO; SCHEME
AB In this paper we present a blind audio watermarking algorithm based on the vector norm and the logarithmic quantization index modulation (LQIM) in the wavelet domain, integrating the robustness of the vector norm with the imperceptibility of the logarithmic quantization index modulation based on mu-Law (or mu-Law) companding. Firstly mu-Law companding is adopted to transform the vector norm of the segmented wavelet approximation components of the original audio signal. And then a binary image scrambled by the chaotic sequence as watermark is embedded in the transformed domain with a uniform quantization scheme. Experimental results demonstrate that even if the capacity of the proposed algorithm is high, up to 102.4 bps, this algorithm can still maintain a high quality of the audio signal, and achieve a better performance, such as imperceptibility, robustness and complexity in comparison with the uniform quantization based algorithms against common attacks. What's more, it can resist amplitude scaling attack effectively.
C1 [Wang, Xinkai; Wang, Pengjun; Zhang, Peng; Xu, Shuzheng; Yang, Huazhong] Tsinghua Univ, Inst Circuits & Syst, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Yang, HZ (corresponding author), Tsinghua Univ, Inst Circuits & Syst, Dept Elect Engn, Beijing 100084, Peoples R China.
EM wxk2004@yahoo.com.cn; wangpj@mail.tsinghua.edu.cn;
   zhangp00@mails.tsinghua.edu.cn; xusz@tsinghua.edu.cn;
   yanghz@tsinghua.edu.cn
RI wang, xinkai/IWE-2290-2023; Zhang, Peng/KJM-0574-2024; zhang,
   hui/GXH-6098-2022
OI Zhang, Peng/0000-0002-1806-4200; 
CR Agreste S, 2007, J COMPUT APPL MATH, V210, P13, DOI 10.1016/j.cam.2006.10.087
   Akhaee MA, 2010, SIGNAL PROCESS, V90, P2487, DOI 10.1016/j.sigpro.2010.02.013
   Al-Haj A, 2011, INT ARAB J INF TECHN, V8, P326
   Al-Haj Ali, 2010, EUR J SCI RES, V39, P6
   [Anonymous], 2000, Digital Watermarking
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Cao ZG, 2003, MODERN COMMUNICATION
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P720, DOI 10.1049/iet-spr.2009.0187
   Chang CY, 2006, IEEE SYS MAN CYBERN, P1214, DOI 10.1109/ICSMC.2006.384880
   Comesana P., 2007, P INT C IMAGE PROCES, P145, DOI [10.1109/ICIP.2007.4379113, DOI 10.1109/ICIP.2007.4379113]
   Eggers JJ, 2003, IEEE T SIGNAL PROCES, V51, P1003, DOI 10.1109/TSP.2003.809366
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Garay A., 2002, THESIS GEORGETOWN U
   Hamadicharef B, 2003, 115 CONV AUD ENG SOC
   Jayamalar T, 2011, INT J MULTIMED APPL, V3, P143
   Kalantari Nima Khademi, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P198, DOI 10.1109/ISSPIT.2007.4458150
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   Lee K, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P459
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   Liew PY, 2007, MULTIMED TOOLS APPL, V35, P357, DOI 10.1007/s11042-007-0133-8
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Ling HF, 2011, SIGNAL PROCESS, V91, P1863, DOI 10.1016/j.sigpro.2011.02.009
   Nikmehr  H., 2010, 1 INT C COMM ENG, P1
   Panda J., 2010, 2010 International Conference on Advances in Computer Engineering (ACE), P163, DOI 10.1109/ACE.2010.41
   Perceptual Evaluation of Speech Quality (PESQ), 2001, PERC EV SPEECH QUAL, P862
   Ravula Rajkiran, 2010, THESIS LOUISIANA STA
   Recommendation BS, 2001, 1387 INT TEL UN
   Scagliola M, 2009, INT CONF ACOUST SPEE, P1489, DOI 10.1109/ICASSP.2009.4959877
   Wang XY, 2011, J SYST SOFTWARE, V84, P1408, DOI 10.1016/j.jss.2011.03.033
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiang SJ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-3
   Zezula Radek, 2008, 2008 3rd International Conference on Systems (ICONS '08), P140, DOI 10.1109/ICONS.2008.21
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 37
TC 11
Z9 13
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1157
EP 1177
DI 10.1007/s11042-012-1259-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000009
DA 2024-07-18
ER

PT J
AU Traore, I
   Woungang, I
   Obaidat, MS
   Nakkabi, Y
   Lai, I
AF Traore, Issa
   Woungang, Isaac
   Obaidat, Mohammad S.
   Nakkabi, Youssef
   Lai, Iris
TI Online risk-based authentication using behavioral biometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Risk-based authentication; Network security; Mouse dynamics; Keystroke
   dynamics biometric technology; Bayesian network model; Digital home
   network; Infrastructure technology
ID USER AUTHENTICATION
AB In digital home networks, it is expected that independent smart devices communicate and cooperate with each other, without the knowledge of the fundamental communication technology, on the basis of a distributed operating system paradigm. In such context, securing the access rights to some objects such as data, apparatus, and contents, is still a challenge. This paper introduces a risk-based authentication technique based on behavioral biometrics as solution approach to tackle this challenge. Risk-based authentication is an increasingly popular component in the security architecture deployed by many organizations to mitigate online identity fraud. Risk-based authentication uses contextual and historical information extracted from online communications to build a risk profile for the user that can be used accordingly to make authentication and authorization decisions. Existing risk-based authentication systems rely on basic web communication information such as the source IP address or the velocity of transactions performed by a specific account, or originating from a certain IP address. Such information can easily be spoofed, and as such, put in question the robustness and reliability of the proposed systems. In this paper, we propose a new online risk-based authentication system that provides more robust user identity information by combining mouse dynamics and keystroke dynamics biometrics in a multimodal framework. We propose a Bayesian network model for analyzing free keystrokes and free mouse movements involved in web sessions. Experimental evaluation of our proposed model with 24 participants yields an Equal Error Rate of 8.21 %. This is very encouraging considering that we are dealing with free text and free mouse movements, and the fact that many web sessions tend to be very short.
C1 [Traore, Issa; Nakkabi, Youssef; Lai, Iris] Univ Victoria, Dept Elect & Comp Engn, Victoria, BC V8W 3P6, Canada.
   [Woungang, Isaac] Ryerson Univ, Dept Comp Sci, Toronto, ON M5B 2K3, Canada.
   [Obaidat, Mohammad S.] Monmouth Univ, Dept Comp Sci & Software Engn, West Long Branch, NJ 07764 USA.
C3 University of Victoria; Toronto Metropolitan University; Monmouth
   University
RP Obaidat, MS (corresponding author), Monmouth Univ, Dept Comp Sci & Software Engn, West Long Branch, NJ 07764 USA.
EM itraore@ece.uvic.ca; iwoungan@scs.ryerson.ca; msobaidat@gmail.com;
   ynakkabi@ece.uvic.ca; irisl@uvic.ca
RI Obaidat, Mohammad S./KBC-2747-2024
OI Obaidat, Mohammad S./0000-0002-1569-9657
CR Ahmed AAE, 2007, IEEE T DEPEND SECURE, V4, P165, DOI 10.1109/TDSC.2007.70207
   Aksari Y, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P569
   [Anonymous], 2007, P 2 ACM S INFORM COM
   Bergadano F., 2002, ACM Transactions on Information and Systems Security, V5, P367, DOI 10.1145/581271.581272
   Bouckaert RemcoR., 2004, BAYESIAN NETWORK CLA
   Bours P, 2009, P 5 INT C INT INF HI
   Cheng P.-C., 2007, RC24190 IBM
   Diep Nguyen Ngoc, 2007, Proceedings of the 2007 International Conference on Security & Management. SAM 2007, P406
   DIMMOCK N, 2005, LNCS, V3477
   DOWLAND P, 2001, P 8 IFIP ANN WORK C
   Dowland PS, 2002, INT FED INFO PROC, V86, P215
   Enokido T, 2011, IEEE T IND ELECTRON, V58, P2216, DOI 10.1109/TIE.2010.2051393
   Fayyad U.M., 1993, Proceedings of the 13th International Joint Conference on Artificial Intelligence
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Gaine R, 1980, R2526NSF RAND CORP
   Gamboa Hugo., 2003, PRIS, P46
   Gunetti D., 2005, ACM Transactions on Information and Systems Security, V8, P312, DOI 10.1145/1085126.1085129
   KONONENKO I, 1995, P 14 INT JOINT C ART
   Legget J, 1988, INT J MAN MACH STUD, V35, P859
   Lian SG, 2012, MULTIMED TOOLS APPL, V57, P49, DOI 10.1007/s11042-010-0521-3
   Monrose F., 1997, Proc. 4th ACM Conf. Comput. Commun. Secur.-CCS, P48, DOI 10.1145/266420.266434
   OBAIDAT MS, 1993, IEEE T IND ELECTRON, V40, P235, DOI 10.1109/41.222645
   Obaidat MS, 1997, IEEE T SYST MAN CY B, V27, P261, DOI 10.1109/3477.558812
   Orozco M, 2012, INT J MULTIMEDIA TOO
   Pusara M, 2004, P 11 ACM WORKSH VIS
   Revett K, 2008, COMM COM INF SC, V12, P210
   Syukri A. F., 1998, Information Security and Privacy. Third Australasian Conference, ACISP'98. Proceedings, P403, DOI 10.1007/BFb0053751
   Traore I., 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P138, DOI 10.1109/ICDH.2012.59
   Tubin G, 2005, V4315N TOW GROUP
   Tuptuk N, 2007, LECT NOTES COMPUT SC, V4543, P188
   Villani M., 2006, P 2006 C COMPUTER VI, P39
NR 31
TC 15
Z9 16
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 575
EP 605
DI 10.1007/s11042-013-1518-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400012
DA 2024-07-18
ER

PT J
AU Xu, S
   An, X
   Qiao, XD
   Zhu, LJ
AF Xu, Shuo
   An, Xin
   Qiao, Xiaodong
   Zhu, Lijun
TI Multi-task least-squares support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task learning; Least-Square Support Vector Machine (LS-SVM);
   Multi-Task LS-SVM (MTLS-SVM); Krylow methods
ID OUT CROSS-VALIDATION; MULTIPLE TASKS; MODEL; FRAMEWORK; ALGORITHM
AB There are often the underlying cross relatedness amongst multiple tasks, which is discarded directly by traditional single-task learning methods. Since multi-task learning can exploit these relatedness to further improve the performance, it has attracted extensive attention in many domains including multimedia. It has been shown through a meticulous empirical study that the generalization performance of Least-Squares Support Vector Machine (LS-SVM) is comparable to that of SVM. In order to generalize LS-SVM from single-task to multi-task learning, inspired by the regularized multi-task learning (RMTL), this study proposes a novel multi-task learning approach, multi-task LS-SVM (MTLS-SVM). Similar to LS-SVM, one only solves a convex linear system in the training phrase, too. What's more, we unify the classification and regression problems in an efficient training algorithm, which effectively employs the Krylow methods. Finally, experimental results on school and dermatology validate the effectiveness of the proposed approach.
C1 [Xu, Shuo; Qiao, Xiaodong; Zhu, Lijun] Inst Sci & Tech Informat China, Informat Technol Supporting Ctr, Beijing 100038, Peoples R China.
   [An, Xin] Beijing Forestry Univ, Sch Econ & Management, Beijing 100083, Peoples R China.
C3 Beijing Forestry University
RP An, X (corresponding author), Beijing Forestry Univ, Sch Econ & Management, 35 Qinghua East Rd, Beijing 100083, Peoples R China.
EM xush@istic.ac.cn; anxin927@gmail.com; qiaox@istic.ac.cn;
   zhulj@istic.ac.cn
RI Xu, Shuo/KVY-0402-2024
OI Xu, Shuo/0000-0002-8602-1819
FU Beijing Forestry University [BLX2011028]; Key Technologies R&D Program
   of Chinese 12th Five-Year Plan [2011BAH10B04, 2011BAH10B06,
   2013BAG06B01]; National Natural Science Foundation [70903032]; Social
   Science Foundation of Jiangsu Province [09TQC011]; MOE Project of
   Humanitites and Social Sciences [09YJC870014]
FX This work was funded partially by Beijing Forestry University Young
   Scientist Fund: Research on Econometric Methods of Auction with their
   Applications in the Circulation of Collective Forest Right under grant
   number BLX2011028, Key Technologies R&D Program of Chinese 12th
   Five-Year Plan (2011-2015): Key Technologies Research on Large Scale
   Semantic Computation for Foreign Scientific & Technical Knowledge
   Organization System, Application Demonstration of Knowledge Service
   based on STKOS, and Key Technologies Research on Data Mining from the
   Multiple Electric Vehicle Information Sources under grant number
   2011BAH10B04, 2011BAH10B06 and 2013BAG06B01, respectively, National
   Natural Science Foundation: Multilingual Documents Clustering based on
   Comparable Corpus under grant number 70903032, Social Science Foundation
   of Jiangsu Province: Study on Automatic Indexing of Digital Newspapers
   under grant number 09TQC011, and MOE Project of Humanitites and Social
   Sciences: Research on Further Processing of e-Newspaper under grant
   number 09YJC870014. Our gratitude also goes to the anonymous reviewers
   for their valuable comments.
CR Allenby GM, 1999, J ECONOMETRICS, V89, P57
   An X, 2009, SPECTROSC SPECT ANAL, V29, P127, DOI 10.3964/j.issn.1000-0593(2009)01-0127-04
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], 1999, The Nature Statist. Learn. Theory
   [Anonymous], LEAST SQUARES SUPPOR
   [Anonymous], P INT C INT SYST KNO
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2003, NEURAL COMPUT
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Arora N, 1998, MARKET SCI, V17, P29, DOI 10.1287/mksc.17.1.29
   Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658
   Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663
   Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731
   Ben-David S, 2003, LECT NOTES ARTIF INT, V2777, P567, DOI 10.1007/978-3-540-45167-9_41
   Ben-David Shai, 2002, Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P443
   Buffoni D, 2012, MULTIMED TOOLS APPL, V60, P161, DOI 10.1007/s11042-011-0806-1
   Caponnetto A, 2008, J MACH LEARN RES, V9, P1615
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Cawley GC, 2006, IEEE IJCNN, P1661
   Cawley GC, 2004, NEURAL NETWORKS, V17, P1467, DOI 10.1016/j.neunet.2004.07.002
   Chapelle O., 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining-KDD'10, page, P1189, DOI 10.1145/1835804.1835953
   Chari R, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-324
   De Brabanter K, 2010, COMPUT STAT DATA AN, V54, P1484, DOI 10.1016/j.csda.2010.01.024
   Dhillon P. S., 2011, P 20 ACM INT C INF K, P957
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   EVGENIOU T, 2006, CONVEX OPTIMIZATION
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hamers B., 2001, 01110 ESATSISTA KU L
   Heskes T., 2000, Proceedings of the Seventeenth International Conference on Machine Learning, P367
   Hsu JL, 2012, MULTIMED TOOLS APPL, V58, P521, DOI 10.1007/s11042-011-0729-x
   Jebara T., 2004, Proceedings of the 21st International Conference on Machine Learning, page
   Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855
   Keerthi SS, 2003, NEURAL COMPUT, V15, P487, DOI 10.1162/089976603762553013
   Micchelli Charles A., 2005, Advances in Neural Information Processing Systems, P921
   Minka S, 2001, ADV NEURAL INFORM PR, V13
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Saad Y, 2003, ITERATIVE METHODS SP, DOI DOI 10.1137/1.9780898718003
   Saunders C., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P515
   Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X
   Suykens J. A. K., 1999, Proceedings of the European Conference on Circuit Theory and Design. ECCTD'99, P839
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Thrun S., 1997, LEARNING LEARN
   Torralba A, 2004, PROC CVPR IEEE, P762
   van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0
   Van Gestel T, 2002, NEURAL COMPUT, V14, P1115, DOI 10.1162/089976602753633411
   Williams CKI, 2001, ADV NEUR IN, V13, P682
   Xu S, 2011, J Inf Comput Sci, V8, P885
   Xu S, 2013, PATTERN RECOGN LETT, V34, P1078, DOI 10.1016/j.patrec.2013.01.015
   Xu S, 2011, SPECTROSC SPECT ANAL, V31, P1208, DOI 10.3964/j.issn.1000-0593(2011)05-1208-04
   Ye J., 2007, Eleventh International Conference on Artificial Intelligence and Statistics, P644
NR 52
TC 42
Z9 47
U1 2
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 699
EP 715
DI 10.1007/s11042-013-1526-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400020
DA 2024-07-18
ER

PT J
AU Belimpasakis, P
   Stirbu, V
AF Belimpasakis, Petros
   Stirbu, Vlad
TI A survey of techniques for remote access to home networks and resources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote access; Home networks; Residential networks; Connectivity
AB Consumer Electronics devices are becoming network enabled, and along with smart phones and personal computers, they are all interconnected in home networks with broadband Internet connectivity. This sets the opportunity of making the home network, its devices and content accessible from the Internet, allowing the home owners to remotely access their connected home any time, any place, using any device. This paper provides a holistic overview of the "Remote Acces" topic, presenting all the problems and issues that make it challenging in different contexts, and most importantly analyzing six techniques and methods for enabling the remote access scenarios. It is a guide created by the combination of scientific research, extensive industrial experiences and first hand participation in relevant standardization activities.
C1 [Belimpasakis, Petros] Bang & Olufsen, Automot Concept & Technol, Pullach, Germany.
   [Stirbu, Vlad] Nokia Res Ctr, Media Lab, Tampere, Finland.
C3 Nokia Corporation; Nokia Finland; Siemens AG; Nokia Siemens Networks
RP Belimpasakis, P (corresponding author), Bang & Olufsen, Automot Concept & Technol, Pullach, Germany.
EM ptb@bang-olufsen.dk; vlad.stirbu@nokia.com
CR [Anonymous], 2000, Dissertation
   BELIMPASAKIS P, 2007, P 3 INT C NETW SERV
   Belimpasakis P, 2006, THESIS TAMPERE U TEC
   Belimpasakis P, 2009, P 6 ANN IEEE CONS CO
   BELIMPASAKIS P, 2006, P 15 IST MOB WIR COM
   Belimpasakis P, 2008, IEEE T CONSUM ELECTR, V54, P1114, DOI 10.1109/TCE.2008.4637596
   BERNERSLEE T, 1999, 2616 RFC
   Bronsted J, 2010, P 7 ANN IEEE CONS CO
   Cain B, 2002, RFC 3376
   Carroll R, 2007, IEEE PERVAS COMPUT, V6, P90, DOI 10.1109/MPRV.2007.72
   Cheshire S., 2005, 3927 RFC
   Cheshire S., 2011, DNS-Based Service Discovery
   Cheshire S., 2011, MULTICAST DNS
   Cohen J., 1998, GEN EVENT NOTIFICATI
   Contributing members of NGTP consortium, 2010, NGTP 2 0 NUTSH 1 0 N
   Contributing members of UPnP Forum, 2009, REM ACC ARCH 1
   Contributing members of UPnP Forum, 2002, UPNP AV ARCH 1
   Contributing members of UPnP Forum, 2002, CONTENTDIRECTORY 1 S
   Contributing members of UPnP Forum, 2002, MEDIASERVER 1 DEV TE
   Contributing members of UPnP Forum, 2001, INT GAT DEV IGD STAN
   Contributing members of UPnP Forum, 2007, UPNP LOW POW ARCH 1
   Contributing members of UPnP Forum, 2003, UPNP DEV ARCH 1 0
   Coughlin TM, 2008, J MAGN MAGN MATER, V320, P2860, DOI 10.1016/j.jmmm.2008.07.040
   Coughlin TM, 2006, P 10 INT S CONS EL I
   Diaz-Sanchez D, 2011, IEEE INT C CONS EL
   dns-sd.org, 2012, 2782 DNS SRV RFC
   Droms R., 1997, RFC 2131
   Dusseault L., 2007, 4918 RFC
   Gill K, 2009, IEEE T CONSUM ELECTR, V55, P422, DOI 10.1109/TCE.2009.5174403
   Goland Y, 1999, MULTICAST UNICAST UD
   Goland Y., 1999, Simple service discovery protocol
   Gomez C, 2010, IEEE COMMUN MAG, V48, P92, DOI 10.1109/MCOM.2010.5473869
   Grinter RE, 2005, P 9 C EUR C COMP SUP
   Gudgin M., 2003, SOAP VERSION 1 2 1
   Guinard D., 2011, THESIS ETH ZURICH
   Haber A, 2010, THESIS U AGDER
   Hoadley CM, 2010, ELECTRON COMMER R A, V9, P50, DOI 10.1016/j.elerap.2009.05.001
   Huang YM, 2009, IEEE J SEL AREA COMM, V27, P400, DOI 10.1109/JSAC.2009.090505
   Kindberg T, 2002, MOBILE NETW APPL, V7, P365, DOI 10.1023/A:1016591616731
   Lai CF, 2010, IEEE SYST J, V4, P262, DOI 10.1109/JSYST.2010.2047175
   Lauren R, 2007, THESIS HELSINKI U TE
   Microsoft, 2011, MICR SMB PROT CIFS P
   Oh H, 2006, LECT NOTES COMPUT SC, V3983, P440
   Postel J., 1980, User datagram protocol
   Richardson T, 1998, IEEE INTERNET COMPUT, V2, P33, DOI 10.1109/4236.656066
   Saito T, 2000, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - 2000 DIGEST OF TECHNICAL PAPERS, P194, DOI 10.1109/ICCE.2000.854579
   Sangani K., 2006, Engineering & Technology, V1, P46, DOI 10.1049/et:20060908
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Scott C., 1999, VIRTUAL PRIVATE NETW
   Srisuresh P., 2001, 3022 RFC
   Teger S, 2002, IEEE COMMUN MAG, V40, P114, DOI 10.1109/35.995860
   Venkatesh A., 2003, Cognition, Technology & Work, V5, P23, DOI 10.1007/s10111-002-0113-8
   Vixie P., 1997, RFC 2136
   Weiss Aaron, 2007, Networker, V11, P16, DOI 10.1145/1327512.1327513
   Zhou L, 2011, IEEE NETWORK, V25, P35, DOI 10.1109/MNET.2011.5772059
NR 55
TC 6
Z9 6
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1899
EP 1939
DI 10.1007/s11042-012-1221-y
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500024
DA 2024-07-18
ER

PT J
AU Bolla, R
   Rapuzzi, R
   Repetto, M
AF Bolla, Raffaele
   Rapuzzi, Riccardo
   Repetto, Matteo
TI User-centric mobility management for multimedia content access
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobility architecture; Pervasive communication; User-centric media;
   Personal address
ID SUPPORT; SESSION; IP
AB Current mobility protocols and architectures are mainly targeted to devices or applications and they usually lack the ability to support user-centric paradigms; moreover, they usually face a single aspect of the problem, i.e., terminal handover or session mobility. Full mobility support is only available to specific applications or protocols (e.g., SIP) but these approaches do not exploit all facilities for movement detection at the network/link layers and do not allow to use the same framework for different applications. This paper proposes a generic mobility framework for terminal handover and session migration. It pursues the user-centric paradigm and builds a cross-layer architecture, yielding to a high level of generality, applicability and flexibility. Unlike other approaches, it does not require any modification in correspondent peers and works with a minimal network infrastructure. Software implementations are described for two representative real-time multimedia applications, i.e., media streaming and interactive conference. The effectiveness of the framework was analyzed by means of both performance measurements in local and Internet testbeds and user evaluation during a live demo conducted at a national science exhibition.
C1 [Bolla, Raffaele; Rapuzzi, Riccardo] Univ Genoa, DIST, Dept Commun Comp & Syst Sci, I-16145 Genoa, Italy.
   [Repetto, Matteo] CNIT, I-43124 Parma, Italy.
C3 University of Genoa
RP Repetto, M (corresponding author), CNIT, Viale GP Usberti 181-A, I-43124 Parma, Italy.
EM raffaele.bolla@unige.it; riccardo.rapuzzi@unige.it;
   matteo.repetto@cnit.it
RI Repetto, Matteo/GPK-8352-2022
OI Repetto, Matteo/0000-0001-8478-2633; BOLLA, RAFFAELE/0000-0003-2861-1586
CR [Anonymous], 2007, US CENTR MED FUT CHA
   [Anonymous], 2005, HIERARCHICAL MOBILE
   [Anonymous], 5631 RFC
   Banerjee N, 2006, IEEE NETWORK, V20, P6, DOI 10.1109/MNET.2006.1607890
   Banerjee N, 2003, IEEE WIREL COMMUN, V10, P54, DOI 10.1109/MWC.2003.1241101
   Bolla R, 2009, INT C MOB TECHN APPL
   Brännström R, 2006, CONSUM COMM NETWORK, P818
   Campbell AT, 2002, IEEE WIREL COMMUN, V9, P72, DOI 10.1109/MWC.2002.986462
   Chen MX, 2007, COMPUT STAND INTER, V29, P531, DOI 10.1016/j.csi.2006.11.008
   Dutta A, 2004, 2004 IEEE 15TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-4, PROCEEDINGS, P1527, DOI 10.1109/PIMRC.2004.1368255
   Eddy WM, 2004, IEEE COMMUN MAG, V42, P155, DOI 10.1109/MCOM.2004.1341274
   Fogelstroem E., 2007, 4857 RFC
   Giordano S, 2005, SECOND ANNUAL CONFERENCE ON WIRELESS ON-DEMAND NETWORK SYSTEMS AND SERVICES, PROCEEDINGS, P224, DOI 10.1109/WONS.2005.36
   Hasegawa M, 2003, P INT S WIR PERS MUL, V2, P357
   Henderson TR, 2003, IEEE WCNC, P2120
   Henderson TR, 2003, IEEE NETWORK, V17, P18, DOI 10.1109/MNET.2003.1248657
   Johnson D., 2004, RFC 3775
   Jung JW, 2003, GLOB TELECOMM CONF, P1190, DOI 10.1109/GLOCOM.2003.1258427
   Kohn R, 2008, IEEE ICC, P3279, DOI 10.1109/ICC.2008.617
   KUMAR V, 2001, IP TELEPHONY H 323 A
   Le DG, 2006, IEEE COMMUN SURV TUT, V8, P38, DOI 10.1109/COMST.2006.323441
   Lu W., 2005, 5 WORKSH APPL SERV W
   Maltz DA, 1998, IEEE INFOCOM SER, P1037, DOI 10.1109/INFCOM.1998.662913
   Montavont N, 2003, MOBILE NETW APPL, V8, P643, DOI 10.1023/A:1026026426784
   MOSKOWITZ R, 2006, 4423 RFC
   Mysore J., 1997, MobiCom '97. Proceedings of the Third Annual ACM/IEEE International Conference on Mobile Computing and Networking, P161, DOI 10.1145/262116.262144
   Nakajima N, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P1085
   Niemegeers IG, 2003, WIRELESS PERS COMMUN, V26, P149, DOI 10.1023/A:1025522402484
   Partridge Craig, 1993, 1546 RFC, DOI DOI 10.17487/RFC1546
   Perkins C., 2002, RFC 3344
   Politis C., 2003, 57 IEEE SEM VEH TECH, V4, P250
   Qi Wang, 2003, 5th European Personal Mobile Communications Conference 2003 (IEE Conf. Publ. 492), P237, DOI 10.1049/cp:20030253
   Ramjee R, 2002, IEEE ACM T NETWORK, V10, P396, DOI 10.1109/TNET.2002.1012370
   Reinbold Pierre, 2003, IEEE Communications Surveys & Tutorials, V5, P40, DOI 10.1109/COMST.2003.5342229
   Riegel M., 2007, MOBILE SCTP INTERNET
   Rosemberg J., 2002, 3261 RFC
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   SCHULZRINNE H., 2000, ACM SIGMOBILE Mobile Computing and Communications Review, V4, P47
   Schulzrinne H., 1998, 2326 RFC
   Seshan S., 1997, Wireless Personal Communications, V4, P141, DOI 10.1023/A:1008830311723
   Shacham R, 2005, WiMob'2005: IEEE International Conference on Wireless and Mobile Computing, Networking and Communications, Vol, 4 Proceedings, P73
   Snoeren A. C., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P155, DOI 10.1145/345910.345938
   SU G, 2002, CUCS00302
   Valko A.G., 1999, ACM SIGCOMM COMPUTER
   Wang Q., 2003, Fourth International Conference on 3G Mobile Communication Technologies (3G 2003) (IEE Conf. Publ.No.494), P205, DOI 10.1049/cp:20030365
   Wedlund E., 1999, WOWMOM, P76, DOI DOI 10.1145/313256.313281
NR 46
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 267
EP 295
DI 10.1007/s11042-011-0827-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300012
DA 2024-07-18
ER

PT J
AU Mossi, JM
   Albiol, A
   Albiol, A
   Oliver, J
AF Mossi, Jose M.
   Albiol, Antonio
   Albiol, Alberto
   Oliver, Javier
TI Ground truth annotation of traffic video data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic; Ground truth; Vehicle; Video; Intelligent transportation
   systems
ID TOOL
AB This paper presents a software application to generate ground-truth data on video files from traffic surveillance cameras used for Intelligent Transportation Systems (IT systems). The computer vision system to be evaluated counts the number of vehicles that cross a line per time unit -intensity-, the average speed and the occupancy. The main goal of the visual interface presented in this paper is to be easy to use without the requirement of any specific hardware. It is based on a standard laptop or desktop computer and a Jog shuttle wheel. The setup is efficient and comfortable because one hand of the annotating person is almost all the time on the space key of the keyboard while the other hand is on the jog shuttle wheel. The mean time required to annotate a video file ranges from 1 to 5 times its duration (per lane) depending on the content. Compared to general purpose annotation tool a time factor gain of about 7 times is achieved.
C1 [Mossi, Jose M.; Albiol, Antonio; Albiol, Alberto; Oliver, Javier] Univ Politecn Valencia, ITeam, E-46071 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Mossi, JM (corresponding author), Univ Politecn Valencia, ITeam, E-46071 Valencia, Spain.
EM jmmossi@dcom.upv.es
RI Albiol, Alberto/AAW-2231-2020; Albiol, Antonio/ABD-3393-2020; Mossi,
   Jose M./F-9777-2016
OI Albiol, Alberto/0000-0002-1970-3289; Albiol,
   Antonio/0000-0002-0679-912X; Mossi, Jose M./0000-0001-9083-3476; Oliver
   Moll, Javier/0000-0002-4754-5433
FU Spanish Government project MARTA under the CENIT program; CICYT
   [TEC2009-09146]
FX This work was funded by the Spanish Government project MARTA under the
   CENIT program and CICYT contract TEC2009-09146.
CR Albiol A, 2011, IEEE T INTELL TRANSP, V12, P1277, DOI 10.1109/TITS.2011.2156791
   [Anonymous], SUS QUICK DIRTY USAB
   [Anonymous], 2011, OpenCV 2 Computer Vision Application Programming Cookbook: Over 50 recipes to master this library of programming functions for real-time computer vision
   Blunsden S., 2010, ANN BMVA, V4, P4, DOI DOI 10.5465/19416521003654160
   Bradski G., 2008, LEARNING OPENCV
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   D'Orazio T, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P559, DOI 10.1109/AVSS.2009.69
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Faro A, 2011, IEEE T INTELL TRANSP, V12, P1398, DOI 10.1109/TITS.2011.2159266
   Giro-i-Nieto X, 2010, MULTIMED TOOLS APPL, V46, P155, DOI 10.1007/s11042-009-0389-2
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Lorist MM, 2000, PSYCHOPHYSIOLOGY, V37, P614, DOI 10.1111/1469-8986.3750614
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Serrano MA, 2010, ADV INTEL SOFT COMPU, V79, P325
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Volkmer T., 2005, PROC 13 ANN ACM INT, P892, DOI DOI 10.1145/1101149.1101341
   Zhang HB, 2012, ADAPTIVE PHOTOGRAPH
   Zou YX, 2011, MULTIMED TOOLS APPL, V52, P133, DOI 10.1007/s11042-010-0466-6
NR 19
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 461
EP 474
DI 10.1007/s11042-013-1396-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300021
OA Green Published
DA 2024-07-18
ER

PT J
AU Bilal, M
   Hussain, A
   Jaffar, MA
   Choi, TS
   Mirza, AM
AF Bilal, Mohsin
   Hussain, Ayyaz
   Jaffar, Muhammad Arfan
   Choi, Tae-Sun
   Mirza, Anwar M.
TI Estimation and optimization based ill-posed inverse restoration using
   fuzzy logic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blur and noise; Deblurring; Fuzzy regularization parameter; Quadratic
   functional regularization; Constrained least square error; Steepest
   descent
ID MODIFIED HOPFIELD NETWORK; IMAGE-RESTORATION; REGULARIZATION
AB Intelligent systems ranging from neural network, evolutionary computations and swarm intelligence to fuzzy systems are extensively exploited by researchers to solve variety of problems. In this paper focus is on deblurring that is considered as an inverse problem. It becomes ill-posed when noise contaminates the blurry image. Hence the problem is very sensitive to small perturbation in data. Conventionally, smoothness constraints are considered as a remedy to cater the sensitivity of the problem. In this paper, fuzzy rule based regularization parameter estimation is proposed with quadratic functional smoothness constraint. For deblurring image in the presence of noise, a constrained least square error function is minimized by the steepest descent algorithm. Visual results and quantitative measurements show the efficiency and robustness of the proposed technique compared to the state of the art and recently proposed methods.
C1 [Bilal, Mohsin; Jaffar, Muhammad Arfan] Natl Univ Comp & Emerging Sci, NU FAST, Islamabad, Pakistan.
   [Hussain, Ayyaz] Int Islamic Univ, Islamabad, Pakistan.
   [Choi, Tae-Sun] Gwangju Inst Sci & Technol, Dept Mechatron, Kwangju, South Korea.
   [Mirza, Anwar M.] King Saud Univ, Riyadh, Saudi Arabia.
C3 International Islamic University, Pakistan; Gwangju Institute of Science
   & Technology (GIST); King Saud University
RP Jaffar, MA (corresponding author), Natl Univ Comp & Emerging Sci, NU FAST, H-11-4, Islamabad, Pakistan.
EM mohsin.bilal@nu.edu.pk; ayyaz.hussain@iiu.edu.pk;
   arfanjaffar@gist.ac.kr; tschoi@gist.ac.kr; ammirza@ksu.edu.sa
RI bilal, Mohsin/AAN-6349-2020; Jaffar, Arfan/GQB-2768-2022; Mirza, Anwar
   M/KHW-9731-2024; mirza, Arshad m/F-3016-2015
OI bilal, Mohsin/0000-0001-8632-2729; Mirza, Anwar M/0000-0001-7600-6247;
   Choi, Tae-Sun/0000-0001-7496-2438
FU Higher Education Commission (HEC) of Pakistan
FX The authors would like to acknowledge Higher Education Commission (HEC)
   of Pakistan for their continuous financial support and the reviewers for
   their many valuable comments and suggestions that helped to improve this
   paper.
CR Annadurai S., 2007, FUNDAMENTAL DIGITAL
   Bilal M, 2010, IEEE INT C FUT INF T, V5, P1
   Castleman K. R., 1996, Digital Image Processing
   Chang FC, 2012, INFORM SCIENCES, V192, P39, DOI 10.1016/j.ins.2010.02.025
   de Castro A., 2008, TRENDS APPL COMPUT M, V9, P41
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gu XJ, 2009, J COMPUT APPL MATH, V225, P478, DOI 10.1016/j.cam.2008.08.013
   Gutierrez J, 2007, ELECT ROBOT AUTO MEC, P229, DOI 10.1109/CERMA.2007.4367691
   Hansen P.C., 2006, DEBLURRING IMAGES MA
   Huang HC, 2009, SOFT COMPUT, V13, P383, DOI 10.1007/s00500-008-0326-8
   JENSEN TK, 2006, THESIS TU DENMARK DE
   Kaganami H.G., 2011, J INFORM HIDING MULT, V2, P33
   Lee CS, 2004, LECT NOTES COMPUT SC, V3174, P375
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Manglem Singh Kh., 2011, J INF HIDING MULTIME, V2, P108
   Mignotte M, 2006, IEEE T IMAGE PROCESS, V15, P1973, DOI 10.1109/TIP.2006.873446
   Paik JK, 1992, IEEE T IMAGE PROCESS, V1, P49, DOI 10.1109/83.128030
   Perry SW, 2000, IEEE T NEURAL NETWOR, V11, P156, DOI 10.1109/72.822518
   Perry SW, 2006, THESIS U SYDNEY
   Puranik P., 2011, J INFORM HIDING MULT, V2, P227
   Ripley B. D., 1981, Spatial statistics, V599, P611
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sun W, 2006, SPRINGER SER OPTIM A, V1, P1, DOI 10.1007/b106451
   Tokhonov AN, 1977, SOLUTION ILL POSED P
   Wu YD, 2007, INT C WIR COMM MOB C, V07, P683, DOI [10.1145/1280940.1281085, DOI 10.1145/1280940.1281085]
   ZHOU YT, 1988, IEEE T ACOUST SPEECH, V36, P1141, DOI 10.1109/29.1641
NR 26
TC 9
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 1067
EP 1087
DI 10.1007/s11042-012-1172-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300022
DA 2024-07-18
ER

PT J
AU Alam, M
   Zhang, XW
   Nauman, M
   Ali, T
   Ali, M
   Anwar, S
   Alam, Q
AF Alam, Masoom
   Zhang, Xinwen
   Nauman, Mohammad
   Ali, Tamleek
   Ali, Muhammad
   Anwar, Sajid
   Alam, Quratulain
TI Behavioral Attestation for Web Services using access policies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trusted computing; Remote attestation; Behavioral attestation; Usage
   control; Web services; Delegation
AB Service Oriented Architecture with underlying technologies like web services and web service orchestration opens new vistas for integration among business processes operating in heterogeneous environments. However, such dynamic collaborations require a highly secure environment at each respective business partner site. Existing web services standards address the issue of security only on the service provider platform. The partner platforms to which sensitive information is released have till now been neglected. Remote Attestation is a relatively new field of research which enables an authorized party to verify that a trusted environment actually exists on a partner platform. To incorporate this novel concept in to the web services realm, a new mechanism called WS-Attestation has been proposed. This mechanism provides a structural paradigm upon which more fine-grained solutions can be built. In this paper, we present a novel framework, Behavioral Attestation for Web Services, in which XACML is built on top of WS-Attestation in order to enable more flexible remote attestation at the web services level. We propose a new type of XACML policy called XACML behavior policy, which defines the expected behavior of a partner platform. Existing web service standards are used to incorporate remote attestation at the web services level and a prototype is presented, which implements XACML behavior policy using low-level attestation techniques.
C1 [Alam, Masoom; Nauman, Mohammad; Ali, Tamleek; Ali, Muhammad; Anwar, Sajid; Alam, Quratulain] Inst Management Sci IMSci, SERG, Peshawar, Pakistan.
   [Zhang, Xinwen] Huawei Res Ctr, Santa Clara, CA USA.
C3 Huawei Technologies
RP Alam, M (corresponding author), Inst Management Sci IMSci, SERG, 1-A,E-5,Phase 7, Peshawar, Pakistan.
EM masoom.alam@imsciences.edu.pk; xinwen.zhang@huawei.com;
   nauman@imsciences.edu.pk; tamleek@imsciences.edu.pk;
   muhammad.ali@imsciences.edu.pk; s.anwar@imsciences.edu.pk;
   q.alam84@gmail.com
RI Ali, Tamleek/AAC-7017-2020
OI Nauman, Mohammad/0000-0003-0941-2549; Anwar, Sajid/0000-0003-3393-1656
CR Alam M, 2008, SACMAT 08
   Alam M, 2008, ASIACCS 08
   Alam M, 2007, IEEE INT ENTERP DIST, P75, DOI 10.1109/EDOC.2007.52
   Anderson A, 2005, SAML 2 0 PROFILE XAC, V1
   Anderson S, 2005, WEB SERVICE IN PRESS, V7
   [Anonymous], SECURITY
   [Anonymous], 2003, Proceedings of the 2003 ACM workshop on XML security
   Atkinson B., 2002, WEB SERVICES SECURIT
   BAJAJ S, 2006, WEB SERVICES POLICY
   Devices A, 2005, AMD PUBLICATION, V33047
   Grawrock David, 2005, INTEL SAFER COMPUTIN
   Jaeger T., 2006, SACMAT 2006. Proceedings of Eleventh ACM Symposium on Access Control Models and Technologies, P19
   Mayer F., 2006, SELinux by Example: Using Security Enhanced Linux
   McCarty Bill., 2004, SELINUX NSAS OPEN SO
   Moses T., 2005, EXTENSIBLE ACCESS CO
   Nagarajan A, 2007, STC 07
   Park J., 2002, P 7 ACM S ACCESS CON, P57, DOI DOI 10.1145/507711.507722
   Pearson Siani., 2002, TRUSTED COMPUTING PL
   PROCTOR S, 2006, SUNS XACML IMPLEMENT
   Sadeghi Ahmad-Reza., 2004, NSPW 04 P 2004 WORKS, P67
   Safford D, 2003, LINUX J SPECIALIZED, V2003, P2
   Shi E, 2005, P IEEE S SECUR PRIV, P154, DOI 10.1109/SP.2005.4
   SONG Z, 2006, 2 WORKSH ADV TRUST C
   Yoshihama S, 2007, TEST ANAL WEB SERVIC, P441
NR 24
TC 0
Z9 0
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 283
EP 302
DI 10.1007/s11042-011-0770-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000009
DA 2024-07-18
ER

PT J
AU Pham, HX
   Jung, JJ
AF Hau Xuan Pham
   Jung, Jason J.
TI Preference-based user rating correction process for interactive
   recommendation systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; User rating; User preference; Interaction
AB In most of the recommendation systems, user rating is an important user activity that reflects their opinions. Once the users return their ratings about items the systems have suggested, the user ratings can be used to adjust the recommendation process.However, while rating the items users can make some mistakes (e.g., natural noises). As the recommendation systems receive more incorrect ratings, the performance of such systems may decrease. In this paper, we focus on an interactive recommendation system which can help users to correct their own ratings. Thereby, we propose a method to determine whether the ratings from users are consistent to their own preferences (represented as a set of dominant attribute values) or not and eventually to correct these ratings to improve recommendation. The proposed interactive recommendation system has been particularly applied to two user rating datasets (e.g., MovieLens and Netflix) and it has shown better recommendation performance (i.e., lower error ratings).
C1 [Hau Xuan Pham; Jung, Jason J.] Yeungnam Univ, Dept Comp Engn, Gyongsan, South Korea.
C3 Yeungnam University
RP Jung, JJ (corresponding author), Yeungnam Univ, Dept Comp Engn, Gyongsan, South Korea.
EM pxhauqbu@gmail.com; j2jung@gmail.com
RI Jung, Jason J./B-9622-2012
OI Jung, Jason J./0000-0003-0050-7445
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2011-0017156]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (No. 2011-0017156).
CR Amatriain X, 2009, LECT NOTES COMPUT SC, V5535, P247, DOI 10.1007/978-3-642-02247-0_24
   Amatriain Xavier, 2009, P 3 ACM C REC SYST, P173, DOI DOI 10.1145/1639714.1639744
   Cheung KW, 2003, DECIS SUPPORT SYST, V35, P231, DOI 10.1016/S0167-9236(02)00108-2
   Cosley Dan, 2003, P SIGCHI C HUM FACT, P585
   De Maeyer P, 2011, J BUS RES, V64, P1067, DOI 10.1016/j.jbusres.2011.02.001
   Eckhardt A, 2009, CEUR WORKSHOP PROCEE, V471, P56
   Harper FM, 2005, LECT NOTES ARTIF INT, V3538, P307
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jung JJ, 2012, EXPERT SYST APPL, V39, P9002, DOI 10.1016/j.eswa.2012.02.035
   Jung JJ, 2012, NEUROCOMPUTING, V88, P36, DOI 10.1016/j.neucom.2011.08.028
   Jung JJ, 2011, LECT NOTES ARTIF INT, V6922, P592, DOI 10.1007/978-3-642-23935-9_58
   Jung JJ, 2012, EXPERT SYST APPL, V39, P4049, DOI 10.1016/j.eswa.2011.09.096
   Jung JJ, 2012, INFORM SCIENCES, V182, P30, DOI 10.1016/j.ins.2010.08.042
   Jung JJ, 2011, EXPERT SYST APPL, V38, P4809, DOI 10.1016/j.eswa.2010.09.165
   Krishnan V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P211
   Liang Z, 2008, PERFORM EVALUATION, V65, P99, DOI 10.1016/j.peva.2007.04.001
   O'Mahony M., 2004, ACM Trans. Internet Technol, V4, DOI DOI 10.1145/1031114.1031116
   O'Mahony M. P., 2006, 2006 International Conference on Intelligent User Interfaces, P109, DOI 10.1145/1111449.1111477
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Pham XH, 2010, P 11 INT C INT TECHN, P75
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Umyarov Akhmed., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P37
NR 22
TC 31
Z9 36
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 119
EP 132
DI 10.1007/s11042-012-1119-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800008
DA 2024-07-18
ER

PT J
AU Jung, JJ
   You, E
   Park, SB
AF Jung, Jason J.
   You, Eunsoon
   Park, Seung-Bo
TI Emotion-based character clustering for managing story-based contents: a
   cinemetric analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character clustering; Relationship; Emotion; Character-net; Social
   network
AB Stories in digital content (e.g., movies) are usually developed using many kinds of relationships among the characters. In order to efficiently manage such contents, we want to exploit a social network (called Character-net) extracted from the stories. Since scripts are composed of several elements (i.e., scene headings, character names, dialogs, actions, etc.), we focus on analyzing interactions (e.g., dialog) among the characters to build such a social network. Most importantly, these relationships between minor and major characters can be abstracted and clustered into similar scenes. Thereby, in this paper, we propose a novel method that can cluster characters using their emotional similarity. If a minor character has a similar emotion vector tothe main character, then the minor character can be classified as a tritagonist who helps the main character. Conversely, this minor character may be clustered into another group and denoted as an antagonist. Additionally, we show the efficiency of our proposed method by experiment in this paper.
C1 [Jung, Jason J.] Yeungnam Univ, Gyongsan, South Korea.
   [You, Eunsoon] Dankook Univ, Storytelling Res Ctr, Gyeonggi Do, South Korea.
   [Park, Seung-Bo] Kyung Hee Univ, Seoul, South Korea.
C3 Yeungnam University; Dankook University; Kyung Hee University
RP Park, SB (corresponding author), Kyung Hee Univ, Seoul, South Korea.
EM j2jung@gmail.com; eunsoony@hotmail.com; molaal@naver.com
RI Jung, Jason J./B-9622-2012; You, Eun-Soon/E-7686-2015
OI Jung, Jason J./0000-0003-0050-7445; You, Eun-Soon/0000-0001-8827-1232
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF); Ministry of Education, Science and Technology
   [2012R1A1A2002839]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology (No. 2012R1A1A2002839).
CR Ajmera J, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P411, DOI 10.1109/ASRU.2003.1318476
   [Anonymous], 1994, P AICS C
   [Anonymous], 2000, AUDIO-VISUAL SPEECH RECOGNITION
   [Anonymous], 2008, Proc. ACM Multimedia, DOI [10.1145/1459359.1459462, DOI 10.1145/1459359.1459462]
   [Anonymous], INDIANA UNDERGRADUAT
   Cour T, 2008, LECT NOTES COMPUT SC, V5305, P158, DOI 10.1007/978-3-540-88693-8_12
   Danisman A., 2008, AISB 2008 Convention Communication, Interaction and Social Intelligence, P53
   Elliot C, 1992, THESIS NW U
   Esuli Andrea., 2006, LREC 2006 Proceedings, 2006, S, P417
   Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018
   Hung H., 2007, P ACM MULTIMEDIA, P835
   Jung JJ, 2012, EXPERT SYST APPL, V39, P9002, DOI 10.1016/j.eswa.2012.02.035
   Jung JJ, 2012, EXPERT SYST APPL, V39, P8066, DOI 10.1016/j.eswa.2012.01.136
   Jung JJ, 2012, COMPUT J, V55, P337, DOI 10.1093/comjnl/bxr102
   Jung JJ, 2012, EXPERT SYST APPL, V39, P4049, DOI 10.1016/j.eswa.2011.09.096
   Ma CL, 2005, LECT NOTES COMPUT SC, V3784, P622
   Niu HN, 2003, INT CONF ACOUST SPEE, P125
   Park S.-B., 2011, Multimedia Tools and Applications - MTA
   Park S-B, 2011, LECT NOTES ELECT ENG, P507
   Park SB, 2011, LECT NOTES ARTIF INT, V6592, P130, DOI 10.1007/978-3-642-20042-7_14
   Quan C, 2010, P 7 C INT LANG RES E, P1146
   Rienks R., 2006, P 8 INT C MULTIMODAL, P257
   Ronfard R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P21
   Salway A., 2003, P 11 ACM INT C MULTI, P299
   Strapparava C., 2004, Lrec, Volume, V4, P1083
   Tsivian Y., 2009, DIGITAL TOOLS MEDIA, P93
   Turetsky R, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1659, DOI 10.1109/ICME.2004.1394570
   van Willegen I, 2009, LECT NOTES ARTIF INT, V5729, P234, DOI 10.1007/978-3-642-04208-9_34
   Vinciarelli A, 2006, P IEEE INT C MULT EX, P779
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Wu Cai, 2005, AMIA Annu Symp Proc, P1158
   Yassine M., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P1136, DOI 10.1109/ICDMW.2010.75
NR 32
TC 17
Z9 18
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 29
EP 45
DI 10.1007/s11042-012-1133-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800003
DA 2024-07-18
ER

PT J
AU Lu, SF
   Jin, XG
   Zhao, HL
   Zhao, YD
AF Lu, Shufang
   Jin, Xiaogang
   Zhao, Hanli
   Zhao, Yandan
TI Real-time image marbleization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual marbling; Figurative marbling; Media art; Fluid simulation
ID ART
AB We present a new real-time image marbleization method that converts an image into a marble-like appearance automatically. The approach models the marbleization process as a two-dimensional fluid dynamics problem, whereby color advection of an input image results in a marbleized image. During the fluid dynamics simulation, we add a pixel-level external force field which is tangent to salient features in the image. The forces are computed from the image characteristics without user intervention. A stylized image with marble-like appearance is easily created that maintains the basic shape of objects in the input image. The entire modeling framework is implemented on a graphics processing unit, thus enabling real-time visual feedback. This approach provides a new tool to design figurative marbling textures without mixing of colors, which are almost impossible with previous computer-generated marbling methods.
C1 [Lu, Shufang; Jin, Xiaogang; Zhao, Yandan] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
   [Zhao, Hanli] Wenzhou Univ, Wenzhou 325035, Peoples R China.
C3 Zhejiang University; Wenzhou University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
EM lushufang@cad.zju.edu.cn; jin@cad.zju.edu.cn; hanlizhao@gmail.com;
   zhaoyandan@cad.zju.edu.cn
FU NSFC-MSRA Joint Funding [60970159]; National Natural Science Foundation
   of China [60933007, 60833007, 61100146]; Zhejiang Provincial Natural
   Science Foundation of China [Z1110154, Y1110004]
FX We would like to thank the anonymous reviewers for their constructive
   comments. This work was supported by the NSFC-MSRA Joint Funding (Grant
   No. 60970159), the National Natural Science Foundation of China (Grant
   Nos. 60933007 and 60833007) and Zhejiang Provincial Natural Science
   Foundation of China (Grant no. Z1110154). Hanli Zhao was supported by
   the National Natural Science Foundation of China (Grant No.61100146) and
   Zhejiang Provincial Natural Science Foundation of China (Grant No.
   Y1110004).
CR Acar R, 2006, IEEE T VIS COMPUT GR, V12, P600, DOI 10.1109/TVCG.2006.66
   Acar R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289606
   Akgun BT, 2004, LEONARDO, V37, P49, DOI 10.1162/002409404772828120
   Ando R, 2011, COMPUT GRAPH-UK, V35, P148, DOI 10.1016/j.cag.2010.11.002
   [Anonymous], 2018, Real-Time Rendering
   [Anonymous], 2012, EBRU ART PAPER MARBL
   [Anonymous], ULTIMATE MARBLING HD
   Bousseau A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276507
   Grossman R, 2009, DIGITIAL PAINTING FU
   Gunter Wyszecki., 1982, COLOR SCI CONCEPTS M, V2nd
   Hays J., 2004, PROC NPAR 01, P113
   Jin XG, 2007, IEEE COMPUT GRAPH, V27, P78, DOI 10.1109/MCG.2007.28
   Kagaya M, 2011, IEEE T VIS COMPUT GR, V17, P74, DOI 10.1109/TVCG.2010.25
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Laramee RS, 2004, COMPUT GRAPH FORUM, V23, P203, DOI 10.1111/j.1467-8659.2004.00753.x
   Lee H, 2009, COMPUT GRAPH FORUM, V28, P1207, DOI 10.1111/j.1467-8659.2009.01498.x
   Lu SF, 2012, IEEE COMPUT GRAPH, V32, P26, DOI 10.1109/MCG.2011.51
   Mao X., 2003, GRAPHITE 03, P79, DOI [10.1145/604471.604489, DOI 10.1145/604471.604489]
   Neyret F., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P147
   Olsen SvenC., 2005, P GRAPHICS INTERFACE, P241
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Suzuki T., 2001, Visualization, Imaging, and Image Processing. Proceedings of the IASTED International Conference, P208
   Xu JY, 2008, IEEE COMPUT GRAPH, V28, P35, DOI 10.1109/MCG.2008.36
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
   Zhao HL, 2009, VISUAL COMPUT, V25, P973, DOI 10.1007/s00371-008-0308-y
   Zhao HL, 2009, MULTIMED TOOLS APPL, V44, P187, DOI 10.1007/s11042-009-0290-z
NR 26
TC 3
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 795
EP 808
DI 10.1007/s11042-012-0989-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600014
DA 2024-07-18
ER

PT J
AU Haesen, M
   Meskens, J
   Luyten, K
   Coninx, K
   Becker, JH
   Tuytelaars, T
   Poulisse, GJ
   Pham, PT
   Moens, MF
AF Haesen, Mieke
   Meskens, Jan
   Luyten, Kris
   Coninx, Karin
   Becker, Jan Hendrik
   Tuytelaars, Tinne
   Poulisse, Gert-Jan
   Phi The Pham
   Moens, Marie-Francine
TI Finding a needle in a haystack: an interactive video archive explorer
   for professional video searchers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Searching and browsing video archives; Information filtering;
   User-centred software engineering; Interactive visualisations
AB Professional video searchers typically have to search for particular video fragments in a vast video archive that contains many hours of video data. Without having the right video archive exploration tools, this is a difficult and time consuming task that induces hours of video skimming. We propose the video archive explorer, a video exploration tool that provides visual representations of automatically detected concepts to facilitate individual and collaborative video search tasks. This video archive explorer is developed by employing a user-centred methodology, which ensures that the tool is more likely to fit to the end user needs. A qualitative evaluation with professional video searchers shows that the combination of automatic video indexing, interactive visualisations and user-centred design can result in an increased usability, user satisfaction and productivity.
C1 [Haesen, Mieke; Meskens, Jan; Luyten, Kris; Coninx, Karin] Hasselt Univ, tUL, IBBT, Expertise Ctr Digital Media, B-3590 Diepenbeek, Belgium.
   [Becker, Jan Hendrik; Tuytelaars, Tinne] Katholieke Univ Leuven, ESAT, PSI, B-3001 Heverlee, Belgium.
   [Poulisse, Gert-Jan; Phi The Pham; Moens, Marie-Francine] Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium.
C3 Hasselt University; KU Leuven; KU Leuven
RP Haesen, M (corresponding author), Hasselt Univ, tUL, IBBT, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM mieke.haesen@uhasselt.be; jan.meskens@uhasselt.be;
   kris.luyten@uhasselt.be; karin.coninx@uhasselt.be;
   janhendrik.becker@esat.kuleuven.be; tinne.tuytelaars@esat.kuleuven.be;
   gert-jan.poulisse@cs.kuleuven.be; phithe.pham@cs.kuleuven.be;
   sien.moens@cs.kuleuven.be
RI Moens, Marie-Francine/B-8378-2014; Tuytelaars, Tinne/B-4319-2015
OI Haesen, Mieke/0000-0003-0815-1885; Luyten, Kris/0000-0002-4194-1101;
   Tuytelaars, Tinne/0000-0003-3307-9723
FU IWT Project AMASS++ [SBO-060051]
FX This research was supported by the IWT Project AMASS++ (SBO-060051). We
   would like to thank all members of the AMASS++ user committee for their
   feedback about the results discussed during the half-yearly user
   committee meetings. Special thanks to the Flemish broadcasting company
   VRT to contribute to the user studies. Grateful acknowledgement is given
   to Koen Deschacht, Wim De Smet, Scott Martens, Ineke Schuurman, Vincent
   Vandeghinste, Frank Van Eynde and Luc Van Gool. Furthermore, we would
   like to thank Jimmy Cleuren for his contribution to the high-fidelity
   prototypes and Karel Robert for the graphic design of the user
   interface.
CR Adcock John., 2008, CIVR 08, P465
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 1998, Contextual design: defining customer-centered systems
   [Anonymous], 2007, P IEEE INT C AC SPEE
   [Anonymous], 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095054, DOI 10.1145/1095034.1095054]
   [Anonymous], **NON-TRADITIONAL**
   Berger N, 2006, MORGAN KAUFMANN SERI
   Boreczky J., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P185, DOI 10.1145/332040.332428
   Card S K., 1999, READINGS INFORM VISU
   Cheng KY, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P789
   Christel M. G., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P171, DOI 10.1145/274644.274670
   Christel M.G., 2008, Proceedings of the International Conference on Content-based Image and Video Retrieval (CIVR '08), P447
   Cilella S, 2011, INTERACTIONS, V18, P62
   Coninx K, 2010, P BCS C HUM COMP INT
   Dragicevic P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P237
   Grün C, 2005, LECT NOTES COMPUT SC, V3652, P174
   Haesen M, 2008, LECT NOTES COMPUT SC, V5247, P150, DOI 10.1007/978-3-540-85992-5_14
   Haubold Alexander., 2007, CIVR, P41, DOI DOI 10.1145/1282280.1282286
   Hauptmann AG, 2008, P IEEE, V96, P602, DOI 10.1109/JPROC.2008.916355
   Heilig Mathias., 2008, Proceedings of the Working Conference on Advanced Visual Interfaces, P490, DOI [10.1145/1385569, DOI 10.1145/1385569]
   Hurst W., 2004, P 12 ANN ACM INT C M, P742, DOI [10.1145/1027527.1027694, DOI 10.1145/1027527.1027694]
   International Standards Organisation, 1999, ISO 13407
   Kankanhalli MS, 2008, P IEEE, V96, P712, DOI 10.1109/JPROC.2008.916383
   Karrer T, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P247
   Meskens Jan, 2010, P 23 ANN ACM S US IN, P129
   Morris M.R., 2007, Proceedings of ACM SIGCHI 2007 workshop on exploratory search and HCI: Designing and evaluating interfaces to support exploratory search interaction, P9
   Patton J, 2008, IEEE SOFTWARE, V25, P72, DOI 10.1109/MS.2008.134
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Phi TP, 2010, IEEE INT CON MULTI, P1528, DOI 10.1109/ICME.2010.5583271
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Poulisse GJ, 2010, MULTIMED TOOLS APPL, V48, P3, DOI 10.1007/s11042-009-0358-9
   REDMONDPYLE D, 1995, GRAPHICAL USER INTER
   Smeaton AF, 2007, MULTIMEDIA SYST, V12, P375, DOI 10.1007/s00530-006-0064-7
   Snoek CGM, 2008, IEEE MULTIMEDIA, V15, P86, DOI 10.1109/MMUL.2008.21
   Tang Anthony., 2008, AVI '08: Proceedings of the Working Conference on Advanced Visual Interfaces 2008, P191, DOI DOI 10.1145/1385569.1385601
   Toshiyuki M., 1995, Proceedings of the Human factors in computing systems, P143, DOI DOI 10.1145/223355.223471
   Twidale MB, 1997, INFORM PROCESS MANAG, V33, P761, DOI 10.1016/S0306-4573(97)00040-X
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   University of Konstanz HCI Group, MED PROJ DESCR
   Wang S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P587
   Wassink I, 2009, ADV INFORM KNOWL PRO, P175, DOI 10.1007/978-1-84800-269-2
   Yang J, 2008, TRECVID 2008
NR 42
TC 15
Z9 15
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 331
EP 356
DI 10.1007/s11042-011-0809-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Mukherjee, DP
AF Mukherjee, Snehasis
   Mukherjee, Dipti Prasad
TI A design-of-experiment based statistical technique for detection of
   key-frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key-frame; Video summarization; Design of experiment; Helmholtz
   principle; Meaningfulness; Gestalt
ID SELECTION
AB In this paper decision variables for the key-frame detection problem in a video are evaluated using statistical tools derived from the theory of design of experiments. The pixel-by-pixel intensity difference of consecutive video frames is used as the factor or decision variable for designing an experiment for key-frame detection. The determination of a key-frame is correlated with the different values of the factor. A novel concept of meaningfulness of a video key-frame is also introduced to select the representative key-frame from a set of possible key-frames. The use of the concepts of design of experiments and the meaningfulness property to summarize a video is tested using a number of videos taken from MUSCLE-VCD-2007 dataset. The performance of the proposed approach in detecting key-frames is found to be superior in comparison to the competing approaches like PME based method (Liu et al., IEEE Trans Circuits Syst Video Technol 13(10):1006-1013, 2003; Mukherjee et al., IEEE Trans Circuits Syst Video Technol 17(5):612-620, 2007; Panagiotakis et al., IEEE Trans Circuits Syst Video Technol 19(3):447-451, 2009).
C1 [Mukherjee, Snehasis; Mukherjee, Dipti Prasad] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Mukherjee, S (corresponding author), Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
EM snehasismukho@gmail.com; dipti@isical.ac.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Mukherjee, Snehasis/0000-0002-2196-8980
CR Adjeroh D, 2009, J IMAGE VIDEO PROCES, V2009
   [Anonymous], P 1 INT WORKSH INT M
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   Calic J, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P28, DOI 10.1109/ITCC.2002.1000355
   Chasanis VT, 2009, IEEE T MULTIMEDIA, V11, P89, DOI 10.1109/TMM.2008.2008924
   Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576
   Desolneux A., 2008, Interdisciplinary Applied Mathematics, V34
   HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952
   Ouyang JQ, 2006, J VIS COMMUN IMAGE R, V17, P1145, DOI 10.1016/j.jvcir.2006.03.003
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Mills M., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P93, DOI 10.1145/142750.142764
   Mukherjee DP, 2007, IEEE T CIRC SYST VID, V17, P612, DOI 10.1109/TCSVT.2007.895353
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Park S.H., 1996, Robust design and analysis for quality engineering, V1st
   Pickering MJ, 2002, LECT NOTES COMPUT SC, V2383, P309
   PYE D, 1998, P INT C SPOK LANG PR
   Ranjit K.R., 2001, DESIGN EXPT USING TA
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Richard G.L., 2007, Statistical Concepts: A Second Course, VThird
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   SONG X, 2005, IEEE P INT C AC SPEE, V2, P126
   Spyrou E, 2009, MULTIMED TOOLS APPL, V41, P337, DOI 10.1007/s11042-008-0237-9
   Valdés V, 2010, MULTIMED TOOLS APPL, V49, P7, DOI 10.1007/s11042-009-0392-7
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 27
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 847
EP 877
DI 10.1007/s11042-011-0882-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500014
DA 2024-07-18
ER

PT J
AU Mohammad, AA
AF Mohammad, Ahmad A.
TI A new digital image watermarking scheme based on Schur decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Schur decomposition; Digital watermarking; Ownership protection; Robust
ID ROBUST; REDUCTION
AB In this paper, we present a new digital watermarking scheme for ownership protection. The algorithm embeds the watermark in the Schur decomposition components of the cover image. We also show that this algorithm is noninvertible. Comparisons with other algorithms indicate that the proposed algorithm is robust against most common attacks including geometrical distortions and jpeg compression attacks. Simulations show that the performance of this algorithm outperforms the closely related singular value decomposition based algorithms. More specifically, the proposed algorithm is more robust and requires less number of computations. In addition, our algorithm does not suffer the false positive detection problem inherent in SVD based algorithms.
C1 Princess Sumaya Univ Technol, Dept Comp Engn, Amman, Jordan.
C3 Princess Sumaya University for Technology
RP Mohammad, AA (corresponding author), Princess Sumaya Univ Technol, Dept Comp Engn, Amman, Jordan.
EM atawayha@psut.edu.jo
RI Mohammad, Ahmad A./AAA-6444-2019
OI Mohammad, Ahmad A./0000-0001-8271-9729
CR Agreste S, 2008, J COMPUT APPL MATH, V221, P274, DOI 10.1016/j.cam.2007.10.057
   ALDHAHERI RW, 1991, INT J CONTROL, V53, P709, DOI 10.1080/00207179108953642
   Aldhaheri RW, 2004, MULTIDIM SYST SIGN P, V15, P65, DOI 10.1023/B:MULT.0000003933.41677.03
   Alturki FT, 2007, SIGNAL PROCESS-IMAGE, V22, P347, DOI 10.1016/j.image.2006.11.005
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chang CC, 2007, INT J INNOV COMPUT I, V3, P609
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Cheung CM, 2007, C IND ELECT APPL, P2403
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cruces Sergio, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P217
   Cruces S, 2003, P 4 INT S IND COMP A, P464
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Ganic E, 2003, P IASTED INT C COMM, P85
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Huang FJ, 2004, PATTERN RECOGN LETT, V25, P1769, DOI 10.1016/j.patrec.2004.07.003
   Kang X., 2008, INT J NETWORK SECURI, V6, P121
   Knockaert L, 1999, IEEE T SIGNAL PROCES, V47, P2724, DOI 10.1109/78.790654
   Kong WH, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P265
   LAUB AJ, 1979, IEEE T AUTOMAT CONTR, V24, P913, DOI 10.1109/TAC.1979.1102178
   Laub AJ, 1982, LECT NOTES CONTROL I, V39, P165
   LEE J, 1990, IEEE T AUTOMAT CONTR, V35, P215, DOI 10.1109/9.45184
   Lei CU, LECT NOTES ELECT ENG, V4, P411
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu J, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P457
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Lu W, 2009, COMPUT ELECTR ENG, V35, P183, DOI 10.1016/j.compeleceng.2008.09.004
   Lu W, 2008, INFORMATICA-LITHUAN, V19, P555
   Martin CDM, 2007, SIAM J MATRIX ANAL A, V29, P184, DOI 10.1137/050631707
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   ORuanaidh JJK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P239, DOI 10.1109/ICIP.1996.560428
   Ouhsain M, 2009, EXPERT SYST APPL, V36, P2123, DOI 10.1016/j.eswa.2007.12.046
   RACHID A, 1992, IEEE T AUTOMAT CONTR, V37, P666, DOI 10.1109/9.135512
   Reddy AA, 2005, PATTERN RECOGN LETT, V26, P1019, DOI 10.1016/j.patrec.2004.09.047
   Rezazadeh Z, 2009, P WORLD AC SCI ENG T, V13, P255
   SAFONOV MG, 1989, IEEE T AUTOMAT CONTR, V34, P729, DOI 10.1109/9.29399
   Sebe F., 2000, Information Security. Third International Workshop, ISW 2000. Proceedings (Lecture Notes in Computer Science Vol.1975), P44
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Song FX, 2006, NEUROCOMPUTING, V69, P1683, DOI 10.1016/j.neucom.2006.01.016
   Tao PN, 2004, PROC SPIE, V5601, P133, DOI 10.1117/12.569641
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang XY, 2008, SIGNAL PROCESS, V88, P2193, DOI 10.1016/j.sigpro.2008.03.005
   Wu YD, 2005, IEEE T MULTIMEDIA, V7, P624, DOI 10.1109/TMM.2005.846774
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 57
TC 35
Z9 38
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 851
EP 883
DI 10.1007/s11042-011-0772-7
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900006
DA 2024-07-18
ER

PT J
AU Lux, M
AF Lux, Mathias
TI How to search in MPEG-7 based semantic descriptions: an evaluation of
   metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-7; Retrieval metrics; Evaluation
ID MULTIMEDIA
AB MPEG-7 is an extensive multimedia metadata standard covering an impressive range of aspects of metadata. However, as with most metadata standards details of usage and application of the standards are-at least partially-by design open to interpretation. In case of MPEG-7, storage and transmission of high level metadata on concept level are well defined but retrieval methods are not proposed by the standard. So if for instance a user annotates photos using the MPEG-7 semantic description scheme, there are no standardized ways to index and retrieve the photos based on the annotation. In this article we revisit metrics for relevance assessment based on the MPEG-7 Semantic Description Scheme in the context of information retrieval. We evaluate them in a digital photo retrieval scenario and investigate correlation of similarity and distance metrics to user perception in a user study.
C1 Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
C3 University of Klagenfurt
RP Lux, M (corresponding author), Klagenfurt Univ, Inst Informat Technol, Klagenfurt, Austria.
EM mlux@itec.uni-klu.ac.at
FU Know-Center; Austrian Competence Center under Austrian Ministry of
   Transport, Innovation and Technology; state of Styria; City of Graz
FX Part of this work has been funded by the Know-Center. The Know-Center is
   a Competence Center funded within the Austrian Competence Center program
   K plus under the auspices of the Austrian Ministry of Transport,
   Innovation and Technology (www.kplus.at), by the state of Styria and by
   the City of Graz.
CR Allan J., 2003, SIGIR FORUM, V37, P31, DOI DOI 10.1145/945546.945549
   [Anonymous], 2009, MM 09 P 2009 ACM MUL, DOI DOI 10.1145/1631272.1631456
   Athanasiadis T, 2004, LECT NOTES COMPUT SC, V3115, P665
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   BERNERSLEE T, 2001, CONCEPTUAL GRAPHS SE
   Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600
   Boll S, 2007, IEEE MULTIMEDIA, V14, P9, DOI 10.1109/MMUL.2007.17
   Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7
   Chadwick B.A., 1984, SOCIAL SCI RES METHO
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   CORBY O, 2000, ICCS, P468
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dickinson PJ, 2003, GRAPHS UNIQUE NODE L, V2726
   Doller Mario., 2002, MULTIMEDIA '02: Proceedings of the tenth ACM international conference on Multimedia, P85
   Eidenberger H, 2003, SPIE P, V5307, P133
   Eysenck M., 2004, Psychology: An international perspective
   FONSECA MJ, 2004, THESIS U TECNICA LIS
   Frankfort-Nachmias Chava., 1992, RES METHODS SOCIAL S, V4th
   Hammiche S, 2004, 2 ACM INT WORKSH MUL, P36, DOI DOI 10.1145/1032604.1032612
   Hunter J., 2001, First International Semantic Web Working Symposium (SWWS'01), P261
   Kosch H., 2003, DISTRIBUTED MULTIMED
   Lux M, 2008, P WIAMIS 2008
   Meyer zu Eissen S, 2005, P 5 INT C KNOWL MAN, P598
   Robertson S., 2004, P 13 ACM INT C INF K, P42
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Salembier P, 2001, IEEE T CIRC SYST VID, V11, P748, DOI 10.1109/76.927435
   Santini S, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P3, DOI 10.1109/MMSP.1998.738904
   Shasha Dennis, 2002, P PRINC DAT SYST POD, P39, DOI DOI 10.1145/543613.543620
   Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sowa J.F., 1979, Proceedings of the 17th Annual Meeting on Association for Computational Linguistics, P39
   Tons R, 2006, LECT NOTES COMPUT SC, V4080, P307
   Troncy R, 2006, LECT NOTES COMPUT SC, V4306, P41
   Tsinaraki C, 2003, LNCS
   Valiente G., 2002, ALGORITHMS TREES GRA
   Yoon K, 2008, 153938122008 ISO IEC
   Zhong JW, 2002, LECT NOTES ARTIF INT, V2393, P92
NR 37
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 673
EP 690
DI 10.1007/s11042-011-0756-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000013
DA 2024-07-18
ER

PT J
AU Ahmad, N
   An, Y
   Park, J
AF Ahmad, Nishat
   An, Youngeun
   Park, Jongan
TI An intrinsic semantic framework for recognizing image objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Object recognition; Computer vision; Visual object
   class recognition; Semantic grouping; Semantic feature computation;
   Graph representation
AB The paper proposes a new approach to find semantic meanings in visual object class structure, in line with the Gestalt laws of proximity. Micro level semantic structures are formed by line segments (arcs also approximated into line segments based on pixel deviation threshold) which are in close proximity. These structures are hierarchically combined till a semantic label can be assigned. The algorithm extracts semantic groups, their inter-relations and represents these using a graph. Invariant geometrical properties of the groups and relations are used as vertex and edge labels. A graph model captures the inter class variability by analyzing the repetitiveness of structures and relations and uses it as a weighting factor for classification. The algorithm has been tested on a standard benchmark database and compared with existing approaches.
C1 [Ahmad, Nishat; An, Youngeun; Park, Jongan] Chosun Univ, Dept Informat & Commun Engn, Kwangju, South Korea.
   [Park, Jongan] Chosun Univ, Sch Elect Informat & Commun Engn, Seoul, South Korea.
C3 Chosun University; Chosun University
RP Ahmad, N (corresponding author), Chosun Univ, Dept Informat & Commun Engn, Kwangju, South Korea.
EM nischat@gmail.com; yean@paran.com; japark@chosun.ac.kr
FU Chosun University
FX This study was supported by research fund from Chosun University, 2011.
CR [Anonymous], LNCS
   [Anonymous], 2004, IEEE COMP SOC C COMP
   Ballard D.H., 1982, Computer Vision
   Berg C., 2005, P INT C COMP VIS PAT
   BERG C, 2005, THESIS U CALIFORNIA
   Dattorro J.C., 2004, Convex optimization and euclidean distance geometry
   Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3
   Grauman K., 2006, MITCSAILTR2006020
   HOLUB AD, 2005, P NIPS WORKSH INT TR
   Kovesi P., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P822
   Lazebnik S, 2006, P INT C COMP VIS PAT
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lowe DG, 1985, SPRINGER INT SERIES, V5
   Mojsilovic A, 2001, IEEE IMAGE PROC, P18, DOI 10.1109/ICIP.2001.958942
   Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0
   POPE AR, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P768, DOI 10.1109/CVPR.1994.323895
   Rosch E, 1976, COGNITIVE PSYCHOL, V8, P291
   SARKAR S, 1993, IEEE T SYST MAN CYB, V23, P382, DOI 10.1109/21.229452
   Serre T, 2005, PROC CVPR IEEE, P994
   Wang G, 2006, P INT C COMP VIS PAT
   WERTHEIMER M, 2004, M WERTHEIMER GESTALT
   WITKIN A. P., 1983, IJCAI, V83, P1023
NR 22
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 423
EP 438
DI 10.1007/s11042-011-0739-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700011
DA 2024-07-18
ER

PT J
AU Fischer, M
   Ekenel, HK
   Stiefelhagen, R
AF Fischer, Mika
   Ekenel, Hazim Kemal
   Stiefelhagen, Rainer
TI Person re-identification in TV series using robust face recognition and
   user feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Person retrieval; Video retrieval; Face
   recognition; Face tracking
AB In this paper, we present a system for person re-identification in TV series. In the context of video retrieval, person re-identification refers to the task where a user clicks on a person in a video frame and the system then finds other occurrences of the same person in the same or different videos. The main characteristic of this scenario is that no previously collected training data is available, so no person-specific models can be trained in advance. Additionally, the query data is limited to the image that the user clicks on. These conditions pose a great challenge to the re-identification system, which has to find the same person in other shots despite large variations in the person's appearance. In the study, facial appearance is used as the re-identification cue, since, in contrast to surveillance-oriented re-identification studies, the person can have different clothing in different shots. In order to increase the amount of available face data, the proposed system employs a face tracker that can track faces up to full profile views. This makes it possible to use a profile face image as query image and also to retrieve images with non-frontal poses. It also provides temporal association of the face images in the video, so that instead of using single images for query or target, whole tracks can be used. A fast and robust face recognition algorithm is used to find matching faces. If the match result is highly confident, our system adds the matching face track to the query set. Finally, if the user is not satisfied with the number of returned results, the system can present a small number of candidate face images and lets the user confirm the ones that belong to the queried person. These features help to increase the variation in the query set, making it possible to retrieve results with different poses, illumination conditions, etc. The system is extensively evaluated on two episodes of the TV series Coupling, showing very promising results.
C1 [Fischer, Mika; Ekenel, Hazim Kemal; Stiefelhagen, Rainer] Karlsruhe Inst Technol, Inst Anthropomat, D-76131 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Fischer, M (corresponding author), Karlsruhe Inst Technol, Inst Anthropomat, Adenauerring 2, D-76131 Karlsruhe, Germany.
EM mika.fischer@kit.edu; ekenel@kit.edu; rainer.stiefelhagen@kit.edu
RI EKENEL, HAZIM KEMAL/A-5293-2016
OI EKENEL, HAZIM KEMAL/0000-0003-3697-8548
FU OSEO, French State agency for innovation; Karlsruhe Institute of
   Technology of the German Excellence Initiative
FX This study is partially funded by OSEO, French State agency for
   innovation, as part of the Quaero Programme, and by the "Concept for the
   Future" of the Karlsruhe Institute of Technology within the framework of
   the German Excellence Initiative.
CR [Anonymous], P CVPR BIOM WORKSH
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], P INT C MULT EXP
   [Anonymous], Open Source Computer Vision Library - v2.4.9
   [Anonymous], P NIST TRECVID WORKS
   [Anonymous], P INT C COMP VIS SYS
   [Anonymous], P INT C BIOM THEOR A
   [Anonymous], P CLEAR EV WORKSH
   [Anonymous], P INT C AUT FAC GEST
   Arandjelovic O, 2005, PROC CVPR IEEE, P860
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Ekenel HK, 2010, COMPUT VIS IMAGE UND, V114, P596, DOI 10.1016/j.cviu.2009.06.009
   Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Hamdoun O., 2008, PROC ACM INT C DISTR, P1
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Li Pengxu., 2007, CIVR, P57
   Ramanan D, 2007, PROC INT C COMPUTER, P1
   Sivic J, 2005, LECT NOTES COMPUT SC, V3568, P226
   Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513
   Smith Kevin., 2005, Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, CVPR Workshops, P36
   Stallkamp J., 2007, PROC INT C COMPUTER, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
NR 23
TC 10
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 83
EP 104
DI 10.1007/s11042-010-0603-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400005
DA 2024-07-18
ER

PT J
AU Jesus, R
   Abrantes, AJ
   Correia, N
AF Jesus, Rui
   Abrantes, Arnaldo J.
   Correia, Nuno
TI Methods for automatic and assisted image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal memories; Media annotation and retrieval; Semantic image
   analysis; Tagging games
ID RETRIEVAL; FRAMEWORK
AB Personal memories composed of digital pictures are very popular at the moment. To retrieve these media items annotation is required. During the last years, several approaches have been proposed in order to overcome the image annotation problem. This paper presents our proposals to address this problem. Automatic and semi-automatic learning methods for semantic concepts are presented. The automatic method is based on semantic concepts estimated using visual content, context metadata and audio information. The semi-automatic method is based on results provided by a computer game. The paper describes our proposals and presents their evaluations.
C1 [Jesus, Rui; Abrantes, Arnaldo J.] Inst Super Engn Lisboa, Multimedia & Machine Learning Grp, Lisbon, Portugal.
   [Correia, Nuno] Univ Nova Lisboa, CITI, Dept Informat, Fac Ciencias & Tecnol,FCT, P-2829516 Caparica, Portugal.
C3 Polytechnic Institute of Lisbon; Universidade Nova de Lisboa
RP Jesus, R (corresponding author), Inst Super Engn Lisboa, Multimedia & Machine Learning Grp, Rua Conselheiro Emidio Navarro 1, Lisbon, Portugal.
EM rjesus@deetc.isel.ipl.pt
RI Correia, Natália T. T./D-6699-2013; Abrantes, Arnaldo/JHS-7043-2023;
   FCTUNL, CITI/G-6714-2011; Jesus, Rui/G-9199-2011; Jesus,
   Rui/JZT-7448-2024; Correia, Nuno/D-2298-2010
OI Abrantes, Arnaldo/0000-0002-9911-6833; Correia,
   Nuno/0000-0002-8704-6698; Jesus, Rui/0000-0003-1869-6491
CR [Anonymous], 2002, CSCW '02, DOI DOI 10.1145/587078.587102
   [Anonymous], 2003, P 11 ACM INT C MULT
   [Anonymous], P ANN INT ACM SIGIR
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Belkhatir M, 2008, LECT NOTES COMPUT SC, V5181, P465, DOI 10.1007/978-3-540-85654-2_41
   Chang EdwardY., 2005, CVDB'05: Proceedings of the 2nd International Workshop on Computer Vision Meets Databases, P5, DOI [10.1145/1160939.1160945, DOI 10.1145/1160939.1160945]
   Choi J.Y., 2008, MIR 08, P44
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   GONCALVES D, 2008, ACM SIGCHI INT C ADV
   Goncalves D., 2008, Extended abstracts on Human Factors in Computing Systems, P2685
   JESUS R, 2008, P IEEE INT WORKSH SE
   JESUS R, 2008, P WORK C ADV VIS INT
   JESUS R, 2007, 5 WORKSH MULT INF RE
   Jesus RM, 2006, LECT NOTES COMPUT SC, V4261, P633
   JIEBO L, 2006, IEEE SIGNAL PROCESS, V22, P101
   Jing F, 2005, IEEE T IMAGE PROCESS, V14, P979, DOI 10.1109/TIP.2005.847289
   KUSTANOWITZ J, MOTIVATING ANNOTATIO
   LAVRENKO V, 2003, NEUR INF PROC SYST C
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J., 2006, P 14 ANN ACM INT C M, P911, DOI DOI 10.1145/1180639.1180841
   Lu Y, 2003, IEEE T MULTIMEDIA, V5, P339, DOI 10.1109/TMM.2003.813280
   Mori Y, 1999, P INT WORKSH MULT IN
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   OVER P, 2006, NIST TRECVID 2006
   Platt JC, 2000, ADV NEUR IN, P61
   Poggio T., 2003, NOTICES AMS, V50, P537
   RODDEN K, 2003, CHI 03, P409
   Shneiderman B, 2000, IEEE INFOR VIS, P88, DOI 10.1109/IV.2000.859742
   SINNOTT RW, 1984, SKY TELESCOPE, V68, P159
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tulving E, 2002, ANNU REV PSYCHOL, V53, P1, DOI 10.1146/annurev.psych.53.100901.135114
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   WENYIN L, 2001, HUM COMP INT INT 01
   Yan R., 2007, WORKSHOP MULTIMEDIA, P13
NR 37
TC 2
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 7
EP 26
DI 10.1007/s11042-010-0586-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tsikrika, T
   Diou, C
   de Vries, AP
   Delopoulos, A
AF Tsikrika, Theodora
   Diou, Christos
   de Vries, Arjen P.
   Delopoulos, Anastasios
TI Reliability and effectiveness of clickthrough data for automatic image
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Concepts; Supervised learning; Search logs;
   Clickthrough data; Collective knowledge; Implicit feedback; Reliability
AB Automatic image annotation using supervised learning is performed by concept classifiers trained on labelled example images. This work proposes the use of clickthrough data collected from search logs as a source for the automatic generation of concept training data, thus avoiding the expensive manual annotation effort. We investigate and evaluate this approach using a collection of 97,628 photographic images. The results indicate that the contribution of search log based training data is positive despite their inherent noise; in particular, the combination of manual and automatically generated training data outperforms the use of manual data alone. It is therefore possible to use clickthrough data to perform large-scale image annotation with little manual annotation effort or, depending on performance, using only the automatically generated training data. An extensive presentation of the experimental results and the accompanying data can be accessed at http://olympus.ee.auth.gr/similar to diou/civr2009/.
C1 [Tsikrika, Theodora; de Vries, Arjen P.] Ctr Wiskunde & Informat, NL-1098 XG Amsterdam, Netherlands.
   [Diou, Christos; Delopoulos, Anastasios] Aristotle Univ Thessaloniki, Multimedia Understanding Grp, Elect & Comp Engn Dept, GR-54006 Thessaloniki, Greece.
   [Diou, Christos; Delopoulos, Anastasios] Ctr Res & Technol Hellas, Informat & Telemat Inst, Thessaloniki, Greece.
   [de Vries, Arjen P.] Delft Univ Technol, Delft, Netherlands.
C3 Aristotle University of Thessaloniki; Centre for Research & Technology
   Hellas; Delft University of Technology
RP Tsikrika, T (corresponding author), Ctr Wiskunde & Informat, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
EM theodora.tsikrika@acm.org; diou@mug.ee.auth.gr; arjen@acm.org;
   adelo@eng.auth.gr
RI Delopoulos, Anastasios/B-2140-2013; de Vries, Arjen P./AAX-4970-2020;
   Diou, Christos/AAM-5533-2021; Delopoulos, Anastasios/ABB-6127-2021
OI de Vries, Arjen P./0000-0002-2888-4202; Diou,
   Christos/0000-0002-2461-1928; Tsikrika, Theodora/0000-0003-4148-9028
FU EU [FP6-045389]; Greek State Scholarships Foundation
FX The authors are grateful to the Belga press agency for providing the
   images and search logs used in this work and to Marco Palomino from the
   University of Sunderland for the extraction of the text features used.
   This work was supported by the EU-funded VITALAS project (FP6-045389).
   Christos Diou is supported by the Greek State Scholarships Foundation
   (http://www.iky.gr).
CR [Anonymous], P ACM MULT
   [Anonymous], P INT C CONT BAS IM
   Ashman H, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P191
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Baeza-Yates R, 2007, J AM SOC INF SCI TEC, V58, P1793, DOI 10.1002/asi.20627
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHANG SF, 2008, P TRECVID 2008
   CHUA TS, 2009, P 8 INT C CONT BAS I
   *COL U, 2006, LSCOM LEX DEF ANN VE
   Craswell N., 2007, Proc. 30th Annual Int. ACM SIGIR CRDIR, P239
   Faymonville P., 2009, HCOMP 09 P ACM SIGKD, P46, DOI DOI 10.1145/1600150.1600167
   Fox S, 2005, ACM T INFORM SYST, V23, P147, DOI 10.1145/1059981.1059982
   Hauptmann Alexander., 2007, CIVR 07, P627
   Hiemstra D., 2006, P 2 INT WORKSH OP SO, P12
   Hiemstra Djoerd., 1998, ECDL 98, P569
   Ho C.-J., 2009, HCOMP 09 P ACM SIGKD, P11
   Joachims T, 2007, SIGIR Forum, V41, P58, DOI [10.1145/1328964.1328974, DOI 10.1145/1328964.1328974]
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Joachims T, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1229179.1229181
   Kelly D., 2003, SIGIR Forum, V37, P18, DOI 10.1145/959258.959260
   MACDONALD C, 2009, P 2009 WORKSH WEB SE, P75, DOI DOI 10.1145/1507509.1507521
   Morrison D., 2009, P ACM SIGKDD WORKSH, P44
   Palomino Marco A, 2009, P 9 DUTCH BELG INF R, P3
   Poblete B., 2008, PROCEEDING 17 INT C, P41
   Scholer F, 2008, LECT NOTES COMPUT SC, V4956, P28
   Setz AT, 2009, IEEE INT CON MULTI, P1460, DOI 10.1109/ICME.2009.5202778
   Sigurbjornsson B., 2008, Proceeding of the 17th International Conference on World Wide Web
   Smith G., 2009, P WEB SCI C SOC ON L
   SNOEK CGM, 2004, P 14 ACM INT C MULT, P421
   TSIKRIKA T, 2009, P 8 INT C CONT BAS I
   Ulges A, 2008, P TRECVID 2008
   Ulges A, 2008, LECT NOTES COMPUT SC, V5008, P415
   VANGEMERT JC, 2006, INT WORKSH SEM LEARN, P105
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Yang J, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (4TH), VOL II, P80
NR 39
TC 13
Z9 13
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 27
EP 52
DI 10.1007/s11042-010-0584-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400003
DA 2024-07-18
ER

PT J
AU Kostomaj, M
   Boh, B
AF Kostomaj, Mitja
   Boh, Bojana
TI Design and evaluation of user's physical experience in an Ambient
   Interactive Storybook and full body interaction games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Full body interaction games; Ambient interactive storybook;
   User's physical experience; Evaluation
AB The paper presents the design and evaluation of an original Ambient Interactive Storybook (AIS) for children, including its platform, the background story, and 10 full body interactive games. The evaluation, which focused on the user's physical experience and elements important to the designer, has been methodologically derived from the Krofli's and Laban's framework Body, Space, Time and Relationship, and additionally supported by sport science measurements. An experiment with 8 participants playing 10 games for 20 min was conducted and recorded to a digital video. Participants' physical experience was evaluated through the analysis of postures, the quality of the movement, the body parts used in the interaction, the playing area, the direction of movement, direction of gaze, tempo, dynamics and the quantity of motion (QoM). Results of the experiment are discussed in relation and with implications for game design. Conclusions are drawn with the summary of main findings, to better understand the mechanisms and principles involved the design of user's physical activity in full body interactive games for children. The theoretical work of Laban and Krofli proved to be useful for interaction and games design in the transition from desktop to full body interactive games.
C1 [Kostomaj, Mitja] Thames Valley Univ, Fac Arts, London, England.
   [Boh, Bojana] Univ Ljubljana, Fac Nat Sci & Engn, Dept Chem Educ & Informat, Ljubljana, Slovenia.
C3 University of West London; University of Ljubljana
RP Kostomaj, M (corresponding author), Thames Valley Univ, Fac Arts, London, England.
EM mitja@kostomaj.net; bojana.boh@ntf.uni-lj.si
RI Podgornik, Bojana Boh/U-7784-2019
CR *3DV SYST, 2006, HARDW SOFTW 3D CAM 3
   *ACT INGR ARTW, 2007, ER BE DRAG I AM AI A
   [Anonymous], 1996, MAND GEST XTREM GX S
   [Anonymous], INTEL TECHNOL J
   Camurri A, 2003, INT J HUM-COMPUT ST, V59, P213, DOI 10.1016/S1071-5819(03)00050-8
   *DIST U GEN INFOMU, 1997, EYESWEB SOFTW VERS 3
   Ermi F., 2005, Worlds in Play: International Perspectives on Digital Games Research, P15, DOI DOI 10.1080/10641260490479818
   Graves L, 2007, BRIT MED J, V335, P1282, DOI 10.1136/bmj.39415.632951.80
   HAMALAINEN P, 2005, P SIGCHI C HUM FACT, P998
   Hayles N. Katherine, 1999, VIRTUAL BODIES CYBER, P283
   HOLLAND S, 2009, TEI 09 3 INT C TANG, P93
   HOYSNIEMI J, 2004, C INT DES CHILDR BUI, P27
   HOYSNIEMI J, 2005, P 2005 C DES US EXPE, P2
   *INT, 2001, INT PLAY ME2CAM VIRT
   KOSTOMAJ M, 2010, THESIS U LJUBLJANA S
   Kroflic B., 1992, USTVARJANJE SKOZI GI
   KRUEGER MW, 2001, MULTIMEDIA WAGNER VI, P379
   Liu CC, 2006, FOURTH IEEE INTERNATIONAL WORKSHOP ON WIRELESS, MOBILE AND UBIQUITOUS TECHNOLOGY IN EDUCATION, PROCEEDINGS, P171
   Loke L, 2007, PERS UBIQUIT COMPUT, V11, P691, DOI 10.1007/s00779-006-0132-1
   Mitchell A., 2004, The use of computer and video games for learning. A review of the literature
   NHS, 2008, STAT OB PHYS ACT DIE
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   UTTERBACK C, 1999, CAMILLE UTTERBACK IN
NR 23
TC 4
Z9 4
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 499
EP 525
DI 10.1007/s11042-010-0549-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700014
DA 2024-07-18
ER

PT J
AU Stockhammer, T
   Heiles, J
   Lüken, J
AF Stockhammer, Thomas
   Heiles, Juergen
   Lueken, Joachim
TI DVB-IPTV content download services-overview and use cases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; MPEG-2 TS; HDTV; Content download; Push VoD; DVB
AB IPTV services have been widely deployed by network operators around the world over the last years. However, real-time streaming of Linear TV and Video-on-Demand (VoD) offerings, especially in High Definition quality, still puts a high burden on the network and content servers concerning bandwidth, Quality-of-Service, processing performance and scalability if 100.000s of users have to be supported simultaneously. While multicast delivery can cope with some of these problems for Linear TV services, the unicast VoD services cannot take advantage of that and especially the request for on-demand content is expected to substantially grow in the future. With the introduction of Content Download Services (CDSs), operators have the option to provide IPTV services in innovative ways: They can provide high-quality video services to users with limited access bandwidth, offload the streaming request for blockbuster movies at peak times from the VoD servers or provided personalized advertisements for insertion into a live program event in advance to the users end device. The Digital Video Broadcast (DVB) Project has recently finalized its CDS specification within its IPTV specification efforts. DVB CDS supports push and pull delivery models with unicast, multicast and peer-to-peer distribution in order to enable various business models and use cases. In this work we introduce the specified technology and map it to example use cases and business models.
C1 [Stockhammer, Thomas] Nomor Res, Munich, Germany.
   [Lueken, Joachim] Nokia Siemens Networks, Div Res, Munich, Germany.
C3 Nokia Corporation; Siemens AG; Nokia Siemens Networks
RP Stockhammer, T (corresponding author), Nomor Res, Munich, Germany.
EM stockhammer@nomor.de; juergen.heiles@nsn.com; joachim.lueken@nsn.com
RI Stockhammer, Thomas/AAC-8090-2022
OI Stockhammer, Thomas/0000-0003-2917-4234
CR *ATIS, 2006, ATIS0800005
   *BBF, 2007, TR069 BBF
   BBF, 2007, TR135 BBF
   *BBF, 2008, TR106 BBF
   *BBF, 2007, TR140 BBF
   *BBF, 2009, TR157 BBF
   *DVB, 2009, A13X DVB
   *ETSI, 102824 ETSI TS
   *ETSI, 102323 ETSI TS
   ETSI, 10282231 ETSI TS
   *ETSI, 102833 ETSI TS
   *ETSI, 102034V141 ETSI TS
   *ETSI, 102539 ETSI TS
   *ETSI, 102034V131 ETSI TS
   *IETF, 2000, 2818 IETF RFC
   *IETF, 5053 IETF RFC
   IETF, 2616 IETF RFC
   *IETF, 3928 IETF RFC
   *ITU T, 2002, Y1541 ITUT
   Jenkac H, 2006, IEEE NETWORK, V20, P14, DOI 10.1109/MNET.2006.1607891
   LUBY M, 2002, P ACM SIGCOMM 2002 P
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   *W3C, 2000, SIMPL OBJ ACC PROT V
NR 23
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2011
VL 53
IS 3
SI SI
BP 533
EP 555
DI 10.1007/s11042-010-0505-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 758OK
UT WOS:000290174100004
DA 2024-07-18
ER

PT J
AU Viana, W
   Miron, AD
   Moisuc, B
   Gensel, J
   Villanova-Oliver, M
   Martin, H
AF Viana, Windson
   Miron, Alina Dia
   Moisuc, Bogdan
   Gensel, Jerome
   Villanova-Oliver, Marlene
   Martin, Herve
TI Towards the semantic and context-aware management of mobile multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Conference on Advances in Mobile Computing and Multimedia
CY NOV 24-26, 2008
CL Linz, AUSTRIA
SP ACM SIGMM
DE Semantic web; Spatial reasoning; Context awareness; Multimedia
   annotation; Semantic image retrieval; Index expansion
ID ANNOTATION; PHOTOMAP
AB Users of mobile devices can nowadays easily create large quantities of mobile multimedia documents tracing significant events attended, places visited or, simply, moments of their everyday life. However, they face the challenge of organizing these documents in order to facilitate searching through them at a later time and sharing them with other users. We propose using context awareness and semantic technologies in order to improve and facilitate the organization, annotation, retrieval and sharing of personal mobile multimedia documents. Our approach combines metadata extracted and enriched automatically from the users' context with annotations provided manually by the users and with annotations inferred by applying user-defined rules to context features. These new contextual metadata are integrated into the processes of annotation, sharing and keyword-based retrieval.
C1 [Viana, Windson; Miron, Alina Dia; Moisuc, Bogdan; Gensel, Jerome; Villanova-Oliver, Marlene; Martin, Herve] STEAMER Team, LIG, F-38402 St Martin Dheres, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Viana, W (corresponding author), STEAMER Team, LIG, 681 Rue Passerelle, F-38402 St Martin Dheres, France.
EM carvalho@imag.fr; Alina-Dia.Miron@imag.fr; Bogdan.Moisuc@imag.fr;
   Jerome.Gensel@imag.fr; Marlene.Villanova-Oliver@imag.fr;
   Herve.Martin@imag.fr
RI Gensel, Jérôme/G-1026-2015; Trambitas-Miron, Alina Dia/AAC-3960-2019;
   Gensel, Jérôme/AAD-8090-2022; VILLANOVA-OLIVER, Marlène/AAE-9943-2019;
   DE CARVALHO, WINDSON VIANA/E-8998-2015
OI Gensel, Jérôme/0000-0003-1398-7118; DE CARVALHO, WINDSON
   VIANA/0000-0002-8627-0823; Trambitas Miron,
   Alina-Dia/0000-0002-2283-2647
CR Aizawa K., 2004, Pervasive 2004 workshop on memory and sharing experiences, P15
   Aleksy M, 2008, MOB INF SYST, V4, P105, DOI 10.1155/2008/142986
   Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   [Anonymous], P 4 INT WORKSH KNOWL
   BLOEHDORN S, 2005, P 2 EUR SEM WEB
   Buscaldi D., 2006, P 3 SIGIR WORKSH GEO
   Carvalho RF, 2009, MULTIMED TOOLS APPL, V42, P73, DOI 10.1007/s11042-008-0249-5
   Christensen CB, 2001, MIND, V110, P789, DOI 10.1093/mind/110.439.789
   Dey A., 2000, CHI 2000 WORKSHOP WH, P304
   FILHO JB, 2008, P SIGSPATIAL ACM GIS, V8, P30
   Frank AU, 1996, INT J GEOGR INF SYST, V10, P269, DOI 10.1080/026937996138043
   GOYAL RK, 2001, IEEE T KNOW IN PRESS
   Gulliver SR, 2007, MOB INF SYST, V3, P71, DOI 10.1155/2007/975892
   Guo B, 2008, MOB INF SYST, V4, P81, DOI 10.1155/2008/463787
   Hammiche S, 2008, STUD COMPUT INTELL, V116, P351
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Hendler J, 2008, COMPUTER, V41, P106, DOI 10.1109/MC.2008.34
   JONES CB, 2001, LECT NOTES COMPUTER, V2205, P322
   KOOLWAAIJ J., 2006, Context Watcher Sharing context information in everyday life
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   LUX M, 2004, P 19 INT CODATA C IN
   Matellanes A., 2006, P 1 INT WORKSH SEM W
   MIRON AD, 2007, 7 INT S WEB WIR GIS
   MOISUC B, 2005, GEOMATICA, P59
   MONAGHAN F, 2006, P 7 INT C MOB DAT MA, P79, DOI DOI 10.1109/MDM.2006.39
   NAAMAN M, 2004, MULTIMEDIA 04 P 12 A
   OHARE N, 2007, P ACM SAC 2007
   Raento M, 2005, IEEE PERVAS COMPUT, V4, P51, DOI 10.1109/MPRV.2005.29
   RESSLER J, 2007, GEOSPATIAL ONTOLOGY
   RILEY M, 2008, P 9 INT C MUSIC INFO
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Sarvas Risto., 2004, P 2 INT C MOBILE SYS, P36
   SCHROETER R, 2003, P K CAP 2003 WORKSH
   SCHWEER A, 2007, WORKSH SUPP HUM MEM
   Tuffield M., 2006, 1 INT WORKSH SEM WEB
   Uren V, 2006, J WEB SEMANT, V4, P14, DOI 10.1016/j.websem.2005.10.002
   VIANA W, 2004, LECT NOTES COMPUTER, V3124, P1015
   Viana W, 2008, J SYST SOFTWARE, V81, P382, DOI 10.1016/j.jss.2007.04.045
   Viana W, 2007, LECT NOTES COMPUT SC, V4857, P187
   Viana W, 2008, J LOCAT BASED SERV, V2, P211, DOI 10.1080/17489720802487956
   Voorhees EllenM., 1999, Proceedings of the 8th Text Retrieval Conference, P77
   WANG S, P SIGCHI C HUM FACT
   Yamabe T, 2005, 11TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P489, DOI 10.1109/RTCSA.2005.32
NR 43
TC 18
Z9 19
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2011
VL 53
IS 2
BP 391
EP 429
DI 10.1007/s11042-010-0502-6
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 753BS
UT WOS:000289739800004
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Wang, SZ
   Zhang, XP
   Wei, WM
   Zhao, Y
AF Tang, Zhenjun
   Wang, Shuozhong
   Zhang, Xinpeng
   Wei, Weimin
   Zhao, Yan
TI Lexicographical framework for image hashing with implementation based on
   DCT and NMF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image hashing; Lexicographic framework; Image retrieval; Digital rights
   management (DRM); Non-negative matrix factorization (NMF)
ID ROBUST
AB Image hash is a content-based compact representation of an image for applications such as image copy detection, digital watermarking, and image authentication. This paper proposes a lexicographical-structured framework to generate image hashes. The system consists of two parts: dictionary construction and maintenance, and hash generation. The dictionary is a large collection of feature vectors called words, representing characteristics of various image blocks. It is composed of a number of sub-dictionaries, and each sub-dictionary contains many features, the number of which grows as the number of training images increase. The dictionary is used to provide basic building blocks, namely, the words, to form the hash. In the hash generation, blocks of the input image are represented by features associated to the sub-dictionaries. This is achieved by using a similarity metric to find the most similar feature among the selective features of each sub-dictionary. The corresponding features are combined to produce an intermediate hash. The final hash is obtained by encoding the intermediate hash. Under the proposed framework, we have implemented a hashing scheme using discrete cosine transform (DCT) and non-negative matrix factorization (NMF). Experimental results show that the proposed scheme is resistant to normal content-preserving manipulations, and has a very low collision probability.
C1 [Tang, Zhenjun; Wang, Shuozhong; Zhang, Xinpeng; Wei, Weimin; Zhao, Yan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Wang, SZ (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 149 Yanchang Rd, Shanghai 200072, Peoples R China.
EM tangzj230@163.com; shuowang@shu.edu.cn; xzhang@shu.edu.cn;
   wwm@shu.edu.cn; yanzhao@shu.edu.cn
FU Natural Science Foundation of China [60773079, 60872116, 60832010];
   High-Tech Research and Development Program of China [2007AA01Z477];
   Innovative Research Foundation of Shanghai University [shucx080148]
FX This work was supported by the Natural Science Foundation of China
   (60773079, 60872116, and 60832010), the High-Tech Research and
   Development Program of China (2007AA01Z477), and the Innovative Research
   Foundation of Shanghai University for Ph.D. Programs (shucx080148). The
   authors would like to thank the anonymous referees for their valuable
   comments and suggestions.
CR [Anonymous], GROUND TRUTH DATABAS
   [Anonymous], USC SIPI IM DAT
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lefebvre F., 2002, P EUR SIGN PROC C, P299
   Lehmann EL., 2005, TESTING STAT HYPOTHE, P590
   LIN Y, 2001, IEEE T CIRCUITS SYST, V11, P153
   Mao Y, 2007, IEEE T INF FOREN SEC, V2, P462, DOI 10.1109/TIFS.2007.902260
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang ZJ, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P183, DOI 10.1109/MUE.2009.42
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang Shuo-zhong, 2007, Journal of Shanghai University, V11, P323, DOI 10.1007/s11741-007-0401-2
   Wang Shuozhong, 2007, Journal of Shanghai University, V11, P205, DOI 10.1007/s11741-007-0302-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Young D. D., 2005, 41st AIAA/ASME/SEA/ASEE Joint Propulsion Conference and Exhibit, DOI [10.2514/6.2005-4020, DOI 10.2514/6.2005-4020]
NR 19
TC 60
Z9 62
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 325
EP 345
DI 10.1007/s11042-009-0437-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000006
DA 2024-07-18
ER

PT J
AU Sun, SP
   Chou, YJ
   Chiu, YH
AF Sun, Shuh-Ping
   Chou, Yi-Jiun
   Chiu, Yi-Hsin
TI Multimedia 3D clinical planning system for simulation of internal
   fixation surgery for calcaneal collapse
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Multimedia; Computer-aided surgery; Reverse engineering; Calcaneal
   fracture
ID FRACTURES
AB This study presents a multimedia 3D clinical planning system that simulates internal fixation surgery for calcaneal collapse. The system uses full-scale computer-assisted engineering techniques in the designing and development of preoperative planning modules. The planning system not only displays a full-sized 3D image of the calcaneus but also provides detailed interior measurements of the calcaneus from various cutting planes. The multimedia user interface integrates the functions of several different software programs to plan and simulate an operation. These functions include 3D image model capturing, sectioning, translocation, rotation, and measurement of relevant foot anatomy; all these functions can be integrated and used for surgical planning. The system also has an enormous databank that is updatable and expandable. The databank can store numerous clinical cases to meet the needs of diverse medical professionals for future study.
C1 [Sun, Shuh-Ping; Chiu, Yi-Hsin] I Shou Univ, Dept Biomed Engn, Kaohsiung, Taiwan.
   [Chou, Yi-Jiun] Kaohsiung Vet Gen Hosp, Dept Orthoped Surg, Kaohsiung, Taiwan.
C3 I Shou University; Kaohsiung Veterans General Hospital
RP Sun, SP (corresponding author), I Shou Univ, Dept Biomed Engn, Kaohsiung, Taiwan.
EM spsun@isu.edu.tw; m9650002@stmail.isu.edu.tw; inp1889i@gmail.com
CR ASHOKE ST, 1999, IEEE T MED IMAGING, V18, P604
   Bråten M, 2000, INJURY, V31, P311, DOI 10.1016/S0020-1383(99)00299-5
   CAPONETTI L, 1993, IEEE COMPUT GRAPH, V13, P86, DOI 10.1109/38.252561
   Grass M, 1999, COMPUT MED IMAG GRAP, V23, P311, DOI 10.1016/S0895-6111(99)00028-2
   JUPITER JB, 1992, J HAND SURG-AM, V17A, P406, DOI 10.1016/0363-5023(92)90340-U
   Klein M, 2001, INT CONGR SER, V1230, P133
   Messmer P, 2001, Comput Aided Surg, V6, P183, DOI 10.3109/10929080109146082
   Rammelt S, 2004, INJURY, V35, P443, DOI 10.1016/j.injury.2003.10.006
   Santler G, 1998, Comput Aided Surg, V3, P248, DOI 10.1002/(SICI)1097-0150(1998)3:5<248::AID-IGS4>3.3.CO;2-1
   Schepers T, 2009, J FOOT ANKLE SURG, V48, P156, DOI 10.1053/j.jfas.2008.11.006
   Schmerber S, 2001, Comput Aided Surg, V6, P1
   Shuh-Ping Sun, 2004, Biomedical Engineering, Applications Basis Communications, V16, P173
   Stapleton John J, 2009, Clin Podiatr Med Surg, V26, P79, DOI 10.1016/j.cpm.2008.10.003
   Stindel E, 2002, Comput Aided Surg, V7, P156, DOI 10.3109/10929080209146026
   Sun SP, 2008, COMPUT METH PROG BIO, V90, P95, DOI 10.1016/j.cmpb.2007.11.013
   Swanson Scott A, 2008, Foot Ankle Clin, V13, P659, DOI 10.1016/j.fcl.2008.09.006
   Wirth S, 2001, INT CONGR SER, V1230, P408
NR 17
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 5
EP 18
DI 10.1007/s11042-009-0454-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500002
DA 2024-07-18
ER

PT J
AU Zhang, H
   Tian, XA
   Chen, YW
AF Zhang, Hua
   Tian, Xiang
   Chen, Yaowu
TI Video image assessment with a distortion-weighing spatiotemporal visual
   attention model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Visual attention model; Focus of Attention (FOA); Saliency map;
   Spatiotemporal; Distortion
AB For the purpose of extracting attention regions from distorted videos, a distortion-weighing spatiotemporal visual attention model is proposed. On the impact of spatial and temporal saliency maps, visual attention regions are acquired directed in a bottom-up manner. Meanwhile, the blocking artifact saliency map is detected according to intensity gradient features. An attention selection is applied to identify one of visual attention regions with more relatively serious blocking artifact as the Focus of Attention (FOA) directed in a top-down manner. Experimental results show that the proposed model can not only accurately analyze the spatiotemporal saliency based on the intensity, the texture, and the motion features, but also able to estimate the blocking artifact of distortions in comparing with Walther's and You's models.
C1 [Zhang, Hua; Tian, Xiang; Chen, Yaowu] Zhejiang Univ, Inst Adv Digital Technol & Instrumentat, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Tian, XA (corresponding author), Zhejiang Univ, Inst Adv Digital Technol & Instrumentat, Hangzhou 310027, Zhejiang, Peoples R China.
EM emma_zhanghua@zju.edu.cn; xiang.t@163.com; cyw@mail.bme.zju.edu.cn
CR Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Grill-Spector K, 2004, ANNU REV NEUROSCI, V27, P649, DOI 10.1146/annurev.neuro.27.070203.144220
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   MA YF, 2002, P INT C IM PROC, V1, P22
   Niebur E, 1998, ATTENTIVE BRAIN, P163
   Rapantzikos K, 2007, IET IMAGE PROCESS, V1, P237, DOI 10.1049/iet-ipr:20060040
   Serences JT, 2006, TRENDS COGN SCI, V10, P38, DOI 10.1016/j.tics.2005.11.008
   Shih HC, 2009, IEEE T MULTIMEDIA, V11, P244, DOI 10.1109/TMM.2008.2009682
   STEFAN W, 2008, IEEE T BROADCAST, V54, P660
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   You JY, 2007, APPL MATH COMPUT, V185, P963, DOI 10.1016/j.amc.2006.07.023
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
   Zheng Y. Y., 2008, THESIS ZHEJIANG U CH
NR 18
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 221
EP 233
DI 10.1007/s11042-010-0470-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500017
DA 2024-07-18
ER

PT J
AU Zhang, JY
   Chen, QA
   Sun, QS
   Sun, HJ
   Xia, DH
AF Zhang, Jieyu
   Chen, Qiang
   Sun, Quansen
   Sun, Huaijiang
   Xia, Deshen
TI A highly repeatable feature detector: improved Harris-Laplace
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Feature detector; Scale-space; Redundant points; Grouping; Repeatability
ID SCALE
AB A feature detector named improved Harris-Laplace is proposed to obtain higher repeatability than that of original Harris-Laplace. In this novel method, all points detected at each scale are tracked and grouped beginning with the largest scale in the scale-space to make each group represent one local structure firstly. Then the point in each group which simultaneously leads to the maxima of corner points measuring and scale normalization Laplace function is selected. Finally, these points are described and matched by scale invariant feature transform (SIFT) descriptor successfully. Experimental results indicate that the proposed method has higher repeatability than original Harris-Laplace. Meanwhile, the new method was evaluated with image registration. Compared with SIFT, more accurate registration precision of multi-sensor remote sensing images was obtained by the advanced method.
C1 [Zhang, Jieyu; Chen, Qiang; Sun, Quansen; Sun, Huaijiang; Xia, Deshen] Nanjing Univ Sci Technol, Dept Comp Sci Technol, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Zhang, JY (corresponding author), Nanjing Univ Sci Technol, Dept Comp Sci Technol, Nanjing 210094, Peoples R China.
EM zjyscy@gmail.com
RI Yin, Jing/KDO-6274-2024; Chen, Qiang/AAC-3689-2019; chen,
   qiang/HGU-5418-2022; Zhang, Jieyu/AAG-1339-2019; Chen,
   Qiang/GRJ-2224-2022; chen, qiang/GWZ-7308-2022
OI Zhang, Jieyu/0000-0001-7268-7663; Chen, Qiang/0000-0001-8714-6819; 
CR Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   *COL U, COIL 100 IM DAT
   LARIOS N, 2007, IEEE WORKSH APPL COM, P26
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   LINDEBERG T, 1994, J APPL STAT, V21, P223
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   MIAN A, 2006, P INT S VIS COMP LAK, P860
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mikolajczyk K., 2002, THESIS I NATL POLYTE
   Qamra A, 2008, MULTIMED TOOLS APPL, V38, P187, DOI 10.1007/s11042-007-0178-8
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Yu L, 2008, COMPUT GEOSCI-UK, V34, P838, DOI 10.1016/j.cageo.2007.10.005
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 17
TC 13
Z9 16
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 175
EP 186
DI 10.1007/s11042-010-0471-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500014
DA 2024-07-18
ER

PT J
AU Kopf, S
   Haenselmann, T
   Kiess, J
   Guthier, B
   Effelsberg, W
AF Kopf, Stephan
   Haenselmann, Thomas
   Kiess, Johannes
   Guthier, Benjamin
   Effelsberg, Wolfgang
TI Algorithms for video retargeting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retargeting; Video adaptation; Seam carving; Region of interest;
   Contrast-based saliency
ID IMAGE; ADAPTATION; NETWORK; MPEG-21
AB The visualization of high resolution video on small mobile devices is still a great challenge today. Most critical are the limited display resolution and different aspect ratios of handheld mobile devices. So far, there is no retargeting algorithm available that guarantees good results for all videos. We introduce a new video retargeting approach that reduces the resolution while preserving as much of the relevant content as possible. A central component of the system selects the most suitable algorithm to adapt a given shot. We have implemented two retargeting algorithms: a region of interest (ROI) based technique, and a fast implementation of seam carving for size adaptation of videos (FSCAV). The ROI-based retargeting detects important regions like faces, objects, text, and contrast-based saliency regions. A rectangular window within the larger frame is selected that defines the visible area of the target video. If several relevant regions are detected, an artificial camera motion (pan, tilt, or zoom) may change the selected view within a shot. For seam carving, we present two extensions: The first reduces the distortion of straight lines (lines may become curved or disconnected); the second avoids jitter in the target video, limits the large memory requirements and computational effort of seam carving, and makes it applicable to video retargeting. In addition, we present a heuristic that estimates the visual quality of the target video. If the quality drops below a threshold, the ROI-based retargeting is used for this shot. User evaluations confirm a very high visual quality of our approach.
C1 [Kopf, Stephan; Haenselmann, Thomas; Kiess, Johannes; Guthier, Benjamin; Effelsberg, Wolfgang] Univ Mannheim, Dept Comp Sci 4, Mannheim, Germany.
C3 University of Mannheim
RP Kopf, S (corresponding author), Univ Mannheim, Dept Comp Sci 4, Mannheim, Germany.
EM kopf@informatik.uni-mannheim.de; haenselmann@informatik.uni-mannheim.de;
   kiess@informatik.uni-mannheim.de; guthier@informatik.uni-mannheim.de;
   effelsberg@informatik.uni-mannheim.de
OI Kopf, Stephan/0000-0002-1140-6685
FU Deutsche Forschungsgemeinschaft (DFG)
FX The authors acknowledge the financial support granted by the Deutsche
   Forschungsgemeinschaft (DFG). We would like to thank the following
   flickr.com users for providing their images via the creative commons
   license: teoruiz (bridge.jpg), the_tahoe_guy (road.jpg) and digital_cat
   (construction_site.jpg). We thank Instituto Luce for providing
   historical films within the European research project ECHO. Furthermore,
   we would like to thank Sabine Olawsky for the development of the
   contrast-based saliency detection.
CR [Anonymous], P 11 IEEE INT C COMP
   [Anonymous], 2006, ACM SIGCHI
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2007, MM
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bai B., 2005, 13th Annual ACM International Conference on Multimedia, P503, DOI 10.1145/1101149.1101262
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BEEK P, 2003, IEEE SIGNAL PROCESSI, V20, P40
   Bjork N., 2000, Proceedings of the 2000 ACM Workshops on Multimedia, P75
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cardellini V., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P520, DOI 10.1145/354756.354861
   Cheng W.-H., 2005, P INT C COMP GRAPH I, P64
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Curran K., 2005, International Journal of Network Management, V15, P75, DOI 10.1002/nem.545
   DONG W, 2010, J COMPUT SCI TECHNOL, V25
   DONG W, 2008, EUROGRAPHICS 2009, V28
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   FARIN D, 2003, HDB VIDEO DATABASES, V8, P561
   FARIN D, 2005, THESIS TU EINDHOVEN
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fox A, 1998, IEEE PERS COMMUN, V5, P10, DOI 10.1109/98.709365
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Han R, 1998, IEEE PERS COMMUN, V5, P8, DOI 10.1109/98.736473
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Harrison P, 2001, W S C G ' 2001, VOLS I & II, CONFERENCE PROCEEDINGS, P190
   Hjelsvold R., 2001, P 10 INT C WORLD WID, P129, DOI [https://doi.org/10.1145/371920.371969, DOI 10.1145/371920.371969]
   HOSSAIN M, 2004, P CAN C EL COMP ENG, P971
   Hwang DS, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1029, DOI 10.1109/ICME.2008.4607613
   *ISO IEC, 2004, 210001 ISOIEC TR
   *ISO IEC, 2003, N5845 ISOIEC
   *ISO IEC, 2002, 159388 ISOIEC TR
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jong-Woo Han, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P38, DOI 10.1109/ISCE.2009.5156936
   KIESS J, 2010, P IS T SPIE C MULT M, V7542
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Kopf S, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P478, DOI 10.1109/ICME.2005.1521464
   Kopf S, 2005, PROC SPIE, V5682, P114, DOI 10.1117/12.587946
   Kopf S, 2004, PROC SPIE, V5307, P417
   KOPF S, 2009, P IS T SPIE C MULT M, V7256
   KOPF S, 2005, TR05002 U MANNHEIM G
   KOPF S, 2006, P 14 ACM INT C MULT, P957
   Kopf S, 2008, MULTIMEDIA SYST, V14, P369, DOI 10.1007/s00530-008-0135-z
   Kopf Stephan., 2009, MM 09, P321
   KRAHENBUHL P, 2009, ACM SIGGRAPH ASIA, P1
   LEI Z, 2002, P 10 ACM INT C MULT, P127
   Lei ZJ, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P913, DOI 10.1109/CCECE.2001.933563
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li Yun, 2010, Proceedings of the 2010 Second World Congress on Software Engineering (WCSE 2010), P45, DOI 10.1109/WCSE.2010.42
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   LIU F, 2003, P 16 ANN ACM S US IN, P153
   Liu Feng, 2006, P ACM INT C MULT, P241, DOI DOI 10.1145/1180639.1180702
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Mokhtarian F., 2003, COMP IMAG VIS, V25
   NEPAL S, 2003, P 5 ACM SIGMM INT WO, P223
   Noble B.D., 1997, P ACM S OPERATING SY, P276
   NURNETT I, 2003, IEEE MULTIMEDIA, V10, P60
   Obrenovic Z, 2004, IEEE MULTIMEDIA, V11, P62, DOI 10.1109/MMUL.2004.1261109
   Ren TW, 2009, IEEE INT CON MULTI, P406, DOI 10.1109/ICME.2009.5202520
   Richter S, 2001, PROC SPIE, V4315, P608, DOI 10.1117/12.410974
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   SCHABER P, 2010, ACM SIGMM C MULT SYS, P23
   SCHNEIDERMAN H, 2010, FACE DETECTION DEMON
   SCHNEIDERMAN H, 2000, P IEEE INT C COMP VI
   SETLUR V, 2005, P 4 INT C MOB UB MUL, P247
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Steiger O, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P45
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   TAO C, 2007, P WORKSH DYN VIS
   Tseng BL, 2004, IEEE MULTIMEDIA, V11, P42, DOI 10.1109/MMUL.2004.1261105
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Vetro A, 2004, IEEE MULTIMEDIA, V11, P84, DOI 10.1109/MMUL.2004.1261111
   VETRO A, 2003, IEEE SIGNAL PROCESSI, V20, P69
   Wai Yip Lum, 2002, IEEE Pervasive Computing, V1, P41, DOI 10.1109/MPRV.2002.1037721
   Wang J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1711
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang YS, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618473
   Zwicker M, 2002, IEEE T VIS COMPUT GR, V8, P223, DOI 10.1109/TVCG.2002.1021576
NR 87
TC 16
Z9 21
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 819
EP 861
DI 10.1007/s11042-010-0717-6
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300017
DA 2024-07-18
ER

PT J
AU Redi, JA
   Taktak, W
   Dugelay, JL
AF Redi, Judith A.
   Taktak, Wiem
   Dugelay, Jean-Luc
TI Digital image forensics: a booklet for beginners
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Multimedia security; Image tampering detection;
   Image source authentication; Counter-forensics
ID CAMERA IDENTIFICATION; COMPRESSION; FORGERIES; TRACES
AB Digital visual media represent nowadays one of the principal means for communication. Lately, the reliability of digital visual information has been questioned, due to the ease in counterfeiting both its origin and content. Digital image forensics is a brand new research field which aims at validating the authenticity of images by recovering information about their history. Two main problems are addressed: the identification of the imaging device that captured the image, and the detection of traces of forgeries. Nowadays, thanks to the promising results attained by early studies and to the always growing number of applications, digital image forensics represents an appealing investigation domain for many researchers. This survey is designed for scholars and IT professionals approaching this field, reviewing existing tools and providing a view on the past, the present and the future of digital image forensics.
C1 [Redi, Judith A.; Taktak, Wiem; Dugelay, Jean-Luc] Eurecom, Sophia Antipolis, France.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Redi, JA (corresponding author), Delft Univ Technol, Dept Mediamat, Mekelweg 4, NL-2628 CD Delft, Netherlands.
EM Judith-Alice.Redi@eurecom.fr; Wiem.Taktak@eurecom.fr;
   Jean-Luc.Dugelay@eurecom.fr
RI DUGELAY, Jean-Luc/ABE-7096-2021
OI DUGELAY, jean-luc/0000-0003-3151-4330
CR Adams J, 1998, IEEE MICRO, V18, P20, DOI 10.1109/40.743681
   Amerini I, 2010, P IEEE ICASSP
   [Anonymous], 1999, AIM1657 MIT
   [Anonymous], IEEE INT S CIRC SYST
   [Anonymous], IEEE PAC AS WORKSH C
   [Anonymous], THESIS DARTMOUTH COL
   [Anonymous], 9 INT WORKSH INF HID
   [Anonymous], 2006, WORKSH MULT SEC
   [Anonymous], SPIE ELECT IMAGING S
   [Anonymous], 2004, DATA SET AUTHENTIC S
   Avcibas, 2004, P IEEE ICIP
   AVCIBAS I, 2003, IEEE T IMAGE PROCESS
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   BAYRAM S, 2006, P WG 11 9 INT C DIG
   Bayram S, 2005, P ICIP, V3, pIII
   Bayram S., 2009, P IEEE ICASSP
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bohme R, 2009, LNCS
   Bregler C, 1997, COMP GRAPH P ANN C S
   Calphoto, 2000, DAT PHOT PLANTS AN H
   Cao H, 2009, IEEE T INF FORENSICS, V4
   CELIKTUTAN O, 2005, P ADCOM
   Chen C, 2008, P IEEE ICPR
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen M, 2007, PROC SPIE, V6505, DOI 10.1117/12.703370
   CHEN W, 2007, SPIE ELECT IMAGING S
   Choi K-S, 2006, P SPIE
   Cox I. J., 2002, Digital Watermarking
   De Rosa A, 2010, P SPIE
   Delp EJ, 2009, P SPIE INT C SEC
   DEVERNAY F, 1995, P SOC PHOTO-OPT INS, V2567, P62, DOI 10.1117/12.218487
   DIRIK AE, 2009, ICIP 09, P429
   Dybala B., 2007, P 9 WORKSH MULT SEC
   Farid H., 2006, Digital image ballistics from JPEG quantization
   Farid H., 2006, Significance, V3, P162, DOI [DOI 10.1111/J.1740-9713.2006.00197.X, 10.1111/j.1740-9713.2006.00197.x]
   Farid H., 2009, IEEE T INFORM FORENS
   Farid H., 2006, P 8 WORKSHOP MULTIME, P29
   FENG X, 2010, SPIE C MED FOR SEC
   Fillion C, 2010, PROC SPIE, V7541, DOI 10.1117/12.838647
   Fridrich A.J., 2003, P DIGITAL FORENSIC R
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   Geradts ZJ, 2000, PROC SPIE, V4232, P505, DOI 10.1117/12.417569
   Gloe T., 2010, The dresden image database for benchmarking digital image forensics
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Gloe Thomas, 2010, SPIE C MED FOR SEC
   Goljan M, 2010, P SPIE ELECT IMAGING, p0S
   Goljan M, 2008, PROC SPIE, V6819, DOI 10.1117/12.766732
   Harris R, 2006, DIGIT INVESTIG, pS44, DOI 10.1016/j.diin.2006.06.005
   Holst G.C., 1998, CCD ARRAYS CAMERAS D
   JOHNSON M.K., 2005, P ACM MULT SEC WORKS
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Katzenbeisser S, 1999, INFORM HIDING TECHNI, P240
   Kee E., 2010, SPIE S EL IM SAN JOS
   Kharrazi M., 2004, P ICIP 04, P24
   Kirchner M., 2010, P SPIE ELECT IMAGING
   Kirchner M., 2009, P SPIE IS T ELECT IM, V7254
   Kirchner M, 2009, IEEE INT WORKS INFOR, P21, DOI 10.1109/WIFS.2009.5386489
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Langille A, 2006, P CRV
   LI CT, 2010, IEEE T INF FORENSICS, V5
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Lin Z., 2009, PATTERN RECOGNITION
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Lukás J, 2006, PROC SPIE, V6072, DOI 10.1117/12.640109
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lukas Jan., 2003, P DFRWS
   Luo W, 2010, IEEE T INFORM FORENS
   LYU S, 2002, P INF HID WORKSH
   Mahdian B, 2010, IEEE AERO EL SYS MAG, V25, P18, DOI 10.1109/MAES.2010.5467652
   Nataraj L, 2010, P SPIE ELECT IMAGING
   Neelamani R, 2006, IEEE T IMAGE PROCESS, V15, P1365, DOI 10.1109/TIP.2005.864171
   Pan X., 2010, P IEEE ICASSP
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Popescu C., 2004, TR2004515 DARTM COLL
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Rubinstein M., 2008, SIGGRAPH
   Sarkar A., 2009, P 11 ACM WORKSH MULT
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Stamm M, 2010, IEEE T INF FOREN SEC, V5, P99
   Stamm M.C., 2010, IEEE INT C IM PROC I
   Stamm MC, 2010, P IEEE INT C AC SPEE
   TSAI MJ, 2006, INT CONF ACOUST SPEE, pA297
   Van LT, 2007, P IEEE INT WORKSH MU
   Wang J, 2009, P ICME
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Wu Q, 2008, MAC LEARN CYB INT C, V3
   Zhang W, 2009, IEEE INT CON MULTI, P1042, DOI 10.1109/ICME.2009.5202676
NR 91
TC 203
Z9 215
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 133
EP 162
DI 10.1007/s11042-010-0620-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800006
OA hybrid
DA 2024-07-18
ER

PT J
AU Sandhaus, P
   Boll, S
AF Sandhaus, Philipp
   Boll, Susanne
TI Semantic analysis and retrieval in personal and social photo collections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal photos; Social photo collections; Semantic image retrieval;
   Survey
ID IMAGE RETRIEVAL; WEB; CLASSIFICATION; AESTHETICS; PICTURES; MEMORY;
   QUERY
AB Semantic understanding of images has been an important topic in the research community for a long time as it is an important prerequisite to build meaningful retrieval systems which are accessible by both users and automatic reasoning algorithms. Recently, especially with the growing trend to share photos online, the social aspect of image retrieval becomes more and more prevalent and image retrieval more and more focusses specifically on photos and their special characteristics, especially on information outside the image itself. Researchers are starting to explore how and why photos are shot, shared and used and try to incorporate this additional knowledge to aid image analysis and retrieval. Several survey papers have been written in the past reviewing works in the general field of image analysis and retrieval. However, the social aspect of image retrieval and the focus on digital photos has not sufficiently been addressed in these works. In this article we give an overview over the current research field of semantic photo understanding, annotation and retrieval. We review over 160 contributions in the field and identify trending topics and implications for future directions of research.
C1 [Sandhaus, Philipp] OFFIS Inst Informat Technol, Oldenburg, Germany.
   [Boll, Susanne] Carl von Ossietzky Univ Oldenburg, Dept Comp Sci Multimedia & Internet Technol, D-2900 Oldenburg, Germany.
C3 Carl von Ossietzky Universitat Oldenburg
RP Sandhaus, P (corresponding author), OFFIS Inst Informat Technol, Escherweg 2, Oldenburg, Germany.
EM sandhaus@offis.de; susanne.boll@uni-oldenburg.de
OI Sandhaus, Philipp/0000-0002-9250-1704
CR *ACM, 2010, MULT GRAND CHALL
   *ADOB, 2005, XMP SPEC
   AIGRAIN P, 1996, REPRESENTATION RETRI, P3
   Ames M, 2010, PERS UBIQUIT COMPUT, V14, P95, DOI 10.1007/s00779-009-0237-4
   ANGUERA X, 2008, MIR 08, DOI DOI 10.1145/1460096.1460127
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], P 1 INT WORKSH WEB D
   [Anonymous], 2002, CSCW '02, DOI DOI 10.1145/587078.587102
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], MSRTR200217
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   Ardizzone E, 2008, IEEE IMAGE PROC, P85, DOI 10.1109/ICIP.2008.4711697
   ARNI T, 2008, CREATING TEST COLLEC
   ASLANDOGAN YA, 2000, P 8 ACM INT C MULT 2, P481
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Banerjee S, 2004, PROC SPIE, V5301, P364, DOI 10.1117/12.526997
   Bentley F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P667
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bloehdorn S, 2005, LECT NOTES COMPUT SC, V3532, P592
   Boutell M, 2005, PATTERN RECOGN, V38, P935, DOI 10.1016/j.patcog.2004.11.013
   Boutell M, 2004, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2004.1333918
   BOUTELL M, 2004, CVPR
   BOUTELL M, 2006, 894 U ROCH
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   BRYANT RE, 2007, CMUCS07128
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   Cao L., 2008, Proc. ACM Multimedia, P121
   Chalfen Richard., 1987, SNAPSHOT VERSIONS LI
   CHANDRAMOULI K, 2010, MIR 10, P507, DOI DOI 10.1145/1743384.1743472
   CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519, DOI 10.1109/TSE.1980.230801
   Chen CF, 2006, LECT NOTES COMPUT SC, V3936, P362
   Chianese A, 2004, MULTIMED TOOLS APPL, V23, P237, DOI 10.1023/B:MTAP.0000031759.22145.5d
   Chu Cheng-Tao, 2007, ADV NEURAL INFORM PR, P281, DOI DOI 10.1234/12345678
   *COM INT TEL PRESS, 1999, IPTC NAA INF INT MOD
   Cooper M, 2005, ACM T MULTIM COMPUT, V1
   Crabtree A., 2004, Computer Supported Cooperative Work Conference Proceedings, P396, DOI 10.1145/1031607.1031673
   CUSANO C, 2003, SOC PHOTOOPTICAL INS, P330
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   DATTA R, 2007, P ACM MULT C
   DATTA R, 2007, ACM COMPUTING SURVEY
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   *DIG IM GROUP, 2001, DIG35 SPEC MET DIG I
   Duygulu P., 2006, COMPUTER VISIONECCV, V2002, P349
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   ESKICIOGLU A, 2000, IEEE INT C AC SPEECH, V4
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fan X., 2005, P 7 ACM SIGMM INT WO, P143
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Frank Nack, 2002, SYNTAX MULTIMEDIA SE
   Frankel C., 1996, Webseer: An image search engine for the world wide web
   FROHLICH D, 2008, P CHI WORKSH COLL SO
   GARGI U, 2002, MANAGING SEARCHING P
   GIRGENSOHN A, 2003, INTERACT
   Girgensohn Andreas., 2004, MIR 04, P99
   GONG Z, 2005, P 4 INT C ONT DAT AP
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   GURRIN C, 2005, MOBILEHCI, P311, DOI DOI 10.1145/1085777.1085842
   HALASCHEKWIENER C, 2005, INT WORKSH KNOWL MAR
   HARDMAN L, 2005, ACM WORKSH MULT HUM
   HARE J, 2006, 3 EUR SEM WEB C
   Hare JS., 2008, Proceedings of the 2008 International Conference on Content-Based Image and Video Retrieval, P359
   HARE JS, 2007, ACM CIVR 2007
   He XF, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230816
   Hollink L., 2003, KNOWLEDGE CAPTURE, P41
   HUNTER J, 2001, INT SEM WEB WORK S S
   Inoue Masashi, 2009, Progress in Informatics, P3, DOI 10.2201/NiiPi.2009.6.2
   JAFFE A, 2006, GENERATING SUMMARIES, P853, DOI DOI 10.1145/1135777.1135911
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   JIA J, 2008, MM 08, P459, DOI DOI 10.1145/1459359.1459421
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   Kirk D. S., 2006, Conference on Human Factors in Computing Systems. CHI2006, P761
   KU W, 2007, INT WORKSH ADV IM TE
   Lacerda YA, 2008, IEEE INT SYM MULTIM, P258, DOI 10.1109/ISM.2008.81
   LAFON Y, 2002, DESCRIBING RETRIEVIN
   Lavrenko V., 2004, Advances in Neural Information Processing Systems, V16
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lew MS, 2000, COMPUTER, V33, P46, DOI 10.1109/2.881694
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li X, 2002, IEEE IMAGE PROC, P449
   Lindley S.E., 2008, CHI '08 Extended Abstracts on Human Factors in Computing Systems (Florence, Italy, April 05-10, P3921, DOI [10.1145/1358628.1358957, DOI 10.1145/1358628.1358957]
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   Loui AC, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1125, DOI 10.1109/ICME.2000.871558
   LU G, 1999, P AUSWEB99 LISM AUST
   Luo JB, 2006, IEEE SIGNAL PROC MAG, V23, P101
   LUX M, 2009, MM 09, P925, DOI DOI 10.1145/1631272.1631456
   LUX M, 2008, MM 08, P1085, DOI DOI 10.1145/1459359.1459577
   Maekawa Takuya, 2006, P 15 INT C WORLD WID, P43, DOI [10.1145/1135777.1135789, DOI 10.1145/1135777.1135789]
   MANSOOR AB, 2009, SCIA 09, P91, DOI DOI 10.1007/978-3-642-02230-2_10
   MARCHANDMAILLET S, 2005, BENCHATHLON NETWORK
   MARCHANDMAILLET S, 2006, MIR 06, P297, DOI DOI 10.1145/1178677.1178718
   Mei T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1757, DOI 10.1109/ICME.2006.262891
   *MET WORK GROUP, 2009, GUID HANDL IM MET VE
   Miller AD, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P347
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MONAGHAN F, 2006, P 7 INT C MOB DAT MA, P79, DOI DOI 10.1109/MDM.2006.39
   Monaghan F, 2007, LECT NOTES COMPUT SC, V4816, P252
   Mori Y., 1999, MISRM
   MULHEM P, 2003, LNCS, P321
   Müller H, 2003, MULTIMED TOOLS APPL, V21, P55, DOI 10.1023/A:1025034215859
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   MULLER H, 2002, CIVR, P38
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   NAAMAN M, 2004, 200426 STANF INFOLAB
   NAIR R, 2005, MULTIMEDIA 05, P223, DOI DOI 10.1145/1101149.1101187
   Negoescu R.A., 2008, Proc. Content-based Image and Video Retrieval, P417, DOI DOI 10.1145/1386352.1386406
   NOV O, 2009, 3 INT C WEBL SOC MED
   Obrador P., 2009, PROC 1 ACM SIGMM WOR, P65
   OHARE N, 2005, P 13 ANN ACM INT C M, P261, DOI DOI 10.1145/1101149.1101196
   Oliva A, 2002, LECT NOTES COMPUT SC, V2525, P263
   ON AV, 2002, EXCHANGEABLE IMAGE F
   ORTEGABINDERBER.M, 2000, WEBMARS MULTIMEDIA S
   Penta A, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P74, DOI 10.1109/DEXA.2007.83
   Petersen T., 1994, ART ARCHITECTURE THE
   PIGEAU A, 2005, MULTIMEDIA 05, P141, DOI DOI 10.1145/1101149.1101170
   Pigeau A, 2010, MULTIMED TOOLS APPL, V46, P289, DOI 10.1007/s11042-009-0373-x
   Platt JC, 2000, AUTOALBUM CLUSTERING
   Ren Kan., 2009, MM'09: Proceedings of the seventeen ACM international conference on Multimedia, P757
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   SANDHAUS P, 2009, P 1 SIGMM WORKSH SOC
   SANDHAUS P, 2008, MS 08, P56, DOI DOI 10.1145/1460676.1460688
   Sandhaus P, 2008, MULTIMEDIA SYST, V14, P351, DOI 10.1007/s00530-008-0136-y
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   SCHERP A, 2007, MS 07, P3, DOI DOI 10.1145/1290067.1290069
   SCHERP A, 2006, 4 SPEC WORKSH MULT S
   Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   SHIRAHATTI NV, 2005, COMP SOC C COMP VIS, V1, P955, DOI DOI 10.1109/CVPR.2005.147
   SINHA P, 2008, ICSC 08, P58, DOI DOI 10.1109/ICSC.2008.87
   Sinha Pinaki., 2008, P 2008 INT C CONTENT, P309
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   TAN T, 2002, MULTIMEDIA 02, P87, DOI DOI 10.1145/641007.641025
   Tong HG, 2004, LECT NOTES COMPUT SC, V3331, P198
   TRONCY R, 2007, IMAGE ANNOTATION SEM
   TRUST G, 2000, UNION LIST ARTISTS N
   TSYMBALENKO Y, 2001, P INT COMP 2001 LAS, V2, P842
   TUFFIELD MM, 2006, INT WORKSH SEM WEB A
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VAILAYA A, 1999, MSUCPS999 MICH STAT
   Van House N., 2005, CHI 05, P1853, DOI DOI 10.1145/1056808.1057039
   VANHOUSE N, 2005, WORKING PAPERS U CAL, V3
   Viana W, 2007, LECT NOTES COMPUT SC, V4857, P187
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WAAL H, 1985, ICONCLASS ICONOGRAPH
   WAGENAAR WA, 1986, COGNITIVE PSYCHOL, V18, P225, DOI 10.1016/0010-0285(86)90013-7
   Wang YM, 2004, COMPUT VIS IMAGE UND, V93, P328, DOI 10.1016/j.cviu.2003.10.006
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wenyin Liu., 2000, MULTIMEDIA'00: Proceedings of the eighth ACM International Conference on Multimedia, Marina del Rey, California, United States, P479, DOI DOI 10.1145/354384.379011
   WU DTP, 2009, P MM 09, P709
   Yan R., 2009, P 1 ACM WORKSHOP LAR, P35, DOI DOI 10.1145/1631058.1631067
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507
   You J., 2009, Proceedings of the 17th ACM International Conference on Multimedia (ACM MM), P561
   Zagoris K, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P154, DOI 10.1109/SISAP.2009.15
   ZHANG T, 2010, CONSUMER IMAGE RETRI
   Zhao J, 2008, LECT NOTES COMPUT SC, V5021, P154
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu CY, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P277
   2005, 3 SPEC WORKSH MULT S
NR 166
TC 11
Z9 13
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 5
EP 33
DI 10.1007/s11042-010-0673-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800002
DA 2024-07-18
ER

PT J
AU Schwartz, M
   Hash, C
   Liebrock, LM
AF Schwartz, Moses
   Hash, Curtis
   Liebrock, Lorie M.
TI Term distribution visualizations with Focus plus Context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Term distribution; Visualization; Focus plus Context; Information
   retrieval; User study
AB Many text searches are meant to identify one particular fact or one particular section of a document. Unfortunately, predominant search paradigms focus mostly on identifying relevant documents and leave the burden of within-document searching on the user. This research explores term distribution visualizations as a means to more clearly identify both the relevance of documents and the location of specific information within them. We present a set of term distribution visualizations, introduce a Focus+Context model for within-document search and navigation, and describe the design and results of a 34-subject user study. This user study shows that these visualizations-with the exception of the grey scale histogram variant-are comparable in usability to our Grep interface. This is impressive given the substantial experience of our users with Grep functionality. Overall, we conclude that user do not find this visualization model difficult to use and understand.
C1 [Schwartz, Moses; Hash, Curtis; Liebrock, Lorie M.] New Mexico Inst Min & Technol, Dept Comp Sci & Engn, Socorro, NM 87801 USA.
   [Schwartz, Moses] Sandia Natl Labs, Albuquerque, NM 87185 USA.
C3 New Mexico Institute of Mining Technology; United States Department of
   Energy (DOE); Sandia National Laboratories
RP Schwartz, M (corresponding author), New Mexico Inst Min & Technol, Dept Comp Sci & Engn, Socorro, NM 87801 USA.
EM moses@nmt.edu; curt.hash@gmail.com; liebrock@nmt.edu
FU NSF [0313885]; Sandia National Laboratories; Division Of Undergraduate
   Education; Direct For Education and Human Resources [0313885] Funding
   Source: National Science Foundation
FX This work was supported in part by NSF Grant #0313885 and Sandia
   National Laboratories.
CR Baeza-Yates R., 1999, Modern information retrieval
   Byrd D., 1999, Digital 99 Libraries. Fourth ACM Conference on Digital Libraries, P122, DOI 10.1145/313238.313283
   Carroll L., 1991, Through the Looking Glass
   Eick S. C., 1992, IEEE Transactions on Software Engineering, V18, P957, DOI 10.1109/32.177365
   FANG S, 2006, SAC 06, P240
   Hagh-Shenas H, 2007, IEEE T VIS COMPUT GR, V13, P1270, DOI 10.1109/TVCG.2007.70623
   Harper D. J., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P76, DOI 10.1145/544220.544234
   Harper DJ, 2004, INFORM RETRIEVAL, V7, P265, DOI 10.1023/B:INRT.0000011207.45988.bb
   Hauglid JO, 2008, MULTIMED TOOLS APPL, V40, P183, DOI 10.1007/s11042-008-0204-5
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   HEARST MA, 1995, CHI 95, P59
   Jerding DF, 1998, IEEE T VIS COMPUT GR, V4, P257, DOI 10.1109/2945.722299
   MANN TM, 1999, DEXA WORKSH, P264
   MANN TM, 1999, P IEEE S INF VIS INF, P59
   Mao Y, 2007, IEEE T VIS COMPUT GR, V13, P1208, DOI 10.1109/TVCG.2007.70592
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   SCHWARTZ M, 2009, SAC 09, P1792
   Schwartz M, 2008, LECT NOTES COMPUT SC, V5210, P36, DOI 10.1007/978-3-540-85933-8_4
   WHITTAKER S, 1999, RES DEV INFORM RETRI, P26
   Wong PC, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P105, DOI 10.1109/INFVIS.2000.885097
   Zhang J., 2007, Visualization for Information Retrieval
NR 21
TC 4
Z9 4
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 509
EP 532
DI 10.1007/s11042-010-0479-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ascenso, J
   Brites, C
   Pereira, F
AF Ascenso, Joao
   Brites, Catarina
   Pereira, Fernando
TI A flexible side information generation framework for distributed video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Wyner-Ziv video coding; Side information;
   Intra coding mode; Quality enhancement
ID EFFICIENT; DECODER
AB One of the most efficient approaches to generate the side information (SI) in distributed video codecs is through motion compensated frame interpolation where the current frame is estimated based on past and future reference frames. However, this approach leads to significant spatial and temporal variations in the correlation noise between the source at the encoder and the SI at the decoder. In such scenario, it would be useful to design an architecture where the SI can be more robustly generated at the block level, avoiding the creation of SI frame regions with lower correlation, largely responsible for some coding efficiency losses. In this paper, a flexible framework to generate SI at the block level in two modes is presented: while the first mode corresponds to a motion compensated interpolation (MCI) technique, the second mode corresponds to a motion compensated quality enhancement (MCQE) technique where a low quality Intra block sent by the encoder is used to generate the SI by doing motion estimation with the help of the reference frames. The novel MCQE mode can be overall advantageous from the rate-distortion point of view, even if some rate has to be invested in the low quality Intra coding blocks, for blocks where the MCI produces SI with lower correlation. The overall solution is evaluated in terms of RD performance with improvements up to 2 dB, especially for high motion video sequences and long Group of Pictures (GOP) sizes.
C1 [Ascenso, Joao] Inst Super Engn Lisboa, Inst Telecomunicacoes, P-1950062 Lisbon, Portugal.
   [Brites, Catarina; Pereira, Fernando] Univ Tecn Lisboa, Inst Telecomunicacoes, Inst Super Tecn, P-1049001 Lisbon, Portugal.
C3 Polytechnic Institute of Lisbon; Instituto de Telecomunicacoes;
   Instituto de Telecomunicacoes; Universidade de Lisboa
RP Ascenso, J (corresponding author), Inst Super Engn Lisboa, Inst Telecomunicacoes, Rua Conselheiro Emidio Navarro 1, P-1950062 Lisbon, Portugal.
EM joao.ascenso@lx.it.pt; catarina.brites@lx.it.pt; fp@lx.it.pt
RI Pereira, Fernando/HNR-7786-2023; Pereira, Fernando/K-4046-2012; Brites,
   Catarina/L-6191-2013; Ascenso, Joao/B-9024-2008
OI Brites, Catarina/0000-0002-6011-4574; Ascenso, Joao/0000-0001-9902-5926;
   Bernardo Pereira, Fernando Manuel/0000-0001-6100-947X
CR Aaron A, 2004, WYNER ZIV VIDEO CODI
   AARON A, 2004, SPIE VISUAL COMMUNIC
   [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 2005, PROC 5 EURASIP C SPE
   ARTIGAS X, 2007, DISCOVER COD ARCH TE
   ASCENSO J, 2006, CONTENT ADAPTIVE WYN
   ASCENSO J, 2005, IEEE INT C ADV VID S
   Ascenso J, 2008, J VIS COMMUN IMAGE R, V19, P600, DOI 10.1016/j.jvcir.2008.06.001
   BRITES C, 2006, IMPROVING TRANSFORM
   BRITES C, 2005, THESIS TECHNICAL U L
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   CLERCKX T, 2007, DISTRIBUTED VIDEO CO
   Kubasov D., 2007, IEEE INT WORKSH MULT
   LIU L, 2008, LOW COMPLEXITY ITERA
   Martinian E., 2006, IEEE MULT SIGN PROC
   MUKHERJEE D, 2007, SPIE VISUAL COMMUNIC
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Song BC, 2004, ELECTRON LETT, V40, P802, DOI 10.1049/el:20040550
   TAGLIASACCHI M, 2006, INTRA MODE DECISION
   TRAPANESE A, 2005, INT WORKSH VER LOW B
   TSAI DC, 2007, DYNAMIC KEY BLOCK DE
   TSENG IH, 2005, AS C SIGN SYST COMP
   Turaga DS, 2005, SIGNAL PROCESS-IMAGE, V20, P1, DOI 10.1016/j.image.2004.08.006
   VARODAYAN D, 2008, EURASIP SIGNAL PROCE, V23, P369
   Vo DT, 2008, IEEE T CIRC SYST VID, V18, P609, DOI 10.1109/TCSVT.2008.918807
   WANG H, EURASIP J APPL SIGNA
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
NR 30
TC 25
Z9 28
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2010
VL 48
IS 3
SI SI
BP 381
EP 409
DI 10.1007/s11042-009-0316-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 587VP
UT WOS:000277023100003
DA 2024-07-18
ER

PT J
AU Khirallah, C
   Stankovic, V
   Stankovic, L
   Cheng, S
AF Khirallah, Chadi
   Stankovic, Vladimir
   Stankovic, Lina
   Cheng, Samuel
TI Multiterminal source coding for multiview images under wireless fading
   channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiview image coding; Distributed source coding; Slepian-Wolf coding;
   Spread spectrum; Complete complementary sequences
ID CODE DESIGN; INFORMATION; DECODER; SYSTEMS
AB This paper addresses the problem of wireless transmission of a captured scene from multiple cameras, which do not communicate among each other, to a joint decoder. Correlation among different camera views calls for distributed source coding for efficient multiview image compression. The fact that cameras are placed within a short range of each other results in a high level of interference, multipath fading, and noise effects during communications. We develop a novel two-camera system, that employs multiterminal source coding and complete complementary data spreading, so that while the former technique exploits the statistical correlation between camera views, and performs joint compression to reduce transmission rates, the spreading technique will protect transmitted data by mitigating the effects of wireless fading channels. Our results indicate that the proposed system is competitive when compared to two independently JPEG encoded streams at low to medium transmission rates.
C1 [Khirallah, Chadi; Stankovic, Vladimir; Stankovic, Lina] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland.
   [Cheng, Samuel] Univ Oklahoma, Sch Elect & Comp Engn, Schusterman Ctr, Tulsa, OK 74135 USA.
C3 University of Strathclyde; University of Oklahoma System; University of
   Oklahoma - Tulsa
RP Khirallah, C (corresponding author), Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland.
EM chadi.khirallah@eee.strath.ac.uk; vladimir.stankovic@eee.strath.ac.uk;
   lina.stankovic@eee.strath.ac.uk; samuel.cheng@ou.edu
RI ; Stankovic, Vladimir/L-6584-2016
OI Stankovic, Lina/0000-0002-8112-1976; Cheng, Samuel/0000-0002-5439-1137;
   Stankovic, Vladimir/0000-0002-1075-2420
FU EPSRC Research [EP/E021964/1]; EPSRC [EP/E021964/1, EP/E021964/2]
   Funding Source: UKRI
FX This work is supported by EPSRC Research Grant EP/E021964/1.
CR [Anonymous], 1977, INFORM THEORY APPROA
   BODDEN E, 200705 MCGILL U SABL
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   Chen H.-W., 2006, NEXT GENERATION WIRE
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   Khirallah C, 2006, IEE P-COMMUN, V153, P533, DOI 10.1049/ip-com:20050404
   Oohama Y, 2005, IEEE T INFORM THEORY, V51, P2577, DOI 10.1109/TIT.2005.850110
   OUARET M, 2007, EUR C SIGN PROC EUSI
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Stankovic V, 2006, IEEE T INFORM THEORY, V52, P1495, DOI 10.1109/TIT.2006.871046
   TAGLIASACCHI M, 2007, P ICIP 2007 IEEE INT
   VARODAYAN D, 2007, P IEEE DAT COMPR C D
   Wagner AB, 2008, IEEE T INFORM THEORY, V54, P1938, DOI 10.1109/TIT.2008.920343
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yang Y, 2008, IEEE T INFORM THEORY, V54, P2278, DOI 10.1109/TIT.2008.920204
   Yang Y, 2009, IEEE T IMAGE PROCESS, V18, P534, DOI 10.1109/TIP.2008.2010148
NR 17
TC 3
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2010
VL 48
IS 3
SI SI
BP 457
EP 470
DI 10.1007/s11042-009-0313-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 587VP
UT WOS:000277023100006
DA 2024-07-18
ER

PT J
AU Misra, S
   Mohanta, D
AF Misra, Sudip
   Mohanta, Debashish
TI Adaptive listen for energy-efficient medium access control in wireless
   sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; Medium access control; Network lifetime;
   Throughput; Latency; Slot-time; Cycle-time; Duty-cycle
ID ROUTING PROTOCOL; SCHEME
C1 [Misra, Sudip; Mohanta, Debashish] Indian Inst Technol, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
   [Mohanta, Debashish] Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Misra, S (corresponding author), Indian Inst Technol, Sch Informat Technol, Kharagpur 721302, W Bengal, India.
EM smisra@sit.iitkgp.ernet.in
RI Misra, Sudip/K-6236-2019
OI Misra, Sudip/0000-0002-2467-6414
FU Department of Science & Technology, Government of India
   [SR/FTP/ETA-36/08]
FX The work of the first author was partly supported by a grant from the
   Department of Science & Technology, Government of India, Grant No.
   SR/FTP/ETA-36/08, which the author gratefully acknowledges.
CR Ai J, 2004, IEEE SYMP COMP COMMU, P214
   Ali M, 2005, IEEE IPCCC, P401
   [Anonymous], NS2 SIMULATOR
   [Anonymous], P 42 ANN SE REG C HU
   [Anonymous], 1997, 802111997 IEEE COMP
   [Anonymous], NEURAL NETWORKS FUZZ
   [Anonymous], 2005, FUZZY LOGIC ENG APPL
   Bennett F, 1997, IEEE PERS COMMUN, V4, P8, DOI 10.1109/98.626977
   Bharghavan V., 1994, Computer Communication Review, V24, P212, DOI 10.1145/190809.190334
   CHANDRASEKAR R, 2008, T SOC MODEL SIMUL I, V84, P131
   Chatterjea S, 2004, Proceedings of the 2004 Intelligent Sensors, Sensor Networks & Information Processing Conference, P381
   Dam T., 2003, the 1st International Conference on Embedded Networked Sensor Systems, P171, DOI DOI 10.1145/958491.958512
   Dhurandher SK, 2008, SIMUL-T SOC MOD SIM, V84, P327, DOI 10.1177/0037549708096606
   Dhurandher SK, 2009, SECUR COMMUN NETW, V2, P215, DOI 10.1002/sec.75
   Dhurandher SK, 2009, INT J COMMUN SYST, V22, P789, DOI 10.1002/dac.991
   DHURANDHER SK, 2009, P 7 ACS IEEE INT C C
   DHURANDHER SK, IEEE WIRELE IN PRESS
   DHURANDHER SK, IET COMMUNICATIONS J, V3, P830
   ELHOIYDI A, 2004, P INT WORKSH ALG ASP, P251
   Gupta I, 2005, PROCEEDINGS OF THE 3RD ANNUAL COMMUNICATION NETWORKS AND SERVICES RESEARCH CONFERENCE, P255
   Jurdak R, 2004, IEEE COMMUN SURV TUT, V6, P2, DOI 10.1109/COMST.2004.5342231
   Kredo K, 2007, COMPUT NETW, V51, P961, DOI 10.1016/j.comnet.2006.06.012
   LI G, GUIDE WIRELESS SENSO, pCH36
   Lin P, 2004, IEEE WCNC, P1534, DOI 10.1109/WCNC.2004.1311671
   Mahlknecht S, 2004, WFCS 2004: IEEE INTERNATIONAL WORKSHOP ON FACTORY COMMUNICATION SYSTEMS, PROCEEDINGS, P73
   Misra S, 2009, SECUR COMMUN NETW, V2, P105, DOI 10.1002/sec.74
   Misra S, 2009, IEEE J SEL AREA COMM, V27, P466, DOI 10.1109/JSAC.2009.090510
   Raghavendra C., 1998, ACM SIGCOMM COMP COM, V28, P5
   Rajendran V., 2003, Proceedings of IEEE International Conference on Embedded Networked Sensor Systems (Sensys), Los Angeles, CA, P181
   Ramachandran C, 2008, INT J COMMUN SYST, V21, P1047, DOI 10.1002/dac.937
   Ren Q., 2005, P 2005 IEEE INT C CO
   Rhee Injong., 2005, SENSYS 05, P90
   STEMM M, 1997, T COMMUNICATIONS SPE, V8, P1125
   van Hoesel L.F. W., 2004, PROC 2 INT C EMBEDDE, P303
   VANHOESEL LFW, 2004, P INT C NETW SENS SY
   WALLACE J, 2005, P IEEE 62 VEH TECHN
   Xia F, 2007, SENSORS-BASEL, V7, P3179, DOI 10.3390/s7123179
   Ye W, 2004, IEEE ACM T NETWORK, V12, P493, DOI 10.1109/TNET.2004.828953
   YUSUF M, 2005, IEEE INT C EM TECHN
   Zabin F, 2008, IET COMMUN, V2, P995, DOI 10.1049/iet-com:20070424
   Zhao F., 2004, Wireless sensor networks: an information processing approach
NR 41
TC 24
Z9 25
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 121
EP 145
DI 10.1007/s11042-009-0410-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400008
DA 2024-07-18
ER

PT J
AU Daniyal, F
   Taj, M
   Cavallaro, A
AF Daniyal, Fahad
   Taj, Murtaza
   Cavallaro, Andrea
TI Content and task-based view selection from multiple video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content scoring; Information ranking; Feature analysis; Camera
   selection; Content analysis; Autonomous video production
ID TRACKING; OBJECTS
C1 [Daniyal, Fahad; Taj, Murtaza; Cavallaro, Andrea] Queen Mary Univ London, Multimedia & Vis Grp, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Daniyal, F (corresponding author), Queen Mary Univ London, Multimedia & Vis Grp, London E1 4NS, England.
EM fahad.daniyal@elec.qmul.ac.uk; murtaza.taj@elec.qmul.ac.uk;
   andrea.cavallaro@elec.qmul.ac.uk
OI Taj, Murtaza/0000-0003-2353-4462
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P 7 IEEE WORKSH APPL
   [Anonymous], ACM INT WORKSH VID S
   [Anonymous], P 9 EUR C COMP VIS G
   Batista J, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P18
   Chen X, 2008, MACH VISION APPL, V19, P217, DOI 10.1007/s00138-007-0094-y
   DANIYAL F, 2008, P ACM IEEE INT C DIS, P1
   Del Bimbo A, 2006, PATTERN RECOGN LETT, V27, P1826, DOI 10.1016/j.patrec.2006.02.014
   GOSHORN R, 2007, P ACM IEEE INT C DIS
   Greiffenhagen M, 2000, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.2000.854840
   Gupta A, 2007, IEEE I CONF COMP VIS, P118
   Jiang H, 2008, IEEE T MULTIMEDIA, V10, P997, DOI 10.1109/TMM.2008.2001379
   Karlsson S, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/526191
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Lien KC, 2006, INT C PATT RECOG, P1123
   Murphy K. P., 2002, Ph.D. Thesis,
   Park HS, 2008, P IEEE RAS-EMBS INT, P109, DOI 10.1109/BIOROB.2008.4762876
   PRINCE SJD, 2005, P IEEE WORKSH APPL C, V1, P439
   Qureshi F., 2005, P 3 ACM WORKSH VID S, P131
   QURESHI FZ, 2007, P IEEE INT C COMP VI
   Rezaeian M, 2007, Fifth Annual IEEE International Conference on Pervasive Computing and Communications Workshops, Proceedings, P307, DOI 10.1109/PERCOMW.2007.105
   SHEN C, 2007, P IEEE INT C IM PROC, P193, DOI DOI 10.1109/ICIP.2007.4379279
   Snidaro L, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P364, DOI 10.1109/AVSS.2003.1217944
   TAJ M, 2008, ONL P TREC VID RETR
   TAJ M, 2008, P IEEE INT C ADV VID
   Taj M, 2007, LECT NOTES COMPUT SC, V4122, P190
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939
   TAYLOR G, 2007, P IEEE INT C COMP VI
   TESSENS L, 2008, P ACM IEEE INT C DIS, P1
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Zhou X., 2003, INT WORKSHOP VIDEO S, P113, DOI DOI 10.1145/982452.982467
NR 31
TC 26
Z9 26
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 235
EP 258
DI 10.1007/s11042-009-0355-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hariri, B
   Pakravan, MR
   Shirmohammadi, S
   Alavi, MH
AF Hariri, Behnoosh
   Pakravan, Mohammad Reza
   Shirmohammadi, Shervin
   Alavi, Mohammad Hossein
TI Using geometrical routing for overlay networking in MMOGs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMOG; Geometrical routing; Locality sensitive hashing; Overlay networks
AB At a first glance, transmitting update information to a geographic region in the virtual space seems to be an attractive primitive in Massively Multiplayer Online Gaming (MMOG) applications where players are constantly moving and need to send updates to their neighbors who are in the same region of the virtual space. The system would become more scalable if entities did not need to keep track of each other or send messages directly to one another. Rather, an entity could just send a message to a specific region in the virtual space (its area of effect), as opposed to sending packets to specific IP addresses, significantly reducing tracking and routing overhead. Fundamentally speaking, update message exchange is mostly based on users' visibility range, which is mainly affected by proximity; i.e., avatars are interested in nodes within a specific distance around them. Therefore MMOG applications require a routing scheme that can deliver messages to specified locations in the virtual space. Such location based routing motivates the use of geographical routing, which has been introduced and successfully used in the context of wireless networks; however, in its current form it is not well suited for MMOGs which run on wired networks. In this article, we propose a scalable MMOG networking architecture based on hierarchical multi-grid geographical routing that is well suited for MMOG networks. We present our concept and design of hierarchical geometrical routing based on locality sensitive hashing, demonstrate its performance, and discuss both the strengths and shortcomings of our approach.
C1 [Hariri, Behnoosh; Pakravan, Mohammad Reza] Sharif Univ Technol, ACRI, Dept Elect Engn, Tehran, Iran.
   [Hariri, Behnoosh; Shirmohammadi, Shervin] Sch Informat Technol & Engn, DISCOVER Lab, Ottawa, ON K1N 6N5, Canada.
C3 Sharif University of Technology
RP Hariri, B (corresponding author), Sharif Univ Technol, ACRI, Dept Elect Engn, POB 11365-8639,Azadi Ave, Tehran, Iran.
EM hariri@ee.sharif.edu
RI Shirmohammadi, Shervin/E-6945-2012; Pakravan, Mohammadreza/E-4489-2010
OI Shirmohammadi, Shervin/0000-0002-3973-4445; Pakravan,
   Mohammadreza/0000-0002-3899-8211
FU Iran Telecommunication Research Center (ITRC)
FX The authors acknowledge the support of Iran Telecommunication Research
   Center (ITRC) in this project.
CR [Anonymous], 2006, P 1 INT C BIOINSP CO
   Bharambe A., 2006, Proceedings of the 3rd conference on Networked Systems Design Implementation - Volume 3, NSDI'06, V3, P12
   Bose P, 2000, LECT NOTES COMPUT SC, V1741, P113
   BOSE P, 2001, J MOBILE COMMUNICATI, V7, P48
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   Douglas S., 2005, P IEEE INT C INFORM, P7
   FINN GG, 1987, ISURR87180 ISI
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hampel T., 2006, PROC 5 ACM SIGCOMM W, P48, DOI [10.1145/1230040.1230058, DOI 10.1145/1230040.1230058]
   IMIELINSKI N, 1997, P IEEE ACM MOBICOM, P66
   Karp B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P243, DOI 10.1145/345910.345953
   Knutsson B, 2004, IEEE INFOCOM SER, P96
   Kranakis E., 1999, P 11 CAN C COMP GEOM, V11, P51
   Kuhn F., 2003, GEOMETRIC ADHOC ROUT, P63, DOI DOI 10.1145/872035.872044
   LEDLIE J, 2007, P IPTPS
   Limura T., 2004, P ACM SIGCOMM 2004 W, P116
   Seada K, 2004, IEEE WCNC, P2551, DOI 10.1109/WCNC.2004.1311490
   SHIRMOHAMMADI S, 2005, P FUT PLAY, P13
   Stojmenovic I, 2001, IEEE T PARALL DISTR, V12, P1023, DOI 10.1109/71.963415
   Subramanian L, 2003, ACM SIGCOMM COMP COM, V33, P11, DOI 10.1145/774763.774764
   TAKAGI H, 1984, IEEE T COMMUN, V32, P246, DOI 10.1109/TCOM.1984.1096061
   Yu A., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P99, DOI 10.1145/1065983.1066007
NR 22
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 61
EP 81
DI 10.1007/s11042-009-0312-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900004
DA 2024-07-18
ER

PT J
AU Chiang, CC
   Wu, JY
   Yang, MT
   Tai, WK
AF Chiang, Cheng-Chin
   Wu, Jyun-Yue
   Yang, Mau-Tsuen
   Tai, Wen-Kai
TI Independent query refinement and feature re-weighting using positive and
   negative examples for content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Relevance feedback; Maximum likelihood
   estimation; Query refinement; Feature re-weighting
ID RELEVANCE FEEDBACK; VIDEO; INFORMATION; SHAPE
AB Query refinement and feature re-weighting are the two core techniques underlying the relevance feedback of content-based image retrieval. Most existing relevance feedback mechanisms generally model the user's query target with a single query point and weight each extracted feature with a single importance factor. A designed estimation procedure then estimates the best query point and all importance factors by optimizing a formulated criterion which measures the goodness of the estimation. This formulated criterion simultaneously encapsulates all positive and negative examples supplied from the user's feedback. Under such formulation, the positive and negative examples may contribute contradictorily to the criterion and sometimes may introduce higher difficulty in attaining a good estimation. In this paper, we propose a different statistical formulation to estimate independently two pairs of query points and feature weights from the positive examples and negative examples, respectively. These two pairs then define the likelihood ratio, a criterion term used to rank the relevance of all database images. This approach simplifies the criterion formulation and also avoids the mutual impeditive influence between positive examples and negative examples. The experimental results demonstrate that the proposed approach outperforms some other related approaches.
C1 [Chiang, Cheng-Chin; Wu, Jyun-Yue; Yang, Mau-Tsuen; Tai, Wen-Kai] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Shoufeng 974, Hualien, Taiwan.
C3 National Dong Hwa University
RP Chiang, CC (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Shoufeng 974, Hualien, Taiwan.
EM ccchiang@mail.ndhu.edu.tw; m9321026@em93.ndhu.edu.tw;
   mtyang@mail.ndhu.edu.tw; wktai@mail.ndhu.edu.tw
OI Yang, Mau-Tsuen/0000-0003-1859-6730
CR Ahmad I, 2003, J VIS COMMUN IMAGE R, V14, P291, DOI 10.1016/S1047-3203(03)00039-7
   ASHLEY J, 1995, IEEE COMPUT, V28, P23
   Chevalier F, 2007, PATTERN RECOGN LETT, V28, P939, DOI 10.1016/j.patrec.2006.12.009
   Dai SY, 2005, PATTERN RECOGN LETT, V26, P565, DOI 10.1016/j.patrec.2004.08.022
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Duda R., 1973, Pattern Classification and Scene Analysis
   Gagaudakis G, 2002, PATTERN RECOGN, V35, P81, DOI 10.1016/S0031-3203(01)00043-7
   GIACINTO G, 2005, ADV NEURAL INFORM PR, V17, P489
   Greenspan H, 2004, COMPUT VIS IMAGE UND, V93, P86, DOI 10.1016/j.cviu.2003.08.004
   Hampapur A, 1997, P SOC PHOTO-OPT INS, V3022, P188, DOI 10.1117/12.263407
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Kherfi ML, 2003, J VIS COMMUN IMAGE R, V14, P428, DOI 10.1016/S1047-3203(03)00043-9
   Kim CR, 2003, INFORM SOFTWARE TECH, V45, P203, DOI 10.1016/S0950-5849(02)00206-9
   Kim NW, 2005, LECT NOTES COMPUT SC, V3568, P454
   Lee DH, 2001, J SYST SOFTWARE, V56, P165, DOI 10.1016/S0164-1212(00)00095-9
   Lew MS, 2000, COMPUTER, V33, P46, DOI 10.1109/2.881694
   Lin HC, 2003, PATTERN RECOGN LETT, V24, P2255, DOI 10.1016/S0167-8655(03)00052-7
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Nascimento MA, 2003, J VISUAL LANG COMPUT, V14, P151, DOI 10.1016/S1045-926X(02)00076-9
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Özer IB, 2002, J VIS COMMUN IMAGE R, V13, P425, DOI 10.1006/jvci.2002.0509
   Qi XJ, 2005, PATTERN RECOGN, V38, P2449, DOI 10.1016/j.patcog.2005.04.005
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Seo KK, 2007, EXPERT SYST APPL, V33, P491, DOI 10.1016/j.eswa.2006.05.030
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   Wu ST, 2005, PATTERN RECOGN, V38, P707, DOI 10.1016/j.patcog.2004.10.005
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   Zhou XS, 2002, INFORM SCIENCES, V148, P129, DOI 10.1016/S0020-0255(02)00286-4
NR 32
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 27
EP 53
DI 10.1007/s11042-008-0218-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400002
DA 2024-07-18
ER

PT J
AU Kantarci, A
AF Kantarci, Aylin
TI Streaming of scalable h.264 videos over the Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE scalable coding; H.264/AVC; content-aware streaming; rate adaptation;
   QoS management
AB To investigate the benefits of scalable codecs in the case of rate adaptation problem, a streaming system for scalable H.264 videos has been implemented. The system considers congestion level in the network and buffer status at the client during adaptation process. The rate adaptation algorithm is content adaptive. It selects an appropriate substream from the video file by taking into account the motion dynamics of video. The performance of the system has been tested under congestion-free and congestion scenarios. The performance results indicate that the system reacts to congestion properly and can be used for Internet video streaming where losses occur unpredictably.
C1 Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
C3 Ege University
RP Kantarci, A (corresponding author), Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
EM aylin.kantarci@ege.edu.tr
CR [Anonymous], 2005, 1449610 ISOIEC
   BISTROM J, 2005, 111590 HELS U TECHN
   CAHNG C, 2004, P IEEE INT C IM PROC
   Gallmeister B., 1995, POSIX 4 PROGRAMMERS
   HOM U, 1999, IMAGE COMMUN, V14, P77
   JI X, 2004, P PICT COD S PCS 200
   Kantarci A, 2004, SIGNAL PROCESS-IMAGE, V19, P479, DOI 10.1016/j.image.2004.03.002
   Kantarci A, 2003, MULTIMED TOOLS APPL, V21, P261, DOI 10.1023/A:1025774901363
   KATOU K, 2003, P INT C CIRC SYST CO
   Lewis Bil., 1998, MULTITHREADED PROGRA
   LI M, 2003, WPICSTR0318
   MASRY M, 2001, P IEEE INT C IM PROC
   Puri A, 2004, SIGNAL PROCESS-IMAGE, V19, P793, DOI 10.1016/j.image.2004.06.003
   REICHEL HJ, 2005, JOINT SCALABLE VIDEO
   Richardson I.E.G., 2002, Video Codec Design: Developing Image and Video Compression Systems
   SANTACRUZ D, 2004, P PICT COD S PCS 200
   SCHULZRINNE H, 1996, 1889 RFC
   SCHWARZ H, 2004, P PICT COD S PCS 2O0
   SEOK JM, 2002, P 2002 INT TECHN C C
   Sun XY, 2004, IEEE T MULTIMEDIA, V6, P291, DOI 10.1109/TMM.2003.822818
   Taubman D, 2003, PROC SPIE, V5150, P791, DOI 10.1117/12.502889
   TRIPHATHI A, 2002, P 2 INT WORKSH INT M
   VANDERSCHAAR M, 2001, P ISAS LA HAV CUB
   WANG Z, 2003, P IEEE MULT 2003 BER
   Wenger S., 2005, RTP payload format for H.264 video
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu DP, 2001, P IEEE, V89, P6, DOI 10.1109/5.904503
   2005, JVTN025D0DOC
NR 28
TC 7
Z9 7
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 303
EP 324
DI 10.1007/s11042-007-0147-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600007
DA 2024-07-18
ER

PT J
AU Kusmierek, E
   Du, DHC
AF Kusmierek, Ewa
   Du, David H. C.
TI Proxy-assisted periodic broadcast for video streaming with multiple
   servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video streaming; periodic broadcast; proxy-caching; distributed servers
AB Large scale video streaming over the Internet requires a large amount of resources such as server I/O bandwidth and network bandwidth. A number of video delivery techniques can be used to lower these requirements. Periodic broadcast by a central server combined with proxy caching offers a significant reduction of the aggregate network and server I/O bandwidth usage. However, the resources available to a single server are still limited. In this paper we propose a system with multiple geographically distributed servers. The problem of multiple servers for periodic broadcast is quite different from the problem of object location for multiple web servers. Multiple servers offer increased amount of resources and service availability and may potentially allow a further reduction of network bandwidth usage. On the other hand, the benefit of periodic broadcast mostly comes from high demand videos. With multiple servers holding a video, the demand of the video at each server is reduced. Therefore, it is a challenge to use multiple servers efficiently. We first analyze the dependence of the resource requirements on the number and locations of the servers. Based on the character of the function describing such a dependence, we formulate and solve the problem of video location and delivery, in a way that minimizes resource usage. We explore a trade-off between network and I/O bandwidth requirements. We evaluate our proposed solutions through a number of tests.
C1 [Kusmierek, Ewa] Poznan Supercomp & Networking Ctr, Poznan, Poland.
   [Kusmierek, Ewa; Du, David H. C.] Univ Minnesota, Digital Technol Ctr, Minneapolis, MN USA.
   [Kusmierek, Ewa; Du, David H. C.] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA.
C3 Polish Academy of Sciences; Poznan Supercomputing & Networking Center;
   University of Minnesota System; University of Minnesota Twin Cities;
   University of Minnesota System; University of Minnesota Twin Cities
RP Kusmierek, E (corresponding author), Poznan Supercomp & Networking Ctr, Poznan, Poland.
EM kusmiere@cs.umn.edu; du@cs.umn.edu
CR ACHARYA S, 2000, P MULT C NETW
   Aggarwal CC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P253, DOI 10.1109/MMCS.1996.534983
   AGGARWAL CC, 1996, P IEEE C MULT SYST
   [Anonymous], 2000, Communications of the Operations Research Society of Japan
   [Anonymous], 1979, COMPUT INTRACTABILIT
   Baentsch M., 1997, IEEE Internet Computing, V1, P18, DOI 10.1109/4236.601083
   Barnett SA, 1996, IEEE J SEL AREA COMM, V14, P1173, DOI 10.1109/49.508287
   GAO L, 1999, P 7 ACM INT C MULT 9, V1, P203
   Gao LX, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P117, DOI 10.1109/MMCS.1999.778179
   Guo Y., 2002, P IEEE INT C COMM, V4, P2607
   HU A, 2001, P IEEE INFOCOM, V1, P508
   Hua K., 1997, PROC SIGCOMM, P89
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   KANGASHARJU J, 2001, P WEB CACH CONT DIST
   KUSMIEREK E, 2006, IEEE T MULTIMEDI APR
   KUSMIEREK E, 2003, 00335 U MINN
   KUSMIEREK E, 2006, MULTIMEDIA TOOLS APP
   KUSMIEREK E, 2004, J INTERNET TECHN OCT
   Lüling R, 1999, INT CON DISTR COMP S, P253, DOI 10.1109/ICDCS.1999.776527
   Ma WH, 2004, IEEE T MULTIMEDIA, V6, P599, DOI 10.1109/TMM.2004.830819
   Ma WH, 2002, IEEE T MULTIMEDIA, V4, P539, DOI 10.1109/TMM.2002.806536
   Qiu LL, 2001, IEEE INFOCOM SER, P1587, DOI 10.1109/INFCOM.2001.916655
   Ramesh S, 2001, IEEE INFOCOM SER, P85, DOI 10.1109/INFCOM.2001.916690
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   Shahabi C, 2002, IEEE T PARALL DISTR, V13, P1183, DOI 10.1109/TPDS.2002.1058101
   Wang B, 2002, IEEE INFOCOM SER, P1726, DOI 10.1109/INFCOM.2002.1019426
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
NR 27
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 243
EP 266
DI 10.1007/s11042-007-0135-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Peng, LN
   Candan, KS
   Mayer, C
   Chatha, KS
   Ryu, KD
AF Peng, Lina
   Candan, K. Selcuk
   Mayer, Christopher
   Chatha, Karamvir S.
   Ryu, Kyung Dong
TI Optimization of media processing workflows with adaptive operator
   behaviors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE media-processing workflows; sensory/reactive environments; quality-cost
   tradeoff; quality-delay tradeoff; interactive arts
AB In this paper, we present the ARIA media processing workflow architecture that processes, filters, and fuses sensory inputs and actuates responses in real-time. The components of the architecture are programmable and adaptable; i.e. the delay, size, and quality/precision characteristics of the individual operators can be controlled via a number of parameters. Each data object processed by qStream components is subject to transformations based on the parameter values. For instance, the quality of an output data object and the corresponding processing delay and resource usage depend on the values assigned to parameters of the operators in the object flow path. In Candan, Peng, Ryu, Chatha, Mayer (Efficient stream routing in quality- and resource-adaptive flow architectures. In: Workshop on multimedia information systems, 2004), we introduced a class of flow optimization problems that promote creation and delivery of small delay or small resource-usage objects to the actuators in single-sensor, single-actuator workflows. In this paper, we extend our attention to multi-sensor media processing workflow scenarios. The algorithms we present take into account the implicit dependencies between various system parameters, such as resource consumption and object sizes. We experimentally show the effectiveness and efficiency of the algorithms.
C1 Arizona State Univ, Dept Comp Sci & Engn, Ira A Fulton Sch Engn, Tempe, AZ 85287 USA.
   IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 Arizona State University; Arizona State University-Tempe; International
   Business Machines (IBM)
RP Candan, KS (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Ira A Fulton Sch Engn, Tempe, AZ 85287 USA.
EM lina.peng@asu.edu; candan@asu.edu; chris.mayer@asu.edu; kchatha@asu.edu;
   kryu@us.ibm.com
RI Mayer, Christopher C./J-5425-2019
OI Mayer, Christopher C./0000-0002-5612-5481
CR Babu S, 2001, SIGMOD REC, V30, P109, DOI 10.1145/603867.603884
   BABU S, 2004, P ACM SIGMOD INT C M, P407
   Black AP, 2002, MULTIMEDIA SYST, V8, P406, DOI 10.1007/s005300200062
   BOM J, 1998, 7 IFIP ICCC C INF NE
   Candan KS, 1998, IEEE T KNOWL DATA EN, V10, P433, DOI 10.1109/69.687977
   CANDAN KS, 2004, WORKSH MULT INF SYST
   CANDAN KS, 1999, ICMCS99
   CHANG F, 2001, CLUSTER COMPUT, V4
   CHATTERJEE S, 1999, P IPPS SPDP 99 WPDRT
   FU X, 2001, P USENIX S INT TECHN
   Gu X., 2005, IEEE Transactions on Multimedia
   Hellerstein JosephM., 2000, IEEE DATA ENG B, V23, P7
   KELEHER P, 1999, P 19 INT C DIST COMP
   KORKMAZ T, 2001, INFOCOM
   Lee C, 1999, PROCEEDINGS OF THE FIFTH IEEE REAL-TIME TECHNOLOGY AND APPLICATIONS SYMPOSIUM, P276, DOI 10.1109/RTTAS.1999.777680
   LORENZ DH, 1998, INFOCOM98
   MADDEN S, 2002, ICDE 2002
   NAHRSTEDT K, 1995, IEEE MULTIMEDIA, V2, P53, DOI 10.1109/93.368603
   PENG L, 2004, ACM MM INTERACTIVE A
   PENG L, WORKSH MAN DAT EM MU
   Raman B, 2003, IEEE INFOCOM SER, P1477
   Raman B, 2003, COMPUT COMMUN, V26, P1727, DOI 10.1016/S0140-3664(03)00042-2
   Sen A, 2000, LECT NOTES COMPUT SC, V1815, P859
   SIACHALOU S, 2003, INFOCOM
   Tatbul N., 2003, VLDB
   Tian Feng, 2003, VLDB
   WANG N, 2003, WORKSH QUAL SERV MUL, P306
   WANG Z, 1996, IEEE JSAC, V14
   XU D, 2002, P SPIE ACM MMCN
NR 29
TC 5
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2007
VL 33
IS 3
BP 245
EP 272
DI 10.1007/s11042-007-0105-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 156SW
UT WOS:000245671200002
DA 2024-07-18
ER

PT J
AU Andreou, I
   Sgouros, NM
AF Andreou, Ioannis
   Sgouros, Nikitas M.
TI Utilizing shape retrieval in sketch synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE sketch synthesis; shape retrieval; multimedia authoring tools
ID OBJECT RECOGNITION
AB This article describes SR-Sketch, a sketch creation tool that can act both as a front-end visual query module to visual information retrieval systems and as an aid tool for fast image composition. The system allows the user to draw shapes on the computer screen using the mouse cursor. At any time during this process the user can query a shape database for similar shapes and then select the ones s/he thinks are more relevant. The system can then automatically align and replace user-drawn objects with the chosen database shapes in the user sketch. For any match between a sketch shape and a database shape, the application can provide a visual explanation of how and why two shapes are considered similar. Evaluation results show that the system achieves favorable results with respect to noise tolerance, speed and reliability. SR-Sketch is freely available for download and experimentation.
C1 Univ Piraeus, Dept Technol Educ & Digital Syst, Piraeus 18534, Greece.
C3 University of Piraeus
RP Sgouros, NM (corresponding author), Univ Piraeus, Dept Technol Educ & Digital Syst, Karaoli & Dimitriou 80, Piraeus 18534, Greece.
EM gandreou@unipi.gr; sgouros@unipi.gr
CR AGOURIS P, 1998, INT ARCH PHOTOGRAMME, V32, P597
   ANDREOU I, 2003, IEEE INT C MULT EXP, V1, P153
   [Anonymous], 2001, P INT C INT MULT DIS
   ASHLEY J, 1995, IEEE COMPUT, V28, P23
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BARTON J, 2003, IEPM 2003 PORT
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   DISCIASCIO E, 1999, J VIS LANG COMPUT SP, V10
   Essert-Villard C, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P124, DOI 10.1109/IV.2001.942048
   Faloutsos C., 1994, J INTELLIGENT INFORM, V3
   HENRICH A, 2000, ADBIS DASFAA S 2000, P88
   HIRATA K, 1993, NEC RES DEV, V34, P263
   HIRATA K, 1992, LECT NOTES COMPUTER, V580
   Landay JA, 2001, COMPUTER, V34, P56, DOI 10.1109/2.910894
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MEHROTRA R, 1995, COMPUTER, V28, P57, DOI 10.1109/2.410154
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   PENTLAND A, 1994, SPIE, V185, P34
   RUI Y, 1996, P 1 WORKSH IM DAT MU
   SMITH JR, 1996, P ACM MULT 96
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604
NR 25
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2007
VL 32
IS 3
BP 275
EP 291
DI 10.1007/s11042-006-0053-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 137TK
UT WOS:000244314900003
DA 2024-07-18
ER

PT J
AU Wu, K
   Yap, KH
AF Wu, Kui
   Yap, Kim-Hui
TI Content-based image retrieval using fuzzy perceptual feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based image retrieval; fuzzy decision; relevance feedback; user
   information need
ID FEATURES
AB In this paper, a new framework called fuzzy relevance feedback in interactive content-based image retrieval (CBIR) systems is introduced. Conventional binary labeling scheme in relevance feedback requires a crisp decision to be made on the relevance of the retrieved images. However, it is inflexible as user interpretation of visual content varies with respect to different information needs and perceptual subjectivity. In addition, users tend to learn from the retrieval results to further refine their information requests. It is, therefore, inadequate to describe the user's fuzzy perception of image similarity with crisp logic. In view of this, we propose a fuzzy relevance feedback approach which enables the user to make a fuzzy judgement. It integrates the user's fuzzy interpretation of visual content into the notion of relevance feedback. An efficient learning approach is proposed using a fuzzy radial basis function (FRBF) network. The network is constructed based on the user's feedbacks. The underlying network parameters are optimized by adopting a gradient-descent training strategy due to its computational efficiency. Experimental results using a database of 10,000 images demonstrate the effectiveness of the proposed method.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Media Technol Lab, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Yap, KH (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Media Technol Lab, Block S2-2,Nanyang Ave, Singapore 639798, Singapore.
EM pg01537831@ntu.edu.sg; ekhyap@ntu.edu.sg
RI Yap, Kim-Hui/A-5157-2011
OI Yap, Kim-Hui/0000-0003-1933-4986
CR AMARNATH G, 1997, COMMUN ACM, V40, P70
   [Anonymous], IEEE COMPUT
   [Anonymous], P IEEE C COMP VIS PA
   Baeza-Yates R., 1999, Modern information retrieval
   COX IJ, 2000, IEEE T IMAGE PROCESS
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   Huang J, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P325, DOI 10.1145/266180.266383
   HUANG TS, 2002, 2 INT C DEV LEARN
   ISHIKAWA Y, 1998, P INT C VER LARG DAT
   Laaksonen J, 2002, IEEE T NEURAL NETWOR, V13, P841, DOI 10.1109/TNN.2002.1021885
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281
   MULLER H, 2000, P INT C PATT REC BAR
   Muneesawang P, 2002, IEEE T NEURAL NETWOR, V13, P821, DOI 10.1109/TNN.2002.1021883
   MUNEESAWNAG P, 2001, P IEEE INT C AC SPEE
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825
   SMITH JR, 1996, P ACM MULT NOV
   SMITH JR, 1996, P IEEE ICASSP 96 ATL
   SU Z, 2001, SPIE EL IM SAN JOS C
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TONG S, 2001, P 9 ACM C MULT OTT C
   VASCONCELOS N, 1999, P NIPS 99 DENV COL
   Wu Y, 2000, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2000.855823
   Zhou XS, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P94, DOI 10.1109/IVL.2001.990862
   ZHOU XS, 2001, P INT C COMP VIS PAT
   1999, COREL GALLERY MAGIC
NR 30
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2007
VL 32
IS 3
BP 235
EP 251
DI 10.1007/s11042-006-0050-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 137TK
UT WOS:000244314900001
DA 2024-07-18
ER

PT J
AU Shyu, ML
   Chen, SC
   Chen, M
   Zhang, CC
   Shu, CM
AF Shyu, Mei-Ling
   Chen, Shu-Ching
   Chen, Min
   Zhang, Chengcui
   Shu, Chi-Min
TI Probabilistic semantic network-based image retrieval using MMM and
   relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 5th IEEE International Symposium on Multimedia Software Engineeting
CY DEC 10-12, 2003
CL Tai Chung, TAIWAN
SP IEEE Comp Soc, Taichung Healthcare & Management Univ, Natl Tsing Hua Univ, Natl Cent Univ, Bioinformat Soc Taiwan, Univ Calif Irvine
DE content-based image retrieval; probabilistic semantic network; MMM
   mechanism; relevance feedback
AB The performance of content-based image retrieval (CBIR) systems is largely limited by the gap between the low-level features and high-level semantic concepts. In this paper, a probabilistic semantic network-based image retrieval framework using relevance feedback is proposed to bridge this gap, which not only takes into consideration the low-level image content features, but also learns high-level concepts from a set of training data, such as access frequencies and access patterns of the images. One of the distinct properties of our framework is that it exploits the structured description of visual contents as well as the relative affinity measurements among the images. Consequently, it provides the capability to bridge the gap between the low-level features and high-level concepts. Moreover, such high-level concepts can be learned off-line, and can be utilized and refined based on the user's specific interest during the on-line retrieval process. Our experimental results demonstrate that the proposed framework can effectively assist in retrieving more accurate results for user queries.
C1 Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
   Florida Int Univ, Sch Comp & Informat Sci, Distibuted Multimedia Informat Syst Lab, Miami, FL 33199 USA.
   Univ Alabama Birmingham, Dept Comp & Informat Sci, Birmingham, AL 35294 USA.
   Natl Yunlin Univ Sci & Technol, Dept Environm & Safety Engn, Yunlin, Taiwan.
C3 University of Miami; State University System of Florida; Florida
   International University; University of Alabama System; University of
   Alabama Birmingham; National Yunlin University Science & Technology
RP Shyu, ML (corresponding author), Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
EM shyu@miami.edu; chens@cs.fiu.edu; mchen005@cs.fiu.edu;
   zhang@cis.uab.edu; shucm@pine.yuntech.edu.tw
RI Shu, Chi-Min/AHE-7272-2022
OI Shu, Chi-Min/0000-0001-9455-6162
CR [Anonymous], IEEE COMPUT
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   e a Beigi M., 1998, Storage and Retrieval for Image and Video Databases VI, V3312, P118
   FRANK O, 1986, J AM STAT ASSOC, V81, P832, DOI 10.2307/2289017
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   KAPLAN LM, 1998, P IS T SPIE STOR RET, P162
   Lin HC, 1997, IEEE T IMAGE PROCESS, V6, P332, DOI 10.1109/83.551706
   Lu Y, 2003, IEEE T MULTIMEDIA, V5, P339, DOI 10.1109/TMM.2003.813280
   MA WY, 1999, HDB MULTIMEDIA COMPU, pCH13
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Rabinowicz E., 1986, Tribology and Mechanics of Magnetic Storage Systems, V3, P1
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Shyu M.-L., 2003, Proceedings of the 1st ACM international workshop on Multimedia databases, P78
   Shyu ML, 2000, P INT COMP SOFTW APP, V24, P149, DOI 10.1109/CMPSAC.2000.884705
   Shyu ML, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P467, DOI 10.1109/ICME.2000.869640
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Stehling R.O., 2000, P 2000 ACM WORKSHOPS, P171
   WIEDERHOLD G, 1992, IEEE COMPUT, V25, P38
   Wolf W, 1997, INT CONF ACOUST SPEE, P2609, DOI 10.1109/ICASSP.1997.595323
   Zhang DS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P425, DOI 10.1109/ICME.2002.1035809
NR 23
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2006
VL 30
IS 2
BP 131
EP 147
DI 10.1007/s11042-006-0023-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 082CG
UT WOS:000240363500002
DA 2024-07-18
ER

PT J
AU Chianese, A
   Picariello, A
   Sansone, L
   Sapino, ML
AF Chianese, A
   Picariello, A
   Sansone, L
   Sapino, ML
TI Managing uncertainties in image databases: A fuzzy approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 7th Workshop on Multimedia Information Systems
CY NOV 07-09, 2001
CL Capri, ITALY
DE image database; content based image retrieval; fuzzy database; NF2 data
   model
AB In this paper we present a fuzzy approach for image databases. We exploit the concept of NF2 relational model as a foundation for building image catalogues containing the semantic description of a given image database. New algebraic operators are defined in order to capture the fuzziness related to the semantic descriptors of an image. We compare our model to the First Normal Form annotated relation model, and show that in a number of interesting cases they can be considered equivalent, from the operational point of view, but in general NF2 relational model is more powerful, and provides a more suitable framework for dealing with uncertainties in image databases.
C1 Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy.
   Univ Turin, Dipartimento Informat, I-10149 Turin, Italy.
C3 University of Naples Federico II; University of Turin
RP Chianese, A (corresponding author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.
EM angelo.chianese@unina.it; antonio.picariello@unina.it;
   lucio.sansone@unina.it; mlsapino@di.unito.it
RI Sansone, Lucia/IAQ-9878-2023; Sapino, Maria Luisa/C-6257-2011;
   Picariello, Antonio/G-9062-2012; PICARIELLO, Antonio/L-6820-2015
OI Sansone, Lucia/0000-0003-2341-5228; PICARIELLO,
   Antonio/0000-0003-4804-1007
CR Cavallo R., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB, P71
   Dey D, 1996, ACM T DATABASE SYST, V21, P339, DOI 10.1145/232753.232796
   DIBATTISTA G, 1993, IEEE T KNOWL DATA EN, V5, P439, DOI 10.1109/69.224196
   Lakshmanan LVS, 1997, ACM T DATABASE SYST, V22, P419, DOI 10.1145/261124.261131
   Makinouchi A., 1977, Proceedings on very large data bases, P447
   Nakata M., 1995, Proceedings of ISUMA - NAFIPS '95 The Third International Symposium on Uncertainty Modeling and Analysis and Annual Conference of the North American Fuzzy Information Processing Society (Cat. No.95TB8082), P643, DOI 10.1109/ISUMA.1995.527770
   RAJU KVSVN, 1988, ACM T DATABASE SYST, V13, P129, DOI 10.1145/42338.42344
   TAKAHASHI Y, 1993, IEEE T KNOWL DATA EN, V5, P122, DOI 10.1109/69.204096
   Yang Q, 2001, IEEE T KNOWL DATA EN, V13, P884, DOI 10.1109/69.971185
   Yazici A, 1999, IEEE T FUZZY SYST, V7, P659, DOI 10.1109/91.811232
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   ZADEH LA, 1971, INFORM SCIENCES, V3, P159, DOI 10.1016/S0020-0255(71)80004-X
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 18
TC 5
Z9 5
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2004
VL 23
IS 3
BP 237
EP 252
DI 10.1023/B:MTAP.0000031759.22145.5d
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 829BJ
UT WOS:000222017700005
DA 2024-07-18
ER

PT J
AU Dohnal, V
   Gennaro, C
   Savino, P
   Zezula, P
AF Dohnal, V
   Gennaro, C
   Savino, P
   Zezula, P
TI D-Index: Distance searching index for metric data sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE metric spaces; similarity search; index structures; performance
   evaluation
AB In order to speedup retrieval in large collections of data, index structures partition the data into subsets so that query requests can be evaluated without examining the entire collection. As the complexity of modern data types grows, metric spaces have become a popular paradigm for similarity retrieval. We propose a new index structure, called D-Index, that combines a novel clustering technique and the pivot-based distance searching strategy to speed up execution of similarity range and nearest neighbor queries for large files with objects stored in disk memories. We have qualitatively analyzed D-Index and verified its properties on actual implementation. We have also compared D-Index with other index structures and demonstrated its superiority on several real-life data sets. Contrary to tree organizations, the D-Index structure is suitable for dynamic environments with a high rate of delete/insert operations.
C1 Masaryk Univ, Brno, Czech Republic.
   CNR, ISI, I-56124 Pisa, Italy.
C3 Masaryk University Brno; Consiglio Nazionale delle Ricerche (CNR)
RP Masaryk Univ, Brno, Czech Republic.
EM xdohnal@fi.muni.cz; c.gennaro@isti.cnr.it; p.savino@isti.cnr.it;
   zezula@fi.muni.cz
RI Gennaro, Claudio/AAH-5171-2019; Dohnal, Vlastislav/D-1196-2012; Savino,
   Pasquale/AAY-7287-2020
OI Gennaro, Claudio/0000-0002-3715-149X; Dohnal,
   Vlastislav/0000-0001-7768-7435; Savino, Pasquale/0000-0002-8841-5440
CR Bozkaya T, 1999, ACM T DATABASE SYST, V24, P361, DOI 10.1145/328939.328959
   Bustos B, 2001, SCCC 2001: XXI INTERNATIONAL CONFERENCE OF THE CHILEAN COMPUTER SCIENCE SOCIETY, PROCEEDINGS, P33, DOI 10.1109/SCCC.2001.972629
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Chávez E, 2001, MULTIMED TOOLS APPL, V14, P113, DOI 10.1023/A:1011343115154
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   DOHNAL V, 2001, P 9 IT S ADV DAT SYS, P45
   Gennaro C., 2001, P ACM MULT 2001 WORK, P1
   HELLERSTEIN JM, 1995, P 21 INT C VER LARG, P562
   Santos RF, 2001, PROC INT CONF DATA, P623, DOI 10.1109/ICDE.2001.914877
   SEEGER B, 1993, P INT C VER LARG DAT, P592
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
   YIANILOS PN, 1999, 6 DIMACS IMPL CHALL
   Yu Cui., 2001, PROC VLDB 01, P421
NR 13
TC 82
Z9 87
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2003
VL 21
IS 1
BP 9
EP 33
DI 10.1023/A:1025026030880
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709HD
UT WOS:000184619000002
DA 2024-07-18
ER

PT J
AU Sutinen, E
   Tarhio, J
   Teräsvirta, T
AF Sutinen, E
   Tarhio, J
   Teräsvirta, T
TI Easy algorithm animation on the Web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE algorithm animation; visualization; Computer Science education; distance
   learning
AB The animation environment Jeliot automates visualization of algorithms over the Internet. The user can visualize algorithms of his own, not merely the selection supplied by a service provider. Jeliot is based on self-animating data types: the user selects the data objects of the source code to be visualized, and Jeliot produces the animation based on operations performed on those types. We present the design of Jeliot and the principles of its implementation. In addition, we discuss the educational applications of Jeliot.
C1 Univ Joensuu, Dept Comp Sci, FIN-80101 Joensuu, Finland.
   Aalto Univ, Dept Comp Sci & Engn, FIN-02015 Helsinki, Finland.
   Digia, FIN-33100 Tampere, Finland.
C3 University of Eastern Finland; Aalto University
RP Univ Joensuu, Dept Comp Sci, POB 111, FIN-80101 Joensuu, Finland.
EM erkki.sutinen@joensuu.fi; jorma.tarhio@hut.fi;
   tommi.terasvirta@digia.com
RI Terasvirta, Timo/J-1621-2019; Tarhio, Jorma A/F-5831-2012
OI Tarhio, Jorma/0000-0003-2455-1985
CR Ben-Ari M, 2002, LECT NOTES COMPUT SC, V2269, P31
   Ben-Bassat Levy R., 2002, COMPUT EDUC, V40, P1
   BERK EJ, JAVA LEX LEXICAL ANA
   Brown M.H., 1988, P SIGCHI C HUMAN FAC, P33, DOI DOI 10.1145/57167
   Brown MH, 1997, IEEE VISLANG, P372, DOI 10.1109/VL.1997.626607
   Brown MH, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P266, DOI 10.1109/VL.1996.545297
   DOMINGUE J, 1997, P PSYCH PROGR INT GR
   FORD L, 1993, 271 U EX DEP COMP SC
   HAIBT LM, 1959, P W JOINT COMP C, V15, P131
   Hudson ScottE., 1999, CUP User's Manual
   IBRAHIM B, 1994, P 1 WORLD WID WEB C, P305
   Järvinen K, 1999, PROCEEDINGS OF THE THIRTIETH SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P217, DOI 10.1145/384266.299761
   Lahtinen SP, 1998, J VISUAL LANG COMPUT, V9, P337, DOI 10.1006/jvlc.1998.0084
   Lattu M., 2000, P 12 WORKSH PSYCH PR, P19
   LATTU M, 2001, P 1 PROGR VIS WORKSH, P141
   MARKKANEN J, 1998, P PSYCH PROGR INT GR, P70
   MEISALO V, 1997, P LETTET 9L LEARN TE, P79
   MEISALO V, 1997, P ITICSE 97 INTEGRAT, P117
   MEISALO V, 1998, P TEL 98 IFIP WORLD, P715
   NAPS T, 1997, P INT TECHN COMP SCI
   Reeves T.C., 1997, WEB BASED INSTRUCTIO, P59
   STASKO J, 1994, POLKA ANIMATION DESI
   TURNER J, 1997, P ITICSE 97 ACM UPPS, P121
   [No title captured]
   [No title captured]
   [No title captured]
NR 26
TC 9
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2003
VL 19
IS 2
BP 179
EP 194
DI 10.1023/A:1022147231170
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 640KE
UT WOS:000180687400004
DA 2024-07-18
ER

PT J
AU Park, DJ
   Kim, HJ
AF Park, DJ
   Kim, HJ
TI An enhanced technique for <i>k</i>-nearest neighbor queries with
   non-spatial selection predicates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia database; spatial database; k-nearest neighbor query;
   multi-dimensional indexing
AB In multimedia databases, k-nearest neighbor queries are popular and frequently contain non-spatial predicates. Among the available techniques for such queries, the incremental nearest neighbor algorithm proposed by Hjaltason and Samet is known as the most useful algorithm [16]. The reason is that if k' > k neighbors are needed, it can provide the next neighbor for the upper operator without restarting the query from scratch. However, the R-tree in their algorithm has no facility capable of partially pruning tuple candidates that will turn out not to satisfy the remaining predicates, leading their algorithm to inefficiency. In this paper, we propose an RS-tree-based incremental nearest neighbor algorithm complementary to their algorithm. The RS-tree used in our algorithm is a hybrid of the R-tree and the S-tree, as its buddy tree, based on the hierarchical signature file. Experimental results show that our RS-tree enhances the performance of Hjaltason and Samet's algorithm.
C1 Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Park, DJ (corresponding author), Seoul Natl Univ, Sch Engn & Comp Sci, San 56-1, Seoul 151742, South Korea.
CR [Anonymous], COMMUNICATIONS ACM
   [Anonymous], P 24 INT C VER LARG
   ARYA S, 1998, J ACM, V45
   BECKMANN N, 1990, P ACM SIGMOD C JUN
   BERCHTOLD S, 1998, P 14 INT C DAT ENG F
   BERCHTOLD S, 1997, P ACM SIGMOD C JUN
   Berchtold S., 1997, P 16 ACM SIGACT SIGM
   BRODER AJ, 1990, PATTERN RECOGNITION, V23
   CAREY MJ, 1998, P 24 INT C VER LARG
   CAREY MJ, 1997, P ACM SIGMOD C JUN
   CHANG WW, 1989, P 15 INT C VER LARG
   CHAUDHURI S, 1999, P 25 INT C VER LARG
   FAGIN R, 1998, P 16 ACM SIGACT SIGM
   FALOUTSOS C, 1987, ACM T DATABASE SYSTE, V12
   FLICKNER M, 1995, IEEE COMPUTER, V28
   GRUMBACH S, 1998, P ACM SIGMOD C JUN
   HENRICH A, 1994, P 2 ACM WORKSH GEOGR
   HJALTASON GR, 1999, ACM T DATABASE SYSTE, V24
   KORN F, 1996, P 22 INT C VER LARG
   MOOERS C, 1949, B ZATOR CO, V31
   OGLE VE, 1995, IEEE COMPUTER, V28
   PATEL JM, 1997, P ACM SIGMOD C JUN
   ROUSSOPOULOS N, 1995, P ACM SIGMOD C MAY
   SEIDL T, 1998, P ACM SIGMOD C JUN
NR 24
TC 7
Z9 8
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2003
VL 19
IS 1
BP 79
EP 103
DI 10.1023/A:1021121030238
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 617QH
UT WOS:000179372000004
DA 2024-07-18
ER

PT J
AU Sharma, H
   Srivastava, S
AF Sharma, Himanshu
   Srivastava, Swati
TI Integrating multimodal features by a two-way co-attention mechanism for
   visual question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE VQA; Attention; Co-attention; Multimodal; Relational reasoning
AB Existing VQA models predominantly rely on attention mechanisms that prioritize spatial dimensions, adjusting the importance of image regions or word token features based on spatial probabilities. However, these approaches often struggle with relational reasoning, treating objects independently, and failing to fuse their features effectively. This hampers the model's ability to understand complex visual contexts and provide accurate answers. To address these limitations, our innovation introduces a novel co-attention mechanism in the VQA model. This mechanism enhances Faster R-CNN's feature extraction by emphasizing image regions relevant to the posed question. This, in turn, improves the model's ability for visual relationship reasoning, making it more adept at analyzing complex visual contexts. Additionally, our model incorporates feature-wise multimodal two-way co-attentions, enabling seamless integration of image and question representations, resulting in more precise answer predictions. Our model achieves impressive results on VQA 1.0, surpassing the best existing model, Re-attention model by 1.14% on test-std. Moreover, on VQA 2.0, our model outperforms the best model, IAHOT model by a significant margin of 2.98% on test-std. These findings demonstrate that our approach not only outperforms earlier models but also establishes a new state-of-the-art performance level in Visual Question Answering.
C1 [Sharma, Himanshu; Srivastava, Swati] GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, India.
EM himanshu.sharma@gla.ac.in; swati.srivastava@gla.ac.in
CR [Anonymous], 2009, Advances in neural information processing systems
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Barra S, 2021, PATTERN RECOGN LETT, V151, P325, DOI 10.1016/j.patrec.2021.09.008
   Bhatt D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202470
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Gao H, 2022, IEEETrans Neural Netw Learn Syst
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gao LL, 2020, NEUROCOMPUTING, V391, P227, DOI 10.1016/j.neucom.2018.11.102
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo DL, 2023, IEEE T NEUR NET LEAR, V34, P1023, DOI 10.1109/TNNLS.2021.3104937
   Guo WY, 2021, IEEE T IMAGE PROCESS, V30, P6730, DOI 10.1109/TIP.2021.3097180
   Ilievski I, 2016, Arxiv, DOI arXiv:1604.01485
   Jiang H., 2020, IEEE CVF C COMP VIS, DOI 10.1109/CVPR42600.2020.01028
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kazemi V, 2017, arXiv
   Kim JJ, 2021, NEURAL NETWORKS, V139, P158, DOI 10.1016/j.neunet.2021.02.001
   Kim O.K., 2017, ICLR
   Kingma D. P., 2014, arXiv
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li W, 2020, PATTERN RECOGN LETT, V133, P334, DOI 10.1016/j.patrec.2020.02.031
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2020, IEEE Trans, VCybern52, P4520
   Liu Y, 2020, KNOWL-BASED SYST, V207, DOI 10.1016/j.knosys.2020.106339
   Long Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10797, DOI 10.1109/CVPR42600.2020.01081
   Lu JS, 2016, ADV NEUR IN, V29
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Peng L, 2022, IEEE T KNOWL DATA EN, V34, P1644, DOI 10.1109/TKDE.2020.2998805
   Peng L, 2022, IEEE T PATTERN ANAL, V44, P318, DOI 10.1109/TPAMI.2020.3004830
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schwartz Idan., 2017, Advances in Neural Information Processing Systems, P3667
   Sharma H, 2021, IMAGING SCI J, V69, P177, DOI 10.1080/13682199.2022.2153489
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P12177, DOI 10.1007/s11042-022-12317-0
   Sharma H, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116159
   Sharma H, 2022, NEURAL PROCESS LETT, V54, P709, DOI 10.1007/s11063-021-10655-y
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P34775, DOI 10.1007/s11042-021-11276-2
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Wang P, 2017, PROC CVPR IEEE, P3909, DOI 10.1109/CVPR.2017.416
   Wu YR, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116319
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Yang X., 2021, P IEEE INT C COMPUTE, P2197
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3316767
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhan HY, 2022, NEUROCOMPUTING, V467, P323, DOI 10.1016/j.neucom.2021.10.016
   Zhang CM, 2021, J IND INF INTEGR, V23, DOI 10.1016/j.jii.2021.100224
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
   Zhang XM, 2023, Arxiv, DOI arXiv:2305.10415
   Zheng WF, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108153
   Zheng XT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3079918
   Zhou YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2054, DOI 10.1109/ICCV48922.2021.00208
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
NR 60
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17945-8
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500013
DA 2024-07-18
ER

PT J
AU Farooq, J
   Muaz, M
   Jadoon, KK
   Aafaq, N
   Khan, MKA
AF Farooq, Javaria
   Muaz, Muhammad
   Jadoon, Khurram Khan
   Aafaq, Nayyer
   Khan, Muhammad Khizer Ali
TI An improved YOLOv8 for foreign object debris detection with optimized
   architecture for small objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Foreign object debris; FOD detection; Deep learning
ID FOD
AB Automated Foreign Object Debris (FOD) detection offers significant benefit to the aviation industry by reducing human error and enabling continuous surveillance. This paper focuses on addressing the intricacies of FOD detection, with a specific emphasis on treating FODs as "small" objects, a facet which has received limited attention in prior research. This study provides a pioneering evaluation of state-of-the-art object detectors, including both anchor-based models including SSD, YOLOv5m, Scaled YOLOv4 and anchorless models CenterNet and YOLOv8m, applied to a multiclass FOD dataset, "FOD in Airports (FOD-A)", as well as meticulously curated subset of FOD-A featuring small FODs. The findings reveal that the anchorless object detector YOLOv8m gives the best time accuracy trade off outperforming all compared anchor-based and anchorless approaches. To address the challenge of detecting small FODs, this study optimizes YOLOv8m model by making architectural modifications and incorporating a dedicated, shallow detection head that is purpose-built for the precise identification of small objects. The proposed model, termed as "Improved YOLOv8", outperforms YOLOv8m by a margin of 1.02 in Average Precision for small objects (APs), achieving a mean average precision (mAP) of 93.8%. Notably, Improved YOLOv8 also has better mAP than all the considered anchor-based and anchorless object detectors examined, as well as those featured in prior FOD-A dataset research.
C1 [Farooq, Javaria; Muaz, Muhammad; Aafaq, Nayyer] Natl Univ Sci & Technol, Coll Aeronaut Engn, Islamabad, Pakistan.
   [Muaz, Muhammad] Hong Kong Ind Artificial Intelligence & Robot Ctr, Hong Kong, Peoples R China.
   [Jadoon, Khurram Khan] Ghulam Ishaq Khan Inst Engn Sci & Technol, Topi, Pakistan.
   [Khan, Muhammad Khizer Ali] Khalifa Univ Sci & Technol, Abu Dhabi, U Arab Emirates.
C3 National University of Sciences & Technology - Pakistan; GIK Institute
   Engineering Science & Technology; Khalifa University of Science &
   Technology
RP Farooq, J (corresponding author), Natl Univ Sci & Technol, Coll Aeronaut Engn, Islamabad, Pakistan.
EM jfarooq.ms14avecae@student.nust.edu.pk
RI Khan, Muhammad Kashif Riaz/ABF-4231-2021; Khan, Muhammad
   kashif/AAU-8650-2021; Muaz, Muhammad/F-4586-2019
OI Khan, Muhammad Kashif Riaz/0000-0001-7530-7291; Khan, Muhammad
   kashif/0000-0002-4893-3251; Farooq, Javaria/0000-0001-8763-3334
CR Aboah A., 2023, P IEEECVF C COMPUTER, P5349
   Administration FA, 2023, Ac 150/5220-24-foreign object debris detection equipment
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Benjumea A, 2021, Arxiv, DOI [arXiv:2112.11798, DOI 10.48550/ARXIV.2112.11798]
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Cao G, 2018, SPIE, V10615, P381
   Cao XG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030737
   Cao XG, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P751, DOI 10.1007/978-3-319-46726-9_1
   Chauhan T, 2020, MATER TODAY-PROC, V33, P4336, DOI 10.1016/j.matpr.2020.07.457
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Copeland M., 2015, Microsoft azure, P3, DOI DOI 10.1007/978-1-4842-1043-7_1
   Cramoisi G, 2010, Air Crash Investigations: The End of the Concorde Era, the Crash of Air France Flight 4590
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng CF, 2022, IEEE T MULTIMEDIA, V24, P1968, DOI 10.1109/TMM.2021.3074273
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Farooq J, 2023, 2023 3 INT C COMP IN, P308, DOI [10.1109/ICCIT58132.2023.10273972, DOI 10.1109/ICCIT58132.2023.10273972]
   Farooq J, 2023, Arxiv, DOI arXiv:2309.13264
   FOD-UNOmaha, 2023, FOD-data
   Gao Q, 2021, 2 INT C COMP DAT SCI, P1
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glenn-Jocher, 2023, GitHub Repository
   Glenn-Jocher, 2023, ultralytics/yolov5
   Gong YQ, 2021, IEEE WINT CONF APPL, P1159, DOI 10.1109/WACV48630.2021.00120
   Gu Y, 2017, SPIE, V10605, P840
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He XW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217422
   He Z, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163182
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jie Xu, 2021, 2021 IEEE 2nd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), P956, DOI 10.1109/ICIBA52610.2021.9687960
   Jing YF, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020382
   Jing Y, 2022, AEROSPACE-BASEL, V9, DOI 10.3390/aerospace9090480
   Jocher G., 2023, YOLO by Ultralytics
   Kaiwen Duan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P399, DOI 10.1007/978-3-030-58580-8_24
   Khan T, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, MEASUREMENT AND APPLICATION (ICSIMA 2017)
   홍재범, 2018, [The Journal of Korea Navigation Institute, 한국항행학회논문지], V22, P522
   Kisantal M, 2019, Arxiv, DOI arXiv:1902.07296
   Li DY, 2022, IET IMAGE PROCESS, V16, P134, DOI 10.1049/ipr2.12339
   Li GF, 2020, IEEE ACCESS, V8, P211164, DOI 10.1109/ACCESS.2020.3036620
   Li HT, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/7297960
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li Y, 2011, SPIE, V8193, P769
   Li YD, 2020, CHINESE J AERONAUT, V33, P1747, DOI 10.1016/j.cja.2020.02.024
   Liang W, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P2103, DOI [10.1109/itnec48623.2020.9085150, 10.1109/ITNEC48623.2020.9085150]
   Liang ZW, 2018, LECT NOTES COMPUT SC, V11166, P554, DOI 10.1007/978-3-030-00764-5_51
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Lindeberg T., 2012, SCHOLARPEDIA, V7, P10491, DOI [10.4249/scholarpedia.10491, DOI 10.4249/SCHOLARPEDIA.10491]
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Liu YK, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P547, DOI 10.1109/SSCI.2018.8628648
   Liu ZM, 2020, IEEE COMPUT SOC CONF, P4422, DOI 10.1109/CVPRW50498.2020.00521
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meta, 2022, Real time object detection on COCO
   Meta AI, 2022, APs object detection on COCO GitHub Repository
   Pham MT, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152501
   Mishra RK, 2015, J FAIL ANAL PREV, V15, P25, DOI 10.1007/s11668-014-9914-3
   Munyer T., 2022, arXiv
   Munyer T, 2021, arXiv
   Nguyen ND, 2020, J ELECTR COMPUT ENG, V2020, DOI 10.1155/2020/3189691
   Ni PS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082316
   Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982
   Noroozi Mohammad, 2023, Expert Systems With Applications, DOI 10.1016/j.eswa.2022.118829
   Öztürk S, 2016, ROBOT AUTON SYST, V75, P244, DOI 10.1016/j.robot.2015.09.022
   Papadopoulos E, 2021, AEROSP CONF PROC, DOI 10.1109/AERO50100.2021.9438489
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qi GQ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020420
   Rabbi J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091432
   Rafiq HA, 2013, BUSINESS STRATEGIES AND APPROACHES FOR EFFECTIVE ENGINEERING MANAGEMENT, P237, DOI 10.4018/978-1-4666-3658-3.ch014
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren MY, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.6.063047
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy AM, 2022, NEURAL COMPUT APPL, V34, P3895, DOI 10.1007/s00521-021-06651-x
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi PF, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163243
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun C, 2021, APPL INTELL, V51, P3311, DOI 10.1007/s10489-020-01949-0
   Talaat FM, 2023, Neural Comput Appl, P1
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Ünel FÖ, 2019, IEEE COMPUT SOC CONF, P582, DOI 10.1109/CVPRW.2019.00084
   Wang C-Y, 2020, Scaled-yolov4: Scaling cross stage partial network, P2011
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang T, 2021, IEEE INT CONF COMP V, P913, DOI 10.1109/ICCVW54120.2021.00107
   Cheng XB, 2021, PATTERN ANAL APPL, V24, P1347, DOI 10.1007/s10044-021-00989-7
   Xiao-jing G., 2013, TELKOMNIKA (Telecommunication Computing Electronics and Control), V11, P759, DOI [10.12928/telkomnika.v11i4.1193, DOI 10.12928/TELKOMNIKA.V11I4.1193]
   Xu HY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0261-2
   Yonemoto N, 2018, 2018 INTERNATIONAL TOPICAL MEETING ON MICROWAVE PHOTONICS (MWP)
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu ZW, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103514
   Yuan Z-D, 2020, Journal of Physics: Conference Series, V1635
   Zhan W, 2022, SOFT COMPUT, V26, P361, DOI 10.1007/s00500-021-06407-8
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang ZX, 2022, INT J COMPUT VISION, V130, P800, DOI 10.1007/s11263-021-01569-2
   Zhong J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030997
   Zhou X, 2023, Centrenet. GitHub Repository
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu LL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183776
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 117
TC 2
Z9 2
U1 38
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17838-w
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200003
DA 2024-07-18
ER

PT J
AU Zheng, H
   Yuan, NEZ
   Ding, HW
   Hu, P
   Yang, ZJ
AF Zheng, Hang
   Yuan, Nangezi
   Ding, Hongwei
   Hu, Peng
   Yang, Zhijun
TI Thermal infrared and visible sequences tracking via dual adversarial
   pixel fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Thermal infrared image; Target tracking; Dual adversarial pixel fusion;
   Weight fusion method
ID NETWORK
AB Due to the strong complementary strengths of visible light and thermal infrared light, to overcome the limitations of visible light imaging, combining these two modes for target tracking has received considerable interest and has achieved rapid development. The original intention of introducing thermal infrared images in the field of visual tracking is to use complementary benefits of the two modalities. Therefore, how to mine more useful and complementary information from thermal infrared (T) images is the key to achieve high-quality tracking in the case of poor visible (RGB) images quality. The existing algorithms of image fusion or feature stitching do not fully exploit the correlation and complementary information between RGB and T images, and are prone to cause feature redundancy and susceptible to interference during tracking. The reliability of single-modal data changes over time, which affects the effectiveness of feature-level modal sharing, while the RGBT images obtained from pixel-level fusion contains richer information than single-peak images, which are more conducive to the sharing of modal information and the detection of tracked targets. Thus, we design a dual adversarial pixel fusion network to adaptively fuse two modal images to generate superpixels to perform modal sharing of RGBT target tracking. In addition, to obtain a more accurate tracking results, we design a new weight fusion method to infer the fusion weights of the three modalities RGB, T and RGBT to find the optimal target in each frame. We have improved the MANet algorithm using the two methods described above. A large number of experiments on two RGBT tracking datasets show that compared with the original MANet target tracking method, the proposed method achieves better tracking results in accuracy and success rate.
C1 [Zheng, Hang; Ding, Hongwei] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Peoples R China.
   [Yuan, Nangezi] Yunnan Univ Finance & Econ, Int Cooperat & Exchange Off, Kunming 650221, Peoples R China.
   [Hu, Peng] Univ Key Lab Internet Things Technol & Applicat, Yunnan Educ Dept, Kunming 650000, Peoples R China.
   [Yang, Zhijun] Youbei Technol Co LTD, Res & Dev Dept, Kunming 650000, Peoples R China.
C3 Yunnan University; Yunnan University of Finance & Economics
RP Ding, HW (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Peoples R China.
EM ynuzhengh@163.com; 806057382@qq.com; ynuhongweiding@163.com;
   2486980561@qq.com; 353738698@qq.com
RI Zheng, Hang/AGA-3832-2022
OI Zheng, Hang/0000-0002-4584-0420
FU National Natural Science Foundation of China [61461053]; National
   Natural Science Foundation of China, Research on Theory and Control
   Protocol of Converged Multiple Access Communication Network
FX The work was supported by National Natural Science Foundation of China,
   Research on Theory and Control Protocol of Converged Multiple Access
   Communication Network(Grant No. 61461053); Hongwei Ding Grassroots
   Expert Workstation in Yunnan Province.
CR Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Chen Z., 2017, GradNorm: gradient normalization for adaptive loss balancing in deep multitask networks
   Chenglong Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P222, DOI 10.1007/978-3-030-58542-6_14
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Gao Y, 2019, IEEE INT CONF COMP V, P91, DOI 10.1109/ICCVW.2019.00017
   Hou Y, 2018, Robust night target tracking via infrared and visible video fusion, P6
   Jiang B, 2018, ARXIV
   Jingchao P., 2021, arXiv
   Li CL, 2022, IEEE T IMAGE PROCESS, V31, P392, DOI 10.1109/TIP.2021.3130533
   Li CL, 2019, IEEE INT CONF COMP V, P2262, DOI 10.1109/ICCVW.2019.00279
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li CL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1856, DOI 10.1145/3123266.3123289
   Li CL, 2018, LECT NOTES COMPUT SC, V11217, P831, DOI 10.1007/978-3-030-01261-8_49
   Li CL, 2018, SIGNAL PROCESS-IMAGE, V68, P207, DOI 10.1016/j.image.2018.08.004
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Lu AD, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3157594
   Lu AD, 2021, IEEE T IMAGE PROCESS, V30, P5613, DOI 10.1109/TIP.2021.3087341
   Luo CW, 2019, INFRARED PHYS TECHN, V99, P265, DOI 10.1016/j.infrared.2019.04.017
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang X, 2023, IEEE T MULTIMEDIA, V25, P4335, DOI 10.1109/TMM.2022.3174341
   Wang YL, 2018, LECT NOTES COMPUT SC, V11259, P295, DOI 10.1007/978-3-030-03341-5_25
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie ZL, 2022, J MANUF SYST, V62, P301, DOI 10.1016/j.jmsy.2021.12.003
   Xu NW, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2018), P44, DOI 10.1145/3198910.3198918
   Zhang H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020393
   Zhang LC, 2019, IEEE INT CONF COMP V, P2252, DOI 10.1109/ICCVW.2019.00278
   Zhang PY, 2022, PROC CVPR IEEE, P8876, DOI 10.1109/CVPR52688.2022.00868
   Zhang PY, 2021, IEEE T IMAGE PROCESS, V30, P3335, DOI 10.1109/TIP.2021.3060862
   Zhang XC, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019), DOI 10.23919/fusion43075.2019.9011253
   Zhu YB, 2021, IEEE T INTELL VEHICL, V6, P121, DOI 10.1109/TIV.2020.2980735
   Zhu YB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P465, DOI 10.1145/3343031.3350928
NR 36
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 23
PY 2023
DI 10.1007/s11042-023-17721-8
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DO9H2
UT WOS:001133108800004
DA 2024-07-18
ER

PT J
AU Tian, SS
   Chen, RF
   Zou, WB
   Li, X
AF Tian, Shishun
   Chen, Ruifeng
   Zou, Wenbin
   Li, Xia
TI MI-RPN: Integrating multi-modalities and multi-scales information for
   region proposal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Region proposal; RGB-D; Feature pyramid; MI-RPN
AB Region proposal is crucial for the two-stage object detectors. Recently, the RGB-based region proposal approaches have achieved impressive progress. However, they still suffer from two problems: (1) RGB images only contain the texture information of objects, while the 3D geometric structure information which is also important for detection is neglected. (2) in a typical Feature Pyramid Network (FPN), the upsampling operation only models the corresponding relation between adjacent locations, the texture structure is not taken into consideration. Besides, the addition operation in FPN ignores the importance of different channels which may affect the propagation of semantic information. In this paper, we propose a Region Proposal Network using Multi-modalities and multi-scales Information (named MI-RPN). Firstly, we propose a Gate-guided Fusion Module (GFM) to fuse the RGB and depth features which respectively contain the texture and geometric information. Secondly, we propose a Flow-guided Upsample Feature Pyramid Network (FUFPN) to optimize the multi-scales feature fusion in typical FPN by taking features of an adjacent layer into consideration. Experimental results on SUNRGBD, NYUv2, and KITTI show that MI-RPN achieves superior results compared to current state-of-the-art methods. Besides, we replace the RPN in typical two-stage object detection models to test the effectiveness of the proposed MI-RPN. The results show that MI-RPN can significantly improve the accuracy of two-stage object detection models.
C1 [Tian, Shishun; Chen, Ruifeng; Zou, Wenbin; Li, Xia] Shenzhen Univ, Guangdong Prov Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Tian, Shishun; Chen, Ruifeng; Zou, Wenbin; Li, Xia] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.
   [Zou, Wenbin] Shenzhen Univ, Shenzhen Key Lab Adv Machine Learning & Applicat, Shenzhen 518060, Peoples R China.
C3 Shenzhen University; Shenzhen University; Shenzhen University
RP Zou, WB (corresponding author), Shenzhen Univ, Guangdong Prov Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.; Zou, WB (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518060, Peoples R China.; Zou, WB (corresponding author), Shenzhen Univ, Shenzhen Key Lab Adv Machine Learning & Applicat, Shenzhen 518060, Peoples R China.
EM stian@szu.edu.cn; 1910433032@email.szu.edu.cn; wzou@szu.edu.cn;
   lixia@szu.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Blum M, 2012, IEEE INT CONF ROBOT, P1298, DOI 10.1109/ICRA.2012.6225188
   Bo LF, 2011, PROC CVPR IEEE, P1729, DOI 10.1109/CVPR.2011.5995719
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao JX, 2020, Arxiv, DOI [arXiv:2005.11475, DOI 10.48550/ARXIV.2005.11475]
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Deng L., 2019, arXiv
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Ghosh R, 2021, MULTIMED TOOLS APPL, V80, P25985, DOI 10.1007/s11042-021-10954-5
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50
   Ji W, 2021, PROC CVPR IEEE, P9466, DOI 10.1109/CVPR46437.2021.00935
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Pérez-Gil O, 2022, MULTIMED TOOLS APPL, V81, P3553, DOI 10.1007/s11042-021-11437-3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sung CS, 2021, MULTIMED TOOLS APPL, V80, P34311, DOI 10.1007/s11042-021-10931-y
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vu T., 2019, 33 C NEUR INF PROC S
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang TY, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1490, DOI 10.1109/ICASSP39728.2021.9414883
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Xu XY, 2017, PATTERN RECOGN, V72, P300, DOI 10.1016/j.patcog.2017.07.026
   Yao YY, 2020, MULTIMED TOOLS APPL, V79, P9645, DOI 10.1007/s11042-017-4820-9
   Zhang XD, 2021, MULTIMED TOOLS APPL, V80, P23723, DOI 10.1007/s11042-020-10231-x
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou XF, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116591
   Zhu JM, 2021, MULTIMED TOOLS APPL, V80, P15469, DOI 10.1007/s11042-021-10574-z
   Zhu LX, 2022, NEUROCOMPUTING, V483, P127, DOI 10.1016/j.neucom.2022.02.016
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou WB, 2021, IEEE T IMAGE PROCESS, V30, P4084, DOI 10.1109/TIP.2021.3069547
NR 49
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-16484-6
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR5X2
UT WOS:001126994000001
DA 2024-07-18
ER

PT J
AU Zhang, HX
   Cheng, DQ
   Jiang, H
   Liu, JJ
   Kou, QQ
AF Zhang, Haoxiang
   Cheng, Deqiang
   Jiang, He
   Liu, Jingjing
   Kou, Qiqi
TI Task-like training paradigm in CLIP for zero-shot sketch-based image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Zero-shot sketch-based image retrieval; Text prompt tutoring; Text-based
   identification learning; Cross-modal consistency learning; Collaborative
   architecture
AB The Contrastive Language-Image Pre-training model (CLIP) has recently gained attention in the zero-shot domain. However it still falls short in addressing cross-modal perception, and the semantic gap between seen and unseen classes in Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR). To overcome these obstacles, we propose a Task-Like Training paradigm (TLT). In this work, we view the cross-modal perception and the semantic gap as a multi-task learning process. Before tackling the challenges, we fully utilize CLIP's text encoder and propose text-based identification learning mechanism to assist the model to learn discriminative features quickly. Next, we propose text prompt tutoring and the cross-modal consistency learning to solve cross-modal perception and the semantic gap, respectively. Meanwhile, we present a collaborative architecture to explore the potential shared information between tasks. Extensive results show that our approach significantly outperforms the state-of-the-art methods on Sketchy, Sketchy-No, Tuberlin, and QuickDraw datasets.
C1 [Zhang, Haoxiang; Cheng, Deqiang; Jiang, He; Liu, Jingjing] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Kou, Qiqi] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Cheng, DQ; Jiang, H (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM zhanghx@cumt.edu.cn; chengdq@cumt.edu.cn; jianghe@cumt.edu.cn;
   liujingjing@cumt.edu.cn; kouqiqi@cumt.edu.cn
OI Jiang, He/0000-0002-3345-9665
FU National Natural Science Foundation of China [52204177, 52304182];
   National Natural Science Foundation of China [2020QN49]; Fundamental
   Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 52204177 and Grant 52304182, and in part
   by the Fundamental Research Funds for the Central Universities under
   Grant 2020QN49.
CR Almeida F, 2023, Arxiv, DOI arXiv:1901.09069
   Deng C, 2020, IEEE T IMAGE PROCESS, V29, P8892, DOI 10.1109/TIP.2020.3020383
   Dey S, 2019, PROC CVPR IEEE, P2174, DOI 10.1109/CVPR.2019.00228
   Dutta A, 2019, PROC CVPR IEEE, P5084, DOI 10.1109/CVPR.2019.00523
   Dutta T, 2021, IEEE T MULTIMEDIA, V23, P2833, DOI 10.1109/TMM.2020.3017918
   Ermolov A, 2022, PROC CVPR IEEE, P7399, DOI 10.1109/CVPR52688.2022.00726
   Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354
   Han C, 2023, P IEEE CVF INT C COM, P17491
   Han C, 2022, Multimedia Tools and Applications, P1
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang ZH, 2021, Arxiv, DOI arXiv:2112.07966
   Jiang H, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16914-5
   Jiao SC, 2022, NEURAL COMPUT APPL, V34, P13469, DOI 10.1007/s00521-022-07169-6
   Jing TT, 2022, IEEE T IMAGE PROCESS, V31, P3657, DOI 10.1109/TIP.2022.3173815
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JT, 2022, COMPUT VIS IMAGE UND, V218, DOI 10.1016/j.cviu.2022.103412
   Liang J, 2023, CLUSTSEG: Clustering for Universal Segmentation
   Lin FY, 2023, Arxiv, DOI arXiv:2303.14348
   Lin KY, 2020, AAAI CONF ARTIF INTE, V34, P11515
   Liu XD, 2019, Arxiv, DOI arXiv:1901.11504
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712
   Qing Liu, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P3661, DOI 10.1109/ICCV.2019.00376
   Radford A, 2021, PR MACH LEARN RES, V139
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sain A, 2023, Arxiv, DOI arXiv:2303.13440
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tian JL, 2022, AAAI CONF ARTIF INTE, P2370
   Tian JL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5473, DOI 10.1145/3474085.3475676
   Tursun O, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108528
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang HJ, 2022, IEEE T PATTERN ANAL, V44, P7253, DOI 10.1109/TPAMI.2021.3092177
   Wang K, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548382
   Wang W., 2022, Adv. Neural Inf. Process. Syst., V35, P12826
   Wang W. J., 2021, IJCAI, P1106, DOI 10.24963/ijcai.2021/153
   Wang ZP, 2021, Arxiv, DOI arXiv:2106.11841
   Xu XX, 2022, Arxiv, DOI arXiv:2003.09869
   Yan L, 2023, P INT JOINT C ART IN, P1622
   Yan LQ, 2022, IEEE T CIRC SYST VID, V32, P6642, DOI [10.1109/TCSVT.2022.3177320, 10.1109/tcsvt.2022.3177320]
   Yang Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1286, DOI 10.1145/2964284.2964319
   Yang ZT, 2021, IEEE SIGNAL PROC LET, V28, P264, DOI 10.1109/LSP.2020.3043972
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Zhan Yu-Wei, 2022, arXiv
   Zhang H., 2023, P IEEE INT C AC SPEE, P1
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhang RR, 2021, Arxiv, DOI arXiv:2111.03930
   Zhang ZL, 2020, AAAI CONF ARTIF INTE, V34, P12943
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zhu JP, 2020, IEEE INT SYMP CIRC S
NR 52
TC 0
Z9 0
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17675-x
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200005
DA 2024-07-18
ER

PT J
AU Dheepa, G
   Chithra, P
AF Dheepa, G.
   Chithra, PL.
TI SPFC NET: Spatial pyramid feature convolution network for brain tumor
   segmentation in mri images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumor segmentation; Magnetic resonance imaging (MRI); SPFC net;
   Tissue-type mapping
ID CONCRETE COMPRESSIVE STRENGTH; MECHANICAL-PROPERTIES; PREDICTION
AB Accurate segmentation of brain tumor from Magnetic Resonance Imaging (MRI) is an essential task for medical assessments like treatment planning and evaluation. The 3-Dimensional nature of MRI images poses challenges, like memory and computational power. This research work proposed a novel SPFC network (Spatial Pyramid Feature Convolution network) to overwhelm existing limitations and effectively segment complete, core and enhanced tumor regions from MRI brain images. All image slices from BRATS-2018 training dataset are first pre-processed using a contour curve to remove the insignificant background pixels. Then, these pre-processed slices are subsequently processed again in the SPFC network to extract the spatial features from all input slices through the cascaded pyramidal convolutions. This SPFC network contains two kinds of layers: downsampling layers composed with the hierarchy of three SPF (Spatial Pyramid Feature) blocks and two max-pooling; upsampling layers containing the hierarchy of two unpooling and two SPF blocks. The outcome of upsampling layers is then processed using a sigmoid function for segmenting complete, core and enhanced tumor regions. Further, a tissue-type mapping technique is effectively applied over these segmented tumor regions to find the tumor volume and their probability density distribution. It is observed that the proposed method achieves an F1-score of 0.95, 0.97 and 0.99 for complete, core and enhanced regions, which is 7%, 21% and 22% of higher results respectively than the state-of-art segmentation methods.
C1 [Dheepa, G.] SRM Inst Sci & Technol, Coll Sci & Humanities, Dept Comp Sci MCA, Chennai 600089, Tamilnadu, India.
   [Chithra, PL.] Univ Madras, Dept Comp Sci, Chennai 600025, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; University of Madras
RP Chithra, P (corresponding author), Univ Madras, Dept Comp Sci, Chennai 600025, Tamil Nadu, India.
EM dheepa.hema@gmail.com; chitrasp2001@yahoo.com
CR Abu Yaman M, 2017, ALEX ENG J, V56, P523, DOI 10.1016/j.aej.2017.04.007
   Al-Musawi AA, 2020, ENG COMPUT-GERMANY, V36, P1, DOI 10.1007/s00366-018-0681-8
   Amar M, 2022, MATERIALS, V15, DOI 10.3390/ma15207045
   B K A MAR, 2021, INFRASTRUCTURES-BASE, V6, DOI 10.3390/infrastructures6020017
   Basyigit C, 2012, CONSTR BUILD MATER, V37, P526, DOI 10.1016/j.conbuildmat.2012.07.055
   Ben Chaabene W, 2020, CONSTR BUILD MATER, V260, DOI 10.1016/j.conbuildmat.2020.119889
   Chen HG, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12030302
   Chopra Palika., 2015, INT J APPL SCI ENG, V13, P187
   Drugan WJ, 1996, J MECH PHYS SOLIDS, V44, P497, DOI 10.1016/0022-5096(96)00007-5
   Duan ZH, 2013, CONSTR BUILD MATER, V44, P524, DOI 10.1016/j.conbuildmat.2013.02.064
   Vu DT, 2016, STRUCT INFRASTRUCT E, V12, P1153, DOI 10.1080/15732479.2015.1086386
   El Said B, 2023, INT J SOLIDS STRUCT, V276, DOI 10.1016/j.ijsolstr.2023.112334
   Feng DC, 2020, CONSTR BUILD MATER, V230, DOI 10.1016/j.conbuildmat.2019.117000
   Frankel AL, 2019, COMP MATER SCI, V169, DOI 10.1016/j.commatsci.2019.109099
   Gholami K, 2023, J COMPOS SCI, V7, DOI 10.3390/jcs7020054
   Gupta T, 2021, NEURAL COMPUT APPL, V33, P6951, DOI 10.1007/s00521-020-05470-w
   Haghighi E.M., 2022, arXiv
   Han ZY, 2021, IEEE SENS J, V21, P7833, DOI 10.1109/JSEN.2019.2923982
   Joshi DA, 2023, EXPERT SYST APPL, V233, DOI 10.1016/j.eswa.2023.120925
   Keshtegar B, 2019, COMPOS STRUCT, V212, P230, DOI 10.1016/j.compstruct.2019.01.004
   Koya BP, 2022, MECH ADV MATER STRUC, V29, P4032, DOI 10.1080/15376494.2021.1917021
   Li FF, 2023, INT J MIN MET MATER, V30, P1093, DOI 10.1007/s12613-022-2536-y
   Muliauwan HN, 2020, J PHYS CONF SER, V1625, DOI 10.1088/1742-6596/1625/1/012018
   Putri AR, 2021, I C INF COMM TECH CO, P1754, DOI 10.1109/ICTC52510.2021.9620781
   Sarveghadi M, 2019, NEURAL COMPUT APPL, V31, P2085, DOI 10.1007/s00521-015-1997-6
   Shaswat K, 2021, COMPUT J, V64, P909, DOI 10.1093/comjnl/bxaa197
   Singh P, 2023, INT J INTERACT DES M, DOI 10.1007/s12008-023-01386-6
   Xu JJ, 2019, CONSTR BUILD MATER, V211, P479, DOI 10.1016/j.conbuildmat.2019.03.234
   Yan HJ, 2018, WIRELESS PERS COMMUN, V102, P683, DOI 10.1007/s11277-017-5086-2
   Yang L, 2020, IEEE ACCESS, V8, P107185, DOI 10.1109/ACCESS.2020.3000960
   Ye F, 2017, Arxiv, DOI arXiv:1703.03930
   Ye S, 2019, APPL PHYS LETT, V115, DOI 10.1063/1.5124529
   Ziolkowski P, 2019, MATERIALS, V12, DOI 10.3390/ma12081256
NR 33
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17738-z
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800012
DA 2024-07-18
ER

PT J
AU Devi, TAM
   Hepzibai, R
AF Devi, T. Arumuga Maria
   Hepzibai, R.
TI Diabetic foot ulcer classification of hybrid convolutional neural
   network on hyperspectral imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic foot ulcers; Classification; Deep learning; Convolution neural
   networks; Support Vector Machine
AB Diabetic foot ulcer is a chief distress of diabetes mellitus. The diabetic foot ulcer (DFU) is the extremely injurious dilemma associated to diabetes mellitus. DFU is a risky illness, and it desires customary cure or else it might direct to foot amputation. When not treated it leads to some health issues and hence a novel method is proposed for efficient classification of DFU images. The DFU in this research is categorized into four classes like normal foot, high risk foot, ulcerated foot, and infected foot. Initially, a DFU dataset is made utilizing hyperspectral DFU images and pre-processing is done with aid of adaptive median filter. Consequently, the image is segmented by improved fuzzy c-means - particle swarm optimization algorithm. Then, a count of second order statistical texture features comprising entropy, energy; correlation, homogeneity, and contrast are produced via Gray Level Co-occurrence Matrix (GLCM). Finally, images are classified with aid of novel hybrid convolution neural network along with support vector machine. Here the novelty is derived by use of a new regularizer. The experiment is done with a manually created dataset. The performance evaluation is done by computing recall, precision, F1-score and accuracy. The results are compared with existing algorithms that show that the proposed hybrid system gives high classification accuracy.
C1 [Devi, T. Arumuga Maria; Hepzibai, R.] Manonmaniam Sundaranar Univ, Ctr Informat Technol & Engn, Tirunelveli Rd,Abishekapatti, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Devi, TAM (corresponding author), Manonmaniam Sundaranar Univ, Ctr Informat Technol & Engn, Tirunelveli Rd,Abishekapatti, Tirunelveli 627012, Tamil Nadu, India.
EM arumughadevi01@gmail.com; hepsib955@gmail.com
CR Alzubaidi L, 2020, MULTIMED TOOLS APPL, V79, P15655, DOI 10.1007/s11042-019-07820-w
   Amin J, 2020, IEEE ACCESS, V8, P228586, DOI 10.1109/ACCESS.2020.3045732
   Babu K., 2018, Int. J. Eng. Technol., V7, P1006
   Calin MA, 2019, ANN C MED IM UND AN, V1065
   Padierna LC, 2020, INFRARED PHYS TECHN, V111, DOI 10.1016/j.infrared.2020.103531
   Cassidy B, 2020, arXiv
   Cruz-Vega I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061762
   Oliveira ALD, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP, P677, DOI 10.5220/0010255506770684
   Das SK, 2022, ICT EXPRESS, V8, P271, DOI 10.1016/j.icte.2021.08.022
   Das SK, 2022, INT J IMAG SYST TECH, V32, P192, DOI 10.1002/ima.22598
   Devi T.A.M., 2021, ANN ROMAN SOC CELL B, V25, P15670
   Devi T.A.M., 2020, SOLID STATE TECHNOL, V63, P4234
   Devi TAM, 2023, IETE J RES, V69, P8705, DOI 10.1080/03772063.2022.2099469
   Gamage C, 2019, IEEE INT C BIOINF BI, P352, DOI 10.1109/BIBE.2019.00069
   Goyal M, 2020, COMPUT BIOL MED, V117, DOI 10.1016/j.compbiomed.2020.103616
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Goyal M, 2019, IEEE J BIOMED HEALTH, V23, P1730, DOI 10.1109/JBHI.2018.2868656
   Jain AKC., 2018, Int J Surg Sci, V2, P26, DOI [10.33545/surgery.2018.v2.i4a.43, DOI 10.33545/SURGERY.2018.V2.I4A.43]
   Jeffcoate WJ, 2015, DIABETIC MED, V32, P798, DOI 10.1111/dme.12778
   Mekhmoukh A, 2015, COMPUT METH PROG BIO, V122, P266, DOI 10.1016/j.cmpb.2015.08.001
   Mennes OA, 2018, CURR PHARM DESIGN, V24, P1304, DOI 10.2174/1381612824666180302141902
   Monteiro-Soares M, 2020, DIABETES-METAB RES, V36, DOI 10.1002/dmrr.3273
   Olaniyi EO, 2017, J FOOD PROCESS ENG, V40, DOI 10.1111/jfpe.12575
   Peng X, 2019, IOP C SER EARTH ENV, V267, DOI 10.1088/1755-1315/267/4/042081
   Rania Niri, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P162, DOI 10.1007/978-3-030-51935-3_17
   Rostami B, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104536
   Smith-Strom H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177176
   Sorna P.G., 2016, International Journal of InformationTechnology & Management Information System, IJITMIS, V7, P36
   Sutojo T, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P182, DOI 10.1109/ICITISEE.2017.8285491
   Syafril S, 2018, IOP C SER EARTH ENV, V125, DOI 10.1088/1755-1315/125/1/012161
   Wang CH, 2015, IEEE ENG MED BIO, P2415
   Wang LF, 2020, IEEE T BIO-MED ENG, V67, P1989, DOI 10.1109/TBME.2019.2953630
   Wang S, 2017, IEEE T BIO-MED ENG, V64, P990, DOI [10.1109/TBME.2016.2585344, 10.1109/TBME.2016.2632522]
   Yang Q, 2018, J IMAGING, V4, DOI 10.3390/jimaging4120144
NR 34
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17710-x
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300008
DA 2024-07-18
ER

PT J
AU Liao, Y
   Yan, LJ
   Hou, ZY
   Shi, SJ
   Fu, ZE
   Ma, Y
AF Liao, Yuan
   Yan, Lijun
   Hou, Zeyu
   Shi, Shujian
   Fu, Zhao'e
   Ma, Yan
TI CutGAN: dual-Branch generative adversarial network for paper-cut image
   generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chinese paper-cutting; Generative adversarial network; Pre-training;
   Skip connection; Image generation
AB Chinese paper-cutting, as an ancient folk art, is facing difficulties in preserving and passing down its traditions due to a lack of skilled paper-cut artists. In contrast to other image generation tasks, paper-cut images not only necessitate symmetry and exaggeration but also demand a certain level of resemblance to human facial features. To address these issues, this paper proposes a dual-branch generative adversarial network model for automatically generating paper-cut images, referred to as CutGAN. Specifically, we first construct a paper-cut dataset consisting of 891 pairs of facial images and handcrafted paper-cut images to train and evaluate CutGAN. Next, during the pre-training phase, we utilize gender and eyeglasses recognition tasks to train the fixed encoder. In the fine-tuning phase, we design a flexible encoder based on the modified U-net structure without skip connections. Furthermore, we introduce an average face loss to augment the diversity and improve the quality of the generated paper-cut images. We conducted extensive qualitative and quantitative experiments, as well as ablation experiments, comparing CutGAN with state-of-the-art baseline models on the test set. The experimental results indicate that CutGAN outperforms other image translation models by generating paper-cut images that more accurately capture the essence of Chinese paper-cut art and closely resemble actual facial images.
C1 [Liao, Yuan; Yan, Lijun; Hou, Zeyu; Ma, Yan] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
   [Shi, Shujian] Shanghai Normal Univ, Coll Artificial Intelligence, Tianhua Coll, Shanghai, Peoples R China.
   [Fu, Zhao'e] Ningxia Art Alliance Cultural & Artist Prod Co Ltd, Ningxia, Peoples R China.
C3 Shanghai Normal University; Shanghai Normal University
RP Yan, LJ; Ma, Y (corresponding author), Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
EM flying@shnu.edu.cn; ma-yan@shnu.edu.cn
RI Zhang, Lu/KHE-5879-2024; zhao, wei/JZD-4475-2024; Liu,
   Chenyu/KBQ-8899-2024; CHEN, MINGWEI/KHT-6744-2024; Li,
   Xintong/KHD-6915-2024; tong, li/KDO-7821-2024; Liu,
   Donghua/KEJ-1974-2024
OI Liu, Donghua/0000-0002-5830-9540; , Yan/0000-0003-4626-1401
FU National Natural Science Foundation of China [61373004]
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant no. 61373004).
CR Back J., 2021, arXiv
   Bińkowski M, 2021, Arxiv, DOI [arXiv:1801.01401, DOI 10.48550/ARXIV.1801.01401]
   Cai GY, 2020, IEEE T NEUR NET LEAR, V31, P3073, DOI 10.1109/TNNLS.2019.2935384
   Chandaliya PK, 2023, NEURAL COMPUT APPL, V35, P2811, DOI 10.1007/s00521-022-07721-4
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Huan Liang, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1516, DOI 10.1109/ICCT46805.2019.8947072
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Islam MR, 2023, Eur J Sci Innov Technol, V3, P219
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karetzky PE., 2022, The J Asian Arts Aesthet, V8, P75
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim J, 2020, Arxiv, DOI [arXiv:1907.10830, DOI 10.48550/ARXIV.1907.10830]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li B, 2022, IEEE T MULTIMEDIA, V24, P4077, DOI 10.1109/TMM.2021.3113786
   Li MJ, 2018, LECT NOTES COMPUT SC, V11213, P186, DOI 10.1007/978-3-030-01240-3_12
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Mo SW, 2020, Arxiv, DOI arXiv:2002.10964
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Ojha U, 2021, PROC CVPR IEEE, P10738, DOI 10.1109/CVPR46437.2021.01060
   Pandey N, 2020, NEUROCOMPUTING, V414, P356, DOI 10.1016/j.neucom.2020.07.092
   Peng XL, 2022, NEURAL COMPUT APPL, V34, P18075, DOI 10.1007/s00521-022-07432-w
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi YC, 2019, PROC CVPR IEEE, P10754, DOI 10.1109/CVPR.2019.01102
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang YX, 2018, LECT NOTES COMPUT SC, V11210, P220, DOI 10.1007/978-3-030-01231-1_14
   Xiong L, 2018, Arxiv, DOI [arXiv:1704.00438, 10.48550/arXiv.1704.00438]
   Xu X, 2023, Int J Front Sociol, V5, DOI [10.25236/IJFS.2023.050301, DOI 10.25236/IJFS.2023.050301]
   Yan L, 2022, P 32 INT JOINT C ART, DOI [10.24963/ijcai.2023/180, DOI 10.24963/IJCAI.2023/180]
   Yan LQ, 2023, IEEE T CIRC SYST VID, V33, P393, DOI 10.1109/TCSVT.2022.3202574
   Yan LQ, 2022, IEEE T CIRC SYST VID, V32, P6642, DOI [10.1109/TCSVT.2022.3177320, 10.1109/tcsvt.2022.3177320]
   Yaxing Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9329, DOI 10.1109/CVPR42600.2020.00935
   Yu J, 2021, IEEE T CYBERNETICS, V51, P4350, DOI 10.1109/TCYB.2020.2972944
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao J, 2022, NEUROCOMPUTING, V506, P355, DOI 10.1016/j.neucom.2022.07.084
   Zhao JF, 2023, COMPUT ELECTRON AGR, V205, DOI 10.1016/j.compag.2022.107583
   Zhao JF, 2023, J SCI FOOD AGR, V103, P1912, DOI 10.1002/jsfa.12318
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 51
TC 0
Z9 0
U1 8
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 2
PY 2023
DI 10.1007/s11042-023-17746-z
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AV0F5
UT WOS:001121103400004
DA 2024-07-18
ER

PT J
AU Roldán-Alvarez, D
   Cañas, JM
   Valladares, D
   Arias-Perez, P
   Mahna, S
AF Roldan-Alvarez, David
   Canas, Jose M.
   Valladares, David
   Arias-Perez, Pedro
   Mahna, Sakshay
TI Unibotics: open ROS-based online framework for practical learning of
   robotics in higher education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Distance learning; Engineering education; Intelligent robotics
ID TECHNOLOGY; STUDENTS; SCIENCE; SIMULATIONS; PERFORMANCE; EXPERIENCES;
   PARALLEL; PLATFORM
AB Robotics provides an increasing number of solutions for real-life problems, from autonomous driving to automatic cleaning, inspection and logistics. The demand of robotics education to train future engineers is also growing, both in regular degrees at universities and also in massive open online courses (MOOCs). Beyond theory lectures, robotics education typically requires hands-on and practiced robot programming to be effective and let the student develop the desired skills. This paper presents Unibotics, an open online learning platform that allows editing and running robot programs from the browser, and provides more than 20 academic units on service robotics, autonomous driving, drones, and mobile robotics. It uses state-of-the art open source robot simulator (Gazebo) and robot middleware (ROS), and so it is extensible with new exercises. It is intended as a tool for practical learning in robotics engineering university courses. The platform has been used by 130 students from four different university degrees. Furthermore, it has been experimentally validated at the Universidad Rey Juan Carlos (URJC) Master Degree in Computer Vision with 22 students.
C1 [Roldan-Alvarez, David; Canas, Jose M.; Valladares, David] Univ Rey Juan Carlos, Madrid, Spain.
   [Arias-Perez, Pedro] Univ Politecn Madrid, Madrid, Spain.
   [Mahna, Sakshay] JdeRobot Org, Madrid, Spain.
C3 Universidad Rey Juan Carlos; Universidad Politecnica de Madrid
RP Roldán-Alvarez, D (corresponding author), Univ Rey Juan Carlos, Madrid, Spain.
EM david.roldan@urjc.es; josemaria.plaza@urjc.es;
   d.valladaresv@alumnos.urjc.es; pedro.ariasp@upm.es;
   10280031@vip.henu.edu.cn
OI Roldan, David/0000-0001-7049-7460; Arias-Perez,
   Pedro/0000-0001-7166-9367
FU Community of Madrid [S2018/NMT-4331]
FX This research was partially funded by the Community of Madrid in the
   framework of the research project RoboCity2030-DIH-CM (2019-2022):
   RoboCity2030-Madrid Robotics Digital Innovation Hub, Programa de
   Actividades de I+D entre Grupos de investigacion de la Comunidad de
   Madrid en Tecnologias 2018 project ref. S2018/NMT-4331. Authors
   appreciate the help of Google for improving RoboticsAcademy through the
   Google Summer of Code program since 2017.
CR Avila EA, 2022, IEEE GLOB ENG EDUC C, P559, DOI 10.1109/EDUCON52537.2022.9766583
   Amsters R, 2020, ADV INTELL SYST COMP, V1023, P170, DOI 10.1007/978-3-030-26945-6_16
   [Anonymous], 2015, Programming Robots with ROS: a practical introduction to the Robot Operating System
   Chunab-Rodríguez MA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147277
   Berenguel M, 2016, COMPUT APPL ENG EDUC, V24, P202, DOI 10.1002/cae.21698
   BORENSTEIN J, 1989, IEEE T SYST MAN CYB, V19, P1179, DOI 10.1109/21.44033
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cañas JM, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122163
   Canas JM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217419
   Carlone L, 2022, Visual Navigation for Autonomous Vehicles (VNAV) Course
   Casañ GA, 2018, J ROBOT, V2018, DOI 10.1155/2018/2312984
   Castillo-Pizarro P., 2010, Proceedings 2010 Latin American Robotics Symposium and Intelligent Robotic Meeting (LARS 2010), P150, DOI 10.1109/LARS.2010.19
   Cervera E, 2019, IEEE ROBOT AUTOM MAG, V26, P64, DOI 10.1109/MRA.2019.2916286
   Cervera E, 2016, J INTELL ROBOT SYST, V81, P77, DOI 10.1007/s10846-015-0201-7
   Chan SSK, 2018, 2018 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET), P162, DOI 10.1109/ISET.2018.00043
   Connolly C, 2009, IND ROBOT, V36, P540, DOI 10.1108/01439910910994605
   Corke P, 2007, IEEE ROBOT AUTOM MAG, V14, P16, DOI 10.1109/M-RA.2007.912004
   Corke P, 2021, IEEE INT CONF ROBOT, P11357, DOI 10.1109/ICRA48506.2021.9561366
   Corke P, 2016, IEEE ROBOT AUTOM MAG, V23, P81, DOI 10.1109/MRA.2016.2548779
   Corke PI, 1996, IEEE ROBOT AUTOM MAG, V3, P24, DOI 10.1109/100.486658
   Danahy E, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58249
   Daniilidis K, 2022, Robotics Perception course
   Dellaert F, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544
   Lopes MSD, 2017, IEEE T LEARN TECHNOL, V10, P526, DOI 10.1109/TLT.2016.2627565
   Escalona F, 2022, 16 INT TECHN ED DEV, P959, DOI [10.21125/inted.2022.0308, DOI 10.21125/INTED.2022.0308]
   Esposito JM, 2017, IEEE ROBOT AUTOM MAG, V24, P157, DOI 10.1109/MRA.2016.2636375
   Fabregas E, 2016, J INTELL ROBOT SYST, V81, P131, DOI 10.1007/s10846-015-0229-8
   Fernández-Ruiz R, 2023, LECT NOTE NETW SYST, V589, P463, DOI 10.1007/978-3-031-21065-5_38
   Fitter NT, 2020, IEEE ROBOT AUTOM LET, V5, P2706, DOI 10.1109/LRA.2020.2970939
   Freeman S, 2014, P NATL ACAD SCI USA, V111, P8410, DOI 10.1073/pnas.1319030111
   Ganbat D., 2018, Embed Selforganising Syst, V5, P3, DOI [10.14464/ess52416, DOI 10.14464/ESS52416]
   Garbev A, 2020, 2020 INT C AUT INF I, P1
   Gerecke U, 2007, INTELL AUTOM SOFT CO, V13, P29, DOI 10.1080/10798587.2007.10642948
   Gouws P, 2021, UnisaRxiv
   Hadgraft Roger G., 2020, Australasian Journal of Engineering Education, V25, P3, DOI 10.1080/22054952.2020.1713522
   Jara CA, 2013, COMPUT APPL ENG EDUC, V21, pE14, DOI 10.1002/cae.20542
   Jara CA, 2011, COMPUT EDUC, V57, P2451, DOI 10.1016/j.compedu.2011.07.003
   Johns K., 2009, PROFESSIONAL MICROSO
   Jung S, 2013, IEEE T EDUC, V56, P129, DOI 10.1109/TE.2012.2213601
   Khosoussi LC, 2022, Visual navigation for autonomous vehicles: An open-source hands-on robotics course at MIT
   Koenig N., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2149
   Lei M, 2022, INT J SOC ROBOT, V14, P1025, DOI 10.1007/s12369-021-00837-y
   López-Nicolás G, 2014, COMPUT APPL ENG EDUC, V22, P509, DOI 10.1002/cae.20576
   Loreto-Gómez G, 2019, INT J ELEC ENG EDUC, V56, P163, DOI 10.1177/0020720918790113
   Ma L, 2021, J STEM Educ Innov Res, V22
   Maurelli F, 2021, INT C ROB ED RIE, P81
   Mogos RI, 2018, REV ROUM SCI TECH-EL, V63, P429
   Mondada F, 2017, IEEE ROBOT AUTOM MAG, V24, P77, DOI 10.1109/MRA.2016.2636372
   Nicolescu AF, 2019, ICERI PROC, P7384
   Paull Liam, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1497, DOI 10.1109/ICRA.2017.7989179
   Peidró A, 2016, IFAC PAPERSONLINE, V49, P268, DOI 10.1016/j.ifacol.2016.07.188
   de Melo MSP, 2019, SYMP VIRTUAL AUGMENT, P242, DOI 10.1109/SVR.2019.00049
   Pinciroli C, 2012, SWARM INTELL-US, V6, P271, DOI 10.1007/s11721-012-0072-5
   Potkonjak V, 2016, COMPUT EDUC, V95, P309, DOI 10.1016/j.compedu.2016.02.002
   Pozzi M, 2018, INT C ROB ED RIE 201, P71
   Reich J, 2019, SCIENCE, V363, P130, DOI 10.1126/science.aav7958
   Rohmer E, 2013, IEEE INT C INT ROBOT, P1321, DOI 10.1109/IROS.2013.6696520
   Roldan-Alvarez D., 2021, INT C ROB ED RIE, P243
   Roy N, 2022, Udacity
   Shi J, 2022, Robotics: Vision Intelligence and Machine Learning course
   Shibata M, 2021, IEEE T EDUC, V64, P283, DOI 10.1109/TE.2020.3041667
   Siegwart R, 2022, Autonomous Mobile Robots course
   Sturm J, 2022, Autonomous Navigation for Flying Robots course
   Tani J, 2022, Self-driving cars with Duckietown course
   Tellez R, 2017, ADV INTELL SYST, V457, P143, DOI 10.1007/978-3-319-42975-5_14
   Thrun S, 2022, Artificial Intelligence for Robotics Nanodegree program
   Tselegkaridis S, 2021, EDUC SCI, V11, DOI 10.3390/educsci11010011
   Ubell R, 2017, IEEE SPECTRUM, V54, P22
   Waslander S, 2022, Self-Driving Cars Specialization course
   Xie MZ, 2018, IOP CONF SER-MAT SCI, V428, DOI 10.1088/1757-899X/428/1/012069
NR 70
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17514-z
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900007
DA 2024-07-18
ER

PT J
AU Zhu, HG
   Wang, JY
   Zhou, YE
   Gao, Z
   Zhang, LB
AF Zhu, Hegui
   Wang, Jiayi
   Zhou, Yange
   Gao, Zhan
   Zhang, Libo
TI Few-shot semantic segmentation via multi-level feature extraction and
   multi-prototype localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Few-shot semantic segmentation; Multi-prototypes; Unsupervised gaussian
   mixture model; Prototypes generation; Prototype localization
ID AGGREGATION; NETWORK
AB Few-shot Semantic Segmentation (FSS) segments query images only by using a few support images with ground truth. The existing methods usually extract a single prototype from the support image feature, which results in the spatial information loss. In this paper, we propose an end-to-end multi-level feature extraction and multi-prototype localization network named MMLNet for few-shot semantic segmentation, which consists of a multi-level feature extraction network, a Prototypes Generation (PG) module, a Prototype Localization (PL) module and a Self-Reinforcing Prototypes Generation(SRPG) module. The multi-level feature extraction network extracts features of different levels and projects them to a uniform size. Then, the PG module is employed to obtain multi-prototypes by an unsupervised Gaussian mixture model with hidden variables, which can get more comprehensive low-level and high-level information. Moreover, the PL module locates the foreground prototypes and guides the activation of foreground-related feature channels, then obtains the foreground and background probability maps. Finally, the SRPG module uses query prototypes to match query features, which can effectively capture the deep consistent features of query objects to match query features appropriately. Experimental results illustrate that the proposed MMLNet can achieve 66.33% and 35.89% mIoU with ResNet-50 backbone in the 1-shot setting of PASCAL-5i and COCO-20i without any post-processing refinement, which is the best performance in all comparable methods. It also verifies the effectiveness and performance of the proposed model.
C1 [Zhu, Hegui; Wang, Jiayi; Zhou, Yange; Gao, Zhan] Northeastern Univ, Coll Sci, Shenyang 110819, Peoples R China.
   [Zhang, Libo] Gen Hosp Northern Theater Command Chinese PLA, Dept Orthoped, Shenyang 110016, Peoples R China.
C3 Northeastern University - China
RP Zhu, HG (corresponding author), Northeastern Univ, Coll Sci, Shenyang 110819, Peoples R China.; Zhang, LB (corresponding author), Gen Hosp Northern Theater Command Chinese PLA, Dept Orthoped, Shenyang 110016, Peoples R China.
EM zhuhegui@mail.neu.edu.cn; zlb19782002@163.com
FU This study was funded by the Natural Science Foundation of Liaoning
   Province (NO. 2020-MS-080), and the National Key Research and
   Development Program of China (NO. 2017YFF0108800). [2020-MS-080];
   Natural Science Foundation of Liaoning Province [2017YFF0108800];
   National Key Research and Development Program of China
FX This study was funded by the Natural Science Foundation of Liaoning
   Province (NO. 2020-MS-080), and the National Key Research and
   Development Program of China (NO. 2017YFF0108800).
CR Alfassy A, 2019, PROC CVPR IEEE, P6541, DOI 10.1109/CVPR.2019.00671
   Boudiaf M, 2021, PROC CVPR IEEE, P13974, DOI 10.1109/CVPR46437.2021.01376
   Boyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P763, DOI 10.1007/978-3-030-58598-3_45
   Chen H, 2023, Arxiv, DOI arXiv:2303.06304
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dong N., 2018, BMVC, V4, P4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan Q, 2022, LECT NOTES COMPUT SC, V13679, P701, DOI 10.1007/978-3-031-19800-7_41
   Finn C, 2017, PR MACH LEARN RES, V70
   Gairola S, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P573
   Gao GY, 2022, IEEE T IMAGE PROCESS, V31, P6733, DOI 10.1109/TIP.2022.3215905
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He H, 2021, AAAI, DOI [10.1609/aaai.v35i2.16243, DOI 10.1609/AAAI.V35I2.16243]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S., 2021, arXiv
   Hwang JJ, 2019, IEEE I CONF COMP VIS, P7333, DOI 10.1109/ICCV.2019.00743
   Iqbal E, 2022, arXiv
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Nguyen K, 2019, IEEE I CONF COMP VIS, P622, DOI 10.1109/ICCV.2019.00071
   Kim S, 2021, Arxiv, DOI [arXiv:2110.08954, 10.48550/arXiv.2110.08954, DOI 10.48550/ARXIV.2110.08954]
   Li G, 2021, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR46437.2021.00823
   Li HY, 2019, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2019.00009
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu BH, 2021, PROC CVPR IEEE, P9742, DOI 10.1109/CVPR46437.2021.00962
   Liu BH, 2021, IEEE T IMAGE PROCESS, V30, P3142, DOI 10.1109/TIP.2021.3058512
   Liu HF, 2023, Arxiv, DOI [arXiv:2301.08160, 10.1109/TMM.2023.3238521]
   Liu J, 2023, Arxiv, DOI arXiv:2301.03194
   Liu J, 2022, PROC CVPR IEEE, P11543, DOI 10.1109/CVPR52688.2022.01126
   Liu JL, 2020, Arxiv, DOI [arXiv:2002.03579, 10.48550/arXiv.2002.03579]
   Liu WD, 2022, INT J COMPUT VISION, V130, P3140, DOI 10.1007/s11263-022-01677-7
   Liu Y., 2020, P EUR C COMP VIS ECC, P142, DOI DOI 10.1007/978-3-030-58545-79
   Liu Y, 2022, MULTIMED TOOLS APPL, V81, P18305, DOI 10.1007/s11042-022-12096-8
   Liu YW, 2022, Arxiv, DOI arXiv:2210.06780
   Liu ZY, 2022, NEURAL COMPUT APPL, V34, P18895, DOI 10.1007/s00521-022-07494-w
   Lu ZH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8721, DOI 10.1109/ICCV48922.2021.00862
   Min J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6921, DOI 10.1109/ICCV48922.2021.00686
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   Okazawa A, 2022, LECT NOTES COMPUT SC, V13689, P362, DOI 10.1007/978-3-031-19818-2_21
   Peng BH, 2023, Arxiv, DOI arXiv:2303.14652
   Rakelly K., 2018, P ICLR WORKSH
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Santoro A, 2016, PR MACH LEARN RES, V48
   Shaban A, 2017, Arxiv, DOI [arXiv:1709.03410, DOI 10.48550/ARXIV.1709.03410]
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi XY, 2022, LECT NOTES COMPUT SC, V13680, P151, DOI 10.1007/978-3-031-20044-1_9
   Siam M, 2020, P 20 9 INT JOINT C A, DOI [10.24963/ijcai.2020/120, DOI 10.24963/IJCAI.2020/120]
   Siam M, 2019, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2019.00535
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sun YP, 2022, Arxiv, DOI arXiv:2206.06122
   Tian ZH, 2020, IEEE INTERNET THINGS, V7, P3901, DOI [10.1109/TPAMI.2020.3013717, 10.1109/JIOT.2019.2951620]
   Tian ZT, 2022, IEEE T PATTERN ANAL, V44, P1050, DOI 10.1109/TPAMI.2020.3013717
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang YN, 2022, COGN COMPUT, V14, P875, DOI 10.1007/s12559-021-09990-y
   Xie GS, 2021, PROC CVPR IEEE, P5471, DOI 10.1109/CVPR46437.2021.00543
   Xiong ZT, 2022, LECT NOTES COMPUT SC, V13680, P133, DOI 10.1007/978-3-031-20044-1_8
   Yang LH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8701, DOI 10.1109/ICCV48922.2021.00860
   Yang X, 2020, 31 BRIT MACH VIS C 2
   Yang Y, 2023, Arxiv, DOI [arXiv:2305.13864, 10.48550/arXiv.2305.13864, DOI 10.48550/ARXIV.2305.13864]
   Yu F., 2015, ARXIV
   Zhang BF, 2021, PROC CVPR IEEE, P8308, DOI 10.1109/CVPR46437.2021.00821
   Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang GW, 2021, ADV NEUR IN, V34
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zhang L, 2023, IEEE Trans Circ Syst Vid Technol, P1
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Q, 2023, Arxiv, DOI arXiv:2108.06600
   Zhao YF, 2021, IEEE T PATTERN ANAL, V43, P1636, DOI 10.1109/TPAMI.2019.2953854
   Zheng ZW, 2023, IEEE T CIRC SYST VID, V33, P2102, DOI 10.1109/TCSVT.2022.3223150
   Zhuge YZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5344, DOI 10.1145/3474085.3475658
NR 75
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17553-6
EA NOV 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700004
DA 2024-07-18
ER

PT J
AU Jouibari, ZE
   Moakhkhar, HN
   Baleghi, Y
AF Jouibari, Zahra Ebrahimi
   Moakhkhar, Hosein Navaei
   Baleghi, Yasser
TI Emergency COVID-19 detection from chest X-rays using deep neural
   networks and ensemble learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Transfer learning; Ensemble learning; Deep neural network; Chest X-ray;
   COVID-19; Emergency condition
AB While several papers have explored the application of deep learning for COVID-19 detection in chest X-ray images, the consideration of images taken under emergency conditions remains limited. In this paper, we define emergency conditions as situations where inevitable errors occur during X-ray imaging in severe respiratory conditions of COVID-19 patients. These errors include positioning errors, protocol parameter errors, and motion artifacts. Our research aims to propose an intelligent tool based on deep neural networks and ensemble learning to detect COVID-19 cases from chest X-ray images in both standard and emergency conditions. As comprehensive datasets incorporating emergency images are scarce, we first generated a local dataset by investigating COVID-19 cases in our local hospital. We specifically selected cases with the aforementioned errors caused by emergency conditions. This dataset comprises patients in acute situations, as well as technical radiographic errors resulting from a significant number of people requiring radiography images. We evaluated the performance of recent popular pre-trained deep neural networks on our local dataset, which highlighted the importance of considering such emergency images. Subsequently, we transfer-learned 11 popular deep neural networks using our local dataset. Furthermore, we identified the transferred neural networks with the highest accuracies (exceeding 95% accuracy) and implemented ensemble learning methods such as Majority Voting and Error-Correcting Output Codes (ECOC). Our proposed methods excel in identifying COVID-19 in both emergency and non-emergency chest X-rays with high accuracy.
C1 [Jouibari, Zahra Ebrahimi; Moakhkhar, Hosein Navaei] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
   [Baleghi, Yasser] Babol Noshirvani Univ Technol, Dept Elect & Comp Engn, Babol, Mazandaran, Iran.
C3 University of Alberta; Babol Noshirvani University of Technology
RP Baleghi, Y (corresponding author), Babol Noshirvani Univ Technol, Dept Elect & Comp Engn, Babol, Mazandaran, Iran.
EM Zahra.Ebrahimi.Jouibari@gmail.com; Hosein.Navaei.Moakhkhar@gmail.com;
   y.baleghi@nit.ac.ir
FU We would like to thank Imam Khomeini Hospital of Fereydunkenar and Dr.
   Rahim Ebrahimi Jouibari, the previous head of the hospital, for
   providing the local dataset. We would also like to thank Mohammad
   Davoudi for examining the existing errors of the emerge
FX We would like to thank Imam Khomeini Hospital of Fereydunkenar and Dr.
   Rahim Ebrahimi Jouibari, the previous head of the hospital, for
   providing the local dataset. We would also like to thank Mohammad
   Davoudi for examining the existing errors of the emergency dataset and
   Mehdi Navaei Moakhkhar for giving access to the workstation system for
   training deep neural networks.
CR Ahemad Mohd Thousif, 2022, Measur Sens, V24, P100537, DOI 10.1016/j.measen.2022.100537
   Ahmad MS., 2018, International Journal of Chemistry, Pharmacy & Technology, V3, P1
   [Anonymous], 2006, Faculty of veterinary medicine
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Atasever S, 2022, Clin. Imaging
   Barrett JF, 2004, RADIOGRAPHICS, V24, P1679, DOI 10.1148/rg.246045065
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Cheng ZY, 2024, Arxiv, DOI arXiv:2304.14614
   Cheng ZY, 2023, Arxiv, DOI arXiv:2301.13487
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Corman VM, 2020, EUROSURVEILLANCE, V25, P23, DOI 10.2807/1560-7917.ES.2020.25.3.2000045
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Das D, 2020, PHYS ENG SCI MED, V43, P915, DOI 10.1007/s13246-020-00888-x
   Elgendi M, 2020, COVID-19-Detection-using-chest-X-rays
   Elgendi M, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00550
   Elkorany AS, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166405
   Ghazali SM, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103858
   Guhathakurata S, 2021, Data Science for COVID-19, P351
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemdan E. E. D., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2003.11055, 10.48550/arXiv.2003.11055]
   Huang F, 2009, Ensemble learning
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kanne Jeffrey P, 2020, Radiology, V296, pE113, DOI 10.1148/radiol.2020200527
   Khan W, 2022, Data intelligence and cognitive informatics, P429
   Khuzani AZ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-88807-2
   Li X, 2020, IEEE
   Mooney P, 2020, Chest X-Ray Images (Pneumonia)
   Myerburg MM, 2010, AM J RESP CELL MOL, V42, P676, DOI 10.1165/2009-0147OC
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Panwar H, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110190
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Cohen JP, 2020, Arxiv, DOI [arXiv:2006.11988, 10.59275/j.melba.2020-48g7, DOI 10.59275/J.MELBA.2020-48G7]
   Polikar R, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7_1
   Puddy E, 2007, BJA EDUC, V7, P71, DOI 10.1093/bjaceaccp/mkm014
   Qi X, 2021, INT J COMPUT ASS RAD, V16, P197, DOI 10.1007/s11548-020-02305-w
   Reddy RN, 2020, Engpaper Journal
   Redmon Joseph, 2013, Darknet: Open Source Neural Networks in C, DOI DOI 10.1109/CVPR.2016.91
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schueler BA, 1998, RADIOGRAPHICS, V18, P731, DOI 10.1148/radiographics.18.3.9599394
   Sethy PK, 2020, Detection of coronavirus disease (covid-19) based on deep features
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tompe A, 2020, StatPearls
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   World Health Organization, 2020, 145 WHO
   Wu Y, 2021, bioRxiv
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xie XZ, 2020, RADIOLOGY, V296, pE41, DOI 10.1148/radiol.2020200343
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 56
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17508-x
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600009
DA 2024-07-18
ER

PT J
AU Gera, D
   Kumar, BVR
   Badveeti, NSK
   Balasubramanian, S
AF Gera, Darshan
   Kumar, Bobbili Veerendra Raj
   Badveeti, Naveen Siva Kumar
   Balasubramanian, S.
TI Dynamic adaptive threshold based learning for noisy annotations robust
   facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial expression recognition; Noisy annotations; Dynamic training;
   Consistency; Strong augmentation; Weak-augmentation
ID ATTENTION
AB The real-world facial expression recognition (FER) datasets suffer from noisy annotations due to crowd-sourcing, ambiguity in expressions, the subjectivity of annotators, and inter-class similarity. However, the recent deep networks have a strong capacity to memorize the noisy annotations leading to corrupted feature embedding and poor generalization. Recent works handle the problem by selecting samples with clean labels based on loss values using a fixed threshold for all the classes which may not always be reliable. They also depend upon the noise rate in the data which may not always be available. In this work, we propose a novel FER framework (DNFER) in which samples with clean labels are selected based on a class-specific threshold, computed dynamically in each mini-batch. Specifically, DNFER uses supervised training on selected clean samples and unsupervised consistent training on all the samples. This threshold is independent of noise rate and does not need any clean data, unlike other methods. In addition, to effectively learn from noisy annotated samples, the posterior distributions between weakly-augmented image and strongly-augmented image are aligned using an unsupervised consistency loss. We demonstrate the robustness of DNFER on both synthetic as well as on real noisy annotated FER datasets. In addition, DNFER obtains state-of-the-art performance on popular benchmark datasets, with 90.41% on RAFDB, 57.77 % on SFEW, 89.32% on FERPlus, and 65.22% on AffectNet-7. Our source codes are made publicly available at https://github.com/1980x/DNFER.
C1 [Gera, Darshan] Sri Sathya Sai Inst Higher Learning, DMACS, Bengaluru 560067, Karnataka, India.
   [Kumar, Bobbili Veerendra Raj; Badveeti, Naveen Siva Kumar; Balasubramanian, S.] Sri Sathya Sai Inst Higher Learning, DMACS, Prasanthi Nilayam, Puttaparthi 515134, Andhra Pradesh, India.
C3 Sri Sathya Sai Institute of Higher Learning; Sri Sathya Sai Institute of
   Higher Learning
RP Gera, D (corresponding author), Sri Sathya Sai Inst Higher Learning, DMACS, Bengaluru 560067, Karnataka, India.
EM darshangera@sssihl.edu.in; veerendra.rajkumar@gmail.com;
   bnaveensivakumar@gmail.com; sbalasubramanian@sssihl.edu.in
RI Gera, Darshan/GOH-0475-2022; gera, darshan/JCN-6865-2023
OI Gera, Darshan/0000-0002-9539-4385; Raj Kumar, Bobbili
   Veerendra/0000-0002-1717-6841; S, Balasubramanian/0000-0001-8947-4840;
   Badveeti, Naveen Siva Kumar/0000-0002-1181-2544
FU We dedicate this work to Bhagawan Sri Sathya Sai Baba, Divine Founder
   Chancellor of Sri Sathya Sai Institute of Higher Learning,
   PrasanthiNilyam, A.P., India.
FX We dedicate this work to Bhagawan Sri Sathya Sai Baba, Divine Founder
   Chancellor of Sri Sathya Sai Institute of Higher Learning,
   PrasanthiNilyam, A.P., India.
CR Abate AF, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P539, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00097
   Arnaud E., 2022, IEEE Trans. Affect. Comput.
   Arpit D, 2017, PR MACH LEARN RES, V70
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Chen Yuedong, 2019, VCIP
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Ding H, 2020, 2020 IEEE INT JOINT, P1
   Fan XY, 2020, IEEE IMAGE PROC, P903, DOI [10.1109/icip40778.2020.9190643, 10.1109/ICIP40778.2020.9190643]
   Fu YJ, 2020, IEEE T IMAGE PROCESS, V29, P6535, DOI 10.1109/TIP.2020.2991510
   Ge HL, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106621
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Gera D, 2021, P 12 IND C COMP VIS, P1
   Gera D, 2021, ICTACT J Image Vid Process (IJIVP), DOI [10.21917/ijivp.2021.0356, DOI 10.21917/IJIVP.2021.0356]
   Gera D, 2022, PATTERN RECOGN LETT, V155, P9, DOI 10.1016/j.patrec.2022.01.013
   Gera D, 2021, IEEE INT CONF COMP V, P3578, DOI 10.1109/ICCVW54120.2021.00399
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hua WT, 2019, IEEE ACCESS, V7, P24321, DOI 10.1109/ACCESS.2019.2900231
   Huang QH, 2021, INFORM SCIENCES, V580, P35, DOI 10.1016/j.ins.2021.08.043
   Jiabei Zeng, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11217), P227, DOI 10.1007/978-3-030-01261-8_14
   Jiang P, 2020, IEEE SIGNAL PROC LET, V27, P1954, DOI 10.1109/LSP.2020.3031504
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu P, 2021, IEEE Trans Cybern
   Liu Y, 2022, Uncertain label correction via auxiliary action unit graphs for facial expression recognition, P777, DOI [10.1109/ICPR56361.2022.9956650.IEEE, DOI 10.1109/ICPR56361.2022.9956650.IEEE]
   Liu ZM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102723
   Lu J, 2018, PR MACH LEARN RES, V80
   Mahmoudi MA, 2020, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP40778.2020.9190694
   Malach E, 2017, ADV NEUR IN, V30
   Mao S, 2022, arXiv
   Mao SS, 2021, Arxiv, DOI arXiv:2107.11061
   Maqableh W, 2022, VIS INFORM, V7, P1, DOI 10.1016/j.visinf.2022.10.001
   Meng DB, 2019, IEEE IMAGE PROC, P3866, DOI [10.1109/ICIP.2019.8803603, 10.1109/icip.2019.8803603]
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Ren MY, 2018, PR MACH LEARN RES, V80
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Sarfraz F, 2021, IEEE WINT CONF APPL, P3158, DOI 10.1109/WACV48630.2021.00320
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   She JH, 2021, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR46437.2021.00618
   Siqueira H, 2020, AAAI CONF ARTIF INTE, V34, P5800
   Song H, 2023, IEEE T NEUR NET LEAR, V34, P8135, DOI 10.1109/TNNLS.2022.3152527
   Sun Z, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109157
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang XS, 2020, Arxiv, DOI arXiv:1903.12141
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Wei Hongxin, 2020, P IEEE C COMP VIS PA
   Yan L, 2022, Multimed Tools Appl, P1
   Yu XR, 2019, PR MACH LEARN RES, V97
   Yuan BD, 2018, IEEE WINT CONF APPL, P757, DOI 10.1109/WACV.2018.00088
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang YH, 2021, ADV NEUR IN, V34
   Zhao ZQ, 2021, AAAI CONF ARTIF INTE, V35, P3510
NR 63
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17510-3
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200006
DA 2024-07-18
ER

PT J
AU Tyagi, S
   Reddy, SRN
   Anand, R
   Sabharwal, A
AF Tyagi, Shivangi
   Reddy, S. R. N.
   Anand, Rishika
   Sabharwal, Aditi
TI Enhancing rice crop health: a light weighted CNN-based disease detection
   system with mobile application integration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Rice leaf disease detection; Agriculture; Image processing; Artificial
   intelligence; Deep learning; Light weighted Convolutional neural network
AB This article introduces an advanced approach for the accurate detection of rice leaf diseases, a critical concern in rice cultivation worldwide. Rice is a staple crop in many countries, and diseases can inflict severe damage on yields. Timely and precise detection is essential for effective disease management. The proposed model offers a solution to enhance detection accuracy while simplifying the process, utilizing a dataset of rice leaf images obtained from Kaggle.com. The dataset, though valuable, presented challenges due to image quality issues, including noise and inadequate clarity. To address these challenges, a two-phase approach was developed. In the pre-processing phase, the Contrast Limited Adaptive Histogram Equalization (CLAHE) technique was applied to adjust image illumination, contrast, and edge sharpness. This significantly improved image quality and paved the way for more accurate disease detection. In the segmentation phase, a hybrid methodology combining HSV and K-means segmentation techniques was employed. This innovative fusion of techniques effectively extracted the Region of Interest (ROI) from images, focusing exclusively on disease-related features, which was vital for precise detection. The core of the system lies in a Light Weighted CNN model, renowned for its efficiency and accuracy. This model was employed to classify rice leaf images, achieving exceptional results. To make this powerful tool accessible and user-friendly, an Android application was developed, enabling users to easily navigate and identify diseases in rice leaves. To validate the effectiveness of the proposed model, comprehensive comparisons were made with standard models such as simple CNN, InceptionResNetV2, MobileNet, and DenseNet. Across all evaluation metrics, including accuracy, precision, recall, and F-score, the proposed model consistently outperformed traditional counterparts, boasting an impressive 99% accuracy rate. This article presents an innovative and practical solution to address a pressing issue in rice cultivation, offering the potential to significantly improve crop health and agricultural outcomes.
C1 [Tyagi, Shivangi; Reddy, S. R. N.; Anand, Rishika; Sabharwal, Aditi] Indira Gandhi Delhi Tech Univ Women, Comp Sci Dept, Delhi 110006, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Tyagi, S (corresponding author), Indira Gandhi Delhi Tech Univ Women, Comp Sci Dept, Delhi 110006, India.
EM shivangi022mtcse20@igdtuw.ac
RI Satti, Rama Gopala Reddy/Q-2080-2016
CR Ahad MT, 2023, ARTIF INTELL AGR, V9, P22, DOI 10.1016/j.aiia.2023.07.001
   Ahmad I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8812019
   Ahmed K, 2019, 2019 INT C SUSTAINAB, P1
   Andrianto H, 2020, INT C INF TECH SYST, P387, DOI [10.1109/ICITSI50517.2020.9264942, 10.1109/icitsi50517.2020.9264942]
   [Anonymous], 2015, International Journal of Electrical and Electronics Engineers
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Arora, 2019, International Journal for Research in Applied Science and Engineering Technology, V7, P415
   Arun Kumar R, 2017, INT P ADV SOFT COMP, P123
   Azath M, 2021, J ELECTR COMPUT ENG, V2021, DOI 10.1155/2021/9981437
   Azim MA., 2021, Telecommun. Comput. Electronics Control TELKOMNIKA, V19, P463, DOI [10.12928/telkomnika.v19i2.16488, DOI 10.12928/TELKOMNIKA.V19I2.16488]
   Baranwal S, 2019, P INT C SUST COMP SC
   Bari BS, 2021, PeerJ Comput. Sci., V7, P432
   Feng S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163207
   Ghosal S, 2020, 2020 IEEE CALCUTTA CONFERENCE (CALCON), P230, DOI [10.1109/CALCON49167.2020.9106423, 10.1109/calcon49167.2020.9106423]
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   Groth D, 2015, IRRI-Rice Science for a better world
   Hu Rongjie, 2020, CSSE '20: Proceedings of the 3rd International Conference on Computer Science and Software Engineering, P58, DOI 10.1145/3403746.3403905
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Joshi AA, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P471, DOI 10.1109/CAST.2016.7915015
   Kartikeyan P., 2021, INT J COMPUT APPL, V975, P8887, DOI [DOI 10.5120/IJCA2021920990, 10.5120/ijca2021920990]
   Kathiresan Gugan, 2021, Journal of Physics: Conference Series, V1911, DOI 10.1088/1742-6596/1911/1/012004
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Li HL, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6868592
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Nagaraju M, 2020, INT J SYST ASSUR ENG, V11, P547, DOI 10.1007/s13198-020-00972-1
   Ng W, 2016, Peerj, V4
   Ogbezuode N, 2021, Rice leaf image dataset
   Pallathadka H, 2022, MATER TODAY-PROC, V51, P2277, DOI 10.1016/j.matpr.2021.11.398
   Pandey A, 2021, International Research Journal of Engineering and Technology (IRJET), V08
   Phadikar S., 2012, International Journal of Information and Electronics Engineering, V2, DOI DOI 10.7763/IJIEE.2012.V2.137
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Qiu RC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222658
   Sethy PK, 2019, International Journal of Innovative Technology and Exploring Engineering (IJITEE), V8, P108
   Shahbandeh M, 2021, Total global rice consumption 2008-2020
   Sharma S, 2021, Int J Res Appl Sci Eng Technol
   Sharma Vikas, 2020, Journal of Multimedia Information System, V7, P17
   Shrivastava Vimal K., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1023, DOI 10.1109/ICAIS50930.2021.9395813
   Singh P, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.105986
   Singh Vimal, 2023, Procedia Computer Science, P348, DOI 10.1016/j.procs.2023.01.017
   Smithashree KP, 2020, International Journal for Technological Research in Engineering (IJTRE), P07
   Wu XP, 2019, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2019.00899
   Yang W, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106092
   Zarbafi SS, 2019, AGRONOMY-BASEL, V9, DOI 10.3390/agronomy9040177
NR 44
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17449-5
EA NOV 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500030
DA 2024-07-18
ER

PT J
AU Ozturk, N
   Ozturk, S
AF Ozturk, Nurullah
   Ozturk, Serkan
TI Efficient and natural image fusion method for low-light images based on
   active contour model and adaptive gamma correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image enhancement; Image fusion; ACM segmentation; Adaptive gamma
   correction; Low-light image
ID QUALITY ASSESSMENT; ENHANCEMENT; RETINEX
AB Image fusion-based methods have received much attention in image processing applications in recent years. In this paper, an efficient and natural image fusion method based on the active contour model (ACM) and adaptive gamma correction (AGC) is proposed for the low-light images. The image is segmented into object and background regions quickly and detailed using hybrid ACM based on Chen-Vese and Local Gaussian Distribution Fitting (CV-LGDF), and a fusion mask is obtained. Then, the effective gamma correction parameter is calculated by using the exposure threshold independently for each region. The dynamic pixel range of each region is distributed using the histogram stretching. The color space of each region is converted to the HSI color space, and then the intensity component of each region is enhanced independently with the AGC method. The enhanced regions are merged using the fusion mask, and the color space of the enhanced image is transformed into RGB color space. Finally, histogram equalization is performed on the input image using the histogram map of the fusion image. The performance of the proposed method is compared to that of other state-of-the-art low-light methods. The experiments illustrate that our method provides effective and natural enhancement of the contrast and brightness in the image.
C1 [Ozturk, Nurullah] Kayseri Univ, Vocat Sch Tech Sci, Dept Comp Technol, Kayseri, Turkiye.
   [Ozturk, Serkan] Erciyes Univ, Dept Comp Engn, Kayseri, Turkiye.
C3 Kayseri University; Erciyes University
RP Ozturk, N (corresponding author), Kayseri Univ, Vocat Sch Tech Sci, Dept Comp Technol, Kayseri, Turkiye.
EM nurullahozturk@kayseri.edu.tr; serkan@erciyes.edu.tr
OI OZTURK, NURULLAH/0000-0001-7766-6757
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Bhandari AK, 2022, MULTIMED TOOLS APPL, V81, P6009, DOI 10.1007/s11042-021-11347-4
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141
   Chen T, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020425
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   Guo J, 2023, Heliyon
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang ZH, 2016, INFRARED PHYS TECHN, V79, P205, DOI 10.1016/j.infrared.2016.11.001
   Jeong I, 2021, MULTIMED TOOLS APPL, V80, P18027, DOI 10.1007/s11042-021-10614-8
   Jiang ZQ, 2021, NEUROCOMPUTING, V454, P361, DOI 10.1016/j.neucom.2021.05.025
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liu JY, 2021, INT J COMPUT VISION, V129, P1153, DOI 10.1007/s11263-020-01418-8
   Liu S, 2021, Multimedia Tools and Applications, P1
   Liu SG, 2019, IEEE T CONSUM ELECTR, V65, P303, DOI 10.1109/TCE.2019.2893644
   Liu SX, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23060746
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Ma Zhongli, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P217
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ozturk N, 2021, SIGNAL IMAGE VIDEO P, V15, P1313, DOI 10.1007/s11760-021-01862-0
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Simi VR, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106364
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Wang L, 2019, IEEE INT CONF MULTI, P276, DOI 10.1109/ICMEW.2019.00054
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Zhao B, 2022, SIGNAL IMAGE VIDEO P, V16, P1409, DOI 10.1007/s11760-021-02093-z
NR 40
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17141-8
EA NOV 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900001
DA 2024-07-18
ER

PT J
AU Diwan, A
   Sonkar, U
AF Diwan, Anjali
   Sonkar, Upasana
TI Visualizing the truth: a survey of multimedia forensic analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia forensics; Image forgery; Video forgery; Audio manipulation;
   Digital manipulation; Forgery detection
ID COPY-MOVE FORGERY; VIDEO FORGERY; DETECTION ALGORITHM; LOCALIZATION;
   NETWORK
AB Multimedia forensics is an essential field of research that deals with the authenticity and integrity of multimedia content in the digital world. With the increasing use of digital platforms and social media, the risk of manipulated and misleading digital content has significantly increased, making it crucial to verify and analyze the authenticity of multimedia content presented as evidence. Multimedia manipulation can affect various forms of media, such as audio, video, and images, and poses significant challenges for investigators, including different formats, time complexity, and a vast amount of data. This paper provides an overview of current techniques for multimedia manipulation detection, focusing on image, video, and audio analysis. The paper presents an in-depth analysis of various techniques used in multimedia forensics, including source device identification, tampering detection, and authentication. Furthermore, the paper discusses the limitations of current techniques and highlights future research directions in the field. The review concludes that multimedia forensics is a challenging and constantly evolving field that requires ongoing research to address emerging threats to multimedia content authenticity. The proposed techniques have shown promising results in detecting and analyzing multimedia manipulation, but more research is needed to enhance their accuracy and applicability in real-world scenarios.
C1 [Diwan, Anjali] Marwadi Univ, CE AI & Bigdata, Rajkot 360003, Gujarat, India.
   [Sonkar, Upasana] SSTC, CSE, Bhilai 481001, Chhattisghar, India.
C3 Marwadi University; Shri Shankaracharya Group of Institutions
RP Diwan, A (corresponding author), Marwadi Univ, CE AI & Bigdata, Rajkot 360003, Gujarat, India.
EM anjali.diwan@ieee.org; upasanasonkar75@gmail.com
OI Diwan, Dr. Anjali/0000-0002-2322-7780
CR Ali Z, 2018, IEEE ACCESS, V6, P15494, DOI 10.1109/ACCESS.2018.2805845
   Ali Z, 2017, IEEE ACCESS, V5, P2994, DOI 10.1109/ACCESS.2017.2672681
   Aloraini M, 2021, IEEE T CIRC SYST VID, V31, P917, DOI 10.1109/TCSVT.2020.2993004
   Amanipour V, 2018, IEEE T INSTRUM MEAS, V67, P505, DOI 10.1109/TIM.2017.2777620
   Antony Neema, 2018, 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1085, DOI 10.1109/ICOEI.2018.8553953
   Vega EAA, 2020, IEEE ACCESS, V8, P11815, DOI 10.1109/ACCESS.2020.2964516
   Bakas J, 2018, LECT NOTES COMPUT SC, V11281, P304, DOI 10.1007/978-3-030-05171-6_16
   Bi Xiuli, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428466
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Changtao Miao, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P71, DOI 10.1109/TBIOM.2021.3119403
   Chao J, 2013, DIGITAL FORENSICS WA, P267
   Chen J, 2022, IEEE Trans Circ Syst Video Technol
   Chen ML, 2022, IEEE T INF FOREN SEC, V17, P457, DOI 10.1109/TIFS.2022.3142993
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   Daniya T, 2021, INT CONF COMP COMMUN, DOI 10.1109/ICCCI50826.2021.9402302
   Dhanya R., 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P58, DOI 10.1109/ICCS1.2017.8325963
   Ding F, 2021, IEEE T MULTIMEDIA, V24, P3429, DOI 10.1109/TMM.2021.3098422
   Diwan A, 2021, IET IMAGE PROCESS, V15, P1298, DOI 10.1049/ipr2.12105
   Dixit A, 2020, IET IMAGE PROCESS, V14, P4528, DOI 10.1049/iet-ipr.2020.1118
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   Dua S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12126223
   Fang H, 2023, IEEE T MULTIMEDIA, V25, P2648, DOI 10.1109/TMM.2022.3149641
   Fang S., 2022, arXiv
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Gengyun Jia, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P308, DOI 10.1109/TBIOM.2021.3086109
   Gill NK, 2017, INT CONF COMPUT
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Fernández EG, 2022, IEEE T INTELL TRANSP, V23, P2596, DOI 10.1109/TITS.2021.3132227
   Hajialilu SF, 2020, IET IMAGE PROCESS, V14, P2799, DOI 10.1049/iet-ipr.2018.6246
   He PS, 2021, IEEE T MULTIMEDIA, V23, P3179, DOI 10.1109/TMM.2020.3021234
   Hu YC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091146
   Huang CC, 2020, INT J DIGIT CRIME FO, V12, P14, DOI 10.4018/IJDCF.2020010102
   Huang HY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0469-9
   Imran M, 2017, IEEE ACCESS, V5, P12843, DOI 10.1109/ACCESS.2017.2717842
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Javed AR, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104456
   Jean H, 2022, COL VIS COMP S 2022
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Johnston P, 2020, NEURAL COMPUT APPL, V32, P12243, DOI 10.1007/s00521-019-04272-z
   Joshi V, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1121
   Kadam K, 2021, IEEE ACCESS, V9, P162499, DOI 10.1109/ACCESS.2021.3130342
   Kaur R., 2012, 2012 International Conference on Computing Sciences (ICCS), P295, DOI 10.1109/ICCS.2012.25
   Kumar N, 2023, AUST J FORENSIC SCI, V55, P331, DOI 10.1080/00450618.2021.2016964
   Kumar V, 2023, Multiple forgery detection in video using convolution neural network
   Li Q., 2022, Sci Rep, V12, P1
   Li Xiang, 2021, IEEE Transactions on Wireless Communications
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin WS, 2009, IEEE T INF FOREN SEC, V4, P911, DOI 10.1109/TIFS.2009.2033224
   Liu YQ, 2022, IEEE T IMAGE PROCESS, V31, P541, DOI 10.1109/TIP.2021.3132828
   Liu YQ, 2020, IEEE ACCESS, V8, P6729, DOI 10.1109/ACCESS.2019.2963745
   Luo YX, 2022, IEEE ACCESS, V10, P110754, DOI 10.1109/ACCESS.2022.3215963
   Meena Kunj Bihari, 2021, Journal of Physics: Conference Series, V1714, DOI 10.1088/1742-6596/1714/1/012038
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Muzaffer G, 2017, 2017 INTERNATIONAL ARTIFICIAL INTELLIGENCE AND DATA PROCESSING SYMPOSIUM (IDAP)
   Nabi ST, 2022, MULTIMEDIA SYST, V28, P939, DOI 10.1007/s00530-021-00873-8
   Nam SH, 2021, IEEE T CIRC SYST VID, V31, P3308, DOI 10.1109/TCSVT.2020.3037662
   Pham NT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010083
   NJ J, 2022, Region duplication tampering detection and localization in digital video using haar wavelet transform
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Prakash CS, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1523346
   Priyadharsini S, 2023, INT J WAVELETS MULTI, V21, DOI 10.1142/S0219691322500515
   Rani P. B. Shailaja, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P959, DOI 10.1109/ICECA.2019.8822064
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Raveendra M., 2019, Int J Eng Adv Technol, V9, P1190, DOI [10.35940/ijeat.A9517.109119, DOI 10.35940/IJEAT.A9517.109119]
   Revi KR, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P2315, DOI 10.1109/ICPCSI.2017.8392130
   Rhee KH, 2020, IEEE ACCESS, V8, P103374, DOI 10.1109/ACCESS.2020.2999308
   Saddique M, 2020, IEEE ACCESS, V8, P56782, DOI 10.1109/ACCESS.2020.2980951
   Sencar, 2022, MULTIMEDIA FORENSICS
   Shelke NA, 2022, MULTIMED TOOLS APPL, V81, P22731, DOI 10.1007/s11042-021-10989-8
   Siddiqi MH, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/4270776
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Soni B, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P197, DOI 10.1109/SPIN.2018.8474093
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Sowmya KN, 2018, J INF SECUR APPL, V41, P159, DOI 10.1016/j.jisa.2018.07.002
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Su LC, 2019, IEEE ACCESS, V7, P109719, DOI 10.1109/ACCESS.2019.2933871
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Tang L, 2022, IEEE Internet of Things Journal
   Thuong Le-Tien, 2016, The Second International Conference on Electrical and Electronic Engineering, Telecommunication Engineering, and Mechatronics (EEETEM2016), P26
   Verde Sebastiano, 2021, IEEE Open Journal of Signal Processing, V2, P217, DOI 10.1109/OJSP.2021.3074298
   Verdoliva DCGPL, 2019, P IEEE CVF C COMP VI
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wang XY, 2023, IEEE T CIRC SYST VID, V33, P5345, DOI 10.1109/TCSVT.2023.3252042
   Wang XF, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108347
   Wang YK, 2022, IEEE T INF FOREN SEC, V17, P500, DOI 10.1109/TIFS.2022.3146766
   Yang JC, 2022, IEEE T CIRC SYST VID, V32, P4854, DOI 10.1109/TCSVT.2021.3133859
   Yang QX, 2021, IEEE T CIRC SYST VID, V31, P4131, DOI 10.1109/TCSVT.2020.3046240
   Yildirim EO, 2018, 2018 26 SIGN PROC CO, P1, DOI [10.1109/SIU.2018.8404325, DOI 10.1109/SIU.2018.8404325]
   Yu PP, 2022, IEEE T INF FOREN SEC, V17, P547, DOI 10.1109/TIFS.2022.3146781
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhang Y., 2021, IEEE Transactions on Circuits and Systems for Video Technology
   Zhao H, 2017, MULTIMED TOOLS APPL, V76, P13897, DOI 10.1007/s11042-016-3758-7
NR 95
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17475-3
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500004
DA 2024-07-18
ER

PT J
AU Arshad, S
AF Arshad, Sadiqa
TI Construction of confusion component based on the isogeny of elliptic
   curves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Substitution box; Elliptic curves; Block ciphers; Permutation; Isogeny;
   Nonlinearity
ID S-BOX; MAP
AB The confusion-creating ability of a substitution box is indispensable. Its utmost involvement in the block cipher motivates researchers to investigate methods and construct cryptographically strong and efficient substitution boxes. In this paper, we define an isogeny that maps the elements of the base curve to the second curve. The points that can generate the maximal order subgroup of the elliptic curve points are the generators of the base curve. A group action is applied to the generators of the base curve to construct the initial S-boxes. The images of the generator points are established through isogeny and used to generate initial S-boxes from the second curve. The idea is cost-effective regarding computation, as both curves share the same prime field, and we only need to find a few generator points and the corresponding images. A suitable permutation from S-n is applied to the selected initial substitution box to improve the nonlinearity. The suggested S-box is balanced and highly nonlinear. We assessed the cryptographic strength of the suggested S-box against linear and differential probabilities. The smaller values of these tests ensure that the suggested S-box is cryptographically strong and can be used securely in any block cipher.
C1 [Arshad, Sadiqa] Inst Space Technol, Islamabad, Pakistan.
RP Arshad, S (corresponding author), Inst Space Technol, Islamabad, Pakistan.
EM ilyas.sadiqa@gmail.com
CR Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Ahmad M, 2020, IEEE ACCESS, V8, P110397, DOI 10.1109/ACCESS.2020.3001868
   [Anonymous], 2016, IACR Cryptol ePrint Arch
   Arshad S, 2023, WIRELESS PERS COMMUN, V131, P1913, DOI 10.1007/s11277-023-10526-w
   Attaullah, 2018, WIRELESS PERS COMMUN, V99, P213, DOI 10.1007/s11277-017-5054-x
   Azam NA, 2019, FRONT INFORM TECH EL, V20, P1378, DOI 10.1631/FITEE.1800434
   Bao Ngoc Tran, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P463, DOI 10.1109/CIS.2009.110
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Cui JE, 2011, INT J INNOV COMPUT I, V7, P2291
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   De Feo L, 2014, J MATH CRYPTOL, V8, P209, DOI 10.1515/jmc-2012-0015
   De Wang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P782, DOI 10.1109/CSSE.2008.296
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Hallappanavar VL, 2014, IOSR J Comput Sci (IOSR-JCE), P35
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hayat U, 2018, WIRELESS PERS COMMUN, V101, P439, DOI 10.1007/s11277-018-5698-1
   Hussain I., 2011, WORLD APPL SCI J, V14, P1779
   Hussain I, 2013, NONLINEAR DYNAM, V74, P271, DOI 10.1007/s11071-013-0963-z
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jao D, 2014, LECT NOTES COMPUT SC, V8772, P160, DOI 10.1007/978-3-319-11659-4_10
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kohel D., 1996, Endomorphism rings of elliptic curves over finite fields
   Mahmood S, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5823230
   Matsui M., 1994, Advances in Cryptology - EUROCRYPT '93. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P386, DOI 10.1007/3-540-48285-7_33
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Razaq A, 2020, IEEE ACCESS, V8, P75473, DOI 10.1109/ACCESS.2020.2989676
   Razaq A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5101934
   Rostovtsev A., 2006, 2006145 CRYPT EPRINT
   Shahzad I, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/2847801
   Skipjack NIST, 1998, KEA algorithm specifications
   Stolbunov A, 2010, ADV MATH COMMUN, V4, P215, DOI 10.3934/amc.2010.4.215
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   VELU J, 1971, CR ACAD SCI A MATH, V273, P238
   Waqas U, 2014, INT CONF FRONT INFO, P159, DOI 10.1109/FIT.2014.38
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Yi X, 1997, GLOB TELECOMM CONF, P689, DOI 10.1109/GLOCOM.1997.638418
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
   Zhuo-Hui Xian, 2010, Proceedings Second International Workshop on Education Technology and Computer Science (ETCS 2010), P84, DOI 10.1109/ETCS.2010.227
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17399-y
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700002
DA 2024-07-18
ER

PT J
AU Priyanka, JH
   Parveen, N
AF Priyanka, J. Himabindu
   Parveen, Nikhat
TI DeepSkillNER: An automatic screening and ranking of resumes using hybrid
   deep learning and enhanced spectral clustering approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Job Resume screening; Deep learning; Resume ranking; Pyramid dilated
   convolutional neural network; Spectral clustering
ID SYSTEM
AB The process of identifying the best job candidates from different sets of resumes is a resource and time consuming process. The common issue in resume screening is the unavailability of annotated data to label the information obtained accurately. To tackle these challenges, this research undergoes feature extraction and feature clustering stages for resume screening and ranking. In this work, the hybrid deep learning (DL) based Pyramid Dilated Convolutional Neural Network with Bidirectional Gated Recurrent Unit (PDCNN-Bi-GRU) is introduced to extract the skill related features from the resumes. Moreover, the Conditional Random Field (CRF) layer is hybridized with the DL technique to generate skill-related information as the outcome. Then, a fuzzy matching module is contemplated to match the skill-related features with the job categories to enhance the accuracy performance. Finally, the candidate resumes of higher skills are clustered using the hybrid Spectral clustering with Hummingbird Optimization (SCHO) technique. The proposed method is tested with both public source and real-time datasets and is implemented in the PYTHON platform. The performances like accuracy, specificity, sensitivity, F-measure, kappa, time complexity, and Mean Square Error (MSE) are analyzed and compared with existing techniques. The proposed method obtains the accuracy of 99.3% and 99.83% for testing with both public source and real-time datasets, respectively.
C1 [Priyanka, J. Himabindu; Parveen, Nikhat] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Priyanka, JH (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
EM himabindupriyanka1@gmail.com
RI Parveen, Nikhat/IUM-8961-2023
OI Parveen, Nikhat/0000-0003-2939-0025
CR Alamelu M, 2021, 2021 10 INT C INT EV, P1
   Ali I, 2022, MEHRAN UNIV RES J EN, V41, P65, DOI 10.22581/muet1982.2201.07
   Amin S, 2019, 2019 INT C NASC TECH, P1
   Bhatia V., 2019, arXiv
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   Deepak G, 2020, J DISCRET MATH SCI C, V23, P157, DOI 10.1080/09720529.2020.1721879
   Fu X, 2023, Multimed Tools Appl, P1
   Gan CG, 2022, Arxiv, DOI arXiv:2208.03219
   Gaur B, 2021, NEURAL COMPUT APPL, V33, P5705, DOI 10.1007/s00521-020-05351-2
   Indira MD, 2016, Int J Comput Sci Inf Secur (IJCSIS), V14, P799
   Kavitha D., 2023, 2023 International Conference on Advances in Electronics, Communication, Computing and Intelligent Information Systems (ICAECIS), P464, DOI 10.1109/ICAECIS58353.2023.10170518
   Kavitha TS, 2022, MULTIMED TOOLS APPL, V81, P31469, DOI 10.1007/s11042-022-12940-x
   Lad A., 2022, Int J Modern Dev Eng Sci, V1, P17
   Manjula S., 2021, Turk J Comput Math Educ (TURCOMAT), V12, P2465
   Mao L., 2019, An Application of Natural Language Processing: Named Entity Recognition with BLSTM in Chinese Corpora
   Mathew L., 2020, Int J Eng Res, V9, P591
   Najjar A, 2021, INFORM-INT J COMPUT, V45, P617, DOI 10.31449/inf.v45i4.3356
   Narendra GO, 2022, International Journal of Advanced Research in Science, Communication and Technology, V2, P728
   Pudasaini Shushanta, 2022, Expert Clouds and Applications: Proceedings of ICOECA 2021. Lecture Notes in Networks and Systems (209), P705, DOI 10.1007/978-981-16-2126-0_55
   Roy PK, 2020, PROCEDIA COMPUT SCI, V167, P2318, DOI 10.1016/j.procs.2020.03.284
   Satheesh K, 2020, Int Res J Eng Technol (IRJET), V7, P74
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Tamang A, 2022, Expert clouds and applications, P705
   Tejaswini K, 2022, Global Trans. Proc., V3, P371, DOI DOI 10.1016/J.GLTP.2021.10.002
   Tiwari A., 2019, International Research Journal of Engineering and Technology, V6, P320
   Uttarwar S, 2020, ADV INTELL SYST COMP, V1108, P909, DOI 10.1007/978-3-030-37218-7_97
   Vishruth RG, 2020, 2020 4 INT C EL COMM, P1127
   Wang YF, 2020, MULTIMED TOOLS APPL, V79, P4553, DOI 10.1007/s11042-019-7678-1
   Zaroor A, 2017, PROC INT C TOOLS ART, P780, DOI 10.1109/ICTAI.2017.00123
   Zu S., 2019, Int J Nat Lang Comput, V8, P29
NR 30
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17264-y
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300009
DA 2024-07-18
ER

PT J
AU Shyla, SI
   Bell, TB
   Sheela, CJJ
AF Shyla, S. Immaculate
   Bell, T. Beula
   Sheela, C. Jaspin Jeba
TI Adaptive golden eagle optimization based multi-objective scientific
   workflow scheduling on multi-cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Makespan; Task scheduling; Multi-cloud environment; Golden eagle
   optimization; Normalized cost; Resource utilization
ID ALGORITHM; TASKS
AB An exemplary for emerging knowledges and the capacity to provide reliable cloud services, cloud computing. Giving consumers on-demand access to "unlimited" computer resources is one of the key components of cloud computing. Single cloud-holding resources, however, are typically constrained and might not be able to handle the unexpected spike in user demands. In order to support resource sharing amongst clouds, the multi-cloud concept is thus established. These days, offering resources and administrations across numerous clouds is unquestionably amazing. The goal of conventional research on cloud scheduling is to reduce costs or increase speed. However, the major indicator of QoS and a vital problem is the dependability of work process scheduling. As a result, multi-objective scheduling for a logical work process in a multi-cloud environment is suggested in this research with the goal of controlling the work process while also balancing cost and timeliness while satisfying the criterion of reliability. The adaptive golden eagle optimisation (AGEO) algorithm is created to realise this idea. The solution encoding, fitness analysis, and updating functions are used in the proposed algorithm's validation. Different workflow models are employed for the experimental study, and performance is assessed using various indicators. The projected approach attained 1920 utilization. Similarly, the PSO and GA achieved 1901 and 1900 utilization.
C1 [Shyla, S. Immaculate] Holy Cross Coll, Dept Comp Sci, Nagercoil, India.
   [Bell, T. Beula] Nesamony Mem Christian Coll, Dept Comp Applicat, Marthandam, India.
   [Sheela, C. Jaspin Jeba] Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
RP Shyla, SI (corresponding author), Holy Cross Coll, Dept Comp Sci, Nagercoil, India.
EM immaculatejudit@gmail.com; Beulamaglin@gmail.com;
   jaspinjebasheela@gmail.com
RI Shyla, Immaculate/HTL-8626-2023
OI Shyla, Immaculate/0000-0003-1265-9729
CR Abd Elaziz M, 2019, KNOWL-BASED SYST, V169, P39, DOI 10.1016/j.knosys.2019.01.023
   Abujassar RS, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9358706
   Abujassar RS, 2016, WIREL NETW, V22, P119, DOI 10.1007/s11276-015-0957-5
   Al-Maytami BA, 2019, IEEE ACCESS, V7, P160916, DOI 10.1109/ACCESS.2019.2948704
   Alsaidy SA, 2022, J KING SAUD UNIV-COM, V34, P2370, DOI 10.1016/j.jksuci.2020.11.002
   Awad AI, 2015, PROCEDIA COMPUT SCI, V65, P920, DOI 10.1016/j.procs.2015.09.064
   Babu LDD, 2013, APPL SOFT COMPUT, V13, P2292, DOI 10.1016/j.asoc.2013.01.025
   Chaudhary D, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105627
   Doostali S, 2021, CLUSTER COMPUT, V24, P3607, DOI 10.1007/s10586-021-03351-y
   Duan HC, 2017, FUTURE GENER COMP SY, V74, P142, DOI 10.1016/j.future.2016.02.016
   Ebadifard F, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4368
   Hu HY, 2018, J NETW COMPUT APPL, V114, P108, DOI 10.1016/j.jnca.2018.03.028
   Ismayilov G, 2020, FUTURE GENER COMP SY, V102, P307, DOI 10.1016/j.future.2019.08.012
   Jena RK, 2015, PROCEDIA COMPUT SCI, V57, P1219, DOI 10.1016/j.procs.2015.07.419
   Joshi SS, 2021, Int J Comput Networks Appl, V8, P538
   Khorsand R, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4379
   Mohammadi-Balani A, 2021, COMPUT IND ENG, V152, DOI 10.1016/j.cie.2020.107050
   Mokeddem D, 2021, J ELECTR ENG TECHNOL, V16, P171, DOI 10.1007/s42835-020-00589-1
   Nayak SC, 2018, J KING SAUD UNIV-COM, V30, P152, DOI 10.1016/j.jksuci.2016.05.003
   Priya V, 2019, APPL SOFT COMPUT, V76, P416, DOI 10.1016/j.asoc.2018.12.021
   Sanaj MS, 2020, ENG SCI TECHNOL, V23, P891, DOI 10.1016/j.jestch.2019.11.002
   Tian WH, 2015, SIMUL MODEL PRACT TH, V58, P239, DOI 10.1016/j.simpat.2015.06.002
NR 22
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17405-3
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500006
DA 2024-07-18
ER

PT J
AU Swarnkar, N
   Thomas, A
   Selwal, A
AF Swarnkar, Neelam
   Thomas, Ani
   Selwal, Arvind
TI A generalized image steganalysis approach via decision level fusion of
   deep models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image steganography; Image steganalysis; Deep learning; Convolution
   neural network; Pre-trained models
ID NETWORK
AB Recent advancements in digital technologies has greatly facilitated the huge growth of complex images over the internet channels leading to security threats causing unauthorised information access. Such complex images are perceived as a reliable means for secret communication. Hence an active research is carried out for steganalysis - a method to determine the presence of hidden information in the multimedia files. The primary challenge faced by the existing steganalysis approaches is, to be able to extract and learn high level feature representations from images of high texture complexity which is somewhat difficult to be achieved by a single deep learning(DL)-based steganalyzer. In this work, we expound an ensemble of deep models with decision level fusion strategy in predicting an image as cover or stego. The ensemble of validated reference models aims to achieve better performance than using a single CNN architecture. The proposed model comprises of three potent pre-trained deep fine-tuned models- VGG19, ResNet50 and Inceptionv3 followed by a majority voting scheme for spatial image steganalysis task. In comparison to convolution neural networks (CNN) specifically created for steganalysis, such as Qian-Net[22],XU-Net[25],Ye-Net[30],Yedroudj-Net[31], Zhu-Net[29], SR-Net[52], GBRASNet[34], trained from scratch, the suggested model performs significantly better. The proposed framework is compared against eight existing competitive state-of-the-art (SOTA) models over a two class dataset. Experiments are conducted on benchmark image dataset BOSSBase1.01 and BOWS2. This claim is substantiated experimentally on two well known content-adaptive steganographic algorithms WOW and S-UNIWARD with payloads 0.2bpp and 0.4bpp respectively. Extensive experiments and evaluations reveal that our proposed approach yields an accuracy of 99.16% on WOW (0.2bpp), 99.21% on WOW (0.4bpp), 99.07% on S-UNIWARD (0.2bpp), and 99.69% on S-UNIWARD (0.4bpp) steganography algorithms. Moreover, our approach results in better generalization performance, reduced training time and increases accuracy (ACC) over the existing state-of-the-art (SOTA) steganalytic architectures.
C1 [Swarnkar, Neelam] Chhattisgarh Swami Vivekananda Tech Univ, Dept Comp Sci & Engn, Durg 490021, India.
   [Thomas, Ani] Chhattisgarh Swami Vivekananda Tech Univ, Dept Informat Technol, Durg 490021, India.
   [Selwal, Arvind] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, India.
C3 Central University of Jammu
RP Swarnkar, N (corresponding author), Chhattisgarh Swami Vivekananda Tech Univ, Dept Comp Sci & Engn, Durg 490021, India.
EM neelamswarnkarnit@gmail.com
OI swarnkar, neelam/0000-0002-9940-4034
CR Agarwal S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110793
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   arstechnica, about us
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Binghamton University, 2015, Steganographic algorithms
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Conway M., 2003, Knowledge Technology & Policy, V16, P45, DOI 10.1007/s12130-003-1026-4
   Denemark T., 2016, Electron. Imag., V28, P1
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Dwaik A, 2022, LECT NOTES COMPUT SC, V13599, P284, DOI 10.1007/978-3-031-20716-7_22
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Holotyak T, 2005, LECT NOTES COMPUT SC, V3677, P273
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kadhim Inas Jawad, 2020, Intelligent Computing Methodologies. 16th International Conference, ICIC 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science. (LNAI 12465), P611, DOI 10.1007/978-3-030-60796-8_53
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kolade O., 2015, J Data Anal Inf Process, V3, P168
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu F, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9020189
   Thampi SM, 2008, Arxiv, DOI arXiv:0802.3746
   Ozcan S, 2018, IEEE INT CONF BIG DA, P2280, DOI 10.1109/BigData.2018.8622437
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Reinel TS, 2021, IEEE ACCESS, V9, P14340, DOI 10.1109/ACCESS.2021.3052494
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shi YQ, 2006, Information Hiding
   Shunxiang Yang, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P2110, DOI 10.1109/CompComm.2018.8780962
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2022, arXiv
   Swarnkar N, 2021, Data Science and Innovations for Intelligent Systems, P209
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tan SQ, 2014, ASIAPAC SIGN INFO PR
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Villa Estrada HF, 2015, Aplicaciones de la esteganografia en la seguridad informatica
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang HW, 2021, IEEE T NETW SCI ENG, V8, P1084, DOI 10.1109/TNSE.2020.2996612
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2020, Pixels-off: Data-augmentation complementary solution for deep-learning steganalysis, DOI [10.1145/3369412.3395061, DOI 10.1145/3369412.3395061]
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zhang H, 2022, IEEE ACCESS, V10, P44116, DOI 10.1109/ACCESS.2022.3150276
   Zhang R, 2018, Arxiv, DOI arXiv:1807.11428
   Zhiping Zhou, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P581, DOI 10.1109/FSKD.2009.230
NR 54
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17068-0
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400028
DA 2024-07-18
ER

PT J
AU Sachar, S
   Kumar, A
AF Sachar, Silky
   Kumar, Anuj
TI A novel transfer learning-based approach for plant species prediction
   using leaf images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional Neural Networks; XGBoost; Machine Learning; Leaf
   identification; Stacking classifier; Ensemble learning
ID CLASSIFICATION
AB There is extensive research going on in the field of automatic identification of plants in order to preserve the plant species which are on the verge of extinction and also to educate people or new generation farmers about the various plants growing in their vicinity. Few plants also possess certain medicinal properties which can be used by the layman to treat commonly occurring ailments. We suggest a novel leaf identification approach using combination of deep learning and conventional machine learning techniques. In this approach, the leaf image features are extracted using a neural network pre-trained on the ImageNet and then fed into the machine learning classifiers for predictions. We prepared three different models and analyzed their performance. Thereafter, we propose an ensemble approach based on stacking classifiers where the predictions of multiple classifiers were used to train a meta-classifier. This approach achieved an accuracy of 99.16% and 98.13% on the unseen samples of Swedish and Flavia datasets respectively.
C1 [Sachar, Silky; Kumar, Anuj] Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
C3 Panjab University
RP Sachar, S (corresponding author), Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
EM silky.sachar@gmail.com
RI SACHAR, SILKY/KHV-3712-2024
OI SACHAR, SILKY/0000-0002-0786-0527
CR Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003
   Beikmohammadi A, 2018, 2018 4TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P21, DOI 10.1109/ICSPIS.2018.8700547
   Bodhwani Vinit, 2019, Procedia Computer Science, V152, P186, DOI 10.1016/j.procs.2019.05.042
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Jasitha P., 2019, 2019 4th International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT), P715, DOI 10.1109/RTEICT46194.2019.9016966
   Naresh YG, 2016, NEUROCOMPUTING, V173, P1789, DOI 10.1016/j.neucom.2015.08.090
   Ni F, 2018, IEEE IMAGE PROC, P1223, DOI 10.1109/ICIP.2018.8451605
   Pearline A, 2019, DDLA: dual deep learning architecture for classification of plant species, DOI [10.1049/iet-ipr.2019.0346, DOI 10.1049/IET-IPR.2019.0346]
   Sachar S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114181
   She YH, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.2.023034
   Soderkvist Oskar., 2001, COMPUTER VISION CLAS, P74
   Sulc M, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0265-4
   Sun Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/7361042
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Turkoglu M, 2019, PHYSICA A, V527, DOI 10.1016/j.physa.2019.121297
   Wäldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Wang B, 2014, IEEE T IMAGE PROCESS, V23, P4101, DOI 10.1109/TIP.2014.2343457
   Ward D., 2018, Deep Leaf Segmentation Using Synthetic Data
   Wu Stephen Gang, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P11, DOI 10.1109/ISSPIT.2007.4458016
   Zaidah Ibrahim, 2018, Indonesian J Electr Eng Comput Sci, V9, P152, DOI DOI 10.11591/IJEECS.V9.I1.PP152-156
NR 20
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17311-8
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900002
DA 2024-07-18
ER

PT J
AU Digumarthi, J
   Gayathri, VM
   Pitchai, R
AF Digumarthi, Jyothirmai
   Gayathri, V. M.
   Pitchai, R.
TI Cardiac arrhythmia detection from ECG signal using Siamese adversarial
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cardiac arrhythmia; ECG signals; Tunicate swarm optimizer; Generative
   adversarial network; Regression model; Gannet optimization; Siamese
   neural network
AB Heart disease is one of the most serious health issues that people faced today. Almost 50 million people worldwide suffer from cardiovascular problems. Electrocardiogram (ECG) signals are more important for diagnosing and monitoring patients with various cardiovascular diseases. This article proposes a novel SANN (Siamese Adversarial Neural Network-based Cardiac Arrhythmia Detection) CAD model for detecting different arrhythmias. First, an optimized Savitzky-Golay (OS-G) digital filter model is used to enhance and smooth the ECG signal. OS-G filtering uses a Tunicate Swarm Optimization (TSO) algorithm to adjust the polynomial order and window size to preserve the characteristics of P, Q, R, S, T, and U waves. A hybrid feature extraction process called Pathfinding Least Absolute Shrinkage and Selection Vector Regression (PLASSVR), which integrates regression analysis and pathfinding optimization, is employed to extract the significant features. The extracted features are fed to a novel Siamese neural network based on the Generative Adversarial Network (SNN-GAN) to classify the signals for arrhythmia disease detection. Furthermore, the Gannet Optimization Algorithm (GOA) is applied in the SNN-GAN model to change the hyperparameters. The proposed SANN CAD model is implemented in the Python platform via the MIT-BIH Arrhythmia Database. The performance of the SANN-CAD model is evaluated against various evaluation criteria and compared to traditional classifiers, using optimization for matching and no optimization for matching. The maximum classification accuracy that the SANN CAD model achieves is 99.74% and 98.23% for with and without optimization, and is superior to conventional classifiers.
C1 [Digumarthi, Jyothirmai; Gayathri, V. M.] SRM Inst Sci & Technol, Fac Engn & Technol, Sch Comp, Dept Networking & Commun, Kattankulathur 603203, Tamil Nadu, India.
   [Pitchai, R.] B V Raju Inst Technol, Dept Comp Sci & Engn, Narsapur 502313, Telangana, India.
C3 SRM Institute of Science & Technology Chennai
RP Digumarthi, J (corresponding author), SRM Inst Sci & Technol, Fac Engn & Technol, Sch Comp, Dept Networking & Commun, Kattankulathur 603203, Tamil Nadu, India.
EM jd6957@srmist.edu.in; gayathrm@srmist.edu.in; pitchrks1984@gmail.com
NR 0
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17071-5
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200017
DA 2024-07-18
ER

PT J
AU Liu, CD
   Peng, KX
   Peng, ZY
   Zhang, XZ
AF Liu, Chengdao
   Peng, Kexin
   Peng, Ziyang
   Zhang, Xingzhi
TI MSFF-UNet: Image segmentation in colorectal glands using an
   encoder-decoder U-shaped architecture with multi-scale feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-scale feature fusion; Feature extraction; U-Net; Boundary loss;
   Gland segmentation
AB Glands are closely related to the diagnosis of tumors. In pathological images, segmentation of the colorectal gland is a prerequisite for quantitative diagnosis. Segmentation algorithms based on deep learning have been widely used in medical images. However, the existing segmentation method has feature fusion only existing in adjacent layers, ignoring cross-layer fusion. And ignoring the combination of local and global information for graphics. To solve the above problems, we propose a multi-scale fusion model (MSFF-UNet) based on U-Net. We enhance the fusion of multi-scale information in the feature fusion module (FFM) and combine spatial attention to highlight the spatial structure of objects. In addition, we use the receptive field extension module (RFEM) to fuse local and global information, thereby reducing information loss and improving segmentation performance. We also propose a boundary loss function, which enables the network to pay more attention to the boundary information and make the segmentation results more accurate. Compared to the U-Net model, our network improved the DICE score by 1.95% and the MIOU score by 2.6%, effectively improving the accuracy of colorectal glandular segmentation.
C1 [Liu, Chengdao; Peng, Kexin; Peng, Ziyang; Zhang, Xingzhi] Chengdu Univ Technol, Coll Comp Sci & Cyber Secur, Chengdu 610059, Peoples R China.
C3 Chengdu University of Technology
RP Peng, KX (corresponding author), Chengdu Univ Technol, Coll Comp Sci & Cyber Secur, Chengdu 610059, Peoples R China.
EM pkx82@cdut.edu.cn
RI Peng, Sylvia/GQH-5869-2022
OI Peng, Sylvia/0000-0002-6591-6509
FU The two colorectal cancer gland segmentation datasets used in this paper
   are public datasets. There is no doubt that they are gold-standard data
   sets. The authors would like to thank all investigators involved in data
   collection.
FX The two colorectal cancer gland segmentation datasets used in this paper
   are public datasets. There is no doubt that they are gold-standard data
   sets. The authors would like to thank all investigators involved in data
   collection.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Dabass M., 2023, Intel-Based Med, V7
   DeSantis CE, 2019, CA-CANCER J CLIN, V69, P452, DOI 10.3322/caac.21577
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Drozdzal M, 2016, INT WORKSH DEEP LEAR, DOI [10.48550/arXiv.1608.04117, DOI 10.48550/ARXIV.1608.04117]
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Lin HB, 2022, ADV INF TECHNOL ELEC, P329, DOI 10.1109/IAEAC54830.2022.9929448
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Mao XQ, 2020, IEEE ENG MED BIO, P1641, DOI [10.1109/embc44109.2020.9175631, 10.1109/EMBC44109.2020.9175631]
   Micikevicius Paulius, 2017, arXiv
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Pi JD, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104800
   Qian LD, 2022, Arxiv, DOI [arXiv:2205.11759, 10.48550/arXiv.2205.11759]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Tian Xuan, 2019, Journal of Software, V30, P440, DOI 10.13328/j.cnki.jos.005659
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2022, J Pract Oncol, V37, P29, DOI [10.13267/j.cnki.syzlzz.2022.005, DOI 10.13267/J.CNKI.SYZLZZ.2022.005]
   Yin X, 2021, Software J, V32, P519, DOI [10.13328/j.cnki.jos.006104, DOI 10.13328/J.CNKI.JOS.006104]
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu Q., 2021, arXiv
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao P, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00670
   Zheng SC, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2020.104183
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhu X., 2021, World Chin J Digestion, V29, P1201, DOI [10.11569/wcjd.v29.i20.1201, DOI 10.11569/WCJD.V29.I20.1201]
NR 35
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17079-x
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800014
DA 2024-07-18
ER

PT J
AU Hu, F
   Li, WH
   Yu, NH
AF Hu, Fei
   Li, Weihai
   Yu, Nenghai
TI (<i>k</i>, <i>n</i>) threshold secret image sharing scheme based on
   Chinese remainder theorem with authenticability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Secret image sharing; Authentication; Chinese remainder theorem; QR code
ID VISUAL CRYPTOGRAPHY SCHEME
AB In the traditional secret image sharing (SIS) scheme, the secret image is divided into several noise-like shares, which lack authentication and may attract the attention of malicious users. Therefore, the authenticability of shadow images may play an important role and is worthy of investigation. Traditional shadow authentication research requires additional image or additional bits for authentication, which may lead to high complexity. In this paper, we propose a novel (k, n) threshold SIS scheme that is based on the Chinese remainder theorem (CRT) with shadow authenticability. Our contribution is that the secret grayscale image is distributed into n shadows, while each shadow image contains authentication information with QR code embedding. Our scheme can realize the 100% detection rate of fake participants when a credible control center is involved. The experimental results confirm that the proposed scheme has low shadow generation, authentication complexity, and the lossless recovery of secret image.
C1 [Hu, Fei; Li, Weihai; Yu, Nenghai] Univ Sci & Technol China, Sch Cyber Sci & Technol, Jinzhai Rd, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Li, WH (corresponding author), Univ Sci & Technol China, Sch Cyber Sci & Technol, Jinzhai Rd, Hefei 230026, Anhui, Peoples R China.
EM feih@mail.ustc.edu.cn; whli@ustc.edu.cn; ynh@ustc.edu.cn
FU National Key Research and Development Program of China [2018YFB0804101];
   National Natural Science Foundation of China [61802357]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFB0804101, in part by the
   National Natural Science Foundation of China under Grant 61802357.
CR Abd El-Latif AA, 2020, IEEE T NETW SERV MAN, V17, P118, DOI 10.1109/TNSM.2020.2969863
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Bhuyan HK, 2023, MULTIMED TOOLS APPL, V82, P7529, DOI 10.1007/s11042-022-13677-3
   Chavan PV, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Cheng JW, 2022, J INF SECUR APPL, V68, DOI 10.1016/j.jisa.2022.103233
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Chuang TW, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P817, DOI 10.1109/IS3C.2016.208
   Denso Wave incorporated, 2000, The quick response code
   Dhawan S, 2023, MULTIMED TOOLS APPL, V82, P14527, DOI 10.1007/s11042-022-13798-9
   Fei Hu, 2020, Artificial Intelligence and Security. 6th International Conference (ICAIS 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12240), P86, DOI 10.1007/978-3-030-57881-7_8
   Fu ZX, 2018, IEEE ACCESS, V6, P59567, DOI 10.1109/ACCESS.2018.2874527
   Hadke Divya, 2020, 2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P1284, DOI 10.1109/I-SMAC49090.2020.9243362
   Hao Luo, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P60
   Hu C, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691312500233
   Hu F, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/7864235
   Jiang Y, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8020234
   Ke Y, 2022, IEEE T CIRC SYST VID, V32, P2469, DOI 10.1109/TCSVT.2021.3081575
   Komargodski I, 2017, J CRYPTOL, V30, P444, DOI 10.1007/s00145-015-9226-0
   Liu JJ, 2021, MATH BIOSCI ENG, V18, P2473, DOI 10.3934/mbe.2021126
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pan JS, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103405
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Wan S, 2020, MULTIMED TOOLS APPL, V79, P2789, DOI 10.1007/s11042-019-08246-0
   Wan S, 2018, J REAL-TIME IMAGE PR, V14, P25, DOI 10.1007/s11554-017-0678-3
   Wang W, 2017, LECT NOTES COMPUT SC, V10431, P406, DOI 10.1007/978-3-319-64185-0_30
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Xiong LZ, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108064
   Yan WQ., 2000, J. North China Univ. Technol, V12, P6
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
   Yan XH, 2017, LECT NOTES COMPUT SC, V10603, P433, DOI 10.1007/978-3-319-68542-7_36
   Yang CN, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102910
   Yang GZ, 2020, MATH BIOSCI ENG, V17, P4295, DOI 10.3934/mbe.2020237
   Zhang C, 2022, IEEE T INTELL TRANSP, V23, P12877, DOI [10.1109/TITS.2021.3118206, 10.1109/TDSC.2022.3208706]
   Zhang C, 2022, IEEE J SEL AREA COMM, V40, P3343, DOI 10.1109/JSAC.2022.3213341
   Zhao XM, 2021, INT J DIGIT CRIME FO, V13, P16, DOI 10.4018/IJDCF.20210701.oa2
NR 37
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-17270-0
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100007
DA 2024-07-18
ER

PT J
AU Hayat, MK
   Daud, A
   Banjar, A
   Alharbey, R
   Bukhari, A
AF Hayat, Malik Khizar
   Daud, Ali
   Banjar, Ameen
   Alharbey, Riad
   Bukhari, Amal
TI A deep co-evolution architecture for anomaly detection in dynamic
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anomaly Detection; Deep Co-evolution Architecture; Deep Learning; Graph
   Neural Network; Heterogeneous Information Network.
ID FRAMEWORK
AB Heterogeneous Information Networks (HINs) are ubiquitous in the real world, and discovering anomalies is essential for understanding network semantics through nodes and edges. Evolution in the nodes along with their attributes leverages the probability of anomalies in the network. Recently, detecting anomalous nodes on attributed graphs has attracted an increasing amount of research attention, with wide-ranging applications in various high-impact domains, such as cybersecurity, finance, healthcare, social networks, and so on. Most of the existing efforts try to capture the evolution structure for anomaly detection problem in HINs with emphasis on the nodes merely. However, technically, in a dynamic attributed network, anomalies occur due to the co-evolution of node attributes that is ignored and needs attention. Consequently, modeling the co-evolution of attributes and their influence over linked nodes is important to tackle the anomaly detection problem. In this paper, we propose a DEep Co-evolution architecture for anOmaly DetEction (DECODE) in HINs. Particularly, the proposed architecture learns the combined embeddings for node and attributes for time-evolving attributed networks. A three-layered Graph Neural Network (GNN) is used for network embedding learning. The approximated Betweenness Centrality (BC) measure is employed to model the dynamic influence of attributes over linked nodes in a Long Short-term Memory (LSTM) layer. The combinatorial effect of GNN and LSTM helps to spot the anomalies by computing network reconstruction errors in terms of both nodes and attributes. Experimentation on real-world dataset depicts the effectiveness of the proposed architecture with the 10.74% performance increase in BlogCatalog, 9.59% in Amazon, and 17.1% increase in ArnetMiner data.
C1 [Hayat, Malik Khizar] Macquarie Univ, Fac Sci & Engn, Sch Comp, Sydney, NSW, Australia.
   [Daud, Ali] Rabdan Acad, Fac Resilience, Abu Dhabi, U Arab Emirates.
   [Banjar, Ameen; Alharbey, Riad; Bukhari, Amal] Univ Jeddah, Coll Comp Sci & Engn, Dept Informat Syst & Technol, Jeddah, Saudi Arabia.
C3 Macquarie University; University of Jeddah
RP Hayat, MK (corresponding author), Macquarie Univ, Fac Sci & Engn, Sch Comp, Sydney, NSW, Australia.; Daud, A (corresponding author), Rabdan Acad, Fac Resilience, Abu Dhabi, U Arab Emirates.
EM malik.khizar@students.mq.edu.au; alimsdb@gmail.com; abanjar@uj.edu.sa;
   ralharbi@uj.edu.sa; aabukhari@uj.edu.sa
RI Bukhari, Amal/GWV-4744-2022; Hayat, Malik Khizar/AAH-4881-2020; Daud,
   Ali/ABA-8422-2020
OI Bukhari, Amal/0000-0003-4888-6253; Hayat, Malik
   Khizar/0000-0001-8177-2042; Daud, Ali/0000-0002-8284-6354
CR Akoglu L, 2015, DATA MIN KNOWL DISC, V29, P626, DOI 10.1007/s10618-014-0365-y
   Alvarez AM, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1545, DOI 10.1145/2505515.2507840
   [Anonymous], 2012, ser. KDD '12, DOI DOI 10.1145/2339530.2339667
   Bhatia S., 2021, arXiv
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chang SY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P119, DOI 10.1145/2783258.2783296
   Chaudhary Anshika, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P346, DOI 10.1109/COMITCon.2019.8862186
   Chen L-H, 2023, Inf Sci
   Cui P, 2019, IEEE T KNOWL DATA EN, V31, P833, DOI 10.1109/TKDE.2018.2849727
   Defferrard M, 2016, ADV NEUR IN, V29
   Ding K., 2019, P 2019 SIAM INT C DA, P594
   Gao J., 2010, P INT C KNOWL DISC D, P813, DOI DOI 10.1145/1835804.1835907
   Gupta Manish, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P692, DOI 10.1007/978-3-642-33486-3_44
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hayat MK, 2017, SCIENTOMETRICS, V113, P149, DOI 10.1007/s11192-017-2467-y
   Huang SY, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P349, DOI 10.1145/3394486.3403077
   Huang X, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P731, DOI 10.1145/3018661.3018667
   Kaur R, 2016, EGYPT INFORM J, V17, P199, DOI 10.1016/j.eij.2015.11.004
   Kingma D. P., 2014, arXiv
   Kwon D, 2019, CLUSTER COMPUT, V22, P949, DOI 10.1007/s10586-017-1117-8
   Hamilton WL, 2018, Arxiv, DOI [arXiv:1709.05584, 10.48550/arXiv.1709.05584]
   Li JD, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2152
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Luo XX, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P657, DOI 10.1145/3488560.3498389
   Ma RR, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P704, DOI 10.1145/3488560.3498473
   Ma XX, 2022, Arxiv, DOI arXiv:2106.07178
   Maurya SK, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2149, DOI 10.1145/3357384.3358080
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Peng Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3513
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1346, DOI 10.1145/2623330.2623682
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shao ML, 2023, KNOWL-BASED SYST, V260, DOI 10.1016/j.knosys.2022.110084
   Shaukat K., 2020, 2020 INT C CYBER WAR, P1, DOI DOI 10.1109/ICCWS48432.2020.9292388
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Tan QY, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00002
   Teng X, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P827, DOI 10.1145/3132847.3132964
   Tengfei Ji, 2012, Web-Age Information Management. Proceedings of the 13th International Conference, WAIM 2012, P434, DOI 10.1007/978-3-642-32281-5_42
   Tian K, 2017, LECT NOTES ARTIF INT, V10535, P809, DOI 10.1007/978-3-319-71246-8_49
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang RY, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P894, DOI 10.1145/3336191.3371876
   Wang XH, 2021, NEURAL COMPUT APPL, V33, P12073, DOI 10.1007/s00521-021-05924-9
   Xue LG, 2020, NEUROCOMPUTING, V407, P39, DOI 10.1016/j.neucom.2020.04.047
   Yu WC, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2672, DOI 10.1145/3219819.3220024
   Zhang DK, 2020, IEEE T BIG DATA, V6, P3, DOI 10.1109/TBDATA.2018.2850013
   Zheng CH, 2020, IEEE T NEUR NET LEAR, V31, P1437, DOI 10.1109/TNNLS.2019.2920267
NR 46
TC 1
Z9 1
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17126-7
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400011
DA 2024-07-18
ER

PT J
AU Devi, TAM
   Jose, VIM
AF Devi, T. Arumuga Maria
   Jose, V. I. Mebin
TI Skip and chain connected deep fusion network for lung cancer screening
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional Neural Network (CNN); Frequency Deep Neural Network
   (FDNN); Spatial Deep Neural Network (SDNN) Lung Cancer; Deep neural
   network (DNN); Support Vector Machine (SVM); Rectified Linear Unit
   (ReLu)
ID COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION
AB The second most prevalent and deadly disease in the world is lung cancer. It is become more difficult to detect lung cancer in its early stages in humans. A novel deep learning architecture is suggested in this study to identify lung cancer in its early stages. To distinguish between the diseased and healthy samples, the suggested deep learning structure facilitates in-depth analysis and the creation of superior feature maps. Two independent deep neural network models are combined in the proposed H-DNN (Hybrid deep neural networks) architecture. DNN-1 or SC-SDNN, the first neural network, is used to analyse spatial data, and DNN-2 or CC-FDNN, the second neural network, is used to evaluate frequency data. In order to prevent vanishing gradients, we also added the short connection in the first deep network and the chain connection in the second. Finally, to achieve a better result, we combine both neural networks. The first neural network uses spatial information from the original raw image as its training input, whereas the second neural network uses frequencies generated by wavelets. Our technique outperformed more traditional CNN and SVM classifiers, with a classification accuracy of 98.2%.
C1 [Devi, T. Arumuga Maria; Jose, V. I. Mebin] Manonmanium Sundaranar Univ, Tirunelveli, India.
C3 Manonmaniam Sundaranar University
RP Devi, TAM (corresponding author), Manonmanium Sundaranar Univ, Tirunelveli, India.
EM deviciteuniversity@gmail.com; josemebin@gmail.com
CR Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Chen S, 2020, ARTIF INTELL MED, V107, DOI 10.1016/j.artmed.2020.101881
   Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479
   de Carvalho AO, 2017, J SIGNAL PROCESS SYS, V87, P179, DOI 10.1007/s11265-016-1134-5
   Demir Cigdem, 2005, TECH REP
   Devi T. Arumuga Maria, 2016, 2016 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT), P788, DOI 10.1109/ICCICCT.2016.7988059
   Devi TAM, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P829, DOI 10.1109/ICCICCT.2015.7475394
   El-Baz A, 2013, INT J BIOMED IMAGING, V2013, DOI [10.1155/2013/942353, 10.1155/2013/517632]
   Fang TT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P286, DOI 10.1109/CCET.2018.8542189
   Firmino M, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-41
   Gomathi M., 2010, American Journal of Applied Sciences, V7, P1532, DOI 10.3844/ajassp.2010.1532.1538
   Gordienko Y, 2018, P INT C COMP SCI ENG, P638
   Hashemi Atiyeh, 2013, International Journal of Image, Graphics and Signal Processing, V5, P16, DOI 10.5815/ijigsp.2013.06.03
   Hosny A, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002711
   Hua KL, 2015, ONCOTARGETS THER, V8, P2015, DOI 10.2147/OTT.S80733
   Jaffar MA, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2, P265, DOI 10.1109/CIMCA.2008.168
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jeyalakshmi A, 2015, DIGIT IMAGE PROCESS, V7, P291
   Jose V, 2017, INT J LATEST TRENDS, V8, p125 130
   Kawagishi M, 2017, INT J COMPUT ASS RAD, V12, P767, DOI 10.1007/s11548-017-1554-0
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Kurniawan E., 2020, Journal of Physics: Conference Series, V1505, DOI 10.1088/1742-6596/1505/1/012018
   Li Z, 2018, COMPUTER AIDED DIAGN
   Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Nishio M, 2017, ACAD RADIOL, V24, P328, DOI 10.1016/j.acra.2016.11.007
   Patz EF, 2014, JAMA INTERN MED, V174, P269, DOI 10.1001/jamainternmed.2013.12738
   Polat H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050940
   Qin RX, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/6153657
   Sakthi T. S., 2016, INT ADV RES J SCI EN, V3, P29
   Shakeel PM, 2019, MEASUREMENT, V145, P702, DOI 10.1016/j.measurement.2019.05.027
   Song QZ, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8314740
   Sun W., 2016, SPIE Medical Imaging, p97850Z, DOI DOI 10.1117/12.2216307
   Suzuki K, 2017, 2017 INTERNATIONAL CONFERENCE ON GREEN ENERGY AND APPLICATIONS (ICGEA 2017), P90, DOI 10.1109/ICGEA.2017.7925461
   Taher F., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P295, DOI 10.1109/IEEEGCC.2011.5752535
   Wang SD, 2020, OPEN MED-WARSAW, V15, P190, DOI 10.1515/med-2020-0028
   Xu YW, 2019, CLIN CANCER RES, V25, P3266, DOI 10.1158/1078-0432.CCR-18-2495
   Zhang YD, 2017, CNS NEUROL DISORD-DR, V16, P122, DOI 10.2174/1871527315666161026115046
   Zhao XQ, 2021, INT J COAL PREP UTIL, V41, P830, DOI [10.1080/19392699.2018.1536045, 10.1007/s11548-017-1696-0]
NR 40
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17110-1
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500007
DA 2024-07-18
ER

PT J
AU Garg, S
   Jindal, B
AF Garg, Shelly
   Jindal, Balkrishan
TI FDLM: An enhanced feature based deep learning model for skin lesion
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Skin Lesion Detection; Deep Learning; Shape Descriptors; Medical
   Imaging; CNN
ID CLASSIFICATION; MELANOMA
AB Automated technologies are increasingly widespread in health care and are used to diagnose crucial disorders such as cancer cells. A skin lesion is a kind of skin cancer with benign and malignant components, and early detection is becoming a typical need. Many researchers have established these types of techniques in the past, yet the need for an efficient method still exists to improve the performance of the skin cancer detection process. Deep learning technology is chosen in this research to detect skin lesions from the provided samples. An improved LeNET method is trained with a feature set optimized using the cuckoo search technique. Here, the feature-based deep learning model presents the novelty of the technique designed with various hybrid shape descriptors and compares their performance. Based on accuracy, a feature-based Convolution Neural Network (CNN) with hybrid SURF and ORB has the highest accuracy of 99.62% for skin lesion detection compared to other distinct combinations used in this work. The findings illustrate the usefulness of several hybrid features and their performance with a deep learning model for skin lesion detection.
C1 [Garg, Shelly] Dronacharya Coll Engn, Dept Elect & Commun, Gurugram 123506, Haryana, India.
   [Jindal, Balkrishan] Punjabi Univ Campus, Yadavindra Coll Engn, Talwandi Sabo 151302, Punjab, India.
C3 Punjabi University
RP Garg, S (corresponding author), Dronacharya Coll Engn, Dept Elect & Commun, Gurugram 123506, Haryana, India.
EM shellygarg96@gmail.com; balkrishan_76@rediffmail.com
OI , Shelly Garg/0000-0002-5139-472X
CR AbdulRaheem M., 2023, ParadigmPlus, V4, P1, DOI [10.55969/paradigmplus.v4n1a1, DOI 10.55969/PARADIGMPLUS.V4N1A1]
   Abualigah L., 2019, Int J Sci Appl Inf Technol, V8, P66, DOI [10.30534/ijsait/2019/098620198, DOI 10.30534/IJSAIT/2019/098620198]
   Abuzaghleh O, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Adjed F, 2016, AIP CONF PROC, V1787, DOI 10.1063/1.4968145
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Al MM., 2021, J Comput Commun, V09, P67, DOI [10.4236/jcc.2021.94005, DOI 10.4236/JCC.2021.94005]
   Alcón JF, 2009, IEEE J-STSP, V3, P14, DOI 10.1109/JSTSP.2008.2011156
   [Anonymous], 2021, KEY STAT MELANOMA SK
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Bansal N., 2020, Int J Appl Eng Res, V15, P1116, DOI DOI 10.37622/IJAER/15.12.2020.1116-1121
   Byrd AL, 2018, NAT REV MICROBIOL, V16, P143, DOI 10.1038/nrmicro.2017.157
   Cook BE, 2001, OPHTHALMOLOGY, V108, P2088, DOI 10.1016/S0161-6420(01)00796-5
   Craythorne E., 2017, Medicine, V45, P431, DOI [DOI 10.1016/J.MPMED.2017.04.003, 10.1016/j.mpmed.2017.04.003]
   Deivanayagampillai N., 2017, International Journal of Multimedia and Ubiquitous Engineering, V12, P19, DOI [10.14257/ijmue.2017.12.5.02, DOI 10.14257/IJMUE.2017.12.5.02]
   Dildar M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105479
   Elgamal M, 2013, INT J ADV COMPUT SC, V4, P287
   Garg S, 2022, INT ARAB J INF TECHN, V19, P29, DOI 10.34028/iajit/19/1/4
   Garg S, 2021, MULTIMED TOOLS APPL, V80, P7397, DOI 10.1007/s11042-020-10064-8
   Gupta Rinki, 2020, Procedia Computer Science, V171, P1542, DOI 10.1016/j.procs.2020.04.165
   Ide H, 2017, IEEE IJCNN, P2684, DOI 10.1109/IJCNN.2017.7966185
   Javed R, 2019, Int J Adv Trends Comput Sci Eng, V8, P95, DOI DOI 10.30534/IJATCSE/2019/1581.62019
   Jindal B, 2023, MULTIMED TOOLS APPL, V82, P6053, DOI 10.1007/s11042-022-13589-2
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Khehra BS, 2022, MULTIMED TOOLS APPL, V81, P17509, DOI 10.1007/s11042-022-12017-9
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Miglani V, 2021, Skin Lesion Classification: A Transfer Learning Approach Using EfficientNets, P315
   Mitra S, 2015, INFORM SCIENCES, V306, P111, DOI 10.1016/j.ins.2015.02.015
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Paul D, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3447586
   R D Seeja, 2019, Asian Pac J Cancer Prev, V20, P1555
   Rotemberg V, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00815-z
   Suárez-Paniagua V, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2195-1
   Suganya R, 2016, INT CONF RECENT
   Togaçar M, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110714
   Upadhyay PK, 2022, J KING SAUD UNIV-COM, V34, P520, DOI 10.1016/j.jksuci.2019.02.007
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Zhang CW, 2019, J ALGORITHMS COMPUT, V13, DOI 10.1177/1748302619873601
NR 39
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17143-6
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600005
DA 2024-07-18
ER

PT J
AU Gupta, M
   Tanwar, S
   Bhatia, TK
   Badotra, S
   Hu, YC
AF Gupta, Medini
   Tanwar, Sarvesh
   Bhatia, Tarandeep Kaur
   Badotra, Sumit
   Hu, Yu-Chen
TI A comparative study on blockchain-based distributed public key
   infrastructure for IoT applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; IoT; PKI; Certificate authority; Smart contract
ID ENCRYPTION; INTERNET
AB Internet of Things (IoT) has gained wide popularity due to its implementation in smart homes and wearables. IoT centralized system increases the risk of a single point of failure and thus reduces the scalability. Public Key Infrastructure (PKI) mitigates these security concerns by providing digital certificates which act as identity proof with a limited lifetime. Certificate Authority (CA) grants public key certificates that consist not only of users but also of servers and software. Once the private key is exposed then an attacker can misuse the information that is intended for the receiver. IoT has low computational power, which can disrupt the encryption process. Blockchain has been transforming cyberspace since its inception as the fundamental technology behind the emergence of cryptocurrencies. Blockchain's key features consist of decentralization, transparency, immutability, encryption, peer to peer which will overcome the shortcomings of IoT infrastructure. Blockchain records every transaction in the blocks, which are secured by hashing algorithms. Smart contracts will be implemented in the PKI and will be executed when certain conditions are fulfilled. PKI with IoT lacks trust in the certificate and the high cost of signing the certificate. IoT with blockchain has real-life use cases in different sectors such as medicine, supply chain, smart home automation, and so on. In this paper, we have done a comparative analysis of existing work by various researchers and focused on the challenges of PKI with IoT, and provided potential solutions for blockchain Implementation with PKI and IoT.
C1 [Gupta, Medini; Tanwar, Sarvesh] Amity Univ Uttar Pradesh, Amity Inst Informat Technol, Noida, Uttar Pradesh, India.
   [Bhatia, Tarandeep Kaur] Univ Petr & Energy Studies UPES Bidholi, Sch Comp Sci, Dehra Dun, India.
   [Badotra, Sumit] Bennett Univ, Sch Comp Sci & Engn, Noida, Uttar Pradesh, India.
   [Hu, Yu-Chen] Tunghai Univ, Dept Comp Sci, Taichung, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
C3 Amity University Noida; Tunghai University; Providence University -
   Taiwan
RP Hu, YC (corresponding author), Tunghai Univ, Dept Comp Sci, Taichung, Taiwan.; Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
EM guptamedini642@gmail.com; s.tanwar1521@gmail.com;
   tarandeepkaur42@gmail.com; summi.badotra@gmail.com; ychu@thu.edu.tw
OI Tanwar, Sarvesh/0000-0003-0136-0182; Hu, Yu-Chen/0000-0002-5055-3645
CR Abbas S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237927
   Aini Q., 2023, APTISI T MANAG, V7, P1, DOI DOI 10.33050/ATM.V7I3.1922
   Alamri M, 2019, INT J COMPUT SCI NET, V19, P244
   Ali Reham Abdelrazek, 2022, Blockchain based Internet of Things. Lecture Notes on Data Engineering and Communications Technologies (112), P81, DOI 10.1007/978-981-16-9260-4_4
   Axon Louise., 2015, Cdt Technical Paper Series, V21, P15
   Badotra Sumit, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P38, DOI 10.1109/ICRITO48877.2020.9197807
   Brotsis S, 2021, COMPUT NETW, V191, DOI 10.1016/j.comnet.2021.108005
   Casino F, 2019, TELEMAT INFORM, V36, P55, DOI 10.1016/j.tele.2018.11.006
   Cheng JR, 2021, MULTIMED TOOLS APPL, V80, P30623, DOI 10.1007/s11042-020-09368-6
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Devi A, 2023, MULTIMED TOOLS APPL, V82, P19021, DOI 10.1007/s11042-022-14154-7
   Dorri Ali, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P618, DOI 10.1109/PERCOMW.2017.7917634
   Doukas C, 2012, IEEE INT C BIOINF BI, P25, DOI 10.1109/BIBE.2012.6399701
   Fan Q, 2021, J SYST ARCHITECT, V117, DOI 10.1016/j.sysarc.2021.102112
   Gao YL, 2021, MULTIMED TOOLS APPL, V80, P30677, DOI 10.1007/s11042-020-09867-6
   Garba A, 2023, IEEE ACCESS, V11, P28370, DOI 10.1109/ACCESS.2023.3259068
   Gupta M, 2021, 2021 9 INT C REL INF, P1
   Hewa T, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148820
   Jiang WB, 2019, FUTURE GENER COMP SY, V96, P185, DOI 10.1016/j.future.2019.01.026
   Kairaldeen AR, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042106
   Kamal R, 2021, MULTIMED TOOLS APPL, V80, P36183, DOI 10.1007/s11042-021-11350-9
   Kfoury E, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1116, DOI 10.1109/Cybermatics_2018.2018.00203
   Khashan OA, 2023, J KING SAUD UNIV-COM, V35, P726, DOI 10.1016/j.jksuci.2023.01.011
   Kubilay MY, 2019, COMPUT SECUR, V85, P333, DOI 10.1016/j.cose.2019.05.013
   Lozupone V, 2018, INT J INFORM MANAGE, V38, P42, DOI 10.1016/j.ijinfomgt.2017.08.004
   Manolache MA, 2022, PROCEDIA COMPUT SCI, V199, P580, DOI 10.1016/j.procs.2022.01.071
   Meisami S, 2023, Arxiv, DOI arXiv:2304.00127
   Pal O, 2021, ICT EXPRESS, V7, P76, DOI 10.1016/j.icte.2019.08.002
   Panigrahi A, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4655
   Pavithran Deepa, 2019, 2019 Sixth HCT Information Technology Trends (ITT), P110, DOI 10.1109/ITT48889.2019.9075105
   Ratta P, 2021, J FOOD QUALITY, V2021, DOI 10.1155/2021/7608296
   Reddy MIS., 2011, J Inf Eng Appl, V1, P29
   Schukat M, 2015, 2015 26TH IRISH SIGNALS AND SYSTEMS CONFERENCE (ISSC)
   Sharma V, 2020, 2020 INT C EM TRENDS, P1
   Singla A, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P9, DOI 10.1109/CIC.2018.00-45
   Tan SY, 2015, MULTIMED TOOLS APPL, V74, P6481, DOI 10.1007/s11042-014-2119-7
   Tanwar S., 2021, INT J APPL SCI ENG, V18, P1, DOI [DOI 10.6703/IJASE.202109_18(5).010, 10.6703/ijase.202109_18, DOI 10.6703/IJASE.202109_18]
   Tanwar S, 2017, INT J INF SECUR PRIV, V11, P1, DOI 10.4018/IJISP.2017070101
   Viriyasitavat W, 2022, ENTERP INF SYST-UK, V16, DOI 10.1080/17517575.2022.2037162
   Yakubov A, 2018, IEEE IFIP NETW OPER
NR 40
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16970-x
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600002
DA 2024-07-18
ER

PT J
AU Sharma, P
   Gangadharappa, M
AF Sharma, Preeti
   Gangadharappa, M.
TI An attention-augmented driven modified two-fold U-net anomaly detection
   model for video surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image augmentation; Anomaly detection; Video surveillance;
   Encoder-decoder model; Localization
AB We propose an effective strategy for detecting and localizing anomalous behavior using a modified end-to-end two-stage encoder-decoder U-shaped network. By building the model from scratch for the detection, segmentation, and classification of an anomalous event in video sequences. The encoder model is helpful for feature extraction which is input to the bottleneck block. The resulting feature maps serve as input to the decoder path which is responsible for transposing feature maps to the original image. For precise localization of anomaly, we included the augmentation feature of both images and their masks in the proposed U-net model. In a two-stage U-net network, the first model is useful for the detection of video frames while the same U-net model is used in the second stage for augmentation of detected video frames from first model, which provides segmentation and classification of images. This precise symmetric path-based architecture is useful in good spatial localization of anomalous events. We apply a pixel-based threshold value for Intersection over Union score to distinguish the pixels. Pixels having values greater than the threshold are considered anomalous or otherwise normal with an IoU score of 0. We have evaluated our two-stage U-net model performance on three benchmark standard datasets and compared performance with the Conventional U-net model, and Attention-U-net models without augmentation features. Our method combines spatial details and deep features that yield an improved accuracy of 99.15%, a mean intersection over union score of 82.33 and 99% ROC values that are higher as compared to other methods.
C1 [Sharma, Preeti] Guru Gobind Singh Indraprastha Univ, Elect & Commun, Delhi, India.
   [Gangadharappa, M.] Netaji Subhas Univ Technol, Elect & Commun, East Campus, Delhi, India.
C3 GGS Indraprastha University; Netaji Subhas University of Technology
RP Sharma, P (corresponding author), Guru Gobind Singh Indraprastha Univ, Elect & Commun, Delhi, India.
EM preetikapil.kec@gmail.com; gangadharaccess@gmail.com
CR Aggarwal A.K., 2022, Int J Biol Biomed, V7
   Anjum N, 2008, IEEE T CIRC SYST VID, V18, P1555, DOI 10.1109/TCSVT.2008.2005603
   Bansod SD, 2020, VISUAL COMPUT, V36, P609, DOI 10.1007/s00371-019-01647-0
   Benabbas Y, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/163682
   Bouindour S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040757
   Cai YH, 2021, NEUROCOMPUTING, V423, P264, DOI 10.1016/j.neucom.2020.10.044
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cruz-Esquivel E, 2022, IEEE ACCESS, V10, P6208, DOI 10.1109/ACCESS.2022.3142247
   HASAN MK, 2016, COMMUNICATION, P1, DOI DOI 10.1109/CVPR.2016.86
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jinshu Ji, 2018, Multi-disciplinary Trends in Artificial Intelligence. 12th International Conference, MIWAI 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11248), P69, DOI 10.1007/978-3-030-03014-8_6
   Kaltsa V, 2014, IEEE IMAGE PROC, P2353, DOI 10.1109/ICIP.2014.7025477
   Kar MK., 2021, SN Computer Sci, V2, P397, DOI DOI 10.1007/S42979-021-00784-5
   Kaur A, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115686
   Kim Y, 2022, J KING SAUD UNIV-COM, V34, P3273, DOI 10.1016/j.jksuci.2022.04.011
   Li NJ, 2019, NEUROCOMPUTING, V369, P92, DOI 10.1016/j.neucom.2019.08.044
   Li YY, 2019, IEEE ACCESS, V7, P172425, DOI 10.1109/ACCESS.2019.2954540
   Liu B, 2009, ULTRASOUND MED BIOL, V35, P1309, DOI 10.1016/j.ultrasmedbio.2008.12.007
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Ma K, 2015, ANOMALY DETECTION CR, P2
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Noceti N, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3086591
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ouardini K, 2019, LECT NOTES COMPUT SC, V11795, P225, DOI 10.1007/978-3-030-33391-1_26
   Prajna Y, 2022, J INTELL FUZZY SYST, V42, P3477, DOI 10.3233/JIFS-211479
   Qiang Y, 2021, IEEE ACCESS, V9, P68108, DOI 10.1109/ACCESS.2021.3077577
   Ramya R, 2020, CIRC SYST SIGNAL PR, V39, P789, DOI 10.1007/s00034-019-01144-8
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ren H, 2016, ARXIV
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Shan J, 2012, MED PHYS, V39, P5669, DOI 10.1118/1.4747271
   Sikdar A, 2020, NEUROCOMPUTING, V415, P317, DOI 10.1016/j.neucom.2020.07.058
   Singh K, 2020, NEUROCOMPUTING, V371, P188, DOI 10.1016/j.neucom.2019.08.059
   Srinivasan A, 2019, MULTIMED TOOLS APPL, V78, P7713, DOI 10.1007/s11042-018-6348-z
   Xiao T, 2015, LECT NOTES COMPUT SC, V9007, P66, DOI 10.1007/978-3-319-16814-2_5
   Xu D., 2015, ARXIV
   Zhang QQ, 2022, MULTIMED TOOLS APPL, V81, P27073, DOI 10.1007/s11042-021-11550-3
   Zhao B., 2016, IEEE J INTELL SYST, V31, P29
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
NR 42
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32019
EP 32040
DI 10.1007/s11042-023-16728-5
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900006
DA 2024-07-18
ER

PT J
AU Du, HS
   Zhang, YH
   Wang, YX
   He, LB
AF Du, Haishun
   Zhang, Yonghao
   Wang, Yuxi
   He, Linbing
TI Double-constrained structured discriminant analysis-synthesis dictionary
   pair learning for pattern classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern classification; Sparse coding; Discriminant dictionary learning;
   Discriminant dictionary pair learning
ID SPARSE REPRESENTATION; FACE RECOGNITION; ROBUST; ILLUMINATION; MODELS
AB Existing discriminant analysis-synthesis dictionary pair learning (ASDPL) methods learn a structured analysis dictionary containing multiple class-specific analysis sub-dictionaries and a structured synthesis dictionary containing multiple class-specific synthesis sub-dictionaries. Although existing discriminant ASDPL methods achieve promising results in the field of pattern classification, most of them ignore the correlation between an analysis sub-dictionary and a synthesis sub-dictionary that belong to different classes, which may degrade the discriminative ability of their learned dictionary pairs. Moreover, most existing discriminant ASDPL methods do not give an explicit constraint to ensure that the reconstruction error of training samples under the joint action of a structured analysis dictionary and a structured synthesis dictionary is as small as possible, leading to insufficient representational ability of their learned dictionary pairs. To address these issues, we present a double-constrained structured discriminant analysis-synthesis dictionary pair learning (DCSDDPL) method. Specifically, we first design a class-specific analysis-synthesis sub-dictionary pair reconstruction constraint term to ensure that the reconstruction error of training samples of a class is as small as possible under the joint action of the analysis and synthesis sub-dictionaries belonging to the same class, which helps to improve the representational ability of the learned dictionary pair. Then, we design an analysis-synthesis sub-dictionary pair independence constraint term to eliminate the correlation between an analysis sub-dictionary and a synthesis sub-dictionary belonging to different classes so as to ensure the discriminative ability of the learned dictionary pair. Finally, we formulate the DCSDDPL model by integrating the two constraint terms into the basic discriminant analysis-synthesis dictionary pair learning model. Moreover, we design an optimization algorithm and use it to obtain the solution of the DCSDDPL model. We experimentally compare our method with five state-of-the-art dictionary learning methods, D-KSVD, LC-KSVD, FDDPL, DASDL and RA-DPL on the Extended Yale B, AR, PIE, CLD 22, Scene 15 and Caltech 101 datasets. The highest classification accuracy achieved by our method on these datasets is 99.13% and the highest F1-Score is 0.9906. The experimental results confirm that our method is effective for pattern classification.
C1 [Du, Haishun; Zhang, Yonghao; Wang, Yuxi; He, Linbing] Henan Univ, Sch Artificial Intelligence, Zhengzhou 450046, Peoples R China.
C3 Henan University
RP Du, HS (corresponding author), Henan Univ, Sch Artificial Intelligence, Zhengzhou 450046, Peoples R China.
EM jddhs@vip.henu.edu.cn; zyhao@henu.edu.cn; yuxiw@henu.edu.cn;
   linbinghe@henu.edu.cn
OI Du, Haishun/0000-0003-0883-8118
FU Science and Technology Development Plan Project of Henan Province, China
   [222102110135]; Natural Science Foundation of Henan Province, China
   [202300410093]
FX This work is supported in part by the Science and Technology Development
   Plan Project of Henan Province, China (No. 222102110135) and the Natural
   Science Foundation of Henan Province, China (No. 202300410093).
CR Benavente R, 1998, 24 COMP VIS CTR
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Chang HY, 2019, IEEE ACCESS, V7, P55398, DOI 10.1109/ACCESS.2019.2912932
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du HS, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106794
   Du HS, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.031
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Foroughi H, 2018, IEEE T IMAGE PROCESS, V27, P806, DOI 10.1109/TIP.2017.2766446
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gu SH, 2014, ADV NEUR IN, V27
   Guo J, 2016, AAAI CONF ARTIF INTE, P1617
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He R, 2014, IEEE T PATTERN ANAL, V36, P770, DOI 10.1109/TPAMI.2013.188
   Nguyen H, 2016, NEUROCOMPUTING, V173, P541, DOI 10.1016/j.neucom.2015.07.031
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li Z, 2021, J AMBIENT INTELL HUM, VComput
   Li ZM, 2019, NEURAL NETWORKS, V119, P93, DOI 10.1016/j.neunet.2019.07.013
   Liao MM, 2019, DIGIT SIGNAL PROCESS, V90, P110, DOI 10.1016/j.dsp.2019.04.006
   Lin GJ, 2018, PATTERN RECOGN, V81, P341, DOI 10.1016/j.patcog.2018.03.021
   Liu BD, 2016, NEUROCOMPUTING, V204, P198, DOI 10.1016/j.neucom.2015.08.128
   LU CS, 1971, ELECTRON LETT, V7, P185, DOI 10.1049/el:19710123
   Ophir B, 2011, IEEE J-STSP, V5, P1014, DOI 10.1109/JSTSP.2011.2155032
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Rubinstein R, 2014, IEEE T SIGNAL PROCES, V62, P5962, DOI 10.1109/TSP.2014.2360157
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Shao S, 2020, NEUROCOMPUTING, V385, P122, DOI 10.1016/j.neucom.2019.12.071
   Shekhar S, 2014, IEEE IMAGE PROC, P5207, DOI 10.1109/ICIP.2014.7026054
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YL, 2020, IEEE T NEUR NET LEAR, V31, P4303, DOI 10.1109/TNNLS.2019.2954545
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang W, 2019, INT CONF ACOUST SPEE, P3682, DOI [10.1109/ICASSP.2019.8683687, 10.1109/icassp.2019.8683687]
   Tang W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2181, DOI 10.1109/ICASSP.2018.8461613
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang JJ, 2017, IEEE SIGNAL PROC LET, V24, P1822, DOI 10.1109/LSP.2017.2734860
   Wang JJ, 2017, NEUROCOMPUTING, V238, P103, DOI 10.1016/j.neucom.2017.01.041
   Wang QY, 2018, MULTIMED TOOLS APPL, V77, P17023, DOI 10.1007/s11042-017-5269-6
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Wang YX, 2021, DIGIT SIGNAL PROCESS, V118, DOI 10.1016/j.dsp.2021.103227
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie SY, 2018, IET COMPUT VIS, V12, P458, DOI 10.1049/iet-cvi.2017.0422
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M, 2017, NEUROCOMPUTING, V269, P13, DOI 10.1016/j.neucom.2016.08.146
   Yang M, 2017, NEUROCOMPUTING, V219, P404, DOI 10.1016/j.neucom.2016.09.037
   Yang M, 2016, AAAI CONF ARTIF INTE, P2251
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Zang F, 2011, NEUROCOMPUTING, V74, P2176, DOI 10.1016/j.neucom.2011.02.012
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang Z, 2013, IEEE T IMAGE PROCESS, V22, P4640, DOI 10.1109/TIP.2013.2277780
   Zheng H, 2015, NEUROCOMPUTING, V162, P9, DOI 10.1016/j.neucom.2015.03.071
NR 59
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30277
EP 30295
DI 10.1007/s11042-023-16772-1
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000003
DA 2024-07-18
ER

PT J
AU Wei, DP
   Wang, Hb
AF Wei Depeng
   Wang Huabin
TI MFFLNet: lightweight semantic segmentation network based on multi-scale
   feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Atrous convolution; Convolutional neural network;
   Multi-scale features; Lightweight feature fusion
ID NEURAL-NETWORKS; IMAGE
AB Semantic segmentation is a typical problem in the field of machine vision. Convolutional neural networks(CNNs)-based methods all have excellent performance in image semantic segmentation. Existing semantic segmentation models tend to focus only on the improvement of image segmentation performance, with little attention to the problems of network lightweighting and multi-scale feature information utilization. To address this problem, we design a multi-scale feature fusion lightweight semantic segmentation network(MFFLNet), which consists of two parts: a deep feature extraction module(DFEM) and a multi-scale feature extraction module(MFEM). First, the deep feature extraction module(DFEM) utilizes the deconvolution layer to replace the convolution layer, which can avoid the problem of feature information loss caused by cropping the feature map when feature fusion is performed. Meanwhile, the dimensionality of the feature map is compressed by using 1 x 1 convolutional layers after each upsampling layer, which can effectively reduce the number of parameters of the model. Then, the multi-scale feature extraction module(MFEM) employs multiple null convolutions with different expansion rates for feature extraction of the image to extract feature information on multiple scales. Finally, the deep features and multi-scale features extracted by the two modules respectively are fused to achieve semantic segmentation of the image. It is shown experimentally that the proposed MFFLNet outperforms the mainstream methods in semantic segmentation on two datasets, PASCAL VOC 2012 and Cityscapes, with mIoU reaching 71. 23% and 79. 24%, respectively, and improving 5. 8% and 8. 8% compared with the state-of-the-art DeepLab V3 + model, respectively.
C1 [Wei Depeng; Wang Huabin] Guangxi Yuchai Machinery Co Ltd, Yulin 537005, Peoples R China.
RP Wei, DP (corresponding author), Guangxi Yuchai Machinery Co Ltd, Yulin 537005, Peoples R China.
EM 1059343169@qq.com
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bueno G, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105273
   Chen BK, 2019, IEEE T INTELL TRANSP, V20, P137, DOI 10.1109/TITS.2018.2801309
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Cheng FY, 2019, NEUROCOMPUTING, V329, P21, DOI 10.1016/j.neucom.2018.10.037
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu H, 2013, NEUROCOMPUTING, V119, P74, DOI 10.1016/j.neucom.2012.01.050
   Fu J, 2017, IEEE IMAGE PROC, P3085, DOI 10.1109/ICIP.2017.8296850
   Garcia-Garcia A, 2017, ARXIV, DOI [10.48550/arXiv.1704.06857, DOI 10.48550/ARXIV.1704.06857]
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Han B, 2017, PATTERN RECOGN, V67, P396, DOI 10.1016/j.patcog.2017.02.022
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang ZY, 2018, NEUROCOMPUTING, V284, P27, DOI 10.1016/j.neucom.2018.01.022
   Jin R, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/1681952
   Li H, IEEE GEOSCI REMOTE S, VPP, P1
   Li H., 2018, P BRIT MACH VIS C
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li R, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107343
   Liang Xiaodan, 2016, PATTERN RECOGN
   Lin D, 2018, LECT NOTES COMPUT SC, V11207, P622, DOI 10.1007/978-3-030-01219-9_37
   Lin GS, 2020, IEEE T PATTERN ANAL, V42, P1228, DOI 10.1109/TPAMI.2019.2893630
   Liu WY, 2016, PR MACH LEARN RES, V48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lottes P, 2020, J FIELD ROBOT, V37, P20, DOI 10.1002/rob.21901
   Yan M, 2020, NEUROCOMPUTING, V386, P293, DOI 10.1016/j.neucom.2019.12.007
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Orsic M, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107611
   Paszke A., 2016, ARXIV160602147
   Peng CL, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107498
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S., 2016, ARXIV
   Shen FL, 2019, NEUROCOMPUTING, V330, P259, DOI 10.1016/j.neucom.2018.11.027
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun JX, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107155
   Sun X, 2021, IEEE T GEOSCI REMOTE, V59, P7224, DOI 10.1109/TGRS.2020.3032523
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wanfu Z., 2017, ELECTRON TECHNOL, V30, P4, DOI [10.16180/j.cnki.issn1007-7820.2017.02.019, DOI 10.16180/J.CNKI.ISSN1007-7820.2017.02.019]
   Xinxin L., 2013, COMPUTER APPL SOFTWA, V30, P4, DOI [10.3969/j.issn.1000-386x.2013.12.008, DOI 10.3969/J.ISSN.1000-386X.2013.12.008]
   Xu HJ, 2020, NEUROCOMPUTING, V397, P39, DOI 10.1016/j.neucom.2020.02.039
   Xue Y, 2015, COMPUT ENG, V41, P253
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   You J, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105750
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu F., 2015, ARXIV
   Yu HS, 2018, NEUROCOMPUTING, V304, P82, DOI 10.1016/j.neucom.2018.03.037
   Zhang C, 2012, COMPUTER CD SOFTWARE, V9, P3
   Zhang M, 2020, IEEE J BIOMED HEALTH, V24, P3095, DOI 10.1109/JBHI.2020.3000484
   Zhang SX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030427
   Zhang Y, 2020, NEURAL COMPUT APPL, V32
   Zhang Y, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107940
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou L, 2019, NEUROCOMPUTING, V340, P196, DOI 10.1016/j.neucom.2019.01.016
   Zhou Z, 2021, NEUROCOMPUTING, V453, P50, DOI 10.1016/j.neucom.2021.04.106
NR 61
TC 0
Z9 0
U1 13
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30073
EP 30093
DI 10.1007/s11042-023-16782-z
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066067700005
DA 2024-07-18
ER

PT J
AU Leng, HS
   Hu, YC
   Tseng, HW
AF Leng, Hui-Shih
   Hu, Yu-Chen
   Tseng, Hsien-Wen
TI A high payload block-based data hiding scheme using multi-encoding
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Least-significant-bit (LSB); Edge detection; Multi-encoding;
   Most-significant-bit (MSB)
ID EDGE-DETECTION; STEGANOGRAPHY; LSB; IMAGES
AB With the rapid development of the Internet, large amounts of data are being transferred globally. As data are becoming increasingly valuable, securing the communicated information is a major concern. In data hiding, the secret data are concealed in a cover medium, which does not reveal the presence of the secret data. The least-significant-bit (LSB) substitution method is a popular data hiding scheme due to its high payload embedding capacity and low distortion. Several studies have achieved a high payload embedding capacity by combining the LSB substitution method with other techniques. A few studies employed an edge detection technique based on the sensitivity of the human visual system to embed the secret bits stored in the edge pixels. However, problems associated with the storage of edge information tend to reduce the embedding capacity. To increase the embedding capacity, a most-significant-bit (MSB) image with edge detection was employed in another study, wherein a fuzzy technique was applied to the edge matrix to increase the weak edge pixels. However, this approach did not ensure the generation of true edge pixels. In the meantime, a high payload reduces the quality of the stego-image. This study proposes a block-based data hiding scheme using a multi-encoding method. Compared to Bai et al.'s approach utilizing image features and fuzzy theory, the proposed method further improves performance by using block segmentation and optimization with multiple encodings. The experimental results show that this approach can enhance security at low cost and yield superior performance compared to Bai et al.'s method. After applying the proposed method, the payload has increased by an average of 396 bits, and the PSNR has increased by an average of 1.5286 dB compared to Bai et al.'s method.
C1 [Leng, Hui-Shih] Natl Changhua Univ Educ, Dept Math, Changhua 50007, Taiwan.
   [Hu, Yu-Chen] Tunghai Univ, Dept Comp Sci, Taichung 407224, Taiwan.
   [Tseng, Hsien-Wen] Chaoyang Univ Technol, Dept Informat Management, Taichung 413310, Taiwan.
C3 National Changhua University of Education; Tunghai University; Chaoyang
   University of Technology
RP Tseng, HW (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung 413310, Taiwan.
EM lenghs@cc.ncue.edu.tw; ychu@thu.edu.tw; hwtseng@cyut.edu.tw
RI Tseng, Hsien-Wen/JUF-2625-2023
OI Tseng, Hsien-Wen/0000-0001-7488-9672
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bhardwaj M, 2019, 2019 4 INT C INF SYS, DOI [10.1109/iscon47742.2019.9036234, DOI 10.1109/ISCON47742.2019.9036234]
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chou C-H, 1994, P 1994 IEEE INT S IN, DOI [10.1109/isit.1994.395035, DOI 10.1109/ISIT.1994.395035]
   Chuang JC, 2019, MULTIMED TOOLS APPL, V78, P35537, DOI 10.1007/s11042-019-08193-w
   Tran DN, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P386, DOI 10.1109/ISCIT.2019.8905158
   Dhargupta S, 2019, MULTIMED TOOLS APPL, V78, P17589, DOI 10.1007/s11042-018-7123-x
   Gaurav K, 2018, J INF SECUR APPL, V41, P41, DOI 10.1016/j.jisa.2018.05.001
   Hu YC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091146
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P127, DOI 10.1007/s11554-017-0719-y
   Kaur K., 2010, INT J COMPUT APPL, V1, P57, DOI [10.5120/442-675, DOI 10.5120/442-675]
   Kutter M, 2002, IEEE T IMAGE PROCESS, V11, P16, DOI 10.1109/83.977879
   Lee CF, 2018, DISPLAYS, V53, P30, DOI 10.1016/j.displa.2018.06.001
   Leng HS, 2022, IEEE ACCESS, V10, P468, DOI 10.1109/ACCESS.2021.3136883
   Leng HS, 2021, DIGIT SIGNAL PROCESS, V113, DOI 10.1016/j.dsp.2021.103026
   Leng HS, 2017, SMART INNOV SYST TEC, V63, P59, DOI 10.1007/978-3-319-50209-0_8
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin JY, 2019, MULTIMED TOOLS APPL, V78, P25855, DOI 10.1007/s11042-019-07783-y
   Lin YH, 2021, MULTIMED TOOLS APPL, V80, P24949, DOI 10.1007/s11042-021-10914-z
   Liu KC, 2008, SITIS 2008: 4TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY AND INTERNET BASED SYSTEMS, PROCEEDINGS, P260, DOI 10.1109/SITIS.2008.67
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Mandal PC, 2022, MULTIMED TOOLS APPL, V81, P5325, DOI 10.1007/s11042-021-11605-5
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Sangwan V, 2018, 2018 2 INT C MICR TE, DOI [10.1109/icmete.2018.00036, DOI 10.1109/ICMETE.2018.00036]
   Setiadi DIM, 2018, CYBERN INF TECHNOL, V18, P74, DOI 10.2478/cait-2018-0029
   SWAIN G, 2014, INDIAN J SCI TECHNOL, V7, P1444
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Tuner L-F, 1989, Patent IPN, Patent No. [WO89/08915, 8908915]
   Wang YT, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164685
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P746, DOI 10.1109/TCSVT.2003.815949
   Xie XZ, 2020, MULTIMED TOOLS APPL, V79, P24329, DOI 10.1007/s11042-019-08402-6
   Yusuf HS, 2018, 2018 10 COMP SCI EL, DOI [10.1109/ceec.2018.8674225, DOI 10.1109/CEEC.2018.8674225]
   Zakaria AA, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112199
NR 43
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15939
EP 15956
DI 10.1007/s11042-023-16888-4
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001066065600004
DA 2024-07-18
ER

PT J
AU Ahammad, SH
   Dwarkanath, S
   Joshi, R
   Madhav, BTP
   Priya, PP
   Faragallah, OS
   Eid, MMA
   Rashed, ANZ
AF Ahammad, Shaik Hasane
   Dwarkanath, Sandeep
   Joshi, Rahul
   Madhav, B. T. P.
   Priya, P. Poorna
   Faragallah, Osama S.
   Eid, Mahmoud M. A.
   Rashed, Ahmed Nabih Zaki
TI Social media reviews based hotel recommendation system using
   collaborative filtering and big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hotel recommendation system; Collaborative filtering; Sentiment
   analysis; Natural language processing
AB To eliminate the concerns of cold-start and scalability within the filtering, collaborative recommendation system for a hotel under the ranking list for the customer; this study proposed an extensive data analysis for such an application. Alongside, the application is very user-friendly. Technology keeps growing daily and is also very helpful in the future. This paper brings out the innovation. This approach configures the latest variant of CNN termed as Capsule Network (CapsNet) to recommend the best suited hotel based on user collaboration. With the help of this application, we can make precise and accurate recommendations to the user. Besides, generally employed, the procedure adopted for the model recommended integrated with the filtering practice that includes analyzing user's preferences and making product or service recommendations through a similarity index among the ratings specified in the database. Finally, the merging technique employed in the system is discussed and evaluated on standard data sets based on the general architectural design of the recommendation system. An enhanced strategy attains fusion idea of filtering technique in collaborative to classified data for addressing this issue. To put the proposed approach to the test, we employ hotel recommendation data. Also, the outcome proved the best findings of the comprehensive list taken as the top listed hotels from which the scale has been considered through the proposed method.
C1 [Ahammad, Shaik Hasane; Madhav, B. T. P.] Koneru Lakshmaiah Educ Fdn, Dept ECE, Vaddeswaram 522302, India.
   [Dwarkanath, Sandeep] MIT Acad Engn, Pune, India.
   [Joshi, Rahul] Symbiosis Int, Symbiosis Inst Technol, Pune, India.
   [Priya, P. Poorna] Dadi Inst Engn & Technol, ECE Dept, Anakapalle, Visakhapatnam, India.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Eid, Mahmoud M. A.] Taif Univ, Coll Engn, Dept Elect Engn, POB 11099, At Taif 21944, Saudi Arabia.
   [Rashed, Ahmed Nabih Zaki] Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32951, Egypt.
   [Rashed, Ahmed Nabih Zaki] SIMATS, Inst Elect & Commun Engn, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tami Nadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Symbiosis International University; Symbiosis Institute of Technology
   (SIT); Taif University; Taif University; Egyptian Knowledge Bank (EKB);
   Menofia University; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering
RP Rashed, ANZ (corresponding author), Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32951, Egypt.; Rashed, ANZ (corresponding author), SIMATS, Inst Elect & Commun Engn, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tami Nadu, India.
EM ahammadklu@gmail.com; sandeep7887pande@gmail.com; rahulj@sitpune.edu.in;
   btpmadhav@kluniversity.in; hodece@diet.edu.in; o.salah@tu.edu.sa;
   m.elfateh@tu.edu.sa; ahmed_733@yahoo.com
RI Faragallah, Osama S./AHB-8031-2022; Madhav, B T P/Q-2633-2016; Rashed,
   Ahmed nabih zaki/AFB-6046-2022; Pande, Sandeep/AAR-6754-2021
OI Faragallah, Osama S./0000-0003-1982-335X; Madhav, B T
   P/0000-0002-6893-6978; Rashed, Ahmed nabih zaki/0000-0002-5338-1623;
   Pande, Sandeep/0000-0001-6969-0423
FU The researchers would like to acknowledge Deanship of Scientific
   Research, Taif University for funding this work.; Deanship of Scientific
   Research, Taif University
FX The researchers would like to acknowledge Deanship of Scientific
   Research, Taif University for funding this work.
CR Abbas A, 2015, COMPUTING, V97, P667, DOI 10.1007/s00607-015-0448-7
   Adoinavicius G, 2007, IEEE INTELL SYST, V22, P48, DOI 10.1109/MIS.2007.58
   Ahammad SH, 2020, IEEE SENS J, V20, P10092, DOI 10.1109/JSEN.2020.2992879
   Chen YY, 2013, IEEE T MULTIMEDIA, V15, P1283, DOI 10.1109/TMM.2013.2265077
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [DOI 10.1145/1341531.1341561, 10.1145/1341531.1341561]
   Gao Huming, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P317, DOI 10.1109/MMIT.2010.14
   Gao Y, 2015, INT C DAT SYST ADV A
   Gattim NK, 2019, INT J EMERGING TREND, V7, P634
   Haruna K, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121211
   Inthiyaz S., 2019, Int J Emerg Trends Eng Res, V7, P690, DOI [10.30534/ijeter/2019/457112019, DOI 10.30534/IJETER/2019/457112019]
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Mobasher B, 2006, AAAI, V6
   Morifuji E, 2007, IEEE T ELECTRON DEV, V54, P715, DOI 10.1109/TED.2007.891869
   Myla S., 2019, International Journal of Scientific and Technology Research, V8, P2199
   Ni JB, 2014, IEEE T PARALL DISTR, V25, P2760, DOI 10.1109/TPDS.2013.199
   Pande S., 2018, J Adv Res Dynam Control Syst, V10, P2765
   Albaladejo-Pina IP, 2009, TOURISM MANAGE, V30, P805, DOI 10.1016/j.tourman.2009.01.001
   Raj Kumar A, 2019, INT J RECENT TECHNOL, V7, P903
   Sánchez F, 2012, IEEE T MULTIMEDIA, V14, P1546, DOI 10.1109/TMM.2012.2217121
   Shahroudnejad A, 2018, ARXIV
   Terveen L., 2001, Beyond recommender systems: Helping people help each other
   Wahyudi K, 2020, J PHYS C SER, V1485, P120
   Xi Chen, 2010, 2010 IEEE International Conference on Web Services (ICWS), P9, DOI 10.1109/ICWS.2010.27
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yu K, 2004, IEEE T KNOWL DATA EN, V16, P56, DOI 10.1109/TKDE.2004.1264822
NR 29
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29569
EP 29582
DI 10.1007/s11042-023-16644-8
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001064737700004
DA 2024-07-18
ER

PT J
AU Laifi, A
   Benmohamed, E
   Ltifi, H
AF Laifi, Aymen
   Benmohamed, Emna
   Ltifi, Hela
TI Xavier-PSO-ELM-based EEG signal classification method for predicting
   epileptic seizures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epileptic seizure; Electroencephalogram (EEG); Classification; Extreme
   Learning Machines (ELM); Particle Swarm Optimization (PSO); Xavier
   initialization
ID EXTREME LEARNING-MACHINE; NEURAL-NETWORKS; OPTIMIZATION; ALGORITHM
AB Epilepsy represents one of the most common neurological diseases that affects a substantial number of individuals worldwide, which is characterized by recurrent, unprovoked seizures detectable via electroencephalogram (EEG). To address this issue, we propose an Extreme Learning Machine (ELM) model for seizure prediction. Firstly, we optimized the ELM with a single hidden-layer feed-forward network using Particle Swarm Optimization (PSO) as a meta-heuristic. Secondly, we employed the Xavier method to initialize random variables and improve model performance. Our optimized classification model was evaluated using a dataset from the University of Bonn. Results from the experiments demonstrate our model's excellent classification performance with 98.13% sensitivity and 91.04% specificity.
C1 [Laifi, Aymen; Benmohamed, Emna; Ltifi, Hela] Res Grp Intelligent Machines Lab, Sfax 3038, Tunisia.
   [Benmohamed, Emna] Onaizah Coll, Coll Engn & Informat Technol, Dept Cyber Secur, POB 5371, Onaizah, Saudi Arabia.
   [Ltifi, Hela] Univ Kairouan, Fac Sci & Technol Sidi Bouzid, Kairouan, Tunisia.
C3 Universite de Sfax; Onaizah Colleges; Universite de Kairouan
RP Benmohamed, E (corresponding author), Res Grp Intelligent Machines Lab, Sfax 3038, Tunisia.; Benmohamed, E (corresponding author), Onaizah Coll, Coll Engn & Informat Technol, Dept Cyber Secur, POB 5371, Onaizah, Saudi Arabia.
EM aymen.laifi@gmail.com; emna.benmohamed@enis.tn; hela.ltifi@ieee.org
RI LTIFI, Hela/K-5469-2012
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX & nbsp;The research leading to these results has received funding from
   the Ministry of Higher Education and Scientific Research of Tunisia
   under the grant agreement number LR11ES48.
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Akyol K, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113239
   Almustafa KM., 2020, Inf. Med. Unlocked, V2, P1, DOI DOI 10.1016/J.IMU.2020.100444
   Alotaiby TN, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1240323
   Alshebeili SA, 2020, APPL ACOUST, V166, DOI 10.1016/j.apacoust.2020.107327
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Bangyal WH, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/6628889
   Bangyal WH, 2020, INT J BIO-INSPIR COM, V15, P1
   Bangyal WH, 2018, INT J ADV COMPUT SC, V9, P523
   Behnam M, 2016, COMPUT METH PROG BIO, V132, P115, DOI 10.1016/j.cmpb.2016.04.014
   Ben Slimen I, 2020, J BIOMED RES, V34, P151, DOI 10.7555/JBR.34.20190026
   Berrar D, 2018, ENCY BIOINFORMAT COM
   Bizopoulos P, 2019, IEEE ENG MED BIO, P702, DOI [10.1109/EMBC.2019.8856620, 10.1109/embc.2019.8856620]
   Brownlee J, 2020, TRANSFER LEARNING KE
   Cho D, 2017, IEEE T NEUR SYS REH, V25, P1309, DOI 10.1109/TNSRE.2016.2618937
   Chu H, 2017, COMPUT METH PROG BIO, V143, P75, DOI 10.1016/j.cmpb.2017.03.002
   Ding SF, 2014, NEURAL COMPUT APPL, V25, P549, DOI 10.1007/s00521-013-1522-8
   Falco-Walter JJ, 2018, EPILEPSY RES, V139, P73, DOI 10.1016/j.eplepsyres.2017.11.015
   Fei KL, 2017, NEUROCOMPUTING, V249, P290, DOI 10.1016/j.neucom.2017.04.019
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Huang GB, 2004, IEEE IJCNN, P985
   ics.uci, ABOUT US
   Jana G C., 2019, 2019 International Conference on Electrical, Electronics and Computer Engineering (UPCON), P1
   Karal O, 2020, 2020 INNOVATIONS INT, P1
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan H, 2018, IEEE T BIO-MED ENG, V65, P2109, DOI 10.1109/TBME.2017.2785401
   Kirichenko Lyudmyla, 2020, 2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP), P84, DOI 10.1109/DSMP47368.2020.9204021
   Liu CL, 2019, IEEE ACCESS, V7, P170352, DOI 10.1109/ACCESS.2019.2955285
   Mahmood SF, 2017, NEUROCOMPUTING, V219, P312, DOI 10.1016/j.neucom.2016.09.046
   Mamli S, 2019, BIOCYBERN BIOMED ENG, V39, P87, DOI 10.1016/j.bbe.2018.10.006
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Myers MH, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00080
   Truong ND, 2018, NEURAL NETWORKS, V105, P104, DOI 10.1016/j.neunet.2018.04.018
   Nkengfack LCD., 2021, INFORM MED UNLOCKED, V23, DOI [10.1016/j.imu.2021.100536, DOI 10.1016/J.IMU.2021.100536]
   Oprea SV, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107329
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Prathaban BP, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114533
   Qian YG, 2020, IEEE ACCESS, V8, P64086, DOI 10.1109/ACCESS.2020.2985097
   Rahmati R, 2022, INT J PROD RES, V60, P5235, DOI 10.1080/00207543.2021.1953179
   Ramchoun H, 2016, INT J INTERACT MULTI, V4, P26, DOI 10.9781/ijimai.2016.415
   Ramyachitra D., 2014, Int. J. Comput. Bus. Res., V5, DOI DOI 10.18533/IJBSR.V4I4.470
   Ranjith E, 2019, INT C INV SYST CONTR
   Savadkoohi M, 2020, BIOCYBERN BIOMED ENG, V40, P1328, DOI 10.1016/j.bbe.2020.07.004
   Shao ZF, 2016, IEEE T CYBERNETICS, V46, P1939, DOI 10.1109/TCYB.2015.2458177
   Siuly S, 2016, DATA SCI ENG, V1, P54, DOI 10.1007/s41019-016-0011-3
   Subasi A, 2019, NEURAL COMPUT APPL, V31, P317, DOI 10.1007/s00521-017-3003-y
   Sun LL, 2019, INFORM SCIENCES, V475, P1, DOI 10.1016/j.ins.2018.09.057
   Tan P, 2016, IEEE ANN INT CONF CY, P228, DOI 10.1109/CYBER.2016.7574827
   Tsiouris KM, 2018, COMPUT BIOL MED, V99, P24, DOI 10.1016/j.compbiomed.2018.05.019
   Usman SM, 2020, IEEE ACCESS, P39
   Vuttipittayamongkol P, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500434
   Wei XY, 2019, J NEUROSCI METH, V327, DOI 10.1016/j.jneumeth.2019.108395
   Zemzam M., 2019, INT J ADV TRENDS COM, V8, P112, DOI DOI 10.30534/IJATCSE/2019/03822019
   Zhang S, 2020, J URBAN TECHNOL, P119
   Zubair M, 2021, IEEE SENS J
NR 55
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30675
EP 30696
DI 10.1007/s11042-023-16514-3
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063374600002
DA 2024-07-18
ER

PT J
AU Bardhan, S
   Roga, S
AF Bardhan, Shawli
   Roga, Sukanta
TI Hypertension detection and indexing from cardiac ECM image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypertension; ECM; BEMD; Feature extraction; Classification; HRI
ID EXTRACELLULAR-MATRIX; CLASSIFICATION; PREDICTION; FEATURES
AB Hypertension is considered as a global public health problem by the World Health Organization. The risk of cardiovascular mortality grows with hypertension. The disease can be diagnosed by combined analysis of cardiac extracellular matrix (ECM) images and machine learning. This study proposes a novel method for automated classification of hypertension and its risk indexing using cardiac ECM images through machine learning. The method includes image pre-processing, Bi-dimensional Empirical Mode Decomposition (BEMD), feature extraction, feature selection, and classification guided by a statistical T-test for hypertension indexing. The proposed method applied over 300 cardiac ECM images and among them 150 belong to the normal group and the rest are from the hypertension group. The classification accuracy of the method is 98.9% with a sensitivity of 0.97 and specificity of 1. The F1 score, False Negative Rate, and False Positive Rate of the proposed method is 0.99, 0.02, and 0 respectively. Inspired by the classification accuracy, a unique Hypertension Risk Indexing (HRI) system has been developed focusing on minimum complexity of execution through prominent feature selection. Such an indexing mechanism can assist clinicians in the preliminary study of hypertension risk assessment.
C1 [Bardhan, Shawli] Techno Coll Engn Agartala, Dept Comp Sci & Engn, Agartala 799004, Tripura, India.
   [Roga, Sukanta] Visvesvaraya Natl Inst Technol, Dept Mech Engn, Nagpur 440010, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Bardhan, S (corresponding author), Techno Coll Engn Agartala, Dept Comp Sci & Engn, Agartala 799004, Tripura, India.
EM shawli.cse@gmail.com; rogasukanta@gmail.com
RI Roga, Sukanta/K-3988-2014
OI Roga, Sukanta/0000-0001-8325-9154; Bardhan, Shawli/0000-0003-2914-2291
CR Acharya UR, 2017, NEURAL COMPUT APPL, V28, P3073, DOI 10.1007/s00521-016-2612-1
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 1979, P IMAGE UNDERSTANDIN
   Aumailley M, 1998, J MOL MED-JMM, V76, P253, DOI 10.1007/s001090050215
   Banu AKS, 2015, 2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Bardhan S, 2015, 2015 INT S ADV COMP, DOI [10.1109/ISACC.2015.7377350, DOI 10.1109/ISACC.2015.7377350]
   Bardhan S., 2021, ADV MECH ENG, P511, DOI [10.1007/978-981-15-3639-7_61, DOI 10.1007/978-981-15-3639-7_61]
   Bardhan S., 2021, EMERGING TECHNOLOGIE, P115, DOI [10.1007/978-3-030-67716-9_8, DOI 10.1007/978-3-030-67716-9_8]
   Bardhan S, 2018, INT J COMPUT INTEL I, V1, P2
   Bardhan S, 2022, QUANT INFR THERM J, V19, P145, DOI 10.1080/17686733.2020.1855390
   Bardhan S, 2019, AUSTRALAS PHYS ENG S, V42, P259, DOI 10.1007/s13246-019-00726-9
   Bardhan S, 2018, BIOCYBERN BIOMED ENG, V38, P903, DOI 10.1016/j.bbe.2018.07.002
   Bardhan S, 2017, INT CONF COMPUT
   Bhowmik MK, 2016, INT SOC OPT PHOTON, V9861, DOI [10.1117/12.2223425, DOI 10.1117/12.2223425]
   Bhowmik MK, 2018, IEEE J BIOMED HEALTH, V22, P1238, DOI 10.1109/JBHI.2017.2740500
   Bosman FT, 2003, J PATHOL, V200, P423, DOI 10.1002/path.1437
   de Haas HJ, 2014, CIRC RES, V114, P903, DOI 10.1161/CIRCRESAHA.113.302680
   Dong WH, 2014, REMOTE SENS-BASEL, V6, P8446, DOI 10.3390/rs6098446
   Fitriyani NL, 2019, IEEE ACCESS, V7, P144777, DOI 10.1109/ACCESS.2019.2945129
   Frangogiannis NG, 2017, J CLIN INVEST, V127, P1600, DOI 10.1172/JCI87491
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Intengan HD, 2001, HYPERTENSION, V38, P581, DOI 10.1161/hy09t1.096249
   Kandil H, 2020, NEUROIMAGE-CLIN, V25, DOI 10.1016/j.nicl.2019.102107
   Kumar T, 2022, COMM COM INF SC, V1534, P359, DOI 10.1007/978-3-030-96040-7_29
   Lemarié CA, 2010, J MOL CELL CARDIOL, V48, P433, DOI 10.1016/j.yjmcc.2009.09.018
   López B, 2004, CURR OPIN NEPHROL HY, V13, P197, DOI 10.1097/01.mnh.0000119532.79618.fa
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   Martinez-Ríos E, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105479
   Martis RJ, 2012, INT J NEURAL SYST, V22, DOI 10.1142/S012906571250027X
   Mookiah MRK, 2015, KNOWL-BASED SYST, V89, P654, DOI 10.1016/j.knosys.2015.09.012
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Parmar KS, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103629
   Patnaik R, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Rajput J.S., 2021, Inform. Med. Unlocked, V26
   Ren YF, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0765-4
   Roga S., 2019, INT C DEEP LEARN ART, DOI [10.1007/978-3-030-67187-7_15, DOI 10.1007/978-3-030-67187-7_15]
   Schelbert EB, 2014, J AM COLL CARDIOL, V63, P2188, DOI 10.1016/j.jacc.2014.01.068
   Sengar P, MACH LEARN DEEP LEAR, P23, DOI [10.1201/9781003226147, DOI 10.1201/9781003226147]
   Skov K, 2004, ACTA PHYSIOL SCAND, V181, P397, DOI 10.1111/j.1365-201X.2004.01311.x
   Streuli C, 1999, CURR OPIN CELL BIOL, V11, P634, DOI 10.1016/S0955-0674(99)00026-5
   Sun YJ, 2007, IEEE T PATTERN ANAL, V29, P1035, DOI 10.1109/TPAMI.2007.1093
   Tjahjadi H, 2020, INFORMATION, V11, DOI 10.3390/info11020093
   Tjahjadi H, 2020, IEEE ACCESS, V8, P20735, DOI 10.1109/ACCESS.2020.2968967
   Tuyet VTH., 2021, INT C NAT COMP COMM, DOI [10.1007/978-3-030-92942-8_2, DOI 10.1007/978-3-030-92942-8_2]
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   White SK, 2012, HEART, V98, P773, DOI 10.1136/heartjnl-2011-301515
   WU CM, 1992, CVGIP-GRAPH MODEL IM, V54, P407, DOI 10.1016/1049-9652(92)90025-S
   WU CM, 1992, IEEE T MED IMAGING, V11, P141, DOI 10.1109/42.141636
   Xie Y, 2021, 2021 THE 7TH INTERNATIONAL CONFERENCE ON COMMUNICATION AND INFORMATION PROCESSING, ICCIP 2021, P82, DOI 10.1145/3507971.3507987
   Yang JD, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103573
   Yue Luo, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P2122, DOI 10.1109/CompComm.2018.8780834
NR 51
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30541
EP 30561
DI 10.1007/s11042-023-16746-3
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900009
DA 2024-07-18
ER

PT J
AU Singhal, M
   Shinghal, K
AF Singhal, Manas
   Shinghal, Kshitij
TI Secure deep multimodal biometric authentication using online signature
   and face features fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal; Biometrics authentication; Deep learning; Equal Error Rate
   (EER)
ID KINSHIP VERIFICATION; RECOGNITION; IMAGES; EAR
AB In Indian banking systems, signatures and faces are the two traits of biometrics that are used for personal identification. The automation of this identification system requires the use of a multimodal verification system. Although many researchers are working in the field of multimodal biometrics, the research involving online signatures and face images is very sparse because it involves the handling of two different types of databases. As the online signature data is in sequence form while the face image data is in image form. Authentication through an online signature requires the generation of a strong feature vector and authentication through a face database requires improving the active area of the face image. The dimensionality of the feature vector generated through the face image is generally large, it needs to be minimized. In this paper, the multimodal biometrics verification method involving online signatures and face images is presented. This is performed by forming a fusion feature vector combining extracted features from online signatures and face images. To extract the features from the face images a modified context aware (MCA) algorithm and Tangential discrimination analysis (TDA) algorithm for dimensionality reduction of feature vector are proposed. The fusion feature vector is used to train a modified mixed sequence deep neural network (MMS-DNN). The proposed system provides an improvement in verification performance in terms of equal error rate (EER). The proposed system achieves the EER of 0.5%, which shows a large improvement from existing work. The proposed system also provides security to the biometric data involved as only a fusion feature vector is used in training and verification algorithms as opposed to raw online signature and face image data.
C1 [Singhal, Manas] Moradabad Inst Technol, Dept ECE, Moradabad 244001, Uttar Pradesh, India.
   [Singhal, Manas] Dr APJ Abdul Kalam Tech Univ, Lucknow, India.
   [Shinghal, Kshitij] Moradabad Inst Technol, Dept ECE, Moradabad 244001, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU)
RP Singhal, M (corresponding author), Moradabad Inst Technol, Dept ECE, Moradabad 244001, Uttar Pradesh, India.; Singhal, M (corresponding author), Dr APJ Abdul Kalam Tech Univ, Lucknow, India.
EM manas.singhal.ec@gmail.com
RI SINGHAL, MANAS/D-8342-2019
OI SINGHAL, MANAS/0000-0002-6343-9112
CR Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ahmad S, 2022, MULTIMED TOOLS APPL, V81, P40931, DOI 10.1007/s11042-022-12688-4
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Aliradi R., 2018, MULTIMED TOOLS APPL, DOI [10.1007/s11042-017-5572-2, DOI 10.1007/S11042-017-5572-2]
   Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5
   Arora A, 2022, MULTIMED TOOLS APPL, V81, P44021, DOI 10.1007/s11042-022-11993-2
   Attia A, 2022, MULTIMED TOOLS APPL, V81, P10961, DOI 10.1007/s11042-022-12384-3
   Azom V, 2015, PROCEEDINGS OF THE 2015 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH), P207, DOI 10.1109/RoboMech.2015.7359524
   Bibi K, 2020, MULTIMED TOOLS APPL, V79, P289, DOI 10.1007/s11042-019-08022-0
   Chandra S, 2022, MULTIMED TOOLS APPL, V81, P40959, DOI 10.1007/s11042-022-13159-6
   Chanukya PSVVN, 2020, MULTIMED TOOLS APPL, V79, P659, DOI 10.1007/s11042-019-08123-w
   Deshpande PP, 2018, P 2018 IEEE 4 INT C, P1
   Dhieb T, 2022, MULTIMED TOOLS APPL, V81, P7817, DOI 10.1007/s11042-022-12140-7
   Dinca LM, 2017, IEEE ACCESS, V5, P6247, DOI 10.1109/ACCESS.2017.2694050
   El-Alfy E.-S.M., 2012, NETWORKED DIGITAL TE, V294, P253
   El-Bendary MAM, 2020, MULTIMED TOOLS APPL, V79, P24507, DOI 10.1007/s11042-020-08926-2
   Galbally J, 2012, PATTERN RECOGN, V45, P2622, DOI 10.1016/j.patcog.2011.12.007
   Galbally J, 2012, PATTERN RECOGN, V45, P2610, DOI 10.1016/j.patcog.2011.12.011
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   He L, 2019, MULTIMED TOOLS APPL, V78, P19253, DOI 10.1007/s11042-019-7264-6
   Jadhav SB, 2023, MULTIMED TOOLS APPL, V82, P30039, DOI 10.1007/s11042-022-14241-9
   Jagadiswary D, 2016, PROCEDIA COMPUT SCI, V85, P109, DOI 10.1016/j.procs.2016.05.187
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Jomaa RM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072085
   Kagawade VC, 2021, MULTIMED TOOLS APPL, V80, P21615, DOI 10.1007/s11042-021-10650-4
   Kamlaskar C., 2021, AIMS Electronics and Electrical Engineering, V5, P229
   Laiadi O, 2019, MULTIMED TOOLS APPL, V78, P16465, DOI 10.1007/s11042-018-7027-9
   Leghari M, 2018, P 2018 INT C COMP MA, P1
   Leghari M, 2021, COMPUTERS, V10, DOI 10.3390/computers10020021
   Lu J, 2015, IEEE T PATTERN ANAL
   Lu T, 2021, MULTIMED TOOLS APPL, V80, P8563, DOI 10.1007/s11042-020-09784-8
   M. S. M. D, 2016, IJRITCC, V4, P66, DOI [10.17762/ijritcc.v4i9.2532, DOI 10.17762/IJRITCC.V4I9.2532]
   Meena K, 2016, BRAZ ARCH BIOL TECHN, V59
   Minaee S., 2019, ARXIV191200271
   Mwaura GW., 2017, INT J SCI TECHNOLOGY, V6, P41
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   Nandhinipreetha A., 2016, 2016 International Conference on Computer Communication and Informatics (ICCCI), P1, DOI DOI 10.1109/ICN-SURV.2016.7486356
   Ou F, 2012, MULTIMED TOOLS APPL, V57, P549, DOI 10.1007/s11042-010-0658-0
   OVEISI IS, 2015, INT C WORKSH COMP CO, P1
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Rekers J, 1997, J VISUAL LANG COMPUT, V8, P27, DOI 10.1006/jvlc.1996.0027
   Sharifi O, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060048
   Singhal M., 2016, International Journal of Electrical and Computer Engineering (IJECE), V6, P2665
   Singhal M., 2016, International Journal of Electrical and Computer Engineering (IJECE), V6, P2658
   Singhal M., 2016, INT J ENG TECH RES I, V6, P34
   Singhal M., 2020, Test Engineering and Management (TEM), V82, P11371
   Talreja V, 2017, IEEE GLOB CONF SIG, P298, DOI 10.1109/GlobalSIP.2017.8308652
   Tan H, 2024, MULTIMED TOOLS APPL, V83, P15195, DOI 10.1007/s11042-021-11063-z
   Thepade SD, 2015, INT CONF COMPUT INTE, P306, DOI 10.1109/CICN.2015.68
   Tiong LCO, 2019, MULTIMED TOOLS APPL, V78, P22743, DOI 10.1007/s11042-019-7618-0
   Toygar Ö, 2018, SIGNAL IMAGE VIDEO P, V12, P1157, DOI 10.1007/s11760-018-1263-3
   Xin Y, 2018, IEEE ACCESS, V6, P21418, DOI 10.1109/ACCESS.2018.2815540
   Xing XL, 2015, IEEE SIGNAL PROC LET, V22, P2349, DOI 10.1109/LSP.2015.2481930
   Yaman D, 2022, MULTIMED TOOLS APPL, V81, P22695, DOI 10.1007/s11042-021-10630-8
   Zhou X., 2011, ACM Multimedia, P953
NR 55
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30981
EP 31000
DI 10.1007/s11042-023-16683-1
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900002
DA 2024-07-18
ER

PT J
AU Vadivu, GE
   Muthusamy, T
AF Vadivu, Gomathi Easwara
   Muthusamy, Thamarai
TI Synthesis of deep learning technique for social distance monitoring in
   pandemic areas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Faster-RCNN; LSTM layer; Regression layer; COCO dataset
ID OBJECT DETECTION; NETWORKS
AB Recently deep learning has been making various achievements in different fields like medical diagnosis, automation, facial recognition, detection, classification, etc. Due to its performance and processing capacity, it is widely utilized in all most all fields. In today's world of epidemics, the spread of the disease has not been completely controlled by the use of various resolutions such as vaccines. And this situation emphasizes the need to actively adhere to social distancing between people. Hence, this research work utilizes a deep learning approach, to detect and monitor whether social distancing is followed between people or not. Our proposed framework utilizes a pre-trained Faster-RCNN for object detection. The Faster RCNN model is trained with the COCO dataset. Further, Transfer learning technique is adopted to increase the performance of the pre-trained model. In this way,pre-trained LSTM and regression layers are deployed over the Faster RCNN. The LSTM layer is trained using an overhead (person) dataset and embedded in the model architecture for efficient human detection. The output regression layer fine tunes the bounding boxes for each of the detected objects of Interest (person). Once the person is detected with a bounding box on an image, the centroid position is determined for each pairwise object bounding box. Then Euclidean distance is calculated between every determined centroid position. We set out a violation threshold that uses distance to pixel knowledge and makes out whether people violate social distancing or not. Experimentation has been done using numerous test images and the results show, our proposed framework monitors social distancing effectively compared to other state-of-art models. Our framework achieves the highest accuracy of 96.5% by using the additional layers(transfer learning) with the architecture and is better than the state of art techniques.
C1 [Vadivu, Gomathi Easwara] Coimbatore Inst Engn & Technol, Dept Artificial Intelligence & Data Sci, Coimbatore, Tamil Nadu, India.
   [Muthusamy, Thamarai] Sri Vasavi Engn Coll, Dept ECE, Tadepalligudem, Andhra Prades, India.
RP Muthusamy, T (corresponding author), Sri Vasavi Engn Coll, Dept ECE, Tadepalligudem, Andhra Prades, India.
EM mthamarai2014@gmail.com
RI Muthusamy, Thamarai/U-9631-2017
OI Muthusamy, Thamarai/0000-0001-6322-8561
CR Ahmad M, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720934738
   Ahmed I, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102571
   Ahmed I, 2020, IEEE INTERNET THINGS, V7, P5737, DOI 10.1109/JIOT.2019.2951365
   Ahuja U, 2023, MULTIMED TOOLS APPL, V82, P7553, DOI 10.1007/s11042-022-13718-x
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Forsyth D, 2014, COMPUTER, V47, P6, DOI 10.1109/MC.2014.42
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu YY, 2017, IEEE I CONF COMP VIS, P2363, DOI 10.1109/ICCV.2017.257
   Mansoor S.S., 2022, J. King Saud Univ.-Eng. Sci.
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Oquab Maxime., 2014, NIPS
   Pandit Dipti, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P279, DOI 10.1109/ICISS49785.2020.9315885
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Pouw CAS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240963
   Punn N. S., 2020, ARXIV
   Ramadass L, 2020, INT J PERVASIVE COMP, V16, P223, DOI 10.1108/IJPCC-05-2020-0046
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sathyamoorthy AJ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259713
   Stuhlsatz A, 2012, IEEE T NEUR NET LEAR, V23, P596, DOI 10.1109/TNNLS.2012.2183645
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang WJ, 2022, EURASIP J ADV SIG PR, V2022, DOI 10.1186/s13634-022-00839-6
   Yu Y., 2010, ECCV WORKSHOP PASCAL
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 43
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30361
EP 30376
DI 10.1007/s11042-023-16681-3
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000006
DA 2024-07-18
ER

PT J
AU Cheng, DQ
   Chen, JH
   Lv, C
   Han, CG
   Jiang, H
AF Cheng, Deqiang
   Chen, Junhui
   Lv, Chen
   Han, Chenggong
   Jiang, He
TI Using full-scale feature fusion for self-supervised indoor depth
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Monocular depth estimation; Feature fusion; Self-supervised; Indoor
   scenes; ResNeSt
AB Monocular depth estimation is a crucial task in computer vision, and self-supervised algorithms are gaining popularity due to their independence from expensive ground truth supervision. However, current self-supervised algorithms may not provide accurate estimation and may suffer from distorted boundaries when applied to indoor scenes. Combining multi-scale features is an important research direction in image segmentation to achieve accurate estimation and resolve boundary distortion. However, there are few studies on indoor self-supervised algorithms in this regard. To solve this issue, we propose a novel full-scale feature information fusion approach that includes a full-scale skip-connection and a full-scale feature fusion block. This approach can aggregate the high-level and low-level information of all scale feature maps during the network's encoding and decoding process to compensate for the network's loss of cross-layer feature information. The proposed full-scale feature fusion improves accuracy and reduces the decoder parameters. To fully exploit the superiority of the full-scale feature fusion module, we replace the encoder backbone from ResNet with the more advanced ResNeSt. Combining these two methods results in a significant improvement in prediction accuracy. We have extensively evaluated our approach on the indoor benchmark datasets NYU Depth V2 and ScanNet. Our experimental results demonstrate that our method outperforms existing algorithms, particularly on NYU Depth V2, where our precision is raised to 83.8%.
C1 [Cheng, Deqiang; Chen, Junhui; Lv, Chen; Han, Chenggong; Jiang, He] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Jiang, H (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM jianghe@cumt.edu.cn
RI Chen, Junhui/HZJ-7077-2023
OI Chen, Junhui/0000-0002-5938-0760; Jiang, He/0000-0002-3345-9665
FU This work was supported by the National Natural Science Foundation of
   China under Grants 52204177.; National Natural Science Foundation of
   China;  [52204177]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 52204177.
CR Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Bian J-W, 2020, ARXIV
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Clevert D., 2016, ARXIV151107289
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Du R., 2020, P 33 ANN ACM S USER, P829, DOI 10.1145/3379337. 3415881
   Eigen D, 2014, ADV NEUR IN, V27
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Han C., 2022, MULTIMED TOOLS APPL, V31, P3251
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, P1, DOI [DOI 10.48550/ARXIV.1503.02531, 10.48550/arXiv.1503.02531]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Ji P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12767, DOI 10.1109/ICCV48922.2021.01255
   Jung G, 2022, MULTIMED TOOLS APPL, V81, P33759, DOI 10.1007/s11042-022-12301-8
   Jung H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12622, DOI 10.1109/ICCV48922.2021.01241
   Kingma D. P., 2014, arXiv
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Lee J, 2019, PR MACH LEARN RES, V97
   Lee S, 2021, AAAI CONF ARTIF INTE, V35, P1863
   Li B, 2021, P IEEECVF INT C COMP, P12663
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu L., 2021, P IEEECVF INT C COMP, P12737
   Lyu XY, 2021, AAAI CONF ARTIF INTE, V35, P2294
   Ma XP, 2023, PHYSIOTHER THEOR PR, DOI [10.1007/978-981-99-1157-8_1, 10.1080/09593985.2023.2232003]
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sun L, 2022, MULTIMED TOOLS APPL, V81, P42485, DOI 10.1007/s11042-021-11212-4
   Trockman A., 2022, arXiv
   Wang H., 2022, P IEEECVF C COMPUTER, P6209
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Y, 2022, IEEE T CIRC SYST VID, V32, P3839, DOI 10.1109/TCSVT.2021.3118681
   Wu CY, 2022, PROC CVPR IEEE, P3804, DOI 10.1109/CVPR52688.2022.00379
   Wu GJ, 2023, IEEE T PATTERN ANAL, V45, P11120, DOI 10.1109/TPAMI.2023.3265499
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan ZQ, 2022, LECT NOTES COMPUT SC, V13687, P214, DOI 10.1007/978-3-031-19812-0_13
   Yin W, 2022, IEEE T PATTERN ANAL, V44, P7282, DOI 10.1109/TPAMI.2021.3097396
   Zehao Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P206, DOI 10.1007/978-3-030-58586-0_13
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhao Wang, 2020, P IEEE CVF C COMP VI
   Zhou JS, 2019, IEEE I CONF COMP VIS, P8617, DOI 10.1109/ICCV.2019.00871
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 53
TC 0
Z9 0
U1 13
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28215
EP 28233
DI 10.1007/s11042-023-16581-6
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600002
DA 2024-07-18
ER

PT J
AU Soni, R
   Roy, P
   Nagwanshi, KK
AF Soni, Ravikant
   Roy, Partha
   Nagwanshi, Kapil Kumar
TI WKNN-FDCNN method for big data driven traffic flow prediction in ITS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Traffic flow prediction; Data mining; Fuzzy logic;
   Spatio-Temporal information
ID DEEP; OPTIMIZATION; SYSTEM; LSTM
AB Traffic prediction is a vital paradigm in intelligent transport system (ITS) due to the increase in traffic flow. The big data traffic flow prediction faces heterogeneity and complexity in data samples due to the huge number of data samples. The proposed WKNN-FDCNN method simplifies the big data handling process by utilizing the Weighted K Nearest Neighbour (WKNN) algorithm for data mining and a Fuzzy based Deep Convolutional Neural Network (FDCNN) for prediction. The spatio-temporal characteristics of traffic flow data are modeled as a weight function in WKNN, which helps in handling heterogeneity and complexity in data samples. The fuzzy logic incorporates uncertain information from real traffic flow data to improve the prediction performance. Finally, a DCNN approach is designed to predict the traffic flow using spatio-temporal features, traffic state information mined using the WKNN, and fuzzy traffic rules. The WKNN-FDCNN outperforms the conventional approaches in terms of Root Mean Squared Error (RMSE= 13.27), Mean Absolute Error (MAE= 10.34), R-square (0.98), and Mean Absolute Percentage Error (MAPE= 0.92) in the PeMSD4 dataset. The proposed method contributes to the development of intelligent transportation systems and provides a promising solution to handle big data challenges in traffic flow prediction.
C1 [Soni, Ravikant] Bhilai Inst Technol, Dept Comp Sci & Engn, Bhilai 491001, Chhattisgarh, India.
   [Roy, Partha] Bhilai Inst Technol, Dept Comp Sci & Engn, Durg, Chhattisgarh, India.
   [Nagwanshi, Kapil Kumar] Guru Ghasidas Vishwavidyalaya, Dept CSE SoS E&T, Bilaspur, India.
C3 Bhilai Institute of Technology; Bhilai Institute of Technology; Guru
   Ghasidas Vishwavidyalaya
RP Soni, R (corresponding author), Bhilai Inst Technol, Dept Comp Sci & Engn, Bhilai 491001, Chhattisgarh, India.
EM ravi.soni25@gmail.com; partha.roy@bitdurg.ac.in; Kapil.cse@ggu.ac.in
OI Soni, Ravikant/0000-0001-8537-6530; , Ravikant Soni/0009-0009-4337-0611
CR An JY, 2019, IEEE ACCESS, V7, P20708, DOI 10.1109/ACCESS.2019.2896913
   Boukerche A, 2020, COMPUT NETW, V182, DOI 10.1016/j.comnet.2020.107484
   Boukerche A, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102224
   Chen L, 2020, NEUROCOMPUTING, V413, P444, DOI 10.1016/j.neucom.2020.07.009
   Chen XQ, 2021, PHYSICA A, V565, DOI 10.1016/j.physa.2020.125574
   Dai XY, 2019, TRANSPORT RES C-EMER, V103, P142, DOI 10.1016/j.trc.2019.03.022
   Djenouri Y, 2019, IEEE ACCESS, V7, P10015, DOI 10.1109/ACCESS.2019.2891933
   Du S.S., 2018, ARXIV
   Duan PB, 2019, IEEE T INTELL TRANSP, V20, P3212, DOI 10.1109/TITS.2018.2873137
   Duan PB, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1610, DOI 10.1109/ITSC.2016.7795773
   George S, 2020, BIG DATA, V8, P291, DOI 10.1089/big.2019.0007
   Hou QZ, 2019, PHYSICA A, V527, DOI 10.1016/j.physa.2019.121065
   Katal A, 2013, INT CONF CONTEMP, P404, DOI 10.1109/IC3.2013.6612229
   Kong FH, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3482
   Kong FH, 2019, FUTURE GENER COMP SY, V93, P460, DOI 10.1016/j.future.2018.10.052
   Li W, 2021, NEUROCOMPUTING, V427, P50, DOI 10.1016/j.neucom.2020.11.032
   Li YQ, 2021, IEEE ACCESS, V9, P11264, DOI 10.1109/ACCESS.2021.3050836
   Liu LB, 2021, IEEE T INTELL TRANSP, V22, P7169, DOI 10.1109/TITS.2020.3002718
   Liu QC, 2018, IEEE ACCESS, V6, P9690, DOI 10.1109/ACCESS.2017.2788639
   Liu Y, 2020, IEEE INTERNET THINGS, V7, P7751, DOI 10.1109/JIOT.2020.2991401
   Lu HK, 2021, NEUROCOMPUTING, V427, P169, DOI 10.1016/j.neucom.2020.11.026
   Lu SQ, 2021, ALEX ENG J, V60, P87, DOI 10.1016/j.aej.2020.06.008
   Luo X, 2019, J ADV TRANSP 2019
   Ma CX, 2022, IEEE T INTELL TRANSP, V23, P5615, DOI 10.1109/TITS.2021.3055258
   Miglani A, 2019, VEH COMMUN, V20, DOI 10.1016/j.vehcom.2019.100184
   Pems.dot.ca.gov, DAT
   Ryu U, 2018, TRANSPORT RES C-EMER, V96, P55, DOI 10.1016/j.trc.2018.09.015
   Suthaharan Shan, 2014, ACM SIGMETRICS Performance Evaluation Review, V41, P70
   Tang JJ, 2019, IEEE ACCESS, V7, P101009, DOI 10.1109/ACCESS.2019.2931920
   Wang K, 2021, PHYSICA A, V583, DOI 10.1016/j.physa.2021.126293
   Wei WY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132946
   Wu YK, 2018, TRANSPORT RES C-EMER, V90, P166, DOI 10.1016/j.trc.2018.03.001
   Xia DW, 2016, IEEE ACCESS, V4, P2920, DOI 10.1109/ACCESS.2016.2570021
   Yang BL, 2019, NEUROCOMPUTING, V332, P320, DOI 10.1016/j.neucom.2018.12.016
   Yang J, 2020, J EVID-BASED MED, V13, P57, DOI 10.1111/jebm.12373
   Zhang Y, 2020, IEEE ACCESS, V8, P91510, DOI 10.1109/ACCESS.2020.2994655
   Zheng HF, 2021, IEEE T INTELL TRANSP, V22, P6910, DOI 10.1109/TITS.2020.2997352
   Zheng LJ, 2020, NEUROCOMPUTING, V412, P339, DOI 10.1016/j.neucom.2020.05.038
   Zheng ZB, 2019, IEEE T INTELL TRANSP, V20, P3927, DOI 10.1109/TITS.2019.2909904
   Zhou F, 2021, TRANSPORT RES C-EMER, V124, DOI 10.1016/j.trc.2020.102912
   Zhou ZY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2297, DOI 10.1145/2783258.2788570
NR 41
TC 1
Z9 1
U1 10
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25261
EP 25286
DI 10.1007/s11042-023-16591-4
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600001
DA 2024-07-18
ER

PT J
AU Kavitha, KJ
   Shan, PB
AF Kavitha, K. J.
   Shan, Priestly B.
TI Medical image watermarking based on novel encoding for EHR and fusion
   based morphological watershed segmentation algorithm for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MIW; Segmentation; DTCWT; Morphology; Watershed algorithm; Fusion
   technique; US; MRI; CT
AB Advancement in the field of healthcare system, the identification of the infection with severity impact of a particular disease may be easily done with the help of scanned radiological images and thereby segmentation plays a major role in detection of presence of foreign objects or infected areas in certain parts of a human body and thereby helps in providing a clinical care to the patient with crucial state. So, precise segmentation is a key-step in the analysis of a disease at the time of radio therapy. Although many traditional segmentation techniques are available to separate region of interest from that of region of non-interest; no complete segmentation algorithm is available which is suitable for all kinds of medical images and moreover, an algorithm suitable for one kind of medical image may not be suitable for other type of medical image as each category of image differs in their characteristics; And hence, in the proposed paper, an improved segmentation algorithm based on dual tree complex wavelet transform (DTCWT) and fusion-morphological watershed algorithm for denoising is proposed for all kinds of scanned medical images and also proposes a medical image watermarking (MIW) based on encoding algorithm with hybrid embedding function for authentication in E-Health care systems. The MIW and segmentation algorithm is applied and evaluated to various modalities of medical images using various quality metrics and statistical parameters. The data integrity of the proposed system is evaluated for constructed MI and EHR and is validated by identifying tampered information in terms of decoding correct and wrong information using secret keys in the proposed system.
C1 [Kavitha, K. J.] GM Inst Technol, Davangere, Karnataka, India.
   [Shan, Priestly B.] Chandigarh Univ, Mohali, India.
C3 Chandigarh University
RP Kavitha, KJ (corresponding author), GM Inst Technol, Davangere, Karnataka, India.
EM kavithakj219@gmail.com; priestlyshan@gmail.com
RI K J, Kavitha/T-9198-2019; Shan, Priestly/T-8891-2019
OI K J, Kavitha/0000-0002-1819-7919; Shan, Priestly/0000-0003-2865-6565
CR Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Akkus Z, 2015, CANCER IMAGING, V15, P1, DOI 10.1186/s40644-015-0047-z
   Al-Haj A, 2015, J DIGIT IMAGING, V28, P179, DOI 10.1007/s10278-014-9734-8
   Atta UR., 2018, J HEALTHC ENG, V2018, P1, DOI DOI 10.1155/2018/8137436
   Benson CC, 2015, BRAIN TUMOR EXTRACTI
   Chaithanya JK., 2014, INT J CURR ENG TECHN, V2, P344, DOI [10.14741/ijcet/spl.2.2014.63, DOI 10.14741/IJCET/SPL.2.2014.63]
   Chourasia S., 2019, INT J ADV RES COMPUT, V9, P26
   Derivaux S, 2010, PATTERN RECOGN LETT, V31, P2364, DOI 10.1016/j.patrec.2010.07.007
   El Jurdi R, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103248
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Fawaz WA., 2016, RES J INF TECHNOL, V8, P88, DOI DOI 10.3923/RJIT.2016.88.97
   Fawaz WA., 2017, J ARTIF INTELL, V10, P32
   Ghadi M, 2016, SECUR COMMUN NETW, V9, P5203, DOI 10.1002/sec.1690
   Giri K. J., 2021, Multimedia Security, P177
   Gopinath J., 2015, INT J MOD TRENDS ENG, V2, P420
   Guo Z, 2019, IEEE T RADIAT PLASMA, V3, P162, DOI [10.1109/TRPMS.2018.2890359, 10.1109/trpms.2018.2890359]
   Habib RU, 2019, INT J ADV COMPUT SC, V10, P163
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Liu J, 2019, CMC-COMPUT MATER CON, V61, P889, DOI 10.32604/cmc.2019.06034
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Meyer F, 1999, LECT NOTES COMPUT SC, V1682, P351
   NHP CC DC National Health Portal India (Gateway of authentic health Information, 2014, ELECT HLTH RECORD ST
   Paulose H., 2015, IOSR J ENG, V5, P1
   Rashmi M, 2020, ETHEALTHWORLD 0106
   Rocek A, 2017, IEEE I C ELECT CIRC, P356, DOI 10.1109/ICECS.2017.8292071
   Sakinis T, 2019, COMPUTER VISION PATT, P1
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Supe PV., 2019, INT J FUTURE REVOLUT, V5, P45
   Thakur P., 2012, INT J COMPUT APPL, V58, P975
   Umamageswari A., 2014, INT J APPL ENG RES, V9, P12163
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25163
EP 25190
DI 10.1007/s11042-023-16490-8
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100004
DA 2024-07-18
ER

PT J
AU Chu, CQ
   Xiao, QK
   Chang, LR
   Shen, JN
   Zhang, N
   Du, Y
   Xing, H
   Gao, H
AF Chu, Chaoqin
   Xiao, Qinkun
   Chang, Leran
   Shen, Jianing
   Zhang, Na
   Du, Yu
   Xing, Heng
   Gao, Hui
TI EEG temporal information-based 1-D convolutional neural network for
   motor imagery classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-computer interface; EEG; 1D CNN; Core blocks; Motor imagery;
   Classification
ID DEEP; SYSTEM
AB Brain-Computer Interface (BCI) enables human beings to interact with the outside world through brain intention. Human-computer interaction (HCI) based on electroencephalogram (EEG) has become the main research direction in the field of BCI. Though many achievements have been made in EEG research recently, the lack of sample data and individual differences, effective motor imagery (MI) classification based on EEG signals is still a challenge. Compared with the 2D and 3D CNN models that are widely used, however, there are few researches on extracting EEG sequence features using 1D CNN model. To this end, considering the temporal structure of multi-channel EEG signals, we propose a EEG-Based temporal one-dimensional convolution neural network (ETIODCNN) to classify MI. First, we extract temporal correlation from EEG signals by introducing the core blocks. Then, we use the global average pooling (GAP) layer and the fully connected (F) layer to fuse the temporal series features, and realize classification task. Our model can automatically learn effective features from EEG signals. We trained and tested the proposed method on BCI competition IV datasets (BCICID). The experiments were conducted on two open-source EEG datasets. The comparison results show that this method has good performance in real-time and accuracy.
C1 [Chu, Chaoqin; Xiao, Qinkun] Xian Technol Univ, Dept Mech & Elect Engn, Xian 710021, Shaanxi, Peoples R China.
   [Xiao, Qinkun; Chang, Leran; Shen, Jianing; Zhang, Na; Du, Yu; Xing, Heng; Gao, Hui] Xian Technol Univ, Dept Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
C3 Xi'an Technological University; Xi'an Technological University
RP Chu, CQ (corresponding author), Xian Technol Univ, Dept Mech & Elect Engn, Xian 710021, Shaanxi, Peoples R China.; Gao, H (corresponding author), Xian Technol Univ, Dept Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
EM chuchaoqin@st.xatu.edu.cn; gaohui@xatu.edu.cn
OI Chu, Chaoqin/0000-0002-5535-4709
FU Nature Science Foundation of China [61671362, 62071366]
FX AcknowledgementsThis work was supported by the Nature Science Foundation
   of China (Nos. 61671362 and 62071366).
CR Al-qaysi ZT, 2018, COMPUT METH PROG BIO, V164, P221, DOI 10.1016/j.cmpb.2018.06.012
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Ang KK, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00039
   Atyabi A, 2017, NEUROCOMPUTING, V224, P19, DOI 10.1016/j.neucom.2016.10.055
   Bahador N, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/abb5bd
   Bang JS, 2022, IEEE T NEUR NET LEAR, V33, P3038, DOI 10.1109/TNNLS.2020.3048385
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Jimenez IAC, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010122
   Croce P, 2019, IEEE T BIO-MED ENG, V66, P2372, DOI 10.1109/TBME.2018.2889512
   Devlaminck D, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/217987
   Di Flumeri G, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00296
   Dose H, 2018, EXPERT SYST APPL, V114, P532, DOI 10.1016/j.eswa.2018.08.031
   Feng JK, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8068357
   Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154
   Gupta A, 2019, SMART INNOV SYST TEC, V107, P731, DOI 10.1007/978-981-13-1747-7_72
   Hou YM, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab4af6
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiao ZC, 2018, PATTERN RECOGN, V76, P582, DOI 10.1016/j.patcog.2017.12.002
   Joadder MAM, 2019, IRBM, V40, P297, DOI 10.1016/j.irbm.2019.05.004
   Kumar Shiu, 2016, 2016 3rd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE), P34, DOI 10.1109/APWC-on-CSE.2016.017
   Leeb R, 2013, IEEE T COMP INTEL AI, V5, P117, DOI 10.1109/TCIAIG.2013.2242072
   Liu Jin-zhen, 2021, Journal of Zhejiang University (Engineering Science), V55, P2054, DOI 10.3785/j.issn.1008-973X.2021.11.005
   Liu X, 2020, FRONT NEUROSCI, V1157
   Lopes AC, 2013, ROBOT AUTON SYST, V61, P245, DOI 10.1016/j.robot.2012.11.002
   Musallam YK, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102826
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Noureddin B, 2012, IEEE T BIO-MED ENG, V59, P2103, DOI 10.1109/TBME.2011.2108295
   Peng DD, 2019, IEEE ACCESS, V7, P10278, DOI 10.1109/ACCESS.2018.2888842
   Perera D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166230
   Perez-Enciso Miguel, 2019, Genes (Basel), V10, DOI 10.3390/genes10070553
   Sadiq MT, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114031
   Saini M, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103494
   Sakhavi S, 2018, IEEE T NEUR NET LEAR, V29, P5619, DOI 10.1109/TNNLS.2018.2789927
   Samek W, 2013, IEEE T BIO-MED ENG, V60, P2289, DOI 10.1109/TBME.2013.2253608
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Sharma G, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102393
   Shen YR, 2017, LECT NOTES COMPUT SC, V10559, P181, DOI 10.1007/978-3-319-67777-4_16
   Sun YN, 2019, EXPERT SYST APPL, V125, P259, DOI 10.1016/j.eswa.2019.01.080
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Wang T, 2012, INT C PATT RECOG, P3304
   Wu H, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01275
   Wu SL, 2017, IEEE T FUZZY SYST, V25, P21, DOI 10.1109/TFUZZ.2016.2598362
   Zhang R, 2016, IEEE T NEUR SYS REH, V24, P128, DOI 10.1109/TNSRE.2015.2439298
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhang Y, 2019, IEEE T CYBERNETICS, V49, P3322, DOI 10.1109/TCYB.2018.2841847
   Zhao XF, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103338
   Zhuang JY, 2021, IEEE T SYST MAN CY-S, V51, P5392, DOI 10.1109/TSMC.2019.2955478
NR 48
TC 0
Z9 0
U1 15
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45747
EP 45767
DI 10.1007/s11042-023-16536-x
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001052828600007
DA 2024-07-18
ER

PT J
AU Wu, QE
   Song, ZC
   Chen, H
   Lu, YB
   Zhou, LT
   Qian, XL
AF Wu, Qing E.
   Song, Zhichao
   Chen, Hu
   Lu, Yingbo
   Zhou, Lintao
   Qian, Xiaoliang
TI A color edge extraction method on color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color images; Function series; Edge extraction; Template transformation;
   Color feature extraction
AB In the field of medical image recognition, industrial defect detection and other fields, because it is impossible to extract the edge of the color image directly, the recognition effect is poor. In order to extract the edge of the color image directly and retain the color information of the edge. This paper proposes a color image edge extraction method called function series. In this paper, the template threshold denoising method is used to denoise the input image. Then the key features of the input image are enhanced by using the image key feature enhancement function proposed in this paper. Then use the function series to extract the color features of the H, S, I space of the input image. The extracted color features are decomposed by eigenvalue decomposition, and the color information with larger eigenvalue is retained to enhance the color information of the edge. Finally, the edge of the target image with color information is obtained by the inverse transformation of the function series. The experimental results show that the correct edge recognition rate of this method is 92.09%. Moreover, this method can accurately extract the contour of the color image, and the color information is preserved completely. Compared with other methods, the correct recognition rate of this method is higher than that of the comparison method and can retain more abundant color information. The method proposed in this paper provides a new extraction method for color image edge extraction, which has certain practical value.
C1 [Wu, Qing E.; Song, Zhichao; Chen, Hu; Lu, Yingbo; Zhou, Lintao; Qian, Xiaoliang] Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry
RP Wu, QE (corresponding author), Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
EM wqe969699@163.com
OI Wu, QingE/0000-0002-7746-8694
FU Key Science and Technology Program of Henan Province [222102210084]; Key
   Science and Technology Project of Henan Province University [23A413007]
FX AcknowledgementsThis work is supported by Key Science and Technology
   Program of Henan Province (222102210084); Key Science and Technology
   Project of Henan Province University (23A413007), respectively.
CR Bao Congwang H., 2023, COMBINED MACH TOOLS, V587, P83
   Chen YJ, 2019, CLUSTER COMPUT, V22, pS8069, DOI 10.1007/s10586-017-1604-y
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Feifei L., 2023, ENG TECHNOL, V52, P206
   Flores-Vidal PA, 2019, SOFT COMPUT, V23, P1809, DOI 10.1007/s00500-018-3540-z
   He DF, 2021, INFORMATION, V12, DOI 10.3390/info12050196
   He YB, 2018, INT J MOD PHYS C, V29, DOI 10.1142/S0129183118500079
   Jiang JL, 2020, KSII T INTERNET INF, V14, P687, DOI 10.3837/tiis.2020.02.012
   Kanchanatripop P, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111749
   Li HA, 2023, IMAGING SCI J, V71, P299, DOI 10.1080/13682199.2023.2180834
   Li HA, 2023, CONNECT SCI, V35, DOI 10.1080/09540091.2023.2182487
   Li O, 2019, SIGNAL PROCESS, V165, P90, DOI 10.1016/j.sigpro.2019.06.036
   Liu C, 2023, KSII T INT INF SYST, V17, P1
   Long MZ, 2018, IEEE T BIOMED CIRC S, V12, P993, DOI 10.1109/TBCAS.2018.2869530
   Lou L., 2020, J PHYS C SERIES, V1607, DOI 10.1088/1742-6596/1607/1/012068
   Mehena J., 2019, INT J COMPUT SCI ENG, V7, P523, DOI DOI 10.26438/IJCSE/V7I6.523528
   Mishra SK, 2021, MULTIMED TOOLS APPL, V80, P29965, DOI 10.1007/s11042-021-11187-2
   Nandal A, 2018, CIRC SYST SIGNAL PR, V37, P3946, DOI 10.1007/s00034-018-0751-6
   Raheja S, 2021, EVOL SYST-GER, V12, P447, DOI 10.1007/s12530-019-09304-6
   Sert E, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540089
   Wang JW, 2019, IEEE T CIRC SYST VID, V29, P2775, DOI 10.1109/TCSVT.2018.2867786
   Xie X, 2020, J AMB INTEL HUM COMP, V11, P2061, DOI 10.1007/s12652-019-01232-2
   Yahya AA, 2019, J ENG-JOE, P455, DOI 10.1049/joe.2018.5345
   YongSang Ryu, 2018, IAENG International Journal of Computer Science, V45
   Zhao Peng, 2023, 2023 IEEE 3rd International Conference on Power, Electronics and Computer Applications (ICPECA), P176, DOI 10.1109/ICPECA56706.2023.10075820
NR 26
TC 0
Z9 0
U1 20
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25435
EP 25460
DI 10.1007/s11042-023-16496-2
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001054228300006
DA 2024-07-18
ER

PT J
AU Gupta, D
   Gupta, U
   Sarma, HJ
AF Gupta, Deepak
   Gupta, Umesh
   Sarma, Hemanga Jyoti
TI Functional iterative approach for Universum-based primal twin bounded
   support vector machine to EEG classification (FUPTBSVM)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Universum support vector machine; Universum twin support vector machine;
   EEG signals; Functional iterative approaches
ID SIGNAL CLASSIFICATION; SEIZURE
AB Due to the increasing popularity of support vector machine (SVM) and the introduction of Universum, many variants of SVM along with Universum such as Universum support vector machine (USVM), Universum twin support vector machine (UTSVM), have been applied to several binary classification problems like electroencephalogram (EEG) signals, handwritten digit recognition and many more. Universum, which is not belonging to either class, is considered recently by many researchers that accept the prior knowledge into the binary classification process. In this paper, an effective and improved approach of TSVM with Universum data is proposed named a functional iterative approach for Universum-based primal twin bounded support vector machine to EEG classification (FUPTBSVM) which provides better performance. It also considers the gist of structural risk minimization (SRM) theory through the inclusion of the regularization parameter in the primal problem of FUPTBSVM and solved through a functional iterative approach. The regularization parameters terms are added to enhance the stability and make the model well-posed. Our proposed approach FUPTBSVM along with four standard classification approaches is tested on various EEG signals datasets with N Universum data or without N and benchmark real-world datasets. After conducting several numerical experiments with our proposed algorithm, one can analyze that FUPTBSVM improves the generalization performance in comparison to USVM, UTSVM, RUTSVM, and ULSTSVM for binary classification problems using Gaussian kernel. It achieves 88.66% accuracy which is higher than other compared approaches for real-world datasets. It is also computationally intensive among all concerned approaches.
C1 [Gupta, Deepak] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, Uttar Pradesh, India.
   [Gupta, Umesh] Bennett Univ, Greater Noida, Uttar Pradesh, India.
   [Sarma, Hemanga Jyoti] Natl Inst Technol Arunachal Pradesh, Jote 791112, Arunachal Prade, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; National Institute of Technology (NIT System);
   National Institute of Technology Arunachal Pradesh
RP Gupta, D (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, Uttar Pradesh, India.
EM deepakjnu85@gmail.com; er.umeshgupta@gmail.com;
   hemangasarma1993@gmail.com
RI GUPTA, UMESH/AAC-4589-2021
OI GUPTA, UMESH/0000-0002-1547-7974
CR Ahangi A, 2013, NEURAL COMPUT APPL, V23, P1319, DOI 10.1007/s00521-012-1074-3
   Alvi AM, 2022, LECT NOTES COMPUT SC, V13459, P177, DOI 10.1007/978-3-031-15512-3_15
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2022, UCI DAT
   Nguyen B, 2017, PATTERN RECOGN LETT, V100, P37, DOI 10.1016/j.patrec.2017.09.031
   Bajaj V, 2012, IEEE T INF TECHNOL B, V16, P1135, DOI 10.1109/TITB.2011.2181403
   Brinkmann BH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133900
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui LM, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P60, DOI 10.1109/ICDMW.2014.8
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   EEG dataset repository, 2022, EP WHO
   Fu K, 2014, BIOMED SIGNAL PROCES, V13, P15, DOI 10.1016/j.bspc.2014.03.007
   Fung G, 2003, NEUROCOMPUTING, V55, P39, DOI 10.1016/S0925-2312(03)00379-5
   Ganaie MA, 2023, ANN OPER RES, V328, P451, DOI 10.1007/s10479-022-04922-x
   Gupta D, 2019, IEEE SYS MAN CYBERN, P2298, DOI 10.1109/SMC.2019.8913897
   Gupta S, 2018, 2018 INT JOINT C NEU, P1
   Gupta U, 2020, ADV INTELL SYST COMP, V1040, P635, DOI 10.1007/978-981-15-1451-7_65
   Gupta U, 2019, APPL INTELL, V49, P3606, DOI 10.1007/s10489-019-01465-w
   Gupta U, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P228, DOI 10.1109/SSCI.2018.8628903
   Hazarika BB, 2020, ENVIRON EARTH SCI, V79, DOI 10.1007/s12665-020-08949-w
   Higashi H, 2013, IEEE T BIO-MED ENG, V60, P1100, DOI 10.1109/TBME.2012.2215960
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Jiao Y, 2010, INT CONF BIOMED, P657, DOI 10.1109/BMEI.2010.5640046
   Joshi V, 2014, BIOMED SIGNAL PROCES, V9, P1, DOI 10.1016/j.bspc.2013.08.006
   Khorshidtalab A., 2011, Mechatronics (ICOM), 2011 4th International Conference On, P1
   Kottaimalai R, 2013, INT C TREND COMPUT C, P227, DOI 10.1109/ICE-CCN.2013.6528498
   Kumar B, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106244
   Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374
   Li DD, 2017, NEURAL PROCESS LETT, V45, P1077, DOI 10.1007/s11063-016-9567-1
   Liu B, 2022, INFORM SCIENCES, V609, P1334, DOI 10.1016/j.ins.2022.07.155
   Lu S, 2014, ADV COMPUT SCI INT J, V3, P17
   Maitin AM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12146967
   Moosaei H, 2022, Arxiv, DOI arXiv:2206.10978
   Moosaei H, 2023, ANN MATH ARTIF INTEL, V91, P109, DOI 10.1007/s10472-022-09783-5
   Nunes TM, 2014, NEUROCOMPUTING, V136, P103, DOI 10.1016/j.neucom.2014.01.020
   Omerhodzic I, 2013, Arxiv, DOI arXiv:1307.7897
   Orhan U, 2011, EXPERT SYST APPL, V38, P13475, DOI 10.1016/j.eswa.2011.04.149
   Pachori RB, 2014, COMPUT METH PROG BIO, V113, P494, DOI 10.1016/j.cmpb.2013.11.014
   Praveena DM, 2022, IETE J RES, V68, P3030, DOI 10.1080/03772063.2020.1749143
   Qi ZQ, 2014, J COMPUT APPL MATH, V263, P288, DOI 10.1016/j.cam.2013.11.003
   Qi ZQ, 2012, NEURAL NETWORKS, V36, P112, DOI 10.1016/j.neunet.2012.09.004
   Richhariya B, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101903
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Richhariya B, 2019, APPL SOFT COMPUT, V76, P53, DOI 10.1016/j.asoc.2018.11.046
   Sabeti M, 2011, EXPERT SYST APPL, V38, P2063, DOI 10.1016/j.eswa.2010.07.145
   Shi M, 2021, BIOMED ENG-BIOMED TE, V66, P137, DOI 10.1515/bmt-2020-0038
   Shiao HT, 2017, IEEE T BIO-MED ENG, V64, P1011, DOI 10.1109/TBME.2016.2586475
   Siuly, 2011, INT J BIOMED ENG TEC, V7, P390, DOI 10.1504/IJBET.2011.044417
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Nguyen T, 2015, EXPERT SYST APPL, V42, P4370, DOI 10.1016/j.eswa.2015.01.036
   Wang D, 2011, EXPERT SYST APPL, V38, P14314, DOI 10.1016/j.eswa.2011.05.096
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Weston J., 2006, P 23 INT C MACH LEAR, P1009
   Zhu CM, 2020, SOFT COMPUT, V24, P10657, DOI 10.1007/s00500-019-04572-5
   Zhu GH, 2014, IEEE J BIOMED HEALTH, V18, P1813, DOI 10.1109/JBHI.2014.2303991
NR 56
TC 3
Z9 3
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-16412-8
EA AUG 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100006
DA 2024-07-18
ER

PT J
AU Xia, DW
   Chen, Y
   Zhang, WY
   Hu, Y
   Li, YT
   Li, HQ
AF Xia, Dawen
   Chen, Yan
   Zhang, Wenyong
   Hu, Yang
   Li, Yantao
   Li, Huaqing
TI RSAB-ConvGRU: A hybrid deep-learning method for traffic flow prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic flow prediction; Deep learning; Conv-GRU; Bi-GRU; Residual
   self-attention mechanism; Convolution
ID SUPPORT VECTOR MACHINE; NEURAL-NETWORK; MODEL; FEATURES; TIME
AB Accurate and real-time traffic flow prediction is crucial in intelligent transportation systems (ITS), and the traditional shallow prediction methods are challenging to capture the nonlinearity and uncertainty of traffic data effectively. To this end, this paper proposes a hybrid deep-learning method based on Residual Self-Attention and Bidirectional Gated Recurrent Unit combined with a Convolution-Gated Recurrent Unit (RSAB-ConvGRU) network to improve the accuracy of traffic flow prediction. The method consists of an RSA-ConvGRU module and two Bidirectional GRU (Bi-GRU) modules. The RSA-ConvGRU module includes a convolution-gated recurrent unit (Conv-GRU) module and a residual self-attention mechanism (RSA) module. Specifically, the Conv-GRU utilizes the convolutional and gated recurrent unit to extract spatial and temporal features. Moreover, the residual self-attention mechanism is used to determine the contribution of traffic features at different periods and stabilize the network's training process to improve Conv-GRU's prediction performance. Finally, the Bi-GRU module obtains the periodic characteristics and forward and backward variance trends in traffic flow data. The experimental results show that the accuracy of the RSAB-ConvGRU method is superior to state-of-the-art methods, such as SVR, LSTM, GRU, DCRNN, CNN-GRU-Attention, Conv-LSTM, AT-Conv-LSTM, Stacked-LSTM, and LSTM-RNN with Attention. Compared to the above nine methods, with a prediction time of 60 minutes and the urban traffic data, the MAPE values of RSAB-ConvGRU are reduced by 56.01%, 22.97%, 25.64%, 16.55%, 7.57%, 11.11%, 12.58%, 7.64%, and 6.3%, respectively.
C1 [Xia, Dawen; Chen, Yan; Zhang, Wenyong] Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Hu, Yang] Guizhou Traff Technician & Transportat Coll, Dept Automot Engn, Guiyang 550008, Peoples R China.
   [Li, Yantao] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Li, Huaqing] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Guizhou Minzu University; Chongqing University; Southwest University -
   China
RP Li, HQ (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM dwxia@gzmu.edu.cn; huaqingli@swu.edu.cn
RI zhao, wei/JZD-4475-2024; chen, ying/HHS-8254-2022; zhang,
   quan/KHY-9180-2024; Chen, YiJun/KFS-9282-2024; li, Shang/KHU-3233-2024;
   CHEN, MINGWEI/KHT-6744-2024; Zhang, jin/KFT-0762-2024; tong,
   li/KDO-7821-2024
FU National Natural Science Foundation of China [62162012, 62173278,
   62072061]; Science and Technology Support Program of Guizhou Province,
   China [QKHZC2021YB531]; Natural Science Research Project of Department
   of Education of Guizhou Province, China [QJJ2022015, QJJ2022047];
   Scientific Research Platform Project of Guizhou Minzu University, China
   [[2021]04]
FX AcknowledgementsThis work described in this paper was supported in part
   by the National Natural Science Foundation of China (Grant nos.
   62162012, 62173278, and 62072061), the Science and Technology Support
   Program of Guizhou Province, China (Grant no. QKHZC2021YB531), the
   Natural Science Research Project of Department of Education of Guizhou
   Province, China (Grant nos. QJJ2022015 and QJJ2022047), and the
   Scientific Research Platform Project of Guizhou Minzu University, China
   (Grant no. GZMUSYS[2021]04).
CR Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   Belhadi A, 2020, APPL INTELL, V50, P3252, DOI 10.1007/s10489-020-01716-1
   Cai LR, 2019, PHYSICA A, V536, DOI 10.1016/j.physa.2019.122601
   Chen XQ, 2020, IEEE SENS J, V20, P14317, DOI 10.1109/JSEN.2020.3007809
   Cho K., 2014, ARXIV14061078
   Djenouri Y, 2023, FUTURE GENER COMP SY, V139, P100, DOI 10.1016/j.future.2022.09.018
   Djenouri Y, 2022, COMPUT COMMUN, V189, P175, DOI 10.1016/j.comcom.2022.03.021
   Djenouri Y, 2019, IEEE ACCESS, V7, P12192, DOI 10.1109/ACCESS.2019.2893124
   Djenouri Y, 2019, IEEE ACCESS, V7, P10015, DOI 10.1109/ACCESS.2019.2891933
   Du SD, 2020, INT J COMPUT INT SYS, V13, P85, DOI 10.2991/ijcis.d.200120.001
   Emami A, 2019, J MOD TRANSP, V27, P222, DOI 10.1007/s40534-019-0193-2
   Fu R, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P324, DOI 10.1109/YAC.2016.7804912
   Ghanim MS, 2022, SUSTAIN CITIES SOC, V81, DOI 10.1016/j.scs.2022.103830
   Giraka O, 2020, TRANSP LETT, V12, P483, DOI 10.1080/19427867.2019.1645476
   Gu YL, 2019, TRANSPORT RES C-EMER, V106, P1, DOI 10.1016/j.trc.2019.07.003
   Habtemichael FG, 2016, TRANSPORT RES C-EMER, V66, P61, DOI 10.1016/j.trc.2015.08.017
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseini MK, 2019, TRANSPORT RES REC, V2673, P425, DOI 10.1177/0361198119841291
   Hu HX, 2022, IEEE T INTELL TRANSP, V23, P16612, DOI 10.1109/TITS.2021.3113935
   Hu XP, 2023, J ADHES SCI TECHNOL, V37, P683, DOI 10.1080/01694243.2022.2036412
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Kumar BP, 2022, J SCI IND RES INDIA, V81, P408
   Li Yaguang, 2018, INT C LEARN REPR
   Lin XF, 2021, WIRELESS PERS COMMUN, V117, P3421, DOI 10.1007/s11277-021-08085-z
   Liu YP, 2017, INT CONF WIRE COMMUN
   Luo J, 2020, PROMET-ZAGREB, V32, P821
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Meng M, 2022, TRANSPORT RES REC, V2676, P353, DOI 10.1177/03611981221074371
   Mondal MA, 2022, ARAB J SCI ENG, V47, P10515, DOI 10.1007/s13369-022-06575-1
   Moniruzzaman M, 2016, TRANSPORT RES C-EMER, V63, P182, DOI 10.1016/j.trc.2015.12.004
   Nagaraj N, 2022, MULTIMED TOOLS APPL, V81, P12519, DOI 10.1007/s11042-022-12306-3
   Nie S.Y. L., 2017, IEEE WCNC, P1, DOI 10.1109/WCNC.2017.7925498.
   Poonia P., 2020, P INT C EM TRENDS CO, P1, DOI 10.1109/ICONC345789.2020.9117329
   Priambodo B, 2021, J INTELL FUZZY SYST, V40, P9059, DOI 10.3233/JIFS-201493
   Ren CX, 2021, J ADV TRANSPORT, V2021, DOI 10.1155/2021/9928073
   Sha SW, 2020, IEEE ACCESS, V8, P15232, DOI 10.1109/ACCESS.2020.2964680
   Shu WN, 2022, IEEE T INTELL TRANSP, V23, P16654, DOI 10.1109/TITS.2021.3094659
   Sun B, 2018, IET INTELL TRANSP SY, V12, P41, DOI 10.1049/iet-its.2016.0263
   Thaduri Amani, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1590, DOI 10.1109/ICICCS51141.2021.9432224
   Toan TD, 2021, TRANSPORT RES REC, V2675, P362, DOI 10.1177/0361198120980432
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2014, TRANSPORT RES C-EMER, V43, P79, DOI 10.1016/j.trc.2014.02.005
   Wu YK, 2018, TRANSPORT RES C-EMER, V90, P166, DOI 10.1016/j.trc.2018.03.001
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P23589, DOI 10.1007/s11042-022-12039-3
   Xia DW, 2022, NEURAL COMPUT APPL, V34, P1557, DOI 10.1007/s00521-021-06409-5
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Xia DW, 2016, NEUROCOMPUTING, V179, P246, DOI 10.1016/j.neucom.2015.12.013
   Xie DF, 2019, TRANSPORT RES C-EMER, V106, P41, DOI 10.1016/j.trc.2019.07.002
   Xu HB, 2020, NEURAL COMPUT APPL, V32, P2027, DOI 10.1007/s00521-019-04339-x
   Xu XC, 2023, J INTELL TRANSPORT S, V27, P1, DOI 10.1080/15472450.2021.1977639
   Yang D, 2019, IEICE T INF SYST, VE102D, P1526, DOI 10.1587/transinf.2018EDP7330
   Yu CY, 2014, J ADV TRANSPORT, V48, P250, DOI 10.1002/atr.1217
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   [张建晋 Zhang Jianjin], 2020, [计算机学报, Chinese Journal of Computers], V43, P286
   Zhang WB, 2019, TRANSPORTMETRICA A, V15, P1688, DOI 10.1080/23249935.2019.1637966
   Zheng HF, 2021, IEEE T INTELL TRANSP, V22, P6910, DOI 10.1109/TITS.2020.2997352
   Zhu Z, 2016, J ADV TRANSPORT, V50, P1111, DOI 10.1002/atr.1392
NR 57
TC 0
Z9 0
U1 13
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20559
EP 20585
DI 10.1007/s11042-023-15877-x
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200015
DA 2024-07-18
ER

PT J
AU Masal, KM
   Bhatlawande, S
   Shingade, SD
AF Masal, Komal Mahadeo
   Bhatlawande, Shripad
   Shingade, Sachin Dattatraya
TI Development of a visual to audio and tactile substitution system for
   mobility and orientation of visually impaired people: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Visually impaired people; Assistive systems; Barrier avoidance; Object
   detection; Mobility and orientation
ID COMPUTER VISION; ASSISTIVE NAVIGATION; BLIND; INDIVIDUALS; FRAMEWORK;
   ADULTS; SOUND
AB According to the World Health Organization (WHO), visual impairment is one of the most common problems affecting approximately one sixth of the world's population. It was found that 39 million of these sufferers have lost their vision completely and require supervision from other people to do their daily chores. Until today, several methodologies have been built to provide effective solutions to visually challenged people, mainly in terms of navigation. The assistive technologies developed for the visually challenged are generally very popular due to the benefits provided, but these technologies are limited in many aspects. One of the main problems with the technologies is that they are non-adaptable and cannot adjust to the changing needs of the participants. The demands of blind people are constantly growing, and there is no powerful technology that can meet all of these demands at the same time. The major constraints with assistive technologies are cost-effectiveness and user-friendliness. This paper presents a complete review of the assistive technologies introduced in the literature to deal with the navigation problems of blind people. Each and every literature work focuses on the requirements of the blind, and several features are considered accordingly. Thus, the presented review provides a detailed description of the evolution of such assistive technologies and the improvements brought in to satisfy the users. Apart from this, the complexities and limitations associated with the technologies are also unwounded to provide a clear perspective on the current scenario for future developers and researchers. Several constraints associated with different assistive technology are interpreted, and this review ends with the insights drawn from the study along with future scopes.
C1 [Masal, Komal Mahadeo] SPPU, Dept Technol DOT, Pune 411007, Maharashtra, India.
   [Masal, Komal Mahadeo] PICT, Pune 411007, Maharashtra, India.
   [Bhatlawande, Shripad] Vishwakarma Inst Technol, Pune 411037, Maharashtra, India.
   [Shingade, Sachin Dattatraya] SPPU, Dept Technol DOT, Pune 411007, Maharashtra, India.
   [Shingade, Sachin Dattatraya] MIT Acad Engn, Pune 411007, Maharashtra, India.
C3 Savitribai Phule Pune University; Savitribai Phule Pune University
RP Masal, KM (corresponding author), SPPU, Dept Technol DOT, Pune 411007, Maharashtra, India.; Masal, KM (corresponding author), PICT, Pune 411007, Maharashtra, India.
EM kmmasal@pict.edu
RI Bhatlawande, Shripad Subhashrao/C-9726-2018
CR Ang LM, 2016, INT J AMBIENT COMPUT, V7, P45, DOI 10.4018/IJACI.2016010103
   Ashraf MM, 2016, INT J DISABIL MANAG, V11, P6
   Bai JQ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060697
   Balan Oana., 2015, International Journal_on_Disability_and_Human_Development, V14, P109, DOI DOI 10.1515/IJDHD-2014-0018
   Bauer Z, 2020, PATTERN RECOGN LETT, V137, P27, DOI 10.1016/j.patrec.2019.03.008
   Bhatt P, 2017, IEEE GLOB HUMANIT C, P81
   Bouteraa Y, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12091082
   Brock AM, 2015, HUM-COMPUT INTERACT, V30, P156, DOI 10.1080/07370024.2014.924412
   Brown DJ, 2016, IEEE J-STSP, V10, P924, DOI 10.1109/JSTSP.2016.2543678
   Calabrese B, 2020, ENERGIES, V13, DOI 10.3390/en13226104
   Campisi T, 2021, RES TRANSP BUS MANAG, V40, DOI 10.1016/j.rtbm.2020.100592
   Caraiman S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122771
   Castle CL, 2021, PUBLIC HEALTH, V194, P232, DOI 10.1016/j.puhe.2021.03.010
   Chang WJ, 2020, IEEE ACCESS, V8, P17013, DOI 10.1109/ACCESS.2020.2967400
   Chen QT, 2017, IEEE ANN INT CONF CY, P1246, DOI 10.1109/CYBER.2017.8446303
   Cheng RQ, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113743
   Cmar JL, 2015, J VISUAL IMPAIR BLIN, V109, P95
   Csapó A, 2015, J MULTIMODAL USER IN, V9, P275, DOI 10.1007/s12193-015-0182-7
   Daudpota MH, 2017, IEEE GLOB HUMANIT C, P161
   Elgendy M, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106112
   Elgendy M, 2019, INT CONF COGN INFO, P425, DOI [10.1109/CogInfoCom47531.2019.9089960, 10.1109/coginfocom47531.2019.9089960]
   Elgendy M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235110
   Elmannai W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030565
   Fernandes H, 2019, UNIVERSAL ACCESS INF, V18, P155, DOI 10.1007/s10209-017-0570-8
   Fusco G, 2020, 17TH INTERNATIONAL WEB FOR ALL CONFERENCE (WEB4ALL), DOI 10.1145/3371300.3383345
   Götzelmann T, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3241066
   Gori M, 2016, NEUROSCI BIOBEHAV R, V69, P79, DOI 10.1016/j.neubiorev.2016.06.043
   Hamledari H, 2017, AUTOMAT CONSTR, V74, P78, DOI 10.1016/j.autcon.2016.11.009
   Hara K, 2015, ACM T ACCESS COMPUT, V6, DOI 10.1145/2717513
   HIMS International, 2018, BRAILLESENSE POL U2
   Hsieh IH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110026
   Hsieh YZ, 2020, MULTIMED TOOLS APPL, V79, P29473, DOI 10.1007/s11042-020-09464-7
   Hu F, 2018, COMPUT VIS PATT REC, P1, DOI 10.1016/B978-0-12-813445-0.00001-0
   Hussain MA., 2016, INT J COMPUT SCI INF, V14, P276
   Pham HH, 2016, J SENSORS, V2016, DOI 10.1155/2016/3754918
   Islam MM, 2019, IEEE SENS J, V19, P2814, DOI 10.1109/JSEN.2018.2890423
   Islam MI, 2018, IN 2018 3 INT C CONV, P1
   Jacko VA, 2015, J VISUAL IMPAIR BLIN, V109, P153
   Kardys P, 2016, SIG P ALGO ARCH ARR, P152, DOI 10.1109/SPA.2016.7763604
   Kim M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18126216
   Kim S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235319
   Kim S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050878
   Lahav O, 2015, COMPUT EDUC, V80, P1, DOI 10.1016/j.compedu.2014.08.003
   Lang L, 2018, 24 C ARG CIENC COMP
   Leo M, 2017, COMPUT VIS IMAGE UND, V154, P1, DOI 10.1016/j.cviu.2016.09.001
   Li B, 2016, LECT NOTES COMPUT SC, V9914, P448, DOI 10.1007/978-3-319-48881-3_31
   Mahendran JK, 2021, IEEE COMPUT SOC CONF, P2418, DOI 10.1109/CVPRW53098.2021.00274
   Malik S, 2018, INT J INSTR, V11, P185, DOI 10.12973/iji.2018.11213a
   Mattoccia S, 2015, LECT NOTES COMPUT SC, V8927, P539, DOI 10.1007/978-3-319-16199-0_38
   Meshram VV, 2019, IEEE T HUM-MACH SYST, V49, P449, DOI 10.1109/THMS.2019.2931745
   Moldoveanu A, 2018, REV ROUM SCI TECH-EL, V63, P112
   Pawluk DTV, 2015, IEEE T HAPTICS, V8, P258, DOI 10.1109/TOH.2015.2471300
   Pissaloux EE, 2017, IEEE T HUM-MACH SYST, V47, P1040, DOI 10.1109/THMS.2017.2736888
   Prescher D, 2018, UNIVERSAL ACCESS INF, V17, P391, DOI 10.1007/s10209-017-0538-8
   Proulx MJ, 2020, APPL ERGON, V85, DOI 10.1016/j.apergo.2020.103072
   Ramadhan AJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030843
   Real S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153404
   Sagale U., 2018, ERGONOMICS CARING PE, P291, DOI [10.1007/978-981-10-4980-4_36, DOI 10.1007/978-981-10-4980-4_36]
   Sanches Emilia Christie Picelli, 2021, Universal Access in Human-Computer Interaction. Design Methods and User Experience. 15th International Conference, UAHCI 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings,, P461, DOI 10.1007/978-3-030-78092-0_31
   Semary NA, 2015, P 5 INT C INF COMM T, P1
   Shaikh F., 2018, IN 2018 2 INT C TREN, P747, DOI 10.1109/ICOEI.2018.8553690
   Shultz C, 2018, IEEE T HAPTICS, V11, P279, DOI 10.1109/TOH.2018.2793867
   Simoes WCSS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143935
   Sivan S, 2016, 7TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT 2016), DOI 10.1145/2967878.2967923
   Sufri N. A. J., 2017, J TELECOMMUN ELECT C, V9, P103
   Tan CJ, 2020, IEEE ST CONF RES DEV, P74, DOI 10.1109/SCOReD50371.2020.9250979
   Tapu R, 2017, MULTIMED TOOLS APPL, V76, P11771, DOI 10.1007/s11042-016-3617-6
   Tseng YC, 2018, QUAL LIFE RES, V27, P1957, DOI 10.1007/s11136-018-1799-2
   Tsirmpas C, 2015, INFORM SCIENCES, V320, P288, DOI 10.1016/j.ins.2014.08.011
   Uematsu H, 2016, LECT NOTES COMPUT SC, V9774, P503, DOI 10.1007/978-3-319-42321-0_47
   Xiao JZ, 2015, IEEE T HUM-MACH SYST, V45, P635, DOI 10.1109/THMS.2014.2382570
   Zhang XC, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050989
NR 72
TC 3
Z9 3
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20387
EP 20427
DI 10.1007/s11042-023-16355-0
EA AUG 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400004
DA 2024-07-18
ER

PT J
AU Rusia, MK
   Singh, DK
AF Rusia, Mayank Kumar
   Singh, Dushyant Kumar
TI An improved deep transfer learning approach to identify the human face
   mask in real-time considering the COVID-19 pandemic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Partial occlusion; Biometrics; Computer vision; Transfer
   learning; Image processing
AB Face recognition systems have always been in great demand for various security-based applications, authentication being one of them. Due to the continuous upsurge of the COVID-19 pandemic and emerging variants of coronaviruses, wearing a face mask has been made mandatory in many countries, especially in crowded places. This situation poses significant challenges to the face recognition systems in recognizing the person's identity with face mask-based partial occlusion. Therefore, an update is needed in the traditional face recognition systems to ascertain whether the person is wearing a mask. This manuscript offers a novel Fiducial Point-based Non-local Means De-Noising (FP-NMDN) method for data pre-processing. This manuscript also proposed two comprehensive feature extraction mechanisms, i.e., transfer learning-based models and a customized Convolutional Neural Network (CNN) model. The experiment is conducted for five popular baseline architectures viz. Visual Geometry Group (VGG16), Residual Network (ResNet50), MobileNetV2, InceptionV3, and EfficientNetB0 with fine-tuning of hyperparameters and a customized CNN architecture. A modified dense network with a new classification layer has been introduced to obtain high classification results in less inference time. The datasets are collected from four valid sources; Kaggle Medical Masked Face, Real-world Masked Face, Face Mask, and open-source datasets that have been resynthesized based on predefined experimental criteria named Dataset-I and other existing datasets as Dataset-II. The experimental results reveal that our optimized transfer learning-based ResNet50 model achieves the best accuracy of 99.68% and 99.67% for Dataset-I and Dataset-II, respectively. Besides, our customized CNN model outperforms other recent methods regarding overhead and inference time.
C1 [Rusia, Mayank Kumar; Singh, Dushyant Kumar] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Rusia, MK (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, Uttar Pradesh, India.
EM mayank.qip18@mnnit.ac.in; dushyant@mnnit.ac.in
RI Singh, Dushyant Kumar/AAD-8512-2021
CR Addagarla SK., 2020, Int. J, V9, P4402, DOI [10.30534/ijatcse/2020/33942020, DOI 10.30534/IJATCSE/2020/33942020]
   Agarwal CIK., 2022, ARTIF INTELL
   Allam Z, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8010046
   [Anonymous], 2020, ADV US MASKS CONT CO
   Ben Fredj H, 2021, VISUAL COMPUT, V37, P217, DOI 10.1007/s00371-020-01794-9
   Ben Said A, 2016, DIGIT SIGNAL PROCESS, V58, P115, DOI 10.1016/j.dsp.2016.07.017
   Besnassi M, 2020, PATTERN ANAL APPL, V23, P309, DOI 10.1007/s10044-019-00784-5
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Chandrikadeb, 2021, GITH FAC MASK DET DA
   Chavda A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9418207
   Christa GH, 2021, INT CO SIG PROC COMM, P115, DOI 10.1109/ICSPC51351.2021.9451688
   Colombo A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2113, DOI 10.1109/ICCVW.2011.6130509
   Derbel A, 2015, ELECTRON LETT, V51, P751, DOI 10.1049/el.2015.0767
   Forouzandeh P, 2021, SAFETY SCI, V133, DOI 10.1016/j.ssci.2020.104995
   Gao F, 2024, MULTIMED TOOLS APPL, V83, P15061, DOI 10.1007/s11042-020-09361-z
   Hamzah F. A. Binti, 2020, B WHO, DOI [10.2471/BLT.20.255695, DOI 10.2471/BLT.20.255695]
   Han DM, 2018, EXPERT SYST APPL, V95, P43, DOI 10.1016/j.eswa.2017.11.028
   Hussain D, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1536318
   Hussain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083495
   Inamdar M, 2020, Real-time face mask identification using facemasknet deep learning network
   Jayaswal R, 2023, MULTIMED TOOLS APPL, V82, P13241, DOI 10.1007/s11042-022-13697-z
   Jiang M., 2020, RETINAMASK FACE MASK
   Joshi Aniruddha Srinivas, 2020, 2020 12th International Conference on Computational Intelligence and Communication Networks (CICN), P435, DOI 10.1109/CICN49253.2020.9242625
   Kai D., 2020, ARXIV200413553
   Khan MJ, 2022, VISUAL COMPUT, V38, P509, DOI 10.1007/s00371-020-02031-z
   Kodali R.K., 2021, 2021 INT C COMP COMM, P1
   Kumar P, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102382
   Li YL, 2013, NEUROCOMPUTING, V101, P68, DOI 10.1016/j.neucom.2012.04.031
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Luz Eduardo, 2022, Research on Biomedical Engineering, V38, P149, DOI 10.1007/s42600-021-00151-6
   Mahdi FP, 2017, INTELL DECIS TECHNOL, V11, P79, DOI 10.3233/IDT-160279
   Menezes P., 2004, IFAC P, V37, P304, DOI DOI 10.1016/S1474-6670(17)31993-6
   Mohan Puranjay, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2021. Lecture Notes in Electrical Engineering (LNEE 756), P657, DOI 10.1007/978-981-16-0749-3_52
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Pei JF, 2013, IEEE INT C BIOINFORM
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Rahman MM, 2020, INT IOT ELECT MECHAT
   Rao T. S., 2020, EUR J MOL CLIN MED, V7, P658
   RMFD, 2021, US
   Rusia MK, 2023, MULTIMED TOOLS APPL, V82, P1669, DOI 10.1007/s11042-022-13248-6
   Rusia MK, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P612, DOI 10.1109/ICIIP47207.2019.8985867
   Saravanan TM, 2022, MATER TODAY-PROC, V58, P150, DOI 10.1016/j.matpr.2022.01.165
   Scheidegger F, 2021, VISUAL COMPUT, V37, P1593, DOI 10.1007/s00371-020-01922-5
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Singhal T, 2020, INDIAN J PEDIATR, V87, P281, DOI 10.1007/s12098-020-03263-6
   Smith P, 2007, IMAGE VISION COMPUT, V25, P1432, DOI 10.1016/j.imavis.2006.12.012
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vesal S, 2018, LECT NOTES COMPUT SC, V10882, P812, DOI 10.1007/978-3-319-93000-8_92
   Waghe S, 2020, KAGGLE MEDICAL MASK
   Wang Z, MASKED FACE RECOGNIT, P1
   WHO, 2021, COVID 19 ADV
   World Health Organization, 2020, 145 WHO
   Wu Y., 2017, P IEEE C COMP VIS PA
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xia YZ, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416600107
   Xiang Q, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2019), DOI 10.1145/3331453.3361658
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Zhang J, 2020, CONCURR COMPUT, Ve5748
NR 60
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21695
EP 21743
DI 10.1007/s11042-023-16182-3
EA JUL 2023
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900009
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Li, Y
   Li, JJ
   Hua, Z
AF Zhang, Xinyu
   Li, Ying
   Li, Jinjiang
   Hua, Zhen
TI LBP-based multi-scale feature fusion enhanced dehazing networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-image dehazing; Multi-scale feature fusion; Ed-local binary
   pattern; Self-attention mechanism; SOS feature enhancement; Inception
   module with dimension reductions
ID IMAGE; CONNECTIONS
AB Image dehazing is a prior process to perform advanced computer vision tasks such as certain target detection, and the degree of haze residue directly determines the performance of these tasks. Most existing dehazing methods follow a physical model of haze formation and obtain clear images indirectly by estimating global atmospheric light and transmission maps, but methods that rely on this model alone are difficult to use in real-world, complex hazy weather environments. In this paper, we propose an LBP-based multiscale feature fusion network for single-image dehazing to generate clear images directly end-to-end, and a multiscale feature fusion module is designed through an error feedback mechanism to alleviate a large amount of missing key feature information caused by the downsampling operation. A feature enhancement module using a Strengthen-Operate-subtract enhancement strategy is introduced into the decoder to improve the quality of the output image by refining the features of the image to be enhanced with the previously estimated image. The Inception module is added to the skip connection to alleviate the problem of excessive semantic gap in feature information at its two ends by increasing and deepening the width and depth of the network, and a self-attention mechanism is introduced to assign higher weights to key features. The above strategies enable the network to recover the haze images not only on the physical model of the input image; but also deep into the feature space to capture the internal correlation between each pixel. In addition, an improved LBP module is used to help the network obtain clearer detailed information and texture images through channel-by-channel matching of LBP images. Our model achieves a PSNR of 35.15 and an SSIM metric of 0.9905 on the SOTS dataset, and also performs well compared to state-of-the-art methods on images with different haze concentrations.
C1 [Zhang, Xinyu; Li, Ying; Li, Jinjiang; Hua, Zhen] Shandong Technol & Business Univ, Coinnovat Ctr Shandong Collages & Univ Future Inte, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University
RP Li, Y (corresponding author), Shandong Technol & Business Univ, Coinnovat Ctr Shandong Collages & Univ Future Inte, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
EM liying@sdtbu.edu.cn
RI Hua, Zhen/ABG-8734-2021
FU National Natural Science Foundation of China [61772319, 62002200,
   62202268, 61972235]; Shandong Natural Science Foundation of China
   [ZR2021MF107, ZR2022MA076]; Youth Innovation Technology Project of
   Higher School in Shandong Province [2021KJ069, 2019KJN042]; Shandong
   Technology and Business University Wealth Management Interdisciplinary
   Research Project
FX The authors acknowledge the National Natural Science Foundation of China
   (61772319, 62002200, 62202268 and 61972235), the Shandong Natural
   Science Foundation of China (ZR2021MF107, ZR2022MA076) Youth Innovation
   Technology Project of Higher School in Shandong Province under
   (2021KJ069, 2019KJN042) and Shandong Technology and Business University
   Wealth Management Interdisciplinary Research Project: Research on the
   innovative path of art management from the perspective of big data
   ecology.
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Ancuti C, 2018, P IEEE C COMP VIS PA, P891
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Berman D, 2017, IEEE INT CONF COMPUT, P115
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2018, LECT NOTES COMPUT SC, V11215, P3, DOI 10.1007/978-3-030-01252-6_1
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chen WT, 2020, IEEE T IMAGE PROCESS, V29, P6773, DOI 10.1109/TIP.2020.2993407
   Dai SY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1039
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Geetanjali M., 2020, ADV MATH SCI J, V9, P3987, DOI [10.37418/amsj.9.6.80, DOI 10.37418/AMSJ.9.6.80]
   Golub D, 2016, ARXIV
   Han S., 2016, ADV NEURAL INF PROCE, P109
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hua Z, 2021, PROCEDIA COMPUT SCI, V187, P18, DOI 10.1016/j.procs.2021.04.028
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Huang PC, 2021, NEUROCOMPUTING, V432, P57, DOI 10.1016/j.neucom.2020.11.039
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Kingma D. P., 2014, arXiv
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li Z, 2023, IEEE T GEOSCI REMOTE
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2019, IEEE I CONF COMP VIS, P2492, DOI 10.1109/ICCV.2019.00258
   Mankowska A, 2018, J CLIN EXP NEUROPSYC, V40, P951, DOI 10.1080/13803395.2018.1457138
   Mathew D, 2021, INFORM PROCESS AGR, V8, P581, DOI 10.1016/j.inpa.2020.11.002
   Mei KF, 2019, LECT NOTES COMPUT SC, V11361, P203, DOI 10.1007/978-3-030-20887-5_13
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Mnih V, 2014, ADV NEUR IN, V27
   Moghimi Mohammad, 2016, BMVC, V5, P6
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Qiyuan L, 2021, ARXIV
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Romano Y, 2015, SIAM J IMAGING SCI, V8, P1187, DOI 10.1137/140990978
   Sharma M, 2021, J SUPERCOMPUT, V77, P5528, DOI 10.1007/s11227-020-03474-w
   Shu XB, 2022, IEEE T CIRC SYST VID, V32, P5281, DOI 10.1109/TCSVT.2022.3142771
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Su XY, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3152425
   Sulami M, 2014, IEEE INT CONF COMPUT
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Vaswani A, 2017, ADV NEUR IN, V30
   Xiao B, 2019, IEEE T CIRC SYST VID, V29, P2796, DOI 10.1109/TCSVT.2018.2869841
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yin HG, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.106983
   Yu AW., 2018, ARXIV
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2018, ARXIV
   Zhang X., 2018, ARXIV
   Zhang XQ, 2021, IEEE T CIRC SYST VID, V31, P4162, DOI 10.1109/TCSVT.2020.3046625
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhu, 2014, BMVC
NR 71
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20083
EP 20115
DI 10.1007/s11042-023-15343-8
EA JUL 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900005
DA 2024-07-18
ER

PT J
AU Nascimento, AS
   Melo, WALD
   Dantas, DO
   Andrade, BT
AF Nascimento, Artur Santos
   Melo, Welerson Augusto Lino de Jesus
   Dantas, Daniel Oliveira
   Andrade, Beatriz Trinchao
TI Feature point detection in HDR images based on coefficient of variation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature point detection; HDR imaging; Computer vision
ID PERFORMANCE
AB Feature point (FP) detection is a fundamental step of many computer vision tasks. However, FP detectors are usually designed for low dynamic range (LDR) images. In scenes with extreme light conditions, LDR images present saturated pixels, which degrade FP detection. On the other hand, high dynamic range (HDR) images usually present no saturated pixels but FP detection algorithms do not take advantage of all the information present in such images. FP detection frequently relies on differential methods, which work well in LDR images. However, in HDR images, the differential operation response in bright areas overshadows the response in dark areas. As an alternative to standard FP detection methods, this study proposes an FP detector based on a coefficient of variation (CV) designed for HDR images. The CV operation adapts its response based on the standard deviation of pixels inside a window, working well in both dark and bright areas of HDR images. The proposed and standard detectors are evaluated by measuring their repeatability rate (RR) and uniformity. Our proposed detector shows better performance when compared to other standard state-of-the-art detectors. In uniformity metric, our proposed detector surpasses all the other algorithms. In other hand, when using the repeatability rate metric, the proposed detector is worse than Harris for HDR and SURF detectors.
C1 [Nascimento, Artur Santos; Melo, Welerson Augusto Lino de Jesus; Dantas, Daniel Oliveira; Andrade, Beatriz Trinchao] Fed Univ Sergipe UFS, Dept Comp, BR-49107230 Sao Cristovao, SE, Brazil.
RP Nascimento, AS (corresponding author), Fed Univ Sergipe UFS, Dept Comp, BR-49107230 Sao Cristovao, SE, Brazil.
EM artur.nascimento@dcomp.ufs.br; welerson.melo@dcomp.ufs.br;
   ddantas@dcomp.ufs.br; beatriz@dcomp.ufs.br
RI Dantas, Daniel Oliveira/F-3041-2013
OI Dantas, Daniel Oliveira/0000-0002-0142-891X; Nascimento, Artur
   Santos/0000-0003-0419-6170
FU Coordenacao de Pesquisa da Universidade Federal de Sergipe (COPES-UFS)
   [PVB6533-2018]
FX This study was partially financed by Coordenacao de Pesquisa da
   Universidade Federal de Sergipe (COPES-UFS) through the project
   PVB6533-2018.
CR Agrafiotis Panagiotis, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P623
   Andrade BT, 2012, J CULT HERIT, V13, P210, DOI 10.1016/j.culher.2011.05.003
   [Anonymous], 2017, IEEE INT C IM PROC I
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen WC, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P687, DOI 10.1109/ICIP.1997.648006
   CHIU K, 1993, GRAPH INTER, P245
   Coello C. A. C., 2007, EVOLUTIONARY ALGORIT, DOI DOI 10.1007/978-0-387-36797-2
   Dias PGT, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2116, DOI 10.1109/ICNN.1995.489004
   Dong YY, 2016, IEEE T MULTIMEDIA, V18, P549, DOI 10.1109/TMM.2016.2522639
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hadizadeh H, 2018, IEEE T MULTIMEDIA, V20, P392, DOI 10.1109/TMM.2017.2740023
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kontogianni G, 2015, INT ARCH PHOTOGRAMM, V40-5, P325, DOI 10.5194/isprsarchives-XL-5-W4-325-2015
   Korshunov P., 2015, Proceedings of the Fourth International Workshop on Crowdsourcing for Multimedia, P39
   Melo WALD, 2018, IEEE SYMP COMP COMMU, P91, DOI 10.1109/ISCC.2018.8538716
   Liu Z, 2015, IEEE T MULTIMEDIA, V17, P538, DOI 10.1109/TMM.2015.2399851
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mai ZC, 2013, IEEE T MULTIMEDIA, V15, P1503, DOI 10.1109/TMM.2013.2266633
   Mantiuk R. K., 2015, High dynamic range imaging. na
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mora M, 2005, COMPUT CARDIOL, V32, P235
   Ntregka A, 2013, ISPRS ANN PHOTOGRAMM, V5, pW1
   Oussalah M., 2014, Kybernetes
   Pribyl B, 2016, J VIS COMMUN IMAGE R, V38, P141, DOI 10.1016/j.jvcir.2016.02.007
   Pribyl Bronislav., 2012, P 28 SPRING C COMPUT, P143, DOI DOI 10.1145/2448531
   Rana A, 2016, IEEE INT WORKSH MULT
   Rana A, 2019, IEEE T MULTIMEDIA, V21, P256, DOI 10.1109/TMM.2018.2839885
   Rana A, 2015, IEEE INT SYM MULTIM, P289, DOI 10.1109/ISM.2015.58
   Rerabek M, 2014, APPL DIGIT IMAGE PRO, V9217
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Snedecor G.W., 1967, Statistical Methods, V6th edn
   Suma R, 2016, VIRTUAL ARCHAEOL REV, V7, P54, DOI 10.4995/var.2016.6319
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Wang TH, 2015, IEEE T MULTIMEDIA, V17, P470, DOI 10.1109/TMM.2015.2403612
   Yu YJ, 2004, IEEE T IMAGE PROCESS, V13, P1640, DOI 10.1109/TIP.2004.836166
   Zhou H, 2016, LECT NOTES COMPUT SC, V9915, P724, DOI 10.1007/978-3-319-49409-8_60
   Zhou TF, 2021, PROC CVPR IEEE, P1622, DOI 10.1109/CVPR46437.2021.00167
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19981
EP 20002
DI 10.1007/s11042-023-16055-9
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Haque, A
   Rao, KS
AF Haque, Arijul
   Rao, K. Sreenivasa
TI Hierarchical emotion recognition from speech using source, power
   spectral and prosodic features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Epoch features; Power spectral features; KL
   distance
ID EXCITATION
AB Features related to the glottal closure instants (GCI) exhibit different patterns for different emotions. In this work, our main objective was to explore the effectiveness of these features in speech emotion recognition (SER). In this regard, we had proposed two distance-based classifiers based on four features related to GCI. This was the first phase of our work. In two later phases of this work, we extended this idea to develop hierarchical two-stage SER systems in order to couple the GCI features with other features to improve our SER systems. The first stage in phase 2 was based on prosodic features and for phase 3, we had used power spectral features in the first stage. The second stage in both the systems was based on the GCI features. The best performance was observed for the phase 3 systems, which outperformed the phase 1 systems by as much as about 10% for the IEMOCAP corpus and by nearly 20% for the EMO-DB and the IITKGP-SEHSC datasets. It also outperformed a related and recent work by Kadiri et al. (Circ Syst Signal Process 39(9):4459-4481, 2020) by 9.6% for the EMO-DB corpus.
C1 [Haque, Arijul; Rao, K. Sreenivasa] Indian Inst Technol Kharagpur, Kharagpur, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Haque, A (corresponding author), Indian Inst Technol Kharagpur, Kharagpur, India.
EM rjlhq05@gmail.com
CR Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Bitouk D, 2010, SPEECH COMMUN, V52, P613, DOI 10.1016/j.specom.2010.02.010
   Bozkurt E., 2009, Proceedings of INTERSPEECH, P324
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   CUMMINGS KE, 1995, J ACOUST SOC AM, V98, P88, DOI 10.1121/1.413664
   Eskimez SE, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5099, DOI 10.1109/ICASSP.2018.8462685
   Fant G., 1981, STL-QPSR, V1, P21
   Fayek HM, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Gangamohan P, 2013, INTERSPEECH, P1915
   Gangamohan P, 2014, INTERSPEECH, P1253
   Haque A, 2017, INT J SPEECH TECHNOL, V20, P15, DOI 10.1007/s10772-016-9386-9
   Iliou T, 2009, ICDT: 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL TELECOMMUNICATIONS, P121, DOI 10.1109/ICDT.2009.30
   Jackson P., 2014, Surrey audio-visual expressed emotion (savee) database
   Jeon JH, 2011, INT CONF ACOUST SPEE, P4940
   Kadin SR, 2020, CIRC SYST SIGNAL PR, V39, P4459, DOI 10.1007/s00034-020-01377-y
   Kadiri SR, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1324
   Kao YH, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1814
   Koolagudi SG, 2011, 2011 international conference on devices and communications (ICDeCom), P1
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Koolagudi SG, 2012, PROCEDIA ENGINEER, V38, P3892, DOI 10.1016/j.proeng.2012.06.447
   Koolagudi SG, 2012, PROCEDIA ENGINEER, V38, P3409, DOI 10.1016/j.proeng.2012.06.394
   Koolagudi SG, 2010, INT CO SIG PROC COMM
   Lee CM, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P240, DOI 10.1109/ASRU.2001.1034632
   Lee CM, 2004, 8 INT C SPOKEN LANGU
   Li LF, 2013, INT CONF AFFECT, P312, DOI 10.1109/ACII.2013.58
   Lugger M, 2007, INT CONF ACOUST SPEE, P17
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mittal VK, 2013, J ACOUST SOC AM, V133, P3050, DOI 10.1121/1.4796110
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Nicholson J, 2000, NEURAL COMPUT APPL, V9, P290, DOI 10.1007/s005210070006
   Nwe TL, 2001, IEEE REGION 10 INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC TECHNOLOGY, VOLS 1 AND 2, P297, DOI 10.1109/TENCON.2001.949600
   Petrushin V., 1999, Proceedings of Artificial Neural Networks in Engineering, P710
   Rozgic V, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P366
   Sahu S., 2018, ARXIV
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Zhao JF, 2018, IET SIGNAL PROCESS, V12, P713, DOI 10.1049/iet-spr.2017.0320
   Zhao Y, 2017, INT CONF ACOUST SPEE, P5300, DOI 10.1109/ICASSP.2017.7953168
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19629
EP 19661
DI 10.1007/s11042-023-16264-2
EA JUL 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800001
DA 2024-07-18
ER

PT J
AU Kong, LY
   Wang, FB
   Yang, FY
   Leng, L
   Zhang, HT
AF Kong, Luoyi
   Wang, Fengbin
   Yang, Fengyu
   Leng, Lu
   Zhang, Haotian
TI FISRCN: a single small-sized image super-resolution convolutional neural
   network by using edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Small-sized image; Pixel shuffle; Sobel
   filter; Median filter
ID RESOLUTION ENHANCEMENT
AB In recent years, deep neural network-based models have shown remarkable success in achieving high-quality reconstruction for single image super-resolution. Among these models, generative adversarial network-based methods have produced satisfying results. However, these methods can be distorted when dealing with small-sized images containing a lot of interference information. This work proposes an improved convolutional neural network-based model (FISRCN) for super-resolution reconstruction of small-sized images, which can provide excellent colour restoration and rich texture features. In addition, to reconstruct the edge characteristics of small-sized images, a Sobel filter is introduced. Then two median filters are used to effectively smooth the noise. To improve runtime efficiency, pixel shuffle is used to upsample the image. The low-resolution image is then mapped to a high-resolution image using a convolutional neural network while simultaneously reconstructing the image using high-dimensional features. The experimental results demonstrate that FISRCN has a more balanced performance in terms of reconstruction quality and runtime efficiency (+ 1.295 dB in PSNR score, + 0.084 in SSIM score and -7.202 s in running time on small-sized images than Real-ESRGAN).
C1 [Kong, Luoyi; Wang, Fengbin; Yang, Fengyu; Leng, Lu] Nanchang Hangkong Univ, Sch Software, Nanchang, Jiangxi, Peoples R China.
   [Kong, Luoyi] Hong Kong Polytech Univ, Dept Elect & Elect Engn, Hong Kong, Peoples R China.
   [Zhang, Haotian] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong, Peoples R China.
C3 Nanchang Hangkong University; Hong Kong Polytechnic University; Hong
   Kong Polytechnic University
RP Wang, FB (corresponding author), Nanchang Hangkong Univ, Sch Software, Nanchang, Jiangxi, Peoples R China.
EM 22050028g@connect.polyu.hk; wfb@nchu.edu.cn; yangfengyu@nchu.edu.cn;
   leng@nchu.edu.cn; hao-tian.zhang@connect.polyu.hk
OI Kong, Luoyi/0000-0002-0049-718X
FU National Natural Science Foundation of China [61866028]; Technology
   Innovation Guidance Program Project (Special Project of Technology
   Cooperation, Science and Technology Department of Jiangxi Province)
   [20212BDH81003]; Youth Science Fund Project of Educational Department in
   JiangXi Province [GJJ12461]
FX AcknowledgementsThis work is partially supported by the National Natural
   Science Foundation of China (61866028), the Technology Innovation
   Guidance Program Project (Special Project of Technology Cooperation,
   Science and Technology Department of Jiangxi Province) (20212BDH81003)
   and the Youth Science Fund Project of Educational Department in JiangXi
   Province (GJJ12461).
CR Ahmed ST, 2020, PROCEDIA COMPUT SCI, V167, P2617, DOI 10.1016/j.procs.2020.03.323
   Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong XW, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901327
   Frieden B.R., 1975, PICTURE PROCESSING D, P177, DOI DOI 10.1007/978-3-662-41612-9_5
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Huang Y., 2020, P ADV NEUR INF PROC, V33, P5632, DOI DOI 10.48550/ARXIV.2010.02631
   Ji XC, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P626, DOI 10.1109/DSC.2016.104
   Ji XZ, 2020, IEEE COMPUT SOC CONF, P1914, DOI 10.1109/CVPRW50498.2020.00241
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S. Sreedhar, 2020, Procedia Computer Science, V171, P1624, DOI 10.1016/j.procs.2020.04.174
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li HM, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00309
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Piao YJ, 2007, IEEE IMAGE PROC, P445
   [浦利 PU Li], 2007, [北京理工大学学报, Transactions of Beijing Institute of Technology], V27, P161
   Saito T, 2011, IEEE IMAGE PROC, P1145, DOI 10.1109/ICIP.2011.6115631
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4771, DOI 10.1109/ICCV48922.2021.00475
NR 31
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19609
EP 19627
DI 10.1007/s11042-023-15380-3
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800004
DA 2024-07-18
ER

PT J
AU Bonny, T
   AlMutairi, F
   Al Nassan, W
AF Bonny, Talal
   AlMutairi, Farah
   Al Nassan, Wafaa
TI A novel clock-glitch-attack-proof image encryption algorithm implemented
   on FPGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Switching-type chaotic oscillator; Autonomous and non-autonomous chaotic
   oscillator; FPGA
AB Nowadays, chaotic systems are widely used in engineering applications. They play a vital role, particularly in cryptography and secure communication systems. This paper proposed an image encryption scheme based on the chaotic oscillator and highlights the risk of using non-autonomous chaotic oscillators as a source of entropy to construct the encryption key. In this study, we propose a symmetric image encryption scheme consisting of two main phases: position permutation and value transformation using XOR bitwise operation. The encryption key is utilized twice, once in the position permutation phase and then again in the value transformation phase. Our analysis of the proposed algorithm reveals that the majority of the computational time required for image encryption is attributed to the position permutation phase. To determine the appropriate number of iterations needed for each image size, we examine the three factors of correlation between adjacent pixels, entropy, and computational time, specifically focusing on the shuffling step. This analysis leads to significant improvements in our initial computational time, reducing it by up to ten times. To evaluate the encryption scheme, we employ two types of chaotic oscillators, autonomous and non-autonomous, across six different image sizes. We consider various metrics such as computational time, correlation between adjacent pixels, and entropy of the ciphered image. Additionally, we implement the non-autonomous chaotic oscillator on an FPGA to assess its vulnerability to a clock glitch attack, which affects the system's randomness. Based on our experimental results, we observe that both oscillators can effectively serve as a source of entropy for cryptographic applications.
C1 [Bonny, Talal; AlMutairi, Farah; Al Nassan, Wafaa] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah
RP Bonny, T (corresponding author), Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
EM tbonny@sharjah.ac.ae; U18200670@sharjah.ac.ae; walnassan@sharjah.ac.ae
OI Al Nassan, Wafaa/0000-0002-3790-7226; Bonny, Talal/0000-0003-1111-0304
CR Abd El-Latif AA, 2020, IEEE T NETW SERV MAN, V17, P118, DOI 10.1109/TNSM.2020.2969863
   Abd El-Latif AA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58636-w
   Al Nassan W, 2020, 2020 3 INT C SIGN PR, P1, DOI DOI 10.1109/ICSPIS51252.2020.9340132
   AlMutairi F, 2020, 2020 3 INT C SIGN PR, ppp1, DOI DOI 10.1109/ICSPIS51252.2020.9340157
   AlMutairi F, 2019, 2019 INT C ELECT COM, ppp1
   Azzaz MS, 2013, COMMUN NONLINEAR SCI, V18, P1792, DOI 10.1016/j.cnsns.2012.11.025
   Bonny T, 2023, MULTIMED TOOLS APPL, V82, P34229, DOI 10.1007/s11042-023-14643-3
   Bonny T, 2023, MULTIMED TOOLS APPL, V82, P1067, DOI 10.1007/s11042-022-13317-w
   Bonny T, 2021, CIRC SYST SIGNAL PR, V40, P1061, DOI 10.1007/s00034-020-01521-8
   Bonny T, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02683-9
   Bonny T, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S021812661950227X
   Bonny T, 2019, NONLINEAR DYNAM, V96, P2087, DOI 10.1007/s11071-019-04907-9
   Bonny T, 2019, CIRC SYST SIGNAL PR, V38, P1342, DOI 10.1007/s00034-018-0905-6
   Bonny T, 2018, NONLINEAR DYNAM, V93, P819, DOI 10.1007/s11071-018-4229-7
   Bonny T, 2008, IEEE T VLSI SYST, V16, P1696, DOI 10.1109/TVLSI.2008.2001950
   Dong YJ, 2020, COMMUN NONLINEAR SCI, V84, DOI 10.1016/j.cnsns.2020.105203
   Elwakil AS, 2014, INT J BIFURCAT CHAOS, V24, DOI 10.1142/S0218127414500795
   Fard EB, 2013, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2013), P190, DOI 10.1109/ICCKE.2013.6682835
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Jin J, 2019, COMPLEXITY, DOI 10.1155/2019/4106398
   Jin J, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618501554
   Jin J, 2018, MICROELECTRON J, V75, P27, DOI 10.1016/j.mejo.2018.02.007
   Karakaya B, 2019, CHAOS SOLITON FRACT, V119, P143, DOI 10.1016/j.chaos.2018.12.021
   Kemwoue FF, 2020, CHAOS SOLITON FRACT, V134, DOI 10.1016/j.chaos.2020.109689
   Krylosova DA, 2020, CHAOS SOLITON FRACT, V134, DOI 10.1016/j.chaos.2020.109716
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2021, SOFT COMPUT, V25, P11077, DOI 10.1007/s00500-021-05849-4
   Liu YJ, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106171
   Martín H, 2015, IEEE T INF FOREN SEC, V10, P266, DOI 10.1109/TIFS.2014.2374072
   Mohamed MA, COMPUTERS MAT CONTIN, V75
   Nassan Wafaa Al, 2022, 2022 International Conference on Electrical and Computing Technologies and Applications (ICECTA), P337, DOI 10.1109/ICECTA57148.2022.9990128
   Qiao ZC, 2020, AEU-INT J ELECTRON C, V121, DOI 10.1016/j.aeue.2020.153205
   Sambas A, 2022, IEEE ACCESS, V10, P68057, DOI 10.1109/ACCESS.2022.3181424
   Sambas A, 2019, IEEE ACCESS, V7, P115454, DOI 10.1109/ACCESS.2019.2933456
   Tahoun N., 2019, P 3 INT C ADV ART IN, P227
   Tutueva AV, 2021, NONLINEAR DYNAM, V104, P727, DOI 10.1007/s11071-021-06246-0
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang Z, 2020, CHAOS SOLITON FRACT, V134, DOI 10.1016/j.chaos.2020.109702
   Zong JY, 2020, OPT COMMUN, V473, DOI 10.1016/j.optcom.2020.126005
NR 39
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18881
EP 18906
DI 10.1007/s11042-023-16283-z
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900006
DA 2024-07-18
ER

PT J
AU Vaish, A
AF Vaish, Ankita
TI An Error Free and key sensitive color Image Encryption using Sine
   powered map and Arnold transform in Stockwell domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Discrete Cosine Stockwell transform; Arnold transform;
   Structural similarity index measure
ID SINGULAR-VALUE DECOMPOSITION; HARTLEY TRANSFORM; OPTICAL ENCRYPTION;
   ALGORITHM; MSVD; DWT
AB This paper presents a new image encryption technique which can securely transmit images over unsecured networks. The security of transmitting information is the biggest point of concern in today's world. The proposed work utilizes Chaos and Arnold transform in the Discrete Cosine Stockwell Transform (DCST) domain for image encryption. For color images, a suitable color space transformation is employed to minimize the correlation among the RGB color planes. Further Sine-powered chaotic map-based confusion is applied on the less correlated planes, which are encrypted using the bands of DCST, sub-matrices permutation, and Arnold transformation. Encryption and decryption keys are generated from the number of bands in DCST, the period of Arnold transform, the arrangement of decomposed sub-matrices, and the initial seed used to generate the chaos sequence. To decrypt the image correctly, it is necessary to have all the keys in their original values and in the same order. The proposed method is compared with state of art methods and recent published papers, and the experimental results and security analysis has been performed to evaluate the performance of proposed work over existing state of art works and the results are found superior than the existing methods.
C1 [Vaish, Ankita] Banaras Hindu Univ, Dept Comp Sci, Varanasi 221005, India.
C3 Banaras Hindu University (BHU)
RP Vaish, A (corresponding author), Banaras Hindu Univ, Dept Comp Sci, Varanasi 221005, India.
EM av21lko@gmail.com
FU Banaras Hindu University, under the seed grant IoE [R/Dev/D/IoE/Seed
   Grant/2020-21/6031]
FX AcknowledgementsThis work is supported by Banaras Hindu University,
   under the seed grant IoE (no. R/Dev/D/IoE/Seed Grant/2020-21/6031)
CR Abuturab MR, 2015, OPT LASER ENG, V69, P49, DOI 10.1016/j.optlaseng.2015.01.001
   Abuturab MR, 2014, OPT LASER ENG, V57, P13, DOI 10.1016/j.optlaseng.2014.01.006
   Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   Chen C, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010174
   Chen LF, 2008, OPTIK, V119, P286, DOI 10.1016/j.ijleo.2006.11.005
   Chen LF, 2013, OPT COMMUN, V291, P98, DOI 10.1016/j.optcom.2012.10.080
   Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   Chen LF, 2006, OPT LETT, V31, P3438, DOI 10.1364/OL.31.003438
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Huang ZW, 2022, OPT LASER TECHNOL, V149, DOI 10.1016/j.optlastec.2022.107879
   John L, 2014, THESIS U WATERLOO ON
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Kumar M, 2017, OPT LASER ENG, V88, P51, DOI 10.1016/j.optlaseng.2016.07.009
   Kumar M, 2015, OPT LASER TECHNOL, V75, P138, DOI 10.1016/j.optlastec.2015.06.022
   Kumar HSR, 2017, CYBERN INF TECHNOL, V17, P134, DOI 10.1515/cait-2017-0046
   Li YB, 2015, OPT LASER ENG, V72, P18, DOI 10.1016/j.optlaseng.2015.03.027
   Liu ST, 2001, OPT LETT, V26, P1242, DOI 10.1364/OL.26.001242
   Liu ZJ, 2007, OPT LETT, V32, P2088, DOI 10.1364/OL.32.002088
   Liu ZJ, 2013, OPT LASER ENG, V51, P967, DOI 10.1016/j.optlaseng.2013.02.015
   Liu ZJ, 2012, OPT LASER ENG, V50, P248, DOI 10.1016/j.optlaseng.2011.08.006
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Musanna F, 2020, IMAGING SCI J, V68, P24, DOI 10.1080/13682199.2020.1732116
   Prasad A, 2012, OPT COMMUN, V285, P1005, DOI 10.1016/j.optcom.2011.10.019
   Qin Y, 2016, OPT LASER ENG, V77, P191, DOI 10.1016/j.optlaseng.2015.09.002
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Singh H, 2016, OPT LASER ENG, V81, P125, DOI 10.1016/j.optlaseng.2016.01.014
   Singh M, 2009, OPT LASER ENG, V47, P1293, DOI 10.1016/j.optlaseng.2009.04.015
   Singh N, 2009, OPT COMMUN, V282, P1104, DOI 10.1016/j.optcom.2008.12.001
   Singh N, 2009, OPT LASER ENG, V47, P539, DOI 10.1016/j.optlaseng.2008.10.013
   Starosolski R, 2014, J VIS COMMUN IMAGE R, V25, P1056, DOI 10.1016/j.jvcir.2014.03.003
   Stockwell RG, 2007, DIGIT SIGNAL PROCESS, V17, P371, DOI 10.1016/j.dsp.2006.04.006
   Sui LS, 2015, OPT LASER ENG, V75, P17, DOI 10.1016/j.optlaseng.2015.06.005
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Vaish A, 2022, OPTIK, V266, DOI 10.1016/j.ijleo.2022.169606
   Vaish A, 2018, OPT APPL, V48, P25, DOI 10.5277/oa180103
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang Y., 2011, Efficient stockwell transform with applications to image processing
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Y, 2002, OPT COMMUN, V202, P277, DOI 10.1016/S0030-4018(02)01113-6
NR 43
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19089
EP 19107
DI 10.1007/s11042-023-16277-x
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900004
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Hu, XJ
AF Zhang, Qiang
   Hu, Xiaojian
TI Tracking-based vehicle statistic system with feature selection for
   traffic investigation and control in normal intersection scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle tracking; Vehicle statistic; Feature selection; Traffic
   investigation; Normal intersection scene
ID MUTUAL INFORMATION; VISION; SEGMENTATION; CLASSIFICATION; PEDESTRIANS;
   ALGORITHMS; REGRESSION; IMAGES
AB In traffic investigations and controls, methods for intelligent traffic statistics should efficiently track vehicles in videos. And this paper focuses on presenting a simple and fast, yet accurate and practicable solution to the problem such as inaccurately and untimely responses of statistics-based adaptive traffic control system in the normal intersection scenes. In this paper, the tracking-based statistic system in combination with feature selection is presented for vehicle statistics in the normal intersection scenes. For the detection module, the vehicle locations and bounding boxes are processed and then used as the input of the tracker. For the tracking module, the approbatory and efficient feature selection algorithm is integrated on adaptive color recognition (ACR) model with good compatibility. Based on benchmark datasets, sufficient evaluations are conducted to further demonstrate the better performance of the presented system. Compared with the other methods in the same category, the presented system has excellent performance. Furthermore, the presented tracking-based statistic system performs excellently on the videos recorded at the intersections. From the results of vehicle statistics, we found that it is significant to consider the direction of vehicle movement when designing and optimizing these systems. Finally, the presented tracking-based statistic system is verified to be effective for vehicle statistics in the normal intersection scenes.
C1 [Zhang, Qiang; Hu, Xiaojian] Southeast Univ, Jiangsu Key Lab Urban ITS, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Qiang; Hu, Xiaojian] Southeast Univ, Jiangsu Prov Collaborat Innovat Ctr Modern Urban T, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Qiang; Hu, Xiaojian] Southeast Univ, Sch Transportat, Nanjing, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Southeast
   University - China
RP Hu, XJ (corresponding author), Southeast Univ, Jiangsu Key Lab Urban ITS, Nanjing, Jiangsu, Peoples R China.; Hu, XJ (corresponding author), Southeast Univ, Jiangsu Prov Collaborat Innovat Ctr Modern Urban T, Nanjing, Jiangsu, Peoples R China.; Hu, XJ (corresponding author), Southeast Univ, Sch Transportat, Nanjing, Jiangsu, Peoples R China.
EM huxiaojian@seu.edu.cn
FU National Natural Science Foundation of China [52272344]; Key Research
   and Development Program of Jiangsu Province [BE2018754]; Fundamental
   Research Funds for the Central Universities
FX AcknowledgementsThe authors would like to sincerely thank the editor and
   anonymous reviewers for their thoughtful and valuable comments which
   have significantly improved the quality of this paper. This work was
   supported in part by National Natural Science Foundation of China (grant
   number 52272344), Key Research and Development Program of Jiangsu
   Province (grant number BE2019713), Key Research and Development Program
   of Jiangsu Province (grant number BE2018754) and the Fundamental
   Research Funds for the Central Universities.
CR [Anonymous], 2012, P 27 C UNCERTAINTY A
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bertoni F, 2022, NEURAL NETWORKS, V145, P42, DOI 10.1016/j.neunet.2021.09.024
   Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Chamakura L, 2019, INFORM SCIENCES, V504, P449, DOI 10.1016/j.ins.2019.07.018
   Chen YC, 2020, NEUROCOMPUTING, V418, P114, DOI 10.1016/j.neucom.2020.08.016
   Chen YH, 2021, INT J COMPUT VISION, V129, P2223, DOI 10.1007/s11263-021-01447-x
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Doulgeris AP, 2015, IEEE T GEOSCI REMOTE, V53, P1819, DOI 10.1109/TGRS.2014.2349575
   Dresner K, 2008, J ARTIF INTELL RES, V31, P591, DOI 10.1613/jair.2502
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao LY, 2020, KNOWL-BASED SYST, V209, DOI 10.1016/j.knosys.2020.106439
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Hafeez KA, 2013, IEEE T VEH TECHNOL, V62, P3069, DOI 10.1109/TVT.2013.2251374
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong JH, 2008, NEUROCOMPUTING, V71, P3275, DOI 10.1016/j.neucom.2008.04.033
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Hsieh JW, 2015, IEEE SENS J, V15, P971, DOI 10.1109/JSEN.2014.2358079
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu HM, 2017, IEEE T MULTIMEDIA, V19, P2706, DOI 10.1109/TMM.2017.2711422
   Hu L, 2018, EXPERT SYST APPL, V93, P423, DOI 10.1016/j.eswa.2017.10.016
   Hua S, 2018, IEEE COMPUT SOC CONF, P153, DOI 10.1109/CVPRW.2018.00028
   Huan-Sheng S, 2019, COMPUTER SYSTEMS APP, P6
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jo A, 2015, MULTIMED TOOLS APPL, V74, P227, DOI 10.1007/s11042-013-1846-5
   Kocur V, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01117-x
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Lee J, 2012, IEEE T INTELL TRANSP, V13, P81, DOI 10.1109/TITS.2011.2178836
   Lenz P, 2015, IEEE I CONF COMP VIS, P4364, DOI 10.1109/ICCV.2015.496
   Li QS, 2022, IEEE T CIRC SYST VID, V32, P2496, DOI 10.1109/TCSVT.2021.3069254
   Li YA, 2009, PROC CVPR IEEE, P2945
   Li Z, 2021, PATTERN ANAL APPL, V24, P203, DOI 10.1007/s10044-020-00916-2
   Lin XH, 2019, COMPUT BIOL CHEM, V83, DOI 10.1016/j.compbiolchem.2019.107149
   Liu H, 2019, INFORM SCIENCES, V492, P13, DOI 10.1016/j.ins.2019.03.075
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   Melzi GRaS, 2016, P BRIT MACH VIS C BM
   Mirchandani P, 2001, TRANSPORT RES C-EMER, V9, P415, DOI 10.1016/S0968-090X(00)00047-4
   Nagpal Arpita, 2018, Procedia Computer Science, V132, P244, DOI 10.1016/j.procs.2018.05.195
   Nguyen Viet H, 2016, TRAFFIC MONITORING S
   Pastor JV, 2007, APPL OPTICS, V46, P888, DOI 10.1364/AO.46.000888
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rafter CB, 2020, IEEE T INTELL TRANSP, V21, P1728, DOI 10.1109/TITS.2020.2971540
   Roffo G, 2015, IEEE I CONF COMP VIS, P4202, DOI 10.1109/ICCV.2015.478
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez-Iborra R., 2016, PROACTIVE INTELLIGEN, DOI [10.1109/DASC-PICom-DataCom-CyberSciTec.2016.104, DOI 10.1109/DASC-PICOM-DATACOM-CYBERSCITEC.2016.104]
   Saunier N, 2006, C COMP ROB VIS
   Shang RH, 2019, MACH LEARN, V108, P659, DOI 10.1007/s10994-018-5765-6
   Sharma V, 2018, IRBM, V39, P313, DOI 10.1016/j.irbm.2018.09.006
   Shi HT, 2018, COMPUT NETW, V132, P81, DOI 10.1016/j.comnet.2018.01.007
   Sivaraman S, 2012, IEEE INT C INTELL TR, P1519, DOI 10.1109/ITSC.2012.6338886
   SMITH SM, 1995, IEEE T PATTERN ANAL, V17, P814, DOI 10.1109/34.400573
   Sreevani, 2018, EXPERT SYST APPL, V108, P61, DOI 10.1016/j.eswa.2018.04.033
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Teichman A, 2011, IEEE INT CONF ROBOT
   Treiber M, 2000, PHYS REV E, V62, P1805, DOI 10.1103/PhysRevE.62.1805
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   Wang W, 2015, IEEE WINT CONF APPL, P17, DOI 10.1109/WACV.2015.10
   Xiong T, 2004, IEEE T INTELL TRANSP, V5, P324, DOI 10.1109/TITS.2004.838192
   Xu Y, 2019, UNIFIED NEURAL NETWO
   Yin HB, 2002, TRANSPORT RES C-EMER, V10, P85, DOI 10.1016/S0968-090X(01)00004-3
   Yuan M, 2018, NEUROCOMPUTING, V323
   Yuan MS, 2019, NEUROCOMPUTING, V323, P231, DOI 10.1016/j.neucom.2018.09.084
   Yuan QA, 2011, IEEE T PATTERN ANAL, V33, P514, DOI 10.1109/TPAMI.2010.117
   [张汝峰 Zhang Rufeng], 2017, [交通信息与安全, Journal of Transport Information and Safety], V35, P28
   Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675
   Zhao JX, 2019, TRANSPORT RES C-EMER, V100, P68, DOI 10.1016/j.trc.2019.01.007
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zou H, 2016, SENSORS-BASEL, V16
NR 81
TC 0
Z9 0
U1 16
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15751
EP 15768
DI 10.1007/s11042-023-16065-7
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700008
DA 2024-07-18
ER

PT J
AU Anilkumar, KK
   Manoj, VJ
   Sagi, TM
AF Anilkumar, K. K.
   Manoj, V. J.
   Sagi, T. M.
TI A review on computer aided detection and classification of leukemia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Leukemia; Computer aided diagnosis; Machine learning; Deep learning;
   Convolutional neural network
ID AUTOMATED DETECTION; BLOOD; INTEROBSERVER; SEGMENTATION; DIAGNOSIS
AB Leukemia is a non-tumor type of cancer and its early diagnosis is important in the treatment and prognosis. Image based diagnosis is quick and easy compared to the conventional methods. This study aims to review the related works on computer aided diagnosis of leukemia by categorizing the works into Machine Learning (ML) and Deep Learning (DL) based technologies. The related works are identified by searching databases of eminent publishers such as ScienceDirect, Springer, IEEE Xplore, Wiley etc. over the years 2005 to 2022. The works are then grouped into those used ML and DL based classifiers. The study identified that under ML based works the SVM was used in majority (50%) of the studies reviewed and under DL category CNN was widely used in about 69% of the works considered. There are only a few works available for the classification of chronic leukemia under the ML category and no works available under the DL category. The proposed review analyzed the works based on the classifier, datasets, features, and application area involved in the studies. There is further scope of research for developing public datasets of leukemia, especially for chronic leukemia, and for developing new automated diagnostic methods for the classification of different types of leukemia. There is a shift towards DL based studies for computer aided diagnosis of leukemia from the year 2019 onwards and not much reviews which classify the related works into ML and DL based techniques are available in the literature.
C1 [Anilkumar, K. K.; Manoj, V. J.] Cochin Univ Sci & Technol, Cochin Univ Coll Engn Kuttanad, Dept Elect & Commun, Plincunnu PO, Alappuzha 688504, Kerala, India.
   [Sagi, T. M.] St Thomas Coll Allied Hlth Sci, Dept Med Lab Technol, Changanacherry PO, Kottayam 686104, Kerala, India.
RP Anilkumar, KK (corresponding author), Cochin Univ Sci & Technol, Cochin Univ Coll Engn Kuttanad, Dept Elect & Commun, Plincunnu PO, Alappuzha 688504, Kerala, India.
EM kkanil@cusat.ac.in; manojmvj@gmail.com; sagianil101@gmail.com
CR Acharya V, 2023, IEEE T ENG MANAGE, V70, P2760, DOI 10.1109/TEM.2021.3103549
   Acharya V, 2019, MED BIOL ENG COMPUT, V57, P1783, DOI 10.1007/s11517-019-01984-1
   Agaian S, 2014, IEEE SYST J, V8, P995, DOI 10.1109/JSYST.2014.2308452
   Alsalem MA, 2018, COMPUT METH PROG BIO, V158, P93, DOI 10.1016/j.cmpb.2018.02.005
   Anilkumar KK, 2022, IRBM, V43, P405, DOI 10.1016/j.irbm.2021.05.005
   Anilkumar KK, 2021, MED ENG PHYS, V98, P8, DOI 10.1016/j.medengphy.2021.10.006
   Anilkumar KK, 2020, BIOCYBERN BIOMED ENG, V40, P1406, DOI 10.1016/j.bbe.2020.08.010
   Anilkumar KK, 2018, 2018 INT C CIRC SYST, DOI [10.1109/ICCSDET.2018.8821067, DOI 10.1109/ICCSDET.2018.8821067]
   [Anonymous], About Us
   [Anonymous], 2014, MAYO CLIN
   ARGYLE JC, 1989, CANCER-AM CANCER SOC, V63, P295, DOI 10.1002/1097-0142(19890115)63:2<295::AID-CNCR2820630215>3.0.CO;2-1
   Begum ARJ, 2017, P WORLD C COMP COMM, DOI [10.1109/WCCCT.2016.63, DOI 10.1109/WCCCT.2016.63]
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bodzas A, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.01005
   Boldú L, 2021, COMPUT METH PROG BIO, V202, DOI 10.1016/j.cmpb.2021.105999
   Buavirat S, 2008, PROC3RD INT SYMPO BI
   Cancer Research UK, ABOUT US
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Corinna C., 1995, MACH LEARN, V20, P273, DOI [DOI 10.1007/BF00994018, 10.1007/BF00994018. S2CID 206787478]
   Deshpande NM, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.460
   DiPietro R, 2020, Handbook of Medical Image Computing and Computer Assisted Intervention, The Elsevier and MICCAI Society Book Series, P503, DOI [10.1016/B978-0-12-816176-0.00026-0, DOI 10.1016/B978-0-12-816176-0.00026-0]
   Elsheikh TM, 2008, AM J CLIN PATHOL, V130, P736, DOI 10.1309/AJCPKP2QUVN4RCCP
   Fakhouri H. N., 2018, Modern Applied Science, V12, P56, DOI 10.5539/mas.v12n3p56
   Firkin F, 1991, GRUCHYS CLIN HAEMATO
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Ghaderzadeh M, 2022, INT J INTELL SYST, V37, P5113, DOI 10.1002/int.22753
   Hegde RB, 2019, BIOCYBERN BIOMED ENG, V39, P382, DOI 10.1016/j.bbe.2019.01.005
   Henry John Bernard, 1989, CLIN DIAGNOSIS MANAG
   Huang G., 2017, DENSELY CONNECT CONV, V1, P3
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Jha KK, 2019, COMPUT METH PROG BIO, V179, DOI 10.1016/j.cmpb.2019.104987
   Kassani SH, 2019, I C INF COMM TECH CO, P271, DOI 10.1109/ictc46691.2019.8939959
   Kimura K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49942-z
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar P, 2017, PROCINT C ADV COMM I, DOI [10.1007/s11517-019-01984-1, DOI 10.1007/S11517-019-01984-1]
   Kutlu H, 2020, MED HYPOTHESES, V135, DOI 10.1016/j.mehy.2019.109472
   Laosai J, 2018, BIOMED SIGNAL PROCES, V44, P127, DOI 10.1016/j.bspc.2018.01.020
   Leukaemia & Lymphoma Society, NEW YORK
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu Y, 2019, LECT N BIOENG, P113, DOI 10.1007/978-981-15-0798-4_12
   Loey M, 2020, COMPUTERS, V9, DOI 10.3390/computers9020029
   Madhloom HT, 2012, INT CONF ADV COMPUT, P330, DOI 10.1109/ACSAT.2012.62
   Matek C, 2019, NAT MACH INTELL, V1, P538, DOI 10.1038/s42256-019-0101-9
   Mohapatra Subrajeet, 2012, International Journal of Computer Information Systems and Industrial Management Applications, V4, P477
   Mohapatra S., 2010, 2010 International Conference on Systems in Medicine and Biology (ICSMB), P49, DOI 10.1109/ICSMB.2010.5735344
   Mohapatra S., 2010, 2010 International Conference on Industrial Electronics, Control and Robotics (IECR), P215, DOI 10.1109/IECR.2010.5720171
   Mohapatra S, 2011, 2011 INT C DEV COMM, P1, DOI 10.1109/PES.2011.6039365
   MoradiAmin M, 2016, MICROSC RES TECHNIQ, V79, P908, DOI 10.1002/jemt.22718
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Mustaqim T, 2023, IEEE ACCESS, V11, P16108, DOI 10.1109/ACCESS.2023.3245128
   National Cancer Institute, About us
   Negm AS, 2018, ALEX ENG J, V57, P2319, DOI 10.1016/j.aej.2017.08.025
   Neoh SC, 2015, SCI REP-UK, V5, DOI 10.1038/srep14938
   Pansombut T, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7519603
   Patel N, 2015, PROCEDIA COMPUT SCI, V58, P635, DOI 10.1016/j.procs.2015.08.082
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Prellberg J, 2019, LECT N BIOENG, P53, DOI 10.1007/978-981-15-0798-4_6
   Putzu L, 2014, ARTIF INTELL MED, V62, P179, DOI 10.1016/j.artmed.2014.09.002
   Qiao YF, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11071237
   Qin FW, 2018, COMPUT METH PROG BIO, V162, P243, DOI 10.1016/j.cmpb.2018.05.024
   Rangayyan R.M., 2005, BIOMED EN S
   Rastogi P, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105236
   Rawat J, 2017, BIOCYBERN BIOMED ENG, V37, P637, DOI 10.1016/j.bbe.2017.07.003
   Rawat J, 2017, MULTIMED TOOLS APPL, V76, P19057, DOI 10.1007/s11042-017-4478-3
   Rehman A, 2018, MICROSC RES TECHNIQ, V81, P1310, DOI 10.1002/jemt.23139
   Rodellar J, 2018, INT J LAB HEMATOL, V40, P46, DOI 10.1111/ijlh.12818
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Safuan Mohd S.N., 2020, Bulletin of Electrical Engineering and Informatics, V9, P611, DOI DOI 10.11591/EEI.V9I2.1857
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Sandadi S, 2022, COMPREHENSIVE GYNECO, P289, DOI [10.1016/B978-0-323-65399-2.00024-3, DOI 10.1016/B978-0-323-65399-2.00024-3]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Scotti F, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P96
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Sheng BS, 2020, BIOTECHNOL BIOTEC EQ, V34, P413, DOI 10.1080/13102818.2020.1765871
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skrobanski S, 2012, PROC IDA, DOI [10.1007/978-3-642, DOI 10.1007/978-3-642]
   Stuart R., 2003, ARTIF INTELL, V2nd
   Sudha K, 2020, BIOCYBERN BIOMED ENG, V40, P639, DOI 10.1016/j.bbe.2020.02.005
   Surya sashank Gundepudi V., 2021, Machine Vision and Augmented Intelligence-Theory and Applications: Select Proceedings of MAI 2021. Lecture Notes in Electrical Engineering (796), P453, DOI 10.1007/978-981-16-5078-9_38
   Suryani E, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012044
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   The Global Cancer Observatory, 2020, US
   The Leukemia & Lymphoma Society, US
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 85
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17961
EP 17981
DI 10.1007/s11042-023-16228-6
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100012
DA 2024-07-18
ER

PT J
AU Verma, G
   Kanrar, S
AF Verma, Garima
   Kanrar, Soumen
TI Secure document sharing model based on blockchain technology and
   attribute-based encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud storage; Cryptography; Document-sharing; Attribute-Based
   Encryption (ABE); Blockchain; Interplanetary File System (IPFS)
ID CLOUD; SCHEME; UPDATE
AB Various cryptographic approaches have been used to resolve concerns about data privacy shared in public cloud storage, assuming that the cloud service provider is trustworthy. However, the necessity to disseminate papers has just emerged. Regarding digital document sharing, the current cloud-based models are successful but have a few downsides. Two significant problems are the high cost of computing and external interference. Blockchain technology and keyword-searchable attribute-based encryption (ABE) are proposed in this study as secure and efficient means of transferring digital certificates, addressing the abovementioned issues. The blockchain records transactions, while the Interplanetary File System (IPFS) stores encrypted data to ensure privacy and immutability. The paradigm also has the added benefits of low computational costs and the ability to revoke attributes. In addition, a smart audit contract is developed to manage who may see certain documents. We then put the model through its paces on the Ethereum network and compared its results to the state of the art. The results of experiments and theoretical analyses are more applicable and practical in challenging settings. Furthermore, security analysis demonstrates that the proposed paradigm is immune to attacks based on guessing keywords and "chosen plaintext" (CPA).
C1 [Verma, Garima] DIT Univ, Sch Comp, Dehra Dun, India.
   [Kanrar, Soumen] Amity Univ Jharkhand, Dept Comp Sci & Engn, Ranchi, India.
C3 DIT University
RP Kanrar, S (corresponding author), Amity Univ Jharkhand, Dept Comp Sci & Engn, Ranchi, India.
EM dr.soumen.kanrar@gmail.com
RI Kanrar, Soumen/N-3113-2019
OI Kanrar, Soumen/0000-0002-0331-4932; Verma, Garima/0000-0002-6715-8596
CR Cao LC, 2020, CHINA COMMUN, V17, P153, DOI 10.23919/JCC.2020.06.013
   Chen NY, 2022, IEEE T COMPUT, V71, P175, DOI 10.1109/TC.2020.3043950
   De SJ, 2020, IEEE T CLOUD COMPUT, V8, P124, DOI 10.1109/TCC.2017.2754255
   Gao S, 2020, IEEE T VEH TECHNOL, V69, P5784, DOI 10.1109/TVT.2020.2967099
   Huang CY, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S021812661950186X
   Hur J, 2013, IEEE T PARALL DISTR, V24, P2171, DOI 10.1109/TPDS.2012.61
   Kang JW, 2019, IEEE INTERNET THINGS, V6, P4660, DOI 10.1109/JIOT.2018.2875542
   Khan AA, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108234
   Khan AA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10243083
   Li FQ, 2022, IEEE T SERV COMPUT, V15, P2755, DOI 10.1109/TSC.2021.3078119
   Liu B, 2020, IEEE ACCESS, V8, P91751, DOI 10.1109/ACCESS.2020.2993921
   Liu SH, 2020, IEEE INTERNET THINGS, V7, P7851, DOI 10.1109/JIOT.2020.2993231
   Maesa DD, 2019, COMPUT SECUR, V84, P93, DOI 10.1016/j.cose.2019.03.016
   Mhatre Siddhesh, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 714), P3, DOI 10.1007/978-981-13-0224-4_1
   Miao YB, 2021, IEEE T DEPEND SECURE, V18, P1667, DOI 10.1109/TDSC.2019.2935044
   Murthy CVNUB, 2020, IEEE ACCESS, V8, P205190, DOI 10.1109/ACCESS.2020.3036812
   Namasudra S, 2021, ARCH COMPUT METHOD E, V28, P1497, DOI 10.1007/s11831-020-09426-0
   Naz M, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11247054
   Pachpande BR., 2018, J COMMERCE MANAGEMEN, V9, P33, DOI [10.5958/0976-478X.2018.00004.6, DOI 10.5958/0976-478X.2018.00004.6]
   Padiya J, 2018, PAC BUS REV INT, V10, P84
   Paillisse J., 2019, IEEE ICC, P1, DOI [10.1109/ICC.2019.8761995, DOI 10.1109/icc.2019.8761995]
   Qin XM, 2021, J SYST ARCHITECT, V112, DOI 10.1016/j.sysarc.2020.101854
   Qiu S, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-5449-9
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Tu SS, 2021, COMPUT NETW, V195, DOI 10.1016/j.comnet.2021.108196
   Verma Garima, 2022, 2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1, DOI 10.1109/ICRITO56286.2022.9965058
   Verma G., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1998/1/012019
   Verma G., 2020, SN Computer Science, V1, DOI DOI 10.1007/S42979-020-00353-2
   Verma G, 2024, J EXP THEOR ARTIF IN, V36, P147, DOI 10.1080/0952813X.2022.2135611
   Verma G, 2022, MULTIAGENT GRID SYST, V18, P45, DOI 10.3233/MGS-220361
   Wang P, 2020, INT J OBESITY, V44, P213, DOI 10.1038/s41366-019-0332-1
   Wang SP, 2018, IEEE ACCESS, V6, P38437, DOI 10.1109/ACCESS.2018.2851611
   Xingjian Li, 2021, Journal of Physics: Conference Series, V1757, DOI 10.1088/1742-6596/1757/1/012161
   Yin H, 2022, J SYST ARCHITECT, V128, DOI 10.1016/j.sysarc.2022.102533
   Yin H, 2020, J PARALLEL DISTR COM, V135, P56, DOI 10.1016/j.jpdc.2019.09.011
   [于金刚 Yu Jingang], 2019, [小型微型计算机系统, Journal of Chinese Computer Systems], V40, P2324
   Zhu NF, 2019, CLUSTER COMPUT, V22, pS8899, DOI 10.1007/s10586-018-2018-1
   Zhu Y, 2018, P IEEE I C SERV COMP, P193, DOI 10.1109/SCC.2018.00032
NR 38
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16377
EP 16394
DI 10.1007/s11042-023-16186-z
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000008
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Liao, JJ
AF Zhang, Xiaoqiang
   Liao, Jingjing
TI Multiple-image encryption algorithm based on 3D-LWT and dynamic stereo
   S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple-image encryption (MIE); 3D integer lifting wavelet transform
   (3D-LWT); Dynamic stereo S-box
AB Digital image is transmitted more and more frequently through the network. To protect the security of batch images in an open network, a multiple-image encryption algorithm is proposed. Firstly, multiple images are combined into an image cube and then three-dimensional integer lifting wavelet transform (3D-LWT) is performed on it; secondly, the low-frequency part is scrambled to obtain the scrambled image cube in frequency domain; thirdly, three-dimensional inverse integer lifting wavelet transform (3D-ILWT) is performed to obtain the scrambled image cube in the spatial domain; finally, the scrambled image cube is replaced by the dynamic stereo S-box. The experimental results and algorithm analyses show that the key space of the algorithm can reach up to 2(628), and its key sensitivity is very strong. Therefore the algorithm is strongly secure and robust.
C1 [Zhang, Xiaoqiang; Liao, Jingjing] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM grayqiang@163.com
CR Abboud AJ., 2018, INT J ELECTR COMPUT, V8, P3568, DOI DOI 10.11591/IJECE.V8I5.PP3568-3586
   Al Khawaldah M., 2018, 2018 Advances in Science and Engineering Technology International Conferences, ASET 2018, P1, DOI DOI 10.1109/ICSCEE.2018.8538373
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bao LY, 2021, NONLINEAR DYNAM, V105, P1911, DOI 10.1007/s11071-021-06688-6
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dongming H., 2023, HELIYON, V9, P1
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Huiyan Z., 2022, MULTIMED TOOLS APPL, V81, P24757
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113925
   Jianqiang B., 2020, SIGNAL PROCESS, V176, P1
   Jun Peng, 2020, 2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA), P213, DOI 10.1109/ICIEA48937.2020.9248115
   Kong DZ, 2013, APPL OPTICS, V52, P2619, DOI 10.1364/AO.52.002619
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P18941, DOI 10.1007/s11042-020-10325-6
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Li L, 2017, FED CONF COMPUT SCI, P555, DOI 10.15439/2017F163
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   LilianHuang WS, 2020, MATH PROBL ENG, P1
   Munir N, 2021, MATH COMPUT SIMULAT, V190, P826, DOI 10.1016/j.matcom.2021.06.008
   Ni RJ, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3076480
   Pak C, 2021, MULTIMED TOOLS APPL, V80, P25367, DOI 10.1007/s11042-021-10660-2
   Rathore V, 2021, MULTIMED TOOLS APPL, V80, P22275, DOI 10.1007/s11042-021-10719-0
   Roy S, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102919
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shafique A, 2020, WIRELESS PERS COMMUN, V115, P2243, DOI 10.1007/s11277-020-07680-w
   Shevchenko II, 2014, PHYS LETT A, V378, P34, DOI 10.1016/j.physleta.2013.10.035
   Shiwei J., 2020, IET IMAGE PROCESS, V15, P1053
   Tao W., 2020, OPT LASER TECHNOL, V132, P1
   Xiaofeng W., 2021, MULTIMED TOOLS APPL, V80, P1
   Xiaohong G., 2021, PHYS SCRIPTA, V96, P1
   Xiaoqiang Z., 2022, J ELECTRON IMAGING, V31, P043047
   Xin L., 2020, IEEE T DEPEND SECURE, V19, P897
   Xiuli C., 2021, SIGNAL PROCESS, V183, P1
   Xiulun Y., 2018, OPT LASER ENG, V102, P106
   Xuelian CH., 2022, J ELECTRON IMAGING, V31, P1
   Ye Tian L., 2017, AIP ADV, V7, P1
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Zhang H, 2020, IET IMAGE PROCESS, V14, P518, DOI 10.1049/iet-ipr.2019.0771
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhihua G, 2021, NEURAL COMPUT APPL, P1
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
NR 49
TC 2
Z9 2
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16337
EP 16362
DI 10.1007/s11042-023-16162-7
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030536100002
DA 2024-07-18
ER

PT J
AU Bahrani, P
   Minaei-Bidgoli, B
   Parvin, H
   Mirzarezaee, M
   Keshavarz, A
AF Bahrani, Payam
   Minaei-Bidgoli, Behrouz
   Parvin, Hamid
   Mirzarezaee, Mitra
   Keshavarz, Ahmad
TI A hybrid semantic recommender system enriched with an imputation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Hybrid method; Clustering; KNN; Wordnet; Ontology
ID OF-THE-ART; MATRIX FACTORIZATION; USER; ACCURACY; CLASSIFICATION
AB Recommender systems are widely used in many applications. They can be viewed as the predictor systems that are to suggest accurate and highly preferred items to consumers or clients. These systems can be considered to be information filtering systems. They counter some important challenges such as cold start (it means the absence of enough data for a new item to make accurate recommendations), scalability, and sparsity. The memory-based recommender systems have high accuracy but lack scalability. Also, the model-based systems are scalable but not accurate. Current recommender systems use hybrid methods to deal with the most important shortages of traditional filtering approaches. Current recommender systems are usually a hybrid of content-based filtering and collaborative filtering, and so on. In this paper, a hybrid recommender system is presented to meet the stated challenges, increase system performance and provide more accurate recommendations. This system uses both content-based filtering and collaborative filtering. In addition, using an automatically collected wordnet, we create an ontology that has been used in the content-based filtering section of our proposed approach. Furthermore, this framework applies KNN (k nearest neighbors) algorithm and clustering to improve its functionality. The proposed system is evaluated on a real benchmark. The experimentations show the proposed method has a better performance compared with the current superior related methods. The experimentations also show that our recommender system has desirable scalability compared with the state-of-the-art recommender systems.
C1 [Bahrani, Payam; Mirzarezaee, Mitra] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Minaei-Bidgoli, Behrouz] Iran Univ Sci & Technol, Sch Comp Engn, Tehran, Iran.
   [Parvin, Hamid] Islamic Azad Univ, Dept Comp Engn, Nourabad Mamasani Branch, Tehran, Iran.
   [Keshavarz, Ahmad] Persian Gulf Univ, Fac Intelligent Syst Engn & Data Sci, Dept Elect Engn, Bushehr 75169, Iran.
C3 Islamic Azad University; Iran University Science & Technology; Islamic
   Azad University; Persian Gulf University
RP Parvin, H (corresponding author), Islamic Azad Univ, Dept Comp Engn, Nourabad Mamasani Branch, Tehran, Iran.
EM parvin@iust.ac.ir
RI Keshavarz, Ahmad/G-7030-2018
OI mirzarezaee, mitra/0000-0002-0809-967X
CR Abdelwahab A, 2009, IEEE NLP-KE 2009: PROCEEDINGS OF INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING, P220
   Adoinavicius G, 2007, IEEE INTELL SYST, V22, P48, DOI 10.1109/MIS.2007.58
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P635, DOI 10.1145/3383313.3411533
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534
   Al-Shamri MYH, 2016, KNOWL-BASED SYST, V100, P175, DOI 10.1016/j.knosys.2016.03.006
   Anand SS, 2007, ACM T INTERNET TECHN, V7, DOI 10.1145/1278366.1278371
   Anand SS, 2005, LECT NOTES ARTIF INT, V3169, P1
   [Anonymous], 2005, P PERS 2005 WORKSH N
   Arazy Ofer, 2009, IT Professional, V11, P38, DOI 10.1109/MITP.2009.76
   Armstrong JS, 2001, INT SER OPER RES MAN, V30, P417
   Bagherifard K, 2017, TELEMAT INFORM, V34, P1772, DOI 10.1016/j.tele.2017.08.008
   Bahrani P, 2020, J INTELL FUZZY SYST, V38, P4471, DOI 10.3233/JIFS-191225
   Bambini R, 2011, RECOMMENDER SYSTEMS HANDBOOK, P299, DOI 10.1007/978-0-387-85820-3_9
   Bennett J., 2007, P KDD CUP WORKSHOP, P35
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bobadilla J, 2013, KNOWL-BASED SYST, V51, P27, DOI 10.1016/j.knosys.2013.06.010
   Bobadilla J, 2011, EXPERT SYST APPL, V38, P14609, DOI 10.1016/j.eswa.2011.05.021
   Bokde D, 2015, PROCEDIA COMPUT SCI, V49, P136, DOI 10.1016/j.procs.2015.04.237
   Breese J., 1998, P 14 C UNC ART INT, P43
   Buitelaar Paul, 2005, Ontology Learning From Text: Methods, Evaluation and Applications
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Chen SL, 2018, KNOWL-BASED SYST, V158, P109, DOI 10.1016/j.knosys.2018.05.040
   Cheng LC, 2014, APPL SOFT COMPUT, V18, P290, DOI 10.1016/j.asoc.2013.09.004
   Cremonesi P., 2010, P 4 ACM C REC SYST, P39, DOI [DOI 10.1145/1864708.1864721, 10.1145/1864708.1864721]
   Das A. S., 2007, P 16 INT C WORLD WID, P271
   Deng Julong, 1989, Journal of Grey Systems, V1, P1
   DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090
   Ebadi A., 2016, International Journal of Computer and Information Engineering, V10, P1377, DOI DOI 10.5281/ZENODO.1125867
   Ekstrand MD, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P161, DOI 10.1145/2645710.2645737
   Feely C, 2020, LECT NOTES ARTIF INT, V12311, P67, DOI 10.1007/978-3-030-58342-2_5
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   FONG YS, 1989, OPT ENG, V28, P749, DOI 10.1117/12.7977031
   Gallego AJ, 2020, IEEE ACCESS, V8, P99312, DOI 10.1109/ACCESS.2020.2997387
   Garcia-Crespo Angel, 2009, International Journal of Advanced Intelligence Paradigms, V1, P418, DOI 10.1504/IJAIP.2009.026762
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   GUARINO N, 1995, TOWARDS VERY LARGE KNOWLEDGE BASES, P25
   Gunawardana A, 2009, J MACH LEARN RES, V10, P2935
   Hearst M. A., 1992, Proceedings of the 12th Conference on Computational Linguistics, V2, P539, DOI DOI 10.3115/992133.992154
   Iaquinta Leo, 2008, 2008 8th International Conference on Hybrid Intelligent Systems (HIS), P168, DOI 10.1109/HIS.2008.25
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jawaheer G., 2010, P 1 INT WORKSHOP INF, P47, DOI DOI 10.1145/1869446
   Ji K, 2016, NEUROCOMPUTING, V173, P912, DOI 10.1016/j.neucom.2015.08.046
   Jiang R, 2013, SCI WORLD J, V2013
   Jorro-Aragoneses J, 2019, LECT NOTES ARTIF INT, V11680, P140, DOI 10.1007/978-3-030-29249-2_10
   Jou JM, 1999, IEEE T CIRC SYST VID, V9, P843, DOI 10.1109/76.785721
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kilanioti Irene, 2019, High-Performance Modelling and Simulation for Big Data Applications: Selected Results of the COST Action IC1406 cHiPSet. Lecture Notes in Computer Science (LNCS 11400), P88, DOI 10.1007/978-3-030-16272-6_4
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu L., 2011, 5 ACM C RECOMMENDER, P77, DOI DOI 10.1145/2043932.2043950
   Liu R, 2020, INT CONF ACOUST SPEE, P4217, DOI [10.1109/icassp40776.2020.9054480, 10.1109/ICASSP40776.2020.9054480]
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Maedche A, 2002, LECT NOTES ARTIF INT, V2473, P251
   Marlin Benjamin M, 2007, P 23 C UNCERTAINTY A, DOI DOI 10.1145/2507157.2507160
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P627
   Meymandpour R., 2014, COMMUN COMPUT PHYS, P475
   Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773
   Montaner M, 2003, ARTIF INTELL REV, V19, P285, DOI 10.1023/A:1022850703159
   Mooney R. J., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P195, DOI 10.1145/336597.336662
   Murthi BPS, 2003, MANAGE SCI, V49, P1344, DOI 10.1287/mnsc.49.10.1344.17313
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Nilashi M, 2015, ELECTRON COMMER R A, V14, P542, DOI 10.1016/j.elerap.2015.08.004
   Nilashi M, 2014, KNOWL-BASED SYST, V60, P82, DOI 10.1016/j.knosys.2014.01.006
   Nilashi M, 2014, EXPERT SYST APPL, V41, P3879, DOI 10.1016/j.eswa.2013.12.023
   Pan RL, 2015, APPL INTELL, V43, P614, DOI 10.1007/s10489-015-0666-x
   Paradarami TK, 2017, EXPERT SYST APPL, V83, P300, DOI 10.1016/j.eswa.2017.04.046
   Park DH, 2012, EXPERT SYST APPL, V39, P10059, DOI 10.1016/j.eswa.2012.02.038
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Pham MC, 2011, J UNIVERS COMPUT SCI, V17, P583
   Pirasteh P, 2015, KNOWL-BASED SYST, V83, P51, DOI 10.1016/j.knosys.2015.03.006
   Powell M., 1981, Approximation Theory and Methods
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Ricci F., 2018, ENCY SOCIAL NETWORK
   Rich E., 1979, Cognitive Science, V3, P329, DOI [DOI 10.1016/S0364-0213, DOI 10.1207/S15516709COG0304_3, 10.1016/S0364-0213]
   Salton G., 1989, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer
   Sarwar Badrul, 2002, P 5 INT C COMP INF T
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Shinde SK, 2012, EXPERT SYST APPL, V39, P1381, DOI 10.1016/j.eswa.2011.08.020
   Solanki SK., 2015, HARYANA, V2015, P212
   Song Q., 2005, 11 IEEE INT SOFTW ME, V2005, P321, DOI [10.1109/METRICS.2005.51, DOI 10.1109/METRICS.2005.51]
   SongJie Gong, 2010, Journal of Software, V5, P745, DOI 10.4304/jsw.5.7.745-752
   Su SL, 2000, IEEE T VEH TECHNOL, V49, P2081, DOI 10.1109/25.901877
   Tejeda-Lorente A, 2015, APPL SOFT COMPUT, V30, P778, DOI 10.1016/j.asoc.2015.02.024
   Truong K, 2007, IEICE T INF SYST, VE90D, P1363, DOI 10.1093/ietisy/e90-d.9.1363
   Tsai CF, 2012, APPL SOFT COMPUT, V12, P1417, DOI 10.1016/j.asoc.2011.11.016
   Van Meteren Robin, 2000, P MACH LEARN NEW INF, P47
   Wang P, 2012, PHYSCS PROC, V24, P812, DOI 10.1016/j.phpro.2012.02.121
   Wang Q, 2022, IEEE T PATTERN ANAL, V44, P390, DOI 10.1109/TPAMI.2020.3007673
   Wei CP, 2008, DECIS SUPPORT SYST, V45, P413, DOI 10.1016/j.dss.2007.05.008
   Ying He, 2011, Proceedings of the 2011 International Symposium on Computer Science and Society (ISCCS 2011), P118, DOI 10.1109/ISCCS.2011.40
   Zhang CQ, 2007, LECT NOTES COMPUT SC, V4426, P1080
   Zhang SC, 2012, J SYST SOFTWARE, V85, P2541, DOI 10.1016/j.jss.2012.05.073
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang ZK, 2011, J COMPUT SCI TECH-CH, V26, P767, DOI 10.1007/s11390-011-0176-1
   Ziakis C, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11020032
NR 100
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15985
EP 16018
DI 10.1007/s11042-023-15258-4
EA JUL 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200010
DA 2024-07-18
ER

PT J
AU Sajid, MZ
   Qureshi, I
   Youssef, A
   Khan, NA
AF Sajid, Muhammad Zaheer
   Qureshi, Imran
   Youssef, Ayman
   Khan, Nauman Ali
TI FAS-Incept-HR: a fully automated system based on optimized inception
   model for hypertensive retinopathy classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Hypertensive retinopathy; Transform learning; CNN
ID VENULAR DIAMETER RATIO; IMAGES; ARTERIES
AB Hypertensive retinopathy (HR) is a well-known eye disease that is caused by high blood pressure (hypertension). In this illness, symptoms typically develop later. The AV nicking, cotton wool patches, constricted veins in the optic nerve, and blood pouring into the eye's optic nerve all contribute to the appearance of the HR symptoms. HR disease may have different types of serious complications, including retinal artery blockage, destruction of the visual nerves, and maybe vision loss. The automated early detection of this illness can be aided by AI and deep learning models. In this research, a novel dataset for HR is collected from Pakistani hospitals (Pak-HR) and internet sources. Second, a brand-new methodology Inception-HR (Incept-HR) is developed to evaluate hypertensive retinopathy using InceptionV3 and residual blocks. 6,000 digital fundus images from the collected dataset were used to train the Incept-HR system. The proposed classification method, Incept-HR, has 99% accuracy and an f1-score of 0.99. The results show that this model produces useful outcomes and can be applied as a diagnostic testing tool. The system is not intended to replace optometrists; rather, it aims to assist professionals. The proposed methodology outperforms both the cutting-edge models VGG19 and VGG16 in terms of accuracy.
C1 [Sajid, Muhammad Zaheer; Qureshi, Imran; Khan, Nauman Ali] Natl Univ Sci & Technol, Mil Coll Signals, Dept Comp Software Engn, Islamabad, Pakistan.
   [Qureshi, Imran] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh 11432, Saudi Arabia.
   [Youssef, Ayman] Elect Res Inst, Dept Comp & Syst, Cairo, Egypt.
C3 National University of Sciences & Technology - Pakistan; Imam Mohammad
   Ibn Saud Islamic University (IMSIU); Egyptian Knowledge Bank (EKB);
   Electronics Research Institute (ERI)
RP Qureshi, I (corresponding author), Natl Univ Sci & Technol, Mil Coll Signals, Dept Comp Software Engn, Islamabad, Pakistan.; Qureshi, I (corresponding author), Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh 11432, Saudi Arabia.
EM msajid.msse-27mcs@student.nust.edu.pk; imran.qureshi@mcs.nust.edu.pk;
   aymanmahgoub@eri.sci.eg; nauman.ali@mcs.nust.edu.pk
RI ; Mahgoub, Ayman/AAF-8219-2019
OI Sajid, Muhammad Zaheer/0009-0005-5794-7902; Mahgoub,
   Ayman/0000-0001-6145-4071; qureshi, imran/0000-0002-8542-7112; Ali Khan,
   Nauman/0000-0002-7940-1960
CR Abbas Q, 2019, MULTIMED TOOLS APPL, V78, P23559, DOI 10.1007/s11042-019-7652-y
   Abbas Q, 2019, ARTIF INTELL REV, V52, P39, DOI 10.1007/s10462-018-9633-3
   Abbasi-Sureshjani S, 2016, I S BIOMED IMAGING, P189, DOI 10.1109/ISBI.2016.7493241
   Agurto C, 2014, IEEE ENG MED BIO, P5406, DOI 10.1109/EMBC.2014.6944848
   Akagi S, 2018, J CARDIOL, V72, P466, DOI 10.1016/j.jjcc.2018.04.014
   Akbar S, 2018, ARTIF INTELL MED, V90, P15, DOI 10.1016/j.artmed.2018.06.004
   Akbar S, 2018, COMPUT METH PROG BIO, V154, P123, DOI 10.1016/j.cmpb.2017.11.014
   AlBadawi S, 2018, LECT NOTES COMPUT SC, V10882, P659, DOI 10.1007/978-3-319-93000-8_75
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Canziani A., 2016, An Analysis of Deep Neural Network Models for Practical Applications
   Cavallari M, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/752957
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gamella-Pozuelo L, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001218
   Gao Y, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/2745183
   García-Floriano A, 2019, COMPUT ELECTR ENG, V75, P218, DOI 10.1016/j.compeleceng.2017.11.008
   Goswami S, 2017, ADV INTELL SYST, V458, P451, DOI 10.1007/978-981-10-2035-3_46
   Grisan E, 2008, IEEE T MED IMAGING, V27, P310, DOI 10.1109/TMI.2007.904657
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holm S, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.1.014503
   Irshad S, 2014, CAIRO INT BIOM ENG, P121, DOI 10.1109/CIBEC.2014.7020932
   Irshad S, 2014, CAIRO INT BIOM ENG, P133, DOI 10.1109/CIBEC.2014.7020937
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Keshavarzian A, 2019, FUTURE GENER COMP SY, V101, P14, DOI 10.1016/j.future.2019.06.009
   Khitran S., 2014, P 2014 4 INT C IM PR, P1, DOI [10.1109/IPTA.2014.7001984., DOI 10.1109/IPTA.2014.7001984]
   Kriplani Himanshu, 2020, Computational Intelligence in Data Mining. Proceedings of the International Conference on ICCIDM 2018. Advances in Intelligent Systems and Computing (AISC 990), P141, DOI 10.1007/978-981-13-8676-3_13
   Manikis G.C., 2011, P 2011 E HLTH BIOENG, P1
   Mozaffarian D, 2016, CIRCULATION, V133, pE38, DOI 10.1161/CIR.0000000000000350
   Muramatsu C, 2011, COMPUT MED IMAG GRAP, V35, P472, DOI 10.1016/j.compmedimag.2011.03.002
   Narasimhan K, 2012, PROCEDIA ENGINEER, V38, P980, DOI 10.1016/j.proeng.2012.06.124
   Nath M. K., 2012, Proceedings of the 2012 2nd National Conference on Computational Intelligence and Signal Processing (CISP 2012), P81, DOI 10.1109/NCCISP.2012.6189682
   Niu D, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P208, DOI 10.1109/SIPROCESS.2017.8124534
   Noronha K.N. K., 2012, International Conference on Electronic Design and Signal Processing (ICEDSP), P7
   Ortíz D, 2010, IEEE ENG MED BIO, P5649, DOI 10.1109/IEMBS.2010.5628047
   Prentasic P, 2015, INT SYMP IMAGE SIG, P188, DOI 10.1109/ISPA.2015.7306056
   Qureshi I, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312086
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Saez M, 2012, COMPUT METH PROG BIO, V108, P367, DOI 10.1016/j.cmpb.2012.02.008
   Sengupta S, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101758
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Syahputra MF, 2018, J PHYS CONF SER, V978, DOI 10.1088/1742-6596/978/1/012106
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Tramontan L, 2009, IFMBE PROC, V25, P141, DOI 10.1007/978-3-642-03891-4_38
   Triwijoyo BK, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012039
   Triwijoyo BK, 2017, PROCEDIA COMPUT SCI, V116, P166, DOI 10.1016/j.procs.2017.10.066
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Welikala RA, 2017, COMPUT BIOL MED, V90, P23, DOI 10.1016/j.compbiomed.2017.09.005
   Wiharto, 2019, IOP Conference Series: Materials Science and Engineering, V620, DOI 10.1088/1757-899X/620/1/012099
   Wu J, 2018, J MED IMAG HEALTH IN, V8, P38, DOI 10.1166/jmihi.2018.2229
   Xu P, 2023, IEEE T PATTERN ANAL, V45, P285, DOI 10.1109/TPAMI.2022.3148853
   Yao ZJ, 2016, INT SYM COMPUT INTEL, P406, DOI [10.1109/ISCID.2016.1100, 10.1109/ISCID.2016.99]
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
   Zou XC, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/7496735
NR 54
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14281
EP 14303
DI 10.1007/s11042-023-15556-x
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023992100003
DA 2024-07-18
ER

PT J
AU Ravi, S
   Climent-Pérez, P
   Florez-Revuelta, F
AF Ravi, Siddharth
   Climent-Perez, Pau
   Florez-Revuelta, Francisco
TI A review on visual privacy preservation techniques for active and
   assisted living
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Visual privacy preservation; Active and assisted living; Privacy by
   design; Perceptual obfuscation; Machine obfuscation; Facial
   de-identification
ID DE-IDENTIFICATION; GAIT RECOGNITION; FACE; PROTECTION
AB This paper reviews the state of the art in visual privacy protection techniques, with particular attention paid to techniques applicable to the field of Active and Assisted Living (AAL). A novel taxonomy with which state-of-the-art visual privacy protection methods can be classified is introduced. Perceptual obfuscation methods, a category in this taxonomy, is highlighted. These are a category of visual privacy preservation techniques, particularly relevant when considering scenarios that come under video-based AAL monitoring. Obfuscation against machine learning models is also explored. A high-level classification scheme of privacy by design, as defined by experts in privacy and data protection law, is connected to the proposed taxonomy of visual privacy preservation techniques. Finally, we note open questions that exist in the field and introduce the reader to some exciting avenues for future research in the area of visual privacy.
C1 [Ravi, Siddharth; Climent-Perez, Pau; Florez-Revuelta, Francisco] Univ Alicante, Dept Comp Technol, Alicante 03690, Valencian Commu, Spain.
C3 Universitat d'Alacant
RP Ravi, S (corresponding author), Univ Alicante, Dept Comp Technol, Alicante 03690, Valencian Commu, Spain.
EM siddharth.ravi@ua.es; pcliment@dtic.ua.es; francisco.florez@ua.es
OI Ravi, Siddharth/0000-0002-2301-569X
FU European Union [861091]; COST Action [CA19121]; COST (European
   Cooperation in Science and Technology); CRUE-CSIC; Springer Nature;
   Marie Curie Actions (MSCA) [861091] Funding Source: Marie Curie Actions
   (MSCA)
FX This work is part of the visuAAL project on Privacy-Aware and Acceptable
   Video-Based Technologies and Services for Active and Assisted Living &
   nbsp;(https://www.visuaal-itn.eu/). This project has received funding
   from the European Union's Horizon 2020 research and innovation programme
   under the Marie Sklodowska-Curie grant agreement No 861091. The authors
   would also like to acknowledge the contribution of COST Action CA19121 -
   GoodBrother, Network on Privacy-Aware Audio- and Video-Based
   Applications for Active and Assisted Living &
   nbsp;(https://goodbrother.eu/), supported by COST (European Cooperation
   in Science and Technology)& nbsp;(https://www.cost.eu/).Open Access
   funding provided thanks to the CRUE-CSIC agreement with Springer Nature.
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551
   Al-Obaidi S, 2020, IEEE ACCESS, V8, P213806, DOI 10.1109/ACCESS.2020.3039740
   Amazon Web Services, 2021, AM REK API
   Chaaraoui AA, 2012, EXPERT SYST APPL, V39, P10873, DOI 10.1016/j.eswa.2012.03.005
   AT &T Laboratories Cambridge, 2002, US
   Avidan S, 2006, LECT NOTES COMPUT SC, V3953, P1, DOI 10.1007/11744078_1
   Barth S, 2017, TELEMAT INFORM, V34, P1038, DOI 10.1016/j.tele.2017.04.013
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bian S, 2020, P IEEE CVF C COMP VI, DOI 10.1109/cvpr42600.2020.00942
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Boulemtafes A, 2020, NEUROCOMPUTING, V384, P21, DOI 10.1016/j.neucom.2019.11.041
   Bristow H, 2015, IEEE I CONF COMP VIS, P4024, DOI 10.1109/ICCV.2015.458
   Brkic K, 2017, PROTECTING PRIVACY H, V87, P41, DOI [10.1016/j.eswa.2017.05.067, DOI 10.1016/J.ESWA.2017.05.067]
   Brkic K, 2017, IEEE COMPUT SOC CONF, P1319, DOI 10.1109/CVPRW.2017.173
   Brkic K, 2017, EXPERT SYST APPL, V87, P41, DOI 10.1016/j.eswa.2017.05.067
   Brown Tom B., 2017, ARXIV
   Cavoukian Ann, 2009, Privacy by design: The 7 foundational principles
   Chang YL, 2019, IEEE I CONF COMP VIS, P9065, DOI 10.1109/ICCV.2019.00916
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Çiftçi S, 2018, IEEE T MULTIMEDIA, V20, P68, DOI 10.1109/TMM.2017.2728479
   Clarke R, 1999, COMMUN ACM, V42, P60, DOI 10.1145/293411.293475
   Climent-Perez P, 2021, PROTECTION VISUAL PR, P1, DOI [10.1007/s11042-020-10249-1, DOI 10.1007/S11042-020-10249-1]
   Climent-Pérez P, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112847
   Corona E, 2021, PROC CVPR IEEE, P11870, DOI 10.1109/CVPR46437.2021.01170
   Council of the European Union European Parliament, 2018, ART 7 GDPR COND CONS
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das S, 2019, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2019.00092
   Dwork C., 2014, The algorithmic foundations of differential privacy, V9, DOI [DOI 10.1561/0400000042, 10.1561/ 0400000042.]
   Erdelyi A., 2013, MediaEval
   Erdélyi A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P44, DOI 10.1109/AVSS.2014.6918642
   Fan LY, 2018, LECT NOTES COMPUT SC, V10980, P148, DOI 10.1007/978-3-319-95729-6_10
   Gaur U, 2017, IEEE I CONF COMP VIS, P1744, DOI 10.1109/ICCV.2017.192
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Google, 2008, CLOUD VIS API
   Gross R., 2006, 2006 C COMPUTER VISI, P161
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Güler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280
   Gurrin C, 2014, DIGITAL ENLIGHTENMENT YEARBOOK 2014: SOCIAL NETWORKS AND SOCIAL MACHINES, SURVEILLANCE AND EMPOWERMENT, P49, DOI 10.3233/978-1-61499-450-3-49
   Haddad WS, 2017, US Patent, Patent No. [9,571,708, 9571708]
   Harvey A, 2009, ANTIPAPARAZZI FASHIO
   Hassan ET, 2017, IEEE COMPUT SOC CONF, P1333, DOI 10.1109/CVPRW.2017.175
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Heitzinger T, 2021, INT C PATT RECOG, P8228, DOI 10.1109/ICPR48806.2021.9412979
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jonsson KS, 2016, US Patent, Patent No. [9,465,276, 9465276]
   Kapadia A, 2007, LECT NOTES COMPUT SC, V4480, P162
   Kim D, 2019, PROC CVPR IEEE, P5785, DOI 10.1109/CVPR.2019.00594
   Knight W, 2021, CONDE NAST
   Komkov S, 2021, INT C PATT RECOG, P819, DOI 10.1109/ICPR48806.2021.9412236
   Konecny J, 2016, ARXIV, DOI DOI 10.48550/ARXIV:1610.05492
   Korshunov P, 2013, INT CONF DIGIT SIG
   Korshunov P, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P208, DOI 10.1109/AVSS.2013.6636641
   Korshunov P, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000488
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee S, 2019, IEEE I CONF COMP VIS, P4412, DOI 10.1109/ICCV.2019.00451
   Li NH, 2007, PROC INT CONF DATA, P81
   Li T, 2019, IEEE COMPUT SOC CONF, P56, DOI 10.1109/CVPRW.2019.00013
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Machanavajjhala A, 2007, ACM T KNOWL DISCOV D, V1, P1, DOI DOI 10.1145/1217299.1217302
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   McPherson Richard., 2016, Defeating image obfuscation with deep learning
   Meden B, 2021, IEEE T INF FOREN SEC, V16, P4147, DOI 10.1109/TIFS.2021.3096024
   Menon S, 2020, PROC CVPR IEEE, P2434, DOI 10.1109/CVPR42600.2020.00251
   Microsoft Azure, 2021, FAC REC MICR AZ
   Mihailidis A, 2020, METHODOLOGICAL APPRO, V46, P1
   Miller K, 2020, US Patent, Patent No. [10,816,878, 10816878]
   Mitskog TF, 2012, Google Patents, Patent No. [13/477,485, 13477485]
   Mondejar-Guerra V., 2019, British Machine Vision Conference, P266
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Oh SJ, 2016, LECT NOTES COMPUT SC, V9907, P19, DOI 10.1007/978-3-319-46487-9_2
   Oh SW, 2019, IEEE I CONF COMP VIS, P4402, DOI 10.1109/ICCV.2019.00450
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Patel ShwetakN., 2009, Protecting Privacy in Video Surveillance, P185
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Perez AJ, 2017, IT PROF, V19, P61, DOI 10.1109/MITP.2017.42
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Pilu M, 2007, US patent App, Patent No. [11/491,174, 11491174]
   Pilu M, 2007, US patent App, Patent No. [11(491):174, 11491174]
   Pons-Moll G, 2015, INT J COMPUT VISION, V113, P163, DOI 10.1007/s11263-015-0818-9
   Prolific, 2021, ABOUT US
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Remagnino P, 2004, AMBIENT INTELLIGENCE
   Rezaei B., 2020, ECCV, DOI [10.1007/978-3-030-58610-218, DOI 10.1007/978-3-030-58610-218]
   Ribaric S, 2016, SIGNAL PROCESS-IMAGE, V47, P131, DOI 10.1016/j.image.2016.05.020
   Rong Y, 2021, IEEE INT CONF COMP V, P1749, DOI 10.1109/ICCVW54120.2021.00201
   Rozumnyi D, 2021, PROC CVPR IEEE, P3455, DOI 10.1109/CVPR46437.2021.00346
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   Shafahi A, 2018, ADV NEUR IN, V31
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Shashank J, 2008, PROC CVPR IEEE, P365
   Shen JC, 2019, IEEE ACCESS, V7, P41498, DOI 10.1109/ACCESS.2019.2905915
   Sightengine, 2021, TEXT MOD IM VID
   Sun QR, 2018, PROC CVPR IEEE, P5050, DOI 10.1109/CVPR.2018.00530
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664
   Thys S, 2019, IEEE COMPUT SOC CONF, P49, DOI 10.1109/CVPRW.2019.00012
   Tieu N-DT, 2017, 2017 IEEE WORKSH INF, P1, DOI [10.1109/WIFS.2017.8267657, DOI 10.1109/WIFS.2017.8267657]
   Tieu NDT, 2019, ASIAPAC SIGN INFO PR, P1686, DOI [10.1109/APSIPAASC47483.2019.9023188, 10.1109/apsipaasc47483.2019.9023188]
   Tieu NDT, 2019, J INF SECUR APPL, V46, P307, DOI 10.1016/j.jisa.2019.03.002
   Upmanyu M, 2009, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2009.5459370
   Wagner I, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3168389
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang Z, 2021, INT J HUM RESOUR MAN, V32, P2264, DOI [10.1080/09585192.2019.1579254, 10.1109/CVPRW.2019.00007]
   Wei LY, 2016, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2016.171
   Wilkowska W, 2021, INT J HUM-COMPUT INT, V37, P1436, DOI 10.1080/10447318.2021.1888487
   Wright C.V., 2015, P 3 ACM WORKSH INF H, P141, DOI 10.1145/2756601.2756618
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yabuta K, 2005, LECT NOTES COMPUT SC, V3767, P831
   Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yonetani R, 2017, IEEE I CONF COMP VIS, P2059, DOI 10.1109/ICCV.2017.225
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu XY, 2007, LECT NOTES COMPUT SC, V4844, P651
   Zhang HT, 2019, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2019.00281
   Zhang HY, 2012, PROCEDIA ENGINEER, V29, P3674, DOI 10.1016/j.proeng.2012.01.551
   Zhang N, 2015, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2015.7299113
   Zhang W, 2005, IEEE IMAGE PROC, P3380
   Zhang YM, 2022, J KING SAUD UNIV-COM, V34, P2993, DOI 10.1016/j.jksuci.2022.04.001
   Zhang ZX, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101172
   Zhou JZ, 2021, IEEE T INF FOREN SEC, V16, P1088, DOI 10.1109/TIFS.2020.3029913
   Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20
   Zhu SL, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P329, DOI 10.1145/3117811.3117820
NR 142
TC 8
Z9 8
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14715
EP 14755
DI 10.1007/s11042-023-15775-2
EA JUL 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800005
OA hybrid, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, R
   Agrawal, N
AF Kumar, Rohit
   Agrawal, Neha
TI Software defined networks (SDNs) for environmental surveillance : A
   Survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software defined networking (SDN); Environmental surveillance; Quality
   of service (QoS); Smart city surveillance; Video surveillance; Military
   surveillance
ID TRAFFIC ENGINEERING METHOD; VIDEO SURVEILLANCE; SMART; SYSTEMS;
   SECURITY; INTERNET; TIME; CHALLENGES; DEFENSE; THINGS
AB There have been a number of new technologies and applications that can track various events and activities in a variety of environments. Software Defined Networking (SDN) is one of these technologies that has the ability to bring the unanticipated changes in the networking space. SDN aids in the implementation and management of new networks, lowering associated expenses. SDN's unique characteristics make it ideal for monitoring the harsh environmental conditions. Agriculture, Military, Industry, Natural disasters, Health monitoring, Crisis response, and Emergency management are just few examples of common applications. In the last few decades, some of these applications have been of critical relevance and the subject of ongoing research. SDN becomes increasingly popular owing to its perfect benefits, which include aid in various surveillance scenarios. Thus, this survey covers several areas of surveillance and assists the readers to have a better grasp of SDN-based surveillance. Furthermore, various open research problems and the related surveillance challenges have also been explored.
C1 [Kumar, Rohit] Shiv Nadar Univ, CSE Dept, Chennai, Tamil Nadu, India.
   [Agrawal, Neha] Indian Inst Informat Technol Sri City, CSE Grp, Chittoor, Andhra Pradesh, India.
C3 Shiv Nadar University
RP Agrawal, N (corresponding author), Indian Inst Informat Technol Sri City, CSE Grp, Chittoor, Andhra Pradesh, India.
EM rohitkumar@snuchennai.edu.in; nehaiiitm345@gmail.com
RI Kumar, Rohit/AES-6893-2022; Agrawal, Neha/AAS-9360-2020
OI Kumar, Rohit/0000-0002-9670-0671; Agrawal, Neha/0000-0002-7254-079X
CR AbdAli AH., 2021, TURK J COMPUT MATH E, V12, P6325
   Abdulqadder IH, 2020, COMPUT NETW, V179, DOI 10.1016/j.comnet.2020.107364
   Agrawal N, 2022, ISA T, V130, P10, DOI 10.1016/j.isatra.2022.03.018
   Agrawal N, 2019, IEEE COMMUN SURV TUT, V21, P3769, DOI 10.1109/COMST.2019.2934468
   Al Mtawa Y, 2019, INT WIREL COMMUN, P1279
   Al-Turjman F, 2020, COMPUT COMMUN, V150, P519, DOI 10.1016/j.comcom.2019.12.004
   Albu-Salih A.T., 2021, Int. J. Electr. Comput. Eng, V11, P4403, DOI [10.11591/ijece.v11i5.pp4403-4412, DOI 10.11591/IJECE.V11I5.PP4403-4412]
   Aljohani SL, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041900
   Alladi T, 2020, COMPUT COMMUN, V160, P81, DOI 10.1016/j.comcom.2020.05.025
   AlZoman R, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P100, DOI 10.1109/SDS49854.2020.9143878
   Arif M, 2020, VEH COMMUN, V26, DOI 10.1016/j.vehcom.2020.100265
   Armando A, 2015, IEEE CONF COMM NETW, P741, DOI 10.1109/CNS.2015.7346913
   Baldoni G, 2017, CONSUM COMM NETWORK, P611, DOI 10.1109/CCNC.2017.7983190
   Barka E, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151787
   Bellavista P, 2018, IEEE ACCESS, V6, P21324, DOI 10.1109/ACCESS.2018.2822401
   Bhatia J, 2020, COMPUT COMMUN, V149, P162, DOI 10.1016/j.comcom.2019.10.011
   Bhattacharjya K, 2021, SIMUL MODEL PRACT TH, V109, DOI 10.1016/j.simpat.2021.102304
   Chiang ML, 2021, CLUSTER COMPUT, V24, P537, DOI 10.1007/s10586-020-03135-w
   Cui X, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030273
   Silva FSD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113078
   Silva TDE, 2019, IEEE ACCESS, V7, P173499, DOI 10.1109/ACCESS.2019.2956724
   Das T, 2020, IEEE COMMUN SURV TUT, V22, P472, DOI 10.1109/COMST.2019.2935453
   Deva Priya Isravel, 2019, Advances in Big Data and Cloud Computing. Proceedings of ICBDCC18. Advances in Intelligent Systems and Computing (AISC 750), P457, DOI 10.1007/978-981-13-1882-5_39
   El Jaouhari S, 2021, J AMB INTEL HUM COMP, V12, P9081, DOI 10.1007/s12652-020-02601-y
   Gaikwad S, 2018, INT WIREL COMMUN, P101, DOI 10.1109/IWCMC.2018.8450440
   Gavaskar K., 2022, Adv Comput Intell, P1, DOI DOI 10.1007/S43674-021-00007-7
   Ghosh U, 2020, INTERNET THINGS SECU, P441, DOI [10.48550/arXiv.2007.11536, DOI 10.48550/ARXIV.2007.11536]
   Gkioulos V, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10090088
   Go SJY, 2019, J NETW COMPUT APPL, V132, P49, DOI 10.1016/j.jnca.2019.01.026
   Guck JW, 2017, IEEE T NETW SERV MAN, V14, P1003, DOI 10.1109/TNSM.2017.2755769
   Ha T, 2016, IEEE NETWORK, V30, P22, DOI 10.1109/MNET.2016.1600106NM
   Han ZB, 2018, IEEE INTERNET THINGS, V5, P1424, DOI 10.1109/JIOT.2018.2801944
   Hossain N., 2021, AM J AGR SCI ENG TEC, V5, P4, DOI [10.54536/ajaset.v5i1.55, DOI 10.54536/AJASET.V5I1.55]
   Hsiao-Chung L, 2016, DESTECH T EC BUSINES, DOI [10.12783/dtem/iceme-ebm2016/4183, DOI 10.12783/DTEM/ICEME-EBM2016/4183]
   Hu L, 2015, IEEE WIREL COMMUN, V22, P67, DOI 10.1109/MWC.2015.7368826
   Iqbal W, 2020, IEEE INTERNET THINGS, V7, P10250, DOI 10.1109/JIOT.2020.2997651
   Isravel S., 2021, Adv. Intell. Syst. Comput., P1, DOI [10.1007/978-981-15-5285-4_38, DOI 10.1007/978-981-15-5285-4_38]
   Javeed D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080918
   Kashef M, 2021, COMPUT HUM BEHAV, V124, DOI 10.1016/j.chb.2021.106923
   Killi BPR, 2019, COMPUT NETW, V163, DOI 10.1016/j.comnet.2019.106883
   Kim NY, 2018, J INF PROCESS SYST, V14, P1361
   Kroculick JB, 2017, PROC SPIE, V10205, DOI 10.1117/12.2263171
   Kumar RM, 2022, J BIOMOL STRUCT DYN, V40, P12165, DOI [10.1080/07391102.2021.1968500, 10.1007/s40860-021-00139-0]
   Letswamotse B, 2017, SO AFRICA TELECOMMUN, P1
   Li WJ, 2020, IEICE T INF SYST, VE103D, P196, DOI 10.1587/transinf.2019INI0002
   Herrera JL, 2021, IEEE INTERNET THINGS, V8, P17172, DOI 10.1109/JIOT.2021.3077992
   Makanju A, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO'17 COMPANION), P287, DOI 10.1145/3067695.3075604
   Makuvaza A., 2021, Social Netw Comput. Sci., V2, P1, DOI DOI 10.1007/S42979-021-00467-1
   Malik J, 2020, IEEE ACCESS, V8, P134695, DOI 10.1109/ACCESS.2020.3009849
   Manso P, 2019, INFORMATION, V10, DOI 10.3390/info10030106
   Martins JS, 2018, ARXIV
   Miao Y, 2017, COMM COM INF SC, V688, P16, DOI 10.1007/978-981-10-4403-8_2
   Mihailescu M, 2015, MIL COMM INF SYST C, P1, DOI [10.1109/MilCIS.2015.7348945, DOI 10.1109/MILCIS.2015.7348945]
   Mishra VK, 2014, IEEE MILIT COMMUN C, P995, DOI 10.1109/MILCOM.2014.170
   Mohammad REA, 2023, INT J ENVIRON AN CH, V103, P6475, DOI 10.1080/03067319.2021.1957464
   Mohammadi R, 2018, INT J BIO-INSPIR COM, V12, P173, DOI 10.1504/IJBIC.2018.10015873
   Mohammadi R, 2017, MULTIMED TOOLS APPL, V76, P23627, DOI 10.1007/s11042-016-4137-0
   Mohammadi R, 2017, IEEE T NETW SERV MAN, V14, P487, DOI 10.1109/TNSM.2017.2701549
   Mohammadi R, 2016, INT J INTELL INF TEC, V12, P45, DOI 10.4018/IJIIT.2016100103
   Montazerolghaem A, 2022, IEEE T SMART GRID, V13, P1952, DOI 10.1109/TSG.2021.3139004
   Munir MS, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P516, DOI 10.1109/ICOIN.2018.8343172
   Nguyen C, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P796, DOI 10.1109/ICCCS49078.2020.9118563
   Nguyen HungXuan., 2016, Military Communications and Information Systems Conference (MilCIS), 2016, P1, DOI [10.1109/MilCIS.2016.7797339, DOI 10.1109/MILCIS.2016.7797339]
   Nowak M, 2019, 2019 GLOBAL IOT SUMMIT (GIOTS), DOI 10.1109/giots.2019.8766380
   Omnes N, 2015, INT CONF INTELL NEXT, P64, DOI 10.1109/ICIN.2015.7073808
   Panev S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3721
   Pourghebleh B, 2020, CLUSTER COMPUT, V23, P641, DOI 10.1007/s10586-019-02950-0
   Qing J, 2015, P IEEE INT C CYBERSP, P1, DOI [10.1049/cp.2015.0834, DOI 10.1049/CP.2015.0834]
   Ragavan PS, 2020, COMPUT COMMUN, V150, P764, DOI 10.1016/j.comcom.2019.11.033
   Rahmani AM, 2021, CLUSTER COMPUT, V24, P1347, DOI 10.1007/s10586-020-03189-w
   Rametta C, 2017, PROCEDIA COMPUT SCI, V110, P361, DOI 10.1016/j.procs.2017.06.078
   Rasool RU, 2020, J NETW COMPUT APPL, V172, DOI 10.1016/j.jnca.2020.102803
   Rasool RU, 2019, IEEE ACCESS, V7, P34885, DOI 10.1109/ACCESS.2019.2904236
   Rego A, 2018, IEEE ACCESS, V6, P31580, DOI 10.1109/ACCESS.2018.2842034
   Rego A, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P45, DOI 10.1109/SDS.2018.8370421
   Rehmani MH, 2019, IEEE COMMUN SURV TUT, V21, P2637, DOI 10.1109/COMST.2019.2908266
   Rezende P, 2019, IEEE ICC
   Rietz R, 2018, J COMPUT NETW COMMUN, V2018, DOI 10.1155/2018/4127487
   Salahuddin MA, 2017, COMPUTER, V50, P74, DOI 10.1109/MC.2017.195
   Scott-Hayward S, 2016, IEEE COMMUN SURV TUT, V18, P623, DOI 10.1109/COMST.2015.2453114
   Silva H, 2016, 2016 IEEE GLOB WORKS, P1, DOI [10.1109/GLOCOMW.2016.7848814, DOI 10.1109/GLOCOMW.2016.7848814]
   Singh KD, 2021, WIRELESS PERS COMMUN, V116, P3331, DOI 10.1007/s11277-020-07855-5
   Singh KD, 2020, COMPUT APPL ENG EDUC, V28, P692, DOI 10.1002/cae.22240
   Sisi Z, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4217
   Sood Sandeep K., 2021, Journal of Optical Communications, V42, P91, DOI 10.1515/joc-2018-0047
   Sultana N, 2019, PEER PEER NETW APPL, V12, P493, DOI 10.1007/s12083-017-0630-0
   Sultana R, 2021, VEH COMMUN, V27, DOI 10.1016/j.vehcom.2020.100284
   Sun LT, 2021, INTERNET TECHNOL LET, V4, DOI 10.1002/itl2.236
   Tadros CN, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P1200, DOI 10.1109/IEMCON.2018.8615087
   Tamizhselvan C, 2020, COMPUT COMMUN, V153, P632, DOI 10.1016/j.comcom.2020.02.029
   Tayyaba SK, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P48, DOI 10.1109/C-CODE.2017.7918900
   Theodorou T, 2020, IEEE ACCESS, V8, P103710, DOI 10.1109/ACCESS.2020.2999087
   Wang C, 2019, IEEE INTERNET THINGS, V6, P8692, DOI 10.1109/JIOT.2019.2922979
   Wang S, 2019, 2019 13TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS), DOI 10.1109/icspcs47537.2019.9008703
   Wrona K, 2017, MIL COMM INF SYST IC, P1, DOI [10.1109/ICMCIS.2017.7956483, DOI 10.1109/ICMCIS.2017.7956483]
   Wrona K, 2016, IEEE COMMUN MAG, V54, P138, DOI 10.1109/MCOM.2016.7588283
   Wrona K, 2015, IEEE MILIT COMMUN C, P1230, DOI 10.1109/MILCOM.2015.7357614
   Youngmi Lee, 2014, 2014 IEEE Military Communications Conference (MILCOM). Proceedings, P268, DOI 10.1109/MILCOM.2014.49
   Yurekten O, 2021, FUTURE GENER COMP SY, V115, P126, DOI 10.1016/j.future.2020.09.006
   Zacarias I, 2017, P 2017 IEEE 16 INT S, P1, DOI [10.1109/NCA.2017.8171390, DOI 10.1109/NCA.2017.8171390]
   Zacarias I, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/2354603
   Zhang XC, 2023, IEEE T SERV COMPUT, V16, P261, DOI 10.1109/TSC.2021.3106264
   Zhou XK, 2021, IEEE INTERNET THINGS, V8, P12588, DOI 10.1109/JIOT.2021.3077449
NR 103
TC 0
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11323
EP 11365
DI 10.1007/s11042-023-15729-8
EA JUN 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900001
DA 2024-07-18
ER

PT J
AU Sang, HF
   Chen, WX
   Wang, HF
   Wang, JY
AF Sang, Haifeng
   Chen, Wangxing
   Wang, Haifeng
   Wang, Jinyu
TI MSTCNN: multi-modal spatio-temporal convolutional neural network for
   pedestrian trajectory prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian trajectory prediction; Multi-modal spatio-temporal
   interaction; Pedestrian movement trend; Convolutional neural network
ID ATTENTION; MODEL
AB Pedestrian trajectory prediction is of great significance in correctly planning a reasonable path. Most of the existing trajectory prediction methods take all the surrounding pedestrians at once into account, inevitably causing redundant information. Besides, they mainly do not make full use of the pedestrian movement trend information. Therefore, a pedestrian trajectory prediction model was proposed in this study based on multi-modal spatio-temporal interaction. The model assigned different weights to different pedestrians in different situations through the multi-modal pedestrian spatial interaction module, so that model could markedly reduce the influence of redundant information. The model trend capture module designed in this research could collect the pedestrian movement trend information, increasing the accuracy of the pedestrian trajectory prediction model. Finally, the temporal convolutional network module was utilized to predict the parameters of the two-dimensional Gaussian distribution of future pedestrian trajectories. Experimental results showed that compared with the latest pedestrian trajectory prediction model, the final displacement error was reduced by 3% in the ETH and UCY datasets. It is noteworthy that the proposed model only used convolutional neural networks, and the number of model parameters was noticeably lower than that of previous models.
C1 [Sang, Haifeng; Chen, Wangxing; Wang, Haifeng; Wang, Jinyu] Shenyang Univ Technol, Sch Informat Sci & Engn, Shenyang 110870, Liaoning, Peoples R China.
C3 Shenyang University of Technology
RP Chen, WX (corresponding author), Shenyang Univ Technol, Sch Informat Sci & Engn, Shenyang 110870, Liaoning, Peoples R China.
EM sanghaif@163.com; 1909703861@qq.com; 798466420@qq.com; 1911131982@qq.com
RI WANG, Haifeng/F-1342-2016; Chen, Wangxing/JRX-5543-2023
OI Sang, Haifeng/0000-0002-1471-6101; Chen, WangXing/0000-0001-8716-7070
FU National Natural Science Foundation of China [62173078]; Natural Science
   Foundation of Liaoning Province [2022-MS-268]
FX AcknowledgmentsThis work was supported by the National Natural Science
   Foundation of China (62173078) and the Natural Science Foundation of
   Liaoning Province (2022-MS-268).
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Amirian J, 2019, IEEE COMPUT SOC CONF, P2964, DOI 10.1109/CVPRW.2019.00359
   Cunjun Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P507, DOI 10.1007/978-3-030-58610-2_30
   Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002
   Ferrer G, 2014, IEEE INT CONF ROBOT, P5940, DOI 10.1109/ICRA.2014.6907734
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Hao Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7414, DOI 10.1109/CVPR42600.2020.00744
   Hasan I, 2018, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2018.00635
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Huang YF, 2019, IEEE I CONF COMP VIS, P6281, DOI 10.1109/ICCV.2019.00637
   Ivanovic B, 2018, IEEE INT C INT ROBOT, P3088, DOI 10.1109/IROS.2018.8594393
   Ivanovic B, 2019, IEEE I CONF COMP VIS, P2375, DOI 10.1109/ICCV.2019.00246
   Kosaraju V, 2019, Advances in Neural Information Processing Systems, P32
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lian J, 2023, APPL INTELL, V53, P2862, DOI 10.1007/s10489-022-03524-1
   Lisotto M, 2019, 2019 IEEE CVF INT C
   Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493
   Mohamed Abduallah, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14412, DOI 10.1109/CVPR42600.2020.01443
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Shi LS, 2021, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR46437.2021.00888
   Wang CX, 2021, IEEE WINT CONF APPL, P3449, DOI 10.1109/WACV48630.2021.00349
   Xue H, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P307
   Xue H, 2020, IEEE ACCESS, V8, P44576, DOI 10.1109/ACCESS.2020.2977747
   Xue H, 2018, IEEE WINT CONF APPL, P1186, DOI 10.1109/WACV.2018.00135
   Zamboni S, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108252
   Zhang P, 2019, PROC CVPR IEEE, P12077, DOI 10.1109/CVPR.2019.01236
   Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675
   Zhao XD, 2020, IEEE-CAA J AUTOMATIC, V7, P965, DOI 10.1109/JAS.2020.1003228
   Zhong JQ, 2020, IEEE ACCESS, V8, P23480, DOI 10.1109/ACCESS.2020.2969994
   Zhou L, 2022, APPL INTELL, V52, P11434, DOI 10.1007/s10489-021-02997-w
   Zou XY, 2020, IEEE ACCESS, V8, P83321, DOI 10.1109/ACCESS.2020.2991435
NR 32
TC 2
Z9 2
U1 10
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8533
EP 8550
DI 10.1007/s11042-023-15989-4
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010006300002
DA 2024-07-18
ER

PT J
AU Periola, A
   Alonge, A
   Ogudo, K
AF Periola, Ayodele
   Alonge, Akintunde
   Ogudo, Kingsley
TI Future dynamic multimedia content access via aerial computing system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia content; Computing networks; Non-terrestrial systems; Data
   sovereignty; Content sharing
ID DATA SOVEREIGNTY; NETWORK; TV
AB Multimedia content access sovereignty arises due to the intention of producers to enable subscribers from pre-defined regions access multimedia content. This limits the number of locations (with subscribers) that can access producer content. Therefore, the ability to access multimedia content across previously unconsidered locations is limited. The presented research addresses this challenge and focuses on multimedia content sharing among subscribers in arid and hyper-arid regions. The use of stratosphere based data centres (SBDCs) is proposed. The paper also presents multi-tier network architecture for network traffic management. This ensures that network traffic congestion does not limit access to multimedia content by subscribers across multiple regions. The use of SBDCs increases the number of locations that engage in the sharing of multimedia content. Evaluation shows that the proposed solution increases the number of data sharing locations by (75.8 - 88.2) % on average.
C1 [Periola, Ayodele] Cape Peninsula Univ Technol, Elect Elect & Comp Engn, Cape Town, South Africa.
   [Alonge, Akintunde; Ogudo, Kingsley] Univ Johannesburg, Elect & Elect Engn Technol, Johannesburg, South Africa.
C3 Cape Peninsula University of Technology; University of Johannesburg
RP Periola, A (corresponding author), Cape Peninsula Univ Technol, Elect Elect & Comp Engn, Cape Town, South Africa.
EM periolaa@cput.ac.za; aalonge@uj.ac.za; kingsleyo@uj.ac.za
RI Alonge, Akintunde/GOP-0730-2022
OI Alonge, Akintunde/0000-0002-4319-7881
FU Cape Peninsula University of Technology
FX Funding Open access funding provided by Cape Peninsula University of
   Technology.
CR Ahmad BS, 2018, ADV INTELLIGENT SYST, V880, P241
   Ala'anzy M, 2019, IEEE ACCESS, V7, P141868, DOI 10.1109/ACCESS.2019.2944420
   Ali AT., 2020, INT J NETW MANAG, V30, P1
   Baresi L, 2020, IEEE 17TH INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2020), P103, DOI 10.1109/ICSA47634.2020.00018
   Bhardwaj K, 2019, INT CONF CLOUD ENG, P156, DOI 10.1109/IC2E.2019.00030
   Celeste E, 2021, DATA PRIVACY TRUST C, P43, DOI [10.1007/978-3-030-54660-1_3, DOI 10.1007/978-3-030-54660-1_3]
   Choi J, 2019, J NETW SYST MANAG, V27, P149, DOI 10.1007/s10922-018-9462-3
   Couture S, 2019, NEW MEDIA SOC, V21, P2305, DOI 10.1177/1461444819865984
   Esposito C, 2019, IEEE INTERNET THINGS, V6, P4521, DOI 10.1109/JIOT.2018.2886410
   Ferdousi S, 2020, IEEE T NETW SERV MAN, V17, P1501, DOI 10.1109/TNSM.2020.2983822
   Gelhaar J., 2021, P 54 HAWAII INT C SY, P6113, DOI DOI 10.24251/HICSS.2021.739
   Geronimo G, 2019, INT J NETW MANAG, V29, DOI 10.1002/nem.2085
   Hummel P, 2021, BIG DATA SOC, V8, DOI 10.1177/2053951720982012
   Jacquenet C, 2021, IEEE T NETW SERV MAN, V18, P1350, DOI 10.1109/TNSM.2021.3076293
   Jarke M, 2020, LECT NOTES COMPUT SC, V12127, P549, DOI 10.1007/978-3-030-49435-3_34
   Jarke M, 2019, BUS INFORM SYST ENG+, V61, P549, DOI 10.1007/s12599-019-00614-2
   Jing WP, 2021, J NETW SYST MANAG, V29, DOI 10.1007/s10922-020-09573-6
   Kodera K, 2019, ATMOS CHEM PHYS, V19, P2655, DOI 10.5194/acp-19-2655-2019
   Maenhaut PJ, 2020, J NETW SYST MANAG, V28, P197, DOI 10.1007/s10922-019-09504-0
   Manabe S, 2019, TELLUS A, V71, DOI 10.1080/16000870.2019.1620078
   Murschetz PC, 2018, CONTRIB MANAG SCI, P55, DOI 10.1007/978-3-319-71722-7_4
   Noam E, 2014, TELECOMMUN POLICY, V38, P684, DOI 10.1016/j.telpol.2013.10.004
   Otrum, CLOUD MAN CONTR SMAR
   Periola AA, 2021, MULTIMEDIA SYST, V27, P1125, DOI 10.1007/s00530-021-00789-3
   Periola AA., 2020, P NIGER ACAD SCI, V13, P79
   Periola AA., 2020, Aerosp Syst, V3, P327, DOI [10.1007/s42401-020-00064-9, DOI 10.1007/S42401-020-00064-9]
   Periola AA, 2022, INTELLIGENT SCHEDULI, P1
   Peterson ZNJ, 2011, P 3 USENIX C HOT TOP, P9
   Pohle Julia, 2020, INTERNET POLICY REV, V9, DOI DOI 10.14763/2020.4.1532
   Popescul D., 2018, INT AC C SOC SCI PRA, V10
   Reznik Y, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020503
   Ruiz MC., 2017, INT C INF INT SYST A, V27-30, P1, DOI [10.1109/IISA.2017.8316364, DOI 10.1109/IISA.2017.8316364]
   Schauerte R, 2021, J CULT ECON, V45, P263, DOI 10.1007/s10824-020-09389-x
   Sebrechts M, 2018, INT J NETW MANAG, V28, DOI 10.1002/nem.2036
   Sharma V, 2019, IEEE ACCESS, V7, P13867, DOI 10.1109/ACCESS.2019.2893775
   Taherkordi A, 2018, IEEE ACCESS, V6, P74120, DOI 10.1109/ACCESS.2018.2883149
   Tang CL, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-00664-y
   Udoakpan N., 2020, Journal of open innovation: technology, market, and complexity, V6, P1
   Yang Y, 2016, CLIM DYNAM, V47, P3767, DOI 10.1007/s00382-016-3040-8
NR 39
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6975
EP 6999
DI 10.1007/s11042-023-15632-2
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700009
OA hybrid
DA 2024-07-18
ER

PT J
AU Kumar, R
   Maheshwari, S
   Sharma, A
   Linda, S
   Kumar, S
   Chatterjee, I
AF Kumar, Ranjan
   Maheshwari, Sajal
   Sharma, Anushka
   Linda, Sonal
   Kumar, Subhash
   Chatterjee, Indranath
TI y Ensemble learning-based early detection of influenza disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Biomedical data analysis; Computer-aided diagnosis (CAD); Early
   detection; Ensemble learning; Influenza; Machine learning
AB Across the world, the seasonal disease influenza is a respiratory illness that impacts all age groups in many ways. Its symptoms are fever, chills, aches, pains, headaches, fatigue, cough, and weakness. Seasonal influenza can cause mild to severe illness and lead to death at times. The task of early detection of influenza is an important research area these days. Various studies show that machine learning techniques have attracted many researchers' attention to the early detection of influenza disease. In this paper, early detection of Influenza disease among all age groups is done using various machine learning techniques. Influenza Research Database and the Human Surveillance Records data sets are used. Data analysis is undertaken, and ensemble-based stacked algorithms are implemented on the whole data set. The performance of different models has been evaluated using different performance metrics. Overall, the study proposes efficient machine learning models that can be implemented to provide a cheaper and quicker diagnostic tool for detecting influenza.
C1 [Kumar, Ranjan; Maheshwari, Sajal; Sharma, Anushka; Linda, Sonal] Univ Delhi, Aryabhatta Coll, Dept Comp Sci, Delhi 110021, India.
   [Kumar, Subhash] Univ Delhi, Acharya Narendra Dev Coll, Dept Phys, Delhi 110019, India.
   [Chatterjee, Indranath] Tongmyong Univ, Dept Comp Engn, Busan 48520, South Korea.
   [Chatterjee, Indranath] Woxsen Univ, Sch Technol, Hyderabad 500033, Telangana, India.
C3 University of Delhi; University of Delhi; Tongmyong University
RP Kumar, R (corresponding author), Univ Delhi, Aryabhatta Coll, Dept Comp Sci, Delhi 110021, India.
EM ranjan301@gmail.com
RI Kumar, Ranjan/CAG-4388-2022; Chatterjee, Indranath/GRO-4311-2022
OI Chatterjee, Indranath/0000-0001-9242-8888
CR Alballa Norah, 2021, Inform Med Unlocked, V24, P100564, DOI 10.1016/j.imu.2021.100564
   Ali F, 2020, INFORM FUSION, V63, P208, DOI 10.1016/j.inffus.2020.06.008
   [Anonymous], United States of America
   Banning Maggi, 2005, Br J Nurs, V14, P1192
   Blümel J, 2009, TRANSFUS MED HEMOTH, V36, P32, DOI 10.1159/000197314
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cheong CW, 2021, BMC INFECT DIS, V21, DOI 10.1186/s12879-021-06169-6
   Dewangan KK, 2022, MULTIMED TOOLS APPL, V81, P13935, DOI 10.1007/s11042-022-12385-2
   Harimoorthy K, 2021, J AMB INTEL HUM COMP, V12, P3715, DOI 10.1007/s12652-019-01652-0
   Khan MA, 2021, CMC-COMPUT MATER CON, V66, P331, DOI 10.32604/cmc.2020.012148
   Larose Daniel T., 2014, Discovering Knowledge in Data: An Introduction to Data Mining, P149, DOI [10.1002/9781118874059.ch7, DOI 10.1002/9781118874059.CH7, 10.1002/9781118874059.CH7, DOI 10.1002/0471687545.CH5]
   Lu HH, 2022, APPL INTELL, V52, P2411, DOI 10.1007/s10489-021-02533-w
   Izquierdo JL, 2020, J MED INTERNET RES, V22, DOI 10.2196/21801
   Marquez E, 2019, IEEE INT AUT MEET, DOI 10.1109/ropec48299.2019.9057056
   Moon J, 2021, CMC-COMPUT MATER CON, V68, P2945, DOI 10.32604/cmc.2021.017435
   Muhammad L J, 2021, SN Comput Sci, V2, P11, DOI 10.1007/s42979-020-00394-7
   Munoz Flor M, 2002, Semin Pediatr Infect Dis, V13, P72, DOI 10.1053/spid.2002.122992
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Osamor VC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94347-6
   Park DJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87171-5
   Pineda AL, 2015, J BIOMED INFORM, V58, P60, DOI 10.1016/j.jbi.2015.08.019
   Platt J., 1998, Advances in Kernel Methods-Support Vector Learning
   Webster RG, 2000, VACCINE, V18, P1686, DOI 10.1016/S0264-410X(99)00507-1
   Xiao RY, 2021, MULTIMED TOOLS APPL, V80, P3969, DOI 10.1007/s11042-020-09738-0
   Yanamala N, 2021, NPJ DIGIT MED, V4, DOI [10.1038/s41746-021-00467-8, 10.1101/2021.01.13.21249540]
   Yousif AY, 2022, INT J INNOV COMPUT I, V18, P57, DOI 10.24507/ijicic.18.01.57
   Zhang Y, 2017, NUCLEIC ACIDS RES, V45, pD466, DOI 10.1093/nar/gkw857
   Zhao Y., 2013, R DATA MINING EXAMPL, P41, DOI [10.1016/B978-0-12-396963-7.00005-2, DOI 10.1016/B978-0-12-396963-7.00005-2]
NR 28
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15848-2
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400010
PM 37362719
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Manjunath, RV
   Ghanshala, A
   Kwadiki, K
AF Manjunath, R. V.
   Ghanshala, Anshul
   Kwadiki, Karibasappa
TI Deep learning algorithm performance evaluation in detection and
   classification of liver disease using CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computed tomography; Deep learning; Metastasis; Carcinoma;
   Cholangiocarcinoma; Labelled images; Unet
AB To diagnose the liver diseases computed tomography images are used. Most of the time even experienced radiologists find it very tough to note the type, size, and severity of the tumor from computed tomography images due to various complexities involved around the liver. In recent years it is very much essential to develop a computer-assisted imaging technique to diagnose liver disease in turn which improves the diagnosis of a doctor. This paper explains a novel deep learning model for detecting a liver disease tumor and its classification. Tumor from computed tomography images has been classified between Metastasis and Cholangiocarcinoma. We demonstrate that our model predominantly performs very well concerning the accuracy, dice similarity coefficient, and specificity parameters compared to well-known existing algorithms, and adapts very well for different datasets. A dice similarity coefficient value of 98.59% indicates the supremacy of the model.
C1 [Manjunath, R. V.] Dayananda Sagar Acad Technol & Management, Dept Elect & Commun Engn, Bangalore 82, India.
   [Ghanshala, Anshul] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Kwadiki, Karibasappa] Graph Era Deemed Be Univ, Dept CS&IT, Dehra Dun 248002, India.
C3 Chinese University of Hong Kong; Graphic Era University
RP Manjunath, RV (corresponding author), Dayananda Sagar Acad Technol & Management, Dept Elect & Commun Engn, Bangalore 82, India.
EM manjunathrv@dsatm.edu.in; anshulghanshala123@gmail.com;
   KwadikiKaribasappa.cse@geu.ac.in
OI R V, Manjunath/0000-0003-4010-0850
CR Ahmad M, 2019, IEEE ACCESS, V7, P20585, DOI 10.1109/ACCESS.2019.2896961
   Balagourouchetty L, 2020, IEEE J BIOMED HEALTH, V24, P1686, DOI 10.1109/JBHI.2019.2942774
   Bevilacqua V, 2017, IEEE C EVOL COMPUTAT, P1856, DOI 10.1109/CEC.2017.7969527
   Bharti P, 2018, ULTRASONIC IMAGING, V40, P357, DOI 10.1177/0161734618787447
   cancer, MET CANC
   Chen DH, 2021, IEEE ACM T COMPUT BI, V18, P891, DOI 10.1109/TCBB.2019.2955484
   Das A, 2019, PATTERN RECOGN IMAGE, V29, P201, DOI 10.1134/S1054661819020056
   Das A, 2019, COGN SYST RES, V54, P165, DOI 10.1016/j.cogsys.2018.12.009
   Phan DV, 2020, INT J CANCER, V147, P2871, DOI 10.1002/ijc.33245
   Gaber A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010521
   Gatos I, 2017, ULTRASOUND MED BIOL, V43, P1797, DOI 10.1016/j.ultrasmedbio.2017.05.002
   Gogate M., 2020, P 2020 INT JOINT C N, P1
   healthline, LIV MET
   Hosseinzadeh M, 2021, MULTIMED TOOLS APPL, V80, P16933, DOI 10.1007/s11042-020-09049-4
   Iraji MS, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/9973277
   Jacob J, 2018, INT RES J ENG TECHNO, V5
   Jaganathan K, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22158073
   Joloudari Javad Hassannataj, 2019, Informatics in Medicine Unlocked, V17, DOI 10.1016/j.imu.2019.100255
   Khan RA, 2022, NEUROCOMPUTING, V468, P492, DOI 10.1016/j.neucom.2021.08.138
   Krishan A, 2021, P I MECH ENG H, V235, P232, DOI 10.1177/0954411920971888
   Miriam E, 2013, TUCK LIV M 2013 AM A
   Mostafa F, 2021, LIVERS-BASEL, V1, P294, DOI 10.3390/livers1040023
   Muthuswamy Jayanthi, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 713), P269, DOI 10.1007/978-981-13-1708-8_25
   radiopaedia, CHOL CANC
   Rahmani AM, 2021, CLUSTER COMPUT, V24, P1347, DOI 10.1007/s10586-020-03189-w
   Rajathi GI, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010033
   Renukadevi NT, 2021, ADV SOFT COMPUTING T, V89, DOI [10.1007/978-3-030-75657-4_12, DOI 10.1007/978-3-030-75657-4_12]
   Maghdid HS, 2020, Arxiv, DOI [arXiv:2004.00038, 10.48550/ARXIV.2004.00038]
   Sung YS, 2021, J GASTROEN HEPATOL, V36, P561, DOI 10.1111/jgh.15414
   Yamakawa M, 2019, IEEE INT ULTRA SYM, P2330, DOI [10.1109/ULTSYM.2019.8925698, 10.1109/ultsym.2019.8925698]
   Zhang T, 2021, FRONT CELL INFECT MI, V11, DOI 10.3389/fcimb.2021.751795
NR 31
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15627-z
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700005
PM 37362702
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Allwadhi, S
   Joshi, K
   Yadav, AK
   Nandal, R
AF Allwadhi, Sachin
   Joshi, Kamaldeep
   Yadav, Ashok Kumar
   Nandal, Rainu
TI A new data hiding model based on adaptive keyed Huffman multi-layer
   midpoint folding and optimized deep wavelet histogram modification
   strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Huffman encoding; Multi-layer midpoint folding strategy;
   Multiple histograms; Cover image; Deep wavelet neural network;
   Equilibrium optimization
ID REGRESSION
AB With recent advanced science and technology, it is much easier to transmit, search and find information on the Internet platform. However, sharing secret data on the Internet is challenging because of the increased number of unauthorized users. Thus, the proposed work introduces a new data-hiding model to enhance the payload capacity with higher security. Initially, the secret image is transformed into binary form, and then four consecutive binary bits are considered to obtain a sequence of decimal values. This work proposes a new adaptive keyed Huffman multi-layer midpoint folding strategy (aKH-MMF) method to minimize the embedded data size. This method uses the Huffman encoding scheme to encode the secret data with a secret key. Additionally, a multi-layer midpoint folding approach is introduced to minimize distortion during the embedding process. The proposed aKH-MMF method finds out an index for each encoded bit. These encoded bits are embedded in the cover image using an Equilibrium-optimized 2D mapping scheme. This scheme utilizes a DeepWave-Hist model (deep wavelet neural network) to generate multiple histograms for the cover images. After the generation of histograms, an optimal mapping scheme is selected for all histograms using the Equilibrium optimization (EO) approach. Finally, the encoded index is embedded into the cover image with the help of a Least Significant Method (LSB). The experimental setup is done using MATLAB software, and the proposed data-hiding model is processed through the MISC dataset. The simulation results show that the proposed model obtains better results in improved payload capacity as 2262.1155 bpp for the images like Lena, Tiffany and Airplane. Also, the attained PSNR of Lena is 57.27 dB, Tiffany is 58 dB, and Airplane is 56.48 dB. Compared with other existing data-hiding models, the results achieved for the proposed study are highly superior.
C1 [Allwadhi, Sachin; Joshi, Kamaldeep; Nandal, Rainu] Maharshi Dayanand Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Rohtak 124001, Haryana, India.
   [Yadav, Ashok Kumar] Amity Univ, Amity Sch Engn & Technol, Noida 201301, Uttar Pradesh, India.
C3 Maharshi Dayanand University; Amity University Noida
RP Joshi, K (corresponding author), Maharshi Dayanand Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Rohtak 124001, Haryana, India.
EM kduiet@mdurohtak.ac.in
RI Yadav, Ashok Kumar/P-6865-2016
OI Yadav, Ashok Kumar/0000-0003-1054-4442; , SACHIN
   ALLWADHI/0009-0002-8353-6582; Joshi, kamaldeep/0000-0002-3238-0234
CR AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Akhtarkavan E, 2020, MULTIMED TOOLS APPL, V79, P13427, DOI 10.1007/s11042-020-08662-7
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Chen CC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103060
   Chen YQ, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102584
   Garg P, 2020, J DISCRET MATH SCI C, V23, P177, DOI 10.1080/09720529.2020.1721882
   He B, 2022, INT J DISTRIB SENS N, V18, DOI 10.1177/15501329221084226
   Hou JC, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116118
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Ke Y, 2020, IEEE T CIRC SYST VID, V30, P2353, DOI 10.1109/TCSVT.2019.2963393
   Khan AA, 2022, IET IMAGE PROCESS, V16, P2854, DOI 10.1049/ipr2.12272
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Li N, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107476
   Lu JC, 2019, IEEE ACCESS, V7, P21702, DOI 10.1109/ACCESS.2019.2896781
   Ma B, 2019, J REAL-TIME IMAGE PR, V16, P821, DOI 10.1007/s11554-019-00891-w
   Ma SM, 2022, IEEE SIGNAL PROC LET, V29, P662, DOI 10.1109/LSP.2022.3149706
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Meenpal A, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01828-z
   Meikap S, 2021, MULTIMED TOOLS APPL, V80, P5617, DOI 10.1007/s11042-020-09823-4
   Nashat D., 2019, J. Egypt. Math. Soc., V27, P1, DOI [10.1186/s42787-019-0061-6, DOI 10.1186/S42787-019-0061-6]
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Sahila K. M., 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P805, DOI 10.1007/978-981-15-9509-7_65
   Sehra K, 2021, IEEE ACCESS, V9, P72465, DOI 10.1109/ACCESS.2021.3079319
   Shafiq M, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8864301
   Shaji C., 2021, IEEE T GEOSCI REMOTE, P83, DOI [10.1007/978-981-16-2248-9_9, DOI 10.1007/978-981-16-2248-9_9]
   Shastri S, 2019, J VIS COMMUN IMAGE R, V61, P130, DOI 10.1016/j.jvcir.2019.03.022
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang X, 2021, INFORM SCIENCES, V567, P375, DOI 10.1016/j.ins.2021.02.079
   Zhao J, 2018, MULTIMEDIA SYST, V24, P95, DOI 10.1007/s00530-016-0529-2
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47189
EP 47214
DI 10.1007/s11042-023-15390-1
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000981387900005
DA 2024-07-18
ER

PT J
AU Tang, R
   Lu, GF
AF Tang, Rong
   Lu, Gui-Fu
TI Multi-view subspace similarity learning based on t-SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view clustering; Similarity learning; t-SVD; Tensor nuclear norm;
   Kernel trick; Nonlinear information
AB Multi-view clustering is extensively applied to practical applications. The similarity matrix acquired by most of the existing approaches is obtained by using original multi-view data. However, when dealing with data in a nonlinear subspace, the results of existing methods are not satisfactory. In addition, the existing methods cannot solve the high order relevance of multi-view data. To solve these problems, we present a novel multi-view subspace similarity learning method, MSSLt-SVD, on the basis of tensor singular value decomposition (t-SVD). First, we map each view of the data to the Hilbert space through a Gaussian kernel and then minimize the reconstruction error of the obtained kernel matrix. Second, we use the t-SVD-based tensor nuclear norm (TNN) instead of the matrix-kernel norm as the regularization term to capture the high-order relevance of multi-view data. Then, we incorporate these two steps into a framework and design the corresponding goal function, which can be solved by using the augmented lagrange multiplier (ALM) method. Experiments on some datasets show that the performance of MSSLt-SVD algorithm is better than some representative ones.
C1 [Tang, Rong] AnHui Polytech Univ, Sch Elect Engn, Wuhu 241000, Anhui, Peoples R China.
   [Lu, Gui-Fu] AnHui Polytech Univ, Sch Comp Sci & Informat, Wuhu 241000, Anhui, Peoples R China.
C3 Anhui Polytechnic University; Anhui Polytechnic University
RP Lu, GF (corresponding author), AnHui Polytech Univ, Sch Comp Sci & Informat, Wuhu 241000, Anhui, Peoples R China.
EM lu-guifu@ahpu.edu.cn
OI tang, rong/0000-0002-0339-7192
FU NSFC [61976005]; Anhui Natural Science Foundation [1908085MF183];
   Safety-Critical Software Key Laboratory Research Program [NJ2018014];
   Training Program for Young and Middle-aged Top Talents of Anhui
   Polytechnic University [201812]; State Key Laboratory for Novel Software
   Technology (Nanjing University) Research Program [KFKT2019B23]; Major
   Project of Natural Science Research in Colleges and Universities of
   Anhui Province [KJ2019ZD15]
FX This research is supported by the NSFC (No. 61976005); the Anhui Natural
   Science Foundation (No. 1908085MF183); the Safety-Critical Software Key
   Laboratory Research Program (Grant No. NJ2018014); the Training Program
   for Young and Middle-aged Top Talents of Anhui Polytechnic University
   (No. 201812); the State Key Laboratory for Novel Software Technology
   (Nanjing University) Research Program (No. KFKT2019B23); and the Major
   Project of Natural Science Research in Colleges and Universities of
   Anhui Province (No. KJ2019ZD15).
CR Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   CAO XC, 2015, PROC CVPR IEEE, P586, DOI DOI 10.1109/CVPR.2015.7298657
   Chao Guoqing, 2021, IEEE Trans Artif Intell, V2, P146, DOI 10.1109/tai.2021.3065894
   Diwakar Manoj, 2020, International Journal of Information and Computer Security, V12, P234
   Diwakar Manoj, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P343, DOI 10.1007/978-981-13-0589-4_32
   Diwakar M, 2019, HDB MULTIMEDIA INFOR, P501, DOI DOI 10.1007/978-3-030-15887-3_24
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Diwakar M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P160, DOI 10.1109/ICIIP.2013.6707574
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Ershad S. F., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P367, DOI 10.1109/ICCSN.2011.6014289
   Gao QX, 2020, NEURAL NETWORKS, V126, P335, DOI 10.1016/j.neunet.2020.03.020
   Guo X., 2017, Identification of cyst nematode B-type CLE peptides and modulation of the vascular stem cell pathway for feeding cell formation, DOI [DOI 10.1371/JOURNAL.PPAT.1006142, 10.1371/journal.ppat.1006142, 10.1109/CISP-BMEI.2017.8301926]
   Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005
   Kang Z, 2019, AAAI CONF ARTIF INTE, P4057
   Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020
   Kumar P., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P816, DOI 10.1109/WICT.2011.6141352
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lu GF, 2022, APPL INTELL, V52, P6539, DOI 10.1007/s10489-021-02710-x
   Ren ZW, 2021, IEEE T CYBERNETICS, V51, P3273, DOI 10.1109/TCYB.2020.3000947
   Sharma P, 2013, C ADV COMMUNICATION, P363
   Wang CD, 2021, IEEE T NEUR NET LEAR, V32, P5047, DOI 10.1109/TNNLS.2020.3026686
   Xia W, 2022, IEEE T CYBERNETICS, V52, P8962, DOI 10.1109/TCYB.2021.3052352
   Xie DY, 2020, NEUROCOMPUTING, V380, P105, DOI 10.1016/j.neucom.2019.11.014
   Xie DY, 2020, IEEE T CYBERNETICS, V50, P4848, DOI 10.1109/TCYB.2019.2922042
   Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2
   Zhan K, 2019, IEEE T KNOWL DATA EN, V31, P1984, DOI 10.1109/TKDE.2018.2872061
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang GY, 2022, APPL INTELL, V52, P716, DOI 10.1007/s10489-021-02365-8
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhou T, 2020, IEEE T CYBERNETICS, V50, P1655, DOI 10.1109/TCYB.2018.2883673
NR 35
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45605
EP 45620
DI 10.1007/s11042-023-15645-x
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900012
DA 2024-07-18
ER

PT J
AU Yang, G
   Chen, SP
AF Yang, Ge
   Chen, Siping
TI Visual detection and tracking algorithms for human motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Pedestrian tracking; Particle filter; Robustness
AB In dense scenes, a large number of individuals can introduce serious complications for motion detection, such as blurred vision, chaotic scenes, and complex behaviours. For low-density pedestrian detection and tracking algorithms, the accuracy is greatly reduced for both detection and tracking. High-density detection or tracking fails too when these problems are encountered in high-density scenes. In light of the above problems, a detection algorithm and a tracking algorithm based on the human head and shoulder model are proposed. A support vector machine is used to train the classifier by machine learning. The detection algorithm proposed in this paper achieves a detection accuracy of 94% by using the MIT and INRIA datasets. The average accuracy of pedestrian tracking in high-density scenes is approximately 95%.
C1 [Yang, Ge; Chen, Siping] Beijing Normal Univ, Res Ctr Intelligent Engn & Educ Applicat, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.
C3 Beijing Normal University
RP Yang, G (corresponding author), Beijing Normal Univ, Res Ctr Intelligent Engn & Educ Applicat, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.
EM yangge@pkusz.edu.cn
FU Major Scientific Research Project for Universities of Guangdong Province
   [2020ZDZX3058]; Guangdong Provincial Special Funds Project for
   Discipline Construction [2013 WYXM0122]; Science and Technology Projects
   of Zhuhai in the Field of Social Development [2220004000066]; Key
   Laboratory of Intelligent Multimedia Technology [201762005]
FX This research was financially supported by the Major Scientific Research
   Project for Universities of Guangdong Province (2020ZDZX3058); Guangdong
   Provincial Special Funds Project for Discipline Construction (No. 2013
   WYXM0122); Science and Technology Projects of Zhuhai in the Field of
   Social Development (2220004000066); Key Laboratory of Intelligent
   Multimedia Technology (201762005)
CR [Anonymous], 2022, MIT PED DAT
   [Anonymous], 2022, INRIA PERSON DATASET
   Bilal M, 2020, IEEE T INTELL TRANSP, V21, P1277, DOI 10.1109/TITS.2019.2906132
   Chen K, 2019, IEEE ACCESS, V7, P26060, DOI 10.1109/ACCESS.2019.2900296
   Chu YD, 2020, IEEE T NEUR NET LEAR, V31, P1297, DOI 10.1109/TNNLS.2019.2919676
   Hasan I, 2021, IEEE T PATTERN ANAL, V43, P1267, DOI 10.1109/TPAMI.2019.2949414
   Hasan I, 2018, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2018.00635
   Kim JU, 2022, IEEE T CIRC SYST VID, V32, P1510, DOI 10.1109/TCSVT.2021.3076466
   Lee HS, 2022, IEEE ACCESS, V10, P15968, DOI 10.1109/ACCESS.2022.3146645
   Leng JX, 2020, IEEE T INTELL TRANSP, V21, P1560, DOI 10.1109/TITS.2019.2909275
   Li SS, 2021, IEEE T CONSUM ELECTR, V67, P129, DOI 10.1109/TCE.2021.3077241
   Li T, 2020, IEEE T VEH TECHNOL, V69, P9330, DOI 10.1109/TVT.2020.2976958
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Qin Z, 2016, IEEE T PATTERN ANAL, V38, P2082, DOI 10.1109/TPAMI.2015.2505292
   Radman A, 2018, MULTIMED TOOLS APPL, V77, P25311, DOI 10.1007/s11042-018-5786-y
   Sanberg WP, 2021, IEEE T INTELL VEHICL, V6, P34, DOI 10.1109/TIV.2020.2992086
   Sun ZH, 2021, IEEE T CIRC SYST VID, V31, P1819, DOI 10.1109/TCSVT.2020.3009717
   Sundararaman R, 2021, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR46437.2021.00386
   Zhang GK, 2021, IEEE J-STARS, V14, P9530, DOI 10.1109/JSTARS.2021.3109661
   Zhang J, 2021, IEEE T IMAGE PROCESS, V30, P9058, DOI 10.1109/TIP.2021.3122102
NR 20
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47165
EP 47188
DI 10.1007/s11042-023-15231-1
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000981387900003
DA 2024-07-18
ER

PT J
AU Sultana, A
   Dey, SK
   Rahman, MA
AF Sultana, Aziza
   Dey, Samrat Kumar
   Rahman, Md. Armanur
TI Facial emotion recognition based on deep transfer learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; VGG19; CK plus; JAFFE; Emotion recognition
ID FACE
AB Facial expressions play a major role in the communication of emotions through nonverbal channels. In recent years, the topic of automatic facial expression recognition (FER) has become very popular. Researchers are looking at how it may be used in education, security surveillance, smart healthcare system, and to understand the behavior of a community or a person. As long as there are variations in images, such as different poses and lighting, accurate and robust FER remains a challenge using computer models. We developed an approach to automatically classifying facial expressions based on deep transfer learning. The approach was constructed with convolutional neural networks (CNN) and VGG19, which is a transfer learning model. To train the model, we employed contemporary deep learning techniques such as optimal learning rate finder, fine-tuning, and data augmentation. On both the Extended Cohn-Kanade (CK+) and the Japanese Female Facial Expression (JAFFE) datasets, the proposed model achieved accuracy values of 94.8% and 93.7%, respectively. The developed system has already been tested on a vast database and can be used to assist online education systems, surveillance systems, and smart healthcare systems in their daily activities.
C1 [Sultana, Aziza] Dhaka Int Univ DIU, Dept Comp Sci & Engn CSE, Dhaka 1205, Bangladesh.
   [Dey, Samrat Kumar] Bangladesh Open Univ BOU, Sch Sci & Technol SST, Gazipur 1705, Bangladesh.
   [Rahman, Md. Armanur] Multimedia Univ, Fac Engn & Technol, Melaka, Malaysia.
C3 Multimedia University
RP Dey, SK (corresponding author), Bangladesh Open Univ BOU, Sch Sci & Technol SST, Gazipur 1705, Bangladesh.
EM azizaantora@gmail.com; samrat.sst@bou.ac.bd; arman.bdmail@gmail.com
RI Dey, Samrat Kumar/AAD-9005-2019
OI Dey, Samrat Kumar/0000-0002-7999-8576
CR Abdulrahman M, 2015, SIG PROCESS COMMUN, P276, DOI 10.1109/SIU.2015.7129813
   Abidin Z, 2012, INT J COMPUT APPL, V59
   Agarwal S, 2019, IEEE T MULTIMEDIA, V21, P902, DOI 10.1109/TMM.2018.2871417
   [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], 2019, HDB RES DEEP LEARNIN
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Erickson BJ, 2018, J AM COLL RADIOL, V15, P521, DOI 10.1016/j.jacr.2017.12.027
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Khorrami P, 2016, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2016.7532431
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li M, 2021, IEEE T AFFECT COMPUT, V12, P544, DOI 10.1109/TAFFC.2018.2880201
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Pramerdorfer C, 2016, Arxiv, DOI arXiv:1612.02903
   Raghuvanshi A., 2016, CS231n Course Projects
   Rao P, 2019, J HOMEPAGE, V6, P64
   Rifai S, 2012, LECT NOTES COMPUT SC, V7577, P808, DOI 10.1007/978-3-642-33783-3_58
   Sharma S, 2022, ARCH COMPUT METHOD E, V29, P3475, DOI 10.1007/s11831-021-09705-4
   Sharma S, 2021, IET BIOMETRICS, V10, P87, DOI 10.1049/bme2.12005
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P26517, DOI 10.1007/s11042-020-09331-5
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P17303, DOI 10.1007/s11042-020-08688-x
   Tan Lianzhi., 2017, P 19 ACM INT C MULT, P549
   Le QV, 2015, Arxiv, DOI arXiv:1504.00941
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
NR 37
TC 1
Z9 1
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44175
EP 44189
DI 10.1007/s11042-023-15570-z
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979963000006
DA 2024-07-18
ER

PT J
AU Zhang, JJ
   Huang, FY
   Chen, YC
   Hao, J
   Chen, YD
AF Zhang, Jianjun
   Huang, Fuyu
   Chen, Yichao
   Hao, Jing
   Chen, Yudan
TI Forward-looking omnidirectional infrared pedestrian detection for driver
   assistance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Infrared; Forward-looking omnidirectional;
   Day-night situation awareness; Driver assistance
ID IMAGE SEGMENTATION; NEURAL-NETWORK; OPTIMIZATION
AB To improve the intelligent driving abilities about the day-night situation awareness and large airspace real-time acquisition, we employ a forward-looking omnidirectional infrared (FLOIR) system and propose a FLOIR pedestrian detection strategy which consists of off-line training and on-line identification. Firstly, the basic scheme of proposed strategy is given generally, and the thoughts of off-line training and on-line identification are introduced briefly. Secondly, the principle of off-line training is illustrated in detail, in which the EHOG describer is created to extract the pedestrian feature and the FART neural network is modified to train the samples. Thirdly, the on-line identification principle is described, integrated with the proposed methods of ROI segmentation, distortion correction, feature extraction and matching. Finally, to verify the adaptability of FLOIR pedestrian detection relative to the climates, the summer and winter experiments, the contrast experiment with deep learning method and the multi-scale pedestrian detection experiment are carried out. The results show that: the proposed strategy has better robustness and detection effect than the traditional methods of FART, ARTMAP and deep learning, and the all-weather accuracy of infrared pedestrian detection is more than 83%. In the next work, the infrared pedestrian database will be improved to further increase the detection accuracy.
C1 [Zhang, Jianjun; Huang, Fuyu; Hao, Jing; Chen, Yudan] Army Engn Univ PLA, Shijiazhuang Campus, Shijiazhuang 050003, Peoples R China.
   [Zhang, Jianjun] 54th Res Inst China Elect Technol Grp Corp, Shijiazhuang 050081, Peoples R China.
   [Chen, Yichao] Chinese Peoples Armed Police Force Res Inst, Beijing 100081, Peoples R China.
   [Hao, Jing] Hebei Univ Econ & Business, Shijiazhuang 050003, Peoples R China.
C3 Army Engineering University of PLA; China Electronics Technology Group;
   Hebei University of Economics & Business
RP Huang, FY (corresponding author), Army Engn Univ PLA, Shijiazhuang Campus, Shijiazhuang 050003, Peoples R China.
EM hfyoptics@163.com
FU National Natural Science Foundation of China [62171467]; Natural Science
   Foundation of Hebei Province [F2021506004]
FX This research was funded by the National Natural Science Foundation of
   China (grant number 62171467) and the Natural Science Foundation of
   Hebei Province (grant number F2021506004).
CR Arifin AZ, 2006, PATTERN RECOGN LETT, V27, P1515, DOI 10.1016/j.patrec.2006.02.022
   Bai XZ, 2018, IEEE T FUZZY SYST, V26, P1946, DOI 10.1109/TFUZZ.2017.2756827
   Biswas SK, 2017, IEEE T IMAGE PROCESS, V26, P4229, DOI 10.1109/TIP.2017.2705426
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Cai L, 2018, J FRANKLIN I, V355, P1991, DOI 10.1016/j.jfranklin.2017.09.003
   Chen ZJ, 2021, IEEE T VLSI SYST, V29, P1095, DOI 10.1109/TVLSI.2021.3069221
   Cheng YH, 2022, IEEE GEOSCI REMOTE S, V19, DOI [10.1109/LGRS.2022.3200110, 10.1109/LGRS.2020.3047524]
   Dai XB, 2019, INFRARED PHYS TECHN, V97, P25, DOI 10.1016/j.infrared.2018.11.028
   Ding M, 2023, IEEE T INTELL VEHICL, V8, P814, DOI 10.1109/TIV.2022.3140344
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ganguly B, 2022, IEEE T INTELL TRANSP, V23, P19042, DOI 10.1109/TITS.2022.3164847
   [郝帅 Hao Shuai], 2022, [光学精密工程, Optics and Precision Engineering], V30, P2390
   Helali A, 2020, NEURAL COMPUT APPL, V32, P12859, DOI 10.1007/s00521-020-04731-y
   Huang CY, 2021, ALEX ENG J, V60, P183, DOI 10.1016/j.aej.2020.06.054
   Huang FY, 2013, OPT LETT, V38, P1392, DOI 10.1364/OL.38.001392
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P27867, DOI 10.1007/s11042-021-10811-5
   Kim T, 2018, PATTERN RECOGN, V79, P44, DOI 10.1016/j.patcog.2018.01.029
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Lee YS, 2015, IEEE T INTELL TRANSP, V16, P1929, DOI 10.1109/TITS.2014.2385707
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li L, 2018, IEEE T INTELL TRANSP, V19, P2826, DOI 10.1109/TITS.2017.2761901
   Lin YC, 2022, IEEE ACCESS, V10, P105214, DOI 10.1109/ACCESS.2022.3211267
   Liu Q, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/7/074022
   [罗艳 Luo Yan], 2022, [中国图象图形学报, Journal of Image and Graphics], V27, P2094
   Ma M, 2020, MULTIMED TOOLS APPL, V79, P9267, DOI 10.1007/s11042-019-7444-4
   Manda MP, 2020, INT SOC DESIGN CONF, P278, DOI 10.1109/ISOCC50952.2020.9332804
   Qi B, 2016, INFRARED PHYS TECHN, V76, P157, DOI 10.1016/j.infrared.2016.02.004
   Wang WX, 2021, PATTERN RECOGN IMAGE, V31, P821, DOI 10.1134/S1054661821040271
   Wang XB, 2019, IEEE T INTELL VEHICL, V4, P519, DOI 10.1109/TIV.2019.2938092
   Wang YF, 2019, IEEE T INTELL TRANSP, V20, P3361, DOI 10.1109/TITS.2018.2875159
   Wang ZW, 2022, MULTIMED TOOLS APPL, V81, P39655, DOI 10.1007/s11042-022-13058-w
   Wu DM, 2022, MULTIMED TOOLS APPL, V81, P33513, DOI 10.1007/s11042-022-13073-x
   Yu XH, 2016, J INF SECUR APPL, V31, P54, DOI 10.1016/j.jisa.2016.08.003
   Zhang JL, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107781
   Zhao Y, 2020, IEEE T INTELL TRANSP, V21, P3777, DOI 10.1109/TITS.2019.2933581
   Zhu YL, 2020, J PHYS CONF SER, V1634, DOI 10.1088/1742-6596/1634/1/012032
NR 36
TC 0
Z9 0
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45389
EP 45410
DI 10.1007/s11042-023-15466-y
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000978530200002
DA 2024-07-18
ER

PT J
AU Saini, M
   Mangat, V
AF Saini, Monika
   Mangat, Veenu
TI Multidimensional empirical analysis of overlapping community detection
   methods in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Overlapping community detection; Empirical analysis; Social networks
ID DETECTION ALGORITHMS
AB The widespread domain of social network analysis leads to numerous research challenges associated with it. Community detection is one of the foremost research challenges. There are several community detection methods available in literature whose effectiveness for detecting communities has been analysed through evaluation of various metrics. But this criteria of empirical analysis for predicting performance of particular community detection method, needs to be further explored and refined. Major challenge with earlier surveys on empirical analysis of overlapping community detection methods is the lack of multidimensional framework for depicting the results. In literature, majority of analysis have been done by considering performance metrics only. Unlike other empirical analysis represented in literature, this paper emphasizes on analysis of interdependencies among various fitness metrics while detecting communities. Co-performance analysis based on partition comparison of overlapping community detection methods is also presented. The evaluation has been performed on real as well as benchmark datasets. This article can serve as a reference work for researchers in selection of particular overlapping community detection algorithm based on the analysis of partition comparison and inter-dependencies among fitness metrics.
C1 [Saini, Monika; Mangat, Veenu] Panjab Univ, UIET, Chandigarh, India.
C3 Panjab University
RP Saini, M (corresponding author), Panjab Univ, UIET, Chandigarh, India.
EM monikahsp@gmail.com; vmangat@pu.ac.in
OI , Dr. Monika/0000-0002-2652-6532
CR Amelio A, 2014, LECT NOTES SOC NETW, P105, DOI 10.1007/978-3-7091-1797-2__6
   [Anonymous], 2020, PYTH PACK
   [Anonymous], 2012, P WORKSHOP EVALUATIO
   Arnaboldi V, 2015, ONLINE SOCIAL NETWOR, P61
   Bedi P, 2016, WIRES DATA MIN KNOWL, V6, P115, DOI 10.1002/widm.1178
   Camacho D, 2020, INFORM FUSION, V63, P88, DOI 10.1016/j.inffus.2020.05.009
   Corradini E, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105721
   Devi JC, 2016, PROCEDIA COMPUT SCI, V89, P349, DOI 10.1016/j.procs.2016.06.082
   DU N., 2007, P 9 WEBKDD 1 SNA KDD, P16, DOI [DOI 10.1145/1348549.1348552, 10.1145/1348549.1348552]
   Harenberg S, 2014, WIRES COMPUT STAT, V6, P426, DOI 10.1002/wics.1319
   Lancichinetti A, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046110
   Lancichinetti A, 2009, NEW J PHYS, V11, DOI 10.1088/1367-2630/11/3/033015
   Luo LB, 2020, INFORM SCIENCES, V510, P70, DOI 10.1016/j.ins.2019.09.022
   Mahabadi A, 2021, MULTIMED TOOLS APPL, V80, P6567, DOI 10.1007/s11042-020-09993-1
   Mahoney Michael, 2010, P 19 INT C WORLD WID, P631, DOI DOI 10.1145/1772690.1772755
   Márquez R, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P822, DOI 10.1145/3289600.3291602
   McCarthy AD, 2019, P 8 INT C COMPLEX NE, P164, DOI DOI 10.1007/978-3-030-36687-214
   Muller E, 2019, INT J RES MARK, V36, P3, DOI 10.1016/j.ijresmar.2018.05.003
   Nagaratna M., 2014, INT J SCI RES, V3, P1690
   Nur N, 2018, ARXIV
   Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607
   Pizzuti C, 2014, BIOINFORMATICS, V30, P1343, DOI 10.1093/bioinformatics/btu034
   Rashmi C, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P1296, DOI 10.1109/SmartTechCon.2017.8358576
   Repository, 2013, ABOUT US
   Rossetti G, 2016, STUD COMPUT INTELL, V644, P133, DOI 10.1007/978-3-319-30569-1_10
   Shelke Sushila, 2019, Online Social Networks and Media, V9, P30, DOI 10.1016/j.osnem.2018.12.001
   Sun ZJ, 2018, IEEE ACCESS, V6, P70919, DOI 10.1109/ACCESS.2018.2879648
   Dao VL, 2020, NETW SCI, V8, P1, DOI 10.1017/nws.2019.59
   Whang JJ, 2016, IEEE T KNOWL DATA EN, V28, P1272, DOI 10.1109/TKDE.2016.2518687
   Xie JR, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501657
   Yang G, 2020, INT J MACH LEARN CYB, V11, P1319, DOI 10.1007/s13042-019-01042-0
   Yang J, 2015, KNOWL INF SYST, V42, P181, DOI 10.1007/s10115-013-0693-z
   Yang Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30750
NR 33
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44655
EP 44671
DI 10.1007/s11042-023-15489-5
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000977296200003
DA 2024-07-18
ER

PT J
AU Kumaran, P
   Sridhar, R
   Nandy, H
AF Kumaran, P.
   Sridhar, Rajeswari
   Nandy, Hiran
TI Multi-layered perceptron based deep learning model for emotion
   extraction on monolingual text using intelligence feature engineering
   and filtering techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filtering; Text sentiment analysis; Feature engineering; Text-based
   features; Non-textual features
ID SENTIMENT ANALYSIS; ARCHITECTURE
AB Text Sentiment Analysis (TSA) for blogs on major microblogging platforms has grown drastically and is also very important as a field of research study. However, the paper focuses on the emotion in short text like Twitter which is exceedingly difficult due to the complexity of natural language and the informal structure employed in it, which has a restriction of 280 characters per tweet. In this proposed work, the combination of data filtering and feature engineering approaches are used to recognize the emotion in the short text. A Multi-Layered Perceptron-based Simplified Deep Learning Model (MLP-SDLM) is used in the proposed work to concatenates the filtering and feature engineering serially and parallelly. The third approach introduces the K-map based technique to combine the filtered and unfiltered textual and non-textual features efficiently. The results of proposed models are compared with traditional machine learning and deep learning classifiers and the performances of the proposed MLP-SDLM model gives 95.13% accuracy, K-map based technique produces 89.17% accuracy and MLP gives 88.7% significantly.
C1 [Kumaran, P.] Natl Inst Technol Puducherry, Dept Comp Sci & Engn, Karaikal, Puducherry, India.
   [Sridhar, Rajeswari; Nandy, Hiran] Natl Inst Technol Tiruchirappalli, Dept Comp Sci & Engn, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry; National Institute of Technology (NIT System);
   National Institute of Technology Tiruchirappalli
RP Kumaran, P (corresponding author), Natl Inst Technol Puducherry, Dept Comp Sci & Engn, Karaikal, Puducherry, India.
EM kumaran.0991@gmail.com; srajeswari@nitt.edu; hiran.tiucse@gmail.com
CR Amolik N., 2016, INT J ENG TECHNOL IJ, V7, P2038
   [Anonymous], 2008, PROC INT C MACHINE L
   [Anonymous], MPQA RES
   [Anonymous], FORB REP
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Augustyniak L, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P924, DOI 10.1109/ASONAM.2014.6921696
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Castelluccil G, 2015, LECT NOTES COMPUT SC, V9103, P73, DOI 10.1007/978-3-319-19581-0_6
   Davidov D., 2010, Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING'10, P241
   Diwan T, 2022, MULTIMED TOOLS APPL, V81, P44405, DOI 10.1007/s11042-021-11759-2
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Gayo-Avello D, 2011, COMMUN ACM, V54, P121, DOI 10.1145/2001269.2001297
   Ghiassi M, 2016, J MANAGE INFORM SYST, V33, P1034, DOI 10.1080/07421222.2016.1267526
   Hagen Matthias, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P741, DOI 10.1007/978-3-319-16354-3_81
   Hasan A, 2018, MATH COMPUT APPL, V23, DOI 10.3390/mca23010011
   Hassan A, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P357, DOI 10.1109/SocialCom.2013.56
   Hatzivassiloglou Vasileios., 2000, P INT C COMPUTATIONA, P299, DOI DOI 10.3115/990820.990864
   Jain VK, 2017, J COMPUT SCI-NETH, V21, P316, DOI 10.1016/j.jocs.2017.01.010
   kaggle, US
   Khattak A, 2022, MULTIMED TOOLS APPL, V81, P26223, DOI 10.1007/s11042-022-12902-3
   Kour H, 2022, MULTIMED TOOLS APPL, V81, P23649, DOI 10.1007/s11042-022-12648-y
   Kumar N., 2017, INT J FUTURE REV COM, V3, P1
   Kumar N, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9983652
   Liang PW, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 2, P91, DOI 10.1109/MDM.2013.73
   Majeed A, 2022, MULTIMED TOOLS APPL, V81, P43163, DOI 10.1007/s11042-022-13147-w
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nandy Hiran, 2020, INT C EV TECHN COMP, P299
   Nandy Hiran, 2019, INT C ART INT DAT EN, P1035
   OConnor B., 2010, P 4 INT AAAI C WEBL, V4, P122, DOI DOI 10.1609/ICWSM.V4I1.14031
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Shrivastava K, 2019, MULTIMED TOOLS APPL, V78, P29607, DOI 10.1007/s11042-019-07813-9
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P6871, DOI 10.1007/s11042-020-10037-x
   Vanzo A., 2014, The 25th International Conference on Computational Linguistics: Technical Papers, P2345
   Yang H, 2022, MULTIMED TOOLS APPL, V81, P15439, DOI 10.1007/s11042-022-12629-1
NR 38
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44037
EP 44052
DI 10.1007/s11042-023-15438-2
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979936300008
DA 2024-07-18
ER

PT J
AU Lin, Q
   Kuang, HB
   Wang, C
   Guo, Y
   Zhang, XL
   Luo, JW
AF Lin, Qiang
   Kuang, Haibo
   Wang, Can
   Guo, Yang
   Zhang, Xilin
   Luo, Jiawei
TI LVUCB: an efficient vehicle network task scheduling system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent Transportation System; Vehicle Edge Computing; Multi-armed
   Bandit; Simulation of Urban Mobility
ID RESOURCE-ALLOCATION; EDGE
AB With the development of vehicle edge computing technology, one of challenge is that in a high-speed motion, the vehicle leads to rapid and unpredictable changes in network topology, wireless channel status and available computing resources. Based on the vehicle edge computing technology, we applied a vehicle network task scheduling framework, and proposed an algorithm, named LVUCB. In addition, we also designed and implemented a vehicle network task scheduling system based on this algorithm. Simulation experiments show that the proposed algorithm can decrease 15% delay than the classic UCB algorithm and meet mostly needs of vehicle network task management in intelligent transportation system.
C1 [Lin, Qiang; Kuang, Haibo] Dalian Maritime Univ, Sch Maritime Econ & Management, Dalian 116026, Peoples R China.
   [Lin, Qiang; Kuang, Haibo] Dalian Maritime Univ, Collaborat Innovat Ctr Transport Studies, Dalian 116026, Peoples R China.
   [Lin, Qiang] Party Sch Dalian Municipal Comm, Commun Party China, Dalian, Peoples R China.
   [Wang, Can; Guo, Yang; Zhang, Xilin; Luo, Jiawei] Dalian Univ Sci & Technol, Dalian, Peoples R China.
C3 Dalian Maritime University; Dalian Maritime University; Dalian
   University of Technology
RP Lin, Q (corresponding author), Dalian Maritime Univ, Sch Maritime Econ & Management, Dalian 116026, Peoples R China.
EM lqchinalunwen@126.com
RI Zhang, Xilin/O-6158-2018
FU Liaoning Social Science Planning Fund Project [L22AGL002]; Scientific
   research project of Liaoning Provincial Department of Education
   [L2020004]
FX This research is sponsored by Liaoning Social Science Planning Fund
   Project (No. L22AGL002) and Scientific research project of Liaoning
   Provincial Department of Education (No. L2020004).
CR Abdelhamid S, 2015, IEEE NETWORK, V29, P12, DOI 10.1109/MNET.2015.7018198
   Chen Y, 2022, IEEE T VEH TECHNOL, V71, P4584, DOI 10.1109/TVT.2021.3133586
   Feng JY, 2017, IEEE T VEH TECHNOL, V66, P10660, DOI 10.1109/TVT.2017.2714704
   Guo HZ, 2019, IEEE INTERNET THINGS, V6, P4317, DOI 10.1109/JIOT.2018.2875535
   Hou XS, 2016, IEEE T VEH TECHNOL, V65, P3860, DOI 10.1109/TVT.2016.2532863
   Jang I, 2017, IEEE VEH TECHNOL MAG, V12, P78, DOI 10.1109/MVT.2017.2665718
   Lin CC, 2018, IEEE INTERNET THINGS, V5, P3692, DOI 10.1109/JIOT.2017.2690961
   Liu Y, 2019, IEEE T VEH TECHNOL, V68, P11158, DOI 10.1109/TVT.2019.2935450
   Qi Q, 2019, IEEE T VEH TECHNOL, V68, P4192, DOI 10.1109/TVT.2019.2894437
   Raza S, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/3159762
   Sun Y, 2018, IEEE INT C COMM ICC, P1
   Sun YX, 2019, IEEE T VEH TECHNOL, V68, P3061, DOI 10.1109/TVT.2019.2895593
   Wang B., 2017, Laser journal, V38, P147
   Wang Z, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292594
   Zhang K, 2017, CAMB MG MEC, P1, DOI [10.1007/s10586-017-1443-x, 10.1017/9781139024853, 10.1109/ICC.2017.7997360]
   Zheng K, 2015, IEEE T IND ELECTRON, V62, P7920, DOI 10.1109/TIE.2015.2482119
   Zhou FH, 2020, IEEE WIREL COMMUN, V27, P140, DOI 10.1109/MWC.001.1800594
   Zhou ZY, 2019, IEEE T VEH TECHNOL, V68, P3113, DOI 10.1109/TVT.2019.2894851
   Zhu C, 2019, IEEE INTERNET THINGS, V6, P4150, DOI 10.1109/JIOT.2018.2875520
NR 19
TC 0
Z9 0
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 25
PY 2023
DI 10.1007/s11042-023-15311-2
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R8JH0
UT WOS:001066758900006
DA 2024-07-18
ER

PT J
AU Tekli, J
   Al Bouna, B
   Tekli, G
   Couturier, R
AF Tekli, Jimmy
   Al Bouna, Bechara
   Tekli, Gilbert
   Couturier, Raphael
TI A framework for evaluating image obfuscation under deep
   learning-assisted privacy attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face obfuscation; Deep learning-assisted attacks; Adversary model;
   Background knowledge; Image transformation; Privacy-preserving
   techniques
AB Image obfuscation techniques (e.g., pixelation, blurring and masking,...) have been developed to protect sensitive information in images (e.g. individuals' faces). In a previous work, we designed a recommendation framework that evaluates the robustness of image obfuscation techniques and recommends the most resilient obfuscation against Deep-Learning assisted attacks. In this paper, we extend the framework due to two main reasons. First, to the best of our knowledge there is not a standardized evaluation methodology nor a defined model for adversaries when evaluating the robustness of image obfuscation and more specifically face obfuscation techniques. Therefore, we adapt a three-components adversary model (goal, knowledge and capabilities) to our application domain (i.e., facial features obfuscations) and embed it in our framework. Second, considering several attacking scenarios is vital when evaluating the robustness of image obfuscation techniques. Hence, we define three threat levels and explore new aspects of an adversary and its capabilities by extending the background knowledge to include the obfuscation technique along with its hyper-parameters and the identities of the target individuals.
   We conduct three sets of experiments on a publicly available celebrity faces dataset. Throughout the first experiment, we implement and evaluate the recommendation framework by considering four adversaries attacking obfuscation techniques (e.g. pixelating, Gaussian/motion blur and masking) via restoration-based attacks. Throughout the second and third experiments, we demonstrate how the adversary's attacking capabilities (recognition-based and Restoration & Recognition-based attacks) scale with its background knowledge and how it increases the potential risk of breaching the identities of blurred faces.
C1 [Tekli, Jimmy] BMW Grp, Munich, Germany.
   [Tekli, Jimmy; Couturier, Raphael] Univ Franche Comte, Inst FEMTO ST, CNRS, F-90000 Belfort, France.
   [Al Bouna, Bechara] Antonine Univ, TICKET Lab, Baabda, Lebanon.
   [Tekli, Gilbert] Univ Balamand, Balamand, Lebanon.
C3 BMW AG; Centre National de la Recherche Scientifique (CNRS); Universite
   de Technologie de Belfort-Montbeliard (UTBM); Universite de
   Franche-Comte; University Balamand
RP Tekli, J (corresponding author), BMW Grp, Munich, Germany.; Tekli, J (corresponding author), Univ Franche Comte, Inst FEMTO ST, CNRS, F-90000 Belfort, France.
EM jimmy.tekli@bmw.de; raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013
OI Couturier, Raphaël/0000-0003-1490-9592
FU EIPHI Graduate School [ANR-17-EURE-0002]
FX The authors especially thank Mr. Marc Kamradt for providing the GPU
   hardware available at the BMW TechOffice located in Munich to conduct
   all the experiments. This work has also been partially funded by the
   EIPHI Graduate School (contract "ANR-17-EURE-0002").
CR Abramian D, 2018, ARXIV
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016, SREZ ADVERSARIAL SUP
   [Anonymous], 1993, P 13 ANN INT CRYPT C
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bellare M, 2000, LECT NOTES COMPUT SC, V1807, P139
   Bellare M., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, P57, DOI 10.1145/225058.225084
   Biggio B., 2012, ARXIV
   Boracchi G, 2012, IEEE T IMAGE PROCESS, V21, P3502, DOI 10.1109/TIP.2012.2192126
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chattopadhyay A, 2021, DET ROB PRIV ENH DEI
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Do Q, 2018, COMPUT SECUR
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dufaux F, 2010, IEEE INT CON MULTI, P66, DOI 10.1109/ICME.2010.5583552
   Frome A, 2009, IEEE I CONF COMP VIS, P2373, DOI 10.1109/ICCV.2009.5459413
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gopalan R., 2012, TPAMI
   Hao H, 2019, ARXIV190611979
   Hao H, 2020, 15 IEEE INT C AUTOMA
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hill S, 2016, PETS
   Hu Hongxin, 2017, P ACM HUM COMP INT
   Hu J., 2019, arXiv
   Jin CB, 2018, SEMANTIC IMAGE INPAI
   Jingzhi L, 2021, P 29 ACM INT C MULT
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Korshunov P, 2013, P SOC PHOTO-OPT INS, V8856, P12
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Laboratories Cambridge, 1994, DAT FAC
   Lander K, 2001, APPL COGNITIVE PSYCH
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li YZ, 2017, ADV NEUR IN, V30
   Linwei Y, 2018, 2018 IEEE 20 INT WOR
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   Majumdar S, 2016, IMAGE SUPER RESOLUTI
   McPherson Richard., 2016, Defeating image obfuscation with deep learning
   Meden B, 2021, IEEE T INF FOREN SEC
   Nawaz T, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.051408
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Packhauser K, 2021, ARXIV
   PETIUSHKO A., 2019, ARXIV
   Punnappurath Abhijith, 2015, IEEE Trans Image Process, V24, P2067, DOI 10.1109/TIP.2015.2412379
   Ra M-R, 2013, P3TOWARD PRIVACY PRE
   Rezaeifar S, 2022, M ASGARI JIRHANDEH K
   Ruchaud N, 2016, ELECT IMAGING
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shafahi A, 2018, ADV NEUR IN, V31
   Shaheed K, 2022, EXPERT SYST APPL
   Shan S, 2020, ARXIV
   Shen Z, 2016, DEEP SEMANTIC FACE D
   Shen ZY, 2018, PROC CVPR IEEE, P8260, DOI 10.1109/CVPR.2018.00862
   Tekli J, 2019, ANN CONF PRIV SECUR, P192, DOI 10.1109/pst47121.2019.8949040
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   WANG Z, 2004, IMAGE PROCESS IEEE T, V13
   Wu Z, 2020, ARXIV
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang K, 2021, ARXIV
   Yang W, 2018, ARXIV
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang K, 2020, IEEE C COMPUT VISION
   Zhu Jun-Yan, 2017, arXiv
NR 72
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42173
EP 42205
DI 10.1007/s11042-023-14664-y
EA APR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967980300005
DA 2024-07-18
ER

PT J
AU Kumar, A
   Rathore, PS
   Dubey, AK
   Agrawal, R
   Sharma, KP
AF Kumar, Abhishek
   Rathore, Pramod Sing
   Dubey, Ashutosh Kumar
   Agrawal, Rashmi
   Sharma, Kanta Prasad
TI LTE-NBP with holistic UWB-WBAN approach for the energy efficient
   biomedical application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UWB; WBAN; HB-UWB; UWB-WBAN; Throughput; Energy consumption and network
   delay
ID BODY; ANTENNA; CHANNEL
AB Increased use of ultra-wideband (UWB) in biomedical applications based on wireless body area networks (WBAN) opens a variety of options in the field of biomedical research. WBAN may aid in the continuous health monitoring of patients while they go about their everyday lives. Many studies and researchers were conducted several experimentations in the same field for the performance improvement. This study covered the hybridization of UWB technology, as well as on-body, off-body, and human-body ultra-wideband communication (HB-UWB). In this paper, the parameters considered are throughput, energy consumption, energy efficiency, energy used, network survival and delay. An improved model for design and assessment of power-saving UWB-WBAN was developed in this paper. A novel protocol model was introduced in this paper, namely low-power traffic-aware emergency based narrowband protocol (LTE-NBP) to overcome the major drawbacks of emergency, critical data transmission, reliability and the power issues in UWB-WBAN. It's the emergency-based low-power traffic-aware narrowband protocol. It is based on the dual-band physical layer technology. The suggested protocol considered an aware traffic model and an emergency medium access control (MAC) protocol. The proposed model's performance was evaluated and compared with the related algorithms on different performance parameters. The improved model is found to be efficient in throughput, energy efficiency, energy consumption, and delay.
C1 [Kumar, Abhishek] Chandigarh Univ, Dept CSE, Mohali, Punjab, India.
   [Rathore, Pramod Sing] Aryabhatta Coll Engn & Res Ctr, Ajmer, Rajasthan, India.
   [Dubey, Ashutosh Kumar] Chitkara Univ, Chitkara Univ Sch Engn & Technol, Rajpura, Himachal Prades, India.
   [Agrawal, Rashmi] Manav Rachna Int Inst Res & Studies, Fac Comp Applicat, Faridabad, Haryana, India.
   [Sharma, Kanta Prasad] GLA Univ Mathura, Comp Engn & Applicat, Chaumuhan, India.
C3 Chandigarh University; Chitkara University, Punjab; Manav Rachna
   International Institute of Research & Studies; GLA University
RP Agrawal, R (corresponding author), Manav Rachna Int Inst Res & Studies, Fac Comp Applicat, Faridabad, Haryana, India.
EM abhishek.e14283@cumail.in; pramodrathore88@gmail.com;
   ashutosh.dubey@chitkara.edu.in; drrashmiagrawal78@gmail.com;
   tokantaprasad@gmail.com
RI Rathore, Pramod/ITT-4922-2023; Agrawal, Rashmi/U-5880-2018; Dubey,
   Ashutosh Kumar/C-9356-2015; Sharma, Kanta Prasad/E-6319-2018
OI Agrawal, Rashmi/0000-0003-2095-5069; Dubey, Ashutosh
   Kumar/0000-0002-9541-4673; Sharma, Kanta Prasad/0000-0003-3976-5839;
   RATHORE, PRAMOD SINGH/0000-0002-4917-1500
CR Alani S, 2020, P 2020 4 INT S MULT, P1, DOI DOI 10.1109/ISMSIT50672.2020.9254219
   Alhawari ARH, 2021, AIP ADV, V11, DOI 10.1063/5.0037232
   Ashraf M, 2022, ENVIRON DEV SUSTAIN, DOI 10.1007/s10668-021-02037-0
   Ashyap AYI, 2020, IEEE ACCESS, V8, P7641, DOI 10.1109/ACCESS.2020.2963997
   Bhatti DMS, 2022, BIG DATA, V10, P54, DOI 10.1089/big.2021.0187
   Chahat N, 2011, IEEE T ANTENN PROPAG, V59, P1123, DOI 10.1109/TAP.2011.2109361
   Chaisang Aditep, 2018, 2018 Global Wireless Summit (GWS), P315, DOI 10.1109/GWS.2018.8686566
   Chávez-Santiago R, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/716973
   Chavez-Santiago R, 2009, P 2 INT S APPL SCI B, P1
   Cherifi F, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2022.107698
   Correa-Chica Juan Camilo, 2017, Dyna rev.fac.nac.minas, V84, P120, DOI 10.15446/dyna.v84n202.61895
   Du CZ, 2022, INT J RF MICROW C E, V32, DOI 10.1002/mmce.22997
   Dubey AK., 2019, INT J INNOV TECHNOL, V9, P87, DOI [10.35940/ijitee.A3925.119119, DOI 10.35940/IJITEE.A3925.119119]
   Filipe L, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/213705
   Goswami D, 2016, HEALTHC TECHNOL LETT, V3, P129, DOI 10.1049/htl.2016.0005
   Hasan K, 2019, J NETW COMPUT APPL, V143, P178, DOI 10.1016/j.jnca.2019.06.016
   Joshi U, 2022, MULTIMED TOOLS APPL, V81, P2827, DOI 10.1007/s11042-021-11387-w
   Karunanithy K, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103280
   Khandelwal A., 2018, INT J ADV COMPUT RES, V8, P191, DOI 10.19101/IJACR.2018.836022
   Kumar V, 2016, AEU-INT J ELECTRON C, V70, P668, DOI 10.1016/j.aeue.2016.02.003
   Legner C, 2019, SENSOR ACTUAT A-PHYS, V296, P200, DOI 10.1016/j.sna.2019.07.020
   Munivel KV, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122189
   Negra R, 2016, PROCEDIA COMPUT SCI, V83, P1274, DOI 10.1016/j.procs.2016.04.266
   Otto C., 2006, J MOBILE MULTIMEDIA, V1, P307
   Panimalar S., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P889, DOI 10.1109/ICCSP48568.2020.9182194
   Parameswari S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03228-3
   Pateriya J, 2020, 2020 5 INT C COMM EL, P330, DOI DOI 10.1109/ICCES48766.2020.9138040
   Promsrisawat Pichayanan, 2018, 2018 International Conference on Digital Arts, Media and Technology (ICDAMT), P225, DOI 10.1109/ICDAMT.2018.8376528
   Pushpan S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092112
   Radha S, 2020, INT CONF ADVAN COMPU, P629, DOI 10.1109/ICACCS48705.2020.9074371
   Rasool SM, 2022, WIRELESS PERS COMMUN, V123, P3223, DOI 10.1007/s11277-021-09285-3
   Sambandam P, 2020, IEEE T ANTENN PROPAG, V68, P5228, DOI 10.1109/TAP.2020.2980367
   Sanguanpuak Chanidaphar, 2019, 2019 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT-NCON), P124, DOI 10.1109/ECTI-NCON.2019.8692288
   Sanguanpuak Chanidaphar, 2018, 2018 Global Wireless Summit (GWS), P16, DOI 10.1109/GWS.2018.8686569
   Shoaran M, 2018, IEEE J EM SEL TOP C, V8, P693, DOI 10.1109/JETCAS.2018.2844733
   Shunmugapriya B, 2022, WIRELESS PERS COMMUN, V122, P2723, DOI 10.1007/s11277-021-09027-5
   Sinde R., 2020, UNDEFINED, V7, P36, DOI [10.19101/IJATEE.2019.650083, DOI 10.19101/IJATEE.2019.650083]
   Sowndeswari S., 2022, INT J PR ENG MAN-GT, V9, P111
   Suliman SI., 2021, INT J ADV TECHNOLOGY, V8, P412, DOI [10.19101/IJATEE.2020.762129, DOI 10.19101/IJATEE.2020.762129]
   Teawchim S, 2016, BIOMED ENG INT CONF
   Umar M, 2020, IEEE ACCESS, V8, P66411, DOI 10.1109/ACCESS.2020.2985261
   Zhang YP, 2007, IEEE T ANTENN PROPAG, V55, P2907, DOI 10.1109/TAP.2007.905825
   Zhuang Ling, 2020, 2020 International Conference on Computing, Networking and Communications (ICNC), P780, DOI 10.1109/ICNC47757.2020.9049666
NR 43
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39797
EP 39811
DI 10.1007/s11042-023-15093-7
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600012
PM 37362741
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chen, LGX
   Cai, YQ
   Lu, CH
   Wang, CB
   He, GQ
AF Chen, Lianggangxu
   Cai, Yiqing
   Lu, Changhong
   Wang, Changbo
   He, Gaoqi
TI Video-based spatio-temporal scene graph generation with efficient
   self-supervision tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatio-temporal scene graphs generation; Self-supervision; Local
   relation-aware attention
AB Spatio-temporal Scene Graphs Generation (STSGG) aims to extract a sequence of graph-based semantic representations for high-level visual tasks. Existing works often fail to exploit the strong temporal correlation and the details of local features, which leads to the inability to distinguish the action between dynamic relation (e.g., drinking) and static relation (e.g., holding). Furthermore, due to bad long-tailed bias, the prediction results are troubled by inaccurate tail predicates classifications. To address these issues, a slowfast local-aware attention (SFLA) Network is proposed for temporal modeling in STSGG. First, a two-branch network is used to extract static and dynamic relation features respectively. Second, a local relation-aware attention (LRA) module is proposed to attach higher importance to the crucial elements in the local relationship. Third, three novel self-supervision prediction tasks are proposed, that is, spatial location, human attention state, and distance variation. Such self-supervision tasks are trained simultaneously with the main model to alleviate the long-tailed bias problem and enhance feature discrimination. Systematic experiments show that our method achieves state-of-the-art performance in the recently proposed Action Genome (AG) dataset and the popular ImageNet Video dataset.
C1 [Chen, Lianggangxu; Cai, Yiqing; Wang, Changbo; He, Gaoqi] Chongqing Inst East China Normal Univ, Chongqing Key Lab Precis Opt, Chongqing, Peoples R China.
   [Chen, Lianggangxu; He, Gaoqi] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
   [Lu, Changhong] East China Normal Univ, Sch Math Sci, Shanghai, Peoples R China.
C3 East China Normal University; East China Normal University
RP He, GQ (corresponding author), Chongqing Inst East China Normal Univ, Chongqing Key Lab Precis Opt, Chongqing, Peoples R China.; He, GQ (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
EM 52194501010@stu.ecnu.edu.cn; 51194501002@stu.ecnu.edu.cn;
   chlu@math.ecnu.edu.cn; cbwang@cs.ecnu.edu.cn; gqhe@cs.ecnu.edu.cn
OI Cai, Yiqing/0000-0001-7315-0024; He, Gaoqi/0000-0001-8365-0970
FU Natural Science Foundation of Chongqing [CSTB2022NSCQ-MSX0552]; National
   Natural Science Foundation of China [62002121, 62072183, 62102151];
   Shanghai Science and Technology Commission [21511100700, 22511104600];
   National Key Research and Development Program of China [2021ZD0111000];
   Research Project of Shanghai Science and Technology Commission
   [20DZ2260300]; Shanghai Sailing Program [21YF1411200]; CAAI-Huawei
   MindSpore Open Fund [CAAIXSJLJJ-2021-031A]; Open Project Program of the
   State Key Lab of CADCG [A2203]
FX This work was supported in part by Natural Science Foundation of
   Chongqing (No. CSTB2022NSCQ-MSX0552), National Natural Science
   Foundation of China (No. 62002121, 62072183, and 62102151), Shanghai
   Science and Technology Commission (No. 21511100700, 22511104600), the
   National Key Research and Development Program of China (No.
   2021ZD0111000), the Research Project of Shanghai Science and Technology
   Commission (No. 20DZ2260300), Shanghai Sailing Program (21YF1411200) and
   CAAI-Huawei MindSpore Open Fund (CAAIXSJLJJ-2021-031A), the Open Project
   Program of the State Key Lab of CAD&CG (No. A2203), Zhejiang University.
CR Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen L, 2021, MULTIMED TOOLS APPL, V80, P6661, DOI 10.1007/s11042-020-10002-8
   Chen VS, 2019, IEEE I CONF COMP VIS, P2580, DOI [10.1109/iccv.2019.00267, 10.1109/ICCV.2019.00267]
   Chen Y, 2019, IEEE INT CON MULTI, P508, DOI 10.1109/ICME.2019.00094
   Chenchen Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10837, DOI 10.1109/CVPR42600.2020.01085
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao K, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4833, DOI 10.1145/3474085.3479231
   Geng S, 2020, ARXIV
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jingwei Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10233, DOI 10.1109/CVPR42600.2020.01025
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Mi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13883, DOI 10.1109/CVPR42600.2020.01390
   Li RJ, 2021, PROC CVPR IEEE, P11104, DOI 10.1109/CVPR46437.2021.01096
   Li YB, 2017, INT CON DISTR COMP S, P1261, DOI 10.1109/ICDCS.2017.54
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lyu F, 2020, NEUROCOMPUTING, V413, P51, DOI 10.1016/j.neucom.2020.06.091
   Peyre J, 2017, IEEE I CONF COMP VIS, P5189, DOI 10.1109/ICCV.2017.554
   Qian XF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P84, DOI 10.1145/3343031.3351058
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shang XD, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1300, DOI 10.1145/3123266.3123380
   Shen K, 2020, P 29 INT JOINT C ART, P3406
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   Tang KH, 2019, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2019.00678
   Trojahn TH, 2021, MULTIMED TOOLS APPL, V80, P17487, DOI 10.1007/s11042-020-10450-2
   Tsai YHH, 2019, PROC CVPR IEEE, P10416, DOI 10.1109/CVPR.2019.01067
   Wang RZ, 2020, AAAI CONF ARTIF INTE, V34, P9185
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Yan ST, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P265, DOI 10.1145/3394171.3413722
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Zareian A, 2020, ARXIV
   Zareian A, 2020, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR42600.2020.00379
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang J, 2019, PROC CVPR IEEE, P11527, DOI 10.1109/CVPR.2019.01180
NR 38
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38947
EP 38966
DI 10.1007/s11042-023-14640-6
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500014
DA 2024-07-18
ER

PT J
AU Beserra, AAR
   Goularte, R
AF Beserra, Antonio A. R.
   Goularte, Rudinei
TI Multimodal early fusion operators for temporal video scene segmentation
   tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal analysis; Fusion operator; Feature fusion; Video scene
   segmentation
AB The Temporal Video Scene Segmentation (TVSS) task is still an open problem presenting challenges in the Multimedia Analysis area. Current approaches employ multimodality, fusing features from different video data modalities as a way to improve segmentation accuracy. Generally, the progress presented in the literature improves the accuracy at the cost of increasing the fusion processing complexity. In this paper, we propose the application of early multimodal fusion operators in the mid-level feature space. We show that, at the mid-level, operators' accuracy presents no statistically significant difference compared with complex techniques. Three different operators (Concatenation, Sum, and Max) were employed to fuse mid-level multimodal video features, using the fused data representations as input for the TVSS task. We analyzed the operators' accuracy with those from current fusion approaches based on correlation detection and deep learning using two TVSS datasets. The results allow us to conclude the contributions are twofold. First, the operators make the fusion a separable step in the TVSS pipeline, easing techniques development. Second, we show that, at the mid-level feature space, TVSS researchers can put efforts otherwise than in the fusion since simple operators provide statistically similar results to those from more complex fusion techniques.
C1 [Beserra, Antonio A. R.; Goularte, Rudinei] Univ Sao Paulo, Inst Ciencias Matemat & Computacao, Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP Beserra, AAR (corresponding author), Univ Sao Paulo, Inst Ciencias Matemat & Computacao, Sao Carlos, SP, Brazil.
EM antonioalessandrorb@gmail.com; rudinei@icmc.usp.br
RI Goularte, Rudinei/E-2441-2011
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   Anyi Rao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10143, DOI 10.1109/CVPR42600.2020.01016
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Baraldi L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1199, DOI 10.1145/2733373.2806316
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9117, P395, DOI 10.1007/978-3-319-19390-8_45
   Beserra AAR., 2020, EVALUATING EARLY FUS, P113
   Bokade R, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113885
   Chen SH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4853, DOI 10.1145/3474085.3479216
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Gaonkar A., 2021 INT C INTELLIGE, V2021, P1, DOI DOI 10.1109/CONIT51480.2021.9498415
   Ghauri J, 2020, CLASSIFICATION IMPOR, V2699
   Gross B.M., 1965, The ANNALS of the American Academy of Political and Social Science, V360, P197, DOI DOI 10.1177/000271626536000140
   Güder M, 2018, MULTIMEDIA SYST, V24, P55, DOI 10.1007/s00530-017-0535-z
   Jhuo IH, 2014, MACH VISION APPL, V25, P33, DOI 10.1007/s00138-013-0567-0
   Ji Z, 2018, SIGNAL PROCESS, V148, P114, DOI 10.1016/j.sigpro.2018.01.028
   Kishi RM, 2019, MULTIMED TOOLS APPL, V78, P15623, DOI 10.1007/s11042-018-6959-4
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Kumar A, 2020, LECT NOTES ELECTR EN, V605, P204, DOI 10.1007/978-3-030-30577-2_17
   Lopes B., 2014, FRONT PSYCHOL, V5, P1
   Media kix, 2018, 11 BIGG STAT KNOW YO
   Münzer B, 2018, LECT NOTES COMPUT SC, V10705, P395, DOI 10.1007/978-3-319-73600-6_40
   Pei Y, 2021, P 2 ACM INT C MULT A, DOI [10.1145/3444685.3446293, DOI 10.1145/3444685.3446293]
   Pereira Jr O, 2018, 14 WORKSH VIS COMP
   Rijsbergen C. J. V., 1979, Information Retrieval
   Rongyong Zhao, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P1599, DOI 10.1109/IAEAC50856.2021.9390889
   Rothfuss Damaris, 2019, Advances in Design for Inclusion. Proceedings of the AHFE 2018 International Conference on Design for Inclusion. Advances in Intelligent Systems and Computing (AISC 776), P229, DOI 10.1007/978-3-319-94622-1_22
   Rotman D, 2017 IEEE 19 INT WOR, DOI [10.1109/mmsp.2017.8122267, DOI 10.1109/MMSP.2017.8122267]
   ROTMAN D, 2017, ROBUST EFFICIENT VID, P275
   Saraceno C, 1997, INT CONF ACOUST SPEE, P2597, DOI 10.1109/ICASSP.1997.595320
   Schoeffmann K, 2019, INT WORK CONTENT MUL
   Sen S., 2019, AUDIO PROCESSING SPE, DOI [10.1007/978-981-13-6098-5, DOI 10.1007/978-981-13-6098-5]
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Snoek CGM, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA21
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Thounaojam D. M., 2014, P INT C ADV COMPUTIN, P903
   Trojahn TH, 2021, MULTIMED TOOLS APPL, V80, P17487, DOI 10.1007/s11042-020-10450-2
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   Vembu A, 2013, INT CONF ACOUST SPEE, P3667, DOI 10.1109/ICASSP.2013.6638342
   Vendrig J, 2002, IEEE T MULTIMEDIA, V4, P492, DOI 10.1109/TMM.2002.802021
   Vrochidis S, 2019, BIG DATA ANAL LARGE
   Wang H, 2021, TRAFFIC SIGN DETECTI, P949
   Wang K, 2017, PATTERN RECOGN, V67, P213, DOI 10.1016/j.patcog.2017.01.034
   Wang ZF, 2011, J COMPUT, V6, P931, DOI 10.4304/jcp.6.5.931-938
   Xie RF, 2011, IEEE INT C BIO BIO W, P165, DOI 10.1109/BIBMW.2011.6112370
   Yang H, 2018, LASER OPTOELECTRON P, V55
   Yang J, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/7790583
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Zhang B, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4848, DOI 10.1145/3474085.3479214
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
NR 51
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31539
EP 31556
DI 10.1007/s11042-023-14953-6
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000984224700010
DA 2024-07-18
ER

PT J
AU Feng, CL
   Chen, SZ
   Zhao, DZ
   Yang, JZ
AF Feng, Chaolu
   Chen, Shuaizheng
   Zhao, Dazhe
   Yang, Jinzhu
TI Region based level sets for image segmentation: a brief comparative
   review with a fast model FREEST
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Level set; Image segmentation; Bias correction; Intensity
   inhomogeneities
ID ACTIVE CONTOURS DRIVEN; SCALABLE FITTING ENERGY; SHAPE PRIOR; EVOLUTION;
   INHOMOGENEITY; MUMFORD
AB Region based level sets are one class of popular image segmentation models. Sorting out the inheritance relationship and comparing their performance on same image repositories are of guiding significance. In this paper, we first propose a generalization model to cover external forces of representative region based level sets and give a brief comparative review on them by describing their evolution process and performing a capacity and complexity analysis. We then briefly review regularizations on level sets, known as internal force in the literature. As the models become more and more complicated to perform well on challenging images, it is significant to ensure both segmentation performance and time performance. Thirdly, we propose a fast region based level set (FREEST) model to segment images with intensity inhomogeneities where smoothness of the estimated intensity bias field is ensured by a convolution operation. We then improve FREEST by introducing global intensity variances and rename it as FREEST sigma to deal with images with different variances between objects of interest and the background. Experiments on representative 120 images (natural images from BSDS500 and well known synthetic images in the field) with simulated intensity biases show that time performances of the proposed models are close to the simplest but most famous level set model and its time incrementing is only about 1/20 of existing models. Qualitative and quantitative comparison with the representative models on the images in terms of Dice Similarity Coefficient and Jaccard Similarity Coefficient demonstrate advantages of the proposed models. Compared with the second-best model, the evaluation indicators increased by 0.09 and 0.13, respectively. Parameter settings and representative influence are discussed, which indicates robustness of the proposed models. Grand challenges and still open problems such as initialization sensitivity, complex background segmentation, and multi-class object segmentation are finally discussed. Codes will be released if this paper was accepted.
C1 [Feng, Chaolu; Yang, Jinzhu] Minist Educ, Key Lab Intelligent Comp Med Image MIIC, Shenyang 110169, Liaoning, Peoples R China.
   [Feng, Chaolu; Chen, Shuaizheng; Zhao, Dazhe; Yang, Jinzhu] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110169, Liaoning, Peoples R China.
   [Zhao, Dazhe; Yang, Jinzhu] Key Lab Med Image Comp MIC, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Feng, CL (corresponding author), Minist Educ, Key Lab Intelligent Comp Med Image MIIC, Shenyang 110169, Liaoning, Peoples R China.; Feng, CL (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110169, Liaoning, Peoples R China.
EM fengchaolu@cse.neu.edu.cn
OI Feng, Chaolu/0000-0002-5575-2328
FU Natural Science Foundation of Liaoning Province of China [2021-MS-085]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of Liaoning Province of China under grant 2021-MS-085.
CR Ali H, 2018, IEEE T IMAGE PROCESS, V27, P3729, DOI 10.1109/TIP.2018.2825101
   Cai Q, 2018, PATTERN RECOGN, V82, P79, DOI 10.1016/j.patcog.2018.05.008
   Chan T, 2005, PROC CVPR IEEE, P1164
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dai LZ, 2015, PATTERN RECOGN, V48, P2513, DOI 10.1016/j.patcog.2015.03.001
   Fang JX, 2021, INFORM SCIENCES, V546, P397, DOI 10.1016/j.ins.2020.08.078
   Fang LL, 2020, INFORM SCIENCES, V513, P504, DOI 10.1016/j.ins.2019.10.051
   Feng CL, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/7595174
   Feng CL, 2017, NEUROCOMPUTING, V219, P107, DOI 10.1016/j.neucom.2016.09.008
   Feng CL, 2016, MED PHYS, V43, P2741, DOI 10.1118/1.4947126
   Feng CL, 2013, LECT NOTES COMPUT SC, V8149, P477, DOI 10.1007/978-3-642-40811-3_60
   Fu XY, 2021, INFORM SCIENCES, V564, P327, DOI 10.1016/j.ins.2021.02.019
   Gibou F, 2018, J COMPUT PHYS, V353, P82, DOI 10.1016/j.jcp.2017.10.006
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Huang GP, 2018, MAGN RESON IMAGING, V52, P33, DOI 10.1016/j.mri.2018.05.011
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li YP, 2020, INFORM SCIENCES, V506, P443, DOI 10.1016/j.ins.2019.08.021
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Min H, 2019, PATTERN RECOGN, V91, P69, DOI 10.1016/j.patcog.2019.02.009
   Min H, 2018, NEUROCOMPUTING, V311, P245, DOI 10.1016/j.neucom.2018.05.070
   Min H, 2018, IEEE T IMAGE PROCESS, V27, P5016, DOI 10.1109/TIP.2018.2848471
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78
   Rousson M, 2008, INT J COMPUT VISION, V76, P231, DOI 10.1007/s11263-007-0054-z
   Shi YG, 2005, PROC CVPR IEEE, P34
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang H, 2014, INFORM SCIENCES, V263, P43, DOI 10.1016/j.ins.2013.10.033
   Wang L, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107297
   Wang L, 2018, SIGNAL PROCESS, V149, P27, DOI 10.1016/j.sigpro.2018.02.025
   Wang L, 2017, INFORM SCIENCES, V418, P61, DOI 10.1016/j.ins.2017.06.042
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Wang ZB, 2021, ARCH COMPUT METHOD E, V28, P2429, DOI 10.1007/s11831-020-09463-9
   Weng GR, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115633
   Yan S, 2020, IEEE T IMAGE PROCESS, V29, P7141, DOI 10.1109/TIP.2020.2998981
   Yang YY, 2021, INFORM SCIENCES, V577, P638, DOI 10.1016/j.ins.2021.07.069
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang F, 2022, INFORM SCIENCES, V596, P439, DOI 10.1016/j.ins.2022.03.035
   Zhang HL, 2019, INFORM SCIENCES, V493, P152, DOI 10.1016/j.ins.2019.04.048
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhi XH, 2018, PATTERN RECOGN, V80, P241, DOI 10.1016/j.patcog.2018.03.010
   Zhu J, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107896
NR 52
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-15073-x
EA MAR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900002
DA 2024-07-18
ER

PT J
AU Xu, XZ
   Guo, YY
   Wang, X
AF Xu, Xinzheng
   Guo, Yanyan
   Wang, Xin
TI Human pose estimation model based on DiracNets and integral pose
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural network; Human pose estimation; DiracNets;
   Integral pose regression
AB Human pose estimation has achieved great progress in recent years. However, many methods use max pooling, average pooling, or simple downsampling in the form of stepped convolution on the feature map to increase the feature receptive field of the network, which will lead to the loss of original feature information and quantization errors. In order to solve above problems, we propose the RM-IPR-DDHPE model. Specifically, we firstly propose the DDHPE model which uses Mask R-CNN as the backbone network. In this model, we replace the residual module with an improved Dirac network module (DiracNets) to adaptively learn deeper features. Besides, we adopt the detail-preserving pooling (DPP) method which can amplify the spatial changes to solve the problem of key details loss in traditional pooling methods. On the basis of the above improvements, a RM-IPR-DDHPE model based on Ranger optimizer, Mish activation function and integral attitude regression is constructed, which can avoid quantization errors, optimize the gradient propagation and structure of the network. We validate the classification ability of DDHPE on the CIFAR dataset and the performance of the RM-IPR-DDHPE model for predicting human keypoints on the MSCOCO2014 dataset and the MPII dataset. The results of DDHPE on CIFAR-10 and CIFAR-100 are 95.27 and 77.51 respectively. The AP, AP(50), AP(75), AP(M), AP(L) of RM-IPR-DDHPE on MSCOCO2014 are 78.0, 93.9, 85.4, 74.3, 84.9. And the average accuracy mAP of all key points on the MPII is 94.1. The results show that DDHPE has a good feature extraction ability, and the RM-IPR-DDHPE model improves the prediction accuracy while solving the quantization error of the DDHPE network joint point estimation.
C1 [Xu, Xinzheng; Guo, Yanyan; Wang, Xin] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Xu, XZ (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM xuxinzh@163.com
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Bin YR, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107410
   Cao DD, 2023, SIGNAL IMAGE VIDEO P, V17, P643, DOI 10.1007/s11760-022-02271-7
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen JT, 2020, PROC CVPR IEEE, P389, DOI 10.1109/CVPR42600.2020.00047
   Chen X, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1407.3399
   Chen Y, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1705.00389
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Chu X, 2017, arXiv, DOI DOI 10.48550/ARXIV.1702.07432
   Clevert D., 2016, ARXIV151107289
   Fang H-S, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1612.00137
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Kumar M, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01869-4
   Li R, 2022, 2022 7 INT C INTELLI, P1166, DOI [10.1109/ICSP54964.2022.9778346, DOI 10.1109/ICSP54964.2022.9778346]
   Li W, 2019, P IEEE C COMP VIS PA, DOI DOI 10.48550/ARXIV.1901.00148
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luvizon DC, 2017, HUMAN POSE REGRESSIO, DOI [10.1016/j.cag.2019.09.002, DOI 10.1016/J.CAG.2019.09.002]
   Manchen Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11085, DOI 10.1109/CVPR42600.2020.01110
   Marusov Alexander, 2022, 2022 31st Conference of Open Innovations Association (FRUCT)., P174, DOI 10.23919/FRUCT54823.2022.9770903
   Misra D, 2019, ARXIV PREPRINT ARXIV, V4, P10, DOI [10.48550/arXiv.1908.0868, DOI 10.48550/ARXIV.1908.0868]
   Newell A., 2016, P ADV NEURAL INFORM, DOI [10.48550/arXiv.1611.05424, DOI 10.48550/ARXIV.1611.05424]
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ou ZL, 2022, J SUPERCOMPUT, V78, P691, DOI 10.1007/s11227-021-03889-z
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A, 2014, Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550, DOI [10.48550/arXiv.1412.6550, DOI 10.48550/ARXIV.1412.6550]
   Saeedan F, 2018, PROC CVPR IEEE, P9108, DOI 10.1109/CVPR.2018.00949
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Songkai Xiong, 2021, 2021 IEEE 7th International Conference on Cloud Computing and Intelligent Systems (CCIS), P183, DOI 10.1109/CCIS53392.2021.9754658
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun X, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1704.00159
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Tong QQ, 2022, NEUROCOMPUTING, V481, P333, DOI 10.1016/j.neucom.2022.01.014
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang WM, 2022, NEUROCOMPUTING, V480, P220, DOI 10.1016/j.neucom.2021.12.083
   Wang Z, 2021, 2021 INT C NETWORKIN, P166, DOI [10.1109/INSAI54028.2021.00039, DOI 10.1109/INSAI54028.2021.00039]
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu XN, 2021, IEEE TALE2021: IEEE INTERNATIONAL CONFERENCE ON ENGINEERING, TECHNOLOGY AND EDUCATION, P1085, DOI 10.1109/TALE52509.2021.9678618
   Xiang Xueyong, 2022, 2022 7th International Conference on Image, Vision and Computing (ICIVC), P340, DOI 10.1109/ICIVC55077.2022.9886287
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.00388
NR 52
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36019
EP 36039
DI 10.1007/s11042-023-15057-x
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000949737500003
DA 2024-07-18
ER

PT J
AU Roy, M
   Chakraborty, S
   Mali, K
AF Roy, Mousomi
   Chakraborty, Shouvik
   Mali, Kalyani
TI An evolutionary image encryption system with chaos theory and DNA
   encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA encoding; Modified logistic map; Elitist genetic
   algorithm
ID HYBRID GENETIC ALGORITHM; MATRIX; DESIGN; MAP
AB This article proposes a novel evolutionary image encryption approach based on an elitist genetic algorithm, a modified logistic map, and DNA encoding. The initial population comprises the DNA masks which are formed using the DNA sequences and modified logistic map. The elitist genetic algorithm determines the optimal mask depending on the value of the information entropy which is used as the objective function. The simple elitist genetic algorithm is used to get the optimal DNA mask to keep the process simple and reduce the computational burden. The proposed approach can significantly improve the performance of the encryption process by determining the optimal mask which is suitable for a certain image. The experimental outcomes and their analysis establish that the proposed approach produces excellent results and is resilient against different types of attacks. A detailed and comprehensive analysis of the overall system will certainly help adapt the proposed approach to make real-life image communications secure.
C1 [Roy, Mousomi; Chakraborty, Shouvik; Mali, Kalyani] Univ Kalyani, Dept Comp Sci & Engn, Kalyani, India.
C3 Kalyani University
RP Chakraborty, S (corresponding author), Univ Kalyani, Dept Comp Sci & Engn, Kalyani, India.
EM iammouroy@gmail.com; shouvikchakraborty51@gmail.com;
   kalyanimali1992@gmail.com
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   [Anonymous], CVG-UGR-Image Database
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878
   Chakraborty S., 2015, 2 NATL C NCETAS 2015, V4, P61
   Chakraborty S., 2021, BIOMEDICAL IMAGE SEG, P299, DOI 10.1007/978-981-15-9433-5_29
   Chakraborty S., 2020, RES ANTHOLOGY MULTII, P17
   Chakraborty S., 2013, First International Conference on Computation and Communication Advancement, P69
   Chakraborty S, 2020, APPL INTELL, V50, P1775, DOI 10.1007/s10489-019-01604-3
   Chakraborty S, 2022, APPL SOFT COMPUT, V129, DOI 10.1016/j.asoc.2022.109625
   Chakraborty S, 2022, MULTIMED TOOLS APPL, V81, P15103, DOI 10.1007/s11042-022-12534-7
   Chakraborty S, 2022, KNOWL INF SYST, V64, P1121, DOI 10.1007/s10115-022-01659-8
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Chakraborty S, 2016, INT J SECUR APPL, V10, P205, DOI 10.14257/ijsia.2016.10.2.19
   Dagadu J.C., 2019, INT J NETW SECUR, V21, P83
   Dai CC, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P281, DOI 10.1109/CSCloud-EdgeCom49738.2020.00056
   De S, 2022, MULTIMED TOOLS APPL, V81, P5485, DOI 10.1007/s11042-021-11696-0
   Duan CF, 2022, OPT LASER ENG, V150, DOI 10.1016/j.optlaseng.2021.106881
   Eisham ZK, 2023, EVOL SYST-GER, V14, P605, DOI 10.1007/s12530-022-09443-3
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Hammad B.T., 2020, Bulletin of Electrical Engineering and Informatics, V9, P2484
   Han CY, 2019, OPTIK, V181, P779, DOI 10.1016/j.ijleo.2018.12.178
   Hore Sirshendu., 2016, International Journal of Electrical and Computer Engineering, V6, P2773, DOI [DOI 10.11591/IJECE.V6I6.11801, 10.11591/ijece.v6i6.11801]
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Li S, 2019, MULTIMEDIA SECURITY, P133
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Liu LF, 2022, MULTIMED TOOLS APPL, V81, P19999, DOI 10.1007/s11042-022-12765-8
   Liu XL, 2022, MULTIMED TOOLS APPL, V81, P21779, DOI 10.1007/s11042-022-12472-4
   Mali K, 2015, IJSRD-Int J Sci Res Dev, V3, P2321
   Mali K, 2015, INT J SECUR APPL, V9, P279, DOI 10.14257/ijsia.2015.9.12.26
   Mohamed Heba G, 2020, Entropy (Basel), V22, DOI 10.3390/e22020158
   Narkhede BE, 2020, INT J ADV MANUF TECH, V108, P3193, DOI 10.1007/s00170-020-05486-5
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Ouyang X, 2020, INT J MOD PHYS B, V34, DOI 10.1142/S0217979220500149
   Patro KAK, 2020, IETE TECH REV, V37, P223, DOI 10.1080/02564602.2019.1595751
   Ratheesh Kumar R, 2020, P 4 INT C COMPUTING
   Reddy MI, 2020, BIOSYSTEMS, V197, DOI 10.1016/j.biosystems.2020.104207
   Rodríguez-Esparza E, 2020, EXPERT SYST APPL, V155, DOI 10.1016/j.eswa.2020.113428
   Roy Mousomi, 2020, Proceedings of International Ethical Hacking Conference 2019. eHaCON 2019. Advances in Intelligent Systems and Computing (AISC 1065), P239, DOI 10.1007/978-981-15-0361-0_19
   Roy Mousomi, 2020, Proceedings of International Ethical Hacking Conference 2019. eHaCON 2019. Advances in Intelligent Systems and Computing (AISC 1065), P49, DOI 10.1007/978-981-15-0361-0_4
   Roy M, 2020, Biomedical Image Security Using Matrix Manipulation and DNA Encryption
   Roy M, 2020, Data Security Techniques Based on DNA Encryption
   Roy M, 2021, An image security method based on low dimensional chaotic environment and DNA encoding, P267
   Roy M, 2021, MICROSYST TECHNOL, V27, P3617, DOI 10.1007/s00542-020-05120-0
   Roy M, 2019, 2019 INTERNATIONAL CONFERENCE ON OPTO-ELECTRONICS AND APPLIED OPTICS (OPTRONIX 2019), DOI 10.1109/optronix.2019.8862350
   Roy M, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P881, DOI [10.1109/aicai.2019.8701382, 10.1109/AICAI.2019.8701382]
   Roy S, 2021, MULTIMED TOOLS APPL, V80, P31529, DOI 10.1007/s11042-020-09880-9
   Seal A, 2017, NEW RESILIENT IMAGE
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Suri Shelza, 2020, International Journal of Information and Computer Security, V12, P199
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu J, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010005
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xian YJ, 2023, MULTIMED TOOLS APPL, V82, P407, DOI 10.1007/s11042-022-13280-6
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 77
TC 1
Z9 1
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33607
EP 33635
DI 10.1007/s11042-023-14948-3
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943970200002
DA 2024-07-18
ER

PT J
AU Kim, KS
   Park, JS
AF Kim, Ki-Sik
   Park, Jong-Seung
TI Spherical PTAM : a versatile SLAM for spherical video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spherical video; SLAM; PTAM; Spherical distortion; Dual projection plane
AB The visual Simultaneous Localization and Mapping (SLAM) working with spherical video gives many advantages of a wide field of view. However, the conventional visual SLAM approaches are not directly applicable to the spherical videos due to the distortion introduced by equirectangular projection. Feature points extracted from spherical video frames are pervaded by spherical distortion. The spherical distortion should be properly handled to apply classical planar SLAM algorithm. For the versatile and accurate map construction, a PTAM for the spherical video requires an effective means to exclude the spherical distortion. This article proposes a novel visual SLAM method for 360-degree spherical video based on the monocular Parallel Tracking and Mapping (PTAM) approach. The propose method performs tracking and mapping with high accuracy through the idea of calculation and matching undistorted patches on the dual projection plane model. The experimental results show the proposed method gives high accuracy and stable performance.
C1 [Kim, Ki-Sik; Park, Jong-Seung] Incheon Natl Univ, Dept Comp Sci & Engn, Incheon, South Korea.
C3 Incheon National University
RP Park, JS (corresponding author), Incheon Natl Univ, Dept Comp Sci & Engn, Incheon, South Korea.
EM jong@inu.ac.kr
OI Park, Jong-Seung/0000-0002-3400-7361
CR [Anonymous], 2010, 10 OMNIVIS RSS
   Caruso D, 2015, IEEE INT C INT ROBOT, P141, DOI 10.1109/IROS.2015.7353366
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   De Croce M, 2019, J INTELL ROBOT SYST, V95, P365, DOI 10.1007/s10846-018-0913-6
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Gamallo C, 2015, ROBOT AUTON SYST, V65, P76, DOI 10.1016/j.robot.2014.11.008
   Harmat Adam, 2012, Intelligent Robotics and Applications. Proceedings of the 5th International Conference, ICIRA 2012, P421, DOI 10.1007/978-3-642-33509-9_42
   Kazerouni IA, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117734
   Khomutenko B, 2016, IEEE ROBOT AUTOM LET, V1, P137, DOI 10.1109/LRA.2015.2502921
   Klein George, 2007, P1
   Li JF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112268
   Liu SY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204494
   Barros AM, 2022, ROBOTICS, V11, DOI 10.3390/robotics11010024
   Matsuki H, 2018, IEEE ROBOT AUTOM LET, V3, P3693, DOI 10.1109/LRA.2018.2855443
   Montemerlo M., 2003, P INT JOINT C ARTIFI, P1151, DOI [10.5555/1630659.1630824, DOI 10.5555/1630659.1630824]
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   RIBEIRO M.I., 2004, Kalman and extended Kalman filters: Concept, derivation and properties
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rybski PE, 2008, AUTON ROBOT, V24, P229, DOI 10.1007/s10514-007-9067-2
   Schlegel C, 2008, LOCALIZATION MAPPING
   Stewénius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636
   Su H, 2020, VLDB J, V29, P3, DOI 10.1007/s00778-019-00574-9
   Taketomi T, 2017, IPSJ Trans. Comput. Vis. Appl, V9, P1, DOI [10.1186/s41074-017-0027-2, DOI 10.1186/S41074-017-0027-2]
   Tong G., 2013, PHOTOGRAMM REC, V28, P293
   Tribou MJ, 2015, INT J ROBOT RES, V34, P1480, DOI 10.1177/0278364915571429
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Valiente D, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121294
   Younes G, 2017, ROBOT AUTON SYST, V98, P67, DOI 10.1016/j.robot.2017.09.010
   Zhang Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030705
   Zhang ZC, 2016, IEEE INT CONF ROBOT, P801, DOI 10.1109/ICRA.2016.7487210
   Zhao Q, 2015, INT J COMPUT VISION, V113, P143, DOI 10.1007/s11263-014-0787-4
NR 37
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32151
EP 32175
DI 10.1007/s11042-023-14535-6
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100021
DA 2024-07-18
ER

PT J
AU Singh, OD
   Gupta, S
   Dora, S
AF Singh, Om Dev
   Gupta, Shailender
   Dora, Shirin
TI Segmentation technique for the detection of Micro cracks in solar cell
   using support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crack detection; Image processing; Machine learning; Segmentation; Solar
   cell; Support vector machine
ID CONCRETE; SYSTEM
AB Micro cracks in solar cells lower the overall performance of the solar panel. These cracks result from poor handling during transportation, fabrication, and installation. Another reason could be the harsh environmental conditions under which they are deployed. Identifying micro-cracks and their replacement is always needed to get the best performance out of available solar panels. Image processing and machine learning are two commonly used schemes for detecting the same. The former techniques cannot produce accurate results because they perform segmentation using fixed equations, whereas the latter techniques learn complex nonlinear features that are difficult for the human mind to process. This paper uses a Support Vector Machines (SVM) model for detecting micro-cracks in solar cells. An image processing technique is proposed to train the SVM model and to generate ground truth for segmentation on Electro-Luminescence Photo-Voltaic (elpv)-dataset, which was used by researchers for defect percentage classification and contains 2624 images in total. The proposed SVM model performed exceptionally well in terms of accuracy (91.079%), precision (87.289%), recall (96.314%), and F1 score (94.678%) in comparison to other available machine learning models.
C1 [Singh, Om Dev; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
   [Dora, Shirin] Ulster Univ, Intelligent Syst Res Ctr, Magee Campus, Londonderry, North Ireland.
C3 J.C. Bose University of Science & Technology, YMCA; Ulster University
RP Gupta, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM devsingh640@gmail.com; shailender81@gmail.com; Shirin.dora@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Anwar SA, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-15
   Anwar SA, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2012), P143, DOI 10.1109/ICCSCE.2012.6487131
   Buerhop C, 2018, A Benchmark for Visual Identification of Defective Solar Cells in Electroluminescence Imagery, P1287, DOI [10.4229/35thEUPVSEC20182018-5CV.3.15, DOI 10.4229/35THEUPVSEC20182018-5CV.3.15]
   Chatterjee A, 2018, EUR SIGNAL PR CONF, P2140, DOI 10.23919/EUSIPCO.2018.8553388
   Chawla R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0186-7
   Chen LC, 2006, J SURV ENG-ASCE, V132, P77, DOI 10.1061/(ASCE)0733-9453(2006)132:2(77)
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dare PM, 2002, PHOTOGRAMM REC, V17, P453, DOI 10.1111/0031-868X.00198
   Deitsch S, 2018, ARXIV
   Deitsch S, 2019, SOL ENERGY, V185, P455, DOI 10.1016/j.solener.2019.02.067
   Dhimish M, 2020, IEEE T IND INFORM, V16, P4769, DOI 10.1109/TII.2019.2946210
   Fujita Y, 2006, INT C PATT RECOG, P901
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ito A, 2002, IEEE IND ELEC, P2202
   Iyer S, 2005, IMAGE VISION COMPUT, V23, P921, DOI 10.1016/j.imavis.2005.05.017
   Moré LG, 2015, IEEE IMAGE PROC, P4644, DOI 10.1109/ICIP.2015.7351687
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Porebski A, 2008, 2008 FIRST INTERNATIONAL WORKSHOPS ON IMAGE PROCESSING THEORY, TOOLS AND APPLICATIONS (IPTA), P206
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Singh OD, 2021, MULTIMED TOOLS APPL, V80, P6509, DOI 10.1007/s11042-020-09915-1
   Sinha SK, 2006, AUTOMAT CONSTR, V15, P47, DOI 10.1016/j.autcon.2005.02.007
   Sinha SK, 2006, AUTOMAT CONSTR, V15, P58, DOI 10.1016/j.autcon.2005.02.006
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Yadav V, 2021, PERFORMANCE ANAL SVM, V7, P15, DOI [10.37628/IJECE, DOI 10.37628/IJECE]
   Yamaguchi T, 2008, IEEJ T ELECTR ELECTR, V3, P128, DOI 10.1002/tee.20244
   Yu SN, 2007, AUTOMAT CONSTR, V16, P255, DOI 10.1016/j.autcon.2006.05.003
   Zayed N, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/267807
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 28
TC 2
Z9 2
U1 7
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32091
EP 32116
DI 10.1007/s11042-023-14509-8
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100003
DA 2024-07-18
ER

PT J
AU Sucharitha, G
   Arora, N
   Sharma, SC
AF Sucharitha, G.
   Arora, Nitin
   Sharma, Subhash C.
TI Medical image retrieval using a novel local relative directional edge
   pattern and Zernike moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; DBSCAN; Feature descriptor; Feature extraction; Local patterns;
   Zernike moments
ID CLASSIFICATION; DESCRIPTOR
AB The traditional annotation-based medical image retrieval faces a problem with competence and precision with the extensive medical image databases. Broad research has been undertaken on Medical image retrieval (MIR) using local, global features of each image, and machine learning algorithms with reliable descriptors have shown the significant improvement of these systems. The proposed method is implemented with a novel approach to address the semantic gap and form efficient texture and shape features clusters. The texture and shape feature vectors are constructed using a novel Relative directional edge binary patterns (RDEBP) and complex Zernike moments. RDEBPs are used to extract the texture features of an image. For every defined square matrix of size 5 x 5, 4 RDEBP patterns are extracted, rich in providing the texture information of an object in the image. The binary patterns are calculated by considering the center pixel's neighbourhood and relations between neighbour pixels. The complex Zernike moments (ZM) give the shape properties of the object involved in the image. Combining these two features is effectively clustered using the Density-based spatial clustering of applications with noise (DBSCAN) algorithm. Finally, images are retrieved from the closest cluster using the d1-similarity metric concerning the query image. Therefore, the searching time for a query image from the specified cluster is reduced compared to the traditional Content-based image retrieval (CBIR), reflecting excellent response time and retrieval accuracy. Experiments on two databases were performed and confirmed the effectiveness of the proposed work over other state-of-the-art methods. The outcomes of the suggested method are more than 2 to 5% better when compared to the average values produced by other methods.
C1 [Sucharitha, G.] Inst Aeronaut Engn, Elect & Commun Engn, Dundigal, India.
   [Arora, Nitin; Sharma, Subhash C.] Indian Inst Technol Roorkee, Roorkee, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Sucharitha, G (corresponding author), Inst Aeronaut Engn, Elect & Commun Engn, Dundigal, India.
EM sucharithasu@gmail.com; nitinarora.iitr@gmail.com; scs60fpt@gmail.com
OI G, Sucharitha/0000-0002-3356-350X; ARORA, NITIN/0000-0002-0132-2648
CR Afifi AJ, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Aggarwal AK, 2020, UNMANNED AERIAL VEHICLE: APPLICATIONS IN AGRICULTURE AND ENVIRONMENT, P159, DOI 10.1007/978-3-030-27157-2_12
   Ahmad J, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0875-4
   [Anonymous], ECT EMPHYSEMA CT DAT
   Ashok S, 2020, P 2020 5 INT C COMM, P979, DOI [DOI 10.1109/ICCES48766.2020.9137986, 10.1109/ICCES48766.2020.9137986]
   Bedi AK, 2020, PATTERN RECOGN IMAGE, V30, P578
   Bhatt N, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.491
   Chen W., 2021, ARXIV
   Cheng, BRAIN TUMOR BRAIN TU
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Garg M, 2021, Autonomous driving and advanced driver-assistance systems (ADAS), P233
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Karanwal S., 2021, J VIS COMMUN IMAGE R, V102948, P110
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Khalid MJ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111886
   Kulshreshtha D, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P634, DOI 10.1109/ICIVC.2017.7984633
   Li Z., 2012, PROC C ASS ADV ARTIF, P1026, DOI DOI 10.1609/AAAI.V26I1.8289
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Liu H, 2021, DIGIT SIGNAL PROCESS, V2021
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Maji Subhadip, 2021, ACM/IMS Transactions on Data Science, V2, DOI 10.1145/3470568
   Martolia M., 2020, Int. J. Adv. Sci. Technol., V29, P1630
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Pathak D, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6851
   Pietikinen M., 2015, Advances in Independent Component Analysis and Learning Machines, P175
   Pradhan J., 2022, J WOMENS HEALTH, V103396, P83
   Pradhan J., 2021, APPL SOFT COMPUT, V107063, P102
   Pradhan J, 2019, MULTIMED TOOLS APPL, V78, P1685, DOI 10.1007/s11042-018-6246-4
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Sasaki Y., 2007, Teach Tutor Mater, V1, P1
   Seetharaman K, 2016, J KING SAUD UNIV-COM, V28, P110, DOI 10.1016/j.jksuci.2014.10.006
   Shabat AM, 2016, LECT NOTES COMPUT SC, V9730, P226, DOI 10.1007/978-3-319-41501-7_26
   Singh V. P., 2017, Int. J. Hybrid Intell. Syst, V14, P31
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Srinivas M, 2015, NEUROCOMPUTING, V168, P880, DOI 10.1016/j.neucom.2015.05.036
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Sucharitha G., 2017, INT J ELECTR COMPUT, V7, P1651
   Tahmasbi A, 2011, COMPUT BIOL MED, V41, P726, DOI 10.1016/j.compbiomed.2011.06.009
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Tuyet VTH, 2021, MOBILE NETW APPL, V26, P1300, DOI 10.1007/s11036-021-01762-0
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Zhang G, 2007, INT C WAVEL ANAL PAT, P169
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
NR 48
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31737
EP 31757
DI 10.1007/s11042-023-14720-7
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000943009100004
DA 2024-07-18
ER

PT J
AU Choukali, MA
   Valizadeh, M
   Amirani, MC
   Mirbolouk, S
AF Choukali, Mohammad Amin
   Valizadeh, Morteza
   Amirani, Mehdi Chehel
   Mirbolouk, Sedighe
TI A desired histogram estimation accompanied with an exact histogram
   matching method for image contrast enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Histogram matching; Desired histogram estimation; 2D
   histogram; Gaussian distribution
ID EQUALIZATION; FRAMEWORK; ALGORITHM
AB In this paper, a novel image contrast enhancement method based on the histogram specification concept is presented. The proposed algorithm first, models the input image's histogram by employing linear combination of three Gaussian functions that are specified by a few parameters. Then, by properly tuning these parameters via some intuitive rules, it provides a desired histogram of the initial version with a larger dynamic range, which will be employed in the subsequent histogram specification phase. After that, the original input histogram is adopted to the desired version through a two dimensional (2D) histogram-based matching scheme. Finally, the input image gray levels are mapped to their corresponding output values through the mentioned framework and the enhanced output image is constructed. Experimental results reveals that the proposed algorithm does not lose any details of the original images and it provides high quality enhanced output with more natural-looking. Also, the suggested method outperforms many well-known enhancement algorithms considering the quantitative and qualitative evaluations.
C1 [Choukali, Mohammad Amin; Valizadeh, Morteza; Amirani, Mehdi Chehel; Mirbolouk, Sedighe] Urmia Univ, Dept Elect & Comp Engn, Orumiyeh, Iran.
C3 Urmia University
RP Valizadeh, M (corresponding author), Urmia Univ, Dept Elect & Comp Engn, Orumiyeh, Iran.
EM mo.valizadeh@urmia.ac.ir
RI Chehel Amirani, Mehdi/AGL-1681-2022
OI Valizadeh, Morteza/0000-0003-2204-3303
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   [Anonymous], 2009, J BIOMED OPT
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Celik T, 2012, IEEE T IMAGE PROCESS, V21, P145, DOI 10.1109/TIP.2011.2162419
   Chaudhary S., 2022, MULTIMED TOOLS APPL, V5, P1
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Cheng F. C., 2013, J DISP TECHNOL, V9, P44, DOI DOI 10.1109/JDT.2012.2226234
   Chiu YS, 2011, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2011.6084119
   Choukali MA, 2020, MULTIDIM SYST SIGN P, V31, P299, DOI 10.1007/s11045-019-00666-3
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Duda R., 1973, Pattern Classification and Scene Analysis
   Eng HL, 2008, IEEE T CIRC SYST VID, V18, P196, DOI 10.1109/TCSVT.2007.913960
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gonzalez RC, 2007, MATLAB SIM SV, P07
   Huang SC, 2014, IEEE T IMAGE PROCESS, V23, P4426, DOI 10.1109/TIP.2014.2348869
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jayasankari S, 2021, CIRC SYST SIGNAL PR, V40, P1252, DOI 10.1007/s00034-020-01515-6
   Jebadass JR, 2022, SOFT COMPUT, V26, P4949, DOI 10.1007/s00500-021-06539-x
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Mirbolouk S, 2021, MULTIMED TOOLS APPL, V80, P2221, DOI 10.1007/s11042-020-09801-w
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panetta K, 2011, IEEE T SYST MAN CY B, V41, P460, DOI 10.1109/TSMCB.2010.2058847
   Rafael C.Gonzalez., 2004, DIGITAL IMAGE PROCES
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Sulochana S., 2011, INT J COMPUT APPL, V35, P1
   Sun CC, 2005, IEEE T CONSUM ELECTR, V51, P1300
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Tsai CM, 2013, APPL MATH INFORM SCI, V7, P2019, DOI 10.12785/amis/070542
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yoon JH, 2002, IEICE T INF SYST, VE85D, P298
   Zhu YL, 2012, PHYSCS PROC, V25, P601, DOI 10.1016/j.phpro.2012.03.132
NR 39
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28345
EP 28365
DI 10.1007/s11042-023-14830-2
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000940065100010
DA 2024-07-18
ER

PT J
AU Rachapudi, V
   Rao, KS
   Rao, TSM
   Dileep, P
   Roy, TLD
AF Rachapudi, Venubabu
   Rao, K. Subba
   Rao, T. Subha Mastan
   Dileep, P.
   Deepika Roy, T. L.
TI Diabetic retinopathy detection by optimized deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy (DR); Butterfly optimization algorithm; Deep neural
   network (DNN); Histogram equalization (HE); Modified expectation
   maximization (MEM) algorithm; Fundus image
ID CLASSIFICATION; EXTRACTION
AB In the medical image analysis, the diagnosis of diabetic retinopathy (DR) from fundus images are identified as an open challenge and requires possible solutions. The major stages of the proposed DR are Pre-processing, Segmentation, Feature Extraction, and Classification. In Pre-processing, the retinal fundus images are RGB images, among them the G-channel is selected. Following that, histogram equalization and contrast limited adaptive histogram equalization (HE and CLAHE) are applied. Then the next stage is removing the optic disc (OD) and it is done by Circle Hough Transform (CHT). Then, the Gray Level thresholding is used for removing the blood vessels. Then the Exudates are segmented by the Modified Expectation Maximization (MEM) algorithm. Then Gray Level Co-occurrence Matrix (GLCM) is used for feature extraction. At last, features are classified by the Deep Neural Network with a Butterfly Optimization Algorithm (DNN-BOA) classifier which is used for classifying the several stages of DR. The proposed scheme is implemented on MATLAB 2021a. The performance of the implemented of the proposed scheme is compared with the other approaches with some measures like precision, accuracy, sensitivity, F-score and specificity on the DIARETDB1 and MESSIDOR datasets. The accuracy of the proposed scheme is 0.983 and 0.989 on the two datasets respectively. The accuracy of the proposed scheme is 25.9%, 23.29%, 14.5% and 16.6% better than the approaches like KNN, SVM, DNN and DBN on the MESSIDOR dataset.
C1 [Rachapudi, Venubabu] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Guntur, Andhra Pradesh, India.
   [Rao, K. Subba] B V Raju Inst Technol, Dept Comp Sci & Engn, Medak, Telangana, India.
   [Rao, T. Subha Mastan] CMR Tech Campus, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Dileep, P.] Malla Reddy Coll Engn & Technol, Dept Comp Sci & Engn, Kompally, Hyderabad, Telangana, India.
   [Deepika Roy, T. L.] CMR Tech Campus, Dept Comp Sci & Engn, AI&ML, Hyderabad, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Malla Reddy College of Engineering & Technology
RP Rachapudi, V (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Guntur, Andhra Pradesh, India.
EM venubabu.r@gmail.com
RI RACHAPUDI, VENUBABU/U-5960-2018; T.L., Deepika Roy/KHT-2172-2024;
   RACHAPUDI, Dr VENU BABU/ABZ-7336-2022; Tummapudi, Subha Mastan
   Rao/IYJ-2795-2023
OI RACHAPUDI, VENUBABU/0000-0002-5969-7733; RACHAPUDI, Dr VENU
   BABU/0000-0002-5969-7733; Tummapudi, Subha Mastan
   Rao/0000-0002-3967-5625; katta, Subbarao/0000-0003-2888-7531
CR Abràmoff MD, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0040-6
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Al Zaid E, 2018, P 2018 1 ST INT C CO, V4-6, P1
   Al-Jarrah Mohammad A., 2017, Journal of Medical Engineering & Technology, V41, P498, DOI 10.1080/03091902.2017.1358772
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   [Anonymous], 3 PART MESS
   [Anonymous], 2019, KNOWL-BASED SYST
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Chakraborty Sabyasachi, 2020, International Journal of Information Technology, V12, P473, DOI 10.1007/s41870-019-00318-6
   Costa P, 2018, IEEE ACCESS, V6, P18747, DOI 10.1109/ACCESS.2018.2816003
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kamble VV, 2020, PROCEDIA COMPUT SCI, V167, P799, DOI 10.1016/j.procs.2020.03.429
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   Kauppi T., 2007, MED IMAGE UNDERSTAND, P61, DOI DOI 10.5244/C.21.15
   Lim S. T., 2011, 2011 IEEE Colloquium on Humanities, Science and Engineering (CHUSER 2011), P265, DOI 10.1109/CHUSER.2011.6163730
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long SC, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/3926930
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu L, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-42999-1
   Mane VM, 2017, BIOMED ENG-BIOMED TE, V62, P321, DOI 10.1515/bmt-2016-0112
   Mobeen-ur-Rehman, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P244, DOI [10.1109/AICAI.2019.8701231, 10.1109/aicai.2019.8701231]
   Patwari M.B., 2013, Int. J. Comput. Appl, V77, P29
   Ponnibala M, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00331-9
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Ramachandran N, 2018, CLIN EXP OPHTHALMOL, V46, P412, DOI 10.1111/ceo.13056
   Sengupta S, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101758
   Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Sikder N, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040670
   Son J, 2020, OPHTHALMOLOGY, V127, P85, DOI 10.1016/j.ophtha.2019.05.029
   Syahputra M. F., 2019, Journal of Physics: Conference Series, V1235, DOI 10.1088/1742-6596/1235/1/012103
   Ting DSW, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0097-x
   Vega R, 2015, COMPUT BIOL MED, V58, P20, DOI 10.1016/j.compbiomed.2014.12.016
   Wang J, 2019, IEEE ACCESS, V7, P102589, DOI 10.1109/ACCESS.2019.2930941
   Welikala RA, 2015, COMPUT MED IMAG GRAP, V43, P64, DOI 10.1016/j.compmedimag.2015.03.003
   Wong TY, 2020, OPHTHALMOLOGICA, V243, P9, DOI 10.1159/000502387
   Yu S, 2015, ULTRASOUND MED BIOL, V41, P2677, DOI 10.1016/j.ultrasmedbio.2015.05.015
NR 43
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27949
EP 27971
DI 10.1007/s11042-023-14606-8
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000940065100003
DA 2024-07-18
ER

PT J
AU Kumar, S
   Sagar, V
   Punetha, D
AF Kumar, Sanjeev
   Sagar, Vikas
   Punetha, Deepak
TI A comparative study on facial expression recognition using local binary
   patterns, convolutional neural network and frequency neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Local binary patterns; Convolutional
   neural network; Frequency neural network; Feature extraction; Deep
   learning
ID CLASSIFICATION
AB As the principal processing method for nonverbal intentions, Facial Expression Recognition (FER) is an important and promising topic of computer vision and artificial intelligence, as well as one of the subject areas of symmetry. This research work provides a thorough and well-organized comprehensive comparative empirical study of facial expression recognition based on a deep learning study in frequency domain, convolution neural network, and local binary patterns features. We have attained the FER by incorporating neutral, joy, anger, fear, sadness, disgust, and surprise as seven universal emotional categories. In terms of methodology, we present a broad framework for a traditional FER approach and analyze the possible technologies that can be used in each component to emphasis the contrasts and similarities. Even though there has been a lot of research done with static images, there is still a lot of work being done to develop new ways that are easier to compute and use less memory than prior methods. This research could pave the way for a new approach to facial emotion identification in terms of accuracy and high-performance.
C1 [Kumar, Sanjeev] GL Bajaj Inst Technol & Management, Dept Master Comp Applicat, Greater Noida, Uttar Pradesh, India.
   [Sagar, Vikas] Noida Inst Engn & Technol, Dept Artificial Intelligence, Greater Noida, Uttar Pradesh, India.
   [Punetha, Deepak] Vellore Inst Technol VIT Univ, Sch Elect Engn, Chennai 600127, Tamilnadu, India.
C3 Noida Institute of Engineering & Technology; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Punetha, D (corresponding author), Vellore Inst Technol VIT Univ, Sch Elect Engn, Chennai 600127, Tamilnadu, India.
EM sanjeevnmc83@gmail.com; vikassagar52@gmail.com; deepak.punetha@vit.ac.in
RI Kumar, Sanjeev/GLU-8026-2022; punetha, deepak/T-1528-2018
OI Kumar, Sanjeev/0000-0001-9065-3010; punetha, deepak/0000-0002-5737-2900
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Al-Akam R, 2018, COMPUT SCI RES NOTES, V2803, P1, DOI 10.24132/CSRN.2018.2803.1
   [Anonymous], 2004, CVPR WORKSHOP FACE P
   Bartlett MS., 2005, PROC CVPR IEEE
   Chang Y., 2004, PROC CVPR IEEE
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Darwin C., 1872, P374
   Ekman P., 1975, EMOTION HUMAN FACE
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Guo Lili., 2016, P IEEE C COMP VIS PA, P86
   Hadid A., 2004, PROC CVPR IEEE
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Jabon ME, 2011, IEEE PERVAS COMPUT, V10, P84, DOI 10.1109/MPRV.2010.46
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kaliouby RE., 2004, REAL TIME VISION HUM
   Khan RA, 2012, IEEE IMAGE PROC, P2593, DOI 10.1109/ICIP.2012.6467429
   Lee CS., 2005, LECT NOTES COMPUT SC
   Li DH, 2021, APPL INTELL, V51, P2269, DOI 10.1007/s10489-020-01895-x
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mehta V, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P530, DOI 10.1109/ICACCE.2015.109
   Mohseni Sina, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P361
   Navjeet K., 2016, Int. J. Signal Process. Image Process. Pattern Recognit, V9, P11, DOI DOI 10.14257/IJSIP.2016.9.12.02
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Sajjad M, 2020, MOBILE NETW APPL, V25, P1611, DOI 10.1007/s11036-019-01366-9
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sun YY, 2019, IEEE ACCESS, V7, P28392, DOI 10.1109/ACCESS.2019.2901943
   Suwa M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P408
   Tang Y, 2018, IEEE ACCESS, V6, P42532, DOI 10.1109/ACCESS.2018.2858278
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Varga D, 2015, 2015 INTERNATIONAL CONFERENCE ON MODELS AND TECHNOLOGIES FOR INTELLIGENT TRANSPORTATION SYSTEMS (MT-ITS), P413, DOI 10.1109/MTITS.2015.7223288
   Wang S, 2021, J PAIN, V22, P196, DOI 10.1016/j.jpain.2020.07.004
   Wong K, 2009, SCI AM, V301, P94
   Xiao YG, 2006, IEEE IJCNN, P2421
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 41
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24369
EP 24385
DI 10.1007/s11042-023-14753-y
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000936292600002
DA 2024-07-18
ER

PT J
AU Bozkurt, I
   Ulutas, G
AF Bozkurt, Isilay
   Ulutas, Guzin
TI Detection and localization of frame duplication using binary image
   template
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensic; Passive forgery; Duplication detection; Discrete Cosine
   Transform (DCT); Binary image; Blurring attack
ID MOVE FORGERY DETECTION
AB Videos are one of the most substantial evidence that can be used to detect incidents. However, videos can be altered easily using current technologies. Alterations can be made for malicious purposes. Therefore, it is essential to determine the integrity of the videos that will be used as evidence or to give people the right idea. Alterations on the videos that have not previously added control data are within the scope of passive fraud detection. This study proposes an effective solution for detecting frame duplication attacks, which is one of the passive forgery types. The study is based on the visualization of feature vectors. A binary image is created with the feature matrix using feature vectors. Thus, a representative approach to the problem is presented. The forged frame-group template is obtained by processing the binary image, and then a search is done using this template. The proposed method provides solutions for both uncompressed and compressed videos. The algorithm's durability against compression has been tested by evaluating MPEG4 and H264 coded videos. A blurring attack can also be applied to the altered videos to hide the forgery. The results show that it is resistant to blurring attacks. Another factor that complicates fraud detection is the location of the forgery. The algorithm can detect forgery at the beginning or end of the video. The source of the forged frames can also be detected in the study. Experimental results show that the algorithm is resistant to compression, fast, and has a high accuracy rate.
C1 [Bozkurt, Isilay] Karadeniz Tech Univ, Technol Fac, Dept Software Engn, Trabzon, Turkiye.
   [Ulutas, Guzin] Karadeniz Tech Univ, Fac Engn, Dept Comp Engn, Trabzon, Turkiye.
C3 Karadeniz Technical University; Karadeniz Technical University
RP Bozkurt, I (corresponding author), Karadeniz Tech Univ, Technol Fac, Dept Software Engn, Trabzon, Turkiye.
EM isilaybozkurt@ktu.edu.tr; gulutas@ktu.edu.tr
OI Bozkurt, Isilay/0000-0001-6941-9721
CR [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   Bakas Jamimamul, 2021, Computers & Electrical Engineering, V89, DOI 10.1016/j.compeleceng.2020.106929
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bozkurt I, 2017, TURK J ELECTR ENG CO, V25, P4558, DOI 10.3906/elk-1703-125
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   Fayyaz MA, 2020, MULTIMED TOOLS APPL, V79, P5767, DOI 10.1007/s11042-019-08236-2
   Guo-Shiang Lin, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P1396, DOI 10.1109/ICCSE.2011.6028891
   Hosler B., 2019, ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). Proceedings, P8271, DOI 10.1109/ICASSP.2019.8682608
   Hosny KM, 2019, IET IMAGE PROCESS, V13, P1437, DOI 10.1049/iet-ipr.2018.5356
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   ieeeXplore, US
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Junyu Xu, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P160, DOI 10.1109/ICALIP.2012.6376604
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Li F., 2014, Proceedings of the 3rd International Conference on Multimedia Technology (ICMT 2013), P63
   Li X, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05975-5
   Long C, 2022, MULTIMEDIA FORENSICS, P333, DOI DOI 10.1007/978-981-16-7621-5_13
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Mukherjee P., 2015, INT J COMPUTER SCI M, V4, P702
   Nabi ST, 2022, MULTIMEDIA SYST, V28, P939, DOI 10.1007/s00530-021-00873-8
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Peterson L. L., 2007, Computer networks: a systems approach
   Prasath R, 2013, LECT NOTES COMPUTER, V8284, DOI [10.1007/978-3-319-03844-5, DOI 10.1007/978-3-319-03844-5]
   Pu H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21123953
   Qadir G., 2012, IET C IMAGE PROCESSI
   Ren HE, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/5595850
   sciencedirect, about us
   Scopus, ABOUT US
   Shelke NA, 2022, MULTIMEDIA SYST, V28, P267, DOI 10.1007/s00530-021-00837-y
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2021, MULTIMEDIA SYST, V27, P449, DOI 10.1007/s00530-020-00749-3
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Thajeel SA, 2019, KSII T INTERNET INF, V13, P4005, DOI 10.3837/tiis.2019.08.010
   Trace Library, US
   Ulutas G, 2020, PAMUKKALE U J ENG SC, V26, P983, DOI 10.5505/pajes.2020.75768
   Ulutas G, 2018, MULTIMEDIA SYST, V24, P549, DOI 10.1007/s00530-017-0581-6
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Ustubioglu B, 2016, LECT NOTES ELECTR EN, V363, P127, DOI 10.1007/978-3-319-22635-4_11
   Vinolin V., 2021, 2021 32nd Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC), P350, DOI 10.1109/ICCCT53315.2021.9711876
   Wang CY, 2019, IEEE ACCESS, V7, P170032, DOI 10.1109/ACCESS.2019.2955308
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Xu JY, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413540013
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yuting Su, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P461, DOI 10.1109/ITAIC.2011.6030373
   Zhenzhen Zhang, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P94, DOI 10.1007/978-3-319-31960-5_9
NR 51
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31001
EP 31034
DI 10.1007/s11042-023-14602-y
EA FEB 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936302600007
DA 2024-07-18
ER

PT J
AU Bhagat, M
   Kumar, D
AF Bhagat, Monu
   Kumar, Dilip
TI Efficient feature selection using BoWs and SURF method for leaf disease
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf disease; BoWs; SURF; K-means; Features; SVM
ID MEANS CLUSTERING-ALGORITHM; PEST DETECTION; CLASSIFICATION
AB When plant diseases appear, they have an adverse effect on agricultural output. Food insecurity would worsen if plant diseases were not identified accurately in time. Without early identification of plant diseases, agricultural production management and decision-making would not be feasible. Now a days deep learning model is widely used for image classification to get more accurate result. But machine learning based classifier also produces good result if good feature selection technique is used. In this paper, we have used hybrid machine learning techniques for classifying leaf diseases present in species such as tomato, potato and pepper bell. We have used bag-of- feature for visually representing diseased leaf features. SURF technique is used to extract strongest number of features and for classification task SVM is used. The proposed method gives good result in terms of precision, accuracy, recall, F1-score, FPR, FNR, and MCC on all the three employed datasets. The classification accuracy obtained in our proposed model on dataset1, dataset2 and dataset3 are 97%, 97% and 93% respectively. We have also calculated percentage feature reduction for all three types of species which are approximately 45.21%, 40.65% and 34.73% for tomato, potato and pepper bell respectively. We have compared disease classification accuracy of several previous work done by various authors on tomato leaf dataset using various machine learning and deep learning technique with our proposed work and find that our method is performing better.
C1 [Bhagat, Monu; Kumar, Dilip] Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Bhagat, M (corresponding author), Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
EM 2018rscs002@nitjsr.ac.in; dilip.cse@nitjsr.ac.in
RI Bhagat, Dr. Monu/GLS-1071-2022
OI Bhagat, Dr. Monu/0000-0001-9074-9653
CR Alahi MEE, 2018, IEEE INTERNET THINGS, V5, P4409, DOI 10.1109/JIOT.2018.2809669
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhagat Monu, 2019, 2019 Devices for Integrated Circuit (DevIC). Proceedings, P141, DOI 10.1109/DEVIC.2019.8783800
   Bhagat M, 2022, MULTIMED TOOLS APPL, V81, P33897, DOI 10.1007/s11042-022-12984-z
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Durmus Halil., 2017, 2017 6 INT C AGRO GE, P1, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2017.8047016
   Dutot M, 2013, POSTHARVEST BIOL TEC, V85, P45, DOI 10.1016/j.postharvbio.2013.04.003
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Elhassouny A., 2019, INT C COMP SCI REN E, P1, DOI [DOI 10.1109/ICCSRE.2019.8807737, 10.1109/ICCSRE.2019.8807737]
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Fuentes AF, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01162
   Gaikwad Sukanya S., 2022, International Journal of Information Technology, P3815, DOI 10.1007/s41870-022-00860-w
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Haque I., 2020, 2 INT C DAT ENG APPL, P1, DOI [DOI 10.1109/IDEA49133.2020.9170725, 10.1109/IDEA49133.2020.9170725]
   Hlaing Chit Su, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P439, DOI 10.1109/ICIS.2018.8466483
   Hlaing Chit Su, 2017, 2017 18th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT). Proceedings, P223, DOI 10.1109/PDCAT.2017.00044
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Li LL, 2021, IEEE ACCESS, V9, P56683, DOI 10.1109/ACCESS.2021.3069646
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahlein AK, 2013, REMOTE SENS ENVIRON, V128, P21, DOI 10.1016/j.rse.2012.09.019
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Tetila EC, 2017, IEEE GEOSCI REMOTE S, V14, P2190, DOI 10.1109/LGRS.2017.2743715
   Trivedi M., 2021, INT J APPL SCI ENG, V18, P1, DOI [DOI 10.6703/IJASE.202106_18(2).003, 10.6703/IJASE.202106_18(2).003]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang DY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40066-y
   Yamamoto K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112557
   Yuan L, 2014, FIELD CROP RES, V156, P199, DOI 10.1016/j.fcr.2013.11.012
   Zhang SW, 2019, COGN SYST RES, V53, P31, DOI 10.1016/j.cogsys.2018.04.006
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 35
TC 10
Z9 10
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28187
EP 28211
DI 10.1007/s11042-023-14625-5
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936501100011
DA 2024-07-18
ER

PT J
AU Mateo-Orcajada, A
   Vaquero-Cristóbal, R
   Abenza-Cano, L
AF Mateo-Orcajada, Adrian
   Vaquero-Cristobal, Raquel
   Abenza-Cano, Lucia
TI Performance and heart rate in elite league of legends players
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiac rhythm; Esports; Plays; Videogames
ID PHYSIOLOGICAL-CHARACTERISTICS; FITNESS; EXERCISE; QUALITY; DEMANDS;
   PROFILE; SPORT; FIT
AB The analysis of the most decisive factors in performance is fundamental in order to train on these aspects to maximize the chances of success in competition. However, in the field of esports, research that has analyzed performance is scarce and includes various modalities, making it difficult to draw conclusions for a specific esports. Due to the growing interest in League of Legends in recent years, this research focuses on this esports and has the following objectives: a) to analyze the differences in the variables of performance and heat rate (HR) as a function of winning or losing; b) to establish the differences in the HR of the players depending on the role of the player, the involvement of the player in the play, and the team that benefited from each action during the game; and c) to determine the physiological changes that players undergo depending on the type of action performed. Ninety games and 4638 plays of an elite League of Legends team composed of five male players were analyzed. The results showed that tower destruction and kills were the most decisive performance factors in the final result. Furthermore, although no differences in HR were found when comparing games won and lost, differences were observed depending on the player's participation and the action performed, with actions that directly involved the player and favored the team showing the greatest differences in HR, more specifically the obtaining of neutral objectives (Baron Nashor and Elder Dragon), the destruction of structures closest to the nexus base and the team fights.
C1 [Mateo-Orcajada, Adrian; Vaquero-Cristobal, Raquel; Abenza-Cano, Lucia] UCAM Univ Catolica Murcia, Fac Deporte, Murcia, Spain.
C3 Universidad Catolica de Murcia
RP Vaquero-Cristóbal, R (corresponding author), UCAM Univ Catolica Murcia, Fac Deporte, Murcia, Spain.
EM amateo5@ucam.edu; rvaquero@ucam.edu; labenza@ucam.edu
RI Vaquero-Cristóbal, Raquel/H-8757-2015; Mateo-Orcajada,
   Adrián/GQQ-7431-2022
OI Vaquero-Cristóbal, Raquel/0000-0003-2708-4817; Mateo-Orcajada,
   Adrián/0000-0001-8111-8358; ABENZA CANO, LUCIA/0000-0001-9583-737X
FU Seneca Foundation [21409/FPI/20]; Fundacion Seneca; Region de Murcia
   (Spain)
FX M-O, A. participation in this research is funding by Seneca Foundation -
   21409/FPI/20. Fundacion Seneca. Region de Murcia (Spain).
CR Ahn J., 2020, International Journal of Esports, V1
   Andre Thomas L, 2020, Int J Exerc Sci, V13, P1418
   [Anonymous], 2012, RAISING STAKES E SPO
   [Anonymous], 2016, International Journal of Applied Psychology, DOI DOI 10.5923/J.IJAP.20160602.01
   Póvoas SCA, 2019, SCAND J MED SCI SPOR, V29, P1537, DOI 10.1111/sms.13472
   Benum SD, 2021, ECOL PSYCHOL, V33, P90, DOI 10.1080/10407413.2021.1885979
   Blanco A., 1994, Apunts: Educacion Fisica y Deportes, V36, P26
   Bonnar D, 2019, SLEEP HEALTH, V5, P647, DOI 10.1016/j.sleh.2019.06.007
   Neto JAD, 2018, ENTERTAIN COMPUT, V26, P10, DOI 10.1016/j.entcom.2017.12.004
   Docherty D, 1982, Br J Sports Med, V16, P96
   Donaldson S, 2017, GAMES CULT, V12, P426, DOI 10.1177/1555412015590063
   Emmonds S, 2015, J STRENGTH COND RES, V29, P3367, DOI 10.1519/JSC.0000000000001002
   Ferrari Simon., 2013, DIGRA C
   Foster CD, 2010, J STRENGTH COND RES, V24, P906, DOI 10.1519/JSC.0b013e3181aeb11a
   Gaina R, 2018, LEAGUE LEGENDS STUDY, P1
   Gilgen-Ammann R, 2019, EUR J APPL PHYSIOL, V119, P1525, DOI 10.1007/s00421-019-04142-5
   Gundogdu S, 2021, MED BIOL ENG COMPUT, V59, P1691, DOI 10.1007/s11517-021-02389-9
   Himmelstein D, 2017, INT J GAMING COMPUT-, V9, P1, DOI 10.4018/IJGCMS.2017040101
   Hopkins WG, 2009, MED SCI SPORT EXER, V41, P3, DOI 10.1249/MSS.0b013e31818cb278
   Hoppe MW, 2014, PEDIATR EXERC SCI, V26, P281, DOI 10.1123/pes.2013-0195
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Hulaj R, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01510
   Jenny SE, 2018, J APPL SPORT MANAG, V10, P34, DOI 10.18666/JASM-2018-V10-I1-8469
   Jenny SE, 2017, QUEST, V69, P1, DOI 10.1080/00336297.2016.1144517
   Kim Yongwoo, 2021, [Journal of Korea Game Society, 한국게임학회 논문지], V21, P3
   Koshy A., 2020, Int. J. Esports, V1, P1
   Lazar N., 2010, COMPUT STAT DATA AN, V2, P243, DOI [10.1002/wics.75, DOI 10.1002/WICS.75]
   Leavitt A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4337, DOI 10.1145/2858036.2858132
   Lee Kyu Bok, 2021, [Global Cultural Contents, 글로벌문화콘텐츠], V47, P107, DOI 10.32611/jgcc.2021.5.47.107
   Leis O, 2020, PSYCHOL SPORT EXERC, V51, DOI 10.1016/j.psychsport.2020.101738
   Lord F, 2020, J SPORT SCI, V38, P2338, DOI 10.1080/02640414.2020.1785185
   Mateo-Orcajada A, 2022, COMPUT HUM BEHAV, V126, DOI 10.1016/j.chb.2021.107030
   Matsui A, 2020, GAMES CULT, V15, P9, DOI 10.1177/1555412019838095
   Maymin PZ, 2021, J QUANT ANAL SPORTS, V17, P11, DOI 10.1515/jqas-2019-0096
   Molodchik M, 2021, J SPORT ECON, V22, P571, DOI 10.1177/15270025211000389
   Moreira GBSM, 2017, 18TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND SIMULATION (GAME-ON(R) 2017), P5
   Nagorsky E, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237584
   Novak AR, 2020, INT J SPORTS SCI COA, V15, P809, DOI 10.1177/1747954120932853
   Pizzo AD, 2018, SPORT MARKET Q, V27, P108
   Pollock ML, 1998, MED SCI SPORT EXER, V30, P975, DOI 10.1097/00005768-199806000-00032
   Póvoas SCA, 2012, J STRENGTH COND RES, V26, P3365, DOI 10.1519/JSC.0b013e318248aeee
   Roffe M., 2007, REV PSICOL DEPORTE, V16, P227
   Sarmento H, 2022, SPORTS MED-OPEN, V8, DOI 10.1186/s40798-022-00454-7
   Sharpe B T., 2022, Journal of Electronic Gaming and Esports, V1, DOI [DOI 10.1123/JEGE.2022-0017, https://doi.org/10.1123/jege.2022-0017]
   Sousa A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01030
   Sporis G, 2010, COLLEGIUM ANTROPOL, V34, P1009
   Sporis G, 2009, J STRENGTH COND RES, V23, P1947, DOI 10.1519/JSC.0b013e3181b3e141
   Stein CM, 2017, METHODS MOL BIOL, V1666, P557, DOI 10.1007/978-1-4939-7274-6_28
   Szot M, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10020186
   ValladAo Silvio P, 2020, Int J Exerc Sci, V13, P1217
   von Elm E, 2007, PLOS MED, V4, P1623, DOI [10.1371/journal.pmed.0040296, 10.1016/S0140-6736(07)61602-X, 10.1371/journal.pmed.0040297]
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Watson B, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3441313
   Watson M., 2015, Journal of comparative research in Anthropology and Sociology, V6, P225
   Yeo M, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0860-y
   Zhuang W, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10070454
NR 56
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30151
EP 30176
DI 10.1007/s11042-023-14415-z
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000924075600003
DA 2024-07-18
ER

PT J
AU Nagakrishnan, R
   Revathi, A
AF Nagakrishnan, R.
   Revathi, A.
TI Novel secured speech communication for person authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D logistic map; DNA encoding; Person authentication system; Feature
   based crypto system
ID SPEAKER IDENTIFICATION; ENCRYPTION; ALGORITHM; VOICE
AB Biometrics is the common method of securely and efficiently identifying and authenticating individuals by using unique biological features. Some common biometrics is fingerprint, speech, iris and signature. In this paper, the cryptosystem is proposed to enhance security and conserve the transmission bandwidth in implementing an authentication system The design of speech based secured authentication systems include the extraction of features from speech, creation of templates and testing procedures to authenticate the persons. The speaker recognition system is formed using Mel Frequency Cepstral coefficients (MFCC) and Recurrent Neural network (RNN) based machine learning technique. For developing a training system, MFCC features are extracted from the training data set. The RNN network is trained with features and a speakers' template is created for each speaker. In testing phase to ensure security in speech based authentication, MFCC features are extracted from the test speech set and these features are encrypted before it gets transmitted through the unsecured channel. The proposed crypto system is developed based on 3D logistic chaotic map and DNA operation. Firstly, MFCC features derived from the test speech set are concatenated and subjected to first level diffusion and confused using 3D logistic map. The resultant is encoded as a DNA sequence E(n), using any one of the eight rules for encoding DNA. The DNA XOR operation is performed between E(n) and 3D logistic map DNA sequence L(n). Finally, the encrypted feature set is attained by DNA decoding. In the test phase, the proposed system decrypts the features and is matched with a stored trained model to locate the identity of the speaker. Overall accuracy is 88% for the text independent and 96% for the text dependent person authentication system tested with genuine utterances. This research is extended to estimate the performance against attacks utterance and propose system is assessed with respect to rejection rate.
C1 [Nagakrishnan, R.; Revathi, A.] SASTRA Deemed Univ, Dept ECE, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Deemed Univ, Dept ECE, Thanjavur, Tamil Nadu, India.
EM nagakrishnan@sastra.ac.in; revathi@ece.sastra.edu
CR Das BB, 2021, PROGR ADV COMPUTING, V1199, DOI [10.1007/978-981-15-6353-9_13, DOI 10.1007/978-981-15-6353-9_13]
   Das RK, 2017, J SIGNAL PROCESS SYS, V88, P259, DOI 10.1007/s11265-016-1148-z
   Dellwo V, 2018, OXFORD HDB VOICE PER, P777, DOI DOI 10.1093/OXFORDHB/9780198743187.013.36
   El Ayadi M, 2017, SPEECH COMMUN, V92, P52, DOI 10.1016/j.specom.2017.05.005
   Elsafty AH, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153347
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Ergünay SK, 2015, INT CONF BIOMETR THE
   Farsana FJ, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P2197, DOI 10.1109/ICCSP.2017.8286804
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   Hochreiter S., 1997, Neural Computation, V9, P1735
   Jiang YJ, 2018, MULTIMEDIA SYST, V24, P355, DOI 10.1007/s00530-017-0565-6
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Juhong A, 2019, WORLD C MED PHYS BIO, V68, DOI 10.1007/978-981-10-9035-6_30
   Kocarev L., 2001, IEEE CIRC SYST MAG, V1, P6, DOI DOI 10.1109/7384.963463
   Lakshmanan S, 2022, PATTERN ANAL APPL, V25, P395, DOI 10.1007/s10044-021-01047-y
   Lakshmi C, 2020, MULTIMEDIA SYST, V26, P301, DOI 10.1007/s00530-019-00644-6
   Li YZ, 2015, COMM COM INF SC, V557, P3, DOI 10.1007/978-3-662-48683-2_1
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Mostafa A, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P235, DOI 10.1109/ICENCO.2015.7416354
   Nagakrishnan R, 2022, MULTIMED TOOLS APPL, V81, P1179, DOI 10.1007/s11042-021-11365-2
   Nagakrishnan R, 2020, MULTIMED TOOLS APPL, V79, P20795, DOI 10.1007/s11042-020-08846-1
   Nagakrishnan R, 2018, 18 INT C INT SYST DE, V1, P1070, DOI [10.1007/978-3-030-16657-1_100, DOI 10.1007/978-3-030-16657-1_100]
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   PEACOCKE RD, 1990, COMPUTER, V23, P26, DOI 10.1109/2.56868
   Resmi P, 2021, INTELLIGENT DATA ENG, V1177, DOI [10.1007/978-981-15-5679-1_63, DOI 10.1007/978-981-15-5679-1_63]
   Revathi A, 2019, MULTIMED TOOLS APPL, V78, P1569, DOI 10.1007/s11042-018-6258-0
   Revathi A, 2018, INT J SPEECH TECHNOL, V21, P1021, DOI 10.1007/s10772-018-09563-9
   Sathiyamurthi P, 2022, MULTIMED TOOLS APPL, V81, P6331, DOI 10.1007/s11042-021-11757-4
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Sayed WS, 2018, IEEE INT CONF INDUST, P1526, DOI 10.1109/ICIT.2018.8352407
   Sheela SJ, 2017, PROCEEDINGS OF THE 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES (ICECCT)
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Singh, 2019, CSI COMMUNICATIONS, V42, P24
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yoo IC, 2015, IEEE-ACM T AUDIO SPE, V23, P2238, DOI 10.1109/TASLP.2015.2476762
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398
NR 37
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24771
EP 24801
DI 10.1007/s11042-022-14246-4
EA DEC 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000894530200001
DA 2024-07-18
ER

PT J
AU Goyal, K
   Kumar, P
   Verma, K
AF Goyal, Kashish
   Kumar, Parteek
   Verma, Karun
TI AI-based fruit identification and quality detection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fruit identification; Fruit quality; Bounding box; Object detection;
   Artificial intelligence
AB The technological development in today's era has unlocked the measures to propose new applications for the fruit industry. Automation boosts the economic growth and productivity of the country. Fruit quality detection in complex backgrounds using an automated system is significant for this sector. Fruit sorting has an impact on the export market and quality evaluation. One of the crucial qualities of grading fruits is their appearance, which affects their market value and the choice of the consumers. The manual sorting and inspection method takes a long time and is more tedious and exhaustive. Hence, an automated system is required to evaluate fruit, detect defects, and sort them based on their quality. Deep learning algorithms have highly influenced the area of object detection. Mask R-CNN and YOLOv5 are two object detection algorithms that have been experimented. YOLOv5 outperforms the Mask R-CNN approach when real-time object detection is required. The fruit identification and quality detection model is developed based on the YOLOv5 object detection system in the proposed work. The dataset includes 10,545 images of four different fruits, i.e., apple, banana, orange, and tomato, based on their quality. The model works in two phases. In phase 1, fruit is identified, and in phase 2, fruit quality detection is performed. The mosaic augmentation on the dataset has been applied for phase 1 training resulting in high detection performance and a robust system. The model classifies the fruit, and then the predicted image is passed to phase 2 for corresponding fruit quality detection. The mAP value of phase 1 is 92.80%. For phase 2, the mAP values for apple and banana quality detection models are 99.60% and 93.1%, respectively. The mAP values are 96.70% and 95% for orange and tomato quality detection models. The results show that the proposed method could realize fruit identification and quality detection on the validation dataset. The samples have been passed to show the real-time performance of the system. The efficiency of the trained model has been validated in different scenarios, including simple, complex, low-quality camera inputs. The fruit identification and quality detection model has been compared with several state-of-the-art detection methods, and the results are very encouraging.
C1 [Goyal, Kashish; Kumar, Parteek; Verma, Karun] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Goyal, K (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM kgoyal60_phd18@thapar.edu; parteek.bhatia@thapar.edu;
   karun.verma@thapar.edu
OI Verma, Karun/0000-0002-8822-6308; Kumar, Parteek/0000-0002-7584-8693
FU Thapar-TAU Center for Excellence in Food Security (T2CEFS) under the
   research project "A Data-Driven Approach to Precision Agriculture in
   Small Farms Project
FX This work is supported by Thapar-TAU Center for Excellence in Food
   Security (T2CEFS) under the research project "A Data-Driven Approach to
   Precision Agriculture in Small Farms Project."
CR ACFR FRUIT DATASET, US
   [Anonymous], 40 VEGETABLES FRUITS
   [Anonymous], GITHUB TZUTALIN LABE
   [Anonymous], BLIND REFERENCELESS
   Azizah LM, 2017, 2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P242, DOI 10.1109/ICCSCE.2017.8284412
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Chen WK, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8859237
   Ciocca G., 2018, Proceedings of 2018 IEEE 8th International Conference on Consumer Electronics - Berlin, P1
   Ciocca G, 2017, LECT NOTES COMPUT SC, V10590, P426, DOI 10.1007/978-3-319-70742-6_41
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Fu LH, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12020391
   Fu LH, 2020, IEEE ACCESS, V8, P196835, DOI 10.1109/ACCESS.2020.3029215
   Fu Y, FRUIT FRESHNESS GRAD
   Fu ZH, 2017, LECT NOTES COMPUT SC, V10361, P273, DOI 10.1007/978-3-319-63309-1_25
   Gan H, 2018, COMPUT ELECTRON AGR, V152, P117, DOI 10.1016/j.compag.2018.07.011
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   GitHub-facebookresearch/detectron2, GITHUB FACEBOOKRESEA
   Goyal K, 2022, ARCH COMPUT METHOD E, V29, P397, DOI 10.1007/s11831-021-09600-y
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   HongJun Wang, 2020, 2020 IEEE International Conference on Mechatronics and Automation (ICMA), P1083, DOI 10.1109/ICMA49215.2020.9233575
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hussain D, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6538117
   Ismail N, 2022, INFORM PROCESS AGR, V9, P24, DOI 10.1016/j.inpa.2021.01.005
   Jia WK, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105380
   Kang HW, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105302
   Kuznetsova A, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10071016
   Lawal MO, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81216-5
   Lawal OM, 2021, MULTIMED TOOLS APPL, V80, P26751, DOI 10.1007/s11042-021-10933-w
   Li GJ, 2021, IET IMAGE PROCESS, V15, P1998, DOI 10.1049/ipr2.12171
   Li YF, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-96103-2
   Liu GX, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072145
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Mezgec S, 2017, NUTRIENTS, V9, DOI 10.3390/nu9070657
   Trieu NM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210558
   Mirhaji H, 2021, COMPUT ELECTRON AGR, V191, DOI 10.1016/j.compag.2021.106533
   Mithun BS, 2018, PROC SPIE, V10665, DOI 10.1117/12.2306367
   Momeny M, 2020, POSTHARVEST BIOL TEC, V166, DOI 10.1016/j.postharvbio.2020.111204
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodríguez FJ, 2018, PROG ARTIF INTELL, V7, P119, DOI 10.1007/s13748-017-0137-1
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Tan WX, 2016, MULTIMED TOOLS APPL, V75, P16741, DOI 10.1007/s11042-015-2940-7
   Tian YN, 2019, J SENSORS, V2019, DOI 10.1155/2019/7630926
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Wan SH, 2020, COMPUT NETW, V168, DOI 10.1016/j.comnet.2019.107036
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang LL, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.839269
   Wang P, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11111059
   Wu A, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106454
   Xu RH, 2021, FRONT PSYCHIATRY, V12, DOI [10.3390/f12020217, 10.3389/fpsyt.2021.657224]
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Yanai K, 2015, IEEE INT C MULTIMEDI
   Yao J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141711
   Yu Y, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.06.001
   Zhang J, 2018, COMPUT ELECTRON AGR, V155, P386, DOI 10.1016/j.compag.2018.10.029
NR 58
TC 7
Z9 7
U1 16
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24573
EP 24604
DI 10.1007/s11042-022-14188-x
EA NOV 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000889417700004
DA 2024-07-18
ER

PT J
AU Muhammad, J
   Altun, H
AF Muhammad, Jawad
   Altun, Halis
TI Guiding genetic search algorithm with ANN based fitness function: a case
   study using structured HOG descriptors for license plate detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate detection; Structured histogram of oriented gradient; ANN
   and Genetic search algorithm
ID RECOGNITION
AB In literature, various metaheuristic approaches such as Genetic Search Algorithm (GSA), has been adopted for finding the sub-optimal solution to a wide range of optimization problems. The main challenges in adopting GSA is the formulation of a proper fitness function which provides a measure of evaluating the generated candidate solutions, as the subsequent steps in the searching process would mainly be based on the quality of the previous and current solutions. As such, this is a highly crucial step in the successful application of GSA. However, in most of the applications, the construction of the suitable fitness function is difficult due to lack of analytical relations between the GSA parameters and the fitness of the solution. In this paper, a GSA approach of using shallow artificial neural network as a surrogate fitness function is proposed to alleviate such difficulties in the application of the GSA. The license plate detection problem is selected as a case study. For this problem, a new set of features which is called structured Histogram of Oriented Gradients (sHOG) is proposed in order to improve the overall performance of the license plate detection problem. The sHOG features were used to train the shallow ANN which assigns a degree of confidence score to the candidate regions and hence guide the GSA search to sub-optimal solution in the search space of a given input image. The performance of the proposed approach was evaluated on a private and public license plates datasets and results proves that it can archive an IOU detection rate of up to 98.74% on the private dataset and 91.66% cross database performance on the public dataset.
C1 [Muhammad, Jawad] Univ Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Altun, Halis] Istanbul Hlth & Technol Univ, Fac Engn & Nat Sci, Dept Software Engn, Istanbul, Turkey.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Istanbul Health & Technology University
RP Muhammad, J (corresponding author), Univ Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
EM jawad@cripac.ia.ac.cn; halis.altun@istun.edu.tr
RI altun, halis/B-1493-2010
OI altun, halis/0000-0002-2126-8757
CR Abo Samra GA, 2014, IEEE T EVOLUT COMPUT, V18, P244, DOI 10.1109/TEVC.2013.2255611
   Al-Shemarry MS, 2018, EXPERT SYST APPL, V92, P216, DOI 10.1016/j.eswa.2017.09.036
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   [Anonymous], 2013, ADV COMPUT SCI INT J
   Arróspide J, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P223, DOI 10.1109/IVS.2012.6232119
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Avci G, 2009, INISTA, V2009, P392
   da Silva FA, 2013, ARXIV
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dias J, 2014, CENT EUR J OPER RES, V22, P431, DOI 10.1007/s10100-013-0289-4
   Dlagnekov L., 2004, License plate detection using adaboost
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Fatih Porikli T.K., 2006, IEEE INT C ADV VIDEO, P107
   Goodfellow I.J., 2013, arXiv
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   Ho WT, 2009, 2009 FIRST ASIAN CONFERENCE ON INTELLIGENT INFORMATION AND DATABASE SYSTEMS, P109, DOI 10.1109/ACIIDS.2009.25
   Jamtsho Y., 2020, ICT EXPRESS
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Kukreja A, 2017, INT RES J ENG TECHNO, V4, P4
   Kumar K, 2018, P 2 INT C COMP VIS P, DOI 10.1007/978-981-10-7898-9_4
   Li Q, 2014, IEEE T IMAGE PROCESS, V23, P4139, DOI 10.1109/TIP.2014.2343456
   Masood SZ, 2017, ARXIV
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Muhammad J, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1269, DOI 10.1109/SIU.2016.7495978
   Ning G, 2013, THESIS U MISSOURI CO, DOI 10.32469/10355/43016
   Pan JS, 2021, INFORM SCIENCES, V561, P304, DOI 10.1016/j.ins.2020.11.056
   Panchal T, 2016, PROCEDIA COMPUT SCI, V79, P419, DOI 10.1016/j.procs.2016.03.054
   Prates RF, 2014, ARXIV
   Puarungroj Wichai, 2018, Procedia Computer Science, V135, P214, DOI 10.1016/j.procs.2018.08.168
   Rafique MA, 2018, SOFT COMPUT, V22, P6429, DOI 10.1007/s00500-017-2696-2
   Saidani T, 2021, MULTIMED TOOLS APPL, V80, P36237, DOI 10.1007/s11042-021-11233-z
   Sedighi A, 2011, EXPERT SYST APPL, V38, P13497, DOI 10.1016/j.eswa.2011.02.030
   Sharma S, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P106, DOI 10.1145/3154979.3154999
   Shashirangana J, 2022, INT J INTELL SYST, V37, P10211, DOI 10.1002/int.22471
   Shi L., 2008, GECCO '08: Proceedings of the 2008 conference on Genetic and evolutionary computation, P1049
   Wang RM, 2014, OPTIK, V125, P2283, DOI 10.1016/j.ijleo.2013.10.126
   Wang YR, 2011, EXPERT SYST APPL, V38, P3142, DOI 10.1016/j.eswa.2010.08.106
   Yang J, 2021, SOFT COMPUT, V25, P1751, DOI 10.1007/s00500-020-05250-7
   Zhang HF, 2006, INT C PATT RECOG, P1102
   Zheng D, 2005, PATTERN RECOGN LETT, V26, P2431, DOI 10.1016/j.patrec.2005.04.014
   Zheng K, 2012, PROC IEEE INT SYMP, P1502, DOI 10.1109/ISIE.2012.6237313
NR 42
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17979
EP 17997
DI 10.1007/s11042-022-14195-y
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886192700002
DA 2024-07-18
ER

PT J
AU Labadin, J
   Hong, BH
   Tiong, WK
   Gill, BS
   Perera, D
   Rigit, ARH
   Singh, S
   Tan, CV
   Ghazali, SM
   Jelip, J
   Mokhtar, N
   Rashid, NBA
   Abu Bakar, HB
   Lim, JH
   Taib, NM
   George, A
AF Labadin, Jane
   Hong, Boon Hao
   Tiong, Wei King
   Gill, Balvinder Singh
   Perera, David
   Rigit, Andrew Ragai Henry
   Singh, Sarbhan
   Tan, Cia Vei
   Ghazali, Sumarni Mohd
   Jelip, Jenarun
   Mokhtar, Norhayati
   Rashid, Norafidah Binti Abdul
   Abu Bakar, Hazlin Bt
   Lim, Jyh Hann
   Taib, Norsyahida Md
   George, Aaron
TI Development and user testing study of MozzHub: a bipartite network-based
   dengue hotspot detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector control; Source of infection; Fogging; Malaysia; Model
   implementation
AB Traditionally, dengue is controlled by fogging, and the prime location for the control measure is at the patient's residence. However, when Malaysia was hit by the first wave of the Coronavirus disease (COVID-19), and the government-imposed movement control order, dengue cases have decreased by more than 30% from the previous year. This implies that residential areas may not be the prime locations for dengue-infected mosquitoes. The existing early warning system was focused on temporal prediction wherein the lack of consideration for spatial component at the microlevel and human mobility were not considered. Thus, we developed MozzHub, which is a web-based application system based on the bipartite network-based dengue model that is focused on identifying the source of dengue infection at a small spatial level (400 m) by integrating human mobility and environmental predictors. The model was earlier developed and validated; therefore, this study presents the design and implementation of the MozzHub system and the results of a preliminary pilot test and user acceptance of MozzHub in six district health offices in Malaysia. It was found that the MozzHub system is well received by the sample of end-users as it was demonstrated as a useful (77.4%), easy-to-operate system (80.6%), and has achieved adequate client satisfaction for its use (74.2%).
C1 [Labadin, Jane; Hong, Boon Hao; Tiong, Wei King] Univ Malaysia Sarawak, Fac Comp Sci & Informat Technol, Kota Samarahan 94300, Malaysia.
   [Gill, Balvinder Singh; Singh, Sarbhan; Tan, Cia Vei; Ghazali, Sumarni Mohd] Minist Hlth, Inst Med Res, Kuala Lumpur, Malaysia.
   [Perera, David] Univ Malaysia Sarawak, Inst Hlth & Community Med, Kota Samarahan 94300, Malaysia.
   [Rigit, Andrew Ragai Henry] Univ Malaysia Sarawak, Fac Engn, Kota Samarahan 94300, Malaysia.
   [Jelip, Jenarun; Mokhtar, Norhayati; Rashid, Norafidah Binti Abdul; Abu Bakar, Hazlin Bt; Lim, Jyh Hann; Taib, Norsyahida Md; George, Aaron] Minist Hlth, Putrajaya, Malaysia.
C3 University of Malaysia Sarawak; Kementerian Kesihatan Malaysia;
   University of Malaysia Sarawak; University of Malaysia Sarawak;
   Kementerian Kesihatan Malaysia
RP Labadin, J (corresponding author), Univ Malaysia Sarawak, Fac Comp Sci & Informat Technol, Kota Samarahan 94300, Malaysia.
EM ljane@unimas.my
RI Boon Hao, Hong/ABE-5304-2021; md taib, norsyahida/KJL-6747-2024
OI Boon Hao, Hong/0000-0002-2822-7480; 
FU Malaysia Ministry of Higher Education [PRGS/1/2020/ICT05/UNIMAS/02/1]
FX The authors thank the Malaysia Ministry of Higher Education for the
   Prototype Research Grant Scheme PRGS/1/2020/ICT05/UNIMAS/02/1 awarded to
   J. Labadin.
CR Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alzahrani T, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P890, DOI 10.1109/ASONAM.2014.6921691
   Alzahrani Taher., 2014, COMPLEX NETWORKS, P157
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Anno S, 2019, GEOSPATIAL HEALTH, V14, P183, DOI 10.4081/gh.2019.771
   [Anonymous], 2017, Int. Med. J.
   Bowman LR, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157971
   Davis F. D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results, DOI DOI 10.1016/S0378-7206(01)00143-4
   Eze M., 2011, 2011 IEEE Symposium on Computers & Informatics (ISCI), P715, DOI 10.1109/ISCI.2011.5959005
   Eze M, 2011, 2011 7TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN ASIA (CITA 11)
   Ge MQ, 2016, GENOM PROTEOM BIOINF, V14, P62, DOI 10.1016/j.gpb.2016.01.004
   Guo P, 2017, PLOS NEGLECT TROP D, V11, DOI 10.1371/journal.pntd.0005973
   Haghshenas SS, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17103730
   Hong BH, 2021, MODELING COVID 19 HO
   Hussain-Alkhateeb L, 2021, PLOS NEGLECT TROP D, V15, DOI 10.1371/journal.pntd.0009686
   Hussain-Alkhateeb L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196811
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   Isah H, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P994, DOI 10.1145/2808797.2808842
   Jain R, 2019, BMC INFECT DIS, V19, DOI 10.1186/s12879-019-3874-x
   Jayaraj VJ, 2019, ACTA TROP, V197, DOI 10.1016/j.actatropica.2019.105055
   Kleinberg JM, 1999, ACM COMPUT SURV, V31
   Kok WC, 2017 INT C COMPUTATI
   Kok WC, 2019, LECT NOTES ELECTR EN, V481, P335, DOI 10.1007/978-981-13-2622-6_33
   Lee J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060372
   Liljeros F, 2001, NATURE, V411, P907, DOI 10.1038/35082140
   Ministry of Health Malaysia, 2020, PRESS STAT DIR GEN H
   Mohd-Zaki AH, 2014, PLOS NEGLECT TROP D, V8, DOI 10.1371/journal.pntd.0003159
   Packierisamy PR, 2015, AM J TROP MED HYG, V93, P1020, DOI 10.4269/ajtmh.14-0667
   Rozilawati H, 2005, Trop Biomed, V22, P143
   Salim NAM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79193-2
   Shi Y, 2016, ENVIRON HEALTH PERSP, V124, P1369, DOI 10.1289/ehp.1509981
   Siswanto S., 2019, PUBLIC HLTH INDONESI, V5, P38, DOI [10.36685/phi.v5i2.261, DOI 10.36685/PHI.V5I2.261]
   Stoddard ST, 2013, P NATL ACAD SCI USA, V110, P994, DOI 10.1073/pnas.1213349110
   Stoddard ST, 2009, PLOS NEGLECT TROP D, V3, DOI 10.1371/journal.pntd.0000481
   Su TA, 2008, SINGAP MED J, V49, P1038
   Ying LC, 2015, PROCEDIA COMPUT SCI, V60, P266, DOI 10.1016/j.procs.2015.08.126
   Zohuri B., 2020, Mod. Approaches Mater. Sci., V2, P241, DOI [DOI 10.32474/MAMS.2020.02.000138, 10.32474/MAMS.2020.02.000138, 10.32474/mams.2020.02.000138]
NR 38
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17415
EP 17436
DI 10.1007/s11042-022-14120-3
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546800002
PM 36404933
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Tang, GC
   Xie, Y
   Li, K
   Liang, RY
   Zhao, L
AF Tang, Guichen
   Xie, Yue
   Li, Ke
   Liang, Ruiyu
   Zhao, Li
TI Multimodal emotion recognition from facial expression and speech based
   on feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal emotion recognition; Attention mechanism; Deep learning;
   Feature fusion
AB Multimodal emotion recognition is designed to use expression and speech information to identify individual behaviors. Feature fusion can enrich various modal information, which is an important method for multimodal emotion recognition. However, there are several modal information synchronizations and overfitting problems due to large feature dimensions. So, an attention mechanism is introduced to automate the network to pay attention to local effective information. It is used to perform audio and video feature fusion tasks and timing modeling tasks in the network. The main contributions are as follows: 1) the multi-head self-attention mechanism is used for feature fusion of audio and video data to avoid the influence of prior information on the fusion results, and 2) a bidirectional gated recurrent unit is used to model the time series of fusion features; furthermore, the autocorrelation coefficient in the time dimension is also calculated as attention for fusion. Experiment results show that the adopted attention mechanism can effectively improve the accuracy of multimodal emotion recognition.
C1 [Tang, Guichen; Xie, Yue; Liang, Ruiyu] Nanjing Inst Technol, Sch Informat & Commun Engn, Nanjing, Peoples R China.
   [Li, Ke; Zhao, Li] Southeast Univ, Informat Sci & Engn, Nanjing, Peoples R China.
C3 Nanjing Institute of Technology; Southeast University - China
RP Liang, RY (corresponding author), Nanjing Inst Technol, Sch Informat & Commun Engn, Nanjing, Peoples R China.
EM liangry@njit.edu.cn
RI Li, Ke/AAE-4203-2019; chen, wang/KGK-5932-2024; Liu,
   Yiwei/JUF-2477-2023; Li, YiXue/JRW-6306-2023; Wang, Luyao/JLL-2001-2023;
   guo, ppdop/KAL-9865-2024
OI Li, Ke/0000-0002-9181-3562; 
FU National Natural Science Foundation of China [62001215]; Research
   Foundation Project of Nanjing Institute of Technology [CKJC202001]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 62001215, the Research Foundation
   Project of Nanjing Institute of Technology under Grant No. CKJC202001.
   The authors would like to thank the reviewers for their valuable
   comments that helped in significant improvement of the quality of the
   paper.
CR Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   Ansari H, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Arias P, 2020, IEEE T AFFECT COMPUT, V11, P507, DOI 10.1109/TAFFC.2018.2811465
   Avots E, 2019, MACH VISION APPL, V30, P975, DOI 10.1007/s00138-018-0960-9
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Beard R., 2018, P 22 C COMP NAT LANG, P251
   Chen M, 2020, INTERSPEECH, P374, DOI 10.21437/Interspeech.2020-3156
   Cho K., 2014, ARXIV14061078
   Dedeoglu Mehmet, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P131, DOI 10.1109/ICDMW.2019.00029
   Nguyen D, 2018, COMPUT VIS IMAGE UND, V174, P33, DOI 10.1016/j.cviu.2018.06.005
   Ghaleb E, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925444, 10.1109/ACII.2019.8925444]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hossain MS, 2016, J MULTIMODAL USER IN, V10, P325, DOI 10.1007/s12193-015-0207-2
   Hsu JH, 2021, IEEE-ACM T AUDIO SPE, V29, P1675, DOI 10.1109/TASLP.2021.3076364
   Kingma D. P., 2014, arXiv
   Kumar S, 2018, IEEE IND APPLIC SOC
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Li SN, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P589, DOI 10.1145/3340555.3355719
   Likitha MS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2257, DOI 10.1109/WiSPNET.2017.8300161
   Liu SQ, 2021, IEEE ACM T COMPUT BI, V18, P1710, DOI 10.1109/TCBB.2020.3018137
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Mangai UG, 2010, IETE TECH REV, V27, P293, DOI 10.4103/0256-4602.64604
   Mansouri-Benssassi E., 2019, IEEE IJCNN, P1, DOI [DOI 10.1109/IJCNN.2019.8852473, DOI 10.1109/ijcnn.2019.8852473]
   Mariooryad S, 2013, IEEE T AFFECT COMPUT, V4, P183, DOI 10.1109/T-AFFC.2013.11
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Mittal T, 2020, AAAI CONF ARTIF INTE, V34, P1359
   Nguyen D, 2017, IEEE WINT CONF APPL, P1215, DOI 10.1109/WACV.2017.140
   Pandeya YR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144927
   Parthasarathy S, 2020, IEEE-ACM T AUDIO SPE, V28, P2697, DOI 10.1109/TASLP.2020.3023632
   Poria S, 2015, NEURAL NETWORKS, V63, P104, DOI 10.1016/j.neunet.2014.10.005
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Song KS, 2018, INT CONF UBIQ ROBOT, P472, DOI 10.1109/URAI.2018.8441795
   Subramanian G., 2021, 7 IEEE INT C BIOSIGN, DOI 10.1109/ICBSII51839.2021.9445146
   Vaswani A, 2017, ADV NEUR IN, V30
   Veni S., 2021, IOP C SERIES MAT SCI, V1084
   VIJAYVERGIA A, 2018, 2018 C INFORM COMMUN
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Wang XD, 2022, IEEE T CYBERNETICS, V52, P13293, DOI 10.1109/TCYB.2021.3130047
   Wang XD, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107443
   Wang XS, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115831
   Xu H, 2019, ARXIV
   Yan JJ, 2014, IEICE T INF SYST, VE97D, P610, DOI 10.1587/transinf.E97.D.610
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
NR 46
TC 5
Z9 5
U1 8
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16359
EP 16373
DI 10.1007/s11042-022-14185-0
EA NOV 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546800003
DA 2024-07-18
ER

PT J
AU Majumder, G
   Rajput, V
   Pakray, P
   Bandyopadhyay, S
   Favre, B
AF Majumder, Goutam
   Rajput, Vikrant
   Pakray, Partha
   Bandyopadhyay, Sivaji
   Favre, Benoit
TI Text summary evaluation based on interpretable semantic textual
   similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural network; Abstractive summarization; Interpretable semantic
   similarity; Alignment; Regression
AB Text summarization methods are much needed to tackle the ever-increasing volume of text data, accessible online to help us find the relevant information and quicker ingestion of relevant data. In this paper, we have reported two issues related to text summarization. At first, we developed a Deep Neural Network (DNN) based abstractive text summarization method. After that, a chunk alignment-based interpretable semantic textual similarity (iSTS) method is designed to evaluate the quality of the summary text with reference to the main text. We have used an attention-based encoder-decoder Recurrent Neural Network (RNN) model to develop the abstractive text summarization method. The encoder compresses the sequence information into a sequence of vectors to save the important information. A Long Short Term Memory (LSTM) based RNN model, composed of three stacks, takes the words in a sequence and produces the output as hidden states. During training, we have used word embeddings for each word with a dimension of 128. At first, the efficiency of the summary text in reference to the main text is evaluated using the BLEU score and ROUGE matrix. Further, the results are compared with the proposed iSTS-based evaluation measure. The quality of the summary text is accessed based on the similarity score, and for that, we have trained a multivariate supervised linear regression model. The supervised algorithm is trained with the features extracted from a pair of the chunk itself. The string similarity, distributional word representations, and relatedness scores between the chunks are provided as a feature vector to get the similarity score.
C1 [Majumder, Goutam] Lovely Profess Univ, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
   [Rajput, Vikrant; Pakray, Partha; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, India.
   [Favre, Benoit] Aix Marseille Univ, Univ Toulon, LIS, CNRS, Marseille, France.
C3 Lovely Professional University; National Institute of Technology (NIT
   System); National Institute of Technology Silchar; Aix-Marseille
   Universite; Centre National de la Recherche Scientifique (CNRS)
RP Pakray, P (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, India.
EM goutam.nita@gmail.com; vilcrantrajput040@gmail.com;
   parthapalcray@gmail.com; sivaji.cseju@gmail.com; benoit.favre@lis-lab.fr
RI Majumder, Dr. Goutam/AAD-6681-2022; Pakray, Partha/H-7805-2012
OI Majumder, Dr. Goutam/0000-0002-9892-4628; Pakray,
   Partha/0000-0003-3834-5154
FU DST-CNRS [IFC/4130/DST-CNRS/2018-19/IT25]
FX The work presented here falls under the research project entitled
   "<BOLD>Deep Summarization Evaluation</BOLD>" and funded by DST-CNRS
   Sanction Order No: IFC/4130/DST-CNRS/2018-19/IT25. The authors are also
   thankful to the Center for Natural Language Processing and Dept. of
   Computer Science & Engineering, NIT Silchar, for providing all the
   infrastructure to conduct all the experiments related to the work.
CR Abney SP, 1992, PRINCIPLE BASED PARS
   Agirre E, 2016, P 10 INT WORKSH SEM
   Agirre E., 2012, 1 JOINT C LEX COMP S
   Agirrea E, 2015, P 9 INT WORKSHOP SEM
   Allahyari Mehdi, 2017, ABS170702268 CORR
   [Anonymous], 2002, ACL
   [Anonymous], 2015, P 2015 C EMP METH NA
   [Anonymous], 2006, A closer look at skip-gram modelling
   [Anonymous], 2000, P 2 WORKSHOP LEARNIN
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cheng JP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P484
   Gao Y, 2019, P 23 C COMPUTATIONAL
   Graham Yvette., 2015, P 2015 C EMPIRICAL M, P128, DOI [DOI 10.18653/V1/D15-1013, 10.18653/v1/D15-1013]
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Jiang J., 1997, P INT C RES COMPUTAT
   Jones KS., 2009, EVALUATING NATURAL L
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Leacock C, 1998, LANG SPEECH & COMMUN, P265
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730
   Lopez-Gazpio I, 2017, KNOWL-BASED SYST, V119, P186, DOI 10.1016/j.knosys.2016.12.013
   Lopyrev K., 2015, ARXIV
   Majumder G, 2021, APPL INTELL, V51, P7322, DOI 10.1007/s10489-020-02144-x
   Majumder G, 2019, J INTELL FUZZY SYST, V36, P4797, DOI 10.3233/JIFS-179028
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nallapati R, 2016, P 20 SIGNLL C COMPUT
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Narayan S, 2018, P 2018 C N AM CHAPT
   Palaskar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6587
   Paszke A, 2019, ADV NEUR IN, V32
   Pavlick E, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P425
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Radev DR, 2002, COMPUT LINGUIST, V28, P399, DOI 10.1162/089120102762671927
   Raffel C, 2020, J MACH LEARN RES, V21
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Savelieva A, 2020, P KDD WORKSH CONV SY
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Sutskever I., 2014, 28 C NEUR INF PROC S
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Zhang Junzhe, 2020, P 37 INT C MACH LEAR
   ZHU J, 2018, P 2018 C EMP METH NA
NR 49
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 NOV 4
PY 2022
DI 10.1007/s11042-022-14082-6
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5Y0DG
UT WOS:000878962300001
DA 2024-07-18
ER

PT J
AU Tanwar, A
   Vishwakarma, DK
AF Tanwar, Ayush
   Vishwakarma, Dinesh Kumar
TI A deep neural network-based hybrid recommender system with user-user
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; User networks; Deep learning system; Hybrid
   recommender systems; Collaborative filtering
ID ALGORITHM
AB In today's digital age, choosing the right product, web page, news article, or even a research paper like this one from an extensive number of options is one of the most tedious tasks. The resolution to this problem is using a recommender system(RS), which helps you choose the suitable item according to your profile. In this research, We present a novel deep neural network based hybrid recommender system that addresses the lacunas of traditional Collaborative Filtering (CF) and current hybrid systems while also delivering higher accuracy in recommendations. Due to insufficient training data, CF recommender systems suffer from low accuracy, linear latent factor, and cold-start problem. To overcome these problems, we employ a Deep neural network-based approach which uses user and item vectors to encapsulate users' and items' data to train on High dimensionality non-linear data to provide more accurate recommendations. User-user networks are employed to provide a better collaboration and synergy facet to our model. In our approach, Combining user-user networks with Deep neural networks yields higher predictive accuracy and better running time than other state-of-art methods. Extensive experimentation on publicly available Flixster and MovieLens Datasets concludes that our technique outperforms current premier methods by achieving improvement of 19% in RMSE, 9.2% in MAE and 4.1% in F1 Score.
C1 [Tanwar, Ayush] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 110042, India.
   [Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
C3 Delhi Technological University; Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
EM ayushtw@gmail.com; dinesh@dtu.ac.in
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047
CR Agarap A. F., 2018, ARXIV
   Ali N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1356-9
   Almaghrabi M, 2018, 2018 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA ENGINEERING (ICMLDE 2018), P121, DOI 10.1109/iCMLDE.2018.00031
   Anowar F, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100378
   Chauhan S, 2021, 2021 5 INT C COMPUTI
   D'Angelo G, 2014, THEOR COMPUT SCI, V516, P1, DOI 10.1016/j.tcs.2013.11.001
   Di Noia Tommaso., 2012, Proceedings of the sixth ACM conference on Recommender systems, P253, DOI 10.1145/2365952.2366007
   Dong, 2017, FLIXSTER DATASET ZIP, DOI [10.6084/m9.figshare.5677741.v1, DOI 10.6084/M9.FIGSHARE.5677741.V1]
   Ertam F, 2019, APPL ACOUST, V156, P351, DOI 10.1016/j.apacoust.2019.07.033
   Ferreira D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165510
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Hameed M. A., 2012, International Journal on Computer Science and Engineering, V4, P859
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Huang LW, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106706
   Hwang TG, 2016, MULTIMED TOOLS APPL, V75, P12843, DOI 10.1007/s11042-016-3526-8
   Jazi SY, 2021, MULTIMED TOOLS APPL, V80, P13559, DOI 10.1007/s11042-020-10386-7
   Jeevamol J, 2021, EDUC INF TECHNOL, V26, P4993, DOI 10.1007/s10639-021-10508-0
   Jung YG, 2014, BIOTECHNOL BIOTEC EQ, V28, pS44, DOI 10.1080/13102818.2014.949045
   Katarya R, 2020, MULTIMED TOOLS APPL, V79, P35927, DOI 10.1007/s11042-020-09199-5
   Kiran R, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113054
   Kumar V, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9660032
   Kuo RJ, 2020, J INTERNET TECHNOL, V21, P701, DOI 10.3966/160792642020052103008
   Luong Vuong Nguyen, 2020, RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems, P96, DOI 10.1145/3400286.3418253
   Malagoli, 2019, GITHUB REPOSITORY
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Rahim R, 2018, J PHYS CONF SER, V1019, DOI 10.1088/1742-6596/1019/1/012036
   Sadaei HJ, 2016, APPL SOFT COMPUT, V40, P132, DOI 10.1016/j.asoc.2015.11.026
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Shaikh S, 2017, IEEE INT ADV COMPUT, P931, DOI [10.1109/IACC.2017.180, 10.1109/IACC.2017.0189]
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Sulthana AR, 2019, COMPUT ELECTR ENG, V74, P498, DOI 10.1016/j.compeleceng.2018.01.034
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Thakker U, 2021, MULTIMED TOOLS APPL, V80, P28647, DOI 10.1007/s11042-021-10965-2
   Xia X, 2021, AAAI CONF ARTIF INTE, V35, P4503
   Yang D, 2021, J ORGAN END USER COM, V33, P19, DOI 10.4018/JOEUC.20210501.oa2
   Yu K, 2004, IEEE T KNOWL DATA EN, V16, P56, DOI 10.1109/TKDE.2004.1264822
   Zafarani R., 2009, SOCIAL COMPUTING DAT
   Zihayat M, 2019, DECIS SUPPORT SYST, V117, P14, DOI 10.1016/j.dss.2018.12.001
NR 39
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15613
EP 15633
DI 10.1007/s11042-022-13936-3
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865911600005
DA 2024-07-18
ER

PT J
AU Liu, TH
   He, ZS
AF Liu, Taiheng
   He, Zhaoshui
TI EAF-SR: an enhanced autoencoder framework for social recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Recommender system; Stacked denoising autoencoder;
   Knowledge distillation; Social recommendation
ID MATRIX-FACTORIZATION; SPEECH; SYSTEMS
AB In the recommendation systems, the user feedback data (e.g., user-item rating and the social information) is usually sparse, discrete and full of noise. However, most of existing methods use it to make recommendations directly, which leads to the reduction of their recommendation accuracy and quality ultimately. To address this problem, this paper proposes an Enhanced Autoencoder Framework with knowledge distillation (EAF-SR) for learning robust information from user feedback data, where it consists of three parts: Pre-training, knowledge distillation layers and Re-training. Specifically, Pre-training is proposed to generate the soft targets by using the stacked denoising autoencoder (SDAE) from user feedbacks and trust information, which aims to reduce data noise. Then, knowledge distillation layers are developed to learn the robust information from the generated soft targets. Finally, Re-training network combined with Pre-training is designed to make recommendations for each user. Extensive experiments done on three real-world datasets (e.g., Flixster, Epinions and Douban) show that the proposed EAF-SR is superior to the state-of-the-art approaches.
C1 [Liu, Taiheng] Shenzhen Univ, Coll Mechatron & Control Engn, Guangdong Key Lab Electromagnet Control & Intelli, Shenzhen 518060, Peoples R China.
   [Liu, Taiheng] Shenzhen Univ, Coll Phys & Optoelect Engn, Shenzhen 518060, Peoples R China.
   [He, Zhaoshui] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.
   [He, Zhaoshui] Minist Educ, Key Lab IoT Intelligent Informat Proc & Syst Inte, Guangzhou 510006, Peoples R China.
   [He, Zhaoshui] Guangdong Key Lab IoT Informat Technol, Guangzhou 510006, Peoples R China.
   [He, Zhaoshui] Guangdong HongKong Macao Joint Lab Smart Discrete, Guangzhou 510006, Peoples R China.
C3 Shenzhen University; Shenzhen University; Guangdong University of
   Technology
RP He, ZS (corresponding author), Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.; He, ZS (corresponding author), Minist Educ, Key Lab IoT Intelligent Informat Proc & Syst Inte, Guangzhou 510006, Peoples R China.; He, ZS (corresponding author), Guangdong Key Lab IoT Informat Technol, Guangzhou 510006, Peoples R China.; He, ZS (corresponding author), Guangdong HongKong Macao Joint Lab Smart Discrete, Guangzhou 510006, Peoples R China.
EM 2111714019@mail2.gdut.edu.cn; zhshhe@gdut.edu.cn
RI Taiheng, Liu/AAA-3260-2022; Taiheng, Liu,/KUD-4826-2024
OI Taiheng, Liu/0000-0002-3282-6785; Taiheng, Liu,/0000-0002-3282-6785
FU Guangdong Key Laboratory of Electromagnetic Control and Intelligent
   Robots; National Natural Science Foundation of China [U1813212,
   62273105, U1911401, 61727810]; Guangdong Province Foundation
   [2019B1515120036, 501200069]; Science and Technology Planning Project of
   Guangdong Province [2020B121201012]; Shenzhen Science and Technology
   Planning Project [JSGG20210802153155018]; Ten Thousand Talent Program
FX This work was supported in part by Guangdong Key Laboratory of
   Electromagnetic Control and Intelligent Robots; in part by the National
   Natural Science Foundation of China under Grants U1813212, 62273105,
   U1911401, and 61727810; in part by the Ten Thousand Talent Program
   approved in 2018; in part by the Guangdong Province Foundation under
   Grants 2019B1515120036, and 501200069; in part by Science and Technology
   Planning Project of Guangdong Province under Grant 2020B121201012, and
   in part by Shenzhen Science and Technology Planning Project under Grant
   JSGG20210802153155018.
CR Anil D, 2018, 2018 IEEE 25TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING WORKSHOPS (HIPCW), P129, DOI [10.1109/HiPCW.2018.00028, 10.1109/HiPCW.2018.8634192]
   Bao R, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/5/052036
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Cui Q, 2020, IEEE T KNOWL DATA EN, V32, P317, DOI 10.1109/TKDE.2018.2881260
   Da'u A, 2020, INFORM SCIENCES, V512, P1279, DOI 10.1016/j.ins.2019.10.038
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng SG, 2017, IEEE T NEUR NET LEAR, V28, P1164, DOI 10.1109/TNNLS.2016.2514368
   Dighe P, 2018, IEEE W SP LANG TECH, P581, DOI 10.1109/SLT.2018.8639579
   Eirinaki M, 2014, IEEE T SYST MAN CY-S, V44, P409, DOI 10.1109/TSMC.2013.2263128
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Fu MS, 2019, IEEE T CYBERNETICS, V49, P1084, DOI 10.1109/TCYB.2018.2795041
   Guo GB, 2015, AAAI CONF ARTIF INTE, P123
   Jain A, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113724
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Ji ZY, 2019, IEEE ACCESS, V7, P40416, DOI 10.1109/ACCESS.2019.2897586
   Kawale J, 2015, P 24 ACM INT C INF K, P811, DOI DOI 10.1145/2806416.2806527
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Li H, 2019, INFORM SCIENCES, V496, P464, DOI 10.1016/j.ins.2018.07.060
   Li J, 2017, KNOWL-BASED SYST, V127, P58, DOI 10.1016/j.knosys.2017.02.032
   Li XP, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P305, DOI 10.1145/3097983.3098077
   Liang DW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P689, DOI 10.1145/3178876.3186150
   Liu ZQ, 2021, BRIEF BIOINFORM, V22, P1639, DOI 10.1093/bib/bbaa005
   Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433
   Ma H., 2011, Proceedings of the 4th ACM International Conference on Web Search and Data Mining, P287
   Magassouba A, 2019, IEEE ROBOT AUTOM LET, V4, P3884, DOI 10.1109/LRA.2019.2926223
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Massa P, 2004, LECT NOTES COMPUT SC, V3290, P492, DOI 10.1007/978-3-540-30468-5_31
   Qian FL, 2016, PHYSICA A, V461, P61, DOI 10.1016/j.physa.2016.05.025
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Qiang RW, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1783, DOI 10.1145/2505515.2505648
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Roy Pradeep Kumar, 2020, IEEE Transactions on Artificial Intelligence, V1, P271, DOI 10.1109/TAI.2021.3064901
   Roy PK, 2022, COMPUT SPEECH LANG, V75, DOI 10.1016/j.csl.2022.101386
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Sedhain S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P111, DOI 10.1145/2740908.2742726
   Shamshoddin S, 2020, ELECTRON COMMER RES, V20, P241, DOI 10.1007/s10660-019-09377-0
   Shen XX, 2021, IEEE T KNOWL DATA EN, V33, P1906, DOI 10.1109/TKDE.2019.2952849
   Tang JL, 2013, SOC NETW ANAL MIN, V3, P1113, DOI 10.1007/s13278-013-0141-9
   Tuzhilin A., 2010, P 1 INT C E BUS INT
   Udendhran R, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103094
   Wang X, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P185, DOI 10.1145/3077136.3080771
   Wang XH, 2019, IEEE ACCESS, V7, P82826, DOI 10.1109/ACCESS.2019.2924443
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   Wu L, 2021, IEEE T SYST MAN CY-S, V51, P464, DOI 10.1109/TSMC.2018.2872842
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P153, DOI 10.1145/2835776.2835837
   Yang B, 2017, IEEE T PATTERN ANAL, V39, P1633, DOI 10.1109/TPAMI.2016.2605085
   Zhang CY, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3466641
   Zhang PC, 2021, IEEE T EMERG TOP COM, V9, P886, DOI 10.1109/TETC.2018.2870734
   Zhang S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P957, DOI 10.1145/3077136.3080689
   Zhao HR, 2022, IEEE T CYBERNETICS, V52, P2070, DOI 10.1109/TCYB.2020.3007506
   Zhao T., 2014, P 23 ACM INT C C INF, P261, DOI [DOI 10.1145/2661829.2661998, 10.1145/2661829.266199829.H]
   Zhao Z, 2016, IEEE T KNOWL DATA EN, V28, P2522, DOI 10.1109/TKDE.2016.2569096
NR 56
TC 0
Z9 0
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14837
EP 14858
DI 10.1007/s11042-022-13918-5
EA OCT 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865154500001
DA 2024-07-18
ER

PT J
AU Adyapady, RR
   Annappa, B
AF Adyapady, Rashmi R.
   Annappa, B.
TI An ensemble approach using a frequency-based and stacking classifiers
   for effective facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Emotion recognition; Deep learning;
   Machine learning; Ensemble model; Stacking classifier
AB Facial Expression Recognition is an essential aspect of human behavior to communicate effectively. A more profound understanding of human behavior, accurate analysis, and interpretation of the emotional content is essential. Hence, facial features play a crucial role as they contain beneficial information about facial expressions. A baseline architecture belonging to the EfficientNet family of models is explored for feature extraction. In this work, two novel strategies, the ensemble model using the frequency-based voting approach (FV-EffNet) and the stacking classifier (SC-EffNet), are proposed to enhance classification results' performance. The proposed system deals with both profile and frontal pose variations. The combination of deep learning models with a stacking classifier gave the best results of 98.35% and 98.06%, and the frequency-based approach used with the ensemble classifier achieved superior performance of 98.71% and 98.56% on Oulu-CASIA and RaFD datasets, respectively. The experiment results with the proposed methodology showed better performance than previous studies on Oulu-CASIA and RaFD datasets, making it more robust to pose variations.
C1 [Adyapady, Rashmi R.; Annappa, B.] Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Surathkal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Adyapady, RR (corresponding author), Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Surathkal, India.
EM rashmiadyapadyr.177co004@nitk.edu.in; annappa@ieee.org
RI Basava, Dr. Annappa/P-3077-2014; R, Rashmi Adyapady/CAI-8646-2022
OI Basava, Dr. Annappa/0000-0002-4049-3677; R, Rashmi
   Adyapady/0000-0001-6370-3385
CR Aggarwal C.C., 2015, Data Mining, P285, DOI [10.1007/978-3-319-14142-8_6, DOI 10.1007/978-3-319-14142-8]
   Alvarez A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010021
   Carcagnì P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Cugu I, 2019, INT CONF IMAG PROC, DOI 10.1109/ipta.2019.8936114
   Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Dino Hivi Ismat, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P70, DOI 10.1109/ICOASE.2019.8723728
   Ekman P, 2009, PHILOS T R SOC B, V364, P3449, DOI 10.1098/rstb.2009.0189
   Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9
   Fathallah A, 2017, I C COMP SYST APPLIC, P745, DOI 10.1109/AICCSA.2017.124
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   González-Hernández F, 2018, J INTELL FUZZY SYST, V34, P3325, DOI 10.3233/JIFS-169514
   Happy SL, 2019, PATTERN RECOGN LETT, V128, P162, DOI 10.1016/j.patrec.2019.08.025
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jiang B., 2013, J INF HID MULTIMED S, V4, P138
   Jiang B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013022
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li W., 2017, P 12 WORKSH INN US N, P390
   Liu K, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P163, DOI 10.1109/CW.2016.34
   Liu MY, 2016, IEEE T IMAGE PROCESS, V25, P5920, DOI 10.1109/TIP.2016.2615424
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Luz E., 2020, EFFECTIVE EFFICIENT
   Malmasi S, 2018, COMPUT LINGUIST, V44, P403, DOI [10.1162/COLI_a_00323, 10.1162/coli_a_00323]
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Mihalcea R, 2002, CLASSIFIER STACKING, P696
   Pramerdorfer C, 2016, ARXIV
   Kurup AR, 2019, NEUROCOMPUTING, V367, P188, DOI 10.1016/j.neucom.2019.08.029
   Rao QY, 2015, INT CONF AFFECT, P630, DOI 10.1109/ACII.2015.7344635
   Rao RS, 2019, PERVASIVE MOB COMPUT, V60, DOI 10.1016/j.pmcj.2019.101084
   Rashid TA, 2016, INT S INT SYST TECHN, P73, DOI [10.1007/978-3-319-47952-1_6, DOI 10.1007/978-3-319-47952-1]
   Renda A, 2019, EXPERT SYST APPL, V136, P1, DOI 10.1016/j.eswa.2019.06.025
   RUSSELL JA, 1991, PSYCHOL BULL, V110, P426, DOI 10.1037/0033-2909.110.3.426
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sakkis G, 2001, ARXIV
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shokrani S, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P215, DOI 10.1109/ICCKE.2014.6993346
   Sun N, 2019, PATTERN RECOGN LETT, V119, P49, DOI 10.1016/j.patrec.2017.10.022
   Sun WY, 2018, NEUROCOMPUTING, V306, P246, DOI 10.1016/j.neucom.2018.04.063
   Sun WY, 2017, NEUROCOMPUTING, V267, P385, DOI 10.1016/j.neucom.2017.06.050
   Tan M., 2019, arXiv
   Tang J., 2015, Data Classification: Algorithms and Applications
   Tang Y, 2018, IEEE ACCESS, V6, P42532, DOI 10.1109/ACCESS.2018.2858278
   Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wen GH, 2017, COGN COMPUT, V9, P597, DOI 10.1007/s12559-017-9472-6
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Yacine YADDADEN., 2018, Proceedings of the 4th International Conference on Signal, Image, Vision and their Applications, P1, DOI 10. 09/ICASS.2018.8651969
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
   Zia MS, 2018, MULTIMED TOOLS APPL, V77, P25537, DOI 10.1007/s11042-018-5806-y
NR 60
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14689
EP 14712
DI 10.1007/s11042-022-13940-7
EA OCT 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863811400004
DA 2024-07-18
ER

PT J
AU Liu, T
   Hu, RY
   Zhu, YX
AF Liu, Tong
   Hu, Rongyao
   Zhu, Yongxin
TI Completed sample correlations and feature dependency-based unsupervised
   feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; Sample correlation; Unsupervised feature
   selection; Graph learning; Self-representation; Mutual information;
   Sparse learning
ID STRUCTURE PRESERVATION; SPARSE REGRESSION; INFORMATION
AB Sample correlations and feature relations are two pieces of information that are needed to be considered in the unsupervised feature selection, as labels are missing to guide model construction. Thus, we design a novel unsupervised feature selection scheme, in this paper, via considering the completed sample correlations and feature dependencies in a unified framework. Specifically, self-representation dependencies and graph construction are conducted to preserve and select the important neighbors for each sample in a comprehensive way. Besides, mutual information and sparse learning are designed to consider the correlations between features and to remove the informative features, respectively. Moreover, various constraints are constructed to automatically obtain the number of important neighbors and to conduct graph partition for the clustering task. Finally, we test the proposed method and verify the effectiveness and the robustness on eight data sets, comparing with nine state-of-the-art approaches with regard to three evaluation metrics for the clustering task.
C1 [Liu, Tong; Hu, Rongyao] Massey Univ, Albany Campus, Auckland 0745, New Zealand.
   [Zhu, Yongxin] Chinese Acad Sci, Jinan Lab Appl Nucl Sci, Inst High Energy Phys, Beijing, Peoples R China.
C3 Massey University; Chinese Academy of Sciences; Institute of High Energy
   Physics, CAS
RP Hu, RY (corresponding author), Massey Univ, Albany Campus, Auckland 0745, New Zealand.
EM hurongyao123@gmail.com
RI Hu, Rongyao/AAH-3834-2020
OI Hu, Rongyao/0000-0001-9989-1103
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Abu Khurma R, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030464
   Agnihotri D, 2017, EXPERT SYST APPL, V81, P268, DOI 10.1016/j.eswa.2017.03.057
   Alsahaf A, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115895
   [Anonymous], 2005, ADV NEURAL INF PROCE
   Askari S, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113856
   Bommert A, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab354
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cai D., 2010, KDD, P333
   Cekik R, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113691
   Chen G, 2015, NEUROCOMPUTING, V159, P219, DOI 10.1016/j.neucom.2015.01.070
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Feng SW, 2018, NEUROCOMPUTING, V312, P310, DOI 10.1016/j.neucom.2018.05.117
   Feofanov V, 2022, APPL INTELL, V52, P12316, DOI 10.1007/s10489-021-03076-w
   HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Hu RY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102782
   Hu RY, 2021, IEEE T MED IMAGING, V40, P3843, DOI 10.1109/TMI.2021.3099641
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Lim H, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu XW, 2014, IEEE T NEUR NET LEAR, V25, P1083, DOI 10.1109/TNNLS.2013.2287275
   Liu YF, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105462
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Miao JY, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108299
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nouri-Moghaddam B, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114737
   Onyema EM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5196000
   Onyema EM, 2020, INT J INNOV SCI ENG, V7, P91, DOI DOI 10.1109/TENSYMP50017.2020.9230464
   Patel VM, 2013, IEEE I CONF COMP VIS, P225, DOI 10.1109/ICCV.2013.35
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Shang RH, 2018, IEEE T CYBERNETICS, V48, P793, DOI 10.1109/TCYB.2017.2657007
   Sheikhpour R, 2017, PATTERN RECOGN, V64, P141, DOI 10.1016/j.patcog.2016.11.003
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Solorio-Fernández S, 2020, PATTERN RECOGN LETT, V138, P321, DOI 10.1016/j.patrec.2020.07.039
   Solorio-Fernández S, 2020, ARTIF INTELL REV, V53, P907, DOI 10.1007/s10462-019-09682-y
   Song L., 2007, P 24 INT C MACH LEAR, P823, DOI DOI 10.1145/1273496.1273600
   Song QJ, 2017, EXPERT SYST APPL, V81, P22, DOI 10.1016/j.eswa.2017.02.049
   Wahid A, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117008
   Wang C, 2021, IEEE T COMPUT, V70, P725, DOI 10.1109/TC.2020.2995761
   Wang SP, 2018, IEEE T SYST MAN CY-S, V48, P329, DOI 10.1109/TSMC.2016.2605132
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wu JS, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107742
   Xu W., 2022, ARXIV
   Yao C, 2017, IEEE T IMAGE PROCESS, V26, P5257, DOI 10.1109/TIP.2017.2733200
   Yuan HL, 2019, PATTERN RECOGN, V89, P119, DOI 10.1016/j.patcog.2019.01.014
   Zhang Y, 2018, PATTERN RECOGN, V76, P662, DOI 10.1016/j.patcog.2017.09.043
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151, DOI DOI 10.1145/1273496.1273641
   Zhu PF, 2016, AAAI CONF ARTIF INTE, P2422
   Zhu PF, 2017, PATTERN RECOGN, V66, P364, DOI 10.1016/j.patcog.2017.01.016
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
NR 58
TC 8
Z9 8
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15305
EP 15326
DI 10.1007/s11042-022-13903-y
EA OCT 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864205500005
OA hybrid
DA 2024-07-18
ER

PT J
AU Shakiba, A
AF Shakiba, Ali
TI A novel randomized chaotic bit-level image encryption algorithm based on
   a novel 2D-CICM hyper-chaotic mapping with CPA-security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chebyshev infinite collapse map; Image encryption; Hyperchaos
ID MAP; ENTROPY; SYSTEM
AB In this paper, we design a novel chaotic mapping and use it to devise a bit-level image encryption algorithm which provides security against chosen plaintext attacks, or CPA-security for short. We also study various properties of the proposed chaotic mapping, such as having two positive Lyapunov exponents. We also evaluate the randomization of the hyperchaotic discretization approach used in the proposed algorithm using the dieharder 3.31.1 test batteries. Our proposed algorithm is a one-round image encryption algorithm, which give faster encryption and decryption in comparison with more complicated multi-round encryption algorithms. Despite its one-round nature, as is shown in the performance evaluation, it provides acceptable and even competitive security compared to recent chaotic image encryption algorithms. Finally, our proposed image encryption algorithm is robust against noise attacks and data loss.
C1 [Shakiba, Ali] Vali E Asr Univ Rafsanjan, Dept Comp Sci, Rafsanjan 7718897111, Iran.
C3 Vali-e-Asr University of Rafsanjan
RP Shakiba, A (corresponding author), Vali E Asr Univ Rafsanjan, Dept Comp Sci, Rafsanjan 7718897111, Iran.
EM a.shakibairan@gmail.com
RI Shakiba, Ali/J-6420-2016
OI Shakiba, Ali/0000-0002-2253-1166
CR Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Barker Elaine, 2020, NIST SPECIAL PUBLICA, V800-57
   Brown R.G., 2021, DieHarder: A Random Number Test Suite Version 3.31.1
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chaboki B., 2021, J ELEC ENG COMPUT SC, V21, P1103
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Donner Allan., 1980, Applied Statistics, V20, P69, DOI DOI 10.2307/2346412
   Elizabeth BL, 2022, J REAL-TIME IMAGE PR, V19, P429, DOI 10.1007/s11554-021-01194-9
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gagunashvili ND, 2010, NUCL INSTRUM METH A, V614, P287, DOI 10.1016/j.nima.2009.12.037
   Gupta K, 2012, ADV ENG SOFTW, V49, P29, DOI 10.1016/j.advengsoft.2012.03.001
   Gupta M, 2021, WIRELESS PERS COMMUN, V121, P1857, DOI 10.1007/s11277-021-08742-3
   Hermassi H, 2013, TELECOMMUN SYST, V52, P539, DOI 10.1007/s11235-011-9459-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Jin X, 2021, MULTIMED TOOLS APPL, P1
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P29303, DOI 10.1007/s11042-018-5959-8
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Katz J., 2014, Introduction to modern cryptography
   Kaur M, 2022, SOFT COMPUT, V26, P3703, DOI 10.1007/s00500-022-06841-2
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Lake DE, 2002, AM J PHYSIOL-REG I, V283, pR789, DOI 10.1152/ajpregu.00069.2002
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500160
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Niu Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4079793
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Ortakci Yasin, 2021, Innovations in Smart Cities Applications. Proceedings of the 5th International Conference on Smart City Applications. Lecture Notes in Networks and Systems (LNNS 183), P877, DOI 10.1007/978-3-030-66840-2_67
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Shakiba A, 2019, J INFORM OPTIM SCI, V40, P725, DOI 10.1080/02522667.2018.1470752
   Shakiba A., 2020, Journal of Computing and Security, V7, P1
   Shakiba A, 2021, MULTIMED TOOLS APPL, V80, P17983, DOI 10.1007/s11042-021-10584-x
   Shakiba A, 2021, J KING SAUD UNIV-COM, V33, P562, DOI 10.1016/j.jksuci.2019.03.003
   Shakiba A, 2020, MULTIMED TOOLS APPL, V79, P32575, DOI 10.1007/s11042-020-09434-z
   Shakiba A, 2019, MULTIMED TOOLS APPL, V78, P34773, DOI 10.1007/s11042-019-08071-5
   Shakiba A, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501121
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Stergiou C, 2017, INT J NETW MANAG, V27, DOI 10.1002/nem.1930
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang XY, 2011, NONLINEAR DYNAM, V63, P587, DOI 10.1007/s11071-010-9821-4
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Yan WH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111313
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou WJ, 2022, OPT LASER ENG, V149, DOI 10.1016/j.optlaseng.2021.106782
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 67
TC 2
Z9 2
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17631
EP 17657
DI 10.1007/s11042-022-13708-z
EA OCT 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000864205500003
DA 2024-07-18
ER

PT J
AU Shao, ZH
   Wang, X
   Tang, YD
   Shang, YY
AF Shao, Zhuhong
   Wang, Xue
   Tang, Yadong
   Shang, Yuanyuan
TI Trinion discrete cosine transform with application to color image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Trinion discrete cosine transform; Discrete
   Fourier transform; Quantum logistic map; Josephus traversing
ID FRACTIONAL FOURIER-TRANSFORM; EQUAL MODULUS DECOMPOSITION
AB This paper introduces trinion discrete cosine transform that can process color image holistically, it can be computed by combination of single-channel discrete cosine transform. Compared with quaternion discrete cosine transform, trinion discrete cosine transform is more efficient and compact to represent color image. Moreover, it is used for developing a robust color image encryption algorithm jointing with quantum logistic map and Josephus traversing. Firstly, color components are precoded into a trinion matrix, which is performed trinion discrete cosine transform. Then three parts of the transformed result are pairwisely combined into complex matrices and the synthesized spectrums satisfying symmetry are established. Followed by Josephus scrambling with variable steps on magnitudes, the ciphertext image can be acquired. The plaintext image can be ideally restored with the granted keys, where the average value of PSNR is close to 300.00 dB. Moreover, the proposed algorithm has high-level security. It also shows better resistance against Gaussian noise and shearing in comparison with some existing algorithms.
C1 [Shao, Zhuhong; Wang, Xue; Tang, Yadong; Shang, Yuanyuan] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Shang, Yuanyuan] Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
C3 Capital Normal University
RP Shao, ZH (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
RI Li, Shiyu/KHE-1376-2024; Zhang, Zhipeng/KHY-2239-2024; Shao,
   Zhuhong/AAD-4129-2022
FU National Natural Science Foundation of China [61876112, 61601311]
FX This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311).
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   [Anonymous], 2015, INT J SIGNAL PROCESS
   Assefa D, 2011, SIGNAL PROCESS, V91, P1887, DOI 10.1016/j.sigpro.2011.02.011
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chen BJ, 2018, IET IMAGE PROCESS, V12, P2238, DOI 10.1049/iet-ipr.2018.5440
   Chen H, 2019, OPT LASER ENG, V112, P7, DOI 10.1016/j.optlaseng.2018.08.020
   Chen L, 2020, NONLINEAR DYNAM, V100, P3959, DOI 10.1007/s11071-020-05735-y
   Chen XD, 2019, OPT LASER ENG, V121, P143, DOI 10.1016/j.optlaseng.2019.04.004
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   Gou XM, 2016, FRONT INFORM TECH EL, V17, P834, DOI 10.1631/FITEE.1601164
   Huang HQ, 2020, MULTIMED TOOLS APPL, V79, P28065, DOI 10.1007/s11042-020-09378-4
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Joshi M, 2010, OPT COMMUN, V283, P2496, DOI 10.1016/j.optcom.2010.02.024
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Li M, 2019, NONLINEAR DYNAM, V96, P31, DOI 10.1007/s11071-019-04771-7
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu S, 2015, SIGNAL PROCESS, V109, P345, DOI 10.1016/j.sigpro.2014.06.024
   Liu XL, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043046
   Nakano K, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106300
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shang YY, 2023, IEEE T AFFECT COMPUT, V14, P2557, DOI 10.1109/TAFFC.2021.3139651
   Shao ZH, 2013, IEEE IMAGE PROC, P4579, DOI 10.1109/ICIP.2013.6738943
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Sui L, 2014, INT C PHOTONICS OPTI, P223
   Sui LS, 2013, OPT LASER TECHNOL, V48, P117, DOI 10.1016/j.optlastec.2012.10.016
   Tang YD, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116168
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wang XL, 2011, OPTIK, V122, P1856, DOI 10.1016/j.ijleo.2010.11.016
   Xiong Y, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105580
   Xu ZH, 2021, MULTIMED TOOLS APPL, V80, P14477, DOI 10.1007/s11042-020-10234-8
   Yao QJ, 2020, MULTIMED TOOLS APPL, V79, P27555, DOI 10.1007/s11042-020-09296-5
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
   Zhu Z, 2020, OPT LASER TECHNOL, V126, DOI 10.1016/j.optlastec.2020.106106
NR 41
TC 6
Z9 6
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14633
EP 14659
DI 10.1007/s11042-022-13898-6
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000862219700002
DA 2024-07-18
ER

PT J
AU Jeyalakshmi, MS
   Robin, CRR
   Doreen, D
AF Jeyalakshmi, M. S.
   Robin, C. R. Rene
   Doreen, D.
TI Predicting cochlear implants score with the aid of reconfigured long
   short-term memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross modal plasticity; Visual evoked potential Cochlear implants (CI);
   Artificial intelligence (AI); Long short-term memory (LSTM); Enhanced
   swarm based crow search optimization (ESCSO)
ID HEARING-LOSS
AB A surgical procedure namely the Cochlear implantation aims in fitting the electronic device the cochlear implant. This electronic device helps person with moderate to severe hearing loss. It becomes very important to treat children with auditory deprivation much earlier, since it prohibits their language development skill too. This research aims to develop a model that can be used to guide Cochlear Implants (CI) programming for new patients in the children of 5 to 10 ages using visual cross modal data obtained from previously programmed patients. The cohort chosen is bilateral congenitally deaf children. This age group is selected since their language development is affected due to their auditory deprivations. The design is based on obtaining the analysis of cross modal plasticity using the visual evoked potential. AI based techniques, which is formed using the patient database. The goal is to use patients, real time database collected from the children and observe if it is likely to discover patterns in the data that can predict something about future patients. The resolution would be a program that can discover factors for the auditory deprived. The objective of this work is to apply Long Short-Term Memory (LSTM) network based Artificial Intelligence (AI) model to discover the unknown pattern. LSTM is suited to classify, process and predict time series given time lags of unknown duration. Relative insensitivity to gap length gives an advantage to LSTM over alternative RNNs. To augment an additional performance, the investigation comprises Enhanced Swarm based Crow Search Optimization (ESCSO) to identify optimal weights. The results exhibit the dominance of suggested ESCSO based LSTM technique over other techniques.
C1 [Jeyalakshmi, M. S.] Jerusalem Coll Engn, Biomed Engn, Chennai, Tamil Nadu, India.
   [Robin, C. R. Rene] Sri Sairam Engn Coll, Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Doreen, D.] Computat Intelligence Res Fdn, Chennai, Tamil Nadu, India.
C3 Sri Sai Ram Engineering College
RP Jeyalakshmi, MS (corresponding author), Jerusalem Coll Engn, Biomed Engn, Chennai, Tamil Nadu, India.
EM jeyalalcsmims20213@gmail.com
RI ROBIN, RENE/ABG-4506-2020
OI ganesan, jeyalakshmi/0000-0002-8004-9546
CR Abdelaziz AY, 2017, ENG SCI TECHNOL, V20, P391, DOI 10.1016/j.jestch.2017.02.004
   Baron S, 2019, EUR ANN OTORHINOLARY, V136, P69, DOI 10.1016/j.anorl.2018.09.004
   Bianchin G, 2017, INT J PEDIATR OTORHI, V102, P10, DOI 10.1016/j.ijporl.2017.08.025
   Cunningham LL, 2017, NEW ENGL J MED, V377, P2465, DOI 10.1056/NEJMra1616601
   Eshaghi A, 2016, NEUROLOGY, V87, P2463, DOI 10.1212/WNL.0000000000003395
   Giardina CK, 2014, CURR SURG REP, V2, DOI 10.1007/s40137-014-0075-9
   Govaerts PJ, 2010, OTOL NEUROTOL, V31, P908, DOI 10.1097/MAO.0b013e3181dd160b
   Helmstaedter V, 2018, INT J PEDIATR OTORHI, V113, P102, DOI 10.1016/j.ijporl.2018.07.034
   Kim HS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19249-6
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Meeuws Matthias, 2017, Cochlear Implants Int, V18, P198, DOI 10.1080/14670100.2017.1325093
   Nemati P, 2014, J PHARM PHARMACOL, V66, P624, DOI 10.1111/jphp.12187
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Ramos-Macías A, 2016, AUDIOL NEURO-OTOL, V21, P36, DOI 10.1159/000448353
   Seeber BU, 2016, NETWORK-COMP NEURAL, V27, P53, DOI 10.1080/0954898X.2016.1223365
   Shew M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40192-7
   Song XY, 2020, J PETROL SCI ENG, V186, DOI 10.1016/j.petrol.2019.106682
   Sun Z, 2019, I S BIOMED IMAGING, P360, DOI [10.1109/ISBI.2019.8759541, 10.1109/isbi.2019.8759541]
   Uciteli A, 2017, J BIOMED SEMANT, V8, DOI 10.1186/s13326-017-0147-8
   Zhang FW, 2019, HEARING RES, V379, P12, DOI 10.1016/j.heares.2019.04.007
NR 20
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12537
EP 12556
DI 10.1007/s11042-022-13812-0
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000857685800002
DA 2024-07-18
ER

PT J
AU Jangam, E
   Annavarapu, CSR
   Barreto, AAD
AF Jangam, Ebenezer
   Annavarapu, Chandra Sekhara Rao
   Barreto, Aaron Antonio Dias
TI A multi-class classification framework for disease screening and disease
   diagnosis of COVID-19 from chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stacked ensemble; Multi-class classification; COVID-19; Deep learning;
   Transfer learning
ID FUSION
AB To accurately diagnose multiple lung diseases from chest X-rays, the critical aspect is to identify lung diseases with high sensitivity and specificity. This study proposed a novel multi-class classification framework that minimises either false positives or false negatives that is useful in computer aided diagnosis or computer aided detection respectively. To minimise false positives or false negatives, we generated respective stacked ensemble from pre-trained models and fully connected layers using selection metric and systematic method. The diversity of base classifiers was based on diverse set of false positives or false negatives generated. The proposed multi-class framework was evaluated on two chest X-ray datasets, and the performance was compared with the existing models and base classifiers. Moreover, we used LIME (Local Interpretable Model-agnostic Explanations) to locate the regions focused by the multi-class classification framework.
C1 [Jangam, Ebenezer] Velagapudi Ramakrishna Siddhartha Engn Coll, Dept Informat Technol, Vijayawada, Andhra Pradesh, India.
   [Jangam, Ebenezer; Annavarapu, Chandra Sekhara Rao] Indian Inst Technol ISM, Dept Comp Sci Engn, Dhanbad, Jharkhand, India.
   [Barreto, Aaron Antonio Dias] Indian Inst Technol ISM, Dept Elect Engn, Dhanbad, Jharkhand, India.
C3 Velagapudi Ramakrishna Siddhartha Engineering College; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology
   (Indian School of Mines) Dhanbad; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (Indian School of Mines)
   Dhanbad
RP Annavarapu, CSR (corresponding author), Indian Inst Technol ISM, Dept Comp Sci Engn, Dhanbad, Jharkhand, India.
EM jebenezer@vrsiddhartha.ac.in; acsrao@iitism.ac.in;
   aaron.18je0003@ece.iitism.ac.in
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Ali Mohd Adli Md, 2020, COVID 19 DEEP LEARNI
   Ali M, 2018, EXPERT SYST APPL, V91, P434, DOI 10.1016/j.eswa.2017.09.027
   Allioui H, 2022, J PERS MED, V12, DOI 10.3390/jpm12020309
   Alyasseri ZAA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12759
   [Anonymous], RADIOLOGY, DOI [10.1148/radiol.2020200642, DOI 10.1148/RADIOL.2020200642, 10.5772/intechopen.80730, DOI 10.1148/radiol.2020200642]
   Asif S., 2020, MEDRXIV
   Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823
   Bassi Pedro R. A. S., 2022, Research on Biomedical Engineering, V38, P139, DOI 10.1007/s42600-021-00132-9
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   Gupta RK, 2021, INT J UNCERTAIN FUZZ, V29, P921, DOI 10.1142/S0218488521500410
   He X, 2020, MEDRXIV
   Himoto Y, 2020, JPN J RADIOL, V38, P400, DOI 10.1007/s11604-020-00958-w
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Ibrahim DM, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104348
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam N, 2021, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD013639.pub4
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Jangam E, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104608
   Jangam E, 2022, APPL INTELL, V52, P2243, DOI 10.1007/s10489-021-02393-4
   Kanne Jeffrey P, 2020, Radiology, V296, pE113, DOI 10.1148/radiol.2020200527
   Karakanis S, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2020.104181
   Karar ME, 2021, COMPLEX INTELL SYST, V7, P235, DOI 10.1007/s40747-020-00199-4
   Kamal KC, 2021, SIGNAL IMAGE VIDEO P, V15, P959, DOI 10.1007/s11760-020-01820-2
   Kermany Daniel, 2018, Mendeley Data, V3
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khan MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217286
   Kongtao C, 2021, ARXIV
   Kovács A, 2021, EUR RADIOL, V31, P2819, DOI 10.1007/s00330-020-07347-x
   Lei JQ, 2020, RADIOLOGY, V295, P18, DOI 10.1148/radiol.2020200236
   LIU H, 2020, J INFECTION
   Loey M, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05437-x
   Lokwani R, 2020, ARXIV
   Long CQ, 2020, EUR J RADIOL, V126, DOI 10.1016/j.ejrad.2020.108961
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Muhammad G, 2021, INFORM FUSION, V72, P80, DOI 10.1016/j.inffus.2021.02.013
   Mukherjee H, 2021, APPL INTELL, V51, P2777, DOI 10.1007/s10489-020-01943-6
   Mukherjee H, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09775-9
   Nishio M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74539-2
   Ouchicha C, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110245
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Sesmero MP, 2015, WIRES DATA MIN KNOWL, V5, P21, DOI 10.1002/widm.1143
   Polsinelli M, 2020, ARXIV
   Rahimzadeh M., 2020, medRxiv
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ribeiro M.T., 2016, ARXIV
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Salam MA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0252573
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Shaban WM, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106270
   Shelke A., 2020, MEDRXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taresh MM, 2021, INT J BIOMED IMAGING, V2021, DOI 10.1155/2021/8828404
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wang Lucy Lu, 2020, CORD 19 COVID 19 OPE
   Wang SH, 2021, INFORM FUSION, V68, P131, DOI 10.1016/j.inffus.2020.11.005
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang Z, 2021, IEEE T KNOWL DATA EN, V33, P3634, DOI 10.1109/TKDE.2020.2971490
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xie XZ, 2020, RADIOLOGY, V296, pE41, DOI 10.1148/radiol.2020200343
   Yadav SS, 2020, ARXIV
   Zagoruyko S., 2016, ARXIV
   Zebin T, 2021, APPL INTELL, V51, P1010, DOI 10.1007/s10489-020-01867-1
NR 73
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14367
EP 14401
DI 10.1007/s11042-022-13710-5
EA SEP 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000859342300006
PM 36157353
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Ihsan, A
   Dogan, N
AF Ihsan, Aysegul
   Dogan, Nurettin
TI Improved affine encryption algorithm for color images using LFSR and XOR
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affine algorithm; Image encryption; Linear feedback shift register; XOR
   encryption
ID TRANSFORMATION; PERMUTATION; SCHEME; SYSTEM
AB In this study, a novel Improved Affine Algorithm (IAA) for color image encryption is proposed. Affine Algorithm (AA) is generally known as an algorithm used for plain text encryption. In the proposed IAA algorithm, Linear Feedback Shift Register (LFSR), XOR encryption, and the AA are combined for color images encryption. The plane image is firstly split into three channels: R, G, and B. The RGB channel image is encrypted using AA encryption with ten keys based on pixel locations and pixel values. The rows and columns of the image are encrypted with LFSR keys and XOR encryption procedures. Finally, the proposed algorithm is tested in Matlab environment to obtain the Histogram, Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Unified Average Changing Intensity (UACI), Number of Pixel Change Rate (NPCR), and Entropy analyses. The values are compared with other algorithms. The results show that the proposed image encryption algorithm is secure and powerful, outperforming other algorithms.
C1 [Ihsan, Aysegul] Selcuk Univ, Dept Informat Technol Engn, Grad Sch Nat & Appl Sci, Alaeddin Keykubat Campus, TR-42075 Konya, Turkey.
   [Dogan, Nurettin] Selcuk Univ, Dept Comp Engn, Fac Technol, Alaeddin Keykubat Campus, TR-42075 Konya, Turkey.
C3 Selcuk University; Selcuk University
RP Dogan, N (corresponding author), Selcuk Univ, Dept Comp Engn, Fac Technol, Alaeddin Keykubat Campus, TR-42075 Konya, Turkey.
EM aysegulihsann@gmail.com; ndogan@ymail.com
RI DOĞAN, Nurettin/C-1090-2013; İhsan, Ayşegül/JCP-4222-2023
OI DOĞAN, Nurettin/0000-0002-8267-8469; 
CR Abu-Issa AS, 2009, IEEE T COMPUT AID D, V28, P755, DOI 10.1109/TCAD.2009.2015736
   Asl AM, 2021, INT J NONLINEAR ANAL, V12, P903, DOI 10.22075/IJNAA.2021.5520
   Bani MA., 2008, IJCSNS INT J COMPUT, V8, P191
   Behnia S, 2013, J SYST SOFTWARE, V86, P2429, DOI 10.1016/j.jss.2013.04.088
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Çelik H, 2023, J POLYTECH, V26, P679, DOI 10.2339/politeknik.1008594
   Chen H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020330
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   Deb S, 2021, MULTIMED TOOLS APPL, V80, P19803, DOI 10.1007/s11042-020-10308-7
   Dogan N, 2022, J POLYTECH, V25, P1475, DOI 10.2339/politeknik.902661
   Hui Wang, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1189, DOI 10.1109/ICMA.2018.8484423
   Khan M, 2021, INTEGRATION, V81, P108, DOI 10.1016/j.vlsi.2021.05.007
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Li PC, 2017, INT J THEOR PHYS, V56, P1961, DOI 10.1007/s10773-017-3341-7
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Lone PN, 2021, J MOD OPTIC, V68, P507, DOI 10.1080/09500340.2021.1924885
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Naveenkumar SK, 2013, 2013 INT C OPTICAL I, P1, DOI 10.1109/ICOISS.2013.6678416
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Sabir S, 2021, MULTIMED TOOLS APPL, V80, P27829, DOI 10.1007/s11042-021-11003-x
   Sayed WS, 2021, EGYPT INFORM J, V22, P155, DOI 10.1016/j.eij.2020.07.002
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Thinnukool O, 2021, CMC-COMPUT MATER CON, V69, P3033, DOI 10.32604/cmc.2021.019153
   Yadav SS., 2017, ARPN J ENG APPL SCI, V12, P3500
   Zhang DZ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030361
NR 31
TC 5
Z9 5
U1 12
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7621
EP 7637
DI 10.1007/s11042-022-13727-w
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000849487500006
PM 36090155
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Singh, D
   Nigam, R
   Mittal, R
   Nunia, M
AF Singh, Deepti
   Nigam, Ritu
   Mittal, Ruchi
   Nunia, Manju
TI Information retrieval using machine learning from breast cancer
   diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Information retrieval; Breast cancer; Data analysis;
   Data processing
ID DECISION TREES; NEURAL-NETWORK; PREDICTION; CLASSIFICATION; TUMOR; MODEL
AB Breast cancer is one of the most common cancers among females. Patients with breast cancer are regularly rising. The survival of patients can be improved by early diagnosis and treatment. Because of its success, machine learning is commonly used in most fields. In this paper, numerous methods for early detection of this disease are employed for machine learning. Here, we consider C 5.0, Naive Bayes, logistic regression, random forest, ctree, KNN, K-Mean, GBM, adaBoost, decision tree model to classify the breast cancer tumor and evaluate their performances based on Wisconsin and SEER datasets. The demonstrations of the classifiers were assessed using accuracy, precision, recall, and F1 measure. We also predict whether the tumor is dead or alive, considering the tumor size, the various cancer stages, and months' survival. The general research will increase people's understanding of breast cancer and reduce tumor fears.
C1 [Singh, Deepti] Netaji Subhas Univ Technol, Div Comp Engn, New Delhi, India.
   [Nigam, Ritu] Univ Delhi, Div Comp Engn, Netaji Subhas Inst Technol, New Delhi, India.
   [Mittal, Ruchi] Ganga Inst Technol & Management, Dept Comp Sci & Engn, Jhajjar, Haryana, India.
   [Nunia, Manju] Jaypee Univ, Dept Comp Sci & Engn, Sect 62, Noida, Uttar Pradesh, India.
C3 Netaji Subhas University of Technology; University of Delhi; Netaji
   Subhas University of Technology; Jaypee Institute of Information
   Technology (JIIT)
RP Mittal, R (corresponding author), Ganga Inst Technol & Management, Dept Comp Sci & Engn, Jhajjar, Haryana, India.
EM ruchi.mittal138@gmail.com
CR Abdar M, 2020, PATTERN RECOGN LETT, V132, P123, DOI 10.1016/j.patrec.2018.11.004
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Asri H, 2016, PROCEDIA COMPUT SCI, V83, P1064, DOI 10.1016/j.procs.2016.04.224
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Chou YH, 2001, ULTRASOUND MED BIOL, V27, P1493, DOI 10.1016/S0301-5629(01)00466-5
   Díaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3
   Drukker K, 2004, ACAD RADIOL, V11, P526, DOI 10.1016/S1076-6332(03)00723-2
   Dumitru D, 2009, ANN UNIV CRAIOVA-MAT, V36, P92
   Dwivedi AK, 2018, CURR SCI INDIA, V115, P2063, DOI 10.18520/cs/v115/i11/2063-2070
   Dwivedi AK, 2018, NEURAL COMPUT APPL, V30, P3837, DOI 10.1007/s00521-017-2969-9
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   Huang QH, 2020, IEEE T KNOWL DATA EN, V32, P728, DOI 10.1109/TKDE.2019.2891622
   Jerez JM, 2005, BREAST CANCER RES TR, V94, P265, DOI 10.1007/s10549-005-9013-y
   Jerez-Aragonés JM, 2003, ARTIF INTELL MED, V27, P45, DOI 10.1016/S0933-3657(02)00086-6
   Kim W, 2012, J BREAST CANCER, V15, P230, DOI 10.4048/jbc.2012.15.2.230
   Kumar G.R., 2013, International Journal of Innovations in Engineering and Technology (IJIET), V2, P139
   Kuo WJ, 2001, BREAST CANCER RES TR, V66, P51, DOI 10.1023/A:1010676701382
   Lawrence RL, 2001, PHOTOGRAMM ENG REM S, V67, P1137
   Liu CY, 2014, 2014 IEEE Healthcare Innovation Conference (HIC), P193, DOI 10.1109/HIC.2014.7038907
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P694, DOI 10.1016/j.dsp.2006.10.008
   Punitha S., 2018, Future Computing and Informatics Journal, V3, P348, DOI 10.1016/j.fcij.2018.10.005
   Ridgeway G, 2007, Update, DOI DOI 10.1111/J.1467-9752.1996.TB00390.X
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Subashini TS, 2009, EXPERT SYST APPL, V36, P5284, DOI 10.1016/j.eswa.2008.06.127
   Varma C, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P134, DOI 10.1109/ICCSP.2018.8524576
   Yousefi M, 2018, COMPUT BIOL MED, V96, P283, DOI 10.1016/j.compbiomed.2018.04.004
   Zhou LL, 2019, TRANSL ONCOL, V12, P292, DOI 10.1016/j.tranon.2018.10.012
NR 27
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8581
EP 8602
DI 10.1007/s11042-022-13550-3
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000849154000001
DA 2024-07-18
ER

PT J
AU Kafetzis, I
   Moysis, L
   Tutueva, A
   Butusov, D
   Nistazakis, H
   Volos, C
AF Kafetzis, Ioannis
   Moysis, Lazaros
   Tutueva, Aleksandra
   Butusov, Denis
   Nistazakis, Hector
   Volos, Christos
TI A 1D coupled hyperbolic tangent chaotic map with delay and its
   application to password generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; One-dimensional map; Pseudo-random bit generator; Encryption;
   Password generator
ID SEQUENCE GENERATOR; SECURITY ANALYSIS; IMPROVEMENT
AB This paper proposes a new one-dimensional chaotic map. The map consists of a coupling between two hyperbolic tangent terms, where the second term is delayed, to avoid dynamical degradation. The map is studied through computation of its bifurcation diagrams and Lyapunov exponent diagrams and is shown to have constant chaotic behavior for almost all parameter values. Afterward, based on the proposed map, a pseudo-random bit generator with a high keyspace is designed. This generator is then used as a basis for a proposed password generator application. The motivation behind this application is to design an algorithm that takes as input an easy-to-remember key by the user and outputs a secure password that can be used for websites or file security. This way, the use of easy-to-crack, repetitive passwords is avoided. The proposed generator is developed as a graphical user interface.
C1 [Kafetzis, Ioannis; Moysis, Lazaros; Volos, Christos] Aristotle Univ Thessaloniki, Phys Dept, Lab Nonlinear Syst Circuits Complex, Thessaloniki, Greece.
   [Tutueva, Aleksandra; Butusov, Denis] St Petersburg Electrotech Univ TETI, Youth Res Inst, 5 Prof Popova St, St Petersburg 197376, Russia.
   [Nistazakis, Hector] Natl & Kapodistrian Univ Athens, Dept Phys, Sect Elect Phys & Syst, Athens 15784, Greece.
C3 Aristotle University of Thessaloniki; National & Kapodistrian University
   of Athens
RP Moysis, L (corresponding author), Aristotle Univ Thessaloniki, Phys Dept, Lab Nonlinear Syst Circuits Complex, Thessaloniki, Greece.
EM kafetzis@physics.auth.gr; lmousis@physics.auth.gr; avtutueva@etu.ru;
   dnbutusov@etu.ru; enistaz@phys.uoa.gr; volos@physics.auth.gr
RI Volos, Christos/AAF-7096-2019; Butusov, Denis/E-6759-2017; Moysis,
   Lazaros/K-9944-2019
OI Butusov, Denis/0000-0002-8941-4220; Moysis, Lazaros/0000-0002-5652-2532
CR Abdelfatah RI, 2020, MULTIMED TOOLS APPL, V79, P19717, DOI 10.1007/s11042-020-08788-8
   Ablay G, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501212
   Ahmad M., 2018, PROC INT S SECUR COM, P543
   Akgul A., 2019, CHAOS THEORY APPL, V1, P1
   Akgul A, 2020, Z NATURFORSCH A, V75, P1025, DOI 10.1515/zna-2020-0222
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Alawida M, 2020, INFORM SCIENCES, V512, P1155, DOI 10.1016/j.ins.2019.10.055
   Algarni AD, 2021, MULTIMED TOOLS APPL, V80, P10679, DOI 10.1007/s11042-020-09369-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2019, INF COMPUT SECUR
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Bovy J., 2004, Tech. Rep, V9, P1
   Chaves DPB, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0405-4
   Chaves Daniel PB, 2014, 2014 INT TEL S ITS, P1
   Evangelista JVC, 2017, AEU-INT J ELECTRON C, V77, P112, DOI 10.1016/j.aeue.2017.04.029
   Giakoumis A, 2018, IEEE LAT AMER SYMP, P154
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hsiao HI, 2015, SIGNAL PROCESS, V113, P169, DOI 10.1016/j.sigpro.2015.01.024
   Hu HP, 2013, COMPUT PHYS COMMUN, V184, P765, DOI 10.1016/j.cpc.2012.11.017
   Hua ZY, 2021, IEEE T SYST MAN CY-S, V51, P3713, DOI 10.1109/TSMC.2019.2932616
   Huang X, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/6567198
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Irfan M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010104
   Jiteurtragool N, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20020136
   Kavrestad J., 2020, IFIP INT C ICT SYST, P95, DOI [https://doi.org/10.1007/978-3-030-58201-2_7, DOI 10.1007/978-3-030-58201-2_7]
   Kavrestad J, 2020, CONSTRUCTING SECURE
   Kingni ST, 2019, J COMPUT NONLIN DYN, V14, DOI 10.1115/1.4043359
   Lai CH, 1998, EUROPHYS LETT, V43, P376, DOI 10.1209/epl/i1998-00368-1
   Lambic D, 2019, J ELECTRON TEST, V35, P519, DOI 10.1007/s10836-019-05818-8
   Lambic D, 2018, NONLINEAR DYNAM, V94, P1117, DOI 10.1007/s11071-018-4412-x
   Liu BC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4926937
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu LF, 2016, INFORM PROCESS LETT, V116, P674, DOI 10.1016/j.ipl.2016.06.011
   Liu LF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1959-1
   Liu LF, 2016, IET INFORM SECUR, V10, P87, DOI 10.1049/iet-ifs.2014.0192
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Liu Z, 2020, NONLINEAR DYNAM, V101, P1383, DOI 10.1007/s11071-020-05804-2
   Moysis L, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050829
   Moysis L, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040474
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Nepomuceno EG, 2019, CHAOS, V29, DOI 10.1063/1.5099261
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Sayed WS, 2020, CIRC SYST SIGNAL PR, V39, P5638, DOI 10.1007/s00034-020-01424-8
   Stoyanov B, 2019, AIP CONF PROC, V2172, DOI 10.1063/1.5133578
   Strogatz S.H., 2018, Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering, DOI [10.1201/9780429492563, DOI 10.1201/9780429492563]
   Tada K, 2004, NOLTA2004, P605
   Tang JY, 2019, MULTIMED TOOLS APPL, V78, P24765, DOI 10.1007/s11042-019-7602-8
   Tutueva AV, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109615
   Wang Y., 2021, IEEE Trans. Cybern.
   Wang Y, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501244
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2016, NONLINEAR DYNAM, V83, P2373, DOI 10.1007/s11071-015-2488-0
   Wheeler DL, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P157
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Yang LJ, 2002, COMMUN THEOR PHYS, V38, P168
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
NR 59
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9303
EP 9322
DI 10.1007/s11042-022-13657-7
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000846136800002
DA 2024-07-18
ER

PT J
AU Aslam, N
   Ehsan, MK
   Ul Rehman, Z
   Hanif, M
   Mustafa, G
AF Aslam, Numan
   Ehsan, Muhammad Khurram
   Ul Rehman, Zia
   Hanif, Muhammad
   Mustafa, Ghulam
TI A modified form of different applied median filter for removal of salt &
   pepper noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Median filter; Salt & pepper noise; Random noise; Impulse noise
ID IMPULSE NOISE
AB An algorithm is presented for removal of Salt & pepper noise. Proposed algorithm uses two phased approach where noise is first detected and then removed using window sizes extending up to 7 x 7. Window size changes depending upon noise density. In any processing window, we have some pre-processed pixels and some unprocessed pixels. If a pixel under consideration is a noise pixel then we consider all processed and unprocessed pixels for noise pixel replacement, if we find one or more noise-free pixels in window then we replace median of these pixels with corrupted pixel. If we do not find any original pixel in window then we increase window size and repeat retrospective process. The proposed algorithm shows improved results as compared to existing methods. Proposed algorithm is tested and compared for Structural Similarity (SSIM) and Peak-Signal-to-Noise Ratio (PSNR) with existing methods.
C1 [Aslam, Numan; Mustafa, Ghulam] Bahria Univ Lahore Campus BULC, Dept Comp Sci, Lahore, Pakistan.
   [Ehsan, Muhammad Khurram] Bahria Univ Lahore Campus BULC, Fac Engn Sci, Lahore, Pakistan.
   [Ul Rehman, Zia] Kinnaird Coll Women Lahore, Dept Comp Sci, Lahore, Pakistan.
   [Hanif, Muhammad] Riphah Int Univ, Riphah Inst Informat, Malakand Campus, Islamabad, Pakistan.
RP Hanif, M (corresponding author), Riphah Int Univ, Riphah Inst Informat, Malakand Campus, Islamabad, Pakistan.
EM muhammad.hanif@riphah.cdu.pk
RI hanif, Muhammad/HJH-5889-2023; Ehsan, Muhammad Khurram/GLR-4831-2022
OI Hanif, Dr. Muhammad/0000-0003-2669-2327; , Muhammad
   Hanif/0000-0002-6520-4464
CR Adhinarayanan V., 2012, Proceedings of the 2012 3rd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2012), P356, DOI 10.1109/ISMS.2012.93
   Benazir TM, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P229, DOI 10.1109/ICSIPR.2013.6498000
   Chen FY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12121990
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Erkan U., 2019, INT J ENG RES DEV, V11, P542, DOI DOI 10.29137/UMAGD.495904
   Erkan U., 2018, INT J COMPUT ELECT E, V70, P1, DOI [10.1016/j.compeleceng.2018.05.026, DOI 10.1016/J.COMPELECENG.2018.05.026]
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Hsieh MH, 2013, ENG APPL ARTIF INTEL, V26, P1333, DOI 10.1016/j.engappai.2012.10.012
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Karthik B, 2021, J AMB INTEL HUM COMP, V12, P3901, DOI 10.1007/s12652-020-01737-1
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Javier MM, 2021, IMAGE ANAL STEREOL, V40, P29, DOI 10.5566/ias.2418
   Nair MS, 2008, LECT NOTES ENG COMP, P611
   Satti P, 2020, IEEE SIGNAL PROC LET, V27, P1475, DOI 10.1109/LSP.2020.3016868
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Turkmen I, 2013, AEU-INT J ELECTRON C, V67, P771, DOI 10.1016/j.aeue.2013.03.006
   Umbaugh SE., 2005, Computer imaging: digital image analysis and processing
   Wang YY, 2013, LECT NOTES ELECTR EN, V256, P367, DOI 10.1007/978-3-642-38466-0_41
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
NR 20
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7479
EP 7490
DI 10.1007/s11042-022-13289-x
EA AUG 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843996100003
DA 2024-07-18
ER

PT J
AU Mohtar, S
   Jomhari, N
   Mustafa, MB
   Yusoff, ZM
AF Mohtar, Syahida
   Jomhari, Nazean
   Mustafa, Mumtaz Begum
   Yusoff, Zulkifli Mohd
TI Mobile learning: research context, methodologies and future works
   towards middle-aged adults - a systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Mobile application; Self-directed learning; Middle-aged adults;
   Methodology
ID HIGHER-EDUCATION; CHALLENGES; READINESS; CLASSROOM; FRAMEWORK; SELF
AB Over the past several years, mobile learning concepts have changed the way people perceived on mobile devices and technology in the learning environment. In earlier days, mobile devices were used mainly for communication purposes. Later, with many new advanced features of mobile devices, they have opened the opportunity for individuals to use them as mediated technology in learning. The traditional way of teaching and learning has shifted into a new learning dimension, where an individual can execute learning and teaching everywhere and anytime. Mobile learning has encouraged lifelong learning, in which everyone can have the opportunity to use mobile learning applications to gain knowledge. However, many of the previous studies on mobile learning have focused on the young and older adults, and less intention on middle-aged adults. In this research, it is targeted for the middle-aged adults which are described as those who are between the ages of 40 to 60. Middle-aged adults typically lead very active lives while at the same time are also very engaged in self-development programs aimed at enhancing their spiritual, emotional, and physical well-being. In this paper, we investigate the methodology used by researchers based on the research context namely, acceptance, adoption, effectiveness, impact, intention of use, readiness, and usability of mobile learning. The research context was coded to the identified methodologies found in the literature. This will help one to understand how mobile learning can be effectively implemented for middle-aged adults in future work. A systematic review was performed using EBSCO Discovery Service, Science Direct, Google Scholar, Scopus, IEEE and ACM databases to identify articles related to mobile learning adoption. A total of 65 journal articles were selected from the years 2016 to 2021 based on Kitchenham systematic review methodology. The result shows there is a need to strengthen research in the field of mobile learning with middle-aged adults.
C1 [Mohtar, Syahida; Jomhari, Nazean; Mustafa, Mumtaz Begum] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Software Engn, Kuala Lumpur 50603, Malaysia.
   [Yusoff, Zulkifli Mohd] Univ Malaya, Acad Islamic Studies, Dept Al Quran & Al Hadith, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Universiti Malaya
RP Mohtar, S (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Software Engn, Kuala Lumpur 50603, Malaysia.
EM msyahida@utem.edu.my
RI Mustafa, Mumtaz Begum/A-7277-2013; YUSOFF, MOHD YAKUB@ ZULKIFLI
   MOHD/B-5492-2010; JOMHARI, NAZEAN/B-9213-2010
OI Mustafa, Mumtaz Begum/0000-0002-2835-4084; YUSOFF, MOHD YAKUB@ ZULKIFLI
   MOHD/0000-0002-5562-2101; JOMHARI, NAZEAN/0000-0002-1609-5353; MOHTAR,
   SYAHIDA/0000-0002-4462-8890
FU Universiti Teknikal Malaysia Melaka (UTeM)
   [UTeM.02.13.04/500-4/12/16/1/2(91)]
FX The corresponding author is sponsored by Universiti Teknikal Malaysia
   Melaka (UTeM) numbered UTeM.02.13.04/500-4/12/16/1/2(91) to pursue her
   PhD degree in these studies.
CR Adedoyin O. B., 2020, INTERACT LEARN ENVIR, P1, DOI [DOI 10.1080/10494820.2020.1813180, 10.1080/10494820.2020.1813180]
   de Lara SMA, 2016, UNIVERSAL ACCESS INF, V15, P445, DOI 10.1007/s10209-015-0419-y
   Al Masarweh M, 2019, INT J EMERG TECHNOL, V14, P153, DOI 10.3991/ijet.v14i05.8296
   Al-Adwan AS, 2018, INT REV RES OPEN DIS, V19, P221
   Al-Sabbagh KW, 2019, LANG LEARN HIGH EDUC, V9, P71, DOI 10.1515/cercles-2019-0004
   Alkhezzi F., 2020, College Student Journal, V54, P491
   Amarya S., 2018, Gerontology, DOI [DOI 10.5772/INTECHOPEN.76249, 10.5772/intechopen.76249]
   Ansari JAN, 2020, SMART LEARN ENVIRON, V7, DOI 10.1186/s40561-020-00118-7
   Anshari M, 2017, EDUC INF TECHNOL, V22, P3063, DOI 10.1007/s10639-017-9572-7
   Bensalem E, 2018, ARAB WORLD ENGL J, V9, P23, DOI 10.24093/awej/vol9no1.2
   Bere A., 2019, International Journal of Education Development Using Information Communication Technology, V15, P132, DOI DOI 10.1504/IJICT.2019.102476
   Botero GG, 2019, COMPUT ASSIST LANG L, V32, P71, DOI 10.1080/09588221.2018.1485707
   Cao YY, 2022, UNIVERSAL ACCESS INF, V21, P71, DOI 10.1007/s10209-020-00762-3
   Cheng CH, 2018, PERS UBIQUIT COMPUT, V22, P921, DOI 10.1007/s00779-018-1172-z
   Chittaro L, 2016, IEEE T VIS COMPUT GR, V22, P1527, DOI 10.1109/TVCG.2015.2443787
   Christensen R, 2017, COMPUT HUM BEHAV, V76, P112, DOI 10.1016/j.chb.2017.07.014
   Cid A, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102504
   Daungcharone Kannika, 2019, International Journal of Mobile Learning and Organisation, V13, P171
   Devshikha Bose KP, 2020, ONLINE J NEW HORIZON
   Dhanapal S, 2019, APLIKASIXYZSEBAGAI A, P1
   Ejaz A, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P979, DOI 10.1109/UEMCON47517.2019.8992970
   Elaish MM, 2019, EDUC REV, V71, P257, DOI 10.1080/00131911.2017.1382445
   Farivar S, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102209
   Galic S, 2020, J NAV ARCHIT MAR ENG, V17, P39, DOI 10.3329/jname.v17i1.42203
   Gan CL, 2018, INT J HUM-COMPUT INT, V34, P666, DOI 10.1080/10447318.2017.1380970
   Garg Radhika, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479513
   Gong Crystal, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3476039
   Gordon Nancy P, 2019, JMIR Aging, V2, pe12243, DOI 10.2196/12243
   Grant MM, 2019, ETR&D-EDUC TECH RES, V67, P361, DOI 10.1007/s11423-018-09641-4
   Guinibert M, 2020, AUSTRALAS J EDUC TEC, V36, P173, DOI 10.14742/ajet.5200
   Hall GS., 1922, SENESCENCE LAST HALF, DOI [10.1037/10896-000, DOI 10.1037/10896-000]
   Huang YM, 2019, UNIVERSAL ACCESS INF, V18, P927, DOI 10.1007/s10209-018-0621-9
   Huizenga J, 2019, COMPUT HUM BEHAV, V99, P137, DOI 10.1016/j.chb.2019.05.020
   Intarasirisawat J, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411837
   Iqbal S., 2017, Int. J. E-Learn. Distance Educ, V32, P1
   Islam MN, 2020, INT J MOB HUM COMPUT, V12, P22, DOI 10.4018/IJMHCI.2020040102
   Jeno LM, 2020, COMPUT EDUC, V159, DOI 10.1016/j.compedu.2020.104022
   Jones J, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3494955
   Jones SL, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448093
   Justo R, 2020, J AMB INTEL HUM COMP, V11, P6125, DOI 10.1007/s12652-020-01983-3
   Kadir M.A. B., 2016, Journal of Education and Practice, V7, P1
   Kadirire J., 2009, The Evolution of Mobile Teaching and Learning, P15
   Kang H., 2019, New Directions for Adult and Continuing Education, V2019, P49, DOI DOI 10.1002/ACE.20325
   Keegan D., 2005, Proceedings of mLearn Conference on mLearning, P1
   Keskin NO, 2011, TURK ONLINE J EDUC T, V10, P202
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Klimova Blanka, 2020, Procedia Comput Sci, V176, P2184, DOI 10.1016/j.procs.2020.09.255
   Knowles M., 1984, ANDRAGOGY ACTION
   Knowles MS., 1975, SELF DIRECTED LEARNI
   Kuciapski M, 2017, J KNOWL MANAG, V21, P1053, DOI 10.1108/JKM-03-2016-0136
   Lachman ME, 2015, INT J BEHAV DEV, V39, P20, DOI 10.1177/0165025414533223
   LACHMAN ME, 1994, J ADULT DEV, V1, P203
   Lazar IM, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235957
   Lee K, 2019, INTERNET HIGH EDUC, V41, P25, DOI 10.1016/j.iheduc.2018.12.001
   Lewis R, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3431924
   Li QC, 2020, BEHAV INFORM TECHNOL, V39, P837, DOI 10.1080/0144929X.2019.1622786
   Lin CJ, 2020, APPL ERGON, V89, DOI 10.1016/j.apergo.2020.103215
   Lin X., 2020, International Journal of Education and Development Using Information and Communication Technology, V16, P6
   lumenlearning, INTRO PSYCHOL LIFESP
   Manca M, 2021, INT J HUM-COMPUT ST, V145, DOI 10.1016/j.ijhcs.2020.102509
   Martos-Benítez FD, 2021, INTERN EMERG MED, V16, P1507, DOI 10.1007/s11739-020-02597-5
   Masrom M., 2016, ISSUES INFORM SYSTEM, V17, P152
   Mather CA, 2017, BMC NURS, V16, DOI 10.1186/s12912-017-0212-8
   Mendel Tamir, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3369821
   Mican D, 2019, J APP COMPUT SCI MAT, V13
   Michelson Rebecca, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479546
   Moore M., 2019, J COMPUT SCI COLL, V34, P134
   Naismith L, 2004, FUTURELAB REPORT, P11
   Nordin N, 2010, PROCD SOC BEHV, V7, P130, DOI 10.1016/j.sbspro.2010.10.019
   Ozdamli F, 2011, PROCD SOC BEHV, V28, DOI 10.1016/j.sbspro.2011.11.173
   Palacio RR, 2017, UNIVERSAL ACCESS INF, V16, P103, DOI 10.1007/s10209-015-0435-y
   Palalas A, 2020, AUSTRALAS J EDUC TEC, V36, P151, DOI 10.14742/ajet.5650
   Sarrab Mohamed, 2016, International Journal of Mobile Learning and Organisation, V10, P129
   Seah D, 2020, INT J MOB LEARN ORG, V14, P36, DOI 10.1504/IJMLO.2020.103937
   Sevkli Aise Zulal, 2017, International Journal of Mobile Learning and Organisation, V11, P295
   Sharma SK, 2017, INTERACT LEARN ENVIR, V25, P847, DOI 10.1080/10494820.2016.1224250
   Shukla S, 2021, EDUC INF TECHNOL, V26, P279, DOI 10.1007/s10639-020-10271-8
   Sin Frances, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479524
   Stewart AJ, 2001, J ADULT DEV, V8, P23, DOI 10.1023/A:1026445704288
   Sundgren M, 2017, EDUC INF TECHNOL, V22, P3081, DOI 10.1007/s10639-017-9576-3
   Swanson JA, 2020, TECHNOL KNOWL LEARN, V25, P389, DOI 10.1007/s10758-018-9372-1
   Tan E, 2016, J SUSTAIN TOUR, V24, P132, DOI 10.1080/09669582.2015.1049610
   Thongsri Nattaporn, 2018, Journal of Systems and Information Technology, V20, P278, DOI 10.1108/JSIT-11-2017-0107
   Traxler J, 2009, ISS ONLINE EDUC, P9
   Tu YG, 2020, INT J MOB LEARN ORG, V14, P370, DOI 10.1504/IJMLO.2020.108199
   Vacher M, 2019, ACM T ACCESS COMPUT, V12, DOI 10.1145/3310132
   Venkataraman Jayendra Bharati, 2018, International Journal of Mobile Learning and Organisation, V12, P99
   Vicente P, 2016, COMMUNICATIONS-GER, V41, P71, DOI 10.1515/commun-2015-0026
   Wang YH, 2018, INNOV AGING, V2, DOI 10.1093/geroni/igy027
   Wardaszko M, 2017, SIMULAT GAMING, V48, P435, DOI 10.1177/1046878117704350
   Wong C.Y., 2018, International Conference on User Science and Engineering, V886, P93, DOI DOI 10.1007/978-981-13-1628-9_9
   YAFFE MJ, 1984, CAN FAM PHYSICIAN, V30, P1089
   Yang HL, 2019, COMPUT HUM BEHAV, V93, P62, DOI 10.1016/j.chb.2018.12.005
   ZAINAL A, 2017, ADV SCI LETT, V23, P4236, DOI DOI 10.1166/asl.2017.8335
   Zhang RF, 2020, INT J MOB LEARN ORG, V14, P533, DOI 10.1504/IJMLO.2020.110798
   Zhiyuan Wan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3369819
NR 96
TC 2
Z9 2
U1 11
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 11117
EP 11143
DI 10.1007/s11042-022-13698-y
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000842724300001
PM 36035325
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wang, FG
   Wang, NB
   Cai, SB
   Zhang, WL
AF Wang, Fugang
   Wang, Nianbin
   Cai, Shaobin
   Zhang, Wulin
TI Dynamically constructing semantic topic hierarchy through formal concept
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic hierarchy; Semantic similarity; FCA; HowNet; IR
ID INFORMATION-RETRIEVAL; CONCEPT SIMILARITY; CATEGORIES; ALGORITHM
AB Dynamic topic analysis can examine the data from different perspectives and know the distribution of data with different correlation degrees thoroughly. It is a challenge to perform dynamic topic analysis on domain text data due to the smaller semantic differences among subtopics. This paper proposes a method of dynamically constructing topic hierarchy, which uses formal concept analysis (FCA)-based information retrieval (IR) as the technical basis and sememes as the semantic basis to perform hierarchical processing from fine-grained to coarse-grained on Chinese domain text data according to the topics of user's query. It can meet the user's need for different scales of the query results, and realize multi-angle inspection of the whole dataset and high-precision retrieval of the query. Taking sememes as formal attributes reduces the size of the concept lattice and expands the application of FCA technology to large-scale text data. The sememe-based word meaning identification (WMI) algorithm and semantic similarity measurement method for long text enable the topic hierarchy to be fine, and the coarse and fine filtering strategy renders the FCA-based method more efficient. Experimental results based on the open dataset show that the method proposed is an efficient and flexible topic-based hierarchical approach.
C1 [Wang, Fugang; Wang, Nianbin] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Wang, Fugang; Zhang, Wulin] Mudanjiang Normal Univ, Sch Phys & Elect Engn, Mudanjiang 157011, Peoples R China.
   [Cai, Shaobin] Foshan Univ, Sch Elect Informat Engn, Foshan 528225, Peoples R China.
C3 Harbin Engineering University; Mudanjiang Normal University; Foshan
   University
RP Wang, NB (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM wangnianbin@hrbeu.edu.cn
RI Wang, Fugang/AAS-2593-2020
OI Wang, Fugang/0000-0001-5360-7808
FU National Natural Science Foundation of China [61772152]; Youth Fund
   Project of Humanities and Social Sciences Research of the Ministry of
   Education of China [20YJCZH172]; Basic Research Project
   [JCKY2019604C004]
FX This work is supported by the National Natural Science Foundation of
   China (61772152), the Basic Research Project (JCKY2019604C004), in part
   by the Youth Fund Project of Humanities and Social Sciences Research of
   the Ministry of Education of China (20YJCZH172).
CR Ali CB, 2018, IEEEACS INT C COMPUT
   Andrews S, 2016, J INTELL INF SYST, V47, P287, DOI 10.1007/s10844-016-0404-9
   Andrews S, 2015, INFORM SCIENCES, V295, P633, DOI 10.1016/j.ins.2014.10.011
   Andrews S, 2014, LECT NOTES ARTIF INT, V8577, P37, DOI 10.1007/978-3-319-08389-6_5
   [Anonymous], 2006, Hownet and the computation of meaning, DOI 10.1142/5935
   [Anonymous], 2006, FOOCA WEB INFORM RET
   Asghari M, 2015, LECT NOTES ARTIF INT, V9101, P503, DOI 10.1007/978-3-319-19066-2_49
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bloomfield L, 1926, LANGUAGE, V2, P153, DOI 10.2307/408741
   Butka P, 2018, LECT NOTES COMPUT SC, V10546, P123, DOI [10.1007/978-3-319-74497-1_12, 10.1007/978-3-319-7497-1_12]
   Carpineto C, 2004, J UNIVERS COMPUT SCI, V10, P985
   Codocedo V, 2014, ANN MATH ARTIF INTEL, V72, P169, DOI 10.1007/s10472-014-9403-0
   Dau F, 2008, LECT NOTES ARTIF INT, V5113, P255, DOI 10.1007/978-3-540-70596-3_18
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Duan XY, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1594
   Eklund P, 2012, INT J GEN SYST, V41, P826, DOI 10.1080/03081079.2012.707451
   Ferrante M, 2021, IEEE ACCESS, V9, P136182, DOI 10.1109/ACCESS.2021.3116857
   Fkih F, 2016, KNOWL INF SYST, V48, P465, DOI 10.1007/s10115-015-0876-x
   Formica A, 2008, KNOWL-BASED SYST, V21, P80, DOI 10.1016/j.knosys.2007.02.001
   Formica A, 2006, INFORM SCIENCES, V176, P2624, DOI 10.1016/j.ins.2005.11.014
   Formica A, 2012, KNOWL-BASED SYST, V26, P40, DOI 10.1016/j.knosys.2011.06.018
   Ganter B., 1997, General Lattice Theory
   Han MT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5971
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Ignatov DI, 2015, COMM COM INF SC, V505, P42, DOI 10.1007/978-3-319-25485-2_3
   Jiang YC, 2018, INT J SEMANT WEB INF, V14, P99, DOI 10.4018/IJSWIS.2018070105
   Li W, 2016, LECT NOTES COMPUT SC, V10102, P461, DOI 10.1007/978-3-319-50496-4_38
   Liu S, 2019, LECT NOTES ARTIF INT, V11838, P787, DOI 10.1007/978-3-030-32233-5_61
   Manning ChristopherD., 2008, Introduction to Information Retrieval, P234
   NAPOLI A, 1994, INT J HUM-COMPUT ST, V41, P5, DOI 10.1006/ijhc.1994.1051
   Negm E, 2017, INFORM PROCESS MANAG, V53, P203, DOI 10.1016/j.ipm.2016.08.002
   Neto SM, 2018, INFORM SCIENCES, V429, P361, DOI 10.1016/j.ins.2017.11.028
   Niu YL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P2049, DOI 10.18653/v1/P17-1187
   Phyo SS, 2022, DATA TECHNOL APPL, V56, P24, DOI 10.1108/DTA-07-2020-0146
   Qi F, 2019, ARXIV
   Qi FC, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-0002-4
   Qian C, 2021, AAAI CONF ARTIF INTE, V35, P13683
   Sakata W, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1113, DOI 10.1145/3331184.3331326
   Shi CY, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P597, DOI 10.1109/SNPD.2016.7515965
   Trillo R, 2011, INFORM SYST, V36, P117, DOI 10.1016/j.is.2010.06.008
   Wan Y, 2019, IEEE ACCESS, V7, P11029, DOI 10.1109/ACCESS.2019.2892016
   Wang FG, 2020, IEEE ACCESS, V8, P75303, DOI 10.1109/ACCESS.2020.2988689
   Wang YS, 2016, J ASSOC INF SCI TECH, V67, P1736, DOI 10.1002/asi.23444
   Wang YC, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5140
   Wille R, 2009, LECT NOTES ARTIF INT, V5548, P314
   Xingyi D, 2019, ARXIV
   Zhang ZS, 2020, AAAI CONF ARTIF INTE, V34, P9628
   Zhendong D, 1999, HOWNET CHINESE INFOR
NR 48
TC 1
Z9 1
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7267
EP 7292
DI 10.1007/s11042-022-13640-2
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842590700001
DA 2024-07-18
ER

PT J
AU Imani, H
   Islam, MB
   Junayed, MS
   Aydin, T
   Arica, N
AF Imani, Hassan
   Islam, Md Baharul
   Junayed, Masum Shah
   Aydin, Tarkan
   Arica, Nafiz
TI Stereoscopic video quality measurement with fine-tuning 3D ResNets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D convolutional neural networks; Fine-tuning; Objective quality
   assessment; Pre-training; Stereoscopic video; Transfer learning
ID IMAGE; SALIENCY; COMPRESSION; DISPARITY; MOTION
AB Recently, Convolutional Neural Networks with 3D kernels (3D CNNs) have shown great superiority over 2D CNNs for video processing applications. In the field of Stereoscopic Video Quality Assessment (SVQA), 3D CNNs are utilized to extract the spatio-temporal features from the stereoscopic video. Besides, the emergence of substantial video datasets such as Kinetics has made it possible to use pre-trained 3D CNNs in other video-related fields. In this paper, we fine-tune 3D Residual Networks (3D ResNets) pre-trained on the Kinetics dataset for measuring the quality of stereoscopic videos and propose a no-reference SVQA method. Specifically, our aim is twofold: Firstly, we answer the question: can we use 3D CNNs as a quality-aware feature extractor from stereoscopic videos or not. Secondly, we explore which ResNet architecture is more appropriate for SVQA. Experimental results on two publicly available SVQA datasets of LFOVIAS3DPh2 and NAMA3DS1-COSPAD1 show the effectiveness of the proposed transfer learning-based method for SVQA that provides the RMSE of 0.332 in LFOVIAS3DPh2 dataset. Also, the results show that deeper 3D ResNet models extract more efficient quality-aware features.
C1 [Imani, Hassan; Islam, Md Baharul; Junayed, Masum Shah; Aydin, Tarkan; Arica, Nafiz] Bahcesehir Univ, Dept Comp Engn, Comp Vis Lab, Istanbul, Turkey.
   [Islam, Md Baharul] Daffodil Int Univ, Dept Comp Sci & Engn, Dhaka 1341, Bangladesh.
C3 Bahcesehir University; Daffodil International University
RP Imani, H (corresponding author), Bahcesehir Univ, Dept Comp Engn, Comp Vis Lab, Istanbul, Turkey.
EM hassan.imani1987@gmail.com
RI Imani, Hassan/KSL-4309-2024; Arica, Nafiz/ADD-3793-2022; Junayed, Masum
   Shah/P-7375-2019; Islam, Md Baharul/R-3751-2019
OI Imani, Hassan/0000-0003-1566-3897; Junayed, Masum
   Shah/0000-0003-3592-4601; Islam, Md Baharul/0000-0002-9928-5776; Aydin,
   Tarkan/0000-0002-2018-405X
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [118C301]
FX This work was supported in part by the Scientific and Technological
   Research Council of Turkey (TUBITAK) through the 2232 Outstanding
   International Researchers Program under Project No. 118C301.
CR [Anonymous], 2005, 1 INT WORKSHOP VIDEO
   [Anonymous], VQM SOFTWARE
   [Anonymous], 2010, P INT WORKSH VID PRO
   Appina B, 2019, IEEE T IMAGE PROCESS, V28, P5027, DOI 10.1109/TIP.2019.2914950
   Appina B, 2018, IEEE IMAGE PROC, P2800, DOI 10.1109/ICIP.2018.8451693
   Banitalebi-Dehkordi A, 2018, MULTIMED TOOLS APPL, V77, P26055, DOI 10.1007/s11042-018-5837-4
   Banitalebi-Dehkordi A, 2016, MULTIMED TOOLS APPL, V75, P4187, DOI 10.1007/s11042-015-2466-z
   Benoit A, 2008, IEEE IMAGE PROC, P389, DOI 10.1109/ICIP.2008.4711773
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Campisi Patrizio, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2110
   Chen K, 2021, ARXIV
   Chen L, 2019, MULTIMED TOOLS APPL, V78, P12139, DOI 10.1007/s11042-018-6759-x
   Chen ZB, 2018, IEEE T IMAGE PROCESS, V27, P721, DOI 10.1109/TIP.2017.2766780
   Cheng E, 2012, INT WORK QUAL MULTIM, P212, DOI 10.1109/QoMEX.2012.6263873
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Feng YL, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P90, DOI 10.1109/SIPROCESS.2017.8124512
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong WH, 2018, IEEE SIGNAL PROC LET, V25, P214, DOI 10.1109/LSP.2017.2780285
   Hou R, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115782
   Huber PJ., 2009, ROBUST STAT, DOI DOI 10.1002/9780470434697
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang GY, 2018, J VIS COMMUN IMAGE R, V50, P247, DOI 10.1016/j.jvcir.2017.12.001
   Jiang GY, 2015, MULTIMED TOOLS APPL, V74, P8197, DOI 10.1007/s11042-014-2051-x
   Joveluro P, 2010, 3DTV CONF
   Kan BC, 2018, OPT EXPRESS, V26, P11418, DOI 10.1364/OE.26.011418
   Kataoka H., 2020, arXiv
   Kay W., 2017, CORR ABS170506950
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar V., 2017, 2017 IEEE 28 INT S P, P1, DOI DOI 10.1109/ICETCCT.2017.8280331
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu XA, 2015, MULTIMED TOOLS APPL, V74, P2803, DOI 10.1007/s11042-013-1698-z
   Lu F., 2009, Proceedings of the Fourth ACM International Workshop on UnderWater Networks, p11:1, DOI [DOI 10.1145/1654130.1654141, 10.1145/1654130.1654141]
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Ma XF, 2019, I C OPT COMMUN NETW, DOI 10.1109/icocn.2019.8934726
   Mahmood SA, 2015, COMPUT SCI ELECTR, P179, DOI 10.1109/CEEC.2015.7332721
   Md SK, 2015, IEEE SIGNAL PROC LET, V22, P1985, DOI 10.1109/LSP.2015.2449878
   Messai O, 2018, 2018 INTERNATIONAL CONFERENCE ON SIGNAL, IMAGE, VISION AND THEIR APPLICATIONS (SIVA)
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Otroshi-Shahreza H, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P637, DOI 10.1109/ISTEL.2018.8661024
   Prieto A, 2016, NEUROCOMPUTING, V214, P242, DOI 10.1016/j.neucom.2016.06.014
   Qi F, 2016, SIGNAL IMAGE VIDEO P, V10, P737, DOI 10.1007/s11760-015-0802-4
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smaira L, 2020, ARXIV
   Statistics, 2011, HOLLYWOOD MOTION PIC
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan Lu, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1372, DOI 10.1109/ICDAR.2019.00221
   Urvoy M, 2012, INT WORK QUAL MULTIM, P109, DOI 10.1109/QoMEX.2012.6263847
   Varga D, 2019, SIGNAL IMAGE VIDEO P, V13, P1569, DOI 10.1007/s11760-019-01510-8
   Varga D, 2019, NEURAL PROCESS LETT, V50, P2595, DOI 10.1007/s11063-019-10036-6
   Voo KHB, 2018, MULTIMED TOOLS APPL, V77, P2313, DOI 10.1007/s11042-017-4361-2
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu XG, 2019, IEEE ACCESS, V7, P85286, DOI 10.1109/ACCESS.2019.2925084
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   Yang JC, 2019, IEEE T IMAGE PROCESS, V28, P1314, DOI 10.1109/TIP.2018.2878283
   Yang JC, 2018, NEUROCOMPUTING, V309, P83, DOI 10.1016/j.neucom.2018.04.072
   Yang JC, 2018, IEEE T BROADCAST, V64, P341, DOI 10.1109/TBC.2018.2789583
   Yang JC, 2017, INFORM SCIENCES, V414, P133, DOI 10.1016/j.ins.2017.05.051
   Yilmaz GN, 2015, MULTIMED TOOLS APPL, V74, P6937, DOI 10.1007/s11042-014-1945-y
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhang Y, 2020, IEEE T NEUR NET LEAR, V31, P2716, DOI 10.1109/TNNLS.2018.2890310
   Zhou W, 2018, LECT NOTES COMPUT SC, V11166, P482, DOI 10.1007/978-3-030-00764-5_44
NR 67
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42849
EP 42869
DI 10.1007/s11042-022-13485-9
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840056800005
DA 2024-07-18
ER

PT J
AU Gour, N
   Khanna, P
AF Gour, Neha
   Khanna, Pritee
TI Ocular diseases classification using a lightweight CNN and class weight
   balancing on OCT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocular disease classification; Optical coherence tomography;
   Convolutional neural networks; Class weight balancing
ID COHERENCE TOMOGRAPHY IMAGES; DIABETIC MACULAR EDEMA
AB Optical coherence tomography (OCT) is a non-invasive technique to capture cross-sectional volumes of the human retina. OCT images are used for the diagnosis of various ocular diseases. However, OCT datasets generally suffer from the problem of class imbalance. This work aims to leverage CNN capability for OCT images classification in the presence of class imbalance. A lightweight convolutional neural network (CNN) with class weight balancing (CWB) is proposed for OCT image classification. Training of CNN is done while penalizing the classes having a higher number of samples using the CWB method. The performance of the proposed method is evaluated on spectral-domain OCT (SD-OCT) images from two publicly available datasets, namely, ZhangLab and Duke. The performance of the proposed method is evaluated on the confusion matrix-based parameters like accuracy, sensitivity, specificity, and F1 - score. The proposed method achieved 99.17% and 98.46% accuracy for ZhangLab and Duke datasets, respectively. It is observed that the proposed method performs better as compared to most of the state-of-the-art OCT classification methods The generalizability and interpretability of the proposed method are also evaluated to improve the understanding of the CNN model.
C1 [Gour, Neha; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur, India.
EM g.neha@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019; gour, neha/ISB-0210-2023
OI Khanna, Pritee/0000-0003-0518-2133; GOUR, NEHA/0000-0002-0860-1260
CR Alqudah AM, 2020, MED BIOL ENG COMPUT, V58, P41, DOI 10.1007/s11517-019-02066-y
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chetoui Mohamed, 2020, Image Analysis and Recognition. 17th International Conference (ICIAR 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12132), P358, DOI 10.1007/978-3-030-50516-5_31
   Daume H., 2017, COURSE MACHINE LEARN
   De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6
   Drexler W, 2008, PROG RETIN EYE RES, V27, P45, DOI 10.1016/j.preteyeres.2007.07.005
   Ertekin S., 2007, Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'07, P823, DOI [DOI 10.1145/1277741.1277927, 10.1145/1277741.1277927]
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fujimoto J, 2008, BIOL MED PHYS BIOMED, P1, DOI 10.1007/978-3-540-77550-8_1
   Gao L, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101935
   Gholami P, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106532
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Hani M, 2021, COMP M BIO BIO E-IV, V9, P146, DOI 10.1080/21681163.2020.1827041
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Huang LF, 2019, IEEE SIGNAL PROC LET, V26, P1026, DOI 10.1109/LSP.2019.2917779
   Hussain MA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198281
   Ibrahim MR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144716
   Ji QG, 2018, ALGORITHMS, V11, DOI 10.3390/a11060088
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Karri SPK, 2017, BIOMED OPT EXPRESS, V8, P579, DOI 10.1364/BOE.8.000579
   Kaymak S, 2018, INT C INTELL COMP CO, P265, DOI 10.1109/ICCP.2018.8516635
   Kermany D., 2018, MENDELEY DATA, Vv3, DOI [10.17632/rscbjbr9sj3, DOI 10.17632/RSCBJBR9SJ3]
   Kermany Daniel, 2018, Mendeley Data, V3
   King G., 2001, POLIT ANAL, V9, P137, DOI [DOI 10.1093/OXFORDJOURNALS.PAN.A004868, https://doi.org/10.1093/oxfordjournals.pan.a004868]
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lemaître G, 2016, J OPHTHALMOL, V2016, DOI 10.1155/2016/3298606
   Li F, 2019, GRAEF ARCH CLIN EXP, V257, P495, DOI 10.1007/s00417-018-04224-8
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Ling Charles X., 2008, Encyclopedia of Machine Learning, P231, DOI [10.1.1.15.7095, 10.1007/978-0-387-30164-8_181, DOI 10.1007/978-0-387-30164-8_181]
   Liu YH, 2018, IEEE DATA MINING, P1146, DOI 10.1109/ICDM.2018.00150
   Najeeb S, 2018, 2018 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P465, DOI 10.1109/ICECE.2018.8636699
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Rasti R, 2018, IEEE T MED IMAGING, V37, P1024, DOI 10.1109/TMI.2017.2780115
   Rasti R, 2018, J BIOMED OPT, V23, DOI 10.1117/1.JBO.23.3.035005
   Rong YB, 2019, IEEE J BIOMED HEALTH, V23, P253, DOI 10.1109/JBHI.2018.2795545
   Sanyal A, 2018, MACH LEARN, V107, P1597, DOI 10.1007/s10994-018-5736-y
   Settles B., 2012, SYNTHESIS LECT AI ML
   Srinivasan PP, 2014, BIOMED OPT EXPRESS, V5, P3568, DOI 10.1364/BOE.5.003568
   Sunija AP, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105877
   Talu Simona-Delia., 2013, ISRN. Biomedical Imaging, P1
   Thomas A, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102538
   Venhuizen FG, 2015, PROC SPIE, V9414, DOI 10.1117/12.2081521
   Wu J, 2020, LECT NOTES COMPUT SC, V11962, P565, DOI 10.1007/978-3-030-37734-2_46
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 50
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41765
EP 41780
DI 10.1007/s11042-022-13617-1
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000838552300012
DA 2024-07-18
ER

PT J
AU Aftab, S
   Ali, SF
   Mahmood, A
   Suleman, U
AF Aftab, Salma
   Ali, Syed Farooq
   Mahmood, Arif
   Suleman, Umar
TI A boosting framework for human posture recognition using spatio-temporal
   features along with radon transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Terms-Human posture recognition; Machine leaning; J48; Adaboost; Human
   action recognition
ID FALL DETECTION; DESCRIPTOR; SYSTEM
AB Automatic human posture recognition in surveillance videos has real world applications in monitoring old-homes, restoration centers, hospitals, disability, and child-care centers. It also has applications in other areas such as security and surveillance, sports, and abnormal activity recognition. Human posture recognition is a challenging problem due to occlusion, background clutter, illumination variations, camouflage, and noise in the captured video signal. In the current study, which is an extension of our previous work (Ali et al. Sensors, 18(6):1918, 2018), we propose a novel combination of a number of spatio-temporal features computed over human blobs in a temporal window. These features include aspect ratios, shape descriptors, geometric centroids, ellipse axes ratio, silhouette angles, and silhouette speed. In addition to these features, we also exploit the radon transform to get better shape based analysis. In order to obtain improved posture classification accuracy, we used J48 classifier under a boosting framework by employing the AdaBoost algorithm.The proposed algorithm is compared with eighteen existing state-of-the-art approaches on four publicly available datasets including MCF, UR Fall detection, KARD, and NUCLA. Our results demonstrate the excellent performance of the proposed algorithm compared to these existing methods.
C1 [Aftab, Salma; Ali, Syed Farooq; Suleman, Umar] Univ Management & Technol, SST, C-2, Lahore, Pakistan.
   [Mahmood, Arif] Informat Technol Univ ITU, Comp Sci, 346-B, Lahore, Pakistan.
C3 University of Management & Technology (UMT)
RP Ali, SF (corresponding author), Univ Management & Technol, SST, C-2, Lahore, Pakistan.
EM s2018114003@umt.edu.pk; farooq.ali@umt.edu.pk; arif.mahmood@itu.edu.pk;
   umar.suleman@umt.edu.pk
RI Mahmood, Arif/R-7949-2019; Ali, Syed Farooq/ADO-7514-2022
OI Mahmood, Arif/0000-0001-5986-9876; Ali, Syed Farooq/0000-0003-3943-903X
FU National ICT RD [NICTRDF/NGIRI/2012-13/Corsp/3]; University of
   Management & Technology, Lahore, Pakistan
FX We are very grateful to Noman Nazar and Reamsha Khan for his support and
   guidance. We also like to extend our special gratitude to Ms. Sumaira
   Zafar, Muhammad Junaid and Mahzaib Khalid for their assistance. We are
   grateful to all the anonymous reviewers for their useful comments. This
   work was supported by the National ICT R&D under grant no.
   NICTRDF/NGIRI/2012-13/Corsp/3; and University of Management &
   Technology, Lahore, Pakistan
CR Adhikari Kripesh., 2019, International Journal of Computer and Systems Engineering, V13, P255
   Alaoui AY, 2021, J IMAGING, V7, DOI 10.3390/jimaging7070109
   Ali SF, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061918
   Auvinet Edouard., 2010, Multiple cameras fall dataset, P1350
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   Darwish A, 2011, SENSORS-BASEL, V11, P5561, DOI 10.3390/s110605561
   Debard G, 2011, AMB INTELL SMART ENV, V10, P441, DOI 10.3233/978-1-60750-795-6-441
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Doukas CN, 2011, IEEE T INF TECHNOL B, V15, P277, DOI 10.1109/TITB.2010.2091140
   Edgcomb AD., 2014, THESIS UC RIVERSIDE
   Elforaici MEA, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P69, DOI 10.1109/LSC.2018.8572079
   Fan KB, 2019, MULTIMED TOOLS APPL, V78, P9101, DOI 10.1007/s11042-018-5638-9
   Fan KB, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717707418
   Feng Q, 2020, PATTERN RECOGN LETT, V130, P242, DOI 10.1016/j.patrec.2018.08.031
   Foroughi H, 2008, INT CONF SIGN PROCES, P1500
   Foroughi H, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P413, DOI 10.1109/ICVGIP.2008.49
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Gasparrini S, 2016, ADV INTELL SYST, V399, P99, DOI 10.1007/978-3-319-25733-4_11
   Ge CJ, 2017, IEEE INT WORKS MACH
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Iazzi A, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Javed S, 2017, IEEE T IMAGE PROCESS, V26, P5840, DOI 10.1109/TIP.2017.2746268
   Ji XF, 2014, INT CONF COMPUT INFO, P801, DOI 10.1109/CIT.2014.87
   Kamal S, 2016, ARAB J SCI ENG, V41, P1043, DOI 10.1007/s13369-015-1955-8
   Kaur G., 2014, INT J COMPUTER APPL, V98, P13, DOI [10.5120/17314-7433, DOI 10.5120/17314-7433]
   Kepski M, 2015, INT WORKSH INT DATA, P755, DOI 10.1109/IDAACS.2015.7341404
   Khalifa OO, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRICAL AND ELECTRONICS ENGINEERING (ICCEEE), P40, DOI 10.1109/ICCEEE.2013.6633905
   Kong YQ, 2019, J VIS COMMUN IMAGE R, V59, P215, DOI 10.1016/j.jvcir.2019.01.024
   Kyrkou C, 2011, IEEE T VLSI SYST, V19, P1034, DOI 10.1109/TVLSI.2010.2048224
   Lahiri D., 2018, 2017 C INF COMMUN TE, V2018-April, P1, DOI DOI 10.1109/INFOCOMTECH.2017.8340622
   Leroux A, 2018, ARXIV
   Li CY, 2018, ARAB J SCI ENG, V43, P7777, DOI 10.1007/s13369-018-3189-z
   Li G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041158
   Li NJ, 2013, INT CONF ACOUST SPEE, P3407, DOI 10.1109/ICASSP.2013.6638290
   Liu EY, 2011, FRONT COMPUT SCI CHI, V5, P148, DOI 10.1007/s11704-011-9134-x
   Liu J., 2017, ARXIV
   Liu MY, 2016, CAAI T INTELL TECHNO, V1, P14, DOI 10.1016/j.trit.2016.03.001
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Lymberis A, 2007, IEEE ENG MED BIOL, V26, P29, DOI 10.1109/MEMB.2007.364926
   Makhlouf A, 2017, PROCEDIA COMPUT SCI, V109, P969, DOI 10.1016/j.procs.2017.05.455
   Memmesheimer R, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P813, DOI 10.1109/IS.2018.8710515
   Min WD, 2018, IEEE ACCESS, V6, P9324, DOI 10.1109/ACCESS.2018.2795239
   Moussa MM, 2018, ARAB J SCI ENG, V43, P597, DOI 10.1007/s13369-017-2694-9
   MOUSSE M A, 2016, INT C PATTERN RECOGN, P2
   Mousse MA, 2017, VISUAL COMPUT, V33, P1529, DOI 10.1007/s00371-016-1296-y
   Munoz-Organero M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091464
   Nizam Y, 2016, INT J INTEGR ENG, V8, P35
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Rimmer JH, 1999, PHYS THER, V79, P495, DOI 10.1093/ptj/79.5.495
   Ronchetti F, 2015, FRONT COMPUT SCI-CHI, V9, P956, DOI 10.1007/s11704-015-4320-x
   Shi H, 2018, INT C PATT RECOG, P2899, DOI 10.1109/ICPR.2018.8545500
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Simonyan K, 2014, ADV NEUR IN, V27
   Stork J. A., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P509, DOI 10.1109/ROMAN.2012.6343802
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tabbone S, 2006, COMPUT VIS IMAGE UND, V102, P42, DOI 10.1016/j.cviu.2005.06.005
   Tanwani AK, 2009, LECT NOTES COMPUT SC, V5483, P128, DOI 10.1007/978-3-642-01184-9_12
   Tinetti ME, 2003, NEW ENGL J MED, V348, P42, DOI 10.1056/NEJMcp020719
   Tomoya A, 2017, PROCEDIA COMPUT SCI, V112, P1994, DOI 10.1016/j.procs.2017.08.125
   Vishwakarma DK, 2016, AEU-INT J ELECTRON C, V70, P341, DOI 10.1016/j.aeue.2015.12.016
   Walse KH, 2016, IIOAB J, V7, P68
   Wang J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3432, DOI 10.1109/BigData.2016.7841004
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wang SM, 2014, ADV MAT RES, V1042, P117
   Wang WJ, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/62163
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yu M, 2013, IEEE J BIOMED HEALTH, V17, P1002, DOI 10.1109/JBHI.2013.2274479
   Zhang BW, 2018, IEEE T IMAGE PROCESS, V27, P2326, DOI 10.1109/TIP.2018.2791180
   Zhou K., 2017, 2017 IEEE VISUAL COM, P1, DOI [10.1109/VCIP.2017.8305063, DOI 10.1109/VCIP.2017.8305063]
NR 73
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42325
EP 42351
DI 10.1007/s11042-022-13536-1
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000836525000006
DA 2024-07-18
ER

PT J
AU Anand, V
   Gupta, S
   Nayak, SR
   Koundal, D
   Prakash, D
   Verma, KD
AF Anand, Vatsala
   Gupta, Sheifali
   Nayak, Soumya Ranjan
   Koundal, Deepika
   Prakash, Deo
   Verma, K. D.
TI An automated deep learning models for classification of skin disease
   using Dermoscopy images: a comprehensive study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dermoscopy images; CNN; Deep learning; Classification; Optimization;
   Skin disease; HAM10000; Transfer learning; Data augmentation
ID COMPUTER-AIDED DIAGNOSIS; CANCER; TIME; PREVALENCE; LESIONS
AB With the explosion of advanced Information and Recognition model, primarily the Deep Learning (DL) and Transfer Learning (TL) models, all aspects of recent research have been influenced. The Biomedical image analysis has also been considerably subjective by recent technology involvements, carrying about a pattern shift towards 'automation' and 'error free diagnosis' classification methods with markedly improved accurate diagnosis productivity and cost effectiveness. This paper proposes an automated deep learning model to diagnose the skin disease at early stage by using Dermoscopy images. The complete proposed framework is achieved by evaluating the four pre-trained transfer learning CNN models such as DenseNet121, ResNet50, VGG16 and ResNet18 for classification accuracy on skin dataset images. Also, some pre-processing steps are followed to enhance the accuracy; in addition with various simulation parameters like epochs, batch size and optimizers are studied to find the best model. Analysis is performed with two different batch sizes i.e. 16 and 32 and two different optimizers i.e. Adam and SGD optimizers. The best accuracy is obtained on proposed ResNet50 and ResNet18 model on batch size 32 and SGD optimizer. The best value of accuracy on ResNet50 and ResNet18 model is 90% followed by second best accuracy of 89% on DenseNet121 model. ResNet50 and ResNet18 have obtained sensitivity as 97% and 94% for Melanocytic Nevi disease whereas DenseNet121 model has obtained 94% sensitivity in case of Basal Cell Carcinoma disease. This model can be used for early diagnosis of skin disease and can also act as second opinion tool for dermatologists.
C1 [Anand, Vatsala; Gupta, Sheifali] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Nayak, Soumya Ranjan] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
   [Koundal, Deepika] Univ Petr & Energy Studies, Sch Comp Sci, Dept Virtualizat, Dehra Dun, Uttarakhand, India.
   [Prakash, Deo] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Fac Engn, Katra 182320, J&K, India.
   [Verma, K. D.] Shri Varshney PG Coll, Dept Phys, Aligarh 202001, Uttar Pradesh, India.
C3 Chitkara University, Punjab; Amity University Noida; University of
   Petroleum & Energy Studies (UPES); Shri Mata Vaishno Devi University
RP Nayak, SR (corresponding author), Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
EM vatsala.anand@chitkara.edu.in; sheifali.gupta@chitkara.edu.in;
   nayak.soumya17@gmail.com; dkoundal@ddn.upes.ac.in;
   deoprakash.a@gmail.com; kdverma1215868@gmail.com
RI Nayak, Soumya Ranjan/S-5908-2018; Gupta, Sheifali/IQU-0129-2023; Verma,
   K.D./K-5758-2018; Prakash, Deo/O-9722-2015; Anand,
   Vatsala/GLS-8493-2022; Koundal, Deepika/I-9927-2019
OI Nayak, Soumya Ranjan/0000-0002-4155-884X; Verma,
   K.D./0000-0002-5492-2997; Koundal, Deepika/0000-0003-1688-8772; gupta,
   sheifali/0000-0001-5692-418X; Anand, Vatsala/0000-0001-6143-250X
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Al-antari MA, INCONFERENCE ISIC201
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Amin J, 2020, PATTERN RECOGN LETT, V131, P63, DOI 10.1016/j.patrec.2019.11.042
   Carli P, 2004, BRIT J DERMATOL, V150, P687, DOI 10.1111/j.0007-0963.2004.05860.x
   Castellino Ronald A, 2005, Cancer Imaging, V5, P17, DOI 10.1102/1470-7330.2005.0018
   Cho WCS, 2008, TECHNOL CANCER RES T, V7, P269, DOI 10.1177/153303460800700401
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Edge SB, 2010, ANN SURG ONCOL, V17, P1471, DOI 10.1245/s10434-010-0985-4
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Goldenberg R, 2012, INT J COMPUT ASS RAD, V7, P819, DOI 10.1007/s11548-012-0684-7
   González-Díaz I, 2019, IEEE J BIOMED HEALTH, V23, P547, DOI 10.1109/JBHI.2018.2806962
   Guy GP, 2014, AM J PUBLIC HEALTH, V104, pE69, DOI [10.2105/AJPH.2013.301850, 10.1016/j.amepre.2014.08.036]
   Haenssle H A, 2019, Ann Oncol, V30, p130e, DOI 10.1093/annonc/mdy520
   Han SS, 2020, JAMA DERMATOL, V156, P29, DOI 10.1001/jamadermatol.2019.3807
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hekler A, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00177
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HW, 2021, J DERMATOL, V48, P310, DOI 10.1111/1346-8138.15683
   Johr RH, 2002, CLIN DERMATOL, V20, P240, DOI 10.1016/S0738-081X(02)00236-5
   KHAN MA, 2021, COMPUT ELECTR ENG, V90, DOI DOI 10.1016/J.COMPELECENG.2020.106956
   Khan MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050811
   Kingma D. P., 2014, arXiv
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Koohbanani NA, 2018, ARXIV PREPRINT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Macià F, 2013, J CLIN EPIDEMIOL, V66, P928, DOI 10.1016/j.jclinepi.2012.12.018
   Mahbod A, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105475
   Massone C, 2005, CURR OPIN ONCOL, V17, P147, DOI 10.1097/01.cco.0000152627.36243.26
   Matthews NH, 2017, CUTANEOUS MELANOMA: ETIOLOGY AND THERAPY, P3, DOI 10.15586/codon.cutaneousmelanoma.2017.ch1
   Mohan SV, 2014, CURR DERMATOL REP, V3, P40, DOI 10.1007/s13671-014-0069-y
   More J, 2020, INT RES J ENG TECHNO, P7644
   Nayak S, 2022, ADV MATER PROCESS TE, V8, P2963, DOI 10.1080/2374068X.2021.1945293
   Polat K., 2020, J. Artif. Intell. Syst., V2, P80, DOI [10.33969/AIS.2020.21006, DOI 10.33969/AIS.2020.21006]
   Salian Abhishek C., 2020, 2020 3rd International Conference on Communication System, Computing and IT Applications (CSCITA). Proceedings, P168, DOI 10.1109/CSCITA47329.2020.9137810
   Seeley R.R., 2008, Anatomy physiology, V8th, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Stern RS, 2010, ARCH DERMATOL, V146, P279, DOI 10.1001/archdermatol.2010.4
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   World Health Organization, CANC PREV
   Zafar K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061601
NR 45
TC 10
Z9 10
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37379
EP 37401
DI 10.1007/s11042-021-11628-y
EA JUL 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000823376700018
DA 2024-07-18
ER

PT J
AU Chen, ST
   Shao, DW
   Zhang, LC
   Zhang, C
AF Chen, Suting
   Shao, Dongwei
   Zhang, Liangchen
   Zhang, Chuang
TI Learning depth-aware features for indoor scene understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic features; Depth features; Feature fusion; Indoor scene
   understanding; Geometric information; Depth-aware features
ID SEMANTIC SEGMENTATION
AB Many methods have shown that jointly learning RGB image features and 3D information from RGB-D domain is favorable to the indoor scene semantic segmentation task. However, most of these methods need precise depth map as the input and this seriously limits the application of this task. This paper is based on a convolutional neural network framework which jointly learns semantic and the depth features to eliminate such strong constraint. Additionally, the proposed model effectively combines learned depth features, multi-scale contextual information with the semantic features to generate more representative features. Experimental results show that only taken an RGB image as the input, the proposed model can simultaneously obtain higher accuracy than state-of- the-art approaches on NYU-Dv2 and SUN RGBD datasets.
C1 [Chen, Suting; Shao, Dongwei; Zhang, Liangchen] Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Peoples R China.
   [Chen, Suting; Zhang, Chuang] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Chen, ST (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Peoples R China.; Chen, ST (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
EM sutingchen@nuist.edu.cn
FU National Natural Science Foundation of China [61906097]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61906097). The authors would like to thank all reviewers and
   editors for their constructive comments for this study.
CR Alonso I, 2019, IEEE COMPUT SOC CONF, P1624, DOI 10.1109/CVPRW.2019.00205
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LZ, 2021, IEEE T IMAGE PROCESS, V30, P2313, DOI 10.1109/TIP.2021.3049332
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Chowdhary C.L., 2019, RECENT PAT COMPUT SC, V12, P18, DOI [10.2174/2213275911666180821092033, DOI 10.2174/2213275911666180821092033]
   Chowdhary CL, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN NETWORKS AND COMPUTER COMMUNICATIONS (ETNCC), P162, DOI 10.1109/ETNCC.2015.7184827
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Di, 2019, IEEE T PATTERN ANAL, V12, P264
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gu Z, 2021, IEEE T SYST MAN CY-S, V51, P6197, DOI 10.1109/TSMC.2019.2960115
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Kendall Alex, 2017, ADV NEURAL INFORM PR, V30, DOI DOI 10.5555/3295222.3295309
   Kingma DP, 2015, ADV NEUR IN, V28
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li S. Z., 2009, Markov random field modeling in image analysis
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Sun L, 2020, IEEE ROBOT AUTOM LET, V5, P5558, DOI 10.1109/LRA.2020.3007457
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9
   Xiang KT, 2021, OPT EXPRESS, V29, P4802, DOI 10.1364/OE.416130
   Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33
   Xiong ZT, 2020, PROC CVPR IEEE, P3991, DOI 10.1109/CVPR42600.2020.00405
   Yu F., 2015, ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou H, 2021, COMPUTER VISIONACCV
NR 51
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42573
EP 42590
DI 10.1007/s11042-021-11453-3
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700007
DA 2024-07-18
ER

PT J
AU Gilanie, G
   Bajwa, UI
   Waraich, MM
   Anwar, MW
   Ullah, H
AF Gilanie, Ghulam
   Bajwa, Usama Ijaz
   Waraich, Mustansar Mahmood
   Anwar, Muhammad Waqas
   Ullah, Hafeez
TI An automated and risk free WHO grading of glioma from MRI images using
   CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WHO-Grading; Glioma grading (low; high); CNN for glioma grading
ID CLASSIFICATION; DIAGNOSIS; TEXTURE; BIOPSY; TUMORS
AB Glioma is among aggressive and common brain tumors, with a low survival rate, in its highest grade. Invasive methods, i.e., biopsy and spinal tap are clinically used to determine the grades of glioma. Depending upon the findings of these methods, treatment is planned to improve the life expectancy of the controls. Magnetic resonance imaging (MRI), the most widely used medical imaging modality to diagnose a brain tumor, is producing a huge volume of MRI data. A reliable, automatic, and noninvasive method of glioma grading are always required as an alternative to these invasive methods. In this research, a model has been proposed using Convolutional Neural Networks to classify low and high-grade glioma. A locally organized dataset, developed in the Department of Radiology (Diagnostics), Bahawal Victoria Hospital, Bahawalpur, Pakistan has been used for research and experiments. Additionally, results have also been validated on a publicly available benchmarked dataset, i.e., BraTS-2017. The proposed method demonstrated significant achievement in terms of classification rates, i.e., the accuracy of 98.93% (for low-grade glioma) and 98.12% (for high-grade glioma). Experimental results proved that the proposed model is accurate (98.52%) and is efficient in glioma grade identification.
C1 [Gilanie, Ghulam] Islamia Univ Bahawalpur, Fac Comp, Dept Artificial Intelligence, Bahawalpur, Pakistan.
   [Bajwa, Usama Ijaz; Anwar, Muhammad Waqas] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
   [Waraich, Mustansar Mahmood] Bahawal Victoria Hosp, Dept Radiol & Diagnost Images, Bahawalpur, Pakistan.
   [Ullah, Hafeez] Islamia Univ Bahawalpur, Inst Phys, Biophoton Imaging Tech Lab, Bahawalpur, Pakistan.
C3 Islamia University of Bahawalpur; COMSATS University Islamabad (CUI);
   Islamia University of Bahawalpur
RP Bajwa, UI (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
EM ghulam.gilanie@iub.edu.pk; usamabajwa@cuilahore.edu.pk;
   mustansarwaraich@gmail.com; waqasanwar@cuilahore.edu.pk;
   hafeezullah@iub.edu.pk
RI Anwar, Muhammad Naseem/IAM-7949-2023; Gilanie, Ghulam/HDN-2595-2022
OI Anwar, Muhammad Naseem/0000-0002-4759-0656; Gilanie,
   Ghulam/0000-0001-6880-8506; Bajwa, Usama/0000-0001-5755-1194
CR Attique M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033616
   Chen QJ, 2020, IEEE ACCESS, V8, P106564, DOI 10.1109/ACCESS.2020.3000895
   Chen QW, 2019, 1ST INTERNATIONAL WORKSHOP ON DEEP LEARNING PRACTICE FOR HIGH-DIMENSIONAL SPARSE DATA WITH KDD (DLP-KDD 2019), DOI 10.1145/3326937.3341261
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   Gilanie G, 2021, MULTIMED TOOLS APPL, V80, P4295, DOI 10.1007/s11042-020-09970-8
   Gilanie G, 2019, INT J IMAG SYST TECH, V29, P260, DOI 10.1002/ima.22312
   Gilanie G, 2018, SIGNAL IMAGE VIDEO P, V12, P479, DOI 10.1007/s11760-017-1182-8
   Gilanie G, 2013, PATTERN RECOGN LETT, V34, P1356, DOI 10.1016/j.patrec.2013.04.010
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Lian ZC, 2015, INT CONF COMPUT ADV
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Majno G., 2004, Cells, tissues, and disease: principles of general pathology
   MANKIN HJ, 1982, J BONE JOINT SURG AM, V64, P1121, DOI 10.2106/00004623-198264080-00002
   Muneer KVA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1228-2
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Priya KM, 2016, INTELLIGENT SYSTEMS
   Reza SMS, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.024501
   Rizwan M, 2022, IEEE ACCESS, V10, P29731, DOI 10.1109/ACCESS.2022.3153108
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Subashini MM, 2016, EXPERT SYST APPL, V43, P186, DOI 10.1016/j.eswa.2015.08.036
   Tearney GJ, 1997, SCIENCE, V276, P2037, DOI 10.1126/science.276.5321.2037
   Tripathi PC, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106597
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Vamvakas A, 2019, PHYS MEDICA, V60, P188, DOI 10.1016/j.ejmp.2019.03.014
   von Bartheld CS, 2016, J COMP NEUROL, V524, P3865, DOI 10.1002/cne.24040
   Wang XY, 2019, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.01046
   WEISS SW, 1983, LAB INVEST, V49, P299
NR 27
TC 3
Z9 3
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2857
EP 2869
DI 10.1007/s11042-022-13415-9
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000823376700026
DA 2024-07-18
ER

PT J
AU Veluchamy, M
   Subramani, B
AF Veluchamy, Magudeeswaran
   Subramani, Bharath
TI Artificial bee Colony optimized image enhancement framework for
   invisible images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Invisible images; Gamma function; Weighted CDF; Contrast change; Image
   enhancement
ID BI-HISTOGRAM EQUALIZATION; ADAPTIVE GAMMA CORRECTION; CONTRAST
   ENHANCEMENT; BRIGHTNESS; ALGORITHM
AB Image enhancement plays an important role in image processing to obtain an image with more perceptual details. In this paper, an artificial bee colony optimization based weighted gamma correction method is proposed to improve the visual quality of the contrast distorted images. The proposed method improves the perceived contrast by expanding and compressing the pixel values. First, Image Expansion and Compression are employed to expose and confine the intensity level present in the image, respectively. Then, an optimally weighted sum approach is used to increase the essential details in the dark regions. Finally, an artificial bee colony optimization algorithm is employed to compute the optimal weighting parameter for brightness preservation. Experimental results demonstrate that the proposed method yields better visual quality images and highlights fine details by enhancing contrast and brightness. The proposed method's quantitative results are competitive compared to the other well-known methods.
C1 [Veluchamy, Magudeeswaran; Subramani, Bharath] PSNA Coll Engn & Technol, Dept Elect & Commun Engn, Dindigul 624622, Tamil Nadu, India.
C3 PSNA College of Engineering & Technology
RP Subramani, B (corresponding author), PSNA Coll Engn & Technol, Dept Elect & Commun Engn, Dindigul 624622, Tamil Nadu, India.
EM magudeeswaran@psnacet.edu.in; bharath.psna@psnacet.edu.in
RI Veluchamy, Magudeeswaran/O-6428-2016; Veluchamy,
   Magudeeswaran/AAS-1568-2020
OI Veluchamy, Magudeeswaran/0000-0001-6427-1094; Veluchamy,
   Magudeeswaran/0000-0002-7260-7608; Subramani,
   Bharath/0000-0001-8989-9320
CR Al-Ameen Z, 2019, IET IMAGE PROCESS, V13, P1314, DOI 10.1049/iet-ipr.2018.6585
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Banharnsakun A, 2019, EVOL SYST-GER, V10, P679, DOI 10.1007/s12530-018-9255-7
   Bhandari AK, 2020, SOFT COMPUT, V24, P1619, DOI 10.1007/s00500-019-03992-7
   Caliskan A, 2020, IEEE T FUZZY SYST, V28, P1084, DOI 10.1109/TFUZZ.2020.2973123
   Cao G, 2018, COMPUT ELECTR ENG, V66, P569, DOI 10.1016/j.compeleceng.2017.09.012
   Chen BH, 2019, IEEE T CIRC SYST VID, V29, P38, DOI 10.1109/TCSVT.2017.2773461
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Draa A, 2014, SWARM EVOL COMPUT, V16, P69, DOI 10.1016/j.swevo.2014.01.003
   Gupta B, 2016, OPTIK, V127, P1671, DOI 10.1016/j.ijleo.2015.10.068
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jeong I, 2021, MULTIMED TOOLS APPL, V80, P18027, DOI 10.1007/s11042-021-10614-8
   Kamoona AM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105749
   Kansal S, 2020, IET IMAGE PROCESS, V14, P1110, DOI 10.1049/iet-ipr.2019.0106
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kumar M, 2020, IEEE T IMAGE PROCESS, V29, P7525, DOI 10.1109/TIP.2020.3004036
   Kumar S, 2018, INT J SYST ASSUR ENG, V9, P577, DOI 10.1007/s13198-014-0278-6
   Li CL, 2021, APPL INTELL, V51, P202, DOI 10.1007/s10489-020-01792-3
   Luque-Chang A, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106607
   Meena, 2018, IEEE J-STARS, DOI [10.1109/JSTARS.2018.2870157, DOI 10.1109/JSTARS.2018.2870157]
   Niu Y, 2014, IEEE IMAGE PROC, P4047, DOI 10.1109/ICIP.2014.7025822
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Öztürk S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106799
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Shanmugavadivu P, 2014, VISUAL COMPUT, V30, P387, DOI 10.1007/s00371-013-0863-8
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Shokrollahi A, 2017, AEU-INT J ELECTRON C, V77, P61, DOI 10.1016/j.aeue.2017.04.026
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Tan SF, 2019, IEEE ACCESS, V7, P70842, DOI 10.1109/ACCESS.2019.2918557
   Veluchamy Magudeeswaran, 2022, IEEE Transactions on Emerging Topics in Computational Intelligence, V6, P602, DOI 10.1109/TETCI.2021.3053253
   Veluchamy M, 2020, MULTIMED TOOLS APPL, V79, P19945, DOI 10.1007/s11042-020-08870-1
   Veluchamy M, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106077
   Wong CY, 2016, J VIS COMMUN IMAGE R, V38, P802, DOI 10.1016/j.jvcir.2016.04.019
   Xiao B, 2018, NEUROCOMPUTING, V275, P2798, DOI 10.1016/j.neucom.2017.11.057
   Yang KF, 2020, IEEE T IMAGE PROCESS, V29, P1493, DOI 10.1109/TIP.2019.2938310
NR 36
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3627
EP 3646
DI 10.1007/s11042-022-13409-7
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000823376700015
DA 2024-07-18
ER

PT J
AU Wang, JW
   Zeng, KH
   Ma, B
   Luo, XY
   Yin, QL
   Liu, GJ
   Jha, SK
AF Wang, Jinwei
   Zeng, Kehui
   Ma, Bin
   Luo, Xiangyang
   Yin, Qilin
   Liu, Guangjie
   Jha, Sunil Kr.
TI GAN-generated fake face detection via two-stream CNN with PRNU in the
   wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial forgery detection; GAN; PRNU; Two-stream CNN
ID NETWORKS
AB The rapid development of the generative adversarial networks (GANs) has made it an unprecedented success in image generation. The emergence of BigGAN, StyleGAN, and other advanced GAN makes the generated images more real and deceptive, which poses potential threats to national security, social stability, and personal privacy. In this paper, we proposed a new framework-two-stream CNN to detect GAN generated fake images, which contains RGB stream and Photo Response Non-Uniformity (PRNU) stream, respectively. In the preprocessing stage of the RGB stream, the use of random erasing enhances the diversity of samples and assists the network to pay more attention to the difference in GAN fingerprints in the image content. The PRNU stream's construction is based on the uniqueness of PRNU features in real images and the robustness of the features to image transformation. The existence of PRNU guides the network to focus on the changes in the image pixel value itself and enhances the generalization performance of the network. Experimental results on multiple datasets show that the proposed method has apparent advantages in accuracy and generalization and is more robust to various image transformations, such as downsampling, JPEG compression, Gaussian noise, and Gaussian blur.
C1 [Wang, Jinwei; Zeng, Kehui; Yin, Qilin; Liu, Guangjie; Jha, Sunil Kr.] Nanjing Univ Informat Sci & Technol, Dept Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Wang, Jinwei; Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.
   [Wang, Jinwei] Minist Educ, Engn Res Ctr Digital Forens, Nanjing 210044, Peoples R China.
   [Wang, Jinwei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Ma, Bin] Qilu Univ Technol, Shandong Prov Key Lab Comp Networks, Jinan 250353, Shandong, Peoples R China.
   [Jha, Sunil Kr.] Univ Informat Technol & Management, Fac Informat Technol, PL-35225 Rzeszow, Poland.
C3 Nanjing University of Information Science & Technology; PLA Information
   Engineering University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Qilu University of Technology; University
   of Information Technology & Management Rzeszow
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.
EM xiangyangluo@126.com
RI Bueno, Regis Cortez/AAG-3852-2020; jinwei, wang/AAG-5700-2019
OI Bueno, Regis Cortez/0000-0002-2923-4930; 
FU National Natural Science Foundation of China [62072250, 61772281,
   61702235, U1636117, U1804263, 62172435, 61872203, 61802212]; Zhongyuan
   Science and Technology Innovation Leading Talent Project of China
   [214200510019]; Plan for Scientific Talent of Henan Province
   [2018JR0018]; Opening Project of Guangdong Provincial Key Laboratory of
   Information Security Technology [2020B1212060078]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD) fund
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.62072250, 61772281, 61702235, U1636117, U1804263,
   62172435, 61872203 and 61802212), the Zhongyuan Science and Technology
   Innovation Leading Talent Project of China (Grant No.214200510019), the
   Plan for Scientific Talent of Henan Province (Grant No.2018JR0018), the
   Opening Project of Guangdong Provincial Key Laboratory of Information
   Security Technology (Grant No.2020B1212060078), and the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD) fund.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Albright M, 2019, CVPR WORKSH, P96
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bai S, 2017, EXPERT SYST APPL, V71, P279, DOI 10.1016/j.eswa.2016.10.038
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berthelot David, 2017, CoRR
   Chen M, 2007, PROC SPIE, V6505, DOI 10.1117/12.703370
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Khan RA, 2019, FRONT COMPUT SCI-CHI, V13, P183, DOI 10.1007/s11704-017-6114-9
   Kingma D. P., 2014, arXiv
   Li C-L, 2016, ARXIV161103879
   Li H., 2018, ARXIV180807276
   Liu X., 2020, P IEEE CVF C COMP VI, P8057
   Lukás J, 2006, PROC SPIE, V6072, DOI 10.1117/12.640109
   Lukas J., 2005, P IEEE INT C IM PROC, V3, P65
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marra F, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P506, DOI 10.1109/MIPR.2019.00103
   McCloskey Scott, 2018, arXiv
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nataraj L, 2020, ARXIV190306836
   Sun Y, 2014, ADV NEUR IN, V27
   Tu K, 2015, FRONT COMPUT SCI-CHI, V9, P713, DOI 10.1007/s11704-015-4224-9
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Wang X, 2017, PATTERN RECOGN, V72, P59, DOI 10.1016/j.patcog.2017.07.001
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu Ning, 2018, ARXIV181108180
   Zhang X, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035107
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
   Zheng LL, 2016, MULTIMED TOOLS APPL, V75, P5055, DOI 10.1007/s11042-015-2847-3
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou ZH, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9182-1
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 3
Z9 3
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42527
EP 42545
DI 10.1007/s11042-021-11592-7
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700023
DA 2024-07-18
ER

PT J
AU Palle, RR
   Boda, R
AF Palle, Rajashekar Reddy
   Boda, Ravi
TI Automated image and video object detection based on hybrid
   heuristic-based U-net segmentation and faster region-convolutional
   neural network-enabled learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Deep learning; Convolutional neural network; Adaptive
   U-net segmentation; Sun flower-deer hunting optimization algorithm;
   Modified faster region-convolutional neural network
ID ALGORITHM; DATASET
AB Object detection is one of the major areas of computer vision, which adopts machine learning approaches in diverse contributions. Nowadays, the machine learning field has been directed through Deep Neural Networks (DNNs) that takes eminent features of progressions in data availability and computing power. In all the cases, the quality of images and videos are biased and noisy, and thus, the distributions of data are also considered as imbalanced and disturbed. Different techniques are developed for solving the abovementioned challenges, which are mostly considered based on deep learning and computer vision. Though, traditional algorithms constantly offer poor detection for dense and small objects and yet fail the detection of objects through random geometric transformations. One of the categories of deep learning called Convolutional Neural Network (CNN) is famous and well-matched method for image-related tasks, in which the network is trained for discovering the numerous features like colour differences, corners, and edges in the images and videos that are combined into more complex shapes. This proposal intends to develop improved object detection in images and videos with the advancements of deep learning models. The three main phases of the proposed object detection model are (a) pre-processing, (b) segmentation, and (c) detection. Once the pre-processing of the image is performed by median filtering approach, the adaptive U-Net segmentation is performed for the object segmentation using the newly proposed Sun Flower-Deer Hunting Optimization Algorithm (SF-DHOA). The maximization of segmentation accuracy and dice coefficient is considered as the main objective of the proposed segmentation. The hybrid meta-heuristic algorithm termed SF-DHOA is proposed with Sun Flower Optimization (SFO) and Deer Hunting Optimization Algorithm (DHOA), which is used for optimally tuning the U-Net by optimizing the encoder depth and the number of epoch. Further, the detection is performed by the modified Faster Region-Convolutional Neural Network (Faster-RCNN), in which the optimization of number of epoch is performed by hybrid SF-DHOA algorithm with the intention of minimizing the error and training loss function. The performance of the proposed algorithm is evaluated, and the proposed algorithm shows high improvement when compared to existing deep learning-based algorithms.
C1 [Palle, Rajashekar Reddy; Boda, Ravi] Koneru Lakshmaiah Educ Fdn KLEF, Dept ECE, Hyderabad, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Palle, RR (corresponding author), Koneru Lakshmaiah Educ Fdn KLEF, Dept ECE, Hyderabad, Telangana, India.
EM raju.sheker@gmail.com; raviou2015@klh.edu.in
RI Boda, Ravi/IWD-5725-2023
CR Azzam R, 2016, J VIS COMMUN IMAGE R, V36, P90, DOI 10.1016/j.jvcir.2015.11.009
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Bonyadi MR, 2016, IEEE T EVOLUT COMPUT, V20, P370, DOI 10.1109/TEVC.2015.2460753
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Brammya G., 2019, Comput J, DOI [10.1093/comjnl/bxy133, DOI 10.1093/COMJNL/BXY133]
   Cao WM, 2018, IEEE ACCESS, V6, P8990, DOI 10.1109/ACCESS.2018.2795798
   Cuevas C, 2016, COMPUT VIS IMAGE UND, V152, P103, DOI 10.1016/j.cviu.2016.08.005
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan M, 2019, METHODS, V166, P103, DOI 10.1016/j.ymeth.2019.02.010
   Gomes GF, 2019, ENG COMPUT-GERMANY, V35, P619, DOI 10.1007/s00366-018-0620-8
   Goyette N, 2014, IEEE T IMAGE PROCESS, V23, P4663, DOI 10.1109/TIP.2014.2346013
   Hambarde P, 2020, BIOCYBERN BIOMED ENG, V40, P1421, DOI 10.1016/j.bbe.2020.07.011
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hu QC, 2016, IEEE T INTELL TRANSP, V17, P1002, DOI 10.1109/TITS.2015.2496795
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Hu ZP, 2020, IEEE J-STARS, V13, P783, DOI 10.1109/JSTARS.2020.2971657
   Huang LL, 2019, IEEE ACCESS, V7, P166203, DOI 10.1109/ACCESS.2019.2953046
   Kim JY, 2020, IEEE ACCESS, V8, P159864, DOI 10.1109/ACCESS.2020.3020818
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Manne R., 2020, Int J Modern Trends Sci Technol, P2455, DOI [10.46501/IJMTST061118, DOI 10.46501/IJMTST061118]
   Murthy MYB, 2022, BIOMED ENG LETT, V12, P37, DOI 10.1007/s13534-021-00209-5
   Patil PW, 2019, IEEE T INTELL TRANSP, V20, P4066, DOI 10.1109/TITS.2018.2880096
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Rhee PK, 2017, COGN SYST RES, V45, P109, DOI 10.1016/j.cogsys.2017.05.006
   Rodriguez-Ramos A, 2020, IEEE ACCESS, V8, P124451, DOI 10.1109/ACCESS.2020.3006191
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Tsang S, 2011, IEEE T KNOWL DATA EN, V23, P64, DOI 10.1109/TKDE.2009.175
   Uçar A, 2017, SIMUL-T SOC MOD SIM, V93, P759, DOI 10.1177/0037549717709932
   Unnisa N, 2022, WIRELESS PERS COMMUN, V122, P3019, DOI 10.1007/s11277-021-09039-1
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Wang KZ, 2019, IEEE T NEUR NET LEAR, V30, P834, DOI 10.1109/TNNLS.2018.2852783
   Wang SH, 2014, J VIS COMMUN IMAGE R, V25, P263, DOI 10.1016/j.jvcir.2013.11.005
   Wu JX, 2015, IEEE T NEUR NET LEAR, V26, P2357, DOI 10.1109/TNNLS.2014.2382123
   Yousif H, 2018, J VIS COMMUN IMAGE R, V55, P802, DOI 10.1016/j.jvcir.2018.08.013
   Yu HK, 2020, NEUROCOMPUTING, V398, P71, DOI 10.1016/j.neucom.2020.02.075
   Zhang C, 2020, IEEE ACCESS, V8, P151681, DOI 10.1109/ACCESS.2020.3017411
   Zhang Z, 2016, IEEE T MULTIMEDIA, V18, P2079, DOI 10.1109/TMM.2016.2594138
   Zhao W, 2019, IEEE ACCESS, V7, P43607, DOI 10.1109/ACCESS.2019.2908016
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 41
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3459
EP 3484
DI 10.1007/s11042-022-13216-0
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000824937500002
DA 2024-07-18
ER

PT J
AU Aranha, RV
   Chaim, ML
   Monteiro, CBM
   Silva, TD
   Guerreiro, FAAC
   Silva, WS
   Nunes, FLS
AF Aranha, Renan V.
   Chaim, Marcos L.
   Monteiro, Carlos B. M.
   Silva, Talita D.
   Guerreiro, Francisca A. A. C.
   Silva, Willian S.
   Nunes, Fatima L. S.
TI EasyAffecta: A framework to develop serious games for virtual
   rehabilitation with affective adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Framework; Serious games; Affective computing; Software adaptation
ID REALITY
AB Serious games have been applied in many contexts, aiming to turn learning and training activities more attractive for users. The motor rehabilitation process is a scenario in which serious games present benefits such as keeping the user's motivation. Nevertheless, the development of these games is a complex task, especially when user's motivation is a key goal. Some strategies have been investigated to automatically adapt these games to keep one's engagement. However, fast implementation with little effort is an open issue. To support a game with automatic adaptation considering the emotional state of the user, we propose an Affective Computing framework, called EasyAffecta. EasyAffecta provides benefits for physiotherapists, developers, and patients alike. The impact of our proposal was analyzed by conducting two experimental evaluations involving different actors. The first one was carried with patients of motor rehabilitation process. Additionally, we conducted an experimental evaluation with developers. The results showed that EasyAffecta was considered useful by developers and efficient to maintain the patient's engagement.
C1 [Aranha, Renan V.] Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
   [Chaim, Marcos L.; Monteiro, Carlos B. M.; Silva, Talita D.; Guerreiro, Francisca A. A. C.; Silva, Willian S.; Nunes, Fatima L. S.] Univ Sao Paulo, Escola Artes Ciencias & Humanidades, Sao Paulo, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo
RP Aranha, RV (corresponding author), Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
EM renan.vinicius@usp.br; chaim@usp.br; carlosmonteiro@usp.br;
   ft.talitadias@gmail.com; francisca.si.guerreiro@gmail.com;
   willian.severino.silva@gmail.com; fatima.nunes@usp.br
RI Chaim, Marcos L/K-4711-2016; de Mello Monteiro, Carlos
   Bandeira/P-2474-2016; da Silva, Talita Dias/F-6519-2012; Nunes, Fatima L
   S/C-4126-2012
OI de Mello Monteiro, Carlos Bandeira/0000-0002-2661-775X; da Silva, Talita
   Dias/0000-0002-4683-4671; 
FU Brazilian National Council of Scientific and Technological Development
   (CNPq) [800585/2016-0]; National Institute of Science and Technology
   Medicine Assisted by Scientific Computing (INCT-MACC); Brazilian Federal
   Agency for Support and Evaluation of Graduate Education (CAPES)
FX Authors thank the Brazilian National Council of Scientific and
   Technological Development (CNPq, Process 800585/2016-0), the National
   Institute of Science and Technology Medicine Assisted by Scientific
   Computing (INCT-MACC), and Brazilian Federal Agency for Support and
   Evaluation of Graduate Education (CAPES) by the financial support.
   Authors are also grateful for Freepik and Flaticon by the images used in
   this article.
CR Affectiva, 2017, AFF DEV PORT
   Affectiva, 2017, EMOTION RECOGNITION
   Affectiva, 2017, DO WE MAP FAC EXPR E
   Affectiva, 2017, ACC
   [Anonymous], 2019, UNAIDS DAT 2019
   [Anonymous], 2016, UN MAN SCRIPT
   Aranha RV, 2021, IEEE T AFFECT COMPUT, V12, P883, DOI 10.1109/TAFFC.2019.2902379
   Aranha RV, 2017, COMP MED SY, P55, DOI 10.1109/CBMS.2017.89
   Bandura A., 2006, Self-Efficacy Beliefs of Adolescents, P307, DOI DOI 10.1017/CBO9781107415324.004
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Dorner R., 2016, SERIOUS GAMES FDN CO, P1, DOI [https://doi.org/10.1007/978-3-319-40612-1_1, DOI 10.1007/978-3-319-40612-1_1]
   El Hussein M, 2014, QUAL REP, V19
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gebara CM, 2016, REV BRAS PSIQUIATR, V38, P24, DOI 10.1590/1516-4446-2014-1560
   Group TP, 2019, PHP HYP PROC
   Hendrix M, 2019, IEEE T GAMES, V11, P320, DOI 10.1109/TG.2018.2791019
   Henrik S-F, 2011, DIGRA P 2011 DIGRA I
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Legris P, 2003, INFORM MANAGE-AMSTER, V40, P191, DOI 10.1016/S0378-7206(01)00143-4
   Levin MF, 2015, PHYS THER, V95, P415, DOI 10.2522/ptj.20130579
   Michael D.R., 2005, Serious games: Games that educate, train, and inform
   Microsoft, 2019, MICROSOFT KINECT
   Mostefai B, 2019, COGN SYST RES, V56, P82, DOI 10.1016/j.cogsys.2019.03.006
   Novak D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-64
   ORACLE, 2019, MYSQL
   Papadimitriou S, 2019, MULTIMED TOOLS APPL, V78, P32023, DOI 10.1007/s11042-019-07955-w
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Pinto JF, 2018, IEEE INT CONF SERIOU
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Robinson R, 2020, P ANN S COMP HUM INT
   Sekhavat YA, 2021, MULTIMED TOOLS APPL, V80, P5225, DOI 10.1007/s11042-020-10006-4
   Strauss A., 1990, BASICS QUALITATIVE R
   Tadayon R, 2018, IEEE INT CONF SERIOU
   Tarozzi M., 2008, Che cos'e la grounded theory
   Unity-3D, 2017, GET UN
NR 35
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2303
EP 2328
DI 10.1007/s11042-022-12600-0
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814451100003
DA 2024-07-18
ER

PT J
AU Misgar, MM
   Mushtaq, F
   Khurana, SS
   Kumar, M
AF Misgar, Muzafar Mehraj
   Mushtaq, Faisel
   Khurana, Surinder Singh
   Kumar, Munish
TI Recognition of offline handwritten Urdu characters using RNN and LSTM
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical character recognition (OCR); Deep learning (DL); Recurrent
   neural network (RNN); Long short term memory (LSTM)
AB Optical Character Recognition (OCR), helps to convert different types of scanned documents, such as images into searchable and editable content. OCR is language dependant and very limited research has been carried out in this field for Urdu and Urdu like scriptures (E.g. Farsi, Arabic, and Urdu) unlike other languages like English, Hindi, etc. The lack of research work is attributed to a lack of publically available benchmark databases and inherent complexities involved in these languages like cursive nature and change in the shape of a character depending upon its position in a ligature. Each character has 2-4 different shapes depending upon its position in the word; initial, medial, or final. In this article, the we have proposed a methodology to automate the data collection process and collected a large handwritten dataset of 110,785 Urdu characters and laid out the comaparative analysis of two deep learning models SimpleRNN and LSTM to showcase the potential of RNN models for chararacter recognition. Data was collected from 250 authors on the A4 size sheet. Each sheet contains 132 shapes for Urdu characters and 10 numerals. As far as the authors know, this is the first time that such a large dataset has been proposed which contains all the possible shapes of Urdu character numerals as well. Experimentation has been done for the numeral, full characters, and for whole data set separately to lay a comparative analysis of classification capabilities of RNN and LSTM models. Despite of such inherit complexities in Urdu script, the RNN and LSTM models proved to be more effective in achieving a high accuracy rates. Respective accuracy for RNN achieved for each category are: 96.96% for numerals, 85.22% for full characters and 73.62% for whole data and LSTM outperforms the prior one with max accuracy for each category of data as 97.80% for numerals, 97.43% for full characters and 91.30% for whole data. Besides, the proposed dataset opens a new window for future research, showcasing the huge potential of this dataset for data analysis not only for Urdu language but for other languages like Arabic, Persian,etc. which uses similar kind of character sets.
C1 [Misgar, Muzafar Mehraj; Mushtaq, Faisel; Khurana, Surinder Singh] Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
C3 Central University of Punjab
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
EM skrzeal@gmail.com; faisel@email.com; surinder.seeker@gmail.com;
   munishcse@gmail.com
RI Mushtaq, Faisel/GLS-2838-2022; Kumar, Munish/P-7756-2018
OI Mushtaq, Faisel/0000-0002-2554-654X; Kumar, Munish/0000-0003-0115-1620;
   Misgar, Muzafar Mehraj/0000-0002-1980-9278
CR Ahmad Z, 2007, PROC WRLD ACAD SCI E, V26, P249
   Ali J., 2014, NUCLEUS, V51, P361
   [Anonymous], 2009, URDU QAEDA RECOGNITI
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2013, SEGMENTATION BASED U
   Benediktsson JA, 2015, ARTECH HSE REMOTE SE, P1
   Bin Ahmed S, 2019, NEURAL COMPUT APPL, V31, P1143, DOI 10.1007/s00521-017-3146-x
   Dong SY, 2023, CURR PSYCHOL, V42, P16082, DOI 10.1007/s12144-020-01268-0
   Ebrahinpour R, 2011, INT J ELECT ENG INFO, V3
   Hafiz AM, 2016, J PATTERN RECOGNIT R, V11, P55, DOI 10.13176/11.711
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Javed N, 2017, CLASSIFICATION URDU
   Javed ST., 2010, JWAoS Engineering, V46, P456
   Khan K, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON HIGH-CAPACITY OPTICAL NETWORKS AND ENABLING/EMERGING TECHNOLOGIES (HONET), P56
   Kumar M, 2014, NATL ACAD SCI LETT, V37, P381, DOI 10.1007/s40009-014-0253-4
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Mushtaq F, 2021, NEURAL COMPUT APPL, V33, P15229, DOI 10.1007/s00521-021-06144-x
   Naz S, 2014, PATTERN RECOGN, V47, P1229, DOI 10.1016/j.patcog.2013.09.037
   Pal U, 2003, PROC INT CONF DOC, P1183
   Pradeep J., 2010, INT J COMPUTER APPL, V8, P10, DOI DOI 10.5120/1236-1693
   Rizvi SSR, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419530045
   Sagheer Malik Waqas, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1900, DOI 10.1109/ICPR.2010.468
   Sagheer MW, 2009, LECT NOTES COMPUT SC, V5716, P538, DOI 10.1007/978-3-642-04146-4_58
   Sattar SA, 2009, INT J COMPUT SCI NET, V9, P116
   Shamsher I., 2007, WORLD ACAD SCI ENG T, V1, P2987
   Ul-Hasan A, 2013, PROC INT CONF DOC, P1061, DOI 10.1109/ICDAR.2013.212
   Wahab A, 2010, J IND STUD RES COMPU, V8
   Zand M., 2008, INT J COMPUTER ELECT, V2, P312
NR 28
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2053
EP 2076
DI 10.1007/s11042-022-13320-1
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000812445100004
DA 2024-07-18
ER

PT J
AU Riad, R
   Ros, F
   Gourrame, K
   El Hajji, M
   Douzi, H
   Harba, R
AF Riad, Rabia
   Ros, Frederic
   Gourrame, Khadija
   El Hajji, Mohamed
   Douzi, Hassan
   Harba, Rachid
TI A preventive and curative watermarking scheme for an industrial solution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Fourier transform; Pre-processing; Counterattacks;
   Print-scan; ID-card
ID FOURIER IMAGE WATERMARKING; MODEL
AB Watermarking for identity images printed on a plastic card support is still challenging. In this application, the scheme must be robust against a combination of geometric and signal processing attacks related to the print/scan process. In addition, the scheme must deal with all the possible aggressions that a smart card can encounter during its lifetime. This paper investigates a robust watermarking solution in the Fourier domain in the continuity of our earlier developments reported in this field. It includes both preventive and curative stages that are complementary. The solution is preventive as only a small set of selected bits presenting a small variance are concerned the watermarking process. This property increases the chances of watermark detection rate while maintaining the same level of security. The curative part consists in pre-processing the watermarked image before the detection process. It comprises two specific and accurate counterattacks: the first one deals with blurring correction under a dedicated Wiener filter and the second one focuses on color corrections. The hybrid scheme is highly efficient and has a low computational cost. The new watermarking scheme clearly outperforms competitive approaches and is compatible with industrial constraints.
C1 [Riad, Rabia] Ibn Zohr Univ, FPO ERMAM, Ouarzazate, Morocco.
   [Ros, Frederic; Harba, Rachid] Univ Orleans, PRISME, Orleans, France.
   [Gourrame, Khadija; El Hajji, Mohamed; Douzi, Hassan] Ibn Zohr Univ, IRF SIC, Agadir, Morocco.
C3 Ibn Zohr University of Agadir; Universite de Orleans; Ibn Zohr
   University of Agadir
RP Riad, R (corresponding author), Ibn Zohr Univ, FPO ERMAM, Ouarzazate, Morocco.
EM r.riad@uiz.ac.ma
RI Riad, R./AAB-4051-2020; El HAJJI, Mohamed/AHE-4167-2022
OI Riad, R./0000-0001-8626-213X; El HAJJI, Mohamed/0000-0002-0327-8249
CR Amiri T, 2016, MULTIMED TOOLS APPL, V75, P8527, DOI 10.1007/s11042-015-2770-7
   [Anonymous], 2006, IEEE INT C IND TECHN, DOI DOI 10.1109/ICIT.2006.372635
   Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bas P, 2002, PATTERN RECOGN, V35, P545, DOI 10.1016/S0031-3203(01)00059-0
   Brauers J, 2010, PROC SPIE, V7537, DOI 10.1117/12.837591
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen ZG, 2018, IEEE T MULTIMEDIA, V20, P1973, DOI 10.1109/TMM.2018.2794985
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Cox IJ, 2004, EURASIP J APPL SIG P, V2004, P2081, DOI 10.1155/S1110865704403072
   Gourrame K, 2019, MULTIMED TOOLS APPL, V78, P2621, DOI 10.1007/s11042-018-6302-0
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Kang XB, 2020, SOFT COMPUT, V24, P10561, DOI 10.1007/s00500-019-04563-6
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu JH, 2018, CIRC SYST SIGNAL PR, V37, P1268, DOI 10.1007/s00034-017-0607-5
   Miller ML, 2000, LECT NOTES COMPUT SC, V1768, P146
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Pan W, 2018, COMPUT METH PROG BIO, V160, P119, DOI 10.1016/j.cmpb.2018.03.011
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Nguyen PB, 2013, SIGNAL PROCESS-IMAGE, V28, P1506, DOI 10.1016/j.image.2013.09.011
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Reed A, 2005, ICIP IEEE INT C IMAG, V1, pI957, DOI 10.1109/ICIP.2005.1529911
   Riad R, 2014, PROC IEEE INT SYMP, P1036, DOI 10.1109/ISIE.2014.6864755
   Riad R, 2017, CONTROL ENG APPL INF, V19, P25
   Riad R, 2016, ADV ELECTR COMPUT EN, V16, P23, DOI 10.4316/AECE.2016.04004
   Riad R, 2014, LECT NOTES COMPUT SC, V8509, P280, DOI 10.1007/978-3-319-07998-1_32
   Salimi L, 2020, MULTIMED TOOLS APPL, V79, P11357, DOI 10.1007/s11042-019-08455-7
   Sharif Zaiton, 2007, Student Conference on Research and Development - SCOReD 2007, P1
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang J, 2020, MULTIMED TOOLS APPL, V79, P24057, DOI 10.1007/s11042-020-09102-2
   Watson AB, 1997, J OPT SOC AM A, V14, P2379, DOI 10.1364/JOSAA.14.002379
   Wilcox M, 1999, MEASURE MTF OTHER PR, P404
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Yu LJ, 2005, IMAGE VISION COMPUT, V23, P807, DOI 10.1016/j.imavis.2005.05.014
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 41
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 651
EP 679
DI 10.1007/s11042-022-13268-2
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527600003
DA 2024-07-18
ER

PT J
AU Ouguissi, H
   Saadi, S
   Merrad, A
   Kious, M
AF Ouguissi, Hadda
   Saadi, Slami
   Merrad, Ahmed
   Kious, Mecheri
TI Hybrid scheme for safe speech transmission based on multiple chaotic
   maps, watermarking and Arnold scrambling algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech security; Hybrid; Chaotic; Watermarking; Arnold
ID ENCRYPTION
AB In this paper, we present a novel scheme for enhancing the security of speech information in communication systems. We build a hybridization of three approaches: Chaotic logistic and tent maps for generating an arbitrary vector by some primarily initiated values to be joined in the original speech signal, an integrated watermark image within the encrypted signal in order to verify, through decryption process, that the encrypted signal is authentic as well as does not suffer from eventual attacks, and the third approach is using an Arnold scrambling key (cat map) to spread signal samples by means of a secret key, then recuperate the original signal from samples which is not possible without this key. Obtained correlation value in the proposed scheme is closer to null which proves that original and encrypted signals are completely dissimilar. Moreover, we recovered the original speech without disturbing the quality. Numerical results of the Signal to Noise Ratio (SNR) and Correlation Coefficient (CC) reported below, and the comparison between the proposed approach to seven recently published works, also reported, reveal the superiority of the proposed scheme and validate our design to be considered amongst the best methods compared to other recently existing strong approaches.
C1 [Ouguissi, Hadda; Kious, Mecheri] Ammar Thelidji Univ Laghouat, Fac Technol Mat Energet Syst Renewable Energies &, Laghouat, Algeria.
   [Saadi, Slami; Merrad, Ahmed] Ziane Achour Univ Djelfa UZAD, Fac Exact Sci & Informat, Djelfa, Algeria.
RP Saadi, S (corresponding author), Ziane Achour Univ Djelfa UZAD, Fac Exact Sci & Informat, Djelfa, Algeria.
EM saadisdz@gmail.com
RI slami, saadi/O-2435-2016
OI slami, saadi/0000-0001-8091-5232
CR Abdelfatah RI, 2020, IEEE ACCESS, V8, P69894, DOI 10.1109/ACCESS.2020.2987197
   Al-Hooti M, 2019, INDONESIAN J ELECT E, P147, DOI [10.11591/ijeecs.v13.i1, DOI 10.11591/IJEECS.V13.I1]
   Dhar PK, 2015, SPRINGER 2015 BRIEFS, DOI [10.1007/978-3-319-14800-7, DOI 10.1007/978-3-319-14800-7]
   Elsafty AH, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153347
   Eyvazian M, 2008, INT J ADV MANUF TECH, V39, P261, DOI 10.1007/s00170-007-1213-7
   Fantacci R, 2009, SECUR COMMUN NETW, V2, P305, DOI 10.1002/sec.70
   Farsana FJ, 2023, APPL COMPUT INFORM, V19, P239, DOI 10.1016/j.aci.2019.10.001
   Farsana FJ, 2020, ADV MATH PHYS, V2020, DOI 10.1155/2020/8050934
   Farsana FJ, 2016, PROCEDIA COMPUT SCI, V93, P816, DOI 10.1016/j.procs.2016.07.302
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Jovic B, 2011, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-642-21849-1
   Kaur G, 2021, MULTIMED TOOLS APPL, V80, P10927, DOI 10.1007/s11042-020-10223-x
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Lalitha NV, 2013, 2013 IEEE ASIA PACIFIC CONFERENCE ON POSTGRADUATE RESEARCH IN MICROELECTRONICS & ELECTRONICS (PRIMEASIA), P196, DOI 10.1109/PrimeAsia.2013.6731204
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Lin W., 2015, AUDIO WATERMARK COMP, P15, DOI DOI 10.1007/978-3-319-07974-5
   Liu H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040343
   Merrad A, 2018, 2 INT C NATURAL LANG, DOI [10.1109/ICNLSP.2018.8374366, DOI 10.1109/ICNLSP.2018.8374366]
   Merrad A, 2018, MULTIMED TOOLS APPL, V77, P27589, DOI 10.1007/s11042-018-5939-z
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Nematollahi MA, 2013, INT J SPEECH TECHNOL, V16, P471, DOI 10.1007/s10772-013-9192-6
   Revathi A, 2018, INT J SPEECH TECHNOL, V21, P1021, DOI 10.1007/s10772-018-09563-9
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Shah D, 2021, MULTIMED TOOLS APPL, V80, P22251, DOI 10.1007/s11042-021-10697-3
   Sheu LJ, 2011, NONLINEAR DYNAM, V65, P103, DOI 10.1007/s11071-010-9877-1
   Subir, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P79, DOI 10.1109/SPIN.2016.7566666
   Wang B, 2016, COMMUN NONLINEAR SCI, V39, P108, DOI 10.1016/j.cnsns.2016.02.035
NR 29
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 327
EP 346
DI 10.1007/s11042-022-13301-4
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806683200003
DA 2024-07-18
ER

PT J
AU Kumar, A
   Chandra, M
AF Kumar, Arvind
   Chandra, Mahesh
TI Empirical mode decomposition based statistical features for
   discrimination of speech and low frequency music signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech; music discrimination; EMD; IMF; Statistical features; Fisher
   method; F-ratio
AB This work aims to investigate the significance of different Empirical Mode Decomposition (EMD) based statistical features for discrimination of speech and low frequency music signal (guitar signals) which mostly lie in the frequency range of 80-1200 Hz. Each of the speech/guitar audio samples is decomposed into 10 Intrinsic Function Mode (IMFs). These IMFs are further analyzed for discriminatory evidence using statistical features like Mean, Absolute Mean, Kurtosis, Variance and Skewness. These features are then fed to different classifiers and their performances were tabulated for varying tuning parameters of the classifiers. Initial experiments were conducted on isolated features to shortlist features with best discriminatory evidence. These shortlisted features were then used in different combinations and their performances were reported. An improvement of 19.13% is observed for hybrid features over isolated features. Speech samples were obtained from Scheirer and Slaney database and Guitar samples were generated from a continuous guitar monologue uploaded on YouTube. Feature selection technique using Fisher Method and F-ratio were also implemented and best feature vectors were reported for both the algorithm. Best overall accuracy of 82.16% is reported for Hybrid features with Radial Basis Function (RBF) kernel of SVM classifier when trained with top 38 feature vectors obtained using F-Ratio Method. Different experiments verified Absolute Mean and Variance as best performing features for our task.
C1 [Kumar, Arvind] Birla Inst Technol, Dept ECE, Ranchi, India.
   [Chandra, Mahesh] Reva Univ, Dept ECE, Bengaluru, India.
C3 Birla Institute of Technology Mesra; REVA University
RP Kumar, A (corresponding author), Birla Inst Technol, Dept ECE, Ranchi, India.
EM arvind9835@gmail.com; shrotriya69@rediffmail.com
RI Chandra, Mahesh/AAR-4679-2021
OI Chandra, Mahesh/0000-0001-9892-5527; KUMAR, ARVIND/0000-0003-3947-7757
CR Alexandre-Cortizo E, 2005, EUROCON 2005: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOL 1 AND 2 , PROCEEDINGS, P1666
   [Anonymous], 2005, Hilbert-Huang Transform and Its Applications [M], V20, P1, DOI [DOI 10.1142/9789812703347, 10.1142/S1363919616500432]
   [Anonymous], 1999, 6 EUR C SPEECH COMM
   Babiker A, 2019, MULTIMED TOOLS APPL, V78, P16261, DOI 10.1007/s11042-018-7016-z
   Birajdar GK, 2019, MULTIMED TOOLS APPL, V78, P15141, DOI 10.1007/s11042-018-6899-z
   Bouzid A, 2004, ISCCSP : 2004 FIRST INTERNATIONAL SYMPOSIUM ON CONTROL, COMMUNICATIONS AND SIGNAL PROCESSING, P603
   Bykhovsky D, 2010, 2010 IEEE 26 CONV EL
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   Gu Q., 2011, P 27 C UNC ART INT U, P266, DOI DOI 10.48550/ARXIV.1202.3725
   Huang H, 2006, SIGNAL PROCESS, V86, P792, DOI 10.1016/j.sigpro.2005.06.011
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Khonglah BK, 2016, DIGIT SIGNAL PROCESS, V48, P71, DOI 10.1016/j.dsp.2015.09.005
   Khonglah BK, 2015, 2015 21 NATL C COMMU, P16, DOI [10.1109/NCC.2015.7084865, DOI 10.1109/NCC.2015.7084865]
   Kim SK, 2009, IEICE T FUND ELECTR, VE92A, P630, DOI 10.1587/transfun.E92.A.630
   Lahmiri S, 2012, IEEE IND ELEC, P1585, DOI 10.1109/IECON.2012.6388532
   Lim C, 2015, MULTIMED TOOLS APPL, V74, P5375, DOI 10.1007/s11042-014-1859-8
   Moreno PJ, 2000, INT CONF ACOUST SPEE, P2417, DOI 10.1109/ICASSP.2000.859329
   Panagiotakis Costas, 2002, 2002 11 EUROPEAN SIG, P1
   Pantazis Y, 2011, IEEE T AUDIO SPEECH, V19, P290, DOI 10.1109/TASL.2010.2047682
   Papakostas M, 2018, EXPERT SYST APPL, V114, P334, DOI 10.1016/j.eswa.2018.05.016
   Roffo Giorgio, 2017, New Frontiers in Mining Complex Patterns. 5th International Workshop, NFMCP 2016, held in conjunction with ECML-PKDD 2016. Revised Selected Papers: LNAI 10312, P19, DOI 10.1007/978-3-319-61461-8_2
   Ruiz-Reyes N, 2009, MULTIMED TOOLS APPL, V41, P253, DOI 10.1007/s11042-008-0228-x
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Seck M, 1999, 6 EUR C SPEECH COMM
   Sharma R., 2015, Cognitive Computing and Information Processing (CCIP), 2015 International Conference on, P1
   Shirazi J, 2010, MULTIMED TOOLS APPL, V50, P415, DOI 10.1007/s11042-009-0416-3
   Tsipas N, 2017, MULTIMED TOOLS APPL, V76, P25603, DOI 10.1007/s11042-016-4315-0
   Wang G, 2010, ADV DATA SCI ADAPT, V2, P277, DOI 10.1142/S1793536910000549
   Wu ZH, 2004, P ROY SOC A-MATH PHY, V460, P1597, DOI 10.1098/rspa.2003.1221
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   YouTube, 2019, REL MUS SUNGH JUNG B
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
NR 34
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 33
EP 58
DI 10.1007/s11042-022-13267-3
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805749900002
DA 2024-07-18
ER

PT J
AU Cai, LQ
   Cao, SZ
   Yi, WY
   Li, H
AF Cai, Linqin
   Cao, Shizhou
   Yi, Wenyuan
   Li, Hao
TI Modeling and simulation of virtual learning environment for automatic
   control principle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual learning environment; Intelligent question-answering; Virtual
   agent; Inverted pendulum
AB To improve students' interest in learning, this paper proposes a Virtual Learning Environment (VLE) for the inverted pendulum control experiments in automatic control principle. The proposed VLE framework includes five levels: user interface, applications layer, models layer, platforms layer, and data layer, which facilitate the design, development, and implementation of the VLE system. And then, this paper constructs an intelligent Question-Answering (QA) model based on BERT, which can help the virtual tutor answer students' questions about the inverted pendulum control input by text or voice. Moreover, in order to improve the interaction and intelligence of the virtual environment, this paper builds a virtual agent model to simulate human behavior. Finally, the VLE system is designed and implemented. Students can learn automatic control principle through the inverted pendulum experiments in the VLE system. By setting the parameters of the typical control algorithm simulated by MATLAB and observing the control result in the virtual reality environment, students can understand the control principle more effectively. According to the primary evaluation experiments, the immersive virtual learning environment can help students enhance their learning enthusiasm.
C1 [Cai, Linqin; Cao, Shizhou; Yi, Wenyuan; Li, Hao] Chongqing Univ Posts & Telecommun, Sch Automat, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Cao, SZ (corresponding author), Chongqing Univ Posts & Telecommun, Sch Automat, Chongqing, Peoples R China.
EM S190301005@stu.cqupt.edu.cn
RI cai, linqin/AFQ-8642-2022
OI cai, linqin/0000-0002-5663-8113
CR Aithal SG, 2021, APPL INTELL, V51, P8484, DOI 10.1007/s10489-021-02348-9
   Quintana MGB, 2015, COMPUT HUM BEHAV, V51, P594, DOI 10.1016/j.chb.2015.03.016
   Cai LQ, 2020, IEEE ACCESS, V8, P32922, DOI 10.1109/ACCESS.2020.2973728
   Cai LQ, 2017, MULTIMED TOOLS APPL, V76, P5851, DOI 10.1007/s11042-015-2547-z
   Catelli R, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106649
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Cheng XY, 2018, J COMPUT INFORM SYST, V58, P39, DOI 10.1080/08874417.2016.1183465
   Dalgarno B, 2016, AUST J TEACH EDUC, V41, P126
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Elfizar, 2020, IOP Conference Series: Earth and Environmental Science, V519, DOI 10.1088/1755-1315/519/1/012019
   Hsi-Hung Peng, 2019, Innovative Technologies and Learning. Second International Conference, ICITL 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11937), P815, DOI 10.1007/978-3-030-35343-8_85
   Hui F, 2012, LNEE, V176, P375
   Lemercier S, 2016, CONTEXT AWARE HUMAN, P257, DOI [10.1007/978-3-319-19947-4_12, DOI 10.1007/978-3-319-19947-4_12]
   Li W, 2020, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.2004.10014, DOI 10.48550/ARXIV.2004.10014]
   Liu X., 2018, P 27 INT C COMP LING, P1952
   Meng YX, 2019, ADV NEUR IN, V32
   Merity Stephen, 2017, ICLR
   Mukhtar, 2020, J PHYS CONF SER, V1462, DOI 10.1088/1742-6596/1462/1/012006
   Nissim Y., 2017, International Education Studies, V10, P52, DOI [10.5539/ies.v10n8p52, DOI 10.5539/IES.V10N8P52, https://doi.org/10.5539/ies.v10n8p52]
   Noraset T, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102431
   Randhavane T, 2019, IEEE T VIS COMPUT GR, V25, P3135, DOI 10.1109/TVCG.2019.2932235
   Reader J., 2020, POSTDIGITAL SCI EDUC, V2, P289, DOI [10.1007/s42438-019-00095-2, DOI 10.1007/S42438-019-00095-2]
   Ruobing Xie, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P3, DOI 10.1007/978-3-030-60450-9_1
   Sait M., 2019, Procedia Computer Science, V163, P338, DOI [DOI 10.1016/J.PROCS.2019.12.116, 10.1016/j.procs.2019.12.116]
   Sasinka C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010003
   Shao XQ, 2020, IEEE ACCESS, V8, P54699, DOI 10.1109/ACCESS.2020.2981539
   Shin S, 2019, INFORM PROCESS MANAG, V56, P445, DOI 10.1016/j.ipm.2018.12.003
   Stocker C, 2010, LECT NOTES ARTIF INT, V6356, P15, DOI 10.1007/978-3-642-15892-6_2
   Theelen H, 2019, COMPUT EDUC, V129, P14, DOI 10.1016/j.compedu.2018.10.015
   Wang Ziheng, 2021, ARXIV PREPRINT ARXIV
   Zhao ZJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3637
NR 31
TC 1
Z9 1
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43679
EP 43699
DI 10.1007/s11042-022-13099-1
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800436600002
DA 2024-07-18
ER

PT J
AU Yousuf, MM
   Rashid, M
AF Yousuf, Mir Mohammad
   Rashid, Mamoon
TI Analysis of the change in bugginess and adaptiveness of python software
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptiveness; Bugs; Correlation; Patch Uplift; Prediction; Regression;
   Software maintenance; Source code analysis; Python software systems
AB The useful constructs in terms of dynamic features of programming languages bring the developers convenience and flexibility, but can also lead to the risks in the software maintenance. Evaluating whether the use of such features affects the maintenance can be significant for both practitioners as well as researchers, yet a very little amount of work has been done to investigate it in python software systems. Researchers believe that the occurrence of the bugs (pre-release or post-release) affects the maintenance activities. Thus, software maintenance is frequently a challenging and hectic process for both engineers as well as IT consultancy firms. There are few studies concerning the different aspects of the source code quality of python software systems such as comprehensiveness, bugginess, and adaptiveness. In this paper, the authors analyzed the python software systems to find the effect of the bugs on the overall project and correlate the effects with the maintenance cost. This study also analyzed the relation between coding practices using the coding standards of the programming language with that of the bugs. In order to provide more experimental evidence about the impact of the source code quality and bugginess on the software development and maintenance, the authors provided an experimental study on the 8 versions of Trac 0.12, 16 versions of Trac 1.0, 6 versions of Trac 1.1, and 3 versions of Trac 1.2. The results are more indicative of the bugs affecting the quality of the product and thus increasing the maintenance cost. Moreover, the results also show that with the uplifting of the software patch, the quality of the code is improved, thus reducing the maintenance cost.
C1 [Yousuf, Mir Mohammad] Univ Kashmir, Dept Comp Sci & Engn, North Campus, Delina, Jammu & Kashmir, India.
   [Rashid, Mamoon] Vishwakarma Univ, Fac Sci & Technol, Dept Comp Engn, Pune 411048, Maharashtra, India.
C3 University of Kashmir
RP Rashid, M (corresponding author), Vishwakarma Univ, Fac Sci & Technol, Dept Comp Engn, Pune 411048, Maharashtra, India.
EM mamoon873@gmail.com
RI Rashid, Mamoon/AAB-7135-2020
OI Rashid, Mamoon/0000-0002-8302-4571; Yousuf, Mir
   Mohammad/0009-0001-7453-3358
CR Alija N., 2017, International Journal of Advanced Research in Computer Science and Software Engineering, V7, P15, DOI [DOI 10.23956/IJARCSSE/V7I2/01207, 10.23956/ijarcsse/V7I2/01207]
   [Anonymous], 2018, UNDERSTAND
   Bauer V, 2013, EUR CON SFTWR MTNCE, P431, DOI 10.1109/CSMR.2013.65
   Bug Defect tracking ST, 2017, 15 BEST BUG TRACK SO
   Castelluccio M, 2017, PROC IEEE INT CONF S, P411, DOI 10.1109/ICSME.2017.82
   Chen ZF, 2016, 2016 INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, TESTING AND EVOLUTION (SATE 2016), P18, DOI 10.1109/SATE.2016.10
   Eyolfson J, 2014, EMPIR SOFTW ENG, V19, P1009, DOI 10.1007/s10664-013-9245-0
   Faouzi J, 2020, J MACH LEARN RES, V21
   Fleming I, 2016, SOFTWARE QUALITY ASSURANCE: IN LARGE SCALE AND COMPLEX SOFTWARE-INTENSIVE SYSTEMS, P47, DOI 10.1016/B978-0-12-802301-3.00003-X
   Gupta V, 2015, INT J ADV COMPUT SC, V6, P60
   Kaur U, 2015, INT J COMPUTER APPL, V118, DOI [10.5120/20707-3021, DOI 10.5120/20707-3021]
   Khan, 2021, ASIAN J MULTIDIM RES, V10, P1167, DOI [10.5958/2278-4853.2021.00983.6, DOI 10.5958/2278-4853.2021.00983.6]
   Kirkpatrick, 2018, BEGINNERS GUIDE CODE, P17
   Ma WWY, 2017, PROC INT CONF SOFTW, P381, DOI 10.1109/ICSE.2017.42
   Maalej W, 2015, INT REQUIR ENG CONF, P116, DOI 10.1109/RE.2015.7320414
   Orru M., 2015, P 11 INT C PRED MOD, P2
   Ostovic V., 2017, The Art and Science of Rotating Field Machines Design: A Practical Approach
   Rother B., 2018, WRITING READABLE COD
   Sepahvand R, 2020, IET SOFTW, V14, P203, DOI 10.1049/iet-sen.2019.0260
   Wu, 2019, 2019 3 INT C ED MANA, P2019
   Zhang W, 2019, INFORM SOFTWARE TECH, V110, P121, DOI 10.1016/j.infsof.2019.03.001
NR 21
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43107
EP 43123
DI 10.1007/s11042-022-13246-8
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900001
DA 2024-07-18
ER

PT J
AU Huang, J
   Ren, LF
   Ji, ZW
   Yan, K
AF Huang, Jing
   Ren, Lifeng
   Ji, Zhiwei
   Yan, Ke
TI Single-channel EEG automatic sleep staging based on transition optimized
   HMM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sleep staging; Maximum information coefficient; Electroencephalography;
   Hidden Markov model
ID HIDDEN MARKOV MODEL; CLASSIFIER; NETWORKS; INSOMNIA; FEATURES; ADULTS;
   LOOP
AB Sleep staging is a key process for evaluating sleep quality and diagnosing somnipathy-related diseases. Psychologists are required to do the traditional sleep stages identification. The manual work by these experts is often time-consuming and error-prone. In order to improve the performance of such a process, automatic Electroencephalography (EEG) signal analysis using machine learning approaches is often used. In this paper, a transitions-optimized Hidden Markov Model (HMM) model is proposed to improve the accuracy of prediction. Our proposed framework includes 4 key modules: feature extraction, feature selection, classification, and transition optimization. By applying, transition optimization process after a general GMM-HMM classification, our experimental results show a convincing improvement in the accuracy of classification.
C1 [Huang, Jing; Ren, Lifeng] Zhejiang Gongshang Univ, Sch Informat & Elect Engn, Sussex Artificial Intelligence Inst, Hangzhou 310018, Zhejiang, Peoples R China.
   [Ji, Zhiwei] Nanjing Agr Univ, Sch Artificial Intelligence, Nanjing 210095, Jiangsu, Peoples R China.
   [Yan, Ke] Natl Univ Singapore, Coll Design & Engn, Dept Built Environm, Singapore 117566, Singapore.
C3 Zhejiang Gongshang University; Nanjing Agricultural University; National
   University of Singapore
RP Yan, K (corresponding author), Natl Univ Singapore, Coll Design & Engn, Dept Built Environm, Singapore 117566, Singapore.
EM yanke@nus.edu.sg
FU Zhejiang Provincial Key Laboratory of New Network Standards and
   Technologies (NNST) [2013E10012]
FX This study is supported by Zhejiang Provincial Key Laboratory of New
   Network Standards and Technologies (NNST)(No.2013E10012). The authors
   would like to thank the editor and reviewers for improving the quality
   of the paper.
CR Alickovic E, 2018, IEEE T INSTRUM MEAS, V67, P1258, DOI 10.1109/TIM.2018.2799059
   ASERINSKY E, 1953, SCIENCE, V118, P273, DOI 10.1126/science.118.3062.273
   Boe AJ, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0210-1
   Boostani R, 2017, COMPUT METH PROG BIO, V140, P77, DOI 10.1016/j.cmpb.2016.12.004
   Chen ZJ, 2015, KNOWL-BASED SYST, V89, P203, DOI 10.1016/j.knosys.2015.07.004
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Demuru M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101760
   Ding K, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101845
   Diykh M, 2016, EXPERT SYST APPL, V63, P241, DOI 10.1016/j.eswa.2016.07.004
   Feng F, 2018, INT J NURS STUD, V77, P189, DOI 10.1016/j.ijnurstu.2017.10.011
   Fraiwan L, 2012, COMPUT METH PROG BIO, V108, P10, DOI 10.1016/j.cmpb.2011.11.005
   Gharbali AA, 2018, COMPUT BIOL MED, V96, P8, DOI 10.1016/j.compbiomed.2018.03.001
   Ghimatgar H, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab965a
   Ghimatgar H, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.108320
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hsu YL, 2013, NEUROCOMPUTING, V104, P105, DOI 10.1016/j.neucom.2012.11.003
   Hu M, 2019, INFORM SCIENCES, V477, P220, DOI 10.1016/j.ins.2018.10.047
   Hu WM, 2018, IEEE T PATTERN ANAL, V40, P2355, DOI 10.1109/TPAMI.2017.2756039
   Hui M, 2018, IEEE ACCESS, V6, P27760, DOI 10.1109/ACCESS.2018.2840086
   Phan H, 2020, PHYSIOL MEAS, V41, DOI 10.1088/1361-6579/ab921e
   Phan H, 2019, IEEE T NEUR SYS REH, V27, P400, DOI 10.1109/TNSRE.2019.2896659
   Kemp B, 2000, IEEE T BIO-MED ENG, V47, P1185, DOI 10.1109/10.867928
   Lajnef T, 2015, J NEUROSCI METH, V250, P94, DOI 10.1016/j.jneumeth.2015.01.022
   Li C, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103667
   Li KY, 2018, NEUROCOMPUTING, V294, P94, DOI 10.1016/j.neucom.2018.03.011
   Li WJ, 2019, MECH SYST SIGNAL PR, V131, P689, DOI 10.1016/j.ymssp.2019.06.021
   Li XJ, 2018, IEEE J BIOMED HEALTH, V22, P375, DOI 10.1109/JBHI.2017.2668993
   Liang SF, 2012, IEEE T INSTRUM MEAS, V61, P1649, DOI 10.1109/TIM.2012.2187242
   Liang SF, 2012, J NEUROSCI METH, V205, P169, DOI 10.1016/j.jneumeth.2011.12.022
   Loewy J, 2013, PEDIATRICS, V131, P902, DOI 10.1542/peds.2012-1367
   Michielli N, 2019, COMPUT BIOL MED, V106, P71, DOI 10.1016/j.compbiomed.2019.01.013
   Mousavi S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216456
   nce R, 2020, CHILDS NERV SYST12
   Nochino T, 2019, BIOMED ENG LETT, V9, P257, DOI 10.1007/s13534-019-00108-w
   Nonoue S, 2017, SLEEP BIOL RHYTHMS, V15, P39, DOI 10.1007/s41105-016-0078-2
   Pillay K, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aaab73
   Prucnal M, 2017, METROL MEAS SYST, V24, P229, DOI 10.1515/mms-2017-0036
   Radha M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49703-y
   Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438
   Seo H, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102037
   Sharma H, 2016, COMPUT BIOL MED, V77, P116, DOI 10.1016/j.compbiomed.2016.08.012
   Supratak A, 2017, IEEE T NEUR SYS REH, V25, P1998, DOI 10.1109/TNSRE.2017.2721116
   Suraev AS, 2020, SLEEP MED REV, V53, DOI 10.1016/j.smrv.2020.101339
   Tang HY, 2021, SLEEP MED, V82, P37, DOI 10.1016/j.sleep.2021.03.025
   Thompson N. C., 2020, MIT Initiative Digit. Econ. Res. Brief
   Tsinalis Orestis, 2016, arXiv
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   Walch O, 2019, SLEEP, V42, DOI 10.1093/sleep/zsz180
   Wei R, 2018, BIOMED ENG LETT, V8, P87, DOI 10.1007/s13534-017-0044-1
   WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901
   Wolpert EA., 1969, ARCH GEN PSYCHIAT, V20, P246, DOI [DOI 10.1001/ARCHPSYC.1969.01740140118016, 10.1001/archpsyc.1969.01740140118016]
   Xie X, 2021, KNOWL-BASED SYST
   Zhao RQ, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102455
   Zhou JJ, 2020, IEEE ACCESS, V8, P57283, DOI 10.1109/ACCESS.2020.2982434
   Zhou Q, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102686
NR 55
TC 0
Z9 0
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43063
EP 43081
DI 10.1007/s11042-022-12551-6
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000797788400001
DA 2024-07-18
ER

PT J
AU Zhang, S
   Shang, ZW
   Zhou, ML
   Wang, YX
   Sun, GL
AF Zhang, Sen
   Shang, Zhaowei
   Zhou, Mingliang
   Wang, Yingxin
   Sun, Guoliang
TI Cross-modal identity correlation mining for visible-thermal person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian reidentification; Cross-modal; Knowledge transfer; Identity
   similarity; Feature embedding
AB Visible-thermal person recognition is a sub problem of image retrieval, which aims to find out the images belonging to the same pedestrian as the current image from the image set of another modality. In this paper, we propose a novel cross-modal identity correlation mining algorithm to mine potential correlation knowledge from the features of visible and thermal modalities. First, aiming at the huge visual differences caused by different imaging mechanisms, we build a correlation-enhanced knowledge transfer module based on cross-modal identity similarity to enhance the feature representation by exchanging identity knowledge between two modalities and then compress it into a shared subspace. Second, in view of different pedestrian posture and camera perspective, we design a symmetric modal-specific feature embedding module to improve the intra-modality feature discrimination, which maps the two modal images to a pair of independent feature subspaces by two fine-grained network branches. The whole algorithm can be trained in an end-to-end manner. Extensive experiments demonstrated that the proposed method outperforms the state-of-the-art methods on SYSU-MM01 and RegDB.
C1 [Zhang, Sen; Shang, Zhaowei; Zhou, Mingliang] Chongqing Univ, Sch Comp Sci, Chongqing 400044, Peoples R China.
   [Wang, Yingxin] Tsinghua Univ, Dept Engn Phys, Natl Engn Lab Dangerous Articles & Explos Detect, Beijing 100084, Peoples R China.
   [Sun, Guoliang] Tsinghua Univ, Suzhou Automot Res Inst, Suzhou 215131, Peoples R China.
C3 Chongqing University; Tsinghua University; Tsinghua University
RP Shang, ZW; Zhou, ML (corresponding author), Chongqing Univ, Sch Comp Sci, Chongqing 400044, Peoples R China.
EM szw@cqu.edu.cn; mingliangzhou@cqu.edu.cn
RI Wang, Ying/HJI-2509-2023; Zhou, Mingliang/HPC-0298-2023; ZHOU,
   MING/JVP-2920-2024
FU National Natural Science Foundation of China [62176027, 62102179];
   General Program of National Natural Science Foundation of Chongqing
   [cstc2020jcyj-msxmX0790]; Smart Community Project Based on Machine
   Vision and Internetof Things Platform [ZH22017002200003PWC]
FX The National Natural Science Foundation of China (Grant No. 62176027 and
   62102179); the General Program of National Natural Science Foundation of
   Chongqing (Grant No. cstc2020jcyj-msxmX0790); Smart Community Project
   Based on Machine Vision and Internetof Things Platform (Grant No.
   ZH22017002200003PWC).
CR Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Basaran E, 2019, ARXIV PREPRINT ARXIV
   Chen B, 2019, INT C COMPUTER VISIO
   Dai P, 2018, IJCAI
   Dargan S, 2019, ARCH COMPUT METHOD E, V26, P1283, DOI 10.1007/s11831-018-9278-z
   Dean J., 2015, NIPS DEEP LEARNING R
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hao Y, 2019, P AAAI C ARTIFICIAL
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Huang G, 2017, 2020 IEEE CVF C COMP
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Li D, 2020, ASS ADV ARTIFICIAL I
   Li J, 2019, IEEECVF INT C COMPUT
   Liang, 2019, IEEE 5 INT C MULT BI
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Liu XB, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P246, DOI 10.1109/MIPR.2019.00051
   Lu, 2020, 2020 IEEE CVF C COMP
   Luo H, 2019, IEEECVF C COMPUTER V
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Peng BY, 2019, IEEE I CONF COMP VIS, P5006, DOI 10.1109/ICCV.2019.00511
   Quan R, 2019, INT C COMPUTER VISIO
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shen Y, 2018, P EUROPEAN C COMPUTE, P504
   Sun Y., 2018, EUROPEAN C COMPUTER
   Szegedy C, 2015, INT C MACH LEARN
   Varior RR, 2016, P EUROPEAN C COMPUTE
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang Z, 2019, CVPR
   Wu A, 2017, P IEEE INT C COMPUTE
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Zhang L, 2019, P IEEE INT C COMPUTE
   Zhang Y, 2018, C COMPUTER VISION PA
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zhong X, 2020, INT C MULT RETR ICMR
   Zhou, 2017, ARXIV 170804106
   Zhu X., 2019, P IEEE INT C IM PROC, P4110
NR 41
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39981
EP 39994
DI 10.1007/s11042-022-13090-w
EA MAY 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791088200001
DA 2024-07-18
ER

PT J
AU Abid, MA
   Ullah, S
   Siddique, MA
   Mushtaq, MF
   Aljedaani, W
   Rustam, F
AF Abid, Muhammad Adeel
   Ullah, Saleem
   Siddique, Muhammad Abubakar
   Mushtaq, Muhammad Faheem
   Aljedaani, Wajdi
   Rustam, Furqan
TI Spam SMS filtering based on text features and supervised machine
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SMS; Spam; Supervised machine learning; TF-IDF; Bag of words;
   Classification
ID FOREST; TWEETS; SMOTE
AB The advancement in technology made a significant mark with time, which affects every field of life like medicine, music, office, traveling, and communication. Telephone lines are used as a communication medium in ancient times. Currently, wireless technology overrides telephone wire technology with much broader features. The advertisement agencies and spammers mostly use SMS as a medium of communication to convey their business brochures to the typical person. Due to this reason, more than 60% of spam SMS are received daily. These spam messages cause users' anger and sometimes scam with innocent users, but it creates large profits for the spammer and advertisement companies. This study proposed an approach for the classification of spam and ham SMS using supervised machine learning techniques. The feature extracting techniques such as Term Frequency-Inverse Document Frequency (TF-IDF) and bag-of-words are used to extract features from data. The SMS dataset used was imbalanced, and to solve this problem, we used over-sampling and under-sampling techniques. The support vector classifier, gradient boosting machine, random forest, Gaussian Naive Bayes, and logistics regression are applied on the spam and ham SMS dataset to evaluate the performance using accuracy, precision, recall, and F1 score. The experiment result shows that the random forest classifies spam ham SMS more accurately with 99% accuracy. The proposed model is trained well to identify the SMS category in terms of Ham or Spam with TF-IDF features and oversampling technique. The performance of the proposed approach was also evaluated on the spam email dataset with significant 99% accuracy.
C1 [Abid, Muhammad Adeel; Ullah, Saleem; Siddique, Muhammad Abubakar] Khwaja Fareed Univ Engn & Informat Technol, Rahim Yar Khan, Pakistan.
   [Mushtaq, Muhammad Faheem] Islmia Univ Bahwalpur, Bahwalpur, Pakistan.
   [Aljedaani, Wajdi] Univ North Texas, Denton, TX 76203 USA.
   [Rustam, Furqan] Univ Management & Technol, Sch Syst & Technol, Dept Software Engn, Lahore 54770, Pakistan.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; University of North Texas System; University of North Texas
   Denton; University of Management & Technology (UMT)
RP Rustam, F (corresponding author), Univ Management & Technol, Sch Syst & Technol, Dept Software Engn, Lahore 54770, Pakistan.
EM creativemind.adeel@gmail.com; saleem.ullah@kfueit.edu.pk;
   abubakar.ahmadani@kfueit.edu.pk; faheem.mushtaq88@gmail.com;
   wajdialjedaani@my.unt.edu; furqan.rustam1@gmail.com
RI Mushtaq, Muhammad Faheem/AAW-8684-2020; Rustam, Furqan/ABE-4772-2020;
   Abid, Muhammad Adeel/HRA-8157-2023
OI Rustam, Furqan/0000-0001-8403-1047; Abid, Muhammad
   Adeel/0000-0003-4679-9033
FU Department of Software Engineering, School of Systems and Technology,
   University of Management Technology
FX The authors would like to thank the Department of Software Engineering,
   School of Systems and Technology, University of Management & Technology,
   for providing a research-oriented environment.
CR Abdulhamid SM, 2017, IEEE ACCESS, V5, P15650, DOI 10.1109/ACCESS.2017.2666785
   Ahmed Ishtiaq, 2014, International Journal of Machine Learning and Computing, V4, P183, DOI 10.7763/IJMLC.2014.V4.409
   Alkhazi B, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106667
   AlOmar EA, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445281
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514
   Benevenuto Fabricio., 2010, CEAS
   Bo H., 2017, 2017 TELEPHONE TRAFF
   Cernian A., 2016, EC COMPUT EC CYBERN, V50, P2
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cormack GV, 2007, P 30 ANN INT ACM SIG
   Dittman David J., 2014, 27 INT FLAIRS C
   Doma V, 2018, ARXIV 180908651
   Duc G M, 2016, NOVEL METHOD IMPROVE
   Fallgren M, 2019, IEEE T BROADCAST, V65, P454, DOI 10.1109/TBC.2019.2912619
   Fang F, 2021, SOFT COMPUT, V25, P7307, DOI 10.1007/s00500-021-05689-2
   Faris H, 2019, INFORM FUSION, V48, P67, DOI 10.1016/j.inffus.2018.08.002
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Fraser JS, 2019, FORESTS, V10, DOI 10.3390/f10010025
   Gadde S, 7 INT C ADV COMP COM, V1
   Gayathri B.M., 2016, International Journal of Computer Application, V148, P16, DOI DOI 10.5120/IJCA2016911146
   Ghosh A, 2019, IEEE ACCESS, V7, P127639, DOI 10.1109/ACCESS.2019.2939938
   Gmez Hidalgo JM, 2006, P 2006 ACM S DOC ENG
   Ishtiaq A, 2019, INT BHURBAN C APPL S, P629, DOI 10.1109/IBCAST.2019.8667174
   Jamil R, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.645
   Kaggle, 2021, SPAM MAILS DAT
   Kaggle, 2016, SMS SPAM COLL DAT
   Ke GL, 2017, ADV NEUR IN, V30
   Kim S.N., 2009, AUSTRALASIAN LANGUAG, P94
   Lee MC., 2012, ADV INF SCI SERV SCI, V4, P18
   Lin WC, 2017, INFORM SCIENCES, V409, P17, DOI 10.1016/j.ins.2017.05.008
   Mujahid M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188438
   Nagwani NK, 2017, J INF SCI, V43, P75, DOI 10.1177/0165551515616310
   Nikam S, 2017, REV PAPER IMAGE SPAM
   Pavlopoulos S, 1998, IEEE Trans Inf Technol Biomed, V2, P261, DOI 10.1109/4233.737581
   Ramsingh J, 2021, J KING SAUD UNIV-COM, V33, P1018, DOI 10.1016/j.jksuci.2018.06.011
   Roy PK, 2020, FUTURE GENER COMP SY, V102, P524, DOI 10.1016/j.future.2019.09.001
   Rupapara V, IMPACT SMOTE IMBALAN
   Rupapara V, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.745
   Russo DP, 2018, MOL PHARMACEUT, V15, P4361, DOI 10.1021/acs.molpharmaceut.8b00546
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Safdari N, 2019, PROC SPIE, V10989, DOI 10.1117/12.2519226
   Sajedi H., 2016, Mach. Learn. Res, V1, P1
   Sohn DN, 2009, P ACL IJCNLP 2009 C
   Speiser JL, 2019, CHEMOMETR INTELL LAB, V185, P122, DOI 10.1016/j.chemolab.2019.01.002
   Subramaniam T, 2010, INT J PHYS SCI, V5, P1869
   Willig A, 2005, P IEEE, V93, P1130, DOI 10.1109/JPROC.2005.849717
   Xia T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10145011
   Zamel Y.K., 2018, INT J PURE APPL MATH, V119, P325
NR 48
TC 14
Z9 16
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39853
EP 39871
DI 10.1007/s11042-022-12991-0
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000790645700001
DA 2024-07-18
ER

PT J
AU Almuashi, M
   Hashim, SZM
   Yusoff, N
   Syazwan, KN
   Ghabban, F
AF Almuashi, Mohammed
   Hashim, Siti Zaiton Mohd
   Yusoff, Nooraini
   Syazwan, Khairul Nizar
   Ghabban, Fahad
TI Siamese convolutional neural network and fusion of the best overlapping
   blocks for kinship verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinship verification; Siamese convolutional neural network; Overlapping
   local block; Fusion
ID FACIAL IMAGES; FACE IMAGES; FEATURES
AB Analysis of facial images decoding familial features has been attracting the attention of researchers to develop a computerized system interested in determining whether a pair of facial images have a biological kin relationship or not. Given that not all regions of an image are useful to determine the kin relation, thus it is possible to obtain irrelevant and inaccurate information of kinship clues, resulting in false matched kinship. Thus, combining all these regions together will likely produces redundant, irrelevant and deceptive information of kinship, along with higher dimensional space. Motivated by the fact that the facial resemblance among the members in a family can be presented separately in different regions of facial images, where each independent region renders different familial features, there is a high probability that selecting and fusing only the most informative local regions and removing the irrelevant can obtain complementary information for further enhanced accuracy. To this end, unlike other methods, the Fusion of the Best Overlapping Blocks with Siamese Convolutional Neural Network (SCNN-FBOB) is an enhanced method for kinship verification in this paper. This method aimed to simultaneously remove the weak local blocks of the image from a set of overlapping local blocks that achieved low accuracy and only retain the local blocks that achieved high accuracy. Extensive experiments conducted on the benchmark KinFaceW-I and KinFaceW-II databases show highly competitive results over many other state-of-the-art methods.
C1 [Almuashi, Mohammed; Hashim, Siti Zaiton Mohd] Univ Teknol Malaysia, Sch Comp, Skudai 81310, Johor, Malaysia.
   [Yusoff, Nooraini; Syazwan, Khairul Nizar] Univ Malaysia Kelantan, Inst Artificial Intelligence & Big Data Pengkalan, Bharu, Malaysia.
   [Ghabban, Fahad] Taibah Univ, Coll Comp Sci & Engn, Medina, Saudi Arabia.
C3 Universiti Teknologi Malaysia; Universiti Malaysia Kelantan; Taibah
   University
RP Almuashi, M (corresponding author), Univ Teknol Malaysia, Sch Comp, Skudai 81310, Johor, Malaysia.
EM mohd.almuashi@gmail.com; sitizaiton@utm.my; nooraini.y@umk.edu.my;
   nizar.w@umk.edu.my; fahdm8520@hotmail.com
RI GHABBAN, FAHAD/GZK-9025-2022
OI ghabban, fahad/0000-0003-3158-6131
CR Abdellah S, 2018, INT S MOD IMPL COMPL, P230
   Akerkar R., 2014, Introduction to artificial intelligence
   Aliradi R, 2018, Multimed Tools Appl, V28, P1
   Alirezazadeh P., 2016, J COMPUTING SECURITY, V3, P183
   Alirezazadeh P, 2015, IEEE SIGNAL PROC LET, V22, P2459, DOI 10.1109/LSP.2015.2490805
   Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5
   [Anonymous], 2014, IDENTITY KINSHIP REL
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Beham MP, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413560053
   Bottino A., 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P405
   Bukovciková Z, 2017, ELMAR PROC, P205, DOI 10.23919/ELMAR.2017.8124469
   Chen XJ, 2017, MULTIMED TOOLS APPL, V76, P4105, DOI 10.1007/s11042-015-2930-9
   Chergui Abdelhakim, 2019, 2019 International Conference on Advanced Systems and Emergent Technologies (IC_ASET). Proceedings, P64, DOI 10.1109/ASET.2019.8871011
   Chergui A, 2018, IEEE HAMMAMET TUNISI, P1
   Chergui A, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON NETWORKING AND ADVANCED SYSTEMS (ICNAS 2019), P34, DOI 10.1109/icnas.2019.8807875
   Chergui A, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2019), P82, DOI 10.1109/icfsp48124.2019.8938055
   Chollet F., 2015, Keras documentation
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Cui LY, 2017, IEEE INT CON MULTI, P751, DOI 10.1109/ICME.2017.8019326
   Dahan E, 2021, IEEE T PATTERN ANAL, V43, P2851, DOI 10.1109/TPAMI.2020.3036993
   Dandekar AR, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Das TK, 2020, J BIOMIM BIOMATER BI, V45, P57, DOI 10.4028/www.scientific.net/JBBBE.45.57
   Dehshibi MM, 2019, VISUAL COMPUT, V35, P23, DOI 10.1007/s00371-017-1442-1
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Dornaika F, 2020, NEURAL COMPUT APPL, V32, P7139, DOI 10.1007/s00521-019-04201-0
   Duan Q., 2017, ADV KIN ADVERSARIAL, V568, P48
   Duan QY, 2017, IEEE INT CONF COMP V, P1590, DOI 10.1109/ICCVW.2017.187
   Duan XD, 2015, IEEE IMAGE PROC, P1573, DOI 10.1109/ICIP.2015.7351065
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Georgopoulos M, 2018, IMAGE VISION COMPUT, V80, P58, DOI 10.1016/j.imavis.2018.05.003
   Goyal A., 2020, TEMPLATE MATCHING KI, P255
   Goyal A., 2019, COGNITIVE INFORM SOF, P371
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Hu JL, 2018, IEEE T CIRC SYST VID, V28, P1875, DOI 10.1109/TCSVT.2017.2691801
   Hu JL, 2015, LECT NOTES COMPUT SC, V9005, P252, DOI 10.1007/978-3-319-16811-1_17
   Jain Apoorv, 2020, ADV DATA SCI SECURIT, P353
   Kamarainen J-K., 2011, LOCAL REPRESENTATION, P79
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Laiadi O, 2019, IEEE INT CONF AUTOMA, P735, DOI 10.1109/fg.2019.8756627
   Laiadi O, 2019, MULTIMED TOOLS APPL, V78, P16465, DOI 10.1007/s11042-018-7027-9
   Li L, 2016, LECT NOTES COMPUT SC, V9730, P539, DOI 10.1007/978-3-319-41501-7_60
   Li YY, 2017, ADV SOC SCI EDUC HUM, V159, P13
   Liang JQ, 2019, IEEE T IMAGE PROCESS, V28, P1149, DOI 10.1109/TIP.2018.2875346
   Liang JY, 2017, COMM COM INF SC, V771, P563, DOI 10.1007/978-981-10-7299-4_47
   Liu HJ, 2017, IEEE INT CON MULTI, P319, DOI 10.1109/ICME.2017.8019375
   Lopez MB, 2018, MACH VISION APPL, V29, P873, DOI 10.1007/s00138-018-0943-x
   Lu JW, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Mahpod S, 2018, COMPUT VIS IMAGE UND, V167, P28, DOI 10.1016/j.cviu.2017.12.003
   Mohamed Ouhda, 2019, Lecture Notes in Real-Time Intelligent Systems. Advances in Intelligent Systems and Computing (AISC 756), P463, DOI 10.1007/978-3-319-91337-7_41
   Moujahid A, 2019, MULTIMED TOOLS APPL, V78, P9335, DOI 10.1007/s11042-018-6517-0
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nandy A, 2019, IEEE INT CONF AUTOMA, P739
   Nguyen TDH, 2020, 2020 15 IEEE INT C A, P887
   Patel B, 2017, COMPUT VIS IMAGE UND, V160, P24, DOI 10.1016/j.cviu.2017.04.009
   Qin XQ, 2020, NEUROCOMPUTING, V377, P213, DOI 10.1016/j.neucom.2019.09.089
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Riccio D, 2014, ADV COMPU INTELL ROB, P187, DOI 10.4018/978-1-4666-5966-7.ch009
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   Robinson JP, 2020, ARXIV200616033
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Sharma S, 2019, P REC ADV INT TRENDS
   Somanath G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P105, DOI 10.1109/BTAS.2012.6374564
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tidjani A, 2018, IET IMAGE PROCESS, V12, P2336, DOI 10.1049/iet-ipr.2018.5552
   Van TN, 2019, ASIA-PAC CONF COMMUN, P116, DOI [10.1109/APCC47188.2019.9026554, 10.1109/apcc47188.2019.9026554]
   Van TN, 2019, 2019 26TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P376, DOI [10.1109/ict.2019.8798781, 10.1109/ICT.2019.8798781]
   Tu CM, 2018, INT POW ELEC APPLICA, P1000
   Vieira T. F., 2013, 18 IB C PATT REC CIA, P326
   Vyas AS, 2019, INT CONF ADVAN COMPU, P102, DOI [10.1109/ICACCS.2019.8728330, 10.1109/icaccs.2019.8728330]
   Wang M., 2015, International Low Impact Development China Conference, P1, DOI [DOI 10.1109/COMPSAC.2015.343, 10.1109/MMSP.2015.7340820, DOI 10.1049/CP.2015.0489, 10.1049/cp.2015.0489]
   Wang MY, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patog.2020.10732
   Wang SW, 2020, PATTERN RECOGN LETT, V138, P38, DOI 10.1016/j.patrec.2020.06.019
   Wang SY, 2017, IEEE INT CONF AUTOMA, P216, DOI [10.1109/FG.2017.35, 10.1109/ICEMI.2017.8265769]
   Wang W, 2020, ARXIV200406382
   Wei ZQ, 2019, IEEE ACCESS, V7, P100029, DOI 10.1109/ACCESS.2019.2929939
   Wu XT, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P187, DOI 10.1109/SIPROCESS.2018.8600423
   Xia C, 2018, AS C COMP VIS, P496
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, INT C PATT RECOG, P549
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xiao Bing Li, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413201
   Xu M, 2016, IEEE ACCESS, V4, P10280, DOI 10.1109/ACCESS.2016.2635147
   Xu M, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4072323
   Yadav Niharika, 2019, Cognitive Informatics and Soft Computing. Proceeding of CISC 2017. Advances in Intelligent Systems and Computing (AISC 768), P381, DOI 10.1007/978-981-13-0617-4_38
   Yan H., 2017, FEATURE LEARNING FAC, P7, DOI [10.1007/978-981-10-4484-7, DOI 10.1007/978-981-10-4484-7]
   Yan HB, 2019, PATTERN RECOGN LETT, V128, P169, DOI 10.1016/j.patrec.2019.08.023
   Yan HB, 2019, PATTERN RECOGN LETT, V117, P146, DOI 10.1016/j.patrec.2018.05.027
   Yan KW, 2017, CHIN CONTR CONF, P4077, DOI 10.23919/ChiCC.2017.8027997
   Yang Y, 2017, 2 INT C ART INT ENG, P928
   Yu J, 2020, ARXIV200600143
   Yu J, 2020, ARXIV200600174
   Zhang K., 2015, BRIT MACH VIS C
   Zhang L, 2021, IEEE T CYBERNETICS, V51, P5883, DOI 10.1109/TCYB.2019.2959403
   Zhao YG, 2018, INFORM SCIENCES, V430, P247, DOI 10.1016/j.ins.2017.11.048
   Zhou X., 2011, ACM Multimedia, P953
   Zhou XZ, 2019, INFORM FUSION, V48, P84, DOI 10.1016/j.inffus.2018.07.011
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
   Zhou X, 2016, IEEE IMAGE PROC, P2911, DOI 10.1109/ICIP.2016.7532892
NR 104
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39311
EP 39342
DI 10.1007/s11042-022-12735-0
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000014
DA 2024-07-18
ER

PT J
AU Singh, KU
   Kumar, A
   Singh, T
   Ram, M
AF Singh, Kamred Udham
   Kumar, Akshay
   Singh, Teekam
   Ram, Mangey
TI Image-based decision making for reliable and proper diagnosing in NIFTI
   format using watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; NIFTI; MSVD; LWT; QR and Image
ID SINGULAR-VALUE DECOMPOSITION; LIFTING WAVELET; OPTIMIZATION; ROBUST;
   DWT; DCT
AB Nowadays, advancement in Magnetic Resonance Imaging (MRI) and Computed Tomography Scan (CT-Scan) technologies have defined modern neuroimaging and drastically change the diagnosing of disease in the world healthcare system. These imaging technologies generate NIFTI (Neuroimaging Informatics Technology Initiative) images. Due to COVID-19 last several months CT-Scan has been performed on millions of the CORONA patients, so billions of the NIFTI images have been produced and communicate over the internet for the diagnosing purpose to detect the coronavirus. The communication of these medical images over the internet yielding the major problem of integrity, copyright protection, and other ethical issues for the world health care system. Another critical problem is that; is doctor diagnose the impeccable medical image of the patient because a large amount of COVID-19 patient's data exists. For proper diagnosing it is also necessary to identify impeccable medical image. Therefore, to address these problems a secure and robust watermarking scheme is needed for these images. Various watermarking schemes have been developed for bmp, .jpg, .png, DICOM, and other image formats but the noticeable contribution is not reported for the NIFTI images. In this paper a robust and hybrid watermarking scheme for NIFTI images based on Lifting Wavelet Transform (LWT), MSVD (Multiresolution Singular Value Decomposition) and QR factorization. The combination of LWT, QR, and MSVD helps in retaining the sensitivity of the NIFTI image and improve the robustness of the watermarking scheme. In this scheme, multiple watermarks are inserted across the first slice of the NIFTI image. The proposed watermarking scheme is sustained against various noise attacks and performance is measured in terms of PSNR, SNR, SSIM, Quality of image, and Normalized correlation. Quality of the image is much significant that lie between .99994 to .99998 and SSIM reported from .94 to .99. Whereas the PSNR of the proposed scheme lies between 56.76 to 57.28 db and NC values lie between .9993 to .9998. which shows that the results are better than the existing schemes where PSNR is lies between 32.66 to 52.02 db. Watermarking, NIFTI, MSVD, LWT, QR and Image.
C1 [Singh, Kamred Udham] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Tainan 701, Taiwan.
   [Singh, Kamred Udham] Graph Era Hill Univ, Sch Comp, Dehra Dun, Uttarakhand, India.
   [Kumar, Akshay] Graph Era Hill Univ, Dept Math, Dehra Dun, Uttarakhand, India.
   [Singh, Teekam] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
   [Ram, Mangey] Graph Era Deemed Univ, Dept Math Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
   [Ram, Mangey] Peter Great St Petersburg Polytech Univ, Inst Adv Mfg Technol, St Petersburg 195251, Russia.
C3 National Cheng Kung University; University of Petroleum & Energy Studies
   (UPES); Graphic Era University; Peter the Great St. Petersburg
   Polytechnic University
RP Ram, M (corresponding author), Graph Era Deemed Univ, Dept Math Comp Sci & Engn, Dehra Dun, Uttarakhand, India.; Ram, M (corresponding author), Peter Great St Petersburg Polytech Univ, Inst Adv Mfg Technol, St Petersburg 195251, Russia.
EM kamredudhamsingh@gmail.com; akshaykr1001@gmail.com;
   teekam.singh@ddn.upes.ac.in; drmrswami@yahoo.com
RI Singh, Kamred Udham/AAB-5895-2022; Kumar, Akshay/AAG-9040-2021; Ram,
   Mangey/B-8214-2012; MANJHVAR, AMIT KUMAR/HNB-6459-2023; Kumar,
   Amit/HJP-6588-2023; Singh, Kamred Udham/AAZ-2488-2021
OI Kumar, Akshay/0000-0003-3523-3122; Ram, Mangey/0000-0002-8221-092X;
   MANJHVAR, AMIT KUMAR/0000-0002-9577-6295; Singh, Kamred
   Udham/0000-0002-7201-6381
CR Agung B. W. R., 2012, 2012 IEEE International Conference on Communication, Networks and Satellite (ComNetSat 2012), P167, DOI 10.1109/ComNetSat.2012.6380799
   Ahn CJ, 2008, IEEE T VEH TECHNOL, V57, P2578, DOI 10.1109/TVT.2007.913179
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Awasthi Y, 2019, PROCEEDINGS OF THE 2019 8TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2019), P250, DOI [10.1109/smart46866.2019.9117522, 10.1109/SMART46866.2019.9117522]
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Darwish SM, 2021, J EXP THEOR ARTIF IN, V33, P945, DOI 10.1080/0952813X.2020.1801853
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Ernawan F, 2021, IEEE ACCESS, V9, P45474, DOI 10.1109/ACCESS.2021.3067245
   Fan WB, 2005, LECT NOTES ARTIF INT, V3802, P838
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gao TG, 2007, INT C WAVEL ANAL PAT, P1771
   Garg P, 2020, J INFORM OPTIM SCI, V41, P1499, DOI 10.1080/02522667.2020.1802124
   Goli MS, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P237, DOI 10.1109/PRIA.2017.7983054
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Hsu LY, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON CONTROL, ROBOTICS AND CYBERNETICS (CRC 2019), P174, DOI 10.1109/CRC.2019.00043
   Kaur G, 2020, J INFORM OPTIM SCI, V41, P205, DOI 10.1080/02522667.2020.1714185
   Khalil OH, 2020, IMAGING SCI J, V68, P90, DOI 10.1080/13682199.2020.1740431
   Loukhaoukha K, 2010, LECT NOTES COMPUT SC, V6134, P394, DOI 10.1007/978-3-642-13681-8_46
   Malini S, 2015, PROCEDIA COMPUT SCI, V46, P1708, DOI 10.1016/j.procs.2015.02.114
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Musanna F, 2020, IMAGING SCI J, V68, P24, DOI 10.1080/13682199.2020.1732116
   Nan Lin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P684, DOI 10.1109/ICCSN.2011.6014360
   Ni RR, 2006, INT CONF SIGN PROCES, P2648
   Rahim T, 2021, IETE TECH REV, V38, P245, DOI 10.1080/02564602.2020.1721342
   Sharmila TS, 2014, SIGNAL IMAGE VIDEO P, V8, P1399, DOI 10.1007/s11760-012-0369-2
   Singh S, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P685, DOI 10.1109/PDGC.2016.7913209
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Sunesh, 2020, J INFORM OPTIM SCI, V41, P1597, DOI 10.1080/02522667.2020.1802131
   Takore TT, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2725, DOI 10.1109/ICEEOT.2016.7755190
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Vinothini K., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0887, DOI 10.1109/ICCSP.2019.8697935
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   ZAIRI M, 2020, 3 INT C NETW INF, pNI294, DOI DOI 10.1145/3386723.3387863
NR 35
TC 12
Z9 12
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39577
EP 39603
DI 10.1007/s11042-022-12192-9
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000005
PM 35505669
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hermann, D
   Gildas, GG
   Fouda, JSAE
   Koepf, W
AF Hermann, Djeugoue
   Gildas, Gnyamsi Gaetan
   Fouda, Jean Sire Armand Eyebe
   Koepf, Wolfram
TI On the implementation of large period piece-wise linear Arnold cat map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamical system; Random number; Circuit theory; Digital circuits
ID ENCRYPTION; SCHEME; CHAOS
AB This paper presents a piece-wise linear cat map (PWLCM) obtained by perturbing the conventional quantized Arnold cat map (QACM) with a nonlinear term. The effect of the nonlinear term on the dynamics of the QACM is investigated. We show that the eigenvalues, hence the Lyapunov exponents of the PWLCM depend on the initial conditions, which is not the case for the QACM. As a result, the proposed PWLCM is a generalized form of the QACM, whose the period exponentially increases with respect to the precision, thus taking as value 1.09 x 10(513) for only 10-bit precision; while that of the corresponding QACM is only 768. The nonlinear term increases the sensitivity of the system to the initial conditions, which contributes to increase its period, hence to enhance its complexity. An electronic implementation of both the QACM and the PWLCM in the case of 4-bit precision using Multisim is presented. The proposed architecture of both the QACM and the PWLCM are implemented using Verilog and prototyped on the Zynq 7020 FPGA board. For 4-bit precision, the FPGA implementation performs 1.072 Gbps throughput at 134 MHz maximum frequency. We verified that experimental and simulation behaviors of the proposed system perfectly match, thus confirming the effectiveness of the proposed electronic circuit for exhibiting the expected dynamics in real-time.
C1 [Hermann, Djeugoue; Gildas, Gnyamsi Gaetan; Fouda, Jean Sire Armand Eyebe] Univ Yaounde I, Dept Phys, Yaounde, Cameroon.
   [Fouda, Jean Sire Armand Eyebe; Koepf, Wolfram] Univ Kassel, Inst Math, Kassel, Germany.
C3 University of Yaounde I; Universitat Kassel
RP Koepf, W (corresponding author), Univ Kassel, Inst Math, Kassel, Germany.
EM efoudajsa@yahoo.fr; koepf@mathematik.uni-kassel.de
OI EYEBE FOUDA, Jean Sire Armand/0000-0003-1114-6366
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bakiri M, 2018, IEEE T IND INFORM, V14, P3754, DOI 10.1109/TII.2018.2815985
   Bakiri M, 2018, IEEE T CIRCUITS-I, V65, P1628, DOI 10.1109/TCSI.2017.2754650
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Bonilla LL, 2016, J MATH IND, V7, DOI 10.1186/s13362-016-0026-4
   Chen F, 2014, THEOR COMPUT SCI, V552, P13, DOI 10.1016/j.tcs.2014.08.002
   Chen F, 2013, IEEE T INFORM THEORY, V59, P3249, DOI 10.1109/TIT.2012.2235907
   Chen F, 2012, IEEE T INFORM THEORY, V58, P445, DOI 10.1109/TIT.2011.2171534
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng Chen, 2015, Pacific Science Review A: Natural Science and Engineering, V17, P97, DOI 10.1016/j.psra.2016.02.001
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Eckmann J.-P., 1985, Reviews of Modern Physics, V57, P617, DOI 10.1103/RevModPhys.57.617
   Fouda JSAE, 2015, COMMUN NONLINEAR SCI, V20, P24, DOI 10.1016/j.cnsns.2014.05.002
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Hu J, 2009, CHAOS, V19, DOI 10.1063/1.3152007
   Hua ZY, 2018, IEEE T CIRCUITS-I, V65, P235, DOI 10.1109/TCSI.2017.2717943
   Kalanadhabhatta S, 2020, IEEE T VLSI SYST, V28, P1740, DOI 10.1109/TVLSI.2020.2979269
   Keating JP, 2000, NONLINEARITY, V13, P747, DOI 10.1088/0951-7715/13/3/313
   Kocarev L, 2004, CHAOS, V14, P1078, DOI 10.1063/1.1821671
   Panda AK, 2020, IEEE T INSTRUM MEAS, V69, P1011, DOI 10.1109/TIM.2019.2909248
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CL, 2017, ADV EXP MED BIOL, V969, P1, DOI 10.1007/978-94-024-1057-0_1
   Li W, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.044102
   Lou DC, 2004, IEEE T MULTIMEDIA, V6, P501, DOI 10.1109/TMM.2004.827493
   Merah L, 2021, IEEE ACCESS, V9, P88997, DOI 10.1109/ACCESS.2021.3089913
   Öztürk I, 2021, NONLINEAR DYNAM, V103, P2805, DOI 10.1007/s11071-021-06235-3
   Öztürk I, 2015, NONLINEAR DYNAM, V80, P1147, DOI 10.1007/s11071-015-1932-5
   Rameshbabu R., 2015, J SCI RES, V23, P36
   Rezk AA, 2020, AEU-INT J ELECTRON C, V113, DOI 10.1016/j.aeue.2019.152947
   Shah DK, 2017, AEU-INT J ELECTRON C, V78, P245, DOI 10.1016/j.aeue.2017.05.005
   Wang DL, 2019, COMMUN NONLINEAR SCI, V68, P302, DOI 10.1016/j.cnsns.2018.08.005
   Wang YP, 2021, PROCEEDINGS OF 2021 11TH INTERNATIONAL CONFERENCE ON BIOSCIENCE, BIOCHEMISTRY AND BIOINFORMATICS, ICBBB 2021, P1, DOI [10.1017/dmp.2021.149, 10.1145/3448340.3448341, 10.1145/3481056.3481108]
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
NR 33
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39003
EP 39020
DI 10.1007/s11042-022-13175-6
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500006
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Shrestha, B
   Alsadoon, A
   Prasad, PWC
   Al-Naymat, G
   Al-Dala'in, T
   Rashid, TA
   Alsadoon, OH
AF Shrestha, Bibek
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Naymat, Ghazi
   Al-Dala'in, Thair
   Rashid, Tarik A.
   Alsadoon, Omar Hisham
TI Enhancing the prediction of type 2 diabetes mellitus using sparse
   balanced SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Type 2 diabetes mellitus; Screening; Noninvasive attributes; Machine
   learning; Support Vector Machine
AB The natural population-based prediction of type 2 diabetes is costly since it needs a high number of resources. Even though much research has used machine learning algorithms to predict type II diabetes, it could not obtain a sufficient sensitivity range due to imbalanced and sparse data. This research aims to utilize noninvasive features from electronic health records with a machine-learning algorithm, namely Sparse Balance- Support Vector Machine (SB-SVM), to handle the imbalanced data and achieve high precision. The proposed system uses SB-SVM to create sparsity and implicitly to select the highest relevant features from the imbalanced data. Initially, we preprocess the data using different baseline variables and filters. Secondly, different features are extracted from the preprocessed data using inclusion and exclusion criteria as filters. Thirdly, we selected 12 highly relevant features to diabetes prediction using statistical analysis and logistic regression. Then, we train and test the proposed model using the nested stratified cross-validation method. Finally, the optimal model performance is evaluated based on the test set. The proposed model predicts type 2 diabetes mellitus using the noninvasive features, with enhanced sensitivity and less processing time. Our solution outperforms the state-of-the-art in most performance metrics. Accuracy, precision, recall, and Area Under the Curve (AUC) of the best solution are 67.22%, 62.93%, 69.96%, and 69.96%, respectively. In comparison, our solution achieved Accuracy, precision, recall, and AUC of 76.39%, 66.86%, 76.74%, and 85.08%, respectively. The average processing time is decreased from 40 similar to 85 folds/sec to 8.9 similar to 10.7 folds/sec. To conclude, the proposed system improves the precision and sensitivity of diabetes prediction with minimal processing time.
C1 [Shrestha, Bibek; Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Al-Naymat, Ghazi] Ajman Univ, Coll Engn & IT, Dept Informat Technol, Ajman, U Arab Emirates.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Ajman University;
   University of Kurdistan Hewler; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Rashid, Tarik A./P-3473-2019; Rashid, Tarik A./HLX-0184-2023; Alsadoon,
   A/Prof. Abeer/AAU-1532-2021
OI Rashid, Tarik A./0000-0002-8661-258X; Rashid, Tarik
   A./0000-0002-8661-258X; Alsadoon, A/Prof. Abeer/0000-0002-2309-3540;
   Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Abbas HT, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219636
   Anderson AE, 2016, J BIOMED INFORM, V60, P162, DOI 10.1016/j.jbi.2015.12.006
   [Anonymous], 2018, NHANES Questionnaires, Datasets, and Related Documentation
   Baghdasarian S, 2018, NUTRIENTS, V10, DOI 10.3390/nu10060665
   Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391
   Bernardini M, 2020, ARTIF INTELL MED, V105, DOI 10.1016/j.artmed.2020.101847
   Bernardini M, 2020, IEEE J BIOMED HEALTH, V24, P235, DOI 10.1109/JBHI.2019.2899218
   Cahn A, 2020, DIABETES-METAB RES, V36, DOI 10.1002/dmrr.3252
   El-Sappagh S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060635
   Han LF, 2015, IEEE J BIOMED HEALTH, V19, P728, DOI 10.1109/JBHI.2014.2325615
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Islam MS, 2020, IEEE ACCESS, V8, P120537, DOI 10.1109/ACCESS.2020.3005540
   Kopitar L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68771-z
   Lai H, 2019, BMC ENDOCR DISORD, V19, DOI 10.1186/s12902-019-0436-6
   Maeta Katsutoshi, 2018, JMIR Diabetes, V3, pe10212, DOI 10.2196/10212
   Miotto R, 2016, SCI REP-UK, V6, DOI 10.1038/srep26094
   Nguyen BP, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105055
   Perveen S, 2020, IEEE ACCESS, V8, P21875, DOI 10.1109/ACCESS.2020.2968608
   Perveen S, 2020, FRONT GENET, V10, DOI 10.3389/fgene.2019.01076
   Pimentel A, 2018, HEALTH INFORM J, V24, P194, DOI 10.1177/1460458216663023
   Roberts S, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2017-017184
   Sneha N, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0175-6
   Stiglic G, 2018, DIABETIC MED, V35, P640, DOI 10.1111/dme.13605
   Wang Y, 2017, IEEE J BIOMED HEALTH, V21, P1280, DOI 10.1109/JBHI.2016.2614991
   Wilson PWF, 2007, ARCH INTERN MED, V167, P1068, DOI 10.1001/archinte.167.10.1068
   Wu JH, 2020, NEURAL COMPUT APPL, V32, P9683, DOI 10.1007/s00521-019-04489-y
   Yang TZ, 2020, JMIR MED INF, V8, DOI 10.2196/15431
   Zhang L, 2020, JMIR MED INF, V8, DOI 10.2196/16850
   Zhang LY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61123-x
   Zheng T, 2017, INT J MED INFORM, V97, P120, DOI 10.1016/j.ijmedinf.2016.09.014
   Zou Q, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00515
NR 31
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38945
EP 38969
DI 10.1007/s11042-022-13087-5
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139100002
DA 2024-07-18
ER

PT J
AU Vikram, R
   Sinha, D
AF Vikram, Raj
   Sinha, Ditipriya
TI A multimodal framework for Forest fire detection and monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neuro-fuzzy; Forest fire; CNN; DNN
ID PREDICTION
AB Forest fire is disastrous to civilizations due to damage to life and property. Forest fire results imbalance of the ecosystem loss of human life and wild animals. Early detection of fire is one of the ways to mitigate this problem. This article proposes a Multimodal framework to identify the fire-prone area of the forest. In this approach, the forest area is divided into different zones. In each zone, two types of sensors are deployed. One type of sensor senses the temperature, relative humidity, drought condition of that zone. Another one is the camera sensors that capture images of that zone simultaneously. All the sensors send the sensed data and image data to the base station. Base station predicts the status (High Active/ Medium Active/Low Active) of the forest zone applying the proposed Multimodal forest fire detection framework. This framework is the integration of the Neuro-fuzzy classification based Sensor model and CNN based Image model. From performance analysis, it is observed that the fire detection accuracy of this proposed Multimodal model is high compared to the individual Sensor and Image model. This model assists the base station in taking necessary action to mitigate fire at that zone in the forest.
C1 [Vikram, Raj; Sinha, Ditipriya] Natl Inst Technol, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Vikram, R (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM raj.cs17@nitp.ac.in; ditipriya.cse@nitp.ac.in
RI Vikram, Raj/GRS-4166-2022
OI Vikram, Raj/0000-0003-1714-664X
CR Alfyani Resty, 2020, 2020 International Seminar on Application for Technology of Information and Communication (iSemantic), P196, DOI 10.1109/iSemantic50169.2020.9234299
   Altintas I, 2021, J COMPUT SCI-NETH, V52, DOI 10.1016/j.jocs.2020.101210
   [Anonymous], 2018, FOR AR PERC
   [Anonymous], 2007, FOREST FIRE DATASET
   Ashutosh DK, 2014, FOREST FIRE DISASTER
   Brun C, 2014, J SUPERCOMPUT, V70, P721, DOI 10.1007/s11227-014-1168-z
   Cruz H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060893
   Das AK, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110713
   Ertugrul M, 2021, ENVIRON MONIT ASSESS, V193, DOI 10.1007/s10661-020-08800-6
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Hashimoto A, 2021, INT J REMOTE SENS, V42, P1917, DOI 10.1080/01431161.2020.1846225
   Jaafari A, 2018, ECOL INFORM, V43, P200, DOI 10.1016/j.ecoinf.2017.12.006
   Javadi SH, 2019, J AMB INTEL HUM COMP, V10, P1443, DOI 10.1007/s12652-017-0584-3
   Kansal A, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P241, DOI 10.1109/ICIIP.2015.7414773
   Kaur H, 2020, CLUSTER COMPUT, V23, P1149, DOI 10.1007/s10586-019-02981-7
   Kaur H, 2020, IEEE SYST J, V14, P2003, DOI 10.1109/JSYST.2019.2923635
   Kaur H, 2020, SOFT COMPUT, V24, P9651, DOI 10.1007/s00500-019-04477-3
   Kaur H, 2019, J EXP THEOR ARTIF IN, V31, P599, DOI 10.1080/0952813X.2019.1591523
   Khetwal MN., 2012, PRAGYAN, V10, P36
   Lin HF, 2018, SUSTAIN COMPUT-INFOR, V18, P101, DOI 10.1016/j.suscom.2017.05.004
   Lloret J, 2017, COMPUT NETW, V129, P340, DOI 10.1016/j.comnet.2017.05.018
   Lv CD, 2020, J SUPERCOMPUT, V76, P3602, DOI 10.1007/s11227-018-2560-x
   Mahmoud MAI, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7612487
   Moumgiakmas SS, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13080200
   Qin HT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107281
   Ranzato F, 2021, ARXIV210100909
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Sevinc V, 2020, FOREST ECOL MANAG, V457, DOI 10.1016/j.foreco.2019.117723
   Sharma R, 2020, MULTIMED TOOLS APPL, V79, P28155, DOI 10.1007/s11042-020-09347-x
   Shotton Jamie, 2016, DECISION JUNGLES COM
   Silva IDB, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106075
   Singh JP, 2019, ANN OPER RES, V283, P737, DOI 10.1007/s10479-017-2522-3
   Sinha D, 2019, WIRELESS PERS COMMUN, V109, P2561, DOI 10.1007/s11277-019-06697-0
   Vikram R, 2020, WIREL NETW, V26, P5177, DOI 10.1007/s11276-020-02393-1
   Vikram R, 2021, J AMB INTEL HUM COMP, V12, P1647, DOI 10.1007/s12652-020-02238-x
   Xu RJ, 2021, FORESTS, V12, DOI 10.3390/f12020217
   Zhang J., 2008, FRONTIERS CHINA, V3, P369, DOI [10.1007/s11461-008-0054-3.24N.U., DOI 10.1007/S11461-008-0054-3.24N.U]
   Zhang TX, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020543
NR 38
TC 4
Z9 4
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9819
EP 9842
DI 10.1007/s11042-022-13043-3
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000785933700001
DA 2024-07-18
ER

PT J
AU He, Z
   Meng, B
   Wang, LN
   Jeon, G
   Liu, ZT
   Yang, XM
AF He, Zheng
   Meng, Bin
   Wang, Lining
   Jeon, Gwanggil
   Liu, Zitao
   Yang, Xiaomin
TI Global and local fusion ensemble network for facial expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial feature learning; Facial expression recognition; Deep learning;
   Ensemble network
ID DEEP NEURAL-NETWORKS
AB Accurate and fast facial feature learning is vital for Facial Expression Recognition (FER). Recent researches have proved that ensemble methods can perform efficiently and effectively on the FER, whereas these methods still confront the issues: incomplete information extraction of facial images and weak robustness on large-scale datasets. In this paper, we propose an efficient global and local perception ensemble network with attention units to tackle the above issues. The overall ensemble module has two components: an efficient ensemble and a locality extraction module for perceiving global information and local details simultaneously. The locality extraction module is proposed to attend to local details from facial regions of interest (ROIs). Furthermore, global and local information is fused by our attention units at the decision-level, which enhances the robustness of the network. The conducted experiments validate the effectiveness and efficiency of our method on diverse benchmark datasets. The results demonstrate that our network not only achieves real-time performance but also outperforms state-of-the-art methods on the in-the-wild facial expression datasets.
C1 [He, Zheng; Meng, Bin; Wang, Lining; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Jeon, Gwanggil] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
   [Liu, Zitao] TAL Educ Grp, Beijing, Peoples R China.
C3 Sichuan University; Xidian University; Incheon National University
RP Yang, XM (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.; Jeon, G (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.; Jeon, G (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
EM ggjeon@gmail.com; arielyang@scu.edu.cn
RI yang, xiao/HJI-7815-2023; LI, XIAO/JCE-6169-2023
FU Science Foundation of Sichuan Science and Technology Department
   [2021YFH0119]; Sichuan University [2020SCUNG205]
FX The research in our paper is sponsored by Science Foundation of Sichuan
   Science and Technology Department 2021YFH0119 and the funding from
   Sichuan University under grant 2020SCUNG205
CR [Anonymous], 2014, P 16 INT C MULT INT
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Chen LH, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102520
   Chen LH, 2020, ARTIF INTELL MED, V106, DOI 10.1016/j.artmed.2020.101857
   Cohn J.F., 1995, A computerized analysis of facial expression: Feasibility of automated discrimination
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Fasel B, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P529, DOI 10.1109/ICMI.2002.1167051
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Hewitt C., 2018, Cnn-based facial affect analysis on mobile devices
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C., 2017, 2017 IEEE UNDERGRADU, P1
   Huang XH, 2012, PATTERN RECOGN LETT, V33, P2181, DOI 10.1016/j.patrec.2012.07.015
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Jingru Zhang, 2020, Recent Trends in Intelligent Computing, Communication and Devices. Proceedings of ICCD 2018. Advances in Intelligent Systems and Computing (AISC 1031), P113, DOI 10.1007/978-981-13-9406-5_15
   Jyothirmaye S, 2019, P 14 IEEE INT C AUT, P1
   Kandeel Amany A., 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P699, DOI 10.1007/978-3-030-68780-9_53
   Kim BK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2818346.2830590
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Li M, 2021, IEEE T AFFECT COMPUT, V12, P544, DOI 10.1109/TAFFC.2018.2880201
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mahmood MR, J PHYS C SER, V1804
   Meena HK, 2021, IETE J RES, V67, P667, DOI 10.1080/03772063.2019.1565952
   Miao S, 2019, IEEE ACCESS, V7, P78000, DOI 10.1109/ACCESS.2019.2921220
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Mousavi R, 2015, APPL SOFT COMPUT, V37, P652, DOI 10.1016/j.asoc.2015.09.009
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pan BW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P566, DOI 10.1145/3343031.3351049
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simcock G, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010330
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siqueira H, 2020, AAAI CONF ARTIF INTE, V34, P5800
   Siqueira H, 2018, IEEE INT C INT ROBOT, P1563, DOI 10.1109/IROS.2018.8594276
   Tang B, 2015, IEEE COMPUT INTELL M, V10, P52, DOI 10.1109/MCI.2015.2437512
   Tonguç G, 2020, COMPUT EDUC, V148, DOI 10.1016/j.compedu.2019.103797
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wen GH, 2017, COGN COMPUT, V9, P597, DOI 10.1007/s12559-017-9472-6
   Yaddaden Y., 2020, INT C COMP SYST APPL, P14
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang T., 2017, ADV INTELLIGENT SYST, P345
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
NR 54
TC 5
Z9 5
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5473
EP 5494
DI 10.1007/s11042-022-12321-4
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000784679300024
DA 2024-07-18
ER

PT J
AU Tan, L
   Wang, G
   Jia, FY
   Lian, XF
AF Tan, Li
   Wang, Ge
   Jia, Feiyang
   Lian, Xiaofeng
TI Research status of deep learning methods for rumor detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rumor detection; Deep learning; Social media; Research status
ID FAKE NEWS DETECTION; DETECTION FRAMEWORK; PROPAGATION; INFORMATION;
   CONTEXT
AB To manage the rumors in social media to reduce the harm of rumors in society. Many studies used methods of deep learning to detect rumors in open networks. To comprehensively sort out the research status of rumor detection from multiple perspectives, this paper analyzes the highly focused work from three perspectives: Feature Selection, Model Structure, and Research Methods. From the perspective of feature selection, we divide methods into content feature, social feature, and propagation structure feature of the rumors. Then, this work divides deep learning models of rumor detection into CNN, RNN, GNN, Transformer based on the model structure, which is convenient for comparison. Besides, this work summarizes 30 works into 7 rumor detection methods such as propagation trees, adversarial learning, cross-domain methods, multi-task learning, unsupervised and semi-supervised methods, based knowledge graph, and other methods for the first time. And compare the advantages of different methods to detect rumors. In addition, this review enumerate datasets available and discusses the potential issues and future work to help researchers advance the development of field.
C1 [Tan, Li; Wang, Ge; Jia, Feiyang] Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing 100048, Peoples R China.
   [Lian, Xiaofeng] Beijing Technol & Business Univ, Sch Artificial Intelligence, Beijing 100048, Peoples R China.
C3 Beijing Technology & Business University; Beijing Technology & Business
   University
RP Tan, L (corresponding author), Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing 100048, Peoples R China.
EM tanli@th.btbu.edu.cn; wanggestu@163.com; jfy539@yeah.net;
   lianxf@th.btbu.edu.cn
RI Wang, Ge/AAH-8592-2020
OI Wang, Ge/0000-0002-2656-7705
CR Alam M, 2021, MOBILE NETW APPL, V26, P200, DOI 10.1007/s11036-020-01703-3
   Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Benamira A, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P568, DOI 10.1145/3341161.3342958
   Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   BROOKS G, 1992, SIGPLAN NOTICES, V27, P1, DOI [10.13334/j.0258-8013.pcsee.213043, 10.1145/143103.143108]
   Cao J., 2020, Disinformation, Misinformation, and Fake News in Social Media (Lecture Notes in Social Networks), P141, DOI 10.1007/978-3-030-42699-6_8
   Cao J, 2018, AUTOMATIC RUMO R DET
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Cheema GS, 2021, CEUR WORKSHOP PROC, V2829
   Chen DC, 2021, IEEE T NEUR NET LEAR, V32, P1776, DOI 10.1109/TNNLS.2020.2991088
   Chen JY, 2022, INT J MENT HEALTH AD, V20, P3162, DOI 10.1007/s11469-021-00571-6
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Chen XQ, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102678
   Chen Y., 2015, Master's thesis
   Chen YX, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1121, DOI 10.1145/3357384.3357950
   Cheng MX, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2892, DOI 10.1145/3366423.3380054
   Choi D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57272-3
   Domm P., 2013, CNBC COM, V23, P2062
   Dong M, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P569, DOI 10.1145/3357384.3357994
   Dun YQ, 2021, AAAI CONF ARTIF INTE, V35, P81
   Fan Z, P 2021 C N AM CHAPT, P1692
   Farajtabar M, 2017, PR MACH LEARN RES, V70
   Gao J, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6094
   Gautam A., 2021, Combating Online Hostile Posts in Regional Languages during Emergency Situation, P189, DOI [10.1007/978-3-030-73696-5, DOI 10.1007/978-3-030-73696-5_18]
   Ghanem B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P679
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guacho GB, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P322, DOI 10.1109/ASONAM.2018.8508241
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Guo L, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION PROCESSING (ICIIP 2019), P1, DOI 10.1145/3378065.3378066
   Guo MF, 2021, WEB CONFERENCE 2021: COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2021), P407, DOI 10.1145/3442442.3452328
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Gupta M., 2012, P 2012 SIAM INT C DA, DOI [10.1137/1.9781611972825.14, DOI 10.1137/1.9781611972825.14]
   Han Y., 2020, Graph Neural Networks with Continual Learning for Fake News Detection from Social Media
   Horne Benjamin, 2017, 11 INT AAAI C WEB SO, V11
   Hosseinzadeh S, 2019, POLYM BULL, V76, P4827, DOI 10.1007/s00289-018-2618-1
   Hu LM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P754
   Huang D-W, 2020, IEEE SYST J
   Jahanbakhsh-Nagadeh Z, 2021, MULTIMED TOOLS APPL, V80, P35267, DOI 10.1007/s11042-020-10077-3
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2016, AAAI CONF ARTIF INTE, P2972
   Jindal S, 2020, NEWSBAG MULTIM ODAL
   Karpathy A, 2014, ADV NEUR IN, V27
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Khoo LMS, 2020, AAAI CONF ARTIF INTE, V34, P8783
   Kochkina E, 2018, P 27 INT C COMP LING
   Kompatsiaris Yiannis, 2015, MediaEval, V3, P7
   Kumar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5047
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lao A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3178, DOI 10.1145/3442381.3450016
   Lazer D, 2014, SCIENCE, V343, P1203, DOI 10.1126/science.1248506
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Li QZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1173
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Lin HB, 2020, PR INT CONF DATA SC, P300, DOI 10.1109/DSAA49011.2020.00043
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Liu Y, 2018, AAAI CONF ARTIF INTE, P354
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J., 2020, P 28 INT C COMPUTATI, P5455, DOI [10.18653/v1/2020.coling-main.476, DOI 10.18653/V1/2020.COLING-MAIN.476]
   Ma J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P585, DOI 10.1145/3184558.3188729
   Ma J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2561
   Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Meeker M, 2018, INTERNET TRENDS 2018
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mishra R, 2020, P IEEECVF C COMPUTER, P652
   Mishra R, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P196, DOI 10.1145/3341981.3344229
   Monti Federico, 2019, Fake News Detection on SocialMedia using Geometric Deep Learning
   Nakamura K, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6149
   Tam NT, 2019, PROC VLDB ENDOW, V12, P1016, DOI 10.14778/3329772.3329778
   Vo N, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P335, DOI 10.1145/3331184.3331248
   Nishi R, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0334-0
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Pawar MD, 2021, MULTIMED TOOLS APPL, V80, P15563, DOI 10.1007/s11042-020-10329-2
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rosenfeld N, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1018, DOI 10.1145/3366423.3380180
   Rubin VL, 2016, P 2 WORKSH COMP APPR, P7
   Shao CC, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P745, DOI 10.1145/2872518.2890098
   Shu K., 2020, P INT AAAI C WEB SOC, P626, DOI DOI 10.1609/ICWSM.V14I1.7329
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Silva A, 2021, AAAI CONF ARTIF INTE, V35, P557
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal S, 2020, AAAI CONF ARTIF INTE, V34, P13915
   Staszewski P, 2022, IEEE T NEUR NET LEAR, V33, P7913, DOI 10.1109/TNNLS.2021.3084633
   Sujana Y, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P18
   Tacchini Eugenio, 2017, ARXIV170407506, P1, DOI [10.48550/arXiv.1704.07506, DOI 10.1257/JEP.31.2.211]
   Thorne James, 2018, P 2018 C N AM CHAPT, P809, DOI DOI 10.18653/V1/N18-1074
   Tu KF, 2021, INFORM SCIENCES, V560, P137, DOI 10.1016/j.ins.2020.12.080
   Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45
   Vaswani A, 2017, ADV NEUR IN, V30
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2915
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Williams ML, 2017, SOCIOLOGY, V51, P1149, DOI 10.1177/0038038517708140
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Xu K, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337923
   Yang F., 2012, P ACM SIGKDD WORKSHO, P1
   Yang KC, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211013861
   Yang S, 2019, AAAI CONF ARTIF INTE, P5644
   Yang XY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1417
   Yang Y., 2018, Ti-cnn: Convolutional neural networks for fake news detection
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yang ZL, 2019, ADV NEUR IN, V32
   Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901
   Yu JF, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1392
   Yuan CY, 2019, IEEE DATA MINING, P796, DOI 10.1109/ICDM.2019.00090
   Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673
   Zhang H, 2021, IEEE T MULTIMEDIA, P1
   Zhang HW, 2021, IEEE T MULTIMEDIA, V23, P4441, DOI 10.1109/TMM.2020.3042055
   Zhang HW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1942, DOI 10.1145/3343031.3350850
   Zhang N, 2014, PHYSICA A, V415, P333, DOI 10.1016/j.physa.2014.07.023
   Zhang XY, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3465, DOI 10.1145/3442381.3450004
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zubiaga A., 2016, arXiv
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 127
TC 6
Z9 6
U1 15
U2 116
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2941
EP 2982
DI 10.1007/s11042-022-12800-8
EA APR 2022
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000784679300021
PM 35469150
OA Green Submitted, Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zaffar, A
   Hussain, SMA
AF Zaffar, Asma
   Hussain, S. M. Aalim
TI Modeling and prediction of KSE-100 index closing based on news
   sentiments: an applications of machine learning model and ARMA (p, q)
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE KSE-100 index; ARMA (p; Q); RMSE; MAE; Theil's U-statistics
AB The main financial markets of every country are stock exchange and consider as an imperative cause for the corporations to increase capital. The novelty of this study to explore machine learning techniques when applied to financial stock market data, and to understand how machine learning algorithms can be applied and compare the result with time series analysis to real lifetime series data and helpful for any investor. Investors are constantly reviewing past pricing history and using it to influence their future investment decisions. The another novelty of this study, using news sentiments, the values will be processed into lists displaying and representing the stock and predicting the future rates to describe the market, and to compare investments, which will help to avoid uncertainty amongst the investors regarding the stock index. Using artificial neural network technique for prediction for KSE 100 index data on closing day. In this regard, six months' data cycle trained the data and apply the statistical interference using a ARMA (p, q) model to calculate numerical result. The novelty of this study to find the relation between them either they are strongly correlated or not, using machine learning techniques and ARMA (p, q) process to forecast the behavior KSE 100 index cycles. The adequacy of model describes via least values Akaike information criterion (AIC), Bayesian Schwarz information criterion (SIC) and Hannan Quinn information criterion (HIC). Durbin- Watson (DW) test is also applied. DW values (< 2) shows that all cycles are strongly correlated. Most of the KSE-100 index cycles expresses that the appropriate model is ARMA (2,1). Cycle's 2nd,3rd,4th and 5th shows that ARMA (3,1) is best fitted. Cycle 8th is shows ARMA (1,1) best fit and cycle 12th shows that the most appropriate model is ARMA (4,1). Diagnostic checking tests like Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Theil's U-Statistics are used to predict KSE-100 index cycles. Theil's U-Statistics demonstrate that each cycle is strongly correlated to previous one.
C1 [Zaffar, Asma; Hussain, S. M. Aalim] Sir Syed Univ Engn & Technol, Dept Math, Karachi, Pakistan.
C3 Sir Syed University of Engineering & Technology
RP Zaffar, A (corresponding author), Sir Syed Univ Engn & Technol, Dept Math, Karachi, Pakistan.
EM aszafar@ssuet.edu.pk
OI Zaffar, Asma/0000-0002-2307-6572
CR Agrawal R., 2013, ArXiv Prepr. ArXiv, V1302, P1
   Anjum S, 2020, FUTUR BUS J, V6, DOI 10.1186/s43093-019-0006-4
   Box GEP., 1994, Time series analysis; forecasting and control
   Cheema A, 2008, WEB BASEDSTOCK FOREC
   Hegazy O., 2013, INT J COMPUT SCI TEL, V4
   Hipel K.W., 2005, TIME SERIES MODELLIN
   Islam RS, C 2016 INT C INN SCI
   Islam RS, 2016, C INT C ADV INF COMM
   Jain R, 2019, WEB SCRAPING SITE PA
   Jenkins JM., 1970, NC AGR EXT CIRC, V44, P1
   Koenig R, 2019, NLP BEGINNERS CLEANI
   Moghaddam AH, 2016, J EC
   Rasel RI, 2015, INT J COMPUT INTELL
   Usmani M, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P322, DOI 10.1109/ICCOINS.2016.7783235
   Yetis Y, 2014, WORLD AUT C
   Yule GU, 1927, PHILOS T R SOC LOND, V226, P267, DOI 10.1098/rsta.1927.0007
NR 16
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33311
EP 33333
DI 10.1007/s11042-022-13052-2
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000783091400003
PM 35463220
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU El-Balka, RM
   Saleh, AI
   Abdullah, AA
   Saki, N
AF El-Balka, Rana Mohamed
   Saleh, Ahmed, I
   Abdullah, Ahmed A.
   Saki, Noha
TI Enhancing the performance of smart electrical grids using data mining
   and fuzzy inference engine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Data mining; Features selection (FS); Fog computing;
   Internet of things (IoT); Load forecasting; Smart grids
ID FEATURE-SELECTION; CLASSIFICATION; MANAGEMENT; ALGORITHM; NETWORKS;
   INTERNET; USER
AB This paper is about enhancing the smart grid by proposing a new hybrid feature-selection method called feature selection-based ranking (FSBR). In general, feature selection is to exclude non-promising features out from the collected data at Fog. This could be achieved using filter methods, wrapper methods, or a hybrid. Our proposed method consists of two phases: filter and wrapper phases. In the filter phase, the whole data go through different ranking techniques (i.e., relative weight ranking, effectiveness ranking, and information gain ranking) The results of these ranks are sent to a fuzzy inference engine to generate the final ranks. In the wrapper phase, data is being selected based on the final ranks and passed on three different classifiers (i.e., Naive Bayes, Support Vector Machine, and neural network) to select the best set of the features based on the performance of the classifiers. This process can enhance the smart grid by reducing the amount of data being sent to the cloud, decreasing computation time, and decreasing data complexity. Thus, the FSBR methodology enables the user load forecasting (ULF) to take a fast decision, the fast reaction in short-term load forecasting, and to provide a high prediction accuracy. The authors explain the suggested approach via numerical examples. Two datasets are used in the applied experiments. The first dataset reported that the proposed method was compared with six other methods, and the proposed method was represented the best accuracy of 91%. The second data set, the generalization data set, reported 90% accuracy of the proposed method compared to fourteen different methods.
C1 [El-Balka, Rana Mohamed; Saleh, Ahmed, I; Saki, Noha] Mansoura Univ, Fac Engn, Comp Engn & Syst Dept, Mansoura, Egypt.
   [Abdullah, Ahmed A.] Delta Univ, Fac Engn, Commun & Comp Engn, Talkha, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University; Delta University for
   Science & Technology
RP El-Balka, RM (corresponding author), Mansoura Univ, Fac Engn, Comp Engn & Syst Dept, Mansoura, Egypt.
EM rana.m.elbalka@gmail.com; aisaleh@yahoo.com;
   ahmed.abdelaleem@deltauniv.edu.eg; Nohasakr83@gmail.com
RI A. Abdullah, Ahmed/KCK-2132-2024
OI A. Abdullah, Ahmed/0000-0003-1088-8608; El-Balka,
   Rana/0000-0002-8137-7752
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abualigah L., 2021, CLUSTER COMPUT, V24, P2161, DOI DOI 10.1007/s10586-021-03254-y
   Ahmad A, 2015, APPL SCI-BASEL, V5, P1756, DOI 10.3390/app5041756
   Ahmed S, 2018, IEEE ACCESS, V6, P27518, DOI 10.1109/ACCESS.2018.2835527
   Al-Turjman F, 2019, FUTURE GENER COMP SY, V96, P579, DOI 10.1016/j.future.2019.02.012
   Alhamidi MR, 2020, INFORMATION, V11, DOI 10.3390/info11010038
   Ali SH, 2020, WIRELESS PERS COMMUN, V113, P1917, DOI 10.1007/s11277-020-07300-7
   Bahassine S, 2020, J KING SAUD UNIV-COM, V32, P225, DOI 10.1016/j.jksuci.2018.05.010
   Bellavista P, 2019, PERVASIVE MOB COMPUT, V52, P71, DOI 10.1016/j.pmcj.2018.12.007
   Cilia ND, 2019, PATTERN RECOGN LETT, V121, P77, DOI 10.1016/j.patrec.2018.04.007
   da Costa NL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114312
   Darwish A, 2019, J AMB INTEL HUM COMP, V10, P4151, DOI 10.1007/s12652-017-0659-1
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Dileep G, 2020, RENEW ENERG, V146, P2589, DOI 10.1016/j.renene.2019.08.092
   Gan JZ, 2020, PATTERN RECOGN LETT, V132, P30, DOI 10.1016/j.patrec.2018.08.029
   Ghobaei-Arani M, 2020, J GRID COMPUT, V18, P1, DOI 10.1007/s10723-019-09491-1
   Ghosh P, 2021, IEEE ACCESS, V9, P19304, DOI 10.1109/ACCESS.2021.3053759
   Goulden M, 2014, ENERGY RES SOC SCI, V2, P21, DOI 10.1016/j.erss.2014.04.008
   Hafeez G, 2020, IEEE ACCESS, V8, P96210, DOI 10.1109/ACCESS.2020.2985732
   Han W, 2018, ISPRS J PHOTOGRAMM, V145, P23, DOI 10.1016/j.isprsjprs.2017.11.004
   Hancer E, 2019, SOFT COMPUT, V23, P5233, DOI 10.1007/s00500-018-3545-7
   Huang YK, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106202
   Javadzadeh G, 2020, WIREL NETW, V26, P1433, DOI 10.1007/s11276-019-02208-y
   Kumar P, 2019, IEEE COMMUN SURV TUT, V21, P2886, DOI 10.1109/COMST.2019.2899354
   Kurniabudi, 2020, IEEE ACCESS, V8, P132911, DOI 10.1109/ACCESS.2020.3009843
   Lim H, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107663
   Liu HY, 2019, IEEE-CAA J AUTOMATIC, V6, P703, DOI 10.1109/JAS.2019.1911447
   Mafarja M, 2019, EXPERT SYST APPL, V117, P267, DOI 10.1016/j.eswa.2018.09.015
   Mafarja MM, 2019, SOFT COMPUT, V23, P6249, DOI 10.1007/s00500-018-3282-y
   Masoudi-Sobhanzadeh Y, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2754-0
   Mekki Kais, 2019, ICT Express, V5, P1, DOI 10.1016/j.icte.2017.12.005
   Mukherjee M, 2018, IEEE COMMUN SURV TUT, V20, P1826, DOI 10.1109/COMST.2018.2814571
   Neggaz N, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113103
   Niu WJ, 2021, ENVIRON RES LETT, V16, DOI 10.1088/1748-9326/abeeb1
   Ozger M, 2018, MOBILE NETW APPL, V23, P956, DOI 10.1007/s11036-017-0961-3
   Pande SK, 2021, CMC-COMPUT MATER CON, V67, P2647, DOI 10.32604/cmc.2021.015026
   Priyanka E.B., 2021, Pet. Res., V6, P77, DOI 10.1016/j.ptlrs.2020.10.001
   Rabie AH, 2019, CLUSTER COMPUT, V22, P241, DOI 10.1007/s10586-018-2848-x
   Rai S, 2021, INT J SUSTAIN ENERGY, V40, P821, DOI 10.1080/14786451.2021.1873339
   Rehmani MH, 2019, IEEE COMMUN SURV TUT, V21, P2637, DOI 10.1109/COMST.2019.2908266
   Sahin DÖ, 2019, AUTOMATIKA-UK, V60, P162, DOI 10.1080/00051144.2019.1602293
   Saleh AI, 2015, KNOWL-BASED SYST, V75, P192, DOI 10.1016/j.knosys.2014.12.002
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Shaban WM, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106270
   Shahzad K, 2021, ENERGIES, V14, DOI 10.3390/en14040881
   Singer G, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113375
   Singh SP, 2019, J SUPERCOMPUT, V75, P2070, DOI 10.1007/s11227-018-2701-2
   Tang B, 2020, NEUROCOMPUTING, V399, P48, DOI 10.1016/j.neucom.2020.02.098
   Tom RJ, 2020, SUSTAIN ENERGY TECHN, V38, DOI 10.1016/j.seta.2020.100653
   Tushar W, 2016, IEEE WIREL COMMUN, V23, P70, DOI 10.1109/MWC.2016.1400377RP
   Verma A, 2020, I CONF VLSI DESIGN, P1, DOI 10.1109/VLSID49098.2020.00018
   Wan YT, 2020, IEEE T GEOSCI REMOTE, V58, P3601, DOI 10.1109/TGRS.2019.2958812
   Wang XZ, 2019, IEEE ACCESS, V7, P151525, DOI 10.1109/ACCESS.2019.2948095
   Wei GF, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106337
   Yoldas Y, 2017, RENEW SUST ENERG REV, V72, P205, DOI 10.1016/j.rser.2017.01.064
   Yousaf A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13116199
   Zhang XL, 2018, NEUROCOMPUTING, V275, P2426, DOI 10.1016/j.neucom.2017.11.016
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhou HF, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113842
   Zhou P, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105417
   Zhu YH, 2018, PATTERN RECOGN LETT, V109, P89, DOI 10.1016/j.patrec.2017.08.018
NR 61
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33017
EP 33049
DI 10.1007/s11042-022-12987-w
EA APR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000783091300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Al Chami, Z
   Abou Jaoude, C
   Chbeir, R
   Barhamgi, M
   Alraja, MN
AF Al Chami, Zahi
   Abou Jaoude, Chady
   Chbeir, Richard
   Barhamgi, Mahmoud
   Alraja, Mansour Naser
TI A No-Reference and Full-Reference image quality assessment and
   enhancement framework in real-time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Real time image processing; Image functions
   adaptation; Convolutional neural network; Face alignment; Image quality
   enhancement
AB These days, social media holds a large portion of our daily lives. Millions of people post their images using a social media platform. The enormous amount of images shared on social network presents serious challenges and requires massive computing resources to ensure efficient data processing. However, images are subject to a wide range of distortions in real application scenarios during the processing, transmission, sharing, or combination of many factors. So, there is a need to guarantee acceptable delivery content, even though some distorted images do not have access to their original version. In this paper, we present a framework developed to process a large amount of images in real-time while estimating and assisting in the enhancement of the No-Reference and Full-Reference image quality. Our quality evaluation is measured using a Convolutional Neural Network, which is tuned by the objective quality methods, in addition to the face alignment metric and enhanced with the help of a Super-Resolution Model. A set of experiments is conducted to evaluate our proposed approach.
C1 [Al Chami, Zahi; Abou Jaoude, Chady] Antonine Univ, Fac Engn, TICKET Lab, Beirut, Lebanon.
   [Al Chami, Zahi; Chbeir, Richard] Univ Pau & Pays Adour, LIUPPA, E2S UPPA, Bayonne, France.
   [Barhamgi, Mahmoud] Claude Bernard Univ Lyon I, Dept Comp Sci, Lyon, France.
   [Alraja, Mansour Naser] Dhofar Univ, Coll Commerce & Business Adm, Dept Management Informat Syst, Salalah, Oman.
C3 Universite de Pau et des Pays de l'Adour; Universite Claude Bernard Lyon
   1; Dhofar University
RP Al Chami, Z (corresponding author), Antonine Univ, Fac Engn, TICKET Lab, Beirut, Lebanon.; Al Chami, Z (corresponding author), Univ Pau & Pays Adour, LIUPPA, E2S UPPA, Bayonne, France.
EM zahi.chami@ua.edu.lb; chady.aboujaoude@ua.edu.lb;
   richard.chbeir@univ-pau.fr; mahmoud.barhamgi@univ-lyon1.fr;
   malraja@du.edu.om
RI Alraja, Mansour/IAP-8215-2023; Chbeir, Richard/A-1071-2013; Alraja,
   Mansour/N-3186-2015
OI Alraja, Mansour/0000-0003-3492-8838
FU National Council for Scientific Research in Lebanon (CNRS-L); Agence
   universitaire de la Francophonie (AUF); Antonine University
FX This work is jointly funded from the National Council for Scientific
   Research in Lebanon (CNRS-L), the Antonine University, and the Agence
   universitaire de la Francophonie (AUF).
CR Abaza A, 2014, IET BIOMETRICS, V3, P314, DOI 10.1049/iet-bmt.2014.0022
   Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420
   Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551
   Al Boum B, 2011, SECRYPT 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, P345
   [Anonymous], 2018, APACHE STORM CLUSTER
   [Anonymous], 2010, P 12 INT C INF INT W, DOI DOI 10.1145/1967486.1967649
   [Anonymous], SOCIAL MEDIA STAT 20
   [Anonymous], 2015, APACHE STORM CONCEPT
   [Anonymous], 2015, SETTING DEV ENV
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Chami Z, 2019, REAL TIME MULTIMEDIA, P270
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   De Bruyne S, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN IMAGE AND SIGNAL PROCESSING, P380, DOI 10.1109/CIISP.2007.369199
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dutta Abhishek, 2015, ARXIV151007119
   Fan J., 2005, Proceedings of the 14th ACM international conference on Information and knowledge management, P609
   Gang Z, 2004, IEEE IMAGE PROC, P2777
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He LH, 2012, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2012.6247795
   Herranz L, 2007, MULTIMEDIA SYST, V13, P103, DOI 10.1007/s00530-007-0090-0
   Hou L., 2016, ARXIV161105916
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kephart JO, 2007, IEEE INTERNET COMPUT, V11, P40, DOI 10.1109/MIC.2007.2
   Kim CS, 2009, IEICE T INF SYST, VE92D, P93, DOI 10.1587/transinf.E92.D.93
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Majumdar S, 2016, IMAGE SUPER RESOLUTI
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Mu Mu, 2009, International Journal of Internet Protocol Technology, V4, P54, DOI 10.1504/IJIPT.2009.024170
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Nguyen, 2011, ARXIV11122095
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Prangl M, 2007, IEEE T CIRC SYST VID, V17, P719, DOI 10.1109/TCSVT.2007.896650
   Rippel O, 2017, PR MACH LEARN RES, V70
   Rueangprathum Atchara, 2016, Journal of Advances in Information Technology, V7, P182, DOI 10.12720/jait.7.3.182-185
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Vega MT, 2017, IEEE SIGNAL PROC LET, V24, P736, DOI 10.1109/LSP.2017.2691160
   Venkatesh MV, 2009, PATTERN RECOGN LETT, V30, P168, DOI 10.1016/j.patrec.2008.03.011
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wickramasuriya J., 2004, MULTIMEDIA '04, P48, DOI DOI 10.1145/1027527.1027537
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zheng Lian, 2020, International Journal of Automation and Computing, V17, P96, DOI 10.1007/s11633-019-1176-9
NR 60
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32491
EP 32517
DI 10.1007/s11042-022-12334-z
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600011
DA 2024-07-18
ER

PT J
AU Li, G
   Togo, R
   Ogawa, T
   Haseyama, M
AF Li, Guang
   Togo, Ren
   Ogawa, Takahiro
   Haseyama, Miki
TI Dataset complexity assessment based on cumulative maximum scaled area
   under Laplacian spectrum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dataset complexity assessment; Classification problem; Laplacian
   spectrum; Spectral clustering
ID CLASSIFICATION; FRAMEWORK
AB Dataset complexity assessment aims to predict classification performance on a dataset with complexity calculation before training a classifier, which can also be used for classifier selection and dataset reduction. The training process of deep convolutional neural networks (DCNNs) is iterative and time-consuming because of hyperparameter uncertainty and the domain shift introduced by different datasets. Hence, it is meaningful to predict classification performance by assessing the complexity of datasets effectively before training DCNN models. This paper proposes a novel method called cumulative maximum scaled Area Under Laplacian Spectrum (cmsAULS), which can achieve state-of-the-art complexity assessment performance on six datasets.
C1 [Li, Guang] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
   [Togo, Ren] Hokkaido Univ, Educ & Res Ctr Math & Data Sci, Sapporo, Hokkaido, Japan.
   [Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Fac Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Hokkaido University; Hokkaido University; Hokkaido University
RP Li, G (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
EM guang@lmd.ist.hokudai.ac.jp; togo@lmd.ist.hokudai.ac.jp;
   ogawa@lmd.ist.hokudai.ac.jp; miki@ist.hokudai.ac.jp
RI Li, Guang/AAU-8927-2021
OI Li, Guang/0000-0003-2898-2504
FU AMED [JP21zf0127004]; Grants-in-Aid for Scientific Research [21H03456]
   Funding Source: KAKEN
FX This work was partly supported by AMED Grant Number JP21zf0127004. This
   study was conducted on the Data Science Computing System of Education
   and Research Center for Mathematical and Data Science, Hokkaido
   University.
CR Anwar N, 2014, STAT ANAL DATA MIN, V7, P194, DOI 10.1002/sam.11228
   Baumgartner R, 2006, PATTERN RECOGN LETT, V27, P1383, DOI 10.1016/j.patrec.2006.01.006
   BEALS EW, 1984, ADV ECOL RES, V14, P1, DOI 10.1016/S0065-2504(08)60168-3
   Binder K., 1993, Comput. Phys., V7, P156
   Borg I., 2005, MODERN MULTIDIMENSIO, DOI DOI 10.18637/JSS.V014.B04
   Branchaud-Charron F, 2019, PROC CVPR IEEE, P3210, DOI 10.1109/CVPR.2019.00333
   Brun AL, 2018, PATTERN RECOGN, V76, P175, DOI 10.1016/j.patcog.2017.10.038
   Bulatov Y., 2011, Notmnist dataset
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Coates A., 2011, P 14 INT C ART INT S, P215
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duin RP, 2006, OBJECT REPRESENTATIO
   Gal Y, 2016, PR MACH LEARN RES, V48
   Garcia LPF, 2015, NEUROCOMPUTING, V160, P108, DOI 10.1016/j.neucom.2014.10.085
   Guang Li, 2020, 2020 IEEE 9th Global Conference on Consumer Electronics (GCCE), P667, DOI 10.1109/GCCE50665.2020.9291997
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289, DOI 10.1109/34.990132
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Jebara T, 2004, J MACH LEARN RES, V5, P819
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Leyva E, 2015, IEEE T KNOWL DATA EN, V27, P354, DOI 10.1109/TKDE.2014.2327034
   Li G, 2021, P IEEE INT C CONS EL
   Li Guang, 2021, ARXIV210402864
   Li Guang, 2021, P IEEE GLOB C CONS E
   Liu Z., 2019, P INT C LEARNING REP
   Lorena AC, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3347711
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mohar B, 1997, NATO ADV SCI I C-MAT, V497, P225
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Nowakowska E., 2014, ARXIV14077172
   Orriols-Puig A., 2010, DOCUMENTATION DATA C, V196, P1
   Pascual-Triana JD, 2020, ARXIV200707935
   Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070
   Tan MX, 2019, PR MACH LEARN RES, V97
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334, DOI 10.1109/TPAMI.2005.165
   Wang W, 2014, IEEE COMPUT SOC CONF, P496, DOI 10.1109/CVPRW.2014.79
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
NR 43
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32287
EP 32303
DI 10.1007/s11042-022-13027-3
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bindal, N
   Ghumaan, RS
   Sohi, PJS
   Sharma, N
   Joshi, H
   Garg, B
AF Bindal, Nishant
   Ghumaan, Rajanbir Singh
   Sohi, Prateek Jeet Singh
   Sharma, Nikhil
   Joshi, Hemdutt
   Garg, Bharat
TI A systematic review of state-of-the-art noise removal techniques in
   digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Median filters; Mean filters; Salt and pepper noise; Impulse noise;
   Image restoration and denoising
ID HIGH-DENSITY SALT; WEIGHTED MEDIAN FILTER; PEPPER NOISE; IMPULSE NOISE;
   MEAN FILTER
AB Digital Image processing is a subcategory of digital signal processing that lays emphasis on the study of processing techniques used for enhancement or restoration. De-noising of images corrupted with various types of noises falls into this category. De-noising is mainly performed to enhance the understandability of an affected image. Images captured with faulty equipment or being transmitted over long distances are highly prone to be depraved by impulse noise, so, various techniques are presented for removal of this noise from images. Each of the presented technique has its own merits and demerits. This paper presents a comprehensive comparative analysis of these techniques over a wide range of noise densities. All the filtering techniques are implemented in MATLAB and simulated with standard benchmark image data and qualitative metrics namely Peak Signal to Noise Ratio (PSNR) and Structural Similarity Index (SSIM) are evaluated and compared. Therefore, this paper presents a comprehensive comparative analysis of various state-of-the-art noise removal techniques.
C1 [Bindal, Nishant; Ghumaan, Rajanbir Singh; Sohi, Prateek Jeet Singh; Sharma, Nikhil; Joshi, Hemdutt; Garg, Bharat] Thapar Inst Engn & Technol Patiala, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bindal, N (corresponding author), Thapar Inst Engn & Technol Patiala, Patiala, Punjab, India.
EM nishant.binda11999@gmail.com; ghumaan1999@gmail.com; sohipjss@gmail.com;
   nikhil.sharma4@yahoo.com; hemdutt.joshi@thapar.edu;
   bharat.garg@thapar.edu
RI Garg, Bharat/GPP-5755-2022
OI Garg, Bharat/0000-0002-2904-3720; Sharma, Nikhil/0000-0003-1681-7907
FU Thapar Institute of Engineering Technology (TIET), Patiala, India
FX This work is supported by Thapar Institute of Engineering Technology
   (TIET), Patiala, India.
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Balasubramanian G, 2016, IMAGING SCI J, V64, P241, DOI 10.1080/13682199.2016.1168144
   Balasubramanian G, 2016, AEU-INT J ELECTRON C, V70, P471, DOI 10.1016/j.aeue.2016.01.013
   Bhadouria VS, 2014, SIGNAL IMAGE VIDEO P, V8, P71, DOI 10.1007/s11760-013-0487-5
   Deivalakshmi S, 2016, AEU-INT J ELECTRON C, V70, P757, DOI 10.1016/j.aeue.2016.03.002
   Deivalakshmi S., 2010, 2010 5th International Conference on Industrial and Information Systems (ICIIS 2010), P309, DOI 10.1109/ICIINFS.2010.5578687
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Enginoglu S, 2019, MULTIMED TOOLS APPL, V78, P35401, DOI 10.1007/s11042-019-08110-1
   Erkan U, 2020, IET IMAGE PROCESS, V14, P1291, DOI 10.1049/iet-ipr.2019.0398
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Faragallah OS, 2016, AEU-INT J ELECTRON C, V70, P1034, DOI 10.1016/j.aeue.2016.04.018
   Garg B, 2020, INT J AD HOC UBIQ CO, V35, P84, DOI 10.1504/IJAHUC.2020.109795
   Garg B, 2020, MULTIMED TOOLS APPL, V79, P32305, DOI 10.1007/s11042-020-09557-3
   Garg B, 2020, SIGNAL IMAGE VIDEO P, V14, P1555, DOI 10.1007/s11760-020-01695-3
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Lu CT, 2016, PATTERN RECOGN LETT, V80, P188, DOI 10.1016/j.patrec.2016.06.026
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Meher SK, 2014, AEU-INT J ELECTRON C, V68, P1173, DOI 10.1016/j.aeue.2014.06.006
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Roy A, 2017, AEU-INT J ELECTRON C, V72, P114, DOI 10.1016/j.aeue.2016.12.006
   Satti P, 2020, IEEE SIGNAL PROC LET, V27, P1475, DOI 10.1109/LSP.2020.3016868
   Sharma N, 2021, WIRELESS PERS COMMUN, V119, P1975, DOI 10.1007/s11277-021-08314-5
   Singh KM, 2002, IEEE ICIT' 02: 2002 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS I AND II, PROCEEDINGS, P980
   Sohi Prateek Jeet Singh, 2021, Innovations in Computational Intelligence and Computer Vision. Proceedings of ICICV 2020. Advances in Intelligent Systems and Computing (AISC 1189), P150, DOI 10.1007/978-981-15-6067-5_18
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Veerakumar T, 2014, SIGNAL IMAGE VIDEO P, V8, P159, DOI 10.1007/s11760-013-0517-3
   Vijaykumar VR, 2014, AEU-INT J ELECTRON C, V68, P1145, DOI 10.1016/j.aeue.2014.06.002
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 32
TC 3
Z9 3
U1 13
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31529
EP 31552
DI 10.1007/s11042-022-12847-7
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336100004
DA 2024-07-18
ER

PT J
AU Huang, HQ
   Cheng, DS
AF Huang, Huiqing
   Cheng, Dongsheng
TI A secure image compression-encryption algorithm using DCT and
   hyperchaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression and encryption; DCT; Hyperchaotic system; Arnold
   transform
ID CHAOTIC SYSTEM
AB Nowadays, thanks to the rapid development of communication network technology, the multimedia data with image and video as the carrier increases exponentially. Therefore, how to transmit data efficiently and securely has become an important research topic. In order to reduce the amount of data during image transmission and ensure the security of images, we propose a joint image compression and encryption method based on discrete cosine transform (DCT) and hyperchaotic system (HCS) in this paper. This scheme consists of two stages, i.e., compression and encryption. In the compression stage, plain-image is transformed by cosine transform in blocks, and then only a small number of DCT coefficients in the upper left corner of each block are retained to achieve the purpose of compression. In the encryption stage, the compressed image is first divided into blocks, and then each block is permutated by Arnold transformation to achieve a local scrambling effect. Next, the scrambled matrix generated by HCS is used to scramble the image after Arnold transformation. By local and global scrambling, the correlation between adjacent pixels can be destroyed effectively. Finally, the chaotic sequence generated by HCS is used to diffuse the scrambled image, and the cipher image is obtained. Moreover, our algorithm exhibits excellent compression performance compared with existing related algorithms. The result of experiment test indicate that our approach possesses excellent image compression ability and cryptographic properties.
C1 [Huang, Huiqing] Jiaying Univ, Sch Math, Meizhou 514015, Guangdong, Peoples R China.
   [Cheng, Dongsheng] Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen 518172, Guangdong, Peoples R China.
C3 Jiaying University; Shenzhen Institute of Information Technology
RP Huang, HQ (corresponding author), Jiaying Univ, Sch Math, Meizhou 514015, Guangdong, Peoples R China.
EM hq-huang2@126.com; chengds@sziit.edu.cn
RI huang, huiqing/ISA-7228-2023
FU Characteristic Innovation Project from the Educational Department of
   Guangdong Province [2018GKTSCX043, 2019KTSCX168]
FX All the authors are deeply grateful to the editors for smooth and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. This work is supported by the Characteristic Innovation
   Project from the Educational Department of Guangdong Province (Grant No.
   2018GKTSCX043, 2019KTSCX168).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2009, EUR J SCI RES
   Boriga Radu Eugen, 2014, IAENG International Journal of Computer Science, V41, P249
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   Fang ZJ, 2011, IEEE SYST J, V5, P584, DOI 10.1109/JSYST.2011.2165602
   Feng W, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2880590
   Gan ZH, 2020, NEURAL COMPUT APPL, V32, P14113, DOI 10.1007/s00521-020-04808-8
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Ge X., 2010, 2010 2 IEEE INT C IN
   Hamdi M, 2017, SIGNAL PROCESS, V131, P514, DOI 10.1016/j.sigpro.2016.09.011
   Haque AKMB, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12753
   Hassaballah M., 2020, Digital Media Steganography: Principles, Algorithms, and Advances
   Houssein EH, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107348
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang HQ, 2019, SOFT COMPUT, V23, P7045, DOI 10.1007/s00500-018-3345-0
   Huang HQ, 2017, IET IMAGE PROCESS, V11, P211, DOI 10.1049/iet-ipr.2016.0552
   Khan S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12101659
   Kumar V, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5512879
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Li PY, 2019, J VIS COMMUN IMAGE R, V58, P12, DOI 10.1016/j.jvcir.2018.11.018
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Oliva D, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115481
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Sateesh S. V. V., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P442, DOI 10.1109/ICSCCN.2011.6024591
   Sen Jaydip, 2009, International Journal of Communication Networks and Information Security, V1, P59
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Socek D, 2005, FIRST INTERNATIONAL CONFERENCE ON SECURITY AND PRIVACY FOR EMERGING AREAS IN COMMUNICATIONS NETWORKS, PROCEEDINGS, P406, DOI 10.1109/SECURECOMM.2005.39
   Wang R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102699
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1417, DOI 10.1007/s11071-015-2579-y
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Yanchuk S, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.056235
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Yen WC, 2005, Fourth Annual ACIS International Conference on Computer and Information Science, Proceedings, P489
   Yuen CH, 2011, APPL SOFT COMPUT, V11, P5092, DOI 10.1016/j.asoc.2011.05.050
   Zhang LY, 2012, J SYST SOFTWARE, V85, P2077, DOI 10.1016/j.jss.2012.04.002
   Zhang M, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043008
   Zhang XJ, 2013, SIGNAL PROCESS, V93, P2422, DOI 10.1016/j.sigpro.2013.03.017
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 49
TC 5
Z9 5
U1 8
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31329
EP 31347
DI 10.1007/s11042-021-11796-x
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700008
DA 2024-07-18
ER

PT J
AU Garcia-Espinosa, FJ
   Concha, D
   Pantrigo, JJ
   Cuesta-Infante, A
AF Garcia-Espinosa, Francisco J.
   Concha, David
   Pantrigo, Juan J.
   Cuesta-Infante, Alfredo
TI Visual classification of dumpsters with capsule networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Capsule networks; Image recognition; Garbage management; Smart cities
AB Garbage management is an essential task in the everyday life of a city. In many countries, dumpsters are owned and deployed by the public administration. An updated what-and-where list is in the core of the decision making process when it comes to remove or renew them. Moreover, it may give extra information to other analytics in a smart city context. In this paper, we present a capsule network-based architecture to automate the visual classification of dumpsters. We propose different network hyperparameter settings, such as reducing convolutional kernel size and increasing convolution layers. We also try several data augmentation strategies, as crop and flip image transformations. We succeed in reducing the number of network parameters by 85% with respect to the best previous method, thus decreasing the required training time and making the whole process suitable for low cost and embedded software architectures. In addition, the paper provides an extensive experimental analysis including an ablation study that illustrates the contribution of each component in the proposed method. Our proposal is compared with the state-of-the-art method, which is based on a Google Inception V3 architecture pretrained with Imagenet. Experimental results show that our proposal achieves a 95.35% accuracy, 2.35% over the previous best method.
C1 [Garcia-Espinosa, Francisco J.; Concha, David; Pantrigo, Juan J.; Cuesta-Infante, Alfredo] Univ Rey Juan Carlos, Escuela Tecn Super Ingn Informat, Mostoles, Spain.
C3 Universidad Rey Juan Carlos
RP Cuesta-Infante, A (corresponding author), Univ Rey Juan Carlos, Escuela Tecn Super Ingn Informat, Mostoles, Spain.
EM franciscojose.garcia@urjc.es; david.concha@urjc.es;
   juanjose.pantrigo@urjc.es; alfredo.cuesta@urjc.es
RI CUESTA-INFANTE, ALFREDO/L-3708-2014; García-Espinosa, Francisco
   José/HTS-5743-2023
OI CUESTA-INFANTE, ALFREDO/0000-0002-3328-501X; García-Espinosa, Francisco
   José/0000-0001-8062-6692; Concha, David/0000-0003-4996-3281
FU Spanish Government (MICINN/FEDER) [RTI2018-098743-B-I00]; Comunidad de
   Madrid [Y2018/EMT-5062]; CRUE-CSIC
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research has been supported by the Spanish
   Government research funding RTI2018-098743-B-I00 (MICINN/FEDER) and the
   Comunidad de Madrid research funding grant Y2018/EMT-5062. We also would
   like to acknowledge Ecoembes for providing the EcoDID-2017 database of
   dumpster images for this work.
CR Ahmed K, 2019, ADV NEUR IN, V32
   Baydilli YY, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2020.101699
   Ding XP, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2237
   Hahn T., 2019, Advances in neural information processing systems, V32, P7658
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2018, INT C LEARN REPR
   Jeong T, 2019, PR MACH LEARN RES, V97
   Lenssen J. E., 2018, Advances in Neural Information Process- ing Systems, V31, P8844
   Mobiny A, 2020, IEEE T MED IMAGING, V39, P1, DOI 10.1109/TMI.2019.2918181
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P2145, DOI 10.1109/TGRS.2018.2871782
   Ramirez I, 2020, NEURAL COMPUT APPL, V32, P13203, DOI 10.1007/s00521-018-3390-8
   Sabour S, 2017, ADV NEUR IN, V30
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Xu Q, 2021, IEEE GEOSCI REMOTE S, V18, P361, DOI 10.1109/LGRS.2020.2970079
   Zhang LH, 2018, ADV NEUR IN, V31
NR 15
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31129
EP 31143
DI 10.1007/s11042-022-12899-9
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500009
OA hybrid
DA 2024-07-18
ER

PT J
AU Dantas, MSM
   Leuchtenberg, PHD
   de Souza, GFR
   Bezerra, D
   Souza, R
   Lins, S
   Kelner, J
   Sadok, DFH
AF Dantas, Marrone Silverio Melo
   Leuchtenberg, Pedro Henrique Dreyer
   de Souza, Gabriel Fonseca Reis
   Bezerra, Daniel
   Souza, Ricardo
   Lins, Silvia
   Kelner, Judith
   Sadok, Djamel Fawzi Hadj
TI Faulty RJ45 connectors detection on radio base station using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radio base station; Maintenance; Classification; Detection; Deep
   learning; Automation
AB A Radio Base Station (RBS), part of the Radio Access Network, is a particular type of equipment that supports the connection between a wide range of cellular user devices and an operator network access infrastructure. Nowadays, most of the RBS maintenance is carried out manually, resulting in a time consuming and costly task. A suitable candidate for RBS maintenance automation is repairing faulty links between devices caused by missing or unplugged connectors. This paper proposes and compares two Deep Learning (DL) solutions applied to identify attached RJ45 connectors on network ports. We named Connector Detection, the DL solution based on object detection, and Connector Classification, the one based on object classification. With connector detection, we achieve an accuracy of 0.934 and a mean average precision of 0.903. Connector Classification, reaches a higher maximum Accuracy of 0.981 and an Area Under the Receiving Operating characteristic Curve (AUC) of 0.989. Although Connector Detection was outperformed in this particular study, it is more flexible for scenarios where there is a lack of precise information about the environment and the possible devices. This in contrast with Connector Classification which requires such information to be well-defined beforehand.
C1 [Dantas, Marrone Silverio Melo; Leuchtenberg, Pedro Henrique Dreyer; de Souza, Gabriel Fonseca Reis; Bezerra, Daniel; Kelner, Judith; Sadok, Djamel Fawzi Hadj] Univ Fed Pernambuco, Informat Ctr, Recife, PE, Brazil.
   [Souza, Ricardo; Lins, Silvia] Ericsson Res, Indaiatuba, Brazil.
C3 Universidade Federal de Pernambuco
RP Dantas, MSM (corresponding author), Univ Fed Pernambuco, Informat Ctr, Recife, PE, Brazil.
EM marrone.dantas@gprt.ufpe.br
RI Sadok, Djamel F Hadj/M-9814-2015; Kelner, Judith/C-6746-2009
OI Dantas, Marrone/0000-0002-7927-8472
CR Adibhatla VA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091547
   Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   [Anonymous], 2020, PITASC APPL USE
   [Anonymous], 2018, Computer Networking: Problems and Solutions
   [Anonymous], ARXIV181201593
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Bharati Puja, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P657, DOI 10.1007/978-981-13-9042-5_56
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Brosnan T, 2004, J FOOD ENG, V61, P3, DOI 10.1016/S0260-8774(03)00183-3
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   D'Amore Giovanni, 2009, Engineer IT, P24
   Dantas D, 2020, TESTBED CONNECTED AR, V01
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Disyadej T, 2019, INNOV SMART GRID TEC, DOI 10.1109/isgt.2019.8791584
   Ehrlinger L., 2019, A survey of data quality measurement and monitoring tools
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Franko J, 2020, ENERGIES, V13, DOI 10.3390/en13102552
   Giesen H, 2018, P 2018 MORN WORKSH I, DOI 10.1145/3229591
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gujrati T, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P2286, DOI 10.1109/ICPCSI.2017.8392124
   Hao B, 2019, PROCEEDINGS OF THE 2019 14TH SYMPOSIUM ON PIEZOELECTRCITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS (SPAWDA19), P52, DOI 10.1109/spawda48812.2019.9019236
   Hatab M, 2020, INTELLISYS
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huaxu Zhou, 2021, 10th International Conference on Computer Engineering and Networks. Advances in Intelligent Systems and Computing (AISC 1274), P685, DOI 10.1007/978-981-15-8462-6_78
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lenchner J., 2011, Proceedings of the 8th IEEE International Conference on Autonomic Computing (ICAC), P81
   Ling Zheng, 2019, 2019 IEEE International Conference on Energy Internet (ICEI), P537, DOI 10.1109/ICEI.2019.00101
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parker, 2003, ROBOTICS APPL MAINTE
   Pinedo-Sánchez LA, 2020, J BRAZ SOC MECH SCI, V42, DOI 10.1007/s40430-020-02711-w
   Prometheus, From metrics to insight
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Robotic fiber patch panel system, 2020, LC DUPL MULT TRIPP L
   Santos L, 2020, ADV INTELL SYST COMP, V1092, P139, DOI 10.1007/978-3-030-35990-4_12
   Shengli W, 2007, 2007 2 INT C DIG INF, V1, P13
   Shinde PP, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Shirazi MS, 2019, MACH VISION APPL, V30, P1097, DOI 10.1007/s00138-019-01040-w
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smirnov EA, 2014, AASRI PROC, V6, P89, DOI 10.1016/j.aasri.2014.05.013
   So-In C, 2020, SURVEY NETWORK TRAFF
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan C, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P599
   Valera A, 2010, 2010 IEEE 21ST INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1814, DOI 10.1109/PIMRC.2010.5671635
   Vithanage RKW, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 2, P278, DOI 10.5220/0006410702780283
   Woschank M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12093760
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yang J, 2019, IEEE ACCESS, V7, P89278, DOI 10.1109/ACCESS.2019.2925561
   Yu LY, 2019, J SENSORS, V2019, DOI 10.1155/2019/3140980
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
NR 56
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30305
EP 30327
DI 10.1007/s11042-022-12694-6
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900004
DA 2024-07-18
ER

PT J
AU Sehar, U
   Naseem, ML
AF Sehar, Uroosa
   Naseem, Muhammad Luqman
TI How deep learning is empowering semantic segmentation Traditional and
   deep learning techniques for semantic segmentation: A comparison
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning algorithm; Pattern recognition; Semantic segmentation;
   Image segments; Object detection
AB Semantic segmentation involves extracting meaningful information from images or input from a video or recording frames. It is the way to perform the extraction by checking pixels by pixel using a classification approach. It gives us more accurate and fine details from the data we need for further evaluation. Formerly, we had a few techniques based on some unsupervised learning perspectives or some conventional ways to do some image processing tasks. With the advent of time, techniques are improving, and we now have more improved and efficient methods for segmentation. Image segmentation is slightly simpler than semantic segmentation because of the technical perspective as semantic segmentation is pixels based. After that, the detected part based on the label will be masked and refer to the masked objects based on the classes we have defined with a relevant class name and the designated color. In this paper, we have reviewed almost all the supervised and unsupervised learning algorithms from scratch to advanced and more efficient algorithms that have been done for semantic segmentation. As far as deep learning is concerned, we have many techniques already developed until now. We have studied around 120 papers in this research area. We have concluded how deep learning is helping in solving the critical issues of semantic segmentation and gives us more efficient results. We have reviewed and comprehensively studied different surveys on semantic segmentation, specifically using deep learning.
C1 [Sehar, Uroosa] Univ Engn & Technol, Taxila, Pakistan.
   [Naseem, Muhammad Luqman] Northeastern Univ, Shenyang, Peoples R China.
C3 University of Engineering & Technology Taxila; Northeastern University -
   China
RP Sehar, U (corresponding author), Univ Engn & Technol, Taxila, Pakistan.
EM 1505253990@qq.com; mluqmannaseem@outlook.com
RI Sehar, Uroosa/AAD-2894-2022
OI Sehar, Uroosa/0000-0003-0250-4352; Naseem, Muhammad
   Luqman/0000-0002-0331-2347
CR Aakur SN, 2019, PROC CVPR IEEE, P1197, DOI 10.1109/CVPR.2019.00129
   Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   Agustsson E, 2019, PROC CVPR IEEE, P11614, DOI 10.1109/CVPR.2019.01189
   [Anonymous], 2021, AUTOMATIC DIAGNOSIS, P1
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Batra A, 2019, PROC CVPR IEEE, P10377, DOI 10.1109/CVPR.2019.01063
   Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939
   Benenson R, 2019, PROC CVPR IEEE, P11692, DOI 10.1109/CVPR.2019.01197
   Blokhinov YB, 2018, COMPUT OPT, V42, P141, DOI 10.18287/2412-6179-2018-42-1-141-148
   Cao JL, 2019, PROC CVPR IEEE, P7384, DOI 10.1109/CVPR.2019.00757
   Cerrone L, 2019, PROC CVPR IEEE, P12551, DOI 10.1109/CVPR.2019.01284
   Chang CY, 2019, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2019.00366
   Chang WL, 2019, PROC CVPR IEEE, P1900, DOI 10.1109/CVPR.2019.00200
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Chen XK, 2021, PROC CVPR IEEE, P2613, DOI 10.1109/CVPR46437.2021.00264
   Chen XY, 2020, IEEE T INTELL TRANSP, V21, P2990, DOI 10.1109/TITS.2019.2922252
   Chen X, 2019, PROC CVPR IEEE, P11624, DOI 10.1109/CVPR.2019.01190
   Cheng D, 2019, PROC CVPR IEEE, P7423, DOI 10.1109/CVPR.2019.00761
   Cholakkal H, 2019, PROC CVPR IEEE, P12389, DOI 10.1109/CVPR.2019.01268
   Ding HH, 2019, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2019.00909
   Du Y, 2021, ARXIV PREPRINT ARXIV
   Fan RC, 2020, COMPUT VIS MEDIA, V6, P191, DOI 10.1007/s41095-020-0173-9
   Feigege Wang, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12640, DOI 10.1109/CVPR.2019.01293
   Fu GZ, 2019, OPT LASER ENG, V121, P397, DOI 10.1016/j.optlaseng.2019.05.005
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   Griffin BA, 2019, PROC CVPR IEEE, P8906, DOI 10.1109/CVPR.2019.00912
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   He T, 2019, PROC CVPR IEEE, P578, DOI 10.1109/CVPR.2019.00067
   He Y., 2021, P COMPUTER VISION PA, V1, P1, DOI DOI 10.5465/AMBPP.2011.1.1DD
   He Y, 2020, IEEE T INSTRUM MEAS, V69, P1493, DOI 10.1109/TIM.2019.2915404
   Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Hu XG, 2022, APPL INTELL, V52, P580, DOI 10.1007/s10489-021-02446-8
   Hu XG, 2020, IEEE ACCESS, V8, P70913, DOI 10.1109/ACCESS.2020.2987080
   Hu YT, 2019, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2019.00322
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Hung W, SCOPS SELF SUPERVISE
   Jain S, 2019, PROC CVPR IEEE, P8858, DOI 10.1109/CVPR.2019.00907
   Jang WD, 2019, PROC CVPR IEEE, P5292, DOI 10.1109/CVPR.2019.00544
   Jiao JB, 2019, PROC CVPR IEEE, P2864, DOI 10.1109/CVPR.2019.00298
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Larsson M, 2019, PROC CVPR IEEE, P9524, DOI 10.1109/CVPR.2019.00976
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Li G, 2020, IEEE ACCESS, V8, P27495, DOI 10.1109/ACCESS.2020.2971760
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li YW, 2019, PROC CVPR IEEE, P7019, DOI 10.1109/CVPR.2019.00719
   Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710
   Lin D, 2019, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2019.00767
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu HY, 2019, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2019.00633
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Lo SY, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901686
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu X., 2019, CVPR, V1, P3623
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Majumder S, 2019, PROC CVPR IEEE, P11594, DOI 10.1109/CVPR.2019.01187
   Marin D, 2018, ARXIV180902322
   Mou LC, 2019, PROC CVPR IEEE, P12408, DOI 10.1109/CVPR.2019.01270
   Nekrasov V, 2019, PROC CVPR IEEE, P9118, DOI 10.1109/CVPR.2019.00934
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Ni TW, 2019, PROC CVPR IEEE, P2104, DOI 10.1109/CVPR.2019.00221
   Orsic M, 2019, PROC CVPR IEEE, P12599, DOI 10.1109/CVPR.2019.01289
   Paszke A., 2016, ARXIV160602147
   Porzi L, 2019, PROC CVPR IEEE, P8269, DOI 10.1109/CVPR.2019.00847
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Sadeghi D., 2021, OVERVIEW ARTIFICIAL, P1
   Shen YH, 2019, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2019.00079
   Shetty Rakshith, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8210, DOI 10.1109/CVPR.2019.00841
   Shoeibi, 2021, APPL EPILEPTIC SEIZU
   Shoeibi A, 2020, ARXIV PREPRINT ARXIV
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Song CF, 2019, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2019.00325
   Sun L, 2020, REAL TIME FUSION NET
   Sun RQ, 2019, PROC CVPR IEEE, P4355, DOI 10.1109/CVPR.2019.00449
   Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Tokunaga H, 2019, PROC CVPR IEEE, P12589, DOI 10.1109/CVPR.2019.01288
   Treml M., 2016, SPEEDING SEMANTIC SE, V2, P1
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang L, 2020, PROC CVPR IEEE, P3773, DOI 10.1109/CVPR42600.2020.00383
   Wang M, 2019, PROC CVPR IEEE, P1495, DOI 10.1109/CVPR.2019.00159
   Wang XL, 2019, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2019.00422
   Wen ZJ, 2021, INT J CLOTH SCI TECH, V33, P1, DOI 10.1108/IJCST-11-2019-0177
   Wu S., 2021, FULLY TRANSFORMER NE, V1, P1
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Wu XY, 2021, PROC CVPR IEEE, P15764, DOI 10.1109/CVPR46437.2021.01551
   Xian YQ, 2019, PROC CVPR IEEE, P8248, DOI 10.1109/CVPR.2019.00845
   Xiang KT, 2021, OPT EXPRESS, V29, P4802, DOI 10.1364/OE.416130
   Xie Echo, 2021, South China Morning Post, P1
   Xiong YW, 2019, PROC CVPR IEEE, P8810, DOI 10.1109/CVPR.2019.00902
   Xu K, 2019, PROC CVPR IEEE, P1379, DOI 10.1109/CVPR.2019.00147
   Xu SJ, 2019, PROC CVPR IEEE, P314, DOI 10.1109/CVPR.2019.00040
   Yang KL, 2022, IEEE T INTELL TRANSP, V23, P1184, DOI 10.1109/TITS.2020.3023331
   Yang KL, 2021, IEEE T IMAGE PROCESS, V30, P1866, DOI 10.1109/TIP.2020.3048682
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu FG, 2019, PROC CVPR IEEE, P9483, DOI 10.1109/CVPR.2019.00972
   Yuan Y, 2018, OCNET OBJECT CONTEXT
   Zendel O, 2018, LECT NOTES COMPUT SC, V11210, P407, DOI 10.1007/978-3-030-01231-1_25
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang JM, 2021, IEEE INT CONF COMP V, P1760, DOI 10.1109/ICCVW54120.2021.00202
   Zhang SH, 2019, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2019.00098
   Zhang XT, 2019, IEEE T IND INFORM, V15, P1183, DOI 10.1109/TII.2018.2849348
   Zhang YH, 2019, PROC CVPR IEEE, P11633, DOI 10.1109/CVPR.2019.01191
   Zhang ZY, 2019, PROC CVPR IEEE, P4101, DOI 10.1109/CVPR.2019.00423
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
   Zhou YZ, 2019, PROC CVPR IEEE, P4041, DOI 10.1109/CVPR.2019.00417
   Zhu Y, 2020, IMPROVING SEMANTIC S
   Zhu Y, 2019, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2019.00323
   Zhuang BH, 2019, PROC CVPR IEEE, P413, DOI 10.1109/CVPR.2019.00050
NR 122
TC 11
Z9 11
U1 15
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30519
EP 30544
DI 10.1007/s11042-022-12821-3
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900001
PM 35411201
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Al-Qurran, R
   Al-Ayyoub, M
   Shatnawi, A
AF Al-Qurran, Raffi
   Al-Ayyoub, Mahmoud
   Shatnawi, Ali
TI Plant classification in the wild: Energy evaluation for deep learning
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Green AI; Energy consumption; iNaturlist;
   Herbarium
ID RECOGNITION
AB Having a system that can take an image of a natural scene and accurately classify the plants in it is of undeniable importance. However, the complexities of dealing with natural scene images and the vast diversity of plants in the wild make designing such a classifier a challenging task. Deep Learning (DL) lends itself as viable solution to tackle such complex problem. However, advanced in DL architectures and software (including DL frameworks) come with a high cost in terms of energy consumption especially when employing Graphics Processing Units (GPU). As data expands rapidly, the need to create energy-aware models increases in order to reduce energy consumption and move towards "Greener AI". Since the problem of designing energy-aware architectures for plant classification has not been studied significantly in the literature, our work comes to start bridging this gap by focusing not only on the models' performance, but also on their energy usage on both CPU and GPU platforms. We consider different state-of-the-art Convolutional Neural Networks (CNN) architectures and train them on two famous challenging plants datasets: iNaturalist and Herbarium. Our experiments are meant to highlight the trade-off between accuracy and energy consumption. For examples, the results show that while GPU-bound models can be about 40% faster in terms of training time than simple models running on CPU, the latter's energy consumption is only two thirds of the former. We hope that such findings will encourage the community to reduce its reliance on accuracy measures to compare different architectures and start taking other factors into account such as power consumption, simplicity, etc.
C1 [Al-Qurran, Raffi; Al-Ayyoub, Mahmoud; Shatnawi, Ali] Jordan Univ Sci & Technol, Irbid, Jordan.
C3 Jordan University of Science & Technology
RP Al-Ayyoub, M (corresponding author), Jordan Univ Sci & Technol, Irbid, Jordan.
EM rlalqurran11@xcit.just.edu.jo; maalshbool@just.edu.jo; ali@just.edu.jo
RI Al-Qurran, Raffi/GYU-3687-2022
FU Deanship of Research at the Jordan University of Science and Technology
   [20180544]
FX We gratefully acknowledge the support of the Deanship of Research at the
   Jordan University of Science and Technology for supporting this work via
   Grant #20180544.
CR Al-Qurran R, 2018, INT ARAB CONF INF TE, P148
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   [Anonymous], 2007, ADV ARTIFICIAL INTEL
   [Anonymous], 2017, CLEF WORKING NOTES
   [Anonymous], 2014, CLEF (Working notes)
   Carneiro T, 2018, IEEE ACCESS, V6, P61677, DOI 10.1109/ACCESS.2018.2874767
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   El Massi I, 2016, LECT NOTES COMPUT SC, V9680, P40, DOI 10.1007/978-3-319-33618-3_5
   El Massie I, 2016, I C COMP GRAPH IM VI, P131, DOI 10.1109/CGiV.2016.34
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jaakkola T., 2019, ARXIV PREPRINT ARXIV
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larese MG, 2014, EXPERT SYST APPL, V41, P4638, DOI 10.1016/j.eswa.2014.01.029
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Liu YY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON FUNCTIONAL-STRUCTURAL PLANT GROWTH MODELING, SIMULATION, VISUALIZATION AND APPLICATIONS (FSPMA), P110, DOI 10.1109/FSPMA.2016.7818296
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Nilsback ME, 2009, THESIS OXFORD U OXFO
   Ouhami M., 2020, P INT C IM SIGN PROC, P65, DOI 10.1007/978-3-030-51935-3_7
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russell S., 2020, ARTIF INTELL
   Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wittmann, 2019, TIMELINE TRANSFER LE
   Yalcin H, 2016, INT CONF AGRO-GEOINF, P233
   Zhang CY, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2147, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.318
NR 34
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30143
EP 30167
DI 10.1007/s11042-022-12695-5
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500012
DA 2024-07-18
ER

PT J
AU Kibriya, H
   Masood, M
   Nawaz, M
   Nazir, T
AF Kibriya, Hareem
   Masood, Momina
   Nawaz, Marriam
   Nazir, Tahira
TI Multiclass classification of brain tumors using a novel CNN architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Deep learning; Convolutional neural network; Medical image
   analysis
ID MRI IMAGES; NETWORKS
AB Brain tumors are a deadly condition that radiologists have a tough time diagnosing. It is critical to make treatment-related decisions based on accurate and timely categorization of malignant cancers. Several approaches for detecting brain tumors have been presented in recent years. These strategies, however, necessitate handmade feature extraction and manual tumor segmentation prior to classification, which is error-prone and time-consuming. To properly extract features and identify brain cancers, an automated tumor diagnosis approach is necessary. Despite significant advancements in the development of such systems, the techniques face challenges due to low accuracy and large false-positive values. In this study, we propose a 13-layer CNN architecture for classifying brain tumors from MRI scans. We tested the suggested model's performance on a benchmark dataset of 3064 MRI images of three different types of brain cancer (glioma, pituitary, and meningioma) and achieved the highest accuracy of 97.2%, outperforming previous work on the same database. Furthermore, we validated our model on a cross-dataset scenario to demonstrate its efficacy in a real-world scenario. The main goal is to create a lightweight CNN architecture with fewer layers and learnable parameters that can reliably detect tumors in MRI images in the shortest amount of time. The findings show that the proposed technique is effective in classifying brain tumors using MRI images. Because of its adaptability, the proposed algorithm can be easily used in practice to assist doctors in diagnosing brain tumors at an early stage.
C1 [Kibriya, Hareem; Masood, Momina; Nawaz, Marriam] Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
   [Nazir, Tahira] Riphah Int Univ, Islamabad, Pakistan.
C3 University of Engineering & Technology Taxila
RP Nazir, T (corresponding author), Riphah Int Univ, Islamabad, Pakistan.
EM tahira.nazir@riphah.edu.pk
RI Nawaz, Marriam/JVD-9229-2023; Masood, Momina/M-6979-2017
OI Masood, Momina/0000-0003-1977-1481; Nawaz, Marriam/0000-0002-2238-4645;
   , Hareem Kibriya/0009-0003-1525-226X; Nazir, Tahira/0000-0001-8130-3721
CR Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Albawi S, 2017, I C ENG TECHNOL
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Anitha R, 2018, INT J IMAG SYST TECH, V28, P48, DOI 10.1002/ima.22255
   [Anonymous], 2016, MICCAI
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Bhuvaji SK, 2021, BRAIN TUMOR CLASSIFI, DOI 10.34740/KAGGLE/DSV/1183165
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144479
   DeAngelis LM, 2001, NEW ENGL J MED, V344, P114, DOI 10.1056/NEJM200101113440207
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Hashemzehi R, 2020, BIOCYBERN BIOMED ENG, V40, P1225, DOI 10.1016/j.bbe.2020.06.001
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Khawaldeh S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010027
   Kibriya H, 2021, INT BHURBAN C APPL S, P346, DOI 10.1109/IBCAST51254.2021.9393311
   Komninos J, 2004, J CLIN ENDOCR METAB, V89, P574, DOI 10.1210/jc.2003-030395
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Peri C, TYPES BRAIN CANC
   Pundir A, 2021, MACHINE LEARNING INT, P307
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Saxena P, 2021, Innovations in Computational Intelligence and Computer Vision, P275, DOI [10.1007/978-981-15-6067-5_30, DOI 10.1007/978-981-15-6067-5_30]
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tharani S., 2016, INT J ADV RES COMPUT, V5, P417, DOI DOI 10.17148/IJARCCE.2016.51296
   Thejaswini P., 2019, INT J ENG MANUFACT I, V9, P11, DOI DOI 10.5815/IJEM.2019.01.02
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Waghmare V.K., 2020, INTERNET THINGS HEAL, P155
   Yakura H, 2018, PROCEEDINGS OF THE EIGHTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY'18), P127, DOI 10.1145/3176258.3176335
NR 42
TC 19
Z9 19
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29847
EP 29863
DI 10.1007/s11042-022-12977-y
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500020
DA 2024-07-18
ER

PT J
AU Hossain, MI
   Al Mahmud, TH
   Islam, MS
   Hossen, MB
   Khan, R
   Ye, ZF
AF Hossain, Md Imran
   Al Mahmud, Tarek Hasan
   Islam, Md Shohidul
   Hossen, Md Bipul
   Khan, Rashid
   Ye, Zhongfu
TI Dual transform based joint learning single channel speech separation
   using generative joint dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech separation (SS); Dual-tree complex wavelet transform (DTCWT);
   Generative joint dictionary learning (GJDL); Short-time Fourier
   transform (STFT); Gini index (GI)
ID DISCRIMINATIVE DICTIONARY; OPTIMIZATION
AB Single channel speech separation (SS) is highly significant in many real-world speech processing applications such as hearing aids, automatic speech recognition, control humanoid robots, and cocktail-party issues. The performance of the SS is crucial for these applications, but better accuracy has yet to be developed. Some researchers have tried to separate speech using only the magnitude part, and some are tried to solve complex domains. We propose a dual transform SS method that serially uses the dual-tree complex wavelet transform (DTCWT) and short-term Fourier transform (STFT), and jointly learns the magnitude, real and imaginary parts of the signal applying a generative joint dictionary learning (GJDL). At first, the time-domain speech signal is decomposed by DTCWT, which produces a set of subband signals. Then STFT is connected to each subband signal, which converts each subband signal to the time-frequency domain and builds a complex spectrogram that prepares three parts like real, imaginary and magnitude for each subband signal. Next, we utilize the GJDL approach for making the joint dictionaries, and then the batch least angle regression with a coherence criterion (LARC) algorithm is used for sparse coding. Afterward, computes the initially estimated signals in two different ways, one by considering only the magnitude part and another by considering real and imaginary components. Finally, we apply the Gini index (GI) to the initially estimated signals to achieve better accuracy. The proposed algorithm demonstrates the best performance in all considered evaluation metrics compared to the mentioned algorithms.
C1 [Hossain, Md Imran; Hossen, Md Bipul; Khan, Rashid; Ye, Zhongfu] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Anhui, Peoples R China.
   [Al Mahmud, Tarek Hasan] Islamic Univ, Deptment ICE, Kushtia, Bangladesh.
   [Islam, Md Shohidul] Islamic Univ, Deptment CSE, Kushtia, Bangladesh.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Islamic University; Islamic University
RP Ye, ZF (corresponding author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Anhui, Peoples R China.
EM imranpost@mail.ustc.edu.cn; tarek@mail.ustc.edu.cn;
   shohid7@mail.ustc.edu.cn; mbipu@mail.ustc.edu.cn;
   rashidkhan@mail.ustc.edu.cn; yezf@ustc.edu.cn
RI khan, Rashid/HSF-9463-2023; KHAN, RASHID MUMTAZ/HHZ-3812-2022; Hossen,
   Md. Bipul/AGJ-1245-2022
OI khan, Rashid/0000-0002-2410-044X; KHAN, RASHID
   MUMTAZ/0000-0001-6097-098X; Hossen, Md. Bipul/0000-0002-8546-5426;
   Hossain, Md. Imran/0000-0001-8030-8379; Al Mahmud, Tarek
   Hasan/0000-0001-5878-7852; Islam, Md Shohidul/0000-0002-2854-4419
FU National Natural Science Foundation of China [61671418]
FX This research was supported by the National Natural Science Foundation
   of China (no. 61671418).
CR ALLEN JB, 1977, IEEE T ACOUST SPEECH, V25, P235, DOI 10.1109/TASSP.1977.1162950
   [Anonymous], P EUSIPCO 98 RHOD SE
   Bao GZ, 2014, IEEE-ACM T AUDIO SPE, V22, P1130, DOI 10.1109/TASLP.2014.2320575
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Demir C, 2013, IEEE T AUDIO SPEECH, V21, P725, DOI 10.1109/TASL.2012.2231072
   Fu JF, 2018, APPL ACOUST, V132, P1, DOI 10.1016/j.apacoust.2017.11.005
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Grais EM, 2013, INTERSPEECH, P808
   Hossain MI, 2021, CIRC SYST SIGNAL PR, V40, P1868, DOI 10.1007/s00034-020-01564-x
   Huang PS, 2015, IEEE-ACM T AUDIO SPE, V23, P2136, DOI 10.1109/TASLP.2015.2468583
   Hurley N, 2008, MACHINE LEARN SIGN P, P55, DOI 10.1109/MLSP.2008.4685455
   Islam MS, 2021, CIRC SYST SIGNAL PR, V40, P4651, DOI 10.1007/s00034-021-01690-0
   Islam MS, 2020, DIGIT SIGNAL PROCESS, V100, DOI 10.1016/j.dsp.2020.102697
   Islam MS, 2020, J SIGNAL PROCESS SYS, V92, P445, DOI 10.1007/s11265-019-01480-7
   Islam MS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030353
   Jang GJ, 2004, J MACH LEARN RES, V4, P1365, DOI 10.1162/jmlr.2003.4.7-8.1365
   [贾海蓉 Jia Hairong], 2019, [西安电子科技大学学报, Journal of Xidian University], V46, P74
   Jiang D, 2021, WIREL COMMUN MOB COM, V2021
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002
   Kates JM, 2010, J AUDIO ENG SOC, V58, P363
   Ke SF, 2020, MULTIMED TOOLS APPL, V79, P32225, DOI 10.1007/s11042-020-09419-y
   Khan MS, 2013, IEEE T AUDIO SPEECH, V21, P1900, DOI 10.1109/TASL.2013.2261814
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lian Q., 2015, J AUTOM, V41, P240
   Lorenz MO, 1905, J AM STAT ASSOC, V9, P209
   Luo Y, 2016, IEEE SIGNAL PROC LET, V23, P237, DOI 10.1109/LSP.2015.2509480
   Mowlaee P, 2012, IEEE T AUDIO SPEECH, V20, P2586, DOI 10.1109/TASL.2012.2208627
   Muhammed B, 2017, NAT C TECHN TRENDS N, P15
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Rivet B, 2014, IEEE SIGNAL PROC MAG, V31, P125, DOI 10.1109/MSP.2013.2296173
   Rix A, 2010, IEEE INT C ACOUSTICS, P749
   Roweis ST, 2001, ADV NEUR IN, V13, P793
   Sigg CD, 2012, IEEE T AUDIO SPEECH, V20, P1698, DOI 10.1109/TASL.2012.2187194
   Sun LH, 2021, EURASIP J AUDIO SPEE, V2021, DOI 10.1186/s13636-021-00218-3
   Sun LH, 2020, SIGNAL IMAGE VIDEO P, V14, P1387, DOI 10.1007/s11760-020-01676-6
   Sun LH, 2019, SPEECH COMMUN, V106, P85, DOI 10.1016/j.specom.2018.11.008
   Sun LH, 2018, INT J SPEECH TECHNOL, V21, P19, DOI 10.1007/s10772-017-9469-2
   Sun Y, 2019, IEEE J-STSP, V13, P359, DOI 10.1109/JSTSP.2019.2908760
   Sun Y, 2017, INT CONF ACOUST SPEE, P4187, DOI 10.1109/ICASSP.2017.7952945
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Ullah R, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107406
   Varshney YV, 2017, ARCH ACOUST, V42, P287, DOI 10.1515/aoa-2017-0031
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang Y, 2014, P 19 INT C DIG SIGN, P20
   Wanng Z, 2014, IEEE INT C AC SPEECH
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Wu B, 2017, IEEE-ACM T AUDIO SPE, V25, P102, DOI 10.1109/TASLP.2016.2623559
   Xu YF, 2015, SIGNAL PROCESS, V106, P134, DOI 10.1016/j.sigpro.2014.07.012
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zohrevandi M, 2021, MULTIMED TOOLS APPL, V80, P12601, DOI 10.1007/s11042-020-10398-3
NR 50
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29321
EP 29346
DI 10.1007/s11042-022-12816-0
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777241600001
DA 2024-07-18
ER

PT J
AU Thanh, TM
   Dan, GN
AF Thanh, Ta Minh
   Dan, Giang Ngoc
TI Pseudo Zero-watermarking Technique based on non-blind watermarking and
   VSS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Visual secret sharing; VSS; Copyright Protection;
   Discrete Wavelet Transform (DWT); Discrete cosine transform (DCT);
   Copyright authority
ID ROBUST; SCHEME
AB This paper proposes a solution for digital image copyright protection technique using the combination of watermarking and visual encryption technique. In our solution, the copyright information (copyright logo) is distributed into n shares using k - out - of - n distributed algorithm, also called (k, n) visual secret sharing method. One of the shares is randomly selected to embed into the original image to prove the user's copyright. The remaining n - 1 shares is used to register with Copyright Department. When claiming the copyright belongs to the user, the verifier only needs to extract the watermark information from the watermarked image, then decodes with any registered k - 1 shares from n - 1 shares for restoring copyright information. Experimental results of the proposed method compared with the method using only digital watermark show that our method has more practical effectiveness in the application of digital product copyright protection.
C1 [Thanh, Ta Minh; Dan, Giang Ngoc] Le Quy Don Syst Univ, 236 Hoang Quoc Viet, Hanoi, Vietnam.
RP Thanh, TM (corresponding author), Le Quy Don Syst Univ, 236 Hoang Quoc Viet, Hanoi, Vietnam.
EM thanhtm@lqdtu.edu.vn
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2019.12]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2019.12.
CR Abdelhedi K., 2020, LECT NOTES COMPUTER, DOI 10.1007/978-3-030-40605-9_32
   [Anonymous], 2003, AES PROPOSAL RIJNDAE
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Bolla VR, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2041, DOI 10.1109/ICEEOT.2016.7755046
   Cedillo-Hernandez M, 2014, 35 IEEE INT C TELECO, P715
   Cimato S, 2014, VISUAL CRYPTOGRAPHY, P91, DOI DOI 10.1007/978-3-642-55046-1_6
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Fu MS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P975
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Hwang R.-J, 2000, TAMKANG J SCI ENG, V3, P97
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2015, MULTIMED TOOLS APPL, V121
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Surekha B., 2013, INT J NETWORK SECURI, V15, P95
   Thanh TM, 2016, MULTIMED TOOLS APPL, V75, P11097, DOI 10.1007/s11042-015-2836-6
   Thanh TM, 2016, INT J MULTIMEDIA TOO
   Thanh TM., 2014, INT J INTELLIGENT IN, V5, P12
   Thanh TM, 2014, P IEEE 25 INT S PERS, P2066
   Tharayil JJ, 2012, PROCEDIA ENGINEER, V38, P2117, DOI 10.1016/j.proeng.2012.06.254
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang, 2007, OPT ENG, V6, P46
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 28
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29119
EP 29136
DI 10.1007/s11042-022-12079-9
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900003
DA 2024-07-18
ER

PT J
AU Bao, JM
   Jing, JF
   Zhang, WC
   Liu, C
   Gao, T
AF Bao, Junmin
   Jing, Junfeng
   Zhang, Weichuan
   Liu, Chao
   Gao, Tian
TI A corner detection method based on adaptive multi-directional
   anisotropic diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Corner detection; Anisotropic diffusion; Multi-direction information;
   Image matching
ID JUNCTION DETECTION; SCALE-SPACE; CLASSIFICATION; EDGE
AB As the most significant feature, corner is widely used in many application areas of computer vision, such as object tracking, image restoration, and 3D reconstruction. Various noises in the image bring about non-negligible negative impact on the accuracy of feature location for a corner detection algorithm. To avoid the influence of noise, the Gaussian filter was utilized by existing algorithms, which lead to loss of detailed information of image edges or even loss of corners. Considering the geometric structure of the corners, a new anisotropic diffusion method taking into consideration the image local multi-directional information was designed at first to achieve significant denoising effect and preserve the edge information and detailed information of the image. Subsequently, a multi-directional structure tensor product is applied to construct feasible corner measure function for detecting corners with high robustness. Finally, metrics about location accuracy, average repeatability, and image matching performance were applied to evaluated the performance of proposed corner detection method. Compare with twelve state-of-the-art methods, the experiments show that the proposed method is optimal in overall performance and the average score is 0.8504. Comparing with other methods, the proposed method has 1%-24% improvement in average performance with image affine transformation. The corner location error is 1.2216 on 'Lab', 1.2617 on 'Block' and 1.7002 on 'Pentagon', which are better than other detectors. In experiment with light and viewpoint changes, our proposed method outperforms other methods by 2.7% to 35.76% on average matching score.
C1 [Bao, Junmin; Jing, Junfeng; Zhang, Weichuan; Liu, Chao; Gao, Tian] Xian Polytech Univ, Sch Elect Informat, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an Polytechnic University
RP Jing, JF (corresponding author), Xian Polytech Univ, Sch Elect Informat, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
EM jingjunfeng0718@sina.com
RI Gao, Tian/AAC-7540-2021; jing, feng jun/HIZ-9409-2022
OI Gao, Tian/0000-0002-1646-5430; jing, feng jun/0000-0001-6646-3698
FU Innovation Capability Support Program of Shaanxi [2021TD-29]; Youth
   Innovation Team of Shaanxi Universities; Key Research and Development
   Program of Shaanxi [2022GY-066]; National Natural Science Foundation of
   China [62176204]
FX This work was supported in part by Innovation Capability Support Program
   of Shaanxi (No.2021TD-29), in part by the Youth Innovation Team of
   Shaanxi Universities, in part by Key Research and Development Program of
   Shaanxi (No.2022GY-066), and in part by the National Natural Science
   Foundation of China (No.62176204).
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Ando S, 2000, IEEE T PATTERN ANAL, V22, P179, DOI 10.1109/34.825756
   [Anonymous], 1979, P 6 INT JOINT C ART
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410
   Barroso-Laguna A, 2019, IEEE I CONF COMP VIS, P5835, DOI 10.1109/ICCV.2019.00593
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bennett S, 2014, COMPUT VIS IMAGE UND, V118, P197, DOI 10.1016/j.cviu.2013.10.008
   BIGUN J, 1990, COMPUT VISION GRAPH, V51, P166, DOI 10.1016/0734-189X(90)90029-U
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Chandrakar R, 2022, MULTIMED TOOLS APPL, V81, P42149, DOI 10.1007/s11042-021-11290-4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Duval-Poo MA, 2015, IEEE T IMAGE PROCESS, V24, P3768, DOI 10.1109/TIP.2015.2451175
   Förstner W, 2009, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2009.5459458
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hasegawa T, 2014, IEEE IMAGE PROC, P5676, DOI 10.1109/ICIP.2014.7026148
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Jing J, 2021, ARXIV PREPRINT ARXIV
   Kenney CS, 2005, PROC CVPR IEEE, P191
   Kohlmann K, 1996, SIGNAL PROCESS, V48, P225, DOI 10.1016/0165-1684(95)00138-7
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mainali P, 2013, INT J COMPUT VISION, V104, P172, DOI 10.1007/s11263-013-0622-3
   Mainali P, 2011, IEEE T CIRC SYST VID, V21, P435, DOI 10.1109/TCSVT.2011.2125411
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   MEHROTRA R, 1990, PATTERN RECOGN, V23, P1223, DOI 10.1016/0031-3203(90)90118-5
   Miao ZW, 2013, PATTERN RECOGN, V46, P2890, DOI 10.1016/j.patcog.2013.03.024
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mishchuk A., 2017, P ADV NEURAL INFORM, P4826
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   Olson CF, 2000, IEEE T PATTERN ANAL, V22, P983, DOI 10.1109/34.877521
   Ono Y, 2018, ADV NEUR IN, V31
   Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Raja Rohit, 2018, International Journal of Information and Computer Security, V10, P303
   Raja R, 2020, WIRELESS PERS COMMUN, V112, P169, DOI 10.1007/s11277-019-07021-6
   Revaud J, 2019, ADV NEUR IN, V32
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shen XL, 2019, PROC CVPR IEEE, P8124, DOI 10.1109/CVPR.2019.00832
   Shui PL, 2013, IEEE T IMAGE PROCESS, V22, P3204, DOI 10.1109/TIP.2013.2259834
   Shui PL, 2012, PATTERN RECOGN, V45, P806, DOI 10.1016/j.patcog.2011.07.020
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Teng SW, 2015, PATTERN RECOGN, V48, P2185, DOI 10.1016/j.patcog.2015.01.016
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   van de Weijer J, 2005, IEEE T PATTERN ANAL, V27, P625, DOI 10.1109/TPAMI.2005.75
   Wang MZ, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107299
   Xia GS, 2014, INT J COMPUT VISION, V106, P31, DOI 10.1007/s11263-013-0640-1
   Xue N, 2018, IEEE T IMAGE PROCESS, V27, P78, DOI 10.1109/TIP.2017.2754945
   Yan P, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107808
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zhang WC, 2015, PATTERN RECOGN, V48, P2785, DOI 10.1016/j.patcog.2015.03.021
   Zhang WC, 2014, IET IMAGE PROCESS, V8, P639, DOI 10.1049/iet-ipr.2013.0641
   Zhang WC, 2020, INT J COMPUT VISION, V128, P438, DOI 10.1007/s11263-019-01257-2
   Zhang WC, 2021, IEEE T PATTERN ANAL, V43, P1213, DOI 10.1109/TPAMI.2019.2949302
   Zhang WC, 2019, IEEE T IMAGE PROCESS, V28, P4444, DOI 10.1109/TIP.2019.2910655
   Zhang WC, 2017, PATTERN RECOGN, V63, P193, DOI 10.1016/j.patcog.2016.10.008
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
   Zhang X, 2017, PROC CVPR IEEE, P4923, DOI 10.1109/CVPR.2017.523
   Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50
NR 62
TC 1
Z9 1
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28729
EP 28754
DI 10.1007/s11042-022-12666-w
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900004
DA 2024-07-18
ER

PT J
AU Oulhadj, M
   Riffi, J
   Chaimae, K
   Mahraz, AM
   Ahmed, B
   Yahyaouy, A
   Fouad, C
   Meriem, A
   Idriss, BA
   Tairi, H
AF Oulhadj, Mohammed
   Riffi, Jamal
   Chaimae, Khodriss
   Mahraz, Adnane Mohamed
   Ahmed, Bennis
   Yahyaouy, Ali
   Fouad, Chraibi
   Meriem, Abdellaoui
   Idriss, Benatiya Andaloussi
   Tairi, Hamid
TI Diabetic retinopathy prediction based on deep learning and deformable
   registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Diabetic retinopathy; Deformable registration; Image
   classification; Convolutional neural networks
ID ELASTIC REGISTRATION
AB Diabetic retinopathy is one of the most dangerous complications of diabetes. It affects the eyes causing damage to the blood vessels of the retina. Eventually, as the disease develops, it is possible to lose sight. The main cure for this pathology is based on the early detection which plays a crucial role in slowing the progress of the underlying disease and protecting many patients from losing their sight. However, the detection of diabetic retinopathy at its early stages remains an arduous task that requires human expert interpretation of fundus images in order to vigilantly follow-up the patient. In this paper, we shall propose a new automatic diabetic retinopathy detection method that based on deep-learning. The aforementioned approach is composed of two main steps: an initial pre-processing step where the deformable registration is applied on the retina to occupy the entire image and eliminate the effect of the background on the classification process. The second step is the classification phase in which we train four convolutional neural networks (CNN) models (Densenet-121, Xception, Inception-v3, Resnet-50) to detect the stage of diabetic retinopathy. The performance of our proposed architecture has been tested on the APTOS 2019 dataset. As the latter is relatively small, a transfer learning is adopted by pre-training the mentioned CNNs on the ImageNet dataset and fine-tuning them on the APTOS dataset. In the testing phase, the final prediction is obtained by a system of voting based on the output of the four convolutional neural networks. Our model has performed an accuracy of 85.28% in the testing phase.
C1 [Oulhadj, Mohammed; Riffi, Jamal; Chaimae, Khodriss; Mahraz, Adnane Mohamed; Yahyaouy, Ali; Tairi, Hamid] Univ Sidi Mohamed Ben Abdellah, Dept Informat, LISAC Lab, Fac Sci Dhar El Mahraz Fez, Fes, Morocco.
   [Chaimae, Khodriss; Ahmed, Bennis; Fouad, Chraibi; Meriem, Abdellaoui; Idriss, Benatiya Andaloussi] Sidi Mohammed Ben Abdellah Univ, Ophtalmol Dept Hassan II Hosp, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Oulhadj, M (corresponding author), Univ Sidi Mohamed Ben Abdellah, Dept Informat, LISAC Lab, Fac Sci Dhar El Mahraz Fez, Fes, Morocco.
EM moulhadj2@gmail.com
RI riffi, jamal/GZH-2170-2022; Yahyaouy, Ali/JNE-0618-2023
OI Yahyaouy, Ali/0000-0003-1954-2734; BENATIYA ANDALOUSSI,
   IDRISS/0000-0002-3097-9104; oulhadj, mohammed/0000-0001-9084-7552
FU CNSRT Morocco
FX This research was supported by CNSRT Morocco, under a project called
   AL-KHAWARIZMI Program (Al-Khwarizmi Program to Support Research in the
   Field of Artificial Intelligence and its Applications). We thank our
   colleagues co-authors from the Department of Ophthalmology, Faculty of
   Medicine and Pharmacy, University of Mohamed Ben Abdallah, Fez, Morocco
   who provided insight and experience that greatly assisted in the
   research.
CR Alyoubi W.L., 2020, INFORM MED UNLOCKED, DOI 10.1016/j.imu.2020.100377
   [Anonymous], 2019, Aptos
   [Anonymous], 2017, INFORMATION, DOI [DOI 10.3390/info8030091, DOI 10.3390/INFO8030091]
   Arganda-Carreras I, 2006, LECT NOTES COMPUT SC, V4241, P85
   Arora M, 2019, 2019 INT C MACH LEAR, P189, DOI DOI 10.1109/COMITCON.2019.8862217
   Atlas D, 2019, INT DIABETES FEDERAT
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Carrera EV, 2017, PROCEEDINGS OF THE 2017 IEEE XXIV INTERNATIONAL CONFERENCE ON ELECTRONICS, ELECTRICAL ENGINEERING AND COMPUTING (INTERCON), DOI 10.1109/INTERCON.2017.8079692
   Chetoui M, 2018, CAN CON EL COMP EN
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Dekhil O, 2019, IEEE CONF IMAGING SY, DOI 10.1109/ist48021.2019.9010333
   EyePACS, Diabetic retinopathy detection
   Fan RZ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121369
   Gangwar Akhilesh Kumar, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), P679, DOI DOI 10.1007/978-981-15-5788-064
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jamal Ibaa., 2012, TELKOMNIKA, V10, P537, DOI [DOI 10.12928/TELKOMNIKA.V10I3.834, DOI 10.12928/telkomnika.v10i3.834]
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   Kassani SH, 2019, IEEE INT SYMP SIGNAL, DOI 10.1109/isspit47144.2019.9001846
   Kumar G, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P379, DOI 10.1109/BigMM50055.2020.00065
   Kybic J, 2003, IEEE T IMAGE PROCESS, V12, P1427, DOI 10.1109/TIP.2003.813139
   Murugan R, 2020, MULTIMED TOOLS APPL, V79, P24949, DOI 10.1007/s11042-020-09217-6
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Orujov F, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106452
   Pak A, 2020, COGENT ENG, V7, DOI 10.1080/23311916.2020.1805144
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Prasad PS., 2020, ARXIV PREPRINT ARXIV
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Ramasamy LK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.456
   Sharma HS, 2019, DETECTION DIABETIC R, DOI [10.2139/ssrn.3419210, DOI 10.2139/SSRN.3419210]
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Solomon SD, 2017, DIABETES CARE, V40, P412, DOI 10.2337/dc16-2641
   Sorzano COS, 2005, IEEE T BIO-MED ENG, V52, P652, DOI 10.1109/TBME.2005.844030
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wu B, 2017, COMPUT MED IMAG GRAP, V55, P106, DOI 10.1016/j.compmedimag.2016.08.001
   Yehui Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P533, DOI 10.1007/978-3-319-66179-7_61
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhou JF, 2022, P IEEE, V110, P31, DOI 10.1109/JPROC.2021.3127493
   Zhuang H, 2020, ARXIV PREPRINT ARXIV
NR 43
TC 14
Z9 14
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28709
EP 28727
DI 10.1007/s11042-022-12968-z
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900016
DA 2024-07-18
ER

PT J
AU Hiremani, VA
   Senapati, KK
AF Hiremani, Vani A.
   Senapati, Kishore Kumar
TI Developing real-time training dataset for human racial classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data collection; Image compression; Image enhancement and face detection
AB In every image processing venture the quality of data sample collected and the processing techniques poses direct impact on the result. This work explains development of these vital phases in the context to exploit it for racial classification. Here we propose a novel Indian regional face database (IRFD) consisting of large set distinctive face images of north, east, west and south regions of India to mitigate the scarcity of regional and labeled face images for future supervised classification process. The face images are collected from different universities and acquired through both online and offline mode. Due to this discrepancy the face database is exposed to challenges like varying dimension size, non-uniform background, low resolution, illumination, and pose variation. In view of addressing these problems we have proposed competent image processing techniques to enhance the quality of images. Varying size and low resolution were the main issues among others encountered while training Convolutional Neural Network (CNN) model. To handle this we have developed an expeditious compression algorithm which would reduce large size of all images to +/- 97% less in size without compromising the quality. Further to enhance low quality images we have proposed brightness and contrast adjusting algorithm. The efficiency of this quantitative and qualitative data set is evaluated against CNN model which has yielded +/- 88.21% accuracy under racial classification.
C1 [Hiremani, Vani A.; Senapati, Kishore Kumar] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Hiremani, VA (corresponding author), Birla Inst Technol, Dept Comp Sci & Engn, Ranchi, Bihar, India.
EM vani.hiremani@gmail.com; kksenapati@bitmesra.ac.in
RI Senapati, Kishore Kumar/M-1222-2017
OI Senapati, Kishore Kumar/0000-0002-5696-4832; Hiremani,
   Vani/0000-0002-3946-4019
CR Abuzneid M, 2018, IMPROVING HUMAN FACE, DOI [10.1109/AICCSA.2018.8612896, DOI 10.1109/AICCSA.2018.8612896]
   Akhtar N, 2014, INT CONF COMM SYST, P866, DOI 10.1109/CSNT.2014.180
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2007, IRANIAN FACE DATABAS, DOI [10.1109/ICMV.2007.4469272, DOI 10.1109/ICMV.2007.4469272]
   Beghdadi A, 2018, CEED A DATABASE IMAG, DOI [10.1109/CVCS.2018.8496603.2018, DOI 10.1109/CVCS.2018.8496603.2018]
   Bhattacharya S, 2014, LOCALIZED IMAGE ENHA, DOI [10.1109/NCC.2014.6811269, DOI 10.1109/NCC.2014.6811269]
   Cao J, 2018, CELEB 500K LARGE TRA, DOI [10.1109/ICIP.2018.8451704, DOI 10.1109/ICIP.2018.8451704]
   Chaudhari MN, 2019, FACE DETECTION USING, DOI [10.1109/ICCUBEA.2018.8697768, DOI 10.1109/ICCUBEA.2018.8697768]
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Esty A, 2018, IEEE ENG MED BIO, P6096, DOI 10.1109/EMBC.2018.8513681
   Hiremani V, 2019, PROC IEEE INT C SMAR, P131
   Hiremani VA, 2013, IJACR
   Hosseini MS, 2020, IEEE T IMAGE PROCESS, V29, P250, DOI 10.1109/TIP.2019.2929865
   Hussein HK, 2002, REALISTIC FACIAL MOD, DOI [10.1109/SMI.2002.10035547, DOI 10.1109/SMI.2002.10035547]
   Jeromel A, 2020, MULTIMED TOOLS APPL, V79, P433, DOI 10.1007/s11042-019-08126-7
   Katti H, 2019, J VISION, V19, DOI 10.1167/19.7.1
   Khanh TL, 2021, MULTIMED TOOLS APPL, V80, P9479, DOI 10.1007/s11042-020-10106-1
   Lee DH, 2021, APPL INTELL, V51, P237, DOI 10.1007/s10489-020-01827-9
   Lin YN, 2020, MULTIMED TOOLS APPL, V79, P34339, DOI 10.1007/s11042-020-08907-5
   Panetta K, 2020, IEEE T PATTERN ANAL, V42, P509, DOI 10.1109/TPAMI.2018.2884458
   Patel R, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2283, DOI 10.1109/WiSPNET.2016.7566549
   Reecha S, 2015, IJCA, DOI [10.5120/ijca2015906055, DOI 10.5120/IJCA2015906055]
   Satone KN, 2017, REV IMAGE COMPRESSIO, DOI [10.1109/ICECA.2017.8203651, DOI 10.1109/ICECA.2017.8203651]
   Setty S, 2013, NAT CONF COMPUT VIS
   Singh KB, 2017, IMAGE ENHANCEMENT AP, DOI [10.1109/IESPC.2017.8071892, DOI 10.1109/IESPC.2017.8071892]
   Somanath G, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130517
   Spahiu CS, 2009, FILE STORAGE MULTIME, DOI [10.1109/ICCGI.2009.13, DOI 10.1109/ICCGI.2009.13]
   Wang R, 2006, ENHANCING TRAINING S, DOI [10.1109/ICPR.2006.493, DOI 10.1109/ICPR.2006.493]
   Wang Y, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P39, DOI 10.1109/MIPR.2018.00015
NR 31
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28103
EP 28127
DI 10.1007/s11042-022-12947-4
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644100019
DA 2024-07-18
ER

PT J
AU Wei, LX
   Xi, ZY
   Hu, ZY
   Sun, H
AF Wei, Lixin
   Xi, Zeyu
   Hu, Ziyu
   Sun, Hao
TI SiamSYB: simple yet better methods to enhance Siamese tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single target tracking; Siamese network; Attention mechanism; Template
   update
AB Siamese-based single target trackers estimate the position of target in following frames of video. When facing complex scenes, obtaining accurate response map is the key to improve tracking performance. The robustness of most trackers is bad without template update. To solve these issues, a simple yet better tracking network (SiamSYB) is proposed. SiamSYB integrates the attention mechanism and template update module. With adding the attention mechanism, the network is more focus on the target. And the template update module makes network more robust when facing the challenges, including background clutter, similar objects and object deformation. Multi-stage offline training strategy is applied to get more accurate model. SiamSYB is the state-of-the-art tracker on 3 official test datasets, including VOT2016, VOT2019 and OTB100. SiamSYB achieves 0.391 EAO and 0.237 EAO on VOT2016 and VOT2019. SiamSYB achieves 0.853 precision score and 0.642 AUC score on OTB100. The tracking speed of SiamSYB is 90 FPS, which far surpasses the real-time speed of 25 FPS.
C1 [Wei, Lixin; Xi, Zeyu; Hu, Ziyu; Sun, Hao] Yanshan Univ, Minist Educ Intelligent Control Syst & Intelligen, Engn Res Ctr, Qinhuangdao, Hebei, Peoples R China.
   [Wei, Lixin; Xi, Zeyu; Hu, Ziyu; Sun, Hao] China Yaohua Glass Grp Co Ltd, Qinhuangdao, Hebei, Peoples R China.
C3 Yanshan University
RP Xi, ZY (corresponding author), Yanshan Univ, Minist Educ Intelligent Control Syst & Intelligen, Engn Res Ctr, Qinhuangdao, Hebei, Peoples R China.; Xi, ZY (corresponding author), China Yaohua Glass Grp Co Ltd, Qinhuangdao, Hebei, Peoples R China.
EM wlx2000@ysu.edu.cn; xi961226@163.com; hzy@ysu.edu.cn; sunhao@ysu.edu.cn
RI Wei, Lixin/AFJ-0797-2022; Hu, Ziyu/AAH-2396-2020
OI Xi, Zeyu/0000-0002-3181-6761
FU National Key Research and Development Program of China [2018YFB1702300];
   National Natural Science Foundation of China [62003296]; Natural Science
   Foundation of Hebei [F2020203031]; Hebei Youth Fund [E2018203162]
FX This work was supported by National Key Research and Development Program
   of China (No.2018YFB1702300), National Natural Science Foundation of
   China (No.62003296), Natural Science Foundation of Hebei
   (No.F2020203031), Hebei Youth Fund (No.E2018203162).
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Bao H, 2020, MULTIMED TOOLS APPL, V79, P27465, DOI 10.1007/s11042-020-09309-3
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Fan H, 2021, INT J COMPUT VISION, V129, P439, DOI 10.1007/s11263-020-01387-y
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Hadfield S., 2016, VISUAL OBJECT TRACKI
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu ZY, 2021, ARCH COMPUT METHOD E, V28, P405, DOI 10.1007/s11831-019-09380-6
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Leng XL, 2021, MULTIMED TOOLS APPL, V80, P12581, DOI 10.1007/s11042-020-10336-3
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P27933, DOI 10.1007/s11042-019-07864-y
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Nam H., 2016, Modeling and propagating CNNs in a tree structure for visual tracking
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wei LX, 2021, VISUAL COMPUT, V37, P133, DOI 10.1007/s00371-019-01787-3
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Zhang HX, 2021, VISUAL COMPUT, V37, P2433, DOI 10.1007/s00371-020-01997-0
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang NN, 2020, MULTIMED TOOLS APPL, V79, P15965, DOI 10.1007/s11042-018-6871-y
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao F, 2020, MM 20
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhong WL, 2020, MULTIMED TOOLS APPL, V79, P22525, DOI 10.1007/s11042-019-08395-2
   Zhu G, 2015, COMPUT SCI, P943
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 51
TC 0
Z9 0
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26245
EP 26264
DI 10.1007/s11042-022-12569-w
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900010
DA 2024-07-18
ER

PT J
AU Gebereselassie, SA
   Roy, BK
AF Gebereselassie, Samuel Amde
   Roy, Binoy Krishna
TI Secure speech communication based on the combination of chaotic
   oscillator and logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure communication; Logistic map; Speech encryption; Synchronize;
   Chaotic oscillator
ID SYNCHRONIZATION; ENCRYPTION; SYSTEM; LU; CHEN
AB This paper uses a combination of a logistic map and a five-term chaotic oscillator to develop a secure speech communication technique. Firstly, an active controller is designed to synchronize the five terms chaotic oscillators at the transmitter and receiver sides. Then, the first encryption level of row-column shift and a bit XOR operation are performed using the chaotic oscillator. It is followed by a bit-level permutation using the combined key, generated by the chaotic oscillator and the logistic map to enhance the security. Various security analysis methods, such as spectrogram analysis, histogram analysis, correlation test, periodogram analysis, SNR analysis, etc. are used to assess the claim of higher security made in this paper. The simulation results confirm that the proposed technique is more secured than some similar available techniques. The proposed technique's ability to resist various attacks is tested and found to have adequate resistance to various attacks.
C1 [Gebereselassie, Samuel Amde; Roy, Binoy Krishna] Natl Inst Technol Silchar, Dept Elect Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Gebereselassie, SA (corresponding author), Natl Inst Technol Silchar, Dept Elect Engn, Silchar 788010, Assam, India.
EM samuel_rs@ee.nits.ac.in; bkr@ee.nits.ac.in
OI Amde Gebereselassie, Samuel/0000-0003-1252-4015
CR Ahmed I, 2020, ARAB J SCI ENG, V45, P1567, DOI 10.1007/s13369-019-04080-6
   Al-Hazaimeh O. M., 2021, International Journal of Electrical and Computer Engineering (IJECE), V11, P2203
   Alemami Y., 2020, INT J ELECTR COMPUT, V10, P5658, DOI DOI 10.11591/IJECE.V10I6.PP5658-5664
   An XL, 2011, MATH COMPUT MODEL, V54, P7, DOI 10.1016/j.mcm.2011.01.020
   Aval K. J., 2013, J COMPUTER SCI COMPU, V3
   Bosworth BT, 2008, IEEE J OCEANIC ENG, V33, P414, DOI 10.1109/JOE.2008.2001780
   Chang WD, 2015, J CONTROL SCI ENG, V2015, DOI 10.1155/2015/471913
   CUOMO KM, 1993, IEEE T CIRCUITS-II, V40, P626, DOI 10.1109/82.246163
   Farsana FJ, 2020, ADV MATH PHYS, V2020, DOI 10.1155/2020/8050934
   Filali RL, 2015, INT J COMPUT COMMUN, V10, P308, DOI 10.15837/ijccc.2015.3.709
   Giap VN, 2021, IEEE ACCESS, V9, P23907, DOI 10.1109/ACCESS.2021.3056413
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hashemi SY, 2023, INT J ENVIRON AN CH, V103, P5368, DOI 10.1080/03067319.2021.1938021
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   JarJar Abdellatif, 2021, Journal of Multimedia Information System, V8, P131, DOI 10.33851/JMIS.2021.8.2.131
   Kalpana M, 2019, MULTIMED TOOLS APPL, V78, P5969, DOI 10.1007/s11042-018-6373-y
   Kaur G, 2021, MULTIMED TOOLS APPL, V80, P10927, DOI 10.1007/s11042-020-10223-x
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Kocamaz UE, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618500573
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   Mahmoud GM, 2009, NONLINEAR DYNAM, V55, P43, DOI 10.1007/s11071-008-9343-5
   Mobini M., 2018, J WORLDS ELECT ENG T, V7, P9
   Munmuangsaen B, 2009, PHYS LETT A, V373, P4038, DOI 10.1016/j.physleta.2009.08.068
   Naskar PK, 2019, MULTIMED TOOLS APPL, V78, P25019, DOI 10.1007/s11042-019-7696-z
   Nwachioma C, 2019, IEEE ACCESS, V7, P7510, DOI 10.1109/ACCESS.2018.2889964
   Roy A, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11808-x
   Salamon M, 2012, APPL CRYPTOGRAPHY NE, P295
   Sasikaladevi N, 2018, INT J SPEECH TECHNOL, V21, P319, DOI 10.1007/s10772-018-9510-0
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Singh JP, 2018, NONLINEAR DYNAM, V92, P373, DOI 10.1007/s11071-018-4062-z
   Singh JP., 2014, IFAC P, V47, P292, DOI DOI 10.3182/20140313-3-IN-3024.00069
   Singh PP, 2014, CHAOS SOLITON FRACT, V69, P31, DOI 10.1016/j.chaos.2014.09.005
   Smaoui N, 2017, NONLINEAR DYNAM, V90, P271, DOI 10.1007/s11071-017-3660-5
   Tamba VK, 2018, ADV MATH PHYS, V2018, DOI 10.1155/2018/5985489
   Uyaroglu Y, 2015, J VIB CONTROL, V21, P1657, DOI 10.1177/1077546313501186
   Vaidyanathan S, 2016, STUD FUZZ SOFT COMP, V337, P481, DOI 10.1007/978-3-319-30340-6_20
   Vincent UE, 2008, NONLINEAR ANAL-MODEL, V13, P253, DOI 10.15388/NA.2008.13.2.14583
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu XJ, 2015, APPL MATH COMPUT, V252, P201, DOI 10.1016/j.amc.2014.12.027
   Xiu CB, 2021, NONLINEAR DYNAM, V104, P789, DOI 10.1007/s11071-021-06302-9
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang QJ, 2008, CHINESE PHYS B, V17, P492, DOI 10.1088/1674-1056/17/2/025
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 44
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26061
EP 26079
DI 10.1007/s11042-022-12803-5
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100011
DA 2024-07-18
ER

PT J
AU Taha, MS
   Rahem, MSM
   Hashim, MM
   Khalid, HN
AF Taha, Mustafa Sabah
   Rahem, Mohd Shafry Mohd
   Hashim, Mohammed Mahdi
   Khalid, Hiyam N.
TI High payload image steganography scheme with minimum distortion based on
   distinction grade value method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Data hiding; Image steganography; Image visual
   quality; LSB; Fibonacci decomposition
ID SECURE; DCT
AB Presently, the design and development of an effective image steganography system are facing several challenges including the low capacity, poor robustness and imperceptibility. To surmount such limitations, it is important to improve the capacity and security of the steganography system while maintaining a high signal-to-noise ratio (PSNR). Based on these factors, this study is aimed to design and develop a distinction grade value (DGV) method to effectively embed the secret data into a cover image for achieving a robust steganography scheme. The design and implementation of the proposed scheme involved three phases. First, a new encryption method called the shuffle the segments of secret message (SSSM) was incorporated with an enhanced Huffman compression algorithm to improve the text security and payload capacity of the scheme. Second, the Fibonacci-based image transformation decomposition method was used to extend the pixel's bit from 8 to 12 for improving the robustness of the scheme. Third, an improved embedding method was utilized by integrating a random block/pixel selection with the DGV and implicit secret key generation for enhancing the imperceptibility of the scheme. The performance of the proposed scheme is assessed experimentally to determine the imperceptibility, security, robustness and capacity. The resistance of the proposed scheme is tested against the statistical, chi(2), Histogram and non-structural steganalysis detection attacks. The obtained PSNR values revealed the accomplishment of the higher imperceptibility and security by the proposed DGV scheme while maintaining higher capacity compared to the reported findings. In short, the proposed steganography scheme outperformed the commercially available data hiding schemes, thereby resolved the existing issues.
C1 [Taha, Mustafa Sabah; Rahem, Mohd Shafry Mohd; Hashim, Mohammed Mahdi] Univ Technol Malaysia, Sch Comp, Facil Engn, Johor Baharu, Malaysia.
   [Taha, Mustafa Sabah] Minist Oil, Missan Oil Training Inst, Baghdad, Iraq.
   [Hashim, Mohammed Mahdi] Middle Tech Univ, Tech Engn Coll, Baghdad, Iraq.
   [Khalid, Hiyam N.] Imam Al Kadhim Univ Islamic Sci, Baghdad, Iraq.
C3 Universiti Teknologi Malaysia; Middle Technical University
RP Taha, MS (corresponding author), Univ Technol Malaysia, Sch Comp, Facil Engn, Johor Baharu, Malaysia.; Taha, MS (corresponding author), Minist Oil, Missan Oil Training Inst, Baghdad, Iraq.
EM timimymustafa@gmail.com
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abdulla A. A., 2015, Ph.D. dissertation
   Abdullatif FA, 2018, J PHYS CONF SER, V1003, DOI 10.1088/1742-6596/1003/1/012027
   Al-Husainy MAF, 2019, INT J TECHNOL, V10, P731, DOI 10.14716/ijtech.v10i4.653
   Al-Tamimi AGT., 2015, INT J COMP SCI INFOR, V13, P1
   ALabaichi A., 2020, INT J ELECT COMPUTER, V10
   Alam S, 2017, ADV INTELL SYST, V516, P467, DOI 10.1007/978-981-10-3156-4_48
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V39, P2977, DOI 10.3233/JIFS-191478
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bower A, 2015, J COMB THEORY A, V135, P130, DOI 10.1016/j.jcta.2015.04.005
   Fadhel S., 2017, B ELECT ENG INFORM, V6, P99, DOI [10.11591/eei.v6i1.599, DOI 10.11591/EEI.V6I1.599]
   Fadhil AM, 2016, THESIS U TEKNOLOGI
   Gambhir A, 2019, ADV INTELL SYST, V810, P1021, DOI 10.1007/978-981-13-1513-8_103
   Mukherjee N, 2020, MULTIMED TOOLS APPL, V79, P13449, DOI 10.1007/s11042-019-08178-9
   Grajeda-Marín IR, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600108
   Gutub A, 2020, ARAB J SCI ENG, V45, P2631, DOI 10.1007/s13369-020-04413-w
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jero SE, 2016, EXPERT SYST APPL, V49, P123, DOI 10.1016/j.eswa.2015.12.010
   Jouini L., 2019, ADV DIFF EQUA, V2019, P1
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kumar R., 2020, HDB COMPUTER NETWORK, P849
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Kuo WC, 2016, INFORM PROCESS LETT, V116, P183, DOI 10.1016/j.ipl.2015.08.003
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Luo XY, 2012, MULTIMED TOOLS APPL, V57, P651, DOI 10.1007/s11042-010-0663-3
   Mahana SK, 2019, P INT C SUST COMP SC
   Nayak, 2015, IJSEAT, V3, P187
   Nikam VP, 2019, INT C INT DAT COMM, P40
   Nisha CD, 2020, ADV INTELL SYST COMP, V1057, P385, DOI 10.1007/978-981-15-0184-5_34
   Nyeem H, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Pradhan A, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1804953
   Prasad, 2019, EMERGING TECHNOLOGIE, P203, DOI DOI 10.1007/978-981-13-1501-5_17
   Rao CS, 2016, MICROELECTRONICS ELE, P103
   Rawat R, 2020, MULTIMED TOOLS APPL, V79, P1971, DOI 10.1007/s11042-019-08263-z
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Setiadi DIM, 2018, CYBERN INF TECHNOL, V18, P74, DOI 10.2478/cait-2018-0029
   Seyyedi Seyyed Amin, 2016, International Journal of Network Security, V18, P124
   Shanthakumari R, 2020, MULTIMED TOOLS APPL, V79, P3975, DOI 10.1007/s11042-019-7584-6
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Stojanovski T, 2001, IEEE T CIRCUITS-I, V48, P281, DOI 10.1109/81.915385
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Swain G, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1505896
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Swain G, 2018, ARAB J SCI ENG, V43, P7549, DOI 10.1007/s13369-018-3163-9
   Thomas E, 2015, THESIS
   Nguyen TD, 2016, MULTIMED TOOLS APPL, V75, P8319, DOI 10.1007/s11042-015-2752-9
   Vikranth BM, 2015, J EMERG TECHNOL INNO, V2
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
   Yeung YL, 2019, MULTIMED TOOLS APPL, V78, P25079, DOI 10.1007/s11042-019-7731-0
   Zodpe Harshali, 2020, Journal of King Saud University - Engineering Sciences, V32, P115, DOI 10.1016/j.jksues.2018.07.002
NR 58
TC 9
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25913
EP 25946
DI 10.1007/s11042-022-12691-9
EA MAR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100001
DA 2024-07-18
ER

PT J
AU Singh, M
   Singh, AK
AF Singh, Monu
   Singh, Amit Kumar
TI A comprehensive survey on encryption techniques for digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital images; Encryption; Security; Attacks; Hashing
ID CHAOTIC SYSTEM; ALGORITHM; SCHEME; MAP; CRYPTANALYSIS
AB With the widespread adoption of smart devices and high-speed networks, investigators are focusing on securing digital image applications, such as those on social media, in healthcare, education, business and defence, from unauthorised use. The aim of this paper is to outline various encryption techniques, especially for digital images, and their merits and limitations. Along with the study, a brief overview, notable applications and evaluation metrics of encryption techniques are provided. Then, the contribution of surveyed techniques is also summarised and compared from different technical perspectives. Finally, the significant challenges are highlighted and a few directions of possible research are proposed that could fill gaps in these domains for researchers and developers.
C1 [Singh, Monu; Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM amit.singh@nitp.ac.in; monus.phd20.cs@nitp.ac.in
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Alvarez G, 2003, PHYS LETT A, V306, P200, DOI 10.1016/S0375-9601(02)01502-5
   [Anonymous], 2010, 2010 6 IR C MACH VIS
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Bechikh R, 2015, SIGNAL PROCESS-IMAGE, V39, P151, DOI 10.1016/j.image.2015.09.006
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Birgani, 2008, 2008 3 INT C INF COM
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Contreras J, 2019, RES COMPUT SCI, V148
   Dagadu JC, 2017, I COMP CONF WAVELET, P206, DOI 10.1109/ICCWAMTIP.2017.8301480
   Dagadu JC, 2016, I COMP CONF WAVELET, P252, DOI 10.1109/ICCWAMTIP.2016.8079849
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Duseja T, 2019, MULTIMED TOOLS APPL, V78, P16727, DOI 10.1007/s11042-018-7023-0
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Faragallah OS, 2020, IEEE ACCESS, V8, P103200, DOI 10.1109/ACCESS.2020.2994583
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang X, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/7685359
   Ibrahim S, 2020, IEEE ACCESS, V8, P160433, DOI 10.1109/ACCESS.2020.3020746
   Jarin I, 2018, 2018 4TH IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2018), P99, DOI 10.1109/WIECON-ECE.2018.8783074
   Jiao K, 2017, HINDAWI SECURITY COM
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Kong DZ, 2013, APPL OPTICS, V52, P2619, DOI 10.1364/AO.52.002619
   Lakshmi C, 2020, NEURAL COMPUT APPL, V32, P11477, DOI 10.1007/s00521-019-04637-4
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Li SS, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6624809
   Li SJ, 2004, PHYS LETT A, V332, P368, DOI 10.1016/j.physleta.2004.09.028
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Lin RG, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5586959
   Liu H, 2014, OPT LASER TECHNOL, V56, P15, DOI 10.1016/j.optlastec.2013.07.009
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu LF, 2018, MULTIMED TOOLS APPL, V77, P21445, DOI 10.1007/s11042-017-5594-9
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Mallouli F, 2019, 2019 6TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (IEEE CSCLOUD 2019) / 2019 5TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (IEEE EDGECOM 2019), P173, DOI 10.1109/CSCloud/EdgeCom.2019.00022
   Mishra M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND SYSTEMS (ICCCS'14), P63, DOI 10.1109/ICCCS.2014.7068169
   Mokhtar MA, 2017, NAT RADIO SCI CO, P197, DOI 10.1109/NRSC.2017.7893504
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Munir R, 2014, TEL SYST SERV APPL T, P1
   Niu Y, 2020, IEEE ACCESS, V8, P22082, DOI 10.1109/ACCESS.2020.2970103
   Nkandeu YPK, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00318-y
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Noura H, 2019, MULTIMED TOOLS APPL, V78, P16527, DOI 10.1007/s11042-018-7000-7
   Oad A., 2014, INT J ENG ADV TECHNO, V3, P373
   Osman M., 2021, Wild and interesting facebook statistics and facts
   Parvees MYM, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1067, DOI 10.1109/ICEEOT.2016.7754851
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P11857, DOI 10.1007/s11042-018-6745-3
   PRASETYO H., 2018, 2018 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW), P1
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Rachmawati D, 2018, J PHYS CONF SER, V978, DOI 10.1088/1742-6596/978/1/012116
   Ramírez-Torres MT, 2014, INT J MOD PHYS C, V25, DOI 10.1142/S0129183114500545
   Rao Anjana, 2018, 2018 3rd International Conference on Computational Systems and Information Technology for Sustainable Solutions (CSITSS), P98, DOI 10.1109/CSITSS.2018.8768797
   Rhouma R, 2009, PHYS LETT A, V373, P3398, DOI 10.1016/j.physleta.2009.07.035
   Roy S, 2021, MULTIMED TOOLS APPL, V80, P31529, DOI 10.1007/s11042-020-09880-9
   Russell, 2017, YEAR BYTE
   Singh N, 2010, OPT LASER TECHNOL, V42, P724, DOI 10.1016/j.optlastec.2009.11.016
   Somaraj S, 2016, INT CONF ADV COMPU, P275, DOI 10.1109/IACC.2016.59
   Sprott JC, 2011, INT J BIFURCAT CHAOS, V21, P2391, DOI 10.1142/S021812741103009X
   Sreeram K. L., 2020, P INT C EM TECHN INC, P1, DOI [10.1109/INCET49848.2020.9154174, DOI 10.1109/INCET49848.2020.9154174]
   Systrom, 2021, INSTAGRAM NUMBERS ST
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Tedmori S, 2012, INT ARAB J INF TECHN, V9, P471
   Wang SY, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/4138654
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wong KW, 2020, MULTIMED TOOLS APPL, V79, P25259, DOI 10.1007/s11042-020-09191-z
   Wu ZZ, 2019, IEEE ACCESS, V7, P37989, DOI 10.1109/ACCESS.2019.2906770
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P21803, DOI 10.1007/s11042-017-5590-0
   Yang Fengxia, 2013, 2013 Fifth International Conference on Computational and Information Sciences (ICCIS 2013), P705, DOI 10.1109/ICCIS.2013.191
   Yassein MB., 2017, 2017 INT C ENG TECHN, P1, DOI [10.1109/ICEngTechnol.2017.8308215, DOI 10.1109/ICENGTECHNOL.2017.8308215]
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Yepdia LMH, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6615708
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang QY, 2021, IET IMAGE PROCESS, V15, P885, DOI 10.1049/ipr2.12069
   Zhang XQ, 2018, IEEE ACCESS, V6, P70025, DOI 10.1109/ACCESS.2018.2879844
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 90
TC 8
Z9 8
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11155
EP 11187
DI 10.1007/s11042-022-12791-6
EA MAR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000770549800017
DA 2024-07-18
ER

PT J
AU Gui, XQ
   Huang, J
   Li, L
   Li, SL
   Cao, J
AF Gui, Xiangquan
   Huang, Jun
   Li, Li
   Li, Shouliang
   Cao, Jie
TI A novel hyperchaotic image encryption algorithm with simultaneous
   shuffling and diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaotic map; Image encryption; Simultaneous shuffling and diffusion
ID COUPLED MAP; BIT-LEVEL; S-BOX; CRYPTANALYSIS; COMBINATION
AB The performance of an image encryption algorithm based on chaos is largely determined by the nonlinear characteristics of the underlying chaotic system. This paper proposes a mixed one- and two-dimensional chaotic map (MOTDCM) that has a wider hyperchaotic interval, a larger maximum Lyapunov exponent, and more complex nonlinear dynamics than most existing chaotic systems. Using the hyperchaotic sequences generated by the MOTDCM, a novel image encryption algorithm with different structures is proposed, in which shuffling and diffusion are carried out simultaneously from the perspective of the whole input image. Simulation results and a comparative analysis show that the proposed encryption algorithm has a large key space, high sensitivity to the secret key, and good statistical ciphertext properties. It has a better diffusion effect than existing algorithms and meets the imposed security requirements within only one round of operation, with a reduction in algorithm complexity and an improvement in encryption efficiency. Experimental results demonstrate that this encryption algorithm has good performance and can resist chosen-plaintext attacks and known-plaintext attacks effectively.
C1 [Gui, Xiangquan; Huang, Jun; Li, Li; Cao, Jie] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
   [Li, Shouliang] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University
RP Huang, J (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM xqgui@lut.cn; brioal@foxmail.com; lili0226@139.com; lishoul@lzu.edu.cn;
   caoj@lut.edu.cn
RI Cao, jie/JXR-6551-2024
OI Huang, Jun/0000-0001-7251-8659
FU National Key Research and Development Program of China [2018YFB1702902];
   National Natural Science Foundations of China [61763028, 61862040]
FX This research is supported by The National Key Research and Development
   Program of China (no.2018YFB1702902) and The National Natural Science
   Foundations of China under grants nos. 61763028 and 61862040. The
   authors gratefully acknowledge the anonymous reviewers for their helpful
   comments and suggestions.
CR Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Cai ST, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040282
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Farwa S, 2020, MULTIMED TOOLS APPL, V79, P28225, DOI 10.1007/s11042-020-09324-4
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   GAO F, 1992, COMP MATH MATH PHYS+, V32, P403
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Li SL, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110326
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   Shevchenko II, 2014, PHYS LETT A, V378, P34, DOI 10.1016/j.physleta.2013.10.035
   Tu GY, 2013, OPTIK, V124, P5411, DOI 10.1016/j.ijleo.2013.03.113
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Wang XY, 2019, OPT LASER ENG, V122, P225, DOI 10.1016/j.optlaseng.2019.04.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2016, J VIB CONTROL, V22, P1171, DOI 10.1177/1077546314534717
   Ye XL, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105905
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
NR 37
TC 7
Z9 8
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21975
EP 21994
DI 10.1007/s11042-022-12239-x
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770205800004
DA 2024-07-18
ER

PT J
AU Lei, HZ
   Li, SY
   Wang, H
AF Lei, Hanzhe
   Li, Shuyu
   Wang, Han
TI A weighted social network publishing method based on diffusion wavelets
   transform and differential privacy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Differential privacy; Diffusion wavelets transform;
   Privacy Preservation
AB Trying to solve the problem of weight information disclosure in weighted social network, a privacy preserving data publishing method named DWT-DP is proposed in the paper. After partitioning the social network into multiple communities by using Louvain algorithm, the DWT-DP method designs an adaptive allocation strategy for privacy budget based on modularity, to extend the life cycle of privacy budget and reduce the amount of injected noise. For each community, diffusion wavelets transform (DWT) is performed and Laplace noise is added to the corresponding DW tree. The DWT-DP method also presents a community re-connection algorithm to connect perturbed communities with certain probability for synthesizing a complete social network. Experimental results on two real datasets show that the proposed method achieves good data utility in condition of preserving sensitive weight information.
C1 [Lei, Hanzhe; Li, Shuyu; Wang, Han] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
C3 Shaanxi Normal University
RP Lei, HZ; Li, SY (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
EM leihanzhe@snnu.edu.cn; lishuyu@snnu.edu.cn; wanghan061@163.com
FU Fundamental Research Funds for the Central Universities [GK201906009];
   CERNET Innovation Project [NGII20190704]; Science and Technology Program
   of Xi'an City [2019216914GXRC005CG006-GXYD5.2]; Key Research and
   Development Program of Shaanxi Province [2021GY-090]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (No. GK201906009), CERNET Innovation Project (No.
   NGII20190704), Science and Technology Program of Xi'an City (No.
   2019216914GXRC005CG006-GXYD5.2), Key Research and Development Program of
   Shaanxi Province (No. 2021GY-090).
CR Abawajy JH, 2016, IEEE COMMUN SURV TUT, V18, P1974, DOI 10.1109/COMST.2016.2533668
   Ahmed F, 2016, INT CON DISTR COMP S, P447, DOI 10.1109/ICDCS.2016.74
   Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P53, DOI 10.1016/j.acha.2006.04.004
   Day WY, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P123, DOI 10.1145/2882903.2926745
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Jorgensen Z, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P107, DOI 10.1145/2882903.2915215
   Knuth D.E, 1993, The Stanford graph base: A platform for combinatorial computing, P577
   Lan L-h., 2015, J COMMUN, V36, P145
   Li XY, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/4267921
   Liu P, 2020, NEUROCOMPUTING, V391, P273, DOI 10.1016/j.neucom.2018.11.104
   Liu Q, 2017, IEEE T PARALL DISTR, V28, P1417, DOI 10.1109/TPDS.2016.2615020
   McSherry F, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P19
   Mehta BB, 2017, IET SOFTW, V11, P271, DOI 10.1049/iet-sen.2016.0264
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Qian Wang, 2018, IEEE Transactions on Dependable and Secure Computing, V15, P591, DOI 10.1109/TDSC.2016.2599873
   Skarkala ME, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P423, DOI 10.1109/ASONAM.2012.75
   Sun T., 2014, 2014 6 INT S PAR ARC
   TIAN H, 2018, DIFFUSION WAVELET BA
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wei JH, 2019, J PARALLEL DISTR COM, V133, P136, DOI 10.1016/j.jpdc.2019.07.002
   Zhang X., 2017, P 2017 7 INT C COMM
   Zheng X, 2020, IEEE T NETW SCI ENG, V7, P880, DOI 10.1109/TNSE.2018.2801798
NR 25
TC 2
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20311
EP 20328
DI 10.1007/s11042-022-12726-1
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600025
DA 2024-07-18
ER

PT J
AU Montalbo, FJ
AF Montalbo, Francis Jesmar
TI Truncating fined-tuned vision-based models to lightweight deployable
   diagnostic tools for SARS-CoV-2 infected chest X-rays and CT-scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coronavirus pneumonia; Covid-19; Deep learning; Deep convolutional
   neural networks; Model truncation; Medical image diagnosis
ID DEEP; COVID-19
AB In such a brief period, the recent coronavirus (COVID-19) already infected large populations worldwide. Diagnosing an infected individual requires a Real-Time Polymerase Chain Reaction (RT-PCR) test, which can become expensive and limited in most developing countries, making them rely on alternatives like Chest X-Rays (CXR) or Computerized Tomography (CT) scans. However, results from these imaging approaches radiated confusion for medical experts due to their similarities with other diseases like pneumonia. Other solutions based on Deep Convolutional Neural Network (DCNN) recently improved and automated the diagnosis of COVID-19 from CXRs and CT scans. However, upon examination, most proposed studies focused primarily on accuracy rather than deployment and reproduction, which may cause them to become difficult to reproduce and implement in locations with inadequate computing resources. Therefore, instead of focusing only on accuracy, this work investigated the effects of parameter reduction through a proposed truncation method and analyzed its effects. Various DCNNs had their architectures truncated, which retained only their initial core block, reducing their parameter sizes to <1 M. Once trained and validated, findings have shown that a DCNN with robust layer aggregations like the InceptionResNetV2 had less vulnerability to the adverse effects of the proposed truncation. The results also showed that from its full-length size of 55 M with 98.67% accuracy, the proposed truncation reduced its parameters to only 441 K and still attained an accuracy of 97.41%, outperforming other studies based on its size to performance ratio.
C1 [Montalbo, Francis Jesmar] Batangas State Univ, Coll Informat & Comp Sci, Rizal Ave Extens, Batangas City, Philippines.
C3 Batangas State University
RP Montalbo, FJ (corresponding author), Batangas State Univ, Coll Informat & Comp Sci, Rizal Ave Extens, Batangas City, Philippines.
EM francismontalbo@ieee.org
OI Montalbo, Francis Jesmar/0000-0002-1493-5080
FU Batangas State University
FX The author wishes to acknowledge Batangas State University for the
   support given to the accomplishment of this work.
CR Afshar P, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00900-3
   Alakus TB, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110120
   Aljondi R, 2020, J MED INTERNET RES, V22, DOI 10.2196/19673
   Alsharif W, 2021, RADIOGRAPHY, V27, P682, DOI 10.1016/j.radi.2020.09.010
   [Anonymous], 2016, ARXIV160207360
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Bai HX, 2020, RADIOLOGY, V296, pE156, DOI 10.1148/radiol.2020201491
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Das D, 2020, PHYS ENG SCI MED, V43, P915, DOI 10.1007/s13246-020-00888-x
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Do S, 2020, KOREAN J RADIOL, V21, P33, DOI 10.3348/kjr.2019.0312
   Druzhkov P. N., 2016, Pattern Recognition and Image Analysis, V26, P9, DOI 10.1134/S1054661816010065
   Feurer M, 2019, SPRING SER CHALLENGE, P3, DOI 10.1007/978-3-030-05318-5_1
   Gabruseva T, 2020, IEEE COMPUT SOC CONF, P1436, DOI 10.1109/CVPRW50498.2020.00183
   Ghassemi, 2020, ARXIV200611988
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Giri AK, 2020, BIOSAF HEALTH, V2, P53, DOI 10.1016/j.bsheal.2020.05.002
   Gunraj H, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.608525
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez Santa Cruz Jose Francisco, 2021, Intell Based Med, V5, P100027, DOI 10.1016/j.ibmed.2021.100027
   Hinz T, 2016, LECT NOTES COMPUT SC, V9887, P80, DOI 10.1007/978-3-319-44781-0_10
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ibrahim DM, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104348
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Istaiteh Othman, 2020, 2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA), P50, DOI 10.1109/IDSTA50958.2020.9264101
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   Kandel I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103359
   Ketkar N, 2017, Deep Learning With Python, P113, DOI DOI 10.1007/978-1-4842-2766-4_8
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai ZF, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/2061516
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Lee LK, 2015, LECT NOTES ELECTR EN, V315, DOI 10.1007/978-3-319-07674-4_99
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Lin M., 2013, ARXIV13124400
   Ma J., 2020, COVID-19 CT Lung and Infection Segmentation Dataset
   Mohammad-Rahimi H, 2021, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.638011
   Montalbo Francis Jesmar P, 2021, MethodsX, V8, P101408, DOI 10.1016/j.mex.2021.101408
   Montalbo FJP, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102583
   Morozov S., 2020, ARXIV200506465, DOI 10.1101/2020.05.20.20100362
   Polsinelli M, 2020, PATTERN RECOGN LETT, V140, P95, DOI 10.1016/j.patrec.2020.10.001
   Qian Y, 2020, INT J NURS SCI, V7, P153, DOI 10.1016/j.ijnss.2020.03.012
   Rahimzadeh M, 2020, FULLY AUTOMATED DEEP, DOI DOI 10.1101/2020.06.08.20121541
   Ramachandran P., 2017, Searching for activation functions
   Sait U, 2020, Medicine, VV1, DOI [10.17632/9XKHGTS2S6.1, 10.17632/9xkhgts2s6.1, DOI 10.17632/9XKHGTS2S6.1]
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Subbarao K, 2020, IMMUNITY, V52, P905, DOI 10.1016/j.immuni.2020.05.004
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thomford NE, 2020, OMICS, V24, P264, DOI 10.1089/omi.2019.0142
   Ting K.M., 2017, Encyclopedia of Machine Learning and Data Mining, P260, DOI [DOI 10.1007/978-1-4899-7687-1_50, 10.1007/978-1-4899-7687-150, DOI 10.1007/978-1-4899-7687-150]
   Udugama B, 2020, ACS NANO, V14, P3822, DOI 10.1021/acsnano.0c02624
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yang X., 2020, Ar xiv preprint ar xiv: 2003.13865
   Yao QH, 2020, INFORM FUSION, V53, P174, DOI 10.1016/j.inffus.2019.06.024
   Ying X, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/2/022022
   Yu T., 2020, ARXIV PREPRINT ARXIV
NR 66
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16411
EP 16439
DI 10.1007/s11042-022-12484-0
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100004
PM 35261555
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Jiang, Y
   Yan, XH
   Qi, JQ
   Li, LL
   Liu, YM
AF Jiang, Yue
   Yan, Xuehu
   Qi, Jianqing
   Li, Longlong
   Liu, Yiming
TI Meaningful secret image sharing resist to typical image processing of
   shadows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Polynomial-based SIS; Image processing; Meaningful
   shares; Lossless recovery
ID ROBUST; SCHEME; STEGANOGRAPHY; IMPROVEMENTS
AB Since the recovery of SIS is based on mathematical operations (such as Lagrange interpolation, XOR, etc), when transmitted over the internet, images are usually filtered, sampled and so on, which makes the existing secret image sharing (SIS) schemes inapplicable. In this paper, we propose a model of meaningful SIS scheme resist to typical image processing of shadows. First, the shadows are generated by extended polynomial-based SIS. Then, through pixel expansion, pixel assignment and fine adjustment, the intermediate shadows are obtained, where the intermediate shadows are consistent with the original shadows after image processing and extraction. We derive three specific algorithms for (k,n) threshold lossless meaningful SIS resist to three kinds of image processing from the model respectively. Further, the analysis of shadows quality is given. Three groups of experiments show the feasibility of the proposed method, and the general model is especially effective against down-sampling and filtering. Besides, the scheme obtains better attributes, such as lossless recovery, (k,n) threshold and meaningful shares.
C1 [Jiang, Yue; Yan, Xuehu; Qi, Jianqing; Li, Longlong] Natl Univ Def Technol, Hefei 230037, Peoples R China.
   [Jiang, Yue; Yan, Xuehu; Qi, Jianqing; Li, Longlong] Anhui Prov Key Lab Cyberspace Secur Situat Awaren, Hefei 230037, Peoples R China.
   [Liu, Yiming] Jilin Univ, Changchun 130012, Peoples R China.
C3 National University of Defense Technology - China; Jilin University
RP Jiang, Y (corresponding author), Natl Univ Def Technol, Hefei 230037, Peoples R China.; Jiang, Y (corresponding author), Anhui Prov Key Lab Cyberspace Secur Situat Awaren, Hefei 230037, Peoples R China.
EM jiangyue17@nudt.edu.cn
RI Yiming, Liu/GYJ-8249-2022; Wang, zhenhua/KFA-8731-2024; su,
   hang/KEH-2976-2024
OI Jiang, Yue/0000-0001-9403-1913; Li, Longlong/0000-0001-7390-3647
CR [Anonymous], 1994, WORKSH THEOR APPL CR
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Cevallos A, 2012, UNCONDITIONALLY SECU
   Chen BL, 2018, IEEE INT WORKSH COMP, P1, DOI 10.1080/00207160.2018.1478415
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Cheraghchi M, 2019, DESIGN CODE CRYPTOGR, V87, P1777, DOI 10.1007/s10623-018-0578-y
   Cramer R, 2008, LECT NOTES COMPUT SC, V4965, P471
   Cramer R, 2015, LECT NOTES COMPUT SC, V9057, P313, DOI 10.1007/978-3-662-46803-6_11
   Espejel-Trujillo A, 2016, MULTIMED TOOLS APPL, V75, P7855, DOI 10.1007/s11042-015-2701-7
   Ghebleh M., 2017, MULTIMED TOOLS APPL, P1
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Jhanwar MP, 2013, INT C FIN CRYPT DAT
   Jiang Y, 2020, SECRET IMAGE SHARING
   Li P.P., 2016, Journal of Trust Research, V6, P1
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Li YN, 2012, IEEE T IMAGE PROCESS, V21, P1963, DOI 10.1109/TIP.2011.2171698
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu LT, 2019, MULTIMED TOOLS APPL, V78, P1265, DOI 10.1007/s11042-018-6202-3
   Liu XX, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2723427
   Liu XL, 2016, J SENSORS, V2016, DOI 10.1155/2016/1078053
   Rabin T., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, P73, DOI 10.1145/73007.73014
   Safavi-Naini R., 2015, J INF PROCESS, V23, P554, DOI DOI 10.2197/IPSJJIP.23.554
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Sun YC, 2023, INT J SYST SCI, V54, P2859, DOI 10.1080/00207721.2020.1869346
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Wang P, 2019, COMPUT SECUR, V85, P107, DOI 10.1016/j.cose.2019.04.010
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2020, MOBIHOC 20
   Weir J, 2009, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2009.5117797
   Xuehu Yan, 2018, Journal of Real-Time Image Processing, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan X., 2018, IEEE ACCESS, P1
   Yan XF, 2021, INT J GEOGR INF SCI, V35, P490, DOI 10.1080/13658816.2020.1768260
   Yan XH, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419750
   Yan XH, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115721
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
NR 40
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 16097
EP 16115
DI 10.1007/s11042-022-12207-5
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000763256600021
DA 2024-07-18
ER

PT J
AU Zandi, MS
   Rajabi, R
AF Zandi, Mojtaba Shahidi
   Rajabi, Roozbeh
TI Deep learning based framework for Iranian license plate detection and
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iranian license plate; Detection; Recognition; Convolutional neural
   network; YOLOv3; Faster R-CNN
ID LOCALIZATION; MODEL; CNN
AB License plate recognition systems have a very important role in many applications such as toll management, parking control, and traffic management. In this paper, a framework of deep convolutional neural networks is proposed for Iranian license plate recognition. The first CNN is the YOLOv3 network that detects the Iranian license plate in the input image while the second CNN is a Faster R-CNN that recognizes and classifies the characters in the detected license plate. A dataset of Iranian license plates consisting of ill-conditioned images also developed in this paper. The YOLOv3 network achieved 99.6% mAP, 98.26% recall, 98.08% accuracy, and average detection speed is only 23ms. Also, the Faster R-CNN network trained and tested on the developed dataset and achieved 98.97% recall, 99.9% precision, and 98.8% accuracy. The proposed system can recognize the license plate in challenging situations like unwanted data on the license plate. Comparing this system with other Iranian license plate recognition systems shows that it is Faster, more accurate and also this system can work in an open environment.
C1 [Zandi, Mojtaba Shahidi; Rajabi, Roozbeh] Qom Univ Technol, Fac Elect & Comp Engn, Commun & Elect Dept, Qom, Iran.
RP Rajabi, R (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Commun & Elect Dept, Qom, Iran.
EM rajabi@qut.ac.ir
RI Zandi, Michael/H-3444-2013
OI Zandi, Michael/0000-0002-9612-9401; Rajabi, Roozbeh/0000-0002-4098-4820
CR AlyanNezhadi MM, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P22, DOI 10.1109/KBEI.2017.8324985
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   Ashoori-Lalimi M., 2011, CIRCUITS SYSTEMS, V2, P320, DOI [10.4236/cs.2011.24044, DOI 10.4236/CS.2011.24044]
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Asif MR, 2019, MULTIMED TOOLS APPL, V78, P35585, DOI 10.1007/s11042-019-08199-4
   Bulan O, 2017, IEEE T INTELL TRANSP, V18, P2351, DOI 10.1109/TITS.2016.2639020
   Chowdhury PN, 2020, MULTIMED TOOLS APPL, V79, P33303, DOI 10.1007/s11042-020-09681-0
   Dashtban M. H., 2011, INT J COMPUT APPL, V26, P22
   Dey B, 2019, IET IMAGE PROCESS, V13, P673, DOI 10.1049/iet-ipr.2018.5985
   Estebsari A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010068
   Faradji F, 2007, IEEE IMAGE PROC, P57
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Heng Sun, 2019, Signal and Information Processing, Networking and Computers. Proceedings of the 4th International Conference on Signal and Information Processing, Networking and Computers (ICSINC). Lecture Notes in Electrical Engineering (LNEE 494), P66, DOI 10.1007/978-981-13-1733-0_9
   Islam R, 2020, MULTIMED TOOLS APPL, V79, P20107, DOI 10.1007/s11042-020-08629-8
   Jorgensen H, 2017, THESIS NTNU
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Khinchi M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P363, DOI 10.1109/iss1.2019.8908014
   Li H., 2016, ARXIV160105610
   Lu Q, 2019, MULTIMED TOOLS APPL, V78, P15665, DOI 10.1007/s11042-018-6889-1
   Min WD, 2019, IET IMAGE PROCESS, V13, P1041, DOI 10.1049/iet-ipr.2018.6449
   Mohadeskasaei Seyed, 2010, INT J COMPUT THEOR E, V2, P264, DOI [10.7763/IJCTE.2010.V2.150, DOI 10.7763/IJCTE.2010.V2.150]
   Polishetty R, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P286, DOI [10.1109/ICMLA.2016.0054, 10.1109/ICMLA.2016.22]
   Pramanik R, 2020, IET IMAGE PROCESS, V14, P959, DOI 10.1049/iet-ipr.2019.0208
   Rajabi R, 2019, 2019 IEEE MILAN POWERTECH
   Rasheed S, 2012, LECT NOTES ENG COMP, P199
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salazar M.B., 2014, The Impact of Shelf Margin Geometry and Tectonics on Shelf-To-Sink Sediment Dynamics and Resultant Basin Fill Architectures, P1
   Tabrizi SS, 2016, PROCEDIA COMPUT SCI, V102, P588, DOI 10.1016/j.procs.2016.09.447
   Tang L, 2019, IET IMAGE PROCESS, V13, P451, DOI 10.1049/iet-ipr.2018.5905
   Wang WW, 2019, IEEE ACCESS, V7, P173875, DOI 10.1109/ACCESS.2019.2956357
   Zang D, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033001
   Zhang JJ, 2019, IEEE SENS J, V19, P5256, DOI 10.1109/JSEN.2019.2900257
   Zhou LJ, 2019, IET IMAGE PROCESS, V13, P1470, DOI 10.1049/iet-ipr.2018.6122
NR 39
TC 7
Z9 7
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15841
EP 15858
DI 10.1007/s11042-022-12023-x
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bi, WH
   Gao, F
   Zhang, A
   Bao, SD
AF Bi, Wenhao
   Gao, Fei
   Zhang, An
   Bao, Shuida
TI A framework for extended belief rule base reduction and training with
   the greedy strategy and parameter learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extended belief rule-based system; Rule reduction; Parameter learning
ID WEIGHT CALCULATION; ACTIVATION METHOD; EXPERT-SYSTEM; CLASSIFICATION;
   INFERENCE; METHODOLOGY; GENERATION; PREDICTION; ALGORITHM
AB The extended belief rule-based system has been used in the field of decision making in recent years for its advantage of expressing various kinds of information under uncertainty, where the extended belief rule base (EBRB) is used to store various types of uncertain knowledge in the form of belief structures. However, as data such as expert knowledge and experimental data is used to directly generate the EBRB, there could be noisy and redundant rules that not only increase the computation cost but also reduce the accuracy. To this end, a novel framework for EBR reduction and training with the greedy strategy and parameter learning is proposed in this paper. Firstly, a greedy-based EBRB reduction method is proposed, where noisy and redundant rules are be searched and removed. Then, the EBRB training method using parameter learning is introduced, where the parameters of the EBRB are trained to increase its accuracy. Next, the framework for EBRB reduction and training is introduced, and the procedure of the proposed method is detailed. Finally, two case studies are conducted to demonstrate the effectiveness and efficiency of the proposed method, and the results show that the proposed method could reduce the size of the EBRB while increasing its accuracy.
C1 [Bi, Wenhao; Gao, Fei; Zhang, An] Northwestern Polytech Univ, Sch Aeronaut, Xian, Peoples R China.
   [Bao, Shuida] Civil Aviat Univ China, Coll Airworthiness, Tianjin, Peoples R China.
C3 Northwestern Polytechnical University; Civil Aviation University of
   China
RP Bi, WH (corresponding author), Northwestern Polytech Univ, Sch Aeronaut, Xian, Peoples R China.
EM biwenhao@nwpu.edu.cn
RI zhang, an/JMR-3763-2023; Gao, Fei/AAT-1572-2020
OI Gao, Fei/0000-0002-9273-4559
FU National Natural Science Foundation of China [61903305, 62073267];
   Aeronautical Science Foundation of China [201905053001]; Key Laboratory
   Open Foundation of Data Link Technology [CLDL-20182113]; Research Funds
   of Interdisciplinary Subject, NWPU
FX Wenhao Bi and Fei Gao contributed equally to this work. This work is
   partially supported by the National Natural Science Foundation of China
   (No. 61903305, 62073267), the Aeronautical Science Foundation of China
   (No. 201905053001), the Key Laboratory Open Foundation of Data Link
   Technology (No. CLDL-20182113) and the Research Funds of
   Interdisciplinary Subject, NWPU.
CR Abellán J, 2014, COMPUT STAT DATA AN, V71, P789, DOI 10.1016/j.csda.2013.02.009
   [Anonymous], 2005, Fuzzy expert systems and fuzzy reasoning
   Bi WH, 2020, IEEE ACCESS, V8, P222187, DOI 10.1109/ACCESS.2020.3043848
   Calzada A, 2014, IEEE ENG MED BIO, P2694, DOI 10.1109/EMBC.2014.6944178
   Calzada Alberto, 2014, Ubiquitous Computing and Ambient Intelligence. Personalisation and User Adapted Services. 8th International Conference, UCAmI 2014. Proceedings: LNCS 8867, P312, DOI 10.1007/978-3-319-13102-3_52
   Calzada A, 2015, IEEE T KNOWL DATA EN, V27, P880, DOI 10.1109/TKDE.2014.2356460
   Chang LL, 2020, IEEE J BIOMED HEALTH, V24, P3111, DOI 10.1109/JBHI.2020.2969322
   Chang LL, 2016, INFORM SCIENCES, V336, P75, DOI 10.1016/j.ins.2015.12.009
   Chang LL, 2015, KNOWL-BASED SYST, V73, P69, DOI 10.1016/j.knosys.2014.09.006
   Chang PC, 2008, EXPERT SYST APPL, V34, P135, DOI 10.1016/j.eswa.2006.08.020
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Derrac J, 2016, INFORM SCIENCES, V329, P144, DOI 10.1016/j.ins.2015.09.007
   Dua D., 2017, UCI MACHINE LEARNING
   Dutu LC, 2018, IEEE T FUZZY SYST, V26, P715, DOI 10.1109/TFUZZ.2017.2688349
   Farhan M., 2020, Computational Mathematics and Modeling, V31, P116, DOI 10.1007/s10598-020-09480-0
   Fu YG, 2020, KNOWL-BASED SYST, V210, DOI 10.1016/j.knosys.2020.106484
   Gao F, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106856
   He W, 2018, MICROELECTRON RELIAB, V87, P33, DOI 10.1016/j.microrel.2018.05.019
   Jiao LM, 2015, INFORM SCIENCES, V309, P26, DOI 10.1016/j.ins.2015.03.005
   Li GL, 2017, SAFETY SCI, V93, P108, DOI 10.1016/j.ssci.2016.11.011
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Ligeza A., 2006, LOGICAL FDN RULE BAS
   Lin YQ, 2017, J INTELL FUZZY SYST, V33, P3695, DOI 10.3233/JIFS-17521
   Liu J, 2013, KNOWL-BASED SYST, V53, P129, DOI 10.1016/j.knosys.2013.08.019
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2020, APPL INTELL, V50, P314, DOI 10.1007/s10489-019-01542-0
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Sanchez MA, 2014, INFORM SCIENCES, V279, P498, DOI 10.1016/j.ins.2014.04.005
   Shao YH, 2015, KNOWL-BASED SYST, V73, P276, DOI 10.1016/j.knosys.2014.10.011
   SUN R, 1995, ARTIF INTELL, V75, P241, DOI 10.1016/0004-3702(94)00028-Y
   Wang YM, 2020, ECOL INDIC, V111, DOI 10.1016/j.ecolind.2020.106070
   Wang YM, 2016, KNOWL-BASED SYST, V96, P40, DOI 10.1016/j.knosys.2016.01.003
   Wang YM, 2009, EXPERT SYST APPL, V36, P8421, DOI 10.1016/j.eswa.2008.10.052
   Wu J, 2015, EXPERT SYST APPL, V42, P1487, DOI 10.1016/j.eswa.2014.09.019
   Xu DL, 2007, EXPERT SYST APPL, V32, P103, DOI 10.1016/j.eswa.2005.11.015
   Yang JB, 2006, IEEE T SYST MAN CY A, V36, P266, DOI 10.1109/TSMCA.2005.851270
   Yang JB, 2007, IEEE T SYST MAN CY A, V37, P569, DOI 10.1109/TSMCA.2007.897606
   Yang L, 2020, INT J PAVEMENT ENG, V21, P781, DOI 10.1080/10298436.2018.1511781
   Yang LH, 2018, APPL SOFT COMPUT, V72, P261, DOI 10.1016/j.asoc.2018.08.004
   Yang LH, 2018, INFORM SCIENCES, V445, P50, DOI 10.1016/j.ins.2018.02.059
   Yang LH, 2017, KNOWL-BASED SYST, V123, P174, DOI 10.1016/j.knosys.2017.02.021
   Yang Y, 2016, KNOWL-BASED SYST, V94, P105, DOI 10.1016/j.knosys.2015.11.012
   Ye FF, 2020, COMPUT IND ENG, V144, DOI 10.1016/j.cie.2020.106454
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   You YQ, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113952
   Zadeh L.A., 1996, FUZZY SETS FUZZY LOG, V6
   Zhang A, 2020, QUAL RELIAB ENG INT, V36, P2459, DOI 10.1002/qre.2708
   Zhang A, 2020, INT J APPROX REASON, V119, P20, DOI 10.1016/j.ijar.2019.12.016
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhou ZG, 2015, KNOWL-BASED SYST, V85, P62, DOI 10.1016/j.knosys.2015.04.019
   Zhou ZJ, 2021, IEEE T SYST MAN CY-S, V51, P4944, DOI 10.1109/TSMC.2019.2944893
   Zhu HZ, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106214
NR 52
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11127
EP 11143
DI 10.1007/s11042-022-12232-4
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400003
DA 2024-07-18
ER

PT J
AU Lin, C
   Wen, ZQ
   Xu, GL
   Cao, YJ
   Pan, YC
AF Lin, Chuan
   Wen, Ze-Qi
   Xu, Gui-Li
   Cao, Yi-Jun
   Pan, Yong-Cai
TI A bio-inspired contour detection model using multiple cues inhibition in
   primary visual cortex
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contour detection; Subfield; Non-classical receptive field; Surround
   inhibition; Surround-surround interaction
ID CLASSICAL RECEPTIVE-FIELD; FUNCTIONAL ARCHITECTURE; SPATIAL-FREQUENCY;
   CORTICAL-NEURONS; V1 NEURONS; COLOR; SEGMENTATION; SUPPRESSION;
   SELECTIVITY; BOUNDARIES
AB The human visual system has efficient architecture for information reception and integration for effectively performing visual tasks like detecting contours. Physiological evidence has shown that most neuronal responses in the classical receptive field (CRF) of the primary visual cortex are modulated, generally suppressed by the non-CRF surround. These center-surround interactions are thought to inhibit or facilitate responses to edges according to other similar edges in the surroundings, which is useful for suppressing textures and enhancing contours. A biologically motivated model with subfield-based inhibition is proposed in this paper to improve the performance of perceptually salient contour detection relative to the existing single-neuron based inhibition model. A novel subfield based inhibition framework is presented, where the inhibition terms are combined with center-surround and surround-surround differences using multiple cues, including orientation based energy distribution and directional saliency within regions. Extensive experimental evaluation demonstrates that the proposed method outperforms most of competing methods, especially biological motivated ones.
C1 [Lin, Chuan; Wen, Ze-Qi; Cao, Yi-Jun; Pan, Yong-Cai] Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Liuzhou 545006, Peoples R China.
   [Xu, Gui-Li] Nanjing Univ Aeronaut & Astronaut, Yudao St 29, Nanjing, Peoples R China.
C3 Guangxi University of Science & Technology; Nanjing University of
   Aeronautics & Astronautics
RP Lin, C (corresponding author), Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Liuzhou 545006, Peoples R China.
EM chuanlin@gxust.edu.cn
RI luo, chuan/IVH-5370-2023; lin, chuan/HHD-2571-2022; lin,
   chuan/HIK-1290-2022; lin, chuan/JBJ-7047-2023
OI lin, chuan/0000-0003-1779-1753; 
FU National Natural Science Foundation of China [61866002]; Guangxi Natural
   Science Foundation [2020GXNSFDA297006, 2018GXNSFAA138122,
   2015GXNSFAA139293]
FX The authors appreciate the anonymous reviewers for their helpful and
   constructive comments on an earlier draft of this paper. This work was
   supported by the National Natural Science Foundation of China (Grant No.
   61866002), Guangxi Natural Science Foundation (Grant No.
   2020GXNSFDA297006 Grant No. 2018GXNSFAA138122 and Grant No.
   2015GXNSFAA139293).
CR Albright TD, 2002, ANNU REV NEUROSCI, V25, P339, DOI 10.1146/annurev.neuro.25.112701.142900
   Angelucci A, 2006, PROG BRAIN RES, V154, P93, DOI 10.1016/S0079-6123(06)54005-1
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Azzopardi G, 2012, BIOL CYBERN, V106, P177, DOI 10.1007/s00422-012-0486-6
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   Boukerroui D, 2004, J MATH IMAGING VIS, V21, P53, DOI 10.1023/B:JMIV.0000026557.50965.09
   Bredfeldt CE, 2002, J NEUROSCI, V22, P1976, DOI 10.1523/JNEUROSCI.22-05-01976.2002
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao YJ, 2019, MULTIMED TOOLS APPL, V78, P25121, DOI 10.1007/s11042-019-7722-1
   Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2547, DOI 10.1152/jn.00693.2001
   Coen-Cagli R, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002405
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cour T, 2005, PROC CVPR IEEE, P1124
   CRONER LJ, 1995, VISION RES, V35, P7, DOI 10.1016/0042-6989(94)E0066-T
   Das A, 1999, NATURE, V399, P655, DOI 10.1038/21371
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Duda R., 1973, Pattern Classification and Scene Analysis
   Gao SB, 2013, IEEE I CONF COMP VIS, P929, DOI 10.1109/ICCV.2013.119
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Landy M. S., 2004, The visual neurosciences, V2, P1106
   Li CY, 1996, NEWS PHYSIOL SCI, V11, P181
   LI CY, 1994, VISION RES, V34, P2337, DOI 10.1016/0042-6989(94)90280-1
   Li CY, 1999, P NATL ACAD SCI USA, V96, P4052, DOI 10.1073/pnas.96.7.4052
   Lin C, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043018
   Maninis KK, 2018, IEEE T PATTERN ANAL, V40, P819, DOI 10.1109/TPAMI.2017.2700300
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Papari G, 2011, PATTERN RECOGN, V44, P1999, DOI 10.1016/j.patcog.2010.08.013
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Seriès P, 2003, J PHYSIOL-PARIS, V97, P453, DOI 10.1016/j.jphysparis.2004.01.023
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Shen ZM, 2007, J PHYSIOL-LONDON, V583, P581, DOI 10.1113/jphysiol.2007.130294
   Spratling MW, 2013, IEEE T IMAGE PROCESS, V22, P1629, DOI 10.1109/TIP.2012.2235850
   Tang QL, 2007, PATTERN RECOGN, V40, P3100, DOI 10.1016/j.patcog.2007.02.009
   Tang QL, 2016, PATTERN RECOGN, V60, P51, DOI 10.1016/j.patcog.2016.05.009
   Walker GA, 2000, VISUAL NEUROSCI, V17, P369, DOI 10.1017/S0952523800173055
   Wei H, 2016, CONNECT SCI, V28, P311, DOI 10.1080/09540091.2016.1212813
   Wei H, 2013, NEUROCOMPUTING, V103, P247, DOI 10.1016/j.neucom.2012.09.027
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu WF, 2005, CEREB CORTEX, V15, P1697, DOI 10.1093/cercor/bhi046
   Yang KF, 2016, IEEE T IMAGE PROCESS, V25, P3475, DOI 10.1109/TIP.2016.2572600
   Yang KF, 2015, PROC CVPR IEEE, P2254, DOI 10.1109/CVPR.2015.7298838
   Yang KF, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425538
   Yang KF, 2014, IEEE T IMAGE PROCESS, V23, P5020, DOI 10.1109/TIP.2014.2361210
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
   Zeng C, 2011, NEUROCOMPUTING, V74, P1527, DOI 10.1016/j.neucom.2010.12.022
   Zeng C, 2011, NEUROIMAGE, V55, P49, DOI 10.1016/j.neuroimage.2010.11.067
NR 61
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11027
EP 11048
DI 10.1007/s11042-022-12356-7
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400006
DA 2024-07-18
ER

PT J
AU Meng, XJ
   Ha, Y
   Tian, JF
AF Meng, Xiangjie
   Ha, Yan
   Tian, Junfeng
TI Neighbor Correlated Graph Convolutional Network for multi-stage malaria
   parasite recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph Convolutional Network; Malaria parasite recognition; Multi-stage;
   Neighbor correlation
AB Malaria is a serious and fatal infectious disease and early detection of the patient's infection severity can effectively curb the outbreak of this infectious disease. Deep learning has been verified to have excellent capability in image classification and disease diagnosis in many challenging tasks, such as cell detection and histological image classification. There exist many deep learning researches on malaria parasite recognition with successful applications, but they mainly focus on binary classification of single Ring stage and red blood cells. The most important disadvantage of them are ignoring other stages of malaria parasites, including Trophozoite, Gametocytes, and Schizont. In this paper, we are the first to study the multi-stage malaria parasite recognition problem, and propose a novel Neighbor Correlated Graph Convolutional Network (NCGCN) for this challenging task. Specifically, NCGCN consists of CNN (Convolutional Neural Network) feature learning, neighbor correlation mining, and graph representation modules. The method firstly extracts CNN representations from each parasite image and then establishes the neighbor correlations among CNN features by combining K-Nearest Neighbor (KNN) and epsilon-radius graph building algorithms, with operating Graph Convolutional Network (GCN) on CNN features and their correlations. To evaluate the performance of our NCGCN model, we compare it with several advanced existing methods, and our model can reach a high Accuracy of 94.17%, Precision of 94.84%, Recall of 94.17% and F1-score of 94.20%. The comparison with these outstanding methods verifies the NCGCN model has an excellent capability for recognizing multi-stage malaria parasites, which is higher than the compared methods at least 8.67% in Accuracy.
C1 [Meng, Xiangjie; Ha, Yan] Hebei Univ, Sch Management, Baoding, Peoples R China.
   [Meng, Xiangjie] Hebei Univ, Coll Math & Informat Sci, Baoding, Peoples R China.
   [Ha, Yan; Tian, Junfeng] Key Lab High Trusted Informat Syst Hebei Prov, Baoding, Peoples R China.
   [Tian, Junfeng] Hebei Univ, Sch Cyber Secur & Comp, Baoding, Peoples R China.
C3 Hebei University; Hebei University; Hebei University
RP Ha, Y (corresponding author), Hebei Univ, Sch Management, Baoding, Peoples R China.; Ha, Y (corresponding author), Key Lab High Trusted Informat Syst Hebei Prov, Baoding, Peoples R China.
EM hayanhbu@163.com
RI Lu, Wang/JVO-0416-2024
CR Aja-Fernández S, 2015, KNOWL-BASED SYST, V83, P1, DOI 10.1016/j.knosys.2015.02.029
   Bernsen J., 1986, In: Proceedings of the Eighth International Conference on Pattern Recognition, P1251
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537
   Delahunt CB, 2015, PROCEEDINGS OF THE FIFTH IEEE GLOBAL HUMANITARIAN TECHNOLOGY CONFERENCE GHTC 2015, P393, DOI 10.1109/GHTC.2015.7344002
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Habibzadeh M, 2013, LECT NOTES ARTIF INT, V7895, P263, DOI 10.1007/978-3-642-38610-7_25
   HANLEY JA, 1983, RADIOLOGY, V148, P839, DOI 10.1148/radiology.148.3.6878708
   Harrison TE, 2020, NATURE, V587, P309, DOI 10.1038/s41586-020-2530-3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Liang, 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P652, DOI 10.1039/C0JM03798B
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   King DB, 2015, ACS SYM SER, V1214, P1
   Kotepui M, 2020, SCI REP-UK, V10, DOI [10.1038/s41598-020-68082-3, 10.1038/s41598-020-69647-y]
   Li S, 2020, BIOINFORMATICS, V36, P4498, DOI 10.1093/bioinformatics/btaa513
   Li S, 2020, MSYSTEMS, V5, DOI 10.1128/mSystems.00445-19
   Li YY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010211
   Ljosa V, 2012, NAT METHODS, V9, P637, DOI 10.1038/nmeth.2083
   López-Puigdollers D, 2019, EXPERT SYST APPL, V115, P695, DOI 10.1016/j.eswa.2018.08.029
   Markiewicz T, 2007, LECT NOTES COMPUT SC, V4432, P318
   Mehanian C, 2017, IEEE INT CONF COMP V, P116, DOI 10.1109/ICCVW.2017.22
   Mustafa W.A., 2018, PROC INT C COMPUT AP, P1, DOI 10.1109/ICASSDA.2018.8477634
   Park HS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163045
   Quinn JA, 2016, MACH LEARN HEALTHC C, P271
   Rifaie-Graham O, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09122-z
   Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sherrard-Smith E, 2020, NAT MED, V26, DOI 10.1038/s41591-020-1025-y
   Simonyan K., 2014, 14091556 ARXIV
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tek FB, 2010, COMPUT VIS IMAGE UND, V114, P21, DOI 10.1016/j.cviu.2009.08.003
   Tukwasibwe S, 2020, CELL MOL IMMUNOL, V17, P799, DOI 10.1038/s41423-020-0482-z
   Umer M, 2020, IEEE ACCESS, V8, P93782, DOI 10.1109/ACCESS.2020.2994810
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vijayalakshmi A, 2020, MULTIMED TOOLS APPL, V79, P15297, DOI 10.1007/s11042-019-7162-y
   Wolf C, 2003, PATTERN ANAL APPL, V6, P309, DOI 10.1007/s10044-003-0197-7
   Yang F, 2020, IEEE J BIOMED HEALTH, V24, P1427, DOI 10.1109/JBHI.2019.2939121
   Yeon J., 2014, P 6 INT C MULT COMP, P77
NR 39
TC 5
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11393
EP 11414
DI 10.1007/s11042-022-12098-6
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200008
DA 2024-07-18
ER

PT J
AU Baniata, MOA
   Asghar, S
AF Baniata, Mahmoud Oglah Al Hasan
   Asghar, Sohail
TI Measuring the impact of social drive across social media forums: a case
   study of COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Facebook; Sentiments; Machine learning; COVID19
ID PARTICIPATION; FACEBOOK
AB Users considered Social media forums like Facebook, Twitter and blogs as the most prominent social networks in the present age, where users share their views quickly in words and respond to feedback from other users within no time. This study aims to: measure the impact of influencing factors on a particular community when social media forums promote it using a machine learning model. In this research work, we performed an association rule-based method to measure the impact of COVID-19 influencing factors on adolescence when they promoted it on social media. The proposed method gave a remarkable output when we compared it with the different existing approaches. It works well in all respective fields we observed. Last but not least, when compared with survey and official results, the proposed method predicts well, and the obtained results are pretty promising.
C1 [Baniata, Mahmoud Oglah Al Hasan; Asghar, Sohail] COMSAT Univ, Dept Comp Sci, Islamabad, Pakistan.
RP Baniata, MOA (corresponding author), COMSAT Univ, Dept Comp Sci, Islamabad, Pakistan.
EM mbaniata2211@gmail.com; sohail.asg@gmail.com
CR Alshoaibi M, 2019, Review of European Studies, V11, P1, DOI [10.5539/RES.V11N1P1, DOI 10.5539/RES.V11N1P1]
   Bozkurt A., 2017, J LEARN DEV, V4, P348
   Brewer K., 2020, CORONAVIRUS PROTECT
   Cellan-Jones R., 2020, TECH TENT IS SOCIAL
   Chew C, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014118
   Dai YF, 2020, KNOWL-BASED SYST, V190, DOI 10.1016/j.knosys.2019.105165
   Depoux A, 2020, J TRAVEL MED, V27, DOI 10.1093/jtm/taaa031
   Devlin H, 2020, DONT LET CORONAVIRUS
   Dillon C., 2020, CORONAVIRUS PSYCHOL
   Ejegwa PA, 2020, NEURAL COMPUT APPL, V32, P10199, DOI 10.1007/s00521-019-04554-6
   El-Terk N., 2020, TOILET PAPER CANNED
   Emmott R, 2020, RUSSIA DEPLOYING COR
   Frenkel S., 2020, Surge of Virus Misinformation Stumps Facebook and Twitter
   Garrett, 2020, CASE MODERN MASS HYS
   Gesser-Edelsburg A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209505
   Gold H, 2020, NEWSCHANNEL 2
   Gough Aisling, 2017, JMIR Public Health Surveill, V3, pe14, DOI 10.2196/publichealth.6313
   Hao K, 2020, The Coronavirus is the First True Social-Media Infodemic
   Hasnain H., 2015, 2 INT RES MAN INN C
   Hernandez S, 2020, PANIC SPREADS FEAR E
   JMIR E-collection, INF INF DIG DIS SURV
   Ke L, 2014, LOND REV EDUC, V12, P50, DOI 10.18546/LRE.12.1.06
   Kent S, 2020, FEAR SPREADS VIRUS C
   Lee AR, 2017, CHILD YOUTH SERV REV, V77, P127, DOI 10.1016/j.childyouth.2017.04.014
   Liang LL, 2020, PSYCHIAT QUART, V91, P841, DOI 10.1007/s11126-020-09744-3
   Mahmood Q.K., 2018, 4 INT C CONT SOC POL, V13, P59
   Merchant RM, 2020, JAMA-J AM MED ASSOC, V323, P2011, DOI 10.1001/jama.2020.4469
   Mian A, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01556-3
   MOLLA R., 2020, How coronavirus took over social media
   Muwahed, CORONAVIRUS PANDEMIC
   Petric D, 2020, NEGATIVE MENTAL HLTH
   Raghavendra P, 2018, RES DEV DISABIL, V76, P110, DOI 10.1016/j.ridd.2018.02.012
   Roblyer MD, 2010, INTERNET HIGH EDUC, V13, P134, DOI 10.1016/j.iheduc.2010.03.002
   Rothschild N., 2020, CORONAVIRUS PANIC SE
   Saud, 2020, IJWBC, V16, P1, DOI [10.1504/ijwbc.2020.10028448, DOI 10.1504/IJWBC.2020.10028448]
   Saud M, 2015, EJBS, P48, DOI [10.33422/ejbs.2018.05.85, DOI 10.33422/EJBS.2018.05.85]
   Shimizu K, 2020, LANCET, V395, P685, DOI 10.1016/S0140-6736(20)30357-3
   The Star, 2020, The Star
   Victor D., 2020, PANIC CRITICISM SPRE
   La VP, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072931
   Wongkoblap A, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7215
   Yang B, 2016, VOLUNTAS, V27, P2150, DOI 10.1007/s11266-015-9632-9
   Yao YY, 2020, INT J APPROX REASON, V116, P106, DOI 10.1016/j.ijar.2019.11.002
   Yin YY, 2017, ADV ELECT GOV DIVIDE, P130, DOI 10.4018/978-1-5225-2463-2.ch007
NR 44
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10777
EP 10795
DI 10.1007/s11042-022-12262-y
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700004
PM 35194382
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Pena-Pena, K
   Lau, DL
   Arce, AJ
   Arce, GR
AF Pena-Pena, Karelia
   Lau, Daniel L.
   Arce, Andrew J.
   Arce, Gonzalo R.
TI QRnet: fast learning-based QR code image embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR codes; Machine learning; Optimization-free
ID BLUE-NOISE
AB Quick Response (QR) codes usage in e-commerce is on the rise due to their versatility and ability to connect offline and online content, taking over almost every aspect of a business from posters to payments. Thus, many efforts have aimed at improving the visual quality of QR codes to be easily included in publicity designs in billboards and magazines. The most successful approaches, however, are slow since optimization algorithms are required for the generation of each beautified QR code, hindering its online customization. The aim of this paper is the fast generation of visually pleasant and robust QR codes. The proposed framework leverages state-of-the-art deep-learning algorithms to embed a color image into a baseline QR code in seconds while keeping a maximum probability of error during the decoding procedure. Halftoning techniques that exploit the human visual system (HVS) are used to smooth the embedding of the QR code structure in the final QR code image while reinforcing the decoding robustness. Compared to optimization-based methods, our framework provides similar qualitative results but is 3 orders of magnitude faster.
C1 [Pena-Pena, Karelia; Arce, Gonzalo R.] Univ Delaware, Newark, DE 19716 USA.
   [Lau, Daniel L.] Univ Kentucky, Lexington, KY 40506 USA.
C3 University of Delaware; University of Kentucky
RP Pena-Pena, K (corresponding author), Univ Delaware, Newark, DE 19716 USA.
EM kareliap@udel.edu; dllau@uky.edu; ajarce100@gmail.com; arce@udel.edu
RI Lau, Daniel L/O-5169-2014
OI Pena-Pena, Karelia/0000-0001-8214-6852
FU Graphiclead LLC
FX This work was supported in part by Graphiclead LLC.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Baharav Z., 2013, Multimedia and Expo (ICME), 2013 IEEE International Conference on, P1
   Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273
   Chidambaram N, 2021, MULTIMED TOOLS APPL, V80, P23359, DOI 10.1007/s11042-020-10210-2
   Chu HK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508408
   Cox R., 2012, QArt codes
   Garateguy GJ, 2014, IEEE T IMAGE PROCESS, V23, P2842, DOI 10.1109/TIP.2014.2321501
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   King DB, 2015, ACS SYM SER, V1214, P1
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Lau DanielL., 2018, Modern digital halftoning, V1
   Lau DL, 2003, IEEE SIGNAL PROC MAG, V20, P28, DOI 10.1109/MSP.2003.1215229
   Lin SS, 2015, IEEE T MULTIMEDIA, V17, P1515, DOI 10.1109/TMM.2015.2437711
   Mullen C, 2020, WILL IT LAST POSTCOV
   Owen S, 2016, MULTIFORMAT 1D 2D BA
   Rodríguez JB, 2008, IEEE T IMAGE PROCESS, V17, P1368, DOI 10.1109/TIP.2008.926145
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samretwit D., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P552, DOI 10.1109/INCoS.2011.117
   Schonfeld E., 2020, 2020 IEEECVF C COMPU, P8204, DOI 10.1109/CVPR42600.2020.00823
   Technology I, 2006, AUT ID DAT CAPT TECH
   Visualead company, FREE VIS QR COD GEN
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Xu M, 2018, ARXIV180302280CSMM
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Yongtai Zhang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P183, DOI 10.1007/978-3-319-14442-9_16
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
NR 30
TC 7
Z9 8
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10653
EP 10672
DI 10.1007/s11042-022-12357-6
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756208600004
DA 2024-07-18
ER

PT J
AU Fan, XN
   Lu, L
   Shi, PF
   Zhang, XW
AF Fan, Xinnan
   Lu, Liang
   Shi, Pengfei
   Zhang, Xuewu
TI A novel sonar target detection and classification algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sonar image; YOLOv4; Target detection; Feature fusion
AB Underwater target detection and classification based on sonar images is a challenging task because of the complex underwater environment. In recent years, deep learning technology has effectively improved the detection accuracy of underwater targets compared to traditional sonar image target detection methods, which have a low accuracy and poor robustness. However, deep learning algorithms for sonar image target detection have fewer training samples and a low detection speed. To solve these problems, an improved YOLOv4 based sonar target detection and classification algorithm is proposed in this paper. First, the feature extraction network CSPDarknet-53 in YOLOv4 is improved to reduce both the model parameters and the network depth. Second, the PANet feature enhancement module in the YOLOv4 model is replaced by the adaptive spatial feature fusion module (ASFF) to obtain a better feature fusion effect. In addition, the number of fusion feature layers is increased to improve the receptive field and detection accuracy. Furthermore, this paper uses the k-means++ algorithm to cluster the sonar image dataset to obtain the appropriate size and number of anchor boxes for model training. The experimental results show that the proposed method has better performance in detection accuracy and detection speed compared to YOLOv4 and YOLOv4-tiny.
C1 [Fan, Xinnan; Lu, Liang; Shi, Pengfei; Zhang, Xuewu] Hohai Univ, Coll IOT Engn, Changzhou 213022, Peoples R China.
C3 Hohai University
RP Shi, PF (corresponding author), Hohai Univ, Coll IOT Engn, Changzhou 213022, Peoples R China.
EM fanxn@hhuc.edu.cn; lul@hhu.edu.cn; flyshn@hotmail.com;
   zhangxw@hhu.edu.cn
RI Zhang, Xuewu/HGB-5196-2022
FU National Natural Science Foundation of China [61801169]; Applied Basic
   Research Programs of Changzhou [CJ20200061]
FX This work is supported by the National Natural Science Foundation of
   China (61801169) and the Applied Basic Research Programs of Changzhou
   (CJ20200061).
CR Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Bochkovskiy A., 2020, PREPRINT
   Chen KJ, 2019, IEEE T SMART GRID, V10, P3943, DOI 10.1109/TSG.2018.2844307
   Ferguson EL, 2017, INT CONF ACOUST SPEE, P2657, DOI 10.1109/ICASSP.2017.7952638
   Gao H, 2017, ARXIV 170400109
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huo GY, 2020, IEEE ACCESS, V8, P47407, DOI 10.1109/ACCESS.2020.2978880
   Karimanzira D, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071180
   Kong WZ, 2020, IEEE SENS J, V20, P3745, DOI 10.1109/JSEN.2019.2960796
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S., 2019, CVPR
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sung MS, 2020, INT J CONTROL AUTOM, V18, P523
   Sung MS, 2019, IEEE SENS J, V19, P9929, DOI 10.1109/JSEN.2019.2925830
   Valdenegro-Toro M, 2017, OCEANS-IEEE
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Williams DP, 2016, INT C PATT RECOG, P2497, DOI 10.1109/ICPR.2016.7900011
NR 23
TC 8
Z9 10
U1 16
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10091
EP 10106
DI 10.1007/s11042-022-12054-4
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800013
DA 2024-07-18
ER

PT J
AU Lanjewar, MG
   Gurav, OL
AF Lanjewar, M. G.
   Gurav, O. L.
TI Convolutional Neural Networks based classifications of soil images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Deep Convolutional Neural Network; K-fold; Confusion matrix; Soil
   types
AB The utilization of Artificial Intelligence (AI) and Machine Learning(ML) in the image processing domain is useful to detect and recognize the types of soil. The main aim of the present work is to process the soil images and classify them accurately by using Tensorflow and Keras Deep Learning (DL) frameworks with pre-trained weights. There are several ML models already implemented for the classification of soil images. A dataset has 903 soil images of four different types of soil (alluvial, black, clay, and red). These images were divided into a training dataset and a validation dataset. The image augmentation process was applied to the dataset, and then the models are trained with these augmented images. In the present work, the Convolutional Neural Network (CNN) model was implemented to classify the soil images and achieved an accuracy of 99.86% for training and 97.68% for validation. Furthermore, six Deep Convolution Neural Network (DCNN) models were implemented, such as Rsnet152V2, VGG-16, VGG-19, Inception-ResNetV2, Xception, and DenseNet201, to classify the soil images. The accuracy of a Rsnet152V2, VGG-16, VGG-19, Inception-ResNetV2, Xception, and Densnet201 DCNN models were 99.15%, 97.58%, 98.44%, 98.15%, 98.86%, and 98.58%, respectively. The performance of CNN and DCNN models was evaluated using a confusion matrix and K-fold technique. The proposed CNN model has outperformed the DCNN models, and also literature reported works.
C1 [Lanjewar, M. G.] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
   [Gurav, O. L.] Sci Coll Pimpri, Pune 411018, Maharashtra, India.
C3 Goa University
RP Lanjewar, MG (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
EM madhusudan@unigoa.ac.in; akashgurav551@gmail.com
OI GURAV, OMKAR/0000-0001-5764-223X; Lanjewar,
   Madhusudan/0000-0002-9670-3020
CR Alemi A., 2016, IMPROVING INCEPTION
   Alom MZ, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01157-3
   Anguraj DK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02704-6
   Ayan E, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105809
   Azizi A, 2020, SOIL TILL RES, V199, DOI 10.1016/j.still.2020.104586
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Barman Utpal, 2020, Information Processing in Agriculture, V7, P318, DOI 10.1016/j.inpa.2019.08.001
   Behrens T, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33516-6
   Bhattacharya B, 2006, NEURAL NETWORKS, V19, P186, DOI 10.1016/j.neunet.2006.01.005
   Cavallaro G, 2015, INT GEOSCI REMOTE SE, P1366, DOI 10.1109/IGARSS.2015.7326030
   Chandan R., 2018, Int J Comput Eng Res (IJCER), V33, P3005
   Chawgien K, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105938
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Chung SO, 2012, J FAC AGR KYUSHU U, V57, P393
   Doulamis A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P684, DOI 10.1109/ICIP.2001.958211
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Foody GM, 2006, REMOTE SENS ENVIRON, V104, P1, DOI 10.1016/j.rse.2006.03.004
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guari Q, 2019, J CANCER, V10, P4876, DOI 10.7150/jca.28769
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Honawad S.K., 2017, International Organization of Scientific Research Journal of Computer Engineering, P25
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain, 2020, WHAT IS RECTIFIED LI
   Javaheri S.H., 2014, Data Mining Applications with R, P153
   Kestrilia RP., 2020, J AGR ENG, VLI, P1082
   Lameck O., 2002, 2002 ASAE ANN INT M
   Lu Y, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P666, DOI 10.1109/UEMCON.2018.8796838
   Mengistu A. D., 2018, Int J Electr Comput Eng, V8, P989, DOI 10.11591/ijece.v8i2.pp989-995
   Mohapatra H, 2022, J AMB INTEL HUM COMP, V13, P407, DOI 10.1007/s12652-021-02908-4
   Nguyen LD, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351550
   Online Article, 2018, TOP 6 IND AGRITECH S
   Pan Y, 2021, J AMB INTEL HUM COMP, V12, P10339, DOI 10.1007/s12652-020-02820-3
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Parab J, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2021.3079714
   Patil N, 2021, MULTIMED TOOLS APPL, V80, P29481, DOI 10.1007/s11042-021-11087-5
   Ramezan CA, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030368
   Rao A., 2016, CROP DETECT, V4, P792
   Sanjay M., 2018, Why and how to Cross Validate a Model
   Santos L, 2020, ADV INTELL SYST COMP, V1092, P139, DOI 10.1007/978-3-030-35990-4_12
   Shenbagavalli R., 2011, Bonfring Int J Adv Image Process, V1, P15, DOI [10.9756/BIJAIP.1004, DOI 10.9756/BIJAIP.1004]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava P, 2021, MULTIMED TOOLS APPL, V80, P14887, DOI 10.1007/s11042-021-10544-5
   Srunitha K., 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P411, DOI 10.1109/SCOPES.2016.7955863
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Vibhute AD, 2015, INT C MAN MACHINE IN
   Vijayakumar V, 2021, J AMB INTEL HUM COMP, V12, P8009, DOI 10.1007/s12652-020-02530-w
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wu W, 2018, COMPUT ELECTRON AGR, V144, P86, DOI 10.1016/j.compag.2017.11.037
   Yang G, 2015, PLASMA SCI TECHNOL, V17, P656, DOI 10.1088/1009-0630/17/8/08
   Zhang XD, 2003, INT GEOSCI REMOTE SE, P2888
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
NR 57
TC 21
Z9 21
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10313
EP 10336
DI 10.1007/s11042-022-12200-y
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800022
DA 2024-07-18
ER

PT J
AU Cotarelo, A
   Redondo, JM
AF Cotarelo, Alba
   Manuel Redondo, Jose
TI Applying color recognition techniques to achieve low-cost portable
   digital board functionalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital board; Color recognition; Portability; Low-cost
AB Digital teaching support devices, like digital boards, are becoming increasingly popular to improve concept learning, as they allow manipulating represented objects in new and very innovative ways if compared with traditional boards. However, their acquisition cost (device, software licenses, additional hardware), and the lack of deployment flexibility to adapt to certain classroom configurations, are the main problems that prevents them to be used in a substantial number of educational environments or slow their adoption rate. This research shows that a color recognition algorithm, applied to projected images captured by consumer-grade webcams, can successfully provide functionalities equivalent to typical digital boards on low-budget educational environments. This way, a pointer object is recognized by its color, and its actions are interpreted at real time to be converted to standard UI actions in the computer screen, as a standard input device. The prototype has been also designed to be usable in classroom environments of different sizes, available space, or configuration, maximizing reutilization of existing elements in the classroom. The research prototype was successfully deployed in a real classroom using modest hardware, inexpensive requirements, and very flexible setup options, adapting both to student and teacher needs.
C1 [Cotarelo, Alba; Manuel Redondo, Jose] Univ Oviedo, Comp Sci Dept, Oviedo, Spain.
C3 University of Oviedo
RP Redondo, JM (corresponding author), Univ Oviedo, Comp Sci Dept, Oviedo, Spain.
EM U0251336@uniovi.es; redondojose@uniovi.es
RI López, José Manuel Redondo/K-9605-2014
OI López, José Manuel Redondo/0000-0002-0939-0186
CR [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Augustine, 2015, INT J COMPUT SCI TRE, P3
   Brown AR, 2020, SOUNDCIPHER MUSIC SO
   Classroom, 2020, USE GOOGLE JAMBOARD
   Cohen, 2019, IOT ED SMARTBOARD
   Corporation I, 2020, INTEL ARK
   Davidovitch N., 2017, Higher Education Studies, V7, P60, DOI DOI 10.5539/HES.V7N1P60
   del Principado de Asturias G, 2020, RADIO TELEVISION PRI
   Diddeniya SIAP, 2020, 2020 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING AND ROBOTICS (ICIPROB 2020, DOI 10.1109/ICIP48927.2020.9367341
   Dosil AG., 2013, DESIGN IMPLEMENTATIO
   Educastur, 2020, COLEGIO PUBLI COBILI
   Evans J., 2019, YOUR LINUX TOOLBOX, V1
   Faek F., 2015, J ZANKOI SULAIMANI, V17, P195, DOI [10.17656/jzs.10437, DOI 10.17656/JZS.10437]
   Foundation P, 2020, PROC LIB REF
   Gesfomedia, 2020, MUNDO PRIMARIA MAYOR
   Habgood MPJ, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P125, DOI 10.1145/3130859.3131437
   Hema, 2009, P INT C MAN MACH SYS
   HUNUD H, 2013, IOP C SERIES MAT SCI, V53
   IMotions, 2017, EYETRACKING COMPLETE
   Inc G, 2020, GOOGLE ED BRING LEAR
   Inc O, 2020, JAVA ROBOT CLASS
   Kaur, 2018, SMART CLASS TECHNOLO
   LOPEZ JMR, 2021, 2021 IEEEACM 43 INT, P134
   Ltd P, 2020, PROM WORLD
   Magnuson M., 2011, PHYS TEACH, V49, P254, DOI 10.1119/1.3566048
   Mun Soh Hon, 2016, 2016 IEEE 8th International Conference on Engineering Education (ICEED), P120, DOI 10.1109/ICEED.2016.7856056
   Navada B, 2014, P INT C CIRC COMM CO, P2014, DOI [10.1109/CIMCA.2014.7057818, DOI 10.1109/CIMCA.2014.7057818]
   Nock CA, 2013, SENSORS-BASEL, V13, P16216, DOI 10.3390/s131216216
   pizarras digitales, 2020, PIZARRAS DIGITALES P
   Pro, 2020, TOBII PRONANO
   Rachmadi R., 2015, ARXIV PREPRINT ARXIV
   Reas, 2014, PROCESSING PROGRAMMI, V1
   Research GV, 2020, GVR2680383966
   Schlegel, 2020, CONTROLP5 GUI GRAPHI
   Soh Hon Mun, 2019, International Journal of Interactive Mobile Technologies, V13, P4, DOI 10.3991/ijim.v13i07.10654
   Tanaka K., 2012, Loading...The Journal of the Canadian Game Studies Association, V6, P69
   Upadhye, 2019, BLACKBOARDS DIGITAL
   Zaleski O., 2018, SOUTHEASTCON 2018, P1
NR 38
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8995
EP 9012
DI 10.1007/s11042-022-12068-y
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000753241100007
PM 35496995
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Babu, SBGT
   Rao, CS
AF Babu, S. B. G. Tilak
   Rao, Ch Srinivasa
TI Efficient detection of copy-move forgery using polar complex exponential
   transform and gradient direction pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy move forgery detection; Image forensics; Polar complex exponential
   transform; Gradient direction pattern; Computer crimes
AB Evidence plays a vital role in image forensics. If evidence is an image, then its authenticity verification is the key to image forensics. One of the common forgeries in digital images is Copy-Move Forgery, which happens in a single image in which some portation of the image is copied and pasted in the same image. Copy Move Forgery Detection has demand in legal evidence, forensic examination and many more areas. The proposed method starts with the conversion of a grey image into overlapping blocks. Rotationally invariant stable Polar Complex Exponential Transform features are obtained from each overlapping block. The extracted feature dimensionality is further reduced using the Gradient Direction Pattern histogram. The similarity is identified among these histogram feature matrix rows. False matches are eliminated with the help of the windowing technique and morphological operators. The performance of the proposed method is calculated in terms of recall rate, precision, and F1score. The testing results are outstanding, even when the suspected image has been subjected to post-processing assaults; the recall rate is the highest in the literature, and the remaining performance metrics are likewise excellent.
C1 [Babu, S. B. G. Tilak] Aditya Engn Coll, Dept ECE, Surampalem, India.
   [Babu, S. B. G. Tilak] JNTUK UCEK, Dept ECE, Kakinada, India.
   [Rao, Ch Srinivasa] JNTUK UCEV, Dept ECE, Vizianagaram, India.
C3 Aditya Engineering College, Surampalem; Jawaharlal Nehru Technological
   University - Kakinada; Jawaharlal Nehru Technological University -
   Kakinada
RP Babu, SBGT (corresponding author), Aditya Engn Coll, Dept ECE, Surampalem, India.; Babu, SBGT (corresponding author), JNTUK UCEK, Dept ECE, Kakinada, India.
EM thilaksayila@gmail.com
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Agarwal R, 2022, EVOL SYST-GER, V13, P27, DOI 10.1007/s12530-021-09367-4
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Al azrak FM, 2020, WIRELESS PERS COMMUN, V110, P503, DOI 10.1007/s11277-019-06739-7
   Al-Hammadi MM, 2016, IEEE INT SYM MULTIM, P341, DOI [10.1109/ISM.2016.91, 10.1109/ISM.2016.0075]
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Babu SBGT, 2022, ICT EXPRESS, V8, P244, DOI 10.1016/j.icte.2021.08.016
   Babu SBGT, 2016, INT CONF IND INF SYS, P154, DOI 10.1109/ICIINFS.2016.8262925
   Chen BJ, 2018, IEEE ACCESS, V6, P56637, DOI 10.1109/ACCESS.2018.2871952
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fridrich J, 2003, DETECTION COPY MOVE, DOI [10.1109/PACIIA.2008.240, DOI 10.1109/PACIIA.2008.240]
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Gong JC, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033010
   Hosny KM, 2011, J REAL-TIME IMAGE PR, V6, P73, DOI 10.1007/s11554-009-0135-z
   Huang DY, 2017, MULTIMED TOOLS APPL, V76, P1509, DOI 10.1007/s11042-015-3152-x
   Huang HY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0469-9
   Huynh K-T., 2021, SN COMP SCI, V2, P278, DOI [10.1007/s42979-021-00682-w, DOI 10.1007/S42979-021-00682-W]
   Islam M. S., 2013, SCI INT LAHORE, V25, P797
   Jung KH, 2016, IETE TECH REV, V33, P441, DOI 10.1080/02564602.2015.1102099
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L, 2013, EFFICIENT SCHEME DET
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Rao C. S, 2016, Lecture Notes in Electrical Engineering, V372, P529
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Wang XY, 2021, PATTERN ANAL APPL, V24, P1025, DOI 10.1007/s10044-021-00968-y
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102536
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 33
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10061
EP 10075
DI 10.1007/s11042-022-12311-6
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000751246700008
DA 2024-07-18
ER

PT J
AU Xu, PF
   Huang, LD
   Song, Y
AF Xu, Panfeng
   Huang, Lidong
   Song, Yan
TI An optimal method based on HOG-SVM for fault detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fault detection; Feature extraction; Image classification; Support
   vector machine
ID DIAGNOSIS; MODEL
AB In this paper, an improved method based on HOG-SVM (histogram of oriented gradient characteristic and support vector machine) is proposed for fault diagnosis. First, by converting mechanical vibration signals to 3-D (three dimensional) images, this proposed method can extract the T-HOG (improved HOG) feature of 3-D images precisely. With the optimal method, all characteristic information of mechanical vibration signal, including fault characteristic signal and health characteristic signal, are converted into characteristic 3-D image. Then, fault information can be accurately recognized though R-SVM's (optimal SVM) classification. Furthermore, the new method which is tested on two kinds of field tests, including rail and gear box fault diagnosis, has achieved high detection accuracy of 97.3% and 96.7% respectively. Finally, compared with other ML and signal feature extraction methods, the proposed method shows superiority in fault diagnosis, which is significant for industry safety and reliability.
C1 [Xu, Panfeng; Huang, Lidong; Song, Yan] Liaoning Univ, Phys Coll, Shenyang, Peoples R China.
   [Song, Yan] Chinese Acad Sci, Shenyang Inst Automat, Shenyang, Peoples R China.
C3 Liaoning University; Chinese Academy of Sciences; Shenyang Institute of
   Automation, CAS
RP Huang, LD (corresponding author), Liaoning Univ, Phys Coll, Shenyang, Peoples R China.
EM 4031731893@smail.lnu.edu.cn
OI Huang, Lidong/0000-0002-7459-5655
CR Abdeljaber O, 2017, J SOUND VIB, V388, P154, DOI 10.1016/j.jsv.2016.10.043
   Chen TR, 2021, IEEE T CYBERNETICS, V51, P5930, DOI 10.1109/TCYB.2019.2963259
   Cho HC, 2010, IEEE T CONTR SYST T, V18, P430, DOI 10.1109/TCST.2009.2020863
   Dai XW, 2013, IEEE T IND INFORM, V9, P2226, DOI 10.1109/TII.2013.2243743
   Don MG, 2019, CHEM ENG SCI, V201, P82, DOI 10.1016/j.ces.2019.01.060
   Duan ZX, 2019, ISA T, V84, P1, DOI 10.1016/j.isatra.2018.09.026
   Oya JRG, 2020, IEEE T INSTRUM MEAS, V69, P947, DOI 10.1109/TIM.2020.2970832
   He WP, 2020, MEAS SCI TECHNOL, V31, DOI 10.1088/1361-6501/ab79c9
   Jia F, 2016, MECH SYST SIGNAL PR, V72-73, P303, DOI 10.1016/j.ymssp.2015.10.025
   Liu XX, 2019, AUTOMATICA, V101, P365, DOI 10.1016/j.automatica.2018.12.006
   Lu C, 2017, SIGNAL PROCESS, V130, P377, DOI 10.1016/j.sigpro.2016.07.028
   Peres FAP, 2019, J PROCESS CONTR, V80, P223, DOI 10.1016/j.jprocont.2019.06.002
   Shi SH, 2020, APPL INTELL, V50, P681, DOI 10.1007/s10489-019-01536-y
   Stojanovic V, 2020, NONLINEAR DYNAM, V100, P2299, DOI 10.1007/s11071-020-05616-4
   Wang C, 2019, IEEE T POWER SYST, V34, P182, DOI 10.1109/TPWRS.2018.2865966
   Wen L, 2018, IEEE T IND ELECTRON, V65, P5990, DOI 10.1109/TIE.2017.2774777
   Xiao L, 2020, J SOUND VIB, V478, DOI 10.1016/j.jsv.2020.115355
   Yan S, 2018, INT J DIGIT MULTIMED
   Zhakov A, 2020, IEEE T SEMICONDUCT M, V33, P337, DOI 10.1109/TSM.2020.2984326
   Zhang XY, 2015, MEASUREMENT, V69, P164, DOI 10.1016/j.measurement.2015.03.017
NR 20
TC 8
Z9 8
U1 2
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6995
EP 7010
DI 10.1007/s11042-022-12020-0
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000745555600001
DA 2024-07-18
ER

PT J
AU Akilandeswari, J
   Jothi, G
   Naveenkumar, A
   Sabeenian, RS
   Iyyanar, P
   Paramasivam, ME
AF Akilandeswari, J.
   Jothi, G.
   Naveenkumar, A.
   Sabeenian, R. S.
   Iyyanar, P.
   Paramasivam, M. E.
TI Design and development of an indoor navigation system using denoising
   autoencoder based convolutional neural network for visually impaired
   people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Denoising autoencoder; Convolutional neural network; Indoor navigation;
   Classification; User positioning; Deep learning
AB A challenging area of research is the development of a navigation system for visually impaired people in an indoor environment such as a railway station, commercial complex, educational institution, and airport. Identifying the current location of the users can be a difficult task for those with visual impairments. The entire selection of the navigation path depends upon the current location of the user. This work presents a detailed analysis of the recent user positioning techniques and methodologies on the indoor navigation system based on the parameters, such as techniques, cost, the feasibility of implementation, and limitations. This paper presents a denoising auto encoder based on the convolutional neural network (DAECNN) to identify the present location of the users. The proposed approach uses the de-noising autoencoder to reconstruct the noisy image and the convolution neural network (CNN) to classify the users' current position. The proposed method is compared with the existing deep learning approaches such as deep autoencoder, sparse autoencoder, CNN, multilayer perceptron, radial basis function neural network, and the performances are analyzed. The experimental findings indicate that the DAECNN methodology works better than the existing classification approaches.
C1 [Akilandeswari, J.; Naveenkumar, A.; Iyyanar, P.] Sona Coll Technol, Dept IT, Salem 636005, Tamil Nadu, India.
   [Jothi, G.] Sona Coll Arts & Sci, Dept BCA, Salem 636005, Tamil Nadu, India.
   [Sabeenian, R. S.; Paramasivam, M. E.] Sona Coll Technol, Dept ECE, Salem 636005, Tamil Nadu, India.
C3 Sona College of Technology; Sona College of Technology
RP Akilandeswari, J (corresponding author), Sona Coll Technol, Dept IT, Salem 636005, Tamil Nadu, India.
EM akilandeswari@sonatech.ac.in
RI R S, SABEENIAN/AAP-7619-2020; PERUMAL, IYYANAR/HLP-3451-2023; A,
   Naveenkumar/HLH-4315-2023
OI R S, SABEENIAN/0000-0002-6452-2006; PERUMAL,
   IYYANAR/0000-0001-7611-4600; A, Naveenkumar/0000-0002-6810-4549
FU Science for Equity Empowerment and Development Division (SEED),
   Department of Science & Technology, Technology Bhavan, New Mehrauli
   Road, New Delhi [SEED//TIDE/202/2016/G]
FX This research work is done as part of the research grant from Science
   for Equity Empowerment and Development Division (SEED), Department of
   Science & Technology, Technology Bhavan, New Mehrauli Road, New Delhi
   under SEED//TIDE/202/2016/G, dated: 12/01/2018.
CR Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   Ahmad M, 2020, OPTIK, V206, DOI 10.1016/j.ijleo.2019.163712
   Akilandeswari J., 2021, Evolution in Computational Intelligence. Frontiers in Intelligent Computing: Theory and Applications (FICTA 2020). Advances in Intelligent Systems and Computing (AISC 1176), P115, DOI 10.1007/978-981-15-5788-0_11
   Akilandeswari J., 2021, INT J PERFORMABILITY, V17, P322, DOI https://doi.org/10.23940/ijpe.21.03.p8.322332
   [Anonymous], 2011, INT C INDOOR POSIT
   [Anonymous], 2016, P INT C IND POS IND
   [Anonymous], 2012, International Conference on Informatics and Applications
   Dourado AMB, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106130
   Bonde G.D., 2015, IJIRST INT J INNOVAT, V1, P202
   Cardoso P, 2016, PROCEDIA COMPUT SCI, V100, P1200, DOI 10.1016/j.procs.2016.09.143
   Cheng RQ, 2019, IEEE INT C INTELL TR, P920, DOI [10.1109/ITSC.2019.8917508, 10.1109/itsc.2019.8917508]
   Ciezkowski M, 2017, 2017 22ND INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P84, DOI 10.1109/MMAR.2017.8046803
   Do TH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050678
   Fang YC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154177
   Gobi R, 2021, MULTIMED TOOLS APPL, V80, P15377, DOI 10.1007/s11042-020-10438-y
   Hakimpour F, 2014, INT ARCH PHOTOGRAMM, V40, P137, DOI 10.5194/isprsarchives-XL-2-W3-137-2014
   Hashemi Fath Aref, 2020, Petroleum, V6, P80, DOI 10.1016/j.petlm.2018.12.002
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Ilkovicova L., 2014, Competence Cent. SMART Technol. Electron. Informatics Syst. Serv. ITMS, V26240220072, P117
   Ivanov Rosen., 2010, P 11 INT C COMPUTER, P143
   Jeyapal A, 2020, J COMPUT THEOR NANOS, V17, P21
   Karim AM, 2019, BIOCYBERN BIOMED ENG, V39, P148, DOI 10.1016/j.bbe.2018.11.004
   Kassim AM, 2016, INT J ADV COMPUT SC, V7, P604
   KIRCHNER N, 2005, P 1 INT C SENS TECHN
   Lachenbruch PA, 1998, STAT MED, V17, P2207, DOI 10.1002/(SICI)1097-0258(19981015)17:19<2207::AID-SIM920>3.3.CO;2-P
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee BH, 2019, DISABIL HEALTH J, V12, P79, DOI 10.1016/j.dhjo.2018.07.012
   Li W, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105489
   Lin SF, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082476
   Liu WF, 2017, SIGNAL PROCESS, V141, P137, DOI 10.1016/j.sigpro.2017.05.030
   Makhzan A, 2013, K SPARSE AUTOENCODER
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Manjari K., 2020, INTERNET THINGS-NETH, V11, DOI [DOI 10.1016/j.iot.2020.100188, 10.1016/j.iot.2020.100188]
   Mashuk MS, 2018, IEEE POSITION LOCAT, P216, DOI 10.1109/PLANS.2018.8373384
   Medina C, 2013, SENSORS-BASEL, V13, P3501, DOI 10.3390/s130303501
   Meliones A, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010004
   Nabney Ian T, 2004, Int J Neural Syst, V14, P201, DOI 10.1142/S0129065704001930
   Nagarajan Bhalaji, 2020, Smart Systems and IoT: Innovations in Computing. Proceeding of SSIC 2019. Smart Innovation, Systems and Technologies (SIST 141), P249, DOI 10.1007/978-981-13-8406-6_25
   Nakajima M, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-37
   Ng A, 2011, ELGAR LAW TECH SOC, P1
   Ovchinnikov I. A., 2020, Advanced Technologies in Robotics and Intelligent Systems. Proceedings of ITR 2019. Mechanisms and Machine Science (MMS 80), P285, DOI 10.1007/978-3-030-33491-8_34
   Potgantwar A., 2015, GLOB J ADV ENG TECHN, V4, P436
   Qi J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112554
   Roy P, 2021, MULTIMED TOOLS APPL, V80, P20501, DOI 10.1007/s11042-020-10456-w
   Sarimveis H, 2006, ADV ENG SOFTW, V37, P218, DOI 10.1016/j.advengsoft.2005.07.005
   Shahid E, 2021, MULTIMED TOOLS APPL, V80, P26213, DOI 10.1007/s11042-021-10906-z
   Shan C., 2012, INT C FIB OPT PHOT, P1, DOI [DOI 10.1364/PHOTONICS.2012.M3A.6, 10.1364/PHOTONICS.2012.M3A.6]
   Taheri A, 2004, CONF LOCAL COMPUT NE, P676
   Tandon K., 2015, INT J COMPUT SYST, V2, P115
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Thoma J, 2019, PROC CVPR IEEE, P7375, DOI 10.1109/CVPR.2019.00756
   Tom M., 1977, MACH LEARN, P870
   Tsirmpas C, 2015, INFORM SCIENCES, V320, P288, DOI 10.1016/j.ins.2014.08.011
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang WP, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101563
   Waqar W, 2011, P NEWF C EL COMP ENG, P1
   Willis S, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P34, DOI 10.1109/ISWC.2005.46
   Xiao AR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072229
   Xie B, 2016, ACM T SENSOR NETWORK, V12, DOI 10.1145/2953880
   Yayan U, 2015, J INTELL ROBOT SYST, V78, P541, DOI 10.1007/s10846-014-0060-7
   Zhang Y, 2016, ENG APPL ARTIF INTEL, V50, P245, DOI 10.1016/j.engappai.2016.01.032
NR 63
TC 9
Z9 9
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3483
EP 3514
DI 10.1007/s11042-021-11287-z
EA JAN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000008
DA 2024-07-18
ER

PT J
AU Bellini, P
   Palesi, LAI
   Nesi, P
   Pantaleo, G
AF Bellini, Pierfrancesco
   Palesi, Luciano Alessandro Ipsaro
   Nesi, Paolo
   Pantaleo, Gianni
TI Multi Clustering Recommendation System for Fashion Retail
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation systems; Clustering; Customer and items clustering
   composed
ID CUSTOMER SEGMENTATION; MANAGEMENT; MODELS
AB Fashion retail has a large and ever-increasing popularity and relevance, allowing customers to buy anytime finding the best offers and providing satisfactory experiences in the shops. Consequently, Customer Relationship Management solutions have been enhanced by means of several technologies to better understand the behaviour and requirements of customers, engaging and influencing them to improve their shopping experience, as well as increasing the retailers' profitability. Current solutions on marketing provide a too general approach, pushing and suggesting on most cases, the popular or most purchased items, losing the focus on the customer centricity and personality. In this paper, a recommendation system for fashion retail shops is proposed, based on a multi clustering approach of items and users' profiles in online and on physical stores. The proposed solution relies on mining techniques, allowing to predict the purchase behaviour of newly acquired customers, thus solving the cold start problems which is typical of the systems at the state of the art. The presented work has been developed in the context of Feedback project partially founded by Regione Toscana, and it has been conducted on real retail company Tessilform, Patrizia Pepe mark. The recommendation system has been validated in store, as well as online.
C1 [Bellini, Pierfrancesco; Palesi, Luciano Alessandro Ipsaro; Nesi, Paolo; Pantaleo, Gianni] Univ Florence, DINFO Dept, DISIT Lab, Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, DINFO Dept, DISIT Lab, Florence, Italy.
EM paolo.nesi@unifi.it
RI Ipsaro Palesi, Luciano Alessandro/JEO-7887-2023; Pantaleo,
   Gianni/J-1864-2016; Bellini, Pierfrancesco/D-5923-2015
OI Ipsaro Palesi, Luciano Alessandro/0000-0001-8992-2084; Pantaleo,
   Gianni/0000-0002-9235-437X; nesi, paolo/0000-0003-1044-3107
FU FEEDBACK project; Regione Toscana
FX The authors would like to thank FEEDBACK project and partners for which
   we have developed a part of the solutions described in this paper, and
   Regione Toscana for the partial founding POR FESR 2020 Phase 2.
   https://www.vargroup.it/progetti-rd/
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Alaa Rana, 2020, ICCTA '20: Proceedings of the 2020 6th International Conference on Computer and Technology Applications, P12, DOI 10.1145/3397125.3397134
   [Anonymous], 2012, J. Database Mark. Customer Strategy Manage., DOI DOI 10.1057/DBM.2012.17
   Antonello F, 2021, RELIAB ENG SYST SAFE, V209, DOI 10.1016/j.ress.2020.107305
   Badii C, 2020, IEEE ACCESS, V8, P23601, DOI 10.1109/ACCESS.2020.2968741
   Bellini P., 2013, LNCS
   Bellini P, 2014, INT J MULTIMED INF R, V3, P147, DOI 10.1007/s13735-014-0058-8
   Bellini P, 2012, MULTIMED TOOLS APPL, V58, P41, DOI 10.1007/s11042-010-0684-y
   Berry MichaelJ., 1996, Data mining techniques for marketing, sales, and customer support
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   BLASHFIELD RK, 1991, J CLASSIF, V8, P277
   Breve B, 2020, EDBT ICDT WORKSH
   Caruccio L, 2020, ACM J DATA INF QUAL, V12, DOI 10.1145/3397462
   Caruccio L, 2016, IEEE T KNOWL DATA EN, V28, P147, DOI 10.1109/TKDE.2015.2472010
   Chan CCH, 2008, EXPERT SYST APPL, V34, P2754, DOI 10.1016/j.eswa.2007.05.043
   Cho YH, 2002, EXPERT SYST APPL, V23, P329, DOI 10.1016/S0957-4174(02)00052-0
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P685, DOI 10.1109/TSC.2020.2964552
   Cuzzocrea Alfredo, 2020, MEDES '20: Proceedings of the 12th International Conference on Management of Digital EcoSystems, P115, DOI 10.1145/3415958.3433051
   Cuzzocrea A, 2020, CEUR WORKSHOP PROC, V2646, P334
   Da'u A, 2019, IEEE ACCESS, V7, P45472, DOI 10.1109/ACCESS.2019.2907729
   Danaf M, 2019, DECIS SUPPORT SYST, V119, P35, DOI 10.1016/j.dss.2019.02.003
   Dang TT., 2014, 7 IEEE S COMP INT SE, V2014, P1, DOI [10.1109/CISDA.2014.7035626, DOI 10.1109/CISDA.2014.7035626]
   Djenouri Y, 2017, LECT NOTES ARTIF INT, V10235, P644, DOI 10.1007/978-3-319-57529-2_50
   Fatemi M, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P351, DOI 10.1109/SocialCom.2013.55
   Gharib TF, 2010, DATA KNOWL ENG, V69, P800, DOI 10.1016/j.datak.2010.03.002
   Giering M, 2008, SIGKDD EXPLOR NEWSL, V10, P84, DOI DOI 10.1145/1540276.1540301
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   Greco G, 2004, LECT NOTES ARTIF INT, V3056, P52
   Grewal D, 2017, J RETAILING, V93, P1, DOI 10.1016/j.jretai.2016.12.008
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hotsum M, 1993, 9567 RJ IBM ALM RES
   Huseynov F, 2016, INFORM DEV, V32, P81, DOI 10.1177/0266666914528929
   Hwang H, 2004, EXPERT SYST APPL, V26, P181, DOI 10.1016/S0957-4174(03)00133-7
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiawei Han, 2000, SIGMOD Record, V29, P1, DOI 10.1145/335191.335372
   Kim SY, 2006, EXPERT SYST APPL, V31, P101, DOI 10.1016/j.eswa.2005.09.004
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lemire Daniel, 2003, RACOFI RULE APPL COL
   Mahmood T, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P73
   Mariappan MB, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P84, DOI 10.1109/ISM.2012.24
   Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856
   McCarty JA, 2007, J BUS RES, V60, P656, DOI 10.1016/j.jbusres.2006.06.015
   Min SH, 2005, LECT NOTES COMPUT SC, V3579, P387
   Miyahara K., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886), P679
   Mu RH, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2880197
   Namvar M, 2010, UKSIM INT CONF COMP, P215, DOI 10.1109/ISMS.2010.48
   Ngai EWT, 2009, EXPERT SYST APPL, V36, P2592, DOI 10.1016/j.eswa.2008.02.021
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Rao KN, 2008, DESIDOC J LIB INF TE, V28, P17
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Rodrigues F, 2016, PROCEDIA COMPUT SCI, V100, P136, DOI 10.1016/j.procs.2016.09.133
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Sedhain S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P111, DOI 10.1145/2740908.2742726
   Swift R.S., 2001, ACCELERATING CUSTOME
   Tran DB., 2020, SCI TECHNOL DEV J EN, DOI [10.32508/stdjet.v3iSI1.540, DOI 10.32508/STDJET.V3ISI1.540]
   Tuinhof Hessel, 2019, Machine Learning, Optimization, and Data Science. 4th International Conference, LOD 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11331), P472, DOI 10.1007/978-3-030-13709-0_40
   Walek B, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P164, DOI 10.1109/AIKE.2018.00036
   Wang C, 2020, IEEE T NEUR NET LEAR, V31, P2731, DOI 10.1109/TNNLS.2019.2907430
   Wei SY, 2012, 2012 FIFTH INTERNATIONAL CONFERENCE ON BUSINESS INTELLIGENCE AND FINANCIAL ENGINEERING (BIFE), P69, DOI 10.1109/BIFE.2012.23
   Wu S, 2016, PROC INT CONF DATA, P1218, DOI 10.1109/ICDE.2016.7498326
   Zhao X., 2017, ARXIV180100209
NR 63
TC 12
Z9 12
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9989
EP 10016
DI 10.1007/s11042-021-11837-5
EA JAN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000742319000005
PM 35043044
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Babbar, H
   Parthiban, S
   Radhakrishnan, G
   Rani, S
AF Babbar, Himanshi
   Parthiban, S.
   Radhakrishnan, G.
   Rani, Shalli
TI A genetic load balancing algorithm to improve the QoS metrics for
   software defined networking for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software defined networking (SDN); Load balancing; Multimedia
   application; Genetic load balancing algorithm; LBBSRT; Round robin;
   Dynamic Server
ID SDN
AB With the increasing growth in the network and latest technologies by which people communicates via voice or data and modifies the radio devices easily and cost effectively. Software defined radio brings the flexibility, power and efficiency including cloud and big data, control and management of the traditional networks has raised the challenges for the development of multimedia applications. Multimedia applications require to handle the large amount of data at the servers which has increased the load on them. To resolve this issue, Software Defined Networking (SDN) came into existence which makes the management of the network more conformable. To satisfy the constraints of Quality of Service (QoS) and Quality of Experience (QoE) with the limited network availability, one of the keynotes that have been taken into consideration is the load balancing. Therefore, many servers can be used with the load balancers which behave as the front end. The present paper aims to reflect impact on the efficiency of the usage of software-defined networks service in various multimedia applications. A genetic load balancing algorithm (GLBA) is proposed and is implemented on POX controller with mininet emulator in python language to compute its effectiveness and efficiency. Validation of GLBA for 100 to 600 users over server load, weighted round robin, round robin, dynamic server and LBBSRT algorithms with parameters, throughput, response time, memory and CPU utilization has proved the significance of proposed algorithm.
C1 [Babbar, Himanshi; Rani, Shalli] Chitkara Univ, Inst Engn & Technol, Chitkara, Punjab, India.
   [Parthiban, S.] Jain Deemed Univ, Dept CSE, Fac Engn & Technol, Bengaluru, Karnataka, India.
   [Radhakrishnan, G.] Sri Krishna Coll Engn & Technol, Dept EEE, Coimbatore, Tamil Nadu, India.
C3 Chitkara University, Punjab; Jain University; Sri Krishna College of
   Engineering & Technology
RP Rani, S (corresponding author), Chitkara Univ, Inst Engn & Technol, Chitkara, Punjab, India.
EM himanshi.babbar@chitkara.edu.in; parthibans1983@gmail.com;
   radhakrishnang@skcet.ac.in; Shalli.Rani@chitkara.edu.in
RI Rani, Shalli/AGY-9513-2022; G, Dr.Radhakrishnan/GNH-6482-2022; S,
   Dr.Parthiban/ADQ-5754-2022
OI Rani, Shalli/0000-0002-8474-9435; S, Dr.Parthiban/0000-0001-8141-1271
CR Adekoya O, 2020, IEEE OPEN J COMM SOC, V1, P1602, DOI 10.1109/OJCOMS.2020.3028971
   [Anonymous], 2017, WIRELESS NETWORK, DOI DOI 10.1007/S11276-015-1119-5
   Arahunashi G. G., 2018, P INT C COMP SYST IN, P87, DOI [10.1109/CSITSS.2018.8768754.9.J., DOI 10.1109/CSITSS.2018.8768754.9.J]
   Azzouni A, 2017, 2017 16TH ANNUAL MEDITERRANEAN AD HOC NETWORKING WORKSHOP (MED-HOC-NET)
   Babbar Himanshi, 2021, Proceedings of the Second International Conference on Information Management and Machine Intelligence (ICIMMI 2020). Lecture Notes in Networks and Systems (LNNS 166), P69, DOI 10.1007/978-981-15-9689-6_8
   Babbar Himanshi, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012024
   Babbar H, 2021, CMC-COMPUT MATER CON, V67, P1301, DOI 10.32604/cmc.2021.014627
   Buyya, SOFTWARE DEFINED NET, P1
   Chen YJ, 2018, IEEE INTERNET THINGS, V5, P1797, DOI 10.1109/JIOT.2018.2812718
   Cui J, 2018, IEEE T NETW SERV MAN, V15, P1197, DOI 10.1109/TNSM.2018.2876369
   Ghumman, 2021, ROUND ROBIN BASED LO, P2
   Gupta, 2019, COMP STUDY LOAD BALA, DOI [10.1007/978-3-030-20615-4_11, DOI 10.1007/978-3-030-20615-4_11]
   Hamed Mohamed I., 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P30, DOI 10.1109/INTELCIS.2017.8260023
   Jamshid, 2018, ENHANCING THROUGHPUT, P0
   Jarraya Y, 2014, IEEE COMMUN SURV TUT, V16, P1955, DOI 10.1109/COMST.2014.2320094
   Johari R, 2014, PLUG N SERVE LOAD BA
   Kaur G, 2014, INT CONF COMP COMMUN
   Keti F, 2015, P INT CONF INTELL, P205, DOI 10.1109/ISMS.2015.46
   Madhu RK, 2019, LOAD BALANCING SOFTW, DOI [10.1007/978-981-13-5802-9_22, DOI 10.1007/978-981-13-5802-9_22]
   Nunes BAA, 2014, IEEE COMMUN SURV TUT, V16, P1617, DOI 10.1109/SURV.2014.012214.00180
   Oliveira Alexandre T., 2018, 2018 IEEE Symposium on Computers and Communications (ISCC), P00602, DOI 10.1109/ISCC.2018.8538694
   Ongaro F, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P505, DOI 10.1109/ICCNC.2015.7069395
   Paliwal M, 2018, IEEE ACCESS, V6, P36256, DOI 10.1109/ACCESS.2018.2846236
   Parsaei M. R., 2017, INT J COMPUTER APPL, V168, P55
   Rishabh K, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTION (CSITSS-2017), P289, DOI 10.1109/CSITSS.2017.8447852
   Sahoo KS, 2020, IEEE INTERNET THINGS, V7, P5852, DOI 10.1109/JIOT.2019.2952527
   Shruthi V., 2017, INT RES J ENG TECHNO, V4, P622
   Singh, 2017, INT J ADV RES COMPUT, V8, P5, DOI [10.26483/ijarcs.v8i8.4567, DOI 10.26483/IJARCS.V8I8.4567]
   Soler, 2019, DYNAMIC SDN CONTROLL, P1
   Suwandika PA, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), P459, DOI 10.1109/ICoICT.2018.8528803
   Yahya, 2016, SCH J ENG TECHNOL SJ, V4, P527
   Yang CT, 2019, COMPUTING, V101, P211, DOI 10.1007/s00607-018-0665-y
   Zhang SJ, 2018, IEEE ACCESS, V6, P18184, DOI 10.1109/ACCESS.2018.2820148
   Zhong H, 2017, FUTURE GENER COMP SY, V68, P183, DOI 10.1016/j.future.2016.10.001
NR 34
TC 8
Z9 8
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9111
EP 9129
DI 10.1007/s11042-021-11467-x
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000740429700022
DA 2024-07-18
ER

PT J
AU Jha, GK
   Gaur, M
   Thakur, HK
AF Jha, Govind Kumar
   Gaur, Manish
   Thakur, Hardeo Kumar
TI A trust-worthy approach to recommend movies for communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Movies recommendation; Inversion similarity; Trust;
   Collaborative filtering; User clone
ID COLLABORATIVE FILTERING APPROACH; IMPROVE
AB Trustworthy recommendation of a movie is a highly complex task for the entertainment industry wherein trust is s a crucial metric of recommendation systems. It depends upon various factors, such as preferences, reviews, emotions, promotions and sentiments. However, these factors are specific to individuals and may vary from person to person. Additionally, the data collected for movie recommendations suffer from data sparsity and cold start problems. Previous studies on movie recommendations have failed to be trustworthy because their performance is greatly affected by fake ratings, data sparsity, and cold start problems. Also, the existing models of Recommender Systems (RS) do not consider the trust score and the user's rating criterion. Keeping this in view, in this paper, the rating and ranking criteria with a trust score of different users is incorporated into the proposed machine learning-based RS models to ensure the trustworthiness of the system. In particular, one can notice that the most relevant viewers have the same taste and preferences. So, the bipartite relationship between the movie and the viewer has been interpreted through the inversion similarity concept which is used to design an efficient and trustworthy movie recommendation model for a community of viewers. The proposed model uses a learning algorithm to measure the trust score of recommendations and also performs cluster analysis to identify the groups having similar behavior in their communities. The information extracted from the cluster analysis identifies the user's pattern of movie watching and predicts their movie selection behavior. We have performed extensive experiments to find and compare the performance of the proposed models with other existing models. The results of the experiments demonstrated the better performance of proposed models and supported the claim.
C1 [Jha, Govind Kumar] Bhagalpur Coll Engn, Bhagalpur, India.
   [Gaur, Manish] Dr APJ Abdul Kalam Tech Univ Lucknow, Inst Engn & Technol, Lucknow, Uttar Pradesh, India.
   [Thakur, Hardeo Kumar] Manav Rachna Univ Faridabad, Faridabad, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow
RP Jha, GK (corresponding author), Bhagalpur Coll Engn, Bhagalpur, India.
EM manish.gaur@ietlucknow.ac.in; hkthakur@mru.edu.in
RI THAKUR, HARDEO KUMAR/Q-3224-2019
OI THAKUR, HARDEO KUMAR/0000-0002-2954-1308; Gaur,
   Manish/0000-0002-4161-2789; JHA, GOVIND KUMAR/0000-0003-2258-1865
CR Bobadilla J, 2012, KNOWL-BASED SYST, V26, P225, DOI 10.1016/j.knosys.2011.07.021
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Cazella SC, 2005, REV TECNOLOGIA INFOR, V4
   Chen L, 2012, USER MODEL USER-ADAP, V22, P125, DOI [10.1007/s11257-011-9115-7, 10.1007/s11257-011-9108-6]
   Cotter P, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P957
   Dong E., 2009, Proceedings of Networking Electronic Commerce Research Conference NAEC 2009, P21
   Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P417, DOI 10.1145/3308558.3313488
   Forsati R, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2641564
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Gong SJ, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P769, DOI 10.1109/WKDD.2009.132
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   HERLOCKER JL, 2017, ACM SIGIR FORUM, V51, P227, DOI DOI 10.1145/3130348.3130372
   Jacobs I. S., 1963, Magnetism, V3, P271
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Lee K, 2018, INFORM SYST FRONT, V20, P577, DOI 10.1007/s10796-016-9689-z
   Leong S, 2012, SURVEY RECOMMENDER S
   Liu HF, 2014, KNOWL-BASED SYST, V56, P156, DOI 10.1016/j.knosys.2013.11.006
   Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI [DOI 10.1145/1458082.1458205, 10.1145/1458082.1458205]
   McNee S.M., 2006, P 20 ANNIVERSARY C C, P171, DOI DOI 10.1145/1180875.1180903
   McNee SM, 2002, P 2002 ACM C COMP SU, P116, DOI [DOI 10.1145/587078.587096, 10.1145/587078.587096]
   Naak A, 2009, LECT NOTES BUS INF P, V26, P25
   Pennock DM, 2013, ARXIV PREPRINT ARXIV
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Sarwar Badrul, 2000, ACM WEBKDD 2000 WORK
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Song WP, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P555, DOI 10.1145/3289600.3290989
   Sun PJ, 2018, ACM/SIGIR PROCEEDINGS 2018, P185, DOI 10.1145/3209978.3210023
   Torre I, 2009, USER MODEL USER-ADAP, V19, P433, DOI 10.1007/s11257-009-9067-3
   Torres R, 2004, ACM-IEEE J CONF DIG, P228, DOI 10.1145/996350.996402
   Vellino A., 2010, Proceedings of the American Society for Information Science and Technology, V47, P1, DOI DOI 10.1002/MEET.14504701330
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu L., 2020, International Conference on Artificial Intelligence and Statistics, P776
   Wu QT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2091, DOI 10.1145/3308558.3313442
   Yang CX, 2009, ACM-IEEE J CONF DIG, P203
   Young M., 1989, The Technical Writer's Handbook
   Zanker M, 2007, IEEE INTELL SYST, V22, P69, DOI 10.1109/MIS.2007.49
   Zheng N, 2010, J INF SCI, V36, P733, DOI 10.1177/0165551510386164
NR 38
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19655
EP 19682
DI 10.1007/s11042-021-11544-1
EA JAN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000740429700021
DA 2024-07-18
ER

PT J
AU Zheng, XB
   Ling, BWK
   Zeng, ZT
AF Zheng, Xiao-Ben
   Ling, Bingo Wing-Kuen
   Zeng, Zhi-Tao
TI Evaluation of effectiveness of eye massage therapy via classification of
   periocular images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evaluation of the effectiveness of the eye massage therapy; Iris
   segmentation; Periocular image classification; Circle Hough transform;
   Normalization; Discrete cosine transform
AB This paper proposes a method to evaluate the effectiveness of the eye message therapy. The existing methods are via the diagnoses conducted by the medical professions based on the measurements acquired by the optical instruments. However, this approach is very expensive. To address this issue, this paper performs the classification between the periocular images taken before performing the eye massage therapy and those after performing the eye massage therapy to address the above difficulty. First, the median filtering is used to suppress the solitary point noise with preserving the edges of the image without causing the significant blurring. Then, the Canny operator is employed to accurately locate the edges. Next, the circle Hough transform (CHT) is used for performing the iris segmentation. Finally, various classifiers are used to perform the classification. The computer numerical simulation results show that our proposed method can achieve the high classification accuracies. This implies that there is a significant difference on the iris before performing the eye massage therapy and after performing the eye massage therapy. In addition, the comparisons with the state of art Daugman method have been performed. It is found that the classification performance achieved by the CHT based method is better than those achieved by the Daugman method.
C1 [Zheng, Xiao-Ben; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
   [Zeng, Zhi-Tao] Bella Guangzhou Intelligent Informat Technol Co L, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Ling, BWK (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
EM 331415325@qq.com; yongquanling@gdut.edu.cn
OI Zheng, Xiao Ben/0000-0003-0260-5882
FU National Nature Science Foundation of China [U1701266, 61671163,
   62071128]; Team Project of the Education Ministry of the Guangdong
   Province [2017KCXTD011]; Guangdong Higher Education Engineering
   Technology Research Center for Big Data on Manufacturing Knowledge
   Patent [501130144]; Hong Kong Innovation and Technology Commission,
   Enterprise Support Scheme [S/E/070/17]
FX This paper was supported partly by the National Nature Science
   Foundation of China (no. U1701266, no. 61671163 and no. 62071128), the
   Team Project of the Education Ministry of the Guangdong Province (no.
   2017KCXTD011), the Guangdong Higher Education Engineering Technology
   Research Center for Big Data on Manufacturing Knowledge Patent (no.
   501130144), the Hong Kong Innovation and Technology Commission,
   Enterprise Support Scheme (no. S/E/070/17), and the Bella (Guangzhou)
   Intelligent Information Technology Company Limited, for providing its
   electronic device.
CR [Anonymous], 2015, INT J SCI TECHNICAL
   [Anonymous], 2003, Recognition of Human Iris Patterns for Biometric Identification
   [Anonymous], 2012, P NAT C INF TECHN CO
   Ayaki M, 2016, SCI REP-UK, V6, DOI 10.1038/srep22480
   Bhatia, 2010, 2010 2 INT C SIGN PR, V1, pV1
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Daugman J, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P715, DOI 10.1016/B978-0-12-374457-9.00025-1
   Divya C. D., 2021, Journal of Physics: Conference Series, V1913, DOI 10.1088/1742-6596/1913/1/012096
   Fahim Magid M, 2006, BMC Ophthalmol, V6, P20, DOI 10.1186/1471-2415-6-20
   George G, 2018, 2018 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P235, DOI 10.1109/ICEDSS.2018.8544273
   Gowrisankaran S, 2015, WORK, V52, P303, DOI 10.3233/WOR-152162
   Hassanein A.S., 2015, IJCSI International Journal of Computer Science Issues, V12, P139
   Holden B, 2014, EYE, V28, P142, DOI 10.1038/eye.2013.256
   Huang YP, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P450
   Jan F, 2013, SIGNAL PROCESS, V93, P230, DOI 10.1016/j.sigpro.2012.07.033
   Jie Y, 2019, OCUL SURF, V17, P440, DOI 10.1016/j.jtos.2019.05.007
   Kang MT, 2016, SCI REP-UK, V6, DOI 10.1038/srep28531
   Lemp MA, 2007, OCUL SURF, V5, P75
   Lin Z, 2013, BMC COMPLEM ALTERN M, V13, DOI 10.1186/1472-6882-13-306
   Lin ZH, 2011, PROCEDIA ENVIRON SCI, V8, P352, DOI 10.1016/j.proenv.2011.10.055
   Mandloi Gaurav, 2014, INT J COMPUTER SCI I, V5, P4615
   Nkole I.U., 2012, An enhanced iris segmentation algorithm using circle Hough transform
   Peng Zhiyong, 2015, Wuhan University Journal of Natural Sciences, V20, P229, DOI 10.1007/s11859-015-1086-9
   Qazi Y, 2014, GRAEF ARCH CLIN EXP, V252, P857, DOI 10.1007/s00417-014-2618-2
   Ranasinghe P, 2016, BMC Res Notes, V9, P150, DOI 10.1186/s13104-016-1962-1
   Singh, 2015, INT J ENG TECH RES, V3, P440
   Singh S., 2013, International Journal Of Emerging Technology And Advanced Engineering, V3, P333
   Verma P., 2012, Int. J. Emerg. Technol. Adv. Eng, V2, P177
   Zainal A., 2012, J TELECOMMUN ELECT C, V4, P41
NR 29
TC 0
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5743
EP 5760
DI 10.1007/s11042-021-11789-w
EA DEC 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735344700001
PM 34975285
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumar, A
   Alsadoon, A
   Prasad, PWC
   Abdullah, S
   Rashid, TA
   Pham, DTH
   Nguyen, TQV
AF Kumar, Ashish
   Alsadoon, Abeer
   Prasad, P. W. C.
   Abdullah, Salma
   Rashid, Tarik A.
   Duong Thu Hang Pham
   Tran Quoc Vinh Nguyen
TI Generative adversarial network (GAN) and enhanced root mean square error
   (ERMSE): deep learning for stock price movement prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stock market prediction; Phase-space reconstruction; Generative
   adversarial networks; Deep learning
ID MARKET PREDICTION; MODEL
AB The prediction of stock price movement direction is significant in financial circles and academic. Stock price contains complex, incomplete, and fuzzy information which makes it an extremely difficult task to predict its development trend. Predicting and analysing financial data is a nonlinear, time-dependent problem. With rapid development in machine learning and deep learning, this task can be performed more effectively by a purposely designed network. This paper aims to improve prediction accuracy and minimizing forecasting error loss through deep learning architecture by using Generative Adversarial Networks. It was proposed a generic model consisting of Phase-space Reconstruction (PSR) method for reconstructing price series and Generative Adversarial Network (GAN) which is a combination of two neural networks which are Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural Network (CNN) as Discriminative model for adversarial training to forecast the stock market. LSTM will generate new instances based on historical basic indicators information and then CNN will estimate whether the data is predicted by LSTM or is real. It was found that the Generative Adversarial Network (GAN) has performed well on the enhanced root mean square error to LSTM, as it was 4.35% more accurate in predicting the direction and reduced processing time and RMSE by 78 s and 0.029, respectively. This study provides a better result in the accuracy of the stock index. It seems that the proposed system concentrates on minimizing the root mean square error and processing time and improving the direction prediction accuracy, and provides a better result in the accuracy of the stock index.
C1 [Kumar, Ashish; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Abdullah, Salma] Univ Technol Baghdad, Dept Comp Engn, Baghdad, Iraq.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Duong Thu Hang Pham; Tran Quoc Vinh Nguyen] Univ Da Nang, Univ Sci & Educ, Fac Informat Technol, Da Nang, Vietnam.
C3 Charles Sturt University; Western Sydney University; University of
   Technology- Iraq; University of Kurdistan Hewler; University of Danang
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Rashid, Tarik A./P-3473-2019; Alsadoon, A/Prof. Abeer/AAU-1532-2021;
   Abdullah, Salma Hameedi/GRJ-1117-2022; Rashid, Tarik A./HLX-0184-2023
OI Rashid, Tarik A./0000-0002-8661-258X; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; Abdullah, Salma Hameedi/0000-0003-2087-0153;
   Rashid, Tarik A./0000-0002-8661-258X; withana,
   chandana/0000-0002-3007-687X
CR Arora M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0557-y
   Basak S, 2019, N AM J ECON FINANC, V47, P552, DOI 10.1016/j.najef.2018.06.013
   Derakhshan A, 2019, ENG APPL ARTIF INTEL, V85, P569, DOI 10.1016/j.engappai.2019.07.002
   Göçken M, 2019, NEURAL COMPUT APPL, V31, P577, DOI 10.1007/s00521-017-3089-2
   Hoseinzade E, 2019, EXPERT SYST APPL, V129, P273, DOI 10.1016/j.eswa.2019.03.029
   Jeon S, 2018, FUTURE GENER COMP SY, V80, P171, DOI 10.1016/j.future.2017.02.010
   Kristjanpoller RW, 2018, APPL SOFT COMPUT, V67, P106, DOI 10.1016/j.asoc.2018.02.055
   Li XD, 2016, NEURAL COMPUT APPL, V27, P67, DOI 10.1007/s00521-014-1550-z
   Long W, 2019, KNOWL-BASED SYST, V164, P163, DOI 10.1016/j.knosys.2018.10.034
   Ning Y, 2018, CLUSTER COMPUT, P1
   Sermpinis G., 2019, ANN OPERATIONS RES, P1
   Song Y, 2019, APPL INTELL, V49, P897, DOI 10.1007/s10489-018-1308-x
   Xingyu Zhou, 2018, Mathematical Problems in Engineering, V2018, DOI 10.1155/2018/4907423
   Yu PF, 2020, NEURAL COMPUT APPL, V32, P1609, DOI 10.1007/s00521-019-04212-x
   Zhang Xi, 2018, KNOWL INF SYST, P1
   Zhou ZK, 2018, WORLD WIDE WEB, V21, P1093, DOI 10.1007/s11280-017-0495-4
NR 16
TC 16
Z9 16
U1 10
U2 94
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3995
EP 4013
DI 10.1007/s11042-021-11670-w
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722981800002
DA 2024-07-18
ER

PT J
AU Sofla, MS
   Kashani, MH
   Mahdipour, E
   Mirzaee, RF
AF Sheikh Sofla, Maryam
   Haghi Kashani, Mostafa
   Mahdipour, Ebrahim
   Faghih Mirzaee, Reza
TI Towards effective offloading mechanisms in fog computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fog computing; Offloading; Internet of things (IoT); Quality of service
   (QoS)
ID OF-THE-ART; RESOURCE-ALLOCATION; COMPREHENSIVE SURVEY; SERVICE
   COMPOSITION; CLOUD; IOT; EDGE; INTERNET; TECHNOLOGIES; SYSTEMS
AB Fog computing is considered a formidable next-generation complement to cloud computing. Nowadays, in light of the dramatic rise in the number of IoT devices, several problems have been raised in cloud architectures. By introducing fog computing as a mediate layer between the user devices and the cloud, one can extend cloud computing's processing and storage capability. Offloading can be utilized as a mechanism that transfers computations, data, and energy consumption from the resource-limited user devices to resource-rich fog/cloud layers to achieve an optimal experience in the quality of applications and improve the system performance. This paper provides a systematic and comprehensive study to evaluate fog offloading mechanisms' current and recent works. Each selected paper's pros and cons are explored and analyzed to state and address the present potentialities and issues of offloading mechanisms in a fog environment efficiently. We classify offloading mechanisms in a fog system into four groups, including computation-based, energy-based, storage-based, and hybrid approaches. Furthermore, this paper explores offloading metrics, applied algorithms, and evaluation methods related to the chosen offloading mechanisms in fog systems. Additionally, the open challenges and future trends derived from the reviewed studies are discussed.
C1 [Sheikh Sofla, Maryam; Haghi Kashani, Mostafa; Mahdipour, Ebrahim] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Faghih Mirzaee, Reza] Islamic Azad Univ, Dept Comp Engn, Shahr e Qods Branch, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Mahdipour, E (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
EM m.sheikh@srbiau.ac.ir; mh.kashani@srbiau.ac.ir; mahdipour@srbiau.ac.ir;
   r.f.mirzaee@qodsiau.ac.ir
RI Haghi Kashani, Mostafa/AAO-4921-2021
OI Haghi Kashani, Mostafa/0000-0002-9812-1331
CR Aazam Mohammad, 2016, IEEE Potentials, V35, P40, DOI 10.1109/MPOT.2015.2456213
   Aazam M, 2018, FUTURE GENER COMP SY, V87, P278, DOI 10.1016/j.future.2018.04.057
   Adhikari M, 2020, IEEE INTERNET THINGS, V7, P4317, DOI 10.1109/JIOT.2019.2958400
   Ahmadi Z, 2021, MULTIMED TOOLS APPL, V80, P36361, DOI 10.1007/s11042-021-11227-x
   Akherfi Khadija, 2018, Applied Computing and Informatics, V14, P1, DOI 10.1016/j.aci.2016.11.002
   Al-Zinati M, 2021, MULTIMED TOOLS APPL, V80, P16805, DOI 10.1007/s11042-020-09050-x
   Ali M, 2017, DIGIT COMMUN NETW, V3, P188, DOI 10.1016/j.dcan.2017.03.002
   [Anonymous], 2016, OpenNESS Ecosystem Services Reference Book. EC FP7 Grant Agreement No. 308428, P1
   Asghari P, 2019, COMPUT NETW, V148, P241, DOI 10.1016/j.comnet.2018.12.008
   Asghari P, 2018, J NETW COMPUT APPL, V120, P61, DOI 10.1016/j.jnca.2018.07.013
   Ashton K., RFID journal, V22 22, P97, DOI DOI 10.1145/2967977
   Balan RajeshKrishna., 2006, Simplifying Cyber Foraging
   Balasubramanian S., 2020, Computing in Engineering and Technology. Proceedings of ICCET 2019. Advances in Intelligent Systems and Computing (AISC 1025), P253, DOI 10.1007/978-981-32-9515-5_24
   Bazzaz Abkenar S., 2020, TELEMAT INFORM, V2020
   Bazzaz Abkenar S, 2021, IEEE T KNOWL DATA EN
   Ben Hamida E, 2009, SIMUL-T SOC MOD SIM, V85, P574, DOI 10.1177/0037549709106633
   Bilal K, 2018, COMPUT NETW, V130, P94, DOI 10.1016/j.comnet.2017.10.002
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bonomi F., 2014, Fog Computing: A Platform for Internet of Things and Analytics, P169
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Bouachir O, 2020, COMPUTER, V53, P36, DOI 10.1109/MC.2020.2996212
   Boukerche A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3286688
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Cai PH, 2020, IEEE INTERNET THINGS, V7, P3067, DOI 10.1109/JIOT.2020.2964951
   Cao B, 2019, IEEE COMMUN MAG, V57, P56, DOI 10.1109/MCOM.2019.1800608
   Chen SG, 2020, IEEE T GREEN COMMUN, V4, P566, DOI 10.1109/TGCN.2019.2960767
   Chen TY, 1997, INT J PROD ECON, V53, P71, DOI 10.1016/S0925-5273(97)00102-3
   Chen Z., 2019, INT C PION COMP SCI, P217, DOI 10.1007/978-981-15-0118-0_17
   Chiti F, 2018, IEEE INTERNET THINGS, V5, P5089, DOI 10.1109/JIOT.2018.2871251
   Dolui K, 2017, 2017 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS 2017), P19
   Dordaie N, 2018, ICT EXPRESS, V4, P199, DOI 10.1016/j.icte.2017.08.001
   Du JB, 2018, IEEE T COMMUN, V66, P1594, DOI 10.1109/TCOMM.2017.2787700
   Fathi M, 2022, ARCH COMPUT METHOD E, V29, P1247, DOI 10.1007/s11831-021-09616-4
   Fricker C., 2016, ACM Transactions on Modeling and Performance Evaluation of Computing Systems (TOMPECS), V1, P16
   Ghobaei-Arani M, 2020, J GRID COMPUT, V18, P1, DOI 10.1007/s10723-019-09491-1
   Guo CX, 2009, ACM SIGCOMM COMP COM, V39, P63, DOI 10.1145/1594977.1592577
   Haghi Kashani M, 2021, IEEE T SERV COMPUT
   Kashani MH, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4340
   Han B, 2015, IEEE COMMUN MAG, V53, P90, DOI 10.1109/MCOM.2015.7045396
   Hu PF, 2017, J NETW COMPUT APPL, V98, P27, DOI 10.1016/j.jnca.2017.09.002
   Hu PF, 2017, IEEE T IND INFORM, V13, P1910, DOI 10.1109/TII.2016.2607178
   Huang D, 2012, IEEE T WIREL COMMUN, V11, P1991, DOI 10.1109/TWC.2012.041912.110912
   Iorga Michaela, 2018, NIST Special Publication, DOI [10.6028/NIST.SP.500-325, DOI 10.6028/NIST.SP.500-325]
   Jiang YL, 2019, IEEE SYST J, V13, P2930, DOI 10.1109/JSYST.2018.2877850
   Jiang YX, 2018, IEEE INTERNET THINGS, V5, P4945, DOI 10.1109/JIOT.2018.2880250
   Jula A, 2014, EXPERT SYST APPL, V41, P3809, DOI 10.1016/j.eswa.2013.12.017
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karimi Y, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6379
   Kashani M. H., 2011, Proceedings of the 2011 3rd International Conference on Advanced Computer Control (ICACC 2011), P422, DOI 10.1109/ICACC.2011.6016445
   Kashani M. H., 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P298, DOI 10.1109/CICSyN.2011.69
   Kashani M. H., 2009, Proceedings of the 2009 First International Conference on Computational Intelligence, Modelling and Simulation. CSSim 2009 Information Getting Started, P265, DOI 10.1109/CSSim.2009.36
   KASHANI MH, 2009, INT J SIMULATION SY, V10, P25
   Kashani MH, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103164
   Kashani MH, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P673, DOI 10.1109/KBEI.2017.8324882
   Kashani MH, 2012, PROC SPIE, V8350, DOI 10.1117/12.920124
   Khan AUR, 2017, WIRELESS PERS COMMUN, V97, P4897, DOI 10.1007/s11277-017-4757-3
   Kim H, 2013, IEEE COMMUN MAG, V51, P114, DOI 10.1109/MCOM.2013.6461195
   Kitchenham B., 2007, 2007001 EBSE
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Krishnanand K. N., 2009, Swarm Intelligence, V3, P87, DOI 10.1007/s11721-008-0021-5
   Kumar K, 2010, COMPUTER, V43, P51, DOI 10.1109/MC.2010.98
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Li L, 2019, IEEE ACCESS, V7, P9912, DOI 10.1109/ACCESS.2019.2891130
   Li QP, 2019, CHINA COMMUN, V16, P32, DOI 10.12676/j.cc.2019.03.004
   Liang K, 2016, CHINA COMMUN, V13, P131, DOI 10.1109/CC.2016.7833467
   Lin H, 2020, J NETW COMPUT APPL, V169, DOI 10.1016/j.jnca.2020.102781
   Liu LQ, 2018, IEEE INTERNET THINGS, V5, P1869, DOI 10.1109/JIOT.2018.2816682
   Liu LQ, 2018, IEEE INTERNET THINGS, V5, P283, DOI 10.1109/JIOT.2017.2780236
   Liu YM, 2018, IEEE T VEH TECHNOL, V67, P12137, DOI 10.1109/TVT.2018.2872912
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Marín-Tordera E, 2017, COMPUT COMMUN, V109, P117, DOI 10.1016/j.comcom.2017.05.013
   Mayes JC, 1998, US Patent, Patent No. [5,793,763, 5793763]
   Mell P, 2010, COMMUN ACM, V53, P50
   Meng XL, 2017, IEEE ACCESS, V5, P21355, DOI 10.1109/ACCESS.2017.2748140
   Tran MQ, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/6215454
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Misra S, 2019, IEEE J SEL AREA COMM, V37, P1159, DOI 10.1109/JSAC.2019.2906793
   Mouradian C, 2018, IEEE COMMUN SURV TUT, V20, P416, DOI 10.1109/COMST.2017.2771153
   Mukherjee A, 2018, J SUPERCOMPUT, V74, P2412, DOI 10.1007/s11227-018-2269-x
   Munir A, 2017, IEEE CONSUM ELECTR M, V6, P74, DOI 10.1109/MCE.2017.2684981
   Naas MI, 2017, 2017 IEEE 1ST INTERNATIONAL CONFERENCE ON FOG AND EDGE COMPUTING (ICFEC), P97, DOI 10.1109/ICFEC.2017.15
   Nan Y, 2017, IEEE ACCESS, V5, P23947, DOI 10.1109/ACCESS.2017.2766165
   Neghabi AA, 2018, IEEE ACCESS, V6, P14159, DOI 10.1109/ACCESS.2018.2805842
   Nikravan M, 2007, 21ST EUROPEAN CONFERENCE ON MODELLING AND SIMULATION ECMS 2007, P639
   Nikravan M, 2007, 21ST EUROPEAN CONFERENCE ON MODELLING AND SIMULATION ECMS 2007, P645
   Niu B, 2012, DISCRETE DYN NAT SOC, V2012, DOI 10.1155/2012/698057
   OpenFogConsortium, 2017, OPENFOG REFERENCE AR
   Orsini G, 2015, PROCEDIA COMPUT SCI, V56, P10, DOI 10.1016/j.procs.2015.07.169
   Pai S, 2008, IEEE SECUR PRIV, V6, P28, DOI 10.1109/MSP.2008.107
   Pandya S, 2004, US Patent, Patent No. [10/704,494, 10704494]
   Plumb JN, 2018, 2018 IEEE 2ND INTERNATIONAL CONFERENCE ON FOG AND EDGE COMPUTING (ICFEC)
   Quinton B, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/1245720
   Rabie AH, 2019, CLUSTER COMPUT, V22, P241, DOI 10.1007/s10586-018-2848-x
   Rahbari D, 2020, PEER PEER NETW APPL, V13, P104, DOI 10.1007/s12083-019-00721-7
   Rahimi M, 2020, J NETW COMPUT APPL, V153, DOI 10.1016/j.jnca.2020.102531
   Rahman G., 2018, IJET, V7, P1615, DOI [10.14419/ijet.v7i3.12612, DOI 10.14419/IJET.V7I3.12612]
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Ruan LN, 2018, J COMMUN NETW-S KOR, V20, P247, DOI 10.1109/JCN.2018.000037
   Sarvizadeh R., 2012, INT J COMPUT APPL, V42, P1, DOI DOI 10.5120/5725-7792
   Sarvizadeh R, 2012, PROC SPIE, V8349, DOI 10.1117/12.920102
   Satyanarayanan M, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.82
   Shah-Mansouri H, 2018, IEEE INTERNET THINGS, V5, P3246, DOI 10.1109/JIOT.2018.2838022
   Shakarami A, 2020, COMPUT NETW, V182, DOI 10.1016/j.comnet.2020.107496
   Shakarami A, 2020, J GRID COMPUT, V18, P639, DOI 10.1007/s10723-020-09530-2
   Shakarami A, 2020, SOFTWARE PRACT EXPER, V50, P1719, DOI 10.1002/spe.2839
   Shnaiwer YN, 2019, IEEE ACCESS, V7, P56147, DOI 10.1109/ACCESS.2019.2913860
   Shuja J, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3174
   Shuja J, 2017, IEEE ACCESS, V5, P24542, DOI 10.1109/ACCESS.2017.2713818
   Shuja J, 2016, J NETW COMPUT APPL, V75, P335, DOI 10.1016/j.jnca.2016.08.021
   Singh S, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P731, DOI [10.1109/ICS.2016.0151, 10.1109/ICS.2016.150]
   Singh SP, 2019, J SUPERCOMPUT, V75, P2070, DOI 10.1007/s11227-018-2701-2
   SINGH VK, 2021, MULTIMEDIA TOOLS APP
   Songhorabadi M, 2020, FOG COMPUTING APPROA
   Su ZY, 2022, IEEE T BIG DATA, V8, P35, DOI 10.1109/TBDATA.2017.2705418
   Vu DN, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3497
   Wang B, 2020, IEEE ACCESS, V8, P186080, DOI 10.1109/ACCESS.2020.3029649
   Wang DY, 2019, IEEE ACCESS, V7, P41356, DOI 10.1109/ACCESS.2019.2908263
   Wang JY, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3284387
   Wang Q, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3880
   Wang T, 2019, IEEE INTERNET THINGS, V6, P4272, DOI 10.1109/JIOT.2018.2875915
   Wang T, 2019, WIREL NETW, V25, P573, DOI 10.1007/s11276-017-1576-0
   Wang XJ, 2018, IEEE T IND INFORM, V14, P4568, DOI 10.1109/TII.2018.2816590
   Wei ZL, 2018, IEEE ACCESS, V6, P49767, DOI 10.1109/ACCESS.2018.2868894
   Wu EHK, 2004, IEEE J SEL AREA COMM, V22, P757, DOI 10.1109/JSAC.2004.825999
   Wu HM, 2018, IEEE ACCESS, V6, P3962, DOI 10.1109/ACCESS.2018.2791504
   Wu Q, 2020, IEEE ACCESS, V8, P1173, DOI 10.1109/ACCESS.2019.2961802
   Xu XL, 2019, FUTURE GENER COMP SY, V95, P522, DOI 10.1016/j.future.2018.12.055
   Yang XS, 2013, ENG COMPUT-GERMANY, V29, P175, DOI 10.1007/s00366-012-0254-1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yang Y, 2020, MULTIMED TOOLS APPL, V79, P10701, DOI 10.1007/s11042-020-08703-1
   Yi S., 2015, P 2015 WORKSH MOB BI, P37, DOI [DOI 10.1145/2757384.2757397, 10.1145/2757384.2757397]
   Yi SH, 2015, 2015 THIRD IEEE WORKSHOP ON HOT TOPICS IN WEB SYSTEMS AND TECHNOLOGIES (HOTWEB), P73, DOI 10.1109/HotWeb.2015.22
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Yousefpour A, 2018, IEEE INTERNET THINGS, V5, P998, DOI 10.1109/JIOT.2017.2788802
   Zaharia GE, 2020, SIMUL MODEL PRACT TH, V101, DOI 10.1016/j.simpat.2019.102045
   Zhang C, 2019, INT CONF AGRO-GEOINF, DOI 10.1109/agro-geoinformatics.2019.8820236
   Zhang GW, 2019, IEEE INTERNET THINGS, V6, P4388, DOI 10.1109/JIOT.2018.2887229
   Zhou Z, 2013, I S MOD ANAL SIM COM, P232, DOI 10.1109/MASCOTS.2013.31
   Zhu QL, 2017, CHINA COMMUN, V14, P59, DOI 10.1109/CC.2017.8233651
NR 140
TC 45
Z9 45
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1997
EP 2042
DI 10.1007/s11042-021-11423-9
EA OCT 2021
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000708822400003
PM 34690529
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Patrick, N
   Bhagvati, C
AF Patrick, Niyishaka
   Bhagvati, Chakravarthy
TI Geometric transformations parameters estimation from copy-move forgery
   using image blobs and keypoints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blobs; CMF; CMFD; DoG; 2D Affine transformation
AB A copy-move forgery is a passive tampering wherein one or more regions have been copied and pasted within the same image. Often, geometric transformations, including scale, rotation, and rotation+scale are applied to the forged areas to conceal the counterfeits to the copy-move forgery detection methods. Recently, copy-move forgery detection using image blobs have been used to tackle the limitation of the existing detection methods. However, the main limitation of blobs-based copy-move forgery detection methods is the inability to perform the geometric transformation estimation. To tackle the above-mentioned limitation, this article presents a technique that detects copy-move forgery and estimates the geometric transformation parameters between the authentic region and its duplicate using image blobs and scale-rotation invariant keypoints. The proposed algorithm involves the following steps: image blobs are found in the image being analyzed; scale-rotation invariant features are extracted; the keypoints that are located within the same blob are identified; feature matching is performed between keypoints that are located within different blobs to find similar features; finally, the blobs with matched keypoints are post-processed and a 2D affine transformations is computed to estimate the geometric transformation parameters. Our technique is flexible and can easily take in various scale-rotation invariant keypoints including AKAZE, ORB, BRISK, SURF, and SIFT to enhance the effectiveness. The proposed algorithm is implemented and evaluated on images forged with copy-move regions combined with geometric transformation from standard datasets. The experimental results indicate that the new algorithm is effective for geometric transformation parameters estimation.
C1 [Patrick, Niyishaka; Bhagvati, Chakravarthy] Univ Hyderabad, Hyderabad, India.
C3 University of Hyderabad
RP Patrick, N (corresponding author), Univ Hyderabad, Hyderabad, India.
OI Patrick, Niyishaka/0000-0003-4200-335X
CR Al Azrak FM, 2020, MULTIMED TOOLS APPL, V79, P18221, DOI 10.1007/s11042-019-08162-3
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Aniket R., 2018, DIGITAL IMAGE FORENS, V755, DOI [10.1007/978-981-10-7644-2, DOI 10.1007/978-981-10-7644-2]
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Blatner D., 2000, MACWORLD
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Lee S., 2019, FAST AFFINE TRANSFOR, P1180
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Lindeberg T., 2008, Encyclopedia of Computer Science and Engineering, V4, P2495, DOI DOI 10.1002/9780470050118.ECSE609
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdi M., 2020, DETECTION COPY MOVE, V01, P17, DOI [10.1007/978-3-030-38752-5_2, DOI 10.1007/978-3-030-38752-5_2]
   Niyishaka P, 2018, LECT NOTES COMPUT SC, V11114, P472, DOI 10.1007/978-3-030-00692-1_41
   Niyishaka P, 2021, MULTIMED TOOLS APPL, V80, P2161, DOI 10.1007/s11042-020-09707-7
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Ojeniyi Joseph A., 2018, International Journal of Image, Graphics and Signal Processing, V10, P22, DOI 10.5815/ijigsp.2018.04.03
   Ramya M., 2016, INT RES J ENG TECHNO, V3, P1350
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Tareen S.A.K., 2018, 2018 INT C COMPUTING, P1, DOI DOI 10.1109/ICOMET.2018.8346440
   Wang XY, 2018, APPL INTELL, V48, P3630, DOI 10.1007/s10489-018-1168-4
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 31
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1953
EP 1969
DI 10.1007/s11042-021-11642-0
EA OCT 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000707680100001
DA 2024-07-18
ER

PT J
AU Karnik, T
   Shivakumara, P
   Chowdhury, PN
   Pal, U
   Lu, T
   Anuar, NB
AF Karnik, Tapan
   Shivakumara, Palaiahnakote
   Chowdhury, Pinaki Nath
   Pal, Umapada
   Lu, Tong
   Anuar, Nor Badrul
TI A new deep model for family and non-family photo identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human trafficking; Kinship verification; Human parsing; Deep learning;
   Multimodal approach; Family and non-family photos
ID KINSHIP VERIFICATION
AB Human trafficking is a global issue of the world and the problems related to human trafficking remain unsolved. This paper presents a new method for the identification of photos of different types of families and non-families such that the method can assist investigation team to find a solution to such issue. We believe that parts of human beings are the main resources for representing family and non-family photos. Based on this intuition, we propose to segment hair, head, cloth, torso, and skin regions from each human in input photos by exploring a self-correlation for human parsing method. This step results in region of interest (ROI). Motivated by ability of deep learning models in solving complex issues and special property of MobileNet, which is light weight model, we further explore MobileNetv2 for the identification of photos of different families and non-families by considering ROI as the input. For the experiment of this work, we consider a dataset of ten classes, which include five family classes, namely, Couple, Nuclear Family, Multi-Cultural Family, Father-Child, Mother-Child and five more non-family classes, namely, Male Friends, Female Friends, Mixed Friends, Male Celebrity, Female Celebrity. The results of the proposed method are demonstrated by testing on our dataset of family and non-family photos classification. Comparative results with the existing methods show that our proposed method outperforms existing methods in terms of classification rate and F-Score.
C1 [Karnik, Tapan; Chowdhury, Pinaki Nath; Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Shivakumara, Palaiahnakote; Anuar, Nor Badrul] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   Universiti Malaya; Nanjing University
RP Lu, T (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM tapankarnik@gmail.com; pinakinathc@gmail.com; umapada@isical.ac.in;
   lutong@nju.edu.cn; badrul@um.edu.my
RI Anuar, Nor Badrul/B-3101-2010; Palaiahnakote, Shivakumara/B-6261-2013;
   Palaiahnakote, Shivakumara/ITU-6488-2023; Pal, Umapada/AAC-4930-2022
OI Anuar, Nor Badrul/0000-0003-4380-5303; 
FU University of Malaya, Malaysia [GPF096A-2020, GPF096B-2020,
   GPF096C-2020]; National Science Foundation of China [61672273]
FX The authors of this paper thank to the anonymous reviewers for their
   constructive comments and suggestions, which help us to improve the
   quality and clarify of the proposed work. This work received the support
   from the Faculty Grant (GPF096A-2020, GPF096B-2020, GPF096C-2020),
   University of Malaya, Malaysia. This work is also supported by the
   National Science Foundation of China under Grant 61672273.
CR Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5
   Bastian BT, 2020, MULTIMED TOOLS APPL, V79, P2931, DOI 10.1007/s11042-019-08498-w
   Cai GC, 2014, EXPERT SYST APPL, V41, P3514, DOI 10.1016/j.eswa.2013.10.057
   Dai QY, 2015, IEEE WINT CONF APPL, P982, DOI 10.1109/WACV.2015.136
   Dandekar AR, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Grouver A, 2019, Asian Conference on Pattern Recognition, P76
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Karpagavalli P, 2020, MULTIMED TOOLS APPL, V79, P28993, DOI 10.1007/s11042-019-08181-0
   Kingma D. P., 2014, arXiv
   Li PC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2909
   Maryam AK., 2019, EXPERT SYST APPL, DOI 10.1016/j.eswax.2019.100008
   PARACCHINI M, 2020, PATTERN RECOGNIT
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   de Andrade DOS, 2018, MULTIMED TOOLS APPL, V77, P423, DOI 10.1007/s11042-016-4281-6
   Stylianou A., 2017, IEEE APP IMG PAT, DOI 10.1109/AIPR.2017.8457947
   Wang XL, 2017, IMAGE VISION COMPUT, V58, P61, DOI 10.1016/j.imavis.2016.07.006
   Xia SY, 2014, INT C PATT RECOG, P2844, DOI 10.1109/ICPR.2014.490
   Xiaolong Wang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163147
NR 20
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1765
EP 1785
DI 10.1007/s11042-021-11631-3
EA OCT 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000706943000002
DA 2024-07-18
ER

PT J
AU Guo, JF
AF Guo, Jiefeng
TI An HEVC-compliant perceptual video coding using just noticeable
   difference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding (HEVC); Just noticeable difference (JND);
   Perceptual video coding (PVC); Temporal masking effect
ID CONTRAST-SENSITIVITY; JND PROFILE; DISTORTION; MODEL; OPTIMIZATION
AB Video coding removes spatial, temporal, and statistic redundancies. After H.265, to further improve the coding efficiency, many efforts have been dedicated to removing the perceptual redundancy by using human perception-based methods. Just noticeable difference (JND) gives a good approximation for the human visual system and provides a valuable solution to remove the perceptual redundancy for perceptual video coding (PVC). However, there are still problems in the PVC architecture and the JND profile. One is although the whole discrete cosine transform (DCT) block are suppressed, there are still many transform coefficients below the suppression levels which are not adequately suppressed. Another problem is, to the best of our knowledge, most JND profiles are measured by image-based test methods and past display equipment. However, compared to images, videos exhibits temporal characteristics, and the current trend of the display equipment is towards full high definition. To solve these problems, we first propose a high efficiency video coding (HEVC)-compliant PVC architecture, where the coefficients in a DCT block can be adequately suppressed in a whole block manner. Second, we propose a video-based test method to model the temporal masking (TM) effect, called TM-JND. Experimental results show that the proposed TM-JND model can more accurately estimate the JND values for today's display equipment and videos, avoiding the overestimate of the JND values like other existing models. The proposed PVC architecture achieves a significant bitrate reduction with a negligible subjective quality loss, compared with the HEVC test model HM 16.9.
C1 [Guo, Jiefeng] Xiamen Univ, Sch Elect Sci & Engn, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Guo, JF (corresponding author), Xiamen Univ, Sch Elect Sci & Engn, Xiamen 361005, Peoples R China.
EM jfguo@xmu.edu.cn
FU Natural Science Foundation of Fujian Province of China [2019J01046]
FX This work was supported by the Natural Science Foundation of Fujian
   Province of China under Grant 2019J01046.
CR Bae S-H, 2013, IEEE INT C IM PROC, V1, P431
   Bae SH, 2017, IEEE T CIRC SYST VID, V27, P1196, DOI 10.1109/TCSVT.2016.2539862
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P3343, DOI 10.1109/TIP.2016.2568459
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P3227, DOI 10.1109/TIP.2014.2327808
   Bae SH, 2013, IEEE SIGNAL PROC LET, V20, P893, DOI 10.1109/LSP.2013.2272193
   Bossen F., 2012, JCTVCJ1100, P1
   Cui X, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111095
   Hadizadeh H, 2017, IEEE SIGNAL PROC LET, V24, P1218, DOI 10.1109/LSP.2017.2717946
   Jaballah S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1797, DOI 10.1109/ICASSP.2018.8461738
   JCT-VC, 2020, HM 169 REF SOFTW
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Jung C, 2017, J VIS COMMUN IMAGE R, V48, P195, DOI 10.1016/j.jvcir.2017.06.007
   Laird J, 2006, PROC SPIE, V6057, DOI 10.1117/12.647870
   Li Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3267128
   Liu D, 2018, J VIS COMMUN IMAGE R, V56, P73, DOI 10.1016/j.jvcir.2018.07.015
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Ma L, 2011, SIGNAL PROCESS-IMAGE, V26, P162, DOI 10.1016/j.image.2011.02.002
   Mak CM, 2009, IEEE INT SYMP CIRC S, P609, DOI 10.1109/ISCAS.2009.5117822
   Ott R.L. Longnecker., 2008, An introduction to statistical methods and data analysis
   Pan ZQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159170
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   ROBSON JG, 1966, J OPT SOC AM, V56, P1141, DOI 10.1364/JOSA.56.001141
   Valizadeh S, 2021, MULTIMED TOOLS APPL, V80, P10235, DOI 10.1007/s11042-020-09442-z
   Vidal E, 2017, SIGNAL PROCESS-IMAGE, V52, P124, DOI 10.1016/j.image.2016.12.003
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Xiang GQ, 2018, J VIS COMMUN IMAGE R, V50, P280, DOI 10.1016/j.jvcir.2017.11.011
NR 28
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1257
EP 1286
DI 10.1007/s11042-021-11535-2
EA SEP 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000701635600001
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Hou, WY
   Zhang, JY
   Cao, CY
   Wu, B
AF Liu, Zihe
   Hou, Weiying
   Zhang, Jiayi
   Cao, Chenyu
   Wu, Bin
TI A Multimodal Approach for Multiple-Relation Extraction in Videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video understanding; Multiple-relation extraction; Social relationship
   recognition; Multimodal fusion
AB Automatically interpreting social relations, e.g., friendship, kinship, etc., from visual scenes has huge potential application value in areas such as knowledge graphs construction, person behavior and emotion analysis, entertainment ecology, etc. Great progress has been made in social analysis based on structured data. However, existing video-based methods consider social relationship extraction as a general classification task and categorize videos into only predefined types. Such methods are unable to recognize multiple relations in multi-person videos, which is obviously not consistent with the actual application scenarios. At the same time, videos are inherently multimodal. Subtitles in the video also provide abundant cues for relationship recognition that is often ignored by researchers. In this paper, we introduce and define a new task named "Multiple-Relation Extraction in Videos (MREV)". To solve the MREV task, we propose the Visual-Textual Fusion (VTF) framework for jointly modeling visual and textual information. For the spatial representation, we not only adopt a SlowFast network to learn global action and scene information, but also exploit the unique cues of face, body and dialogue between characters. For the temporal domain, we propose a Temporal Feature Aggregation module to perform temporal reasoning, which assesses the quality of different frames adaptively. After that, we use a Multi-Conv Attention module to capture the inter-modal correlation and map the features of different modes to a coordinated feature space. By this means, our VTF framework comprehensively exploits abundant multimodal cues for the MREV task and achieves 49.2% and 50.4% average accuracy on a self-constructed Video Multiple-Relation(VMR) dataset and ViSR dataset, respectively. Extensive experiments on VMR dataset and ViSR dataset demonstrate the effectiveness of the proposed framework.
C1 [Liu, Zihe; Hou, Weiying; Zhang, Jiayi; Cao, Chenyu; Wu, Bin] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, 10 Xitucheng Rd, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wu, B (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, 10 Xitucheng Rd, Beijing 100876, Peoples R China.
EM ziheliu@bupt.edu.cn; weiying.hou@bupt.edu.cn; brokenarrow@bupt.edu.cn;
   ccyu@bupt.edu.cn; wubin@bupt.edu.cn
RI Chen, John/GPW-8839-2022
FU National Natural Science Foundation of China [61972047]; National Key
   Research and Development Program of China [2018YFC0831500]; NSFC-General
   Technology Basic Research Joint Funds [U1936220]
FX This study was supported by the National Natural Science Foundation of
   China (grant no. 61972047), the National Key Research and Development
   Program of China (2018YFC0831500), and the NSFC-General Technology Basic
   Research Joint Funds (grant no. U1936220).
CR [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2393439
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Barr JR, 2014, IEEE WINT CONF APPL, P969, DOI 10.1109/WACV.2014.6835999
   Bourdev, 2014, ARXIV14120767, V2, P7
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chiu YI, 2013, MVA, P431
   Dai PL, 2019, IEEE INT CON MULTI, P1132, DOI 10.1109/ICME.2019.00198
   Dai QY, 2015, IEEE WINT CONF APPL, P982, DOI 10.1109/WACV.2015.136
   Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dibeklioglu H, 2017, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2017.269
   Ding L, 2011, IEEE I CONF COMP VIS, P699, DOI 10.1109/ICCV.2011.6126306
   Ding L, 2010, LECT NOTES COMPUT SC, V6314, P410, DOI 10.1007/978-3-642-15561-1_30
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feng F., 2020, ARXIV PREPRINT ARXIV
   Goel A, 2019, PROC CVPR IEEE, P11178, DOI 10.1109/CVPR.2019.01144
   Golder S, 2008, P 19 ACM C HYP HYP, P43, DOI 10.1145/1379092.1379104
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Kampman O, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P606
   Kanagaraj K, 2021, SIGNAL IMAGE VIDEO P, V15, P779, DOI 10.1007/s11760-020-01796-z
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Khademi M, 2020, P 58 ANN M ASS COMP, P7177, DOI 10.18653/v1/2020.acl-main.643
   Kohli N, 2019, IEEE T IMAGE PROCESS, V28, P1329, DOI 10.1109/TIP.2018.2840880
   Kukleva Anna, 2020, P IEEE CVF C COMP VI, P9849
   Li JN, 2017, IEEE I CONF COMP VIS, P2669, DOI 10.1109/ICCV.2017.289
   Li ML, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P77
   Liu J., 2015, ARXIV150607310
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2018, INT C LEARN REPR
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Lv JN, 2019, LECT NOTES COMPUT SC, V11296, P390, DOI 10.1007/978-3-030-05716-9_32
   Lv JN, 2018, IEEE ACCESS, V6, P25958, DOI 10.1109/ACCESS.2018.2832087
   Lv JN, 2018, LECT NOTES COMPUT SC, V10704, P355, DOI 10.1007/978-3-319-73603-7_29
   Nan CJ, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P831, DOI 10.1145/2808797.2809306
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   [彭宇新 Peng Yuxin], 2019, [计算机研究与发展, Journal of Computer Research and Development], V56, P183
   Ramanathan V, 2013, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2013.320
   Aimar ES, 2019, IEEE IMAGE PROC, P3227, DOI [10.1109/ICIP.2019.8803634, 10.1109/icip.2019.8803634]
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun QR, 2017, PROC CVPR IEEE, P435, DOI 10.1109/CVPR.2017.54
   Vicol P, 2018, PROC CVPR IEEE, P8581, DOI 10.1109/CVPR.2018.00895
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang Z, 2018, IEEE WINT CONF APPL, P1888, DOI 10.1109/WACV.2018.00209
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Wu P, 2009, IEEE INT CON MULTI, P1652, DOI 10.1109/ICME.2009.5202837
   Wu XY, 2020, IEEE T IND ELECTRON, V67, P6629, DOI 10.1109/TIE.2019.2937036
   Yan HB, 2018, PATTERN RECOGN, V75, P15, DOI 10.1016/j.patcog.2017.03.001
   Yeh MC, 2012, IEEE INT CONF MULTI, P242, DOI 10.1109/ICMEW.2012.48
   Yuan K, 2010, INT CONF ACOUST SPEE, P798, DOI 10.1109/ICASSP.2010.5494953
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zhang M, 2019, IEEE INT CON MULTI, P1618, DOI 10.1109/ICME.2019.00279
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zhong YJ, 2019, LECT NOTES COMPUT SC, V11362, P35, DOI 10.1007/978-3-030-20890-5_3
   Zhou L, 2018, CCF C BIG DAT, P442
   Zhou LL, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P382, DOI 10.1109/DSC.2017.78
   Zhu ZH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1097
NR 63
TC 4
Z9 4
U1 4
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4909
EP 4934
DI 10.1007/s11042-021-11466-y
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000695787500001
DA 2024-07-18
ER

PT J
AU Al-Karawi, KA
   Ahmed, ST
AF Al-Karawi, Khamis A.
   Ahmed, Shaymaa T.
TI Model selection toward robustness speaker verification in reverberant
   conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Reverberation time; Blind estimation; Robustness;
   MFCC; GMM
ID RECOGNITION; NOISY
AB Speech signals that recorded in the far field or with a distant microphone typically comprise additive noise and reverberation, which cause degradation and distortion in the reliability and intelligibility of speech signal, and the recognition performance of speaker recognition systems, with severe consequences in a wide range of real applications. Channel equalization, i.e. the removal or reduction or other cleaning methods of the channel effects, to some extent, mitigates the mismatching problem at the cost of added distortions to the vulnerable speech signal themselves, and therefore, its effectiveness is limited. This paper proposed to estimate the reverberation first and incorporate them into individual training examples to create virtually matched channels. The training process is performed before the final decision-making. In the training stage, the selection training target model out of the dataset of models that are trained in different reverberate environments and then using acoustic matched models for the reverberate in the test stage. The best matching model is selected by blindly estimating the full band reverberation time RT using maximum likelihood. Speaker recognition experiments in the artificial and real reverberate conditions show the efficiency of the proposed method in terms of decreased equal error rate EER and detection error trade-off DET.
C1 [Al-Karawi, Khamis A.] Univ Diyala, Diyala, Baqubah, Iraq.
   [Ahmed, Shaymaa T.] Univ Diyala, Coll Basic Educ, Diyala, Baqubah, Iraq.
C3 University of Diyala; University of Diyala
RP Al-Karawi, KA (corresponding author), Univ Diyala, Diyala, Baqubah, Iraq.
EM alkasi_68@yahoo.com; mrs.sh.ta.ah@gmail.com
RI AL-KARAWI, Khamis A./AGB-6700-2022
OI AL-KARAWI, Khamis A./0000-0001-9275-6902
CR Al-Karawi K, 2018, ROBUST SPEAKER RECOG
   Al-Karawi KA, 2020, INT J SPEECH TECHNOL, P1
   Al-Karawi KA., 2019, INT J SENSORS WIRELE, V9, P1, DOI [10.2174/221032790901190307103859, DOI 10.2174/221032790901190307103859]
   Al-Karawi KA, 2019, INT J SPEECH TECHNOL, V22, P1077, DOI 10.1007/s10772-019-09648-z
   Al-Karawi KA, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P52, DOI 10.1109/INTECH.2017.8102427
   Al-Noori AH, 2015, 2015 European Intelligence and Security Informatics Conference (EISIC), P180, DOI 10.1109/EISIC.2015.20
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   CATT-Acoustic, 2010, V8 0C ROOM ACOUSTIC
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1527
   Ganapathy S, 2011, INT CONF ACOUST SPEE, P4836
   Gaubitch N.D., 2012, Proc. International Workshop on Acoustic Signal Enhancement (IWAENC), P1
   GonzalezRodrigeuz J, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1333, DOI 10.1109/ICSLP.1996.607859
   Jeub M, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P550
   Kuttruff H., 2000, Room Acoustics
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li FF, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P194, DOI 10.1109/INTECH.2016.7845036
   Lollmann H. W., 2008, P INT WORKSH AC ECH
   Lollmann Heiner, 2010, P INT WORKSH AC ECH, P1
   Mammone RJ, 1996, IEEE SIGNAL PROC MAG, V13, P58, DOI 10.1109/79.536825
   Ming J, 2007, IEEE T AUDIO SPEECH, V15, P1711, DOI 10.1109/TASL.2007.899278
   Mohammed, 2020, MITIGATE REVERBERANT, DOI 10.1007/978-3-030-38752-5_8
   Muda Lindasalwa, 2010, Journal of Computing, DOI DOI 10.48550/ARXIV.1003.4083
   Probability RV, 2002, STOCHASTIC PROCESSES
   Ratnam R, 2003, J ACOUST SOC AM, V114, P2877, DOI 10.1121/1.1616578
   Ravanelli M, 2012, EUR SIGNAL PR CONF, P1668
   Sabine WallaceClement., 1964, COLLECTED PAPERS ACO
   Sadjadi S. O., 2013, Speech Lang. Process. Techn. Comm. Newsl, V1, P1
   Sadjadi SO, 2012, INT CONF ACOUST SPEE, P4225, DOI 10.1109/ICASSP.2012.6288851
   Wang L, 2009, P WESPAC 2009
   Wang N, 2011, IEEE T AUDIO SPEECH, V19, P196, DOI 10.1109/TASL.2010.2045800
   Zhang, 2006, 2006 14 EUR SIGN PRO
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398
NR 34
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36549
EP 36566
DI 10.1007/s11042-021-11356-3
EA SEP 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000693494500001
DA 2024-07-18
ER

PT J
AU Iqbal, N
   Hanif, M
AF Iqbal, Nadeem
   Hanif, Muhammad
TI An efficient grayscale image encryption scheme based on variable length
   row-column swapping operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Encryption; Decryption; Swapping; Intersection filter
ID HYPERCHAOTIC SYSTEM; DNA ENCRYPTION; CRYPTANALYSIS; MATRIX; CHAOS;
   SECURITY
AB Swapping a row with a row, a column with a column or row with a column are usual operations carried out to scramble the given input plain image. To introduce more complications for the potential hackers, a novel grayscale image encryption scheme using the variable length row-column swapping based scrambling (VLRCSBS) has been proposed in this study. Security of the cipher would be improved in this way. Two chaotic maps, Henon map and piecewise linear chaotic map (PWLCM) have been used. These maps provide three streams of random numbers. Two more streams of random numbers have been created by manipulating the two streams of Henon map. After the grayscale image is input, arbitrary row and column are selected from this image to realize the scrambling effects. A randomly selected vector of pixels from these selected rows and columns is swapped with each other for a number of times. If selected vectors of pixels intersect each other, then to avoid the loss of pixels data, an intersection filter (IF) has been employed to forgo the intersecting vectors of selected pixels from the row and column for swapping. Resultantly, the given image is confused abundantly. An Exclusive-OR(XOR) operation is conducted between the scrambled image and the keystream given by PWLCM to get the final encrypted image. In the previous studies, whole rows and whole columns were swapped with each other. Our study swapped randomly selected portions of the rows and columns for scrambling, which spawned more security. In order to introduce the plaintext sensitivity in the proposed cipher, the hash codes given by the SHA-256 hash function for each input image have been used to update the system parameters and the initial values of the chaotic systems. The value of information entropy attained through the proposed algorithm is 7.9975 which is very competitive. Besides, the simulation and the performance analyses with varied validation metrics express the robustness, defiance to the multifarious threats and potential for some real world application of the cipher.
C1 [Iqbal, Nadeem] Univ Lahore, Dept Comp Sci & IT, Lahore, Pakistan.
   [Hanif, Muhammad] Bahria Univ Lahore Campus, Dept Comp Sci, Lahore, Pakistan.
C3 University of Lahore
RP Iqbal, N (corresponding author), Univ Lahore, Dept Comp Sci & IT, Lahore, Pakistan.
EM nadeem.iqbal537@gmail.com; mhanif.bulc@bahria.edu.pk
RI Iqbal, Nadeem/GWB-9856-2022
OI Hanif, Dr. Muhammad/0000-0003-2669-2327; Iqbal,
   Nadeem/0000-0002-0954-5563; , Muhammad Hanif/0000-0002-6520-4464
CR Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Da HU, 2018, J SW JIAOTONG U, V53
   Diaconu AV, 2015, P ROMANIAN ACAD A, V16, P313
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Floating-Point Working Group, 1985, 7541985 FLOAT POINT
   Guo HF, 2020, IEEE ACCESS, V8, P55540, DOI 10.1109/ACCESS.2020.2981771
   Hanif M, 2020, IEEE ACCESS, V8, P123536, DOI 10.1109/ACCESS.2020.3004536
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Iqbal N, 2019, IEEE ACCESS, V7, P174051, DOI 10.1109/ACCESS.2019.2956389
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Joe H, 2005, J MULTIVARIATE ANAL, V94, P401, DOI 10.1016/j.jmva.2004.06.003
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   Rehman A, 2022, MULTIMEDIA SYST, V28, P1339, DOI 10.1007/s00530-020-00736-8
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sivakumar T, 2016, J INF SCI ENG, V32, P133
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Hoang TM, 2018, OPTIK, V155, P366, DOI 10.1016/j.ijleo.2017.10.072
   Wang B, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165737
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2010, PROC SPIE, V7708, DOI 10.1117/12.853197
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou Y, 2021, NONLINEAR DYNAM, V103, P2043, DOI 10.1007/s11071-021-06206-8
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 51
TC 8
Z9 8
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36305
EP 36339
DI 10.1007/s11042-021-11386-x
EA SEP 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692489400004
DA 2024-07-18
ER

PT J
AU Varshney, N
   Bakariya, B
AF Varshney, Neeraj
   Bakariya, Brijesh
TI Deep convolutional neural model for human activities recognition in a
   sequence of video by combining multiple CNN streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Features extraction; Deep convolution neural
   network; Spatial and temporal; Convolution fusion; Average fusion
AB The video file is a collection of image sequential; this image sequence holds both spatial and temporal information. Optical flow and motion history images are two well-known methods for the identification of human activities. Optical flow describes the speed of every individual pixel point in the picture. Still, this information about the motion cannot represent the complete action and different movement speeds. The durations of Local body parts show almost similar intensity in the Motion history image. Therefore, similar actions are not identifying with good precision. In this paper, a deep convolutional neural model for human activities recognition video has been proposed in which multiple CNN streams are combined. The model combines spatial and temporal information. Two fusion schemes, i.e. Average fusion and convolution fusion of spatial and temporal stream, are discussed in this paper. The proposed method performs better than other approaches based on human activity recognition methods on a benchmark dataset, namely UCF101 and HMDB51.Average fusion score 95.4% test accuracy and convolution fusion score 97.2% test accuracy on UCF101 and for HMDB51, average fusion score 84.3% and convolution fusion score 85.1% respectively.
C1 [Varshney, Neeraj] IK Gujral Punjab Tech Univ, Kapurthala, India.
   [Bakariya, Brijesh] IK Gujral Punjab Tech Univ, Hoshiarpur Campus, Hoshiarpur, India.
C3 I. K. Gujral Punjab Technical University; I. K. Gujral Punjab Technical
   University
RP Varshney, N (corresponding author), IK Gujral Punjab Tech Univ, Kapurthala, India.
EM neeraj.varshney@gla.ac.in; dr.brijeshbakariya@ptu.ac.in
RI VARSHNEY, NEERAJ/AAD-9051-2019; bakariya, brijesh/ABB-5497-2021
CR BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Chandni, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P333, DOI 10.1007/978-981-13-2685-1_32
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girdhar R., 2017, PROC CVPR IEEE, P971, DOI DOI 10.1109/CVPR.2017.337
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kushwaha AKR., 2019, P IC3E 2018, DOI [10.1007/978-981-13-2685-1_32, DOI 10.1007/978-981-13-2685-1_32]
   Kushwaha AKS, 2017, MULTIMEDIA SYST, V23, P451, DOI 10.1007/s00530-016-0505-x
   Roy D, 2016, PATTERN RECOGN, V59, P55, DOI 10.1016/j.patcog.2016.03.011
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Tsai DM, 2015, SIGNAL IMAGE VIDEO P, V9, P1897, DOI 10.1007/s11760-014-0677-9
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2018, PROC CVPR IEEE, P1149, DOI 10.1109/CVPR.2018.00126
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Zhu Y, 2018, AS C COMP VIS, P363, DOI DOI 10.1007/978-3-030-20893-6
NR 26
TC 6
Z9 7
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42117
EP 42129
DI 10.1007/s11042-021-11220-4
EA AUG 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000690516400001
DA 2024-07-18
ER

PT J
AU Zhu, QY
   He, ZK
   Ye, X
AF Zhu, Qiuyu
   He, Zikuang
   Ye, Xin
TI Incremental classifier learning based on PEDCC-loss and cosine distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incremental learning; PEDCC-loss; Convolutional neural network; Ensemble
   learning
AB Traditionally, the performance of deep convolutional neural networks relies on a large number of labeled datasets in advance. However, in real-world applications, training data are not collected at once, so an algorithm which can deal with continuous incoming data is needed. This learning method is called incremental learning, whose main problem is the catastrophic forgetting. Neural network will perform badly on the old classes after training for the new classes. To solve this problem, this paper proposes an integrated incremental network approach based on the PEDCC-loss, and the cosine distance between the sample's output feature and the PEDCC (predefined evenly distributed class centroids). Old and new knowledge learned by neural networks are stored separately. During the training of each network, PEDCC-Loss is used to constrain the cosine distance between the output feature and their corresponding pre-defined class center. Meanwhile, the old knowledge is retained by different learning rates across the network, and the retention mode of the old samples is discussed. In test phase, the final prediction is determined by the cosine distances between PEDCC and output features across all networks. Our experiments on EMNIST, CIFAR100 and TinyImageNet datasets show that our approach can learn classes incrementally without quickly failing of performance. Compared with some existing algorithms, such as Hou, iCaRL and finetune, our approach has better performance.
C1 [Zhu, Qiuyu; He, Zikuang; Ye, Xin] Shanghai Univ, Sch Commun & Informat Engn, 99 ShangDa Rd, Shanghai, Peoples R China.
C3 Shanghai University
RP Zhu, QY (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 99 ShangDa Rd, Shanghai, Peoples R China.
EM zhuqiuyu@staff.shu.edu.cn; hezikuang@shu.edu.cn; yexin@shu.edu.cn
RI ZHU, Qiuyu/GRX-5167-2022
OI ZHU, Qiuyu/0000-0001-9514-9323
CR Castro FM, 2018, LECT NOTES COMPUT SC, V11216, P241, DOI 10.1007/978-3-030-01258-8_15
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhar P, 2019, PROC CVPR IEEE, P5133, DOI 10.1109/CVPR.2019.00528
   Girshick R, 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.119
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou SH, 2019, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2019.00092
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37
   Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Rebuffi Sylvestre-Alvise, 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.587
   Rusu A.A., 2016, ARXIV
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shalev, 2018, ADV NEUR IN, P7375
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Valentini G, 2002, LECT NOTES COMPUT SC, V2486, P3
   Venkatesan Ragav, 2017, ARXIV170500744
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wu Y., 2018, ARXIV180200853
   Xiao TJ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P177, DOI 10.1145/2647868.2654926
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu QY, 2020, IEEE ACCESS, V8, P10888, DOI 10.1109/ACCESS.2019.2960065
NR 27
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33827
EP 33841
DI 10.1007/s11042-021-11163-w
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690516400005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yu, SS
   Lin, ZS
   Liang, J
   Shu, GX
   Yu, JL
   Zhu, A
AF Yu, SongSen
   Lin, ZeSheng
   Liang, Jun
   Shu, GangXu
   Yu, JiaLin
   Zhu, Ao
TI Sketch works ranking based on improved transfer learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch classification; Transfer learning; Data augmentation; Dropout;
   Feature fusion
AB Classification and evaluation of sketch works is an important step in sketch teaching. The speed for manual evaluation of massive works is very slow and its cost is also high. Regarding the sketch works after scoring is hard to be collected, the limitations from small dataset create many challenges for training a great scoring model. In this paper, we firstly collects 400 teaching sketches of college students from South China Normal University and constructs a dataset. Then an improved transfer learning model based on ResNet50 was proposed for learning the high-level abstract characteristics of sketch works because transfer learning can reuse knowledge from a large dataset and employ the feature extraction capability in sketch subject scenario. In our improved model, three strategies (i.e., data augmentation, dropout and feature fusion) are used to prevent the model from early overfitting and improve the accuracy and stability of the model. Comparing with traditional feature extraction algorithms, our model provides an end-to-end mechanism. Moreover, compared with the accuracy of AlexNet and ResNet50, it is improved by 24.2% and 7.82% respectively. Our results indicate that the three strategies have outstanding effects for the transfer learning model for sketch works ranking.
C1 [Yu, SongSen; Lin, ZeSheng; Liang, Jun; Shu, GangXu; Yu, JiaLin; Zhu, Ao] South China Normal Univ, Sch Software, Foshan, Guangdong, Peoples R China.
C3 South China Normal University
RP Liang, J (corresponding author), South China Normal Univ, Sch Software, Foshan, Guangdong, Peoples R China.
EM liangjun@m.scnu.edu.cn
RI Zhu, Ao/GQI-0959-2022; Liang, Jun/GQO-8542-2022
OI Liang, Jun/0000-0003-0034-2601
FU Guangdong Basic and Applied Basic Research Fund Regional Joint Fund
   Project (Key Project) [2020B1515120089]; Featured Innovation Project of
   Guangdong Province Department of Education (Natural Science)
   [2019KTSCX035]
FX This work was partially supported by Guangdong Basic and Applied Basic
   Research Fund Regional Joint Fund Project (Key Project)
   (2020B1515120089) and the Featured Innovation Project of Guangdong
   Province Department of Education (Natural Science)(2019KTSCX035).
CR Changchun, 2015, ART WORKS RETRIEVAL
   Fan GF, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102320
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hao X, 2016, INT J SEMANT COMPUT, V10, P417, DOI 10.1142/S1793351X16500045
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2017, IEEE T PATTERN ANAL, VPP, P1
   Huang Hua, 2009, CHINESE J COMPUT, V1, P32
   Hughes JM, 2010, P NATL ACAD SCI USA, V107, P1279, DOI 10.1073/pnas.0910530107
   Iwendi C, 2020, COMPUT COMMUN, V161, P160, DOI 10.1016/j.comcom.2020.07.032
   Jia-chuan S, 2013, THESIS TIANJIN U TIA
   Jingte T, 2018, THESIS JIANGXI NORMA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Chao, 2017, Journal of Computer Aided Design & Computer Graphics, V29, P1898
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   [李玉芝 Li Yuzhi], 2018, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V30, P893
   Lu Cewu., 2012, Proc. NPAR, P65
   Mei-Jun, 2017, J NANJING NORMAL U N, V40, P79
   Peng L, 2009, NEURAL NETWORK BASED
   Ran Yi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8214, DOI 10.1109/CVPR42600.2020.00824
   Sang Sang, 2010, Journal of Shanghai University, V16, P312, DOI 10.3969/j.issn.1007-2861.2010.03.019
   Shan-xiao G, 2016, THESIS FUJIAN NORMAL
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   [孙硕 SUN Shuo], 2007, [计算机工程与应用, Computer Engineering and Application], V43, P34
   Sun Zhi-jun, 2012, Application Research of Computers, V29, P2806, DOI 10.3969/j.issn.1001-3695.2012.08.002
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yi R, 2019, PROC CVPR IEEE, P10735, DOI 10.1109/CVPR.2019.01100
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Yu-sheng W, THESIS XIAN U ARCHIT
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1541
   Zhang P, 2021, COMPUTING, V103, P473, DOI 10.1007/s00607-020-00860-3
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 36
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33663
EP 33678
DI 10.1007/s11042-021-11305-0
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687495000001
DA 2024-07-18
ER

PT J
AU Chalabi, NE
   Attia, A
   Bouziane, A
   Akhtar, Z
AF Chalabi, Nour Elhouda
   Attia, Abdelouahab
   Bouziane, Abderraouf
   Akhtar, Zahid
TI Particle swarm optimization based block feature selection in face
   recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Optimization; Particle Swarm Optimization (PSO);
   Feature Selection
ID EIGENFACES
AB Face is one of the most widely used and accepted biometric traits. Face recognition systems are now being utilized in many applications ranging from individual (e.g., smartphone user authentication) to large scale (e.g., border crossing screening) scenarios. Most face recognition systems employ feature selection after feature extraction to enhance the accuracy of the frameworks. In other words, feature selection is one of the important phases that any recognition system must go through as the final results depend on it. Thus, in this paper, we present an optimized feature selection method based on Particle Swarm Optimization (PSO) to select a block of feature instead of single feature to ensure the distinctiveness and variations of features with application to face recognition system. In particular, first the captured face image is divided into a regular number of blocks (sub-images), then Binarized Statistical local features (BSIF) local descriptor is applied on each block for feature extraction. Next, a PSO scheme is utilized to select the blocks/features. The nearest neighbour classifier is employed to get the value of the fitness function (here, equal error rate (EER)) for block/feature selection. The blocks with the smallest EERs are chosen to represent the face image representation and recognition. Experimental results on public ORL faces database show promising results. The proposed face recognition system obtained EER equals to 1.028% with only 4 blocks out of 16, and recognition rate up to 93.5%. While the system was able to obtain an EER equals to 0.5% and recognition rate = 97% using 8 blocks out of 64 blocks.
C1 [Chalabi, Nour Elhouda; Attia, Abdelouahab; Bouziane, Abderraouf] El Ibrahimi Univ Bordj Bou Arreridj, Comp Sci Dept Mohamed El Bachir, El Anceur 34000, Algeria.
   [Chalabi, Nour Elhouda; Attia, Abdelouahab; Bouziane, Abderraouf] El Ibrahimi Univ Bordj Bou Arreridj, MSE Lab Mohamed El Bachir, El Anceur 34000, Algeria.
   [Akhtar, Zahid] SUNY Polytech Inst, Dept Network & Comp Secur, Utica, NY 13502 USA.
C3 SUNY Polytechnic Institute
RP Chalabi, NE (corresponding author), El Ibrahimi Univ Bordj Bou Arreridj, Comp Sci Dept Mohamed El Bachir, El Anceur 34000, Algeria.; Chalabi, NE (corresponding author), El Ibrahimi Univ Bordj Bou Arreridj, MSE Lab Mohamed El Bachir, El Anceur 34000, Algeria.
EM chalabi.houda94@gmail.com
RI ATTIA, Abdelouahab/HJA-2990-2022; ATTIA, Abdelouahab/ADD-8906-2022
OI Akhtar, Zahid/0000-0002-5026-5416; ATTIA,
   Abdelouahab/0000-0003-1558-7273; Chalabi, Nour
   Elhouda/0000-0001-5231-1597
CR Agarwal V, 2015, INT CONF CONTEMP, P257, DOI 10.1109/IC3.2015.7346689
   Akhtar Z, 2018, IEEE MULTIMEDIA, V25, P22, DOI 10.1109/MMUL.2018.2873494
   Akhtar Z, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.119
   Al-Arashi WH, 2014, NEUROCOMPUTING, V128, P415, DOI 10.1016/j.neucom.2013.08.022
   [Anonymous], 2011, ANT COLONY OPTIMIZAT
   [Anonymous], 2009, Encyclopedia of Biometrics
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cambridge AL, 2009, ORL FAC DAT
   Chomboon K., 2015, P 3 INT C IND APPL E, P280, DOI DOI 10.12792/ICIAE2015.051
   Darestani MRY, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P181, DOI 10.1109/IKT.2013.6620061
   Dora L, 2017, ENG APPL ARTIF INTEL, V62, P286, DOI 10.1016/j.engappai.2017.04.011
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Guojian Cheng, 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P1229, DOI 10.1109/CIS.2011.272
   Jin W, 2011, EXPERT SYST APPL, V38, P4390, DOI 10.1016/j.eswa.2010.09.108
   Kanan HR, 2008, APPL MATH COMPUT, V205, P716, DOI 10.1016/j.amc.2008.05.115
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Khadhraoui T, 2016, I C COMP GRAPH IM VI, P99, DOI 10.1109/CGiV.2016.28
   Krisshna NLA, 2014, APPL SOFT COMPUT, V22, P141, DOI 10.1016/j.asoc.2014.05.007
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Malhotra P, 2019, J INTELL SYST, V28, P321, DOI 10.1515/jisys-2017-0127
   Nefian AV, 2000, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2000.900885
   Preeti, 2017, International Journal of Information Technology, V9, P411, DOI 10.1007/s41870-017-0051-6
   Ramadan R.M., 2009, INT J SIGNAL PROCESS, V2, P51
   Rath SK, 2014, INT J MOD ED COMPUT, V6
   Saad WK., 2019, J ENG APPL SCI, V14, P2982, DOI [10.36478/jeasci.2019.2982.2987, DOI 10.36478/JEASCI.2019.2982.2987]
   Sukhija P, 2016, PROCEDIA COMPUT SCI, V85, P410, DOI 10.1016/j.procs.2016.05.183
   Sundararajan K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190618
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang X-S, 2010, Nature-Inspired Metaheuristic Algorithms, V2
   Yang XS, 2020, J COMPUT SCI-NETH, V46, DOI 10.1016/j.jocs.2020.101104
   Zafaruddin GM., 2019, FACE RECOGNITION USI, P855
   Zhalehpour S, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P116, DOI 10.1109/INISTA.2014.6873606
   Zhi H, 2019, J VIS COMMUN IMAGE R, V58, P495, DOI 10.1016/j.jvcir.2018.12.012
NR 37
TC 12
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33257
EP 33273
DI 10.1007/s11042-021-11367-0
EA AUG 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000685156200001
DA 2024-07-18
ER

PT J
AU Sebai, D
   Manai, E
AF Sebai, D.
   Manai, E.
TI MPEG-DASH parametrisation for adaptive online streaming of different
   MOOC videos categories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-DASH; MOOCs videos; Adaptive online streaming; Quality of
   Experience; Compression
AB The Dynamic Adaptive Streaming over HTTP (MPEG-DASH) ensures online videos display of good quality and without interruption. It provides an adequate streaming for each display device and network transmission. This can be verfield of Massive Open Online Courses (MOOCs). In fact, MPEG-DASH tracks the bandwidth fluctuations so hat the learner profits from continuous streaming, without worrying about frequent interruption of courses videos. Therefore, the learners profit from an exceptional visual experience that improves their commitment level and eases the course assimilation. These MPEG-DASH assets can become more and more advantageous if a good choice of its parameters is made. Being a recent branch, the MPEG-DASH adaptive diffusion presents a research field where the efforts are still limited, even more for MOOCs videos. Most of the work published in this sense focus on the Quality of Service (QoS) and the technical specifications of the network transmission. In this paper, we aim to consider the quality of the streamed content that directly impacts the learners Quality of Experience (QoE). For this, we develop a content-aware dataset that includes several MOOCs videos of different characteristics and types. These videos are firstly encoded using the latest codecs then dashified according to a coding scheme of several combinations of bitrates and display resolutions. Then, and in order to enhance the learners QoE, the so generated MPEG-DASH manifest files and segments are subsequently exploited to study the most appropriate codecs, bitrates and segment durations for each type of MOOCs videos.
C1 [Sebai, D.; Manai, E.] Univ Manouba, Natl Sch Comp Sci, Cristal Lab, Manouba, Tunisia.
C3 Universite de la Manouba
RP Sebai, D (corresponding author), Univ Manouba, Natl Sch Comp Sci, Cristal Lab, Manouba, Tunisia.
EM dorsaf.sebai@ensi-uma.tn
OI Sebai, Dorsaf/0000-0001-7720-2741
CR [Anonymous], 2019, ADOBE HTTP DYNAMIC S
   [Anonymous], 2018, FFmpeg: A complete, cross-platform solution to record, convert andstream audio and video
   [Anonymous], 2014, POJET 4EVER GPAC
   [Anonymous], 2019, DASH JS
   [Anonymous], 2017, AVERAGE GLOBAL INTER
   [Anonymous], 2019, 4 IND REVOLUTION
   [Anonymous], 2018, SCREEN RESOLUTION ST
   Brandenburg K, 1999, AUDIO ENG SOC C 17 I
   Brandenburg K, 2008, SUBJECTIVE METHOD VI
   Feuvre J L., 2014, ACM Multimedia Systems Conference, P7
   García L, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1117, DOI 10.1109/ICACCI.2016.7732194
   Kazakovsky A, 2016, TMETER FREEWARE EDIT
   Lou, 2016, IEEE INT S MULT ISM
   Mueller C, 2015, APPLE LIVE STREAMING
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Noel O, 2012, STREAMING VIDEO ADAP
   Rovcanin, 2016, THESIS
   Shah D., 2018, By The Numbers: MOOCS in 2018
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Timmerer C, 2016, MPEG CMAF THREAT OPP
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zambelli A., 2009, IIS Smooth Streaming Technical Overview
NR 23
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33193
EP 33212
DI 10.1007/s11042-021-11352-7
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000684916500004
DA 2024-07-18
ER

PT J
AU Ramella, G
AF Ramella, Giuliana
TI Evaluation of quality measures for color quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality; Image Quality Assessment; Full reference; Quality
   measure; Color Quantization; Image Quality Assessment Database
ID STRUCTURAL SIMILARITY; BLUR ASSESSMENT; IMAGE; CONTRAST; CLASSIFICATION;
   PSNR
AB The visual quality evaluation is one of the fundamental challenging problems in image processing. It plays a central role in the shaping, implementation, optimization, and testing of many methods. The existing image quality assessment methods centered mainly on images altered by common distortions while paying little attention to the distortion introduced by color quantization. This happens despite there is a wide range of applications requiring color quantization as a preprocessing step since many color-based tasks are more efficiently accomplished on an image with a reduced number of colors. To fill this gap, at least partially, we carry out a quantitative performance evaluation of nine currently widely-used full-reference image quality assessment measures. The evaluation runs on two publicly available and subjectively rated image quality databases for color quantization degradation by considering their appropriate combinations and subparts. The evaluation results indicate what are the quality measures that have closer performances in terms of their correlation to the subjective human rating and prove that the selected image database significantly impacts the evaluation of the quality measures, although a similar trend on each database is maintained. The detected strong trend similarity, both on individual databases and databases obtained by a proper combination, provides the ability to validate the database combination process and consider the quantitative performance evaluation on each database as an indicator for performance on the other databases. The experimental results are useful to address the choice of appropriate quality measures for color quantization and to improve their future employment.
C1 [Ramella, Giuliana] Natl Res Council CNR, Inst Applicat Calculus, Via P Castellino 111, I-80131 Naples, Italy.
RP Ramella, G (corresponding author), Natl Res Council CNR, Inst Applicat Calculus, Via P Castellino 111, I-80131 Naples, Italy.
EM giuliana.ramella@cnr.it
RI Ramella, Giuliana/AAN-7025-2021
OI RAMELLA, Giuliana/0000-0001-6044-5237
FU GNCS (Gruppo Nazionale di Calcolo Scientifico) of the INDAM (Istituto
   Nazionale di Alta Matematica)
FX This work has been supported by the GNCS (Gruppo Nazionale di Calcolo
   Scientifico) of the INDAM (Istituto Nazionale di Alta Matematica).
CR [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 2008, Color Gamut Mapping
   Bhattacharyya S., 2020, RECENT ADV HYBRID ME
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bruni Vittoria, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P323
   Bruni V, 2017, LECT NOTES COMPUT SC, V10484, P671, DOI 10.1007/978-3-319-68560-1_60
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   De K, 2016, IEEE STUDENT TECHNOL, P40, DOI 10.1109/TechSym.2016.7872652
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Dohyoung Lee, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P166, DOI 10.1109/ICASSP.2014.6853579
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Frackiewicz M, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268531
   Gao F, 2016, SIGNAL PROCESS, V124, P210, DOI 10.1016/j.sigpro.2015.08.012
   Gaubatz M., 2014, MeTriX MuX visual quality assessment package
   Gervautz M., 1990, GLASSNER GRAPHICS GE, P287, DOI [10.1016/B978-0-08-050753-8.50061-9, DOI 10.1016/B978-0-08-050753-8.50061-9]
   Gibbons JD., 2020, NONPARAMETRIC STAT I, DOI DOI 10.1201/9781439896129
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gomes J., 2009, IMAGE PROCESSING COM, P293
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Hassan M., 2015, EVALUATION-US, V9
   Hassan Mohammed Ahmed, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P691, DOI 10.1109/ICITECH.2017.8079929
   Heckbert P., 1982, Computer Graphics, V16, P297, DOI 10.1145/965145.801294
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   ISO/IEC 2010, 2010, WG1N5598 ISOIEC
   Kamble V, 2015, OPTIK, V126, P1090, DOI 10.1016/j.ijleo.2015.02.093
   KARUNASEKERA SA, 1995, IEEE T IMAGE PROCESS, V4, P713, DOI 10.1109/83.388074
   Lahoulou A, 2013, ARAB J SCI ENG, V38, P2327, DOI 10.1007/s13369-012-0509-6
   Larabi M.-C., 2004, Traitement du Signal, V21, P385
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Lee D, 2015, IEEE T IMAGE PROCESS, V24, P3950, DOI 10.1109/TIP.2015.2456419
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lissner I, 2013, IEEE T IMAGE PROCESS, V22, P435, DOI 10.1109/TIP.2012.2216279
   Liu M, 2017, IEEE T BROADCAST, V63, P71, DOI 10.1109/TBC.2016.2597545
   Liu YT, 2017, J VIS COMMUN IMAGE R, V46, P70, DOI 10.1016/j.jvcir.2017.03.007
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   Ly DS, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.061207
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Mojsilovic A, 2002, IEEE T IMAGE PROCESS, V11, P1238, DOI 10.1109/TIP.2002.804260
   Ortiz-Jaramillo B, 2019, SIGNAL PROCESS-IMAGE, V71, P128, DOI 10.1016/j.image.2018.11.009
   Pedersen M, 2011, FOUND TRENDS COMPUT, V7, P1, DOI 10.1561/0600000037
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Prins N., 2010, PRACTICAL INTRO
   Rajashekar U, 2009, IEEE IMAGE PROC, P2213, DOI 10.1109/ICIP.2009.5413889
   Ramella Giuliana, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P78
   Ramella G, 2020, VISAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4: VISAPP, P452, DOI 10.5220/0009144904520459
   Ramella G, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P1, DOI 10.1109/SITIS.2016.10
   Ramella G, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P798, DOI 10.1109/SITIS.2016.131
   Ramella G, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413600069
   Ramella G, 2011, LECT NOTES COMPUT SC, V6854, P76, DOI 10.1007/978-3-642-23672-3_10
   Ramella G, 2010, LECT NOTES COMPUT SC, V6419, P22
   RECOMMENDATION ITU-R BT, 2002, METH SUBJ ASS QUAL T
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Sazzad Z. P., 2008, MICT IMAGE QUALITY E
   Sertel O, 2008, INT CONF ACOUST SPEE, P597, DOI 10.1109/ICASSP.2008.4517680
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Shokrollahi A, 2017, AEU-INT J ELECTRON C, V77, P61, DOI 10.1016/j.aeue.2017.04.026
   Silverstein DA, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P881, DOI 10.1109/ICIP.1996.559640
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Temel D, 2016, SIGNAL PROCESS-IMAGE, V48, P92, DOI 10.1016/j.image.2016.08.008
   Thomas S, 2020, J NONPROFIT PUBLIC S, V32, P488, DOI 10.1080/10495142.2019.1606757
   Toet A, 2003, DISPLAYS, V24, P197, DOI 10.1016/j.displa.2004.01.006
   Venetsanopoulos N, 2000, COMMUN ACM, V34, P30
   Verikas, 2017, P SOC PHOTO-OPT INS, V1034
   VQEG 1, 2008, 1 VQEG
   VQEG 2, 2003, 2 VQEG
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2008, J VISION, V8, DOI 10.1167/8.12.8
   Weeks AR, 1996, SPIE IEEE SERIES IMA, DOI [10.1109/9780470544709, DOI 10.1109/9780470544709]
   Wen Y, 2017, J VIS COMMUN IMAGE R, V43, P119, DOI 10.1016/j.jvcir.2016.12.005
   Wilkes DM., 2020, MACHINE LEARNING BAS, P195
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Wu X., 1991, Graphics Gems, V11, P126, DOI DOI 10.1016/B978-0-08-050754-5.50035-9
   Yan B, 2019, IEEE T MULTIMEDIA, V21, P2603, DOI 10.1109/TMM.2019.2904879
   Yang YJ, 2012, ABSTR APPL ANAL, DOI 10.1155/2012/697565
   Zaric A, 2012, AUTOMATIKA, V53, P344, DOI 10.7305/automatika.53-4.241
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 98
TC 12
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32975
EP 33009
DI 10.1007/s11042-021-11385-y
EA AUG 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000683686700001
DA 2024-07-18
ER

PT J
AU Singh, B
   Verma, HK
AF Singh, Balraj
   Verma, Harsh K.
TI EMM: Extended matching market based scheduling for big data platform
   hadoop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matching market; Trade-off; Scheduling; Performance; Hadoop
ID MAPREDUCE; EFFICIENT; ALGORITHM
AB Hadoop has emerged as a popular choice for processing Big data. Its cluster is used to process large scale jobs. The performance of a cluster is largely dependent upon the different kind of scheduling policies employed for job processing. However, a single type of scheduling policy may not be suitable for different kind of jobs. Inefficient performance of a cluster is an apparent outcome of inappropriate scheduling policies. These policies are either too complex or they are too elementary to understand the diverse jobs and their needs. Most of them follow a fixed pattern, which cannot be considered as a common solution for different jobs. The effect of such a non-fitting mechanism is lower resource utilization and poor cluster performance. In this paper, a pluggable scheduling mechanism is proposed for efficient and adaptive processing of the jobs. It utilizes the Matching Market concept for the allocation and further adaptively accommodates the diverse needs of the multiple jobs by understanding the varying requirements of the tasks. The experimental results reveal an enhanced resource utilization and improved cluster performance with an overall reduction in makespan. In certain instances, we have seen resource utilization improved up to 80% and performance improvement up to 60% with the proposed technique. Cluster efficiency is increased up of 31%. The evaluation and comparisons were conducted on various scheduling policies using different benchmarks of Hadoop with the same data and identical configurations. The proposed system has shown significant improvement in cluster efficiency.
C1 [Singh, Balraj] NIT, Dept Comp Sci, Jalandhar, Punjab, India.
   [Singh, Balraj; Verma, Harsh K.] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Lovely Professional University
RP Singh, B (corresponding author), NIT, Dept Comp Sci, Jalandhar, Punjab, India.; Singh, B (corresponding author), Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, India.
EM singh.balraj@hotmail.com; vermah@nitj.ac.in
RI Verma, Harsh Kumar/Y-4606-2019
OI Verma, Harsh Kumar/0000-0003-4826-6150
CR Akbarpour M., 2014, Dynamic matching market design
   Apache, HAD YARN
   Apache H, FAIR SCHEDULER
   Apache H, FIFO SCHEDULER
   Apache H, CAPACITY SCHEDULER
   Baranowski Z, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921404058
   Bloch F, 2012, ECON THEOR, V51, P13, DOI 10.1007/s00199-011-0616-8
   Bu X., 2013, P 22 INT S HIGH PERF, P227, DOI DOI 10.1145/2493123.2462904
   Callan J., 2009, Clueweb09 Data Set
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen JL, 2013, J COMPUT, V8, P929, DOI 10.4304/jcp.8.4.929-936
   Cheng DZ, 2017, IEEE T PARALL DISTR, V28, P774, DOI 10.1109/TPDS.2016.2594765
   Chugh A, 2020, ALGO INTELL SY, P337, DOI 10.1007/978-981-15-0222-4_30
   Curino Carlo., 2014, P ACM S CLOUD COMPUT, P1
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Easley D., 2010, Networks, Crowds, and Markets: Reasoning about a highly connected world, V8
   Ghodsi An, 2011, Computer Communication Review, V41, P507, DOI 10.1145/2018584.2018586
   Glushkova D, 2019, INFORM SYST, V79, P32, DOI 10.1016/j.is.2017.11.006
   Grandl R, 2014, ACM SIGCOMM COMP COM, V44, P455, DOI 10.1145/2740070.2626334
   Gummaraju J, 2019, U.S. Patent, Patent No. [10,193,963, 10193963]
   Gupta Shekhar., 2013, Proceedings of the 10th International Conference on Autonomic Computing (ICAC 13), P159
   Hall B.H., 2001, The NBER patent citation data file: lessons, insights and methodological tools
   He B, 2016, IEEE T SERV COMPUT
   Hindman B., 2011, NSDI, V11, P295, DOI DOI 10.1016/0375-6505(85)90011-2
   Hsu JB, 2021, CLUSTER COMPUT, V24, P1583, DOI 10.1007/s10586-020-03206-y
   Isard M, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P261
   Islam MT, 2020, J SYST SOFTWARE, V162, DOI 10.1016/j.jss.2019.110515
   Kc K., 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P388, DOI 10.1109/CloudCom.2010.97
   Khelifa Amel, 2020, Procedia Computer Science, V176, P3143, DOI 10.1016/j.procs.2020.09.174
   Lama Palden, 2012, P 9 INT C AUT COMP, DOI DOI 10.1145/2371536.2371547
   Lu HC, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106497
   Naik NS, 2019, FUTURE GENER COMP SY, V90, P423, DOI 10.1016/j.future.2018.07.043
   Niu ZJ, 2015, INT CONF CLOUD COMP, P66, DOI 10.1109/CloudCom.2015.52
   Parvin H, 2020, J SUPERCOMPUT, P1
   Polo J, 2011, LECT NOTES COMPUT SC, V7049, P187
   Rasooli A, 2012, 2012 SC COMPANION: HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SCC), P1284, DOI 10.1109/SC.Companion.2012.155
   Sandholm T, 2012, 26 AAAI C ART INT
   Sharma V., 2020, EGYPT INFORM J
   Singaravel, 2020, WIRELESS PERS COMMUN, P1
   Stoica I, 2013, CHOOSY MAX MIN FAIR
   Tang Z, 2012, IEEE SYM PARA DISTR, P2012, DOI 10.1109/IPDPSW.2012.250
   Thaman J., 2016, INT J FOUND COMPUT S, V6, P65
   Usama M, 2017, DIGIT COMMUN NETW, V3, P260, DOI 10.1016/j.dcan.2017.07.008
   Verma A., 2012, 2012 IEEE 20th International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS), P11, DOI 10.1109/MASCOTS.2012.12
   Wang JY, 2014, IEEE INT CONF CLOUD, P761, DOI 10.1109/CLOUD.2014.106
   Wang LZ, 2013, FUTURE GENER COMP SY, V29, P739, DOI 10.1016/j.future.2012.09.001
   Wang W, 2014, PROCEEDINGS OF THE 2014 CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'14), P235, DOI 10.1145/2674005.2675010
   Wiktorski T., 2019, DATA INTENIVE SYSTEM, P51, DOI DOI 10.1007/978-3-030-04603-3_6
   Wohlk S, 2017, COMPUT OPER RES, V87, P107, DOI 10.1016/j.cor.2017.06.006
   Yahoo, DAT
   Yao Y, 2014, IEEE INT CONF CLOUD, P184, DOI 10.1109/CLOUD.2014.34
   Yao Y, 2013, 2013 IEEE PES INNOVATIVE SMART GRID TECHNOLOGIES (ISGT)
   Zacheilas N, 2017, EURASIP J EMBED SYST, DOI 10.1186/s13639-017-0077-7
   Zaharia M, 2010, EUROSYS'10: PROCEEDINGS OF THE EUROSYS 2010 CONFERENCE, P265
NR 54
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34823
EP 34847
DI 10.1007/s11042-021-11283-3
EA AUG 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000683638400001
DA 2024-07-18
ER

PT J
AU Zhang, J
   Yin, BQ
   Deng, XY
AF Zhang, Jie
   Yin, Baoquan
   Deng, Xiangyu
TI A novel color image encryption method based on an evolved dynamic
   parameter-control chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image encryption; Dynamic parameter-control; Bit-level plane
ID COUPLED MAP; BIT-LEVEL; SCHEME
AB The majority of existing image encryption algorithms use single chaotic systems, such as Logistic map or Lorentz system, to be the pseudo-random sequence generator. Actually, neither low nor high dimensional chaotic system can get rid of pseudo-randomness deterioration of chaotic sequence calculated by limited precision computer. Additionally, most of them use only one chaotic pseudo-random sequence throughout the encryption process. These are the more obvious deficiencies. In the current paper, a novel compound chaotic system is applied to color images domain to solve the mentioned problems. Dynamic parameter-control chaotic system can enhance the sequence's randomness after digitalizing. Corresponding the different sequences generated by the novel chaotic system to each color channel of image is a helpful method to reduce the image's statistical characteristics in the scrambling process. Finally, the effectiveness and security of the proposed encryption has been illustrated by the experimental, and at the meantime, excellent performance is also demonstrated.
C1 [Zhang, Jie; Yin, Baoquan; Deng, Xiangyu] Northwest Normal Univ, Lanzhou 730070, Gansu, Peoples R China.
C3 Northwest Normal University - China
RP Zhang, J (corresponding author), Northwest Normal Univ, Lanzhou 730070, Gansu, Peoples R China.
EM zhangjie@nwnu.edu.cn; moyingxiang@foxmail.com; dengxy000@126.com
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Anishchenko V. S., 1992, International Journal of Bifurcation and Chaos in Applied Sciences and Engineering, V2, P633, DOI 10.1142/S0218127492000756
   [Anonymous], 2019, WEAPONRY, P1
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Fan SW, 2020, IEEE ACCESS, V8, P183411, DOI 10.1109/ACCESS.2020.3029263
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, IEEE T CYBERNETICS, V46, P3330, DOI 10.1109/TCYB.2015.2504180
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Li M, 2018, IEEE MULTIMEDIA, V25, P92, DOI 10.1109/MMUL.2018.112142439
   Li SJ, 2003, COMPUT PHYS COMMUN, V153, P52, DOI 10.1016/S0010-4655(02)00875-5
   Liu Y, 2020, APPL MULTIDIMENSIONA, V79, P29
   Lv XP, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501245
   Ni Z, 2016, IEEE INT C SIGN IM P
   Özoguz S, 2006, IEE P-CIRC DEV SYST, V153, P506, DOI 10.1049/ip-cds:20050100
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Perko L., 2001, Differential Equations and Dynamical Systems, DOI DOI 10.1007/978-1-4613-0003-8
   Pickover CA, 2010, GRAPHICS BIFURCATION, V6, P26
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Rajagopalan S, 2018, APPL NETWORKED HARDW, V77, P1
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tariq S, 2020, APPL NOVEL HYBRID EN
   Thompson JMT, 2000, NONLINEAR DYNAMICS C, V78, P1635
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/1/010501
   Ye GD, 2018, NONLINEAR DYNAM, V94, P3155, DOI 10.1007/s11071-018-4614-2
   Ye GD, 2016, J VIB CONTROL, V22, P1171, DOI 10.1177/1077546314534717
   Yue Zhou, 2014, SOC S DISCRETE WHEEL
NR 34
TC 6
Z9 6
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27155
EP 27170
DI 10.1007/s11042-021-10960-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000678822000011
DA 2024-07-18
ER

PT J
AU Juneja, M
   Saini, SK
   Gupta, J
   Garg, P
   Thakur, N
   Sharma, A
   Mehta, M
   Jindal, P
AF Juneja, Mamta
   Saini, Sumindar Kaur
   Gupta, Jatin
   Garg, Poojita
   Thakur, Niharika
   Sharma, Aviral
   Mehta, Manan
   Jindal, Prashant
TI Survey of denoising, segmentation and classification of magnetic
   resonance imaging for prostate cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PCa; MRI; Denoising; Segmentation; Classification
ID AUTOMATIC CLASSIFICATION; MRI; NOISE; IMAGES; TOMOGRAPHY; GLAND;
   FRAMEWORK; FILTERS; MODEL; ATLAS
AB Prostate cancer (PCa) has become the second most dreadful cancer in men after lung cancer. Traditional approaches used for treatment of PCa were manual, time consuming and prone to subjective errors. Thus, there is a need for a Computer aided diagnosis system (CADs) consisting of denoising, segmentation, and classification approaches for diagnosis of PCa. CADs may act as a second opinion for the medical experts and save their precious time used in manual analysis. Magnetic resonance imaging (MRI) is the commonly used modality, as it produces detailed and fine contrast images of internal organs for diagnosis of PCa, but it may contain a certain amount of rician and gaussian noise which is necessary to be denoising before segmentation and classification. Denoising offers several challenges such as suppressing of significance image details leading in inaccurate segmentation and classification for prediction of abnormality. Thus, improved denoising, segmentation, and classification approaches can overcome the challenges by analyzing the pitfalls in the state of the art. This paper presents the experimental analysis state of the art denoising and segmentation approaches to analyse their performance based on the values of Peak signal to noise ratio (PSNR), Mean squared error (MSE), Structured similarity index (SSIM), dice metric, area overlap and accuracy. Based on the experimental analysis it was analysed that anisotropic filter outperforms other filters for gaussian noise with PSNR of 28.29, MSE of 96.22 and SSIM of 0.64. Also, for the rician noise anisotropic filter outperforms others with PSNR of 28.06, MSE of 101.52 and SSIM of 0.01. Similarly, for the combined gaussian and rician noise, anisotropic filter outperform others with PSNR of 28.34, MSE of 95.13 and SSIM of 0.652. Further, the analysis of segmentation approaches such as contour and shape-based, region/atlas based, thresholding based, clustering based and deep learning based was performed. Amongst these approaches deep learning based segmentation was found to outperform with dice metric of 0.89 and area overlap of 0.80. Also, CNN based classification outperformed machine learning based Support vector machine (SVM), K nearest neighbour (K-NN) and Random forest (RF) with 94.55% sensitivity, 93.34% specificity, 95.45% accuracy. Finally, the paper discusses challenges and future scope based on analysis in the concerned field for diagnosis of PCa.
C1 [Juneja, Mamta; Saini, Sumindar Kaur; Gupta, Jatin; Garg, Poojita; Thakur, Niharika; Sharma, Aviral; Mehta, Manan; Jindal, Prashant] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Jindal, P (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM mamtajuneja@pu.ac.in; sumindarkaursaini@gmail.com;
   jatingupta1595@gmail.com; poojita8garg@gmail.com;
   niharikathakur04@gmail.com; 100aviral100@gmail.com;
   manan161200@gmail.com; jindalp@pu.ac.in
OI Jindal, Dr. Prashant/0000-0002-3844-3494; Garg,
   Poojita/0009-0006-5308-0296
FU Ministry of Human Resource Development (MHRD), Govt. of India under
   Design Innovation Centre (DIC) sub-theme Medical Devices & Restorative
   Technologies [17-11/2015-PN-1]
FX The authors are also grateful to the Ministry of Human Resource
   Development (MHRD), Govt. of India for funding this
   project(17-11/2015-PN-1) under Design Innovation Centre (DIC) sub-theme
   Medical Devices & Restorative Technologies.
CR Abraham B, 2018, COMPUT MED IMAG GRAP, V69, P60, DOI 10.1016/j.compmedimag.2018.08.006
   Abraham B, 2018, BIOCYBERN BIOMED ENG, V38, P733, DOI 10.1016/j.bbe.2018.06.009
   Ahmed HU, 2017, LANCET, V389, P815, DOI 10.1016/S0140-6736(16)32401-1
   Aja-Fernández S, 2008, IEEE T IMAGE PROCESS, V17, P1383, DOI 10.1109/TIP.2008.925382
   Alta Klinik, 2019, MULT MRI PROST
   Alvarez C, 2015, PROC SPIE, V9287, DOI 10.1117/12.2073449
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2013, AUTOMATIC DIAGNOSIS
   [Anonymous], 2012, MICCAI GRAND CHALLEN
   [Anonymous], 2018, High-Resolution Neuroimaging-Basic Physical Principles and Clinical Applications
   [Anonymous], 2019, PROSTATE CANC INDIA
   [Anonymous], 2019, PROSTATE CANC IS LEA
   [Anonymous], 2019, APPL CLIN BENEFITS M
   [Anonymous], 2009, Insight J
   [Anonymous], 2019, CT PROSTATE CANC BEA
   [Anonymous], 2006, THEORY POINT ESTIMAT, DOI DOI 10.1007/0-387-22728-8_1
   Barbu A, 2009, IEEE T IMAGE PROCESS, V18, P2451, DOI 10.1109/TIP.2009.2028254
   Bhadauria HS, 2013, COMPUT ELECTR ENG, V39, P1451, DOI 10.1016/j.compeleceng.2012.04.003
   Biswas R, 2018, LECT NOTES ELECTR EN, V442, P575, DOI 10.1007/978-981-10-4762-6_55
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burrus C.S., 1998, Introduction to wavelets and wavelet transforms: A primer, V1
   CAMMOUN D, 1985, WESTERN J MED, V143, P793
   Candes E., 1999, Curvelets
   Chandra SS, 2012, IEEE T MED IMAGING, V31, P1955, DOI 10.1109/TMI.2012.2211377
   Chen JD, 2006, IEEE T AUDIO SPEECH, V14, P1218, DOI 10.1109/TSA.2005.860851
   Chilali O, 2016, J DIGIT IMAGING, V29, P730, DOI 10.1007/s10278-016-9890-0
   Choyke Peter, 2016, Data From PROSTATE-MRI
   Clark T, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.041307
   Das CJ, 2018, INDIAN J UROL, V34, P172, DOI 10.4103/iju.IJU_320_17
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dowling JA, 2011, LECT NOTES COMPUT SC, V6963, P10, DOI 10.1007/978-3-642-23944-1_2
   Fehr D, 2015, P NATL ACAD SCI USA, V112, pE6265, DOI 10.1073/pnas.1505935112
   Flores-Tapia D, 2008, IEEE ENG MED BIO, P3020, DOI 10.1109/IEMBS.2008.4649839
   Gao Y, 2011, I S BIOMED IMAGING, P1401, DOI 10.1109/ISBI.2011.5872662
   Garg, 2018, MULTIMED TOOLS APPL, P1
   GARG G, 2016, INDIAN J SCI TECHNOL, V9, pNI519, DOI DOI 10.17485/ijst/2016/v9i44/105093
   Garg G, 2018, CURR MED IMAGING, V14, P19, DOI 10.2174/1573405613666170504145842
   Ghose S, 2012, COMPUT METH PROG BIO, V108, P262, DOI 10.1016/j.cmpb.2012.04.006
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   Golshan HM, 2013, MAGN RESON IMAGING, V31, P1206, DOI 10.1016/j.mri.2013.04.004
   Gonzalez R., 2002, THRESHOLDING DIGITAL, P595
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gopinath N, 2012, INTERNATERNATIONAL J, V1, P27
   GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618
   Guo Yanrong, 2014, Med Phys, V41, P072303, DOI 10.1118/1.4884224
   Guo YR, 2016, IEEE T MED IMAGING, V35, P1077, DOI 10.1109/TMI.2015.2508280
   Guo Y, 2014, I S BIOMED IMAGING, P866, DOI 10.1109/ISBI.2014.6868008
   HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892
   Hassanzadeh T, 2019, IEEE ACCESS, V7, P36748, DOI 10.1109/ACCESS.2019.2903284
   He BC, 2018, IEEE ACCESS, V6, P2005, DOI 10.1109/ACCESS.2017.2781278
   Hossain MS, 2018, LECT NOTES COMPUT SC, V11307, P510, DOI 10.1007/978-3-030-04239-4_46
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Imielinska C, 2004, INSIGHT IN IMAGES: PRINCIPLES AND PRACTICE FOR SEGMENTATION REGISTRATION AND IMAGE ANALYSIS, P351
   Isa IS, 2015, PROCEDIA COMPUT SCI, V60, P760, DOI 10.1016/j.procs.2015.08.231
   Ishioka J, 2018, BJU INT, V122, P411, DOI 10.1111/bju.14397
   Jadvar H, 2011, J NUCL MED, V52, P81, DOI 10.2967/jnumed.110.077941
   Judith Marcin M, 2018, MED NEWS TODAY
   Karimi D, 2018, INT J COMPUT ASS RAD, V13, P1211, DOI 10.1007/s11548-018-1785-8
   Kaur R, 2018, COMPUT ELECTR ENG
   Klosowski J, 2017, MAGN RESON MED, V77, P1340, DOI 10.1002/mrm.26205
   Kumar Sharma Krishna, 2019, Smart Innovations in Communication and Computational Sciences. Proceedings of ICSICCS-2018. Advances in Intelligent Systems and Computing (AISC 851), P495, DOI 10.1007/978-981-13-2414-7_46
   Lehaire J, 2014, IEEE IMAGE PROC, P2251, DOI 10.1109/ICIP.2014.7025456
   Lemaitre G, 2015, 12 INT C QUAL CONTR, V9534, p95340A
   Lemaître G, 2015, COMPUT BIOL MED, V60, P8, DOI 10.1016/j.compbiomed.2015.02.009
   Leventon Michael E., 2002, 5th IEEE EMBS International Summer School on Biomedical Imaging, 2002, P8
   Li J, 2018, EUR J RADIOL, V98, P61, DOI 10.1016/j.ejrad.2017.11.001
   Lim J.S., 1990, 2 DIMENSIONAL SIGNAL, P710
   Liu H, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1, DOI [10.1109/INTMAG.2017.8007847, 10.1109/ITNEC.2017.8284747]
   Liu L, 2019, BIOMED SIGNAL PROCES, V49, P506, DOI 10.1016/j.bspc.2018.11.008
   Liu P, 2013, PROC SPIE, V8670, DOI 10.1117/12.2007927
   Luisier F, 2012, IEEE T IMAGE PROCESS, V21, P3454, DOI 10.1109/TIP.2012.2191565
   Macovski A, 1996, MAGNET RESON MED, V36, P494, DOI 10.1002/mrm.1910360327
   Manjón JV, 2015, MED IMAGE ANAL, V22, P35, DOI 10.1016/j.media.2015.01.004
   Martin S, 2010, MED PHYS, V37, P1579, DOI 10.1118/1.3315367
   Masulli F, 1999, ARTIF INTELL MED, V16, P129, DOI 10.1016/S0933-3657(98)00069-4
   To NN, 2018, INT J COMPUT ASS RAD, V13, P1687, DOI 10.1007/s11548-018-1841-4
   Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092
   Mohammadi M, IMPROVEMENT AUTO CON
   Mohan J, 2013, BIOMED SIGNAL PROCES, V8, P779, DOI 10.1016/j.bspc.2013.07.005
   Nam D, 2014, CLIN ORTHOP RELAT R, V472, P3665, DOI 10.1007/s11999-014-3579-9
   Niaf E, 2012, PHYS MED BIOL, V57, P3833, DOI 10.1088/0031-9155/57/12/3833
   Ozer S, 2010, MED PHYS, V37, P1873, DOI 10.1118/1.3359459
   Parfait S, 2012, BIOMED SIGNAL PROCES, V7, P499, DOI 10.1016/j.bspc.2011.09.003
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rajan J, 2012, MAGN RESON IMAGING, V30, P1512, DOI 10.1016/j.mri.2012.04.021
   Reda I, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533034618775530
   Reda I, 2017, COMPUT BIOL MED, V81, P148, DOI 10.1016/j.compbiomed.2016.12.010
   Redpath TW, 1998, BRIT J RADIOL, V71, P704, DOI 10.1259/bjr.71.847.9771379
   Rohlfing T, 2005, TOP BIOMED ENGN, P435
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Roth S, 2005, PROC CVPR IEEE, P860
   Rundo L, 2017, INFORMATION, V8, DOI 10.3390/info8020049
   Ryan O, 2018, HARE RES INVESTIGATE
   Samiee M, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P203, DOI 10.1109/ISSPIT.2006.270797
   Sarkar S, 2016, BIOMED ENG COMPUT BI, V7, P1, DOI 10.4137/BECB.S34255
   Seetha J, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P765, DOI 10.1109/WiSPNET.2016.7566236
   Shah V, 2012, MED PHYS, V39, P4093, DOI 10.1118/1.4722753
   Smith CP, 2019, ABDOM RADIOL, V44, P2021, DOI 10.1007/s00261-018-1660-7
   Smith-Bindman R, 2010, NEW ENGL J MED, V363, P1, DOI 10.1056/NEJMp1002530
   Subudhi BN, 2016, MAGN RESON IMAGING, V34, P1292, DOI 10.1016/j.mri.2016.07.002
   Sudeep PV, 2015, BIOMED SIGNAL PROCES, V20, P125, DOI 10.1016/j.bspc.2015.04.015
   Tian Z, 2015, MED IMAGING 2015 IMA, V9413
   Tian ZQ, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021208
   Tian ZQ, 2016, IEEE T MED IMAGING, V35, P791, DOI 10.1109/TMI.2015.2496296
   Trigui R, 2017, BIOMED SIGNAL PROCES, V31, P189, DOI 10.1016/j.bspc.2016.07.015
   Ucla technology development group, 2019, U CAL
   Wang XX, 2017, SCI REP-UK, V7, DOI [10.1038/s41598-017-01529-2, 10.1038/s41598-017-15720-y]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xin L, 2009, IEEE T MED IMAGING, V28, P906, DOI 10.1109/TMI.2009.2012888
   Yang X, 2017, MED IMAGE ANAL, V42, P212, DOI 10.1016/j.media.2017.08.006
   Yanong Zhu born in 1975 graduated Zhu, 2007, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V17, P252
   Yuan JJ, 2018, COMPUT MATH APPL, V76, P2212, DOI 10.1016/j.camwa.2018.05.044
   Yuan YX, 2019, MED PHYS, V46, P756, DOI 10.1002/mp.13367
   Zhu HT, 2009, J AM STAT ASSOC, V104, P623, DOI 10.1198/jasa.2009.0029
   Zhu W., 2010, NESUG P HLTH CARE LI, V19, P67
   Zhu Y, 2019, J MAGN RESON IMAGING, V49, P1149, DOI 10.1002/jmri.26337
NR 117
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29199
EP 29249
DI 10.1007/s11042-021-11044-2
EA JUN 2021
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000664414400001
DA 2024-07-18
ER

PT J
AU Kumar, S
   Pradhan, J
   Pal, AK
AF Kumar, Sumit
   Pradhan, Jitesh
   Pal, Arup Kumar
TI Adaptive tetrolet based color, texture and shape feature extraction for
   content based image retrieval application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; BDIP; BVLC; Mid-rise quantization; Tetrolet transformation
ID LOCAL BINARY PATTERNS; HISTOGRAM; REPRESENTATION; TRANSFORM; SCENE
AB The performance of any content-based image retrieval (CBIR) system depends on the quality and importance of the extracted features. Those extracted features like texture, shape, and color carry the most vital image information, reflecting the image's visual perception. Since a natural image possesses these features, in this paper, we have proposed a novel CBIR system that uses all these primitive image features to realize an efficient CBIR system. It has been observed that a natural image contains entirely overlapping information, so in this approach, we have evaluated concerned image features from their respective component. Hence, we have used YCbCr color space for the feature extraction process because Y, Cb, and Cr color planes are minimally overlapped. Since a natural image carries a significant amount of redundant and dispensable pixel values. Hence, as a pre-processing step, we have employed a mid-rise quantization scheme on an individual component. This step reduces the non- essential information and fastens the image feature extraction process by a significant margin. To extract texture and shape information from the intensity, i.e., Y-plane, we have deployed the difference of inverse probability (BDIP) and block variance of the local correlation coefficient (BVLC). We have subsequently used adaptive tetrolet transform in the output of BDIP and BVLC to extract local textural and geometrical features. Parallelly, we have selected the Cb and Cr component and used adaptive tetrolet transform to analyze the regional local color variations of the image. The use of tetrolet transform will enhance not only the local geometrical and textural features but also emphasis the color distribution on the entire image. Finally, we have combined the non-overlapping extracted shape, texture, and color features to form the final feature vector for the retrieval process. The proposed method has been tested on three color dominated, two shape dominated, and textural image dataset and subsequently, results are drawn from each of them in terms of precision, recall, and f-score. Further, the proposed scheme has also been compared with different state-of-art CBIR methods, and the results are showing satisfactory improvement over other methods for most instances.
C1 [Kumar, Sumit; Pradhan, Jitesh; Pal, Arup Kumar] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engg, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Kumar, S (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engg, Dhanbad, Bihar, India.
EM sumitkumar@cse.ism.ac.in; jitpradhan02@gmail.com; arupkrpal@gmail.com
RI Kumar, Sumit/HHS-8959-2022; kumar, sumit/HDM-6772-2022
OI Pradhan, Jitesh/0000-0002-6264-4093
CR [Anonymous], 2011, INT J INF TECHNOL KN
   Banerji S, 2013, NEUROCOMPUTING, V117, P173, DOI 10.1016/j.neucom.2013.02.014
   Bo Hua, 2006, Acta Electronica Sinica, V34, P155
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Chan YK, 2003, INT J PATTERN RECOGN, V17, P1417, DOI 10.1142/S0218001403002927
   Chun YD, 2003, IEEE T CIRC SYST VID, V13, P951, DOI 10.1109/TCSVT.2003.816507
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   FAIR RC, 1972, REV ECON STAT, V54, P444, DOI 10.2307/1924572
   Galshetwar GM, 2017, PROCEDIA COMPUT SCI, V115, P440, DOI 10.1016/j.procs.2017.09.103
   Golomb S. W., 1996, Polyominoes: Puzzles, Patterns, Problems, and Packings
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   IDC, ANALYZE FUTURE DIGIT
   Khokher A, 2017, MULTIMED TOOLS APPL, V76, P21787, DOI 10.1007/s11042-016-4096-5
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Krommweh J, 2010, J VIS COMMUN IMAGE R, V21, P364, DOI 10.1016/j.jvcir.2010.02.011
   Kumar Pal A, 2017, FUND INFORM
   Kumar S, 2018, ADV INTELL SYST, V706, P737, DOI 10.1007/978-981-10-8237-5_71
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Li Z, PATTERN RECOGN, P48
   Liu ML, 2015, OPTIK, V126, P2629, DOI 10.1016/j.ijleo.2015.06.058
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pal AK, 2016, MULTIMED TOOLS APPL, P1
   Pandey S, 2016, INFORM PROCESS MANAG, V52, P571, DOI 10.1016/j.ipm.2015.12.005
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Rao MB, 2011, INT J COMPUTER SCI I, V9, P41
   Reddy P. Gangadhara, 2010, 2010 Recent Advances in Space Technology Services and Climate Change (RSTSCC), P138, DOI 10.1109/RSTSCC.2010.5712832
   Shao H, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P753
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Song W, 2018, EXPERT SYST APPL, V96, P347, DOI 10.1016/j.eswa.2017.12.006
   Sriram R, 1996, IEEE T IMAGE PROCESS, V5, P1382, DOI 10.1109/83.535852
   Stankovic RS, 2003, COMPUT ELECTR ENG, V29, P25, DOI 10.1016/S0045-7906(01)00011-8
   Velisavljevic V, 2006, IEEE T IMAGE PROCESS, V15, P1916, DOI 10.1109/TIP.2006.877076
   Vimina ER, 2020, MULTIMED TOOLS APPL, V79, P25357, DOI 10.1007/s11042-020-09207-8
   Vimina ER, 2019, IET IMAGE PROCESS, V13, P1979, DOI 10.1049/iet-ipr.2018.5381
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 51
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29017
EP 29049
DI 10.1007/s11042-021-10835-x
EA JUN 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000662846600001
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zhang, R
AF Zhang, Yan
   Zhang, Rui
TI Research on multimedia image classification technology based on chaos
   optimization machine learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Machine learning; Chaotic time series; Support
   vector machine; Particle swarm optimization
ID MATRIX COMPLETION
AB With the advent of the era of information explosion, multimedia big data with images as the main carrier has increased dramatically and has penetrated into various fields of people's lives. As the basis of image recognition, classification has become an important tool for analyzing and understanding image information. Therefore, how to quickly and efficiently image classification has become a challenging research hotspot. In order to solve the limitation of traditional machine learning algorithm in classification performance, an image classification method based on chaotic optimization machine learning algorithm is proposed. This method combines the support vector machine in the machine learning algorithm with the chaotic time series to construct the classification prediction model. The particle swarm optimization algorithm is used to realize the optimal parameter search of the support vector machine to improve the performance of the prediction model. The test results show that compared with other multi-machine learning algorithm predictions, the proposed method effectively reduces the dependence of classification results on sample types and features, and has a higher and robust classification effect.
C1 [Zhang, Yan] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Zhang, Rui] Shandong Prov Inst Elect Informat Prod Inspect, Jinan 250000, Peoples R China.
C3 Shandong University of Finance & Economics
RP Zhang, Y (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
EM zhangyan1778@126.com
CR Aiguo L., 2015, POW SYS PROTECT CONT, V43, P90
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234
   Cao J, 2016, SCI REP-UK, V6, P382
   Faggini M, 2014, CHAOS, V24, DOI 10.1063/1.4903797
   Gong C, 2016, IEEE T IMAGE PROCESS, V25, P3249, DOI 10.1109/TIP.2016.2563981
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Li Y, 2017, REC PAT COMPUT SCI, V10, P290
   Lin YJ, 2014, APPL MECH MATER, V513-517, P738, DOI 10.4028/www.scientific.net/AMM.513-517.738
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Masdari M, 2017, J NETW SYST MANAG, V25, P122, DOI 10.1007/s10922-016-9385-9
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489
   Pasolli E, 2014, IEEE T GEOSCI REMOTE, V52, P2217, DOI 10.1109/TGRS.2013.2258676
   Ristin M, 2016, IEEE T PATTERN ANAL, V38, P490, DOI 10.1109/TPAMI.2015.2459678
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Tan SuiYan Tan SuiYan, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P201
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wenjing Z, 2016, MICROELECTRO COMPUT, V33, P89
   Xiaozhou Y, 2018, J IMAG GRAPH, V14, P2299
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 21
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22645
EP 22656
DI 10.1007/s11042-019-7636-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100014
DA 2024-07-18
ER

PT J
AU Wang, XY
   Shen, X
   Tian, JL
   Niu, PP
   Yang, HY
AF Wang, Xiang-yang
   Shen, Xin
   Tian, Jia-lin
   Niu, Pan-pan
   Yang, Hong-ying
TI Statistical image watermark decoder based on local frequency-domain
   Exponent-Fourier moments modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermark decoder; Statistical modeling; Stationary wavelet
   transform; Exponent-Fourier moments; Hidden Markov tree
ID HIDDEN MARKOV MODEL; DETECTOR; TRANSFORM; ALGORITHM; SCHEME
AB There are three indispensable, yet contrasting requirements for a watermarking scheme: perceptual transparency, watermark capacity, and robustness against attacks. Therefore, a watermarking scheme should provide a trade-off among these requirements from the information-theoretic perspective. In this paper, we propose a statistical image watermark decoder based on the local frequency-domain Exponent-Fourier moments modeling, which can achieve the tradeoff among imperceptibility, robustness and data payload. The frequency-domain EFMs magnitudes are first generated by combining stationary wavelet transform (SWT) and Exponent-Fourier moments (EFMs). We divide the target region to select local frequency-domain EFMs magnitudes, which are planned to embed watermarks, statistical modeling, and extract watermarks. In order to achieve an accurate modeling process, we conduct the comprehensive statistical analyses of local frequency-domain EFMs magnitudes and establish the powerful Beta Generalized Weibull mixtures-based hidden Markov tree (BGW-HMT) model, which can take into account the non-Gaussian distribution characteristic and the interscale dependency at the same time. The Expectation/Conditional Maximisation Either (ECME) algorithm and upward-downward algorithm are successfully applied to estimate the parameters of BGW-HMT model. At the receiver, the BGW-HMT model is used in the design process of watermark decoder. The decoder structure is developed by using the maximum likelihood decision. In order to prove the effectiveness of proposed watermarking scheme, multi-angle performance tests are performed, including imperceptibility, robustness, watermark capacity and time complexity. The corresponding experimental results from the above four perspectives are inspiring. Compared with the state-of-the-art schemes, our statistical decoder is significantly superior to other statistical decoders.
C1 [Wang, Xiang-yang; Shen, Xin; Tian, Jia-lin; Niu, Pan-pan; Yang, Hong-ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Shen, Xin/JBI-6913-2023; Niu, Panpan/Q-9953-2017; Yang,
   Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Key Scientific Research
   Project of Liaoning Provincial Education Department (LZ2019001), and
   Natural Science Foundation of Liaoning Province (2019-ZD-0468).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, MIDWEST SYMP CIRCUIT, P611, DOI 10.1109/MWSCAS.2017.8052997
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   Amirmazlaghani M, 2017, LECT NOTES COMPUT SC, V10485, P547, DOI 10.1007/978-3-319-68548-9_50
   Amirmazlaghani M, 2016, INFORM SCIENCES, V370, P1, DOI 10.1016/j.ins.2016.06.037
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Bi HB, 2016, MATH PROBL ENG, V7, P1
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Etemad S, 2016, 2016 2ND INTERNATIONAL CONFERENCE OF SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P103
   Fisher NI, 2001, AM STAT, V55, P233, DOI 10.1198/000313001317098248
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   Hu HT, 2014, PATTERN RECOGN, V47, P2596, DOI 10.1016/j.patcog.2014.02.014
   Jindal, 2019, MULTIMED TOOLS APPL, P1
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   LIU CH, 1994, BIOMETRIKA, V81, P633
   Liu JH, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P668, DOI 10.1109/ICIVC.2018.8492868
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Nason Guy P, 1995, Wavelets and Statistics, P281, DOI [DOI 10.1007/978-1-4612-2544-7_17, 10.1007/978-1-4612-2544-7_17]
   Niu PP, 2020, IEEE ACCESS, V8, P46624, DOI 10.1109/ACCESS.2020.2978119
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Sadreazami H, 2015, IEEE INT SYMP CIRC S, P1050, DOI 10.1109/ISCAS.2015.7168817
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Singla N, 2012, RELIAB ENG SYST SAFE, V102, P5, DOI 10.1016/j.ress.2012.02.003
   Wang XY, 2019, J VIS COMMUN IMAGE R, V62, P309, DOI 10.1016/j.jvcir.2019.05.012
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
NR 34
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27717
EP 27755
DI 10.1007/s11042-021-11056-y
EA MAY 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000653635800001
DA 2024-07-18
ER

PT J
AU Guo, JF
   Luo, Y
AF Guo, Jiefeng
   Luo, Yao
TI No-reference omnidirectional video quality assessment based on
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks (GAN); Omnidirectional video quality
   assessment (OVQA); No-reference; Omnidirectional video; Deep learning
AB Omnidirectional video quality assessment (OVQA) helps to evaluate the viewers' visual experience and promotes the development of omnidirectional video. The perceived quality of omnidirectional video is affected not only by the video content and distortion, but also by the viewing directions of viewer's preference. At present, there are some quality assessment methods for omnidirectional video, but most of them are full-reference (FR). Compared with the FR method, the no-reference (NR) method becomes more difficult due to the lack of the reference video. In this paper, a NR OVQA based on generative adversarial networks (GAN) is proposed, which is composed of the reference video generator and the quality score predictor. Generally, a reference image/video is distorted by some distortion types, and each distortion type has some distortion levels. To the best of our knowledge, there are some NR methods using GAN to generate the reference images/videos for quality assessment. In these methods, the reference images/videos is generated by GAN when the distorted images/videos, which are from a distortion type but with different distortion level, are input into the GAN. In order to achieve an accurate quality assessment, the generated reference images/videos, which are from a distortion type but with different distortion level, are expected to have as similar quality as possible with each other. However, the distorted images/videos are independent for GAN, and the GAN will generate a little different reference images/videos for these distorted images/videos. This issue is not considered in the existing GAN-based methods. To solve this issue, we introduced a level loss in OVQA. For the quality score predictor, as a further contribution of this paper, the viewing direction of the omnidirectional video is incorporated to guide the quality and weight regression. The publicly available dataset is used to evaluate the proposed method. The experimental results indicate the effectiveness of the proposed method.
C1 [Guo, Jiefeng; Luo, Yao] Xiamen Univ, Sch Elect Sci & Engn, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Guo, JF (corresponding author), Xiamen Univ, Sch Elect Sci & Engn, Xiamen 361005, Peoples R China.
EM jfguo@xmu.edu.cn
OI Yao, Luo/0009-0005-5719-3813
FU Natural Science Foundation of Fujian Province of China [2019J01046]
FX This work was supported by the Natural Science Foundation of Fujian
   Province of China under Grant 2019J01046.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Dendi SVR, 2020, IEEE T IMAGE PROCESS, V29, P5612, DOI 10.1109/TIP.2020.2984879
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I., 2017, Advances in neural information processing systems, P5769
   Huawei iLab, 2019, HUAWEI REPORT
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim HG, 2020, IEEE T CIRC SYST VID, V30, P917, DOI 10.1109/TCSVT.2019.2898732
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P932, DOI 10.1145/3240508.3240581
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Orduna M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P683, DOI [10.1109/VRW50115.2020.00-83, 10.1109/VRW50115.2020.00192]
   Ren HY, 2018, AAAI CONF ARTIF INTE, P7308
   Salimans T, 2016, ADV NEUR IN, V29
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Sun W, 2020, IEEE J-STSP, V14, P64, DOI 10.1109/JSTSP.2019.2955024
   Wang SQ, 2018, IEEE T CIRC SYST VID, V28, P1, DOI 10.1109/TCSVT.2016.2602764
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1109/TCSVT.2018.2886277, 10.1080/17445302.2018.1558727]
   Yang JC, 2018, IEEE ACCESS, V6, P38669, DOI 10.1109/ACCESS.2018.2854922
   Yang JC, 2018, NEUROCOMPUTING, V309, P83, DOI 10.1016/j.neucom.2018.04.072
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang Y, 2020, IEEE T NEUR NET LEAR, V31, P2716, DOI 10.1109/TNNLS.2018.2890310
NR 35
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27531
EP 27552
DI 10.1007/s11042-021-10862-8
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652455100001
DA 2024-07-18
ER

PT J
AU Nazemi, K
   Burkhardt, D
   Kock, A
AF Nazemi, Kawa
   Burkhardt, Dirk
   Kock, Alexander
TI Visual analytics for technology and innovation management An interaction
   approach for strategic decision making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual analytics; Information visualization; Interaction design; Visual
   trend analytics; Emerging trend identification; Technology management;
   Innovation management; Multimedia interaction
ID CORPORATE FORESIGHT; SEARCH
AB The awareness of emerging trends is essential for strategic decision making because technological trends can affect a firm's competitiveness and market position. The rise of artificial intelligence methods allows gathering new insights and may support these decision-making processes. However, it is essential to keep the human in the loop of these complex analytical tasks, which, often lack an appropriate interaction design. Including special interactive designs for technology and innovation management is therefore essential for successfully analyzing emerging trends and using this information for strategic decision making. A combination of information visualization, trend mining and interaction design can support human users to explore, detect, and identify such trends. This paper enhances and extends a previously published first approach for integrating, enriching, mining, analyzing, identifying, and visualizing emerging trends for technology and innovation management. We introduce a novel interaction design by investigating the main ideas from technology and innovation management and enable a more appropriate interaction approach for technology foresight and innovation detection.
C1 [Nazemi, Kawa; Burkhardt, Dirk] Darmstadt Univ Appl Sci, Human Comp Interact & Visual Analyt, Darmstadt, Germany.
   [Kock, Alexander] Tech Univ Darmstadt, Technol & Innovat Management, Darmstadt, Germany.
C3 Hochschule Darmstadt; Technical University of Darmstadt
RP Nazemi, K (corresponding author), Darmstadt Univ Appl Sci, Human Comp Interact & Visual Analyt, Darmstadt, Germany.
EM kawa.nazemi@h-da.de; dirk.burkhardt@h-da.de; kock@tim.tu-darmstadt.de
RI Nazemi, Kawa/HTR-7512-2023; Kock, Alexander/X-6768-2019; Burkhardt,
   Dirk/I-1553-2016
OI Kock, Alexander/0000-0003-2402-0340; Nazemi, Kawa/0000-0002-2907-2740;
   Burkhardt, Dirk/0000-0002-6507-7899
FU Hessen State Ministry for Higher Education, Research and the Arts
FX "This work was partially funded by the Hessen State Ministry for Higher
   Education, Research and the Arts within the program "Forschung fur die
   Praxis" and was conducted within the research group on Human-Computer
   Interaction and Visual Analytics (https://vis.h-da.de)".
CR AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   AGRAWAL R, 1995, P 21 INT C VER LARG
   [Anonymous], 1995, P 1 INT C KNOWL DISC
   Bertin J, 1983, IN PRESS
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bloom B., 1956, Taxonomy of educational objectives: the classification of educational goals, handbook 1, cognitive domain
   Bonino D, 2010, WORLD PAT INF, V32, P30, DOI 10.1016/j.wpi.2009.05.008
   BRUNER JS, 1961, HARVARD EDUC REV, V31, P21
   Bun KK, 2002, WISE 2002: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING, P73, DOI 10.1109/WISE.2002.1181645
   Card S K., 1999, READINGS INFORM VISU
   Chen KY, 2007, IEEE T KNOWL DATA EN, V19, P1016, DOI 10.1109/TKDE.2007.1040
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Eggers JP, 2018, ACAD MANAG ANN, V12, P357, DOI 10.5465/annals.2016.0051
   Erzurumlu SS, 2020, TECHNOL FORECAST SOC, V156, DOI 10.1016/j.techfore.2020.120041
   Feldman R, 1998, LECT NOTES ARTIF INT, V1510, P38
   Gordon AV, 2020, TECHNOL FORECAST SOC, V154, DOI 10.1016/j.techfore.2020.119966
   Han Q, 2017, WORLD PAT INF, V49, P34, DOI 10.1016/j.wpi.2017.04.003
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Hurtado Jose L., 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0039-2
   Joho H., 2010, P 3 S INF INT CONT I, P13, DOI [DOI 10.1145/1840784.1840789, 10.1145/1840784]
   Kaupp L, 2020, P 24 INT C INF VIS I
   Keim D., 2010, Mastering the information age solving problems with visual analytics, DOI [DOI 10.1016/J.PROCS.2011.12.035, 10.1016/j.procs.2011.12.035]
   Nguyen KL, 2016, INT CONF BIG DATA, P223, DOI 10.1109/BIGCOMP.2016.7425917
   Kim Y., 2009, P ACM S APPL COMPUTI, P1480, DOI [10.1145/1529282, DOI 10.1145/1529282]
   Kock A, 2011, J PROD INNOVAT MANAG, V28, P28, DOI 10.1111/j.1540-5885.2011.00859.x
   LEE B, 2010, IEEE TVCG, V16
   Lent B., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P227
   Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101
   Lohmann S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P753, DOI 10.1145/2254556.2254701
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Mei Qiaozhu., 2005, KDD 05, P198, DOI DOI 10.1145/1081870.1081895
   Montes-y-Gomez M, 2001, COMPUT SIST, V5, P14
   Muhlroth C., 2018, Journal of Business Economics, P1, DOI DOI 10.1007/S11573-018-0898-4
   Muhlroth C, 2022, IEEE T ENG MANAGE, V69, P493, DOI 10.1109/TEM.2020.2989214
   NAZEMI K, 2016, STUDIES COMPUTATIONA, V646
   Nazemi K., 2015, P 15 INT C KNOWL TEC, DOI DOI 10.1145/2809563.2809569
   Nazemi K, 2019, LECT NOTES COMPUT SC, V11845, P283, DOI 10.1007/978-3-030-33723-0_23
   Nazemi K, 2019, IEEE INT CON INF VIS, P191, DOI 10.1109/IV.2019.00041
   Nazemi K, 2014, LECT NOTES COMPUT SC, V8888, P872, DOI 10.1007/978-3-319-14364-4_84
   Noh Y., 2011, P 11 ACM IEEE JCDL
   Rohrbeck R, 2018, TECHNOL FORECAST SOC, V129, P105, DOI 10.1016/j.techfore.2017.12.013
   Rohrbeck R, 2015, TECHNOL FORECAST SOC, V101, P1, DOI 10.1016/j.techfore.2015.11.002
   Rohrbeck R, 2011, TECHNOL FORECAST SOC, V78, P231, DOI 10.1016/j.techfore.2010.06.019
   Roth RA, 2009, EXPLORATORY SEARCH Q, DOI [10.2200/s00174-d1v01y200901icr003, DOI 10.2200/S00174-D1V01Y200901ICR003]
   Schoemaker PJH, 2017, MIT SLOAN MANAGE REV, V58, P28
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Tomokiyo, 2004, WWW 2004 WS WEBL
   Ungar, 2010, P 16 ACM SIGKDD, DOI 10.1145/1835804.1835815
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Viermetz M, 2008, I W ADV ISS E COMMER, P215, DOI [10.1109/CEC/EEE.2008.33, 10.1109/CECandEEE.2008.112]
   Wallach Hanna M., 2009, Advances in neural information processing systems, P1973, DOI DOI 10.1007/S10708-008-9161-9
   Wenwen Dou, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P231, DOI 10.1109/VAST.2011.6102461
   Yu ZG, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 1, P440, DOI 10.1109/ICMLA.2013.89
   Zhai C., 2004, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P743, DOI DOI 10.1145/1014052.1014150
NR 55
TC 7
Z9 7
U1 4
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14803
EP 14830
DI 10.1007/s11042-021-10972-3
EA MAY 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000652455300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, YK
   Wu, B
   Tan, LF
   Liu, JY
AF Zhang, Yukun
   Wu, Bei
   Tan, Lifeng
   Liu, Jiayi
TI Information visualization analysis based on historical data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Historical data; Visualization; Data quantification; GIS; Coastal
   defense system
AB Visual expression is increasingly used in historical research due to its intuitiveness and distinctness. However, most of the common research contents focus on the spatial concept, but lack the visualization analysis of the attribute characteristics of the research elements. In order to achieve this goal, based on a case study of the coastal military defense system in Ming Dynasty, the Geographic Information System (GIS) platform was adopted to reconstruct the historical map and its spatial data were extracted. On this foundation, the attribute characteristics of the military settlements, accessibility, was quantified by constructing a hierarchy evaluation model, and then the results were projected into the spatial geographic coordinates to realize the visualization of the accessibility of the military settlements in Ming Dynasty. The results showed that the combined method of quantification and visualization not only enabled more comprehensive and intuitive display of historical information, but also promoted data extraction and correlation analysis, creating a possibly for more in-depth future research.
C1 [Zhang, Yukun; Wu, Bei; Tan, Lifeng] Tianjin Univ, Sch Architecture, Minist Culture & Tourism China, Key Lab Informat Technol Architectural Heritage I, Tianjin, Peoples R China.
   [Liu, Jiayi] Tianjin Univ, Sch Marine Sci & Technol, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Tan, LF (corresponding author), Tianjin Univ, Sch Architecture, Minist Culture & Tourism China, Key Lab Informat Technol Architectural Heritage I, Tianjin, Peoples R China.; Liu, JY (corresponding author), Tianjin Univ, Sch Marine Sci & Technol, Tianjin, Peoples R China.
EM tanlf_arch@163.com; liujiayi2012@126.com
OI Tan, Lifeng/0009-0000-7716-9777
FU National Natural Science Foundation of China [52078324, 51778400]; Major
   Research on Philosophy and Social Sciences of the Ministry of Education
   of China [18JZD059, 19JZD056]; China Scholarship Council
FX Thanks to the National Natural Science Foundation of China (grant no.
   52078324 and 51778400) and Major Research on Philosophy and Social
   Sciences of the Ministry of Education of China (grant no. 18JZD059 and
   19JZD056) for their funding of this study. Thanks to the China
   Scholarship Council for their support of this study.
CR Bentley E, 2012, CARTOGR GEOGR INF SC, V39, P219, DOI 10.1559/15230406394219
   [曹迎春 Cao Yingchun], 2014, [河北农业大学学报, Journal of Agricultural University of Hebei], V37, P138
   CLARK PJ, 1954, ECOLOGY, V35, P445, DOI 10.2307/1931034
   Fan Z., 1990, HIST RES, V03, P44
   Gong S., 1993, ACTA GEOGRAPH SIN, V04, P304
   Guan Weihe Wendy, 2012, Annals of GIS, V18, P121, DOI 10.1080/19475683.2012.668559
   HANSEN WG, 1959, J AM I PLANNERS, V25, P73, DOI 10.1080/01944365908978307
   Institute of Geographical Sciences, 1987, POP ATL CHIN
   Lin C., 1981, SCI GEOGR SIN, V02, P97
   Liu J., 2013, J ARCHITECT, VS1, P108
   Oldenderfer M., 1996, ANTHR SPACE GEOGRAPH, DOI [10.1093/oso/9780195085754.001.0001, DOI 10.1093/OSO/9780195085754.001.0001]
   Pawson E, 1997, J HIST GEOGR, V23, P496, DOI 10.1006/jhge.1997.0065
   Pearce M.W., 2008, Cartography and Geographic Information Science, V35, P17, DOI DOI 10.1559/152304008783475661
   Piatti Barbara., 2009, Cartography and Art, P1, DOI DOI 10.1007/978-3-540-68569-215
   Shi H., 1996, HIST ATLAS XIAN
   Shi Y., 2018, ZHOUSHAN DAILY, P005
   St-Hilaire M, 2007, HIST METHOD, V40, P76, DOI 10.3200/HMTS.40.2.76-91
   Staley D.J., 2002, Computers, visualization, and history: How new technology will transform our understanding of the past
   [谭立峰 Tan Lifeng], 2018, [城市规划, City Planning Review], V42, P92
   Tan Q.X., 1982, The historical atlas of China
   [王加胜 Wang Jiasheng], 2015, [地理科学, Scientia Geographica Sinica], V35, P608
   Wang T., 2010, THESIS SE U
   Wang Z., 2017, RES CHINESE EC HIST, V05, P28
   Wu Y., 1995, HIST ATLAS COUNTER J
   Yang Z., 2020, STUDY DEFENSE EFFICI
   Yang Z., 1994, RES POSTSTATION MING
   Yin Z., 2016, ARCHITECT CULT, V001, P104
   Zhang S, 1560, NINGBO ANN JIAJING P
   Zhang Y., 2012, RES COASTAL DEFENSE
   Zheng RZ, 2007, Chou Hai Tu Bian
NR 30
TC 2
Z9 2
U1 5
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4735
EP 4751
DI 10.1007/s11042-021-11030-8
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000651346700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Sujanaa, J
   Palanivel, S
   Balasubramanian, M
AF Sujanaa, J.
   Palanivel, S.
   Balasubramanian, M.
TI Emotion recognition using support vector machine and one-dimensional
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Feature extraction; Mouth detection;
   Histogram of oriented gradients (HOG); Local binary pattern (LBP);
   Scale-invariant feature transform (SIFT); Speeded-up robust features
   (SURF); Support vector machine (SVM)
ID FACIAL EXPRESSION; CLASSIFICATION; SCALE
AB Emotion recognition is the most regularly reviewed concept in examining behavioural perception and human-computer interface. The proposed system considers happy, normal and surprise categories of emotions. The dataset comprises mouth images containing emotions in the form of video frames. The Haar-based cascade classifier is used to segment the mouth region in the face images and the video frames are extracted at 20 frames per second. The histogram of oriented gradients (HOG) and local binary pattern (LBP) are applied to capture the edge and local information from the emotion image by extracting the gradient information and finally combined into a single histogram to form the features where each histogram represents a mouth image. The speeded-up robust features (SURF) and scale-invariant feature transform (SIFT) methods are employed to extract unique points in emotion image with varying number of key-points as features. The support vector machine (SVM) and one-dimensional convolutional neural network (1D-CNN) are trained using these texture features. Trained models are utilized to detect emotions in testing video frames. The experimental results depict that SVM and 1D-CNN achieve an accuracy of 97.44% and 98.51% respectively.
C1 [Sujanaa, J.; Palanivel, S.; Balasubramanian, M.] Annamalai Univ, Dept Comp Sci & Engn, Chidambaram 608002, Tamil Nadu, India.
C3 Annamalai University
RP Sujanaa, J (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Chidambaram 608002, Tamil Nadu, India.
EM sujanaajohn@gmail.com; spal_yughu@yahoo.com; balu_june1@yahoo.co.in
RI M., Balasubramanian/ABB-9541-2021
OI M, Balasubramanian/0000-0003-4251-5144; S, Palanivel/0000-0003-0818-381X
CR Abadi, 2016, PRELIM WHITE PAP, V1, P1, DOI [10.1109/TIP.2003.819861, DOI 10.1109/TIP.2003.819861]
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fabianpedregosa FP., 2011, J MACH LEARN RES, V12
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Jondhale K, 2016, ACM INT C P SERIES, P81, DOI [10.1145/2983402.2983425, DOI 10.1145/2983402.2983425]
   Julina J. Kulandai Josephine, 2019, 2019 4th International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT), P56, DOI 10.1109/RTEICT46194.2019.9016766
   Kalsum T, 2018, IET IMAGE PROCESS, V12, P1004, DOI 10.1049/iet-ipr.2017.0499
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Liu CL, 2005, PROC INT CONF DOC, P121, DOI 10.1109/ICDAR.2005.119
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Mao QR, 2017, IEEE T MULTIMEDIA, V19, P861, DOI 10.1109/TMM.2016.2629282
   Neeru N, 2016, J ENG-NY, V2016, DOI 10.1155/2016/9387545
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ragb H. K., 2016, IS T INT S EL IM SCI, V3, P1, DOI [10.2352/ISSN.2470-1173.2016.3.VSTIA-511, DOI 10.2352/ISSN.2470-1173.2016.3.VSTIA-511]
   Sharma M, 2019, MULTIMED TOOLS APPL, V78, P16195, DOI 10.1007/s11042-018-7030-1
   Shen H, 2018, P 2017 10 INT C IM S, P1, DOI [10.1109/CISP-BMEI.2017.8301923, DOI 10.1109/CISP-BMEI.2017.8301923]
   SUJANAA J, 2020, INDIAN J SCI TECHNOL, V13, P3222, DOI DOI 10.17485/IJST/v13i31.1118
   Tan Lianzhi., 2017, P 19 ACM INT C MULT, P549
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yolcu G, 2017, IEEE INT C BIOINFORM, P1652, DOI 10.1109/BIBM.2017.8217907
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang HS, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P544, DOI 10.1109/IAEAC.2017.8054074
   2020, INT CONF ADVAN COMPU, P317
NR 33
TC 6
Z9 7
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27171
EP 27185
DI 10.1007/s11042-021-11041-5
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650128900001
DA 2024-07-18
ER

PT J
AU Kim, J
   Lee, YJ
AF Kim, Jihun
   Lee, Young Jae
TI RETRACTED: Smart indoor crop grower based on smart database using IoT
   (Retracted Article)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Smart indoor crop grower; IoT; Smart database; FCM; Image processing
AB We propose a new type of smart server based smart indoor crop grower using IoT(Internet of Things). The proposed smart indoor crop grower provides visual information for intuitively knowing the current cultivation status, as well as IoT-based sensor control, sensor data processing, communication control controller, smart server based sensor data storage, and building the optimal cultivation environment. It consists of a smart app that allows the user to know the real-time situation information of the smart indoor crop grower and to control the grower according to the situation. In particular, the FCM (Firebase Cloud Messaging) function was used to quickly notify the user in the event of an emergency with the grower, and the grower was constructed by applying an image processing technique to extract the growth status information of the cultivated grain. In addition, functional expansion was secured by configuring a programming function module to enable active coping even when a sensor is added. The proposed algorithm was applied to a self-produced smart indoor crop grower to confirm the superiority of its performance through experiments. The proposed smart indoor crop grower can be used as a basic resource for strengthening agricultural technology capabilities by developing technologies that are central to the agricultural field.
C1 [Kim, Jihun] Jeonju Univ, ICT Convergence Studies, Smart Agro, Jeonju, South Korea.
   [Lee, Young Jae] Jeonju Univ, Dept Smart Media, Jeonju, South Korea.
C3 Jeonju University; Jeonju University
RP Lee, YJ (corresponding author), Jeonju Univ, Dept Smart Media, Jeonju, South Korea.
EM kjh6512@jj.ac.kr; leeyj@jj.ac.kr
CR Ahmed N, 2018, IEEE INTERNET THINGS, V5, P4890, DOI 10.1109/JIOT.2018.2879579
   Ban F, 2018, INT J SOCIAL HUMANIS, V3, P34, DOI [DOI 10.1504/IJSHC.2018.095011, 10.1504/IJSHC.2018.095011]
   Choi Y-C., 2019, KOREAN INS COMMUN SC, V36, P9
   HeejinYou, 2019, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V17, P73, DOI 10.14801/jkiit.2019.17.6.73
   Joo HJ, 2017, MULTIMED TOOLS APPL, V76, P17785, DOI 10.1007/s11042-015-3092-5
   Kim SC, 2018, KOREAN AUTON SOC MON, V151, P62
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Raut R., 2017, INTELLIGENT COMMUNIC, p67 
   SjaakWolfert L G., 2017, AGR SYSTEMS ELSEVIER, V153, P69
   김송주, 2017, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V15, P117, DOI 10.14801/jkiit.2017.15.9.117
NR 10
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34313
EP 34331
DI 10.1007/s11042-021-10790-7
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000648376700006
DA 2024-07-18
ER

PT J
AU Wang, S
   Sun, ZX
AF Wang, Shuang
   Sun, Zhengxing
TI Dyeing creation: a textile pattern discovery and fabric image generation
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dyeing creation; Repetitive pattern discovery; Image super-resolution;
   Fabric images
AB Creating different textile patterns to generate printable fabric images is a difficult image processing task. To accomplish this task, we propose a novel framework for dyeing creation, which allows non-professionals to design individual fabric images. The two main components of this framework are textile pattern discovery and fabric image generation. Since the objects in the fabric image are multi-category and multi-scale, we employ a combination of object pattern and template pattern to discover the repetitive pattern, which can better extract objects and analyze spatial structure. However, the image created with objects and templates cannot be dyed directly, because it does not meet the physical size requirements of dyeing. Therefore, we propose an image super-resolution method for fabric image generation based on edge information prior. It solves the high magnification problem of single image by using deep neural network without training data sets. Extensive experiments on fabric images demonstrate that the proposed algorithm achieves good results both qualitatively and quantitatively. Our method has comparable accuracy compared with state-of-the-art methods and visual results demonstrate our superiority in restoring edges while generating fabric images.
C1 [Wang, Shuang; Sun, Zhengxing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
   [Wang, Shuang] Jiangsu Vocat Inst Commerce, Nanjing 211168, Peoples R China.
C3 Nanjing University; Jiangsu Vocational Institute of Commerce
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
EM szx@nju.edu.cn
OI Wang, Shuang/0000-0003-2224-5108
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai YL, 2013, IEEE COMPUT SOC CONF, P223, DOI 10.1109/CVPRW.2013.40
   Cai YL, 2013, IEEE T IMAGE PROCESS, V22, P2343, DOI 10.1109/TIP.2013.2251649
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dutre, 2005, PROCEDURAL OBJECT DI
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gong K, 2019, IEEE T MED IMAGING, V38, P1655, DOI 10.1109/TMI.2018.2888491
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim K., 2018, ARXIV181207174
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu JC, 2013, PROC CVPR IEEE, P2003, DOI 10.1109/CVPR.2013.261
   Liu SY, 2015, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2015.29
   Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731
   Mastan ID, 2019, IEEE COMPUT SOC CONF, P1728, DOI 10.1109/CVPRW.2019.00223
   Nazeri K., 2019, ARXIV190100212
   Park M, 2009, IEEE T PATTERN ANAL, V31, P1804, DOI 10.1109/TPAMI.2009.73
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosenfeld A., 1976, DIGITAL PICTURE PROC
   Santoni C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982417
   Schindler G, 2008, PROC CVPR IEEE, P925
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Spinello L, 2010, LECT NOTES COMPUT SC, V6315, P296, DOI 10.1007/978-3-642-15555-0_22
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Zhang W, 2018, IEEE CONF COMPUT
NR 30
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26511
EP 26530
DI 10.1007/s11042-021-10902-3
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646953200003
DA 2024-07-18
ER

PT J
AU Yadav, SP
AF Yadav, Satya Prakash
TI Emotion recognition model based on facial expressions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Emotion recognition; Facial expression; Action units;
   Facial recognition
AB Face mining is characterized as the revelation of picture designs in a given congregation of pictures. It is an exertion that generally attracts upon information PC (Personal Computer) vision, picture handling, information mining, AI (Artificial Intelligence), database, and human-made reasoning. Facial acknowledgement breaks down and contemplates the examples from the images of the facial. Facial component extraction is a programmed acknowledgment of human faces by recognizing its highlights, for example, eyebrows, eyes, and lips. In this paper, we are assessing the execution of PCA (Priniciple Component Analysis), GMM (Gaussian Mixture Models), GLCM (Gray Level CoOccurrence Matrix), and SVM (Support Vector Machines) to perceive seven distinctive outward appearances of two people, for example, angry, sad, happy, disgust, neutral, fear, and surprise in database. Our point is to talk about the best systems that work best for facial acknowledgement. The present investigation demonstrates the plausibility of outward appearance acknowledgement for viable applications like surveillance and human PC communication.
C1 [Yadav, Satya Prakash] ABES Inst Technol ABESIT, Dept Informat Technol, Ghaziabad 201009, India.
RP Yadav, SP (corresponding author), ABES Inst Technol ABESIT, Dept Informat Technol, Ghaziabad 201009, India.
EM prakashyadav.satya@gmail.com
CR Chakraborty, 2012, INT J COMPUTER APPL, V40, P50
   Chu CC, 2015, INT CONF MACH LEARN, P586, DOI 10.1109/ICMLC.2015.7340620
   Dai Y, 1996, PATTERN RECOGN, V29, P1007, DOI 10.1016/0031-3203(95)00139-5
   Durmusoglu A, 2016, INT CONF SYST SIGNAL
   Gosavi K., 2013, INT J SOFT COMPUTING, V3, P258
   Kiran T, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P115, DOI 10.1109/SNPD.2016.7515888
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Mao QR, 2015, FRONT INFORM TECH EL, V16, P272, DOI 10.1631/FITEE.1400209
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sablik VK, 2013, AUTOMATIC PRIVACY PR, P199
   Salman Madaini Kissi, 2016, IEEE INT C COMP GRAP, P120
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Voisan EI, 2016, 2016 IEEE 11TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P63, DOI 10.1109/SACI.2016.7507341
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Yang J, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P142, DOI 10.1109/ACV.1996.572043
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6
NR 18
TC 15
Z9 15
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26357
EP 26379
DI 10.1007/s11042-021-10962-5
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000647349000004
OA Bronze
DA 2024-07-18
ER

PT J
AU JarJar, A
AF JarJar, Abdellatif
TI Two advanced classics exploiting DNA and RNA characteristics to encrypt
   a color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; FEISTEL round diagram; Genetic algorithm; DNA; RNA
AB Absctract This article tracks the development of a new algorithms supported by the abundant Vigenere lap, followed by two deeply improved Feistel lathes, acting on arbitrary-sized nucleotide blocks calculated from the chaos map used. This step can be ensured by adapting the basic gWith the progress of the theory of some mathemenetic operator to encrypt the color image. At the end of the second round, mutations and genetic crosses will be applied on the global image. Finally, a passage to the codons writing with the intention of modification of the released protein, extracting the Exons, Introns and Stop codons. Testing on a large number of different sizes images and formats randomly selected from the color image database ensures that our system can endures any known attacks.
C1 [JarJar, Abdellatif] Moulay Rachid High Sch, Taza, Morocco.
RP JarJar, A (corresponding author), Moulay Rachid High Sch, Taza, Morocco.
EM abdoujjar@gmail.com
CR Alkhalid AS, 2015, CRYPTANALYSE HILL CI
   Dewangga IGAP., 2017, Int J Appl Eng Res, V12, P10626
   Ge R, 2019, NOVEL CHAOS BASED SY
   Jarjar A, 2017, INT J STAT APPL MATH, V2
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Lin CH, 2004, J CHIN INST ENG, V27, P743, DOI 10.1080/02533839.2004.9670922
   Mesran NAH, INT J ENG RES TECHNO, V6
   Overbey J, 2005, CRYPTOLOGIA, V29, P59, DOI 10.1080/0161-110591893771
   Reddy VVK, 2018, INT J PURE APPL MATH, V118
   Roy A, 2019, OPTIK, V176, P119, DOI 10.1016/j.ijleo.2018.09.062
   Saeednia S, 2000, CRYPTOLOGIA, V24, P353, DOI 10.1080/01611190008984253
   Siahaan APU, 2016, INT J SCI REIJSR, V5, P1149, DOI DOI 10.21275/V5I7.ART2016437
   Siahaan APU, 2016, INT ASS SCI INNOV RE, V15
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
NR 16
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24603
EP 24629
DI 10.1007/s11042-021-10658-w
EA APR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638027800002
DA 2024-07-18
ER

PT J
AU Khan, MU
   Aziz, S
   Iqtidar, K
   Zaher, GF
   Alghamdi, S
   Gull, M
AF Khan, Muhammad Umar
   Aziz, Sumair
   Iqtidar, Khushbakht
   Zaher, Galila Faisal
   Alghamdi, Shareefa
   Gull, Munazza
TI A two-stage classification model integrating feature fusion for coronary
   artery disease detection and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phonocardiogram; Coronary artery disease; Empirical mode decomposition;
   Feature extraction; K-nearest neighbor; Support vector machine
ID SIGNALS; IDENTIFICATION; RECOGNITION; DIAGNOSIS; NETWORK; PATTERN;
   GOALS; RISK
AB According to the World Health Organization, Coronary Artery Disease (CAD) is a leading cause of death globally. CAD is categorized into three types, namely Single Vessel Coronary Artery Disease (SVCAD), Double Vessel Coronary Artery Disease (DVCAD), and Triple Vessel Coronary Artery Disease (TVCAD). At present, angiography is the most popular technique to detect CAD that is quite expensive and invasive. Phonocardiogram (PCG), being economical and non-invasive, is a crucial modality towards the detection of cardiac disorders, but only trained medical professionals can interpret heart auscultations in clinical environments. This research aims to detect CAD and its types from PCG signatures through feature fusion and a two-stage classification strategy. The self-developed low-cost stethoscope was used to collect PCG data from a local hospital. The PCG signals were preprocessed through an iterative signal decomposition method known as Empirical Mode Decomposition (EMD). EMD decomposes the raw PCG signal into its constituent components called Intrinsic Mode Functions (IMFs). Preprocessed PCG signal was generated exclusively through combining those signal components that contain high discriminative characteristics and less redundancy. Next, Mel Frequency Cepstral Coefficients (MFCCs), spectral and statistical features were extracted. A two-stage classification framework was devised to identify healthy and CAD types. The first stage framework relies on the fusion of MFCC and statistical features with the K-nearest neighbor classifier to predict normal and CAD cases. The second stage is activated only when the first stage detects CAD. The fusion of spectral, statistical, and MFCC features was employed with Support Vector Machines classifier to categorize PCG signatures into DVCAD, SVCAD, and TVCAD classes in the second stage. The proposed method yields mean accuracy values of 88.0%, 89.2%, 91.1%, and 85.3% for normal, DVCAD, SVCAD, and TVCAD, respectively, through 10-fold cross-validation. Comparative analysis with existing approaches confirmed the reliability of the proposed method for categorizing CAD in general clinical environments. The proposed model enhances the diagnosis performance by providing a second opinion during the medical examination.
C1 [Khan, Muhammad Umar; Aziz, Sumair] Univ Engn & Technol Taxila, Dept Elect Engn, Taxila, Pakistan.
   [Iqtidar, Khushbakht] Natl Univ Sci & Technol, Dept Comp & Software Engn, Islamabad, Pakistan.
   [Zaher, Galila Faisal] King Abdulaziz Univ, Hematol Dept, Jeddah 21589, Saudi Arabia.
   [Alghamdi, Shareefa; Gull, Munazza] King Abdulaziz Univ, Biochem Dept, Jeddah 21589, Saudi Arabia.
C3 University of Engineering & Technology Taxila; National University of
   Sciences & Technology - Pakistan; King Abdulaziz University; King
   Abdulaziz University
RP Khan, MU (corresponding author), Univ Engn & Technol Taxila, Dept Elect Engn, Taxila, Pakistan.
EM sa.umarkhan@gmail.com
RI Aziz, Sumair/ABI-3400-2020; Iqtidar, Khushbakht/KPY-5189-2024; Khan,
   Muhammad Umar/HJP-5766-2023; AlGhamdi, Shareefa Abdullah/L-5152-2017
OI Aziz, Sumair/0000-0003-4372-0772; Iqtidar,
   Khushbakht/0000-0001-9645-5736; Khan, Muhammad Umar/0000-0001-6992-6432;
   AlGhamdi, Shareefa Abdullah/0000-0002-6603-6116
CR Acharya UR, 2017, KNOWL-BASED SYST, V132, P62, DOI 10.1016/j.knosys.2017.06.003
   Acharya UR, 2017, BIOMED SIGNAL PROCES, V31, P31, DOI 10.1016/j.bspc.2016.07.003
   Akanksha S., 2017, 2017 14 IEEE IND COU, P1
   Arabasadi Z, 2017, COMPUT METH PROG BIO, V141, P19, DOI 10.1016/j.cmpb.2017.01.004
   Aziz S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133790
   Aziz S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050483
   BANERJEE R, 2017, L N INST COMP SCI SO, V360, P241
   Banerjee R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P950, DOI 10.1109/ICASSP.2018.8462604
   Banerjee R, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1084, DOI 10.1145/2968219.2972712
   Choudhury A. D., 2017, P 11 EAI INT C PERV, P217
   Clifford GD, 2016, COMPUT CARDIOL CONF, V43, P609
   Dey S, 2017, L N INST COMP SCI SO, V181, P370, DOI 10.1007/978-3-319-49655-9_44
   Dolatabadi AD, 2017, COMPUT METH PROG BIO, V138, P117, DOI 10.1016/j.cmpb.2016.10.011
   El Bouny L, 2019, MULTIMED TOOLS APPL, V78, P13067, DOI 10.1007/s11042-018-6143-x
   Fihn SD., 2012, J AM COLL CARDIOL, V60, P44
   Ghiasi S, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.159-327
   Gorey A, 2019, BIOMED PHYS ENG EXPR, V5, DOI 10.1088/2057-1976/ab101c
   Griffel B., 2012, Cardiovasc. Eng. Technol., V3, P333, DOI 10.1007/s13239-012-0094-6
   Hassan AR, 2016, BIOCYBERN BIOMED ENG, V36, P256, DOI 10.1016/j.bbe.2015.11.003
   Huang YY, 2015, RES DEV DISABIL, V36, P366, DOI 10.1016/j.ridd.2014.10.019
   JOHNSTON JD, 1988, IEEE J SEL AREA COMM, V6, P314, DOI 10.1109/49.608
   Khan Muhammad Umar, 2019, 2019 International Conference on Frontiers of Information Technology (FIT), P95, DOI 10.1109/FIT47737.2019.00027
   Khan MU, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010247
   Khan MYA, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673406
   Kones R, 2011, DRUG DES DEV THER, V5, P325, DOI 10.2147/DDDT.S14934
   Kranjec J, 2014, BIOMED SIGNAL PROCES, V13, P102, DOI 10.1016/j.bspc.2014.03.004
   Kumar S, 2017, BIOMED SIGNAL PROCES, V31, P181, DOI 10.1016/j.bspc.2016.08.004
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Lerch Alexander, 2012, An introduction to audio content analysis: Applications in signal processing and music informatics
   Li H, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103733
   Lloyd-Jones DM, 2010, CIRCULATION, V121, P586, DOI 10.1161/CIRCULATIONAHA.109.192703
   Lubaib P, 2016, PROC TECH, V24, P1024, DOI 10.1016/j.protcy.2016.05.225
   Makaryus AN, 2013, AM J CARDIOL, V111, P786, DOI 10.1016/j.amjcard.2012.11.039
   Mathers CD, 2006, PLOS MED, V3, DOI 10.1371/journal.pmed.0030442
   Mc Namara K, 2019, INTEGR PHARM RES PRA, V8, P1, DOI 10.2147/IPRP.S133088
   Nandy A, 2019, MULTIMED TOOLS APPL, V78, P19697, DOI 10.1007/s11042-019-7310-4
   Nishiyama S, 1997, JPN HEART J, V38, P181
   Nishiyama S, 1998, JPN HEART J, V39, P67
   Oresko JJ, 2010, IEEE T INF TECHNOL B, V14, P734, DOI 10.1109/TITB.2010.2047865
   Paithane AN, 2014, IEEE I C COMP INT CO, P962
   Paradkar N, 2017, IEEE ENG MED BIO, P100, DOI 10.1109/EMBC.2017.8036772
   Roth GA, 2017, J AM COLL CARDIOL, V70, P1, DOI 10.1016/j.jacc.2017.04.052
   Samanta P., 2018, PROC 24 NATL C COMMU, P1
   Samanta P, 2019, BIOCYBERN BIOMED ENG, V39, P426, DOI 10.1016/j.bbe.2019.02.003
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Schmidt SE, 2015, IEEE T BIO-MED ENG, V62, P2611, DOI 10.1109/TBME.2015.2432129
   Semmlow J, 2007, ANNU REV BIOMED ENG, V9, P449, DOI 10.1146/annurev.bioeng.9.060906.151840
   Shah H, 2018, J SAUDI HEART ASSOC, V30, P305, DOI 10.1016/j.jsha.2018.04.002
   Sharma M, 2019, PATTERN RECOGN LETT, V125, P235, DOI 10.1016/j.patrec.2019.04.014
   Sharma RR, 2019, IEEE SENS J, V19, P3912, DOI 10.1109/JSEN.2019.2894706
   SHARMA RR, 2019, ADV INTELL SYST, P597
   Tan JH, 2018, COMPUT BIOL MED, V94, P19, DOI 10.1016/j.compbiomed.2017.12.023
   Venkatesan C, 2018, MULTIMED TOOLS APPL, V77, P10365, DOI 10.1007/s11042-018-5762-6
   Yadav A, 2020, NEURAL COMPUT APPL, V32, P17843, DOI 10.1007/s00521-019-04547-5
   Zipes DP., 2018, BRAUNWALDS HEART DIS
NR 55
TC 13
Z9 13
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13661
EP 13690
DI 10.1007/s11042-021-10805-3
EA APR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000637685200004
DA 2024-07-18
ER

PT J
AU Al-wajih, E
   Ghazali, R
AF Al-wajih, Ebrahim
   Ghazali, Rozaida
TI An enhanced LBP-based technique with various size of sliding window
   approach for handwritten Arabic digit recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern; Sliding window; Arabic digit recognition; Pattern
   recognition; Feature extraction
ID NEURAL-NETWORKS; CLASSIFICATION; DESCRIPTORS; FACE; PATTERNS
AB Many variations of local binary pattern (LBP) were proposed to enhance its performance, including uniform local binary pattern (ULBP), center-symmetric local binary patterns (CS-LBP), center symmetric local ternary patterns (CS-LTP), center symmetric local multilevel pattern (CS-LMP), etc. In this paper, the accuracies of LBP technique and its variations are enhanced using four different sizes of a sliding window approach. This approach is used for investigating whether the features extracted by LBP are significant enough or its versions are needed as well. Five LBP-based techniques have been used including LBP, CS-LBP, CS-LTP, CS-LMP, and U2LBP. They have been applied to an Arabic digit image dataset called MAHDBase. Support vector machine (SVM) and random forests are utilized as classifiers. The experimental results show that the obtained accuracies have been improved by 19.56%, 21.43%, 5.63%, 6.51% and 5.62% for CS-LBP, CS-LMP, U2LBP, CS-LTP, and LBP, respectively, when the sliding window approach has been applied and SVM with linear kernel has been used as a classifier. Moreover, the results show that there is no need to use LBP variations to enhance the accuracy if the sliding window is applied because the highest accuracy has been acquired using LBP. At the end, the accuracy of proposed systems has been compared against other state-of-the-art LBP-based techniques showing the significance of the proposed systems.
C1 [Al-wajih, Ebrahim; Ghazali, Rozaida] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Parit Raja 86400, Johor, Malaysia.
   [Al-wajih, Ebrahim] Hodeidah Univ, Soc Dev & Continuing Educ Ctr, Alduraihimi 3114, Hodeidah, Yemen.
C3 University of Tun Hussein Onn Malaysia; Hodeidah University
RP Al-wajih, E (corresponding author), Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Parit Raja 86400, Johor, Malaysia.; Al-wajih, E (corresponding author), Hodeidah Univ, Soc Dev & Continuing Educ Ctr, Alduraihimi 3114, Hodeidah, Yemen.
EM ebrahim.q.alwajih@gmail.com; rozaida@uthm.edu.my
RI Ghazali, Rozaida/D-3985-2013; Alwajih, Ebrahim/AAY-6512-2021; Al-wajih,
   Ebrahim Qasem/JHU-4353-2023
OI Alwajih, Ebrahim/0000-0002-8418-688X; Al-wajih, Ebrahim
   Qasem/0000-0002-8418-688X
FU Universiti Tun Hussein Onn Malaysia (UTHM); Ministry of Higher Education
   (MOHE) Malaysia [1641]
FX This work was supported by the Universiti Tun Hussein Onn Malaysia
   (UTHM) and Ministry of Higher Education (MOHE) Malaysia [grant number
   1641].
CR Al-wajih E, 2020, ADV INTELL SYST COMP, V978, P25, DOI 10.1007/978-3-030-36056-6_3
   Al-Wajih E, 2020, INT ARAB J INF TECHN, V17, P178, DOI 10.34028/iajit/17/2/5
   Al-wajih E, 2019, EVOL INTELL, V12, P633, DOI 10.1007/s12065-019-00264-z
   Alghazo JM, 2019, J IMAGING SCI TECHN, V63, DOI 10.2352/J.ImagingSci.Technol.2019.63.2.020502
   AlKhateeb JH, 2014, INT CONF COMP SCI, P222, DOI 10.1109/CSIT.2014.6806004
   Alkhawaldeh RS, 2021, SOFT COMPUT, V25, P3131, DOI 10.1007/s00500-020-05368-8
   Almodfer R, 2017, LECT NOTES COMPUT SC, V10635, P450, DOI 10.1007/978-3-319-70096-0_47
   [Anonymous], 2018, J U BABYLON
   [Anonymous], 2013, INT J SCI ENG RES
   [Anonymous], 2015, 2015 INT C ELECT ENG, DOI DOI 10.1109/ICEEICT.2015.7307371
   Arbain Nur Atikah, 2018, International Journal of Computer Information Systems and Industrial Management Applications, V10, P87
   Ashiquzzaman A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR)
   Badeka E., 2020, 2020 INT C INT SYST, P1, DOI [10.1109/ISCV49265.2020.9204176, DOI 10.1109/ISCV49265.2020.9204176]
   Balili CC, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P655, DOI 10.1109/ACPR.2015.7486584
   Biglari M., 2014, Int J Digit Inf Wirel Commun (IJDIWC), V4, P486
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Can YS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165430
   Chan JCW, 2008, REMOTE SENS ENVIRON, V112, P2999, DOI 10.1016/j.rse.2008.02.011
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   El Khadiri I, 2018, INFORM SCIENCES, V467, P634, DOI 10.1016/j.ins.2018.02.009
   El Khadiri I, 2018, COMPUT VIS IMAGE UND, V169, P14, DOI 10.1016/j.cviu.2018.01.004
   El Merabet Y, 2018, PATTERN RECOGN, V76, P303, DOI 10.1016/j.patcog.2017.11.005
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   El-Sherif Ezzat Ali, 2007, Proceedings of the 2007 International Conference on Artificial Intelligence and Pattern Recognition (AIPR-07), P237
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Ghofrani Ali, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P168, DOI 10.1109/PRIA.2019.8785981
   Gonnade, 2014, INT J ADV RES COMPUT, V4, P549
   Gouveia C, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2019.101835
   Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195
   Hasan AM, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22091033
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Ilmi N, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT)
   Jabid T, 2010, IEEE ICCE
   Jaha ES, 2019, INT J ADV COMPUT SC, V10, P112
   Jayasudha A., 2016, INT J ADV SIGNAL IMA, V2, P24, DOI [10.29284/ijasis.2.1.2016.24-30, DOI 10.29284/IJASIS.2.1.2016.24-30]
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Kumar KK, 2017, 2017 8TH IEEE ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P204, DOI 10.1109/IEMCON.2017.8117193
   Lawgali A., 2015, INT J DATABASE THEOR, V8, P215, DOI DOI 10.14257/IJDTA.2015.8.5.18
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   Montazer GA., 2017, OPT MEM NEURAL NETW, V26, P117, DOI [10.3103/S1060992X17020060, DOI 10.3103/S1060992X17020060]
   Myers J. L., 2010, RES DESIGN STAT ANAL
   Nadim Uddin, 2019, ARXIV E PRINTS ARXIV, V1908
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Radwan Elsayed, 2013, International Journal of Advanced Research in Artificial Intelligence, V2, P39
   Rakshit RD, 2017, J CHIN INST ENG, V40, P82, DOI 10.1080/02533839.2016.1259020
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Shang J, 2016, IET IMAGE PROCESS, V10, P662, DOI 10.1049/iet-ipr.2016.0058
   Shilbayeh NF., 2013, WORLD SCI ENG ACAD S, P94
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vapnik V.N., 2015, MEASURES COMPLEXITY, P11
   Weidner L, 2019, ENG GEOL, V263, DOI 10.1016/j.enggeo.2019.105326
   Yuan FN, 2016, INFORM SCIENCES, V372, P225, DOI 10.1016/j.ins.2016.08.040
   Zeebaree Diyar Qader, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P106, DOI 10.1109/ICOASE.2019.8723827
   Zeng H, 2016, INT J OPT, V2016, DOI 10.1155/2016/1584514
   Zhao Y, 2016, NEUROCOMPUTING, V207, P354, DOI 10.1016/j.neucom.2016.05.016
   Zheng Jun, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P421, DOI 10.1109/ICEMI.2017.8265841
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
NR 65
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24399
EP 24418
DI 10.1007/s11042-021-10762-x
EA APR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637475700003
DA 2024-07-18
ER

PT J
AU Sengan, S
   Kumar, K
   Subramaniyaswamy, V
   Ravi, L
AF Sengan, Sudhakar
   Kumar, Kailash
   Subramaniyaswamy, V.
   Ravi, Logesh
TI Cost-effective and efficient 3D human model creation and
   re-identification application for human digital twins
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital twin; Ground truth; Human model; Kinect; Point cloud
AB As health-care budgets are continuously under increasing demands, Artificial Intelligence resources such as digital heart twins could save millions of dollars by predicting results and preventing unnecessary surgery. Can we start to make digital human body twins to plant and predict health outcomes for a patient? By using a way to design competent simulation models from real objects, digital twins were created through IoT. But the digital twin is a complicated system and a very long-drawn step away from its possibilities. Researchers must design all components of entities or structures. There is a need to collect and merge various types of data. Many engineering researchers and participants aren't sure about which technologies and resources to use. The 3D digital twin model offers a reference guide for digital twin comprehension and implementation. This paper aims to investigate and outline the recent technologies and tools used for digital twin applications from a 3-D digital model perspective, such as references to technologies and tools for future digital twin applications.
C1 [Sengan, Sudhakar] PSN Coll Engn & Technol, Dept Comp Sci & Engn, Tirunelveli 627152, Tamil Nadu, India.
   [Kumar, Kailash] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
   [Subramaniyaswamy, V.] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
   [Ravi, Logesh] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Saudi Electronic University; Shanmugha Arts, Science, Technology &
   Research Academy (SASTRA); Vel Tech Rangarajan Dr Sagunthala R&D
   Institute of Science & Technology
RP Ravi, L (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM sudhasengan@gmail.com; k.kumar@seu.edu.sa; vsubramaniyaswamy@gmail.com;
   LogeshPhD@gmail.com
RI Senagn, Sudhakar/AAH-6502-2020; Kumar, Kailash/ABG-4712-2020
OI Senagn, Sudhakar/0000-0003-4901-1432; Kumar,
   Kailash/0000-0003-2916-719X; R, Logesh/0000-0002-0034-4714; ,
   Subramaniyaswamy/0000-0001-5328-7672
FU Science and Engineering Research Board (SERB), Department of Science &
   Technology, India through the Mathematical Research Impact Centric
   Support (MATRICS) scheme [MTR/2019/000542]
FX The authors gratefully acknowledge the Science and Engineering Research
   Board (SERB), Department of Science & Technology, India, for the
   financial support through the Mathematical Research Impact Centric
   Support (MATRICS) scheme (MTR/2019/000542). The authors also acknowledge
   SASTRA Deemed University, Thanjavur, for extending infrastructural
   support to carry out this research work.
CR Afzal H, 2014, INT C PATT RECOG, P2459, DOI 10.1109/ICPR.2014.425
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2010, MICROSOFT KINECT
   [Anonymous], 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587758
   [Anonymous], 2003, MULTICAMERA SELF CAL
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boje C, 2020, AUTOMAT CONSTR, V114, DOI 10.1016/j.autcon.2020.103179
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Fuller A, 2020, IEEE ACCESS, V8, P108952, DOI 10.1109/ACCESS.2020.2998358
   General Electric, 2017, PRED TECHN BRIEF DIG
   Grieves M., 2014, White paper
   Vu HH, 2012, IEEE T PATTERN ANAL, V34, P889, DOI 10.1109/TPAMI.2011.172
   Infosys Insights, 2016, FUT IND SERV DIG TWI
   Kim Y, 2017, ETRI J, V39, P181, DOI 10.4218/etrij.17.2816.0045
   Lee J, 2019, PROCESS SAF ENVIRON, V132, P325, DOI 10.1016/j.psep.2019.10.021
   Lefloch Damien, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P3, DOI 10.1007/978-3-642-44964-2_1
   Li C., 2017, 19 AIAA NOND APPR C, DOI [10.2514/6.2017-1566, DOI 10.2514/6.2017-1566]
   Liao YJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071491
   Ma X, 2019, PROC CIRP, V83, P789, DOI 10.1016/j.procir.2019.04.330
   Maimone Andrew, 2012, P 3DTV C TRUE VIS CA, P1
   Min Y, 2009, IEEE 12 INT C COMP V, P1542
   Patriarca R, 2019, SAFETY SCI, V118, P551, DOI 10.1016/j.ssci.2019.05.040
   Qi QL, 2018, PROC CIRP, V72, P237, DOI 10.1016/j.procir.2018.03.103
   Richards-Rissetto H., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P331, DOI 10.1109/VSMM.2012.6365942
   Ruchay A, 2018, LECT NOTES COMPUT SC, V10716, P280, DOI 10.1007/978-3-319-73013-4_26
   Scoles S., 2016, DIGITAL TWIN YOUR BO
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Smelkina NA, 2017, COMPUT OPT, V41, P897, DOI 10.18287/2412-6179-2017-41-6-897-904
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Telenti A, 2016, P NATL ACAD SCI USA, V113, P11901, DOI 10.1073/pnas.1613365113
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430
   Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134
NR 34
TC 9
Z9 10
U1 9
U2 97
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26839
EP 26856
DI 10.1007/s11042-021-10842-y
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000634660700003
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H. I.
TI Rib chest radiographs for detection of the cancer using double stage
   adaptive processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radiography; Rib chest images; Histogram processing
ID IMAGE FUSION; CONTRAST ENHANCEMENT; MODEL
AB This paper suggests elegant two enhancement approaches for rib chest images. The first approach is based on adaptive contrast and luminance model (ACLM).The second approach is depended on mixing the Exponential Contrast Limited Adaptive Histogram Equalization model (ECLAHE) with the Local Histogram Equalization (LHE). The idea of this approach is depended on applying on rib chest radiograph and make optimization for clip limit for ECLAHE. This second algorithm has helped rib chest radiograph details are more important for the detection of cancerous cells. The performance qualities of the suggested models are entropy, average gradient, contrast factor, Sobel magnitude, lightness order error and the similarity of edges point of views. The second approach presents enhancement of rib chest images with better resolution visual details and quality metrics point of views with comparing the first approach.
C1 [Ashiba, H. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
CR [Anonymous], 2013, Int. J. Comput. Appl, DOI DOI 10.5120/13766-1620
   [Anonymous], DIGITAL IMAGE PROCES
   Athanasiadis E, 2011, COMPUT METH PROG BIO, V104, P307, DOI 10.1016/j.cmpb.2011.03.007
   Bai XZ, 2017, INFRARED PHYS TECHN, V80, P44, DOI 10.1016/j.infrared.2016.11.011
   Freedman M, 2001, PROC SPIE, V4324, P184, DOI 10.1117/12.431187
   Hussein NJ, 2017, PATTERN RECOGN LETT, V94, P219, DOI 10.1016/j.patrec.2016.12.011
   Kong WW, 2014, INFRARED PHYS TECHN, V63, P110, DOI 10.1016/j.infrared.2013.12.016
   Li Y, 2016, OPT LASER TECHNOL, V83, P99, DOI 10.1016/j.optlastec.2016.03.017
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Liu HT, 2019, LECT NOTES ELECTR EN, V527, P271, DOI 10.1007/978-981-13-2481-9_32
   Liu N, 2016, INFRARED PHYS TECHN, V77, P405, DOI 10.1016/j.infrared.2016.06.017
   Liu N, 2014, INFRARED PHYS TECHN, V67, P138, DOI 10.1016/j.infrared.2014.07.013
   Cañada PM, 2013, J SYST ARCHITECT, V59, P30, DOI 10.1016/j.sysarc.2012.10.005
   Paramanandham N, 2018, INFRARED PHYS TECHN, V88, P13, DOI 10.1016/j.infrared.2017.11.006
   Pinoli JC, 1997, SIGNAL PROCESS, V58, P11, DOI 10.1016/S0165-1684(97)00011-X
   Qi W, 2016, INFRARED PHYS TECHN, V76, P684, DOI 10.1016/j.infrared.2016.04.038
   Raja N. Sri Madhava, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P961, DOI 10.1007/s12652-018-0854-8
   Schlenke J, 2012, ANAL CHIM ACTA, V754, P8, DOI 10.1016/j.aca.2012.10.012
   Schowengerdt RA, 2007, REMOTE SENSING: MODELS AND METHODS FOR IMAGE PROCESSING, 3RD EDITION, P355, DOI 10.1016/B978-012369407-2/50011-5
   Song Q, 2016, INFRARED PHYS TECHN, V77, P464, DOI 10.1016/j.infrared.2016.06.023
   Zhang XL, 2015, EXPERT SYST APPL, V42, P2382, DOI 10.1016/j.eswa.2014.10.050
   Zhao H, 2001, P SPIE INT SOC OPTIC
   Zhao JC, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.703
   Zhao JF, 2017, INFRARED PHYS TECHN, V81, P201, DOI 10.1016/j.infrared.2017.01.012
   Zhu P, 2017, INFRARED PHYS TECHN, V81, P282, DOI 10.1016/j.infrared.2017.01.013
   Zhuqing J, 2011, THESIS
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21315
EP 21337
DI 10.1007/s11042-020-10214-y
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100001
DA 2024-07-18
ER

PT J
AU Jeong, CY
   Shin, HC
   Kim, M
AF Jeong, Chi Yoon
   Shin, Hyung Cheol
   Kim, Mooseop
TI Sensor-data augmentation for human activity recognition with
   time-warping and data masking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Data augmentation; Smartphone
   accelerometers; Convolutional neural networks; Deep learning
ID NEURAL-NETWORK; DEEP; MOBILE
AB Human activity recognition (HAR) using an accelerometer can provide valuable information for understanding user context. Therefore, several studies have been conducted using deep learning to increase the recognition rate of activity classification. However, the existing dataset that is publicly available for HAR tasks contains limited data. Previous works have applied data augmentation methods that simply transform the entire accelerometer-signal dataset. However, the label of the augmented signal cannot be easily recognized by humans, and the augmentation methods cannot ensure that the label of the signal is preserved. Therefore, we propose a novel data augmentation method that reflects the characteristics of the sensor signal and can preserve the label of the augmented signal by generating partially occluded data of the accelerometer signals. To generate the augmented data, we apply time-warping, which deforms the time-series data in the time direction. We handle jittering effects and subsequently apply data masking to drop out a part of the input signals. We compare the performance of the proposed augmentation method with that of conventional methods by using two public datasets and an activity recognition model based on convolutional neural networks. The experimental results show that the proposed augmentation method improves the recognition rate of the activity classification model, regardless of the dataset. Additionally, the proposed method shows superior performance over conventional methods on the two datasets.
C1 [Jeong, Chi Yoon; Shin, Hyung Cheol; Kim, Mooseop] Elect & Telecommun Res Inst ETRI, Artificial Intelligence Res Lab, Human Enhancement & Assist Technol Res Sect, Daejeon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Kim, M (corresponding author), Elect & Telecommun Res Inst ETRI, Artificial Intelligence Res Lab, Human Enhancement & Assist Technol Res Sect, Daejeon, South Korea.
EM iamready@etri.re.kr; shc@etri.re.kr; gomskim@etri.re.kr
OI Kim, Mooseop/0000-0003-4914-0584; Jeong, Chi Yoon/0000-0001-7089-2516
FU Institute of Information & Communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [1711103127]; Electronics
   and Telecommunications Research Institute (ETRI) - Korean government
   (MSIT) [20ZS1100]
FX This work was partly supported by the Institute of Information &
   Communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT) [1711103127, Development of Human
   Enhancement Technology for auditory and muscle support] and Electronics
   and Telecommunications Research Institute (ETRI) grant funded by the
   Korean government (MSIT) [20ZS1100, Core Technology Research for
   Self-Improving Integrated Artificial Intelligence System].
CR [Anonymous], 2016, P 30 AAAI C ART INT
   Avilés-Cruz C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071556
   Chollet F., 2015, Keras: Deep learning library for theano and tensorflow
   Chung S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071716
   Cui XD, 2015, IEEE-ACM T AUDIO SPE, V23, P1469, DOI 10.1109/TASLP.2015.2438544
   DeVries T, 2017, PREPRINT
   Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146
   Hinton G. E., 2012, 12070580 ARXIV
   Inoue M, 2018, ARTIF LIFE ROBOT, V23, P173, DOI 10.1007/s10015-017-0422-x
   Jeong CY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173688
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Kalouris G, 2019, IEEE INTL CONF IND I, P1387, DOI [10.1109/indin41052.2019.8972135, 10.1109/INDIN41052.2019.8972135]
   Kim M, 2021, MULTIDIM SYST SIGN P, V32, P115, DOI 10.1007/s11045-020-00731-2
   Kim M, 2018, I C INF COMM TECH CO, P1482, DOI 10.1109/ICTC.2018.8539419
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Mathur A, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P200, DOI 10.1109/IPSN.2018.00048
   Micucci D, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101101
   Mukherjee D, 2020, MULTIMED TOOLS APPL, V79, P31663, DOI 10.1007/s11042-020-09537-7
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   NANNI L, 2019, ARXIV191207756
   Ohashi H, 2017, TIM SER WORKSH ICML
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P56, DOI 10.1109/JBHI.2016.2633287
   Rueda FM, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020026
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stisen A, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P127, DOI 10.1145/2809695.2809718
   Um T. T., 2017, P 19 ACM INT C MULTI, P216, DOI DOI 10.1145/3136755.3136817
   Weiss G, 2012, 26 AAAI C ART INT
   Yoo SB, 2020, ETRI J, V42, P411, DOI 10.4218/etrij.2019-0245
   Yun K, 2019, ETRI J, V41, P494, DOI 10.4218/etrij.2018-0520
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 39
TC 12
Z9 12
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20991
EP 21009
DI 10.1007/s11042-021-10600-0
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628104400003
DA 2024-07-18
ER

PT J
AU Zhang, M
   Hu, HY
   Li, ZJ
   Chen, J
AF Zhang, Min
   Hu, Haiyang
   Li, Zhongjin
   Chen, Jie
TI Attention-based encoder-decoder networks for workflow recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Workflow recognition; Activity detection; Temporal action localization
AB Behavior recognition is a fundamental yet challenging task in intelligent surveillance system, which plays an increasingly important role in the process of "Industry 4.0". However, monitoring the workflow of both workers and machines in production procedure is quite difficult in complex industrial environments. In this paper, we propose a novel workflow recognition framework to recognize the behavior of working subjects based on the well-designed encoder-decoder structure. Namely, attention-based workflow recognition framework, termed as AWR. To improve the accuracy of workflow recognition, a temporal attention cell (AttCell) is introduced to draw dynamic attention distribution in the last stage of the framework. In addition, a Rough-to-Refine phase localization model is exploited to improve localization accuracy, which can effectively identify the boundaries of a specific phase instance in long untrimmed videos. Comprehensive experiments indicate a 1.4% mAP@IoU= 0.4 boost on THUMOS'14 dataset and a 3.4% mAP@IoU= 0.4 boost on hand-crafted workflow dataset detection challenge compared to the advanced GTAN pipeline respectively. More remarkably, the effectiveness of the workflow recognition system is validated in a real-world production scenario.
C1 [Zhang, Min; Hu, Haiyang; Li, Zhongjin; Chen, Jie] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Hangzhou Dianzi University
RP Hu, HY (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
EM huhaiyang@hdu.edu.cn
OI hu, haiyang/0000-0002-6070-8524; zhang, min/0000-0002-6059-3798
FU National Science Foundation of China [61572251, 61572162, 61702144,
   61802095]; Natural Science Foundation of Zhejiang Province
   [LQ17F020003]; Key Science and Technology Project Foundation of Zhejiang
   Province [2018C01012]
FX This work is supported by National Science Foundation of China (Grant
   no. 61572251, 61572162, 61702144 and 61802095), the Natural Science
   Foundation of Zhejiang Province (LQ17F020003), the Key Science and
   Technology Project Foundation of Zhejiang Province (2018C01012).
CR [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2712608
   [Anonymous], 2016, ARXIV COMPUTER VISIO
   [Anonymous], 2013, INT WORKSH IMAG ANAL
   [Anonymous], 2017, ICCV
   Bengio Y., 2014, TECHNICAL REPORT
   Blum T, 2010, LECT NOTES COMPUT SC, V6363, P400
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen YW, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0316-4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dogan E, 2015, IEEE IMAGE PROC, P4421, DOI 10.1109/ICIP.2015.7351642
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gorban A., 2015, THUMOS challenge: Action recognition with a large number of classes
   Hu HY, 2020, PATTERN RECOGN LETT, V130, P267, DOI 10.1016/j.patrec.2018.10.011
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Jin YM, 2018, IEEE T MED IMAGING, V37, P1114, DOI 10.1109/TMI.2017.2787657
   Kosmopoulos DI, 2012, COMPUT VIS IMAGE UND, V116, P422, DOI 10.1016/j.cviu.2011.09.006
   Kulkarni A., 2019, NATURAL LANGUAGE PRO, P185, DOI [10.1007/978-1-4842-4267-4_6, DOI 10.1007/978-1-4842-4267-4_6]
   Lalys F, 2012, IEEE T BIO-MED ENG, V59, P966, DOI 10.1109/TBME.2011.2181168
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Lu JS, 2015, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2015.7299000
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Makantasis K, 2016, IEEE IMAGE PROC, P1609, DOI 10.1109/ICIP.2016.7532630
   Padoy N, 2019, MINIM INVASIV THER, V28, P82, DOI 10.1080/13645706.2019.1584116
   Protopapadakis E, 2012, P 2 INT C ADV COMM C, P21
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Sharma S., 2015, NEURAL INFORM PROCES
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Tao LL, 2013, LECT NOTES COMPUT SC, V8151, P339, DOI 10.1007/978-3-642-40760-4_43
   Thomay C, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P69, DOI 10.1145/3316782.3321523
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Voulodimos A, 2012, IEEE MULTIMEDIA, V19, P42, DOI 10.1109/MMUL.2012.31
   Voulodimos A, 2011, NEURAL NETWORKS, V24, P852, DOI 10.1016/j.neunet.2011.06.001
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang Limin., 2014, THUMOS14 Action Recognition Challenge
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Zaremba W., 2014, ARXIV
   Zhang L, 2018, XIOLIFT DATABASE
   Zhang QL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P561, DOI 10.1145/2733373.2806224
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
NR 44
TC 5
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 34973
EP 34995
DI 10.1007/s11042-021-10633-5
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000625713700009
DA 2024-07-18
ER

PT J
AU Rao, RV
   Prasad, TJC
AF Rao, R. Varaprasada
   Prasad, T. Jaya Chandra
TI Content-based medical image retrieval using a novel hybrid scattering
   coefficients - bag of visual words - DWT relevance fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scattering transform; Bag of visual word; Discrete wavelet transform;
   Grey wolf optimization; Particle swarm optimization; Contrast limited
   adaptive histogram equalization
ID FEATURE DESCRIPTOR; PATTERNS; TEXTURE; CLASSIFICATION; HISTOGRAM
AB Image content analysis plays a major role in image classification, retrieval, and indexing together with object and scene recognition. Numerous image content descriptors are proposed in the literature, but their high computational costs and lower-performance scores make them inappropriate for content-based medical image retrieval (CBMIR) for large medical image datasets. To overcome these drawbacks, a novel hybrid Scattering Coefficients - Bag of Visual Words - Discrete Wavelet Transform (SC-BoVW- DWT) relevance fusion algorithm is proposed for effective CBMIR. For preprocessing, resizing and contrast limited adaptive histogram equalization (CLAHE) are carried out. Then scattering transform (ST), BoVW and DWT are applied to extract texture features, visual features, and low-level features of the preprocessed images respectively. A hybrid Grey Wolf Optimization - Particle Swarm Optimization (GWO-PSO) approach is used for optimal feature selection. Finally, image fusion (IF) is carried out with a relevance fusion based Euclidean distance technique. Experiments based on three standard medical computer tomography image databases namely, EXACT-09, TCIA-CT and NEMA-CT, are carried out. The proposed hybrid method outperforms the existing techniques in terms of precision, F-score, and recall values. Improvement in the average rate of precision (ARP), average rate of recall (ARR) and F-score values of 6.02%, 2.82% and 3.57% respectively, for the EXACT-09 dataset and 3.55%, 1.84%, and 2.12% respectively for the TCIA-CT dataset are observed compared with the existing Scattering Transform- canonical correlation analysis vertical projection (ST-CCA(v)). For NEMA-CT an improvement of 0.21% (ARP) is obtained compared with the existing Histogram of compressed scattering coefficients (HCSC).
C1 [Rao, R. Varaprasada; Prasad, T. Jaya Chandra] JNTUA, Rajeev Gandhi Mem Coll Engn & Technol, Dept Elect & Commun Engn, Nandyal, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Rao, RV (corresponding author), JNTUA, Rajeev Gandhi Mem Coll Engn & Technol, Dept Elect & Commun Engn, Nandyal, Andhra Pradesh, India.
EM rvr712@gmail.com
RI Talari, Jayachandra Prasad/P-2766-2019
OI Talari, Jayachandra Prasad/0000-0002-7804-982X
CR Ahmad J, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0875-4
   Amrani M, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281707
   Bressan RS, 2018, COMP MED SY, P158, DOI 10.1109/CBMS.2018.00035
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Das P, 2017, INT J MULTIMED INF R, V6, P271, DOI 10.1007/s13735-017-0135-x
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Jenitta A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0799-z
   Jyothi B., 2015, 2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO), P1, DOI 10.1109/ISCO.2015.7282301
   Kim J, 2016, IEEE T VEH TECHNOL, V65, P1150, DOI 10.1109/TVT.2015.2414936
   Kitanovski I, 2017, MULTIMED TOOLS APPL, V76, P2955, DOI 10.1007/s11042-016-3261-1
   Kumar A, 2015, IEEE J BIOMED HEALTH, V19, P1734, DOI 10.1109/JBHI.2014.2361318
   Kumar SS., 2019, MED IMAGE FUSION UDW
   Kumar TGS, 2019, PATTERN ANAL APPL, V22, P1233, DOI 10.1007/s10044-018-0724-1
   Kumar TGS, 2018, SIGNAL IMAGE VIDEO P, V12, P591, DOI 10.1007/s11760-017-1197-1
   Lan RS, 2018, COMPUT ELECTR ENG, V69, P669, DOI 10.1016/j.compeleceng.2018.01.027
   Lan RS, 2017, IEEE J BIOMED HEALTH, V21, P1338, DOI 10.1109/JBHI.2016.2623840
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li L, 2018, J CENT SOUTH UNIV, V25, P259, DOI 10.1007/s11771-018-3735-6
   Lo P, 2012, IEEE T MED IMAGING, V31, P2093, DOI 10.1109/TMI.2012.2209674
   Ma YB, 2017, IEEE J BIOMED HEALTH, V21, P1114, DOI 10.1109/JBHI.2016.2611615
   Mehmood Z, 2018, APPL INTELL, V48, P166, DOI 10.1007/s10489-017-0957-5
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Muramatsu C, 2018, RADIOL PHYS TECHNOL, V11, P109, DOI 10.1007/s12194-018-0461-6
   Bedo MVN, 2016, J DIGIT IMAGING, V29, P22, DOI 10.1007/s10278-015-9809-1
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Panchal P.M., 2013, International Journal of Innovative Research in Computer and Communication Engineering, V1
   Qiu CY, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Renuka Devi B, 2016, ELIXIR INT J ELIXIR, V96, P41229
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Rocha R, 2015, COMP MED SY, P370, DOI 10.1109/CBMS.2015.43
   Shinde A, 2019, MULTIMED TOOLS APPL, V78, P23489, DOI 10.1007/s11042-019-7697-y
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tirupal T., 2021, Current Signal Transduction Therapy, V16, P142, DOI 10.2174/1574362415666200226103116
   Tirupal T, 2018, ADV INTELLIGENT SYST, V799, DOI [10.1007/978-981-13-1135-2_37, DOI 10.1007/978-981-13-1135-2_37]
   Varish N, 2018, APPL INTELL, V48, P2930, DOI 10.1007/s10489-017-1125-7
   WHOAN LEE JOON, 2015, International Journal of Fuzzy Logic and Intelligent systems, V15, P35
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 44
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11815
EP 11841
DI 10.1007/s11042-020-10415-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200004
DA 2024-07-18
ER

PT J
AU Mahajan, S
   Mittal, N
   Pandit, AK
AF Mahajan, Shubham
   Mittal, Nitin
   Pandit, Amit Kant
TI Image segmentation using multilevel thresholding based on type II fuzzy
   entropy and marine predators algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Digital image; Type II fuzzy entropy;
   Stochastic optimization; Marine predators algorithm; Evolutionary
   computation
AB The digital image segmentation is an open problem that is growing day by day and is attracting the attention of researchers from last few years. Image resolution and their speed has led to the use of thresholding approaches. Image thresholding is simple, easy and effective method for image segmentation. Multi-level image thresholding is a key perspective in several real-time pattern recognition and image processing-based applications. It identifies pixels quickly and effectively in different groups indicating multiple regions in an image. Segmentation of images based on thresholding by using various intelligent optimization techniques with fuzzy entropy is widely utilized for defining thresholds in a better way to use them precisely. In this research, a novel technique for multi-level thresholding is proposed by combining Fuzzy Entropy Type II (FE-TII) with recently developed meta-heuristics named Marine Predators Algorithm (MPA). For achieving optimal thresholds of an image, the maximization of entropy is tedious and consumes a lot of time with an increasing number of thresholds. The MPA method presented is analyzed in context with image segmentation, particularly on thresholds with TII-FE. For this reason, proposed methodology is evaluated using several images along with the distribution of histograms. For analyzing the performance efficiency of the proposed methodology, the results are compared and robustness is tested with efficiency of proposed technique to multi-level image segmentation, several images are used randomly from datasets.
C1 [Mahajan, Shubham; Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra 182320, J&K, India.
   [Mittal, Nitin] Chandigarh Univ, Dept Elect & Commun Engn, Mohali 140413, Punjab, India.
C3 Shri Mata Vaishno Devi University; Chandigarh University
RP Mahajan, S (corresponding author), Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra 182320, J&K, India.
EM mahajanshubham2232579@gmail.com; mittal.nitin84@gmail.com;
   amitkantpandit@gmail.com
RI MAHAJAN, SHUBHAM/AAY-6389-2020
OI MAHAJAN, SHUBHAM/0000-0003-0385-3933; mittal, nitin/0000-0003-0758-2755
CR Abd Elaziz M, 2020, SOFT COMPUT, V24, P14885, DOI 10.1007/s00500-020-04842-7
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   [Anonymous], 1992, R. woods digital image processing
   Bartumeus F, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.097901
   Benzid R., 2008, 5 INT MULT SYST SIGN, P1, DOI DOI 10.1109/SSD.2008.4632831
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Burman R, 2013, LECT NOTES COMPUT SC, V8297, P274, DOI 10.1007/978-3-319-03753-0_25
   Castillo O, 2017, INFORMATION, V8, DOI 10.3390/info8030097
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Faramarzi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113377
   Filmalter JD, 2011, B MAR SCI, V87, P325, DOI 10.5343/bms.2010.1057
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kumar S, 2013, MEMET COMPUT, V5, P323, DOI 10.1007/s12293-013-0123-5
   Lan S, 2010, SEGMENTATION APPROAC
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Miao QG, 2015, NEUROCOMPUTING, V168, P808, DOI 10.1016/j.neucom.2015.05.043
   Mostafa A, 2017, MULTIMED TOOLS APPL, V76, P24931, DOI 10.1007/s11042-017-4638-5
   Oliva D, 2015, EXPERT SYST APPL, V42, P5874, DOI 10.1016/j.eswa.2015.03.028
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   Oliva D, 2013, J APPL MATH, DOI 10.1155/2013/575414
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Parouha RP, 2016, APPL SOFT COMPUT, V38, P501, DOI 10.1016/j.asoc.2015.10.022
   Premaratne U, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, P279, DOI 10.1109/ICIINFS.2009.5429852
   Riomoros I., 2010, 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR 2010), P462, DOI 10.1109/SOCPAR.2010.5685936
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Salhi A., 2011, INT C NUM AN OPT, VK2, DOI [10.13140/2.1.3262.0806, DOI 10.13140/2.1.3262.0806]
   Sarkar S, 2012, LECT NOTES COMPUT SC, V7677, P17, DOI 10.1007/978-3-642-35380-2_3
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Talbi E-G, 2009, Metaheuristics: from Design to Implementation, DOI DOI 10.1002/9780470496916
   Talbi EG, 2002, J HEURISTICS, V8, P541, DOI 10.1023/A:1016540724870
   Tao WB, 2003, PATTERN RECOGN LETT, V24, P3069, DOI 10.1016/S0167-8655(03)00166-1
   Tian WJ, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 1, PROCEEDINGS, P38, DOI 10.1109/APCIP.2009.18
   Tizhoosh H.R., 2008, FUZZY SETS THEIR EXT
   Tizhoosh HR, 2005, PATTERN RECOGN, V38, P2363, DOI 10.1016/j.patcog.2005.02.014
   TIZHOOSH HR, 1998, FUZZY IMAGE PROCESSI
   Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743
NR 42
TC 41
Z9 41
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19335
EP 19359
DI 10.1007/s11042-021-10641-5
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622247800003
DA 2024-07-18
ER

PT J
AU Ansari, SA
   Pal, K
   Govil, MC
   Ahmed, M
   Chawla, T
   Choudhary, A
AF Ansari, Sarfaraj Alam
   Pal, Kunwar
   Govil, Mahesh Chandra
   Ahmed, Mushtaq
   Chawla, Tanvi
   Choudhary, Anita
TI Score-based Incentive Mechanism (SIM) for live multimedia streaming in
   peer-to-peer network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-to-peer network; Live multimedia streaming; Incentive mechanism;
   Score-based mechanism
ID FREE-RIDING BEHAVIOR; SCHEDULING SCHEME; REPUTATION; MODEL; OVERLAY;
   ROBUST; SYSTEM; TRUST
AB A decentralized model is primarily used for communication and file transfer, the peer-to-peer network is based on this model. The field of real-time communication and media streaming has witnessed enormous growth in recent times owing to their use of peer-to-peer network. A significant part of Internet traffic is being created by the peer-to-peer network resulting in an increase in its demand. The rise in prominence of peer-to-peer network can be attributed to its properties like resource utilization and distributed nature. Resource utilization of peer-to-peer network is one foremost motive for selecting this network over the traditional client-server architecture. The availability of selfish peer or free riders affects the total resource utilization and degrades the performance of the network. So, there is a requirement of an incentive-based mechanism to motivate the selfish peer or free riders in the network to improve the performance of the network. In this paper, we will discuss a new score based incentive mechanism to improve the overall resource utilization. This approach is based on a reward-punishment based method, so the peers are encouraged or motivated to share more resources and chastise selfish peers. For calculating the score value of a peer, parameters like upload capacity, video quality, control packets, a time period for which peers stay in the network can be used. Different score values are assigned for different parameters. The simulation results presented in this paper verify the approach and illustrate that the quality of video and performance of network improves using our new score based incentive mechanism. The parameters used for calculating the performances are; end-to-end delay, playback delay, start-up delay, and frame redundancy etc.
C1 [Ansari, Sarfaraj Alam] Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Sikkim, India.
   [Pal, Kunwar] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
   [Govil, Mahesh Chandra; Ahmed, Mushtaq; Chawla, Tanvi; Choudhary, Anita] Malaviya Natl Inst Technol Jaipur, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Sikkim; National Institute of Technology (NIT System); Dr B R
   Ambedkar National Institute of Technology Jalandhar; National Institute
   of Technology (NIT System); Malaviya National Institute of Technology
   Jaipur
RP Pal, K (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM mdsarfarajalam@gmail.com; kunwar.11mar@gmail.com; govilmc@gmail.com;
   mahmed.cse@mnit.ac.in; tanvi90.chawla@gmail.com; anitach312@gmail.com
RI PAL, KUNWAR/A-5785-2019; Ansari, Md. Sarfaraj Alam/JBJ-3548-2023; Ahmed,
   Mushtaq/GSN-9818-2022
OI PAL, KUNWAR/0000-0001-9482-696X; Ansari, Md. Sarfaraj
   Alam/0000-0002-9716-7012; 
CR Adar E., 2000, First Monday, V5, DOI 10.5210/fm.v5i10.792
   Alotibi B, 2019, PROCEDIA COMPUT SCI, V151, P1060, DOI 10.1016/j.procs.2019.04.150
   Anagnostakis KG, 2004, INT CON DISTR COMP S, P524, DOI 10.1109/ICDCS.2004.1281619
   [Anonymous], 2010, CONSUM COMM NETWORK
   Antoniadis P., 2007, Digital Information Management, P756
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Benazir SAM, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Bocek T, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P653
   Buragohain C, 2003, THIRD INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING (P2P2003), PROCEEDINGS, P48, DOI 10.1109/PTP.2003.1231503
   Byun H, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P840
   Chang JS, 2014, J SUPERCOMPUT, V69, P1382, DOI 10.1007/s11227-014-1204-z
   Cho JH, 2018, IEEE T DEPEND SECURE, V15, P151, DOI 10.1109/TDSC.2016.2530705
   Cohen B., 2003, WORKSH EC PEER TO PE
   Devadkar, 2019, 2019 INT C COMM SIGN
   Dorji D, 2016, INT JOINT CONF COMP, P487
   Feldman M., 2004, EC 04, P102, DOI [10.1145/988772.988788, DOI 10.1145/988772.988788]
   Feldman M, 2005, ACM SIGECOM EXCH, V5, P41
   Golle P, 2001, LECT NOTES COMPUTER, P75, DOI DOI 10.1007/3-540-45598-1_9
   Gupta R, 2004, IEEE INT CONF NETWOR, P624
   Hsu TH, 2020, IEEE ACCESS, V8, P95574, DOI 10.1109/ACCESS.2020.2995274
   Index CVN, 2015, FORECAST METHODOLOGY
   Iosifidis G, 2008, INT WORKSH QUAL SERV, P22
   Irwin D., 2005, P2PECON '05, P93
   Kamvar M. T., 2003, P 12 INT C WORLD WID, P640
   Kan Zhang, 2009, Proceedings of the 2009 First International Conference on Advances in P2P Systems (AP2PS 2009), P45, DOI 10.1109/AP2PS.2009.15
   Karakaya M, 2008, COMPUT NETW, V52, P675, DOI 10.1016/j.comnet.2007.11.002
   Li B, 2007, IEEE J SEL AREA COMM, V25, P1627, DOI 10.1109/JSAC.2007.071203
   Li MC, 2019, KNOWL-BASED SYST, V166, P156, DOI 10.1016/j.knosys.2018.12.024
   Lian Q., 2007, P 27 INT C DISTRIBUT, P56, DOI DOI 10.1109/ICDCS.2007.84
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Liu Y, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1379
   Lu K, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P2049, DOI 10.1109/FSKD.2015.7382266
   Lua EK, 2005, IEEE COMMUN SURV TUT, V7, P72, DOI 10.1109/COMST.2005.1610546
   Ma RTB, 2006, IEEE ACM T NETWORK, V14, P978, DOI 10.1109/TNET.2006.882904
   Magharei N., 2006, P 2006 INT WORKSHOP, P1
   Magnetto A, 2010, IEEE T MULTIMEDIA, V12, P901, DOI 10.1109/TMM.2010.2077623
   Montazeri Alireza, 2011, 2011 International Conference on Information Networking (ICOIN), P108, DOI 10.1109/ICOIN.2011.5723143
   NISHI Y, 2020, CONSUM COMM NETWORK
   Pal K, 2019, MULTIMED TOOLS APPL, V78, P33679, DOI 10.1007/s11042-019-08010-4
   Pal K, 2018, MULTIMED TOOLS APPL, V77, P24427, DOI 10.1007/s11042-018-5741-y
   Pal K, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3440
   Pal K, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P431, DOI 10.1109/ICACCI.2015.7275647
   Peng F, 2017, MULTIMED TOOLS APPL, V76, P3235, DOI 10.1007/s11042-016-3710-x
   Reiter M., 2006, CARNEGIE MELLON, V703, P06
   Romero Victor  II, 2015, Information Science and Applications, P143, DOI 10.1007/978-3-662-46578-3_17
   Saeed S, 2009, NDT: 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKED DIGITAL TECHNOLOGIES, P504, DOI 10.1109/NDT.2009.5272098
   Seeling P, 2012, IEEE COMMUN SURV TUT, V14, P1142, DOI 10.1109/SURV.2011.082911.00067
   Shabut AM, 2018, J NETW COMPUT APPL, V123, P32, DOI 10.1016/j.jnca.2018.07.008
   Shahriar I, 2016, INT CONF COMPUT NETW, P729
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P10083, DOI 10.1007/s11042-016-3599-4
   Tang Z, 2018, IEEE T INF FOREN SEC, V13, P2047, DOI 10.1109/TIFS.2018.2807793
   Tian Junfeng, 2010, Journal of Electronics (China), V27, P59, DOI 10.1007/s11767-009-0018-2
   Venkataraman V., 2006, 5 INT WORKSH PEER TO
   Wang EK, 2020, FUTURE GENER COMP SY, V102, P14, DOI 10.1016/j.future.2019.07.034
   Wang FL, 2007, SER CONTEMP CHINA, V10, P49
   Wang HL, 2018, INT CONF CONTR AUTO, P526, DOI 10.1109/ICCAIS.2018.8570670
   Wang Xing-Wei, 2012, 2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA 2012). Proceedings, P1030, DOI 10.1109/ICIEA.2012.6360874
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
   Yang B., 2003, Proceedings of the 10th ACM conference on Computer and communications security, P300
   Yang QW, 2016, MULTIMED TOOLS APPL, V75, P10201, DOI 10.1007/s11042-015-3079-2
   Yao J, 2018, J SUPERCOMPUT, V74, P7003, DOI 10.1007/s11227-018-2596-y
   Yu B, 2004, 2004 IEEE 1ST SYMPOSIUM ON MULTI-AGENT SECURITY & SURVIVABILITY, P1
   Zhang J, 2021, IEEE T DEPEND SECURE, V18, P722, DOI 10.1109/TDSC.2019.2904274
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhang Z, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5264526
   Zhou RF, 2007, IEEE T PARALL DISTR, V18, P460, DOI 10.1109/TPDS.2007.1015
NR 66
TC 6
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19263
EP 19290
DI 10.1007/s11042-021-10709-2
EA FEB 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621742800005
DA 2024-07-18
ER

PT J
AU Goyal, LM
   Mittal, M
   Kumar, M
   Kaur, B
   Sharma, M
   Verma, A
   Kaur, I
AF Goyal, Lalit Mohan
   Mittal, Mamta
   Kumar, Munish
   Kaur, Bhavneet
   Sharma, Meenakshi
   Verma, Amit
   Kaur, Iqbaldeep
TI An efficient method of multicolor detection using global optimum
   thresholding for image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi color detection; RGB color space; Optimum thresholding;
   Efficiency; Computational time; Image segmentation
ID COLOR SEGMENTATION; RECOGNITION; MODEL; RGB
AB Image segmentation is a key step in the image analysis, pattern recognition, low-level vision, medical data analysis, objects tracking, recognition task and grasping of things from the field of robotics. Being a problematic and demanding chore in image processing, it governs the eminence of absolute outcomes of image analysis. The method aims to improve color detection using formulations in RGB arrays. First targeted color is selected and identified the desired color location by sliding window techniques. Then threshold has been calculated using the summation of within and between the class variance of the selected color. Proposed method overcomes the limitation of complex, the dearth incorrectness, and steadiness of conventional multilevel thresholding for image segmentation. This work is tested on a different kind of images such as two-dimensional images, low-quality images, complex images, blur images, and medical images. The simulated results designate the maximum accuracy and minimum computational time over other methods.
C1 [Goyal, Lalit Mohan] JC Bose Univ Sci Technol, YMCA, Dept Comp Engn, Faridabad, India.
   [Mittal, Mamta] GB Pant Govt Engn Coll, Dept CSE, New Delhi, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Kaur, Bhavneet; Sharma, Meenakshi] Chandigarh Univ, Univ Inst Comp, Mohali, Punjab, India.
   [Verma, Amit; Kaur, Iqbaldeep] Chandigarh Grp Coll, Dept Comp Sci & Engn, Chandigarh, Punjab, India.
C3 J.C. Bose University of Science & Technology, YMCA; Chandigarh
   University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM lalitgoyal78@gmail.com; mittalmamta79@gmail.com; munishcse@gmail.com;
   bhavneetkaur20121@gmail.com; meenakshi13234@gmail.com;
   dramitverma.cu@gmail.com; eriqbaldeepkaur@gmail.com
RI Sharma, Meenakshi/AAW-5493-2021; Kaur, Bhavneet/IZE-0785-2023; Kumar,
   Munish/P-7756-2018; Mittal, Mamta/AAC-2229-2020; GOYAL, LALIT
   MOHAN/AAH-4030-2020
OI Kumar, Munish/0000-0003-0115-1620; Mittal, Mamta/0000-0003-0490-4413;
   GOYAL, LALIT MOHAN/0000-0003-4618-0281
CR Alsultanny YA, 2009, ELE COM ENG, P63
   [Anonymous], 2012, IEEE INT C MICR
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Batavia PH, 2001, IEEE INT CONF ROBOT, P705, DOI 10.1109/ROBOT.2001.932633
   Benalla M, 2003, IEEE18231826
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Chavolla E, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2786952
   Chen JQ, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P777, DOI 10.1109/ICIP.2002.1039087
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Díaz-Cortés MA, 2017, INTEL SYST REF LIBR, V129, P59, DOI 10.1007/978-3-319-57813-2_4
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   Ghamisi P, 2013, PROC SPIE, V8892, DOI 10.1117/12.2027641
   Goel Vishesh, 2017, Int. J. Comput. Appl., V161, P38
   Gothwal R., 2014, COLOR IMAGE SEGMENTA, P1
   He YH, 2004, IEEE T INTELL TRANSP, V5, P309, DOI 10.1109/TITS.2004.838221
   Hyams J, 2000, AUTON ROBOT, V9, P7, DOI 10.1023/A:1008963932386
   Islam T, 2017, GLOBAL J COMPUTER SC, V17, P32
   Kaur M., 2015, IOSR J ELECT COMMUNI, V10, P35
   Latha, INT ENG, V8, P443
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   Milotta FLM, 2020, PATTERN RECOGN LETT, V131, P135, DOI 10.1016/j.patrec.2019.12.008
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Niraimathi S., 2017, INT J COMPUT SCI MOB, V6, P430
   Nummiaro K., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P353
   Palus H., 2007, INT C MACH LEARN CYB, P1
   Pinho TM, 2017, J SENSORS, V2017, DOI 10.1155/2017/7321950
   Pujol FA, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19010026
   Rahmat RF, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P391, DOI 10.1109/ICCOINS.2016.7783247
   Rajinikanth V, 2015, PROCEDIA COMPUT SCI, V46, P1449, DOI 10.1016/j.procs.2015.02.064
   Raval K., 2017, EUR J ADV ENG TECHNO, V4, P194
   Safuan SNM, 2018, MEASUREMENT, V116, P543, DOI 10.1016/j.measurement.2017.11.002
   Srivastava DK, 2016, SMART INNOV SYST TEC, V51, P47, DOI 10.1007/978-3-319-30927-9_5
   Su QH, 2013, COMPUT INTEL NEUROSC, V2013, DOI 10.1155/2013/231916
   Sun T.-Y., 2006, IEEE INTELL TRANSP S, P1168, DOI DOI 10.1109/ITSC.2006.1707380
   Tanaka J, 2001, TRENDS COGN SCI, V5, P211, DOI 10.1016/S1364-6613(00)01626-0
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   Verma O. P., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P500, DOI 10.1109/CSNT.2011.107
   Wang JS, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING, FINANCE ANALYSIS SECTION, P19
   Wu MN, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P245
   Xuan L, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.2.023101
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Ying ZQ, 2017, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2017.7952418
   Zhan Q., 2009, Laser scanning, V38, P155
NR 43
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18969
EP 18991
DI 10.1007/s11042-020-10365-y
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000620422600002
DA 2024-07-18
ER

PT J
AU Abdulsattar, FS
AF Abdulsattar, Fatimah Shamsulddin
TI Towards a high capacity coverless information hiding approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eigen decomposition; Information hiding; ASCII-codes; Hiding capacity
ID PIXEL-VALUE; SYSTEM
AB Most of the coverless information hiding approaches use a set of cover images as stego-images which make them unsuitable for real-time applications. Moreover, the parameters that affect the hiding capacity and the robustness against image processing attacks are not explicitly studied. This paper explores the effectiveness of coverless information hiding using only one cover image to transmit secret information based on eigen decomposition. The proposed approach performs coverless information hiding by establishing mapping relationships between the hash codes of the image blocks and the characters of the secret message. The hash code is calculated by splitting the block into 9 sub-blocks and then comparing the largest eigenvalues of the sub-blocks according to four arrangements. To speed up the embedding process, we build a lookup table to store the pre-computed hash codes with the corresponding block locations. The approach has three important parameters: overlapping blocks, arrangements of sub-blocks, and block sizes. Several experiments are conducted to analyze the effect of these parameters on performance. The results of the analyses indicate that the overlapping between image blocks is necessary to generate a sufficient number of unique hash codes. Otherwise, the embedding process could not be completed using a single image. The arrangement between sub-blocks has a lower impact on the number of unique hash codes and the resilience against image processing attacks. The block size is another important parameter. As the block size increases, the hiding capacity decreases and the resilience against image processing attacks improves. Compared with other coverless information hiding approaches, the proposed approach has a higher hiding capacity and better resilience against image processing attacks. Moreover, the approach has short execution time and better resistance to detecting tools.
C1 [Abdulsattar, Fatimah Shamsulddin] Mustansiriyah Univ, Dept Comp Engn, Engn Coll, Baghdad, Iraq.
C3 Mustansiriya University
RP Abdulsattar, FS (corresponding author), Mustansiriyah Univ, Dept Comp Engn, Engn Coll, Baghdad, Iraq.
EM fsa@uomustansiriyah.edu.iq
RI Abdulsattar, Fatimah Shamsulddin/N-8671-2017
OI Abdulsattar, Fatimah Shamsulddin/0000-0001-8918-6777
FU Mustansiriyah University / Baghdad / Iraq
FX The author would like to thank Mustansiriyah University / Baghdad / Iraq
   for its support in the present work.
CR Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo YC, 2019, CMC-COMPUT MATER CON, V58, P829, DOI 10.32604/cmc.2019.03729
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Kang ZW, 2007, J SYST ENG ELECTRON, V18, P628, DOI 10.1016/S1004-4132(07)60139-X
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   McKeon R. T., 2007, 2007 IEEE INT C EL T, P178, DOI DOI 10.1109/EIT.2007.4374540
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   Sahu AK, 2019, 3D RES, V10, DOI 10.1007/s13319-018-0211-x
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhili Zhou, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P123, DOI 10.1007/978-3-319-27051-7_11
   Zhou Zhi-li, 2016, Journal of Applied Sciences - Electronics and Information Engineering, V34, P527, DOI 10.3969/j.issn.0255-8297.2016.05.005
   Zhou ZL, 2019, IEEE ACCESS, V7, P179891, DOI 10.1109/ACCESS.2019.2955990
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
   Zhou ZL, 2018, PATTERN RECOGN LETT, V109, P18, DOI 10.1016/j.patrec.2017.08.013
   Zhou ZL, 2017, J INTERNET TECHNOL, V18, P1177, DOI 10.6138/JIT.2017.18.5.20160815b
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 25
TC 6
Z9 6
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18821
EP 18837
DI 10.1007/s11042-021-10608-6
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619905700001
DA 2024-07-18
ER

PT J
AU Alsadoon, A
   Murugesan, Y
   Prasad, PWC
   Haddad, S
   Deva, A
AF Alsadoon, Abeer
   Murugesan, Yahini
   Prasad, P. W. C.
   Haddad, Sami
   Deva, Anand
TI A novel gaussian distribution and tukey weight (gdatw) algorithms:
   deformation accuracy for augmented reality (ar) in facelift surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Facelift surgery; Facial deformation; Elastic; ICP
   algorithm; Skin deformation; Shape changes; Image processing; Facial
   soft tissues
AB In facelift surgeries, tracking the exact position of the patient's facial nerves, blood vessels and other tissues can help the surgeons make the right decisions during surgery. Using Augmented Reality technologies that display the mapping of soft tissues beneath the skin, surgeons will be able to detect and locate the regions of cutting correctly prior to making the first cut. The study of Augmented Reality-assisted surgeries has not been found in facelift surgeries involving facial soft tissues, thus this journal can provide with invaluable first steps into the more concentrated studies involving this area. The current available systems in the oral and maxillofacial areas has shown limitation in supporting the elastic nature of facial soft tissues, which shape shifts and changes due to patient's movement, or movement caused by surgeon during surgery. This paper aims to increase overlay accuracy by reducing elastic deformation error for Augmented Reality in facelift surgeries. The proposed system consists of a Gaussian Distribution and Tukey Weight (GDaTW) algorithm to reduce the deformation error after the geometric error algorithm had been performed. The test results confirm that the new algorithm improves the video accuracy by similar to 0.10 mm by reducing the overlay error caused by elastic deformation with the display framerate of 5-10 frames per second compared to 10-13 frames per second in existing system. The improvement proposed in this system increases the overlay accuracy by reducing elastic deformation error. The correct display of soft tissues in the mandibular region using Augmented Reality aims to aid plastic surgeons perform facelift surgeries with confidence, to avoid making the wrong cuts of vital areas occluded by the patient's skin.
C1 [Alsadoon, Abeer; Murugesan, Yahini; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Sydney, NSW, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
   [Deva, Anand] Macquarie Univ, Fac Med & Hlth Sci, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Florey Institute of Neuroscience & Mental Health; Macquarie
   University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Australian Plastic and
   Reconstructive Surgery Research Network, ASPS/0000-0002-3818-308X; Deva,
   Anand/0000-0002-0314-7177
CR Ai DN, 2016, BIOMED OPT EXPRESS, V7, P2565, DOI 10.1364/BOE.7.002565
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chu YK, 2017, MED IMAGE ANAL, V42, P241, DOI 10.1016/j.media.2017.08.003
   Gold S., 1995, Advances in neural information processing systems, P957
   Haouchine N, 2015, IEEE T VIS COMPUT GR, V21, P584, DOI 10.1109/TVCG.2014.2377772
   Hayashi Y, 2016, INT J COMPUT ASS RAD, V11, P837, DOI 10.1007/s11548-015-1346-3
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kersten-Oertel M, 2015, INT J COMPUT ASS RAD, V10, P1823, DOI 10.1007/s11548-015-1163-8
   Kong SH, 2017, SURG ENDOSC, V31, P2863, DOI 10.1007/s00464-016-5297-8
   Lu P, 2018, IEEE T BIO-MED ENG, V65, P178, DOI 10.1109/TBME.2017.2697916
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Ng, 2018, 7 INT C COMP COMM EN, DOI [10.1109/ICCCE.2018.8539344, DOI 10.1109/ICCCE.2018.8539344]
   Nicolau S, 2011, SURG ONCOL, V20, P189, DOI 10.1016/j.suronc.2011.07.002
   Nosrati MS, 2016, INT J COMPUT ASS RAD, V11, P1409, DOI 10.1007/s11548-015-1331-x
   Puerto-Souza GA, 2014, IEEE T BIO-MED ENG, V61, P2609, DOI 10.1109/TBME.2014.2323999
   Ren S, 2019, SIGNAL PROCESS-IMAGE, V75, P1, DOI 10.1016/j.image.2019.03.008
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sagawa Ryusuke, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1558, DOI 10.1109/ICCVW.2009.5457428
   Ulrich M, 2012, IEEE T PATTERN ANAL, V34, P1902, DOI 10.1109/TPAMI.2011.266
   Wang JC, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1754
   Wang R., 2017, IEEE J BIOMED HEALTH, V12
NR 23
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15719
EP 15743
DI 10.1007/s11042-021-10590-z
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900011
DA 2024-07-18
ER

PT J
AU Miao, H
   Fei, Y
   Wang, SZ
   Wang, F
   Wen, DY
AF Miao, Hao
   Fei, Yan
   Wang, Senzhang
   Wang, Fang
   Wen, Danyan
TI Deep learning based origin-destination prediction via contextual
   information fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OD prediction; Spatio-Temporal network; Auxiliary task
ID FLOWS
AB Origin-Destination (OD) prediction which aims to predict the number of passenger's travel demands from one region to another, is critically important to many real applications including intelligent transportation systems and public safety. The challenges of this problem lie in both the dynamic patterns of the human mobility data and data sparsity in issue in some regions. Thus it is difficult to model the complex spatio-temporal correlations of the human mobility data to predict the OD of their trips. Meanwhile, the crowd flows in different regions of a city and the context features (e.g. holiday, weather and POIs) are potentially useful to alleviate the data sparsity issue and improve the OD prediction, but are largely ignored by existing works. In this paper, we propose a deep spatio-temporal framework which named Auxiliary-tasks Enhanced Spatio-Temporal Network (AEST) to more effectively address the OD prediction problem. AEST trains a model to conduct OD inference via learning crowd flow and external data as auxiliary task. The novel Hierarchical Convolutional LSTM (HC-LSTM) Network is proposed which combines CNN, GCN and LSTM to effectively capture spatiao-temporal correlations. In addition, we design a Contextual Network (ContextNet) which learns representations of contextual information to assist OD prediction. We conduct extensive experiments over bike and taxicab trip datasets in New York. The results show that our method is superior to the state-of-art approaches.
C1 [Miao, Hao; Wang, Senzhang] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Fei, Yan] Nanjing Tech Univ, Coll Comp Sci & Technol, Nanjing 211816, Peoples R China.
   [Wang, Senzhang] Collaborat Innovat Ctr Novel Software Technol & I, Nanjing 211106, Peoples R China.
   [Wang, Fang] Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
   [Wen, Danyan] Nanjing Univ Sci & Technol, Sch Econ & Management, Nanjing 210094, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing Tech
   University; Beijing Institute of Petrochemical Technology; Nanjing
   University of Science & Technology
RP Wang, SZ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.; Wang, SZ (corresponding author), Collaborat Innovat Ctr Novel Software Technol & I, Nanjing 211106, Peoples R China.
EM miaohao@nuaa.edu.cn; 201961120003@njtech.edu.cn; szwang@nuaa.edu.cn;
   fangwang@bipt.edu.cn; wendy2018@njust.edu.cn
RI Li, Kexin/KAO-2519-2024; Alidadi, Mehdi/HJZ-0235-2023; Miao,
   Hao/C-8304-2019
OI Alidadi, Mehdi/0000-0001-5183-7829; 
FU National Key R&D Program of China [2018YFB1003900]; CCF-Tencent Open
   Research Fund; Fundamental Research Funds for the Central Universities
   [NZ2020014]
FX This work is supported by National Key R&D Program of China (No.:
   2018YFB1003900), CCF-Tencent Open Research Fund and the Fundamental
   Research Funds for the Central Universities (No.: NZ2020014).
CR [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:160902907
   Ashok K, 2002, TRANSPORT SCI, V36, P184, DOI 10.1287/trsc.36.2.184.563
   Bierlaire M, 2004, OPER RES, V52, P116, DOI 10.1287/opre.1030.0071
   Cetin M, 2006, TRANSPORT RES REC, P23, DOI 10.3141/1965-03
   Chen Yue-ming, 2009, Control and Decision, V24, P1177
   Chu KF, 2020, IEEE T INTELL TRANSP, V21, P3219, DOI 10.1109/TITS.2019.2924971
   Diao ZL, 2019, AAAI CONF ARTIF INTE, P890
   Du BW, 2020, IEEE T INTELL TRANSP, V21, P972, DOI 10.1109/TITS.2019.2900481
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S., 1999, J TRANSPORTATION RES, V1678, P179, DOI DOI 10.3141/1678-22
   Lin ZQ, 2019, AAAI CONF ARTIF INTE, P1020
   Liu LB, 2019, IEEE T INTELL TRANSP, V20, P3875, DOI 10.1109/TITS.2019.2915525
   Liu Y, ARXIV170701926
   Ren JT, 2017, IEEE INT CONF MOB DA, P180, DOI 10.1109/MDM.2017.32
   Seo Y, 2018, LECT NOTES COMPUT SC, V11301, P362, DOI 10.1007/978-3-030-04167-0_33
   Shi XJ, 2015, ADV NEUR IN, V28
   Wang SZ, 2022, IEEE T KNOWL DATA EN, V34, P3681, DOI 10.1109/TKDE.2020.3025580
   Wang SZ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1555, DOI 10.1145/3340531.3412054
   Wang SZ, 2020, ACM TRANS SPAT ALGOR, V6, DOI 10.1145/3378889
   Wang YD, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1227, DOI 10.1145/3292500.3330877
   Williams BM, 2001, TRANSPORT RES REC, P194, DOI 10.3141/1776-25
   Yao HX, 2019, AAAI CONF ARTIF INTE, P5668
   Yao HX, 2018, AAAI CONF ARTIF INTE, P2588
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634
   Zhang J., 2019, IEEE T KNOWL DATA EN, P1
   Zhang JL, 2019, IEEE ACCESS, V7, P133452, DOI 10.1109/ACCESS.2019.2941177
   Zhang JB, 2017, AAAI CONF ARTIF INTE, P1655
   Zhang YX, 2021, IEEE T INTELL TRANSP, V22, P219, DOI 10.1109/TITS.2019.2955794
NR 31
TC 7
Z9 7
U1 4
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12029
EP 12045
DI 10.1007/s11042-020-10492-6
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000613057400008
DA 2024-07-18
ER

PT J
AU Rawal, K
   Sethi, G
AF Rawal, Kirti
   Sethi, Gaurav
TI Interpolating average based detrending fluctuation method for measuring
   heart rate variability in the menstrual cycle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detrended fluctuation analysis; Heart rate variability; HRV analysis
   methods; Menstrual cycle phases
ID SUDDEN CARDIAC DEATH; PHASE
AB Every woman spends her life with a cyclic occurrence of the menstrual cycle of approximately 28 days. During a menstrual cycle, there are many physical, psychological and behavioural changes in women that affect the autonomic activities of the heart. However, health management is an important factor to be considered as it influences the entire quality of women life. Thus, Heart Rate Variability (HRV) analysis is an appropriate tool to examine the physiological effects of the menstrual cycle in young healthy women. So, in this paper, Detrended Fluctuation Analysis method (DFA) is used for analyzing the HRV in the phases of the menstrual cycle. In DFA, there is a limitation of abrupt jumps in detrended profile that leads to the inaccurate detection of properties of HRV. In order to overcome the limitations of abrupt jumps in the DFA method, a novel method is proposed in this paper. The trend in proposed method is created by averaging the integrated HRV time series of each window in its respective time scale. Then, cubic interpolation is done for estimating new data points within each averaged segment. Finally, proposed trend is used to estimate scaling exponent function. The proposed method detects the properties of HRV variations accurately among phases of the menstrual cycle when applied on self-recorded dataset.
C1 [Rawal, Kirti; Sethi, Gaurav] Lovely Profess Univ, Phagwara, Punjab, India.
C3 Lovely Professional University
RP Rawal, K (corresponding author), Lovely Profess Univ, Phagwara, Punjab, India.
EM kirti.20248@lpu.co.in; gaurav.11106@lpu.co.in
CR Acharya UR, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-24
   Acharya UR, 2006, MED BIOL ENG COMPUT, V44, P1031, DOI 10.1007/s11517-006-0119-0
   Alvarez-Ramirez J, 2005, PHYSICA A, V354, P199, DOI 10.1016/j.physa.2005.02.020
   Bai XP, 2009, AM J PHYSIOL-HEART C, V297, pH765, DOI 10.1152/ajpheart.01283.2008
   Baker FC, 2008, J PSYCHOSOM RES, V65, P13, DOI 10.1016/j.jpsychores.2008.04.008
   Bashan A, 2008, PHYSICA A, V387, P5080, DOI 10.1016/j.physa.2008.04.023
   Bindiya R S., 2011, Research Journal of Pharmaceutical, Biological and Chemical Sciences, V2, P297
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Chung Min-Huey., 2011, Journal of Experimental and Clinical Medicine, P121
   Devi R, 2019, BIOCYBERN BIOMED ENG, V39, P586, DOI 10.1016/j.bbe.2019.05.011
   Ebrahimzadeh E., 2018, Trends Med. Res, V1, P1, DOI DOI 10.15761/TR.1000105
   Ebrahimzadeh E, 2019, COMPUT METH PROG BIO, V169, P19, DOI 10.1016/j.cmpb.2018.12.001
   Gao JB, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024331
   Guasti L, 1999, ACTA CARDIOL, V54, P209
   Kantelhardt JW, 2001, PHYSICA A, V295, P441, DOI 10.1016/S0378-4371(01)00144-3
   Kavitha C, 2012, INT J BIOL MED RES, V3, P2313
   KAY SM, 1981, P IEEE, V69, P1380, DOI 10.1109/PROC.1981.12184
   Kokts-Porietis RL, 2020, J PSYCHOPHYSIOL, V34, P60, DOI 10.1027/0269-8803/a000237
   Krstacic G, 2012, MED BIOL ENG COMPUT, V50, P1037, DOI 10.1007/s11517-012-0947-z
   Landén M, 2004, PSYCHONEUROENDOCRINO, V29, P733, DOI 10.1016/S0306-4530(03)00117-3
   Leicht AS, 2003, EXP PHYSIOL, V88, P441, DOI 10.1113/eph8802535
   MALIK M, 1989, MED BIOL ENG COMPUT, V27, P603, DOI 10.1007/BF02441642
   Masek O, 2009, THESIS CZECH TU PRAG
   Matsumoto T., 2006, INT C SER, V1287, P323, DOI [10.1016/j.ics.2005.09.023, DOI 10.1016/J.ICS.2005.09.023]
   Matsumoto T, 2007, BIOPSYCHOSOC MED, V1, DOI 10.1186/1751-0759-1-24
   McKinley PS, 2009, PSYCHOPHYSIOLOGY, V46, P904, DOI 10.1111/j.1469-8986.2009.00811.x
   Melillo P, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-96
   Nakagawa M, 2006, PACE, V29, P607, DOI 10.1111/j.1540-8159.2006.00407.x
   Nepal G Banskota, 2012, Nepal Med Coll J, V14, P298
   PENG CK, 1995, CHAOS, V5, P82, DOI 10.1063/1.166141
   Princi Tanja, 2005, V41, P340
   Qian XY, 2011, PHYSICA A, V390, P4388, DOI 10.1016/j.physa.2011.07.008
   Rodriguez E, 2007, PHYSICA A, V384, P429, DOI 10.1016/j.physa.2007.05.022
   Rohila A, 2020, BIOCYBERN BIOMED ENG, V40, P1140, DOI 10.1016/j.bbe.2020.06.003
   Saeki Y, 1997, J AUTONOM NERV SYST, V66, P69, DOI 10.1016/S0165-1838(97)00067-2
   SATO N, 1995, PSYCHOSOM MED, V57, P331, DOI 10.1097/00006842-199507000-00004
   Sharma RR, 2019, BIOCYBERN BIOMED ENG, V39, P312, DOI 10.1016/j.bbe.2018.10.001
   Shetty Sneha B., 2011, International Journal of Biomedical and Advance Research, P402, DOI [10.7439/ijbar.v2i10.167, DOI 10.7439/IJBAR.V2I10.167]
   Singh S., 2011, CURR NEUROBIOL, V2, P49
   Visrutha K, 2012, INT J APPL BIOL PHAR, V3, P306
   Walawalkar SR., 2014, J Med Sci Clin Res, V2, P503
   Wang XF, 2020, MULTIMED TOOLS APPL, V79, P10141, DOI 10.1007/s11042-019-08004-2
   Watanabe Nobuhiro, 2007, Chiropr Osteopat, V15, P19
   Wu WQ, 2019, IEEE J BIOMED HEALTH, V23, P703, DOI 10.1109/JBHI.2018.2832069
   Yeh JR, 2009, MED ENG PHYS, V31, P92, DOI 10.1016/j.medengphy.2008.04.011
   Yildirir A, 2002, ANN NONINVAS ELECTRO, V7, P60
NR 46
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14191
EP 14211
DI 10.1007/s11042-020-10328-3
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400015
DA 2024-07-18
ER

PT J
AU Ali, A
   Zhu, YM
   Zakarya, M
AF Ali, Ahmad
   Zhu, Yanmin
   Zakarya, Muhammad
TI A data aggregation based approach to exploit dynamic spatio-temporal
   correlations for citywide crowd flows prediction in fog computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Crowd prediction; Neural networks; Road safety; Data
   aggregation; Attention mechanism
ID TRAFFIC FLOW; LEARNING ALGORITHM; NETWORK; ENERGY
AB Accurate and timely predicting citywide traffic crowd flows precisely is crucial for public safety and traffic management in smart cities. Nevertheless, its crucial challenge lies in how to model multiple complicated spatial dependencies between different regions, dynamic temporal laws among different time intervals with external factors such as holidays, events, and weather. Some existing work leverage the long short-term memory (LSTM) and convolutional neural network (CNN) to explore temporal relations and spatial relations, respectively; which have outperformed the classical statistical methods. However, it is difficult for these approaches to jointly model spatial and temporal correlations. To address this problem, we propose a dynamic deep hybrid spatio-temporal neural network namely DHSTNet, to predict traffic flows in every region of a city with high accuracy. In particular, our DSHTNet model comprises four properties i.e., closeness volume, daily volume, trend volume, and external branch, respectively. Moreover, the projected model dynamically assigns different weights to various branches and, then, integrate outputs of four properties to produce final prediction outcomes. The model has been evaluated, both for offline and online predictions, using an edge/fog infrastructure where training happens on the remote cloud and prediction occurs at the edge i.e. in the proximity of users. Extensive experiments and evaluation on two real-world datasets demonstrate the advantage of the proposed model, in terms of high accuracy over prevailing state-of-the-art baseline methods. Moreover, we apply the exaggeration approach based on an attention mechanism to the above model, called as AAtt-DHSTNet; to predict citywide short-term traffic crowd flows; and show its notable performance in the traffic flows prediction. The aggregation method collects information from the related time series, remove redundancy and, thus, increases prediction speed and accuracy. Our empirical evaluation suggests that the AAtt-DHSTNet model is approximately 20.8% and 8.8% more accurate than the DHSTNet technique, for two different real-world traffic datasets.
C1 [Ali, Ahmad; Zhu, Yanmin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Minhang Dist, Peoples R China.
   [Zakarya, Muhammad] Abdul Wali Khan Univ, Dept Comp Sci, Mardan, Pakistan.
C3 Shanghai Jiao Tong University; Abdul Wali Khan University
RP Zhu, YM (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Minhang Dist, Peoples R China.; Zakarya, M (corresponding author), Abdul Wali Khan Univ, Dept Comp Sci, Mardan, Pakistan.
EM yzhu@sjtu.edu.cn; mohd.zakarya@awkum.edu.pk
RI Ali, Dr. Ahmad/AAC-5713-2021; Zhu, Yanmin/AAG-7589-2019; Alidadi,
   Mehdi/HJZ-0235-2023; Zakarya, Muhammad/L-5606-2013
OI Zhu, Yanmin/0000-0001-6406-4992; Alidadi, Mehdi/0000-0001-5183-7829;
   Zakarya, Muhammad/0000-0001-7070-6699; Ali, Ahmad/0000-0002-6029-5889
FU National Key Research and Development Program [2018AAA0100503,
   2018AAA0100500]; National Science Foundation of China [61772341,
   61472254, 61772338, 61672240]; ShanghaiMunicipal Science and Technology
   Commission [18511103002, 19510760500, 19511101500]; Innovation and
   Entrepreneurship Foundation for overseas high-level talents of Shenzhen
   [KQJSCX20180329191021388]; Program for Changjiang Young Scholars in the
   University of China; Program for China Top Young Talents; Program for
   Shanghai Top Young Talents; Shanghai Engineering Research Center of
   Digital Education Equipment; SJTU Global Strategic Partnership Fund
   (2019 SJTU-HKUST)
FX This research is financially supported, in part, by the National Key
   Research and Development Program (No. 2018AAA0100503, No.
   2018AAA0100500), National Science Foundation of China (No. 61772341, No.
   61472254, No. 61772338 and No. 61672240), ShanghaiMunicipal Science and
   Technology Commission (No. 18511103002, No. 19510760500, 19511101500),
   the Innovation and Entrepreneurship Foundation for overseas high-level
   talents of Shenzhen (No. KQJSCX20180329191021388), the Program for
   Changjiang Young Scholars in the University of China, the Program for
   China Top Young Talents, the Program for Shanghai Top Young Talents,
   Shanghai Engineering Research Center of Digital Education Equipment, and
   SJTU Global Strategic Partnership Fund (2019 SJTU-HKUST).
CR Abadi A, 2015, IEEE T INTELL TRANSP, V16, P653, DOI 10.1109/TITS.2014.2337238
   Abdulhai B, 2002, ITS J, V7, P3, DOI 10.1080/10248070190048664
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Altché F, 2017, IEEE INT C INTELL TR
   [Anonymous], ARXIV161201022
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Chandra SR, 2009, J INTELL TRANSPORT S, V13, P53, DOI 10.1080/15472450902858368
   Chen C, 2020, ACM T KNOWL DISCOV D, V14, DOI 10.1145/3385414
   Chen C, 2019, AAAI CONF ARTIF INTE, P485
   Chen C, 2018, IEEE DATA MINING, P893, DOI 10.1109/ICDM.2018.00107
   Chen C, 2017, IEEE T SYST MAN CY-S, V47, P2740, DOI 10.1109/TSMC.2017.2690673
   Chen PT, 2014, IEEE DATA MINING, P80, DOI 10.1109/ICDM.2014.139
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen WH, 2018, FUTURE GENER COMP SY, V89, P78, DOI 10.1016/j.future.2018.06.021
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chorowski J, 2015, ADV NEUR IN, V28
   Das M, 2019, EXPERT SYST APPL, V117, P211, DOI 10.1016/j.eswa.2018.08.057
   Feng XC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4002
   Gillam L, 2018, IEEE CONF COMPUT, P148, DOI 10.1109/infcomw.2018.8406890
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jeong YS, 2013, IEEE T INTELL TRANSP, V14, P1700, DOI 10.1109/TITS.2013.2267735
   Jian-Min X, CHINA J HIGHWAY TRAN, V4, P118
   Khan AA, 2020, J NETW COMPUT APPL, V150, DOI 10.1016/j.jnca.2019.102497
   Khan AA, 2019, SIMUL MODEL PRACT TH, V92, P82, DOI 10.1016/j.simpat.2018.12.001
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XL, 2012, FRONT COMPUT SCI-CHI, V6, P111, DOI 10.1007/s11704-011-1192-6
   Li Z, ARXIV180301254
   Liang YX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3428
   Lippi M, 2013, IEEE T INTELL TRANSP, V14, P871, DOI 10.1109/TITS.2013.2247040
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Ma XL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040818
   Moreira-Matias L, 2013, IEEE T INTELL TRANSP, V14, P1393, DOI 10.1109/TITS.2013.2262376
   Shekhar S, 2007, TRANSPORT RES REC, P116, DOI 10.3141/2024-14
   Shi XJ, 2015, ADV NEUR IN, V28
   Sun SL, 2006, IEEE T INTELL TRANSP, V7, P124, DOI 10.1109/TITS.2006.869623
   Sutskever Ilya, 2011, P 28 INT C MACH LEAR, P1017
   Tong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1653, DOI 10.1145/3097983.3098018
   Van Lint J.W.C., 2012, Artificial Intelligence Applications to Critical Transportation Issues, V22, P22
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2012, INT CONF ACOUST SPEE, P4085, DOI 10.1109/ICASSP.2012.6288816
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wei H, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2203, DOI 10.1145/2983323.2983667
   Williams BM, 2003, J TRANSP ENG, V129, P664, DOI 10.1061/(ASCE)0733-947X(2003)129:6(664)
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu ZR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2940
   Yang ZL, 2016, ADV NEUR IN, V29
   Yao HX, 2019, AAAI CONF ARTIF INTE, P5668
   Yu Rose, 2017, 2017 SIAM INT C DAT, P777, DOI DOI 10.1137/1.9781611974973.87
   Zakarya M, 2019, FUTURE GENER COMP SY, V93, P529, DOI 10.1016/j.future.2018.10.044
   Zeng Z, 2019, PATTERN RECOGN LETT, V128, P23, DOI 10.1016/j.patrec.2019.08.002
   Zhang J., 2019, IEEE T KNOWL DATA EN, P1
   Zhang J, 2017, PROCEEDINGS OF THE ASME 11TH INTERNATIONAL CONFERENCE ON ENERGY SUSTAINABILITY, 2017
   Zhang JB, 2018, ARTIF INTELL-AMST, V259, P147, DOI 10.1016/j.artint.2018.03.002
   Zhang JB, 2016, 24TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2016), DOI 10.1145/2996913.2997016
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001
   Zhang LN, 2019, INFRARED PHYS TECHN, V99, P1, DOI [10.1109/TNNLS.2019.2944455, 10.1016/j.infrared.2019.03.035]
   Zhou YR, 2020, INFORM SCIENCES, V513, P372, DOI 10.1016/j.ins.2019.10.071
   Zivot E., 2006, Modeling Financial Time Series with S-PLUS, P385, DOI [DOI 10.1007/978-0-387-32348-0, 10.1007/978-0-387-21763-5_11, DOI 10.1007/978-0-387-21763-5_11]
   Zong-Yuan M, CHINA J HIGHWAY TRAN, V13, P83
NR 65
TC 142
Z9 145
U1 10
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31401
EP 31433
DI 10.1007/s11042-020-10486-4
EA JAN 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000608669700001
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Portalés, C
   Pérez, M
   Casanova-Salas, P
   Gimeno, J
AF Portales, Cristina
   Perez, Manolo
   Casanova-Salas, Pablo
   Gimeno, Jesus
TI Virtual Loom: a tool for the interactive 3D representation of historical
   fabrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D modelling; Fabrics; Designs; Interaction; Image analysis
ID CULTURAL-HERITAGE; AUGMENTED REALITY; RECONSTRUCTION
AB 3D modelling of man-made objects is widely used in the cultural heritage sector, among others. It is relevant for its documentation, dissemination and preservation. Related to historical fabrics, weaves and weaving techniques are still mostly represented in forms of 2D graphics and textual descriptions. However, complex geometries are difficult to represent in such forms, hindering the way this legacy is transmitted to new generations. In this paper, we present the design and implementation of SILKNOW's Virtual Loom, an interactive tool aimed to document, preserve and represent in interactive 3D forms historical weaves and weaving techniques of silk fabrics, dating from the 15th to the 19th centuries. To that end, our tool only requires an image of a historical fabric. Departing from this image, the tool automatically subtracts the design, and allows the user to apply different weaves and weaving techniques. In its current version, the tool embeds five traditional weaving techniques, 39 weaves and six types of yarns, which have been defined thanks to close collaboration of experts in computer graphics, art history and historical fabrics. Additionally, users can change the color of yarns and produce different 3D representations for a given fabric, which are interactive in real time. In this paper, we bring the details of the design and implementation of this tool, focusing on the input data, the strategy to process images, the 3D modelling of yarns, the definition of weaves and weaving techniques and the graphical user interface. In the results section, we show some examples of image analysis in order to subtract the design of historical fabrics, and then we provide 3D representations for all the considered weaving techniques, combining different types of yarns.
C1 [Portales, Cristina; Perez, Manolo; Casanova-Salas, Pablo; Gimeno, Jesus] Univ Valencia, Inst Robot & Informat & Commun Technol IRTIC, Valencia, Spain.
C3 University of Valencia
RP Portalés, C (corresponding author), Univ Valencia, Inst Robot & Informat & Commun Technol IRTIC, Valencia, Spain.
EM cristina.porlales@uv.es
RI ; Portales, Cristina/K-2296-2015
OI Casanova-Salas, Pablo/0000-0003-1588-9888; Portales,
   Cristina/0000-0002-4520-2250
FU European Union [769504]; Spanish government postdoctoral grant Ramon y
   Cajal [RYC2018-025009-I]
FX The research leading to these results is in the frame of the "SILKNOW.
   Silk heritage in the Knowledge Society: from punched cards to big data,
   deep learning and visual/tangible simulations" project, which has
   received funding from the European Union's Horizon 2020 research and
   innovation program under grant agreement No. 769504. Cristina Portales
   is supported by the Spanish government postdoctoral grant Ramon y Cajal
   under award No. RYC2018-025009-I.
CR Alivizatou-Barakou M., 2017, MIXED REALITY GAMIFI, P129, DOI [10.1007/978-3-319-49607-8_5, DOI 10.1007/978-3-319-49607-8_5]
   [Anonymous], 2020, ADASILK
   [Anonymous], 2018, ESPOLINES GARIN 1820
   [Anonymous], 2005, WISETEX SOFTWARE SUI
   [Anonymous], 2020, 35D WEAVE
   [Anonymous], 2019, IMATEX
   [Anonymous], 2020, VIRT LOOM STAND VERS
   [Anonymous], 2020, SCOTWEAVE
   [Anonymous], 2019, SILKNOW VIRTUAL LOOM
   [Anonymous], 2020, SILKNOWS THESAURUS
   [Anonymous], 2015, P 14 ACM SIGGRAPHEUR
   Arbace L, 2013, J CULT HERIT, V14, P332, DOI 10.1016/j.culher.2012.06.008
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chow SK, 2009, J CULT HERIT, V10, P161, DOI 10.1016/j.culher.2008.08.011
   Dieck MCT, 2017, J DESTIN MARK MANAGE, V6, P110, DOI 10.1016/j.jdmm.2017.03.002
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   Gaitán M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050742
   Gaitán M, 2019, HERITAGE-BASEL, V2, P1892, DOI 10.3390/heritage2030115
   Galceran Escobet V., 1961, TECNOLOGIA TEJIDO TO
   Gimeno J, 2017, COMPUT GRAPH-UK, V69, P92, DOI 10.1016/j.cag.2017.09.001
   Granero-Montagud L, 2013, OPTICS ARTS ARCHITEC, V8790, P879008
   Jiang Y., 2005, Journal of the Textile Institute, V96, P237, DOI 10.1533/joti.2005.0005
   Kaldor JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360664
   Liarokapis Fotis., 2017, MIXED REALITY GAMIFI, P371
   Lomov SV, 2011, COMPOSITE REINFORCEMENTS FOR OPTIMUM PERFORMANCE, P200
   Martinez Bibiana, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020033
   Nawab Y., 2017, Structural textile design: interlacing and interlooping
   Portales Cristina, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020028
   Portales C, 2017, 3D VIRTUAL RECONSTRU, P8, DOI [10.4995/var.2017.5890, DOI 10.4995/VAR.2017.5890]
   Portalés C, 2019, LECT NOTES COMPUT SC, V11540, P733, DOI 10.1007/978-3-030-22750-0_72
   RojoIranzo L, 2020, REPORT STUDY HIST SI
   Rua H, 2011, J ARCHAEOL SCI, V38, P3296, DOI 10.1016/j.jas.2011.07.015
   TexGen, 2018, COMP RES GROUP U NOT
   Wu K., 2017, P 21 ACM SIGGRAPH S
   Zhao S., 2016, ACM T GRAPHIC, V35, P1, DOI [DOI 10.1145/2897824.2925932, 10.1145/2897824.2925932]
NR 35
TC 6
Z9 6
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13735
EP 13760
DI 10.1007/s11042-020-10294-w
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608106900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sharma, P
   Singh, A
   Singh, KK
   Dhull, A
AF Sharma, Poonam
   Singh, Akansha
   Singh, Krishna Kant
   Dhull, Anuradha
TI Vehicle identification using modified region based convolution network
   for intelligent transportation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transportation system; RCNN; Vehicle detection; Deep
   learning; Smart city
ID CLASSIFICATION
AB Intelligent transportation systems (ITS) are the integration of information and communications technologies with applications which are significant in traffic control and management. The increased number of on road vehicles in urban areas urges the need of development of automated methods for traffic management. Vehicle identification, classification and analysis enable the intelligent transportation systems to make decisions. In this paper, an automated method for video analysis for vehicle identification using a modified Region based Convolution Neural Network (RCNN) has been proposed. The traffic videos collected by CCTV cameras installed on the roads are analyzed for vehicle identification in a given frame. The pretrained google net is used to extract features. These features are used by the Region based Convolution Neural Network for vehicle identification. The vehicles are identified using probability score computed using intersection of objects (IoU). The identified vehicles are classified into ten different vehicle classes. The proposed network concatenates features from previous layers to reduce loss and consequently improve the vehicle identification accuracy. The vehicle identification method is further extended for vehicle counting and behavioral analysis. The vehicle counting information can be used for congestion control in smart cities. The behavioral analysis includes computation of speed of vehicles. The speed information is useful for traffic law enforcement in smart cities. The proposed method is applied on MIO-TCD vehicle dataset and EBVT video dataset. The results are calculated using three different metrics namely average accuracy, mean precision and mean recall. Obtained results are also compared with other state of the art methods. The results show significant improvement and thus the method can be effectively used for video analysis.
C1 [Sharma, Poonam] Amity Univ Haryana, Dept CSE, Gurugram, India.
   [Sharma, Poonam; Dhull, Anuradha] NorthCap Univ, Dept CSE, Gurugram, India.
   [Singh, Akansha] Amity Univ, Dept CSE, ASET, Noida, Uttar Pradesh, India.
   [Singh, Krishna Kant] Delhi NCR, Dept ECE, KIET Grp Inst, Ghaziabad, India.
C3 The Northcap University; Amity University Noida; KIET Group of
   Institutions
RP Singh, A (corresponding author), Amity Univ, Dept CSE, ASET, Noida, Uttar Pradesh, India.
EM akanshasing@gmail.com
RI Sharma, Poonam/ABD-5808-2020; dhull, anuradha/AAI-8971-2021; Singh,
   Krishna Kant/V-3003-2019; dhull, anuradha/AAI-8898-2021; Singh,
   Akansha/W-4033-2019
OI dhull, anuradha/0000-0002-1073-8215; Singh, Krishna
   Kant/0000-0002-6510-6768; Singh, Akansha/0000-0002-5520-8066
CR Arinaldi A, 2018, PROCEDIA COMPUT SCI, V144, P259, DOI 10.1016/j.procs.2018.10.527
   Atiq Hafiz Muhammad, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P223, DOI 10.1109/ICMLC.2010.73
   Chen YL, 2011, IEEE T IND ELECTRON, V58, P2030, DOI 10.1109/TIE.2010.2055771
   Chen ZZ, 2012, IEEE INT C INTELL TR, P951, DOI 10.1109/ITSC.2012.6338852
   Dong Z, 2014, INT C PATT RECOG, P172, DOI 10.1109/ICPR.2014.39
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Gangodkar D, 2012, IEEE T INTELL TRANSP, V13, P1738, DOI 10.1109/TITS.2012.2206076
   HILBERT EE, 1980, IEEE T VEH TECHNOL, V29, P208, DOI 10.1109/T-VT.1980.23842
   Jia YQ, 2009, PATTERN RECOGN, V42, P313, DOI 10.1016/j.patcog.2008.07.015
   Jung H, 2017, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2017.129
   Kalaki AS, 2014, 2014 IRANIAN CONFERENCE ON INTELLIGENT SYSTEMS (ICIS)
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101
   Li Y, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P110
   Li Y, 2013, IEEE T INTELL TRANSP, V14, P984, DOI 10.1109/TITS.2013.2250501
   Luo ZM, 2018, IEEE T IMAGE PROCESS, V27, P5129, DOI 10.1109/TIP.2018.2848705
   Mandellos NA, 2011, EXPERT SYST APPL, V38, P1619, DOI 10.1016/j.eswa.2010.07.083
   Mithun NC, 2012, IEEE T INTELL TRANSP, V13, P1215, DOI 10.1109/TITS.2012.2186128
   Moghaddam MJ, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P124, DOI 10.1109/AISP.2015.7123500
   Pang CCC, 2007, IEEE T INTELL TRANSP, V8, P441, DOI 10.1109/TITS.2007.902647
   Rashid N. U., 2010, 2010 6th International Conference on Electrical & Computer Engineering (ICECE 2010), P502, DOI 10.1109/ICELCE.2010.5700739
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma P, 2017, INT CONF COMPUT
   Sharma P, 2020, J DERMATOL TREAT, V31, P749, DOI 10.1080/09546634.2019.1612835
   Sivaraman S, 2009, IEEE INT VEH SYM, P399, DOI 10.1109/IVS.2009.5164311
   Sutar VB., 2012, IOSR J VLSI SIGNAL P, V1, P1, DOI [10.9790/4200-0140109, DOI 10.9790/4200-0140109]
   Theagarajan R, 2017, IEEE COMPUT SOC CONF, P906, DOI 10.1109/CVPRW.2017.125
   Unzueta L, 2012, IEEE T INTELL TRANSP, V13, P527, DOI 10.1109/TITS.2011.2174358
   Wang XC, 2019, J REAL-TIME IMAGE PR, V16, P5, DOI 10.1007/s11554-017-0712-5
   Wu BF, 2012, IEEE T INTELL TRANSP, V13, P817, DOI 10.1109/TITS.2011.2181366
   Yao YJ, 2013, IEEE INT C INTELL TR, P614, DOI 10.1109/ITSC.2013.6728299
   Zhang FK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030594
   Zhou J, 2007, IEEE T VEH TECHNOL, V56, P51, DOI 10.1109/TVT.2006.883735
NR 34
TC 14
Z9 15
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34893
EP 34917
DI 10.1007/s11042-020-10366-x
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000607504000004
DA 2024-07-18
ER

PT J
AU Abdel-Aziz, MM
   Hosny, KM
   Lashin, NA
AF Abdel-Aziz, Mostafa M.
   Hosny, Khalid M.
   Lashin, Nabil A.
TI Improved data hiding method for securing color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; DCT; Left-most significant bit; JPEG; YCbCr; PSNR; MSE;
   Hyper chaotic; Secret data
ID HIGH-CAPACITY; MEDICAL IMAGES; SCHEME; ENCRYPTION; DCT; STEGANOGRAPHY;
   DOMAIN
AB Recently, data hiding techniques have become very popular in several vital applications, especially in telemedicine. The reason for this is their ability to give good results such as high embedding capacity while preserving visual image quality as much as possible after extracting the hidden secret message. In earlier studies, many researchers have achieved the goal of reversible data hiding (RDH) algorithm. All these methods have achieved excellent results on standard and natural images. However, in the case of medical images, especially color medical images, we face the problem of how to preserve the visual quality of image contents while achieving the goals of RDH in avoiding the loss of patient data or the distortion of the diagnosing image. In this paper, we proposed a secure data hiding method using a hyper chaotic map and left-most embedding strategy. The proposed methods are hybrid, where it is applied in the DCT frequency domain and encrypted domain together as presented here. This gives a higher embedding rate and higher visual image quality than existing methods without any loss or distortion of both hidden secrets data and reconstructed image. The novelty of this paper is to embed the desired secret data in each quantized block of DCT using (8-bit LMSB) strategy for embedding process. We tested our algorithm on both color medical images and standard color images of different sizes and different formats. We evaluated the performance of our algorithm on the basis of the quality metrics MSE, PSNR, BER, SSIM, Correlation, Symbol Error Rate, additional quality evaluation metrics, execution time, and different types of geometric and signal attacks. All of these parameters are demonstrated and represented in this proposed work in detail.
C1 [Abdel-Aziz, Mostafa M.; Hosny, Khalid M.; Lashin, Nabil A.] Zagazig Univ, Dept Informat Technol, Fac Comp & Informat, Zagazig 44519, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University
RP Hosny, KM (corresponding author), Zagazig Univ, Dept Informat Technol, Fac Comp & Informat, Zagazig 44519, Egypt.
EM k_hosny@yahoo.com
RI Hosny, Khalid M./B-1404-2008
OI Hosny, Khalid M./0000-0001-8065-8977; M. Abdel-Aziz,
   Mostafa/0000-0002-8932-3513
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abd-El-Atty B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113108
   Abdelwahab O. F., 2019, J. Telecommun. Comput. Electron. Control, V17, P1168, DOI [10.12928/telkomnika.v17i3.12230, DOI 10.12928/TELKOMNIKA.V17I3.12230]
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   [Anonymous], 2020, MED MELANOMA IMAGES
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Attaby AA, 2018, AIN SHAMS ENG J, V9, P1965, DOI 10.1016/j.asej.2017.02.003
   Batra N, 2012, INT J ADV RES COMPUT, V1
   Elkamchouchi Hassan, 2017, DATA HIDING DIGITAL, DOI 10.1109/ICCES.2017.8275302
   Haque NI, 2018, 2018 5 INT C NETWORK
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   karAbatak Murat, 2018, DEV LSB METHOD USING
   Ke G, 2019, MEASUREMENT, V135, P385, DOI 10.1016/j.measurement.2018.11.074
   Khalili M, 2015, OPTIK, V126, P4367, DOI 10.1016/j.ijleo.2015.08.042
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kordov K, 2017, INT J ELECTRON TELEC, V63, P417, DOI 10.1515/eletel-2017-0061
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   PUTEAUX U, 2018, IEEE T INFORM FORENS
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Saeed MJ, 2013, J ENG SCI TECHNOL, V8, P508
   Saleem Shiffa, 2017, INT C INT COMP INSTR
   Sharma VK, 2019, INFORM COMMUNICATION, DOI 10.1007/978-981-13-1742-2_66
   Tang ZJ, 2018, OPTIK, V157, P750, DOI 10.1016/j.ijleo.2017.11.154
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Turker T, 2017, EUROPEAN J TECHNIC, V7
   Wang DQ, 2017, J SIGNAL PROCESS SYS, V87, P215, DOI 10.1007/s11265-016-1169-7
   Zaghbani S, 2017, J IMAGE GRAPHICS, V5, DOI 10.18178/joig.5.1.10-15
NR 31
TC 18
Z9 18
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12641
EP 12670
DI 10.1007/s11042-020-10217-9
EA JAN 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100002
DA 2024-07-18
ER

PT J
AU Aman, M
   Abdulkadir, SJ
   Aziz, IA
   Alhussian, H
   Ullah, I
AF Aman, Muhammad
   Abdulkadir, Said Jadid
   Aziz, Izzatdin Abdul
   Alhussian, Hitham
   Ullah, Israr
TI KP-Rank: a semantic-based unsupervised approach for keyphrase extraction
   from text data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyphrase extraction; Key concept extraction; Information retrieval;
   Information extraction; Text mining
ID FREQUENCY; LSA
AB Automatic key concept identification from text is the main challenging task in information extraction, information retrieval, digital libraries, ontology learning, and text analysis. The main difficulty lies in the issues with the text data itself, such as noise in text, diversity, scale of data, context dependency and word sense ambiguity. To cope with this challenge, numerous supervised and unsupervised approaches have been devised. The existing topical clustering-based approaches for keyphrase extraction are domain dependent and overlooks semantic similarity between candidate features while extracting the topical phrases. In this paper, a semantic based unsupervised approach (KP-Rank) is proposed for keyphrase extraction. In the proposed approach, we exploited Latent Semantic Analysis (LSA) and clustering techniques and a novel frequency-based algorithm for candidate ranking is introduced which considers locality-based sentence, paragraph and section frequencies. To evaluate the performance of the proposed method, three benchmark datasets (i.e. Inspec, 500N-KPCrowed and SemEval-2010) from different domains are used. The experimental results show that overall, the KP-Rank achieved significant improvements over the existing approaches on the selected performance measures.
C1 [Aman, Muhammad] Univ Teknol Petronas, Dept Comp & Informat Sci, Seri Iskandar, Perak, Malaysia.
   [Aman, Muhammad] Natl Database & Registrat Author NADRA, Technol & Dev Directorate, Islamabad, Pakistan.
   [Abdulkadir, Said Jadid; Aziz, Izzatdin Abdul; Alhussian, Hitham] Univ Teknol Petronas, Dept Comp & Informat Sci, Ctr Res Data Sci CeRDaS, Seri Iskandar, Perak, Malaysia.
   [Ullah, Israr] Virtual Univ Pakistan, Dept Comp Sci, Lahore, Pakistan.
C3 Universiti Teknologi Petronas; Universiti Teknologi Petronas; Virtual
   University of Pakistan
RP Abdulkadir, SJ (corresponding author), Univ Teknol Petronas, Dept Comp & Informat Sci, Ctr Res Data Sci CeRDaS, Seri Iskandar, Perak, Malaysia.
EM muhammad.aman@nadra.gov.pk; saidjadid.a@utp.edu.my;
   israr.ullah@vu.edu.pk
RI Aziz, Izzatdin Abdul/AAT-3037-2021; Aman, Muhammad/IAM-8380-2023; Jadid
   Abdulkadir, Said/T-9616-2019
OI Aziz, Izzatdin Abdul/0000-0003-2654-4463; Aman,
   Muhammad/0000-0001-9391-3535; Jadid Abdulkadir,
   Said/0000-0003-0038-3702; Ullah, Dr. Israr/0000-0001-5548-1743
FU Universiti Teknologi PETRONAS, under the Yayasan Universiti Teknologi
   PETRONAS (YUTP), Cost Centre [015LC0-119]
FX This research was fully funded and supported by Universiti Teknologi
   PETRONAS, under the Yayasan Universiti Teknologi PETRONAS (YUTP), Cost
   Centre (015LC0-119).
CR Adar E, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P606
   Aman M, 2018, IEEE ACCESS, V6, P60403, DOI 10.1109/ACCESS.2018.2875135
   Aman M, 2018, INFORMATION, V9, DOI 10.3390/info9050128
   Barker K, 2000, LECT NOTES ARTIF INT, V1822, P40
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boudin Florian, 2016, P COLING 2016 26 INT, P69
   Bougouin A., 2013, INT JOINT C NAT LANG, P543
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Chandu K., 2017, BIONLP 2017, P58, DOI DOI 10.18653/V1/W17-2307
   Danesh S., 2015, P 4 JOINT C LEX COMP, P117, DOI 10.18653/v1/s15-1013
   Danilevsky M., 2014, P 2014 SIAM INT C DA, P398
   Das Gollapalli S, 2014, AAAI CONF ARTIF INTE, P1629
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   El-Beltagy SR, 2009, INFORM SYST, V34, P132, DOI 10.1016/j.is.2008.05.002
   Florescu C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1105, DOI 10.18653/v1/P17-1102
   Frank E, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P668
   Geiss J, 2011, LATENT SEMANTIC SENT
   Gollapalli SD, 2017, AAAI CONF ARTIF INTE, P3180
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hasan K. S., 2010, P 23 INT C COMP LING, P365
   Hasan KS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1262
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   Hongyuan Zha, 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P113
   Hu Y, 2009, ASIA-PAC POWER ENERG, P2062
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Hulth A, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P537
   Kang YB, 2014, EXPERT SYST APPL, V41, P4494, DOI 10.1016/j.eswa.2014.01.006
   Kashyap A, 2016, LANG RESOUR EVAL, V50, P125, DOI 10.1007/s10579-015-9319-2
   Kim SN, 2013, LANG RESOUR EVAL, V47, P723, DOI 10.1007/s10579-012-9210-3
   Kim Su Nam, 2010, P 5 INT WORKSHOP SEM, P21, DOI 10.1007/s10579-012-9210-3
   Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150
   Kwon H, 2017, TECHNOVATION, V60-61, P15, DOI 10.1016/j.technovation.2017.01.001
   Lahiri S., 2014, ARXIV14016571
   Lewis D. D., 1995, SIGIR Forum, P246
   Li L, 2018, IEEE INT CONF BIG DA, P3111, DOI 10.1109/BigData.2018.8622189
   Liu Z., 2010, P 2010 C EMP METH NA, P366
   Liu Zhiyuan, 2009, P 2009 C EMP METH NA, P257, DOI DOI 10.3115/1699510.1699544
   Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Martinez-Romo J, 2016, J ASSOC INF SCI TECH, V67, P71, DOI 10.1002/asi.23365
   Marujo L, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P399
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Medelyan O., 2009, P 2009 C EMP METH NA, P1318
   Mendoza M, 2018, BOOSTING TEXT CLUSTE
   Merchant K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1803, DOI 10.1109/ICACCI.2018.8554831
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rafiei-Asl J, 2017, APPL SOFT COMPUT, V58, P620, DOI 10.1016/j.asoc.2017.05.014
   Rijsbergen C. J. V., 1979, Information Retrieval
   Shen Y., 2018, INT C INF SCI APPL, P401
   Süzek TÖ, 2017, TURK J ELECTR ENG CO, V25, P1784, DOI 10.3906/elk-1511-203
   Tang JP, 2012, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE OF MATRICES AND OPERATORS (MAO 2012), P171
   Teneva N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P530, DOI 10.18653/v1/P17-2084
   Tho Thi Ngoc Le, 2016, AI 2016: Advances in Artificial Intelligence. 29th Australasian Joint Conference. Proceedings: LNAI 9992, P665, DOI 10.1007/978-3-319-50127-7_58
   Tomokiyo T., 2003, P ACL 2003 WORKSH MU, P33
   Turney P., 1997, EXTRACTION KEYPHRASE
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   Turney Peter., 2003, P 18 INT JOINT C ART, P434
   Turpin A., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P11, DOI 10.1145/1148170.1148176
   Wan X., 2008, P 22 INT C COMPUTATI, P969
   Wan XJ, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1740592.1740596
   Wan Xiaojun., 2007, ANN M ASS COMPUTATIO, P552
   Wang Rui, 2014, SOFTW ENG RES C, V39
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Zhang Q., 2016, P 2016 C EMP METH NA, P836, DOI [10.18653/v1/d16-1080, DOI 10.18653/V1/D16-1080]
   Zhang Yongzheng., 2007, Journal of Digital Information Management, V5, P323
NR 66
TC 5
Z9 5
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12469
EP 12506
DI 10.1007/s11042-020-10215-x
EA JAN 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038100002
DA 2024-07-18
ER

PT J
AU Fekri-Ershad, S
AF Fekri-Ershad, Shervan
TI Cell phenotype classification using multi threshold uniform local
   ternary patterns in fluorescence microscope images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cell phenotype classification; Fluorescence microscope images; Feature
   extraction; Texture image analysis; Multi threshold uniform local
   ternary patterns
ID INVARIANT TEXTURE CLASSIFICATION; FEATURES
AB Identifying locations of protein expression in live cells plays an important role in several medical applications ranging from early disease diagnosis to monitoring effectiveness of drugs. Protein localization is directly related to their cell types. Today florescence imaging is widely used to understand biology at the cellular level. Hence, cell phenotype classification in fluorescence microscope images, is related with protein localization. Today it is performed by human, which is very time consuming with low accuracy. According to the visual structure, it can be seen that samples of a unique cell type have quite similar texture, but the texture of different cell types, are very different. In this respect, texture information can be used more widely than shape or color information, to classify types. Local ternary pattern is a noise-resistant texture descriptor that provides discriminative features. In this paper a local texture analysis descriptor is proposed titled multi threshold uniform-based local ternary patterns with notation MT-ULTP. MT-ULTP extracts local significant texture information in different locality levels. In this respect, local ternary patterns are extracted in different thresholds and finally the occurrence probability of the uniform patterns is extracted as features. MT-ULTP is a skillful combination of LTP and MLBP with novelty in feature extracting and local pattern selecting. Performance of the proposed descriptor is evaluated on 2d-hela dataset in terms of accuracy. 2d-hela is the benchmark dataset of cell phenotype images. Experimental results show that MT-ULTP provides higher classification rates than very well-known texture descriptors such as lbp-like descriptors. In other experiments, it has been shown that ignoring uniform textural patterns in the image analysis can increase the accuracy of cell phenotype classification and some other computer vision-based applications. The results also showed that extraction uniform patterns based on a combination of thresholds provide better results than the simple form in local ternary patterns. The proposed image texture descriptor is a general case which can be used in many computer vision applications to describe the image contents.
C1 [Fekri-Ershad, Shervan] Islamic Azad Univ, Najafabad Branch, Fac Comp Engn, Najafabad, Iran.
   [Fekri-Ershad, Shervan] Islamic Azad Univ, Najafabad Branch, Big Data Res Ctr, Najafabad, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Najafabad Branch, Fac Comp Engn, Najafabad, Iran.; Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Najafabad Branch, Big Data Res Ctr, Najafabad, Iran.
EM fekriershad@pco.iaun.ac.ir
RI Fekri-Ershad, Shervan/J-7600-2019
OI Fekri-Ershad, Shervan/0000-0003-1226-7610
CR Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213
   Fekri-Ershad S, 2019, MULTIMED TOOLS APPL, V78, P31121, DOI 10.1007/s11042-019-07937-y
   Fekriershad S, 2017, SENSOR REV, V37, P33, DOI 10.1108/SR-07-2016-0120
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lin D, 2017, P IEEE INT S CIRC SY
   Liu D, 2016, COMPUT BIOL MED, V72, P185, DOI 10.1016/j.compbiomed.2016.03.010
   Murphy RF, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P67, DOI 10.1109/NNSP.2002.1030018
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, ADV EXP MED BIOL, V680, P207, DOI 10.1007/978-1-4419-5913-3_24
   Nanni L, 2010, EXPERT SYST APPL, V37, P1556, DOI 10.1016/j.eswa.2009.06.062
   Nguyen LD, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351550
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Su XT, 2015, OPT EXPRESS, V23, P27558, DOI 10.1364/OE.23.027558
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang XQ, 2019, MED BIOL ENG COMPUT, V57, P1187, DOI 10.1007/s11517-018-01946-z
NR 22
TC 15
Z9 15
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12103
EP 12116
DI 10.1007/s11042-020-10321-w
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605930700002
DA 2024-07-18
ER

PT J
AU Sharma, S
   Saha, AK
   Majumder, A
   Nama, S
AF Sharma, Sushmita
   Saha, Apu Kumar
   Majumder, Arindam
   Nama, Sukanta
TI MPBOA-A novel hybrid butterfly optimization algorithm with symbiosis
   organisms search for global optimization and image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization techniques; Butterfly optimization algorithm; Symbiosis
   organisms search; Mutualism phase; Parasitism phase; MPBOA; Benchmark
   function; Image segmentation
ID ARTIFICIAL BEE COLONY; LEARNING-BASED OPTIMIZATION; DIFFERENTIAL
   EVOLUTION; THRESHOLDING METHOD; SWARM OPTIMIZATION; SELECTION; ENTROPY;
   KAPURS
AB The conventional Butterfly Optimization Algorithm (BOA) does not appropriately balance the exploration and exploitation characteristics of an algorithm to solve present-day challenging optimization problems. For the same, in this paper, a novel hybrid BOA (MPBOA, in short) is suggested, where the BOA is combined with mutualism and parasitism phases of the Symbiosis Organisms Search (SOS) algorithm to enhance the search behaviour (both global and local) of BOA. The mutualism phase is applied with the global phase of BOA, and the parasitism phase is added with the local phase of BOA to ensure a better trade-off between the global and local search of the proposed algorithm. A suit of twenty-five benchmark functions is employed to investigate its performance with several other state-of-the-art algorithms available in the literature. Also, to check its performance statistically, the Friedman rank test and t-test are carried out. The consistency of the proposed algorithm is tested with a boxplot diagram. Also, four real-world problems are solved to check the efficiency of the algorithm in solving industrial problems. Finally, the proposed MPBOA is utilized to obtain the optimal threshold in the multilevel thresholding problem of the segmentation of individual images. From the obtained results, it is found that the overall performance of the newly introduced MPBOA is satisfactory in terms of its search behaviour and convergence time to obtain global optima.
C1 [Sharma, Sushmita; Saha, Apu Kumar; Nama, Sukanta] Natl Inst Technol Agartala, Dept Math, Agartala 799046, India.
   [Majumder, Arindam] Natl Inst Technol Agartala, Dept Mech Engn, Agartala 799046, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Agartala; National Institute of Technology (NIT System);
   National Institute of Technology Agartala
RP Saha, AK (corresponding author), Natl Inst Technol Agartala, Dept Math, Agartala 799046, India.
EM apusaha_nita@yahoo.co.in
RI Saha, Apu Kumar/ABE-6548-2021; Saha, Apu Kumar/ABB-6226-2020; Majumder,
   Arindam/ABE-7026-2021
OI Saha, Apu Kumar/0000-0002-3475-018X; Majumder,
   Arindam/0000-0001-8314-1260
CR Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Ali M, 2014, APPL SOFT COMPUT, V17, P1, DOI 10.1016/j.asoc.2013.11.018
   Arora S, 2019, EXPERT SYST APPL, V116, P147, DOI 10.1016/j.eswa.2018.08.051
   Arora S, 2018, J BRAZ SOC MECH SCI, V40, DOI 10.1007/s40430-017-0927-1
   Arora S, 2017, INT J INTERACT MULTI, V4, P14, DOI 10.9781/ijimai.2017.442
   Arora S, 2017, J INTELL FUZZY SYST, V32, P1079, DOI 10.3233/JIFS-16798
   Arora S, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P220, DOI 10.1109/ISPCC.2015.7375029
   Aydilek IB, 2018, APPL SOFT COMPUT, V66, P232, DOI 10.1016/j.asoc.2018.02.025
   Badem H, 2018, APPL SOFT COMPUT, V70, P826, DOI 10.1016/j.asoc.2018.06.010
   Bekdas G, 2018, AIP CONF PROC, V1978, DOI 10.1063/1.5043887
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Chen C, 2011, INT J BIOMED IMAGING, V2011, DOI 10.1155/2011/606857
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Cheng MY, 2014, COMPUT STRUCT, V139, P98, DOI 10.1016/j.compstruc.2014.03.007
   Das AK, 2019, APPL INTELL, V49, P1841, DOI 10.1007/s10489-018-1364-2
   Das PK, 2016, SWARM EVOL COMPUT, V28, P14, DOI 10.1016/j.swevo.2015.10.011
   Dhanya K.M., 2019, INT J ENG ADV TECHNO, V8, P375
   Ding GS, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105704
   Du SY, 2020, MULTIMED TOOLS APPL, V79, P4619, DOI 10.1007/s11042-019-08142-7
   Ewees AA, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063008
   Ezugwu AE, 2019, EXPERT SYST APPL, V119, P184, DOI 10.1016/j.eswa.2018.10.045
   Freixenet J, 2002, LECT NOTES COMPUTER, V2352, DOI [10.1007/3-540-47977-5-27, DOI 10.1007/3-540-47977-5-27]
   Gandomi AH, 2014, ISA T, V53, P1168, DOI 10.1016/j.isatra.2014.03.018
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P245, DOI 10.1007/s00366-012-0308-4
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Ghosh A, 2017, IEEE ACCESS, V5, P26944, DOI 10.1109/ACCESS.2017.2773825
   Gupta S, 2020, NEURAL COMPUT APPL, V32, P9521, DOI 10.1007/s00521-019-04465-6
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   He Q, 2007, ENG APPL ARTIF INTEL, V20, P89, DOI 10.1016/j.engappai.2006.03.003
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   Huang FZ, 2007, APPL MATH COMPUT, V186, P340, DOI 10.1016/j.amc.2006.07.105
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaveh A, 2017, INT J OPTIM CIVIL EN, V6, P469
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Liu H, 2010, APPL SOFT COMPUT, V10, P629, DOI 10.1016/j.asoc.2009.08.031
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033
   Mezura-Montes E, 2008, INT J GEN SYST, V37, P443, DOI 10.1080/03081070701303470
   Ming-Huwi Horng, 2010, 2010 Proceedings of 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing (UIC/ATC 2010), P58, DOI 10.1109/UIC-ATC.2010.47
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Nama S, 2020, HYBRID TLBO ALGORITH, DOI [10.1007/978-3-030-32644-9_30, DOI 10.1007/978-3-030-32644-9_30]
   Nama S., 2016, Int. J. Ind. Eng. Comput, V7, P323
   Nama S., 2016, DECIS SCI LETT, V5, P361, DOI [10.5267/j.dsl.2016.2.004, DOI 10.5267/J.DSL.2016.2.004]
   Nama S., 2018, Decis. Sci. Lett., V7, P103, DOI [10.5267/J.DSL.2017.6.006, DOI 10.5267/J.DSL.2017.6.006]
   Nama S, 2022, COMPUT INTELL-US, V38, P947, DOI 10.1111/coin.12290
   Nama S, 2018, APPL INTELL, V48, P1657, DOI 10.1007/s10489-017-1016-y
   Nama S, 2017, MEMET COMPUT, V9, P261, DOI 10.1007/s12293-016-0194-1
   Nama S, 2017, APPL SOFT COMPUT, V52, P885, DOI 10.1016/j.asoc.2016.09.037
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan XQ, 2019, MULTIMED TOOLS APPL, V78, P29921, DOI 10.1007/s11042-018-6602-4
   Prakash KR, 2019, APPL SOFT COMPUT, V85, P105823
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Sadollah A, 2013, APPL SOFT COMPUT, V13, P2592, DOI 10.1016/j.asoc.2012.11.026
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Skoullis VI, 2017, APPL SOFT COMPUT, V52, P277, DOI 10.1016/j.asoc.2016.10.038
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tejani GG, 2019, EXPERT SYST APPL, V125, P425, DOI 10.1016/j.eswa.2019.01.068
   Truong KH, 2019, APPL SOFT COMPUT, V77, P567, DOI 10.1016/j.asoc.2019.01.043
   Tsai JF, 2005, ENG OPTIMIZ, V37, P399, DOI 10.1080/03052150500066737
   Wang GG, 2003, J MECH DESIGN, V125, P210, DOI 10.1115/1.1561044
   Wang Y, 2019, COMPUT IND ENG, V131, P269, DOI 10.1016/j.cie.2019.04.008
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu B, 2020, INFORM SCIENCES, V533, P72, DOI 10.1016/j.ins.2020.05.033
   Xing ZK, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105570
   Yan ZP, 2020, MULTIMED TOOLS APPL, V79, P32415, DOI 10.1007/s11042-020-09664-1
   Yang X.S., 2012, P UNC COMP NAT COMP, DOI [10.1007/978-3-642-32894-7-27, DOI 10.1007/978-3-642-32894-7-27]
   Zhang M, 2008, INFORM SCIENCES, V178, P3043, DOI 10.1016/j.ins.2008.02.014
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 78
TC 48
Z9 48
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12035
EP 12076
DI 10.1007/s11042-020-10053-x
EA JAN 2021
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605930700001
DA 2024-07-18
ER

PT J
AU Agarwal, D
   Bansal, A
AF Agarwal, Diwakar
   Bansal, Atul
TI A utility of pores as level 3 features in latent fingerprint
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint recognition; Fusion; Latent; Minutiae; Pores; Score
ID RECOGNITION; ALGORITHM
AB Latent fingerprint identification is the most prevalent process used by the forensic community from a long time. Smudgy, blurred, and small fingerprint area of the latent impressions results into the deficiency of the level 2 features i.e. minutiae. Most of the commercially available Automated Fingerprint Identification Systems (AFISs) which mainly dependent on minutiae; seems less efficient in latent fingerprint matching. In this paper, the usefulness of pores (level 3 features) besides minutiae in latent fingerprint matching is examined. An algorithm based on Lindeberg's automatic scale selection method is proposed for pores extraction in latent fingerprints. The fusion of pores and minutiae at score level is used to re-rank the minutiae based latent matcher. The effectiveness of the proposed algorithm and pores utility are evaluated by observing and comparing the latent recognition accuracy obtained for minutiae matching and matching after fusion. Both minutiae and pores are automatically extracted in latent and reference fingerprints. The experimental results show that the fusion significantly improves the latent recognition rate in comparison to the minutiae matching.
C1 [Agarwal, Diwakar; Bansal, Atul] GLA Univ, Mathura, India.
C3 GLA University
RP Agarwal, D (corresponding author), GLA Univ, Mathura, India.
EM diwakar.agarwal@gla.ac.in; atul.bansal@gla.ac.in
RI Agarwal, Diwakar/A-1839-2016; Bansal, Atul/I-1823-2019
OI Agarwal, Diwakar/0000-0002-1311-0079; Bansal, Atul/0000-0002-8012-0349
CR Abraham Joshua, 2011, State of the Art in Biometrics, P25
   Agarwal D, 2020, INT J BIOMETRICS, V12, P317
   [Anonymous], 2014, 18 IEEE INT S CONS E
   [Anonymous], 2003, Handbook of fingerprint recognition
   ASAI K, 1987, Patent No. 4646352
   Ashbaugh D.R., 1999, CRC SER PR CRIM, DOI 10.1201/9781420048810
   Cai JG, 2008, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE OF MODELLING AND SIMULATION, VOL VI, P1
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   CDEFFS, 2008, ANSI NIST CDEFFS GRO
   Champod C., 2004, FINGERPRINTS OTHER R
   Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597
   Chen Y, 2007, GLOB TELECOMM CONF, P1
   Dahia G., 2018, ARXIV181106846
   Dvornychenko VN, 2006, NIST LAT FING TEST W
   Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Garris M.D., 2000, NIST Special Database 27: Fingerprint Minutiae from Latent and Matching Tenprint Images
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gu JW, 2006, IEEE T IMAGE PROCESS, V15, P1952, DOI 10.1109/TIP.2006.873443
   Haixia Wang, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P279, DOI 10.1007/978-3-319-69923-3_30
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   HRECHAK AK, 1990, PATTERN RECOGN, V23, P893, DOI 10.1016/0031-3203(90)90134-7
   *IBG, 2008, AN LEV 3 FEAT HIGH R
   Jain Anil K., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563117
   Jain AK, 2007, IEEE T PATTERN ANAL, V29, P15, DOI 10.1109/TPAMI.2007.250596
   Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59
   Jang HU, 2017, IEEE SIGNAL PROC LET, V24, P1808, DOI 10.1109/LSP.2017.2761454
   Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016
   Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252
   Komarinski P., 2005, Automated fingerprint identification systems (AFIS)
   Kryszczuk K., 2004, PROC COST ACTION 275, P83
   Kwan P.W., 2006, Proceedings of The 21st Image and Vision Computing New Zealand (IVCNZ 2006) Great Barrier Island, V1, P115
   Labati RD, 2018, PATTERN RECOGN LETT, V113, P58, DOI 10.1016/j.patrec.2017.04.001
   Lee H.C., 1991, ADV FINGERPRINT TECH
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu F, 2020, Advanced fingerprint recognition: from 3D shape to ridge detail, P165
   Liu F., 2020, Advanced Fingerprint Recognition: From 3D Shape to Ridge Detail, P107
   Liu F, 2010, ADV FUNCT MATER, V20, P3163, DOI 10.1002/adfm.201000379
   Liu F, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107208
   Liu F, 2011, PATTERN RECOGN, V44, P1604, DOI 10.1016/j.patcog.2011.02.010
   Mngenge N.A., 2012, NAT C COMP COMM SYST, P1
   Nguyen D., 2019, ABS190511472 CORR
   Parsons N.R., 2008, LAW PROBAB RISK, V7, P1, DOI DOI 10.1093/LPR/MGM018
   Paulino AA, 2013, IEEE T INF FOREN SEC, V8, P31, DOI 10.1109/TIFS.2012.2223678
   QI J, 2005, PATTERN RECOGN, V26, P2424
   Ramírez-Sáyago E, 2020, LECT NOTES COMPUT SC, V12088, P76, DOI 10.1007/978-3-030-49076-8_8
   Ratha NK, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Ray M, 2005, SOUTHEAST SYMP SYSTE, P282, DOI 10.1109/SSST.2005.1460922
   RUTOVITZ D, 1966, J R STAT SOC SER A-G, V129, P504, DOI 10.2307/2982255
   Sanchez-Fernandez AJ, 2020, IEEE ACCESS, V8, P124236, DOI 10.1109/ACCESS.2020.3005476
   Sankaran A., 2011, Biometrics (IJCB), 2011 International Joint Conference On, P1, DOI [10.1109/IJCB.2011.6117525, DOI 10.1109/IJCB.2011.6117525]
   Singla N, 2020, FORENSIC SCI INT, V309, DOI 10.1016/j.forsciint.2020.110187
   STOSZ JD, 1994, P SOC PHOTO-OPT INS, V2277, P210, DOI 10.1117/12.191885
   Su HR, 2017, INT CONF ACOUST SPEE, P2057, DOI 10.1109/ICASSP.2017.7952518
   Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7
   Teixeira RFS, 2014, IEEE IMAGE PROC, P4962, DOI 10.1109/ICIP.2014.7026005
   Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604
   Wahab A, 1998, IEE P-VIS IMAGE SIGN, V145, P160, DOI 10.1049/ip-vis:19981809
   Wan DR, 2006, IEEE T IMAGE PROCESS, V15, P1690, DOI 10.1109/TIP.2006.873442
   Zhao Q., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P9, DOI DOI 10.1109/CVPRW.2010.5543239
   Zhao QJ, 2010, PATTERN RECOGN, V43, P2833, DOI 10.1016/j.patcog.2010.02.016
   Zhao QJ, 2010, PATTERN RECOGN, V43, P1050, DOI 10.1016/j.patcog.2009.08.004
   Zhao QJ, 2009, LECT NOTES COMPUT SC, V5558, P597, DOI 10.1007/978-3-642-01793-3_61
NR 64
TC 4
Z9 4
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23605
EP 23624
DI 10.1007/s11042-020-10207-x
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000604479100008
DA 2024-07-18
ER

PT J
AU Kathuria, M
   Gambhir, S
AF Kathuria, Madhumita
   Gambhir, Sapna
TI Reliable packet transmission in WBAN with dynamic and optimized QoS
   using multi-objective lion cooperative hunt optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of service; Patient monitoring; Wireless body area network;
   Reliable packet transmission; Priority queue; Loss recovery; Assorted
   traffic; Dynamic environment; Lion cooperative hunt optimizer
ID CONGESTION AVOIDANCE; ENERGY-EFFICIENT; ROUTING PROTOCOL; WIRELESS;
   ALGORITHM
AB Recent studies demonstrate that handling a patient's health-related data needs dynamic Quality of Service (QoS) to cope up with significant changes in the functioning of a Patient Monitoring Wireless Body Area Network (PA-WBAN). This kind of system demands a remarkable improvement in the QoS as it is dealing with the reliable transmission of a large volume of assorted data in a frequently changing environment. The QoS in a PA-WBAN is not only about how it senses or reads data from various body parts but is how it deciphers the sensed data. In the patient monitoring system, if the required data is not available in a readable format or not in a specific time, then this data becomes useless and is of no use. However, to harmonize these requirements, two approaches are proposed in this paper. The first protocol is developed for obtaining dynamic QoS for reliable packet transmission. It offers both node and packet-level dynamic-priority assignment policy, which further helps in fair and dynamic resource allocation, queuing, scheduling, retransmission, drop, and delay. It provides fair queuing and percentile scheduling policies, which estimates service rate for each priority queue and serves only highly significant packets with high waiting time during scheduling. Additionally, it offers application-specific reliability through a predictive retransmission and loss recovery policy. During retransmission and loss recovery, it calculates a retransmission rate for each sensor node and retransmits only that amount of packets from each sensor node. It also controls congestion with its dynamic priority-based rate adjustment and packet drop policies. It further provides a concept of time-bound based packet transmission policy that minimizes delay and jitter more appropriately. The second protocol is designed for attaining optimized QoS in the dynamic and assorted PA-WBAN. It applies a Lion Cooperative Hunt Optimization (LCHO) technique for the optimization of multi-objective QoS. Both theoretical and simulation results examine the usefulness of the proposed protocols and illustrate its advantage over the existing protocols.
C1 [Kathuria, Madhumita] Manav Rachna Int Inst Res & Studies, Faridabad, Haryana, India.
   [Gambhir, Sapna] JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
C3 Manav Rachna International Institute of Research & Studies; J.C. Bose
   University of Science & Technology, YMCA
RP Kathuria, M (corresponding author), Manav Rachna Int Inst Res & Studies, Faridabad, Haryana, India.
EM madhumita.fet@mriu.edu.in
CR Ahmed O, 2020, IEEE ACCESS, V8, P41085, DOI 10.1109/ACCESS.2020.2976819
   Ahmed T, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040780
   Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   Ambigavathi M, 2018, FUTURE GENER COMP SY, V88, P586, DOI 10.1016/j.future.2018.05.044
   [Anonymous], 2018, INT J COMPUTATIONAL
   [Anonymous], 2014, INT C REC ADV ENG CO
   Ben Elhadj H, 2016, AD HOC NETW, V42, P1, DOI 10.1016/j.adhoc.2015.10.007
   Bilandi N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1514-0
   Faheem M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235072
   Gambhir S., 2018, INDONES J ELECT ENG, V4, P3, DOI DOI 10.11591/IJEEI.V4I4.238
   Gambhir S, 2020, J CRITICAL REV INDER, V7, P488
   Gambhir S, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3380
   Gambhir S, 2015, INT CONF CONTEMP, P428, DOI 10.1109/IC3.2015.7346719
   Gouda KC, 2020, NAT INSP COMP WIR SE, P57
   Haider Z, 2020, INT J SECUR APPL, V14, P15, DOI 10.33832/ijsia.2020.14.1.02
   Iftikhar M, 2014, PROCEDIA COMPUT SCI, V34, P518, DOI 10.1016/j.procs.2014.07.060
   Javaid N., 2013, RES J APPL SCI ENG T, V7, P123, DOI [10.19026/rjaset.7.229, DOI 10.19026/RJASET.7.229]
   Kathuria Madhumita, 2016, International Journal of Information Technology and Computer Science, V8, P83, DOI 10.5815/ijitcs.2016.12.10
   Kathuria Madhumita, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P333, DOI 10.1109/ABLAZE.2015.7155007
   Kathuria M, 2016, INT J COMPUT APPL, V144, P36
   Kathuria M., 2014, IEEE INT C REC ADV I, P1
   Kathuria M., 2016, INT J ENERGY INF COM, V7, P1
   Kathuria M, 2020, AD HOC SENS WIREL NE, V47, P279
   Kathuria M, 2020, INT J E-HEALTH MED C, V11, P52, DOI 10.4018/IJEHMC.2020010104
   Kathuria M, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P222, DOI 10.1109/ICROIT.2014.6798318
   Khan Z, 2012, PROCEDIA COMPUT SCI, V10, P188, DOI 10.1016/j.procs.2012.06.027
   Khan ZA, 2013, PROCEDIA COMPUT SCI, V19, P171, DOI 10.1016/j.procs.2013.06.027
   Kim TY, 2016, MULTIMED TOOLS APPL, V75, P12859, DOI 10.1007/s11042-015-2832-x
   Manfredi Sabato, 2014, IEEE Wireless Communications, V21, P81, DOI 10.1109/MWC.2014.6812295
   Misra S, 2009, IEEE J SEL AREA COMM, V27, P466, DOI 10.1109/JSAC.2009.090510
   Mohanty P, 2016, INT J WIREL INF NETW, V23, P162, DOI 10.1007/s10776-016-0307-2
   Monowar MM, 2017, IEEE ACCESS, V5, P10209, DOI 10.1109/ACCESS.2017.2708760
   Narawade V, 2018, ALEX ENG J, V57, P131, DOI 10.1016/j.aej.2016.10.005
   Oftadeh R, 2010, COMPUT MATH APPL, V60, P2087, DOI 10.1016/j.camwa.2010.07.049
   Pasandideh Faezeh, 2018, International Journal of Wireless and Mobile Computing, V14, P1
   Pramanik P.K.D., 2019, Telemedicine Technologies, P89
   Puspitaningayu P, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012116
   Rajakumar BR, 2012, PROC TECH, V1, P126, DOI 10.1016/j.protcy.2012.10.016
   Rakhee, 2019, ADV INTELL SYST, V741, P423, DOI 10.1007/978-981-13-0761-4_41
   Rezaee AA, 2014, WIRELESS PERS COMMUN, V75, P11, DOI 10.1007/s11277-013-1337-z
   Salayma M, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3041956
   Samiullah M, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P493, DOI 10.1109/ICIEV.2012.6317349
   Takabayashi K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113969
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Wang B, 2012, SCI CHINA INFORM SCI, V55, P2369, DOI 10.1007/s11432-012-4548-0
   Wu DP, 2016, IEEE ACCESS, V4, P7251, DOI 10.1109/ACCESS.2016.2611820
   Xie ZJ, 2014, PROCEDIA COMPUT SCI, V31, P1092, DOI 10.1016/j.procs.2014.05.364
   Yaakob N, 2016, IEEE J BIOMED HEALTH, V20, P669, DOI 10.1109/JBHI.2015.2406884
   Yaghmaee MH, 2013, WIRELESS PERS COMMUN, V72, P2605, DOI 10.1007/s11277-013-1169-x
   Yan J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103268
   Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003
   Zuhra FT, 2019, IEEE ACCESS, V7, P152777, DOI 10.1109/ACCESS.2019.2947337
NR 52
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10533
EP 10576
DI 10.1007/s11042-020-10144-9
EA NOV 2020
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000592635700002
DA 2024-07-18
ER

PT J
AU Li, X
   Meng, LL
   Tan, YY
   Zhang, J
   Wan, WB
   Zhang, HX
AF Li, Xue
   Meng, Lili
   Tan, Yanyan
   Zhang, Jia
   Wan, Wenbo
   Zhang, Huaxiang
TI Deep semantic segmentation-based multiple description coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description coding; Deep semantic segmentation; Generative
   adversarial network; Compact network; Reconstruction network
ID SCHEME
AB In this paper, we propose a deep semantic segmentation-based multiple description coding (DSSMDC). In the proposed scheme, the input image is divided into two different subsets and getting two descriptions, which is named multiple description pre-processing (MDP). Then, two descriptions are encoded and decoded respectively by utilizing the deep semantic segmentation codec, in which the semantic segmentation label is as side information for improving image reconstruction quality. We can get one side reconstruction, when only one description is received at the decoder. If both descriptions are received at the decoder, we can get the central reconstruction. Experimental results show that the proposed scheme achieves better performance than other existing compression methods.
C1 [Li, Xue; Meng, Lili; Tan, Yanyan; Zhang, Jia; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
   [Li, Xue; Meng, Lili; Tan, Yanyan; Zhang, Jia; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Meng, LL (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.; Meng, LL (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Peoples R China.
EM rosylixue@hotmail.com; mengll_83@hotmail.com
RI meng, li/HTQ-7341-2023; meng, li/GVT-2063-2022
CR Agustsson E, 2019, ARXIV180402958V3
   Agustsson E, 2017, ADV NEUR IN, V30
   Akbari M., 2018, ARXIV180603348
   [Anonymous], 2017, ARXIV161101704V3
   Baccaglini E, 2007, IEEE SIGNAL PROC LET, V14, P197, DOI 10.1109/LSP.2006.883986
   Bayraktar E, 2017, INT J THEOR APPL FIN, V20, DOI 10.1142/S0219024917500364
   Feng J, 2017, IEEE T VEH TECHNOL
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Liu ML, 2009, IEEE SIGNAL PROC LET, V16, P253, DOI 10.1109/LSP.2009.2014104
   Luo SH, 2018, LECT NOTES COMPUT SC, V11301, P96, DOI 10.1007/978-3-030-04167-0_9
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Meng LL, 2014, IEEE T IMAGE PROCESS, V23, P582, DOI 10.1109/TIP.2013.2288928
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stergiou C., 2018, ALGORITHMS EFFICIENT
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Sukthankar R., 2015, INT C LEARN REPR
   Sun GQ, 2009, IEEE T IMAGE PROCESS, V18, P1037, DOI 10.1109/TIP.2009.2013068
   Theis L., 2017, ICLR
   Tillo T, 2004, IEEE SIGNAL PROC LET, V11, P908, DOI 10.1109/LSP.2004.836949
   Tillo T, 2007, IEEE T IMAGE PROCESS, V16, P673, DOI 10.1109/TIP.2007.891152
   TODERICI G, 2017, P IEEE C COMP VIS PA, P5306
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Wang, 2016, ESANN 2017 P, P589
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xu YY, 2013, IEEE T CIRC SYST VID, V23, P1523, DOI 10.1109/TCSVT.2013.2249018
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao  L., 2017, ARXIV171205969
   Zhao L, 2019, INT J HYPERTHER, V35, P528, DOI 10.1080/02656736.2018.1511836
   Zhu C, 2009, IEEE T CIRC SYST VID, V19, P511, DOI 10.1109/TCSVT.2009.2013521
NR 38
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10323
EP 10337
DI 10.1007/s11042-020-09283-w
EA NOV 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590967300002
DA 2024-07-18
ER

PT J
AU Mangolin, RB
   Pereira, RM
   Britto, AS 
   Silla, CN 
   Feltrim, VD
   Bertolini, D
   Costa, YMG
AF Mangolin, Rafael B.
   Pereira, Rodolfo M.
   Britto, Alceu S., Jr.
   Silla, Carlos N., Jr.
   Feltrim, Valeria D.
   Bertolini, Diego
   Costa, Yandre M. G.
TI A multimodal approach for multi-label movie genre classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie genre classification; Multi-label classification; Multimodal
   classification; Movie trailer
ID REPRESENTATION; RECOGNITION; INSTANCE
AB Movie genre classification is a challenging task that has increasingly attracted the attention of researchers. The number of movie consumers interested in taking advantage of automatic movie genre classification is overgrowing, thanks to media streaming service providers' popularization. In this paper, we addressed the multi-label classification of movie genres in a multimodal way. To this end, we created a dataset composed of trailer video clips, subtitles, synopses, and movie posters from 152,622 movie titles of the Movie Database (TMDb). Such a large dataset was carefully curated, organized, and made available as a contribution of this work. We labeled each movie of the dataset according to a set of eighteen genre labels. In the experimental evaluation performed in this paper, we computed different kinds of descriptors, such as Mel Frequency Cepstral Coefficients (MFCCs), Statistical Spectrum Descriptor (SSD), Local Binary Pattern (LBP) from spectrograms, Long-Short Term Memory (LSTM), and Convolutional Neural Networks (CNN). With these descriptors, we trained different monolithic classifiers using BinaryRelevance and ML-kNN techniques. Besides, we also explored the combination of classifiers/features using a late fusion strategy. The fusion of a LSTM trained on synopses and another LSTM trained on the movie subtitles provided our best results in F-Score (0.674) and AUC-PR (0.725) metrics. These results corroborate the existence of complementarity among classifiers trained on different sources of information in this field of application. As far as we know, this is the most comprehensive study developed in terms of diversity of multimedia sources of information to perform movie genre classification.
C1 [Mangolin, Rafael B.; Feltrim, Valeria D.; Costa, Yandre M. G.] Univ Estadual Maringa, Dept Informat, Ave Colombo 5790, Maringa, Parana, Brazil.
   [Pereira, Rodolfo M.] Fed Inst Parana, Pinhais, Parana, Brazil.
   [Pereira, Rodolfo M.; Britto, Alceu S., Jr.; Silla, Carlos N., Jr.] Pontificia Univ Catolica Parana, Curitiba, Parana, Brazil.
   [Bertolini, Diego] Fed Technol Univ Parana, Campo Mourao, Parana, Brazil.
C3 Universidade Estadual de Maringa; Instituto Federal do Parana;
   Pontificia Universidade Catolica do Parana; Universidade Tecnologica
   Federal do Parana
RP Mangolin, RB (corresponding author), Univ Estadual Maringa, Dept Informat, Ave Colombo 5790, Maringa, Parana, Brazil.
EM rbmangolin@gmail.com; rodolfomp123@gmail.com; valeria.feltrim@gmail.com;
   diegobertolini@utfpr.edu.br; yandre@din.uem.br
RI Silla Jr., Carlos/F-7227-2012
OI Silla Jr., Carlos/0000-0002-1603-9378; Costa,
   Yandre/0000-0002-0630-3171; Bertolini, Diego/0000-0002-6196-4538;
   Miranda Pereira, Rodolfo/0000-0003-1272-5378
FU CNPq - National Council for Scientific and Technological Development
   [156956/2018-7, 164837/2018-3]; CAPES - Coordination for the Improvement
   of Higher Education Personnel; FA - Araucaria Foundation; NVIDIA
   Corporation
FX We thank the Brazilian Research Support Agencies: CNPq - National
   Council for Scientific and Technological Development (grants
   #156956/2018-7 and #164837/2018-3), CAPES - Coordination for the
   Improvement of Higher Education Personnel and FA - Araucaria Foundation
   for their financial support for their financial support. We also
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of a Titan XP GPU used in this research.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2019, ARXIV190803180
   [Anonymous], P 17 EUR C ART INT E
   [Anonymous], 2017, ARXIV170704916
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Baraniuk RG, 2010, P IEEE, V98, P959, DOI 10.1109/JPROC.2009.2038076
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Brezeale D, 2006, P INT WORKSH MULT DA
   Charte F, 2015, KNOWL-BASED SYST, V89, P385, DOI 10.1016/j.knosys.2015.07.019
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Costa YMG, 2012, SIGNAL PROCESS, V92, P2723, DOI 10.1016/j.sigpro.2012.04.023
   DAMASHEK M, 1995, SCIENCE, V267, P843, DOI 10.1126/science.267.5199.843
   Davis JE, 2006, DEAF WAY II READER: PERSPECTIVES FROM THE SECOND INTERNATIONAL CONFERENCE ON DEAF CULTURE, P233
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Frakes W.B., 1992, Information retrieval: Data structures algorithms, V331
   Fu ZK, 2015, LECT NOTES COMPUT SC, V9242, P72, DOI 10.1007/978-3-319-23989-7_8
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hasan M. R., 2004, 3 INT C EL COMP ENG, P565
   Herrera F., 2016, MULTILABEL CLASSIFIC
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hong HZ, 2015, LECT NOTES COMPUT SC, V9132, P159, DOI 10.1007/978-3-319-20248-8_14
   Huang YC, 2012, SCI WORLD J, P1, DOI 10.1100/2012/793039
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   Jurafsky D., 2009, SPEECH LANGUAGE PROC
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Lidy T, 2010, SIGNAL PROCESS, V90, P1032, DOI 10.1016/j.sigpro.2009.09.014
   Logan, 2000, ISMIR, P1
   Nanni L., 2014, Set of texture descriptors for music genre classification
   Nanni L, 2016, PROC INT C TOOLS ART, P396, DOI [10.1109/ICTAI.2016.64, 10.1109/ICTAI.2016.0067]
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pereira RM, 2020, NEUROCOMPUTING, V383, P95, DOI 10.1016/j.neucom.2019.11.076
   Pons J, 2019, INT CONF ACOUST SPEE, P336, DOI 10.1109/ICASSP.2019.8682912
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI [10.1108/00330330610681286, 10.1108/eb046814]
   Portolese G, 2018, P NAT M ART COMP INT, DOI [10.5753/eniac.2018.4476, DOI 10.5753/ENIAC.2018.4476]
   Portolese G, 2019, LECT NOTES ARTIF INT, V11805, P669, DOI 10.1007/978-3-030-30244-3_55
   Provost F, 1998, P INT C MACH LEARN
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Simoes GS, 2016, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2016.7727207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101
   Wang CM, 2010, EXPERT SYST APPL, V37, P2826, DOI 10.1016/j.eswa.2009.09.008
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Wilcoxon Frank, 1992, BREAKTHROUGHS STAT, P196, DOI [DOI 10.1007/978-1-4612-4380-9_16, 10.1007/978-1-4612-4380-9_16, DOI 10.1007/978-1-4612-4380-9]
   Wu JN, 2008, PROC CVPR IEEE, P2221
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhou W, 2010, ACTA POLYM SIN, P747
NR 57
TC 16
Z9 17
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19071
EP 19096
DI 10.1007/s11042-020-10086-2
EA NOV 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000587279700005
DA 2024-07-18
ER

PT J
AU Sepehrinour, M
   Kasaei, S
AF Sepehrinour, Maryam
   Kasaei, Shohreh
TI NRSfPP: non-rigid structure-from-perspective projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid structure-from-motion; Perspective projection; Single-view 3D
   reconstruction
ID 3D SHAPE; MOTION; FACTORIZATION
AB A state-of-the-art algorithm for perspective projection reconstruction of non-rigid surfaces from single-view and realistic videos is proposed. It overcomes the limitations arising from the usage of orthographic camera model and also the complexity and non-linearity issues of perspective projection equation. Unlike traditional non-rigid structure-from-motion (NRSfM) methods, which have been studied only on synthetic datasets and controlled lab environments that require some prior constraints (such as manually segmented objects, limited rotations and occlusions, and full-length trajectories); the proposed method can be used in realistic video sequences. In addition, contrary to previous methods that use multiple cameras with different relative viewing angles, only a single-view video is required to reconstruct the 3D structures. By only using the 2D frames of incoming video stream, the proposed method extracts the projective depth coefficients of each point in each input frame, rotation matrix, translation vector, varying camera parameters (such as focal lengths for each input frame), and finally reconstructs the 3D deformable shape. Due to the high number of unknowns, the problem has been divided into two parts of projective depth coefficients extraction and 3D shape reconstruction. Perspective reconstruction of non-rigid surfaces has been extended to be certainly converged which leads to a significant increase in execution frequency of the iterated algorithm that has been presented for projective depth coefficients extraction. As such, it produces promising results for perspective projection reconstruction of non-rigid surfaces from single-view and realistic videos. The accuracy and robustness of the proposed method is demonstrated quantitatively on synthetic data and qualitatively on real image sequences. The experimental results show that NRSfPP provides the state-of-the-art results and resolves the failures of previous approaches by eliminating all of the predefined situations and constraints of applying perspective projection as the camera model.
C1 [Sepehrinour, Maryam; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM kasaei@sharif.edu
CR Aan s H, 2002, P VIS MOD DYN SCEN W, V2, P3
   Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293
   Agudo A, 2015, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2015.7298830
   Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202
   Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201
   Akhter Ijaz, 2009, NeurIPS, P41
   Brand M, 2005, PROC CVPR IEEE, P122
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   Bronte S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102342
   Cha G, 2018, PATTERN RECOGN LETT, V110, P51, DOI 10.1016/j.patrec.2018.03.019
   Chhatkuli A., 2014, BRIT MACH VIS C
   Chhatkuli A, 2018, IEEE T PATTERN ANAL, V40, P2428, DOI 10.1109/TPAMI.2017.2762669
   Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2
   Del Bue A., 2006, PROC IEEE C COMPUTER, V1, P1191
   Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168
   Garg R, 2013, INT J COMPUT VISION, V104, P286, DOI 10.1007/s11263-012-0607-7
   Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50
   Hartley R, 2008, LECT NOTES COMPUT SC, V5302, P276, DOI 10.1007/978-3-540-88682-2_22
   Kong C, 2019, ARXIV190210840
   Kumar S, 2020, IEEE WINT CONF APPL, P51, DOI 10.1109/WACV45572.2020.9093514
   Kumar S, 2017, PATTERN RECOGN, V71, P428, DOI 10.1016/j.patcog.2017.05.014
   Malik J., 2014, ADV NEURAL INFORM PR, P55
   Paladini M, 2012, INT J COMPUT VISION, V96, P252, DOI 10.1007/s11263-011-0468-5
   Parashar S., 2018, P EUROPEAN C COMPUTE, P252
   Probst Thomas, 2018, PROC EUR C COMPUT VI, P756
   Rehan A, 2014, IEEE WINT CONF APPL, P69, DOI 10.1109/WACV.2014.6836116
   Russell C, 2014, LECT NOTES COMPUT SC, V8695, P583, DOI 10.1007/978-3-319-10584-0_38
   Sepehrinour M, 2017, IRAN CONF ELECTR ENG, P1452, DOI 10.1109/IranianCEE.2017.7985271
   Sepehrinour M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P199, DOI 10.1109/IranianMVIP.2015.7397536
   Simon T, 2014, LECT NOTES COMPUT SC, V8691, P204, DOI 10.1007/978-3-319-10578-9_14
   Taylor J, 2010, PROC CVPR IEEE, P2761, DOI 10.1109/CVPR.2010.5540002
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torresani L, 2004, ADV NEUR IN, V16, P1555
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Varol A, 2009, IEEE I CONF COMP VIS, P1811, DOI 10.1109/ICCV.2009.5459403
   Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31
   Wang X, 2016, LECT NOTES COMPUT SC, V9911, P648, DOI 10.1007/978-3-319-46478-7_40
   Wang YM, 2015, SENSORS-BASEL, V15, P25730, DOI 10.3390/s151025730
   Xiao J, 2005, IEEE I CONF COMP VIS, P1075
   Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9
   Yu R, 2015, IEEE I CONF COMP VIS, P918, DOI 10.1109/ICCV.2015.111
   Zhao F, 2015, INT J CLIN EXP MED, V8, P20751
NR 42
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9093
EP 9108
DI 10.1007/s11042-020-10068-4
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587279700004
DA 2024-07-18
ER

PT J
AU Zhu, L
   Song, JY
   Wei, XX
   Yu, H
   Long, J
AF Zhu, Lei
   Song, Jiayu
   Wei, Xiangxiang
   Yu, Hao
   Long, Jun
TI CAESAR: concept augmentation based semantic representation for
   cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Deep learning; Multi-modal representation
   learning; Concept augmentation
ID IMAGES
AB With the increasing amount of multimedia data, cross-modal retrieval has attracted more attentions in the area of multimedia and computer vision. To bridge the semantic gap between multi-modal data and improve the performance of retrieval, we propose an effective concept augmentation based method, named CAESAR, which is an end-to-end framework including cross-modal correlation learning and concept augmentation based semantic mapping learning. To enhance the representation and correlation learning, a novel multi-modal CNNs based CCA model is developed, which is to capture high-level semantic information during the cross-modal feature learning, and then capture maximal nonlinear correlation. In addition, to learn the semantic relationships between multi-modal samples, a concept learning model named CaeNet is proposed, which is realized by word2vec and LDA to capture the closer relations between texts and abstract concepts. Reenforce by the abstract concept information, cross-modal semantic mappings are learnt with a semantic alignment strategy. We conduct comprehensive experiments on four benchmark multimedia datasets. The results show that our method has great performance for cross-modal retrieval.
C1 [Zhu, Lei; Song, Jiayu; Wei, Xiangxiang; Yu, Hao; Long, Jun] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhu, Lei; Wei, Xiangxiang; Long, Jun] Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Peoples R China.
C3 Central South University; Central South University
RP Yu, H; Long, J (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.; Long, J (corresponding author), Cent South Univ, Big Data & Knowledge Engn Inst, Changsha, Peoples R China.
EM leizhu@csu.edu.cn; jiayusong@csu.edu.cn; Xiangxiangwei@csu.edu.cn;
   yuhooo@csu.edu.cn; junlong@csu.edu.cn
RI Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-5348-7532
FU National Natural Science Foundation of China [61702560, 61472450,
   61972203]; Key Research Program of Hunan Province [2016JC2018]; Science
   and Technology Plan of Hunan Province [2018JJ3691]; Research and
   Innovation Project of Central South University Graduate Students
   [2018zzts177]
FX This work was supported in part by the National Natural Science
   Foundation of China (61702560, 61472450, 61972203), the Key Research
   Program of Hunan Province (2016JC2018), project (2018JJ3691) of Science
   and Technology Plan of Hunan Province, and the Research and Innovation
   Project of Central South University Graduate Students (2018zzts177).
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 1979, Multivariate analysis
   [Anonymous], 2014, 2 INT C LEARN REPR I
   [Anonymous], 2009, P 18 INT C WORLD WID
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Ballan Lamberto, 2014, P INT C MULT RETR IC, P73
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cao GQ, 2018, IEEE T CYBERNETICS, V48, P2542, DOI 10.1109/TCYB.2017.2742705
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Donahue J, 2014, PR MACH LEARN RES, V32
   DPLSNTMCM C, 2018, ACM SIGIR
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Fu RG, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P638, DOI 10.1109/CompComm.2016.7924779
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Gu JX, 2018, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR.2018.00750
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   He XT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1740, DOI 10.1145/3343031.3350974
   Herbrich R, 2000, ADV NEUR IN, P115
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li C, 2018, DES AUT CON, DOI 10.1145/3195970.3196091
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matsuo S, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P309, DOI 10.1145/2911996.2912057
   MUIRHEAD RJ, 1986, J BUS ECON STAT, V4, P135, DOI 10.2307/1391399
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P5585, DOI 10.1109/TIP.2018.2852503
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rasiwasia N, 2010, NEW APPROACH CROSS M
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Seddati O, 2017, IEEE INT CONF COMP V, P1246, DOI 10.1109/ICCVW.2017.150
   Shen YM, 2017, IEEE I CONF COMP VIS, P4117, DOI 10.1109/ICCV.2017.441
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun PX, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC)
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thompson B., 2005, Canonical correlation analysis. Encyclopedia of statistics in behavioral science
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Virtanen S., ARXIV12104920
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Wang K., ARXIV160706215
   Wang S, 2016, NEUROCOMPUTING, V171, P425, DOI 10.1016/j.neucom.2015.06.043
   Wang SP, 2017, IEEE T MULTIMEDIA, V19, P1454, DOI 10.1109/TMM.2017.2663324
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Yakhnenko O., 2009, Proceedings of the 2009 SIAM International Conference on Data Mining, SDM '09, P283
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yang JF, 2018, IEEE T IMAGE PROCESS, V27, P5288, DOI 10.1109/TIP.2018.2845136
   Yang XT, 2017, PROC CVPR IEEE, P5066, DOI 10.1109/CVPR.2017.538
   Yang Y, 2010, PATTERN RECOGN, V43, P2927, DOI 10.1016/j.patcog.2010.02.015
   Yu J, 2018, LECT NOTES COMPUT SC, V11164, P223, DOI 10.1007/978-3-030-00776-8_21
   Yu J, 2012, INT C PATT RECOG, P246
   Zhai XH, 2012, INT CONF ACOUST SPEE, P2337, DOI 10.1109/ICASSP.2012.6288383
   [张博 Zhang Bo], 2015, [计算机研究与发展, Journal of Computer Research and Development], V52, P1463
   Zhang CY, 2019, MULTIMED TOOLS APPL, V78, P30839, DOI 10.1007/s11042-018-6750-6
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
   Zhu L, 2019, IEEE ACCESS, V7, P180571, DOI 10.1109/ACCESS.2019.2940055
   Zu C, 2016, NEUROCOMPUTING, V191, P263, DOI 10.1016/j.neucom.2016.01.053
NR 79
TC 10
Z9 10
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34213
EP 34243
DI 10.1007/s11042-020-09983-3
EA OCT 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000587058000017
DA 2024-07-18
ER

PT J
AU Majhi, M
   Pal, AK
AF Majhi, Mukul
   Pal, Arup Kumar
TI An image retrieval scheme based on block level hybrid dct-svd fused
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Singular value decomposition; Discrete
   cosine transform; Hybrid features
ID COLOR; EXTRACTION; TEXTURE; SHAPE
AB In this paper, an image retrieval scheme has been proposed based on block level hybrid features. The block level salient feature are extracted in two parts: first level features are formed after the application of DCT and second level features are obtained after the processing of SVD. In the first level feature, salient components are computed from image blocks based on DCT transformation, which results into DC and AC coefficients. Here, the DC component is considered as the first level feature and the AC components are processed further to get the second level feature. Now, to extract second level feature, SVD is applied over the AC components which results into singular, left singular and right singular matrices. Based on the values of left and right singular matrices, some statistical parameters are computed which serve as the second level feature for the proposed scheme. To highlight the importance of extracted feature a weight factor is assigned to both first and second level features. However, more weight is given to the significant feature i.e the first level feature than the second level feature. Also, the feature extraction process is carried out separately for all the three planes of a color image, which in return gives more detailed feature for the proposed scheme. For the retrieval mechanism, similarity is measured by utilizing five existing distance measure schemes and the results are thoroughly analyzed to check the retrieval efficiency of the proposed scheme. Due to the variable weight factor, experimental results shows decent retrieval performance and the work is comparable to the existing works in image retrieval domain.
C1 [Majhi, Mukul; Pal, Arup Kumar] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Majhi, M (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM mukulmajhi@gmail.com; arupkrpal@gmail.com
RI Majhi, Mukul/ABA-6776-2021; Majhi, Mukul/HZI-8636-2023
OI Majhi, Mukul/0000-0003-1690-4461; 
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2011, Int. J. Comput. Vis. Robot, DOI DOI 10.1504/IJCVR.2011.045267
   Bai C, 2012, NEW DESCRIPTOR BASED
   Bai C, 2012, EUR SIGNAL PR CONF, P170
   Belalia A, 2015, INT J MULTIMED INF R, V4, P261, DOI 10.1007/s13735-015-0084-1
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Bhardwaj SB, 2020, J GLOB INFECT DIS, V12, P11, DOI 10.4103/jgid.jgid_110_19
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Chang CC, 2004, IMAGE VISION COMPUT, V22, P471, DOI 10.1016/j.imavis.2003.11.008
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Dabbaghchian S, 2010, PATTERN RECOGN, V43, P1431, DOI 10.1016/j.patcog.2009.11.001
   Dokmanic I, 2015, IEEE SIGNAL PROC MAG, V32, P12, DOI 10.1109/MSP.2015.2398954
   Dubey SR, 2017, J VIS COMMUN IMAGE R, V49, P141, DOI 10.1016/j.jvcir.2017.09.004
   Edmundson D, 2012, IEEE IMAGE PROC, P2421, DOI 10.1109/ICIP.2012.6467386
   Edmundson D, 2012, INT C PATT RECOG, P3188
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Feng GC, 2003, PATTERN RECOGN, V36, P977, DOI 10.1016/S0031-3203(02)00114-0
   Ferecatu M., 2004, P 6 ACM SIGMM INT WO, P23
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Jiao YH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P351
   Koskela M, 2004, LECT NOTES COMPUT SC, V3115, P508
   Latif G., 2017, 2017 International Conference on Wireless Technologies, Embedded and Intelligent Systems WITS, P1, DOI DOI 10.1109/WITS.2017.7934618
   Li J, 2018, COREL 1K DATASET
   Liu G-H, 2015, COREL 10K DATASET
   Liu G-H, 2015, GHIM 10K DATASET
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   Mohamed A, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P237, DOI 10.1109/CW.2009.61
   Narwaria M, 2010, IEEE T NEURAL NETWOR, V21, P515, DOI 10.1109/TNN.2010.2040192
   Naveena AK, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P48, DOI 10.1109/CSPC.2017.8305805
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pavithra LK, 2018, COMPUT ELECTR ENG, V70, P580, DOI 10.1016/j.compeleceng.2017.08.030
   Phadikar BS, 2018, PATTERN ANAL APPL, V21, P469, DOI 10.1007/s10044-016-0589-0
   Po LM, 2004, IEEE IMAGE PROC, P1533
   Rahimi M, 2015, SIGNAL IMAGE VIDEO P, V9, P691, DOI 10.1007/s11760-013-0506-6
   Rejito J, 2017, J PHYS CONF SER, V893, DOI 10.1088/1742-6596/893/1/012055
   Sai NST, 2016, PROCEDIA COMPUT SCI, V79, P579, DOI 10.1016/j.procs.2016.03.073
   Shao J, 2019, MULTIMED TOOLS APPL, V78, P16615, DOI 10.1007/s11042-018-7068-0
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   SIKORA T, 1995, IEEE T CIRC SYST VID, V5, P254, DOI 10.1109/76.401104
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srinivas M, 2015, NEUROCOMPUTING, V168, P880, DOI 10.1016/j.neucom.2015.05.036
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Varish N, 2016, INT J IMAGE MINING
   Wang D, 2019, PATTERN RECOGN, V86, P134, DOI 10.1016/j.patcog.2018.09.006
   Wang XY, 2014, NEUROCOMPUTING, V127, P214, DOI 10.1016/j.neucom.2013.08.007
   Wang XF, 2019, J VIS COMMUN IMAGE R, V61, P260, DOI 10.1016/j.jvcir.2019.03.024
   Yan LY, 2019, MULTIMED TOOLS APPL, V78, P15101, DOI 10.1007/s11042-018-6855-y
   Yousuf M, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2134395
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhang J, 2020, IEEE T CYBERNETICS, V50, P489, DOI 10.1109/TCYB.2018.2868826
   Zhang J, 2018, IEEE T MULTIMEDIA, V20, P2400, DOI 10.1109/TMM.2018.2804763
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhong D, 2005, PATTERN RECOGN LETT, V26, P2272, DOI 10.1016/j.patrec.2005.04.012
   Zhong D, 2007, PATTERN RECOGN LETT, V28, P2003, DOI 10.1016/j.patrec.2007.05.019
NR 63
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7271
EP 7312
DI 10.1007/s11042-020-10005-5
EA OCT 2020
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584568200001
DA 2024-07-18
ER

PT J
AU Koley, S
AF Koley, Subhadeep
TI Visual attention model based dual watermarking for simultaneous image
   copyright protection and authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual watermark; Hessenberg factorization; Multimedia security; Copyright
   protection; Tamper detection; Tamper localization
ID TAMPER DETECTION; ALGORITHM; SCHEME; ROBUST; IMPLEMENTATION; TRANSFORM
AB In this paper, a visual attention model based dual watermarking scheme has been proposed for simultaneous image copyright protection and authentication. The suggested method simultaneously embeds two watermarks inside the host image. First of all, the robust watermark is embedded in the most visually salient region by Hessenberg factorization technique, which has proven to give better results in terms of imperceptibility and robustness. Subsequently, the second watermark acts as a fragile watermark for the purpose of tamper detection and localization. The fragile watermark is infused inside the image via fragile 8 Bit Plane Slicing, as we require for the watermark to be highly responsive to majority of geometric, and non-geometric impairments. The proposed scheme achieves an average Peak Signal to Noise Ratio and Structural SIMilarity Index of 46.88 dB and 0.9897 respectively. Experimental results depict that the projected scheme is extremely robust against most kinds of geometric, signal-processing, and hybrid attacks with an average Normalized Cross Correlation of 0.9401. Moreover, due to the incorporation of the fragile watermark, it can detect and localize tampering of an image with extreme accuracy.
C1 [Koley, Subhadeep] RCC Inst Informat Technol, Dept ECE, Canal South Rd, Kolkata 700015, WB, India.
C3 RCC Institute of Information Technology (RCCIIT)
RP Koley, S (corresponding author), RCC Inst Informat Technol, Dept ECE, Canal South Rd, Kolkata 700015, WB, India.
EM subhadeepkoley@gmail.com
RI Koley, Subhadeep/HME-1003-2023
OI Koley, Subhadeep/0000-0002-4010-4387
CR Abdelhakim AM, 2018, MULTIMED TOOLS APPL, V77, P27895, DOI 10.1007/s11042-018-6014-5
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2020, Feature Extraction and Image Processing
   [Anonymous], 2011, DIGITAL IMAGE PROCES
   [Anonymous], 1996, MATRIX COMPUTATION
   [Anonymous], 2013, APPL MATH SCI
   Ansari IA, 2016, OPTIK, V127, P5711, DOI 10.1016/j.ijleo.2016.03.070
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Aytekin C, 2018, PATTERN RECOGN, V74, P359, DOI 10.1016/j.patcog.2017.09.023
   Aytekin C, 2017, MULTIMED TOOLS APPL, V76, P10443, DOI 10.1007/s11042-016-3431-1
   Aytekin Ç, 2015, IEEE IMAGE PROC, P1692, DOI 10.1109/ICIP.2015.7351089
   Bal SN, 2021, J KING SAUD UNIV-COM, V33, P552, DOI 10.1016/j.jksuci.2018.04.006
   Basu A, 2013, INF SECUR J, V22, P10, DOI 10.1080/19393555.2013.779400
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Esgandari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P988, DOI 10.1109/KBEI.2015.7436179
   Ghebleh M, 2014, SECUR COMMUN NETW, V7, P800, DOI 10.1002/sec.783
   Ghosh Ananya, 2019, Recent Trends in Signal and Image Processing. Proceedings of ISSIP 2018. Advances in Intelligent Systems and Computing (AISC 922), P103, DOI 10.1007/978-981-13-6783-0_10
   Gu F, 2005, IEEE INT SYMP CIRC S, P4417
   Gupta P, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P527, DOI 10.1109/COMPTELIX.2017.8004026
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P172, DOI 10.1016/j.aeue.2015.11.003
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Koley Subhadeep, 2019, Advances in Communication, Devices and Networking. ICCDN 2018. Proceedings: Lecture Notes in Electrical Engineering (LNEE 537), P201, DOI 10.1007/978-981-13-3450-4_23
   Koley S, 2022, J KING SAUD UNIV-COM, V34, P636, DOI 10.1016/j.jksuci.2019.03.002
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Kutter M, 1999, SECURITY WATERMARKIN, P1
   Lin C. H., 2011, J INFORM HIDING MULT, V2, P239
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Nayak MR, 2015, INF SECUR J, V24, P118, DOI 10.1080/19393555.2015.1073410
   Nematollahi MA, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5454768
   Parah SA, 2017, STUD COMPUT INTELL, V660, P427, DOI 10.1007/978-3-319-44790-2_19
   Parah SA, 2018, MULTIDIM SYST SIGN P, V29, P1095, DOI 10.1007/s11045-017-0490-z
   Parah SA, 2017, INT J ELECTRON, V104, P659, DOI 10.1080/00207217.2016.1242162
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Shen H, 2012, COMPUT ELECTR ENG, V38, P1310, DOI 10.1016/j.compeleceng.2011.11.012
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Sung M, 2016, OPTIK, V127, P11828, DOI 10.1016/j.ijleo.2016.09.098
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Tian LH, 2011, SIGNAL PROCESS-IMAGE, V26, P427, DOI 10.1016/j.image.2011.06.001
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   University of Granada, 2012, COMP VIS GROUP CVG U
   Wang DY, 2016, J INF PROCESS SYST, V12, P765, DOI 10.3745/JIPS.03.0055
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 57
TC 7
Z9 9
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6755
EP 6783
DI 10.1007/s11042-020-09918-y
EA OCT 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000581952100001
DA 2024-07-18
ER

PT J
AU Singh, OD
   Malik, A
   Yadav, V
   Gupta, S
   Dora, S
AF Singh, Om Dev
   Malik, Anjali
   Yadav, Vishakha
   Gupta, Shailender
   Dora, Shirin
TI Deep Segmenter system for recognition of micro cracks in solar cell
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Classification; Crack detection; Deep Segmenter; Image processing;
   Machine learning; Segmentation; Solar panel; Unsharp filter; VGG16
ID CONCRETE; INSPECTION
AB A solar panel is array of Photo-Voltaic modules (PVC) that are mounted together in a mechanical frame and are placed in the open fields so that sunlight impinges on those cells to produce electricity. The effectiveness of solar panels is cogently restricted by the impurities and defects present in the PVC. These imperfections bring profound energy levels in the semiconductor bandgap, depreciating the carrier lifetime and quantum efficiency of cells. It is significant to recognize the defects physics so that apposite methods may be employed to restrain the formation of severe flaws. In various past techniques, image processing, machine learning, and deep learning techniques are implemented to recognize, classify, or predict the probability of defects and their effect on PVC's overall performance. One of these approaches is an automatic recognition of micro-cracks, which is a compelling but challenging task. To achieve this, a deep learning approach based on the classification and segmentation process is proposed in this paper. This mechanism not only detects the micro-cracks but also effectively locates the area of the defected pixels. For the categorization of defects, VGG16 is used as a CNN classifier, and a Deep crack approach for the segmentation process is used. Thresholding and Decision Making are added to remove redundant pixels related to diverse types of frames present in PVC's, and finally, a decision is made. An unsharp filter is utilized because of efficient performance. This technique exhibits effective results in decision making, whether the solar cell needs to be replaced or not based on the percentage area of irregularity. The proposed model outperforms state-of-the-art methods with better performance in all aspects.
C1 [Singh, Om Dev; Malik, Anjali; Yadav, Vishakha; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
   [Dora, Shirin] Ulster Univ, Intelligent Syst Res Ctr, Magee Campus, Coleraine, Londonderry, North Ireland.
C3 J.C. Bose University of Science & Technology, YMCA; Ulster University
RP Gupta, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Dora, Shirin/0000-0001-6182-4124;
   Malik, Anjali/0009-0006-9598-3522; Yadav, Vishakha/0000-0001-6375-5361
CR Anwar SA, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-15
   Anwar SA, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2012), P143, DOI 10.1109/ICCSCE.2012.6487131
   Buerhop-Lutz C., 2018, 35 EUR PV SOL EN C E, DOI [10.4229/35thEUPVSEC20182018-5CV.3.15, DOI 10.4229/35THEUPVSEC20182018-5CV.3.15]
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Chawla R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0186-7
   Chen LC, 2006, J SURV ENG-ASCE, V132, P77, DOI 10.1061/(ASCE)0733-9453(2006)132:2(77)
   Dare PM, 2002, PHOTOGRAMM REC, V17, P453, DOI 10.1111/0031-868X.00198
   Deitsch S, 2018, ABS180606530 CORR
   Deitsch S, 2019, SOL ENERGY, V185, P455, DOI 10.1016/j.solener.2019.02.067
   Dhimish M, 2020, IEEE T IND INFORM, V16, P4769, DOI 10.1109/TII.2019.2946210
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Fu Z, 2004, 2004 INTERNATIONAL CONFERENCE ON THE BUSINESS OF ELECTRONIC PRODUCT RELIABILITY AND LIABILITY, PROCEEDINGS, P77, DOI 10.1109/BEPRL.2004.1308153
   Fujita Y, 2006, INT C PATT RECOG, P901
   Hsieh YA, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000918
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Iqbal T, 2019, IEEE INT CONF ROBOT, P5019, DOI [10.1109/ICRA.2019.8794054, 10.1109/icra.2019.8794054]
   Ito A., 2002, Proceedings IECON2002, P77
   Iyer S, 2005, IMAGE VISION COMPUT, V23, P921, DOI 10.1016/j.imavis.2005.05.017
   Liu K, 2019, STAT SINICA, V29, P1, DOI 10.5705/ss.202015.0316
   Liu Y, COMPUTER VISION REMO
   Liu YH, 2019, NEUROCOMPUTING, V338, P139, DOI 10.1016/j.neucom.2019.01.036
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nashat S, 2014, J FOOD ENG, V120, P233, DOI 10.1016/j.jfoodeng.2013.08.006
   Oh JK, 2009, AUTOMAT CONSTR, V18, P929, DOI 10.1016/j.autcon.2009.04.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha SK, 2006, AUTOMAT CONSTR, V15, P47, DOI 10.1016/j.autcon.2005.02.007
   Sinha SK, 2006, AUTOMAT CONSTR, V15, P58, DOI 10.1016/j.autcon.2005.02.006
   Stromer D, 2019, IEEE J PHOTOVOLT, V9, P752, DOI 10.1109/JPHOTOV.2019.2895808
   Wayne Fulton, 1997, SCANTIPS
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yamaguchi T, 2009, ELECTR COMMUN JPN, V92, P41, DOI 10.1002/ecj.10040
   Yamaguchi T, 2008, IEEJ T ELECTR ELECTR, V3, P128, DOI 10.1002/tee.20244
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yu SN, 2007, AUTOMAT CONSTR, V16, P255, DOI 10.1016/j.autcon.2006.05.003
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zou Q, 2012, PATTERN RECOGN LETT, V33, P227, DOI 10.1016/j.patrec.2011.11.004
NR 36
TC 4
Z9 4
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6509
EP 6533
DI 10.1007/s11042-020-09915-1
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000579257300002
DA 2024-07-18
ER

PT J
AU Phamtoan, D
   Vovan, T
AF Dinh Phamtoan
   Tai Vovan
TI Automatic fuzzy genetic algorithm in clustering for images based on the
   extracted intervals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cluster analysis; Fuzzy genetic algorithm; Image processing; Interval
   data; Pattern recognition; Unsupervised learning
ID CLASSIFICATION
AB This research proposes the method to extract the characteristics of images to become the intervals. These intervals are used to build the automatic fuzzy genetic algorithm for images (AFGI). In the proposed model, the overlap measure is the criterion to evaluate the closeness of intervals, and the new Davies and Bouldin index is the objective function. The AFGI can determine the proper number of clusters, the images in each cluster, and the probability to belong to clusters of images at the same time. The experiments with different types of images illustrate the steps of AFGI, and show its significant benefit in comparing to other algorithms.
C1 [Dinh Phamtoan] Univ Sci, Ho Chi Minh City, Vietnam.
   [Dinh Phamtoan] Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
   [Dinh Phamtoan] Van Lang Univ, Fac Engn, Ho Chi Minh City, Vietnam.
   [Tai Vovan] Can Tho Univ, Coll Nat Sci, Can Tho, Vietnam.
C3 Vietnam National University Hochiminh City; Van Lang University; Can Tho
   University
RP Vovan, T (corresponding author), Can Tho Univ, Coll Nat Sci, Can Tho, Vietnam.
EM phamtoandinh@vanlanguni.edu.vn; vvtai@ctu.edu.vn
RI Pham, Dinh Toan/JBJ-7780-2023
OI Pham, Dinh Toan/0000-0001-7873-9794; Tai, Vovan/0000-0002-1343-4647
CR [Anonymous], 2014, INT J SCI RES COMPUT, DOI DOI 10.48550/ARXIV.1406.4007
   [Anonymous], 2011, International Journal of Computer Applications, DOI DOI 10.5120/1756-2395
   Arivazhagan S., 2010, J. Emerg. Trends Comput. Inf. Sci, V1, P90
   Arkarnis A, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, TELECOMMUNICATION AND COMPUTER ENGINEERING (ELTICOM), P1
   Cabanes G, 2013, PATTERN RECOGN, V46, P3030, DOI 10.1016/j.patcog.2013.03.023
   Chen JH, 2015, J STAT COMPUT SIM, V85, P3047, DOI 10.1080/00949655.2014.949715
   Cheng HD, 2010, PATTERN RECOGN, V43, P299, DOI 10.1016/j.patcog.2009.05.012
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   de Carvalho FD, 2007, IEEE IJCNN, P224
   de Souza RMCR, 2004, LECT NOTES COMPUT SC, V3316, P775
   Eleyan A, 2011, TURK J ELECTR ENG CO, V19, P97, DOI 10.3906/elk-0906-27
   Engin MA, 2019, MULTIMED TOOLS APPL, V78, P6581, DOI 10.1007/s11042-018-6368-8
   Fadl S, 2020, MULTIMED TOOLS APPL, V79, P17619, DOI 10.1007/s11042-019-08603-z
   Ge Y, 2014, MULTIMED TOOLS APPL, V70, P781, DOI 10.1007/s11042-012-1102-4
   He ZL, 2019, MULTIMED TOOLS APPL, V78, P24285, DOI 10.1007/s11042-018-6988-z
   Holland J. H., 1973, SIAM Journal on Computing, V2, P88, DOI 10.1137/0202009
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   HUBERT L, 1977, BRIT J MATH STAT PSY, V30, P98, DOI 10.1111/j.2044-8317.1977.tb00728.x
   Hung WL, 2016, IEEE INT FUZZY SYST, P1494, DOI 10.1109/FUZZ-IEEE.2016.7737867
   Jeng JT, 2019, INT J FUZZY SYST, V21, P2102, DOI 10.1007/s40815-019-00707-w
   Kabir S, 2017, IEEE INT CONF FUZZY
   Lai CC, 2005, INTELL AUTOM SOFT CO, V11, P143, DOI 10.1080/10798587.2005.10642900
   Liu YG, 2011, APPL MATH COMPUT, V218, P1267, DOI 10.1016/j.amc.2011.06.007
   Malarvizhi N, 2019, MULTIMED TOOLS APPL, P1
   Mirkin BG., 1970, Avtomatika i Telemekhanika, V5, P120
   Nair L. R., 2019, MULTIMED TOOLS APPL, P1
   Peng W, 2006, PROC INT C TOOLS ART, P355
   Pham-Gia T, 2008, COMMUN STAT-SIMUL C, V37, P320, DOI 10.1080/03610910701790475
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Rodrigo Sergio G., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8872869
   Sato-Ilic M, 2011, PROCEDIA COMPUT SCI, V6, DOI 10.1016/j.procs.2011.08.066
   Selvi AS, 2020, MULTIMED TOOLS APPL, V79, P4115, DOI 10.1007/s11042-019-7727-9
   Setia L., 2006, MIR '06, P173
   Tai V, 2019, COMMUN STAT SIMUL CO, P1
   Van TV, 2018, SANKHYA SER B, V80, P19, DOI 10.1007/s13571-018-0159-0
   Tai VV, 2017, J STAT COMPUT SIM, V87, P1964, DOI 10.1080/00949655.2017.1300663
   VoVan T, 2018, COMMUN STAT-THEOR M, V47, P1792, DOI 10.1080/03610926.2017.1327075
   Thao NT, 2017, ADV DATA ANAL CLASSI, V11, P629, DOI 10.1007/s11634-016-0253-y
   Vovan T, 2021, ANN OPER RES, V303, P359, DOI 10.1007/s10479-020-03606-8
   Vovan T, 2017, J APPL STAT, V44, P385, DOI 10.1080/02664763.2016.1174194
   Wang MH, 2018, CELL DEATH DIS, V9, DOI 10.1038/s41419-017-0013-8
   Zhang XF, 2020, MULTIMED TOOLS APPL, V79, P633, DOI 10.1007/s11042-019-08041-x
   Zhao YK, 2020, MULTISENS RES, V33, P313, DOI 10.1163/22134808-20191350
NR 43
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35193
EP 35215
DI 10.1007/s11042-020-09975-3
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000578275300001
DA 2024-07-18
ER

PT J
AU Gao, YK
   Zhang, YB
   Li, HB
   Zhang, WM
AF Gao, Yakun
   Zhang, Yanbo
   Li, Haibin
   Zhang, Wenming
TI Single image dehazing based on single pixel energy minimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Random initialization; Propagation; Random search;
   Energy minimization
ID QUALITY ASSESSMENT; VISIBILITY
AB The common dehazing algorithms always assume that the transmission values of all the pixels in an image block are the same (local consistency assumption). However, it is easy to appear "halo" for image regions where the depth changes obviously. In this paper, we calculate the transmission of each pixel separately without the local consistency assumption. First, we initialize a random transmission value for each pixel in the whole image. Then, we optimize the transmission values through several iterations by minimizing an energy function, which contains the data term and penalty term. In each iteration, we take two procedures of propagation and random search to optimize transmission values. Finally, we use the optimized transmission and the estimated atmospheric light to calculate the haze-free image. Comparison experiments show that our algorithm can remove haze effectively, and obtain the best performance.
C1 [Gao, Yakun] Henan Inst Technol, Sch Elect Engn & Automat, Xinxiang 453003, Henan, Peoples R China.
   [Gao, Yakun; Zhang, Yanbo; Li, Haibin; Zhang, Wenming] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Henan Institute of Technology; Yanshan University
RP Li, HB (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM hbli@ysu.edu
RI li, haibin/A-1012-2012; Zhang, Yanbo/IQU-6845-2023
CR Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Carnec M, 2008, SIGNAL PROCESS-IMAGE, V23, P239, DOI 10.1016/j.image.2008.02.003
   Economopoulos TL, 2010, IMAGE VISION COMPUT, V28, P45, DOI 10.1016/j.imavis.2009.04.011
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   FATTAL R, 2008, ACM T GRAPHIC, V27
   Gao YK, 2018, IET IMAGE PROCESS, V12, P637, DOI 10.1049/iet-ipr.2017.0570
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang DW, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER NETWORK, ELECTRONIC AND AUTOMATION (ICCNEA), P294, DOI 10.1109/ICCNEA.2017.107
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Koschmieder H., 1924, PHYS FREIEN ATM, P171
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Li YA, 2016, NEUROCOMPUTING, V182, P221, DOI 10.1016/j.neucom.2015.12.032
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mi ZT, 2016, IET IMAGE PROCESS, V10, P206, DOI 10.1049/iet-ipr.2015.0112
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Rahman MAA, 1997, V. YERLICI - ENGINEERING AND EDUCATION, P1
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
NR 32
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5111
EP 5129
DI 10.1007/s11042-020-08964-w
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574800200001
DA 2024-07-18
ER

PT J
AU Yang, TJ
   Zhang, TS
   Huang, L
AF Yang, Tiejun
   Zhang, Tianshu
   Huang, Lin
TI Classification of industrial surface defects based on neural
   architecture search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural architecture search; Deep convolutional neural networks; Surface
   defect classification
AB Surface defect classification (SDC) is the visual inspection of the surface of an object to identify appearance defects. Efficient and accurate SDC is i mportant for improving the quality of industrial products. A manually designed convolutional neural network (CNN) is traditionally used for SDC. In this study, a simpler SDC scheme with a higher classification accuracy, named NAS-SDC, is developed based on the neural architecture search (NAS) technique. A max-pooling cell based on NASNet is introduced to reduce the search space and the number of network parameters, thus simplifying the candidate operators for the search. Two network architectures are proposed to stack the search candidates or the best cells. The proposed method can be used to automatically design an efficient CNN model for SDC on a specific dataset. Experimental results show that the proposed method can find the best cells in similar to 11 h using a single graphics processing unit (GPU) and achieves higher classification accuracies (99.98%, 99.8% and 99.26%) than state-of-the-art methods on the Northeastern University (NEU-CLS), DAGM, and bridge defect datasets. The number of network parameters used in the proposed method is only 0.35 M, and the average test time per sample is approximately 61 ms, thus achieving a balance between performance and speed.
C1 [Yang, Tiejun; Zhang, Tianshu; Huang, Lin] Guilin Univ Technol, Guangxi Key Lab Embedded Technol & Intelligent Sy, Guangxi 541004, Guilin, Peoples R China.
C3 Guilin University of Technology
RP Huang, L (corresponding author), Guilin Univ Technol, Guangxi Key Lab Embedded Technol & Intelligent Sy, Guangxi 541004, Guilin, Peoples R China.
EM hlcucu@qq.com
RI Yang, Tiejun/AAJ-8197-2020; zhang, tian/GZK-6001-2022
OI Yang, Tiejun/0000-0002-8644-4651; Huang, Lin/0000-0002-2678-2085
FU National Natural Science Foundation of China [61941202]; Guangxi Natural
   Science Foundation [2018GXNSFBA281081]; Guangxi Key Laboratory Fund of
   Embedded Technology and Intelligent System [2019-01-08, 2019-02-01]
FX This research was supported in part by the National Natural Science
   Foundation of China (61941202), the Guangxi Natural Science Foundation
   (2018GXNSFBA281081), and the Guangxi Key Laboratory Fund of Embedded
   Technology and Intelligent System (2019-01-08, 2019-02-01).
CR [Anonymous], 2017, P ICLR
   Baker B., 2017, ICLR
   Cai NA, 2016, IEEE T COMP PACK MAN, V6, P161, DOI 10.1109/TCPMT.2015.2501284
   Chen PH, 2016, IEEE IMAGE PROC, P749, DOI 10.1109/ICIP.2016.7532457
   Chondronasios A, 2016, INT J ADV MANUF TECH, V83, P33, DOI 10.1007/s00170-015-7514-3
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elsken T., 2018, The Journal of Machine Learning Research
   Hassaballah M., 2020, DEEP LEARNING COMPUT, V1st
   Hassaballah M., 2016, Image Feature Detectors and Descriptors
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hsieh YA, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000918
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jäger M, 2008, IEEE T IMAGE PROCESS, V17, P1700, DOI 10.1109/TIP.2008.2001043
   Jiang X, 2008, CIRP ANN-MANUF TECHN, V57, P555, DOI 10.1016/j.cirp.2008.03.110
   Lei J, 2018, NEUROCOMPUTING, V294, P72, DOI 10.1016/j.neucom.2018.03.013
   Li L, 2021, ASIA PAC J TOUR RES, V26, P428, DOI 10.1080/10941665.2018.1544913
   Lin M., 2013, ARXIV13124400
   Liu H., 2018, PROC INT C LEARN REP
   Pham H, 2018, PR MACH LEARN RES, V80
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Ren RX, 2018, IEEE T CYBERNETICS, V48, P929, DOI 10.1109/TCYB.2017.2668395
   Shao ZF, 2019, IEEE J-STARS, V12, P2663, DOI 10.1109/JSTARS.2019.2925456
   Siebel NT, 2008, IEEE C EVOL COMPUTAT, P3925, DOI 10.1109/CEC.2008.4631331
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002
   Stanley KO, 2019, NAT MACH INTELL, V1, P24, DOI 10.1038/s42256-018-0006-z
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tao X, 2018, IEEE T COMP PACK MAN, V8, P689, DOI 10.1109/TCPMT.2018.2794540
   Timm F, 2011, IMAGE PROCESSING MAC, VIV, P78
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang T, 2018, INT J ADV MANUF TECH, V94, P3465, DOI 10.1007/s00170-017-0882-0
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Xiao M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0197-y
   Zhong Z, 2018, PROC CVPR IEEE, P2423, DOI 10.1109/CVPR.2018.00257
   Zoph B., 2016, INT C LEARN REPR
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 39
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5187
EP 5202
DI 10.1007/s11042-020-09968-2
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574800200003
DA 2024-07-18
ER

PT J
AU Jelodar, H
   Wang, YL
   Rabbani, M
   Ahmadi, SBB
   Boukela, L
   Zhao, RX
   Larik, RSA
AF Jelodar, Hamed
   Wang, Yongli
   Rabbani, Mahdi
   Ahmadi, Sajjad Bagheri Baba
   Boukela, Lynda
   Zhao, Ruxin
   Larik, Raja Sohail Ahmed
TI A NLP framework based on meaningful latent-topic detection and sentiment
   analysis via fuzzy lattice reasoning on youtube comments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Topic model; LDA; Social media; YouTube
ID FLR CLASSIFIER; NETWORKS
AB Social media platforms such as Twitter, Facebook, and YouTube have unique architecture, norms, and culture. These platforms are valuable sources of people's opinions which should be examined for knowledge discovery and user behavior analysis. This paper proposed a novel content analysis to examine user reviews or movie comments on YouTube. In fact, the proposed hybrid framework is based on semantic and sentiment aspects using fuzzy lattice reasoning to meaningful latent-topic detection and utilizing sentiment analysis of user comments of the Oscar-nominated movie trailers on YouTube. Based on the word vector feature, classification algorithms are employed to detect the comments' sentiment level. The results of this study suggest that the hybrid framework could be effective to extract features associated and latent topics with sentiment valence on user comments. In addition, NLP methods can have an impressive role for exploring the relationship between user opinion and Oscar movies comments on YouTube.
C1 [Jelodar, Hamed; Wang, Yongli; Rabbani, Mahdi; Ahmadi, Sajjad Bagheri Baba; Boukela, Lynda; Zhao, Ruxin; Larik, Raja Sohail Ahmed] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Jelodar, H (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.
EM jelodar@njust.edu.cn; yongliwang@njust.edu.cn
RI Rabbani, Mahdi/JXN-0412-2024; Jelodar, Hamed/HTM-7150-2023; Bagheri Baba
   Ahmadi, Sajjad/ABG-5654-2020
OI Rabbani, Mahdi/0000-0002-6613-0954; Bagheri Baba Ahmadi,
   Sajjad/0000-0003-0382-0832; Jelodar, Hamed/0000-0002-0713-3143
FU National Natural Science Foundation of China [61941113]; Fundamental
   Research Fund for the Central Universities [30918015103, 30918012204];
   Nanjing Science and Technology Development Plan Project [201805036];
   China Academy of Engineering Consulting Research Project
   [2019-ZD-1-02-02]; National Social Science Foundation [18BTQ073]; State
   Grid Technology Project [5211XT190033]
FX This article has been awarded by the National Natural Science Foundation
   of China (61941113), the Fundamental Research Fund for the Central
   Universities (30918015103, 30918012204), Nanjing Science and Technology
   Development Plan Project (201805036), China Academy of Engineering
   Consulting Research Project(2019-ZD-1-02-02), National Social Science
   Foundation (18BTQ073), State Grid Technology Project (5211XT190033).
CR Abdi A, 2019, INFORM PROCESS MANAG, V56, P1245, DOI 10.1016/j.ipm.2019.02.018
   AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   Ahmad U, 2017, INFORM SYST, V69, P25, DOI 10.1016/j.is.2016.10.004
   Amarasekara I, 2019, PUBLIC UNDERST SCI, V28, P68, DOI 10.1177/0963662518786654
   Athanasiadis IN, 2007, STUD COMP INTELL, V67, P175
   Bhuiyan H, 2017, IEEE I C SIGNAL IMAG, P474, DOI 10.1109/ICSIPA.2017.8120658
   Blei David M, 2009, Text mining, P101, DOI DOI 10.1201/9781420059458.CH4
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chauhan Ganpat Singh, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P63, DOI 10.1007/978-981-13-3600-3_6
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Chidambarathanu K, 2019, CLUSTER COMPUT, P1
   Coban A, 2019, ARXIV190311983
   Cordero P, 2015, KNOWL-BASED SYST, V87, P16, DOI 10.1016/j.knosys.2015.07.018
   Cripps A, 2007, STUD COMPUT INTELL, V67, P263
   Curiskis SA, 2019, EVALUATION DOCUMENT
   Cutler A., 2001, Computing Science and Statistics, V33, P490
   Das S, 2019, TRANSPORT RES REC, V2673, P242, DOI 10.1177/0361198119842110
   De Gregorio M, 2018, APPL SOFT COMPUT, V72, P338, DOI 10.1016/j.asoc.2018.07.052
   Denecke K, 2015, ARTIF INTELL MED, V64, P17, DOI 10.1016/j.artmed.2015.03.006
   Dogan E, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP 2019), DOI 10.1109/idap.2019.8875879
   Edara Deepak Chowdary, 2023, Journal of Ambient Intelligence and Humanized Computing, P5309, DOI 10.1007/s12652-019-01399-8
   Ernst Julian, 2017, The Journal for Deradicalization, P1
   Ezpeleta E, 2018, LECT NOTES ARTIF INT, V10870, P514, DOI 10.1007/978-3-319-92639-1_43
   Gao Z, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014164
   Geng Y, 2016, ESANN 2017 P, P589
   Hoiles W, 2019, ARXIV191011703
   Hsu WY, 2019, WORLD WIDE WEB, V22, P1297, DOI 10.1007/s11280-018-0561-6
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Kaburlasos VG, 2007, INT J APPROX REASON, V45, P152, DOI 10.1016/j.ijar.2006.08.001
   Khan ML, 2017, COMPUT HUM BEHAV, V66, P236, DOI 10.1016/j.chb.2016.09.024
   Larsono RA, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), P49, DOI 10.1109/ICTS.2019.8850982
   Cunha AAL, 2019, LECT NOTES ARTIF INT, V11508, P561, DOI 10.1007/978-3-030-20912-4_51
   Li B, 2012, APPL SOFT COMPUT, V12, P1708, DOI 10.1016/j.asoc.2012.01.020
   Jiménez-Zafra SM, 2019, ARTIF INTELL MED, V93, P50, DOI 10.1016/j.artmed.2018.03.007
   Obadimu A, 2019, LECT NOTES COMPUT SC, V11549, P214, DOI 10.1007/978-3-030-21741-9_22
   Oksanen A, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.5007
   Orimaye S. O, 2012, P 21 INT C WORLD WID, P583
   Ottoni R, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P323, DOI 10.1145/3201064.3201081
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Poché E, 2017, INT C PROGRAM COMPRE, P196, DOI 10.1109/ICPC.2017.26
   Rambocas M, 2018, J RES INTERACT MARK, V12, P146, DOI 10.1108/JRIM-05-2017-0030
   Ranganatha S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATION SYSTEM AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTIONS (CSITSS), P1, DOI 10.1109/CSITSS.2016.7779430
   Schmidt T, 2019, LANGUAGE DATA KNOWLE
   Sharma A., 2012, P 2012 ACM RES APPL, P1, DOI DOI 10.1145/2401603.2401605
   Soldner F, 2019, P 3 WORKSH NAT LANG, P84
   Thelwall M, 2014, SENTISTRENGTH
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Thulasi PK, 2016, 2016 INTERNATIONAL CONFERENCE ON NEXT GENERATION INTELLIGENT SYSTEMS (ICNGIS), P272
   Tripto NI, 2018, 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING (ICBSLP)
   Tulkens Stephan., 2016, CLIN Journal, V6, P3
   Veletsianos G, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197331
   Walker J, 2019, SCALED ANAL MINECRAF
   Wu Shih-Jung, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1927, DOI 10.1007/s12652-018-0683-9
   Xia HS, 2020, ELECTRON COMMER RES, V20, P343, DOI 10.1007/s10660-019-09354-7
   Yang JF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3266
   Yang JF, 2018, PROC CVPR IEEE, P7584, DOI 10.1109/CVPR.2018.00791
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P303
   Zhao SC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P192, DOI 10.1145/3343031.3351062
NR 61
TC 16
Z9 17
U1 7
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4155
EP 4181
DI 10.1007/s11042-020-09755-z
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573192100002
DA 2024-07-18
ER

PT J
AU Kurmi, Y
   Chaurasia, V
AF Kurmi, Yashwant
   Chaurasia, Vijayshri
TI Content-based image retrieval algorithm for nuclei segmentation in
   histopathology images CBIR algorithm for histopathology image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histopathology images; Microscopic image segmentation; Contour
   enhancement; Content-based image retrieval (CBIR); Nuclei segmentation
ID CLUSTERING-ALGORITHM; ACTIVE CONTOUR; MODEL; CLASSIFICATION; RESOLUTION;
   DATASET; SCHEME; SET
AB In today's world, the medical diagnostic system shows a high reliance on medical imagery and digital nosology. To facilitate the fast and precise screening of samples, technology is leading towards the computer-aided disease diagnosis and grading. Image segmentation possesses high worth in the computer-aided disease diagnosis and grading systems to extract the region of interest. This paper presents a content-based image retrieval algorithm for histopathology image segmentation for identification and extraction of nuclei. The proposed technique furnishes nuclei segmentation in three cascaded stages; pre-processing, nuclei points and region refining, and composite nuclei segmentation. The performance of nuclei segmentation is investigated on six hematoxylins and eosin (H&E) stained histopathology images datasets. Simulation outcomes of the segmentation schemes confirm the superiority of the proposed method for nuclei segmentation in histopathology images in qualitative and quantitative analysis.
C1 [Kurmi, Yashwant] Maulana Azad Natl Inst Technol, Bhopal 462003, India.
   [Chaurasia, Vijayshri] Maulana Azad Natl Inst Technol, Elect & Commun Engn Dept, Bhopal 462003, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal; National Institute of Technology (NIT
   System); Maulana Azad National Institute of Technology Bhopal
RP Kurmi, Y (corresponding author), Maulana Azad Natl Inst Technol, Bhopal 462003, India.
EM yashwantkurmi18@gmail.com; vchaurasia@manit.ac.in
RI Chaurasia, Vijayshri/A-5554-2016; Kurmi, Yashwant/AAK-1374-2021
OI Chaurasia, Vijayshri/0000-0002-3347-5630; Kurmi,
   Yashwant/0000-0003-4986-2106
CR Ahmed PK, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1497-9
   Al-Kofahi Y, 2010, IEEE T BIO-MED ENG, V57, P841, DOI 10.1109/TBME.2009.2035102
   Ali S, 2012, IEEE T MED IMAGING, V31, P1448, DOI 10.1109/TMI.2012.2190089
   Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang H, 2013, IEEE T MED IMAGING, V32, P670, DOI 10.1109/TMI.2012.2231420
   Chowdhary C, 2015, DECREASE FALSE ASSUM, P12
   Chowdhary C, 2018, SEGMENTATION MAMMOGR, V01, P75
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Dice Lee R, 1945, ECOLOGY
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Dundar MM, 2011, IEEE T BIO-MED ENG, V58, P1977, DOI 10.1109/TBME.2011.2110648
   Fatakdawala H, 2010, IEEE T BIO-MED ENG, V57, P1676, DOI 10.1109/TBME.2010.2041232
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gu YF, 2017, IEEE T GEOSCI REMOTE, V55, P6547, DOI 10.1109/TGRS.2017.2729882
   Hanbury AG, 2001, IEEE T IMAGE PROCESS, V10, P1842, DOI 10.1109/83.974569
   HARALICK RM, 1989, IEEE T ACOUST SPEECH, V37, P2067, DOI 10.1109/29.45553
   HEIJMANS HJAM, 1991, IEEE T PATTERN ANAL, V13, P568, DOI 10.1109/34.87343
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Ishii S, 2020, MICROSCOPY-JPN, V69, P79, DOI 10.1093/jmicro/dfaa007
   Janowczyk A, 2018, COMP M BIO BIO E-IV, V6, P270, DOI 10.1080/21681163.2016.1141063
   Jiu MY, 2017, IEEE T IMAGE PROCESS, V26, P1820, DOI 10.1109/TIP.2017.2666038
   Khayam S., 2003, DISCRETE COSINE TRAN
   Kim W, 2020, IEEE T IMAGE PROCESS, V29, P8055, DOI 10.1109/TIP.2020.3011269
   Kresch R, 1998, IEEE T IMAGE PROCESS, V7, P1387, DOI 10.1109/83.718480
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Kurmi Y, 2020, OPTIK, V218, DOI 10.1016/j.ijleo.2020.164636
   Kurmi Y, 2020, IET IMAGE PROCESS, V14, P2808, DOI 10.1049/iet-ipr.2019.1631
   Kurmi Y, 2021, SIGNAL IMAGE VIDEO P, V15, P175, DOI 10.1007/s11760-020-01732-1
   Kurmi Y, 2019, J MED IMAGING RADIAT, V50, P514, DOI 10.1016/j.jmir.2019.07.004
   Kurmi Y, 2018, IET IMAGE PROCESS, V12, P1491, DOI 10.1049/iet-ipr.2017.1020
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Lei W, 2020, IEEE ACCESS, V8, P132694, DOI 10.1109/ACCESS.2020.3011025
   Li XY, 2015, IEEE T BIO-MED ENG, V62, P1862, DOI 10.1109/TBME.2015.2405791
   Liang JL, 2013, IEEE T IMAGE PROCESS, V22, P2207, DOI 10.1109/TIP.2013.2246518
   Ma DF, 2020, J PHYTOPATHOL, V168, P652, DOI 10.1111/jph.12945
   McCann MT, 2014, IEEE T IMAGE PROCESS, V23, P2033, DOI 10.1109/TIP.2014.2307475
   Mujica-Vargas D, 2020, INT J FUZZY SYST, V22, P901, DOI 10.1007/s40815-020-00824-x
   Nameirakpam D, 2020, MULTIMED TOOLS APPL, V03
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng YL, 2019, J COMPUT SCI-NETH, V33, P11, DOI 10.1016/j.jocs.2019.03.003
   Vu QD, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00053
   Sheela C, 2020, MULTIMED TOOLS APPL, V02
   Sirinukunwattana K, 2015, IEEE T MED IMAGING, V34, P2366, DOI 10.1109/TMI.2015.2433900
   Song J, 2018, IEEE T IMAGE PROCESS, V27, P5759, DOI 10.1109/TIP.2018.2857001
   Song J, 2017, IEEE J BIOMED HEALTH, V21, P451, DOI 10.1109/JBHI.2015.2504422
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Srinivas U, 2014, IEEE T MED IMAGING, V33, P1163, DOI 10.1109/TMI.2014.2306173
   Su H, 2016, IEEE T MED IMAGING, V35, P1575, DOI 10.1109/TMI.2016.2520502
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Wang W, 2011, IEEE T MED IMAGING, V30, P621, DOI 10.1109/TMI.2010.2089693
   Wang ZZ, 2016, PATTERN RECOGN, V53, P300, DOI 10.1016/j.patcog.2015.12.009
   Xia J, 2020, IEEE ACCESS, V8, P135897, DOI 10.1109/ACCESS.2020.3011224
   Xu Y, 2012, PROC CVPR IEEE, P964, DOI 10.1109/CVPR.2012.6247772
   Ye JB, 2017, IEEE T SIGNAL PROCES, V65, P2317, DOI 10.1109/TSP.2017.2659647
   Yu CJ, 2020, COMPUT MED IMAG GRAP, V81, DOI [10.1016/j.compmedimag.2019.101697, 10.1016/j.compmedimg.2019.101697]
   Zafari S, 2015, IEEE T IMAGE PROCESS, V24, P5942, DOI 10.1109/TIP.2015.2492828
   Zerovnik J, 2017, TEACH STAT, V39, P88, DOI 10.1111/test.12133
   Zhao H, 2020, MULTIMED TOOLS APPL, V02
NR 62
TC 12
Z9 13
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3017
EP 3037
DI 10.1007/s11042-020-09797-3
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100009
DA 2024-07-18
ER

PT J
AU Asadianfam, S
   Shamsi, M
   Kenari, AR
AF Asadianfam, Shiva
   Shamsi, Mahboubeh
   Kenari, Abdolreza Rasouli
TI TVD-MRDL: traffic violation detection system using MapReduce-based deep
   learning for large-scale data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MapReduce-based; Deep learning; Distributed processing; Drivers'
   behavior detection; Hadoop; Unsafe behaviors
ID BIG DATA ANALYTICS; NEURAL-NETWORKS; DRIVING BEHAVIORS; SIGN DETECTION;
   RECOGNITION; ALGORITHM; MODELS; OPTIMIZATION; RISK; LANE
AB Maintaining a fluid and safe traffic is a major challenge for human societies because of its social and economic impacts. Various technologies have considerably paved the way for the elimination of traffic problems and have been able to effectively detect drivers' violations. However, the high volume of the real-time data collected from surveillance cameras and traffic sensors along with the data obtained from individuals have made the use of traditional methods ineffective. Therefore, using Hadoop for processing large-scale structured and unstructured data as well as multimedia data can be of great help. In this paper, the TVD-MRDL system based on the MapReduce techniques and deep learning was employed to discover effective solutions. The Distributed Deep Learning System was implemented to analyze traffic big data and to detect driver violations in Hadoop. The results indicated that more accurate monitoring automatically creates the power of deterrence and behavior change in drivers and it prevents drivers from committing unusual behaviors in society. So, if the offending driver is identified quickly after committing the violation and is punished with the appropriate punishment and dealt with decisively and without negligence, we will surely see a decrease in violations at the community level. Also, the efficiency of the TVD-MRDL performance increased by more than 75% as the number of data nodes increased.
C1 [Asadianfam, Shiva] Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
   [Shamsi, Mahboubeh; Kenari, Abdolreza Rasouli] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
C3 Islamic Azad University
RP Shamsi, M (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
EM sh_asadianfam_stu@qom-iau.ac.ir; shamsi@qut.ac.ir; rasouli@qut.ac.ir
RI Rasouli, Abdolreza/A-9461-2010; Asadianfam, Shiva/ABF-1231-2021; Shamsi,
   Mahboubeh/AAF-4417-2022; Rasouli Kenari, Abdolreza/AAC-5678-2022;
   Shamsi, Mahboubeh/AFI-9693-2022
OI Asadianfam, Shiva/0000-0002-0062-7079; Shamsi,
   Mahboubeh/0000-0003-1238-4315; Rasouli Kenari,
   Abdolreza/0000-0003-4817-9380; Shamsi, Mahboubeh/0000-0003-1238-4315
CR Afrati FN, 2018, INFORM SYST, V77, P129, DOI 10.1016/j.is.2018.06.005
   Afrati FN, 2018, J COMPUT SYST SCI, V94, P98, DOI 10.1016/j.jcss.2017.02.007
   Alham NK, 2011, COMPUT MATH APPL, V62, P2801, DOI 10.1016/j.camwa.2011.07.046
   Aoyama K, 1997, IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P649, DOI 10.1109/ITSC.1997.660550
   Arcos-García A, 2018, NEUROCOMPUTING, V316, P332, DOI 10.1016/j.neucom.2018.08.009
   Arcos-García A, 2018, NEURAL NETWORKS, V99, P158, DOI 10.1016/j.neunet.2018.01.005
   Arcos-García A, 2017, EXPERT SYST APPL, V89, P286, DOI 10.1016/j.eswa.2017.07.042
   Asadianfam S, 2020, MULTIMED TOOLS APPL, V79, P24645, DOI 10.1007/s11042-020-09099-8
   Banharnsakun A, 2017, PATTERN RECOGN LETT, V93, P78, DOI 10.1016/j.patrec.2016.07.027
   Bendre M, 2019, EXPERT SYST APPL, V116, P108, DOI 10.1016/j.eswa.2018.09.017
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Cantabella M, 2019, FUTURE GENER COMP SY, V90, P262, DOI 10.1016/j.future.2018.08.003
   Cattaneo G, 2016, ENCY BIOINFORMATICS, P1
   Chen CH, 2017, PATTERN RECOGN LETT, V93, P113, DOI 10.1016/j.patrec.2016.11.004
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   de la Escalera A, 2004, IEEE T INTELL TRANSP, V5, P57, DOI 10.1109/TITS.2004.828173
   De Mauro A, 2018, INFORM PROCESS MANAG, V54, P807, DOI 10.1016/j.ipm.2017.05.004
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Elotmani S, 2014, INT CONF MULTIMED, P459, DOI 10.1109/ICMCS.2014.6911250
   Gantz J., 2011, IDC IVIEW, P1
   Ríos LG, 2014, IEEE INT CONGR BIG, P816, DOI 10.1109/BigData.Congress.2014.142
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Jeon S, 2016, FUTURE GENER COMP SY, V65, P182, DOI 10.1016/j.future.2015.11.022
   Kasaei S. H. M., 2011, 2011 European Intelligence and Security Informatics Conference, P234, DOI 10.1109/EISIC.2011.50
   Kouanou AT, 2018, INFORM MED UNLOCKED
   Krishnan A.R., 2009, Proc. IEEE Global Telecommun. Conf., Honolulu, P1
   Laney D., 2001, META GROUP RES NOTE, P1, DOI [10.1016/j.infsof.2008.09.005, DOI 10.1016/J.INFSOF.2008.09.005]
   Lotfi E, 2011, MAJLESI J MULTIMEDIA, V1
   Manogaran G, 2018, FUTURE GENER COMP SY, V86, P433, DOI 10.1016/j.future.2018.02.048
   Millie DF, 2013, ESTUAR COAST SHELF S, V125, P57, DOI 10.1016/j.ecss.2013.04.001
   Moghaddam AM, 2014, SAFETY SCI, V62, P90, DOI 10.1016/j.ssci.2013.08.004
   Munoz-Organero M, 2018, COMPUT ENVIRON URBAN, V68, P1, DOI 10.1016/j.compenvurbsys.2017.09.005
   Nguyen V, 2018, ENG SCI TECHNOL, V21, P822, DOI 10.1016/j.jestch.2018.06.006
   Osman AMS, 2019, FUTURE GENER COMP SY, V91, P620, DOI 10.1016/j.future.2018.06.046
   Patterson J., 2017, Deep Learning: A Practitioners Approach
   Rahemi Z, 2017, PERS INDIV DIFFER, V116, P314, DOI 10.1016/j.paid.2017.05.004
   Rakotonirainy A, 2014, PERVASIVE MOB COMPUT, V14, P147, DOI 10.1016/j.pmcj.2014.06.004
   Sallah M, 2011, ROAD SIGN DETECTION
   Saptharishi M, 2002, IEEE T ROBOTIC AUTOM, V18, P826, DOI 10.1109/TRA.2002.804501
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Se Hyun Park, 1999, Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300), P201, DOI 10.1109/ICCIMA.1999.798529
   Secundo G, 2017, J INTELLECT CAP, V18, P242, DOI 10.1108/JIC-10-2016-0097
   Shvachko K, 2010, IEEE S MASS STOR SYS
   Phung SL, 2016, COMPUT VIS IMAGE UND, V149, P186, DOI 10.1016/j.cviu.2016.01.011
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tao D, 2017, ACCIDENT ANAL PREV, V99, P228, DOI 10.1016/j.aap.2016.12.009
   Bui-Minh T, 2012, INT CONF CONTR AUTO, P120, DOI 10.1109/ICCAIS.2012.6466570
   Le TM, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9050798
   Valcarce D, 2018, ENG APPL ARTIF INTEL, V75, P114, DOI 10.1016/j.engappai.2018.08.006
   Wang JJ, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P1203, DOI 10.1109/ICCT.2012.6511380
   Wang WN, 2015, SIGNAL PROCESS-IMAGE, V39, P499, DOI 10.1016/j.image.2015.07.006
   White T., 2012, HADOOP DEFINITIVE GU
   YANG J, 2014, SPRINGERBRIEF COMPUT, P1
   Yi SC, 2015, COMPUT ELECTR ENG, V42, P23, DOI 10.1016/j.compeleceng.2015.01.002
   Yin L, 2015, APPL GEOGR, V63, P337, DOI 10.1016/j.apgeog.2015.07.010
   Yu Y, 2015, COMPUT HUM BEHAV, V48, P392, DOI 10.1016/j.chb.2015.01.075
   Yu YT, 2016, ISPRS J PHOTOGRAMM, V113, P106, DOI 10.1016/j.isprsjprs.2016.01.005
   Zhang B, 2018, FUTURE GENER COMP SY, V87, P549, DOI 10.1016/j.future.2017.09.063
   Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066
   Zhao WZ, 2009, LECT NOTES COMPUT SC, V5931, P674, DOI 10.1007/978-3-642-10665-1_71
NR 60
TC 9
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2489
EP 2516
DI 10.1007/s11042-020-09714-8
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000005
DA 2024-07-18
ER

PT J
AU Albargathe, SMBK
   Kamberli, E
   Kandemirli, F
   Rahebi, J
AF Boubakar Khalifa Albargathe, Salma M.
   Kamberli, Ersin
   Kandemirli, Fatma
   Rahebi, Javad
TI Blood vessel segmentation and extraction using H-minima method based on
   image processing techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fundus camera; Image processing; Retina image
ID RETINAL IMAGES
AB In this paper, the H-minima transform is used for blood vessel segmentation. The aim of this study is to get the high accuracy of blood vessel segmentation in retinal images. In this study the good result and good performance were got. We compared our result with other methods. Also for simulation result we implemented on DRIVE and STARE database. The proposed method shows very remarkable performance on pathological retinal images. For the implementing of the proposed method MATLAB 2019a software is used. The running time of this method was 1 s for each image and the average accuracy for STARE dataset and DRIVE dataset achieved to 0.9591 and 0.9672 respectively.
C1 [Boubakar Khalifa Albargathe, Salma M.] Kastamonu Univ, Dept Mat Sci & Engn, Kastamonu, Turkey.
   [Kamberli, Ersin; Kandemirli, Fatma] Kastamonu Univ, Dept Biomed Engn, Kastamonu, Turkey.
   [Rahebi, Javad] Altinbas Univ, Dept Elect & Comp Engn, Istanbul, Turkey.
C3 Kastamonu University; Kastamonu University; Altinbas University
RP Kamberli, E (corresponding author), Kastamonu Univ, Dept Biomed Engn, Kastamonu, Turkey.
EM albragate83@yahoo.com; ekamberli@kastamonu.edu.tr;
   fatma@kastamonu.edu.tr; cevat.rahebi@altinbas.edu.tr
CR Acharjya PP, 2014, INT J COMPUT ELECT A, V8, P859
   Bhabatosh C, 2011, DIGITAL IMAGE PROCES
   da Silva SS, 2017, INT J INNOV, V5, P1, DOI 10.5585/iji.v5i1.138
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feng ZW, 2017, IEEE IMAGE PROC, P1742, DOI 10.1109/ICIP.2017.8296580
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Ghoshal R, 2019, MULTIMED TOOLS APPL, V78, P25221, DOI 10.1007/s11042-019-7719-9
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   HUNT B.R., 2014, A guide to MATLAB: For beginners and experiences users
   Ismail NHF, 2016, MATEC WEB CONF, V74, DOI 10.1051/matecconf/20167400025
   Kumbhar PG., 2015, INT J ADV RES COMPUT, V5, P160
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Rahebi J, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0085-2
   Raimondo F, 2005, IEEE T IMAGE PROCESS, V14, P1288, DOI 10.1109/TIP.2005.852806
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Saleh MD, 2012, COMPUT METHOD BIOMEC, V15, P517, DOI 10.1080/10255842.2010.545949
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tashfeen S.H., 2017, THESIS BRAC U DHAKA
   WOLF GW, 1991, COMPUT GEOSCI, V17, P1359, DOI 10.1016/0098-3004(91)90002-U
NR 24
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2565
EP 2582
DI 10.1007/s11042-020-09646-3
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000001
DA 2024-07-18
ER

PT J
AU Ershadi-Nasab, S
   Kasaei, S
   Sanaei, E
AF Ershadi-Nasab, Sara
   Kasaei, Shohreh
   Sanaei, Esmaeil
TI Uncalibrated multi-view multiple humans association and 3D pose
   estimation by adversarial learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D pose estimation; Multi-view; Human associations; Uncalibrated
   cameras; Generative adversarial
ID ANOMALY DETECTION; REGRESSION; ALGORITHM; NETWORK; MOTION
AB Multiple human 3D pose estimation is a useful but challenging task in computer vison applications. The ambiguities in estimation of 2D and 3D poses of multiple persons can be verified by using multi-view frames, in which the occluded or self-occluded body parts of some persons might be visible in other camera views. But, when cameras are moving and uncalibrated, estimating the association of multiple human body parts among different camera views is a challenging task. This paper presents novel methods for multiple human 3D pose estimation and pose association in multi-view camera frames in an uncalibrated camera setup using an adversarial learning framework. The generator is a 3D pose estimation network that learns a mapping of distance and angular difference matrices between 2D and 3D spaces. The discriminator tries to distinguish the predicted 3D poses from the ground-truth, which helps to enforce the pose estimator to generate valid 3D poses. To increase the accuracy of the generator network, multi-view frames are used. The estimated 3D poses are associated among multi-view frames by a statistical method. The association and relative rotation and translation of cameras to each other are also obtained. This step empowers the generator network and removes ambiguities in the estimation of occluded or self-occluded body parts. The global 3D poses are the inputs to the discriminator network to imposter the discriminator that they come from the ground-truth. Experimental results conducted on multi-view and multi-person datasets (such as Campus, Shelf,Utrecht Multi-Person Motion(UMPM), and also KTH Football 2) indicate that the proposed method achieves superior performance in comparison with other state-of-the-art methods while it does require any calibration information in priori.
C1 [Ershadi-Nasab, Sara; Sanaei, Esmaeil] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology; Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM ershadinasab@sharif.edu; kasaei@sharif.edu; sanaei@sharif.edu
CR Afrouzian R, 2016, MULTIMED TOOLS APPL, V75, P6809, DOI 10.1007/s11042-015-2611-8
   Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45
   Aujla GS, 2022, IEEE T SUST COMPUT, V7, P263, DOI 10.1109/TSUSC.2019.2907110
   BELAGIANNIS V, 2016, IEEE T PATTERN ANAL, V38, P1929, DOI DOI 10.1109/TPAMI.2015.2509986
   Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Biswas P, 2006, IEEE T AUTOM SCI ENG, V3, P360, DOI 10.1109/TASE.2006.877401
   Bridgeman Lewis, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2487, DOI 10.1109/CVPRW.2019.00304
   Burenius M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1634, DOI 10.1109/ICCVW.2011.6130445
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen C, 2016, ARXIV ABS161206524
   Chen L, 2020, PROC CVPR IEEE, P3276, DOI 10.1109/CVPR42600.2020.00334
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dong JT, 2019, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2019.00798
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Ershadi-Nasab S, 2018, ELECTRON LETT, V54, P292, DOI 10.1049/el.2017.4052
   Ershadi-Nasab S, 2016, MMTA UNPUB
   Garg S, 2019, IEEE T NETW SERV MAN, V16, P924, DOI 10.1109/TNSM.2019.2927886
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gower J, 2004, OXFORD STAT SCI SERI
   Gulati A., 2018, PROC IEEE INT C COMM, V2018, P1
   Heng L, 2013, IEEE INT C INT ROBOT, P1793, DOI 10.1109/IROS.2013.6696592
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   HURLEY JR, 1962, BEHAV SCI, V7, P258, DOI 10.1002/bs.3830070216
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Jindal A, 2018, IEEE GLOB COMM CONF, DOI 10.1109/ICOPS35962.2018.9575456
   Kazemi V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.48
   Kim JH, 2013, IEEE I CONF COMP VIS, P1896, DOI 10.1109/ICCV.2013.238
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Li MP, 2020, COMPUT VIS MEDIA, V6, P147, DOI 10.1007/s41095-020-0171-y
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Lian J, 2020, IEEE T IND INFORM, V16, P1343, DOI 10.1109/TII.2019.2945403
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Makkar A., 2018, PROC IEEE GLOBAL COM, P1
   Makkar A, 2018, SUSTAIN COMPUT-INFOR, V20, P174, DOI 10.1016/j.suscom.2018.02.003
   Miglani A, 2019, VEH COMMUN, V20, DOI 10.1016/j.vehcom.2019.100184
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3
   Rosales R., 2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, pI, DOI 10.1109/CVPR.2001.990566
   Schick A, 2015, IEEE WINT CONF APPL, P140, DOI 10.1109/WACV.2015.26
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tanke J, 2019, LECT NOTES COMPUT SC, V11824, P537, DOI 10.1007/978-3-030-33676-9_38
   Tekin B, 2016, ARXIV ABS160505180
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   van der Aa N. P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1264, DOI 10.1109/ICCVW.2011.6130396
   Varga D, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P184, DOI 10.1109/ICCVW.2015.33
   Wang XY, 2019, IEEE ACCESS, V7, P119668, DOI 10.1109/ACCESS.2019.2936709
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
   Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17
NR 62
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2461
EP 2488
DI 10.1007/s11042-020-09733-5
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000002
DA 2024-07-18
ER

PT J
AU Raghuwanshi, G
   Tyagi, V
AF Raghuwanshi, Ghanshyam
   Tyagi, Vipin
TI Texture image retrieval using hybrid directional Extrema pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture patterns; Extrema patterns; Image retrieval; CBIR
ID CLASSIFICATION; DESCRIPTOR; FEATURES
AB In this paper, a new descriptor Hybrid Directional Extrema Pattern (HDEP) for the retrieval of texture images by integrating the concept of Weight Difference Directional Local Extrema Pattern (WDDLEP) and Directional Local Extrema Pattern (DLEP) is proposed. The texture patterns are computed for four principle directions i.e., 0 degrees, 45 degrees, 90 degrees, 135 degrees. The proposed approach considers the difference between central pixel and corresponding neighboring pixels in the specified directions. This difference is used as weight in next stage. This weight is compared with a user-defined threshold to determine the value of strong bits in a feature vector. Experimental evaluation on three benchmark datasets (Brodatz, VisTex and Describable Textures Dataset) illustrates the better performance of proposed system with the other state-of-the-art techniques on two basic parameters i.e., average retrieval rate and time. The proposed approach is evaluated against various state-of-the-art texture image-retrieval systems based on local binary pattern, directional local extrema pattern, local tetra pattern, block-based local binary pattern, center-symmetric local binary pattern and wavelet. Significant improvement has been achieved in image retrieval performance due to assignment of weight in the pattern generation process. Further, the proposed approach is capable of differentiating different texture patterns more efficiently because it uses magnitude of pixel differences to determine the value of current pixel rather than the sign of pixel differences.
C1 [Raghuwanshi, Ghanshyam] Manipal Univ Jaipur, Jaipur, Rajasthan, India.
   [Tyagi, Vipin] Jaypee Univ Engn & Technol, Guna 473226, MP, India.
C3 Manipal University Jaipur
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Guna 473226, MP, India.
EM ghanshyam.raghuwanshi@jaipur.manipal.edu; dr.vipin.tyagi@gmail.com
RI Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686
CR Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Brodatz P., 1996, TEXTURES PHOTOGRAPHI
   Camalan S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232776
   CHANG SK, 1992, IEEE T KNOWL DATA EN, V4, P431, DOI 10.1109/69.166986
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Deselaers T., 2005, WORK NOT CLEF WORKSH
   Dinakaran S, 2010, J INSECT SCI, V10, DOI 10.1673/031.010.4601
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gemert JC, 2003, THESIS
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Krommweh J, 2010, J VIS COMMUN IMAGE R, V21, P364, DOI 10.1016/j.jvcir.2010.02.011
   Long FH, 2003, SIG COM TEC, P1
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pi MH, 2006, IEEE T IMAGE PROCESS, V15, P3078, DOI 10.1109/TIP.2006.877509
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Raghuwanshi G, 2018, ADV COMPUTING DATA S, V905, DOI [10.1007/978-981-13-1810-8_45, DOI 10.1007/978-981-13-1810-8_45]
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Reddy AH, 2015, AEU-INT J ELECTRON C, V69, P290, DOI 10.1016/j.aeue.2014.09.015
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Shyu CR, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P30, DOI 10.1109/IVL.1998.694482
   Singh M, 2019, ADV COMPUTING DATA S
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song JK, 2020, INT J COMPUT VISION, V128, P2243, DOI 10.1007/s11263-020-01305-2
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Tyagi V., 2017, Content-based image retrieval, DOI [10.1007/978-981-10-6759-4, DOI 10.1007/978-981-10-6759-4]
   Tyagi V., 2018, UNDERSTANDING DIGITA
   Vassilieva NS, 2009, PROGRAM COMPUT SOFT+, V35, P158, DOI 10.1134/S0361768809030049
   Wei Z, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6283987
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Yuan BH, 2020, NEURAL COMPUT APPL, V32, P11717, DOI 10.1007/s00521-019-04657-0
   Zand M, 2015, J VIS COMMUN IMAGE R, V26, P305, DOI 10.1016/j.jvcir.2014.10.005
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
NR 44
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2295
EP 2317
DI 10.1007/s11042-020-09618-7
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366600006
DA 2024-07-18
ER

PT J
AU Paul, S
   Saha, S
   Hasanuzzaman, M
AF Paul, Sayanta
   Saha, Sriparna
   Hasanuzzaman, Mohammed
TI Identification of cyberbullying: A deep learning based multimodal
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyberbullying; Multimodal information fusion; Deep learning
AB Cyberbullying can be delineated as a purposive and recurrent act, which is aggressive in nature, done via different social media platforms such as Facebook, Twitter, Instagram and others. While existing approaches for detecting cyberbullying concentrate on unimodal approaches, e.g., text or visual based methods, we proposed a deep learning based early identification framework which is a multimodal (textual and visual) approach (inspired by the informal nature of social media data) and performed a broad analysis on vine dataset. Early identification framework predicts a post or a media session as bully or non-bully as early as possible as we have processed information for each of the modalities (both independently and fusion-based) chronologically. Our multimodal feature-fusion based experimental analysis achieved 0.75 F-measure using ResidualBiLSTM-RCNN architecture, which clearly reflects the effectiveness of our proposed framework. All the codes of this study are made publicly available on paper's companion repository.
C1 [Paul, Sayanta; Saha, Sriparna] Indian Inst Technol Patna, Bihta, India.
   [Hasanuzzaman, Mohammed] Cork Inst Technol Cork, Cork, Ireland.
C3 Indian Institute of Technology (IIT) - Patna; Munster Technological
   University (MTU)
RP Paul, S (corresponding author), Indian Inst Technol Patna, Bihta, India.
EM 1811cs16@iitp.ac.in; sriparna@iitp.ac.in; Mohammed.Hasanuzzaman@cit.ie
RI Hasanuzzaman, Mohammed/AAT-6303-2020
OI Hasanuzzaman, Mohammed/0000-0003-1838-0091
FU Young Faculty Research Fellowship (YFRF) Award; Visvesvaraya Ph.D.
   Scheme for Electronics and IT, Ministry of Electronics and Information
   Technology (MeitY), Government of India
FX We would like to express our gratitude to Rahat et al. [25, 26] for
   sharing their labeled multimodal dataset, Vine. Dr. Sriparna Saha
   gratefully acknowledges the Young Faculty Research Fellowship (YFRF)
   Award, supported by Visvesvaraya Ph.D. Scheme for Electronics and IT,
   Ministry of Electronics and Information Technology (MeitY), Government
   of India, being implemented by Digital India Corporation (formerly Media
   Lab Asia) for carrying out this research.
CR Agrawal S, 2018, LECT NOTES COMPUT SC, V10772, P141, DOI 10.1007/978-3-319-76941-7_11
   [Anonymous], 2011, Modeling the detection of Textual Cyberbullying
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Basu T., 2012, Proceedings of the International Conference on Advanced Data Mining and Applications, ADMA'12, V7713, P296, DOI DOI 10.1007/978-3-642-35527-1_25
   Cambria E, 2013, PROCEEDINGS OF THE 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR HUMAN-LIKE INTELLIGENCE (CIHLI), P108, DOI 10.1109/CIHLI.2013.6613272
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Djuric N, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P29, DOI 10.1145/2740908.2742760
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   GOODMAN LA, 1961, ANN MATH STAT, V32, DOI [DOI 10.1214/AOMS/1177705148, 10.1214/aoms/1177705148]
   Hosseinmardi H, 2015, LECT NOTES COMPUT SC, V9471, P49, DOI 10.1007/978-3-319-27433-1_4
   Ibn Rafiq R, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0398-x
   Ibn Rafiq R, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P617, DOI 10.1145/2808797.2809381
   Jandhyala SK, 2018, CLEF WORKING NOTES
   Kumari K, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3907
   Kumari K, 2020, SOFT COMPUT, V24, P11059, DOI 10.1007/s00500-019-04550-x
   Kumari K, 2019, LECT NOTES COMPUT SC, V11701, P415, DOI 10.1007/978-3-030-29374-1_34
   Meng TL, 2019, DATA, V4, DOI 10.3390/data4030110
   Nuzzo R, 2014, NATURE, V506, P150, DOI 10.1038/506150a
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P5585, DOI 10.1109/TIP.2018.2852503
   Pinheiro Pedro., 2014, International conference on machine learning. PMLR, P82
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2015, NEURAL NETWORKS, V63, P104, DOI 10.1016/j.neunet.2014.10.005
   Prakash Aaditya, 2016, P COLING 2016 26 INT
   Qureshi SA, 2019, IEEE INTELL SYST, V34, P45, DOI 10.1109/MIS.2019.2925204
   Reynolds K., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P241, DOI 10.1109/ICMLA.2011.152
   Smith PK, 2008, J CHILD PSYCHOL PSYC, V49, P376, DOI 10.1111/j.1469-7610.2007.01846.x
   Sun Shichao., 2017, National CCF Conference on Natural Language Processing and Chinese Computing, P431
   Targ S., 2016, Resnet in Resnet: Generalizing Residual Architectures
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
NR 30
TC 18
Z9 18
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26989
EP 27008
DI 10.1007/s11042-020-09631-w
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000568184100010
DA 2024-07-18
ER

PT J
AU Mukhopadhyay, S
   Paul, M
   Pal, R
   De, D
AF Mukhopadhyay, Somnath
   Paul, Munti
   Pal, Ramen
   De, Debashis
TI Tea leaf disease detection using multi-objective image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tea leaf disease detection; NSGA-II based image clustering; Multi-class
   SVM; PCA; Feature reduction
ID ALGORITHM
AB Tea leaves' diseases caused by constant exposure to pathogens lead to significant crop yield loss globally. Diagnosing the tea leave disease at an early stage minimizes the tea yield loss. In this study, a novel approach is presented for automatically detecting tea leaves diseases based on image processing technology. The Non-dominated Sorting Genetic Algorithm (NSGA-II) based image clustering is proposed for detecting the disease area in tea leaves. After that, PCA and multi-class SVM is used for feature reduction and identifying the disease in the tea leaves, respectively. The result shows that the proposed algorithm can detect the type of disease persisting in tea leaves with an average accuracy of 83%. Five different tea leaf diseases are considered here, such as Red Rust, Red Spider, Thrips, Helopeltis, and Sunlight Scorching.
C1 [Mukhopadhyay, Somnath; Paul, Munti; Pal, Ramen] Assam Univ Silchar, Dept Comp Sci, Engn, Silchar, India.
   [De, Debashis] West Bengal Univ Technol, Dept Comp Sci, Engn, Kolkata, India.
C3 Assam University; Maulana Abul Kalam Azad University of Technology
RP Mukhopadhyay, S (corresponding author), Assam Univ Silchar, Dept Comp Sci, Engn, Silchar, India.
EM som.cse@live.com; muntip7@gmail.com; ramen.pal673@gmail.com;
   dr.debashis.de@ieee.org
RI Pal, Ramen/GQB-3157-2022
OI Pal, Ramen/0000-0002-0337-242X; Mukhopadhyay,
   Somnath/0000-0002-4532-6245
CR Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   [Anonymous], 2007, ARXIV07093967
   [Anonymous], 2016, International Journal of Computer Applications
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   BAKONYI M, 1995, SIAM J MATRIX ANAL A, V16, P646, DOI 10.1137/S0895479893249757
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chen J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030343
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Dae Gwan Kim, 2009, International Journal of Agricultural and Biological Engineering, V2, P41, DOI 10.3965/j.issn.1934-6344.2009.03.041-050
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Dey AK, 2016, PROCEDIA COMPUT SCI, V85, P748, DOI 10.1016/j.procs.2016.05.262
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278
   El-Helly M., 2003, IND INT C ART INT II, P1182
   Golberg D.E., 1989, Genetic algorithms in search, optimization, and machine learning, P36
   Goldberg DE, 1991, COMP ANAL SELECTION, V1
   Golhani Kamlesh, 2018, Information Processing in Agriculture, V5, P354, DOI 10.1016/j.inpa.2018.05.002
   Hossain MS, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P150, DOI 10.1109/CSPA.2018.8368703
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Kalaivani S, 2020, MULTIMED TOOLS APPL, V79, P9145, DOI 10.1007/s11042-018-7126-7
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karmokar BC, 2015, INT J COMPUTER APPL, V114
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Knowles J, 1999, P 1999 C EV COMP CEC, P98, DOI [DOI 10.1109/CEC.1999.781913, 10.1109/cec.1999.781913]
   Li H, 2009, IEEE T EVOLUT COMPUT, V13, P284, DOI 10.1109/TEVC.2008.925798
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lindeberg T., 2012, SCHOLARPEDIA, V7, P10491, DOI [10.4249/scholarpedia.10491, DOI 10.4249/SCHOLARPEDIA.10491]
   Liu Y., 2010, DAT MIN ICDM IEEE 10, DOI DOI 10.1109/ICDM.2010.35
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu X, 2020, ABS200305020 ARXIV
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Madzarov G, 2009, INFORM-J COMPUT INFO, V33, P225
   Mathanker SK, 2011, COMPUT ELECTRON AGR, V77, P60, DOI 10.1016/j.compag.2011.03.008
   Mukhopadhyay A, 2009, IEEE T GEOSCI REMOTE, V47, P1132, DOI 10.1109/TGRS.2008.2008182
   Mukhopadhyay S, 2013, ADAPTIVE MEDIAN FILT
   Mukhopadhyay S, 2013, OPEN COMPUT SCI, V3, P158, DOI 10.2478/s13537-013-0111-3
   NA S, 2010, 2010 3 INT S INT INF, P63
   Omran M, 2005, INT J PATTERN RECOGN, V19, P297, DOI 10.1142/S0218001405004083
   Omrani E, 2014, MEASUREMENT, V55, P512, DOI 10.1016/j.measurement.2014.05.033
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Peng JT, 2016, IEEE T CYBERNETICS, V46, P1616, DOI 10.1109/TCYB.2015.2453091
   Phadikar S., 2012, International Journal of Information and Electronics Engineering, V2, DOI DOI 10.7763/IJIEE.2012.V2.137
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Salehi M, 2019, INT J IND ENG PRODUC, V30
   Shen JB, 2019, IEEE T NEUR NET LEAR, V30, P2637, DOI 10.1109/TNNLS.2018.2885591
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Shen JB, 2017, IEEE T IMAGE PROCESS, V26, P4911, DOI 10.1109/TIP.2017.2722691
   Shen JB, 2014, IEEE T CIRC SYST VID, V24, P1088, DOI 10.1109/TCSVT.2014.2302545
   Shrivastava S, 2017, MULTIMED TOOLS APPL, V76, P26647, DOI 10.1007/s11042-016-4191-7
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Sun X., 2019, ARXIV190102694
   Sun X, 2019, ABS190102694 ARXIV
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wong MT, 2011, IEEE C EVOL COMPUTAT, P262
   Yao Q, 2009, 2009 INTERNATIONAL CONFERENCE ON ENGINEERING COMPUTATION, P79, DOI 10.1109/ICEC.2009.73
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
   Zitzler E., 2001, TIK-Report, V103, P1
NR 64
TC 45
Z9 46
U1 14
U2 105
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 753
EP 771
DI 10.1007/s11042-020-09567-1
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566043200006
DA 2024-07-18
ER

PT J
AU Chowdhury, PN
   Shivakumara, P
   Pal, U
   Lu, T
   Blumenstein, M
AF Chowdhury, Pinaki Nath
   Shivakumara, Palaiahnakote
   Pal, Umapada
   Lu, Tong
   Blumenstein, Michael
TI A new augmentation-based method for text detection in night and day
   license plate images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmentation; Gradient vector flow; RGB color space; Text detection;
   License plate detection; License plate recognition
ID SCENE; RECOGNITION; MODEL
AB Despite a number of methods that have been developed for License Plate Detection (LPD), most of these focus on day images for license plate detection. As a result, license plate detection in night images is still an elusive goal for researchers. This paper presents a new method for LPD based on augmentation and Gradient Vector Flow (GVF) in night and day images. The augmentation involves expanding windows for each pixel in R, G and B color spaces of the input image until the process finds dominant pixels in both night and day license plate images of the respective color spaces. We propose to fuse the dominant pixels in R, G and B color spaces to restore missing pixels. For the results of fusing night and day images, the proposed method explores Gradient Vector Flow (GVF) patterns to eliminate false dominant pixels, which results in candidate pixels. The proposed method explores further GVF arrow patterns to define a unique loop pattern that represents hole in the characters, which gives candidate components. Furthermore, the proposed approach uses a recognition concept to fix the bounding boxes, merging the bounding boxes and eliminating false positives, resulting in text/license plate detection in both night and day images. Experimental results on night images of our dataset and day images of standard license plate datasets, demonstrate that the proposed approach is robust compared to the state-of-the-art methods. To show the effectiveness of the proposed method, we also tested our approach on standard natural scene datasets, namely, ICDAR 2015, MSRA-TD-500, ICDAR 2017-MLT, Total-Text, CTW1500 and MS-COCO datasets, and their results are discussed.
C1 [Chowdhury, Pinaki Nath; Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Blumenstein, Michael] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   Universiti Malaya; Nanjing University; University of Technology Sydney
RP Lu, T (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM pinakinathc@gmail.com; shiva@um.edu.my; umapada@isical.ac.in;
   lutong@nju.edu.cn; Michael.Blumenstein@uts.edu.au
RI Pal, Umapada/AAC-4930-2022; Palaiahnakote, Shivakumara/B-6261-2013;
   Palaiahnakote, Shivakumara/ITU-6488-2023
FU Natural Science Foundation of China [61672273, 61832008]; Science
   Foundation for Distinguished Young Scholars of Jiangsu [BK20160021,
   GPF014D-2019]; University of Malaya, Malaysia [GPF014D-2019]
FX This work is supported by the Natural Science Foundation of China under
   Grant 61672273 and Grant 61832008, and the Science Foundation for
   Distinguished Young Scholars of Jiangsu under Grant BK20160021. This
   work was also partially supported by a Faculty Grant: GPF014D-2019,
   University of Malaya, Malaysia.
CR Afifi M, 2019, IEEE I CONF COMP VIS, P243, DOI 10.1109/ICCV.2019.00033
   Afifi M, 2019, PROC CVPR IEEE, P1535, DOI 10.1109/CVPR.2019.00163
   Ahmed AH, 2015, P AISI, P151
   [Anonymous], 2016, ABS160609002 CORR
   Asif MR, 2017, J VIS COMMUN IMAGE R, V46, P176, DOI 10.1016/j.jvcir.2017.03.020
   Bazazian D, 2019, PATTERN RECOGN LETT, V119, P112, DOI 10.1016/j.patrec.2017.08.030
   Boonsim N, 2017, PATTERN ANAL APPL, V20, P1195, DOI 10.1007/s10044-016-0559-6
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Chowdhury P. N., 2019, P ACPR, P749
   Deng D, 2018, P AAAI
   Deng LJ, 2019, NEUROCOMPUTING, V334, P134, DOI 10.1016/j.neucom.2019.01.013
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Gupta N, 2019, MULTIMED TOOLS APPL, V78, P10821, DOI 10.1007/s11042-018-6613-1
   He WH, 2018, IEEE T IMAGE PROCESS, V27, P5406, DOI 10.1109/TIP.2018.2855399
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Khare V, 2017, MULTIMED TOOLS APPL, V76, P16625, DOI 10.1007/s11042-016-3941-x
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Li H, 2019, IEEE T INTELL TRANSP, V20, P1126, DOI 10.1109/TITS.2018.2847291
   Lin CH, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P224, DOI 10.1109/ICASI.2018.8394573
   Liu Y, ARXIV171202170
   Liu YL, 2019, PATTERN RECOGN, V90, P337, DOI 10.1016/j.patcog.2019.02.002
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Liu ZD, 2019, MULTIMED TOOLS APPL, V78, P18205, DOI 10.1007/s11042-019-7177-4
   Long S, 2018, P EUR C COMP VIS ECC, P19
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Panahi R, 2017, IEEE T INTELL TRANSP, V18, P767, DOI 10.1109/TITS.2016.2586520
   Raghunandan KS, 2018, IEEE T CIRC SYST VID, V28, P2276, DOI 10.1109/TCSVT.2017.2713806
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shemarry MSA, 2018, ESWA, V92, P216
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shivakumara P, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P782, DOI 10.1109/ACPR.2017.45
   Shivakumara P, 2019, EXPERT SYST APPL, V118, P1, DOI 10.1016/j.eswa.2018.08.015
   Tian SX, 2015, NEUROCOMPUTING, V161, P183, DOI 10.1016/j.neucom.2015.02.044
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Xie LL, 2018, IEEE T INTELL TRANSP, V19, P507, DOI 10.1109/TITS.2017.2784093
   Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589
   Xue CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P989
   Xue L, 2019, SAVING FOOD: PRODUCTION, SUPPLY CHAIN, FOOD WASTE, AND FOOD CONSUMPTION, P1, DOI 10.1016/B978-0-12-815357-4.00001-8
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yuan YL, 2017, IEEE T IMAGE PROCESS, V26, P1102, DOI 10.1109/TIP.2016.2631901
   Zamberletti A, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P196, DOI 10.1109/ACPR.2015.7486493
   Zhai X, 2012, P ICMST
   Zhang C, 2018, LECT NOTES COMPUT SC, V11166, P46, DOI 10.1007/978-3-030-00764-5_5
   Zhang XN, 2018, NEUROCOMPUTING, V307, P61, DOI 10.1016/j.neucom.2018.03.070
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhao X, 2019, NEUROCOMPUTING, V333, P284, DOI 10.1016/j.neucom.2018.12.009
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 51
TC 2
Z9 4
U1 3
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33303
EP 33330
DI 10.1007/s11042-020-09681-0
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000565163400006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Costa, D
   Duarte, C
AF Costa, Daniel
   Duarte, Carlos
TI Alternative modalities for visually impaired users to control smart TVs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accessibility; visually impaired users; Multimodality; Touch gestures;
   Mid-air gestures; Speech recognition; User centered design; TV
   applications; Smart TV
AB Smart TVs offer a variety of features that increase interactivity and available services when compared to other TVs. Furthermore, remote controls have become more complex, with more and smaller buttons, making interaction difficult for people with visual impairments. To address some of these concerns, the solution described herein offers, through a mobile application, a set of alternative interaction modalities ranging from mid-air gestures to speech commands. This paper presents the results of a user study comparing user and system performance using the proposed modalities. Touch and speech were the most efficient modalities. The combined usage of the mobile application and TalkBack resulted in more user errors, consequence of the introduction of an additional interaction layer. Most participants reported they would replace the remote control with this solution. The discussion of the findings and a lessons learned section are the main contributions of this work.
C1 [Costa, Daniel; Duarte, Carlos] Univ Lisbon, Fac Ciencias, Dept Informat, LASIGE, P-1749016 Lisbon, Portugal.
C3 Universidade de Lisboa
RP Costa, D (corresponding author), Univ Lisbon, Fac Ciencias, Dept Informat, LASIGE, P-1749016 Lisbon, Portugal.
EM thewisher@lasige.di.fc.ul.pt
RI Duarte, Carlos/M-1802-2015
OI Duarte, Carlos/0000-0003-1370-5379; Costa, Daniel/0000-0001-7613-6201
CR Abrams M, 1999, COMPUT NETW, V31, P1695, DOI 10.1016/S1389-1286(99)00044-4
   Ali MF, 2002, CHI 02 EXTENDED ABST
   [Anonymous], 2003, HUM FAC ER
   [Anonymous], 2011, PROC SPIE
   Azenkot S, 2013, P 15 INT ACM SIGACCE
   Bailly G, 2011, P 13 INT C MULT INT
   Balbo S., 2005, LEADING WEB USABILIT, V1
   Bhachu AS, 2011, SIGACCESS ACCESS COM, P9
   Brewster SA, 1993, P INTERACT 93 CHI 93
   Costa D, 2017, UNIVERSAL ACCESS INF, V16, P197, DOI 10.1007/s10209-016-0451-6
   Courtois C., 2012, P 10 EUR C INT TV VI
   Duarte C., 2017, FRONTIERS ICT, V4, P26, DOI DOI 10.3389/FICT.2017.00026
   E. B. Union, 2008, DIGITAL TV ACCESSIBI
   Epelde G, 2013, MULTIMED TOOLS APPL, V67, P497, DOI 10.1007/s11042-011-0949-0
   Epelde G, 2013, UNIVERSAL ACCESS INF, V12, P73, DOI 10.1007/s10209-011-0266-4
   Freeman WT, 1994, TELEVISION CONTROL H, V1
   Funes MM, 2017, P 23 BRAZ S MULT WEB
   Gajos KZ, 2007, P 20 ANN ACM S US IN
   Godard N, 2013, P 11 EUR C INT TV VI
   Hinne T. Bruhn, 2011, UNIVERSAL ACCESS HUM
   Hwang I., 2015, 2015 21 KOR JAP JOIN
   Johnston M, 2010, P 12 INT ACM SIGACCE
   Kearney-Volpe C, 2019, 2019 CHI C HUM FACT
   Kohler M, 1998, P GEST WORKSH
   Kühnel C, 2011, INT J HUM-COMPUT ST, V69, P693, DOI 10.1016/j.ijhcs.2011.04.005
   Luo X, 2014, CHI 14 HUM FACT COMP
   Mehrotra S., 2018, P 20 INT ACM SIGACCE
   Nandakumar A, 2014, P 2014 ACM INT C INT
   Neate T., 2015, P 33 ANN ACM C HUM F
   Oh U, 2017, P 19 INT ACM SIGACCE
   Oliveira R, 2011, PROC 9 INT INT C INT
   Santana V. F., 2014, 16 INT C HUM COMP IN, V8510
   Santana VF, 2019, P 16 WEB ALL 2019 PE
   Sauro J, 2011, MEASURING USABILITY
   Shah I, 2008, J KING SAUD UNIV-COM, V20, P31, DOI 10.1016/S1319-1578(08)80003-1
   Shinohara K, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2827857
   Springett MV, 2007, P 5 EUR C INT TV SHA
   Torres DZ, 2018, P 20 INT C HUM COMP
   Trindade D, 2018, P 2018 CHI C HUM FAC
   Vatavu RD, 2012, MULTIMED TOOLS APPL, V59, P113, DOI 10.1007/s11042-010-0698-5
   Vatavu RD, 2008, CHANGING TELEVISION
   Vatavu RD, 2012, P 10 EUR C INT TV VI
NR 42
TC 4
Z9 4
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31931
EP 31955
DI 10.1007/s11042-020-09656-1
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360100001
DA 2024-07-18
ER

PT J
AU Zhang, LM
   Yan, HW
   Zhu, R
   Du, P
AF Zhang, Liming
   Yan, Haowen
   Zhu, Rui
   Du, Ping
TI Combinational spatial and frequency domains watermarking for 2D vector
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector map; Multiple watermarking; Watermarking algorithm; DFT
ID SCHEME
AB Watermarking plays an import role in digital copyright protection. It enables copyright owners to embed invisible watermarks within copies of data before distribution. However, most existing watermarking algorithms for 2D vector maps use either spatial domain methods, e.g., the Least Significant Bit or frequency domain methods, e.g., discrete Fourier transform (DFT), and very few algorithms combine the two domains. In order to improve the robustness of watermarks to against more common attacks, a novel algorithm using a combination of spatial and frequency domains is presented. Both the spatial domain and the frequency domain can be used for watermark embedding. Obviously, the advantages of each method are retained and the disadvantages of each method are offset by complementation. The watermark was also shuffled before embedding. A one-way hash function was used to map the watermark and 2D vector map. By using two different methods, one part of the watermark was embedded into the spatial domain first and another part of the watermark was embedded into the DFT domain. Additionally, the watermark was embedded multiple times. No original map data are required for the watermark extraction procedure. Analysis shows that the distortions of the watermarked data are extremely small, and the algorithm is more robust than methods using a single domain. It can resist the most common attacks, such as vertex insertion and removal, cropping, compression, reordering, and data format conversion attacks. It is also robust against rotation scaling and translation attacks.
C1 [Zhang, Liming; Yan, Haowen; Zhu, Rui; Du, Ping] Lanzhou Jiaotong Univ, Fac Geomat, Lanzhou 730070, Peoples R China.
   [Zhang, Liming; Yan, Haowen; Zhu, Rui; Du, Ping] Natl Local Joint Engn Res Ctr Technol & Applicat, Lanzhou 730070, Peoples R China.
C3 Lanzhou Jiaotong University
RP Zhang, LM (corresponding author), Lanzhou Jiaotong Univ, Fac Geomat, Lanzhou 730070, Peoples R China.; Zhang, LM (corresponding author), Natl Local Joint Engn Res Ctr Technol & Applicat, Lanzhou 730070, Peoples R China.
EM Zhanglm8@gmail.com
RI zhu, rui/GTK-1978-2022; Zhang, Li/GWM-7501-2022; zhang,
   lin/IZQ-4870-2023; Zhang, Liqun/JDN-3523-2023; Du, Pingwu/G-3329-2010
FU Natural Science Foundation Committee, China [41761080, 41671447]; Talent
   Innovation Venture Science and Technology Program of Lanzhou
   [2016-RC-59]; Guidance Project of Gansu Colleges and Universities
   [2019C-04]
FX This work is funded by the Natural Science Foundation Committee, China
   (No. 41761080, and No. 41671447), Talent Innovation Venture Science and
   Technology Program of Lanzhou, No. 2016-RC-59, and Industrial Support
   and Guidance Project of Gansu Colleges and Universities, No. 2019C-04.
CR [Anonymous], 2007, INTELLIGENT MULTIMED
   Bertone A, 2017, J GEOVIS SPAT ANAL, V1, DOI 10.1007/s41651-017-0002-6
   Chang HJ, 2009, IEEE INT CON MULTI, P1014, DOI 10.1109/ICME.2009.5202669
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Da QG, 2018, MOBILE NETW APPL, V23, P734, DOI 10.1007/s11036-018-0997-z
   Giannoula A, 2002, MULTIMEDIA EXPO 2002
   Kang H, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P234, DOI 10.1109/ITCC.2001.918797
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kitamura I, 2001, GEOSC REM SENS S 200
   Lee SH, 2014, IEICE T INF SYST, VE97D, P34, DOI 10.1587/transinf.E97.D.34
   Leng L, 2010, 2010 INT C INF COMM
   [李媛媛 Li Yuanyuan], 2004, [光子学报, Acta Photonica sinica], V33, P97
   Liu F, 2020, J GEOVIS SPAT ANAL, V4, DOI 10.1007/s41651-020-00057-4
   Lopez C, 2002, INT J GEOGR INF SCI, V16, P589, DOI 10.1080/13658810210129148
   Muttoo Sunil Kumar, 2012, Annals of GIS, V18, P135, DOI 10.1080/19475683.2011.640640
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Ohbuchi R, 2003, SHAPE MODELING INT 2
   Ohbuchi R, 2002, P IEEE INT C MULT EX
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Schmidt S, 2020, J GEOVIS SPAT ANAL, V4, DOI 10.1007/s41651-020-00055-6
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Voigt M, 2003, ELECT IMAGING 2003
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang X, 2011, ADV MAT RES
   Yan HW, 2017, EARTH SCI INFORM, V10, P471, DOI 10.1007/s12145-017-0310-x
   Yan HW, 2011, COMPUT ENVIRON URBAN, V35, P485, DOI 10.1016/j.compenvurbsys.2010.10.004
   Zhang Liming, 2015, Geomatics and Information Science of Wuhan University, V40, P990, DOI 10.13203/j.whugis20130686
NR 28
TC 9
Z9 13
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31375
EP 31387
DI 10.1007/s11042-020-09573-3
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560998700001
DA 2024-07-18
ER

PT J
AU Gul, E
   Ozturk, S
AF Gul, Ertugrul
   Ozturk, Serkan
TI A novel triple recovery information embedding approach for self-embedded
   digital image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Integrity; Self-embedding; Watermarking; Triple recovery
ID DATA HIDING SCHEME; FRAGILE WATERMARKING; AUTHENTICATION SCHEME; TAMPER
   DETECTION; RESTORATION; INTERPOLATION; DCT
AB Image tamper detection and recovery has become an important issue in recent years. In order to detect and recover high tampering rated images, this paper presents a novel self-embedded fragile watermarking method with triple recovery information embedding approach. In this proposed method host image is divided into sixteen main blocks. Four partner blocks are selected from main blocks as a partner group using Look-Up table which is constructed for recovery against high tampering rated images. Each partner block is divided into 4 x 4 blocks. Recovery data of each partner block is generated from the mean values of the 4 x 4 blocks. Then, triple recovery information for each partner block is constructed by combining recovery data of the three other partner blocks. After the generation of the recovery information, each partner block is divided into 16 x 16 blocks. Then, these blocks are divided into four 8 x 8 sub-blocks. Recovery bits for each partner block are embedded into the first and second least significant bits (LSBs) of the first three sub-blocks. It means that triple copies of recovery information for each partner block are embedded into three other blocks in the image, which provides triple chance for recovery of the tampered areas. On the other hand, authentication information is generated from the pixels of the 16 x 16 recovery information embedded image blocks by using MD5 hash function. This authentication information is embedded into the quarter part of each 16 x 16 block by using LSB substitution. The performance of the proposed method has been demonstrated by applying different size of cropping attacks to the different areas of the watermarked images. Experimental results show that the proposed method satisfactory recovers up to 75% tampering rated images.
C1 [Gul, Ertugrul] Nigde Omer Halisdemir Univ, Comp Engn Dept, Nigde, Turkey.
   [Gul, Ertugrul; Ozturk, Serkan] Erciyes Univ, Comp Engn Dept, Kayseri, Turkey.
C3 Nigde Omer Halisdemir University; Erciyes University
RP Gul, E (corresponding author), Nigde Omer Halisdemir Univ, Comp Engn Dept, Nigde, Turkey.; Gul, E (corresponding author), Erciyes Univ, Comp Engn Dept, Kayseri, Turkey.
EM ertugrulgul@erciyes.edu.tr; serkan@erciyes.edu.tr
RI GUL, ERTUGRUL/AAC-4451-2021; Ozturk, Serkan/B-4673-2013
OI GUL, ERTUGRUL/0000-0002-5591-3435; 
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Aslantas V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P241, DOI 10.1109/ICME.2008.4607416
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Depovere G., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P202, DOI 10.1109/ICIP.1999.822884
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   GULL S, 2018, J AMB INTEL HUM COMP, P1
   He HJ, 2006, LECT NOTES COMPUT SC, V4283, P422
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang R, 2019, MULTIMED TOOLS APPL, V78, P26701, DOI 10.1007/s11042-019-07802-y
   Jindal H, 2016, NOVEL IMAGE ZOOMING
   Jindal H, 2018, WIREL NETW, V24, P3241, DOI 10.1007/s11276-017-1532-z
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   Jindal H, 2017, WIRELESS PERS COMMUN, V97, P881, DOI 10.1007/s11277-017-4542-3
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim C, 2018, PERS UBIQUIT COMPUT, V22, P11, DOI 10.1007/s00779-017-1061-x
   Kunhu A, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTING TECHNOLOGIES AND APPLICATIONS (ICECTA), P350
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li CL, 2013, MULTIMED TOOLS APPL, V64, P757, DOI 10.1007/s11042-011-0974-z
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin PY, 2009, IEEE T CIRC SYST VID, V19, P1169, DOI 10.1109/TCSVT.2009.2020263
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu HT, 2003, ELECTRON LETT, V39, P898, DOI 10.1049/el:20030589
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Peng YY, 2018, J INF SECUR APPL, V40, P236, DOI 10.1016/j.jisa.2018.04.007
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P6389, DOI 10.1007/s11042-015-3198-9
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Tang S., 2019, CoRR abs/1902.06197
   Tsai P, 2005, IMAGING SCI J, V53, P149, DOI 10.1179/136821905X50406
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A. G., 1997, USC-SIPI Report, V315
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yang SS, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P130, DOI 10.1109/IIH-MSP.2014.39
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
NR 58
TC 12
Z9 13
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31239
EP 31264
DI 10.1007/s11042-020-09548-4
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560998800001
DA 2024-07-18
ER

PT J
AU Bouhlel, N
   Feki, G
   Amar, CB
AF Bouhlel, Noura
   Feki, Ghada
   Amar, Chokri Ben
TI Hypergraph-based image search reranking with elastic net regularized
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image search; Visual reranking; Hypergraph; Elastic net; Regularized
   regression
ID RE-RANKING; RETRIEVAL; REPRESENTATION; SPARSE; TREE
AB Image search reranking is emerging as an effective technique to refine the text-based image search results using visual information. In this paper, we introduce a novel hypergraph-based image search reranking method that accounts for both relevance and diversity of search results. Namely, the text-based image search results are taken as vertices in a probabilistic regression-based hypergraph model and reranking is formulated as a hypergraph ranking problem with absorbing nodes. More specifically, to discover related samples and characterize the relationships among them, we bring the Elastic Net regularized regression model into the hypergraph construction. Exceeding the conventional hypergraph construction schemes, our scheme is able to describe the high-order relationships and the local manifold structure among visual samples while ensuring the datum-adaptiveness. Afterward, we apply a hypergraph-based ranking with absorbing nodes to ensure a diversified reranking. That is, during the reranking process, previously-ranked samples are transformed into absorbing nodes at each iteration, thereby redundant ones are prevented from receiving high ranking scores. Extensive experiments on real-world data from Flickr suggest our proposed reranking method achieves promising results compared to existing reranking methods.
C1 [Bouhlel, Noura; Feki, Ghada; Amar, Chokri Ben] Univ Sfax, REGIM Res Grp Intelligent Machines, Natl Engn Sch Sfax ENIS, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Bouhlel, N (corresponding author), Univ Sfax, REGIM Res Grp Intelligent Machines, Natl Engn Sch Sfax ENIS, BP 1173, Sfax 3038, Tunisia.
EM noura.bouhlel.tn@ieee.org; ghada.feki@ieee.org; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; Bouhlel, Noura/AAF-4072-2021
OI Bouhlel, Noura/0000-0002-5602-8892
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX The research leading to these results has received funding from the
   Ministry of Higher Education and Scientific Research of Tunisia under
   the grant agreement number LR11ES48.
CR [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   Boteanu B, 2017, MULTIMED TOOLS APPL, V76, P11889, DOI 10.1007/s11042-016-3678-6
   Bouchakwa M, 2020, PROG ARTIF INTELL, V9, P1, DOI 10.1007/s13748-019-00195-x
   Bouchrika T, 2012, CCCA12, P1
   Boughrara H, 2012, INT CONF MULTIMED, P233, DOI 10.1109/ICMCS.2012.6320263
   Bouhlel N, 2020, INT J MULTIMED INF R, V9, P205, DOI 10.1007/s13735-019-00191-w
   Bouhlel N, 2017, LECT NOTES COMPUT SC, V10424, P279, DOI 10.1007/978-3-319-64689-3_23
   Bouhlel N, 2015, INT CONF INTELL SYST, P479, DOI 10.1109/ISDA.2015.7489162
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cai JJ, 2015, IEEE T IMAGE PROCESS, V24, P261, DOI 10.1109/TIP.2014.2372616
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Cheng XQ, 2013, IEEE T KNOWL DATA EN, V25, P177, DOI 10.1109/TKDE.2011.190
   DANGNGUYEN DT, 2015, IEEE INT CON MULTI, pNI651
   Dang-Nguyen DT, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3103613
   ElAdel A, 2016, MACH VISION APPL, V27, P781, DOI 10.1007/s00138-016-0789-z
   Feki G, 2016, MED 2016 WORKSH, V1739
   Feki G, 2015, INT CONF INTELL SYST, P499, DOI 10.1109/ISDA.2015.7489166
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gao Y, 2014, TSINGHUA SCI TECHNOL, V19, P250, DOI 10.1109/TST.2014.6838195
   Gu-Li Lin, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P2416, DOI 10.1109/ICMLC.2010.5580733
   Pedronette DCG, 2012, INT J MULTIMED INF R, V1, P115, DOI 10.1007/s13735-012-0002-8
   Hong CQ, 2013, NEUROCOMPUTING, V101, P94, DOI 10.1016/j.neucom.2012.09.001
   Huang B., 2010, THESIS
   Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012
   Ionescu B, 2014, IEEE IMAGE PROC, P3072, DOI 10.1109/ICIP.2014.7025621
   Ionescu Bogdan, 2015, P 6 ACM MULT SYST C, P207
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mejdoub M, 2008, INT WORK CONTENT MUL, P349
   Mejdoub M, 2009, J VIS COMMUN IMAGE R, V20, P145, DOI 10.1016/j.jvcir.2008.12.003
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Sabetghadam S, 2015, MED 2015 WORKSH, V1436
   Spyromitros-Xioufis E, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P323, DOI 10.1145/2671188.2749334
   Suica VI, 2015, PROTEOME SCI, V13, DOI 10.1186/s12953-015-0087-0
   Sunderrajan S, 2016, IEEE T MULTIMEDIA, V18, P51, DOI 10.1109/TMM.2015.2496139
   Teyeb I, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P379, DOI 10.1109/IISA.2014.6878809
   Tian XM, 2012, IEEE T MULTIMEDIA, V14, P490, DOI 10.1109/TMM.2012.2189923
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P810, DOI 10.1109/TPAMI.2013.214
   Xu J, 2019, PATTERN RECOGN, V88, P679, DOI 10.1016/j.patcog.2018.12.023
   Yan R, 2003, LECT NOTES COMPUT SC, V2728, P238
   ZHAO XL, 2019, IEEE ACCESS, V141
   Zhou D., 2006, ADV NEURAL INFORM PR, P1601, DOI DOI 10.7551/MITPRESS/7503.003.0205
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 48
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30257
EP 30280
DI 10.1007/s11042-020-09418-z
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900003
DA 2024-07-18
ER

PT J
AU Qu, LF
   He, HJ
   Chen, F
AF Qu Lingfeng
   He Hongjie
   Chen Fan
TI Security analysis of multiple permutation encryption adopt in reversible
   data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Multiple permutation encryption; Known plaintext
   attack; Security analysis
ID IMAGE; CRYPTANALYSIS
AB In order to improve the security of reversible data hiding algorithm in encrypted images, Liu designed an image multi-permutation encryption algorithm. By combining bit-plane permutation with pixel-block permutation, the embedding capacity of the algorithm is improved, and the ability of the encryption algorithm to resist existing Ciphertext-Only and Known-Plaintext attack is effectively improved. To analyze the security performance of the encryption algorithm, a Known-plaintext attack method based on the Root Mean Square(RMS) of image block is proposed in this paper. Firstly, the permutation order of bit plane is estimated by using the invariant distribution ratio of 0 and 1 before and after image encryption, the original pixel values is restored. Then, according to the characteristics that the pixel values of the image remain unchanged during block permutation and intra-block pixel permutation, the image block RMS feature is defined to search and estimate the block permutation sequence. Image block RMS equivalence class is defined by the image block RMS value, the ratio of the maximum number of elements in the equivalence class to the total number of pixels is p, which determines the difficulty of known plaintext attack. For the common image test set, 96% of the images have ap-value of less than 0.1, and only 4% of the images have ap-value greater than 0.1. Experimental results show that, Whenp<0.1, under the condition of 2 x 2 block size, the attacker only needs to know one pair of plaintext-ciphertext to decode about 50% of the encrypted image content. For a few images withp> 0.1, the attacker can crack more than 80% of the image content by two pairs of plaintext and ciphertext.
C1 [Qu Lingfeng; He Hongjie; Chen Fan] Southwest Jiaotong Univ, Chengdu 610031, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Chengdu 610031, Sichuan, Peoples R China.
EM fchen@swjtu.edu.cn
RI Lingfeng, Qu/ABB-1995-2020; Lingfeng, Qu/GLT-0330-2022
OI Lingfeng, Qu/0000-0002-2544-4324; Lingfeng, Qu/0000-0002-2544-4324
FU National Natural Science Foundation of China [61872303, U1936113];
   Science and Technology Innovation Talents Program of Sichuan Science and
   Technology Department [2018RZ0143]; Key Project of Sichuan Science and
   Technology Innovation Pioneering Miaozi Project [19MZGC0163]
FX This work has been supported by the National Natural Science Foundation
   of China (61872303 and U1936113), the Science and Technology Innovation
   Talents Program of Sichuan Science and Technology Department
   (2018RZ0143) and the Key Project of Sichuan Science and Technology
   Innovation Pioneering Miaozi Project (19MZGC0163).
CR Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Khelifi F, 2018, SIGNAL PROCESS, V143, P336, DOI 10.1016/j.sigpro.2017.09.020
   Li C, 2009, SIGNAL PROCESSING IM
   Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li W, 2012, P 20 ACM INT C MULT
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2016, J VIS COMMUN IMAGE R, V40, P732, DOI 10.1016/j.jvcir.2016.08.020
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   [屈凌峰 Qu Lingfeng], 2019, [光电子·激光, Journal of Optoelectronics·Laser], V30, P168
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Yin ZX, 2016, INT CONF ACOUST SPEE, P2129, DOI 10.1109/ICASSP.2016.7472053
   Yin ZX, 2014, SCI WORLD J, DOI 10.1155/2014/604876
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 24
TC 9
Z9 10
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29451
EP 29471
DI 10.1007/s11042-020-09379-3
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400010
DA 2024-07-18
ER

PT J
AU Jiao, L
   Wang, RJ
   Xie, CJ
AF Jiao, Lin
   Wang, Rujing
   Xie, Chengjun
TI C-FCN: Corners-based fully convolutional network for visual object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Anchor-free; Corners; Region proposals; Fully
   convolutional network
ID FACE DETECTION; GRADIENTS; FEATURES
AB Object detection has achieved significantly progresses in recent years. Proposal-based methods have become the mainstream object detectors, achieving excellent performance on accurate recognition and localization of objects. However, region proposal generation is still a bottleneck. In this paper, to address the limitations of conventional region proposal network (RPN) that defines dense anchor boxes with different scales and aspect ratios, we propose an anchor-free proposal generator named corner region proposal network (CRPN) which is based on a pair of key-points, including top-left corner and bottom-right corner of an object bounding box. First, we respectively predict the top-left corners and bottom-right corners by two sibling convolutional layers, then we obtain a set of object proposals by grouping strategy and non-maximum suppression algorithm. Finally, we further merge CRPN and fully convolutional network (FCN) into a unified network, achieving an end-to-end object detection. Our method has been evaluated on standard PASCAL VOC and MS COCO datasets using a deep residual network. Experiment results present that the proposed method outperforms previous detectors in the term of precision. Additionally, it runs with a speed of 76 ms per image on a single GPU by using ResNet-50 as the backbone, which is faster than other detectors.
C1 [Jiao, Lin; Wang, Rujing; Xie, Chengjun] Chinese Acad Sci, Inst Intelligent Machines, Hefei Inst Phys Sci, Hefei 230031, Peoples R China.
   [Jiao, Lin] Univ Sci & Technol China, Hefei 230026, Peoples R China.
C3 Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Xie, CJ (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei Inst Phys Sci, Hefei 230031, Peoples R China.
EM cjxie@iim.ac.cn
FU National Natural Science Foundation of China [31671586, 61773360]
FX This work was supported by the National Natural Science Foundation of
   China (grant numbers 31671586, 61773360).
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fang F, 2018, MULTIMED TOOLS APPL, V77, P31159, DOI 10.1007/s11042-018-6228-6
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R. B., 2011, Advances in Neural Information Processing Systems, P442
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P6109, DOI 10.1007/s11042-019-08501-4
   Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li J, 2017, MULTIMED TOOLS APPL, V76, P23017, DOI 10.1007/s11042-016-4211-7
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li TP, 2019, MULTIMED TOOLS APPL, V78, P21963, DOI 10.1007/s11042-019-7414-x
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Nagarajan MB, 2013, MACH VISION APPL, V24, P1371, DOI 10.1007/s00138-012-0456-y
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sekaran K, 2020, MULTIMED TOOLS APPL, V79, P10233, DOI 10.1007/s11042-019-7419-5
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tychsen-Smith L, 2017, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2017.54
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang G, 2020, Deep Learning in Computer Vision: Principles and Applications, V30, P41, DOI DOI 10.1201/9781351003827-2
   Wang S, 2020, MULTIMED TOOLS APPL, P1
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Yang WK, 2019, MULTIMED TOOLS APPL, V78, P24373, DOI 10.1007/s11042-018-6995-0
   Zhang Y, 2019, MULTIMED TOOLS APPL, V78, P26661, DOI 10.1007/s11042-019-07836-2
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 46
TC 2
Z9 2
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28841
EP 28857
DI 10.1007/s11042-020-09503-3
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300001
DA 2024-07-18
ER

PT J
AU Li, Y
   Wang, JX
   Miao, Z
   Wang, JB
AF Li, Yang
   Wang, Jixiao
   Miao, Zhuang
   Wang, Jiabao
TI Unsupervised densely attention network for infrared and visible image
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Deep learning; Densely connection; Attention mechanism
AB Integrating the information of infrared and visible images without human supervision is a long-standing problem. A key technical challenge in this domain is how to extract features from heterogeneous data-sources and fuse them appropriately. Prior deep learning works either extract the middle layers information or use costly training step to improve fusion performance, which limited their performances in cluttered scenes and real-time applications. In this paper, we introduce a novel and pragmatic unsupervised infrared and visible image fusion method based on a pre-trained deep network, which employs a densely connection structure and incorporates the attention mechanism to achieve high fusion performance. Furthermore, we propose to use the cross-dimensional weighting and aggregation to compute the attention map for infrared and visible image fusion. The attention map enables more efficient feature extraction and captures more structure information from source images. We evaluate our method and compare it with ten typical state-of-the-art fusion methods. Extensive experimental results demonstrate that our method achieves state-of-the-art fusion performance in both subjective and objective evaluation.
C1 [Li, Yang; Wang, Jixiao; Miao, Zhuang; Wang, Jiabao] Army Engn Univ PLA, Command & Control Engn Coll, Nanjing 210007, Peoples R China.
C3 Army Engineering University of PLA
RP Li, Y (corresponding author), Army Engn Univ PLA, Command & Control Engn Coll, Nanjing 210007, Peoples R China.
EM solarleeon@outlook.com; jixiao_wang@126.com; miao_zhuang@163.com;
   jiabao_1108@163.com
OI Li, Yang/0000-0003-1682-0284
FU National Natural Science Foundation of China [61806220]
FX This work was supported by the National Natural Science Foundation of
   China (No.61806220). The authors would like to thank the anonymous
   reviewers for their comments and insight, which helped to shape the
   final version of this paper.
CR Bai XZ, 2013, INFRARED PHYS TECHN, V60, P81, DOI 10.1016/j.infrared.2013.03.002
   Bavirisetti DP, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P701
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Dumbgen F., 2018, Electron. Imaging, V30, P321, DOI 10.2352/
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Haghighat M., 2014, 2014 IEEE 8th Int. Conf. on Application of Information and Communication Technologies (AICT), P1, DOI DOI 10.1109/ICAICT.2014.7036000
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Kumar B.K.S., 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI DOI 10.1007/S11760-013-0556-9
   KUMAR BKS, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI DOI 10.1007/S11760-012-0361-X
   Lahoud F, 2019, ARXIV 1905 03590
   Lahoud F, 2018, IEEE IMAGE PROC, P3893, DOI 10.1109/ICIP.2018.8451811
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu CH, 2017, INFRARED PHYS TECHN, V83, P94, DOI 10.1016/j.infrared.2017.04.018
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Mnih V, 2014, ADV NEUR IN, V27
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang Y, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.025005
   Wu X, 2018, ARXIV 1806 07119
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang XY, 2017, J OPT SOC AM A, V34, P1400, DOI 10.1364/JOSAA.34.001400
NR 34
TC 8
Z9 9
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34685
EP 34696
DI 10.1007/s11042-020-09301-x
EA AUG 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000556182200005
DA 2024-07-18
ER

PT J
AU Chaturvedi, SS
   Tembhurne, JV
   Diwan, T
AF Chaturvedi, Saket S.
   Tembhurne, Jitendra V.
   Diwan, Tausif
TI A multi-class skin Cancer classification using deep convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin Cancer; Dermoscopy; Classification; Deep convolutional neural
   network
ID COMPUTER-AIDED DIAGNOSIS; ABCD RULE; MELANOMA; LESIONS; ACCURACY;
   STATISTICS; STRATEGIES; FRAMEWORK
AB Skin Cancer accounts for one-third of all diagnosed cancers worldwide. The prevalence of skin cancers have been rising over the past decades. In recent years, use of dermoscopy has enhanced the diagnostic capability of skin cancer. The accurate diagnosis of skin cancer is challenging for dermatologists as multiple skin cancer types may appear similar in appearance. The dermatologists have an average accuracy of 62% to 80% in skin cancer diagnosis. The research community has been made significant progress in developing automated tools to assist dermatologists in decision making. In this work, we propose an automated computer-aided diagnosis system for multi-class skin (MCS) cancer classification with an exceptionally high accuracy. The proposed method outperformed both expert dermatologists and contemporary deep learning methods for MCS cancer classification. We performed fine-tuning over seven classes of HAM10000 dataset and conducted a comparative study to analyse the performance of five pre-trained convolutional neural networks (CNNs) and four ensemble models. The maximum accuracy of 93.20% for individual model amongst the set of models whereas maximum accuracy of 92.83% for ensemble model is reported in this paper. We propose use of ResNeXt101 for the MCS cancer classification owing to its optimized architecture and ability to gain higher accuracy.
C1 [Chaturvedi, Saket S.] PIET, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Tembhurne, Jitendra V.; Diwan, Tausif] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
RP Tembhurne, JV (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM saketschaturvedi@gmail.com; jitendra.tembhurne@cse.iiitn.ac.in;
   tausif.diwan@cse.iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456; Chaturvedi,
   Saket/0000-0003-0700-404X
CR Abbas Q, 2013, SKIN RES TECHNOL, V19, pE93, DOI 10.1111/j.1600-0846.2012.00614.x
   Alom MZ, 2020, PROC SPIE, V11318, DOI 10.1117/12.2550146
   [Anonymous], 2016, INT J SIGNAL PROCESS, DOI [10.14257/ijsip.2016.9.9.18, DOI 10.14257/IJSIP.2016.9.9.18]
   [Anonymous], 2017, SKIN CANC
   Australian Government, 2018, MEL SKIN STAT
   Ballerini L., 2013, Color medical image analysis, P63
   BINDER M, 1995, ARCH DERMATOL, V131, P286, DOI 10.1001/archderm.131.3.286
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Blum A, 2004, BRIT J DERMATOL, V151, P1029, DOI 10.1111/j.1365-2133.2004.06210.x
   Burroni M, 2004, CLIN CANCER RES, V10, P1881, DOI 10.1158/1078-0432.CCR-03-0039
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   Celebi ME, 2008, COMPUT MED IMAG GRAP, V32, P670, DOI 10.1016/j.compmedimag.2008.08.003
   Chaturvedi SS, 2019, ARXIV190703220
   Chollet F., 2015, GitHub-Keras-Team/Keras: Deep Learning for Humans
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fu K., 2020, P IEEE CVF C COMP VI, P3052
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Goodson AG, 2009, J AM ACAD DERMATOL, V60, P719, DOI 10.1016/j.jaad.2008.10.065
   Harangi B, 2018, IEEE ENG MED BIO, P2575, DOI 10.1109/EMBC.2018.8512800
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Iyatomi H, 2006, MELANOMA RES, V16, P183, DOI 10.1097/01.cmr.0000215041.76553.58
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jemal A, 2010, CA-CANCER J CLIN, V60, P277, DOI 10.3322/caac.20073
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Kawahara J, 2016, LECT NOTES COMPUT SC, V10019, P164, DOI 10.1007/978-3-319-47157-0_20
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Kingma D. P., 2014, arXiv
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Koh HK, 1996, ARCH DERMATOL, V132, P436, DOI 10.1001/archderm.132.4.436
   Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Maglogiannis I, 2009, IEEE T INF TECHNOL B, V13, P721, DOI 10.1109/TITB.2009.2017529
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Majtner T, 2018, ARXIV180805071
   Masood A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/323268
   Mhaske HR, 2013, 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, CONTROLS AND COMMUNICATIONS (CCUBE)
   MILTON M.A. A. J. A. P. A., 2019, Automated Skin Lesion Classification Using Ensemble of Deep Neural Networks in ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection Challenge
   Morton CA, 1998, BRIT J DERMATOL, V138, P283
   Moura N, 2019, MULTIMED TOOLS APPL, V78, P6869, DOI 10.1007/s11042-018-6404-8
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   NACHBAR F, 1994, J AM ACAD DERMATOL, V30, P551, DOI 10.1016/S0190-9622(94)70061-3
   Nyíri T, 2018, LECT NOTES COMPUT SC, V11324, P438, DOI 10.1007/978-3-030-04070-3_34
   Oliveira RB, 2018, NEURAL COMPUT APPL, V29, P613, DOI 10.1007/s00521-016-2482-6
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkin DM, 2011, BRIT J CANCER, V105, pS66, DOI 10.1038/bjc.2011.486
   Pathan S, 2018, BIOMED SIGNAL PROCES, V39, P237, DOI 10.1016/j.bspc.2017.07.010
   Piccolo D, 2002, BRIT J DERMATOL, V147, P481, DOI 10.1046/j.1365-2133.2002.04978.x
   Polat K., 2020, J. Artif. Intell. Syst., V2, P80, DOI [10.33969/AIS.2020.21006, DOI 10.33969/AIS.2020.21006]
   Ramalingam M, 2017, WOODH PUBL SER BIOM, P1
   Ramteke N.S., 2013, INT J COMPUT APPL T, V4, P691
   Ratul M.A.R., 2020, bioRxiv, DOI DOI 10.1101/860700
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rogers HW, 2015, JAMA DERMATOL, V151, P1081, DOI 10.1001/jamadermatol.2015.1187
   Rosado B, 2003, ARCH DERMATOL, V139, P361, DOI 10.1001/archderm.139.3.361
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815
   SILVERBERG E, 1990, CA-CANCER J CLIN, V40, P9, DOI 10.3322/canjclin.40.1.9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Vestergaard ME, 2008, BRIT J DERMATOL, V159, P669, DOI 10.1111/j.1365-2133.2008.08713.x
   Wei J., 2019, ARXIV191111445
   WHITE R, 1991, DERMATOL CLIN, V9, P695
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu Z, 2017, I S BIOMED IMAGING, P301, DOI 10.1109/ISBI.2017.7950524
   Zhang MF, 2012, J CLIN ONCOL, V30, P1588, DOI 10.1200/JCO.2011.39.3652
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zongyuan Ge, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P250, DOI 10.1007/978-3-319-66179-7_29
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 79
TC 88
Z9 89
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28477
EP 28498
DI 10.1007/s11042-020-09388-2
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000555748500001
DA 2024-07-18
ER

PT J
AU El Houby, EMF
   Yassin, NIR
AF El Houby, Enas M. F.
   Yassin, Nisreen I. R.
TI Wavelet-Hadamard based blind image watermarking using genetic algorithm
   and decision tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Genetic algorithm; Decision tree; Hadamard
   transform; Discrete wavelet transform
ID ROBUST; DECOMPOSITION; TRANSFORM
AB Recently the active use of Internet and multimedia technologies has increased the violation of copyright. Digital watermarking has a crucial role in the field of multimedia copyright protection. In this paper, an optimized image watermarking technique based on Discrete Wavelet Transform (DWT) and Hadamard transform is proposed. Genetic Algorithm (GA) is an optimizing technique used to satisfy the tradeoff between robustness and imperceptibility. Blind property is conducted using the estimation capability of Decision Tree (DT). First the host image is transformed using second level DWT, then Hadamard transform is applied on selected DWT sub-bands. Adaptive multiple strength values are computed using GA. The watermark is successfully extracted using the trained DT which estimates the original coefficients needed for the extraction process without the need for the original host image. The proposed technique is evaluated against several types of attacks: compression, median filtering, salt and pepper noise, histogram equalization, blurring, scaling, painting, and cropping. Experimental results show that the proposed watermarking technique is robust against these attacks while keeping good imperceptibility. The proposed technique outperforms the compared techniques according to robustness, imperceptibility, and capacity.
C1 [El Houby, Enas M. F.; Yassin, Nisreen I. R.] Natl Res Ctr, Syst & Informat Dept, Div Engn, Cairo 12311, Egypt.
C3 Egyptian Knowledge Bank (EKB); National Research Centre (NRC)
RP Yassin, NIR (corresponding author), Natl Res Ctr, Syst & Informat Dept, Div Engn, Cairo 12311, Egypt.
EM enas_mfahmy@yahoo.com; nisreen.yassin20@gmail.com
OI Yassin, Nisreen/0000-0003-0735-3231; M.F.El Houby,
   Enas/0000-0002-6005-8787
CR Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Bamatraf A, 2011, ARXIV11116727
   Bassel Atheer, 2017, Advances in Visual Informatics. 5th International Visual Informatics Conference, IVIC 2017. Proceedings: LNCS 10645, P702, DOI 10.1007/978-3-319-70010-6_65
   Gen M., 2000, Genetic Algorithms and Engineering Optimization
   Han J, 2012, MOR KAUF D, P1
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Huang H-C, 2013, RECENT ADV INFORM HI, P139, DOI DOI 10.1007/978-3-642-28580-6_7
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Kazemivash B, 2017, MULTIMED TOOLS APPL, V76, P20499, DOI 10.1007/s11042-016-3962-5
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kumaran T, 2008, INT C WAVEL ANAL PAT, P585, DOI 10.1109/ICWAPR.2008.4635847
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Mohananthini N., 2016, Journal of Electrical Systems and Information Technology, V3, P68, DOI 10.1016/j.jesit.2015.11.009
   Nikolaidis A, 2001, IEEE T IMAGE PROCESS, V10, P1726, DOI 10.1109/83.967400
   Pai YT, 2011, INT J INNOV COMPUT I, V7, P5893
   Patil P, 2013, INT J ENG ADV TECHNO
   Pullayikodi SK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3040046
   Samee Muhammad Kashif, 2014, International Journal of Future Computer and Communication, V2, P138, DOI 10.7763/IJFCC.2013.V2.138
   Sarker MIH, 2013, SMARTCR, V3, P298, DOI DOI 10.6029/SMARTCR.2013.05.001
   Shaamala A., 2011, International Journal of Computer Science Issues, V8, P220
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Vahedi E, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P635
   Vahedi E, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P58
   Vahedi E, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1383
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Viswanatham VM, 2012, ANALE SERIA INFORM, V10
   [王娟 Wang Juan], 2014, [计算机科学, Computer Science], V41, P212
   Wang XY, 2016, AEU-INT J ELECTRON C, V70, P416, DOI 10.1016/j.aeue.2016.01.002
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yadav AK, 2016, MULTIMED TOOLS APPL, V75, P9371, DOI 10.1007/s11042-016-3381-7
   Yassin NI, 2014, ALEX ENG J, V53, P833, DOI 10.1016/j.aej.2014.07.008
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang JB, 2018, INT C PATT RECOG, P159, DOI 10.1109/ICPR.2018.8546290
   Zhou X, 2018, ADAPTIVE DIGITAL WAT
NR 41
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28453
EP 28474
DI 10.1007/s11042-020-09333-3
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555748500002
DA 2024-07-18
ER

PT J
AU Kerkaou, Z
   El Ansari, M
AF Kerkaou, Zakaria
   El Ansari, Mohamed
TI Support vector machines based stereo matching method for advanced driver
   assistance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo vision; Support vector machine; Spatio-temporal matching; ADAS
ID REAL-TIME STEREO; FAST SPATIOTEMPORAL STEREO; COST AGGREGATION;
   SPACETIME STEREO; RECOVERY; DEPTH
AB Stereo vision is a measurement method for finding correspondence between two or more input images in order to obtain a detailed 3D representation of a scene. This paper presents an approach for matching stereo sequences acquired by a stereo sensor mounted on an intelligent vehicle. The approach uses machine learning alongside spatio-temporal information to predict the matching results. This means that the obtained matching results during the previous frame are used as a training samples for a support vector machine classifier, as well as to derive disparity ranges for each scan-line, which are then used to predict the matching of the current frame. The distance to the hyper-plan computed by the SVM is used as a cost function to fill a 2D search space. Then, the dynamic programming algorithm is performed for matching edge points in the stereo pair. Experiments on both virtual and real stereo image sequences have been conducted, demonstrating satisfactory performance.
C1 [Kerkaou, Zakaria; El Ansari, Mohamed] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Kerkaou, Z (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM kerkaou.zakaria@gmail.com; m.elansari@uiz.ac.ma
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
CR Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cech J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3129, DOI 10.1109/CVPR.2011.5995442
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CRUZ JM, 1995, PATTERN RECOGN LETT, V16, P933, DOI 10.1016/0167-8655(95)00028-F
   Pham CC, 2013, IEEE T CIRC SYST VID, V23, P1119, DOI 10.1109/TCSVT.2012.2223794
   Davis J, 2003, PROC CVPR IEEE, P359
   Dobias M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P704, DOI 10.1109/ICCVW.2011.6130317
   El Ansari M, 2011, IEEE INT C INTELL TR, P1483, DOI 10.1109/ITSC.2011.6082875
   El Ansari M, 2010, PATTERN RECOGN LETT, V31, P1226, DOI 10.1016/j.patrec.2010.03.023
   El Jaafari I, 2017, SIGNAL IMAGE VIDEO P, V11, P267, DOI 10.1007/s11760-016-0932-3
   El Jaafari I, 2016, NEUROCOMPUTING, V194, P24, DOI 10.1016/j.neucom.2016.02.010
   Ellahyani A, 2017, MULTIMED TOOLS APPL, V76, P24495, DOI 10.1007/s11042-016-4207-3
   Gong ML, 2006, LECT NOTES COMPUT SC, V3953, P564, DOI 10.1007/11744078_44
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Jiang J, 2014, NEUROCOMPUTING, V142, P335, DOI 10.1016/j.neucom.2014.04.027
   Jiao JB, 2014, IEEE MULTIMEDIA, V21, P16, DOI 10.1109/MMUL.2014.51
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Kerkaou Z, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053015
   Kerkaou Z, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Klaus A, 2006, INT C PATT RECOG, P15
   Kogler J, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.4.043011
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kong D., 2004, BRIT MACHINE VISION, V1, P2
   Labayrade R, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P646
   Lahmyed R, 2019, MULTIMED TOOLS APPL, V78, P15861, DOI 10.1007/s11042-018-6974-5
   Lahmyed R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063011
   LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682
   Li YC, 2019, OPTIK, V178, P1318, DOI 10.1016/j.ijleo.2018.10.126
   Liu Y., 2018, ARXIV180402864
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Mazoul A, 2014, PATTERN ANAL APPL, V17, P211, DOI 10.1007/s10044-012-0310-x
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925
   Motten A, 2012, IEEE INT CONF VLSI, P247, DOI 10.1109/VLSI-SoC.2012.6379038
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   Raghavendra U, 2015, SIGNAL IMAGE VIDEO P, V9, P893, DOI 10.1007/s11760-013-0524-4
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Song X, 2020, INT J COMPUT VISION, V128, P910, DOI 10.1007/s11263-019-01287-w
   Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tao H, 2001, PROC CVPR IEEE, P118
   van der Mark W., 2008, SYNTHETIC STEREO IMA
   Wang L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P129
   Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yu W, 2009, IEEE IMAGE PROC, P4281, DOI 10.1109/ICIP.2009.5413693
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
   Zhang JM, 2019, IEEE ROBOT AUTOM LET, V4, P1162, DOI 10.1109/LRA.2019.2894913
   Zhang L, 2003, PROC CVPR IEEE, P367
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu SP, 2017, MULTIMED TOOLS APPL, V76, P199, DOI 10.1007/s11042-015-3023-5
NR 59
TC 6
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27039
EP 27055
DI 10.1007/s11042-020-09260-3
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551000700002
DA 2024-07-18
ER

PT J
AU Shoitan, R
   Moussa, MM
   Elshoura, SM
AF Shoitan, Rasha
   Moussa, Mona M.
   Elshoura, S. M.
TI A robust video watermarking scheme based on Laplacian pyramid, SVD, and
   DWT with improved robustness towards geometric attacks via SURF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; DWT; SVD; Laplacian pyramid; SURF; Image hashing
ID PERFORMANCE ANALYSIS; TRANSFORM; SECURE
AB In this paper, a new robust and secure video watermarking scheme based on discrete Wavelet Transform (DWT), singular value decomposition (SVD), and Laplacian pyramid is proposed for copyright protection applications. The main contributions of this work are: 1) Increasing watermark robustness towards common signal processing attacks by separating the watermark image into a high-frequency image and a low-frequency image using laplacian pyramid. Then, the singular values of each of the low-frequency watermark image and the high-frequency watermark image are hidden in two different DWT subbands of the original video frame. Separating the watermark and hiding its two parts in two different subbands of the DWT of the video frame makes it robust towards noise, filtering, and compression attacks. 2) Improving the quality of the extracted watermarks via correcting the received watermarked videos using SURF points when those videos are geometrically attacked, mainly by rotation, scaling, and shear attacks. 3) Increasing security and avoiding false positive problems (FPP) associated with SVD by using perceptual image hashing in the proposed scheme. Through experimental results and comparisons to other techniques, the proposed scheme has shown very high imperceptibility for the tested watermarked videos in terms of peak signal to noise ratio (PSNR). Also, the proposed scheme has demonstrated high watermark robustness towards various types of attacks, and an improvement in the quality of the extracted watermarks from 4 to 20 dB compared to other techniques.
C1 [Shoitan, Rasha; Moussa, Mona M.; Elshoura, S. M.] Elect Res Inst, Dept Comp & Syst, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI)
RP Shoitan, R (corresponding author), Elect Res Inst, Dept Comp & Syst, Cairo, Egypt.
EM rasha.shoitan@eri.sci.eg
RI shoitan, rasha mahmoud/D-2391-2015; shoitan, rasha/AAX-4574-2020
OI shoitan, rasha/0000-0003-0372-4293; moussa, mona/0000-0002-3647-1993
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   [Anonymous], 2011, International Journal of Wisdom Based Computing
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Blahut R., 1994, THEORY PRACTICE ERRO
   Burt PJ, 1983, LAPLACIAN PYRAMID CO, P532
   [陈善学 Chen Shanxue], 2013, [计算机应用, Journal of Computer Applications], V33, P1626
   Chitrasen, 2015, IJARCCE, V4, P307, DOI DOI 10.17148/IJARCCE.2015.4170
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   El-Bolok H, 2009, 19 INT C COMP THEOR
   Elkabbany GF, 2020, MULTIMED TOOLS APPL, V79, P17427, DOI 10.1007/s11042-020-08717-9
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Fung C. W. H., 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P233, DOI 10.1109/CIMSim.2011.48
   Goel B, 2013, INT CONF CONTEMP, P307, DOI 10.1109/IC3.2013.6612210
   Gopika V, 2013, INT J SCI RES PUBL, V3, P763
   Grgic S., 2004, Journal of Electrical Engineering, V55, P3
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kaur MAA, 2016, INT J COMPUT APPL, V146, P11, DOI [10.5120/ijca2016910699, DOI 10.5120/IJCA2016910699]
   Kong WH, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P265
   Kothari AM, 2019, WATERMARKING TECHNIQ
   Kumar M, 2015, INT J INNOV RES COMP, V3, P3001
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Loukhaoukha K, 2009, 2009 11TH CANADIAN WORKSHOP ON INFORMATION THEORY, P177, DOI 10.1109/CWIT.2009.5069549
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Mawande S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P1161, DOI 10.1109/ICCMC.2017.8282656
   Mikolajczyk K, 2010, INDEXING BASED SCALE
   Mistry D., 2017, GRD JOURNALSGLOBAL R, V2, P7
   Patil AS, 2014, IOSR J ENG, V3, P45, DOI [10.9790/3021-031144549, DOI 10.9790/3021-031144549]
   Potkar AN, 2014, REV DIFFERENT VIDEO, V3, P190
   Raghavendra R, 2010, INT J BIOMETRICS, V2, P19, DOI 10.1504/IJBM.2010.030414
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Rathorel SA, ITHEA OFTAME NUSI CR, P2
   Reyes R, 2010, IEEE LAT AM T, V8, P304, DOI 10.1109/TLA.2010.5538406
   Shanmugam M, 2018, MICROSYST TECHNOL, V24, P4757, DOI 10.1007/s00542-018-3870-x
   Singh KM, 2018, MULTIMED TOOLS APPL, V77, P16419, DOI 10.1007/s11042-017-5213-9
   Tabassum T, 2012, INT CONF COMPUT INFO, P101, DOI 10.1109/ICCITechn.2012.6509780
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P15191, DOI 10.1007/s11042-016-3744-0
   Wai CK, 2014, ROBUST DWT SVD IMAGE, P227
NR 42
TC 2
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26837
EP 26860
DI 10.1007/s11042-020-09258-x
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549799000006
DA 2024-07-18
ER

PT J
AU Lin, YP
   Song, PP
   Long, H
AF Lin, Yuping
   Song, Panpan
   Long, Hong
TI Accurate language achievement prediction method based on multi-model
   ensemble using personality factors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality factors; Regression; Correntropy; Multi-model ensemble
ID MODEL
AB To overcome the noise in personality factors and precisely predict language achievement, we propose a robust regression algorithm based on the maximum correntropy criterion (MCC) and the coarse-to-fine method. Firstly, as there are many samples while few personality factors correlate to the language achievement in the data set, we propose a regression method based on Pearson feature selection to eliminate the noise and redundant features for solving the overfitting problem. Secondly, as the learning ability of each traditional regression model is different and limited, we introduce the model ensemble method based on MCC to predict language achievement via personality factors. Thirdly, owing to the fact that the language achievement data is unevenly distributed and the same model parameter cannot fit all the data effectively, we propose a coarse-to-fine prediction method to reduce prediction errors, which divides the range of the language achievement into multiple intervals and then establishes different regression models at each interval to obtain more accurate results. The experimental results on the data set of the personality factors and English achievement demonstrate the high precision and robustness of the proposed algorithm compared with the traditional single regression models.
C1 [Lin, Yuping] Xi An Jiao Tong Univ, Sch Foreign Studies, Xian 710049, Shaanxi, Peoples R China.
   [Song, Panpan; Long, Hong] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Lin, YP (corresponding author), Xi An Jiao Tong Univ, Sch Foreign Studies, Xian 710049, Shaanxi, Peoples R China.
EM linyouchen@xjtu.edu.cn
FU Shaanxi Province Education Science "13th Five-Year" Planning Project of
   China [SGH17H003]
FX This work was supported by the Shaanxi Province Education Science "13th
   Five-Year" Planning Project of China (Grant No. SGH17H003).
CR [Anonymous], 1954, J CONSULT PSYCHOL, V18, P75
   [Anonymous], 2004, FOREIGN LANGUAGE WOR
   BERKEY CS, 1995, STAT MED, V14, P395, DOI 10.1002/sim.4780140406
   Blick G, 1996, EUR J PERSONAL, V10, P1231
   BUTCHER HJ, 1963, BRIT J EDUC PSYCHOL, V33, P276, DOI 10.1111/j.2044-8279.1963.tb00590.x
   Cattell HEP, 2001, PERSP INDIV, P187
   Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2
   [答会明 Da Huiming], 2007, [心理科学, Psychological Science], V30, P676
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Ding D, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918401152
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   EYSENCK HJ, 1972, BRIT J SOC CLIN PSYC, V11, P265, DOI 10.1111/j.2044-8260.1972.tb00812.x
   Fatahi S, 2016, ARTIF INTELL REV, V46, P413, DOI 10.1007/s10462-016-9469-7
   FRIEDMAN AF, 1976, J PERS ASSESS, V40, P302, DOI 10.1207/s15327752jpa4003_9
   He YY, 2019, INT J ELEC POWER, V113, P515, DOI 10.1016/j.ijepes.2019.05.075
   HORWITZ EK, 1986, MOD LANG J, V70, P125, DOI 10.2307/327317
   Maclmtyre PID, 1993, LANG LEARN, V44, P283
   Marina O. A., 2014, PASAA: Journal of Language Teaching and Learning in Thailand, V47, P61
   MEHRYAR AH, 1972, BRIT J SOC CLIN PSYC, V11, P257, DOI 10.1111/j.2044-8260.1972.tb00811.x
   MERSHON B, 1988, J PERS SOC PSYCHOL, V55, P675, DOI 10.1037/0022-3514.55.4.675
   Mikhnenko G, 2018, ADV EDUC, P33, DOI 10.20535/2410-8286.121057
   NOLLER P, 1987, J PERS SOC PSYCHOL, V53, P775, DOI 10.1037/0022-3514.53.4.775
   Qing-Shui Qiao, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P209, DOI 10.1109/ICMLC.2011.6016737
   Rimfeld K, 2016, J PERS SOC PSYCHOL, V111, P780, DOI 10.1037/pspp0000089
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   SAVILLETROIKE M, 1984, TESOL QUART, V18, P199, DOI 10.2307/3586690
   SHAUGHNESSY MF, 1994, PSYCHOL REP, V75, P348, DOI 10.2466/pr0.1994.75.1.348
   Shen H, 2010, IEEE T WIREL COMMUN, V9, P3480, DOI 10.1109/TWC.2010.091510.091836
   Tempelaar DT, 2007, CONTEMP EDUC PSYCHOL, V32, P105, DOI 10.1016/j.cedpsych.2006.10.004
   Vilaça M, 2019, INT J INJ CONTROL SA, V26, P379, DOI 10.1080/17457300.2019.1645185
   Xin W, 2013, INFORM MANAGEMENT SC, VIV, P739
   Zabihi R., 2011, Continental Journal Education Research, V4, P1
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
   Zhu W., 2010, Northeast SAS Users Group 2010: Health Care and Life Sciences, P1
NR 34
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17415
EP 17428
DI 10.1007/s11042-020-09297-4
EA JUL 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000547805500001
DA 2024-07-18
ER

PT J
AU Fooladgar, F
   Kasaei, S
AF Fooladgar, Fahimeh
   Kasaei, Shohreh
TI Lightweight residual densely connected convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Convolutional neural networks; Deep learning;
   Efficient architecture
AB Extremely efficient convolutional neural network architectures are one of the most important requirements for limited-resource devices (such as embedded and mobile devices). The computing power and memory size are two important constraints of these devices. Recently, some architectures have been proposed to overcome these limitations by considering specific hardware-software equipment. In this paper, the lightweight residual densely connected blocks are proposed to guaranty the deep supervision, efficient gradient flow, and feature reuse abilities of convolutional neural network. The proposed method decreases the cost of training and inference processes without using any special hardware-software equipment by just reducing the number of parameters and computational operations while achieving a feasible accuracy. Extensive experimental results demonstrate that the proposed architecture is more efficient than the AlexNet and VGGNet in terms of model size, required parameters, and even accuracy. The proposed model has been evaluated on the ImageNet, MNIST, Fashion MNIST, SVHN, CIFAR-10, and CIFAR-100. It achieves state-of-the-art results on Fashion MNIST dataset and reasonable results on the others. The obtained results show the superiority of the proposed method to efficient models such as the SqueezNet. It is also comparable with state-of-the-art efficient models such as CondenseNet and ShuffleNet.
C1 [Fooladgar, Fahimeh; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM fahimehfooladgar@ce.sharif.edu; kasaei@sharif.edu
CR [Anonymous], 2016, ARXIV160202830
   [Anonymous], 2014, Advances in Neural Information Processing Systems (NIPS)
   Assunçao F, 2019, GENET PROGRAM EVOL M, V20, P5, DOI 10.1007/s10710-018-9339-y
   Baker B., 2017, INT C LEARNING REPRE
   Cai Han, 2019, INT C LEARN REPR
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Denil M., 2013, ADV NEURAL INFORM PR
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   FOOLADGAR F, 2019, SCI INF C, V3, P544
   Fooladgar F, 2020, MULTIMED TOOLS APPL, V79, P4499, DOI 10.1007/s11042-019-7684-3
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HU Y, 2018, ARXIV180708920
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KUUTTI S, 2020, IEEE T INTELLIGENT T
   Liu Chenxi, 2018, P EUR C COMP VIS, P19
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu HL, 2015, CHIN CONT DECIS CONF, P2885
   NASEER M, 2018, ARXIV180303352
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sabour Sara, 2017, Advances in Neural Information Processing Systems, P3856
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377, DOI DOI 10.48550/ARXIV.1505.00387
   Srivastava RupeshKumar., 2015, CoRR
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tarannum A, 2020, J BIOMOL STRUCT DYN, V38, P918, DOI 10.1080/07391102.2019.1585952
   Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25
   Wen W, 2016, ADV NEUR IN, V29
   Xiao H., 2017, ARXIV170807747
   Yang YB, 2018, PROC CVPR IEEE, P2413, DOI 10.1109/CVPR.2018.00256
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   ZHANG Y, 2018, ARXIV181210477
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhong ZX, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177655
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou H, 2016, LECT NOTES COMPUT SC, V9908, P662, DOI 10.1007/978-3-319-46493-0_40
NR 53
TC 9
Z9 10
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25571
EP 25588
DI 10.1007/s11042-020-09223-8
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545195700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ben Ali, R
   Ejbali, R
   Zaied, M
AF Ben Ali, Ramzi
   Ejbali, Ridha
   Zaied, Mourad
TI Classification of medical images based on deep stacked patched
   auto-encoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Images classification; Pattern recognition; Deep learning; Wavelet
   network; Deep neural wavelets network; Sparse auto-encoder
ID BREAST MASS CLASSIFICATION; LUNG SEGMENTATION; NETWORK; RECOGNITION;
   MAMMOGRAMS; ALGORITHM
AB The concept of artificial intelligence is not new. Without going into details of the evolution of artificial intelligence, we can confess that recent techniques of deep neural networks have considerably relaunched the trend with a significant advance namely the ability to automatically learn high-level concepts. However, a great step has been taken in deep learning to help researchers perform segmentation, feature extraction, classification and detection from raw medical images. This paper concerns the automatic classification of medical images with deep neural networks. We aimed at developing a system for automatic classification of medical images and detection of anomalies in order to provide a decision-making tool for the doctor. In this component we proposed a method for classifying medical images based on deep neural network using sparse coding and wavelet analysis. Serval real databases are used to test the proposed methods: MIAS and DDSM for mammogram images, LIDC-IDRI for lung images and dental dataset images. Classifications rates given by our approach show a clear improvement compared to those cited in this article.
C1 [Ben Ali, Ramzi; Ejbali, Ridha] Univ Gabes, ENIG, Res Team Intelligent Machines RTIM, Zrig 6029, Gabes, Tunisia.
   [Zaied, Mourad] RTIM, Gabes, Tunisia.
C3 Universite de Gabes; Universite de Gabes
RP Ben Ali, R (corresponding author), Univ Gabes, ENIG, Res Team Intelligent Machines RTIM, Zrig 6029, Gabes, Tunisia.
EM ramzi.benali@gmail.com; ridha_ejbali@ieee.org; mourad.zaied@ieee.org
RI Ali, Ramzi Ben/ABD-3555-2020; Ejbali, Ridha/K-4234-2012
OI Ejbali, Ridha/0000-0002-8148-1621; Ben Ali, Ramzi/0000-0001-7820-2233
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Ali RB., 2018, J COMPUT SCI, V69, P1488, DOI [10.3844/jcssp.2018.1488.1498, DOI 10.3844/JCSSP.2018.1488.1498]
   AlQoud A, 2016, INT J COMPUT SCI NET, V16, P16
   [Anonymous], COMPUT MATH METHODS
   [Anonymous], 2013, FOUND TRENDS SIGNAL, DOI DOI 10.1561/2000000039
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2008, 1 WORKSH IM PROC THE
   [Anonymous], 2016, ICSEA 2016 11 INT C
   [Anonymous], NEURAL NETWORKS
   [Anonymous], 2016, 2016 3 INT C ART INT, DOI DOI 10.1109/ICAIPR.2016.7585230
   Arias DG, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P234, DOI 10.1109/ICMLA.2017.0-153
   Ben Ali R, 2015, INT CONF INTELL SYST, P505, DOI 10.1109/ISDA.2015.7489167
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Choi WJ, 2014, COMPUT METH PROG BIO, V113, P37, DOI 10.1016/j.cmpb.2013.08.015
   DALI AD, 2018, INDONESIAN J ELECT E, V12, P570, DOI DOI 10.11591/IJEECS.V12.I2
   Daood Amar, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P321, DOI 10.1007/978-3-319-50835-1_30
   de Carvalho AO, 2014, ARTIF INTELL MED, V60, P165, DOI 10.1016/j.artmed.2013.11.002
   Debelee Taye Girma, 2018, Information and Communication Technology for Development for Africa. First International Conference, ICT4DA 2017. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 244), P89, DOI 10.1007/978-3-319-95153-9_9
   Dixit A, 2018, 2018 9 INT C COMP CO, P1
   Ejbali R, 2010, INT J SPEECH TECHNOL, V13, P163, DOI 10.1007/s10772-010-9076-y
   da Silva GLF, 2018, COMPUT METH PROG BIO, V162, P109, DOI 10.1016/j.cmpb.2018.05.006
   Froz BR, 2017, EXPERT SYST APPL, V69, P176, DOI 10.1016/j.eswa.2016.10.039
   Hepsag PU, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P418, DOI 10.1109/UBMK.2017.8093429
   Huang ZY, 2017, IEEE T CYBERNETICS, V47, P920, DOI 10.1109/TCYB.2016.2533424
   Jemai O., 2010, IJCNN, P1
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Yann, 2015, Nature
   Mahersia H, 2016, COMPUT METH PROG BIO, V126, P46, DOI 10.1016/j.cmpb.2015.10.017
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Namin ST, 2010, IEEE SYS MAN CYBERN, P3774, DOI 10.1109/ICSMC.2010.5641820
   Peng W, 2016, COMPUT METH PROG BIO, V125, P134, DOI 10.1016/j.cmpb.2015.09.019
   Pratiwi M, 2015, PROCEDIA COMPUT SCI, V59, P83, DOI 10.1016/j.procs.2015.07.340
   Pu J, 2008, COMPUT MED IMAG GRAP, V32, P452, DOI 10.1016/j.compmedimag.2008.04.005
   Reyad YA, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0100-7
   Shen SW, 2015, COMPUT BIOL MED, V57, P139, DOI 10.1016/j.compbiomed.2014.12.008
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Tomè D, 2016, SIGNAL PROCESS-IMAGE, V47, P482, DOI 10.1016/j.image.2016.05.007
   Torrents-Barrena Jordina, 2014, Breast Imaging. 12th International Workshop, IWDM 2014. Proceedings: LNCS 8539, P581, DOI 10.1007/978-3-319-07887-8_81
   Wang SS, 2017, ANAL CHEM, V89, P5646, DOI 10.1021/acs.analchem.7b00965
   Xie WY, 2016, NEUROCOMPUTING, V173, P930, DOI 10.1016/j.neucom.2015.08.048
   Zaied M, 2011, INT J WAVELETS MULTI, V9, P923, DOI 10.1142/S0219691311004389
   Zaied M, 2005, J DECIS SYST, V14, P109, DOI 10.3166/jds.14.109-122
   Zhang F, 2013, 2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA), P185
   Zhang GY, 2010, INT CONF COMP SCI, P335, DOI 10.1109/ICCSIT.2010.5565021
   [No title captured]
   [No title captured]
NR 47
TC 7
Z9 7
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25237
EP 25257
DI 10.1007/s11042-020-09056-5
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544843700004
DA 2024-07-18
ER

PT J
AU Wang, XY
   Zhao, HY
AF Wang, Xingyuan
   Zhao, Hongyu
TI Fast image encryption algorithm based on parallel
   permutation-and-diffusion strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel permutation-and-diffusion; Image encryption; Coupled map
   lattices; Chaos
ID SPATIOTEMPORAL CHAOS; DIGITAL MEDIA; DES
AB In the image encryption algorithms, expansion of size and increase of data lead to a large amount of time consumption. To improve the efficiency, the current efforts are mainly limited to the design of streaming encryption algorithms, which do not greatly reduce encryption time and may cause security issues. Therefore, we propose a new image encryption algorithm, which based on the parallel permutation-and-diffusion (PPAD) strategy, and adopt the sub-key cross-fusion method to form the different secret keys in different rounds. The proposed algorithm significantly improves the parallelism of encryption while ensuring security, and achieves an excellent enhancement in efficiency over conventional streaming encryption algorithms. The performance evaluations prove that the proposed strategy has high security to resist common attacks and is suitable for image encryption.
C1 [Wang, Xingyuan; Zhao, Hongyu] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY; Zhao, HY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM xywang@dlmu.edu.cn; 330251657@qq.com
RI Wang, Xing-yuan/I-6353-2015
CR Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Bai YR, 2018, OPTIK, V168, P553, DOI 10.1016/j.ijleo.2018.04.054
   Bansal A, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P928, DOI 10.1109/IADCC.2009.4809139
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bouslehi H, 2018, MULTIMED TOOLS APPL, V77, P30841, DOI 10.1007/s11042-018-5997-2
   Busch C, 2002, IEEE COMPUT GRAPH, V19, P16
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   George RT, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND COMMUNICATIONS (ICCSC), P203, DOI 10.1109/COMPSC.2014.7032648
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   Kim J, 2010, COMPUT MATH APPL, V60, P347, DOI 10.1016/j.camwa.2010.01.011
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Masters BR, 2009, J BIOMED OPT, V14
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Memon N, 1998, COMMUN ACM, V41, P34
   Patil P, 2016, PROCEDIA COMPUT SCI, V78, P617, DOI 10.1016/j.procs.2016.02.108
   Prakash SJ, 2018, SOLITONS FRACTALS, V114, P81
   Rehman A.-U., 2016, MULTIMED TOOLS APPL, V75, P1, DOI DOI 10.1007/s11042-014-2221-x
   SAMUELSON P, 1991, COMMUN ACM, V34, P23, DOI 10.1145/125223.125289
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Sui LS, 2015, OPT LASER ENG, V75, P17, DOI 10.1016/j.optlaseng.2015.06.005
   Tang GN, 2003, PHYS LETT A, V318, P388, DOI 10.1016/j.physleta.2003.09.042
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Tang ZY, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-008680
   Tromer E, 2010, J CRYPTOL, V23, P37, DOI 10.1007/s00145-009-9049-y
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, PHYSICA A, V402, P104, DOI 10.1016/j.physa.2014.01.051
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-016-1461-2
NR 43
TC 16
Z9 16
U1 2
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19005
EP 19024
DI 10.1007/s11042-020-08810-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500006
DA 2024-07-18
ER

PT J
AU Xu, JB
   Zhang, JD
   Zhang, KP
   Liu, T
   Wang, DH
   Wang, X
AF Xu, Jiabin
   Zhang, Jindong
   Zhang, Kunpeng
   Liu, Tong
   Wang, Donghui
   Wang, Xue
TI An APF-ACO algorithm for automatic defect detection on vehicle paint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ant colony algorithm; Defect detection; Image edge detection; Computer
   vision
ID CLASSIFICATION; VISION
AB As a popular technology in the field of artificial intelligence, computer vision is gradually adapting to the needs of convenience for human beings, improving production efficiency and reducing production costs. Therefore, this study proposes a computer vision algorithm to locate and identify the location of defects. For the traditional edge detection algorithm Sobel, LoG, Canny, the decisive factor for the detection effect of paint defect image is the adjustment of parameters, which can't achieve an adaptive edge detection algorithm for paint defects, so it is thought that the evolution idea of ant colony algorithm can be used to achieve accurate detection of defects. This paper proposes an automatic detection method for vehicle body paint film defects based on computer vision. An ant colony optimization edge detection algorithm based on automotive paint features (APF-ACO) is proposed. By combining global update and local update, the convergence speed of ant colony algorithm is improved and a new pheromone calculation and update method is proposed to effectively preserve the edge details of the detected image. A reflection area detection algorithm based on HSV color space is designed to detect the reflective area and eliminate interference. Establish defect classification identification rules, identify and mark five types of defects, and determine defect categories. Experiments show that the method can effectively detect the defect area and the recognition accuracy is 97.76%.
C1 [Xu, Jiabin; Zhang, Jindong; Zhang, Kunpeng; Liu, Tong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
   [Wang, Donghui; Wang, Xue] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
EM 15843715316@163.com; zhangjindong_100@163.com; zkp0113@sina.com;
   15165434950@163.com; 1547976690@qq.com; 892881066@qq.com
RI Li, Mengqi/AAG-6804-2021; li, yao/IYJ-1364-2023; Liu, Gui/JHU-8707-2023;
   Yang, Ying/ABD-2481-2022
OI Zhang, Kunpeng/0000-0002-4299-9129
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies; National Natural Science Foundation of
   China [61872158]; Science and Technology Development Plan Project of
   Jilin Province [20190701019GH]; Fundamental Research Funds for the
   Central Universities; Jilin University [5157050847, 2017XYB252]
FX This work is supported by National Key Research and Development Program
   of China (2017YFB0102500), Natural Science Foundation of Jilin province
   (20170101133JC), Korea Foundation for Advanced Studies' International
   Scholar Exchange Fellowship for the academic year of 2017-2018, the
   National Natural Science Foundation of China (61872158), Science and
   Technology Development Plan Project of Jilin Province (20190701019GH),
   the Fundamental Research Funds for the Central Universities, and Jilin
   University (5157050847, 2017XYB252).
CR BORSU V, 2010, IEEE INT C AUTOM SCI, V2010, P551, DOI DOI 10.1109/COASE.2010.5584643
   Chen P, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, CONTROL, COMPUTING AND ELECTRONICS ENGINEERING (ICCCCEE)
   Chen T, 2015, INT J ADV COMPUT SC, V6, P47
   CHUNG YC, 2006, P SICE ICASE INT JOI, P4639, DOI DOI 10.1109/SICE.2006.315177
   Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, P53, DOI 10.1109/4235.585892
   DORIGO M, 1999, DORIGO MANIEZZO COLO, V26, P1
   Edris MZB, 2015, Proceedings 5th IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2015), P117, DOI 10.1109/ICCSCE.2015.7482169
   Eichhorn A, 2005, APPL SOFT COMPUT, V5, P301, DOI 10.1016/j.asoc.2004.08.002
   Giudice O, 2018, IEEE IMAGE PROC, P1138, DOI 10.1109/ICIP.2018.8451221
   Jelen L, 2008, INT J AP MAT COM-POL, V18, P75, DOI 10.2478/v10006-008-0007-x
   Jeyaraj PR, 2019, INT J CLOTH SCI TECH, V31, P510, DOI 10.1108/IJCST-11-2018-0135
   Jian Zhang, 2010, 2010 Proceedings of International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P215, DOI 10.1109/AICI.2010.167
   Jiang JL, 2020, KSII T INTERNET INF, V14, P687, DOI 10.3837/tiis.2020.02.012
   Kamani P., 2011, Proceedings of the 2011 First International Conference on Informatics and Computational Intelligence (ICI 2011), P244, DOI 10.1109/ICI.2011.47
   Kheirinejad S, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P12, DOI 10.1109/ICCKE.2018.8566516
   León FP, 2006, MEASUREMENT, V39, P536, DOI 10.1016/j.measurement.2005.12.007
   Li CL, 2018, IEEE ACCESS, V6, P27659, DOI 10.1109/ACCESS.2018.2841055
   Liantoni F, 2018, EMITTER, V6, P328, DOI 10.24003/emitter.v6i2.306
   LIN H, 2003, MOD SURV MAPP, V26, P8
   Liu J, 2019, MATEC WEB CONF, V256, DOI 10.1051/matecconf/201925605001
   Liu XC, 2015, OPT COMMUN, V353, P147, DOI 10.1016/j.optcom.2015.05.019
   Molina J, 2017, ROBOT CIM-INT MANUF, V48, P263, DOI 10.1016/j.rcim.2017.04.009
   Palanikkumar D, 2020, MULTIMED TOOLS APPL, V79, P3743, DOI 10.1007/s11042-018-6908-2
   Sun L, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-019-46684-w, 10.1038/s41598-019-45223-x]
   Tandiya A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P285, DOI 10.1109/CRV.2018.00047
   Wei XK, 2020, IEEE T INTELL TRANSP, V21, P947, DOI 10.1109/TITS.2019.2900385
   XU P, 2019, MULTIMED TOOLS APPL
   Yin XL, 2019, MULTIMED TOOLS APPL, V78, P12203, DOI 10.1007/s11042-018-6762-2
   Yue LW, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1474-5
   Zhang JD, 2019, MULTIMED TOOLS APPL, V78, P27663, DOI 10.1007/s11042-019-07890-w
   Zhao LM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040980
   2012, ANT COLONY OPTIMIZAT
NR 32
TC 12
Z9 13
U1 6
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25315
EP 25333
DI 10.1007/s11042-020-09245-2
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544843700005
DA 2024-07-18
ER

PT J
AU Yao, LY
   Yang, W
   Huang, W
AF Yao, Leiyue
   Yang, Wei
   Huang, Wei
TI A fall detection method based on a joint motion map using double
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Fall detection; Deep learning; Data
   visualization
ID ACTION RECOGNITION; ATTENTION
AB Automatic fall detection approaches are essential for elderly people, particularly for those who live alone, because of the pressing need for immediate medical assistance. In this paper, we proposed a highly effective fall detection method based on a joint motion map using two parallel convolutional neural networks. Compared with the most commonly used joint trajectory method (JTM), our proposed method provided three major improvements. First, the three channels (R, G and B) of a pixel were creatively used to store relative motion information of a certain joint in 3D coordinates. Thus, the human action recognition problem was simplified as a multi-class problem after actions were encoded as images. Moreover, the input parameters were dramatically reduced because of concentration only on 25 joints of the human skeleton. Second, human motion information in each frame was encoded as an independent slice of a motion image, which avoids the information loss problem caused by action trajectory overlap. Third, under the guidance of a medical experiment, the limit of stability test (LOST), the start key frame and end key frame of a possible fall can be exactly estimated. Therefore, motion images can be generated with a fixed size. Our method was evaluated on two publicly available datasets: the Telecommunication Systems Team fall detection dataset V2 (TST v2) and UTKinect-Action3D Dataset (UT-A3D). The experimental results show that our method achieved an accuracy of 97.35% on TST v2 and performed excellently in the fall discrimination capability test on UT-A3D.
C1 [Yao, Leiyue; Huang, Wei] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Yao, Leiyue; Yang, Wei] JiangXi Univ Technol, Sch Informat Engn, Nanchang 330098, Jiangxi, Peoples R China.
C3 Nanchang University
RP Yao, LY (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.; Yao, LY (corresponding author), JiangXi Univ Technol, Sch Informat Engn, Nanchang 330098, Jiangxi, Peoples R China.
EM leiyue_yao@163.com; wei.yang@163.com; n060101@e.ntu.edu.sg
RI Yao, Leiyue/HKN-3959-2023
FU National Natural Science Foundation of China [61862043]; Science and
   Technology Research Project of Jiang Xi Science and Technology Agency
   [20171BBE50060]
FX This research was supported by the National Natural Science Foundation
   of China under Grant 61862043 and the Science and Technology Research
   Project of Jiang Xi Science and Technology Agency under Grant
   20171BBE50060.
CR Abdelbaky A, 2020, NEURAL COMPUT APPL, V32, P12561, DOI 10.1007/s00521-020-04712-1
   Abu-Bakar SAR, 2019, IET IMAGE PROCESS, V13, P2381, DOI 10.1049/iet-ipr.2019.0350
   Ahmad T, 2020, IEEE ACCESS, V8, P305, DOI 10.1109/ACCESS.2019.2961770
   de la Concepción MAA, 2017, PERVASIVE MOB COMPUT, V34, P3, DOI 10.1016/j.pmcj.2016.05.002
   [Anonymous], 2018, J CAN RHEUMATOL ASS
   Burinskiene A, 2017, J SYSTEM MANAGEMENT, V7, P1
   Caetano C, 2019, SIBGRAPI, P16, DOI 10.1109/SIBGRAPI.2019.00011
   Chen HN, 2019, 2019 URSI ASIA-PACIFIC RADIO SCIENCE CONFERENCE (AP-RASC), DOI [10.3390/polym11122039, 10.23919/ursiap-rasc.2019.8738337]
   Chen Y, 2019, MULTIMED TOOLS APPL, V79, P1707
   Clemente J, 2020, IEEE J BIOMED HEALTH, V24, P524, DOI 10.1109/JBHI.2019.2907498
   Droghini D, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1512670
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Gasparrini S, 2015, 7 ICT INN C EM TECHN, P1
   Guo F, 2016, ONCOGENE, V35, P816, DOI 10.1038/onc.2015.139
   Haq M.R., 2019, 2019 International Joint Conference on Neural Network (IJCNN'19), P1
   Li YX, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010061
   Liang XY, 2019, PROCEEDINGS OF THE 2019 IEEE EURASIA CONFERENCE ON IOT, COMMUNICATION AND ENGINEERING (ECICE), P350, DOI 10.1109/ecice47484.2019.8942672
   Liu KC, 2020, IEEE SENS J, V20, P3303, DOI 10.1109/JSEN.2019.2955141
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Melzer I, 2009, AGE AGEING, V38, P119, DOI 10.1093/ageing/afn249
   Min WD, 2018, IET COMPUT VIS, V12, P1133, DOI 10.1049/iet-cvi.2018.5324
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Naeem A., 2019, 2019 15 INT C EMERGI, P1
   Ngu Anne, 2017, Smart Health. International Conference, ICSH 2017. Proceedings: LNCS 10347, P81, DOI 10.1007/978-3-319-67964-8_8
   Phyo CN, 2019, IEEE T CONSUM ELECTR, V65, P243, DOI 10.1109/TCE.2019.2908986
   Planinc R, 2013, PERS UBIQUIT COMPUT, V17, P1063, DOI 10.1007/s00779-012-0552-z
   Rougier C, 2013, IMAGE VISION COMPUT, V31, P246, DOI 10.1016/j.imavis.2012.11.003
   Thilo FJS, 2019, J CLIN NURS, V28, P310, DOI 10.1111/jocn.14599
   Wang D, 2019, J SYSTEM MANAGEMENT, V9, P104
   Wang H, 2017, IEEE T MOBILE COMPUT, V16, P511, DOI 10.1109/TMC.2016.2557795
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Yang HY, 2020, IEEE ACCESS, V8, P10040, DOI 10.1109/ACCESS.2020.2964115
   Yang L, 2015, SENSORS-BASEL, V15, P23004, DOI 10.3390/s150923004
   Yang ZY, 2019, IEEE T CIRC SYST VID, V29, P2405, DOI 10.1109/TCSVT.2018.2864148
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 37
TC 8
Z9 10
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4551
EP 4568
DI 10.1007/s11042-020-09181-1
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000542143000001
DA 2024-07-18
ER

PT J
AU Afzal, I
   Parah, SA
   Hurrah, NN
   Song, OY
AF Afzal, Ifrah
   Parah, Shabir A.
   Hurrah, Nasir N.
   Song, O. Y.
TI Secure patient data transmission on resource constrained platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic Health Record; Chaotic encryption; Mobile-Cloud transmission;
   Bitplane encryption; e-Healthcare
ID IMAGE ENCRYPTION; CLOUD; STEGANOGRAPHY; HEALTH
AB Electronic Health Record, which comprises of medical imagery, patient history, prescription and clinical observations is a highly sensitive data. This data is not generally sent over the network in its original form as it is prone to numerous security related issues. Generally, some encryption algorithms are applied on the data (medical image) before transmission over the network. However, resource constrained devices cannot perform complex encryption sand the process of encryption is entrusted to some third party like Cloud. But this third-party encryption requires the privacy of data to be preserved. After ensuring the privacy and performing third party encryption, the encrypted data can be securely transmitted over the network. This concept is used in the proposed work and a secure data transmission method is implemented. We have used two encryption techniques viz, chaotic encryption and bitplane encryption on the medical image which gives extra security to the image. While using the facilities of cloud for encryption (chaotic) the proposed method ensures that the cloud administrators get no hint about the information present in the data that is sent to them. In addition, the authenticity of the medical images is ensured and the encryption time obtained is small (must criterion for real time applications). The objectives of our work are verified by experimentations that are carried out on various medical images. The experimental results and theoretical analysis confirm the effectiveness of proposed work in terms of encryption time, security and authenticity.
C1 [Afzal, Ifrah; Parah, Shabir A.; Hurrah, Nasir N.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, India.
   [Song, O. Y.] Sejong Univ, Dept Software, Seoul, South Korea.
C3 University of Kashmir; Sejong University
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, India.
EM shabireltr@gmail.com
RI Hurrah, Nasir/AAX-2729-2021; Parah, Shabir/AAB-7603-2021
OI Hurrah, Nasir/0000-0002-0798-0158; Parah, Shabir/0000-0001-5983-0912;
   Hurrah, Nasir/0000-0003-3011-4255
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Ball MJ, 2001, INT J MED INFORM, V61, P1, DOI 10.1016/S1386-5056(00)00130-1
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Dong L, 2011, MULAN'S LEGEND AND LEGACY IN CHINA AND THE UNITED STATES, P195
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   ELLATIF AAA, 2020, OPTICS LASER TECHNOL
   Gentry C, 2010, COMMUN ACM, V53, P97, DOI 10.1145/1666420.1666444
   Ghazvini A, 2013, PROC TECH, V11, P212, DOI 10.1016/j.protcy.2013.12.183
   Han Qi, 2012, 2012 Second International Conference on Digital Information and Communication Technology and it's Applications (DICTAP), P195, DOI 10.1109/DICTAP.2012.6215350
   Hewitt C, 2008, IEEE INTERNET COMPUT, V12, P96, DOI 10.1109/MIC.2008.107
   Hong LX, 2008, PROC INT CONF ANTI, P223, DOI 10.1109/IWASID.2008.4688405
   Huang ZB, 2019, IEEE ACCESS, V7, P174541, DOI 10.1109/ACCESS.2019.2957497
   KAUR A, 2015, INT J COMPUTER APPL, V123, P20
   Liu B, 2019, J INTERNET TECHNOL, V20, P1333, DOI 10.3966/160792642019092005002
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Murakami K, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P503, DOI 10.1109/ICAwST.2013.6765492
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Priyanka V.P., 2016, J For Res, V2, P20
   Raphael AJ., 2010, International Journal of Computer Applications, V2, P626
   Rohith S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Salleh M, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P508
   SHARMA P, 2016, INT J ADV RES COMPUT, V6, P152
   SINGH S, 2013, INT J COMPUT SCI NET, V2, P142
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Venkatesh A., 2018, International Journal of Scientific Research in Computer Science, Engineering and Information Technology, V3, P1741
   Wang XL, 2019, IEEE ACCESS, V7, P66774, DOI 10.1109/ACCESS.2019.2917701
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Wu HM, 2018, IEEE ACCESS, V6, P3962, DOI 10.1109/ACCESS.2018.2791504
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xia ZH, 2020, IEEE T IND INFORM, V16, P629, DOI 10.1109/TII.2019.2913217
   Xiang T, 2015, DIGIT SIGNAL PROCESS, V43, P28, DOI 10.1016/j.dsp.2015.05.006
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Yao A. C., 1986, 27th Annual Symposium on Foundations of Computer Science (Cat. No.86CH2354-9), P162, DOI 10.1109/SFCS.1986.25
   Yao AC, 1982, P 23 IEEE S FDN COMP, P160, DOI DOI 10.1109/SFCS.1982.38
   Yu HL, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P252, DOI 10.1109/GCIS.2009.491
   Zhang Dinghui, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P849, DOI 10.1109/CSSE.2008.1165
NR 40
TC 7
Z9 8
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15001
EP 15026
DI 10.1007/s11042-020-09139-3
EA JUN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000538977500004
DA 2024-07-18
ER

PT J
AU Fang, YL
   Wang, H
   Wang, LT
   Di, RT
   Song, YQ
AF Fang, Youli
   Wang, Hong
   Wang, Lutong
   Di, Ruitong
   Song, Yongqiang
TI Feature-maximum-dependency-based fusion diagnosis method for COPD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COPD; Feature-maximum-dependency; Multi-dimensional feature; Integrated
   learning
ID EXTERNAL VALIDATION; PREDICTION MODELS; ROUGH SET; MACHINE
AB Chronic Obstructive Pulmonary Disease (COPD) is a chronic lung disease that causes a progressive decline in respiratory function. COPD has become the fourth most lethal disease in the world, and worldwide deaths continue to become more common as a result of COPD. Therefore, it is important to help doctors diagnose COPD more accurately using big data analytics and effective algorithms. In the past, COPD was mainly studied as follows: applying data to determine the impact of a single feature on the disease, such as the effect of FEV1/FVC (forced expiratory volume in the first second/forced vital capacity), and analyzing a case with simple models, such as logistic regression or a support vector machine. Therefore, there are obviously deficiencies in previous studies. First, the impacts of multi-dimensional features on COPD have not been considered comprehensively. Second, there is no fusion of multiple study methods on the diagnosis and prognosis of COPD. Thus, this paper presents a feature-maximum-dependency-based fusion diagnosis method for COPD. First, the MDF-RS (feature maximum dependency-rough set) algorithm is proposed to extract the optimal combination of multi-dimensional features. Second, the integrated model DSA-SVM (direct search simulated annealing-support vector machine) is presented to classify the disease. Finally, the proposed method is experimentally tested. The results show that the algorithms outperform other classic methods.
C1 [Fang, Youli; Wang, Hong; Wang, Lutong; Di, Ruitong; Song, Yongqiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
   [Fang, Youli; Wang, Hong; Wang, Lutong; Di, Ruitong; Song, Yongqiang] Shandong Prov Key Lab Distributed Comp Software N, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University
RP Wang, H (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.; Wang, H (corresponding author), Shandong Prov Key Lab Distributed Comp Software N, Jinan 250014, Shandong, Peoples R China.
EM wanghong106@163.com
OI yongqiang, Song/0000-0001-9964-9456
CR Ali MM, 2002, COMPUT OPER RES, V29, P87, DOI 10.1016/S0305-0548(00)00064-2
   [Anonymous], 2009, BMJ BRIT MED J, DOI DOI 10.1136/BMJ.B375
   Bleeker SE, 2003, J CLIN EPIDEMIOL, V56, P826, DOI 10.1016/S0895-4356(03)00207-5
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chen YM, 2010, PATTERN RECOGN LETT, V31, P226, DOI 10.1016/j.patrec.2009.10.013
   Cheung N, 2017, NEW ENGL J MED, V26, P126
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Du Zhan-long, 2015, Systems Engineering and Electronics, V37, P2777, DOI 10.3969/j.issn.1001-506X.2015.12.18
   Gao CQ, 2016, MULTIMED TOOLS APPL, V75, P9315, DOI 10.1007/s11042-016-3344-z
   Guo H-M., 2017, HLTH STAT, V34, P288
   Himes BE, 2009, J AM MED INFORM ASSN, V16, P371, DOI 10.1197/jamia.M2846
   Hoogendoorn M, 2017, INT J CHRONIC OBSTR, V12, P3183, DOI 10.2147/COPD.S142378
   Kaneiwa K, 2011, ROUGH SET APPROACH M, V11, P204
   Kaya Y, 2013, APPL SOFT COMPUT, V13, P3429, DOI 10.1016/j.asoc.2013.03.008
   Li CQ, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P211, DOI 10.1109/SERA.2017.7965730
   Liu R, 2018, INFORM SCIENCES, V450, P200, DOI 10.1016/j.ins.2018.03.031
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2016, ENVIRON CHEM, V13, P127, DOI 10.1071/EN15025
   López-Campos JL, 2016, RESPIROLOGY, V21, P14, DOI 10.1111/resp.12660
   Ma YC, 2016, J INTELL SYST, V25, P251, DOI 10.1515/jisys-2014-0179
   Mega JL, 2012, NEW ENGL J MED, V366, P9, DOI 10.1056/NEJMoa1112277
   Moons KGM, 2012, HEART, V98, P691, DOI 10.1136/heartjnl-2011-301247
   Sartakhti JS, 2012, COMPUT METH PROG BIO, V108, P570, DOI 10.1016/j.cmpb.2011.08.003
   Steyerberg EW, 2011, ACTA ANAESTH SCAND, V39, P134
   Steyerberg EW, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001381
   Thangavel K, 2009, APPL SOFT COMPUT, V9, P1, DOI 10.1016/j.asoc.2008.05.006
   [张友鹏 Zhang Youpeng], 2017, [铁道学报, Journal of the China Railway Society], V39, P68
NR 27
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15191
EP 15208
DI 10.1007/s11042-018-6876-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900049
DA 2024-07-18
ER

PT J
AU Jeong, J
   Kwon, S
   Hong, MP
   Kwak, J
   Shon, T
AF Jeong, JaeHan
   Kwon, Sungmoon
   Hong, Man-Pyo
   Kwak, Jin
   Shon, Taeshik
TI Adversarial attack-based security vulnerability verification using deep
   learning library for multimedia video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autoencoder; Security; Deep learning; CNN; MNIST; NSL-KDD; Adversarial
   attack
AB Recently, although deep learning has been employed in various fields, it poses the risk of a possible adversarial attack. In this study, we experimentally verified that classification accuracy in the image classification model of deep learning is lowered by adversarial samples generated by malicious attackers. We used the MNIST dataset, a representative image sample, and the NSL-KDD dataset, a representative network data. We measured the detection accuracy by injecting adversarial samples into the Autoencoder and Convolution Neural Network (CNN) classification models created using the TensorFlow and PyTorch libraries. Adversarial samples were generated by transforming the MNIST and NSL-KDD test datasets using the Jacobian-based Saliency Map Attack (JSMA) method and Fast Gradient Sign Method (FGSM). While measuring the accuracy by injecting the samples into the classification model, we verified that the detection accuracy was reduced by a minimum of 21.82% and a maximum of 39.08%.
C1 [Jeong, JaeHan; Kwon, Sungmoon; Hong, Man-Pyo; Kwak, Jin; Shon, Taeshik] Ajou Univ, Suwon 443749, Gyung Gi Do, South Korea.
C3 Ajou University
RP Shon, T (corresponding author), Ajou Univ, Suwon 443749, Gyung Gi Do, South Korea.
EM tsshon@ajou.ac.kr
OI Kwak, Jin/0000-0001-6931-2705
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 1999, KDD Cup
   BOTTOU L, 1994, PATT REC 1994 C B, V2, P1994
   Finlayson S. G., 2018, Science
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Heckerman D, 1997, P 13 C UNC ART INT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, WORKSHOP TRACK P
   Papernot N, 2016, ARXIV161000768
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Zhang G., 2017, P 2017 ACM SIGSAC C
NR 13
TC 8
Z9 8
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16077
EP 16091
DI 10.1007/s11042-019-7262-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600015
DA 2024-07-18
ER

PT J
AU Lee, K
   Kim, S
   Choi, HO
   Lee, J
   Nam, Y
AF Lee, Keonsoo
   Kim, Sora
   Choi, Hyung Oh
   Lee, Jinseok
   Nam, Yunyoung
TI Analyzing electrocardiogram signals obtained from a nymi band to detect
   atrial fibrillation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arrhythmia; Atrial fibrillation; Smartphone; Electrocardiogram
ID ECG; PREVALENCE; STROKE
AB In this paper, we propose a method for detecting atrial fibrillation (AF) from electrocardiogram (ECG) signals obtained from a wearable device. The proposed method uses three classification methods: neural networks (NNs), k-nearest neighbors (kNN), and decision trees (DT). The results from each of the three classifiers are combined using a voting system to make the final decision as to whether AF is present. To develop the classification system, we collected data from 61 subjects using a Nymi Band that is wrist-worn ECG monitoring device. From these signals, we extracted the root-mean square of the successive differences (RMSSD) and the Shannon entropy (ShE) of the RR interval, QS interval, and R peak amplitude. These properties were then used as features to train the classifiers. The accuracy, sensitivity, specificity, and precision of this classifier were 97.94%, 100.00%, 96.72%, and 94.74%, respectively for dataset with six features. The ensemble method of NNs, kNN, and DT was evaluated. Depending on the rules for ensemble, the accuracy, sensitivity, specificity, and precision are different among those classifiers. With a rule of unanimous determination for AF, false positive is decreased and false negative is increased. With a rule of unanimous determination for NSR, false positive is increased and false negative decreased. Even though accuracies of each classifier are depending on the set of features, with ensemble method, the accuracy of AF detection can be preserved.
C1 [Lee, Keonsoo] Soonchunhyang Univ, Convergence Inst Med Informat Commun Technol & Ma, Asan, South Korea.
   [Kim, Sora] Soonchunhyang Univ, Dept ICT Convergence Rehabil Engn, Asan, South Korea.
   [Choi, Hyung Oh] Soonchunhyang Univ, Coll Med, Dept Cardiol, Bucheon, South Korea.
   [Lee, Jinseok] Wonkwang Univ, Dept Biomed Engn, Sch Med, Iksan, South Korea.
   [Nam, Yunyoung] Soonchunhyang Univ, Dept Comp Sci & Engn, Asan, South Korea.
C3 Soonchunhyang University; Soonchunhyang University; Soonchunhyang
   University; Wonkwang University; Soonchunhyang University
RP Nam, Y (corresponding author), Soonchunhyang Univ, Dept Comp Sci & Engn, Asan, South Korea.
EM ynam@sch.ac.kr
RI Lee, Jinseok/AAV-7182-2021; Lee, Jinseok/ACF-1247-2022; Nam,
   Yunyoung/AAI-4536-2020; Lee, Jinseok/GRR-6086-2022
OI Lee, Jinseok/0000-0002-8580-490X; Lee, Jinseok/0000-0002-8580-490X; Nam,
   Yunyoung/0000-0002-3318-9394; Lee, Jinseok/0000-0002-8580-490X
CR [Anonymous], VISI MOB SYST
   [Anonymous], 2003, KLUWER INT SER ENG C
   [Anonymous], W ME GET KNOW YOUR I
   [Anonymous], ZIO XT
   [Anonymous], FITN TRAIN ACC
   [Anonymous], SMART WEAR ECG EKG M
   [Anonymous], DAT ACQ LOGG AMPL TR
   Barros RC, 2012, IEEE T SYST MAN CY C, V42, P291, DOI 10.1109/TSMCC.2011.2157494
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Couceiro R., 2008, P 19 INT C PATT REC, V19, P1
   De Bacquer D, 1998, HEART, V80, P570, DOI 10.1136/hrt.80.6.570
   Elgendi M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084018
   Hajjar I, 2003, JAMA-J AM MED ASSOC, V290, P199, DOI 10.1001/jama.290.2.199
   Harold JG, 2014, J AM COLL CARDIOL, V63, pE57, DOI [10.1016/j.jacc.2014.02.537, 10.1016/j.jacc.2014.02.536, 10.1016/j.jtcvs.2014.05.014]
   Ho KKL, 1997, CIRCULATION, V96, P842
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Larose Daniel T., 2014, Discovering Knowledge in Data: An Introduction to Data Mining, P149, DOI [10.1002/9781118874059.ch7, DOI 10.1002/9781118874059.CH7, 10.1002/9781118874059.CH7, DOI 10.1002/0471687545.CH5]
   Lin CT, 2010, IEEE T INF TECHNOL B, V14, P726, DOI 10.1109/TITB.2010.2047401
   Lobodzinski SS, 2012, CARDIOL J, V19, P210, DOI 10.5603/CJ.2012.0039
   Logan B, 2005, COMPUT CARDIOL, V32, P619
   Mohebbi M, 2008, IEEE ENG MED BIO, P177, DOI 10.1109/IEMBS.2008.4649119
   Munger TM, 2014, J BIOMED RES, V28, P1, DOI 10.7555/JBR.28.20130191
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   SELVESTER RH, 1982, MYOCARDIAL INFARCTIO, P23
   STEIN PK, 1994, AM HEART J, V127, P1376, DOI 10.1016/0002-8703(94)90059-0
   Tsang TSM, 2003, J AM COLL CARDIOL, V42, P93, DOI 10.1016/S0735-1097(03)00500-X
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   WOLF PA, 1991, STROKE, V22, P983, DOI 10.1161/01.STR.22.8.983
   Zephyr Performance Systems, ZEPH PERF SYST
NR 29
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15985
EP 15999
DI 10.1007/s11042-018-7075-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600011
DA 2024-07-18
ER

PT J
AU Naz, F
   Khan, A
   Ahmed, M
   Khan, MI
   Din, S
   Ahmad, A
   Jeon, G
AF Naz, Farah
   Khan, Abid
   Ahmed, Mansoor
   Khan, Majid Iqbal
   Din, Sadia
   Ahmad, Awais
   Jeon, Gwanggil
TI Watermarking as a service (WaaS) with anonymity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Buyer seller watermarking protocol; Zero-watermarking; Content
   integrity; Tamper detection; Database watermarking
ID SELLER; PROTECTION; EFFICIENT; PROTOCOL
AB With rapid increase in Internet usage, it has become quite easy to produce illegal digital contents. As a result, copyright protection and authentication problems have risen. Besides audio, video and image, protection of database integrity is now a very active research in digital watermarking. Watermarking for databases has been introduced, however, most of the existing schemes produce distortion in the original content during watermark insertion phase. As a result of distortion to underlying data, the quality of watermarked content reduces. Moreover, most of the existing schemes provide watermarking techniques to protect specific data types, such as categorical or numeric. Furthermore, anonymity is also a critical challenge in prior watermarking techniques. In the said perspective, we propose watermarking as a service with anonymity for database integrity using zero watermarking schemes. Our proposed technique does not add any extra information, and neither any physical change is made to the database content. We also performed the security and performance analysis of our proposed scheme. For security analysis, we have evaluated against tuple insertion, tuple deletion, and attribute value tempering attacks. We can extract watermark with high probability, which shows resilience against the said attacks. Experiments are conducted to yield the satisfactory performance.
C1 [Naz, Farah; Khan, Abid; Ahmed, Mansoor; Khan, Majid Iqbal] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Din, Sadia] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Ahmad, Awais] Bahria Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
C3 COMSATS University Islamabad (CUI); Kyungpook National University;
   Incheon National University
RP Khan, A (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
EM farah1489@gmail.com; abidkhan@comsats.edu.pk; mansoor@comsats.edu.pk;
   majid_iqbal@comsats.edu.pk; saadia.deen@gmail.com;
   aahmad.marwat@gmail.com; gjeon@inu.ac.kr
RI Ahmed, Mansoor/IVU-8924-2023
OI Ahmed, Mansoor/0000-0003-2034-1403; Khan, Abid/0000-0003-2712-1956; Din,
   Sadia/0000-0003-0921-4462
CR Agrawal R., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P155
   Agrawal R, 2003, VLDB J, V12, P157, DOI [10.1007/s000778-003-0097-x, 10.1007/s00778-003-0097-x]
   Aihab K, 2013, FRAGILE ZERO WATERMA, P16
   [Anonymous], 1883, Journal des sciences militaires
   Ashwani K, 2011, INT J COMPUT APPL, V21, P0975
   Chang CC, 2010, COMPUT SECUR, V29, P269, DOI 10.1016/j.cose.2009.08.008
   Choi JG, 2003, LECT NOTES COMPUT SC, V2846, P265
   Chun-I Fan, 2010, 2010 International Computer Symposium (ICS 2010), P294, DOI 10.1109/COMPSYM.2010.5685498
   Cox I., 2001, Digital Watermarking
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1998, IEEE J SEL AREA COMM, V16, P587, DOI 10.1109/49.668980
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Eslami Z, 2013, MULTIMEDIA TOOLS APP
   Guo J, 2006, LECT NOTES COMPUT SC, V4176, P359
   Hang D, 2010, JDCTA, V4, P89, DOI [10.4156/jdcta.vol4.issue2.10, DOI 10.4156/JDCTA.VOL4.ISSUE2.10]
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Jing LJ, 2005, INT C COMMUN CIRCUIT, P5
   Jonathan KS, 2002, IEEE T MULTIMEDIA, V4
   Kamel I, 2009, COMPUT SECUR, V28, P698, DOI 10.1016/j.cose.2009.04.001
   Katariya S. S., 2012, INT J ENG INNOVATIVE, V1, P143
   Khan A, 2016, J NETW COMPUT APPL, V75, P317, DOI 10.1016/j.jnca.2016.08.026
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Li Y, 2003, P 13 WORKSH INF TECH, P195
   Li YJ, 2008, J DATABASE MANAGE, V19, P1, DOI 10.4018/jdm.2008070101
   Li YJ, 2005, IEEE T DEPEND SECURE, V2, P34, DOI 10.1109/TDSC.2005.12
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Meng S, 2010, AISS, V2, P18, DOI [10.4156/aiss.vol2.issue3.3, DOI 10.4156/AISS.VOL2.ISSUE3.3]
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Raju H, 2010, J UNIVERSAL COMPUTER, V16
   Rial A, 2011, INFORM FORENSICS SEC, V6
   Robert L., 2009, International Journal of Recent Trends in Engineering, V1, P223
   Song CL, 2018, MULTIMED TOOLS APPL, V77, P225, DOI 10.1007/s11042-016-4247-8
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Yu Z, 2011, SOFTWARE PRACTICE EX
   Zhang LY, 2020, IEEE T DEPEND SECURE, V17, P1218, DOI 10.1109/TDSC.2018.2864748
NR 35
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16051
EP 16075
DI 10.1007/s11042-018-7074-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600014
DA 2024-07-18
ER

PT J
AU Xiao, F
   Liu, BT
   Li, RN
AF Xiao, Feng
   Liu, Baotong
   Li, Runa
TI Pedestrian object detection with fusion of visual attention mechanism
   and semantic computation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention mechanism; Semantic computation; Pedestrian detection;
   Skin; Head-shoulders
AB In response to the problem that the primary visual features are difficult to effectively address pedestrian detection in complex scenes, we present a method to improve pedestrian detection using a visual attention mechanism with semantic computation. After determining a saliency map with a visual attention mechanism, we can calculate saliency maps for human skin and the human head-shoulders. Using a Laplacian pyramid, the static visual attention model is established to obtain a total saliency map and then complete pedestrian detection. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on the INRIA dataset with 92.78% pedestrian detection accuracy at a very competitive time cost.
C1 [Xiao, Feng; Liu, Baotong; Li, Runa] Xian Technol Univ, Sch Comp Sci & Engn, Xian, Peoples R China.
C3 Xi'an Technological University
RP Xiao, F (corresponding author), Xian Technol Univ, Sch Comp Sci & Engn, Xian, Peoples R China.
EM xffriends@163.com; 615937993@qq.com; 136520729@qq.com
OI XIAO, Feng/0000-0002-2895-1727
CR Bruce N., 2006, P ADV NEUR INF PROC, P155
   Cai SX, 2017, C IND ELECT APPL, P636, DOI 10.1109/ICIEA.2017.8282920
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gajjar V., 2018, P IEEE C COMP VIS PA, P1908
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hoai M, 2014, PROC CVPR IEEE, P875, DOI 10.1109/CVPR.2014.117
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L., 2000, MODELS BOTTOM UP TOP
   Jing ZL, 2007, IMAGE FUSION THEORIE
   Ketenci Seniha, 2013, IEEE EUROCON 2013, P1653, DOI 10.1109/EUROCON.2013.6625198
   Leibe B, 2005, PROC CVPR IEEE, P878
   Liu QH, 2014, PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL SYMPOSIUM - MANAGEMENT SCIENCE & ENGINEERING (2014), P59
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu Huimin, 2019, IEEE WIRELESS COMMUN
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Maji S, 2008, PROC CVPR IEEE, P2245
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Shashua A, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P1
   [王国华 Wang Guohua], 2015, [电子学报, Acta Electronica Sinica], V43, P1444
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wu ZD, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P606, DOI 10.1109/ICAwST.2013.6765511
   Xu Yuan, 2016, Computer Engineering, V42, P56, DOI 10.3969/j.issn.1000-3428.2016.01.011
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang S, 2014, CVPR
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
   Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325
   [黎宁 Li Ning], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P723
   Zitnick CL, 2016, IEEE T PATTERN ANAL, V38, P627, DOI 10.1109/TPAMI.2014.2366143
   Zuo HQ, 2017, IEEE SIGNAL PROC LET, V24, P289, DOI 10.1109/LSP.2017.2654803
NR 38
TC 9
Z9 10
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14593
EP 14607
DI 10.1007/s11042-018-7143-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900016
DA 2024-07-18
ER

PT J
AU Choudhury, A
AF Choudhury, Anustup
TI Robust HDR image quality assessment using combination of quality metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range; Image quality assessment; Machine learning;
   Combination of quality metrics
ID STRUCTURAL SIMILARITY; EFFICIENT; INFORMATION; VISIBILITY; DEVIATION;
   MODEL; INDEX
AB We propose a framework to combine various quality metrics using a full reference approach for High Dynamic Range (HDR) Image quality assessment (IQA). We combine scores from metrics exclusively designed for different applications such as HDR, Standard Dynamic Range (SDR) and color difference measures, in a non-linear manner using machine learning (ML) approaches with weights determined during an offline training process. We explore various ML techniques and find that support vector machine regression and gradient boosting regression trees are effective. To improve performance and reduce complexity, we use the back-tracking based Sequential Floating Forward Selection technique during training to include a subset of metrics from a list of quality metrics in our model. We evaluate the performance on five publicly available calibrated HDR databases with different types of distortion (including different types of compression, Gaussian noise, gamut mismatch, chromatic distortions and so on) and demonstrate improved performance using our method as compared to several existing IQA metrics. We perform extensive statistical analysis to demonstrate significant improvement over existing approaches and show the generality and robustness of our approach using cross-database validation.
C1 [Choudhury, Anustup] Dolby Labs Inc, Sunnyvale, CA 94085 USA.
C3 Dolby Laboratories, Inc.
RP Choudhury, A (corresponding author), Dolby Labs Inc, Sunnyvale, CA 94085 USA.
EM AnustupKumar.Choudhury@dolby.com
OI Choudhury, Anustup/0000-0001-6618-9211
CR [Anonymous], INT C MULT SIGN PROC
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 2012, 2012 ANN TECHN C EXH, DOI DOI 10.5594/M001446
   [Anonymous], 2012, METH METR PROC STAT
   [Anonymous], 2017, Quality and User Experience, DOI DOI 10.1007/S41233-017-0007-4
   Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   Aydin TO, 2008, PROC SPIE, V6806, DOI 10.1117/12.765095
   Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   *BT, 2016, 2100 IM PAR VAL HIGH
   CHOUDHURY A, 2019, ELECT IMAGING, V2019
   CHOUDHURY A, 2019, SMPTE 2019 ANN TECHN
   Choudhury A, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P179, DOI 10.1109/MIPR.2019.00039
   Choudhury A, 2018, IEEE GLOB CONF SIG, P91, DOI 10.1109/GlobalSIP.2018.8646579
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Duda R., 1973, Pattern Classification and Scene Analysis
   Freitas PG, 2018, IEEE T MULTIMEDIA, V20, P3353, DOI 10.1109/TMM.2018.2839529
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2013, SIGNAL IMAGE VIDEO P, V7, P423, DOI 10.1007/s11760-013-0445-2
   Guan FF, 2018, APPL OPTICS, V57, P839, DOI 10.1364/AO.57.000839
   Hanhart P, 2016, QOMEX, P1
   Hanhart P, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0091-4
   *ITU R BT, 2019, 2124 0 OBJ METR ASS
   Jia S, 2017, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2017.8296384
   Korshunov P, 2015, INT WORK QUAL MULTIM
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   LI Z, 2016, VMAF VIDEO QUALITY M
   Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338
   Lin JY, 2014, ASIAPAC SIGN INFO PR
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   Mai ZC, 2011, IEEE T IMAGE PROCESS, V20, P1558, DOI 10.1109/TIP.2010.2095866
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Nafchi HZ, 2018, IEEE T BROADCAST, V64, P518, DOI 10.1109/TBC.2018.2818402
   Nafchi HZ, 2016, IEEE ACCESS, V4, P5579, DOI 10.1109/ACCESS.2016.2604042
   Nafchi HZ, 2015, IEEE SIGNAL PROC LET, V22, P1026, DOI 10.1109/LSP.2014.2381458
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Narwaria M, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.10.102008
   PIERI E, 2017, SMPTE 2017 ANN TECHN, P1
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rousselot M, 2019, J IMAGING, V5, DOI 10.3390/jimaging5010018
   Rousselot M, 2018, EUR SIGNAL PR CONF, P1442, DOI 10.23919/EUSIPCO.2018.8553212
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Valenzise G., 2014, SPIE OPTICAL ENG APP
   Ververidis Dimitrios, 2005, 2005 13th European Signal Processing Conference, P1
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yeh CH, 2018, MULTIMED TOOLS APPL, V77, P20001, DOI 10.1007/s11042-017-5430-2
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 72
TC 4
Z9 4
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22843
EP 22867
DI 10.1007/s11042-020-08985-5
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000536433700002
DA 2024-07-18
ER

PT J
AU Bernacki, J
AF Bernacki, Jaroslaw
TI Automatic exposure algorithms for digital photography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Photography; Automatic exposure; Exponential
   smoothing; Time series analysis
ID TIME IMAGE FUSION
AB In this paper we deal with the problem of calculating Automatic Exposure (AE) in digital cameras. The main problem that often occurs when taking pictures is correct exposure setting. Typically, smartphones with built-in cameras, as well as "cheap" compact digital cameras do not offer possibility of manual exposure setting. The reason is that users do not have knowledge how to set the optimal exposure, or just simply do not want to do this. Therefore, it forces that user has to rely on automatic exposure algorithms implemented in the camera. Unfortunately, these algorithms often do not perform well what causes improperly exposed images. In this paper, new algorithms for automatic exposure are proposed with the special focus on minimizing overexposed areas in the images. We have implemented proposed algorithms and conducted experiments for their efficiency, comparing with some modern cameras or smartphones. Experimental verification (enhanced by statistical analysis) shows that proposed algorithms give statistically less overexposed areas than comparative AEs.
C1 [Bernacki, Jaroslaw] Czestochowa Tech Univ, 1, Czestochowa, Poland.
C3 Technical University Czestochowa
RP Bernacki, J (corresponding author), Czestochowa Tech Univ, 1, Czestochowa, Poland.
EM jaroslaw.bernacki@outlook.com
OI Bernacki, Jaroslaw/0000-0002-4488-3488
CR Brierley J, 2005, DIGITAL BIRD PHOTOGR
   Carní DL, 2005, INT WORKSH INT DATA, P570, DOI 10.1109/IDAACS.2005.283048
   Davis H, 2006, DIGITAL PHOTOGRAPHY
   Douglas A, 2005, PROGRAMMED AUTOMATIC, P1
   Eastman Kodak Company, 1992, EASTM KOD CO KOD PUB, VR-28
   Farrell I, 2014, KOMPENDIUM
   Freeman M, 2008, COMPLETE GUIDE NIGHT
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Jones LA, 1986, PH271986 ANSI
   Kacperczyk L, HISTOGRAM GWARANCJA
   Kao WC, 2007, ELECTRON LETT, V43, P975, DOI 10.1049/el:20070835
   Kao WC, 2006, IEEE INT SYMP CIRC S, P935
   Kelby S, 2010, DIGITAL PHOTOGRAPHY, V3
   Kiran BR, 2014, ADV INTELL SYST, V247, P509, DOI 10.1007/978-3-319-02931-3_58
   Kiran Ravi B, 2013, INT J COMPUT APPL, V83, p0975 8887
   Kremens R, 1999, SYSTEM IMPLICATIONS
   Liang JY, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P725, DOI 10.1109/ICASIC.2007.4415733
   O'Malley R, 2011, IET INTELL TRANSP SY, V5, P1, DOI 10.1049/iet-its.2010.0032
   O'Malley R, 2010, IEEE T INTELL TRANSP, V11, P453, DOI 10.1109/TITS.2010.2045375
   Ray S., 2002, Applied Photographic Optics
   Ray SF., 2000, The Manual of Photography: Photographic and Digital Imaging
   Sorel M, 2009, IEEE IMAGE PROC, P157, DOI 10.1109/ICIP.2009.5414145
   Thomas Dennis J, 2012, NIKON D800 D800E DIG
   Vuong Q.K, 2008, P WORLD C ENG COMP S
   Young B, DETERMINING EXPOSURE
NR 25
TC 7
Z9 10
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12751
EP 12776
DI 10.1007/s11042-019-08318-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Han, MY
   Wang, RG
   Yang, J
   Xue, LX
   Hu, M
AF Han, Mengya
   Wang, Ronggui
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Multi-scale feature network for few-shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Multi-scale feature; Label feature; No-metric method
AB Few-shot learning aims to learn a classifier that has good generalization performance in new classes, where each class only a small number of labeled examples are available. The existing few-shot classification methods use the single-scale image do not learn effective feature representation. Moreover, most of previous methods still depend on standard metrics to calculate visual similarities, such as Euclidean or cosine distance. Standard metrics are independent of data and lack nonlinear internal structure that captures the similarity between data. In this paper, we propose a new method for few-shot learning problem, which learns a multi-scale feature space, and classification is performed by computing similarities between the multi-scale representation of the image and the label feature of each class (i.e. class representation). Our method, called the Multi-Scale Feature Network (MSFN), is trained end-to-end from scratch. The proposed method improves 1-shot accuracy from 50.44% to 54.48% and 5-shot accuracy from 68.2% to 69.06% on MiniImagenet dataset compared to competing approaches. Experimental results on Omniglot, MiniImagenet, Cifar100, CUB200, and Caltech256 datasets demonstrate the effectiveness of the proposed method.
C1 [Han, Mengya; Wang, Ronggui; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM hanmengya@mail.hfut.edu.cn; wangrgui@foxmail.com; yangjuan6985@163.com;
   xlxzzm@163.com; jsjxhumin@hfut.edu.cn
RI Han, Mengya/JCD-9489-2023; Lin, Kuan-Yu/JXM-6653-2024
CR [Anonymous], 2018, SEMANTIC FEATURE AUG
   [Anonymous], 1996, LEARNING LEARN INTRO
   Boney Rinu, 2017, ARXIV171110856
   Dixit M, 2017, PROC CVPR IEEE, P3328, DOI 10.1109/CVPR.2017.355
   Edwards H, 2017, ARXIV160602185
   Finn C, 2017, PR MACH LEARN RES, V70
   Garcia Victor., 2017, 6 INT C LEARN REPR
   Ge WF, 2017, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2017.9
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hilliard N, 2017, ARXIV170806819
   Hilliard N, 2018, ARXIV18020476
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kaiser Lukasz, 2017, ICLR
   Kingma D. P., 2014, arXiv
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Mehrotra A., 2017, ARXIV170308033
   Mishra N., 2018, INT C LEARN REPR
   Munkhdalai Tsendsuren, 2017, Proc Mach Learn Res, V70, P2554
   Ravi S., 2016, INT C LEARNING REPRE
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santoro A, 2016, PR MACH LEARN RES, V48
   Snell J., 2017, ADV NEURAL INFORM PR, V30, P4077
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang P, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/5307219
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Ye Meng, 2018, CoRR
   Zhou F., 2018, Technical report
NR 35
TC 11
Z9 11
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11617
EP 11637
DI 10.1007/s11042-019-08413-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400016
DA 2024-07-18
ER

PT J
AU Jing, PG
   Guan, WL
   Bai, X
   Guo, HB
   Su, YT
AF Jing, Peiguang
   Guan, Weili
   Bai, Xu
   Guo, Hongbin
   Su, Yuting
TI Single image super-resolution via low-rank tensor representation and
   hierarchical dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Low-rank representation; Tensor decomposition;
   Dictionary learning
ID RESOLUTION; ALGORITHM
AB Super-resolution (SR) has been widely studied due to its importance in real applications and scenarios. In this paper, we focus on generating an SR image from a single low-resolution (LR) input image by employing the multi-resolution structures of an input image. By taking the LR image and its downsampled resolution (DR) and upsampled resolution (UR) versions as inputs, we propose a hierarchical dictionary learning approach to learn the latent UR-LR dictionary pair by preserving the internal structure coherence with the LR-DR dictionary pair. Note that an imposed restriction involved in this process is that the pairwise resolution images are jointly trained to obtain more compact patterns of image patches. In particular, to better explore the underlying structures of tensor data spanned by image patches, we propose a low-rank tensor approximation (LRTA) algorithm based on nuclear-norm regularization to embed input image patches into a low-dimensional space. Experimental results from publicly used images show that our proposed method achieves performance comparable with that of other state-of-the-art SR algorithms, even without using any external training databases.
C1 [Jing, Peiguang; Bai, Xu; Guo, Hongbin; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Guan, Weili] Hewlett Packard Enterprise Singapore, Singapore, Singapore.
C3 Tianjin University
RP Guo, HB (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM pgjing@tju.edu.cn; honeyguan@gmail.com; xubaitju@gmail.com;
   ghb3011204117@163.com; ytsu@tju.edu.cn
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2016, P IEEE C COMP VIS PA
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen XX, 2014, IEEE SIGNAL PROC LET, V21, P79, DOI 10.1109/LSP.2013.2286417
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2015, IEEE I CONF COMP VIS, P442, DOI 10.1109/ICCV.2015.58
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   GRASEDYCK L., 2013, GAMM-Mitteilungen36, V36, P53, DOI 10.1002/gamm.201310004
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jia CC, 2014, AAAI CONF ARTIF INTE, P1228
   Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P970, DOI 10.1145/3123266.3123341
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Marcia RE, 2008, INT CONF ACOUST SPEE, P833, DOI 10.1109/ICASSP.2008.4517739
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Qi N, 2016, PROC CVPR IEEE, P5916, DOI 10.1109/CVPR.2016.637
   Shi F, 2015, IEEE T MED IMAGING, V34, P2459, DOI 10.1109/TMI.2015.2437894
   Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364
   Sun JA, 2010, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2010.5540206
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Veganzones MA, 2016, IEEE T IMAGE PROCESS, V25, P274, DOI 10.1109/TIP.2015.2496263
   Wang H, 2014, AAAI CONF ARTIF INTE, P2846
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang JH, 2008, CRYST RES TECHNOL, V43, P999, DOI 10.1002/crat.200800010
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhang XY, 2018, PROC CVPR IEEE, P8232, DOI 10.1109/CVPR.2018.00859
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 50
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11767
EP 11785
DI 10.1007/s11042-019-08259-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400023
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Liu, G
   Zhang, L
   Pu, JX
AF Liu, Zhonghua
   Liu, Gang
   Zhang, Lin
   Pu, Jiexin
TI Linear regression classification steered discriminative projection for
   dimension reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discriminative projection; Linear regression classification (LRC);
   Dimension reduction; Image classification
ID FACE-RECOGNITION
AB Because of the simplicity and effectiveness of linear regression classification (LRC), LRC is widely applied into image classification. However, it processes the original high-dimensional data directly. It is well known that the original data usually contains a lot of redundant information or noise, which will reduce the performance of LRC algorithm and increase its running cost. At the same time, it usually suffers from out of sample problem. In order to overcome the weaknesses of LRC, a novel dimension reduction algorithm termed linear regression classification steered discriminative projection (LRC-DP) is presented by combining LRC with discriminative projection. LRC-DP not only fits LRC well, but also seeks a linear projection, in which the ratio of between-class reconstruction errors to within-class reconstruction errors is maximized in the transformation space. The proposed LRC-DP can learn a robust low-dimensional projection subspace from the original sample images in high-dimension space. In order to validate the performance of LRC-DP algorithm, extensive experiments are conducted on several public image databases. Experimental results reveal that the LRC-DP algorithm is feasible and effective.
C1 [Liu, Zhonghua; Liu, Gang; Zhang, Lin; Pu, Jiexin] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang, Peoples R China.
C3 Henan University of Science & Technology
RP Liu, ZH (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang, Peoples R China.
EM lzhua_217@163.com
CR [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 24 U AUT BARC
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Chen SB, 2018, INFORM SCIENCES, V467, P74, DOI 10.1016/j.ins.2018.07.066
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   Gao GW, 2015, APPL SOFT COMPUT, V37, P48, DOI 10.1016/j.asoc.2015.07.034
   Gao QX, 2015, IEEE T IMAGE PROCESS, V24, P5684, DOI 10.1109/TIP.2015.2479559
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hua JL, 2016, NEUROCOMPUTING, V193, P1, DOI 10.1016/j.neucom.2016.01.060
   Huang KK, 2017, PATTERN RECOGN, V62, P87, DOI 10.1016/j.patcog.2016.08.024
   Huang P, 2017, IEEE ACCESS, V5, P4340, DOI 10.1109/ACCESS.2017.2680437
   Jeevaratnam K, 2010, ACTA PHYSIOL, V200, P23, DOI 10.1111/j.1748-1716.2010.02110.x
   Li P, 2017, IEEE T CYBERNETICS, V47, P4250, DOI 10.1109/TCYB.2016.2623638
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2016, IEEE T SIGNAL PROCES, V64, P5623, DOI 10.1109/TSP.2016.2586753
   Liu ZH, 2018, INT J SYST SCI, V49, P847, DOI 10.1080/00207721.2018.1424964
   Liu ZH, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107456
   Liu ZH, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105768
   Lu YW, 2016, IEEE T CYBERNETICS, V46, P1900, DOI 10.1109/TCYB.2015.2457611
   Ma ZM, 2018, IEEE ACCESS, V6, P55537, DOI 10.1109/ACCESS.2018.2871825
   Mo DM, 2019, PATTERN RECOGN, V93, P164, DOI 10.1016/j.patcog.2019.04.011
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Pang YW, 2019, IEEE T NEUR NET LEAR, V30, P2779, DOI 10.1109/TNNLS.2018.2886317
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Wang LF, 2015, IEEE T CIRC SYST VID, V25, P651, DOI 10.1109/TCSVT.2014.2335851
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie LF, 2018, IEEE T IMAGE PROCESS, V27, P5261, DOI 10.1109/TIP.2018.2855426
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022
   Zhang LX, 2011, J NANOMATER, V2011, DOI 10.1155/2011/467170
   Zhang N, 2013, NEUROCOMPUTING, V111, P13, DOI 10.1016/j.neucom.2012.12.012
   Zhang Z, 2014, NEURAL NETWORKS, V53, P81, DOI 10.1016/j.neunet.2014.01.001
NR 38
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11993
EP 12005
DI 10.1007/s11042-019-08434-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400033
DA 2024-07-18
ER

PT J
AU Song, HT
   Tang, GM
   Sun, YF
   Yang, SX
AF Song, Haitao
   Tang, Guangming
   Sun, Yifeng
   Yang, Shunxiang
TI Anisotropic distortion cost update strategy in spatial image
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive steganography; Distortion cost; Non-additive distortion
   function; Anisotropy; Image gradient
AB In current adaptive steganography study, the distortion function is used to describe pixel modification distortion cost. Distortion cost can describe the influence of pixel modification to the cover. And it plays an important actor in adaptive stegaography. Based on previous researches, in this paper, an Anisotropic Distortion cost Update strategy (ADU strategy) is proposed to adaptively update the initial distortion cost (obtained by HILL .etc) to describe the interaction between multiple embedding modifications more accurately. Based on steanographic security theorty, it is proved that clustering modification strategy can improve steganographic security through theoretical derivation. And through study on steganalysis features, it is analyzed and proved that the determination of optimal modification method of the central pixel is anisotropic and much more complicated. Following these two proofs, the image gradient and thermal conductivity are used to quantify the anisotropy of 4 neighboring pixels. Then the optimal modification method of the central pixel is calculated. Finally, the distortion cost of the central pixel can be updated based on the optimal modification method. Experiments with the optimal embedding simulator show that the ADU strategy has better performance when the scaling factor is 2; the proposed ADU strategy can effectively improve the steganography schemes, especially for steganalytic performance with maxSRMd2 features.
C1 [Song, Haitao; Tang, Guangming; Sun, Yifeng; Yang, Shunxiang] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University
RP Song, HT (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
EM kernelsong@yeah.net; 893018060@qq.com; yfsun001@163.com;
   yangshunxiang1994@163.com
RI song, haitao/KHV-3582-2024; Li, Binxu/KDO-3273-2024; TANG,
   Guang-Ming/E-5315-2013
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   Bachrach M, 2011, WIRES COMPUT STAT, V3, P251, DOI 10.1002/wics.152
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2018, IEEE T INF FOREN SEC, V13, P823, DOI 10.1109/TIFS.2017.2766580
   Cachin C, 2004, INFORM COMPUT, V192, P41, DOI 10.1016/j.ic.2004.02.003
   Denemark T, 2014, P SPIE EL IM MED WAT, V9028, p[902, 805, 805]
   Denemark T., 2014, IEEE WORKSH INF FOR
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guang Xu, 2017, International Journal of Mining, Reclamation and Environment, V31, P251, DOI 10.1080/17480930.2016.1138570
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu Y, 2016, PLANT PHYSIOL BIOCH, V99, P1, DOI 10.1016/j.plaphy.2015.11.020
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sedighi V, 2015, IS T SPIE ELECT IMAG, p94090H
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Song HT, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3546367
   Tang GM, 2017, J ELECTRON INF TECHN, V39, P58, DOI 10.11999/JEIT160254
   Zang Y, 2015, IEEE T VIS COMPUT GR, V21, P1015, DOI 10.1109/TVCG.2015.2410296
   Zhou WB, 2017, IEEE T INF FOREN SEC, V12, P2654, DOI 10.1109/TIFS.2017.2718480
NR 26
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11973
EP 11992
DI 10.1007/s11042-020-08615-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400032
DA 2024-07-18
ER

PT J
AU Kandhasamy, JP
   Balamurali, S
   Kadry, S
   Ramasamy, LK
AF Kandhasamy, J. Pradeep
   Balamurali, S.
   Kadry, Seifedine
   Ramasamy, Lakshmana Kumar
TI Diagnosis of diabetic retinopathy using multi level set segmentation
   algorithm with feature extraction using SVM with selective features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Fundus images; Multi-level set segmentation;
   Genetic algorithm; Local binary patterns; Support vector machine
ID COMPUTER-AIDED DIAGNOSIS; IDENTIFICATION; IMAGES; INDEX
AB Diabetic retinopathy is a major cause of blindness in diabetic patients. It is an eye disease caused by diabetes mellitus which affects the retina. Recognition of the severity of this disease at early stage is a challenging factor for the ophthalmologists. In this article, a novel diagnosis system for identifying the severity of diabetic retinopathy is proposed using a multi level set segmentation algorithm and support vector machine with selective features along with genetic algorithm. The proposed system uses some mathematical morphological operations for clustering. After that the clusters are passed to the multi level set segmentation algorithm and some features are extracted using Local Binary Patterns as a texture descriptor for retinal images, color moments and statistical features such as mean, median etc. to detect the major regions of retina. Then the extracted features are given to the support vector machine classifier to classify the disease severity. This system was evaluated and compared using measures of sensitivity and specificity. We obtain sensitivity of 97.14%, specificity of 100% and accuracy of 99.3% on an average. From the seen results, it is observed that our proposed system is suited for the diagnosis of diabetic retinopathy at the early stage.
C1 [Kandhasamy, J. Pradeep; Balamurali, S.] Kalasalingam Acad Res & Educ, Sch Comp, Dept Comp Applicat, Krishnankoil, India.
   [Kadry, Seifedine] Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
   [Ramasamy, Lakshmana Kumar] Hindusthan Coll Engn & Technol, Dept Comp Applicat, Coimbatore, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education; Beirut Arab University
RP Kadry, S (corresponding author), Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut, Lebanon.
EM s.kadry@bau.edu.lb
RI Balamurali, Saminathan/AAP-4017-2020; Kadry, Seifedine/C-7437-2011;
   Ramasamy, Lakshmana Kumar/G-2346-2011; Kandhasamy, Pradeep/AAP-4079-2020
OI Balamurali, Saminathan/0000-0002-3010-245X; Kadry,
   Seifedine/0000-0002-1939-4842; RAMASAMY, LAKSHMANA
   KUMAR/0000-0002-0643-6599
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Acharya UR, 2016, COMPUT BIOL MED, V73, P131, DOI 10.1016/j.compbiomed.2016.04.009
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2013, UN EYE HLTH GLOB ACT
   Aravind C, 2013, INT J COMPUTER APPL, VAppl11, P18
   Bhaskaranand Malavika, 2016, J Diabetes Sci Technol, V10, P254, DOI 10.1177/1932296816628546
   Bhattacharjee R., 2012, 2012 NATL C COMPUT C, P266, DOI [10.1109/NCCCS.2012.6413019, DOI 10.1109/NCCCS.2012.6413019]
   Engelgau MM, 2004, ANN INTERN MED, V140, P945, DOI 10.7326/0003-4819-140-11-200406010-00035
   Fadzil MHA, 2011, MED BIOL ENG COMPUT, V49, P693, DOI 10.1007/s11517-011-0734-2
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Kandhasamy JP, 2015, PROCEDIA COMPUT SCI, V47, P45, DOI 10.1016/j.procs.2015.03.182
   Krishnan MMR, 2013, J MED IMAG HEALTH IN, V3, P306, DOI 10.1166/jmihi.2013.1165
   Li BX, 2013, CURR DIABETES REP, V13, P453, DOI 10.1007/s11892-013-0393-9
   Mishra PK, 2014, BIOINFORMATION, V10, P556, DOI 10.6026/97320630010556
   Mookiah MRK, 2013, J MED IMAG HEALTH IN, V3, P598, DOI 10.1166/jmihi.2013.1210
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Paranjpe M.J., 2013, INT J RES SCI ADV TE, V3, P86
   Prakash N. B., 2014, INT J ELECT ENG INFO, V6, P717
   Priya R., 2013, ICTACT J. Soft Comput., V3, P563, DOI [10.21917/ijsc.2013.0083, DOI 10.21917/IJSC.2013.0083]
   Sturman MC, 2011, CORNELL SCHOOL OF HOTEL ADMINISTRATION ON HOSPITALITY: CUTTING EDGE THINKING AND PRACTICE, P1
   Washington RE, 2014, DIABETES RES CLIN PR, V103, P504, DOI 10.1016/j.diabres.2013.12.014
   World Health Organization, 2010, ACT PLAN PREV AV BLI
   Yun WL, 2008, INFORM SCIENCES, V178, P106, DOI 10.1016/j.ins.2007.07.020
NR 25
TC 29
Z9 29
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10581
EP 10596
DI 10.1007/s11042-019-7485-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600046
DA 2024-07-18
ER

PT J
AU Khan, N
   Ahmed, I
   Kiran, M
   Rehman, H
   Din, S
   Paul, A
   Reddy, AG
AF Khan, Nazish
   Ahmed, Imran
   Kiran, Mahreen
   Rehman, Hamoodur
   Din, Sadia
   Paul, Anand
   Reddy, Alavalapati Goutham
TI Automatic segmentation of liver & lesion detection using H-minima
   transform and connecting component labeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liver; Lesion; Segmentation; Detection; H-minima transform; CCL;
   Automatic; Opening by reconstruction
ID CT; TOMOGRAPHY
AB Automatic segmentation of the liver and the Lesion detection can be a very challenging task due to its variability in size, shape, position and the presence of other organs with similar intensities. Manual segmentation and detection of a tumor is a time-consuming task and greatly depends upon the expertise and experience of the physician. We proposed a method which consists of automatic segmentation and detection of liver and lesion using CT scan modality. H-minima transform filter, Otsu global thresholds, Morphological opening by reconstruction and modified Connected Component Labeling algorithms are applied for liver segmentation. To keep the technique simple and effective, an appropriate range of threshold values are defined to detect different types of lesions. Performance of the proposed system is evaluated and compared with the state-of-the art algorithms. The results of the comparison show that the proposed approach is robust and efficient due to its simplicity. The dice coefficient score for the hepatic segmentation is 94% while sensitivity and specificity for hepatic lesion are 93% and 87% respectively.
C1 [Khan, Nazish; Ahmed, Imran; Kiran, Mahreen; Rehman, Hamoodur] Ctr Excellence Informat Technol, Inst Management Sci, Peshawar, Pakistan.
   [Din, Sadia; Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Korea, South Korea.
   [Reddy, Alavalapati Goutham] Natl Inst Technol, Dept Comp Sci & Engn, Tadepalligudem, Andhra Pradesh, India.
C3 Kyungpook National University; National Institute of Technology (NIT
   System); National Institute of Technology Andhra Pradesh
RP Reddy, AG (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tadepalligudem, Andhra Pradesh, India.
EM diyanoor82@yahoo.com; imran.ahmed@imsciences.edu.pk;
   mehreen.kiran89@gmail.com; hamoodurrehman@imsciences.edu.pk;
   saadia.deen@gmail.com; paul.editor@gmail.com; goutham.ace@gmail.com
RI Ahmed, Imran/HDL-7255-2022; Alavalapati, Goutham Reddy/AGN-0905-2022;
   Paul, Anand/V-6724-2017; Kiran, Mahreen/HGC-9076-2022
OI Alavalapati, Goutham Reddy/0000-0002-4335-8331; Paul,
   Anand/0000-0002-0737-2021; Paul, Anand/0000-0003-3115-2325; Din,
   Sadia/0000-0003-0921-4462
CR [Anonymous], J BIOMED SCI
   [Anonymous], MAJLESI J ELECT ENG
   [Anonymous], FULLY AUTOMATIC TECH
   [Anonymous], 2015, SIGNAL IMAGE PROCESS
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 2018, MULTIMED TOOLS APPL
   Anter AM, 2013, FED CONF COMPUT SCI, P193
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Chen L, 2016, HUM-COMPUT INT-SPRIN, P201, DOI 10.1007/978-3-319-31413-6_11
   Ciecholewski M, 2014, J SIGNAL PROCESS SYS, V74, P151, DOI 10.1007/s11265-013-0755-1
   Ding XW, 2016, PROCEDIA COMPUT SCI, V90, P87, DOI 10.1016/j.procs.2016.07.028
   Goryawala M, 2012, IEEE T INF TECHNOL B, V16, P62, DOI 10.1109/TITB.2011.2171191
   Huang SH, 2006, 2006 3RD IEEE/EMBS INTERNATIONAL SUMMER SCHOOL ON MEDICAL DEVICES AND BIOSENSORS, P145, DOI 10.1109/ISSMDBS.2006.360120
   Jamil U, 2018, SOFT COMPUT, V22, P1577, DOI 10.1007/s00500-017-2947-2
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jiang HY, 2009, INT C COMP AID DES C, P540, DOI 10.1109/CADCG.2009.5246845
   Kumar S. S., 2011, Journal of Advances in Information Technology, V2, P63, DOI 10.4304/jait.2.1.63-70
   Massoptier L, 2007, P ANN INT IEEE EMBS, P5243, DOI 10.1109/IEMBS.2007.4353524
   Massoptier L, 2008, EUR RADIOL, V18, P1658, DOI 10.1007/s00330-008-0924-y
   Militzer A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2524, DOI 10.1109/ICPR.2010.618
   Moghbel M, 2016, EXCLI J, V15, P406, DOI 10.17179/excli2016-402
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Suzuki K, 2010, MED PHYS, V37, P2159, DOI 10.1118/1.3395579
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Zafar B, 2018, COMPUT SCI INF SYST, V15, P615, DOI [10.2298/CSIS180105025z, 10.2298/CSIS180105025Z]
   Zidan A, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P96, DOI 10.1109/HIS.2012.6421316
NR 27
TC 7
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8459
EP 8481
DI 10.1007/s11042-019-7347-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600009
DA 2024-07-18
ER

PT J
AU Mishra, D
   Majhi, B
   Bakshi, S
   Sangaiah, AK
   Sa, PK
AF Mishra, Deepasikha
   Majhi, Banshidhar
   Bakshi, Sambit
   Sangaiah, Arun Kumar
   Sa, Pankaj Kumar
TI Single image super resolution for texture images through neighbor
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; Manifold learning; Pseudo Zernike moment; Feature
   similarity index
ID SUPERRESOLUTION; RECONSTRUCTION; HALLUCINATION; ALGORITHM; LIMITS
AB This article proposes an improved learning based super resolution scheme using manifold learning for texture images. Pseudo Zernike moment (PZM) has been employed to extract features from the texture images. In order to efficiently retrieve similar patches from the training patches, feature similarity index matrix (FSIM) has been used. Subsequently, for reconstruction of the high resolution (HR) patch, a collaborative optimal weight is generated from the least square (LS) and non-negative matrix factorization (NMF) methods. The proposed method is tested on some color texture, gray texture, and some standard images. Results of the proposed method on texture images advocate its superior performance over established state-of-the-art methods.
C1 [Mishra, Deepasikha; Majhi, Banshidhar; Bakshi, Sambit; Sa, Pankaj Kumar] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
   [Sangaiah, Arun Kumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Vellore Institute of Technology (VIT); VIT Vellore
RP Bakshi, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM deepasikhame@gmail.com; bmajhi@nitrkl.ac.in; bakshisambit@nitrkl.ac.in;
   sarunkumar@vit.ac.in; pankajksa@nitrkl.ac.in
RI K, Pankaj/A-9362-2017; Bakshi, Sambit/JDC-3355-2023; Sangaiah, Arun
   Kumar/U-6785-2019
OI Bakshi, Sambit/0000-0002-6107-114X; Sangaiah, Arun
   Kumar/0000-0002-0229-2460
CR [Anonymous], ARXIV161200085
   [Anonymous], ARXIV170404126
   [Anonymous], EUROGRAPHICS 2009
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bégin I, 2004, INT C PATT RECOG, P85, DOI 10.1109/ICPR.2004.1334046
   Bevilacqua M, 2013, 18 INT C DIG SIGN PR, P1
   Cao MM, 2012, INT CONF SIGN PROCES, P825, DOI 10.1109/ICoSP.2012.6491708
   Chan TM, 2009, PATTERN RECOGN LETT, V30, P494, DOI 10.1016/j.patrec.2008.11.008
   Chan TM, 2006, LECT NOTES COMPUT SC, V3832, P756
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen XX, 2014, SIGNAL PROCESS, V94, P6, DOI 10.1016/j.sigpro.2013.06.016
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Dai XY, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2414181
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Fan W, 2007, PROC CVPR IEEE, P244
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   Gao XB, 2011, IEEE T IMAGE PROCESS, V20, P2738, DOI 10.1109/TIP.2011.2134859
   GERCHBERG RW, 1974, OPT ACTA, V21, P709, DOI 10.1080/713818946
   Guo K, 2012, IET IMAGE PROCESS, V6, P337, DOI 10.1049/iet-ipr.2010.0430
   HaCohen Y., 2010, ICCP, P1
   Kanan HR, 2016, SIGNAL PROCESS, V118, P103, DOI 10.1016/j.sigpro.2015.05.015
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu L, 2017, INT J REMOTE SENS, V38, P5673, DOI 10.1080/01431161.2017.1346325
   Mishra D., 2017, P INT C COMP VIS IM, P13, DOI DOI 10.1007/978-981-10-2107-7_2
   Mishra D, 2014, ANNU IEEE IND CONF
   Mishra D, 2016, NEUROCOMPUTING, V202, P49, DOI 10.1016/j.neucom.2016.04.013
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Patanavijit V., 2009, THE J, V12, P149
   Rajan D, 2003, IEEE SIGNAL PROC MAG, V20, P49, DOI 10.1109/MSP.2003.1203209
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Sun J, 2003, PROC CVPR IEEE, P729
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A., 1997, The usc-sipi image database
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   [杨经绥 YANG Jing-sui], 2010, [中国地质, Geology of China], V37, P1
   Yang SY, 2014, IEEE T IMAGE PROCESS, V23, P2793, DOI 10.1109/TIP.2014.2319742
   Yoo SB, 2016, SIGNAL PROCESS-IMAGE, V46, P29, DOI 10.1016/j.image.2016.04.007
   Zachevsky I, 2014, IEEE T IMAGE PROCESS, V23, P2096, DOI 10.1109/TIP.2014.2312284
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 54
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8337
EP 8366
DI 10.1007/s11042-017-5367-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600002
DA 2024-07-18
ER

PT J
AU Sangi, AR
   Alkatheiri, MS
   Anamalamudi, S
   Liu, JW
AF Sangi, Abdur Rashid
   Alkatheiri, Mohammed Saeed
   Anamalamudi, Satish
   Liu, Jianwei
TI Cognitive AODV routing protocol with novel channel-route failure
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive Radio; AODV protocol; Selfish nodes; Throughput
ID SPECTRUM HANDOFF; RADIO NETWORKS; ALLOCATION
AB Performance of routing protocol at network layer in Cognitive Radio Adhoc Networks (CRAHNs) is mainly based on the probability of channel availability for application data transmission. To attain, end-to-end channel-route control messages should be disseminated in an efficient mechanism with minimal channel-route re-connection delays. In CRAHNs, end-to-end channel-route failures can be mainly due to spectrum handoff (dynamic primary user intervention), selfish node activity, CR node handoff and bandwidth degradation. In order to enhance the application throughput, it is pivotal to determine the exact channel-route failure and provide alternate end-to-end channel-route path. To achieve, this paper proposes a "channel-route failure based Cognitive-AODV routing protocol" with the modifications in channel-route-error (channel-RERR) to detect the exact channel-route failure and provide the best alternate end-to-end channel-route path in between source and destination. Experimental results reveal that the performance of proposed Cognitive AODV routing protocol with selfish node activity, spectrum handoff and node handover is outperformed when compared with the existing Cognitive AODV routing protocols.
C1 [Sangi, Abdur Rashid] Huaiyin Inst Technol HYIT, Fac Comp & Software Engn, Huaian City, Peoples R China.
   [Alkatheiri, Mohammed Saeed] Univ Jeddah, Coll Comp Sci & Engn, Dept Cybersecur, Jeddah, Saudi Arabia.
   [Anamalamudi, Satish] SRM Univ AP, Dept Comp Sci Engn, Amaravati, India.
   [Liu, Jianwei] Beihang Univ, Sch Cyber Sci & Technol, Beijing, Peoples R China.
C3 University of Jeddah; SRM University-AP; Beihang University
RP Sangi, AR (corresponding author), Huaiyin Inst Technol HYIT, Fac Comp & Software Engn, Huaian City, Peoples R China.
EM sangi_bahrian@yahoo.com
RI Alkatheiri, Mohammed/AAX-4623-2020
OI Alkatheiri, Mohammed/0000-0001-8172-8375
CR Anamalamudi Satish, 2014, International Journal of Information and Electronics Engineering, V4, P216, DOI 10.7763/IJIEE.2014.V4.437
   Anamalamudi S., 2012, 2012 IEEE/ACIS 11th International Conference on Computer and Information Science (ICIS), P88, DOI 10.1109/ICIS.2012.84
   [Anonymous], 2017, P 2017 INT C INNOVAT, DOI DOI 10.1109/ICIIECS.2017.8275896
   Baykas T, 2012, IEEE WIREL COMMUN, V19, P10, DOI 10.1109/MWC.2012.6155872
   Bouaziz M, 2017, CONSUM COMM NETWORK, P19, DOI 10.1109/CCNC.2017.7983074
   Chen YS, 2013, IEEE SYST J, V7, P77, DOI 10.1109/JSYST.2012.2205089
   Chun SH, 2013, IEEE ACM T NETWORK, V21, P176, DOI 10.1109/TNET.2012.2191418
   Ciobanu RI, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1161
   Cordeiro C, 2005, IEEE S NEW FRONT DYN
   Demirkol AS, 2015, INT WIREL COMMUN, P899, DOI 10.1109/IWCMC.2015.7289202
   Devroye N, 2008, IEEE SIGNAL PROC MAG, V25, P12, DOI 10.1109/MSP.2008.929286
   Ge YM, 2013, MULTIMED TOOLS APPL, V67, P213, DOI 10.1007/s11042-011-0937-4
   Khalifé H, 2009, IEEE NETWORK, V23, P20, DOI 10.1109/MNET.2009.5191142
   Lacatus C, 2009, IEEE SYST J, V3, P254, DOI 10.1109/JSYST.2009.2017391
   Li SX, 2011, 2011 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND APPLICATIONS, P1, DOI 10.1109/GSIS.2011.6044018
   Lo BF, 2011, PHYS COMMUN-AMST, V4, P26, DOI 10.1016/j.phycom.2010.12.004
   Mehrnoush M, 2015, IET COMMUN, V9, P1877, DOI 10.1049/iet-com.2015.0010
   Nekovee M, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/236568
   Perkins C., 2003, Internet RFCs
   Rodriguez-Mayol A, 2010, 2010 IEEE 21ST INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2533, DOI 10.1109/PIMRC.2010.5671751
   Sengupta S, 2013, IEEE COMMUN MAG, V51, P168, DOI 10.1109/MCOM.2013.6495776
   Sun B, 2009, 2009 5 INT C WIR COM, P1
   Tandra R, 2009, P IEEE, V97, P824, DOI 10.1109/JPROC.2009.2015710
   Tayel AF, 2016, IEEE T COMMUN, V64, P4487, DOI 10.1109/TCOMM.2016.2607741
   The CMU Monarch Project, 1998, WIR MOB EXT NS
   Wang CW, 2012, IEEE J SEL AREA COMM, V30, P2016, DOI 10.1109/JSAC.2012.121116
   Yan ZW, 2013, IEEE T PARALL DISTR, V24, P2060, DOI 10.1109/TPDS.2012.305
   Zhong J, 2009, THESIS
   Zhu RB, 2013, MULTIMED TOOLS APPL, V67, P269, DOI 10.1007/s11042-011-0942-7
NR 29
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8951
EP 8968
DI 10.1007/s11042-019-7352-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600030
DA 2024-07-18
ER

PT J
AU Wei, Y
AF Wei, Yong
TI RETRACTED: Group intelligent deep learning model based on grouping
   combinatorial geometric path (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Grouping combination; Combination generating; Swarm intelligence; Ant
   colony algorithm; Deep learning
ID ANT SYSTEM; OPTIMIZATION
AB Grouping is a combination problem of dividing n objects into k groups. Grouping combinatorial problem has a wide range of applications. However, because of the huge combination solutions, it is almost impossible to find the best fitness solution through enumerating. On the basis of grouped geometric model, this paper proposes to simulate the process of ant colony foraging by using ant colony algorithm in swarm intelligence. It passes through different routes repeatedly and leaves pheromones according to the fitness, so that the algorithm has memory function. Finally, a solution with high fitness can be obtained quickly according to pheromone graph. The depth learning algorithm proposed in this paper provides a new way to solve the timetable problem, because the timetable process is the problem of arranging different courses into timetable units, in essence, the timetable units are grouped according to the number of units occupied by the curriculum.
C1 [Wei, Yong] Shenzhen Inst Informat Technol, Software Sch, Shenzhen, Peoples R China.
C3 Shenzhen Institute of Information Technology
RP Wei, Y (corresponding author), Shenzhen Inst Informat Technol, Software Sch, Shenzhen, Peoples R China.
EM tsh-xyz@163.com
CR [Anonymous], Q J INDIAN PULP PAPE
   [Anonymous], REV TECHNICA FACULTA
   [Anonymous], 1997, Complexity
   Hemmatian H, 2013, ADV ENG SOFTW, V57, P8, DOI 10.1016/j.advengsoft.2012.11.005
   Hsu CH, 2013, IEEE T FUZZY SYST, V21, P100, DOI 10.1109/TFUZZ.2012.2202665
   Pehlivanoglu YV, 2013, IEEE T EVOLUT COMPUT, V17, P436, DOI 10.1109/TEVC.2012.2196047
   Samuel RDJ, 2020, MULTIMED TOOLS APPL, V79, P5225, DOI 10.1007/s11042-018-6356-z
   Samuel RDJ, 2019, NEURAL COMPUT APPL, V31, P1533, DOI 10.1007/s00521-018-3564-4
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Tang JF, 2013, EXPERT SYST APPL, V40, P7468, DOI 10.1016/j.eswa.2013.06.068
   Tatsumi K, 2013, APPL MATH COMPUT, V219, P8991, DOI 10.1016/j.amc.2013.03.029
   [文仁强 Wen Renqiang], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P1464
   Zhang YD, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/705238
NR 13
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10597
EP 10607
DI 10.1007/s11042-019-08017-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600047
DA 2024-07-18
ER

PT J
AU Wu, QH
AF Wu, Qinghai
TI Image retrieval method based on deep learning semantic feature
   extraction and regularization softmax
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Semantic features; Deep Boltzmann machine;
   Convolutional neural network; Dropout regularization
ID LINE
AB In content-based image retrieval (CBIR), an image retrieval method combining deep learning semantic feature extraction and regularization Softmax is proposed for the "semantic gap" between the underlying visual features and high-level semantic features. First, the deep Boltzmann machine (DBM) and the convolutional neural network (CNN) in the deep learning method are combined to construct a convolution depth Boltzmann machine (C-DBM), which enables it to extract High-order semantic features of images, and robust to image scaling, affine and other transformations. Then, the Dropout regularized Softmax classifier is used to classify the image features. Finally, the image is retrieved according to the sort output. The experimental results show that the proposed method can extract semantic features effectively and has high retrieval accuracy. The classification precision rate in STL-10 image data set reaches 60.3%.
C1 [Wu, Qinghai] Jilin Agr Sci & Technol Univ, Jilin 132101, Jilin, Peoples R China.
C3 Jilin Agricultural Science & Technology University
RP Wu, QH (corresponding author), Jilin Agr Sci & Technol Univ, Jilin 132101, Jilin, Peoples R China.
EM 904201126@qq.com
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], SIGNAL PROCESS
   [Anonymous], 10 INT C COMP INT SE
   [Anonymous], 2017, IEEE INT C COMP COMM
   [Anonymous], CONSUM ELECT
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Feng FX, 2015, NEUROCOMPUTING, V154, P50, DOI 10.1016/j.neucom.2014.12.020
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Lavrenko V., 2003, ADV NEURAL INFORM PR, V1, P2
   Liao B, 2015, IETE TECH REV, V32, P294, DOI 10.1080/02564602.2015.1015631
   Liu LJ, 2016, INT C INTEL HUM MACH, P21, DOI 10.1109/IHMSC.2016.91
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Ma XR, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0071-8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Tang XS, 2017, PATTERN RECOGN LETT, V94, P55, DOI 10.1016/j.patrec.2017.05.025
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yang J, 2018, ALGORITHMS, V11, DOI 10.3390/a11030028
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
NR 20
TC 13
Z9 13
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9419
EP 9433
DI 10.1007/s11042-019-7605-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600060
DA 2024-07-18
ER

PT J
AU Asad, M
   Hussain, A
   Mir, U
AF Asad, Muhammad
   Hussain, Ayyaz
   Mir, Usama
TI Low complexity hybrid holistic - landmark based approach for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Low computational cost; Pose specific classification;
   Classification
ID ADAPTIVE HISTOGRAM EQUALIZATION; INVARIANT; ALGORITHM
AB Modern Face Recognition (FR) systems have to cope with high intra-class variability. Face is a 3D object with wide variability in appearances from each pose. This, along with other causes like luminance variation, becomes one of the main reasons for the high variability. While incremental learning is an unsuited approach for most scenarios, techniques proposed to deal with this issue are often of enormous complexity during training phase and require computational power during operation that is scarcely credible for compact devices. This paper proposes a novel technique where pose specific classification system has been used to attain better classification with low computational cost. State of the art performance measures have been used to assess the validity. Results demonstrate the effectiveness of our pose specific classification system.
C1 [Asad, Muhammad] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Hussain, Ayyaz] Quaid I Azam Univ, Dept Comp Sci, Islamabad 44000, Pakistan.
   [Mir, Usama] Saudi Elect Univ, Dept Comp & Informat, Dammam, Saudi Arabia.
C3 International Islamic University, Pakistan; Quaid I Azam University;
   Saudi Electronic University
RP Hussain, A (corresponding author), Quaid I Azam Univ, Dept Comp Sci, Islamabad 44000, Pakistan.
EM ayyaz.hussain@qau.edu.pk
RI Mir, Usama/HNT-0516-2023
CR Abikoye O., 2019, FUOYE J ENG TECHNOL, V4, P67, DOI [10.46792/fuoyejet.v4i1.309, DOI 10.46792/FUOYEJET.V4I1.309]
   Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206
   Alippi C, 2013, IEEE T NEUR NET LEAR, V24, P620, DOI 10.1109/TNNLS.2013.2239309
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], THESIS
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], 2001, THESIS
   Anwer RM, 2018, ISPRS J PHOTOGRAMM, V138, P74, DOI 10.1016/j.isprsjprs.2018.01.023
   Ashraf AB, 2008, IEEE C COMP VIS PATT
   Bendjillali RI, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030324
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Connolly JF, 2012, INFORM SCIENCES, V192, P50, DOI 10.1016/j.ins.2010.02.026
   Deng AW, 2016, PATTERN RECOGN, V56, P16, DOI 10.1016/j.patcog.2016.02.014
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Ghazi MM, 2016, P IEEE C COMP VIS PA
   Gonzalez Rafel C., 2018, DIGITAL IMAGE PROCES, V4th
   Guo S, 2016, INF AUT ICIA 2016 IE
   Han C, 2018, P EUR C COMP VIS ECC
   Jones M., 2003, Mitsubishi Electric Research Lab TR-20003-96, V3, P2
   Kittler J, 2009, INT WORKSH EN MIN ME
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449
   Li S, 2012, EUR C COMP VIS
   Liu XG, 2018, FUTURE GENER COMP SY, V80, P653, DOI 10.1016/j.future.2016.07.007
   Lucey S, 2008, INT J COMPUT VISION, V80, P58, DOI 10.1007/s11263-007-0119-z
   Minku LL, 2012, IEEE T KNOWL DATA EN, V24, P619, DOI 10.1109/TKDE.2011.58
   Pagano C, 2014, INFORM SCIENCES, V286, P75, DOI 10.1016/j.ins.2014.07.005
   Pereira TD, 2019, IEEE T INF FOREN SEC, V14, P1803, DOI 10.1109/TIFS.2018.2885284
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Singh R, 2007, IEEE T SYST MAN CY B, V37, P1212, DOI 10.1109/TSMCB.2007.903537
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tran CK, 2017, INT C GEN EV COMP
   Zadeh A, 2017, IEEE INT CONF COMP V, P2519, DOI 10.1109/ICCVW.2017.296
   Zhang HJ, 2018, IEEE T NEUR NET LEAR, V29, P5304, DOI 10.1109/TNNLS.2018.2797060
   Zhu Z., 2013, ICCV
NR 46
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30199
EP 30212
DI 10.1007/s11042-020-08872-z
EA MAR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000522013800002
DA 2024-07-18
ER

PT J
AU Zhu, X
   Mao, ZD
   Chen, ZN
   Li, YY
   Wang, ZH
   Wang, B
AF Zhu, Xi
   Mao, Zhendong
   Chen, Zhineng
   Li, Yangyang
   Wang, Zhaohui
   Wang, Bin
TI Object-difference drived graph convolutional networks for visual
   question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual question answering; Graph convolutional networks;
   Object-difference
AB Visual Question Answering(VQA), an important task to evaluate the cross-modal understanding capability of an Artificial Intelligence model, has been a hot research topic in both computer vision and natural language processing communities. Recently, graph-based models have received growing interest in VQA, for its potential of modeling the relationships between objects as well as its formidable interpretability. Nonetheless, those solutions mainly define the similarity between objects as their semantical relationships, while largely ignoring the critical point that the difference between objects can provide more information for establishing the relationship between nodes in the graph. To achieve this, we propose an object-difference based graph learner, which learns question-adaptive semantic relations by calculating inter-object difference under the guidance of questions. With the learned relationships, the input image can be represented as an object graph encoded with structural dependencies between objects. In addition, existing graph-based models leverage the pre-extracted object boxes by the object detection model as node features for convenience, but they are suffering from the redundancy problem. To reduce the redundant objects, we introduce a soft-attention mechanism to magnify the question-related objects. Moreover, we incorporate our object-difference based graph learner into the soft-attention based Graph Convolutional Networks to capture question-specific objects and their interactions for answer prediction. Our experimental results on the VQA 2.0 dataset demonstrate that our model gives significantly better performance than baseline methods.
C1 [Zhu, Xi; Wang, Zhaohui] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Zhu, Xi; Wang, Zhaohui] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Mao, Zhendong] Univ Sci & Technol China, Hefei, Peoples R China.
   [Chen, Zhineng] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Li, Yangyang] China Acad Elect & Informat Technol, Beijing, Peoples R China.
   [Wang, Bin] Xiaomi Inc, Xiaomi AI Lab, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Mao, ZD (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
EM zhuxi@iie.ac.cn; maozhendong2008@gmail.com; zhineng.chen@ia.ac.cn;
   yli@csdclab.net; wangzhaohui@iie.ac.cn; wangbin11@xiaomi.com
RI chen, zhineng/AAD-6723-2020; Li, Yangyang/HTL-9531-2023
OI Li, Yangyang/0000-0001-5737-8678
FU National Key Research and Development Program of China [2016QY03D0505];
   National Natural Science Foundation of China [U19A2057]
FX Zhendong Mao is the corresponding author. This work was supported by the
   National Key Research and Development Program of China (grant No.
   2016QY03D0505) and the National Natural Science Foundation of China
   (grant No. U19A2057).
CR An-An Liu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Ilievski I., 2017, NEURIPS, P551
   Kazemi Vahid., 2017, Show, ask, attend, and answer: A strong baseline for visual question answering
   Kim JH, 2016, ADV NEUR IN, V29
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Li G., 2017, INCORPORATING EXTERN
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P801, DOI 10.1145/3240508.3240605
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P4860, DOI 10.1109/TIP.2018.2803306
   Lu J, 2016, ADV NEUR IN, V29
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Narasimhan M, 2018, ADV NEUR IN, V31
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shang Chao., 2018, Edge attention-based multi-relational graph convolutional networks
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Tang S, 2017, IEEE T MULTIMEDIA, V19, P2105, DOI 10.1109/TMM.2017.2729786
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P519, DOI 10.1145/3240508.3240513
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Yan S., 2018, AAAI, P1
   Yang X, 2018, LECT NOTES COMPUT SC, V11216, P38, DOI 10.1007/978-3-030-01258-8_3
   YANG Z, 2018, MULTIMODAL LEARNING
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhang Y., 2018, LEARNING COUNT OBJEC
NR 40
TC 19
Z9 19
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16247
EP 16265
DI 10.1007/s11042-020-08790-0
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000521018700001
DA 2024-07-18
ER

PT J
AU Li, RP
AF Li, Ruiping
TI Fingerprint-related chaotic image encryption scheme based on blockchain
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic image encryption; Fingerprint; Blockchain; CPA
ID CRYPTANALYSIS; SYSTEMS
AB Chaotic image encryption has been greatly investigated in recent years. However, a considerable number of the encryption schemes had been cracked by chosen plaintext attack (CPA). Although the new proposed plaintext-related chaotic image encryption schemes can resist CPA effectively, the emerged key management problem is a hot potato. In this paper, a novel fingerprint-related chaotic image encryption scheme is proposed. The generation of key streams is affected by the fingerprints of distributors rather than the plaintexts of images. In addition, the blockchain framework is adopted to ensure that the encrypted image was sent correctly form the distributor. Moreover, the distributors' fingerprints embedded in the encrypted images are encoded by the anti-collusion code in order to record multiple fingerprints with fixed length of data. The proposed method has the following superiorities: 1) Security. CPA is invalid because the attacker does not have the fingerprint of the legal receiver. Meanwhile, no key management problem is caused. 2) Authenticity. The image, the sender and the receiver are all verified by using blockchain framework. 3) Traceability. All distributors' fingerprints can be extracted correctly from the merged fingerprint based on the anti-collusion code, and the transmission of the image can be traced.
C1 [Li, Ruiping] Henan Normal Univ, Modern Educ Technol Ctr, Xinxiang 453007, Henan, Peoples R China.
C3 Henan Normal University
RP Li, RP (corresponding author), Henan Normal Univ, Modern Educ Technol Ctr, Xinxiang 453007, Henan, Peoples R China.
EM liruiping@htu.edu.cn
FU Educational Science Research Foundation of Henan Normal University
   [2018JK20]
FX This work was supported by the Educational Science Research Foundation
   of Henan Normal University (2018JK20).
CR Alawida M, 2019, SIGNAL PROCESS, V164, P249, DOI 10.1016/j.sigpro.2019.06.013
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Blake-Wilson S, 2000, DESIGN CODE CRYPTOGR, V19, P77, DOI 10.1023/A:1008345904539
   Borujeni SE, 2012, INT J BIFURCAT CHAOS, V22, DOI 10.1142/S0218127412501271
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen L, 2019, IEEE ACCESS, V7, P97549, DOI 10.1109/ACCESS.2019.2926831
   Chen YC, 2019, IEEE T INF FOREN SEC, V14, P3332, DOI 10.1109/TIFS.2019.2914557
   Cheng MQ, 2011, IEEE T INFORM THEORY, V57, P4843, DOI 10.1109/TIT.2011.2146130
   Chuman T, 2019, IEEE T INF FOREN SEC, V14, P1515, DOI 10.1109/TIFS.2018.2881677
   Conti M, 2018, IEEE COMMUN SURV TUT, V20, P3416, DOI 10.1109/COMST.2018.2842460
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Gao ED, 2019, INFORM SCIENCES, V505, P549, DOI 10.1016/j.ins.2019.07.101
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   He XY, 2019, MULTIMED TOOLS APPL, V78, P29137, DOI 10.1007/s11042-018-6589-x
   Hoffmann L, 2016, COMMUN ACM, V59, P112, DOI 10.1145/2911977
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Hussain I, 2013, NONLINEAR DYNAM, V71, P133, DOI 10.1007/s11071-012-0646-1
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Khalilov MCK, 2018, IEEE COMMUN SURV TUT, V20, P2543, DOI 10.1109/COMST.2018.2818623
   Kim Y, 2016, MULTIMED TOOLS APPL, V75, P14143, DOI 10.1007/s11042-016-3242-4
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li M, 2019, NONLINEAR DYNAM, V96, P31, DOI 10.1007/s11071-019-04771-7
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Natgunanathan I, 2017, IEEE-ACM T AUDIO SPE, V25, P2176, DOI 10.1109/TASLP.2017.2749001
   Nuida K, 2009, DESIGN CODE CRYPTOGR, V52, P339, DOI 10.1007/s10623-009-9285-z
   Salman T, 2019, IEEE COMMUN SURV TUT, V21, P858, DOI 10.1109/COMST.2018.2863956
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Tardos G, 2008, J ACM, V55, DOI 10.1145/1346330.1346335
   Wang D, 2018, IEEE SYST J, V12, P916, DOI 10.1109/JSYST.2016.2585681
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang ZJ, 2005, IEEE T IMAGE PROCESS, V14, P804, DOI 10.1109/TIP.2005.847284
   Wen WY, 2016, MULTIMED TOOLS APPL, V75, P3553, DOI 10.1007/s11042-015-2464-1
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhang YS, 2019, IEEE COMMUN SURV TUT, V21, P1093, DOI 10.1109/COMST.2018.2878943
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhen P, 2014, 2014 NINTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P237, DOI 10.1109/3PGCIC.2014.69
NR 44
TC 15
Z9 15
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30583
EP 30603
DI 10.1007/s11042-020-08802-z
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000520640300001
DA 2024-07-18
ER

PT J
AU Piccialli, F
   Casolla, G
   Cuomo, S
   Giampaolo, F
   Prezioso, E
   di Cola, VS
AF Piccialli, Francesco
   Casolla, Giampaolo
   Cuomo, Salvatore
   Giampaolo, Fabio
   Prezioso, Edoardo
   di Cola, Vincenzo Schiano
TI Unsupervised learning on multimedia data: a Cultural Heritage case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; Machine learning; Data science; Multimedia
AB Integrating and analyzing a large amount of data extracted from different sources can be considered a key asset for businesses, organizations, research institutions that also deal with the Cultural Heritage domain. In the last decade, Internet of Things (IoT) technologies and the massive use of mobile devices contributed to generate an enormous flow of multimedia data, whose collection, analysis and interpretation allows for real-time analysis related to the behaviours, preferences and opinions of users. In this paper we present and discuss an unsupervised learning approach on multimedia features of a dataset coming from an Internet of Things framework. The main research objective of this work is to assess how the collection of behavioural IoT data coming from the Cultural Heritage domain can be opportunely exploited by means of unsupervised learning techniques in order to produce useful insights for the stakeholders, especially considering the multimedia features of such data. The presented experimental results, executed in a real case study, assess how the Cultural Heritage domain, and the related stakeholders, can benefit from these kind of services and applications.
C1 [Piccialli, Francesco; Casolla, Giampaolo; Cuomo, Salvatore; Giampaolo, Fabio; Prezioso, Edoardo; di Cola, Vincenzo Schiano] Univ Naples Federico II, Naples, Italy.
C3 University of Naples Federico II
RP Piccialli, F (corresponding author), Univ Naples Federico II, Naples, Italy.
EM francesco.piccialli@unina.it
RI Piccialli, Francesco/ABC-2457-2020; Cuomo, Salvatore/Q-1365-2016
OI Piccialli, Francesco/0000-0002-5179-2496; Cuomo,
   Salvatore/0000-0003-4128-2588; Giampaolo, Fabio/0000-0001-5414-3435;
   Prezioso, Edoardo/0000-0002-0401-8422
FU OPS-REMIAM project [PON03PE_00161]; Cultural Equipment with Transmedial
   Recommendation Analytics - C.E.T.R.A. project [Regione Campania - Bando
   RIS3 2018 - Fase 2 - Supporto di progetti, anche collaborativi, di
   sviluppo precompetitivo, trasferimento tecnologico da parte delle MPMI
   campane]
FX This work was supported by the OPS-REMIAM project [Grant Number
   PON03PE_00161] and the Cultural Equipment with Transmedial
   Recommendation Analytics - C.E.T.R.A. project [Regione Campania - Bando
   RIS3 2018 - Fase 2 - Supporto di progetti, anche collaborativi, di
   sviluppo precompetitivo, trasferimento tecnologico da parte delle MPMI
   campane]
CR Aria M, 2017, J INFORMETR, V11, P959, DOI 10.1016/j.joi.2017.08.007
   Bollo A, 2016, QUADERNI VALORIZZAZI, V2
   Ibba A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3360, DOI 10.1109/ICPR.2010.820
   Jung YJ, 2018, TECHTRENDS, V62, P509, DOI 10.1007/s11528-018-0310-9
   Katifori A, 2018, LECT NOTES COMPUT SC, V11318, P603, DOI 10.1007/978-3-030-04028-4_70
   Kawashima T, 2005, ANAT EMBRYOL, V209, P425, DOI 10.1007/s00429-005-0462-1
   Krause A, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P88, DOI 10.1109/ISWC.2003.1241398
   MA W, 1935, PROBLEMS INSTALLATIO, V14, P29
   Maechler M., 2019, cluster: Cluster Analysis Basics and Extensions
   Martella C, 2017, PERVASIVE MOB COMPUT, V38, P430, DOI 10.1016/j.pmcj.2016.08.011
   Ohlei A., 2018, Mensch und Computer 2018-Workshopband
   Pekalska E., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096), P359
   Piccialli F, 2020, NEURAL COMPUT APPL, V32, P7785, DOI 10.1007/s00521-019-04099-8
   Pierdicca R, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061387
   PORTALES Cristina., 2018, Multimodal Technologies and Interact, V2, P1, DOI [10.3390/mti2030058, DOI 10.3390/MTI2030058]
   Reynolds AP., 2006, J Math Model Algorithm, V5, P475, DOI [DOI 10.1007/S10852-005-9022-1, https://doi.org/10.1007/s10852-005-9022-1]
   Roussou Maria, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020032
   Traboulsi Christelle, 2018, TQM Journal, V30, P530, DOI 10.1108/TQM-11-2017-0155
   Won H, 2018, LECT NOTES COMPUT SC, V11197, P111, DOI 10.1007/978-3-030-01765-1_13
   Zancanaro M, 2007, LECT NOTES ARTIF INT, V4511, P238
NR 20
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34429
EP 34442
DI 10.1007/s11042-020-08781-1
EA MAR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000564453200001
DA 2024-07-18
ER

PT J
AU Park, SB
AF Park, Seung-Bo
TI Detection of the helper types from story in multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character-net; Visualization; Helper type; Story; Movie; Multimedia
ID CHARACTER
AB A story unfolds through the relationships formed by the major and minor characters. The major characters are central to the main plot of the story, creating and resolving the conflicts. In contrast, the minor characters tend to play the role of awakening the major characters or solving their problems. Although the minor characters appear less frequently than the major characters, they play crucial roles in that they create tension, provide clues that lead to a solution, and so on, thereby making the story more interesting and engaging. Therefore, an analysis of the minor characters is essential for analyzing the entire story. However, the existing character analysis methods such as Character-net and RoleNet are not entirely suitable for analyzing the roles of minor characters in a story, even though they are adequate for classifying whether a character is one of the major characters or a minor character based on an analysis of the cumulative outcomes of the story. For an accurate analysis of the roles of minor characters, there is a need to study the pattern in which the characters appear as the story progresses, not to analyze the story based on cumulative outcomes. Accordingly, this paper proposes a method of classifying minor characters as either a mentor or a best friend, based on a three-dimensional visualization of Character-net which can depict the story progress. In order to make such distinctions, a set of classification rules based on appearance patterns and density was proposed, and forty characters chosen from twenty-five movies were examined for the purpose of performance evaluation. The results showed that the proposed method had a significant classification performance with an F1-measure of 0.565 with respect to the forty characters.
C1 [Park, Seung-Bo] Inha Univ, Dept Software Convergence Engn, Incheon, South Korea.
C3 Inha University
RP Park, SB (corresponding author), Inha Univ, Dept Software Convergence Engn, Incheon, South Korea.
EM molaal@inha.ac.kr
OI Park, Seung Bo/0000-0002-0000-4453
FU INHA UNIVERSITY Research Grant [INHA-55931]
FX This work was supported by INHA UNIVERSITY Research Grant. (INHA-55931)
CR [Anonymous], 2006, INSIDE STORY POWER T
   Aristotle, 1917, POETICS ARISTOTELES
   Brooks L, 2011, STORY ENG
   Chatman, 1978, STORY DISCOURSE NARR
   Choia I-K, 2017, J BROADCAST ENG, V22
   de Lima ES, 2017, BRAZIL SYMP GAME DIG, P144, DOI 10.1109/SBGames.2017.00024
   Gulino Paul., 2004, Screenwriting: The Sequence Approach. Bloomsbury Academic
   Han YH, 2020, IEEE T CIRC SYST VID, V30, P875, DOI 10.1109/TCSVT.2019.2897604
   Jung H, 2016, CLUSTER COMPUT, V19, P2261, DOI 10.1007/s10586-016-0672-8
   Jung JJ, 2013, MULTIMED TOOLS APPL, V65, P29, DOI 10.1007/s11042-012-1133-x
   Jung KY, 2004, IEICE T INF SYST, VE87D, P2781
   김민준, 2016, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V21, P782, DOI 10.5909/JBE.2016.21.5.782
   Kybartas B, 2017, IEEE T COMP INTEL AI, V9, P239, DOI 10.1109/TCIAIG.2016.2546063
   Li XS, 2017, INT CON ADV INFO NET, P189, DOI 10.1109/AINA.2017.127
   Liu C, 2019, EXPERT SYST APPL, V123, P246, DOI 10.1016/j.eswa.2019.01.003
   Nan CJ, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P831, DOI 10.1145/2808797.2809306
   Park HR, 2010, INT J DERMATOL, V49, P48, DOI 10.1111/j.1365-4632.2009.04191.x
   Park H, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P166, DOI 10.1145/1454115.1454140
   Park SB, 2014, MULTIMED TOOLS APPL, V68, P391, DOI 10.1007/s11042-012-1320-9
   Park SB, 2012, MULTIMED TOOLS APPL, V59, P601, DOI 10.1007/s11042-011-0725-1
   Schmid VL, 2012, 45 MASTER CHARACTERS
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Yangchen Wang, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P709, DOI 10.1109/ICIS.2018.8466530
NR 23
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34479
EP 34497
DI 10.1007/s11042-020-08778-w
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000562592900001
DA 2024-07-18
ER

PT J
AU Noor, A
   Zhao, YQ
   Khan, R
   Wu, LW
   Abdalla, FYO
AF Noor, Alam
   Zhao, Yaqin
   Khan, Rahim
   Wu, Longwen
   Abdalla, Fakheraldin Y. O.
TI Median filters combined with denoising convolutional neural network for
   Gaussian and impulse noises
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Median filters; Gaussian noise; Impulse
   noise
ID REMOVAL; ALGORITHM
AB Elimination of combined Gaussian and impulse noises in digital image processing with preservation of image details and suppression of noise are challenging problem. For this purpose, a new filter which is median filters combined with convolutional neural network for Gaussian and salt & pepper noises. The previous methods are application dependents; some used for impulse noise and other employed only for Gaussian noise. The elimination of Gaussian and impulse noise completed into two steps. First the detection of impulse noise with the rejection of noise by employed of 3 x 3 and 5 x 5 window size median filters. In the second step removal of Gaussian noise performed by residual learning denoising convolutional neural network. It is very favorable and the ability of learning and denoising performance in the field of digital image processing. Denoising convolutional neural network also has active Gaussian noise with an unknown level of noise. Experimental work showed that the proposed method can achieve low loss and root mean square error during training, high peak signal to noise ratio, low mean square error, image quality assessment with good quality and mean absolute error for close prediction between denoised and original color images.
C1 [Noor, Alam] Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
   [Zhao, Yaqin; Khan, Rahim; Wu, Longwen; Abdalla, Fakheraldin Y. O.] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin, Heilongjiang, Peoples R China.
   [Noor, Alam] Prince Sultan Univ, Robot & Internet Of Things Lab, Riyadh, Saudi Arabia.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Prince
   Sultan University
RP Zhao, YQ (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin, Heilongjiang, Peoples R China.
EM pinkheart_gold@yahoo.com; yaqinzhao@hit.edu.cn; rahimkhan9001@yahoo.com;
   wulongwen@hit.edu.cn; fakheraldin.abdalla@hit.edu.cn
RI Noor, Alam/B-2353-2019; Wu, Longwen/ACU-0254-2022
OI Noor, Alam/0000-0002-0077-6509; Wu, Longwen/0000-0002-6914-6695
FU National Natural Science Foundation of China, China [:61671185]
FX This Paper is supported by the National Natural Science Foundation of
   China, China [Grand number:61671185].
CR Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   Chen PY, 2008, IEEE SIGNAL PROC LET, V15, P833, DOI 10.1109/LSP.2008.2005047
   Delon J, 2013, SIAM J IMAGING SCI, V6, P1140, DOI 10.1137/120885000
   Demirkaya O, 2004, LECT NOTES COMPUT SC, V3117, P111
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   KHMOU Y, 2012, MATHWORKS
   King DB, 2015, ACS SYM SER, V1214, P1
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   LEHMMAN EL, 1998, THEORY POINT ESTIMAT
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Lin TC, 2007, INFORM SCIENCES, V177, P1073, DOI 10.1016/j.ins.2006.07.030
   Luo WB, 2006, IEEE T CONSUM ELECTR, V52, P523, DOI 10.1109/TCE.2006.1649674
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   PHAM TD, 2007, DOUBLE ADAPTIVE FILT
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Toh KKV, 2008, IEEE T CONSUM ELECTR, V54, P1956, DOI 10.1109/TCE.2008.4711258
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 23
TC 19
Z9 19
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18553
EP 18568
DI 10.1007/s11042-020-08657-4
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518306100003
DA 2024-07-18
ER

PT J
AU Ullah, I
   Khusro, S
AF Ullah, Irfan
   Khusro, Shah
TI Social book search: the impact of the social web on book retrieval and
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Book retrieval; Book recommendation; Social book
   search; Professional metadata; Social metadata
ID GOOGLE SCHOLAR; QUERY EXPANSION; INFORMATION; RELEVANCE; SYSTEMS; MODELS
AB Social media has changed the digital landscape of book retrieval and recommendation on the Web. The availability of the social collaborative cataloging and search applications including Amazon, GoodReads, and LibraryThing has enabled users to discuss their complex information needs and request recommendations on books in natural language. Others with similar interests and preferences suggest books. On these social book websites, users not only benefit from the available professionally-curated, publisher-provided (professional) metadata but also look at how group members assess books by reading their reviews, tags, and ratings, which are commonly referred to as the user-generated content or social metadata. This social collaborative cataloging practice and the resulting rich metadata collection attracted researchers under the broader topic of Social Book Search (SBS). The aim is to exploit the social metadata in book retrieval and understand the search behavior of users while interacting with the rich metadata collection. The retrieval side of the SBS research, which is the main focus of this paper, attempts to come up with book retrieval solutions considering the ambiguity of the natural language and the complexity of the information needs of the users. This paper gives in-depth and comprehensive coverage to the current state of the retrieval side of SBS research from its origin to the present day by critically and analytically reviewing the academically significant relevant research contributions. It reports on the retrieval methods, evaluation methodology, and best-performing runs using different evaluation metrics. It identifies the current trends as well as research challenges and opportunities.
C1 [Ullah, Irfan; Khusro, Shah] Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
C3 University of Peshawar
RP Khusro, S (corresponding author), Univ Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
EM cs.irfan@uop.edu.pk; khusro@uop.edu.pk
RI Khusro, Shah/C-1661-2014; Ullah, Irfan/AGE-7574-2022; Ullah,
   Irfan/C-9213-2014; Ullah, Irfan/CAA-4310-2022
OI Khusro, Shah/0000-0002-7734-7243; Ullah, Irfan/0000-0003-0693-5467;
   Ullah, Irfan/0000-0003-0693-5467; Ullah, Irfan/0000-0003-0693-5467;
   Ullah, Irfan/0000-0003-3961-888X
CR Adriaans F, 2012, FOCUSED RETRIEVAL CO, V7424, P30, DOI [10.1007/978-3-642-35734-3_2, DOI 10.1007/978-3-642-35734-3_2]
   Aggarwal K, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1970-6
   Alharthi H, 2018, J INTELL INF SYST, V51, P139, DOI 10.1007/s10844-017-0489-9
   Alyari F, 2018, KYBERNETES, V47, P985, DOI 10.1108/K-06-2017-0196
   Amati G., 2002, ACM Transactions on Information Systems, V20, P357, DOI 10.1145/582415.582416
   Amer Nawal Ould, 2016, NEU IR SIGIR 2016 WO
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 10 INT WORKSH IN EV
   [Anonymous], CUER WORKSHOP P
   [Anonymous], 18 ACM C INF KNOWL M
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], CEUR WORKSHOPT P
   [Anonymous], 13 DUTCH BELG WORKSH
   [Anonymous], P 3 ACM C REC SYST N
   [Anonymous], 4 INT C CLEF IN CLEF
   [Anonymous], 7 INT C CLEF ASS CLE
   [Anonymous], 10 INT WORKSH IN EV
   [Anonymous], 6 INT C CLEF ASS CLE
   [Anonymous], P KNOWL AW CONV REC
   [Anonymous], 4 INT C CLEF IN CLEF
   [Anonymous], ADV COMPUTER SCI RES
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 7 INT C CLEF ASS CLE
   [Anonymous], 36 EUR C IR RES ADV
   [Anonymous], 6 INT C CLEF ASS CLE
   [Anonymous], ICONFERENCE 2017 P 2
   [Anonymous], 6 INT C CLEF ASS CLE
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 2 WORKSH SUPP COMPL
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], ICONFERENCE P 2015 I
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], BEHAV INFORM TECHNOL
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], CEUR WORKSHOPT P
   [Anonymous], ENCY DATABASE SYSTEM
   [Anonymous], 3 INT C CLEF IN CLEF
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 3 INT C CLEF IN CLEF
   [Anonymous], 2 WORKSH SUPP COMPL
   [Anonymous], IEEE WIC ACM INT C W
   [Anonymous], LIB SCI INFORM SCI
   [Anonymous], 10 INT WORKSH IN EV
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], 4 INT C CLEF IN CLEF
   [Anonymous], CEUR WORKSHOPT P
   [Anonymous], 30 INT FLAIRS C MARC
   [Anonymous], 5 INT C CLEF IN CLEF
   [Anonymous], SEARCH ENGINES INFOR
   [Anonymous], 7 INT C CLEF ASS CLE
   [Anonymous], 2 EUR C THEOR PRACT
   [Anonymous], 2 WORKSH NEW TRENDS
   [Anonymous], 10 INT WORKSH IN EV
   Badache I, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P155, DOI 10.1145/3020165.3020177
   Bellot P, 2013, LECT NOTES COMPUT SC, V8138, P269, DOI 10.1007/978-3-642-40802-1_27
   Benkoussas C, 2015, 2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 1, P385, DOI 10.1109/WI-IAT.2015.200
   Besbes Ghada, 2016, International Journal of Metadata, Semantics and Ontologies, V11, P221
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bogers Toine., 2017, Data and Information Management, V1, P17, DOI 10.1515/dim-2017-0004
   Chaa M, 2018, LECT NOTES COMPUT SC, V11018, P64, DOI 10.1007/978-3-319-98932-7_6
   Chaa Messaoud, 2016, CLEF CEUR WORKSHOP P, P1072
   Chen W, 2013, IEEE CONF IMAGING SY, P441, DOI 10.1109/IST.2013.6729738
   Dixon L, 2010, REF USER SERV Q, V50, P170, DOI 10.5860/rusq.50n2.170
   Ettaleb M, 2018, PROCEDIA COMPUT SCI, V126, P768, DOI 10.1016/j.procs.2018.08.011
   Feng S.-H, 2016, WORKING NOTES CLEF 2, V1609, P1089
   Garcia-Molina H, 2011, COMMUN ACM, V54, P121, DOI 10.1145/2018396.2018423
   Halevi G, 2017, J INFORMETR, V11, P823, DOI 10.1016/j.joi.2017.06.005
   Hamad F, 2017, EXPLOITING SOCIAL ME, P107, DOI [10.1007/978-3-319-55354-2_9, DOI 10.1007/978-3-319-55354-2_9]
   Han Y, 2014, 2014 INTERNATIONAL CONFERENCE ON BIOLOGICAL ENGINEERING AND BIOMEDICAL (BEAB 2014), P203
   Huurdeman H., 2012, INEX 2012 Workshop pre-proceedings, P125
   Imhof M, 2018, INFORM RETRIEVAL J, V21, P81, DOI 10.1007/s10791-017-9322-x
   Ingwersen P, 1996, J DOC, V52, P3, DOI 10.1108/eb026960
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Kamps J., 2019, INFORM RETRIEVAL EVA, P415
   Kazai G, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1554, DOI 10.1109/ITNG.2009.281
   Kazai G, 2008, LECT NOTES COMPUT SC, V4862, P148, DOI 10.1007/978-3-540-85902-4_14
   Khan MS, 2014, ENVIRON SCI ENG, P521, DOI 10.1007/978-3-319-03002-9_130
   Khusro Shah, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P1179, DOI 10.1007/978-981-10-0557-2_112
   Koolen M., 2012, ACM Conference on Information and Knowledge Management (CIKM), P185, DOI DOI 10.1145/2396761.2396788
   Koolen M, 2016, LECT NOTES COMPUT SC, V9822, P351, DOI 10.1007/978-3-319-44564-9_29
   Koolen M, 2015, LECT NOTES COMPUT SC, V9283, P545, DOI 10.1007/978-3-319-24027-5_51
   Kumar R, 2017, ADV INF SECUR PRIV, P1, DOI 10.4018/978-1-5225-2154-9
   Kumar R, 2020, ARTIF INTELL REV, V53, P95, DOI 10.1007/s10462-018-9647-x
   Kumar R, 2019, APPL INTELL, V49, P2178, DOI 10.1007/s10489-018-1383-z
   Lavrenko V., 2001, SIGIR Forum, P120
   Li XY, 2013, ADV MATER RES-SWITZ, V774-776, P1838, DOI 10.4028/www.scientific.net/AMR.774-776.1838
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   MADRIGAL A., 2010, ATLANTIC
   Metzler D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P472, DOI 10.1145/1076034.1076115
   Metzler D, 2004, INFORM PROCESS MANAG, V40, P735, DOI 10.1016/j.ipm.2004.05.001
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Portugal I, 2018, EXPERT SYST APPL, V97, P205, DOI 10.1016/j.eswa.2017.12.020
   Preminger M, 2013, WORKING NOTES CLEF 2, V1179, P1
   Preminger M, 2012, WORKING NOTES CLEF 2, P1
   Ramirez G, 2012, FOCUSED RETRIEVAL CO, P146, DOI [10.1007/978-3-642-35734-3_12, DOI 10.1007/978-3-642-35734-3_12]
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109
   Sahebi Shaghayegh, 2013, User Modeling, Adaptation, and Personalization. 21th International Conference, UMAP 2013. Proceedings., P289, DOI 10.1007/978-3-642-38844-6_25
   Saracevic Tefko., 2016, Synthesis Lectures on Information Concepts, Retrieval, and Services, V8, pi, DOI [DOI 10.2200/S00723ED1V01Y201607ICR050, 10.2200/s00723ed1v01y201607icr050]
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   SCHAMBER L, 1990, INFORM PROCESS MANAG, V26, P755, DOI 10.1016/0306-4573(90)90050-C
   Tresca C, 2015, 2D MATER, V2, DOI 10.1088/2053-1583/2/1/015001
   Wang Y, 2012, J WEB LIBRARIANSH, V6, P94, DOI 10.1080/19322909.2012.672067
   Wu SH, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1553, DOI 10.1145/2882903.2915227
   Xiao W.-L, 2013, WORKING NOTES CLEF 2, V1179, P1
   Yada S, 2020, INT J DIGIT LIBRARIE, V21, P265, DOI [10.1080/09715010.2019.1594417, 10.1007/s00799-019-00273-4]
   Yin XC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148479
   Zhang BW, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1109, DOI 10.1145/3077136.3080734
   Zhang BW, 2016, INFORM SCIENCES, V367, P909, DOI 10.1016/j.ins.2016.07.004
   Zhang Bo-Wen., 2014, Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, P361, DOI [DOI 10.1145/2661829.2661940, 10.1145/2661829.2661940]
   Zhao CG, 2015, FRONT MICROBIOL, V6, DOI 10.3389/fmicb.2015.00986
   Zhou F., 2017, 2017 IEEE INT C COMM, P1, DOI [10.1109/ICC.2017.7997425, DOI 10.1109/ICC.2017.7997425]
   Zientek LR, 2018, NEW HORIZ ADULT EDUC, V30, P39, DOI 10.1002/nha3.20209
NR 118
TC 8
Z9 8
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8011
EP 8060
DI 10.1007/s11042-019-08591-0
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100052
DA 2024-07-18
ER

PT J
AU Gong, XH
   Chen, L
   Yu, F
   Zhao, XH
   Wang, SH
AF Gong, Xinhui
   Chen, Lei
   Yu, Feng
   Zhao, Xiaohong
   Wang, Shihong
TI A secure image authentication scheme based on dual fragile watermark
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Dual fragile watermark; Chosen cover image
   attacks; Collage attacks; 3D Arnold transformation
ID TAMPER DETECTION
AB Both security and tamper localization are essential for fragile watermarking techniques. Embedded fragile watermark should be sensitive enough to cover images. But high sensitivity maybe bring inaccurate tamper localization, and both high sensitivity and accurate tamper localization seem contradictory. This paper proposes a watermark scheme based on dual fragile watermark: diffusion watermark and authentication watermark. The diffusion watermark is determined by a cover image, a secret key and two random numbers via nonlinear transformations, and the authentication watermark is generated from the cover image, the diffusion watermark and another secret key. The diffusion watermark and the authentication watermark have high sensitivity to cover images and at meantime the authentication watermark can verify the integrity of images and localize tampered area. The scrambled authentication watermark and the diffusion watermark are arbitrarily embedded into the two lowest significant bit layers of the cover image through a random sequence controlled by a secret key. The design aims to enhance the security of fragile watermarking, and the statistical results and security analysis show that this scheme can resist chosen cover-image attacks.
C1 [Gong, Xinhui; Chen, Lei; Yu, Feng; Zhao, Xiaohong; Wang, Shihong] Beijing Univ Posts & Telecommun, Sch Sci, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wang, SH (corresponding author), Beijing Univ Posts & Telecommun, Sch Sci, Beijing 100876, Peoples R China.
EM shwang@bupt.edu.cn
CR Barreto PSLM, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P494, DOI 10.1109/ICIP.2001.958536
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Botta M, 2015, AEU-INT J ELECTRON C, V69, P242, DOI 10.1016/j.aeue.2014.09.004
   Caragata D, 2016, AEU-INT J ELECTRON C, V70, P777, DOI 10.1016/j.aeue.2016.03.001
   Chaluvadi SB, 2009, WOR CONG NAT BIOL, P992
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Ding W, 2018, MULTIMED TOOLS APPL, P1
   Doyoddorj M, 2012, DESIGN ANAL FRAGILE
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   Fridrich J, 2000, IEEE IMAGE PROC, P446, DOI 10.1109/ICIP.2000.900991
   Gul E, 2019, MULTIMED TOOLS APPL, P1
   Haouzia A., 2008, METHODS IMAGE AUTHEN
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Lazarov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P723, DOI 10.1109/IS.2016.7737391
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Liu X.-L., 2016, J. Inf. Hiding Multimedia Signal Process., V7, P1282
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Ma LS, 2019, MULTIMED TOOLS APPL, V78, P9827, DOI 10.1007/s11042-018-6598-9
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Pan T. G., 2011, ADV ENG FORUM, V1, P183, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AEF.1.183
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Phan CW, 2008, TAMPERING WATERMARKI
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Teng L, 2013, AEU-INT J ELECTRON C, V67, P540, DOI 10.1016/j.aeue.2012.12.001
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wong PW, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P374
   Xiao D, 2017, MULTIMED TOOLS APPL, V76, P9265, DOI 10.1007/s11042-016-3532-x
   Xinhui G, ARXIV181211735V2
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 45
TC 13
Z9 14
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18071
EP 18088
DI 10.1007/s11042-019-08594-x
EA FEB 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000517016900003
DA 2024-07-18
ER

PT J
AU Kim, JS
AF Kim, Jin-Su
TI Multimedia emotion prediction using movie script and spectrogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Emotion prediction; CNN; Spectrogram; Big data; TF-IPF
ID NEURAL-NETWORKS; CLASSIFICATION; WORD2VEC; SYSTEM; SPEECH
AB This article proposes a multimedia emotion-prediction approach using movie scripts and spectrograms with speech information. First, a variety of information is extracted from textual dialogues in scripts for emotion prediction. In addition, spectrograms transformed from speech information help to identify subtle representations of difficult-to-predict emotions from scripts. Accent helps predict emotions because it is an important means of expressing emotion states in speech. These are to analyze emotion words with a similar tendency on the basis of the emotion keywords in scripts and spectrograms. Emotion candidate keywords are extracted from text data using morphological analysis, and representative emotion keywords are extracted through Word2Vec_ARSP. Emotion keywords and speech data from the last part of the dialogue are extracted and converted into images. This multimedia information is used for the input layer in a convolutional neural network. In this paper, we propose a multi-modal method for more efficiently extracting and predicting emotions by mixing and learning integrated multimedia information through the character's speech and background sounds, as well as dialogue that can directly express the emotional situation of the context. In order to improve the accuracy of emotion prediction using multimedia information in movies, we propose a system with a CNN for learning, testing, and prediction using a multi-modal method. The proposed multi-modal system compensates for unpredictable emotions from certain parts of the text through the spectrogram. The prediction accuracy is improved by 20.9% and 6.7%, compared to using only text information and only voice information, respectively.
C1 [Kim, Jin-Su] Anyang Univ, Div Ari Liberal Arts, 22 Samdeok Ro 37 Beon Gil, Anyang Si 14028, Gyeonggi Do, South Korea.
C3 Anyang University
RP Kim, JS (corresponding author), Anyang Univ, Div Ari Liberal Arts, 22 Samdeok Ro 37 Beon Gil, Anyang Si 14028, Gyeonggi Do, South Korea.
EM kjspace@anyang.ac.kr
RI kim, jinsu/JEP-4929-2023
OI kim, jinsu/0000-0002-9800-7264
CR [Anonymous], 2009, INTRO INFORM RETRIEV
   [Anonymous], 2014, UNDERSTANDING MACHIN
   Birajdar GK, 2019, MULTIMED TOOLS APPL, V78, P15141, DOI 10.1007/s11042-018-6899-z
   Bird Steven, 2009, NATURAL LANGUAGE PRO, DOI DOI 10.1007/S10579-010-9124-X
   Bordwell DavidKristin Thompson Jeff Smith., 2016, FILM ART INTRO, V11th
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Endo P, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P696, DOI 10.1109/WAINA.2014.113
   George KK, 2018, PATTERN RECOGN LETT, V112, P285, DOI 10.1016/j.patrec.2018.08.019
   Jeong-Sik Park，, 2011, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V9, P39
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   김옥섭, 2015, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V18, P1068, DOI 10.9717/kmms.2015.18.9.1068
   Levy O., 2015, Transactions of the Association for Computational Linguistics, V3, P211
   Maaoui Choubeila, 2010, Cutting Edge Robotics 2010, P317
   McGuinness Deborah., 2009, OWL Web Ontology Language
   Metz CE, 2008, RADIOL PHYS TECHNOL, V1, P2, DOI 10.1007/s12194-007-0002-1
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Ouali C, 2016, MULTIMED TOOLS APPL, V75, P9145, DOI 10.1007/s11042-015-3081-8
   Park E.L., 2014, P 26 ANN C HUM COGN, VVolume 6
   Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Scherer KR., 2014, APPROACHES EMOTION
   Sewak M., 2018, Practical Convolutional Neural Networks: Implement Advanced Deep Learning Models Using Python
   Tang GC, 2019, MULTIMED TOOLS APPL, V78, P15801, DOI 10.1007/s11042-018-6991-4
   Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63, DOI 10.3115/1117794.1117802
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Umeozor Susan Nnadozie, 2019, International Journal of Knowledge Content Development & Technology, V9, P33, DOI 10.5865/IJKCT.2019.9.2.033
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   김진수, 2014, [Journal of Digital Convergence, 디지털융복합연구], V12, P249, DOI 10.14400/JDC.2014.12.12.249
NR 32
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34535
EP 34551
DI 10.1007/s11042-020-08777-x
EA FEB 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000515925400005
DA 2024-07-18
ER

PT J
AU Abdel-Basset, M
   Manogaran, G
   Fakhry, AE
   El-Henawy, I
AF Abdel-Basset, Mohamed
   Manogaran, Gunasekaran
   Fakhry, Ahmed E.
   El-Henawy, Ibrahim
TI 2-Levels of clustering strategy to detect and locate copy-move forgery
   in digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Digital image forensics; Manipulating detection;
   Copy-move localization
ID FORENSICS
AB Understanding is considered a key purpose of image forensic science in order to find out if a digital image is authenticated or not. It can be a sensitive task in case images are used as necessary proof as an impact judgment. it's known that There are several different manipulating attacks but, this copy move is considered as one of the most common and immediate one, in which a region is copied twice in order to give different information about the same scene, which can be considered as an issue of information integrity. The detection of this kind of manipulating has been recently handled using methods based on SIFT. SIFT characteristics are represented in the detection of image features and determining matched points. A clustering is a key step which always following SIFT matching in-order to classify similar matched points to clusters. The ability of the image forensic tool is represented in the assessment of the conversion that is applied between the two duplicated images of one region and located them correctly. Detecting copy-move forgery is not a new approach but using a new clustering approach which has been purposed by using the 2-level clustering strategy based on spatial and transformation domains and any previous information about the investigated image or the number of clusters need to be created is not necessary. Results from different data have been set, proving that the proposed method is able to individuate the altered areas, with high reliability and dealing with multiple cloning.
C1 [Abdel-Basset, Mohamed] Zagazig Univ, Dept Operat Res, Fac Comp & Informat, Zagazig, Egypt.
   [Manogaran, Gunasekaran] VIT Univ, Vellore, Tamil Nadu, India.
   [Fakhry, Ahmed E.] October 6 Univ, Fac Informat Syst & Comp Sci, Cairo, Egypt.
   [El-Henawy, Ibrahim] Zagazig Univ, Comp Sci Dept, Fac Comp & Informat, Zagazig, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Vellore Institute of
   Technology (VIT); VIT Vellore; Egyptian Knowledge Bank (EKB); October 6
   University (O6U); Egyptian Knowledge Bank (EKB); Zagazig University
RP Abdel-Basset, M (corresponding author), Zagazig Univ, Dept Operat Res, Fac Comp & Informat, Zagazig, Egypt.
EM analyst_mohamed@zu.edu.eg; gunvit@gmail.com; a.e.fakluy@gmail.comand;
   ielhenawy@zu.edu.eg
RI Fakhry, Ahmed E/KSL-9541-2024; Abdel-Basset, Mohamed/AAH-2833-2019;
   Manogaran, Gunasekaran/K-7621-2017
OI Fakhry, Ahmed E/0009-0004-0622-8396; Abdel-Basset,
   Mohamed/0000-0003-1102-1387; Manogaran, Gunasekaran/0000-0003-4083-6163;
   abd el aziz, mohamed/0000-0002-7682-6269; Ewees,
   Ahmed/0000-0002-0666-7055; Hassanien, Professor Aboul
   Ella/0000-0002-9989-6681
CR Amerini I, 2014, COPY MOVE FORGERY DE
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], P EUSIPCO ANT TURK
   [Anonymous], P IEEE ICME BEIJ CHI
   [Anonymous], P IEEE CVPR WORKSH S
   [Anonymous], P INT WORKSH INF HID
   [Anonymous], P INT WORKSH INF HID
   [Anonymous], P IEEE W NEW YORK IM
   [Anonymous], P IEEE ICASSP WASH D
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Bashar M, 2018, IEEE T IMAGE PROCESS
   Bravo Solorio S, 2009, P EUSIPCO GLASG SCOT
   Chang, 2004, TECH REP
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Christlein V, 2010, P IEEE WIFS SEATTL W
   Cox I. J., 2002, Digital Watermarking
   FAHIM A, 2009, COMPUT SCI TELECOMMU, P53
   Farid H, 2009, ADV COMPUT, V77, P1, DOI 10.1016/S0065-2458(09)01201-7
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J, 2003, P DFRWS CLEV OH US
   Fridrich Jessica., 2003, P DFRWS
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   KAUR H, 2015, INT J ELECT ELECT CO, V4
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Mohamed Mursi MF, 2017, INT J ADV RES COMPUT, V6
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Singh RD, 2017, FORENSIC SCI INT, V281, P75, DOI 10.1016/j.forsciint.2017.10.028
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Wang J, 2009, P MINES WASH DC US
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
NR 40
TC 70
Z9 74
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5419
EP 5437
DI 10.1007/s11042-018-6266-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500067
DA 2024-07-18
ER

PT J
AU Ferkova, Z
   Urbanova, P
   Cerny, D
   Zuzi, M
   Matula, P
AF Ferkova, Zuzana
   Urbanova, Petra
   Cerny, Dominik
   Zuzi, Marek
   Matula, Petr
TI Age and gender-based human face reconstruction from single frontal image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face reconstruction; Single photo reconstruction; Depth image database;
   Frontal image; Forensic anthropology
ID 3D; SHAPE; MODEL
AB We present an approach for the human face reconstruction from a single frontal image for the use in forensic anthropology when the subject's age and gender is known. In our approach we build a database of several depth images per each age and gender group pair, marked with facial landmarks. To reconstruct a 3D facial model from an unknown frontal image we search the most similar face in the depth database based on the automatically detected landmarks and assign its depth to the model. In the evaluation part, we compared our approach to a recent automatic convolutional neural network based algorithm and a semi-automatic approach, where landmarks are required to be detected manually. In contrast to other tested approaches our algorithm can estimate all major components, such as eyes, nose and mouth, evenly. Thanks to the external depth database, it can also reconstruct human faces from images with partial facial occlusions and uneven lighting. Additionally, we have found that a single depth image provides a good approximation of the human face and a combination of multiple precomputed depth images has a little impact on the final 3D face reconstruction result. Speed measurements show that our algorithm provides a quick and a fully automatic way to reconstruct a human face from a single frontal image for the use in forensic anthropology.
C1 [Ferkova, Zuzana; Zuzi, Marek; Matula, Petr] Masaryk Univ, Dept Visual Comp, Bot 68a, Brno 60200, Czech Republic.
   [Urbanova, Petra; Cerny, Dominik] Masaryk Univ, Dept Anthropol, Kotlarska 2, Brno 60200, Czech Republic.
C3 Masaryk University Brno; Masaryk University Brno
RP Ferkova, Z (corresponding author), Masaryk Univ, Dept Visual Comp, Bot 68a, Brno 60200, Czech Republic.
EM xferkova@mail.muni.cz
RI Urbanova, Petra/AFA-6848-2022; Matula, Petr/L-2119-2013
OI Urbanova, Petra/0000-0001-9321-3360; Matula, Petr/0000-0003-4125-1597;
   Ferkova, Zuzana/0000-0003-2197-7622
CR Adm M.B., 2011, 2011 NATL POSTGRAD C, P1, DOI [10.1109/NatPC.2011.6136297, DOI 10.1109/NATPC.2011.6136297]
   Ahmed A, 2008, IEEE IMAGE PROC, P201, DOI 10.1109/ICIP.2008.4711726
   [Anonymous], P 68 ANN SCI M AM AC
   [Anonymous], 2008, MESHLAB OPEN SOURCE, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   [Anonymous], 1967, ANTROPOLOGIE
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Castelán M, 2009, IET COMPUT VIS, V3, P60, DOI 10.1049/iet-cvi.2008.0060
   Castelan M, 2007, IEEE T IMAGE PROCESS, V16, P1139, DOI 10.1109/TIP.2006.891351
   Cristinacce D., 2007, British Mach. Vision Conf, P880
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Du SY, 2010, J VIS COMMUN IMAGE R, V21, P442, DOI 10.1016/j.jvcir.2010.02.005
   Enlow DH, 1996, ESSENTIALS FACIAL GR, P122
   Evison M, 2010, J FORENSIC SCI, V55, P159, DOI 10.1111/j.1556-4029.2009.01213.x
   Furmanova K, 2017, P 33 SPRING C COMP G, P17, DOI [10.1145/3154353.3154363, DOI 10.1145/3154353.3154363]
   Hassner T., 2006, 2006 C COMP VIS PATT, P15, DOI DOI 10.1109/CVPRW.2006.76
   Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448
   Heo J, 2012, IEEE T INF FOREN SEC, V7, P563, DOI 10.1109/TIFS.2012.2184755
   Hu YX, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P843
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Jandova M., 2016, ANTHROPOL REV, V79, P181, DOI [DOI 10.1515/anre-2016-0014, 10.1515/anre-2016-0014]
   Jiang DL, 2005, PATTERN RECOGN, V38, P787, DOI 10.1016/j.patcog.2004.11.004
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z
   Kemelmacher I, 2006, LECT NOTES COMPUT SC, V3951, P277
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Klare BF, 2012, IEEE T INF FOREN SEC, V7, P1789, DOI 10.1109/TIFS.2012.2214212
   Loop CT, 1987, THESIS
   Ning ZT, 2014, 2014 INTERNATIONAL CONFERENCE ON SMART COMPUTING WORKSHOPS (SMARTCOMP WORKSHOPS), P48
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Reiter M, 2006, INT C PATT RECOG, P425
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Saeed A, 2018, MULTIMED TOOLS APPL, V77, P2261, DOI 10.1007/s11042-016-4261-x
   Segundo MP, 2012, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2012.6467230
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   TIBCO Software Inc, 2017, Statistica (Data Analysis Software System)
   URBANOVA P, 2018, ANTHROPOL REV, V81, P202, DOI DOI 10.2478/anre-2018-0016
   Urbanova P., 2016, Egyp. J. Foren. Sci., V6, P135, DOI [10.1016/j.ejfs.2016.04.004, DOI 10.1016/J.EJFS.2016.04.004]
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wang CH, 2004, LECT NOTES COMPUT SC, V3332, P553
   Zeng D, 2017, IMAGE VISION COMPUT, V58, P193, DOI 10.1016/j.imavis.2016.03.001
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 44
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3217
EP 3242
DI 10.1007/s11042-018-6869-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700009
DA 2024-07-18
ER

PT J
AU Liu, YZ
   Gu, XY
   Huang, L
   Ouyang, JL
   Liao, M
   Wu, LR
AF Liu, Yizhi
   Gu, Xiaoyan
   Huang, Lei
   Ouyang, Junlin
   Liao, Miao
   Wu, Liangran
TI Analyzing periodicity and saliency for adult video detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based pornography detection; Multimodal fusion; Semantic
   representation; Periodicity analysis; Saliency analysis
ID COHERENT
AB Content-based adult video detection plays an important role in preventing pornography. However, existing methods usually rely on single modality and seldom focus on multi-modality semantics representation. Addressing at this problem, we put forward an approach of analyzing periodicity and saliency for adult video detection. At first, periodic patterns and salient regions are respectively analyzed in audio-frames and visual-frames. Next, the multi-modal co-occurrence semantics is described by combining audio periodicity with visual saliency. Moreover, the performance of our approach is evaluated step by step. Experimental results show that our approach obviously outperforms some state-of-the-art methods.
C1 [Liu, Yizhi; Ouyang, Junlin; Liao, Miao; Wu, Liangran] Hunan Univ Sci & Technol, Coll Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Gu, Xiaoyan] Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
   [Huang, Lei] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266100, Shandong, Peoples R China.
C3 Hunan University of Science & Technology; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS; Ocean University of China
RP Gu, XY (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
EM guxiaoyan@iie.ac.cn
CR [Anonymous], 2006, The 3rd European Conference on Visual Media Production (CVMP 2006)-Part of the 2nd Multimedia Conference 2006, IET, DOI DOI 10.1049/CP:20061978
   [Anonymous], P 6 AS C COMP VIS JU
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Borji A., 2017, COMPUT VIS IMAGE UND, P1
   Borji A, 2014, IEEE T IMAGE PROCESS, P1
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   Chen ZN, 2019, MULTIMEDIA SYST, V25, P1, DOI 10.1007/s00530-017-0544-y
   Deselaers T, 2008, PROC CVPR IEEE, P3017
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Endeshaw T., 2008, P 37 APPL IM PATT RE
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   H Xie, 2018, ACM T MULTIMED COMPU
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Jiang HB, 2015, ISME J, V9, P297, DOI 10.1038/ismej.2014.123
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kim CY, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1435
   Kuan YH, 2004, INT C IM SCI SYST TE
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Lee H, 2006, 8TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1-3, pU959
   Li PJ, 2010, TEXTILE BIOENGINEERING AND INFORMATICS SYMPOSIUM PROCEEDINGS, VOLS 1-3, P316, DOI 10.3993/tbis2010054
   Li Y, 2014, PR IEEE COMP DESIGN, P521, DOI 10.1109/ICCD.2014.6974732
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu W, 2017, J VIS COMMUN IMAGE R, V48, P502, DOI 10.1016/j.jvcir.2017.01.010
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu YZ, 2014, FUTURE GENER COMP SY, V31, P69, DOI 10.1016/j.future.2012.08.012
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171
   Moreira D, 2019, INFORM FUSION, V45, P307, DOI 10.1016/j.inffus.2018.03.001
   Ouyang J., 2018, MULTIMED TOOLS APPL, P1
   Ouyang JL, 2017, MULTIMED TOOLS APPL, V76, P2609, DOI 10.1007/s11042-015-3225-x
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Phan S, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1255, DOI 10.1145/2733373.2806330
   Qing-Fang Zheng, 2004, Proceedings. Third International Conference on Image and Graphics, P150
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   TANG S, 2009, INT C MULT, P1003
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JM, 2009, IEEE IMTC P, P845
   Wang Yu-shi, 2008, Transactions of Beijing Institute of Technology, V28, P410
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Xia C., 2017, PROC CVPR IEEE, P4142, DOI DOI 10.1109/CVPR.2017.468
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie HT, 2011, IEEE T MULTIMEDIA, V13, P1319, DOI 10.1109/TMM.2011.2167224
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Y Cheng, 2014, P IEEE INT C COMP VI
   Yan CC, 2014, J VIS COMMUN IMAGE R, V25, P1130, DOI 10.1016/j.jvcir.2014.03.005
   Yizhi Liu, 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P404, DOI 10.1109/ICCIT.2009.5407272
   Yoo SJ, 2004, LECT NOTES COMPUT SC, V3213, P164
   Z Chen, 2019, ACM T MULTIMEDIA COM
   Zeng Z, 2009, IEEE INT CON MULTI, P486, DOI 10.1109/ICME.2009.5202540
   Zhao D, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1185, DOI 10.1109/ICME.2008.4607652
   Zuo HQ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P37, DOI 10.1109/ICME.2008.4607365
NR 55
TC 4
Z9 4
U1 7
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4729
EP 4745
DI 10.1007/s11042-019-7576-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500027
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nazari, M
   Dorostkar Ahmadi, I
AF Nazari, Mahboubeh
   Dorostkar Ahmadi, Iman
TI A novel chaotic steganography method with three approaches for color and
   grayscale images based on FIS and DCT with flexible capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Discrete Cosine Transform; Human Visual System;
   Fuzzy Inference System; Chaotic map; high capacity; color image;
   grayscale image
ID DIGITAL IMAGE; HIDING DATA; WATERMARKING; SCHEME; JPEG; AUTHENTICATION;
   STEGANALYSIS; VISIBILITY; FRAMEWORK
AB In this paper, a new chaotic steganography method based on Fuzzy Inference System (FIS), using Discrete Cosine Transform (DCT) on color and grayscale images is proposed. The proposed algorithm is designed in three different approaches to have important factors of robustness, imperceptibility, and transparency with respect to applications. In order to achieve this goal, important parameters in the Human Visual System (HVS), such as texture and luminance, using DCT coefficients are computed. For more precision and flexibility in selecting host blocks for embedding, FIS system is used. Due to the importance of robustness and transparency in different applications, the best target host blocks are intelligently determined using the degree defined in the fuzzy system. This flexibility greatly enhances the efficiency of the algorithm in various using goals. One of the outstanding aspects of the proposed method is error controlling with increasing capacity. At first, embedding is done on middle frequency (MF) then to increase the capacity, coefficients in high frequency are also considered with two different zigzag scanning directions in selection, middle to high (MHF) and high to middle (HMF). The ordering selection of different color channels (for color image), blocks, coefficients in embedding phase, and encryption algorithm of secret message are done by chaotic sequences which has a positive impact on security level. Providing an efficient integration technique (synchronization) in the number of coefficients of each block leads to increasing the security of the proposed method. One of best novelty which causes decreasing bit error rate (BER) beside increasing capacity, is approximating of the distortion during DCT and IDCT operations in embedding phase. The experimental results demonstrate that high level of transparency and robustness for MF, and if more capacity is needed, although both algorithms HMF and MHF have desirable results, but HMF provides higher level of transparency and MHF more robustness against noises and attacks which can be used with respect to applications.
C1 [Nazari, Mahboubeh; Dorostkar Ahmadi, Iman] Imam Reza Int Univ, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
RP Dorostkar Ahmadi, I (corresponding author), Imam Reza Int Univ, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM ma.am.math@gmail.com; idorostkarahmadi@gmail.com
OI dorostkar ahmadi, iman/0000-0002-7791-691X
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   [Anonymous], 2014, ARXIV14056147
   [Anonymous], 1999, IMAGE VIDEO COMPRESS
   Artz D, 2001, IEEE INTERNET COMPUT, V5, P75, DOI 10.1109/4236.935180
   Baig F, 2016, NONLINEAR DYNAM, V84, P1431, DOI 10.1007/s11071-015-2580-5
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chowdhuri P., 2018, INT J COMPUT APPL, V43, P1, DOI DOI 10.1080/1206212X.2018.1505024
   Dande SC, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1466, DOI 10.1109/ICCSP.2016.7754401
   Darshni P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P269, DOI 10.1109/CICT.2015.82
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   El Rahman SA, 2018, COMPUT ELECTR ENG, V70, P380, DOI 10.1016/j.compeleceng.2016.09.001
   Fan L, 2013, COMPUT ELECTR ENG, V39, P873, DOI 10.1016/j.compeleceng.2012.06.014
   Fridrich J., 2009, INFORM HIDING
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jagadeesh B, 2016, SOFT COMPUT, V20, P3679, DOI 10.1007/s00500-015-1729-y
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kumar S, 2019, DEF TECHNOL, V15, P162, DOI 10.1016/j.dt.2018.08.003
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Lou Der-Chyuan, 2008, J CCIT, V37, P151
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Morkel T., 2005, ISSA, V1, P1
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Nazari M, 2016, MULTIMED TOOLS APPL, P1
   Nikooghadam M, 2017, MULTIMED TOOLS APPL, V76, P13401, DOI 10.1007/s11042-016-3704-8
   Oueslati S., 2010, Int J Image Process, V4, P218
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sajedi H, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P379, DOI 10.1109/CIT.2008.Workshops.34
   Sakr N., 2005, 2005 IEEE International Workshop on Haptic Audio Visual Environments and thier Applications (IEEE Cat. No.05EX1164C)
   Silman J., 2001, STEGANOGRAPHY STEGAN, V3, P61
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Suchitra B, 2013, INT J ADV RES COMPUT, V2
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Vanmathi C, 2018, INT J FUZZY SYST, V20, P460, DOI 10.1007/s40815-017-0420-0
   Walia Ekta., 2010, Global Journal of Computer Science and Technology, V10
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CN, 2018, J REAL-TIME IMAGE PR, V14, P147, DOI 10.1007/s11554-015-0555-x
   Yi-zhen Chen, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1151, DOI 10.1109/CISP.2010.5646724
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   [No title captured]
NR 49
TC 12
Z9 13
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13693
EP 13724
DI 10.1007/s11042-019-08415-1
EA FEB 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510371400003
DA 2024-07-18
ER

PT J
AU Prabha, KR
   Jagadeeswari, M
AF Prabha, K. R.
   Jagadeeswari, M.
TI Enhanced imperialist competitive algorithm based efficient reversible
   data hiding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data compression; Data hiding; DCT; BWT; EICA; VQ; SMVQ
ID IMAGE; VIDEO
AB This paper presents a novel reversible data hiding into a Vector Quantization (VQ) and Side Match Vector Quantization (SMVQ) based compression image to embed high capacity secret bits and recover cover image after data extraction. For optimal embedding capacity and to achieve exact recovery of cover image, this paper uses Enhanced Imperialist Competitive Algorithm (EICA). The threshold value is determined by the fitness function contrast sensitivity in EICA in order to signify embedding rate of each region in a cover image based on the size of the secret message. During data hiding, the output size of code stream is preserved in hiding two secret bits into a single index value. Discrete Cosine Transform (DCT) and Burrows Wheeler Transform (BWT) is applied before quantization for exact recovery of cover image and to achieve high compression ratio. Excellent energy compaction is provided by DCT and BWT reorders the symbols according to their context. Thus the proposed method provides a novel technique to embed secret bits into the cover image and compresses the embedded image. The output will be in the form of code streams with preserved size. The experimental results show that the proposed technique achieves high embedding capacity and compression rate.
C1 [Prabha, K. R.; Jagadeeswari, M.] Sri Ramakrishna Engn Coll, Dept Elect & Commun Engn, Coimbatore 641022, Tamil Nadu, India.
C3 Sri Ramakrishna Engineering College
RP Prabha, KR (corresponding author), Sri Ramakrishna Engn Coll, Dept Elect & Commun Engn, Coimbatore 641022, Tamil Nadu, India.
EM prabhaaa34@yahoo.com
CR Bansal P., 2007, ASIAN J INFORM TECHN, V6, P938
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Goswami P, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2012-002183
   Hou DD, 2018, IEEE T IMAGE PROCESS, V27, P5087, DOI 10.1109/TIP.2018.2851074
   Huang CT, 2013, IMAGING SCI J, V61, P195, DOI 10.1179/1743131X11Y.0000000031
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Laskar S. A., 2012, INT J-TORONTO
   Lin JL, 2012, ALGORITHMS, V5, P433, DOI 10.3390/a5040433
   Moreno-Trejo J, 2012, INT J SYST ASSUR ENG, V3, P6, DOI 10.1007/s13198-012-0090-0
   Ni Z. C., 2004, IEEE INT C MULT EXP, V3, P2199
   Nimse Madhuri S, 2014, INT J INNOVATIVE RES, V1
   Prabha KR, 2017, J COMPUT THEOR NANOS, V14, P1, DOI [10.1166/jctn.2017.6673, DOI 10.1166/JCTN.2017.6673]
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Sathish M, 2014, RES J APPL SCI, V9, P511
   Si Van V, 2009, THESIS
   Tseng HW, 2004, INFORMATICA-LITHUAN, V15, P127
   Tyagi V., 2012, INT J ADV RES COMPUT, V2, P120
   VARSAKI E, 2006, HELLENIC OPEN U J IN, V1
   Wang WJ, 2011, IEEE SYST J, V5, P528, DOI 10.1109/JSYST.2011.2165603
   Wang Z, 2010, ENCODING METHOD BOTH
   Wazirali R, 2015, J NETWORKS, V10
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Yang HF, 2009, RADIOENGINEERING, V18, P509
   Yih-Chuan Lin, 2011, Journal of Multimedia, V6, P349, DOI 10.4304/jmm.6.4.349-358
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
NR 27
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4057
EP 4074
DI 10.1007/s11042-019-07772-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700054
DA 2024-07-18
ER

PT J
AU Rida, I
   Al-Maadeed, N
   Al-Maadeed, S
   Bakshi, S
AF Rida, Imad
   Al-Maadeed, Noor
   Al-Maadeed, Somaya
   Bakshi, Sambit
TI A comprehensive overview of feature representation for biometric
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Feature representation; Dimensionality reduction; Feature
   selection; Decomposition learning
ID DIMENSIONALITY REDUCTION; FEATURE-SELECTION; PRESERVING PROJECTIONS;
   SPARSE REPRESENTATION; MUTUAL INFORMATION; GROUP LASSO; CLASSIFICATION;
   REGRESSION; ALGORITHM; MODEL
AB The performance of any biometric recognition system heavily dependents on finding a good and suitable feature representation space where observations from different classes are well separated. Unfortunately, finding this proper representation is a challenging problem which has taken a huge interest in machine learning and computer vision communities. In the this paper we present a comprehensive overview of the different existing feature representation techniques. This is carried out by introducing simple and clear taxonomies as well as effective explanation of the prominent techniques. This is intended to guide the neophyte and provide researchers with state-of-the-art approaches in order to help advance the research topic in biometrics.
C1 [Rida, Imad; Al-Maadeed, Noor; Al-Maadeed, Somaya] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
   [Bakshi, Sambit] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, India.
C3 Qatar University; National Institute of Technology (NIT System);
   National Institute of Technology Rourkela
RP Rida, I (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
EM rida.imad@gmail.com; n.alali@qu.edu.qa; s_alali@qu.edu.qa;
   sambitbaksi@gmail.com
RI Bakshi, Sambit/JDC-3355-2023; Rida, Imad/AAA-5044-2022
OI Bakshi, Sambit/0000-0002-6107-114X; Rida, Imad/0000-0003-2789-5070;
   Al-maadeed, Somaya/0000-0002-0241-2899
CR Al Maadeed S, 2019, MULTIMED TOOLS APPL, V78, P5665, DOI 10.1007/s11042-018-5655-8
   Amari S, 1999, NEURAL COMPUT, V11, P1875, DOI 10.1162/089976699300015990
   [Anonymous], 2013, SIN 13, DOI DOI 10.1145/2523514.2523597
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   [Anonymous], 2011, ARXIV11064199
   [Anonymous], TECHNICAL REPORT
   Archibald R, 2007, IEEE GEOSCI REMOTE S, V4, P674, DOI 10.1109/LGRS.2007.905116
   Bach FR, 2008, J MACH LEARN RES, V9, P1179
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bellet A., 2013, SURVEY METRIC LEARNI
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bishop Christopher M., 2006, Machine Learning, V128, P9
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen XJ, 2018, IEEE T NEUR NET LEAR, V29, P6362, DOI 10.1109/TNNLS.2018.2830186
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506
   de Ridder Dick, 2002, LECT NOTES COMPUTER, P587
   Diamant I, 2017, IEEE T BIO-MED ENG, V64, P1380, DOI 10.1109/TBME.2016.2605627
   Dijkstra E., 1959, NUMER MATH, V1, P269, DOI [DOI 10.1007/BF01386390, 10.1007/bf01386390]
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Eshelman LarryJ., 2014, FDN GENETIC ALGORITH, V1, P265, DOI DOI 10.1016/B978-0-08-050684-5.50020-3
   Evgeniou T, 2002, COMPUT STAT DATA AN, V38, P421, DOI 10.1016/S0167-9473(01)00069-X
   Fan MY, 2017, AAAI CONF ARTIF INTE, P1870
   Fei LK, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500206
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Goldberg DavidEdward., 1989, Genetic algorithms in search, optimization, V412
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hastie T., 2009, The Elements of Statistical Learning
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Huan Liu, 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P319
   Hyvarinen A., 2004, INDEPENDENT COMPONEN
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Jimenez LO, 1998, IEEE T SYST MAN CY C, V28, P39, DOI 10.1109/5326.661089
   John G.H., 1994, P 11 INT C MACH LEAR, P121
   Joho M., 2000, Second International Workshop on Independent Component Analysis and Blind Signal Separation. Proceedings, P81
   Journée M, 2010, J MACH LEARN RES, V11, P517
   Kao YH, 2013, MACH LEARN, V91, P279, DOI 10.1007/s10994-013-5345-8
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Kong S, 2012, ARXIV12056544
   Langley Pat., 1994, SELECTION RELEVANT F
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Lazar C, 2012, IEEE ACM T COMPUT BI, V9, P1106, DOI 10.1109/TCBB.2012.33
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Luo M., 2016, P 25 INT JOINT C ART
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Luo MN, 2017, NEURAL COMPUT, V29, P1124, DOI 10.1162/NECO_a_00937
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal Julien, 2014, ARXIV14113230
   Mukherjee S, 2003, LECT NOTES STAT, V171, P111
   NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Platt JC, 2000, ADV NEUR IN, P61
   Ramirez I., 2010, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2010.5539964, 10.1109/CVPR.2010.5539964]
   Rida I, 2019, IET BIOMETRICS, V8, P14, DOI 10.1049/iet-bmt.2018.5063
   Rida I, 2019, PATTERN RECOGN LETT, V126, P21, DOI 10.1016/j.patrec.2018.04.033
   Rida I, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2047, DOI 10.1109/ICASSP.2018.8462051
   Rida I, 2018, IEEE ACCESS, V6, P3241, DOI 10.1109/ACCESS.2017.2787666
   Rida I, 2017, SIGNAL PROC SEC TEC, P141, DOI 10.1007/978-3-319-47301-7_6
   Rida I, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P652, DOI 10.1109/TSP.2016.7760963
   Rida I, 2015, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2015.7362559
   Rida I, 2016, IEEE SIGNAL PROC LET, V23, P154, DOI 10.1109/LSP.2015.2507200
   Rida I, 2016, SIGNAL IMAGE VIDEO P, V10, P463, DOI 10.1007/s11760-015-0766-4
   Rida I, 2015, LECT NOTES COMPUT SC, V9280, P119, DOI 10.1007/978-3-319-23234-8_12
   Rida I, 2014, INT C MICROELECTRON, P40, DOI 10.1109/ICM.2014.7071801
   Rida I, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P336, DOI 10.1109/ICMLA.2014.60
   Roweis S, 1998, ADV NEUR IN, V10, P626
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salakhutdinov R., 2009, AISTATS
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Scholkopf B., 2002, Learning with Kernels
   Silva V., 2002, NIPS, P721
   Spearman C, 1904, AM J PSYCHOL, V15, P201, DOI 10.2307/1412107
   Subrahmanya N, 2010, IEEE T PATTERN ANAL, V32, P788, DOI 10.1109/TPAMI.2009.98
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Theis TJ, 2004, NEUROCOMPUTING, V56, P381, DOI 10.1016/j.neucom.2003.09.008
   Tibshirani R, 2005, J R STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   vander Maaten L., 2009, J MACH LEARN RES, V10, P13, DOI [10.1080/13506280444000102, DOI 10.1080/13506280444000102]
   Verleysen M, 2005, LECT NOTES COMPUT SC, V3512, P758
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Wang S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003729
   Wang S, 2016, IEEE T KNOWL DATA EN, V28, P3191, DOI 10.1109/TKDE.2016.2605687
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Welling M, 2004, IEEE T NEURAL NETWOR, V15, P838, DOI 10.1109/TNN.2004.828765
   Weston J., 2003, Journal of Machine Learning Research, V3, P1439, DOI 10.1162/153244303322753751
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu L, 2017, IEEE T CYBERNETICS, V47, P4497, DOI 10.1109/TCYB.2016.2612686
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729
   Zhang LQ, 1999, IEEE SIGNAL PROC LET, V6, P293, DOI 10.1109/97.796292
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 113
TC 48
Z9 48
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4867
EP 4890
DI 10.1007/s11042-018-6808-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500035
DA 2024-07-18
ER

PT J
AU Zhang, F
   Zhang, K
AF Zhang, Feng
   Zhang, Kai
TI Superpixel guided structure sparsity for multispectral and hyperspectral
   image fusion over couple dictionary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure sparse; Superpixel; Couple dictionary; Hyperspectral;
   Multispectral; Image fusion
ID DECOMPOSITION; ALGORITHM; QUALITY
AB This paper proposed a hyperspectral (HS) and multispectral (MS) image fusion method based on superpixel guided structure sparsity and couple dictionary (SGSSCD). It is assumed that the pixels in a homogeneous area of MS image are similar due to the consistent spatial consistency. Superpixel technique is used to find the similar pixels in MS image by considering the region homogeneity. Then these pixels naturally share the same atoms in low spectral resolution dictionary. In order to capture the similarity prior, structural sparsity is employed to find more efficient coding of the similar pixels in MS image over low spectral resolution dictionary. Finally, high spatial resolution HS image can be produced by combining the codes of MS image with high spectral resolution dictionary. Besides, the couple dictionary is learned from HS and low spatial resolution MS images to ensure the spectral correspondence, which can further improve the quality of fusion results. The experimental results on different datasets demonstrate the effectiveness of the proposed method when compared with some existing methods.
C1 [Zhang, Feng; Zhang, Kai] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Feng] China Mobile Online Serv Co Ltd, Zhengzhou 450000, Henan, Peoples R China.
C3 Shandong Normal University
RP Zhang, K (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM 2428902470@qq.com
RI Zhang, Kai/HWQ-4396-2023
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aiazzi B, 2009, IEEE GEOSCI REMOTE S, V6, P302, DOI 10.1109/LGRS.2008.2012003
   Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986
   Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5
   Amro I, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-79
   Anderson J, 1991, Photogramm. Eng. Remote Sens, V57, P265
   Ankarao V, 2018, MULTIMED TOOLS APPL, V77, P30381, DOI 10.1007/s11042-018-6114-2
   [Anonymous], MULTIM TOOLS APPL
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chen HY, 2012, MULTIMED TOOLS APPL, V60, P495, DOI 10.1007/s11042-011-0820-3
   Chen Z, 2014, IEEE GEOSCI REMOTE S, V11, P1418, DOI 10.1109/LGRS.2013.2294476
   CONN AR, 1991, SIAM J NUMER ANAL, V28, P545, DOI 10.1137/0728030
   Hancock GR, 2001, EDUC PSYCHOL MEAS, V61, P741, DOI 10.1177/00131640121971491
   Kanmani M, 2016, MULTIMED TOOLS APPL, V20, P1
   Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457
   KUNKEL B, 1991, INT J REMOTE SENS, V12, P753, DOI 10.1080/01431169108929691
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lin BH, 2018, IEEE ACCESS, V6, P16901, DOI 10.1109/ACCESS.2018.2817071
   Mangalraj P., 2017, MULTIMED TOOLS APPL, P1
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Nasrabadi NM, 2014, IEEE SIGNAL PROC MAG, V31, P34, DOI 10.1109/MSP.2013.2278992
   Nezhad ZH, 2016, IEEE J-STARS, V9, P2377, DOI 10.1109/JSTARS.2016.2528339
   Schweizer SM, 2001, IEEE T IMAGE PROCESS, V10, P584, DOI 10.1109/83.913593
   Selva M, 2017, IEEE J-STARS, V6, P3008
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730
   Veganzones MA, 2016, IEEE T IMAGE PROCESS, V25, P274, DOI 10.1109/TIP.2015.2496263
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wald L., 2000, 3 C FUS EARTH DAT ME, P99
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei J, 2017, ROYAL SOC OPEN SCI, V4, P1
   Wei Q, 2015, IEEE T IMAGE PROCESS, V11, P1632
   Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Yuhas R., 1992, SUMMARIES 4 ANN JPL, P147
   Zhang K, 2018, IEEE J-STARS, V11, P1030, DOI 10.1109/JSTARS.2017.2785411
   Zhang K, 2017, IEEE T GEOSCI REMOTE, V55, P1363, DOI 10.1109/TGRS.2016.2623626
   Zhu XX, 2016, IEEE T GEOSCI REMOTE, V54, P2664, DOI 10.1109/TGRS.2015.2504261
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 44
TC 13
Z9 13
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4949
EP 4964
DI 10.1007/s11042-019-7188-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500039
DA 2024-07-18
ER

PT J
AU Zhang, YY
   Shen, ZJ
   Liu, SH
AF Zhang, Yuanyi
   Shen, Zhenjiang
   Liu, Shuhu
TI Virtual reality with the integrated automatic presentation scrip for
   improving concepts understanding of Urban Design-a case study in Tatsumi
   region of Tokyo Bay zone, Japan
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urban design; Automatic presentation script; Concepts understanding;
   Virtual environment
ID SPACE; TOOLS
AB Urban environment is the place that human depends on to survive. The quality of urban design concepts will directly impact the change of urban environment. However, due to the lack of user interaction and clear information exchange between users and designers, it is difficult for users to understand urban design concepts, and sometimes even misunderstanding will be caused. Thus, the present paper seeks to improve users' understanding of urban design concepts via available communication media and using useful presentation technology (VR with the integrated APS). In this research, we recruited 60 participants to view the script video (the running result of APS) or/and free navigate in the virtual environment of Tatsumi region, Tokyo Bay Zone, Japan. By studying the data of subjective feedbacks, we investigated how APS impacts participants' cognition and evaluation of Sustainable Taches and Reactivate Space (STARS, the design concepts). Furthermore, qualitative interview was developed to further understand participants' design concepts understanding and to verify whether VR with the integrated APS can improve users' understanding of urban design concepts. Results from this research explains the future use of VR with the integrated APS technology as an efficient tool in urban design schemes presentation.
C1 [Zhang, Yuanyi; Shen, Zhenjiang; Liu, Shuhu] Fuzhou Univ, Sch Architecture, Fuzhou, Peoples R China.
   [Zhang, Yuanyi; Shen, Zhenjiang] Kanazawa Univ, Sch Environm Design, Kanazawa, Ishikawa, Japan.
C3 Fuzhou University; Kanazawa University
RP Zhang, YY (corresponding author), Fuzhou Univ, Sch Architecture, Fuzhou, Peoples R China.; Zhang, YY (corresponding author), Kanazawa Univ, Sch Environm Design, Kanazawa, Ishikawa, Japan.
EM 12001445@qq.com
RI Shen, Zhenjiang/J-7979-2015; Zhang, Yuanyi/IQT-3678-2023
OI Shen, Zhenjiang/0000-0002-0417-5962; Zhang, Yuanyi/0000-0003-0314-7481;
   zhang, yuanyi/0000-0001-8957-2846
CR Abdelhameed WA, 2012, INT J ARCHIT COMPUT, V10, P205, DOI 10.1260/1478-0771.10.2.205
   [Anonymous], 2016, ARXIV161009462
   Biljecki F, 2015, ISPRS INT GEO-INF, V4, P2842, DOI 10.3390/ijgi4042842
   Brockmeier J, 2010, CULT PSYCHOL, V16, P5, DOI 10.1177/1354067X09353212
   Conniff A, 2010, DESIGN STUD, V31, P419, DOI 10.1016/j.destud.2010.04.003
   Davis A., 2019, The Open Nutrition Journal, V9, P65, DOI [10.2174/1876396001509010065, DOI 10.2174/1876396001509010065]
   Ding S., 2008, Engineering Design Graphics Journal, V72, P1
   Fares F, 2018, ALEX ENG J, V57, P1821, DOI 10.1016/j.aej.2017.07.010
   Grossman Thomas A., 2009, INFORMS Transactions on Education, V10, P18, DOI 10.1287/ited.1090.0027
   Hasebrink Uwe., 2012, Participations, Journal of Audience and Reception Studies, V9, P757, DOI DOI 10.5325/JINF0P0LI.1.2011.0321
   He M., 2014, The Reading Matrix, V14, P16
   Joseph R, 2013, INT J ENG SCI EMERG, V6, P258
   Jutraz A, 2015, LECT NOTES GEOINF CA, P391, DOI 10.1007/978-3-319-18368-8_21
   Kameda M., 2013, JAPAN TIMES
   Liu LA, 2012, ADMIN SCI QUART, V57, P269, DOI 10.1177/0001839212453456
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Lv ZH, 2018, MULTIMED TOOLS APPL, V77, P10077, DOI 10.1007/s11042-017-5119-6
   McTague C, 2013, APPL GEOGR, V44, P182, DOI 10.1016/j.apgeog.2013.07.019
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Okazaki H, 2012, CALL USING LEARNING, P228
   Paes D, 2017, AUTOMAT CONSTR, V84, P292, DOI 10.1016/j.autcon.2017.09.016
   Phan V. T., 2010, INT J COMPUT APPL, V4, P26, DOI [10.5120/809-1149, DOI 10.5120/809-1149]
   R Banai, 2010, EDUCATION
   Rahim N., 2013, INT J MULTIMEDIA ITS, V5, P17, DOI DOI 10.5121/IJMA.2013.5502
   Revers M, 2015, INT ENCY SOCIAL BEHA, P133
   Roberts M, 2014, APPROACHING URBAN DE, V5
   Roupé M, 2014, COMPUT ENVIRON URBAN, V43, P42, DOI 10.1016/j.compenvurbsys.2013.10.003
   S Felasari, 2012, SUPPORTING URBAN DES
   Sampaio AZ, 2010, OPEN VIRT REAL J, V88, P285
   Schaffer J, 2018, INT J HUM-COMPUT ST, V113, P1, DOI 10.1016/j.ijhcs.2018.01.002
   Shakibamanesh A, 2014, EVENING STANDARD
   Siemens G., 2005, Connectivism: learning as network creation
   Steven BG, 2010, THOUGHTS DEV DESIGN
   T Ohno, 2014, 2020 TOKYO OLYMPICS
   Tan Christine L., 2015, Pharmacy Pract (Granada), V13, DOI 10.18549/PharmPract.2015.03.598
   Tavakol M, 2011, INT J MED EDUC, V2, P53, DOI 10.5116/ijme.4dfb.8dfd
   Turner DW III, 2010, QUAL REP, V15, P754
   van der Land S, 2013, COMPUT HUM BEHAV, V29, P1054, DOI 10.1016/j.chb.2012.09.006
   Wong TC, 2011, ECO-CITY PLANNING- POLICIES, PRACTICE AND DESIGN, P1, DOI 10.1007/978-94-007-0383-4
   Wu HY, 2010, COMPUT ENVIRON URBAN, V34, P291, DOI 10.1016/j.compenvurbsys.2009.12.001
   Yang X, 2015, BUILDINGS, V5, P1302, DOI 10.3390/buildings5041302
   Yesilbek KT, 2017, COMPUT GRAPH-UK, V69, P80, DOI 10.1016/j.cag.2017.08.016
   Zhang YY, 2017, INT REV SPAT PLAN SU, V5, P29, DOI 10.14246/irspsd.5.1_29
NR 43
TC 7
Z9 7
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3125
EP 3144
DI 10.1007/s11042-018-6588-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700005
DA 2024-07-18
ER

PT J
AU Kaur, B
   Singh, D
   Roy, PP
AF Kaur, Barjinder
   Singh, Dinesh
   Roy, Partha Pratim
TI A study of EEG for enterprise multimedia security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Electroencephalogram (EEG); Brain computer interface (BCI);
   Multimedia security
ID AUTHENTICATION; SIGNALS; IDENTIFICATION; FRAMEWORK; SYSTEM
AB In this era of technological advancement the security of one's own identity to access multimedia content have become a major concern for big enterprises. The traditional security mechanisms like PIN numbers, ID cards, passwords, etc., can be easily divulged by the intruders. User identification using these traditional approaches is prone to various security threats. Thus, a robust security system is required to deal with the security issues for user identification and verification before providing access to the multimedia. Recently, the use of Electroencephalogram (EEG) signals as a biometric trait has opened novel ways for the development of various Brain-Computer-Interface (BCI) based applications. Due to the inherent nature of uniqueness in every individual, EEG signals are considered as a robust alternate for biometric systems. In this paper, we perform a detailed review of EEG based security techniques to investigate its robustness in securing enterprise related multimedia contents.
C1 [Kaur, Barjinder; Singh, Dinesh] DCRUST, Dept Comp Sci & Engn, Sonipat 131039, India.
   [Roy, Partha Pratim] IIT Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kaur, B (corresponding author), DCRUST, Dept Comp Sci & Engn, Sonipat 131039, India.
EM kaur.barjinder@gmail.com; Dineshsingh.cse@dcrust.org;
   proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/AAV-9061-2020; Roy, Partha Pratim/AAW-2994-2020; Roy,
   Partha Pratim/GPF-4253-2022; singh, dinesh/AAB-4046-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; singh,
   dinesh/0000-0002-7614-5789
CR Abbas SN, 2017, SIGNAL PROC SEC TEC, P121, DOI 10.1007/978-3-319-47301-7_5
   ABDULKADER SN, 2015, LECT NOTES COMPUTER, P3
   Abo-Zahhad M, 2016, PATTERN RECOGN LETT, V82, P216, DOI 10.1016/j.patrec.2015.07.034
   Altahat S, 2015, LECT NOTES COMPUT SC, V9492, P162, DOI 10.1007/978-3-319-26561-2_20
   [Anonymous], 2008, BCI competition 2008-Graz data set B
   [Anonymous], 2009, INT J BIOMEDICAL SOF
   Ashby C, 2011, I IEEE EMBS C NEUR E, P442, DOI 10.1109/NER.2011.5910581
   Baietti A, 2012, WOR BANK STUD, P1, DOI 10.1596/978-0-8213-9488-5
   BOOKER LB, 1989, ARTIF INTELL, V40, P235, DOI 10.1016/0004-3702(89)90050-7
   Brigham K, 2010, INT CONF BIOINFORM
   Brunner C, 2008, TRANS DISTRIB CONF, P1342
   Campbell P, 2011, INT J CULT POLICY, V17, P510, DOI 10.1080/10286632.2010.543461
   Chang V, 2017, 2017 INT C ENG TECHN, P1
   Chang V, 2018, NEURAL COMPUT APPL, V29, P1243, DOI 10.1007/s00521-017-3000-1
   Cheng IL, 2016, IEEE INT CONF ADV LE, P493, DOI 10.1109/ICALT.2016.64
   Cho H, 2017, GIGASCIENCE, V6, P1, DOI 10.1093/gigascience/gix034
   Chuang J, 2013, LECT NOTES COMPUT SC, V7862, P1, DOI 10.1007/978-3-642-41320-9_1
   Das BB, 2019, MULTIMED TOOLS APPL, V78, P28157, DOI 10.1007/s11042-019-07905-6
   De Vico FF, 2011, IEEE ENG MED BIO, P2331, DOI 10.1109/IEMBS.2011.6090652
   Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808
   El-Fiqi H, 2018, IEEE SYS MAN CYBERN, P1062, DOI 10.1109/SMC.2018.00188
   Garcia-Salicetti S., 2003, Audio-and Video-Based Biometric Person Authentication, P1056
   Gauba H, 2017, NEURAL NETWORKS, V92, P77, DOI 10.1016/j.neunet.2017.01.013
   Gui Q, 2014, IEEE SIG PROC MED
   Gupta A, 2019, J GRID COMPUT, V17, P325, DOI 10.1007/s10723-018-9462-2
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta Cota Navin, 2012, International Journal of Cognitive Biometrics, V1, P26, DOI 10.1504/IJCB.2012.046513
   HAJARE MP, 2016, INT J RES ENG, V3, P18
   Hettich S., 1999, UCI KDD ARCH, P152
   Hunter M, 2005, CLIN EEG NEUROSCI, V36, P76, DOI 10.1177/155005940503600206
   ISHIKAWA Y, 2014, INT C PAR DISTR PROC, P1
   Karyotis C, 2018, INFORM SCIENCES, V433, P448, DOI 10.1016/j.ins.2017.02.004
   Kaur B, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P459, DOI 10.1109/ACPR.2017.33
   Kaur B, 2019, NEURAL COMPUT APPL, V31, P5887, DOI 10.1007/s00521-018-3397-1
   Kaur B, 2017, MULTIMED TOOLS APPL, V76, P25581, DOI 10.1007/s11042-016-4232-2
   Kaya M, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.211
   KEIRN ZA, 1990, IEEE T BIO-MED ENG, V37, P1209, DOI 10.1109/10.64464
   Kent J.L., 2010, Psychedelic Information Theory: Shamanism in the Age of Reason
   Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Koike-Akino T, 2016, IEEE ENG MED BIO, P854, DOI 10.1109/EMBC.2016.7590835
   Kumar P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214641
   Kumar P, 2018, DISPLAYS, V55, P64, DOI 10.1016/j.displa.2018.09.006
   Kuo CT, 2018, FUTURE GENER COMP SY, V86, P1424, DOI 10.1016/j.future.2017.12.069
   La Rocca D, 2014, IEEE T BIO-MED ENG, V61, P2406, DOI 10.1109/TBME.2014.2317881
   La Rocca Daria, 2013, Proceedings of the 6th International Conference on Bio-inspired Systems and Signal Processing. BIOSIGNALS 2013, P419
   Lee HJ, 2013, I IEEE EMBS C NEUR E, P13, DOI 10.1109/NER.2013.6695859
   Maiorana E, 2016, IEEE T INF FOREN SEC, V11, P163, DOI 10.1109/TIFS.2015.2481870
   Maiorana E, 2016, NEUROCOMPUTING, V171, P638, DOI 10.1016/j.neucom.2015.07.005
   Malmivuo J., 1995, BIOELECTROMAGNETISM
   Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012
   Miyamoto C, 2008, I S INTELL SIG PROC, P130
   MIYAMOTO SBC, 2008, PERSONAL AUTHENTICAT
   Mu ZD, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18120432
   Nakanishi I, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P651, DOI 10.1109/ISPACS.2009.5383756
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Pal A, 2016, SP SER WIRELESS TECH, P93, DOI 10.1007/978-3-319-42141-4_9
   Palaniappan R, 2006, PATTERN RECOGN LETT, V27, P726, DOI 10.1016/j.patrec.2005.10.020
   Palaniappan R, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1442
   Palaniappan R, 2004, IEE P-SCI MEAS TECH, V151, P16, DOI 10.1049/ip-smt:20040003
   Palaniappan R, 2008, INT J NEURAL SYST, V18, P59, DOI 10.1142/S0129065708001373
   Palaniappan R, 2007, J VLSI SIG PROC SYST, V49, P243, DOI 10.1007/s11265-007-0078-1
   Palaniappan R, 2006, LECT NOTES COMPUT SC, V4224, P604
   Pham T., 2013, INT C ADV DAT MIN AP, V8347, P513, DOI DOI 10.1007/978-3-642-53917-6_46
   Phothisonothai M, 2015, ASIAPAC SIGN INFO PR, P923, DOI 10.1109/APSIPA.2015.7415406
   Phung D., 2014, P 22 EUR S ART NEUR, P413
   RAJESWARI P, 2016, INTELLIGENT TECHNIQU, P469
   Ravi KVR, 2005, EUROCON 2005: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOL 1 AND 2 , PROCEEDINGS, P1386
   Riera A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/143728
   Rodrigues D, 2016, EXPERT SYST APPL, V62, P81, DOI 10.1016/j.eswa.2016.06.006
   Saini R, 2018, INFORM SCIENCES, V430, P163, DOI 10.1016/j.ins.2017.11.045
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Sharma PK, 2016, OPTIK, V127, P2143, DOI 10.1016/j.ijleo.2015.09.020
   Shedeed H. A., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P1205, DOI 10.1109/WICT.2011.6141420
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Sohal AS, 2018, COMPUT SECUR, V74, P340, DOI 10.1016/j.cose.2017.08.016
   SONAWANE V, 2016, INT J ENG SCI, P3184
   TANGKRAINGKIJ P, 2015, STUDIES COMPUTATIONA, P103
   van Andel J, 2016, EPILEPSY BEHAV, V57, P82, DOI 10.1016/j.yebeh.2016.01.003
   Nguyen VTN, 2013, INT C PAR DISTRIB SY, P430, DOI 10.1109/ICPADS.2013.70
   WILAIPRASITPORN T, 2019, IEEE T COGN DEV SYS
   Yadava M, 2017, MULTIMED TOOLS APPL, V76, P19087, DOI 10.1007/s11042-017-4580-6
   YuM Kaongoen N, 2016, 2016 4 INT WINT C BR, P1
   Zhu D, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), P281, DOI 10.1109/ISDEA.2012.70
   Zúquete A, 2010, BIOSIGNALS 2010: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P103
NR 86
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10805
EP 10823
DI 10.1007/s11042-020-08667-2
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000515798800007
DA 2024-07-18
ER

PT J
AU Singh, N
   Mishra, KK
   Bhatia, S
AF Singh, Navjot
   Mishra, K. K.
   Bhatia, Sanjiv
TI SEAM-an improved environmental adaptation method with real parameter
   coding for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Environmental adaptation method; Salient object detection; Color map;
   Saliency map
ID VISUAL-ATTENTION; MODEL; FEATURES; CONJUNCTION; EXTRACTION; TREE
AB Object detection is an important problem in computer vision attracting researchers from various domains. It deals with separating objects of interest from their background. Image-related low-level features are used to detect salient objects from images, however these features vary from image to image. There is no single feature that can clearly identify salient objects in all the images. Rather, a linear combination of these features may be useful for detection of salient objects. The computation of optimal weights of these features in a learning algorithm is an NP-Hard problem and requires an approximation of an optimization problem. So in the first phase, three low-level features capturing the edge and color information are extracted from the image. In the second phase, these features are integrated to form the saliency map. The linear weights are used for the combination which guides the dominance of feature(s). Thereafter, a threshold is applied over the saliency map to extract the salient objects. We use a linear weight vector and threshold that play a vital role in increasing the detection accuracy of the model. Identification of these parameters can be mapped to an optimization problem to identify the optimal linear weights best suited for the image. The problem is solved using an improved environmental adaptation method. There are three contributions of the paper. First being the identification of weight vector so that important feature(s) for an image are selected where the salient object is highlighted. The second is posing the salient object detection as an optimization problem with a relevant fitness function. Finally the third is utilization of Environment Adaptation Method (EAM) to solve the optimization problem pointed in the paper. The model is extensively validated over six complex datasets and achieves good results on standard performance measures used in comparison to twenty six related works. Four variants of the optimization algorithm are also presented. The EAM optimizer outperforms the GA, PSO and GWO optimizers.
C1 [Singh, Navjot; Mishra, K. K.; Bhatia, Sanjiv] Motilal Nehru Natl Inst Technol, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Singh, N (corresponding author), Motilal Nehru Natl Inst Technol, Allahabad, Uttar Pradesh, India.
EM navjot.singh.09@gmail.com
RI Mishra, K.K/AAT-3083-2021; Singh, Navjot/I-5444-2017
OI mishra, k.k./0000-0001-7557-5288; Singh, Navjot/0000-0003-0409-8482
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2006, P SIGCHI C HUM FACT
   [Anonymous], 2017, MULTIMED TOOLS APPL
   Arya R, 2019, KNOWL INF SYST, V60, P327, DOI 10.1007/s10115-018-1243-5
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Fu H, 2013, IEEE T IMAGE PROCESS
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Graefe V, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P363, DOI 10.1109/IVS.1996.566407
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, MODELS BOTTOM TOP VI
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Karssemeijer N, 1996, IEEE T MED IMAGING, V15, P611, DOI 10.1109/42.538938
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Meur O L, 2006, IEEE T PATTERN ANAL, V28, P802
   Peng P, 2015, NEUROCOMPUTING, V166, P337, DOI 10.1016/j.neucom.2015.03.067
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Singh M, 2019, IET COMPUT VIS, V13, P578, DOI 10.1049/iet-cvi.2018.5814
   Singh M, 2018, IEEE ACCESS, V6, P22441, DOI 10.1109/ACCESS.2018.2826924
   Singh N, 2017, MULTIMED TOOLS APPL, V76, P10521, DOI 10.1007/s11042-016-3676-8
   Singh N, 2016, DIGIT SIGNAL PROCESS, V55, P22, DOI 10.1016/j.dsp.2016.05.003
   Singh N, 2015, SIGNAL IMAGE VIDEO P, V9, P427, DOI 10.1007/s11760-013-0457-y
   Singh N, 2014, PATTERN RECOGN, V47, P1731, DOI 10.1016/j.patcog.2013.11.012
   Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yu J, 2014, INT WORKS EARTH OB
   Yu ZW, 2007, IEEE T MULTIMEDIA, V9, P766, DOI 10.1109/TMM.2007.893351
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu L, 2014, IEEE T IMAGE PROCESS, V23, P5094, DOI 10.1109/TIP.2014.2361024
NR 44
TC 9
Z9 9
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12995
EP 13010
DI 10.1007/s11042-020-08678-z
EA JAN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900001
DA 2024-07-18
ER

PT J
AU Jiang, CL
   Pang, YL
AF Jiang, Cuiling
   Pang, Yilin
TI Encrypted images-based reversible data hiding in Paillier cryptosystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Homomorphic public key
   cryptosystem; Difference expansion
AB Homomorphic public key technology effectively protects privacy, allowing algebraic operations directly in the cipher-text. Therefore, it has been extensively studied in the field of cloud computing. In this study, an encrypted image-based data hiding (EIRDH) algorithm with homomorphic public key cryptosystem is presented. The key contributions are these two sides. (1) An improved fast Paillier homomorphic public key cryptosystem system is proposed for encrypting image. It improves the efficiency of encryption operations greatly. (2) A difference expansion (DE) scheme is developed by exploiting the cover pixel to construct a new pair of pixels for data hiding. Compared with other methods, the experimental results show that, the proposed method has larger payload and higher stego-image quality. It accomplishes the image quality's increasing instead of general decreasing.
C1 [Jiang, Cuiling; Pang, Yilin] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
C3 East China University of Science & Technology
RP Jiang, CL (corresponding author), East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China.
EM cuilingjiang@ecust.edu.cn; yilinpang@ecust.edu.cn
FU National Natural Science Foundation of China [61371150]
FX The authors are grateful for the anonymous reviewers' insightful
   comments and valuable suggestions sincerely, which can substantially
   improve the quality of this study. This work is partially supported by
   the National Natural Science Foundation of China (No.61371150).
CR Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Di F., 2017, ADV INTERNETWORKING, P138
   Di Fuqiang, 2017, ADV INTERNETWORKING, P150
   Gutub AAA, 2007, IET COMPUT DIGIT TEC, V1, P389, DOI 10.1049/iet-cdt:20060183
   Gutub AAA, 2003, SIPS 2003: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P93, DOI 10.1109/SIPS.2003.1235650
   Gutub AAA, 2002, IEEE COMP SOC ANN, P53, DOI 10.1109/ISVLSI.2002.1016874
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Janani S, 2014, IJRCCT, V3, P223
   Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li M, 2015, ELECTRON LETT, V51, P690, DOI 10.1049/el.2014.4476
   Li M, 2014, ETRI J, V36, P325, DOI 10.4218/etrij.14.0213.0449
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Qian Z, 2015, IEEE T CIRCUITS SYST
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xiang Shi-Jun, 2016, Journal of Software, V27, P1592, DOI 10.13328/j.cnki.jos.005007
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiang SJ, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0496-6
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Yin Z., 2014, SCI WORLD J
   Zhang S., 2014, J APPL MATH
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
NR 37
TC 12
Z9 12
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 693
EP 711
DI 10.1007/s11042-019-07874-w
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600028
DA 2024-07-18
ER

PT J
AU Kas, M
   El-merabet, Y
   Ruichek, Y
   Messoussi, R
AF Kas, M.
   El-merabet, Y.
   Ruichek, Y.
   Messoussi, R.
TI A comprehensive comparative study of handcrafted methods for face
   recognition LBP-like and non LBP operators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Texture descriptor; LBP-like descriptors; Feature
   extraction; Texture classification; Pre-processing
ID LOCAL BINARY PATTERNS; TEXTURE CLASSIFICATION; FEATURE DESCRIPTOR; IMAGE
   RETRIEVAL; REGRESSION; SPECTRUM; UNIT
AB Pattern recognition and computer vision fields experienced the proposal of several architectures and approaches to deal with the demands of real world applications including face recognition. They have almost the same structure, based generally on a series of steps where the main ones are feature extraction and classification. The literature works interessted in face recognition problems, insist on the role of texture description as one of the key elements in face analysis, since it greatly affects recognition accuracy. Therefore, texture feature extraction has gained much attention and became a long-standing research topic thanks to its abilities to efficiently understand the face recognition process, especially in terms of face description. Recently, several literature researches in face application proposed new architectures based on pattern description proved by their discriminative power when extracting the feature information from facial images. These advantages combined with an outstanding performance in many classification applications, allowed the LBP-like descriptors to be one of the most prominent texture description method. Given this period of remarkable evolution, this research work includes a comprehensive analytical study of the face recognition performance of 64 LBP-like and 3 non-LBP texture descriptors recently proposed in the literature. To this end, we adopted a face recognition framework composed of four stages: 1) image pre-processing using gamma correction; 2) feature extraction using texture descriptors; 3) histogram calculation and 4) face recognition and classification based on the simple parameter-free Nearest Neighbors classifier (NN). The conducted comprehensive evaluations and experiments on the challenging and widely used benchmarks ORL, YALE, Extended YALE B and FERET databases presenting different challenges, indicate that a number of evaluated texture descriptors, which are tested for the first time on face recognition task, achieve better or competitive compared to several recent systems reported in face recognition literature.
C1 [Kas, M.; El-merabet, Y.; Messoussi, R.] Univ Ibn Tofail, Fac Sci, Dept Phys, Lab LASTID, BP 133, Kenitra 14000, Morocco.
   [Kas, M.; Ruichek, Y.] Univ Bourgogne Franche Comte, UTBM, CIAD UMR 7533, F-90010 Belfort, France.
C3 Ibn Tofail University of Kenitra; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Universite de Franche-Comte; Universite de
   Bourgogne
RP Kas, M (corresponding author), Univ Ibn Tofail, Fac Sci, Dept Phys, Lab LASTID, BP 133, Kenitra 14000, Morocco.; Kas, M (corresponding author), Univ Bourgogne Franche Comte, UTBM, CIAD UMR 7533, F-90010 Belfort, France.
EM mohamed.kas@utbm.fr; y.el-merabet@univ-ibntofail.ac.ma;
   yassine.ruichek@utbm.fr; messoussi@uit.ac.ma
RI Ruichek, Yassine/GRX-3627-2022; KAS, Mohamed/AAB-5618-2021; El merabet,
   Youssef/P-1034-2015
OI KAS, Mohamed/0000-0001-5123-4681; El merabet,
   Youssef/0000-0001-6938-9374; RUICHEK, Yassine/0000-0003-4795-8569
FU Centre National de la Recherche Scientifique et Technique (CNRST-Maroc)
   [7UIT2017]
FX The authors gratefully acknowledge the Scholarship funding received from
   Centre National de la Recherche Scientifique et Technique (CNRST-Maroc)
   under the grant number 7UIT2017.
CR Abdullah MFA, 2014, EXPERT SYST APPL, V41, P6131, DOI 10.1016/j.eswa.2014.04.006
   Abhishree TM, 2015, PROCEDIA COMPUT SCI, V45, P312, DOI 10.1016/j.procs.2015.03.149
   Ahonen T., 2008, Recognition of blurred faces using local phase quantization
   [Anonymous], INT J FDN COMPUTER S
   [Anonymous], INT J SCI REIJSR
   [Anonymous], 2012 21 INT C PATT R
   [Anonymous], 2017, NEURAL COMPUT APPL
   [Anonymous], 2007, INT WORKSH AN MOD FA
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], 4 INT C NAT COMP
   [Anonymous], 2018, NEURAL COMPUT APPL
   [Anonymous], LOCAL QUADRUPLE PATT
   [Anonymous], IEEE ACCESS
   [Anonymous], NEUROCOMPUTING
   [Anonymous], J KING SAUD U COMPUT
   [Anonymous], INT JOINT C COMP VIS
   [Anonymous], 2005, INT J SIGNAL PROCESS
   [Anonymous], ROTATED LOCAL BINARY
   [Anonymous], INFORM SCI
   [Anonymous], ENERGY PROCEDIA
   [Anonymous], COMP IMAGES VARIABLE
   Bashier HK, 2016, OPTIK, V127, P638, DOI 10.1016/j.ijleo.2015.10.096
   Belahcene M., 2016, 2016 6th European Workshop on Visual Information Processing (EUVIP), P1
   Bereta M, 2013, J VIS COMMUN IMAGE R, V24, P1213, DOI 10.1016/j.jvcir.2013.08.004
   Cavalcanti GDC, 2013, EXPERT SYST APPL, V40, P4971, DOI 10.1016/j.eswa.2013.03.003
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chang CL, 2004, OPT ENG, V43, P1891, DOI 10.1117/1.1768183
   Dong S, 2015, KSII T INTERNET INF, V9, P4126, DOI 10.3837/tiis.2015.10.020
   Dora L, 2017, ENG APPL ARTIF INTEL, V62, P286, DOI 10.1016/j.engappai.2017.04.011
   El Aroussi M, 2011, SIGNAL PROCESS, V91, P38, DOI 10.1016/j.sigpro.2010.06.005
   El Merabet Y, 2019, ENG APPL ARTIF INTEL, V78, P158, DOI 10.1016/j.engappai.2018.11.011
   El Merabet Y, 2018, PATTERN RECOGN, V76, P303, DOI 10.1016/j.patcog.2017.11.005
   Fathi A, 2016, J VIS COMMUN IMAGE R, V38, P65, DOI 10.1016/j.jvcir.2016.02.010
   Fernández A, 2013, J MATH IMAGING VIS, V45, P76, DOI 10.1007/s10851-012-0349-8
   Fernández A, 2011, OPT LASER ENG, V49, P1177, DOI 10.1016/j.optlaseng.2011.05.003
   Gaidhane VH, 2014, PATTERN RECOGN, V47, P1869, DOI 10.1016/j.patcog.2013.11.027
   Gao T, 2013, OPTIK, V124, P6286, DOI 10.1016/j.ijleo.2013.05.007
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Ghinea G, 2014, IEEE ACCESS, V2, P914, DOI 10.1109/ACCESS.2014.2348018
   Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406
   Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195
   Hadid A, 2015, PATTERN RECOGN LETT, V68, P231, DOI 10.1016/j.patrec.2015.04.017
   HE DC, 1992, PATTERN RECOGN, V25, P247, DOI 10.1016/0031-3203(92)90108-U
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P91, DOI 10.1109/LSP.2012.2230257
   Huang SC, 2016, NEUROCOMPUTING, V208, P373, DOI 10.1016/j.neucom.2016.02.063
   Huang ZH, 2015, IMAGE VISION COMPUT, V37, P12, DOI 10.1016/j.imavis.2014.12.005
   Jabid T, 2010, IEEE ICCE
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li HJ, 2016, PATTERN RECOGN, V60, P13, DOI 10.1016/j.patcog.2016.05.014
   Li L, 2016, OPTIK, V127, P7408, DOI 10.1016/j.ijleo.2016.05.105
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu T, 2016, NEUROCOMPUTING, V214, P944, DOI 10.1016/j.neucom.2016.06.071
   Lu GF, 2012, PATTERN RECOGN, V45, P2510, DOI 10.1016/j.patcog.2012.01.018
   Lumini Alessandra, 2017, Applied Computing and Informatics, V13, P79, DOI 10.1016/j.aci.2016.04.001
   Madrid-Cuevas FJ, 2003, LECT NOTES COMPUT SC, V2652, P470
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048
   Pan J, 2016, IEEE ACCESS, V4, P2873, DOI 10.1109/ACCESS.2016.2574366
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Piao N, 2015, IEEE SIGNAL PROC LET, V22, DOI 10.1109/LSP.2015.2492980
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sayeed S., 2013, Australian Journal of Basic and Applied Sciences, V7, P29
   Secchi P., 2013, COMPUT STAT DATA AN, V67, P236
   Song KC, 2015, J VIS COMMUN IMAGE R, V33, P323, DOI 10.1016/j.jvcir.2015.09.016
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Sun JP, 2014, ELECTRON J DIFFER EQ, P1
   Nguyen TP, 2016, NEUROCOMPUTING, V173, P1565, DOI 10.1016/j.neucom.2015.09.029
   Tian DY, 2016, IEEE T IMAGE PROCESS, V25, P961, DOI 10.1109/TIP.2015.2509418
   Topi M, 2000, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2000.903698
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Vipparthi SK, 2016, INT J AUTOM COMPUT, V13, P457, DOI 10.1007/s11633-016-0978-2
   Vipparthi SK, 2015, NEUROCOMPUTING, V167, P336, DOI 10.1016/j.neucom.2015.04.062
   Wang Y., 2016, IEEE T CYBERNETICS, P1
   Wu XS, 2011, COMM COM INF SC, V214, P359
   Xu B, 2003, PHOTOGRAMM ENG REM S, V69, P529, DOI 10.14358/PERS.69.5.529
   Yang WK, 2016, NEUROCOMPUTING, V213, P183, DOI 10.1016/j.neucom.2015.11.134
   Yuan S, 2017, IEEE T IMAGE PROCESS, V26, P2669, DOI 10.1109/TIP.2017.2685343
   Zeng HQ, 2016, NEUROCOMPUTING, V217, P3, DOI 10.1016/j.neucom.2015.11.130
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang FL, 2015, IEEE T NEUR NET LEAR, V26, P2247, DOI 10.1109/TNNLS.2014.2376530
   Zhao Y, 2016, NEUROCOMPUTING, V207, P354, DOI 10.1016/j.neucom.2016.05.016
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 93
TC 19
Z9 19
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 375
EP 413
DI 10.1007/s11042-019-08049-3
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600016
DA 2024-07-18
ER

PT J
AU Sumathi, R
   Raajan, NR
AF Sumathi, R.
   Raajan, N. R.
TI A multilevel distributed image based encryption for full integrity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Confusion; Diffusion; Random sequence; Image division; Legitimate user;
   Combination of logistic and tent map
ID TRANSFORM; SCHEME; CHAOS; PERMUTATION
AB Sending and receiving information in today's world has become easy. Recent advancements in the technology have made the world shrink. The transfer of data hence has become effortless. At one touch of the 'send' button, the data is made available to the required receiver. This has put the sender and receiver at ease to communicate. Ensuring the safety of the data being transmitted and also that it is in the right hands are the prime aspects of the communication process. Anyone who is interested in knowing the information may mess about the data. Hence it is required to protect the information from the unauthorized user. The very intention of this work is to provide enough security to the confidential color images that are to reach only the legitimate receiver. This paper focuses on the essential quantum of work required to ensure that the confidential images are out of harm's way. It also is a sincere effort to accomplish the same using not very complicated techniques and to make use of a combination of simple algorithms like tent map and logistic map. The goal of the work is achieved with exertion which employs the technique of splitting the image into required number of appropriate blocks followed by the implementation of the vital processes: confusion and diffusion to achieve the mission. Confusion involves shuffling of the blocks and diffusion is implemented using a random sequence. This technique applied has helped to reach the least amount of correlation between the pixels in the ciphered image. The lesser is the degree of association between the nearby pixels in the encrypted image, higher is the efficiency of the encryption. The method implemented in this work is a simple version of the combination of tent map and logistic map and is trouble free and at the same time gives the required security to the image so that no unauthenticated user can make out the data even if he manages to get the ciphered adaptation of it.
C1 [Sumathi, R.; Raajan, N. R.] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sumathi, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur, Tamil Nadu, India.
EM sumathi@ece.sastra.edu; nrraajan@ece.sastra.edu
RI N R, Dr. RAAJAN/HDN-4829-2022; Renga Raajan, Narasimhan/IST-5582-2023
OI N R, Dr. RAAJAN/0000-0002-9537-1140; 
CR Abuturab MR, 2014, OPT LASER ENG, V58, P39, DOI 10.1016/j.optlaseng.2014.01.025
   Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Alsaedi M, 2017, MULTIMED TOOLS APPL, V76, P24527, DOI 10.1007/s11042-016-4206-4
   [Anonymous], HYBRID IMAGE ENCRYPT
   [Anonymous], SECURE IMAGE ENCRYPT
   [Anonymous], IEEE INT C SYST MAN
   [Anonymous], INT J RES ADVENT TEC
   [Anonymous], INT J IMAGING ROBOTI
   Beloucif Assia, 2016, International Journal of Information and Computer Security, V8, P205
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chen R., 2006, IEEE 10 INT S CONSUM, P1
   Chen RJ, 2005, IEEE INT SYMP CIRC S, P1690, DOI 10.1109/ISCAS.2005.1464931
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Kumar S, 2015, ADV INTELL SYST, V340, P379, DOI 10.1007/978-81-322-2247-7_39
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Sharma M., 2016, COMPREHENSIVE STUDY
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Yang YG, 2013, QUANTUM INF PROCESS, V12, P3477, DOI 10.1007/s11128-013-0612-y
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
NR 30
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2161
EP 2183
DI 10.1007/s11042-019-08104-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000021
DA 2024-07-18
ER

PT J
AU Zhou, LY
   Zhang, T
AF Zhou, Luoyu
   Zhang, Tao
TI Image denoising based on mixed total variation regularization with
   decision-making scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed total variation; Image denoising; Decision-making scheme; Noise
   estimation; Generalized cross-validation
ID NONLOCAL MEANS
AB The denosing method based on total variation has achieved a remarkable denoising performance. However, it usually generates some staircase effects. To overcome the defect of total variation, a novel image denoising method based on total variation is proposed for improving image quality. The present research contains two contributions. Firstly, the mixed total variation model is proposed to suppress staircase effects. Secondly, the optimal threshold and the regularization parameter are all achieved by the decision-making scheme rather than experience. The difference is that the regularization parameter is achieved by the generalized cross-validation approach and the optimal threshold is achieved by the estimated standard deviation of noise. Experiments on some synthetic noisy images and the noisy images on TID2008 database demonstrate that our method is superior to state-of-the-art denoising method in terms of visual quality and objective evaluation.
C1 [Zhou, Luoyu] Yangtze Univ, Elect & Informat Sch, Jingzhou, Hubei, Peoples R China.
   [Zhang, Tao] Univ Huddersfield, Huddersfield, W Yorkshire, England.
C3 Yangtze University; University of Huddersfield
RP Zhou, LY (corresponding author), Yangtze Univ, Elect & Informat Sch, Jingzhou, Hubei, Peoples R China.
EM luoyuzh@yangtzeu.edu.cn
RI Zhang, Tao/AAZ-8359-2020
FU National Natural Science Foundation of China [61901059]; Hubei
   Provincial Natural Science Foundation of China [2019CFB233]
FX This work is supported by National Natural Science Foundation of China
   (61901059) and Hubei Provincial Natural Science Foundation of China
   (2019CFB233).
CR [Anonymous], PHILOS T ROYAL SOC A
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chen YT, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143145
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Ghimpeteanu G, 2016, IEEE T IMAGE PROCESS, V25, P388, DOI 10.1109/TIP.2015.2498413
   GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751
   Iglesias JA, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aab92a
   Jun Z, 2011, APPL MATH MODEL, V35, P2516, DOI 10.1016/j.apm.2010.11.049
   Kim JH, 2017, EXPERT SYST APPL, V87, P252, DOI 10.1016/j.eswa.2017.06.015
   Li HJ, 2016, PATTERN RECOGN, V49, P237, DOI 10.1016/j.patcog.2015.05.028
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Nguyen MP, 2017, IEEE T IMAGE PROCESS, V26, P1637, DOI 10.1109/TIP.2017.2658941
   Tran-Dinh Q, 2017, COMPUT OPTIM APPL, V66, P425, DOI 10.1007/s10589-016-9873-6
   Ren C, 2017, IEEE T IMAGE PROCESS, V26, P90, DOI 10.1109/TIP.2016.2619265
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shahdoosti Hamid Reza, 2018, Multimedia Tools and Applications, V77, P7013, DOI 10.1007/s11042-017-4618-9
   Wu LN, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053003
   Xie L, 2017, 26 INT JOINT C ART I
   Yao SK, 2018, J VIS COMMUN IMAGE R, V50, P111, DOI 10.1016/j.jvcir.2017.11.019
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhou LY, 2017, APPL MATH MODEL, V51, P469, DOI 10.1016/j.apm.2017.07.009
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 25
TC 1
Z9 2
U1 5
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7543
EP 7557
DI 10.1007/s11042-019-08531-y
EA DEC 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164400001
DA 2024-07-18
ER

PT J
AU Fan, HY
   Lu, ZM
   Liu, YL
AF Fan, Hang-Yu
   Lu, Zhe-Ming
   Liu, Yong-Liang
TI A low-frequency construction watermarking based on histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Robust watermarking; Histogram; Low frequency
   construction
ID ROBUST IMAGE WATERMARKING; DCT; SCHEME; DWT; EXPANSION; TRANSFORM; SVD
AB The robust watermarking scheme has very broad application scenarios. For robust watermarking methods, the transform domain based watermarking algorithms are popular. Indeed, these algorithms have strong robustness, but the visual effects may be affected. In order to balance the robustness and imperceptibility, a histogram based watermarking scheme is proposed. In this scheme, in order to enhance the robustness and imperceptibility, the low-frequency construction method (LFCM) is proposed. In LFCM, the most suitable pixels for modifications are selected by calculating the weights of pixels at different positions, and these pixels will be modified in the histogram based embedding process. After the modification, the low-frequency of the image will enhance, and the robustness of the watermarking will enhance at the same time. Experiment results show that the proposed scheme can resist compression, scaling, noise, and median blur attacks, and can resist rotation attacks to a certain extent. The proposed scheme is a non-blind watermarking scheme, and non-blind watermarking scheme is feasible when this scheme has good performance.
C1 [Fan, Hang-Yu; Lu, Zhe-Ming] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
   [Fan, Hang-Yu; Lu, Zhe-Ming; Liu, Yong-Liang] Alibaba Grp, Hangzhou 311121, Zhejiang, Peoples R China.
   [Lu, Zhe-Ming] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Zhejiang University; Alibaba Group; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.; Lu, ZM (corresponding author), Alibaba Grp, Hangzhou 311121, Zhejiang, Peoples R China.; Lu, ZM (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
EM zheminglu@zju.edu.cn
FU Alibaba-Zhejiang University Joint Institute of Frontier Technologies
FX This work was supported by Alibaba-Zhejiang University Joint Institute
   of Frontier Technologies.
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2004, ELECT IMAGING
   Chen F, 2017, MULTIMED TOOLS APPL, V76, P9681, DOI 10.1007/s11042-016-3574-0
   Cox I., 2002, J. Electron. Imag., V11, P414, DOI 10.1117/1.1494075
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Das Soumik, 2017, International Journal of Image, Graphics and Signal Processing, V9, P40, DOI 10.5815/ijigsp.2017.09.05
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Lee YS, 2019, SIGNAL PROCESS-IMAGE, V70, P104, DOI 10.1016/j.image.2018.09.004
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Liu F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P380, DOI 10.1109/CISP.2008.412
   Liu F, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P283, DOI 10.1109/ICICISYS.2009.5357687
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Niu XM, 2000, IEEE T CONSUM ELECTR, V46, P137, DOI 10.1109/30.826391
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Pizzolante R, 2018, COMPUT SECUR, V74, P384, DOI 10.1016/j.cose.2017.06.003
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   Yadav B., 2018, Adv. Intell. Syst. Comput, V583, P25
NR 28
TC 1
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5693
EP 5717
DI 10.1007/s11042-019-08289-3
EA DEC 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000501289400001
DA 2024-07-18
ER

PT J
AU Fayyaz, MA
   Anjum, A
   Ziauddin, S
   Khan, A
   Sarfaraz, A
AF Fayyaz, Muhammad Aizad
   Anjum, Adeel
   Ziauddin, Sheikh
   Khan, Ahmed
   Sarfaraz, Aaliya
TI An improved surveillance video forgery detection technique using sensor
   pattern noise and correlation of noise residues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Video forgery; Digital forgery; Sensor pattern noise
ID CAMERA IDENTIFICATION; DETECTION ALGORITHM; FRAME
AB Digital videos have become an important aspect of our lives lately, from a personal memorable to surveillance videos which can be presented in a court as an evidence now, this video evidence can be very important for the court of law and the investigators to understand the events as they occurred. Huge inventions in the video editing world have resulted in a margin of doubt, to the point where courts are now reluctant to accept any video evidence in to their case files, as for a digital video to be presented as an evidence, it's integrity and authenticity is very important. This progression in technology can push the courts to a point where they refuse to trust anything that was caught on a video. Thus, more efforts have to be made in the video forensics world to avoid such a future. It has been shown that sources induce their specific noise patterns (i.e. Sensor pattern noise) to the captured media, and these patterns can be used to trace the source sensor and also to detect any forgeries. Acquiring SPN (sensor pattern noise) consists of two steps, first to get noise residues by subtracting denoised frames from the actual frames taken from the sample data and then to average those noise residues to get the sensor pattern noise. Problem arises when the attacker can also extract sensor pattern noise or has access to it. The attacker can induce SPN in forged frames which will prevent detection using the previous SPN based detection technique. This paper first proposes how the attacker can compensate a forged image by inducing SPN in it and then proposes a forgery detection technique for such a scenario which would not only rely on noise residue correlation with SPN but correlation with noise residue from the previous frame as well. We first estimate sensor pattern noise based on locally adaptive discrete cosine transform, then we correlate noise residue of frame n under investigation with the sensor pattern noise and with the noise residue of the previous frame n-1 as well. Now, even if the attacker compensates the forged frame by inducing SPN in it, the inter-frame continuity of noise shall be disturbed hence identified. Simulations using benchmark dataset for SPN extraction technique and custom dataset for video forgery detection, show that this methodology successfully detects any forgeries and locate their positions in the normal case and in the case where SPN is induced in the forged frames as well.
C1 [Fayyaz, Muhammad Aizad; Anjum, Adeel; Ziauddin, Sheikh; Khan, Ahmed; Sarfaraz, Aaliya] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Khan, A (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
EM aizadhashmiofficial@gmail.com; adeel.anjum@comsats.edu.pk;
   sheikh.ziauddin@comsats.edu.pk; ahmd_iub4849@yahoo.com;
   engr_aaliya@yahoo.com
RI Anjum, Adeel/L-4391-2013; , Ziauddin/P-1154-2015
OI Anjum, Adeel/0000-0001-5083-0019; 
CR Altinisik E, 2018, EUR SIGNAL PR CONF, P1367, DOI 10.23919/EUSIPCO.2018.8553173
   [Anonymous], SEC FOR STEG WAT MUL, V6819
   Ba ZJ, 2019, IEEE T INF FOREN SEC, V14, P2987, DOI 10.1109/TIFS.2019.2911173
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Chen RC, 2014, FORENSIC SCI INT, V236, P164, DOI 10.1016/j.forsciint.2013.12.022
   Cooper AJ, 2013, FORENSIC SCI INT, V226, P132, DOI 10.1016/j.forsciint.2012.12.018
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   He CB, 2016, 2016 INTERNATIONAL CONFERENCE ON MATERIAL, ENERGY AND ENVIRONMENT ENGINEERING (ICM3E 2016), P1, DOI 10.1109/iWEM.2016.7505041
   Hosler B., 2019, ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). Proceedings, P8271, DOI 10.1109/ICASSP.2019.8682608
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hsu YF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P28
   Huang TQ, 2018, COMPUT SECUR, V77, P412, DOI 10.1016/j.cose.2018.04.013
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Hyun D-K, 2013, FORGERY DETECTION SU, P25
   Jeyalakshmi A, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P1407, DOI 10.1109/ICISC.2018.8398923
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Jung SH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11133499
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin XF, 2016, IEEE SIGNAL PROC LET, V23, P381, DOI 10.1109/LSP.2016.2521349
   Lin XF, 2016, IEEE T INF FOREN SEC, V11, P126, DOI 10.1109/TIFS.2015.2478748
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P7405, DOI 10.1007/s11042-017-4652-7
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Malik SUR, 2013, IEEE T CLOUD COMPUT, V1, P50, DOI 10.1109/TCC.2013.3
   Mehrish A, 2016, IEEE SIGNAL PROC LET, V23, P693, DOI 10.1109/LSP.2016.2549059
   Ngiam Jiquan, 2011, P 28 INT C MACH LEAR, P265
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wu GD, 2012, IEEE IMAGE PROC, P237, DOI 10.1109/ICIP.2012.6466839
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yaqub W, 2018, IEEE IMAGE PROC, P3798, DOI 10.1109/ICIP.2018.8451749
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
   Zhu Y, 2018, DETECTION METHOD FAC
NR 38
TC 15
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5767
EP 5788
DI 10.1007/s11042-019-08236-2
EA DEC 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000501289400003
DA 2024-07-18
ER

PT J
AU Alimohammadi, K
   Bayat, M
   Javadi, HHS
AF Alimohammadi, Kobra
   Bayat, Majid
   Javadi, Hamid H. S.
TI A secure key-aggregate authentication cryptosystem for data sharing in
   dynamic cloud storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aggregate key; Authentication cryptosystem; Cloud storage; Data sharing
ID ATTRIBUTE-BASED-ENCRYPTION; IDENTITY-BASED ENCRYPTION; ACCESS-CONTROL;
   SEARCHABLE ENCRYPTION; SHORT CIPHERTEXTS; SHORT SIGNATURES; PRIVACY;
   SCHEME; IMPLEMENTATION
AB The ability of data owner in secure and efficient arbitrary data sharing with others is of great importance in the outsourced encrypted data on the cloud. To protect data confidentiality, data owner encrypts his files before storing information on the cloud. Data sharing schemes are used to share encrypted files with others. Guo et al.'s data sharing scheme in dynamic cloud storage is evaluated in this paper. We investigate its vulnerability against DoS and impersonation attacks. In this scheme, anyone can forge the authentication key and access any arbitrary set of files stored on the cloud. We present a new scheme to overcome the weaknesses. Moreover, we evaluate the security and efficiency of our scheme comparing to some related ones. The results indicate that the proposed scheme is suitable for data sharing in dynamic cloud storage.
C1 [Alimohammadi, Kobra; Javadi, Hamid H. S.] Shahed Univ, Dept Math Sci & Comp, Tehran, Iran.
   [Bayat, Majid] Shahed Univ, Dept Comp Engn, Tehran, Iran.
C3 Shahed University; Shahed University
RP Bayat, M (corresponding author), Shahed Univ, Dept Comp Engn, Tehran, Iran.
EM k.alimohammadi@shahed.ac.ir; mbayat@shahed.ac.ir;
   h.s.javadi@shahed.ac.ir
RI Javadi, Hamid Haj Seyyed/AAU-6168-2020
OI Javadi, Hamid Haj Seyyed/0000-0003-0082-036X
CR AKL SG, 1983, ACM T COMPUT SYST, V1, P239, DOI 10.1145/357369.357372
   AlZain MA, 2015, INT J CLOUD APPL COM, V5, P35, DOI 10.4018/IJCAC.2015070103
   [Anonymous], LNCS
   Atallah MJ, 2009, ACM T INFORM SYST SE, V12, DOI 10.1145/1455526.1455531
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Ateniese G, 2012, J CRYPTOL, V25, P243, DOI 10.1007/s00145-010-9094-6
   Bayat M, 2015, WIREL NETW, V21, P1733, DOI 10.1007/s11276-014-0881-0
   Bayat M, 2015, WIREL NETW, V21, P871, DOI 10.1007/s11276-014-0824-9
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Boneh D, 2005, LECT NOTES COMPUT SC, V3621, P258
   Boneh D, 2005, LECT NOTES COMPUT SC, V3494, P440, DOI 10.1007/11426639_26
   Boneh D, 2004, J CRYPTOL, V17, P297, DOI 10.1007/s00145-004-0314-9
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P56
   Boyen X, 2006, LECT NOTES COMPUT SC, V4117, P290
   Chase M, 2007, LECT NOTES COMPUT SC, V4392, P515
   Chick G.C., 1989, P ADV CRYPTOLOGY CRY, V435, P316
   Chu CK, 2014, IEEE T PARALL DISTR, V25, P468, DOI 10.1109/TPDS.2013.112
   Cui BJ, 2016, IEEE T COMPUT, V65, P2374, DOI 10.1109/TC.2015.2389959
   Fan CI, 2014, IEEE T COMPUT, V63, P1951, DOI 10.1109/TC.2013.83
   Goyal V., 2006, P 2006 INT C PRIVACY, P1
   Guo C, 2018, FUTURE GENER COMP SY, V84, P190, DOI 10.1016/j.future.2017.07.038
   Guo C, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0588-0
   Guo FC, 2007, LECT NOTES COMPUT SC, V4575, P392
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Horwitz J, 2002, LECT NOTES COMPUT SC, V2332, P466, DOI 10.1007/3-540-46035-7_31
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   King WC, 2015, US Patent, Patent No. [8,990,555, 8990555]
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Li T, 2016, SIGNAL COMMUN PLANTS, P153, DOI 10.1007/978-3-319-33498-1_7
   Liu ZL, 2018, FUTURE GENER COMP SY, V78, P778, DOI 10.1016/j.future.2017.02.024
   Okamoto T, 2015, DESIGN CODE CRYPTOGR, V77, P725, DOI 10.1007/s10623-015-0131-1
   Patranabis S, 2017, IEEE T COMPUT, V66, P891, DOI 10.1109/TC.2016.2629510
   Pournaghi SM, 2018, COMPUT NETW, V134, P78, DOI 10.1016/j.comnet.2018.01.015
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   SANDHU RS, 1988, INFORM PROCESS LETT, V27, P95, DOI 10.1016/0020-0190(88)90099-3
   Sun Y, 2004, IEEE INFOCOM SER, P1296
   Tong Y, 2014, IEEE J BIOMED HEALTH, V18, P419, DOI 10.1109/JBHI.2013.2294932
   Tzeng WG, 2002, IEEE T KNOWL DATA EN, V14, P182, DOI 10.1109/69.979981
   Urama J, 2016, IEEE INT CONF MO, P186, DOI 10.1109/MobServ.2016.41
   Vahedi E, 2017, COMPUT NETW, V129, P28, DOI 10.1016/j.comnet.2017.08.025
   Wang SL, 2016, IEEE T INF FOREN SEC, V11, P1265, DOI 10.1109/TIFS.2016.2523941
   Wang ZQ, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/9875298
   Wang ZW, 2019, FUTURE GENER COMP SY, V93, P770, DOI 10.1016/j.future.2017.09.041
   Waters B, 2005, LECT NOTES COMPUT SC, V3494, P114
   Zhang Q, 2004, GLOB TELECOMM CONF, P2067
   Zhou R, 2018, IEEE T IND INFORM, V14, P3648, DOI 10.1109/TII.2018.2794442
   Zhou ZB, 2015, IEEE T COMPUT, V64, P126, DOI 10.1109/TC.2013.200
NR 48
TC 12
Z9 12
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2855
EP 2872
DI 10.1007/s11042-019-08292-8
EA DEC 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500319500002
DA 2024-07-18
ER

PT J
AU Wang, JC
   Zhou, YN
   Hu, ZZ
   Zhang, X
   Wang, M
AF Wang, Jicheng
   Zhou, Yuanen
   Hu, Zhenzhen
   Zhang, Xu
   Wang, Meng
TI Sequential image encoding for vision-to-language problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Visual question answering; Object detection
AB The combination of visual recognition and language understanding is aim to build a commonly shared space between heterogeneous data of vision and text, such as the tasks of image captioning and visual question answering (VQA). Most existing approaches convert an image into a semantic visual feature vector via deep convolutional neural networks (CNN), while keep the sequential property of text data and represent it with Recurrent Neural Networks(RNN). The key to analyse multi-source heterogeneous data is to construct the inherent correlations between data. In order to reduce the heterogeneous gap among the vision and language, in this work, we represent the image in a sequential way as well as the text. We utilize the objects in the visual scenes and convert the image to a sequence of detected objects and their locations. Then we analogize a sequence of objects(visual language) to a sequence of words(natural language). We take the order of objects into account and evaluate different permutations and combinations of objects. Experimental results on the image captioning and VQA benchmarks demonstrate our hypothesis it's beneficial to appropriately arrange objects sequence on the Vision-to-Language(V2L) problems.
C1 [Wang, Jicheng; Zhou, Yuanen; Hu, Zhenzhen; Wang, Meng] Hefei Univ Technol, Hefei, Anhui, Peoples R China.
   [Zhang, Xu] Suzhou Vocat Univ, Suzhou, Peoples R China.
C3 Hefei University of Technology; Suzhou Vocational University
RP Hu, ZZ (corresponding author), Hefei Univ Technol, Hefei, Anhui, Peoples R China.
EM zzhu@hfut.edu.cn
RI Wang, Meng/ITR-8699-2023
OI Hu, Zhenzhen/0000-0003-1042-8361
CR ANDERSON P, 2018, BOTTOM UP TOP DOWN A
   Andreas J., 2016, P 2016 C N AM CHAPT, P1545, DOI DOI 10.18653/V1/N16-1181
   [Anonymous], Simple baseline for visual question answering
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen WZ, 2017, IEEE IJCNN, P1403, DOI 10.1109/IJCNN.2017.7966017
   DAI B, 2018, RETHINKING FORM LATE
   ELLIOTT D, 2013, P 2013 C EMP METH NA, P1292
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim JH, 2016, ADV NEUR IN, V29
   Kuznetsova P., 2012, Long Papers, P359
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4216
   Lu JH, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING TECHNOLOGY (CSET2015), MEDICAL SCIENCE AND BIOLOGICAL ENGINEERING (MSBE2015), P289
   Lu P, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1880, DOI 10.1145/3219819.3220036
   Lu P, 2018, AAAI CONF ARTIF INTE, P7218
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Mason R, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Mun J, 2017, AAAI CONF ARTIF INTE, P4233
   Ordonez V, 2016, INT J COMPUT VISION, V119, P46, DOI 10.1007/s11263-015-0840-y
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I, 2014, ADV NEUR IN, V27
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang Peng, 2015, ARXIV151102570
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yin X, 2017, INT SYM COMPUT INTEL, P171, DOI 10.1109/ISCID.2017.41
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang Y., 2018, 6 INT C LEARN REPR I
NR 44
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16141
EP 16152
DI 10.1007/s11042-019-08439-7
EA DEC 2019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000501121200002
DA 2024-07-18
ER

PT J
AU Elhassan, MA
   Abd-Elnaby, M
   El-Dolil, SA
   Abd El-Samie, FE
AF Elhassan, Mohamed Abo
   Abd-Elnaby, Mohammed
   El-Dolil, Sami A.
   Abd El-Samie, Fathi E.
TI Throughput maximization for multimedia communication with cooperative
   cognitive radio using adaptively controlled sensing time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radio; Spectrum sensing; Energy detection; Cooperative
   communication
ID OPTIMIZATION; NETWORKS; TRADEOFF
AB In the last years, most researches proved that spectrum holes are not efficiently utilized in wireless communications. Cognitive radio (CR) is an efficient solution to face inefficient utilization of spectrum resources. The key technique, which enables CR to provide efficient utilization of spectrum resources is called spectrum sensing. Spectrum sensing enables a secondary user (SU) to track the activity of the primary user (PU) and the availability of spectrum holes that can be used without any disturbance to the PU. Fixed sensing time schemes give inefficient throughput performance with varying received signal-to-noise ratios (SNRs). So, in this paper, an adaptive sensing time optimization scheme in cooperative CR based on energy detection is investigated with different fusion rules. The proposed scheme adapts the sensing time based on the value of received SNR to maximize the achieved throughput with an acceptable probability of false alarm. The performance of the proposed scheme is investigated with AND, OR, and Marjory fusion rules and compared to those of fixed sensing time schemes. Simulation results show that the proposed scheme significantly enhances the achieved throughput, and reduces the probability of false alarm compared to those of the fixed sensing time schemes. In addition, the proposed scheme provides better performance as the number of SUs increases with the marjory fusion rule.
C1 [Elhassan, Mohamed Abo; Abd-Elnaby, Mohammed; El-Dolil, Sami A.; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
   [Abd-Elnaby, Mohammed] Taif Univ, Dept Comp Engn, Coll Comp & Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Taif University
RP Abd El-Samie, FE (corresponding author), Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
EM engaboomar2010@gmail.com; moh_naby@yahoo.com; msel_dolil@yahoo.com;
   fathi_sayed@yahoo.com
RI Abd-Elnaby, Mohammed/AAD-6573-2022; Sayed, Fathi/HRA-4752-2023
OI Abd-Elnaby, Mohammed/0000-0002-8217-1190; Sayed,
   Fathi/0000-0001-8749-9518
CR Abdulsattar M., 2012, Int. J. Comput. Networks Commun, V4, P223
   Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   [Anonymous], ACTION2ACTIVITY RECO
   [Anonymous], P 30 AAAI C ART INT
   [Anonymous], ACTION ACTIVITY SENS
   [Anonymous], IEEEWCN MAC
   [Anonymous], US FREQ ALL
   [Anonymous], INT J ENG INNOV TECH
   Axell E, 2012, IEEE SIGNAL PROC MAG, V29, P101, DOI 10.1109/MSP.2012.2183771
   Ben Letaief K, 2009, P IEEE, V97, P878, DOI 10.1109/JPROC.2009.2015716
   Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380
   Li JC, 2017, DESTECH TRANS ENVIR, V168, P90, DOI 10.1016/j.aeue.2017.05.026
   Liang YC, 2007, IEEE ICC, P5330, DOI 10.1109/ICC.2007.882
   Liu X, 2013, RADIO SCI, V48, P23, DOI 10.1029/2012RS005009
   Maleki S, 2011, SPAWC 2011: 2011 IEEE 12TH INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING ADVANCES IN WIRELESS COMMUNICATIONS, P71, DOI 10.1109/SPAWC.2011.5990482
   Peh E, 2007, IEEE WCNC, P27, DOI 10.1109/WCNC.2007.11
   Peh ECY, 2009, IEEE T VEH TECHNOL, V58, P5294, DOI 10.1109/TVT.2009.2028030
   Peng Q., 2006, IEEE 17th International Symposium on Personal, Indoor and Mobile Radio Communications, P1
   Smitha KG, 2012, AEU-INT J ELECTRON C, V66, P619, DOI 10.1016/j.aeue.2012.03.016
   Stotas S, 2012, IEEE T WIREL COMMUN, V11, P97, DOI 10.1109/TWC.2011.111611.101716
   Subhedar Mansi., 2011, INT J NEXT GENERATIO, V3, P37
   Tang HY, 2005, 2005 1st IEEE International Symposium on New Frontiers in Dynamic Spectrum Access Networks, Conference Record, P151
   Tang L, 2011, IEEE T WIREL COMMUN, V10, P1063, DOI 10.1109/TWC.2011.020111.101870
   Visotsky E, 2005, 2005 1st IEEE International Symposium on New Frontiers in Dynamic Spectrum Access Networks, Conference Record, P338
   You C, 2011, IEEE T CONSUM ELECTR, V57, P62, DOI 10.1109/TCE.2011.5735482
   Yücek T, 2009, IEEE COMMUN SURV TUT, V11, P116, DOI 10.1109/SURV.2009.090109
   Zou YL, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON CHILDREN AND YOUTH FITNESS AND HEALTH, VOL 1, P1, DOI 10.1109/NLPKE.2010.5587770
NR 27
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34999
EP 35025
DI 10.1007/s11042-019-07782-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800034
DA 2024-07-18
ER

PT J
AU Hassan, M
   Shanableh, T
AF Hassan, Mahitab
   Shanableh, Tamer
TI Predicting split decisions of coding units in HEVC video compression
   using machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Pattern recognition; Video compression
ID SIZE DECISION; EFFICIENCY; INTER; ALGORITHM; DEPTH; TERMINATION; MODE
AB In this work, we propose to reduce the complexity of HEVC video encoding by predicting the split decisions of coding units. We use a sequence-dependent approach in which a number of frames belonging to the video being encoded are used for generating a classification model. At each coding depth of the coding units, features representing the coding unit at that particular depth are extracted from both the present and previously encoded coding units. The feature vectors are then used for generating a dimensionality reduction model and a classification model. The generated models at each coding depth are then used to predict the split decisions of subsequent coding units. Stepwise regression, random forest reduction and principal component analysis are used for dimensionality reduction; whereas, polynomial networks and random forests are utilized for classification. The proposed solution is assessed in terms of classification accuracy, BD-rate, BD-PSNR and computational time complexity. Using seventeen video sequences with four different classes of resolution, an average classification accuracy of 86.5% is reported for the proposed classification system. In comparison to regular HEVC coding, the proposed solution resulted in a BD-rate loss of 0.55 and a BD-PSNR of -0.02 dB. The average reported computational complexity reduction is found to be 39.2%.
C1 [Hassan, Mahitab; Shanableh, Tamer] Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
   [Hassan, Mahitab] IBM Cloud, Dubai, U Arab Emirates.
C3 American University of Sharjah
RP Shanableh, T (corresponding author), Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
EM mahitab.hassan@alumni.aus.edu; tshanableh@aus.edu
RI Shanableh, Tamer/AAC-7893-2021
OI Shanableh, Tamer/0000-0002-7651-3094
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Bjontegaard G., 2008, VCEGAI11
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Chung CH, 2017, I S INTELL SIG PROC, P570, DOI 10.1109/ISPACS.2017.8266543
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Deng X, 2016, IEEE T CIRC SYST VID, V26, P91, DOI 10.1109/TCSVT.2015.2474075
   Du B, 2015, P APSIPA ANN SUMM C
   Genuer R, 2010, PATTERN RECOGN LETT, V31, P2225, DOI 10.1016/j.patrec.2010.03.014
   Goswami K, 2016, INFORM SCIENCES, V364, P72, DOI 10.1016/j.ins.2016.05.018
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hu Q, 2016, IEEE T MULTIMEDIA, V18, P379, DOI 10.1109/TMM.2015.2512799
   Jiménez-Moreno A, 2016, IEEE T MULTIMEDIA, V18, P563, DOI 10.1109/TMM.2016.2524995
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim I-K, 2013, 15 M GEN
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Liu ZY, 2016, J VIS COMMUN IMAGE R, V38, P474, DOI 10.1016/j.jvcir.2016.03.025
   Livingston Frederick., 2005, ECE591Q Machine Learning Journal Paper
   Mallikarachchi T, 2018, IEEE T CIRCUITS SYST, V28
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Park SJ, 2016, SIGNAL PROCESS-IMAGE, V42, P79, DOI 10.1016/j.image.2015.12.006
   Peixoto E, 2014, IEEE T CIRCUITS SYST, V24
   Radosavljevic M, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1377, DOI 10.1109/GlobalSIP.2015.7418424
   Shanableh T, 2010, NEUROCOMPUTING, V73, P1752, DOI 10.1016/j.neucom.2009.11.045
   Shanableh T, 2013, IEEE T CIRCUITS SYST, V23
   Shanableh T, 2011, IEEE SIGNAL PROC LET, V18, P335, DOI 10.1109/LSP.2011.2130524
   Shen LQ, 2015, SIGNAL PROCESS-IMAGE, V32, P121, DOI 10.1016/j.image.2015.01.008
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tai K-H, 2017, IEEE T BROADCASTING, V63
   Toh KA, 2004, IEEE T PATTERN ANAL, V26, P740, DOI 10.1109/TPAMI.2004.3
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Xiong J, 2015, IEEE T MULTIMEDIA, V17, P2147, DOI 10.1109/TMM.2015.2491018
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yang S-H, 2017, IEEE INT C COMP INF
   Yoo HM, 2014, ELECTRON LETT, V50, P750, DOI 10.1049/el.2014.0451
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao WJ, 2015, IEEE T CIRC SYST VID, V25, P1651, DOI 10.1109/TCSVT.2015.2395751
   Zupancic I, 2016, IEEE T MULTIMEDIA, V18, P1677, DOI 10.1109/TMM.2016.2579505
NR 41
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32735
EP 32754
DI 10.1007/s11042-018-6882-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600007
DA 2024-07-18
ER

PT J
AU Huang, Y
   Zhao, ZQ
   Wu, B
   Mei, ZL
   Cui, ZM
   Gao, GY
AF Huang, Yang
   Zhao, Zhiqiang
   Wu, Bin
   Mei, Zhuolin
   Cui, Zongmin
   Gao, Guangyong
TI Visual object tracking with discriminative correlation filtering and
   hybrid color feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Hybrid color feature; Correlation filtering; Histogram
   of oriented gradients; Opponent; Color name
AB The technology of visual object tracking based on correlation filter has good accuracy and efficiency. However, it is still necessary to be study further on the appearance model of the target, the scale variation of the target and so on. This paper proposes a tracking algorithm based on discriminative correlation filtering and a hybrid color feature. The hybrid color feature is composed of two parts, which are compressed color name features and Histogram of Oriented Gradient features based on opponent color space. These two parts features above are extracted from the target patch, respectively. For the first part, color-name features are extracted from a target patch firstly, and then block-based compressed color-name features are extracted according to these color-name features. For the second part, opponent color features are extracted from the target patch firstly, and then HOG features are extracted from these opponent color features. At the basis of the hybrid color feature, two different discriminative correlation filters are used to estimate the translation and the scale of the target, respectively. Finally, extensive experiments show that the tracking algorithm with the hybrid color features of this paper outperforming several state-of-the-art tracking algorithms.
C1 [Huang, Yang; Zhao, Zhiqiang; Wu, Bin; Mei, Zhuolin; Cui, Zongmin; Gao, Guangyong] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Jiangxi, Peoples R China.
   [Gao, Guangyong] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210000, Jiangsu, Peoples R China.
C3 Jiujiang University; Nanjing University of Information Science &
   Technology
RP Zhao, ZQ (corresponding author), Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Jiangxi, Peoples R China.
EM hy55001144@foxmail.com; zqzhao2000@foxmail.com; wubincs@gmail.com;
   meizhuolin@126.com; cuizm01@gmail.com; gaoguangyong@163.com
OI Zhiqiang, Zhao/0000-0001-6627-9807
FU Science and Technology Research Project of Jiangxi Education Department
   [GJJ180904]; National Natural Science Foundation of China [61762055,
   61572214, 61662039]; Jiangxi Provincial Natural Science Foundation of
   China [20181BAB202014]; Humanities and Social Sciences Foundation of
   Colleges and Universities in Jiangxi Province [TQ18111]
FX Thank the editor and the anonymous referees for their valuable comments.
   This research was supported by the Science and Technology Research
   Project of Jiangxi Education Department (No. GJJ180904), the National
   Natural Science Foundation of China (No. 61762055, 61572214 and
   61662039), the Jiangxi Provincial Natural Science Foundation of China
   (No. 20181BAB202014) and the Humanities and Social Sciences Foundation
   of Colleges and Universities in Jiangxi Province (No. TQ18111).
CR [Anonymous], REAL TIME RGB TRACKI
   [Anonymous], IEEE T PATTERN ANAL
   Bai B, 2018, NEUROCOMPUTING, V286, P109, DOI 10.1016/j.neucom.2018.01.068
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bolme DS, 2009, PROC CVPR IEEE, P2105, DOI 10.1109/CVPRW.2009.5206701
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang HL, 2016, NEUROCOMPUTING, V207, P189, DOI 10.1016/j.neucom.2016.03.074
   Khalid O, 2017, IEEE T CIRC SYST VID, V27, P1527, DOI 10.1109/TCSVT.2016.2542699
   Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0
   Kim DH, 2012, ETRI J, V34, P399, DOI [10.4218/etrij.11.0111.0383, 10.4218/etrij.12.0111.0383]
   Kristan M., 2014, 13 EUR C COMP VIS EC, P191
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   van de Sande KEA, 2008, PROC CVPR IEEE, P2463
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yao R, 2017, IEEE T MULTIMEDIA, V19, P772, DOI 10.1109/TMM.2016.2631727
   Yu L, 2018, MACH VISION APPL, V29, P361, DOI 10.1007/s00138-017-0902-y
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
NR 45
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34725
EP 34744
DI 10.1007/s11042-019-07901-w
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800023
DA 2024-07-18
ER

PT J
AU Li, YX
   Zhang, YH
   Li, XK
   Liu, ML
   Wang, WC
   Yang, JC
AF Li, Yanxiong
   Zhang, Yuhan
   Li, Xianku
   Liu, Mingle
   Wang, Wucheng
   Yang, Jichen
TI Acoustic event diarization in TV/movie audios using deep embedding and
   integer linear programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep embedding; integer linear programming; acoustic event detection;
   audio content analysis
ID CLASSIFICATION; FEATURES; DISTANCE; SCENES
AB In this study, we propose a method for acoustic event diarization based on a feature of deep embedding and a clustering algorithm of integer linear programming. The deep embedding learned by deep auto-encoder network is used to represent the properties of different classes of acoustic events, and then the integer linear programming is adopted for merging audio segments belonging to the same class of acoustic events. Four kinds of TV/movie audios (21.5 h in total) are used as experimental data, including Sport, Situation comedy, Award ceremony, and Action movie. We compare the deep embedding with state-of-the-art features. Further, the clustering algorithm of integer linear programming is compared with other clustering algorithms adopted in previous works. Finally, the proposed method is compared to both supervised and unsupervised methods on four kinds of TV/movie audios. The results show that the proposed method is superior to other unsupervised methods based on agglomerative information bottleneck, Bayesian information criterion and spectral clustering, and is little inferior to the supervised method based on deep neural network in terms of acoustic event error.
C1 [Li, Yanxiong; Zhang, Yuhan; Li, Xianku; Liu, Mingle; Wang, Wucheng; Yang, Jichen] South China Univ Technol, Sch Elect & Informat Engn, Room 223,Shaw Sci Bldg,381 Wushan Rd, Guangzhou 510640, Guangdong, Peoples R China.
C3 South China University of Technology
RP Yang, JC (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Room 223,Shaw Sci Bldg,381 Wushan Rd, Guangzhou 510640, Guangdong, Peoples R China.
EM NisonYoung@yahoo.cn
RI zhang, yuhan/HLH-1222-2023; yang, jichen/HDL-9203-2022
OI zhang, yuhan/0009-0001-3739-7238; Li, Yanxiong/0000-0003-4362-1125
FU national natural science foundation of China [61771200, 6191101285,
   6191101306]; project of international science and technology cooperation
   of Guangdong province [2019A050509001]; national laboratory of pattern
   recognition (NLPR) [201800004]; fundamental research funds for the
   central universities, South China University of Technology; project of
   science and technology of Guangzhou [201704040062]
FX The work was supported by the national natural science foundation of
   China (61771200, 6191101285, and 6191101306), the project of
   international science and technology cooperation of Guangdong province
   (2019A050509001), the open project program of the national laboratory of
   pattern recognition (NLPR) (201800004), the fundamental research funds
   for the central universities, South China University of Technology
   (Research on key techniques for analyzing complex audio scene contents,
   2019), and the project of science and technology of Guangzhou
   (201704040062).
CR Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   [Anonymous], 2016, P DET CLASS AC SCEN
   [Anonymous], 2013, P 21 EUR SIGN PROC C
   Benetos E, 2017, IEEE-ACM T AUDIO SPE, V25, P1266, DOI 10.1109/TASLP.2017.2690576
   Burileanu D, 2000, LECT NOTES ARTIF INT, V1902, P177
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Garcia-Romero D, 2010, INT CONF ACOUST SPEE, P1806, DOI 10.1109/ICASSP.2010.5495407
   Gencoglu O, 2014, EUR SIGNAL PR CONF, P506
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Tran HD, 2011, IEEE T AUDIO SPEECH, V19, P1556, DOI 10.1109/TASL.2010.2093519
   Phan H, 2015, IEEE-ACM T AUDIO SPE, V23, P20, DOI 10.1109/TASLP.2014.2367814
   Küçükbay SE, 2015, IEEE INT C SEMANT CO, P475, DOI 10.1109/ICOSC.2015.7050855
   Kumar A, 2012, INT CONF ACOUST SPEE, P489, DOI 10.1109/ICASSP.2012.6287923
   Laffitte P, 2016, INT CONF ACOUST SPEE, P6460, DOI 10.1109/ICASSP.2016.7472921
   Lee D, 2017, 2017 INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP), P71, DOI 10.1109/ICVISP.2017.19
   Li Lu, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P292, DOI 10.1109/iCECE.2010.78
   Li YX, 2009, SIGNAL PROCESS, V89, P1625, DOI 10.1016/j.sigpro.2009.03.001
   Li YX, 2018, IEEE ACCESS, V6, P58043, DOI 10.1109/ACCESS.2018.2872931
   Li YX, 2018, MULTIMED TOOLS APPL, V77, P897, DOI 10.1007/s11042-016-4332-z
   Li YX, 2017, DIGIT SIGNAL PROCESS, V63, P123, DOI 10.1016/j.dsp.2016.12.012
   Li YX, 2017, COMPUT SPEECH LANG, V42, P81, DOI 10.1016/j.csl.2016.09.002
   Li YX, 2014, IET SIGNAL PROCESS, V8, P844, DOI 10.1049/iet-spr.2013.0340
   Lu L, 2008, IEEE T MULTIMEDIA, V10, P74, DOI 10.1109/TMM.2007.911304
   McLoughlin I, 2015, IEEE-ACM T AUDIO SPE, V23, P540, DOI 10.1109/TASLP.2015.2389618
   Mesaros A, 2017, DCASE 2017 WORKSHOP
   Niessen ME, 2013, IEEE WORK APPL SIG
   Plumbley M. D., 2018, P DET CLASS AC SCEN
   Portêlo J, 2009, INT CONF ACOUST SPEE, P1973, DOI 10.1109/ICASSP.2009.4959998
   Reynolds DA, 2005, INT CONF ACOUST SPEE, P953
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Schädler MR, 2012, J ACOUST SOC AM, V131, P4134, DOI 10.1121/1.3699200
   Schröder J, 2017, IEEE-ACM T AUDIO SPE, V25, P1304, DOI 10.1109/TASLP.2017.2690569
   Schröder J, 2015, IEEE-ACM T AUDIO SPE, V23, P2198, DOI 10.1109/TASLP.2015.2467964
   Schröder J, 2013, INT CONF ACOUST SPEE, P493, DOI 10.1109/ICASSP.2013.6637696
   Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
   Temko A, 2007, LECT NOTES COMPUT SC, V4122, P311
   Valente F, 2010, INT CONF ACOUST SPEE, P4954, DOI 10.1109/ICASSP.2010.5495087
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Xugang Lu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6255, DOI 10.1109/ICASSP.2014.6854807
   Yang JC, 2013, J COMPUT, V8, P638, DOI 10.4304/jcp.8.3.638-644
   Yipei Wang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1360, DOI 10.1109/ICASSP.2014.6853819
   Yu D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P244
   Zhang XY, 2015, INT CONF ACOUST SPEE, P166, DOI 10.1109/ICASSP.2015.7177953
NR 44
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33999
EP 34025
DI 10.1007/s11042-019-07991-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600064
DA 2024-07-18
ER

PT J
AU Liu, T
   Zhu, JT
   Zhou, JK
   Zhu, YX
   Zhu, XF
AF Liu, Tong
   Zhu, Jingting
   Zhou, Jukai
   Zhu, YongXin
   Zhu, Xiaofeng
TI Initialization-similarity clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE k-means clustering; Spectral clustering; Initialization; Similarity
ID SELECTION; MATRIX
AB Classic k-means clustering algorithm randomly selects centroids for initialization to possibly output unstable clustering results. Moreover, random initialization makes the clustering result hard to reproduce. Spectral clustering algorithm is a two-step strategy, which first generates a similarity matrix and then conducts eigenvalue decomposition on the Laplacian matrix of the similarity matrix to obtain the spectral representation. However, the goal of the first step in the spectral clustering algorithm does not guarantee the best clustering result. To address the above issues, this paper proposes an Initialization-Similarity (IS) algorithm which learns the similarity matrix and the new representation in a unified way and fixes initialization using the sum-of-norms regularization to make the clustering more robust. The experimental results on ten real-world benchmark datasets demonstrate that our IS clustering algorithm outperforms the comparison clustering algorithms in terms of three evaluation metrics for clustering algorithm including accuracy (ACC), normalized mutual information (NMI), and Purity.
C1 [Liu, Tong; Zhu, Xiaofeng] GuangXi Normal Univ, GuangXi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Liu, Tong; Zhu, Jingting; Zhou, Jukai; Zhu, Xiaofeng] Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
   [Zhu, YongXin] Hebei GEO Univ, Dept Comp Sci & Technol, Shijiazhuang 050000, Hebei, Peoples R China.
C3 Guangxi Normal University; Massey University; Hebei GEO University
RP Zhu, XF (corresponding author), GuangXi Normal Univ, GuangXi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Zhu, XF (corresponding author), Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
EM S.Zhu@massey.ac.nz
RI Zhu, Xiaofeng/HII-5291-2022; lin, yuan/JXL-9592-2024
OI Zhu, Xiaofeng/0000-0001-6840-0578; Zhu, Jinting/0000-0002-0682-1796;
   Liu, Tong/0000-0003-3047-1148
FU GuangxiKey Lab of Multi-source Information Mining Security
   [MIMS18-M-01]; Natural Science Foundation of China [61876046, 61573270];
   Guangxi High Institutions Program of Introducing 100 High-Level Overseas
   Talents; Strategic Research Excellence Fund at Massey University;
   Marsden Fund of New Zealand [MAU1721]
FX This work was partially supported by the Research Fund of GuangxiKey Lab
   of Multi-source Information Mining & Security (MIMS18-M-01), the Natural
   Science Foundation of China (Grants No: 61876046 and 61573270); the
   Guangxi High Institutions Program of Introducing 100 High-Level Overseas
   Talents; the Strategic Research Excellence Fund at Massey University,
   and the Marsden Fund of New Zealand (Grant No: MAU1721).
CR Ahmed T, 2018, IET IMAGE PROCESS, V12, P1056, DOI 10.1049/iet-ipr.2017.0550
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], 2007, INT J COMPUT SCI
   [Anonymous], 2013, INT J CURR ENG TECHN
   Barron J.T., 2017, A more general robust loss function
   Bian ZK, 2019, IEEE T FUZZY SYST, V27, P31, DOI 10.1109/TFUZZ.2018.2856081
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Bu Z, 2018, KNOWL INF SYST, V55, P741, DOI 10.1007/s10115-017-1105-6
   Cherng JS, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P83, DOI 10.1109/ICDM.2001.989504
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Das A, 2018, AKCE INT J GRAPHS CO, V15, P261, DOI 10.1016/j.akcej.2017.10.006
   Domeniconi C., 2009, ACM Transactions on Knowledge Discovery from Data, V2, P1, DOI [10.1145/1460797.1460800, DOI 10.1145/1460797.1460800]
   Duan YL, 2018, AIP CONF PROC, V1955, DOI 10.1063/1.5033710
   Estivill-Castro V, 2000, ISSDH, P1
   Geman S., 1987, Bull. Internat. Statist. Inst., V4, P5
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kang Z, 2019, KNOWL-BASED SYST, V163, P510, DOI 10.1016/j.knosys.2018.09.009
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kuncheva LI, 2006, IEEE T PATTERN ANAL, V28, P1798, DOI 10.1109/TPAMI.2006.226
   Lakshmi Muddana A., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P27, DOI 10.1007/978-981-13-3600-3_3
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Lindsten F, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P201, DOI 10.1109/SSP.2011.5967659
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Moftah HM, 2014, NEURAL COMPUT APPL, V24, P1917, DOI 10.1007/s00521-013-1437-4
   Motwani M, 2019, ADV INTELL SYST COMP, V731, P211, DOI 10.1007/978-981-10-8848-3_21
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Park S, 2018, BIOINFORMATICS, V34, P2069, DOI 10.1093/bioinformatics/bty050
   Pavan K. Karteeka, 2010, Journal of Computer Sciences, V6, P60, DOI 10.3844/jcssp.2010.60.66
   Radhakrishna V, 2018, FUTURE GENER COMP SY, V83, P582, DOI 10.1016/j.future.2017.03.016
   Rasmussen CE, 2000, ADV NEUR IN, V12, P554
   Rong H, 2018, SOFT COMPUT, V22, P2583, DOI 10.1007/s00500-017-2513-y
   Satsiou A, 2018, INSCI
   Saxena A, 2017, NEUROCOMPUTING, V267, P664, DOI 10.1016/j.neucom.2017.06.053
   Shah SA, 2017, P NATL ACAD SCI USA, V114, P9814, DOI 10.1073/pnas.1700770114
   Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307
   Silva FB, 2018, PATTERN RECOGN, V74, P266, DOI 10.1016/j.patcog.2017.09.018
   Singh A., 2013, International Journal of Computer Applications, V67, P13, DOI [10.5120/11430-6785, 10.5120/11430-6785,10, DOI 10.5120/11430-6785,10]
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Voloshinov VV, 2018, COMP MATH MATH PHYS+, V58, P364, DOI 10.1134/S0965542518030132
   Wang CL, 2018, IEEE ACCESS, V6, P77911, DOI 10.1109/ACCESS.2018.2884441
   Wong KC, 2015, ISCMI
   Wu S, 2014, NEUROCOMPUTING, V135, P229, DOI 10.1016/j.neucom.2013.12.027
   Xiao X, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P373, DOI 10.1145/2818346.2823297
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu XW, 1998, PROC INT CONF DATA, P324, DOI 10.1109/ICDE.1998.655795
   Yan Q, 2019, COGN SYST RES, V53, P98, DOI 10.1016/j.cogsys.2018.01.003
   Zahra S, 2015, INFORM SCIENCES, V320, P156, DOI 10.1016/j.ins.2015.03.062
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou X, 2020, IEEE T CYBERNETICS, V50, P1460, DOI 10.1109/TCYB.2018.2883970
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
NR 61
TC 7
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33279
EP 33296
DI 10.1007/s11042-019-7663-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600032
DA 2024-07-18
ER

PT J
AU Wu, YF
   Liu, XL
   Zhou, DX
   Liu, Y
AF Wu, Yongfei
   Liu, Xilin
   Zhou, Daoxiang
   Liu, Yang
TI Adaptive active contour model driven by image data field for image
   segmentation with flexible initialization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour model; Image segmentation; Image data field;
   Initialization
ID TRANSITION REGION EXTRACTION; SCALABLE FITTING ENERGY; LEVEL SET
   EVOLUTION; INTELLIGENT SURVEILLANCE; ENTROPY; MUMFORD; TRACKING
AB In this paper, a novel adaptive active contour model based on image data field for image segmentation with robust and flexible initializations is proposed. We firstly construct a new external energy term deduced from the image data field that drives the level set function to move in the opposite direction along the boundaries of object and an adaptive length regularization term based on the image local entropy. The designed external energy and length regularization term are then incorporated into a variationlevel set framework with an additional penalizing energy term. Due to the adaptive sign-changing property of the external energy and the adaptive length regularization term, the proposed model can tackle images with clutter background and noise, the level set function can be initialized as any bounded functions (e.g., constant function), which implies the proposed model is robust to initialization of contours. Experimental results on both synthetic and real images from different modalities confirm the effectiveness and competivive performance of the proposed method compared with other representative models.
C1 [Wu, Yongfei; Liu, Xilin; Zhou, Daoxiang] Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Shanxi, Peoples R China.
   [Wu, Yongfei] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Taipa, Macau, Peoples R China.
   [Liu, Yang] Chongqing Univ, Coll Math & Stat, Chongqing 401331, Peoples R China.
C3 Taiyuan University of Technology; University of Macau; Chongqing
   University
RP Zhou, DX (corresponding author), Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Shanxi, Peoples R China.
EM yongfeiwu522@sina.com; liuxilin@tyut.edu.cn; dxzhou@cqu.edu.cn;
   cquyangliu@163.com
RI Wu, Yongfei/AAI-2243-2019; Liu, Xilin/AAL-6947-2021; Liu,
   Xilin/AFQ-1082-2022
OI Liu, Xilin/0000-0002-1136-6783
FU National Natural Science Foundation of China [61901292]; Scientific and
   Technological Innovation Programs of Higher Education Institutions in
   Shanxi [2017141]; Natural Science Foundation of Shanxi Province, China
   [201801D221186]; School Foundation of Taiyuan University of Technology
   [2017QN11, 2017QN12]
FX The authors would like to thank the editor and anonymous reviewers for
   their helpful and vaulable comments for improving our paper. This work
   is paritally supported by the National Natural Science Foundation of
   China (No. 61901292), Scientific and Technological Innovation Programs
   of Higher Education Institutions in Shanxi (No. 2017141), the Natural
   Science Foundation of Shanxi Province, China (No. 201801D221186) and
   School Foundation of Taiyuan University of Technology (No. 2017QN11, No.
   2017QN12).
CR Appleton B, 2005, J MATH IMAGING VIS, V23, P67, DOI 10.1007/s10851-005-4968-1
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Basaeed E, 2016, KNOWL-BASED SYST, V99, P19, DOI 10.1016/j.knosys.2016.01.028
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Crandall R., 2009, 532 ECE
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Esedoglu S, 2006, J COMPUT PHYS, V211, P367, DOI 10.1016/j.jcp.2005.05.027
   FRIEDEN BR, 1972, J OPT SOC AM, V62, P511, DOI 10.1364/JOSA.62.000511
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537
   Lee SH, 2006, IEEE T IMAGE PROCESS, V15, P2843, DOI 10.1109/TIP.2006.877308
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li M, 2016, E ASIAN J APPL MATH, V6, P1, DOI 10.4208/eajam.231114.240915a
   Li ZY, 2009, COMPUT ELECTR ENG, V35, P696, DOI 10.1016/j.compeleceng.2009.02.001
   Liu B, 2010, PATTERN RECOGN, V43, P2028, DOI 10.1016/j.patcog.2010.01.002
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu Y, 2018, DIGIT SIGNAL PROCESS, V78, P42, DOI 10.1016/j.dsp.2018.01.017
   Liu ZX, 2006, APPL MATH COMPUT, V178, P380, DOI 10.1016/j.amc.2005.11.053
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Ren ZM, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/145343
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   SHIOZAKI A, 1986, COMPUT VISION GRAPH, V36, P1, DOI 10.1016/S0734-189X(86)80025-1
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang B, 2014, IEEE T CYBERNETICS, V44, P418, DOI 10.1109/TCYB.2013.2256891
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Wang Y, 2012, APPL MATH MODEL, V36, P3211, DOI 10.1016/j.apm.2011.10.023
   Wu T, 2012, COMPUT ELECTR ENG, V38, P459, DOI 10.1016/j.compeleceng.2011.10.002
   Wu T, 2012, OPT LASER ENG, V50, P131, DOI 10.1016/j.optlaseng.2011.09.017
   Wu YF, 2016, NEUROCOMPUTING, V171, P194, DOI 10.1016/j.neucom.2015.06.027
   Wu YF, 2015, SIGNAL PROCESS, V106, P123, DOI 10.1016/j.sigpro.2014.07.013
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xu HY, 2018, COMPUT ELECTR ENG, V70, P317, DOI 10.1016/j.compeleceng.2016.06.010
   Yan CX, 2003, PATTERN RECOGN LETT, V24, P2935, DOI 10.1016/S0167-8655(03)00154-5
   Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhao F, 2013, DIGIT SIGNAL PROCESS, V23, P184, DOI 10.1016/j.dsp.2012.09.016
NR 50
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33633
EP 33658
DI 10.1007/s11042-019-08098-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600049
DA 2024-07-18
ER

PT J
AU Azimi, Z
   Ahadpour, S
AF Azimi, Z.
   Ahadpour, S.
TI Color image encryption based on DNA encoding and pair coupled chaotic
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Cryptography; DNA computing; Pair coupled chaotic maps
ID SEQUENCE OPERATION; ALGORITHM; DIFFUSION; SECURE
AB Information security has become a significant issue in encryption due to the rapid progress of internet and network. Therefore, the development of the encryption algorithm is a growing and significant problem. In this study, a new color image encryption was introduced based on DNA complementary rules and pair coupled chaotic maps. At first, the plain color image was divided into three components (R, G, B) being converted into three DNA matrices using DNA encoding rules. Secondly, DNA addition for R, G and B components was implemented and scrambled the elements position of three DNA sequence via the pair coupled chaotic maps. Three gray coded images obtained and RGB encrypted image was achieved by restructuring R, G, B components. The simulation of experimental result and security analysis showed that this algorithm had larger secret key space and strong secret key sensitivity and it had excellent ability to resist against statistical and differential attacks.
C1 [Azimi, Z.; Ahadpour, S.] Univ Mohaghegh Ardabili, Dept Phys, Ardebil, Iran.
C3 University of Mohaghegh Ardabili
RP Ahadpour, S (corresponding author), Univ Mohaghegh Ardabili, Dept Phys, Ardebil, Iran.
EM z.azimi@uma.ac.ir; ahadpour@uma.ac.ir
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Ahadpour S, 2009, COMMUN NONLINEAR SCI, V14, P2916, DOI 10.1016/j.cnsns.2008.10.029
   Ahadpour S, 2013, DISCRETE IMPULSIVE B, V20, P283
   Ahadpour S, 2012, INFORM SCIENCES, V197, P161, DOI 10.1016/j.ins.2012.02.022
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Behnia S, 2011, DYNAM CONT DIS SER A, V18, P245
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Jafarizadeh MA, 2001, J STAT PHYS, V104, P1013, DOI 10.1023/A:1010449627146
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 32
TC 29
Z9 29
U1 2
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1727
EP 1744
DI 10.1007/s11042-019-08375-6
EA NOV 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2UJ
UT WOS:000495202900001
DA 2024-07-18
ER

PT J
AU Jiang, YT
   Wu, CX
   Deng, KF
   Wu, Y
AF Jiang, Yuantao
   Wu, Chunxue
   Deng, Kaifa
   Wu, Yan
TI An audio fingerprinting extraction algorithm based on lifting wavelet
   packet and improved optimal-basis selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Intelligent multimedia; Artificial intelligence;
   Audio fingerprinting; Lifting wavelet packet; Improved optimum-basis
   selection algorithm
ID LAGRANGE INTERPOLATION; CLASSIFICATION; SEARCH; RETRIEVAL; TRANSFORM;
   FEATURES; SCHEME
AB Audio fingerprinting technology is widely applied to the analysis and processing of digital signal, especially in the application of speech recognition which is one of the most popular fields of the intelligent multimedia and artificial intelligence. Traditional audio fingerprinting extraction algorithm is based on the decomposition and reconstruction of the wavelet packet. But the requirement of computational capacity and memory is so large. So this paper proposed an algorithm which is based on the lifting wavelet packet and the improved optimal-basis selection to find the coefficient of optimal wavelet packet. Then the average of the logarithmic energy entropy is adopted as the characteristic parameter. And the capacity of computing and memory is better than the traditional algorithm because of the lifting wavelet packet which is more suitable for processing of speech online and the design of intelligent multimedia. And the experiment results indicate that this algorithm is not only robust for the audio which is handled by some kinds of methods and can reflect the overall characteristics of the audio very well, but also has good distinguishability between different audio.
C1 [Jiang, Yuantao; Wu, Chunxue] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
   [Deng, Kaifa] Shanghai Univ Engn Sci, Sch Art & Design, Shanghai, Peoples R China.
   [Wu, Yan] Indiana Univ, Sch Publ & Environm Affairs, Bloomington, IN USA.
C3 University of Shanghai for Science & Technology; Shanghai University of
   Engineering Science; Indiana University System; Indiana University
   Bloomington
RP Wu, CX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
EM j17621607346@163.com; wcx@usst.edu.cn; dengkaifa@126.com;
   wuyan8910@126.com
RI Chunxue, Wu/L-1972-2019
OI Chunxue, Wu/0000-0001-8498-3881
FU Shanghai Science and Technology Innovation Action Plan Project
   [16111107502, 17511107203]; National Natural Science Foundation of China
   [61502220]; Zhejiang Provincial Natural Science Foundation of China;
   program for tackling key problems in Henan science and technology
   [172102310636]; Nanjing Leading Science and Technology Entrepreneurial
   Talents Introduction ProgramFunded Project [2014A090002]
FX This study was supported by the Shanghai Science and Technology
   Innovation Action Plan Project (16111107502, 17511107203),the National
   Natural Science Foundation of China (61502220), the Zhejiang Provincial
   Natural Science Foundation of China (No.LY14F020044), the program for
   tackling key problems in Henan science and technology (No.172102310636)
   and the Nanjing Leading Science and Technology Entrepreneurial Talents
   Introduction ProgramFunded Project (2014A090002).
CR Baluja S, 2008, PATTERN RECOGN, V41, P3467, DOI 10.1016/j.patcog.2008.05.006
   Brechet L, 2007, IEEE T BIO-MED ENG, V54, P2186, DOI 10.1109/TBME.2007.896596
   Burges CJC, 2003, IEEE T SPEECH AUDI P, V11, P165, DOI 10.1109/TSA.2003.811538
   Calvi JP, 2013, LMS J COMPUT MATH, V16, P45, DOI 10.1112/S1461157013000016
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Cano P, 2005, STUD COMP INTELL, V2, P233
   Cano P., 2005, 13th Annual ACM International Conference on Multimedia, P211, DOI 10.1145/1101149.1101181
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   Cotton CV, 2010, INT CONF ACOUST SPEE, P2386, DOI 10.1109/ICASSP.2010.5496185
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Haitsma J, 2003, J NEW MUSIC RES, V32, P211, DOI 10.1076/jnmr.32.2.211.16746
   LOWEN R, 1990, FUZZY SET SYST, V34, P33, DOI 10.1016/0165-0114(90)90124-O
   Lu CS, 2002, AUD FING BAS AN TIM
   Mitrovic D, 2010, ADV COMPUT, V78, P71, DOI 10.1016/S0065-2458(10)78003-7
   Muntean O, 2007, BEST SUBTREE GENETIC
   Ramalingam A, 2006, IEEE T INF FOREN SEC, V1, P457, DOI 10.1109/TIFS.2006.885036
   Seo JS, 2006, IEEE SIGNAL PROC LET, V13, P209, DOI 10.1109/LSP.2005.863678
   Suyi Li, 2009, 2009 2nd IEEE International Conference on Computer Science and Information Technology (ICCSIT 2009), P491, DOI 10.1109/ICCSIT.2009.5234650
   SWELDENS W, 1995, P SOC PHOTO-OPT INS, V2569, P68, DOI 10.1117/12.217619
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Umapathy K, 2007, IEEE T AUDIO SPEECH, V15, P1236, DOI 10.1109/TASL.2006.885921
   Wachter A, 2006, MATH PROGRAM, V106, P25, DOI 10.1007/s10107-004-0559-y
   Wang D, 2011, EXPERT SYST APPL, V38, P14314, DOI 10.1016/j.eswa.2011.05.096
   Wang Huawei, 2005, Tsinghua Science and Technology, V10, P128, DOI 10.1016/S1007-0214(05)70019-5
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Xie L, 2011, MULTIMEDIA SYST, V17, P101, DOI 10.1007/s00530-010-0205-x
NR 29
TC 10
Z9 12
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30011
EP 30025
DI 10.1007/s11042-018-6802-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200021
DA 2024-07-18
ER

PT J
AU Kaur, H
   Pannu, HS
   Malhi, AK
AF Kaur, Harsurinder
   Pannu, Husanbir Singh
   Malhi, Avleen Kaur
TI Multimedia blog volume prediction using adaptive neuro fuzzy inference
   system and evolutionary algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia blogs; Prediction; Adaptive neuro fuzzy inference system;
   Particle swarm optimization; Genetic algorithms
ID SOCIAL MEDIA; SENTIMENT CLASSIFICATION; E-GOVERNMENT; ANFIS;
   OPTIMIZATION; INTELLIGENCE; EDUCATION; ADOPTION; MODELS; IMPACT
AB Due to wide streaming multimedia blogs over the social networks, volume prediction has become indispensable for the analysis of blog popularity. As a rule base driven method, Adaptive Neuro Fuzzy Inference System has gained popularity in various prediction tasks for its efficiency and ease of implementation. In this paper, two modified Adaptive Neuro Fuzzy Inference System models have been proposed by tuning its premise and consequent parameters using (a) Particle swarm optimization and (b) Genetic algorithms, to improve its predictive performance. Particle Swarm Optimization helps in reducing the training and cross validation error of the predictive model whereas Genetic Algorithms optimize minimum clustering radius which aids in the formation of rule base. Comparative analysis of proposed method has been performed against Neural Networks, Support Vector Machines and basic Adaptive Neuro-Fuzzy Inference System. Both of the proposed variants have outperformed state-of-art techniques using Genetic algorithms and Particle swarm optimization when tested on UCI public dataset and real dataset of Twitter, making it well suitable for multimedia blog volume forecasting.
C1 [Kaur, Harsurinder; Pannu, Husanbir Singh; Malhi, Avleen Kaur] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Malhi, AK (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM hkaur2_me16@thapar.edu; hspannu@thapar.edu; avleen@thapar.edu
CR Ahmed Kamal, 2015, Applied Mechanics and Materials, V735, P190, DOI 10.4028/www.scientific.net/AMM.735.190
   [Anonymous], ARXIV151105296
   [Anonymous], 2017, ADV FUZZY LOGIC TECH
   [Anonymous], 2011, Proceedings of the International Conference on Web Intelligence, Mining and Semantics, DOI [DOI 10.1145/1988688.1988766, 10.1145/1988688.1988766]
   [Anonymous], ICWSM
   [Anonymous], 2006, 3 ANN WORKSH WEBL EC
   [Anonymous], NEW APPROACH ADAPTIV
   [Anonymous], 2011, J COMPUT SCI-NETH, DOI DOI 10.1016/j.jocs.2010.12.007
   [Anonymous], INF EL VIS ICIEV 201
   [Anonymous], 2016, Search and Optimization by Metaheuristics
   [Anonymous], 2015, ISMIR
   Arafat J., 2013, American Journal of Engineering Research, V2, P265
   Artzi Y., 2012, P 2012 C N AM CHAPT
   Bandari R., 2012, ICWSM, P26
   Bermingham Adam, 2011, On using twitter to monitor political sentiment and predict election results, P2
   Bessi A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159641
   Billah M., 2015, INT J COMPUTER APPL, V129, P1, DOI [10.5120/ijca2015906952, DOI 10.5120/IJCA2015906952]
   Bliss CA, 2014, J COMPUT SCI-NETH, V5, P750, DOI 10.1016/j.jocs.2014.01.003
   Blum Christian, 2008, P43, DOI 10.1007/978-3-540-74089-6_2
   Bonsón E, 2015, GOV INFORM Q, V32, P52, DOI 10.1016/j.giq.2014.11.001
   Buza K, 2014, STUD CLASS DATA ANAL, P145, DOI 10.1007/978-3-319-01595-8_16
   Cappallo S, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P195, DOI 10.1145/2671188.2749405
   Caschera MC, 2018, EVOLVING SYSTEMS, P1
   Castillo C., 2014, P 17 ACM C COMP SUPP, P211, DOI [10.1145/2531602.2531623, DOI 10.1145/2531602.2531623]
   Chau M, 2012, MIS QUART, V36, P1189
   Chavan VS, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2354, DOI 10.1109/ICACCI.2015.7275970
   Chen YY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/2/026101
   Cheung CMK, 2008, INTERNET RES, V18, P229, DOI 10.1108/10662240810883290
   Chiao-Fang Hsu, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P90, DOI 10.1109/CSE.2009.109
   Christin A, 2018, AM J SOCIOL, V123, P1382, DOI 10.1086/696137
   Chun Soon Ae, 2010, Information Polity, V15, P1, DOI 10.3233/IP-2010-0205
   Coursey D, 2008, PUBLIC ADMIN REV, V68, P523, DOI 10.1111/j.1540-6210.2008.00888.x
   Cui C, 2018, IEEE T MULTIMEDIA
   Dabbagh N, 2012, INTERNET HIGH EDUC, V15, P3, DOI 10.1016/j.iheduc.2011.06.002
   De Choudhury M., 2013, ICWSM, P1
   De Choudhury M., 2013, P 5 ANN ACM WEB SCI, P47
   Djuric N, 2014, IEEE DATA MINING, P779, DOI 10.1109/ICDM.2014.150
   Dorigo M, 2016, SWARM INTELL-US, V10, P245, DOI 10.1007/s11721-016-0130-5
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Emerson MDF, 2015, WORLD ALLERGY ORGAN, V8, pA136
   Falco N, 2015, IEEE T GEOSCI REMOTE, V53, P6223, DOI 10.1109/TGRS.2015.2436335
   Feng FB, 2017, INT GEOSCI REMOTE SE, P13, DOI 10.1109/IGARSS.2017.8126821
   Fornacciari Paolo, 2017, Personal Analytics and Privacy. An Individual and Collective Perspective. First International Workshop, PAP 2017 Held in Conjunction with ECML PKDD 2017. Revised Selected Papers. LNCS 10708, P98, DOI 10.1007/978-3-319-71970-2_9
   Gao H, 2011, IEEE INTELL SYST, V26, P10, DOI 10.1109/MIS.2011.52
   Garnier Simon, 2007, Swarm Intelligence, V1, P3, DOI 10.1007/s11721-007-0004-y
   Ghose DK, 2013, ALEX ENG J, V52, P209, DOI 10.1016/j.aej.2013.01.001
   Greer J, 2015, TELEMAT INFORM, V32, P594, DOI 10.1016/j.tele.2015.02.001
   Hosoya H, 2016, NEURAL COMPUT, V28, P1249, DOI 10.1162/NECO_a_00843
   Hvattum LM, 2011, WILEY ENCY OPERATION
   Imran A, 2017, SINDH U RES J SURJ S, V49, P1
   Jamali S, 2009, WISM: 2009 INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND MINING, PROCEEDINGS, P32, DOI 10.1109/WISM.2009.15
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kaur H., 2018, CHI 2018 EXTENDED AB, P1
   Kim J, 2015, CLUSTER COMPUT, V18, P157, DOI 10.1007/s10586-013-0337-9
   Krebs F., 2017, ARXIV171203249
   Kumar Nagendra, 2017, Mining Intelligence and Knowledge Exploration. 5th International Conference, MIKE 2017. Proceedings: LNAI 10682, P308, DOI 10.1007/978-3-319-71928-3_30
   Kushin MJ, 2010, MASS COMMUN SOC, V13, P608, DOI 10.1080/15205436.2010.516863
   Leskovec J., 2011, Proceedings of the 20th international conference companion on World wide web, P277, DOI [DOI 10.1145/1963192.1963309, 10.1145/1963192.1963309]
   Linders D, 2012, GOV INFORM Q, V29, P446, DOI 10.1016/j.giq.2012.06.003
   Liu L, 2018, LECT NOTES COMPUT SC, V10942, P351, DOI 10.1007/978-3-319-93818-9_33
   Maine S, 2001, SUICIDE LIFE-THREAT, V31, P320, DOI 10.1521/suli.31.3.320.24248
   Mazloom M, 2018, LECT NOTES COMPUT SC, V10704, P594, DOI 10.1007/978-3-319-73603-7_48
   Mergel I, 2013, PUBLIC ADMIN REV, V73, P390, DOI 10.1111/puar.12021
   Miguens J., 2008, ADV TOURISM RES, V26, P1, DOI [DOI 10.1088/1751-8113/44/8/085201, 10.1088/1751-8113/44/8/085201]
   Momeni E, 2013, ACM-IEEE J CONF DIG, P1
   Natarajan A, 2017, US Patent, Patent No. [9,852, 239, 9852239]
   Pantelidis IS, 2010, CORNELL HOSP Q, V51, P483, DOI 10.1177/1938965510378574
   Persing Isaac, 2014, P 2014 C EMP METH NA, P1127
   Pollara P., 2011, P SOC INFORM TECHNOL, P3330
   Prasad K, 2016, ATMOS ENVIRON, V128, P246, DOI 10.1016/j.atmosenv.2016.01.007
   Qualman E., 2010, Socialnomics: How social media transforms the way we live and do business
   Ryfe D, 2016, DIGIT JOURNAL, V4, P41, DOI 10.1080/21670811.2015.1093269
   Sadilek Adam., 2012, AAAI, DOI DOI 10.1609/AAAI.V26I1.8103
   Serrat O., 2017, Knowledge Solutions, P925, DOI DOI 10.1007/978-981-10-0983-9_105
   Shah P., 2018, 2018 4th International Conference on Computing Communication and Automation, ICCCA 2018, P1, DOI [DOI 10.23919/ICONAC.2018.8749023, 10.1109/CCAA.2018.8777602, DOI 10.1109/CCAA.2018.8777602]
   Shin KS, 2002, EXPERT SYST APPL, V23, P321, DOI 10.1016/S0957-4174(02)00051-9
   Singh Kamaljot, 2015, IEEE UKSIM AMSS 17 I
   Sterling M, 2017, ACAD MED, V92, P1043, DOI 10.1097/ACM.0000000000001617
   Su-Do Kim, 2011, Proceedings of the 2011 IEEE 11th International Conference on Computer and Information Technology (CIT 2011), P449, DOI 10.1109/CIT.2011.104
   Taylor M, 2016, STEP BY STEP WORDPRE
   Tess PA, 2013, COMPUT HUM BEHAV, V29, pA60, DOI 10.1016/j.chb.2012.12.032
   Tran H, 2016, LECT NOTES COMPUT SC, V9795, P273, DOI 10.1007/978-3-319-42345-6_24
   Tsagkias M, 2010, LECT NOTES COMPUT SC, V5993, P191, DOI 10.1007/978-3-642-12275-0_19
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wang SF, 2015, INT J MOL SCI, V16, P30343, DOI 10.3390/ijms161226237
   Wang X, 2012, J INTERACT MARK, V26, P198, DOI 10.1016/j.intmar.2011.11.004
   Wood SA, 2013, SCI REP-UK, V3, DOI 10.1038/srep02976
   Yano T, 2010, ICWSM
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   You QZ, 2015, IEEE T MULTIMEDIA, V17, P2271, DOI 10.1109/TMM.2015.2487863
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zhu HH, 2011, EXPERT SYST APPL, V38, P10161, DOI 10.1016/j.eswa.2011.02.075
NR 93
TC 1
Z9 1
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31673
EP 31707
DI 10.1007/s11042-019-07903-8
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000032
DA 2024-07-18
ER

PT J
AU Li, GF
   Zhang, LL
   Sun, Y
   Kong, JY
AF Li, Gongfa
   Zhang, Leilei
   Sun, Ying
   Kong, Jianyi
TI Towards the sEMG hand: internet of things sensors and haptic feedback
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things sensors; sEMG signal; sEMG hands; Sensory perception;
   Haptic feedback
ID UPPER-EXTREMITY PROSTHESIS; TACTILE; CLASSIFICATION; IDENTIFICATION;
   TECHNOLOGIES; MANIPULATION; VIBROTACTILE; STIMULATION; FINGERTIP;
   SENSATION
AB With the trend going on in ubiquitous computing, everything is going to be connected to the Internet and its data will be used for various progressive purposes, creating not only information from it, but also, knowledge and even wisdom. Internet of Things (IoT) is becoming important because the amount of data could make it possible to create more usefulness and develop smart applications for the users. Meanwhile, it mainly focuses on how to enable general objects to see, hear, and smell the physical world for themselves, and make them connected to share the observations. In this paper, we focus our attention on the integration of artificial sensory perception and haptic feedback in sEMG hands, which is an intelligent application of the IoT. Artificial sensory perception and haptic feedback are essential elements for amputees with myoelectric hands to restore the grasping function. They can provide information to users, such as forces of interaction and surface properties at points of contact between hands and objects. Recent advancements in robot tactile sensing led to development of many computational techniques that exploit this important sensory channel. At the same time, Surface electromyography (sEMG) is perhaps most useful for providing insight into how the neuromuscular system behaves. Therefore, integration of sEMG technology, artificial sensation and haptic feedback plays an important role in improving the manipulation performance and enhancing perceptual embodiment for users. This paper provides sEMG technologies that involve Multichannel sEMG electrodes array and processing methods, and then reviews current state-of-the-art of artificial sensation and haptic feedback. Drawing from advancements and taking into design considerations of each feedback modality and individual haptic technology, the paper outline challenging issues and future developments.
C1 [Li, Gongfa; Zhang, Leilei; Kong, Jianyi] Wuhan Univ Sci & Technol, Key Lab Met Equipment & Control Technol, Minist Educ, Wuhan 430081, Hubei, Peoples R China.
   [Li, Gongfa; Zhang, Leilei] Wuhan Univ Sci & Technol, Res Ctr Biomimet Robot & Intelligent Measurement, Wuhan 430081, Hubei, Peoples R China.
   [Li, Gongfa] Wuhan Univ Sci & Technol, Inst Precis Mfg, Wuhan 430081, Hubei, Peoples R China.
   [Sun, Ying; Kong, Jianyi] Wuhan Univ Sci & Technol, Hubei Key Lab Mech Transmiss & Mfg Engn, Wuhan 430081, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology; Wuhan University of Science & Technology; Wuhan University
   of Science & Technology
RP Li, GF (corresponding author), Wuhan Univ Sci & Technol, Key Lab Met Equipment & Control Technol, Minist Educ, Wuhan 430081, Hubei, Peoples R China.; Li, GF (corresponding author), Wuhan Univ Sci & Technol, Res Ctr Biomimet Robot & Intelligent Measurement, Wuhan 430081, Hubei, Peoples R China.; Li, GF (corresponding author), Wuhan Univ Sci & Technol, Inst Precis Mfg, Wuhan 430081, Hubei, Peoples R China.
EM ligongfa@wust.edu.cn; zhang.leilei1988@foxmail.com;
   sunying65@wust.edu.cn; 15697188659@wo.com.cn
FU National Natural Science Foundation of China [51575407, 51575338,
   51575412, 61273106]; National Defense Pre-Research Foundation of Wuhan
   University of Science and Technology [GF201705]
FX This work was supported by grants of National Natural Science Foundation
   of China (Grant No. 51575407, 51575338, 51575412, 61273106) and the
   Grants of National Defense Pre-Research Foundation of Wuhan University
   of Science and Technology (GF201705).
CR Antfolk C, 2013, IEEE T NEUR SYS REH, V21, P112, DOI 10.1109/TNSRE.2012.2217989
   Atieh A, 2011, NORTHEAST BIOENGIN C
   Balasubramanian R, 2014, HUMAN HAND INSPIRATI, P95
   Bandari NM, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.7.077002
   Barbadillo G, 2011, COMPUT SCI TECH REP, V511, P147
   Bhattacharyya S, 2016, EUR J TRANSL MYOL, V26, P165
   Casini S, 2015, IEEE INT C INT ROBOT, P1186, DOI 10.1109/IROS.2015.7353520
   Cipriani C, 2008, IEEE T ROBOT, V24, P170, DOI 10.1109/TRO.2007.910708
   Cipriani C, 2012, IEEE T BIO-MED ENG, V59, P400, DOI 10.1109/TBME.2011.2173342
   Cloutier Aimee, 2013, Critical Reviews in Biomedical Engineering, V41, P161
   Cotton DPJ, 2007, IEEE SENS J, V7, P752, DOI 10.1109/JSEN.2007.894912
   Cotton DPJ, 2009, IEEE SENS J, V9, P2008, DOI 10.1109/JSEN.2009.2030709
   Dahiya RS, 2010, IEEE T ROBOT, V26, P1, DOI 10.1109/TRO.2009.2033627
   Dang H, 2014, AUTON ROBOT, V36, P309, DOI 10.1007/s10514-013-9355-y
   Engelhart K, 1999, MED ENG PHYS, V21, P431, DOI 10.1016/S1350-4533(99)00066-1
   Fang YF, 2015, INT J HUM ROBOT, V12, DOI 10.1142/S0219843615500115
   Farina D, 2015, IEEE SIGNAL PROC MAG, V32, P115, DOI 10.1109/MSP.2014.2359242
   Fishel Jeremy A, 2012, Front Neurorobot, V6, P4, DOI 10.3389/fnbot.2012.00004
   Gibson A, 2015, INT C REHAB ROBOT, P37, DOI 10.1109/ICORR.2015.7281172
   Gonzalez J, 2012, IEEE ENG MED BIO, P1789, DOI 10.1109/EMBC.2012.6346297
   Gonzalez J, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-33
   Gonzalez MG, 2014, POLYM TEST, V37, P163, DOI 10.1016/j.polymertesting.2014.05.014
   Hargrove L, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P2203
   Hargrove LJ, 2007, IEEE T BIO-MED ENG, V54, P847, DOI 10.1109/TBME.2006.889192
   He Y, 2017, INT J COMPUT SCI MAT, DOI [10.1007/s10586-017-1237-1, DOI 10.1007/S10586-017-1237-1]
   Heo JS, 2008, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON SENSING TECHNOLOGY, P486, DOI 10.1109/ICSENST.2008.4757153
   Heyneman B, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2012)
   Hongbin Liu, 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P138, DOI 10.1109/MFI.2012.6343036
   Hosoda K, 2006, ROBOT AUTON SYST, V54, P104, DOI 10.1016/j.robot.2005.09.019
   Huang H, 2008, IEEE T NEUR SYS REH, V16, P37, DOI 10.1109/TNSRE.2007.910282
   Hudgins B, 1997, CANADIAN MEDICAL AND BIOLOGICAL ENGINEERING SOCIETY, PROCEEDINGS, P138
   Jara CA, 2014, SENSORS-BASEL, V14, P1787, DOI 10.3390/s140101787
   [姜力 Jiang Li], 2017, [机器人, Robot], V39, P387
   Jiang Ning, 2010, Critical Reviews in Biomedical Engineering, V38, P381, DOI 10.1615/CritRevBiomedEng.v38.i4.30
   KACZMAREK KA, 1991, IEEE T BIO-MED ENG, V38, P1, DOI 10.1109/10.68204
   Kappassov Z, 2015, ROBOT AUTON SYST, V74, P195, DOI 10.1016/j.robot.2015.07.015
   Kimoto A, 2010, IEEE SENS J, V10, P1508, DOI 10.1109/JSEN.2010.2044407
   Konstantinova J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102337
   Kramer RK, 2011, IEEE INT CONF ROBOT, P1103, DOI 10.1109/ICRA.2011.5980082
   Lang SB, 2006, APPL PHYS A-MATER, V85, P125, DOI 10.1007/s00339-006-3688-8
   Lee HK, 2011, J MICROMECH MICROENG, V21, DOI 10.1088/0960-1317/21/3/035010
   Li B., 2017, SCI ADV, V3, P1
   Li CY, 2008, J MICROELECTROMECH S, V17, P334, DOI 10.1109/JMEMS.2007.911375
   Li GL, 2010, IEEE T NEUR SYS REH, V18, P185, DOI 10.1109/TNSRE.2009.2039619
   Li KR, 2017, IEEE SENS J, V17, P2625, DOI 10.1109/JSEN.2017.2674965
   Maereg AT, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00042
   Martinez-Hernandez U, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P341, DOI 10.1109/WHC.2013.6548432
   Miao W, 2015, APPL COMPUT MATH-BAK, V14, P238
   Ohka M, 2008, IEEE INT CONF ROBOT, P3425, DOI 10.1109/ROBOT.2008.4543734
   Peerdeman B, 2011, J REHABIL RES DEV, V48, P719, DOI 10.1682/JRRD.2010.08.0161
   [刘平 Ping Liu], 2011, [高分子材料科学与工程, Polymer Materials Science & Engineering], V27, P112
   Rafiee J, 2011, EXPERT SYST APPL, V38, P4058, DOI 10.1016/j.eswa.2010.09.068
   Schmitz A, 2011, IEEE T ROBOT, V27, P389, DOI 10.1109/TRO.2011.2132930
   Schofield JS, 2014, EXPERT REV MED DEVIC, V11, P499, DOI 10.1586/17434440.2014.929496
   Seminara L, 2013, IEEE SENS J, V13, P4022, DOI 10.1109/JSEN.2013.2268690
   Shair E. F., 2015, 2015 International Symposium on Technology Management and Emerging Technologies (ISTMET), P233, DOI 10.1109/ISTMET.2015.7359035
   Stanley AA, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P25, DOI 10.1109/WHC.2013.6548379
   Stassi S, 2014, SENSORS-BASEL, V14, P5296, DOI 10.3390/s140305296
   Sun Y, 2018, MOBILE NETW APPL, V23, P797, DOI 10.1007/s11036-018-1008-0
   Tegin J, 2005, IND ROBOT, V32, P64, DOI 10.1108/01439910510573318
   Tejeiro C, 2012, P IEEE RAS-EMBS INT, P521, DOI 10.1109/BioRob.2012.6290268
   Teshigawara S, 2010, IEEE INT CONF ROBOT, P4867, DOI 10.1109/ROBOT.2010.5509288
   Tiwana MI, 2012, SENSOR ACTUAT A-PHYS, V179, P17, DOI 10.1016/j.sna.2012.02.051
   Wang Huaqing, 2016, Sensors (Basel), V16
   Wijk U, 2015, J HAND THER, V28, P269, DOI 10.1016/j.jht.2015.01.013
   Xu DF, 2013, IEEE INT CONF ROBOT, P3056, DOI 10.1109/ICRA.2013.6631001
   Yousef H, 2011, SENSOR ACTUAT A-PHYS, V167, P171, DOI 10.1016/j.sna.2011.02.038
   Zardoshti-Kermani M., 1995, IEEE Transactions on Rehabilitation Engineering, V3, P324, DOI 10.1109/86.481972
NR 68
TC 63
Z9 63
U1 1
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29765
EP 29782
DI 10.1007/s11042-018-6293-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200008
DA 2024-07-18
ER

PT J
AU Soumya, T
   Thampi, SM
AF Soumya, T.
   Thampi, Sabu M.
TI Nighttime visual refinement techniques for surveillance video: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Video surveillance; Night video enhancement; Night video restoration;
   Context enhancement
ID LOW-CONTRAST IMAGES; NOISE-REDUCTION; REAL-TIME; ENHANCEMENT; DARK;
   REMOVAL
AB Video surveillance systems substitute manual efforts in various safety critic domains such as border area, assisted living, banking, service stations, and transportation. The multimedia-based surveillance system has a significant role in security and forensic systems because people tend to be easily convinced after observing voice, image, and video. Hence, these videos are strong evidence in the forensic investigation. However, most of the criminal activities such as ATM robbery and assassination are occur at nighttime because of the crime supporting dark environment. Many of the night surveillance systems in military, as well as commercial applications, are equipped with infrared and thermal based night vision systems. Its poor capability of texture and color interpretations are the major issues to ensure secure nighttime video monitoring. Specifically, visual refinements of nighttime surroundings and foreground objects provide a valuable assistance in the nighttime security system. In this scenario, it is highly recommended a review of the state-of-the-art nighttime visual refinement approaches. We conducted an extensive literature review and classified the nighttime visual refinement approaches into nighttime restoration and enhancement. This comparative literary analysis identified the research gap fields to explore future research directions in nighttime visual enhancement techniques. Finally, we discussed various open issues and future directions in the context enhancement based nighttime enhancement research.
C1 [Soumya, T.] Univ Kerala, Coll Engn Perumon, Thiruvananthapuram, Kerala, India.
   [Thampi, Sabu M.] Indian Inst Informat Technol & Management, Trivandrum, Kerala, India.
C3 University of Kerala; Kerala University of Digital Sciences, Innovation
   & Technology (Digital University Kerala)
RP Soumya, T (corresponding author), Univ Kerala, Coll Engn Perumon, Thiruvananthapuram, Kerala, India.
EM tsoumyabaiju@gmail.com; sabu.thampi@iiitmk.ac.in
RI Thampi, Sabu/D-3833-2016
OI Thampi, Sabu/0000-0001-6453-5520
CR [Anonymous], IET IMAGE PROCESS
   [Anonymous], ARXIV11023328
   [Anonymous], 2015 IEEE INT C SIGN
   [Anonymous], 2011, P 2011 VISUAL COMMUN
   [Anonymous], P 2008 IEEE C COMP V
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], J INF COMPUT SCI
   Benoit A, 2010, COMPUT VIS IMAGE UND, V114, P758, DOI 10.1016/j.cviu.2010.01.011
   Cai L, 2009, IEEE SARNOFF SYMPOS, P198
   Celik T, 2013, IET IMAGE PROCESS, V7, P543, DOI 10.1049/iet-ipr.2012.0687
   Chen RR, 2020, INFORM SYST J, V30, P458, DOI 10.1111/isj.12265
   Chen YZ, 2013, IEEE T CIRC SYST VID, V23, P74, DOI 10.1109/TCSVT.2012.2203198
   Cheng HY, 2014, INT C PATT RECOG, P714, DOI 10.1109/ICPR.2014.133
   Chouhan R, 2013, ANNU IEEE IND CONF
   Chouhan R, 2015, SIGNAL IMAGE VIDEO P, V9, P255, DOI 10.1007/s11760-015-0812-2
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115
   Fan XL, 2019, MULTIMED TOOLS APPL, V78, P17653, DOI 10.1007/s11042-018-7103-1
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Honda Hiroto, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P82, DOI 10.1109/CVPRW.2015.7301300
   Hu JH, 2013, IEEE IMAGE PROC, P1090, DOI 10.1109/ICIP.2013.6738225
   Hu YM, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P119, DOI 10.1109/CISP.2015.7407861
   Ilie A, 2005, INT J PATTERN RECOGN, V19, P533, DOI 10.1142/S0218001405004137
   Jha RK, 2012, IEEE IMAGE PROC, P973, DOI 10.1109/ICIP.2012.6467024
   Jiang XS, 2019, SIGNAL IMAGE VIDEO P, V13, P189, DOI 10.1007/s11760-018-1345-2
   Jiang XS, 2013, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2013.6738114
   Jing Li, 2009, Journal of Electronics, V26, P88, DOI 10.1007/s11767-007-0052-x
   Jing Li, 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P169
   Jing Yu, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P441, DOI 10.1109/DICTA.2010.81
   Jung CK, 2017, J VIS COMMUN IMAGE R, V42, P28, DOI 10.1016/j.jvcir.2016.11.001
   Kim M, 2015, IEEE T CONSUM ELECTR, V61, P72, DOI 10.1109/TCE.2015.7064113
   Lee SW, 2005, IEEE T CONSUM ELECTR, V51, P648, DOI 10.1109/TCE.2005.1468014
   Li Y, 2013, INT C DIGIT MANUF, P823, DOI 10.1109/ICDMA.2013.195
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Loza A, 2013, DIGIT SIGNAL PROCESS, V23, P1856, DOI 10.1016/j.dsp.2013.06.002
   Makwana I., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P196, DOI 10.1109/NCVPRIPG.2011.49
   Malm H, 2007, IEEE I CONF COMP VIS, P1395
   Meng YY, 2019, NEURAL PROCESS LETT, V50, P799, DOI 10.1007/s11063-018-09968-2
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Quevedo E, 2014, IEEE T CONSUM ELECTR, V60, P420, DOI 10.1109/TCE.2014.6937326
   Rao YB, 2014, MULTIMED TOOLS APPL, V70, P2235, DOI 10.1007/s11042-012-1226-6
   Rao YB, 2010, OPT ENG, V49, DOI 10.1117/1.3520553
   Rivera AR, 2012, IEEE T IMAGE PROCESS, V21, P3967, DOI 10.1109/TIP.2012.2198667
   Soumya T, 2017, J INTELL FUZZY SYST, V32, P3143, DOI 10.3233/JIFS-169257
   Soumya T, 2017, SIGNAL IMAGE VIDEO P, V11, P57, DOI 10.1007/s11760-016-0893-6
   Su HN, 2019, DISPLAYS, V56, P11, DOI 10.1016/j.displa.2018.10.005
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Warrant E, 2014, P IEEE, V102, P1411, DOI 10.1109/JPROC.2014.2332533
   Xu Q, 2014, SIGNAL PROCESS, V103, P309, DOI 10.1016/j.sigpro.2014.02.013
   Zhang C, 2018, LECT NOTES COMPUT SC, V11166, P46, DOI 10.1007/978-3-030-00764-5_5
   Zhang J., 2016, ARXIV160601460
   Zhang J, 2014, IEEE IMAGE PROC, P4557, DOI 10.1109/ICIP.2014.7025924
   Zhang Q, 2016, IEEE T VIS COMPUT GR, V22, P1773, DOI 10.1109/TVCG.2015.2461157
   Zhang XD, 2012, INT C PATT RECOG, P2034
   Zhuo L, 2019, CHINESE J ELECTRON, V28, P316, DOI 10.1049/cje.2018.12.004
NR 57
TC 4
Z9 4
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32137
EP 32158
DI 10.1007/s11042-019-07944-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000050
DA 2024-07-18
ER

PT J
AU Zhang, W
   Zhu, YC
   Wang, JP
AF Zhang, Wei
   Zhu, Yan-chun
   Wang, Jia-peng
TI An intelligent textual corpus big data computing approach for lexicons
   construction and sentiment classification of public emergency events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Textual corpus; Big data; Lexicon construction; Sentiment computing;
   Public emergency events
ID EMOTIONS; EXTRACTION; MEDIA
AB Considering the deficiencies in the existing emotional lexicons like too many manual interventions, lack of scalability and ignorance of dependency parsing in emotional computing, this paper first uses Word2Vec, cosine word vector similarity calculation and SO-PMI algorithms to build a public event-oriented Weibo emotional lexicon; then, it proposes a Weibo emotion computing method based on dependency parsing and designs an emotion binary tree based on dependency parsing, and dependency-based emotion calculation rules; and at last, through an experiment, it shows that this emotional lexicon has a wider coverage and higher accuracy than the existing ones, and it also performs a public opinion evolution analysis on an actual public event and the empirical results show that the algorithm is feasible and effective.
C1 [Zhang, Wei; Wang, Jia-peng] Cent Univ Finance & Econ, Sch Informat, Beijing 100081, Peoples R China.
   [Zhu, Yan-chun] Beijing Normal Univ, Business Sch, Beijing 100875, Peoples R China.
C3 Central University of Finance & Economics; Beijing Normal University
RP Zhu, YC (corresponding author), Beijing Normal Univ, Business Sch, Beijing 100875, Peoples R China.
EM weizhang@cufe.edu.cn; kddzw@163.com; wangjiapeng.8888@163.com
FU National Natural Science Foundation of China [71874215]; Beijing Natural
   Science Foundation [9182016]; MOE (Ministry of Education in China)
   Project of Humanities and Social Sciences [17YJAZH120]; Beijing's
   Philosophical and Social Science Foundation [13JGC128, 13JGB058]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 71874215), Beijing Natural Science Foundation
   (9182016), MOE (Ministry of Education in China) Project of Humanities
   and Social Sciences (17YJAZH120), and Beijing's Philosophical and Social
   Science Foundation (Grant No. 13JGC128, 13JGB058). We wish to thank the
   anonymous reviewers who helped to improve the quality of the paper. The
   authors gratefully acknowledge the helpful comments and suggestions of
   the reviewers, which have improved the presentation.
CR [Anonymous], 2016, INT C INN TECHN APPL
   [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   [Anonymous], 2018, ARXIV180700775
   Badaro G., 2018, P 7 JOINT C LEXICAL, P86, DOI [DOI 10.18653/V1/S18-2009, 10.18653/v1/S18-2009]
   Bandhakavi A, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12332
   Bandhakavi A, 2017, PATTERN RECOGN LETT, V93, P133, DOI 10.1016/j.patrec.2016.12.009
   Bestgen Y, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P496
   Che W., 2010, Proceedings of the 23rd international conference on computational linguistics: Demonstrations, P13
   Ghiassi M, 2013, EXPERT SYST APPL, V40, P6266, DOI 10.1016/j.eswa.2013.05.057
   Guan T, 2018, J CHIN POLIT SCI, P1
   Guo SJ, 2017, PUBLIC RELAT REV, V43, P755, DOI 10.1016/j.pubrev.2017.07.003
   [黄发良 Huang Faliang], 2017, [计算机学报, Chinese Journal of Computers], V40, P872
   [蒋盛益 Jiang Shengyi], 2015, [中文信息学报, Journal of Chinese Information Processing], V29, P166
   Kalamatianos G, 2018, J SYSTEMS INFORM TEC
   Kuang WB, 2018, SOCIOL MED JOUR CHIN, P257, DOI 10.1007/978-981-13-0914-4_10
   Kuen E, 2017, 5 INT C FUT INT THIN, P132
   Kusen Ema, 2018, Online Social Networks and Media, V5, P37, DOI 10.1016/j.osnem.2017.12.002
   Lecheler S, 2015, J MASS COMMUN Q, V92, P812, DOI 10.1177/1077699015596338
   Lee J, 2018, TELEMAT INFORM, V35, P1382, DOI 10.1016/j.tele.2018.03.009
   Li XM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124672
   Lin DZ, 2018, NEUROCOMPUTING, V272, P258, DOI 10.1016/j.neucom.2017.06.078
   Montejo-Ráez A, 2014, COMPUT SPEECH LANG, V28, P93, DOI 10.1016/j.csl.2013.04.001
   Narendra B., 2016, International Journal of Intelligent Systems and Applications, V8, P66, DOI 10.5815/ijisa.2016.08.08
   Nip JYM, 2016, CHINA QUART, V225, P122, DOI 10.1017/S0305741015001654
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   Peng HY, 2017, COGN COMPUT, V9, P423, DOI 10.1007/s12559-017-9470-8
   Poria S, 2017, NEUROCOMPUTING, V261, P217, DOI 10.1016/j.neucom.2016.09.117
   Reka M., 2018, SOFTW ENG TECHNOL, V10, P69
   Stojanovski D., 2018, MULTIMED TOOLS APPL, V77, P1
   Sun X, 2018, J COMPUT SCI-NETH, V25, P193, DOI 10.1016/j.jocs.2017.05.029
   Sun X, 2017, J ELECTRON INF TECHN, V39, P2048, DOI 10.11999/JEIT160975
   Tubishat M, 2018, INFORM PROCESS MANAG, V54, P545, DOI 10.1016/j.ipm.2018.03.008
   Vermeulen A, 2018, COMPUT HUM BEHAV, V84, P211, DOI 10.1016/j.chb.2018.02.022
   [万常选 Wan Changxuan], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P2554
   Wang QY, 2015, KNOWL-BASED SYST, V81, P46, DOI 10.1016/j.knosys.2015.02.006
   Xu, 2017, P 2017 IEEE ACM INT, P321, DOI [10.1145/3110025.3110031, DOI 10.1145/3110025.3110031]
   Yadollahi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057270
   [杨小平 Yang Xiaoping], 2017, [计算机科学, Computer Science], V44, P42
   Yu LA, 2017, J CLEAN PROD, V143, P1203, DOI 10.1016/j.jclepro.2016.11.184
NR 40
TC 13
Z9 14
U1 2
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30159
EP 30174
DI 10.1007/s11042-018-7018-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200030
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Kampffmeyer, M
   Liang, XD
   Zhang, DW
   Tan, M
   Xing, EP
AF Zhang, Yujia
   Kampffmeyer, Michael
   Liang, Xiaodan
   Zhang, Dingwen
   Tan, Min
   Xing, Eric P.
TI Dilated temporal relational adversarial network for generic video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Dilated temporal relation; Generative adversarial
   network; Three-player loss
AB The large amount of videos popping up every day, make it more and more critical that key information within videos can be extracted and understood in a very short time. Video summarization, the task of finding the smallest subset of frames, which still conveys the whole story of a given video, is thus of great significance to improve efficiency of video understanding. We propose a novel Dilated Temporal Relational Generative Adversarial Network (DTR-GAN) to achieve frame-level video summarization. Given a video, it selects the set of key frames, which contain the most meaningful and compact information. Specifically, DTR-GAN learns a dilated temporal relational generator and a discriminator with three-player loss in an adversarial manner. A new dilated temporal relation (DTR) unit is introduced to enhance temporal representation capturing. The generator uses this unit to effectively exploit global multi-scale temporal context to select key frames and to complement the commonly used Bi-LSTM. To ensure that summaries capture enough key video representation from a global perspective rather than a trivial randomly shorten sequence, we present a discriminator that learns to enforce both the information completeness and compactness of summaries via a three-player loss. The loss includes the generated summary loss, the random summary loss, and the real summary (ground-truth) loss, which play important roles for better regularizing the learned model to obtain useful summaries. Comprehensive experiments on three public datasets show the effectiveness of the proposed approach.
C1 [Zhang, Yujia; Tan, Min] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Zhang, Yujia; Tan, Min] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Kampffmeyer, Michael] UiT Arctic Univ Norway, Machine Learning Grp, N-9019 Tromso, Norway.
   [Liang, Xiaodan; Xing, Eric P.] Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA.
   [Zhang, Dingwen] Xidian Univ, Xian 710071, Shaanxi, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS; UiT
   The Arctic University of Tromso; Carnegie Mellon University; Xidian
   University
RP Zhang, YJ (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.; Zhang, YJ (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM zhangyujia2014@ia.ac.cn
RI zhang, dingwen/R-3463-2019
OI zhang, dingwen/0000-0001-8369-8886
FU Department of Defense [FA8702-15-D-0002]; Carnegie Mellon University;
   National Natural Science Foundation of China [61673378, 61333016];
   Norwegian Research Council FRIPRO grant [239844]
FX We would like to thank Xiaohui Zeng for her valuable discussions. This
   project is supported by the Department of Defense under Contract No.
   FA8702-15-D-0002 with Carnegie Mellon University for the operation of
   the Software Engineering Institute, a federally funded research and
   development center. This work is also partially funded by the National
   Natural Science Foundation of China (Grant No. 61673378 and 61333016),
   and Norwegian Research Council FRIPRO grant no. 239844 on developing the
   Next Generation Learning Machines.
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   [Anonymous], ARXIV160909444
   [Anonymous], 2017, CVPR
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], ARXIV160505396
   [Anonymous], 2017, ARXIV170809545
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2017, ICCV
   [Anonymous], 2016, ARXIV161105267
   [Anonymous], P ACM TUR CEL C CHIN
   [Anonymous], 2019, IEEE T CIRCUITS SYST
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2018, P 2018 ACM MULT C, DOI DOI 10.1145/3240508.3240591
   [Anonymous], P IEEE C COMP VIS PA
   Arjovsky Martin, 2017, P INT C MACH LEARN
   Chen H, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P606, DOI 10.1109/ITME.2018.00139
   Chen L.-C., 2017, IEEE C COMP VIS PATT
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   Chu Wen-Sheng, 2015, P IEEE C COMP VIS PA
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C., 2016, P INT C NEUR INF PRO, P3468
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu TJ, 2019, IEEE WINT CONF APPL, P1579, DOI 10.1109/WACV.2019.00173
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SY, 2019, IEEE T IMAGE PROCESS, V28, P2654, DOI 10.1109/TIP.2018.2889265
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Kulesza A, 2012, FOUND TRENDS MACH LE, V5, P123, DOI 10.1561/2200000044
   Li YX, 2018, DESTECH TRANS SOC, P156
   Liang X., 2017, Dual Motion GAN for Future-Flow Embedded Video Prediction
   Liu YB, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/973069
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mathieu M. F., 2016, ADV NEUR IN
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Radford A., 2016, COMPUT SCI
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Shrivastava A, 2017, P IEEE C COMP VIS PA, P2107
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yao T, 2016, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2016.112
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
NR 53
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35237
EP 35261
DI 10.1007/s11042-019-08175-y
EA OCT 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000492236300003
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Sina, M
   Dehghan, M
   Rahmani, AM
AF Sina, Majid
   Dehghan, Mehdi
   Rahmani, Amir Masoud
TI CaR-PLive: Cloud-assisted reinforcement learning based P2P live video
   streaming: a hybrid approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Peer-to-peer networks; Live video streaming; Resource
   provisioning; Reinforcement learning
ID SCHEDULING SCHEME; MECHANISM; SYSTEMS; VOD; CDN; ARCHITECTURE;
   STRATEGIES; NETWORK
AB In recent years, live video streaming has become one of the most popular and prevalent applications of the Internet. The Peer-to-Peer (P2P) and Content Delivery Network (CDN) are popular approaches to stream video contents. These approaches respectively have faced some drastic challenges such as obtaining the desired Quality of Service (QoS) level and minimizing economic cost. The cloud computing infrastructures can reveal proper solutions to these problems. The P2P systems can eliminate their bandwidth shortage by renting resources from the cloud environment. This paper depicts CaR-PLive as a hybrid cloud-assisted P2P live streaming system. CaR-PLive uses video servers such as Amazon EC2 from cloud to stream video contents and rents Cloud Storage Services (CSSs) such as Amazon S3 to assist P2P live streaming system to reach the desired playback continuity. In CaR-PLive, we proposed two stages (sub-windows) sliding window for buffer management that a sub-window belongs to the P2P system and another one belongs to CSS. The objective of CAR-PLive is to optimize the size of sub-windows to minimize the overall rental cost of CSS restricted to a desired QoS level. We formulate this problem as an optimization problem and model it with Markov Decision Process (MDP) and then propose a reinforcement learning based algorithm to solve this problem. Finally, we evaluate the performance of CaR-PLive by performing extensive simulations and experiments with realistic settings. Simulation results demonstrate that CaR-PLive efficiently mitigates overall CSS billing cost in different system configurations and provides desired playback continuity in different system settings.
C1 [Sina, Majid; Rahmani, Amir Masoud] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Dehghan, Mehdi] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Hafez Ave, Tehran 15914, Iran.
   [Rahmani, Amir Masoud] Univ Human Dev, Comp Sci, Sulaimanyah, Iraq.
C3 Islamic Azad University; Amirkabir University of Technology
RP Dehghan, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Hafez Ave, Tehran 15914, Iran.
EM sinamajid@yahoo.com; dehghan@aut.ac.ir; rahmani@srbiau.ac.ir
RI Rahmani, Amir Masoud/K-2702-2013; Dehghan, Maziar/F-8525-2013; Sina,
   Majid/AAN-8081-2021
OI Rahmani, Amir Masoud/0000-0001-8641-6119; Dehghan,
   Maziar/0000-0003-2106-6300; Sina, Majid/0000-0003-2673-6895
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Aggarwal V., 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P637, DOI 10.1109/INFCOMW.2011.5928890
   Ahmad S, 2018, PEER PEER NETW APPL, V11, P44, DOI 10.1007/s12083-016-0495-7
   [Anonymous], 2006, INFOCOM
   Aslani R, 2018, MULTIMED TOOLS APPL, V77, P14625, DOI 10.1007/s11042-017-5051-9
   Bharambe AR, 2006, IEEE INFOCOM SER, P2884
   Budhkar S, 2018, J NETW SYST MANAG, V26, P401, DOI 10.1007/s10922-017-9420-5
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chen ZJ, 2007, GLOB TELECOMM CONF, P2086
   Cisco V, 2018, 1 CISC V
   Gao GQ, 2019, J NETW SYST MANAG, V27, P815, DOI 10.1007/s10922-018-09485-6
   Ghaderzadeh A, 2018, TELECOMMUN SYST, V67, P231, DOI 10.1007/s11235-017-0336-x
   Gheorghe G, 2011, PEER PEER NETW APPL, V4, P75, DOI 10.1007/s12083-010-0070-6
   GUMMADI K. P., 2002, P 2 ACM SIGCOMM WORK
   Haitao Li, 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P203, DOI 10.1109/CLOUD.2011.41
   He J, 2014, IEEE T CIRC SYST VID, V24, P669, DOI 10.1109/TCSVT.2013.2283430
   He J, 2013, IEEE T CIRC SYST VID, V23, P1717, DOI 10.1109/TCSVT.2013.2255423
   He YF, 2009, IEEE INT CON MULTI, P790, DOI 10.1109/ICME.2009.5202613
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Huang ZX, 2011, IEEE INFOCOM SER, P201, DOI 10.1109/INFCOM.2011.5935009
   Ishakian V, 2017, COMPUT COMMUN, V111, P14, DOI 10.1016/j.comcom.2017.06.011
   Lin SH, 2017, IEEE T MULTIMEDIA, V19, P984, DOI 10.1109/TMM.2016.2644868
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Lu ZH, 2011, INT C PAR DISTRIB SY, P581, DOI 10.1109/ICPADS.2011.113
   Lu ZH, 2010, LECT NOTES COMPUT SC, V6488, P578, DOI 10.1007/978-3-642-17616-6_50
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Mahini H, 2016, INT J COMMUN SYST, V29, P1187, DOI 10.1002/dac.3085
   Montresor A, 2011, IEEE INT CONF PEER, P250, DOI 10.1109/P2P.2011.6038743
   Mostafavi S, 2017, TELECOMMUN SYST, V64, P87, DOI 10.1007/s11235-016-0161-7
   Mostafavi S, 2016, MULTIMED TOOLS APPL, V75, P8545, DOI 10.1007/s11042-015-2771-6
   Niu D, 2012, IEEE INFOCOM SER, P460, DOI 10.1109/INFCOM.2012.6195785
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Pal K, 2018, MULTIMED TOOLS APPL, V77, P24427, DOI 10.1007/s11042-018-5741-y
   Pal K, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3440
   Payberah AH, 2013, LIVE STREAMING P2P H
   Payberah AH, 2012, IEEE INT CONF PEER, P79
   Pianese F, 2007, IEEE T MULTIMEDIA, V9, P1645, DOI 10.1109/TMM.2007.907466
   Rocha V, 2016, COMPUTING, V98, P73, DOI 10.1007/s00607-014-0428-3
   Rodriguez-Silva D. A., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P991, DOI 10.1109/CLOUD.2012.44
   Rongfei M, 2019, PERS UBIQUIT COMPUT, P1
   Song Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1009, DOI 10.1109/ICME.2008.4607608
   Sutton RS., 2020, REINFORCEMENT LEARNI
   Tian Y, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P321, DOI 10.1109/CCWC.2018.8301615
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Varga A., 2008, P 1 INT C SIMULATION, P60, DOI DOI 10.4108/ICST.SIMUTOOLS2008.3027
   Wang CC, 2016, INT J COMMUN SYST, V29, P2517, DOI 10.1002/dac.3193
   Wang F, 2012, IEEE INFOCOM SER, P199, DOI 10.1109/INFCOM.2012.6195578
   Wang JJ, 2008, IEEE IMAGE PROC, P2300, DOI 10.1109/ICIP.2008.4712251
   Wang M, 2013, IEEE ACM T NETWORK, V21, P162, DOI 10.1109/TNET.2012.2194165
   Wang M, 2011, COMPUT NETW, V55, P4069, DOI 10.1016/j.comnet.2011.07.014
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wu C, 2008, IEEE INFOCOM SER, P2029
   Wu D, 2009, IEEE INFOCOM SER, P73, DOI 10.1109/INFCOM.2009.5061908
   Wu Y, 2011, INT CON DISTR COMP S, P268, DOI 10.1109/ICDCS.2011.50
   Xiao WH, 2016, IEEE T PARALL DISTR, V27, P1954, DOI 10.1109/TPDS.2015.2470676
   Xin Jin, 2010, Proceedings 2010 IEEE 16th International Conference on Parallel and Distributed Systems (ICPADS 2010), P800, DOI 10.1109/ICPADS.2010.78
   Xuanjia Qiu, 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P137, DOI 10.1109/PV.2012.6229726
   Yichao Jin, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P934, DOI 10.1109/ICCNC.2012.6167562
   Yin H, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823750
   Zhang JW, 2018, COMPUT NETW, V138, P77, DOI 10.1016/j.comnet.2018.03.031
   Zhang JW, 2014, COMPUT COMMUN, V40, P22, DOI 10.1016/j.comcom.2013.12.002
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhou YP, 2011, IEEE ACM T NETWORK, V19, P42, DOI 10.1109/TNET.2010.2065237
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
   Zhu ZQ, 2013, IEEE T MULTIMEDIA, V15, P758, DOI 10.1109/TMM.2013.2238908
NR 65
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 34095
EP 34127
DI 10.1007/s11042-019-08102-1
EA OCT 2019
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000489286700002
DA 2024-07-18
ER

PT J
AU Lv, ZH
   Su, TY
AF Lv, Zhihan
   Su, Tianyun
TI An ubiquitous 3D visual analysis platform of seabed
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; WebVR; Seabed; GPU
AB We built a 'virtual-world' of real seabed for the visual analysis. Sub-bottom profile is imported in the 3D environment." section-drilling" three-dimensional model is designed according to the characteristics of the multi-source comprehensive data under the seabed. In this model, the seabed stratigraphic profile obtained by seismic reflection is digitized into discrete points and interpolated with an approved Krig- ing arithmetic to produce uniform grid in every strata layer. The Delaunay triangular model is then constructed in every layer and calibrated using the drilling data to rec- tify the depth value of the dataset within the buffer. Finally, the constructed 3D seabed stratigraphic model is rendered in every layer by GPU shader engine. Based on this model, two state-of-the-art applications on website explorer and smartphone prove its ubiquitous feature. The resulting '3D Seabed' is used for simulation, visualization, and analysis, by a set of interlinked, real-time layers of information about the 3D Seabed and its analysis result.
C1 [Lv, Zhihan] Qingdao Univ, Sch Data Sci & Software Engn, Qingdao 266071, Shandong, Peoples R China.
   [Su, Tianyun] MNR, Inst Oceanog 1, Marine Data & Informat Ctr, Qingdao 266061, Shandong, Peoples R China.
C3 Qingdao University
RP Su, TY (corresponding author), MNR, Inst Oceanog 1, Marine Data & Informat Ctr, Qingdao 266061, Shandong, Peoples R China.
EM lvzhihan@gmail.com; sutiany@fio.org.cn
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU National Key Research and Development Program of China [2016YFC1402000];
   Shandong Provincial Natural Science Founda-tion [ZR2017QF015]; National
   Natural Science Foundation of China [61902203]
FX The authors are thankful to the National Key Research and Development
   Program of China (Grant No. 2016YFC1402000), Shandong Provincial Natural
   Science Founda-tion (ZR2017QF015), National Natural Science Foundation
   of China (No. 61902203).
CR [Anonymous], THESIS
   Arnaud S, 1999, COMP GRAPH, P469
   Back M, 2010, IEEE INT CON MULTI, P1160, DOI 10.1109/ICME.2010.5582532
   BAK PRG, 1989, 3 DIMENSIONAL APPL G, P155
   Bell D. G., 2007, NASA WORLD WIND OPEN
   BOWYER A, 1981, COMPUT J, V24, P162, DOI 10.1093/comjnl/24.2.162
   Breunig M, 2011, COMPUT GEOSCI-UK, V37, P791, DOI 10.1016/j.cageo.2010.04.016
   Butkiewicz T, 2011, OCEANS 2011
   Chen G, 2010, REMOTE SENS ENVIRON, V114, P2524, DOI 10.1016/j.rse.2010.05.028
   Coors V, 2001, P INT WORKSH 3D CAD, P159
   ESRI, 1997, ARCVIEW 3D AN
   Estkowski Regina., 2002, P 18 ANN S COMPUTATI, P254
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Lv Z, 2015, IEEE PAC VIS S PACIF
   Lv Z, 2014, SIGGRAPH ASIA 2014 P
   Oliver M. A., 1990, International Journal of Geographical Information Systems, V4, P313, DOI 10.1080/02693799008941549
   Pfund M, 2001, P 3 ISPRS WORKSH DYN, P233
   Shi R, 2018, I S MOD ANAL SIM COM, P333, DOI 10.1109/MASCOTS.2018.00039
   Su TY, 2014, IEEE INT CON MULTI
   Su Y, 2000, COMPUT GEOSCI, V26, P741749, DOI 10.1016/S0098-3004(99)00130-2
   Sun Y, 2006, VISUALIZING OCEANIC
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   WATSON DF, 1981, COMPUT J, V24, P167, DOI 10.1093/comjnl/24.2.167
   Wu DL, 2009, SIMUL MODEL PRACT TH, V17, P1254, DOI 10.1016/j.simpat.2009.04.010
   Yawen H, 2010, GEOINF 2010 18 INT C, P16
   Yoshida N, 1998, CHEM LETT, P55
   Zhihan Lv, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8226, P503, DOI 10.1007/978-3-642-42054-2_63
   Zlatanova S., 1998, P ISPRS COMM STUTTG, P691
NR 28
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34613
EP 34625
DI 10.1007/s11042-019-08180-1
EA OCT 2019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000497839500001
DA 2024-07-18
ER

PT J
AU Batool, SI
   Waseem, HM
AF Batool, Syeda Iram
   Waseem, Hafiz Muhammad
TI A novel image encryption scheme based on Arnold scrambling and Lucas
   series
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold scrambling; Lucas encryption; Data security; Diffie-Hellman
   algorithm
ID BIFURCATION-ANALYSIS; S-BOXES; TRANSFORM; ROTATION; SYSTEM; MAP
AB Secure data transmission over the public channels have high impact and increasingly important due to theft and manipulation in contents. The requirement of public/ private organizations to develop an efficient scheme to provide security to their contents. We developed a digital contents encryption scheme based Arnold scrambling and Lucas series, which is very simple to implement but almost impossible to breach in this article. We perform encryption at standard images by using Lucas series at different iterations of scrambled images of Arnold transform. Numerical simulation analyses performed to analyze the efficiency and effectiveness of the projected structure.
C1 [Batool, Syeda Iram] Inst Space Technol, CISL, Islamabad, Pakistan.
   [Batool, Syeda Iram] Inst Space Technol, Dept Avion Engn, Islamabad, Pakistan.
   [Waseem, Hafiz Muhammad] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
RP Batool, SI (corresponding author), Inst Space Technol, CISL, Islamabad, Pakistan.; Batool, SI (corresponding author), Inst Space Technol, Dept Avion Engn, Islamabad, Pakistan.
EM syedairambatool@gmail.com
OI Hafiz, Muhammad Waseem/0000-0002-9418-1492
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Aljawarneh S., 2016, 2016 International conference on engineering MIS (ICEMIS), P1, DOI DOI 10.1109/ICEMIS.2016.7745355
   Aljawarneh S, 2018, J COMPUT SCI-NETH, V25, P152, DOI 10.1016/j.jocs.2017.03.006
   Aljawarneh SA, 2020, J SUPERCOMPUT, V76, P4376, DOI 10.1007/s11227-018-2397-3
   Aljawarneh SA, 2017, FUTURE GENER COMP SY, V74, P430, DOI 10.1016/j.future.2017.01.013
   [Anonymous], INT J CRYPTOGRAPHY I
   [Anonymous], P S PURE MATH AM MAT
   [Anonymous], 1968, VLADIMIR ARNOLD COLL
   [Anonymous], HINDAWI SCI WORLD
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Boriga Radu Eugen, 2014, IAENG International Journal of Computer Science, V41, P249
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Elshamy AM, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0461-x
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Huang HF, 2010, INTERNATIONAL CONFERENCE OF CHINA COMMUNICATION (ICCC2010), P208
   Hussain I, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11987-x
   KEATING JP, 1991, NONLINEARITY, V4, P277, DOI 10.1088/0951-7715/4/2/005
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2019, INT J THEOR PHYS, V58, P2720, DOI 10.1007/s10773-019-04162-z
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2016, SIGNAL IMAGE VIDEO P, V10, P293, DOI 10.1007/s11760-014-0741-5
   Khan M, 2015, J VIB CONTROL, V21, P3450, DOI 10.1177/1077546314523029
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Li L, 2017, FED CONF COMPUT SCI, P555, DOI 10.15439/2017F163
   Liu Fang, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P771, DOI 10.1109/ICSPS.2010.5555253
   Liu ZJ, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3557790
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Munir Noor, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P48, DOI 10.1109/ICAEM.2018.8536308
   Narsimha G., 2017, INT J INTELLIGENT EN, V4, P128
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Premaratne P, 2012, COMM COM INF SC, V304, P259
   Radhakrishna V, 2018, SOFT COMPUT, V22, P1903, DOI 10.1007/s00500-016-2445-y
   Stoyanov B, 2015, ENTROPY-SWITZ, V17, P2117, DOI 10.3390/e17042117
   Wang XY, 2015, ENTROPY-SWITZ, V17, P3877, DOI 10.3390/e17063877
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Waseem HM, 2018, INT J THEOR PHYS, V57, P3584, DOI 10.1007/s10773-018-3872-6
   Weber A. G., 1997, USC-SIPI Report, V315
   Wei ZC, 2019, APPL MATH COMPUT, V347, P265, DOI 10.1016/j.amc.2018.10.090
   Wei ZC, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417300087
   Wei ZC, 2016, NONLINEAR DYNAM, V85, P1635, DOI 10.1007/s11071-016-2783-4
   Wei ZC, 2015, NONLINEAR DYNAM, V82, P131, DOI 10.1007/s11071-015-2144-8
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Yassein M.B., 2017, Challenges and features of iot communications in 5g networks, P1
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou YC, 2008, PROC SPIE, V6812, DOI 10.1117/12.766591
NR 61
TC 53
Z9 54
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27611
EP 27637
DI 10.1007/s11042-019-07881-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000038
DA 2024-07-18
ER

PT J
AU Carrara, F
   Elias, P
   Sedmidubsky, J
   Zezula, P
AF Carrara, Fabio
   Elias, Petr
   Sedmidubsky, Jan
   Zezula, Pavel
TI LSTM-based real-time action detection and prediction in human motion
   streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture data; Stream annotation; Action detection and
   recognition; Action prediction; LSTM
ID ACTION RECOGNITION; CAPTURE DATA; SEGMENTATION; NETWORKS; POSE
AB Motion capture data digitally represent human movements by sequences of 3D skeleton configurations. Such spatio-temporal data, often recorded in the stream-based nature, need to be efficiently processed to detect high-interest actions, for example, in human-computer interaction to understand hand gestures in real time. Alternatively, automatically annotated parts of a continuous stream can be persistently stored to become searchable, and thus reusable for future retrieval or pattern mining. In this paper, we focus on multi-label detection of user-specified actions in unsegmented sequences as well as continuous streams. In particular, we utilize the current advances in recurrent neural networks and adopt a unidirectional LSTM model to effectively encode the skeleton frames within the hidden network states. The model learns what subsequences of encoded frames belong to the specified action classes within the training phase. The learned representations of classes are then employed within the annotation phase to infer the probability that an incoming skeleton frame belongs to a given action class. The computed probabilities are finally compared against a learned threshold to automatically determine the beginnings and endings of actions. To further enhance the annotation accuracy, we utilize a bidirectional LSTM model to estimate class probabilities by considering not only the past frames but also the future ones. We extensively evaluate both the models on the three use cases of real-time stream annotation, offline annotation of long sequences, and early action detection and prediction. The experiments demonstrate that our models outperform the state of the art in effectiveness and are at least one order of magnitude more efficient, being able to annotate 10 k frames per second.
C1 [Carrara, Fabio] ISTI CNR, Pisa, Italy.
   [Elias, Petr] Masaryk Univ, Brno, Czech Republic.
   [Sedmidubsky, Jan; Zezula, Pavel] Masaryk Univ, Comp Sci, Brno, Czech Republic.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); Masaryk
   University Brno; Masaryk University Brno
RP Carrara, F (corresponding author), ISTI CNR, Pisa, Italy.
EM fabio.carrara@isti.cnr.it; petr.eli.cz@gmail.com; xsedmid@fi.muni.cz;
   zezula@fi.muni.cz
RI Elias, Petr/ABE-6672-2020; Carrara, Fabio/R-2275-2019; Sedmidubsky,
   Jan/J-3195-2013
OI Elias, Petr/0000-0003-4558-6802; Carrara, Fabio/0000-0001-5014-5089;
   Sedmidubsky, Jan/0000-0002-7668-8521
FU Smart News, "Social sensing for breaking news" [CUP CIPE
   D58C15000270008]; Automatic Data and documents Analysis to enhance
   human-based processes (ADA) [CUP CIPE D55F17000290009]; ERDF
   "CyberSecurity, CyberCrime and Critical Information Infrastructures
   Center of Excellence" [CZ. 02.1.01/0.0/0.0/16 019/0000822]; NVIDIA
   Corporation
FX This research was supported by Smart News, "Social sensing for breaking
   news", CUP CIPE D58C15000270008, by Automatic Data and documents
   Analysis to enhance human-based processes (ADA), CUP CIPE
   D55F17000290009, and by ERDF "CyberSecurity, CyberCrime and Critical
   Information Infrastructures Center of Excellence" (No. CZ.
   02.1.01/0.0/0.0/16 019/0000822). We gratefully acknowledge the support
   of NVIDIA Corporation with the donation of the Tesla K40 GPU used for
   this research.
CR Aberman K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322999
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG'15
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.214
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Boulahia SY, 2018, COMPUTER VISION IMAG
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Elias P, 2017, IEEE INT SYM MULTIM, P154, DOI 10.1109/ISM.2017.29
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Felder E, 2009, WISSEN DURCH SPRACHE: THEORIE, PRAXIS UND ERKENNTNISINTERESSE DES FORSCHUNGSNETZWERKES SPRACHE UND WISSEN, P1
   Field M, 2015, PATTERN RECOGN, V48, P2394, DOI 10.1016/j.patcog.2015.03.004
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hussein, 2013, INT JOINT C ART INT
   JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573
   Kadu H, 2014, IEEE T MULTIMEDIA, V16, P2191, DOI 10.1109/TMM.2014.2360793
   Kingma D. P., 2014, arXiv
   Kratz L., 2007, Proc.Future Play, P209, DOI DOI 10.1145/1328202.1328241
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Lakens D, 2010, J EXP SOC PSYCHOL, V46, P701, DOI 10.1016/j.jesp.2010.03.015
   Laraba S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1782
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131344
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Muller M., 2007, Tech. Rep. CG-2007-2
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Poppe R, 2014, BEHAV RES METHODS, V46, P625, DOI 10.3758/s13428-013-0398-y
   Sedmidubsky J, 2018, MULTIMED TOOLS APPL, V77, P12073, DOI 10.1007/s11042-017-4859-7
   Singh D, 2017, LECT NOTES COMPUT SC, V10410, P267, DOI 10.1007/978-3-319-66808-6_18
   Song SJ, 2018, IEEE T IMAGE PROCESS, V27, P3459, DOI 10.1109/TIP.2018.2818328
   Vieira AW, 2012, INT C PATT RECOG, P2934
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xu Y, 2017, PERVASIVE MOB COMPUT, V40, P324, DOI 10.1016/j.pmcj.2017.07.001
   Yu XM, 2017, J VISUAL LANG COMPUT, V43, P50, DOI 10.1016/j.jvlc.2017.09.001
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhao X, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2648583
NR 46
TC 39
Z9 42
U1 5
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27309
EP 27331
DI 10.1007/s11042-019-07827-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000024
DA 2024-07-18
ER

PT J
AU Nguyen, KD
   Nguyen, K
   Le, DD
   Duong, DA
   Nguyen, T
AF Khanh-Duy Nguyen
   Khang Nguyen
   Duy-Dinh Le
   Duc Anh Duong
   Nguyen, Tam, V
TI YADA: you always dream again for better object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Deep learning; Data synthesis
AB Object detection has been attracting a lot of attention from the computer vision community. It has a wide range of practical applications ranging from the traditional use such as image annotation to modern uses such as self-driving vehicles, robotics, surveillance systems, and augmented reality. Recently, deep learning has significantly improved the state-of-the-art performance of the object detection task. Many works explore various deep network structures to improve the performance. However, the impact of training data is still not well investigated. Although some works focus on data augmentation and data synthesis, there is no guarantee that they are effective for the training process. In this paper, we propose a novel framework addressing the problem of generating relevant data and how to use them effectively. We apply lucid data synthesizing which generates data by mining hard examples and embedding them to the same context locations. Further, we utilize a dual-level deep network leveraged with these generated data to effectively detect hard objects in images. Extensive experiments on two benchmarks, PASCAL VOC and KITTI, demonstrate the superiority of our approach over the state-of-the-art methods.
C1 [Khanh-Duy Nguyen; Khang Nguyen; Duy-Dinh Le; Duc Anh Duong] VNU HCM, Univ Informat Technol, Ho Chi Minh City, Vietnam.
   [Nguyen, Tam, V] Univ Dayton, Dept Comp Sci, Dayton, OH 45469 USA.
C3 Vietnam National University Hochiminh City; University System of Ohio;
   University of Dayton
RP Nguyen, KD (corresponding author), VNU HCM, Univ Informat Technol, Ho Chi Minh City, Vietnam.
EM khanhnd@uit.edu.vn; khangnttm@uit.edu.vn; duyld@uit.edu.vn;
   ducda@uit.edu.vn
RI Nguyen, Tam/AAU-6504-2020; Nguyen, Tam/HSG-3007-2023
OI Nguyen, Tam/0000-0003-0236-7992; Nguyen, Khanh/0000-0003-4237-2737
FU Viet Nam National University Ho Chi Minh City (VNU-HCM) [B2017-26-01]
FX This research is funded by Viet Nam National University Ho Chi Minh City
   (VNU-HCM) under Grant No. B2017-26-01.
CR [Anonymous], 2018, COMPUTER VISION PATT
   [Anonymous], 2008, 2008 IEEE COMP SOC C
   [Anonymous], 2016, 14 EUR C COMP VIS EC
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, DEEP FOREST ALTERNAT
   [Anonymous], 2017, P 31 AAAI C ART INT
   [Anonymous], 2016, ARXIV160207360
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.470
   [Anonymous], 2018, ARXIV180500932
   [Anonymous], 2017, ARXIV170505502
   [Anonymous], 2018, ARXIV180406516
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2016, PROC CVPR IEEE, P2884, DOI 10.1109/CVPR.2016.315
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Handa A, 2016, IEEE INT CONF ROBOT, P5737, DOI 10.1109/ICRA.2016.7487797
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Johnson-Roberson Matthew, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P746, DOI 10.1109/ICRA.2017.7989092
   KAHAN TL, 1994, CONSCIOUS COGN, V3, P246, DOI 10.1006/ccog.1994.1014
   Nguyen KD, 2019, J VIS COMMUN IMAGE R, V60, P206, DOI 10.1016/j.jvcir.2019.02.020
   Mengdie Chu, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P605, DOI 10.1007/978-3-319-69923-3_65
   Nguyen TV, 2019, IEEE T IMAGE PROCESS, V28, P3130, DOI 10.1109/TIP.2019.2894284
   Nguyen TV, 2018, INT J COMPUT VISION, V126, P86, DOI 10.1007/s11263-017-1042-6
   Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K., 2014, 14091556 ARXIV
   Singh B, 2018, 32 C NEURAL INFORM P
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tam V N, 2016, ICARCV, P1
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XY, 2015, IEEE T PATTERN ANAL, V37, P2071, DOI 10.1109/TPAMI.2015.2389830
   Zhang D., 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4
NR 50
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28189
EP 28208
DI 10.1007/s11042-019-07888-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000063
DA 2024-07-18
ER

PT J
AU Kim, YS
   Yoon, JC
   Lee, IK
AF Kim, Yeong-Seok
   Yoon, Jong-Chul
   Lee, In-Kwon
TI Real-time human segmentation from RGB-D video sequence based on adaptive
   geodesic distance computation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time foreground segmentation; Natural background substitution;
   Depth video processing; RGB-D video; Geodesic matting
ID BILATERAL FILTER; IMAGE
AB In this paper, we propose a method for extracting humans in the foreground of video frames using color and depth information. To ensure real-time performance and to increase accuracy, we classify a video frame into two parts by degree of noise: head region with high noise level, and non-head region with low noise level. Then, we apply a high-computational geodesic matting algorithm to the noisy head region that includes hair, and a low-computational hole filling with smoothing method to other regions. Additionally, we modify the traditional color-based geodesic segmentation algorithm to consider additional depth information. Then, we apply temporal/spatial smoothing to the blended foreground mask in order to enhance the coherence between video frames. Experimental results show that the proposed method outperforms a previous approach by accuracy and performance.
C1 [Kim, Yeong-Seok; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Yonsei Ro 50, Seoul 03722, South Korea.
   [Yoon, Jong-Chul] Kangwon Natl Univ, Dept Broadcasting Media Technol, Dogye, South Korea.
C3 Yonsei University; Kangwon National University
RP Lee, IK (corresponding author), Yonsei Univ, Dept Comp Sci, Yonsei Ro 50, Seoul 03722, South Korea.
EM kys71015@gmail.com; iklee@yonsei.ac.kr
RI Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882
FU ZoYool Co., Ltd.; KCTVJEJU Co., Ltd.
FX This work was supported by ZoYool Co., Ltd. and KCTVJEJU Co., Ltd.
CR [Anonymous], 2006 I E COMP SOC C
   [Anonymous], 3DTV C TRUE VIS CAPT
   [Anonymous], 2007, IBPRIA 07 P 3 IB C P
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2010, IEEE C COMP VIS PATT
   Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z
   Banterle F, 2012, COMPUT GRAPH FORUM, V31, P19, DOI 10.1111/j.1467-8659.2011.02078.x
   Barrón C, 2001, COMPUT VIS IMAGE UND, V81, P269, DOI 10.1006/cviu.2000.0888
   Camplani M, 2012, PROC SPIE, V8290, DOI 10.1117/12.911909
   Chandra S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P436, DOI 10.1109/ICCVW.2015.64
   Ding R, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/576759
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Gallego J, 2014, J VIS COMMUN IMAGE R, V25, P184, DOI 10.1016/j.jvcir.2013.03.019
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hedayati M., 2012, J COMPUTATIONAL INFO, P493
   Hernández-Vela A, 2012, SENSORS-BASEL, V12, P15376, DOI 10.3390/s121115376
   Juan O, 2005, LECT NOTES COMPUT SC, V3752, P186
   Karaman M, 2005, PROC SPIE, V5960, P2140, DOI 10.1117/12.633437
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Landau MJ, 2016, IEEE T CYBERNETICS, V46, P3018, DOI 10.1109/TCYB.2015.2494877
   Oliveira GL, 2016, IEEE INT CONF ROBOT, P1634, DOI 10.1109/ICRA.2016.7487304
   SHIMODA S, 1989, IEEE T BROADCAST, V35, P357, DOI 10.1109/11.40835
   Song CF, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P474, DOI 10.1109/ACPR.2015.7486548
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   Sung-Yeol Kim, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2358, DOI 10.1109/ICPR.2010.577
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Weber O, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409626
   Yu HC, 2009, IEEE T IMAGE PROCESS, V18, P2364, DOI 10.1109/TIP.2009.2026685
   Zhang C, 2006, IEEE IMAGE PROC, P481, DOI 10.1109/ICIP.2006.312498
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 31
TC 2
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28409
EP 28421
DI 10.1007/s11042-017-5375-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700004
DA 2024-07-18
ER

PT J
AU Krishnaveni, B
   Sridhar, S
AF Krishnaveni, B.
   Sridhar, S.
TI Approximation algorithm based on greedy approach for face recognition
   with partial occlusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Partial occlusion; Approximation; String matching;
   Greedy approach
ID EXPRESSION VARIANT FACES; NEURAL-NETWORKS; IMAGE; REPRESENTATION; ROBUST
AB The problem of partial occlusion in face recognition has received less attention over the last few years. Partial occlusion is an important challenge of the face recognition, in which certain parts of a face are hidden by the objects such as sunglasses, hats, scarves, and a mask that can cause significant degradation in the performance of the recognition system. This paper specifically addresses face recognition with partial occlusion. The proposed algorithm is an approximate version of conventional dynamic time warping (DTW), which is an exact algorithm and based on dynamic programming. An exact algorithm provides an exact result and involves huge computation efforts when there is a gallery with more images. Hence, a faster approximation algorithm based on greedy approach is proposed to solve the partially occluded face recognition problem by finding a near optimal solution with a guarantee on its performance. Many image processing applications are real-time and need a near-optimal solution. The proposed work has two contributions, the first one is in designing a string generation algorithm for converting a face into a sequence of strings and the second is designing an approximation algorithm based on greedy approach for matching strings. The proposed work uses standard face databases such as FEI, IAB, ORL, and Extended Yale-B for evaluating the effectiveness of the system.
C1 [Krishnaveni, B.; Sridhar, S.] Anna Univ, Informat Sci & Technol Dept, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Krishnaveni, B (corresponding author), Anna Univ, Informat Sci & Technol Dept, Chennai, Tamil Nadu, India.
EM Krishnaveni@auist.net; ssridhar@auist.net
RI Bommidi, Krishnaveni/AAS-8881-2021
OI , Sridhar S/0000-0002-2483-104X
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Amaral V, 2009, PORTUGUESE PERIODICO, V1
   Amaral V, 2008, TECHNICAL REPORT
   [Anonymous], P INT C BIOM
   AT&T LABORATORIES CAMBRIDGE, 2002, DAT FAC
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen WP, 2013, IEEE T IMAGE PROCESS, V22, P4798, DOI 10.1109/TIP.2013.2277920
   Chen WP, 2010, LECT NOTES COMPUT SC, V6313, P496
   Dagnes N, 2018, MACH VISION APPL, V29, P789, DOI 10.1007/s00138-018-0933-z
   Dhamecha TI, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099212
   Ekenel HK, 2009, LECT NOTES COMPUT SC, V5558, P299, DOI 10.1007/978-3-642-01793-3_31
   Fuino M, 2014, FACE RECOGNITION USI
   Georghiades A, 2001, FEW MANY ILLUMINATIO
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Hu GS, 2018, IEEE T IMAGE PROCESS, V27, P293, DOI 10.1109/TIP.2017.2756450
   Jia H., 2008, Proc. FG, P1
   Jia HJ, 2009, PROC CVPR IEEE, P136, DOI 10.1109/CVPRW.2009.5206862
   Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Lee K-C, 2005, ACQUIRING LINEAR SUB
   Liao S., 2011, P INT JOINT C BIOM I
   Lin D, 2007, SACMAT'07: PROCEEDINGS OF THE 12TH ACM SYMPOSIUM ON ACCESS CONTROL MODELS AND TECHNOLOGIES, P1
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4042, DOI 10.1109/TIP.2017.2713940
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Mehdipour G.M., 2016, P P IEEE C COMP VIS, P34
   MiarNaimi H., 2008, IRANIAN J ELECT ELEC, V4
   Oh HJ, 2008, IMAGE VISION COMPUT, V26, P1515, DOI 10.1016/j.imavis.2008.04.016
   Rama A., 2008, P 8 IEEE INT C AUT F
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rui Min, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P442, DOI 10.1109/FG.2011.5771439
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Storer Markus., 2010, P WORKSHOPS IEEE C C, P122
   Tan XY, 2009, IEEE T INF FOREN SEC, V4, P217, DOI 10.1109/TIFS.2009.2020772
   Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Wan M, 2014, INF SCI, V27, P455
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wei XJ, 2014, IEEE T INF FOREN SEC, V9, P2035, DOI 10.1109/TIFS.2014.2359632
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
NR 45
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27511
EP 27531
DI 10.1007/s11042-019-07831-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000033
DA 2024-07-18
ER

PT J
AU Cheng, DS
   Zhang, YQ
   Liu, C
   Liu, XF
AF Cheng, Dansong
   Zhang, Yongqiang
   Liu, Ce
   Liu, Xiaofang
TI Sign-correlation cascaded regression for face alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign correlation; Supervised descent method; Face alignment; cascaded
   regression
AB Face alignment plays an important role in many applications such as face recognition and face reconstruction. Current regression based approaches can ease the multi-pose face alignment problem, but they fail to deal with the multiple local minima problem directly. To improve the performance of multi-pose facial landmark localization, in this paper we propose a sign correlation supervised descent method (SC-SDM) based on a nonlinear optimization theory. SC-SDM analyses the sign correlation between features and shapes and project both of them into a mutual sign-correlation subspace. By partitioning the whole multi-pose samples into a series of pose-consistent subsets, a group of models are learned from each subset. The experiments using the public multi-pose datasets has validated the partition and proved that SC-SDM can accurately separate samples into pose-consistent subsets, which reveals their latent relationships to pose. The comparison with state-of-the-art methods demonstrates that SC-SDM outperforms them, especially in uncontrolled conditions with various poses.
C1 [Cheng, Dansong; Zhang, Yongqiang; Liu, Ce] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Liu, Xiaofang] Harbin Inst Technol, Sch Elect Engn & Automat, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Liu, XF (corresponding author), Harbin Inst Technol, Sch Elect Engn & Automat, Harbin 150001, Heilongjiang, Peoples R China.
EM cdsinhit@hit.edu.cn; liuxf@hit.edu.cn
RI Cheng, Dan/ITT-7298-2023
CR Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Cao X, 2012, US Patent App, Patent No. [13/728,584, 13728584]
   Cheng D, 2015, SOFT COMPUT, V21, P1
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Dong S, 2016, C P IEEE ENG MED BIO, V1, P3791
   Gonzalez-Mora J, 2007, IEEE I CONF COMP VIS, P2776
   Gu L, 2009, FACE ALIGNMENT
   Huang G. B., 2008, WORKSH FAC REAL LIF
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Koestinger M., 2011, IEEE INT C COMP VIS, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lee HS, 2009, IEEE T PATTERN ANAL, V31, P1102, DOI 10.1109/TPAMI.2008.286
   Ramanan D, 2015, IEEE C COMP VIS PATT, P31
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Romdhani S., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P483
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Sánchez-Lozano E, 2016, PATTERN RECOGN LETT, V73, P19, DOI 10.1016/j.patrec.2015.11.014
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Wilks D. S., 2011, GEOPHYS J INT, V100, P563, DOI DOI 10.1016/B978-0-12-385022-5.00013-0
   Xing JL, 2014, PROC CVPR IEEE, P1829, DOI 10.1109/CVPR.2014.236
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P2393, DOI 10.1109/TIP.2015.2421438
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang Y, 2017, IEEE CONFERENCE ON C
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 31
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26681
EP 26699
DI 10.1007/s11042-019-7737-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700062
DA 2024-07-18
ER

PT J
AU Liu, HF
   Han, XF
   Li, XR
   Yao, YZ
   Huang, P
   Tang, ZM
AF Liu, Huafeng
   Han, Xiaofeng
   Li, Xiangrui
   Yao, Yazhou
   Huang, Pu
   Tang, Zhenmin
TI Deep representation learning for road detection using Siamese network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road detection; Siamese network; Data fusion; Deep learning
AB Robust road detection is a key challenge in safe autonomous driving. Recently, with the rapid development of 3D sensors, more and more researchers are trying to fuse information across different sensors to improve the performance of road detection. Although many successful works have been achieved in this field, methods for data fusion under deep learning framework is still an open problem. In this paper, we propose a Siamese deep neural network based on FCN-8s to detect road region. Our method uses data collected from a monocular color camera and a Velodyne-64 LiDAR sensor. We project the LiDAR point clouds onto the image plane to generate LiDAR images and feed them into one of the branches of the network. The RGB images are fed into another branch of our proposed network. The feature maps that these two branches extract in multiple scales are fused before each pooling layer, via padding additional fusion layers. Extensive experimental results on public dataset KITTI ROAD demonstrate the effectiveness of our proposed approach.
C1 [Liu, Huafeng; Han, Xiaofeng; Li, Xiangrui; Yao, Yazhou; Tang, Zhenmin] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Huang, Pu] Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Big Data Secur, Intelligent Proc, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of Posts
   & Telecommunications
RP Tang, ZM (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM liu.hua.feng@outlook.com; tzm.cs@njust.edu.cn
RI Tang, Zhenmin/AAY-6058-2020; han, xiao/HDN-9782-2022
OI Tang, Zhenmin/0000-0001-6708-2205; Liu, Huafeng/0000-0001-5396-3183
FU Major Special Project of Core Electronic Devices, High-end Generic Chips
   and Basic Software [2015ZX01041101]; National Defense Preresearch
   Foundation [41412010101]; China Postdoctoral Science Foundation
   [2016M600433]
FX This research was supported by the Major Special Project of Core
   Electronic Devices, High-end Generic Chips and Basic Software(Grant No.
   2015ZX01041101), National Defense Preresearch Foundation(Grant No.
   41412010101) and the China Postdoctoral Science Foundation (Grant No.
   2016M600433).
CR Almazan Emilio J., 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P96, DOI 10.1007/978-3-319-46604-0_7
   [Anonymous], IEEE INT TRANSP SYST
   [Anonymous], 2016, CORR
   [Anonymous], IEEE C INT TRANSP SY
   [Anonymous], 2016, NIPS WORKSH
   Asvadi A, 2018, PATTERN RECOGN LETT, V115, P20, DOI 10.1016/j.patrec.2017.09.038
   Asvadi A, 2016, ROBOT AUTON SYST, V83, P299, DOI 10.1016/j.robot.2016.06.007
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Caltagirone L, 2017, IEEE INT VEH SYM, P1019
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen TT, 2014, J INTELL ROBOT SYST, V76, P563, DOI 10.1007/s10846-013-9889-4
   Chen YF, 2017, IEEE INT C INT ROBOT, P1343, DOI 10.1109/IROS.2017.8202312
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P639, DOI 10.1145/3178876.3186145
   Han XF, 2018, IEEE SIGNAL PROC LET, V25, P551, DOI 10.1109/LSP.2018.2809685
   Han XF, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417738102
   Hata AY, 2014, IEEE INT VEH SYM, P1264
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongwu Qin, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P3619, DOI 10.1109/ICNC.2010.5584032
   Hu X, 2014, IEEE INT VEH SYM, P1365, DOI 10.1109/IVS.2014.6856466
   Laddha A, 2016, IEEE INT VEH SYM, P118, DOI 10.1109/IVS.2016.7535374
   Li J, 2018, IEEE T COMPUT SOC SY, V5, P324, DOI 10.1109/TCSS.2018.2797225
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Moghadam P, 2012, IEEE T IMAGE PROCESS, V21, P425, DOI 10.1109/TIP.2011.2162422
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Schlosser J, 2016, IEEE INT CONF ROBOT, P2198, DOI 10.1109/ICRA.2016.7487370
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Siam M, 2017, IEEE INT C INTELL TR
   Simonyan K, 2015, IEEE INT C ICLR
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Mendes CCT, 2016, IEEE INT CONF ROBOT, P3174, DOI 10.1109/ICRA.2016.7487486
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wijesoma WS, 2004, IEEE T ROBOTIC AUTOM, V20, P456, DOI 10.1109/TRA.2004.825269
   Xiao L, 2018, INFORM SCIENCES, V432, P543, DOI 10.1016/j.ins.2017.04.048
   Xiao L, 2015, IEEE INT VEH SYM, P192, DOI 10.1109/IVS.2015.7225685
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 43
TC 10
Z9 12
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24269
EP 24283
DI 10.1007/s11042-018-6986-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900026
DA 2024-07-18
ER

PT J
AU Bashir, T
   Usman, I
   Albesher, A
   Almejalli, KA
   Naqvi, SS
AF Bashir, Tariq
   Usman, Imran
   Albesher, Abdulaziz
   Almejalli, Khalid A.
   Naqvi, Syed Saud
TI GP based smart reversible watermarking of depth image based rendering
   for stereoscopic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpolation error expansion; Reversible watermarking; Genetic
   programming (GP); Depth image based rendering 3D television (DIBR 3D-TV)
ID DIFFERENCE EXPANSION
AB Depth Image Based Rendering (DIBR) for 3D-TV, or free-view TV, is one of the most promising techniques in multimedia world, whereby a monoscopic image and the depth image of the same view are utilized to generate stereoscopic left and right images. Therefore, the protection of valuable content generated for 3D TV is an important concern in the world of digital media. In this paper, we exploit an interpolation errors expansion scheme by employing Genetic Programming based smart reversible watermarking technique that is viable for 3D-TV. The proposed technique exploits directional weights using hidden dependencies pertaining to the imperceptibility and capacity of the watermark in a previously established interpolation scheme. It then embeds the watermark in the 3D content using interpolation error expansion based reversible watermarking scheme. Previously presented empirical techniques are not much effective as they use hit and trial strategies for selecting optimal weights for watermark embedding. The proposed technique achieves significant watermark capacity as well as imperceptibility, and is reversible when compared to existing state of the art techniques.
C1 [Bashir, Tariq; Naqvi, Syed Saud] COMSATS Univ, Dept Elect Engn, Islamabad, Pakistan.
   [Usman, Imran; Albesher, Abdulaziz; Almejalli, Khalid A.] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); Saudi Electronic University
RP Usman, I (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
EM i.usman@seu.edu.sa
RI Bashir, Tariq/AAC-8823-2019
OI Bashir, Tariq/0000-0002-8014-7816
CR Abdeldaim AM, 2018, ADV SOFT COMPUTING M, P730
   Alattar AM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alattar AM, 2003, IEEE IMAGE PROC, P501
   Baird JL, BAIRD TELEVISION
   Barton J.M., 1997, Method and apparatus for embedding authentication information within digital data
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chen M, 2009, IEEE IMAGE PROC, P4253, DOI 10.1109/ICIP.2009.5413717
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Chia-Chen Lin, 2010, Journal of Software, V5, P1, DOI 10.4304/jsw.5.2.214-224
   Christoph F, 2003, 3D TV APPROACH USING, P482
   CHRISTOPH F, 2004, SPIE P STER DISPL VI, V5291, P93, DOI DOI 10.1117/12.524762
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   De Vleeschouwer C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P345, DOI 10.1109/MMSP.2001.962758
   Elhoseny M, 2020, MULTIMED TOOLS APPL, V79, P5005, DOI 10.1007/s11042-018-6095-1
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Jung SW, 2016, SIGNAL PROCESS, V122, P39, DOI 10.1016/j.sigpro.2015.11.018
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Ko LT, 2011, COMPUTATIONAL MATHEM
   Ko LT, 2012, MATH PROBL ENG
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Lu TC, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1133, DOI 10.1109/IIH-MSP.2008.7
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Luo T, 2016, DIGIT SIGNAL PROCESS, V48, P116, DOI 10.1016/j.dsp.2015.09.007
   Memon NA, 2011, INT J COMPUT MATH, V88, P1573, DOI 10.1080/00207160.2010.509429
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Rabbani M., 2001, LOSSLESS RECOVERY OR, V6, P791
   Redert A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P313
   Saberian MJ, 2008, INT CONF ACOUST SPEE, P1677, DOI 10.1109/ICASSP.2008.4517950
   Sara SA, GENETIC PROGRAMMING
   Scharstein D, MIDDLEBURY COMPUTER
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Usman I, 2010, APPL SOFT COMPUT, V10, P332, DOI 10.1016/j.asoc.2009.08.004
   Wen CY, 2015, MULTIMED TOOLS APPL, V74, P7181, DOI [10.1007/s11042-014-1958-6, DOI 10.1007/S11042-014-1958-6]
   Wien Hong, 2009, Information Technology Journal, V8, P1287, DOI 10.3923/itj.2009.1287.1291
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Yiu-ming Cheung, 2007, IEEE Transactions on Circuits and Systems for Video Technology, V17, P1007, DOI 10.1109/TCSVT.2007.903553
NR 48
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21943
EP 21962
DI 10.1007/s11042-019-7399-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400061
DA 2024-07-18
ER

PT J
AU Corcella, L
   Manca, M
   Nordvik, JE
   Paternò, F
   Sanders, AM
   Santoro, C
AF Corcella, Luca
   Manca, Marco
   Nordvik, Jan Egil
   Paterno, Fabio
   Sanders, Anne-Marthe
   Santoro, Carmen
TI Enabling personalisation of remote elderly assistance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE End-user development; Ambient assisted living; Personalisation rules
AB One of the goals of Ambient Assisted Living (AAL) solutions is to extend the time that elderly people can live independently in their preferred environments by using ICT technologies for personal healthcare. However, in order to be optimal, remote monitoring services and health-related interventions should be strongly personalised to specific individuals' requirements, preferences, abilities and motivations, which can vary among the elderly, and even dynamically evolve over time for the same person depending on changing user needs and context-dependent conditions. In this paper we present an End User Development (EUD) tool for the personalisation of context-dependent assistance by non-technical users in the AAL domain. In particular, we have considered applications for remotely monitoring and assisting elderly people at home through sending multimedia messages and reminders, as well as changing the state of various domestic appliances (e.g. lamps, heating system, TV) and devices available in the context surrounding the user. The design and development of the tailoring environment has been carried out in an iterative manner, informed by the feedback that was gathered through empirical evaluations done with older adults and caregivers.
C1 [Corcella, Luca; Manca, Marco; Paterno, Fabio; Santoro, Carmen] CNR ISTI HIIS Lab, Pisa, Italy.
   [Nordvik, Jan Egil; Sanders, Anne-Marthe] SUNNAS RH, Oslo, Norway.
RP Santoro, C (corresponding author), CNR ISTI HIIS Lab, Pisa, Italy.
EM carmen.santoro@isti.cnr.it
RI Manca, Marco/AAX-1274-2020; Santoro, Carmen/C-7477-2015; Paterno,
   Fabio/H-6443-2017
OI Manca, Marco/0000-0003-1029-9934; Paterno, Fabio/0000-0001-8355-6909
FU Ambient Assisted Living Project PersonAAL
FX This work was partly supported by the Ambient Assisted Living Project
   PersonAAL (http://www.personaal-project.eu).
CR Cabitza F, 2017, MULTIMED TOOLS APPL, V76, P5221, DOI 10.1007/s11042-016-3511-2
   Carmien SP, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P597
   Cesta A, 2018, J AMB INTEL SMART EN, V10, P49, DOI 10.3233/AIS-170471
   Chesta C, 2017, CHITALY, V6
   Consolvo S, 2004, LECT NOTES COMPUT SC, V3205, P1
   Corcella L, 2017, P 6 INT S END US DEV, P18, DOI [10. 1007/978-3-319-58735-6_2, DOI 10.1007/978-3-319-58735-6_2]
   Corno F, 2017, COMPUTER, V50, P18, DOI 10.1109/MC.2017.4041355
   Corno Fulvio., 2017, Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P1546
   Coutaz J, 2016, IEEE PERVAS COMPUT, V15, P26, DOI 10.1109/MPRV.2016.24
   Criel J, 2011, LECT NOTES COMPUT SC, V6646, P94, DOI 10.1007/978-3-642-20754-9_11
   Criel J, 2011, BELL LABS TECH J, V16, P35, DOI 10.1002/bltj.20484
   DEMIRIS G, 2008, YB MED INFORM, V2008, P33
   Desolda G, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3057859
   Dinte E., 2018, APPL ADHESIVE BONDIN, V120
   Ghiani G, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3057861
   Huang J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P215, DOI 10.1145/2750858.2805830
   Lieberman H, 2006, END USER DEV EMERGIN, P1, DOI DOI 10.1007/1-4020-5386-X_1
   Lucci G, INT C HUM CTR SOFTW, P182
   MARKLAND D, 1993, PERS INDIV DIFFER, V15, P289, DOI 10.1016/0191-8869(93)90219-S
   Metaxas G, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3057860
   Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Steinke F, 2012, P 5 INT C PERVASIVE, DOI 10. 1145/2413097. 2413116
   Teixeira PJ, 2012, INT J BEHAV NUTR PHY, V9, DOI 10.1186/1479-5868-9-78
   Tetteroo D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4133, DOI 10.1145/2702123.2702504
   Ur B., 2014, CHI, DOI 10.1145/2556288.2557420
   Vergados DD, 2010, PERS UBIQUIT COMPUT, V14, P575, DOI 10.1007/s00779-009-0278-8
   Yarosh S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2993, DOI 10.1145/3025453.3025617
   Zejda D, 2010, P INT C INT ENV
   Zhao JC, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1583, DOI 10.1145/2702123.2702588
NR 30
TC 10
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21557
EP 21583
DI 10.1007/s11042-019-7449-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400046
DA 2024-07-18
ER

PT J
AU Debnath, S
   Talukdar, FA
AF Debnath, Sushanta
   Talukdar, Fazal A.
TI Brain tumour segmentation using memory based learning method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumour; Segmentation; Magnetic Resonance image; Histogram
   stretching; Iterative process
ID DEFORMABLE MODEL
AB A brain tumour is a mass of tissue formed by abnormal growth of cells within the brain. Automated detection of brain tumour becomes essential for introduction of robotics based treatment process. The proposed method focuses on enhancing the speed of brain tumour segmentation in 2D sliced images without compromising the detection accuracy. The method uses memory based learning of a particular database along with two fold of histogram stretching for faster and accurate identification of tumour portion in a 2D sliced image.The second histogram stretching is used when the segmentation criterion gets failed after the first histogram stretching. It is necessary to reduce the computational time of accurate tumour segmentation in 2D sliced images obtained from a 3D Magnetic Resonance (MR) image so that faster detection of 3D tumour portion becomes possible without deteriorating the accuracy of detection. 2D tumour segmentation accuracy and computational time of the system is found to be 100% and 0.179 s respectively in the performance analysis. The proposed method reduces the computational time to a large extend by eliminating the conventional iterative process of computation.
C1 [Debnath, Sushanta; Talukdar, Fazal A.] Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Debnath, S (corresponding author), Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
EM sushantadebnath020@gmail.com
RI Talukdar, Fazal/AAX-4652-2020
OI Talukdar, Fazal/0000-0002-5067-3444
FU Speech and Signal Processing Laboratory, ECE Department, National
   Institute of Technology Silchar, Assam, India
FX The authors would like to acknowledge Speech and Signal Processing
   Laboratory, ECE Department, National Institute of Technology Silchar,
   Assam, India for providing support and necessary facilities for carrying
   out the research work. Moreover, the authors would like to thank Mr.
   Mohiul Islam, a Ph.D. Scholar of the same department for his valuable
   suggestions.
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Ahmadvand A, 2018, MULTIMED TOOLS APPL, V77, P8001, DOI 10.1007/s11042-017-4696-8
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], DES AUTOM EMBED SYST
   [Anonymous], 2012, IET CHENNAI 3 INT C, DOI DOI 10.1049/CP.2012.2181
   [Anonymous], 2015, 2015 8 INT C ADV PAT
   [Anonymous], 2014, P INT ACM SIGIR WORK
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], EL EL COMM COMP OPT
   Aruchamy S, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2043
   Arulmani S, 2018, MICRO NANO TECHNOL, P1, DOI 10.1016/B978-0-12-813731-4.00001-1
   Aslam A, 2015, PROCEDIA COMPUT SCI, V58, P430, DOI 10.1016/j.procs.2015.08.057
   Banday SA, 2017, MULTIMED TOOLS APPL, V76, P3809, DOI 10.1007/s11042-016-3979-9
   Busa Srikanth, 2019, Innovations in Computer Science and Engineering. Proceedings of the Fifth ICICSE 2017. Lecture Notes in Networks and Systems (LNNS 32), P249, DOI 10.1007/978-981-10-8201-6_28
   Chandra GR, 2016, PROCEDIA COMPUT SCI, V79, P449, DOI 10.1016/j.procs.2016.03.058
   Chansuparp M, 2015, 2015 8TH BIOMEDICAL ENGINEERING INTERNATIONAL CONFERENCE (BMEICON)
   Ebadati EOM, 2017, STUD BIG DATA, V23, P335, DOI 10.1007/978-3-319-49736-5_14
   Gonzalez R.C., 2002, Digital image processing second edition, P455
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Kiranmayee BV, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P46, DOI 10.1109/IC3I.2016.7917933
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mudgal TK, 2017, INT C SOFT COMP ITS, P1, DOI [DOI 10.1109/ICSOFTCOMP.2017.8280091, 10.1109/ICSOFTCOMP.2017.8280091]
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Patel A, 2012, LECT NOTES ENG COMP, P142
   Rajendran A, 2012, PROCEDIA ENGINEER, V30, P327, DOI 10.1016/j.proeng.2012.01.868
   Roslan R., 2010, 2010 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2010), P26, DOI 10.1109/IECBES.2010.5742193
   Ségonne F, 2004, NEUROIMAGE, V22, P1060, DOI 10.1016/j.neuroimage.2004.03.032
   Shanthi KJ, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P422
   Singh N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1325, DOI 10.1109/ICCSP.2017.8286598
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Subudhi A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P931, DOI 10.1109/ICCSP.2016.7754284
   Thara KS, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1504, DOI 10.1109/WiSPNET.2016.7566388
   Vijay V, 2016, PROCEDIA COMPUT SCI, V92, P475, DOI 10.1016/j.procs.2016.07.370
   Wei Zhao, 2010, Proceedings 2010 Second International Conference on Computer Modeling and Simulation (ICCMS), P159, DOI 10.1109/ICCMS.2010.277
NR 38
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23689
EP 23706
DI 10.1007/s11042-019-7673-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400066
DA 2024-07-18
ER

PT J
AU Dong, YC
   Lin, MJ
   Yue, JG
   Shi, L
AF Dong, Yanchao
   Lin, Minjing
   Yue, Jiguang
   Shi, Liang
TI A low-cost photorealistic CG dataset rendering pipeline for facial
   landmark localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Labelled face dataset; Facial landmark localization; CG rendering
   pipe-line; Varying factors analysis; Across large rotation
ID FACE ALIGNMENT; DATABASE
AB Face analysis has been a hot research field in computer vision for decades. The dataset is of vital importance for modern machine learning methods. The paper proposes a flexible CG (Computer Graphics) rendering pipe-line for creating facial image datasets together with automatic ground truth labelling. The proposed pipe-line could produce a huge amount of labelled data fast and in low cost compared to traditional dataset creation methods which need high cost hardware and longtime manual ground truth labelling. The paper also proposes a data capture setup in the CG environment for creating the dataset for facial landmark localization. The effectiveness of the proposed method is verified by cross validation with Multi-PIE dataset. For creating a high quality training dataset, some of the varying factors of the dataset should be considered. The paper analyzes a few varying factors for accurate eye landmark localization, such as eye closure levels, eye and eyebrow shapes and wearing glasses. Based on the benefits of the proposed CG rendering pipe-line, the paper implemented a facial landmark localization system across large face rotation by integrating off-the-shelves algorithms. The experiments on Multi-PIE and real persons show that the implemented system could localize facial landmarks accurately across [-90 degrees, +90 degrees] in yaw rotation in real time.
C1 [Dong, Yanchao; Lin, Minjing; Shi, Liang] Tongji Univ, Shanghai, Peoples R China.
   [Yue, Jiguang] Tongji Univ, Dept Control Theory & Control Engn, Shanghai, Peoples R China.
C3 Tongji University; Tongji University
RP Dong, YC (corresponding author), Tongji Univ, Shanghai, Peoples R China.
EM dongyanchao@tongji.edu.cn; 1730756@tongji.edu.cn;
   yuejiguang@tongji.edu.cn; 1531794@tongji.edu.cn
OI Dong, Yanchao/0000-0001-6864-8354
FU National Natural Science Foundation of China [61873189]; Natural Science
   Foundation of Shanghai [18ZR1442500]; Fundamental Research Funds for the
   Central Universities
FX The work was partially supported by the National Natural Science
   Foundation of China under Grant No. 61873189, the Natural Science
   Foundation of Shanghai under Grant No. 18ZR1442500 and the Fundamental
   Research Funds for the Central Universities.
CR [Anonymous], 2013 IEEE INT C COMP
   [Anonymous], CVPR 7
   [Anonymous], MUCT LANDMARKED FACE
   [Anonymous], 2017, IEEE T PATTERN ANAL
   [Anonymous], ROBUST FACIAL LANDMA
   [Anonymous], SPRINGER TEXTS ELECT
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Criminisi A., 2013, DECISION FORESTCOM, DOI DOI 10.1007/978-1-4471-4929-3
   Deng WH, 2018, NEUROCOMPUTING, V273, P222, DOI 10.1016/j.neucom.2017.07.052
   Dong YC, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081157
   Dong YC, 2016, MULTIMED TOOLS APPL, V75, P11763, DOI 10.1007/s11042-015-2635-0
   Fan X, 2018, IEEE T MULTIMEDIA, V20, P567, DOI 10.1109/TMM.2017.2751143
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guo JH, 2019, MECH ADV MATER STRUC, V26, P1390, DOI 10.1080/15376494.2018.1432810
   Huang G.B., 2008, PROC WORKSHOP FACES
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kasinski A., 2008, Image Processing and Communications, V13, P59
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kendrick C, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10060230
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Ma DS, 2015, BEHAV RES METHODS, V47, P1122, DOI 10.3758/s13428-014-0532-5
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Siddiqi MH, 2015, MULTIMEDIA SYST, V21, P541, DOI 10.1007/s00530-014-0400-2
   Wang YM, 2016, NEUROCOMPUTING, V214, P881, DOI 10.1016/j.neucom.2016.07.025
   Weng RL, 2016, IEEE T MULTIMEDIA, V18, P2066, DOI 10.1109/TMM.2016.2591508
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yu J, 2016, MULTIMED TOOLS APPL, V75, P12021, DOI 10.1007/s11042-016-3368-4
NR 33
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22397
EP 22420
DI 10.1007/s11042-019-7516-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400010
DA 2024-07-18
ER

PT J
AU Kaur, T
   Saini, BS
   Gupta, S
AF Kaur, Taranjit
   Saini, Barjinder Singh
   Gupta, Savita
TI An adaptive fuzzy K-nearest neighbor approach for MR brain tumor image
   classification using parameter free bat optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy K-nearest neighbor; PFree BAT optimization; Diagnosis system;
   Model parameters
ID FEATURE-SELECTION; FEATURE-EXTRACTION; TEXTURE ANALYSIS; NEURAL-NETWORK;
   GLIOMA DETECTION; PERFORMANCE; SEGMENTATION; FEATURES; PREDICTION;
   TRANSFORMATION
AB This paper presents an automatic diagnosis system for the tumor grade classification through magnetic resonance imaging (MRI). The diagnosis system involves a region of interest (ROI) delineation using intensity and edge magnitude based multilevel thresholding algorithm. Then the intensity and the texture attributes are extracted from the segregated ROI. Subsequently, a combined approach known as Fisher+ Parameter-Free BAT (PFreeBAT) optimization is employed to derive the optimal feature subset. Finally, a novel learning approach dubbed as PFree BAT enhanced fuzzy K-nearest neighbor (FKNN) is proposed by combining FKNN with PFree BAT for the classification of MR images into two categories: High and Low-Grade. In PFree BAT enhanced FKNN, the model parameters, i.e., neighborhood size k and the fuzzy strength parameter m are adaptively specified by the PFree BAT optimization approach. Integrating PFree BAT with FKNN enhances the classification capability of the FKNN. The diagnostic system is rigorously evaluated on four MR images datasets including images from BRATS 2012 database and the Harvard repository using classification performance metrics. The empirical results illustrate that the diagnostic system reached to ceiling level of accuracy on the test MR image dataset via 5-fold cross-validation mechanism. Additionally, the proposed PFree BAT enhanced FKNN is evaluated on the Parkinson dataset (PD) from the UCI repository having the pre-extracted feature space. The proposed PFree BAT enhanced FKNN reached to an average accuracy of 98% and 97.45%. with and without feature selection on PD dataset. Moreover, solely to contrast, the performance of the proposed PFree BAT enhanced FKNN with the existing FKNN variants the experimentations were also done on six other standard datasets from KEEL repository. The results indicate that the proposed learning strategy achieves the best value of accuracy in contrast to the existing FKNN variants.
C1 [Kaur, Taranjit; Saini, Barjinder Singh] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Elect & Commun Engn, Jalandhar 144011, Punjab, India.
   [Gupta, Savita] Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Sect 25, Chandigarh, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Panjab University
RP Kaur, T (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Elect & Commun Engn, Jalandhar 144011, Punjab, India.
EM taran.rehal@yahoo.com; sainibss@gmail.com; savita2k8@yahoo.com
RI Kaur, Taranjit/IUP-1687-2023; Gupta, Savita/AAB-3257-2021; Saini,
   Barjinder Singh/Y-2321-2019
OI Gupta, Savita/0000-0001-5401-2208; Saini, Barjinder
   Singh/0000-0003-0932-6851; Kansal, Harmesh Kumar/0000-0002-3304-7476
CR AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 1995, INTUITIONISTIC FUZZY
   Arif Muhammad, 2010, Journal of Biomedical Science & Engineering, V3, P380, DOI 10.4236/jbise.2010.34053
   Åström F, 2011, EXPERT SYST APPL, V38, P12470, DOI 10.1016/j.eswa.2011.04.028
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Bakwad KM, 2009, WOR CONG NAT BIOL, P1076
   Cai Z, 2018, COMPUT MATH METHOD M, V2018, P1, DOI DOI 10.1155/2018/2396952
   Chen HL, 2016, NEUROCOMPUTING, V184, P131, DOI 10.1016/j.neucom.2015.07.138
   Chen HL, 2013, EXPERT SYST APPL, V40, P263, DOI 10.1016/j.eswa.2012.07.014
   Chen HL, 2011, KNOWL-BASED SYST, V24, P1348, DOI 10.1016/j.knosys.2011.06.008
   Cheng MY, 2014, J COMPUT CIVIL ENG, V28, DOI 10.1061/(ASCE)CP.1943-5487.0000275
   Colominas MA, 2014, BIOMED SIGNAL PROCES, V14, P19, DOI 10.1016/j.bspc.2014.06.009
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Das R, 2010, EXPERT SYST APPL, V37, P1568, DOI 10.1016/j.eswa.2009.06.040
   DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493
   Derrac J, 2016, INFORM SCIENCES, V329, P144, DOI 10.1016/j.ins.2015.09.007
   Bui DT, 2017, LANDSLIDES, V14, P1, DOI 10.1007/s10346-016-0708-4
   Emblem KE, 2009, J MAGN RESON IMAGING, V30, P1, DOI 10.1002/jmri.21815
   Fawcett T., 2004, MACH LEARN, V31, P1
   Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007
   Gibbs P, 2003, MAGN RESON MED, V50, P92, DOI 10.1002/mrm.10496
   Guo PF, 2010, LECT NOTES COMPUT SC, V6165, P306
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hemanth DJ, 2019, APPL SOFT COMPUT, V75, P21, DOI 10.1016/j.asoc.2018.10.054
   Hemanth DJ, 2011, COMM COM INF SC, V260, P356
   Herlidou-Même S, 2003, MAGN RESON IMAGING, V21, P989, DOI 10.1016/S0730-725X(03)00212-1
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hu X., 2005, J. Comput. Inf. Syst., V1, P203
   Iftekharuddin KM, 2009, APPL MATH COMPUT, V207, P23, DOI 10.1016/j.amc.2007.10.063
   Kaur T, 2018, NEURAL COMPUT APPL, V30, P1317, DOI 10.1007/s00521-016-2751-4
   Kaur T, 2018, NEURAL COMPUT APPL, V29, P193, DOI 10.1007/s00521-017-2869-z
   Kaur T, 2017, IET IMAGE PROCESS, V11, P620, DOI 10.1049/iet-ipr.2016.1103
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Lahmiri S, 2017, BIOMED SIGNAL PROCES, V31, P148, DOI 10.1016/j.bspc.2016.07.008
   Lee MC, 2008, ARTIF INTELL MED, V43, P61, DOI 10.1016/j.artmed.2008.03.002
   Lee SH, 2015, ENG APPL ARTIF INTEL, V45, P482, DOI 10.1016/j.engappai.2015.08.003
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li DC, 2011, ARTIF INTELL MED, V52, P45, DOI 10.1016/j.artmed.2011.02.001
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Little MA, 2009, IEEE T BIO-MED ENG, V56, P1015, DOI 10.1109/TBME.2008.2005954
   Liu DY, 2012, J MED SYST, V36, P3243, DOI 10.1007/s10916-011-9815-x
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu YH, 2012, J MED BIOL ENG, V32, P22, DOI 10.5405/jmbe.813
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu SY, 2017, CNS NEUROL DISORD-DR, V16, P23, DOI 10.2174/1871527315666161019153259
   Luukka P, 2011, EXPERT SYST APPL, V38, P4600, DOI 10.1016/j.eswa.2010.09.133
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033
   Mahmoud-Ghoneim D, 2003, MAGN RESON IMAGING, V21, P983, DOI 10.1016/S0730-725X(03)00201-7
   Materka A., 1998, TEXTURE ANAL METHODS
   Meng XB, 2015, EXPERT SYST APPL, V42, P6350, DOI 10.1016/j.eswa.2015.04.026
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Murthy GR, 2009, INT J BIO-INSPIR COM, V1, P14, DOI 10.1504/IJBIC.2009.022771
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Ozcift A, 2011, COMPUT METH PROG BIO, V104, P443, DOI 10.1016/j.cmpb.2011.03.018
   Psorakis I, 2010, IEEE T NEURAL NETWOR, V21, P1588, DOI 10.1109/TNN.2010.2064787
   Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, P1357, DOI 10.1162/153244303322753706
   Rhee FCH, 2003, IEEE INT CONF FUZZY, P802
   Sachdeva J, 2016, APPL SOFT COMPUT, V47, P151, DOI 10.1016/j.asoc.2016.05.020
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Saehdeva J, 2012, MAGN RESON IMAGING, V30, P694, DOI 10.1016/j.mri.2012.01.006
   Sakar CO, 2010, J MED SYST, V34, P591, DOI 10.1007/s10916-009-9272-y
   Shahbaba B, 2009, J MACH LEARN RES, V10, P1829
   Shrivastava P, 2017, COMPUT METH PROG BIO, V139, P171, DOI 10.1016/j.cmpb.2016.07.029
   Skogen K, 2016, EUR J RADIOL, V85, P824, DOI 10.1016/j.ejrad.2016.01.013
   Spadoto AA, 2011, IEEE ENG MED BIO, P7857, DOI 10.1109/IEMBS.2011.6091936
   Subashini MM, 2016, EXPERT SYST APPL, V43, P186, DOI 10.1016/j.eswa.2015.08.036
   Sudarshan VK, 2015, COMPUT BIOL MED, V62, P86, DOI 10.1016/j.compbiomed.2015.03.033
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Tencer L., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P1430, DOI 10.1109/ISSPA.2012.6310525
   Wagner F, 2012, BIOMED ENG-BIOMED TE, V57, P490, DOI 10.1515/bmt-2012-4240
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Wang SM, 2009, NEUROIMAGE, V44, P653, DOI 10.1016/j.neuroimage.2008.09.027
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Xu Y, 2006, ACAD RADIOL, V13, P969, DOI 10.1016/j.acra.2006.04.017
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Yang MS, 1998, IEEE T SYST MAN CY B, V28, P461, DOI 10.1109/3477.678652
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yilmaz S, 2015, APPL SOFT COMPUT, V28, P259, DOI 10.1016/j.asoc.2014.11.029
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zhang Y., 2013, The Scientific World Journal
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zöllner FG, 2012, Z MED PHYS, V22, P205, DOI 10.1016/j.zemedi.2012.03.007
NR 91
TC 19
Z9 20
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21853
EP 21890
DI 10.1007/s11042-019-7498-3
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400058
DA 2024-07-18
ER

PT J
AU Li, JY
   Fong, S
   Liu, LS
   Dey, N
   Ashour, AS
   Moraru, L
AF Li, Jinyan
   Fong, Simon
   Liu, Lian-sheng
   Dey, Nilanjan
   Ashour, Amira S.
   Moraru, Luminita
TI Dual feature selection and rebalancing strategy using metaheuristic
   optimization algorithms in X-ray image datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meta-heuristic; Medical X-ray image; Rebalancing; Feature selection;
   Dynamic multi-objective; Bat algorithm
ID SWARM OPTIMIZATION; CHEST RADIOGRAPHS; CLASSIFICATION; FILTER;
   INFORMATION; PREDICTION; WRAPPERS; DATABASE; NETWORK; DISEASE
AB The imbalance and multi-dimension are two common problems in the medical image datasets, which affect the performances of the image processing procedures. The traditional methods to solve these two problems are notoriously difficult. Accordingly, this work employed metaheuristic methods to optimize the rebalancing process of the imbalanced class distribution for further use in the feature selection procedure for dimensionality reduction for the medical X-ray image datasets. Different metaheuristic algorithms were used to maximize the parameter values of the rebalancing and feature selection phases to preprocess the datasets. The proposed work devised a multi-objective optimization strategy in the process of the metaheuristic algorithms search to solve the problem of dual imbalanced dataset and feature selection. Afterward, a comparative study of the proposed optimized approach with the conventional methods was conducted to evaluate the proposed method performance. The results established the superiority of the proposed method to overcome the imbalanced and multi-dimensional problem. The proposed method generated a reasonable number of minority class samples and selected a sensible subset of features to ultimately obtain a very extraordinary accuracy with great credibility from a negative value of kappa and a false high accuracy. It produced higher credibility and correctness classification performance in the practical problem of medical X-ray images compared to other algorithms. Feature selection with Random-SMOTE (RSMOTE) using the self-adaptive Bat algorithm is superior to the optimization using particle swarm optimization. The proposed method using the Bat algorithm achieved 94.6% classification accuracy with 0.883 Kappa value using the lung X-ray first dataset.
C1 [Li, Jinyan] Huawei Technol CO LTD, Dept Consumer BG, Data & Analysing Platform, Shenzhen, Peoples R China.
   [Fong, Simon] Univ Macau, Dept Comp & Informat Sci, Data Analyt & Collaborat Comp Lab, Taipa, Macau, Peoples R China.
   [Liu, Lian-sheng] Guangzhou Univ Tradit Chinese Med, Affiliated Hosp 1, Med Imaging Dept, Guangzhou 510405, Guangdong, Peoples R China.
   [Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Kolkata, India.
   [Ashour, Amira S.] Tanta Univ, Fac Engn, Depatrment Elect & Elect Commun Engn, Tanta, Egypt.
   [Moraru, Luminita] Dunarea de Jos Univ Galati, Fac Sci & Environm, 47 Domneasca St, Galati 800008, Romania.
C3 Huawei Technologies; University of Macau; Guangzhou University of
   Chinese Medicine; Egyptian Knowledge Bank (EKB); Tanta University;
   Dunarea De Jos University Galati
RP Ashour, AS (corresponding author), Tanta Univ, Fac Engn, Depatrment Elect & Elect Commun Engn, Tanta, Egypt.
EM yb47432@connect.umac.mo; ccfong@umac.mo; llsjnu@sina.com;
   neelanjan.dey@gmail.com; amirasashour@yahoo.com; Luminita.Moraru@ugal.ro
RI Ashour, Amira S./T-5454-2019; Moraru, Luminita/A-8532-2012; Li,
   Jinyan/K-4293-2012; Fong, Simon/C-9388-2009
OI Ashour, Amira S./0000-0003-3217-6185; Moraru,
   Luminita/0000-0002-9121-5714; Fong, Simon/0000-0002-1848-7246; Li,
   Jinyan/0000-0003-1833-7413
FU University of Macau [MYRG2015-00128-FST, MYRG2016-00217-FST,
   FDCT/126/2014/A3]; Macau FDCT
FX The authors are thankful for the financial support from the Research
   Grants, "Temporal Data Stream Mining by Using Incrementally Optimized
   Very Fast Decision Forest (iOVFDF), Grant no. MYRG2015-00128-FST",
   "Improving the Protein-Ligand Scoring Function for Molecular Docking by
   Fuzzy Rule-based Machine Learning Approaches, Grant no.
   MYRG2016-00217-FST", and "A Scalable Data Stream Mining Methodology:
   Stream-based Holistic Analytics and Reasoning in Parallel, Grant no.
   FDCT/126/2014/A3", offered by the University of Macau and Macau FDCT
   respectively. We thank also Ms. Dantong Wang, our former MSc student,
   for her technical contribution to this paper as well as a geat
   appreciation is directed to Dr. Li Tengyue (Department of Computer and
   Information Science, University of Macau, Taipa, Macau SAR) for her
   helps.
CR Ahmed SS, 2017, MED BIOL ENG COMPUT, V55, P101, DOI 10.1007/s11517-016-1508-7
   Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   [Anonymous], 2015, COMP BUS INT ISCBI 2
   [Anonymous], APPLIED COMPUTATIONA
   [Anonymous], 2017, J MED IMAGING HLTH I
   [Anonymous], BIOM IM NAN 2004 IEE
   [Anonymous], ICDM 04 4 IEEE INT C
   [Anonymous], ADV APPL METAHEURIST
   [Anonymous], CONTR INSTR COMM COM
   [Anonymous], INT C MACH INT RES A
   [Anonymous], 2010, NEUR NETW IJCNN 2010
   [Anonymous], MULTILEVEL CLASSIFIC
   [Anonymous], 20 INT C INT C MACH
   [Anonymous], 2016, ADV DATA MINING APPL
   [Anonymous], 2012, IEEE T SYST MAN CY C, DOI DOI 10.1109/TSMCC.2011.2161285
   [Anonymous], SCI WORLD J
   [Anonymous], 4 INT C BUS INT FIN
   [Anonymous], ADV DAT MIN APPL 12
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], DAT MIN 2001 ICDM 20
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Ashour AmiraS., 2015, Journal of Signal and Information Processing, V6, P244, DOI DOI 10.4236/JSIP.2015.63023
   Beagum S, 2017, MICROSC RES TECHNIQ, V80, P419, DOI 10.1002/jemt.22811
   Chatterjee S, 2016, NEURAL COMPUT APPL, P1
   Chatterjee S, 2017, NEURAL COMPUT APPL, V28, P2005, DOI 10.1007/s00521-016-2190-2
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Drummond Chris, 2003, WORKSH LEARN IMB DAT, V11, P1
   Fong S, 2014, IT PROF, V16, P24, DOI 10.1109/MITP.2014.50
   Fonseca CM, 1998, IEEE T SYST MAN CY A, V28, P26, DOI 10.1109/3468.650319
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2013, IEEE SYS MAN CYBERN, P2103, DOI 10.1109/SMC.2013.360
   Hsu WH, 2004, INFORM SCIENCES, V163, P103, DOI 10.1016/j.ins.2003.03.019
   Ichikawa T, 2007, AM J ROENTGENOL, V188, P409, DOI 10.2214/AJR.05.1918
   Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Kira K., 1992, AAAI, V2
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Krawczyk B, 2012, ELEVENTH SYMPOSIUM ON NEURAL NETWORK APPLICATIONS IN ELECTRICAL ENGINEERING (NEUREL 2012)
   Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027
   Li J, 2016, INT J CLIN EXP PATHO, V9, P37, DOI 10.14257/ijdta.2016.9.9.04
   Li JQ, 2016, J NEUROL NEUROSUR PS, V87, P476, DOI [10.1007/s12650-016-0404-4, 10.1136/jnnp-2014-310095]
   Li JY, 2016, J MED IMAG HEALTH IN, V6, P1102, DOI 10.1166/jmihi.2016.1807
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li XC, 2008, ENG APPL ARTIF INTEL, V21, P785, DOI 10.1016/j.engappai.2007.07.001
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Saba L, 2016, COMPUT METH PROG BIO, V130, P118, DOI 10.1016/j.cmpb.2016.03.016
   Samanta S, 2017, QUANTUM INSPIRED COMPUTATIONAL INTELLIGENCE: RESEARCH AND APPLICATIONS, P285, DOI 10.1016/B978-0-12-804409-4.00009-7
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu ZL, 2010, IEEE T NEURAL NETWOR, V21, P1033, DOI 10.1109/TNN.2010.2047114
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhou XB, 2004, J BIOL SYST, V12, P371, DOI 10.1142/S0218339004001178
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 67
TC 12
Z9 12
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20913
EP 20933
DI 10.1007/s11042-019-7354-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400017
DA 2024-07-18
ER

PT J
AU Mortezaie, Z
   Hassanpour, H
   Amiri, SA
AF Mortezaie, Z.
   Hassanpour, H.
   Amiri, S. Asadi
TI An adaptive block based un-sharp masking for image quality enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Un-sharp masking; Image enhancement; Gradient information of the block;
   Blur image
ID SEGMENTATION
AB An image may suffer from some degradation such as blurriness. This degradation affects the image contrast. There are various approaches to improve the contrast of the images. Among these approaches, un-sharp masking is a popular method due to its simplicity in implementation and computation. In the un-sharp masking method, the details of the input image are boosted to improve the image quality. In this method, the quality of the enhanced image directly depends on the parameter named gain factor. Since the quality of an image may not be the same throughout the image, in this paper we propose an adaptive un-sharp masking method to locally improve the quality of the images. In this method, at first, the input image is divided into a number of overlapping blocks. Then the appropriate gain factor is estimated for the pixels of each block using the gradient information of the block. Subjective and objective image quality assessments are used to compare the performance of the proposed method with both the classic and the recently developed un-sharp masking methods. The experimental results show that the proposed method has a better performance in comparison to the other existing methods.
C1 [Mortezaie, Z.; Hassanpour, H.] Shahrood Univ Technol, Dept Comp Engn, Shahrood, Iran.
   [Amiri, S. Asadi] Univ Mazandaran, Dept Engn & Technol, Babol Sar, Iran.
C3 Shahrood University of Technology; University of Mazandaran
RP Amiri, SA (corresponding author), Univ Mazandaran, Dept Engn & Technol, Babol Sar, Iran.
EM s.asadi@umz.ac.ir
RI Amiri, Sekineh Asadi/AAI-7676-2021; Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822
CR Amiri SA., 2012, International Journal of Computer Applications, V12, P38
   Amiri SA, 2018, MULTIMED TOOLS APPL, V77, P787, DOI 10.1007/s11042-016-4246-9
   [Anonymous], 2011, 8 INT MULTICONFERENC, DOI DOI 10.1109/SSD.2011.57673787
   Chitwong S, 2006, ASPRS 2006 ANN C REN
   Gupte R, 2012, PROCD SOC BEHV, V37, P1, DOI 10.1016/j.sbspro.2012.03.268
   Hajian A, 2018, PROCEDIA COMPUT SCI, V126, P431, DOI 10.1016/j.procs.2018.07.277
   Hu YB, 2013, APPL MECH MATER, V278-280, P1232, DOI 10.4028/www.scientific.net/AMM.278-280.1232
   Hudson R.D., 1969, INFRARED SYSTEM ENG
   Jane O, 2010, PROCEEDINGS OF THE 15TH CONFERENCE ON MICROWAVE TECHNIQUES, COMITE 2010, P9, DOI 10.1109/COMITE.2010.5481711
   Javaran TA, 2017, VISUAL COMPUT, V33, P151, DOI 10.1007/s00371-015-1166-z
   Joseph A, 2015, INT J SCI REIJSR, V4, P2576
   Kwok N, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P217, DOI 10.1109/CISP.2014.7003780
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Li CF, 2010, SIGNAL PROCESS-IMAGE, V25, P517, DOI 10.1016/j.image.2010.03.004
   Lin SCF, 2016, OPTIK, V127, P407, DOI 10.1016/j.ijleo.2015.08.046
   Liu Ying, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1053, DOI 10.1109/CSSE.2008.1631
   Mai C. L. D. A., 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P646, DOI 10.1109/CISP.2011.6100322
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   Mortezaie Z, 2017, INT J ENG-IRAN, V30, P1118, DOI 10.5829/ije.2017.30.08b.02
   Mortezaie Z, 2017, WORLD ACAD SCI ENG T, V11, P981
   Ortiz A, 2013, NEUROCOMPUTING, V114, P118, DOI 10.1016/j.neucom.2012.08.047
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Sharma S., 2013, Advance in Electronic and Electric Engineering, V3, P1063
   Tustison NJ, 2015, NEUROINFORMATICS, V13, P209, DOI 10.1007/s12021-014-9245-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie LC, 2015, INT CONF INSTR MEAS, P378, DOI 10.1109/IMCCC.2015.87
   Zhang ML, 2017, SMART INNOV SYST TEC, V64, P19, DOI 10.1007/978-3-319-50212-0_3
   [No title captured]
NR 30
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23521
EP 23534
DI 10.1007/s11042-019-7594-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400058
DA 2024-07-18
ER

PT J
AU Pourhashemi, SM
   Mosleh, M
   Erfani, Y
AF Pourhashemi, Seyed Mostafa
   Mosleh, Mohammad
   Erfani, Yousof
TI Audio watermarking based on synergy between Lucas regular sequence and
   Fast Fourier Transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Lucas math series; Fast Fourier Transform; High
   capacity; Imperceptibility; Robustness
ID ROBUST; DCT; OPTIMIZATION; DECOMPOSITION; PERFORMANCE
AB The growth of digital technology over the recent years has led to increased sending and saving of electronic media. Taking advantage of digital works without observing copyright is always considered as an important threat for publishers. One of the techniques proposed for overcoming this threat is watermarking. Audio watermarking is one of the most challenging fields of watermarking, because detection of watermark in audio is much easier than in image. In this paper, a new approach is proposed for audio watermarking based on the values of energy levels in FFT domain. Despite preservation of imperceptibility and robustness, this method has also a very high capacity. The main idea of the proposed method is employing a regular embedding procedure on the basis of closing the energy of the sub-frames to Lucas math sequence, which is capable of embedding two bits in each audio frame. In addition, appropriate parameters values of the proposed approach such as frame-size and frequency-band are calculated by an intelligent recursive tuning process. Extraction process is done in a blind manner and without any need to the host original signal. In order to evaluate the proposed method, five types of audio files including Electronic, Classic, Jazz, Blues, and Rock audio files have been used in wave format. The results show that despite having a high watermarking capacity, the proposed method has a high imperceptibility and an acceptable robustness against the common attacks such as Noise Addition, 64 kbps MPEG Compression (MP3), FFT-Invert, Re-sampling etc., compared with the previous methods.
C1 [Pourhashemi, Seyed Mostafa; Mosleh, Mohammad; Erfani, Yousof] Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
   [Erfani, Yousof] McMaster Univ, AEL Grp, Dept Elect & Comp Engn, Hamilton, ON, Canada.
C3 Islamic Azad University; McMaster University
RP Mosleh, M (corresponding author), Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
EM s.mostafa.pourhashemi@hotmail.com; Mosleh@iaud.ac.ir;
   erfaniy@mcmaster.ca
OI Mosleh, Mohammad/0000-0002-0991-1623
CR Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bruce IC, 2018, HEARING RES, V360, P40, DOI 10.1016/j.heares.2017.12.016
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Chen N, 2013, DIGIT SIGNAL PROCESS, V23, P1216, DOI 10.1016/j.dsp.2013.01.012
   Chen ST, 2015, IET SIGNAL PROCESS, V9, P166, DOI 10.1049/iet-spr.2013.0399
   Chen ST, 2013, DIGIT SIGNAL PROCESS, V23, P971, DOI 10.1016/j.dsp.2012.12.013
   Dhar PK, 2014, INT J SPEECH TECHNOL, V17, P133, DOI 10.1007/s10772-013-9214-4
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Erfani Y, 2017, IEEE T INF FOREN SEC, V12, P840, DOI 10.1109/TIFS.2016.2636094
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Fu ZY, 2015, MULTIMED TOOLS APPL, V74, P6019, DOI 10.1007/s11042-014-1905-6
   Hu HT, 2017, CIRC SYST SIGNAL PR, V36, P1890, DOI 10.1007/s00034-016-0383-7
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu HT, 2014, SIGNAL PROCESS, V105, P316, DOI 10.1016/j.sigpro.2014.05.003
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Hua G, 2015, IEEE T INF FOREN SEC, V10, P1850, DOI 10.1109/TIFS.2015.2431997
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Huo Yongjin, 2013, Wuhan University Journal of Natural Sciences, V18, P455, DOI 10.1007/s11859-013-0956-2
   Hussain I, 2013, MATH COMPUT MODEL, V57, P963, DOI 10.1016/j.mcm.2012.10.007
   Jeyhoon M, 2017, MULTIMED TOOLS APPL, V76, P3343, DOI 10.1007/s11042-016-3934-9
   Khalil M, 2015, MULTIMED TOOLS APPL, V74, P5973, DOI 10.1007/s11042-014-1902-9
   Khalil M, 2014, DIGIT SIGNAL PROCESS, V34, P116, DOI 10.1016/j.dsp.2014.07.009
   Kiah M. M., 2011, International Journal of Physicial Sciences, V6, P3837
   Latifpour H, 2015, INT J SPEECH TECHNOL, V18, P697, DOI 10.1007/s10772-015-9318-0
   Lei BY, 2015, SIGNAL PROCESS, V113, P80, DOI 10.1016/j.sigpro.2014.11.007
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Lerch A., 2002, ZPLANE DEV EAQUAL EV
   Li RK, 2016, IET SIGNAL PROCESS, V10, P266, DOI 10.1049/iet-spr.2014.0388
   Lu C.-S., 2004, Multimedia Security: Steganography and Digital Watermarking Techniques for Protection of Intellectual Property: Steganography and Digital Watermarking Techniques for Protection of Intellectual Property
   Mohsenfar SM, 2015, MULTIMED TOOLS APPL, V74, P759, DOI 10.1007/s11042-013-1694-3
   Mosleh M, 2016, FRONT INFORM TECH EL, V17, P1320, DOI 10.1631/FITEE.1500297
   Peng H, 2013, DIGIT SIGNAL PROCESS, V23, P382, DOI 10.1016/j.dsp.2012.08.006
   Rao KR, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4020-6629-0
   Shine KP, 2015, CSI T ICT, V3, P111, DOI [10.1007/s40012-016-0076-1, DOI 10.1007/S40012-016-0076-1]
   Shokri S, 2013, PROC TECH, V11, P107, DOI 10.1016/j.protcy.2013.12.168
   Weisstein EW, LUCAS NUMBER MATHWOR
   Weisstein EW, GOLDEN RATIO MATHWOR
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   Xu ZG, 2016, IEEE SIGNAL PROC LET, V23, P20, DOI 10.1109/LSP.2015.2497460
   Yuan XC, 2015, INFORM SCIENCES, V298, P159, DOI 10.1016/j.ins.2014.11.040
NR 43
TC 9
Z9 9
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22883
EP 22908
DI 10.1007/s11042-019-7595-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400032
DA 2024-07-18
ER

PT J
AU Rakheja, P
   Vig, R
   Singh, P
AF Rakheja, Pankaj
   Vig, Rekha
   Singh, Phool
TI An asymmetric hybrid cryptosystem using hyperchaotic system and random
   decomposition in hybrid multi resolution wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Four dimensional hyperchaotic system; Hybrid multi-resolution wavelet;
   Random decomposition
ID OPTICAL-IMAGE ENCRYPTION; FRACTIONAL FOURIER-TRANSFORM; EQUAL MODULUS
   DECOMPOSITION; RANDOM-PHASE ENCRYPTION; COHERENT SUPERPOSITION; SECURITY
   ENHANCEMENT; PLAINTEXT ATTACK; INFORMATION; PLANE; COMPRESSION
AB In this paper, an asymmetric hybrid cryptosystem utilizing four-dimensional (4D) hyperchaotic framework by means of coherent superposition and random decomposition in hybrid multi-resolution wavelet domain is put forward. The 4D hyperchaotic framework is utilized for creating permutation keystream for a pixel swapping procedure. The hybrid multi-resolution wavelet is formed by combining Walsh transform and fractional Fourier transform of various orders. The 4D hyperchaotic framework's parameters and preliminary conditions alongside the fractional orders extend the key-space and consequently give additional strength to the proposed cryptosystem. The proposed cryptosystem has an extended key-space to avoid any brute-force attack and is nonlinear in nature. The scheme is validated on greyscale images. Computer-based simulations have been executed to validate the robustness of the proposed scheme against different types of attacks. Results demonstrate that the proposed cryptosystem along with offering higher protection against noise and occlusion attacks is also unassailable to special attack.
C1 [Rakheja, Pankaj; Vig, Rekha] NorthCap Univ, Dept EECE, Gurugram 122017, India.
   [Singh, Phool] Cent Univ Haryana, Dept Math, Mahendergarh 609602, India.
C3 The Northcap University; Central University of Haryana
RP Rakheja, P (corresponding author), NorthCap Univ, Dept EECE, Gurugram 122017, India.
EM pankajrakheja@ncuindia.edu
RI Rakheja, Pankaj/AAI-8096-2021; Vig, Rekha/KIB-5038-2024; Rakheja,
   Pankaj/AGE-1879-2022; Singh, Phool/AFV-9080-2022; Vig,
   Rekha/AAQ-7296-2021
OI Rakheja, Pankaj/0000-0001-5312-2181; Vig, Rekha/0000-0002-0789-8840;
   Rakheja, Pankaj/0000-0001-5312-2181; 
CR Abuturab MR, 2015, J OPT SOC AM A, V32, P1811, DOI 10.1364/JOSAA.32.001811
   Barfungpa SP, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0786-5
   Biryukov A., 2011, ENCY CRYPTOGRAPHY SE
   Biryukov A., 2011, Encyclopedia of Cryptography and Security, P704, DOI [10.1007/978-1-4419-5906-5_588, DOI 10.1007/978-1-4419-5906-5_588]
   Cai JJ, 2017, OPT LASER TECHNOL, V95, P105, DOI 10.1016/j.optlastec.2017.04.018
   Cai JJ, 2015, OPT LETT, V40, P475, DOI 10.1364/OL.40.000475
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen AM, 2006, PHYSICA A, V364, P103, DOI 10.1016/j.physa.2005.09.039
   Chen H, 2017, OPT LASER ENG, V93, P1, DOI 10.1016/j.optlaseng.2017.01.005
   Chen JX, 2014, J OPTICS-UK, V16, DOI 10.1088/2040-8978/16/12/125403
   Chen LF, 2006, OPT LETT, V31, P3438, DOI 10.1364/OL.31.003438
   Chen W, 2010, OPT LETT, V35, P3817, DOI 10.1364/OL.35.003817
   Cheng XC, 2008, OPT LETT, V33, P1575, DOI 10.1364/OL.33.001575
   Cho M, 2013, OPT LETT, V38, P3198, DOI 10.1364/OL.38.003198
   Deng XP, 2015, OPT LETT, V40, P3913, DOI 10.1364/OL.40.003913
   Deng XP, 2012, OPT LASER TECHNOL, V44, P374, DOI 10.1016/j.optlastec.2011.07.019
   Elshamy AM, 2013, J LIGHTWAVE TECHNOL, V31, P2533, DOI 10.1109/JLT.2013.2267891
   Fatima A, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/8/085701
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   Fu C, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2708532
   Ge M, 2019, EGYPT INFORM J, V20, P45, DOI 10.1016/j.eij.2018.10.001
   Gopinathan U, 2006, OPT EXPRESS, V14, P3181, DOI 10.1364/OE.14.003181
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Huang JJ, 2012, APPL OPTICS, V51, P2388, DOI 10.1364/AO.51.002388
   Javidi B, 2000, OPT LETT, V25, P28, DOI 10.1364/OL.25.000028
   Kekre HB, 2015, INT J ELECTRON, V102, P2108, DOI 10.1080/00207217.2015.1020882
   Kumar R, 2017, ANN ONCOL, V28
   Kumar R, 2017, OPT LASER TECHNOL, V95, P51, DOI 10.1016/j.optlastec.2017.03.041
   Li T, 2015, OPT EXPRESS, V23, P21384, DOI 10.1364/OE.23.021384
   Liu ST, 2001, OPT LETT, V26, P1242, DOI 10.1364/OL.26.001242
   Liu W, 2013, OPT LETT, V38, P1651, DOI 10.1364/OL.38.001651
   Liu ZJ, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3557790
   Maluenda D, 2015, OPT EXPRESS, V23, P655, DOI 10.1364/OE.23.000655
   Mehra I, 2014, OPT EXPRESS, V22, P5474, DOI 10.1364/OE.22.005474
   Nishchal NK, 2004, OPT COMMUN, V235, P253, DOI 10.1016/j.optcom.2004.02.052
   Nomura T, 2000, OPT ENG, V39, P2031, DOI 10.1117/1.1304844
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Qin W, 2011, OPT ENG, V50, DOI 10.1117/1.3607421
   Qin W, 2010, OPT LETT, V35, P118, DOI 10.1364/OL.35.000118
   Rajput SK, 2013, OPT COMMUN, V309, P231, DOI 10.1016/j.optcom.2013.06.036
   Rajput SK, 2013, APPL OPTICS, V52, P871, DOI 10.1364/AO.52.000871
   Rakheja P, 2019, OPTIK, V176, P425, DOI 10.1016/j.ijleo.2018.09.088
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Saini I., 2017, Int. J. Soc. Comput. Cyber Phys. Syst., V2, P59
   Sharma N, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0149-4
   Singh H, 2018, J MOD OPTIC, V65, P2065, DOI 10.1080/09500340.2018.1496286
   Singh P, 2017, AIP CONF PROC, V1802, DOI 10.1063/1.4973267
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Sui LS, 2013, OPT LASER TECHNOL, V48, P117, DOI 10.1016/j.optlastec.2012.10.016
   Tajahuerce E, 2000, APPL OPTICS, V39, P2313, DOI 10.1364/AO.39.002313
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang XG, 2014, APPL OPTICS, V53, P208, DOI 10.1364/AO.53.000208
   Wang XG, 2013, OPT LETT, V38, P3684, DOI 10.1364/OL.38.003684
   Wang XG, 2013, APPL OPTICS, V52, P6170, DOI 10.1364/AO.52.006170
   Wang XG, 2012, OPT COMMUN, V285, P1078, DOI 10.1016/j.optcom.2011.12.017
   Wang XG, 2011, APPL OPTICS, V50, P6645, DOI 10.1364/AO.50.006645
   Wang Y, 2016, APPL OPTICS, V55, P679, DOI 10.1364/AO.55.000679
   Wang Y, 2015, APPL OPTICS, V54, P6874, DOI 10.1364/AO.54.006874
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu HF, 2018, J MOD OPTIC, V65, P1245, DOI 10.1080/09500340.2018.1431314
   Zhao SM, 2015, OPT COMMUN, V353, P90, DOI 10.1016/j.optcom.2015.04.063
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 65
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20809
EP 20834
DI 10.1007/s11042-019-7406-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400012
DA 2024-07-18
ER

PT J
AU Usman, MA
   Seong, CH
   Lee, MH
   Shin, SY
AF Usman, Muhammad Arslan
   Seong, Chi-Hyeok
   Lee, Man Hee
   Shin, Soo Young
TI A novel error detection & concealment technique for videos streamed over
   error prone channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyclic redundancy check; Error concealment; Median filter; Noise
   mitigation; Video quality
ID MEDIAN FILTERS; REMOVAL
AB In video streaming services and applications, impulse noise occurs due to transmission errors or sometimes it is introduced during signal acquisition. The work presented in this paper proposes a novel impulse noise detection and mitigation (INDAM) method that can significantly recover video frames heavily impaired by impulse noise. The proposed technique uses cyclic redundancy check (CRC) method to create an error mask of the received impaired video frames. This error mask contains pixel-by-pixel error information of the video frames and is exploited further to mitigate the error from the impaired video frame. Each impaired pixel in the video frame is replaced by the average of its corresponding error-free neighboring pixels' values, hence removing the impaired pixels and replacing them with the newly calculated average. The proposed technique uses the error mask created from the CRC method and uses only those pixels which do not contain error for calculating the averages. Results show that INDAM outperforms other contemporary methods in terms of peak signal to noise ratio (PSNR) and structural similarity index metric (SSIM).
C1 [Usman, Muhammad Arslan; Shin, Soo Young] Kumoh Natl Inst Technol, Dept IT Convergence Eng, Gumi 39177, South Korea.
   [Seong, Chi-Hyeok] Union Community Co Ltd, Seoul, South Korea.
   [Lee, Man Hee] EM Tech Co Ltd, Seoul, South Korea.
C3 Kumoh National University Technology
RP Usman, MA (corresponding author), Kumoh Natl Inst Technol, Dept IT Convergence Eng, Gumi 39177, South Korea.
EM arslanusman@ieee.org; sung2935@naver.com; lmh910420@gmail.com;
   wdragon@kumoh.ac.kr
RI Shin, Soo Young/ABG-4608-2021; Lee, Man Hee/HLG-5344-2023; Usman,
   Muhammad/AAF-3895-2019
OI Shin, Soo Young/0000-0002-2526-2395; Lee, Man Hee/0000-0003-1901-0279;
   Usman, Muhammad Arslan/0000-0002-6440-4595
FU MSIT (Ministry of Science, ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2019-2014-1-00639]
FX This research was supported by the MSIT (Ministry of Science, ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2019-2014-1-00639) supervised by the IITP (Institute for
   Information & communications Technology Planning & Evaluation).
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   Boyce JM, US patent, Patent No. [US9204167B2, 9204167]
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   LIN HM, 1988, IEEE T CIRCUITS SYST, V35, P675, DOI 10.1109/31.1805
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Pyun JY, 2008, IEEE T CONSUM ELECTR, V54, P1705, DOI 10.1109/TCE.2008.4711224
   Sobolewski JS, 2003, Cyclic Redundancy check, P476, DOI [10.5555/1074100.1074303, DOI 10.5555/1074100.1074303]
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Takahashi A, 2010, TECH REP
   Usman MA, 2018, IEEE T MULTIMEDIA
   Usman MA, 2017, IETE TECH REV, V34, P309, DOI 10.1080/02564602.2016.1185975
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 21
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22959
EP 22975
DI 10.1007/s11042-019-7639-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400035
DA 2024-07-18
ER

PT J
AU Wang, S
   Yao, R
   Zhang, YK
   Jiang, QN
   Zhang, CB
AF Wang, Shi
   Yao, Rui
   Zhang, Yikun
   Jiang, Qingnan
   Zhang, Changbin
TI Data augmentation of random grid-hiding for video object segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Random grid-hiding; Data augmentation;
   Convolutional neural network
AB Video object segmentation is an important field in computer vision. However, the challenges in video object segmentation such as background clutter, occlusion and edge ambiguity cannot be avoided. In addition, existing labeled video object segmentation datasets are limited in size, which prevents CNN models from reaching their full generalization capabilities. In this paper, we propose a novel approach, called random grid-hiding (RGH), to perform data augmentation. We divide the training image into several rectangular regions and hide some regions randomly during model training. Thus, the convolutional neural network automatically focuses on the discriminative parts of the image. When the most discriminative part of the image is hidden, it compels the network focus on the other related parts of the image. Further, occlusion images are randomly generated in various levels. More features can be obtained by random grid-hiding, which can effectively reduce the risk of overfitting. Our approach is an effective extension of the data augmentation (such as random cropping and random flipping), and leads to improved accuracy in the task of the video object segmentation method on DAVIS dataset. Our experimental results show that the proposed method is a stable and effective method for data augmentation.
C1 [Wang, Shi; Yao, Rui; Zhang, Yikun; Jiang, Qingnan; Zhang, Changbin] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Yao, R (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM wangshi@cumt.edu.cn; ruiyao@cumt.edu.cn; yikunzhang@cumt.edu.cn;
   qingnanjiang@cumt.edu.cn; changbinzhang@cumt.edu.cn
RI Yikun, Zhang/HNI-6209-2023
OI Yao, Rui/0000-0003-2734-915X; Zhang, Yikun/0000-0002-4048-4869
FU National Natural Science Foundation of China [61772530]; Natural Science
   Foundation of Jiangsu Province of China [BK20171192]; Fundamental
   Research Funds for the Central Universities [2017XKQY075]
FX This work was supported by the National Natural Science Foundation of
   China (61772530), Natural Science Foundation of Jiangsu Province of
   China (BK20171192), and the Fundamental Research Funds for the Central
   Universities (No. 2017XKQY075).
CR [Anonymous], BRIT MACH VIS C
   [Anonymous], 2017, ARXIV
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, COMPUTER VISION PATT
   [Anonymous], 2017, ARXIV E PRINTS
   [Anonymous], 2016 BRIT MACH VIS C
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], LEARNING VIDEO OBJEC
   [Anonymous], 2014, PROC BRIT MACH VIS C, DOI DOI 10.5244/C.28.21
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], INT C COMP VIS
   [Anonymous], 2015, Deep image: Scaling up image recognition
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2016, CVPR
   [Anonymous], COUNTEREXAMPLE GUIDE
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Caelles S., 2017, ARXIV170401926
   Chen L. C., 2015, Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs, P357, DOI [10.1080/17476938708814211, DOI 10.1080/17476938708814211]
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeVries T., 2017, P 2017 COMPUTER VISI
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He K, 2017, IEEE INT WORKSH MULT
   Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43
   Krizhevsky Alex., 2012, u International Conference on Neural Information Processing Systems - Volume, V1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43
   Smirnov EA, 2014, AASRI PROC, V6, P89, DOI 10.1016/j.aasri.2014.05.013
   Takahashi R, 2020, IEEE T CIRC SYST VID, V30, P2917, DOI 10.1109/TCSVT.2019.2935128
   Tran T., 2017, Advances in Neural Information Processing Systems, P2794
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou Bolei., 2015, Learning Deep Features for Discriminative Localization, P2921, DOI DOI 10.1109/CVPR.2016.319
NR 44
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23029
EP 23048
DI 10.1007/s11042-019-7569-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400038
DA 2024-07-18
ER

PT J
AU Athanesious, JJ
   Chakkaravarthy, SS
   Vasuhi, S
   Vaidehi, V
AF Athanesious, J. Joshan
   Chakkaravarthy, S. Sibi
   Vasuhi, S.
   Vaidehi, V.
TI Trajectory based abnormal event detection in video traffic surveillance
   using general potential data field with spectral clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE General potential data field; Impact factor matrix; Spatial trajectory
   data; Dynamic time warping; Spectral clustering; Abnormal detection
ID ANOMALY DETECTION
AB Detection of abnormal trajectories in a traffic scene is an important problem in Video Traffic Surveillance (VTS). Recently, General Potential Data Field (GPDf)-based trajectory clustering scheme has been adopted for detecting abnormal events such as illegal U-turn, wrong side and unusual driving behaviors and it uses spatial and temporal attributes explicitly. The concept of data field is used to discover the relation between the spatial points in data-space and grouping them into clusters based on their mutual interaction. Existing methodologies related to potential data field-based clustering have certain limitations such as pre-defined cluster size, non-effective cluster center identification, and limitation in range estimation using isotropic impact factor (h) which leads to inaccurate results. In order to address the above-mentioned issues, this paper proposes an efficient anomaly detection scheme based on General Potential Data field with Spectral Clustering (GPDfSC). The proposed GPDfSC scheme utilizes potential data field technique along with spectral clustering for effective identification of abnormalities. The Limitation in impact factor(h) is overcome by using anisotropic impact parameter Bmat. Further, Bayesian Decision theory is used to classify the events as normal or abnormal. The proposed scheme is implemented in real time using GPU and from the results it is found that it gives 12% better accuracy in detecting abnormalities than the state of art technique.
C1 [Athanesious, J. Joshan; Chakkaravarthy, S. Sibi; Vasuhi, S.] Madras Inst Technol, Dept Elect Engn, Chennai, Tamil Nadu, India.
   [Vaidehi, V.] VIT Univ, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Madras Institute of Technology; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Athanesious, JJ (corresponding author), Madras Inst Technol, Dept Elect Engn, Chennai, Tamil Nadu, India.
EM joathenz@mitindia.edu; sb.sibi@gmail.com; vasuhi_s@annauniv.edu;
   vaidehi.vijayakumar@vit.ac.in
RI j, j/GQP-4038-2022; Chakkaravarthy, Sibi S/D-3735-2019; S, Sibi
   Chakkaravarthy/W-7245-2019; J, JoshaN/AAQ-6583-2021; Vasuhi,
   S/AFT-5371-2022; V, Vaidehi/AAD-4040-2022
OI S, Sibi Chakkaravarthy/0000-0001-7778-0453; ,
   joshan/0000-0002-6661-3200; Srinivasan, Vasuhi/0000-0001-6368-8293
FU Anna university
FX The first author extends his sincere gratitude to Anna university for
   supporting this research through Anna Centenary Research Fellowship
   (ACRF) and also grateful to Dr. R. Balasubramanian and Dr. Partha Pratim
   Roy from IIT-Roorkee for their valuable inputs and suggestions.
CR Batapati P, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P5500, DOI 10.1109/WCICA.2014.7053655
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Blatt F. J., 1986, PRINCIPLES PHYS
   Cai YF, 2015, IET INTELL TRANSP SY, V9, P810, DOI 10.1049/iet-its.2014.0238
   Cyert R.M., 1987, BAYESIAN ANAL UNCERT, DOI DOI 10.1007/978-94-009-3163-3_2
   Djalalov M., 2010, INT ADV SYST ICIAS 2, P1, DOI DOI 10.1109/ICIAS.2010.5716189
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Fang M, 2010, LECT NOTES ARTIF INT, V6440, P262, DOI 10.1007/978-3-642-17316-5_25
   Fu ZY, 2005, IEEE IMAGE PROC, P2029
   Horová I, 2013, COMPUT STAT DATA AN, V57, P364, DOI 10.1016/j.csda.2012.07.006
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Jiang F, 2009, IEEE T IMAGE PROCESS, V18, P907, DOI 10.1109/TIP.2008.2012070
   Jung CR, 2008, IEEE T CIRC SYST VID, V18, P1565, DOI 10.1109/TCSVT.2008.2005600
   Kumar PMA, 2015, KSII T INTERNET INF, V9, P169, DOI 10.3837/tiis.2015.01.010
   Kumar PMA, 2017, SADHANA-ACAD P ENG S, V42, P1431, DOI 10.1007/s12046-017-0705-x
   Kumar PA, 2015, INT J COMPUT SCI ELE, V3, P301
   Laxhammar R, 2014, IEEE T PATTERN ANAL, V36, P1158, DOI 10.1109/TPAMI.2013.172
   Li D., 2007, ARTIF INTELL, P193, DOI [10.1201/9781584889991, DOI 10.1201/9781584889991]
   Liu YH, 2014, J SUPERCOMPUT, V67, P723, DOI 10.1007/s11227-013-0984-x
   Mao-Hsiung Hung, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P297, DOI 10.1109/PCSPA.2010.79
   Meng H-D, 2013, T TECH PUBLIC, V760-762, P1925
   Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Ranjith R., 2015, IEEE, P1, DOI DOI 10.1109/ICOAC.2015.7562795
   Sheather SJ, 2004, STAT SCI, V19, P588, DOI 10.1214/088342304000000297
   Wan YW, 2014, IET INTELL TRANSP SY, V8, P526, DOI 10.1049/iet-its.2012.0119
   Wand M.P., 1994, KERNEL SMOOTHING
   Wang SL, 2018, COMPUTING, V100, P403, DOI 10.1007/s00607-018-0605-x
   Wang SL, 2016, GEO-SPAT INF SCI, V19, P106, DOI 10.1080/10095020.2016.1179896
   Wang SL, 2011, INT J DATA WAREHOUS, V7, P43, DOI 10.4018/jdwm.2011100103
   Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6
   Yan-hua Liu, 2011, 2011 Proceedings of IEEE International Conference on Computer Science and Automation Engineering (CSAE), P64, DOI 10.1109/CSAE.2011.5952424
   Zhang TZ, 2013, IEEE T IND INFORM, V9, P149, DOI 10.1109/TII.2012.2218251
   Zhao PX, 2017, INT J GEOGR INF SCI, V31, P1101, DOI 10.1080/13658816.2016.1213845
   Zhou Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1087
NR 38
TC 14
Z9 14
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19877
EP 19903
DI 10.1007/s11042-019-7332-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800043
DA 2024-07-18
ER

PT J
AU Li, YQ
   Wu, B
   Zhao, Y
   Yao, HX
   Ji, Q
AF Li, Yongqiang
   Wu, Baoyuan
   Zhao, Yongping
   Yao, Hongxun
   Ji, Qiang
TI Handling missing labels and class imbalance challenges simultaneously
   for facial action unit recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face action unit recognition; Multi-label learning; Missing labels;
   Class imbalance
ID EXPRESSION
AB Facial action unit (AU) recognition has attracted great attention because of the applications in a wide range of fields. Missing labels and class imbalance (CIB) are both challenges for facial action unit recognition. Missing labels means that there are only apart label assignments for training samples. CIB is observed from two perspectives: firstly, the number of positive AUs is much smaller than that of negative AUs for each expressional image; secondly, the rate of positive samples of different AUs are significantly different. Both missing labels and CIB lead to performance degradation in AU recognition. In this work, we propose to handle these two challenges in AU recognition simultaneously. Specifically, we formulate AU recognition with missing labels as a multi label learning with missing labels (MLML) problem, which handles the missing label challenge naturally. However, different from most existing MLML approaches which usually employ same features from whole image for all classes, we select the most related features for each AU. To handle the CIB challenge, we further introduce class cardinality bounds which constrain the number of positive AUs for each data instance, as well as the number of positive labels for each AU in the overall dataset. The class cardinality bounds serve as linear constraints for the objective function, which turns the optimization NP-hard. Thus we present convex approximation based on the Lovasz extension, which leads to a linear program that can be efficiently solved by the alternative direction method of multipliers (ADMM). Experimental results on both posed and spontaneous facial expression datasets demonstrate the superiority of the proposed method compared to state-of-the-art.
C1 [Li, Yongqiang] Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
   [Zhao, Yongping] Harbin Inst Technol, Dept Instrument Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Yao, Hongxun] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Wu, Baoyuan] Tencent AI Lab, Bellevue, WA 98004 USA.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Tro, NY 12180 USA.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Harbin
   Institute of Technology
RP Wu, B (corresponding author), Tencent AI Lab, Bellevue, WA 98004 USA.
EM liyongqiang@hit.edu.cn; wubaoyuan1987@gmail.com; zhaoyp2590@hit.edu.cn;
   H.Yao@hit.edu.cn; jiq@rpi.edu
FU National Natural Science Foundation of China [61402129, 61472103];
   Postdoctoral Foundation Projects [LBH-Z14090, 2015M571417, 2017T100243];
   Tencent AI Lab Foundation;  [61133003]
FX Yongqiang Li is supported by National Natural Science Foundation of
   China (No. 61402129), and Postdoctoral Foundation Projects (No.
   LBH-Z14090, No. 2015M571417 and No. 2017T100243). Baoyuan Wu is
   supported by Tencent AI Lab Foundation. Hongxun Yao is partially
   supported by National Natural Science Foundation of China (No. 61472103)
   and Key Program (No. 61133003).
CR [Anonymous], 2005, COMPUT SCI
   [Anonymous], AAM TOOLS
   [Anonymous], 2011, Advances in Neural Information Processing Systems
   [Anonymous], 2016, ADV NEURAL INF PROCE
   Bach F, 2013, FOUND TRENDS MACH LE, V6, P145, DOI 10.1561/2200000039
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Boyd S., 2013, CONVEX OPTIMIZATION
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Breazeal C., 2000, Sociable Machines: Expressive Social Exchange between Humans and Robots
   Bucak S. S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2801, DOI 10.1109/CVPR.2011.5995734
   Chen G., 2008, P SIAM INT C DAT MIN, P410, DOI DOI 10.1137/1.9781611972788.37
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ekman P., 2002, FACIAL ACTION CODING
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Goldberg A. B., 2010, Advances in Neural Information Processing Systems, P757
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Hullermeier E., 2013, INT C MACH LEARN PML, P1130
   Li YQ, 2016, PATTERN RECOGN, V60, P890, DOI 10.1016/j.patcog.2016.07.009
   Li YQ, 2013, IEEE T AFFECT COMPUT, V4, P127, DOI 10.1109/T-AFFC.2013.5
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Li ZK, 2011, 4TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING ( ICACTE 2011), P317
   Liao WH, 2009, PATTERN RECOGN, V42, P3046, DOI 10.1016/j.patcog.2009.04.006
   Liu Z, 2013, PROCEEDINGS OF THE 2013 IEEE INTERNATIONAL CONFERENCE ON EVOLVABLE SYSTEMS (ICES), P9, DOI 10.1109/ICES.2013.6613276
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mahoor Mohammad H., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P74, DOI 10.1109/CVPR.2009.5204259
   Manor LZ., 2005, Proceedings of the Advances in Neural Information Processing Systems, V27, P1601
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Petterson James, 2010, ADV NEURAL INFORM PR, V23
   Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192
   Sandbach G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P738, DOI 10.1109/ICCVW.2013.101
   Sorower M.S., 2010, A literature survey on algorithms for multi-label learning, V18, P1
   Sun YY, 2010, AAAI CONF ARTIF INTE, P593
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Tong Yan, 2008, IEEE CVPR, P1
   Valstar MF, 2007, LECT NOTES COMPUT SC, V4796, P118
   Wang QF, 2014, LECT NOTES COMPUT SC, V8691, P378, DOI 10.1007/978-3-319-10578-9_25
   Wu B., 2016, 30 AAAI C ART INT
   Wu BY, 2015, IEEE I CONF COMP VIS, P4157, DOI 10.1109/ICCV.2015.473
   Wu BY, 2014, INT C PATT RECOG, P1964, DOI 10.1109/ICPR.2014.343
   Wu BY, 2015, PATTERN RECOGN, V48, P2279, DOI 10.1016/j.patcog.2015.01.022
   Xu Miao, 2013, ADV NEURAL INFORM PR, P2301, DOI DOI 10.5555/2999792.2999869
   Zehfuss G., 1858, Z MATH PHYS, V3, P298
   Zhang ML, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4041
NR 47
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20309
EP 20332
DI 10.1007/s11042-018-6836-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800062
DA 2024-07-18
ER

PT J
AU Zhang, FY
   Luo, T
   Jiang, GY
   Yu, M
   Xu, HY
   Zhou, WJ
AF Zhang, Fangyan
   Luo, Ting
   Jiang, Gangyi
   Yu, Mei
   Xu, Haiyong
   Zhou, Wujie
TI A novel robust color image watermarking method using RGB correlations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Tucker decomposition; Tensor; Singular value decomposition
ID WAVELET-BASED WATERMARKING; ALGORITHM; SCHEME
AB In order to protect the copyright of the color image, a novel robust color image watermarking method using correlations of RGB channels is presented. RGB three channels of the color image have much strong correlations, which are stable under various image attacks, and thus these correlations can be mined to embed watermark for robustness. In order to keep RGB correlations and chrominance perception, the color image is considered as the third-order tensor, and tucker decomposition is employed to operate on the color image. At first, Tucker decomposition is used to generate the first feature image, which includes the most of image energies and correlations between three channels. Then, the first feature image is divided into non-overlap blocks, and the singular value decomposition (SVD) is used to decompose the block to compute the left-singular matrix. Finally, the stable coefficients relationship of the left-singular matrix is modified to embed watermark for obtaining the robustness. Experimental results show that the proposed method outperforms other existing color image watermarking methods, which can resist JPEG compression, salt & pepper noise, median filtering, scaling, blurring, low-pass filtering, and so on attacks.
C1 [Zhang, Fangyan; Luo, Ting; Xu, Haiyong] Ningbo Univ, Coll Sci & Technol, Ningbo 315000, Zhejiang, Peoples R China.
   [Zhang, Fangyan; Jiang, Gangyi; Yu, Mei; Xu, Haiyong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Zhou, Wujie] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310027, Peoples R China.
C3 Ningbo University; Ningbo University; Zhejiang University of Science &
   Technology
RP Luo, T (corresponding author), Ningbo Univ, Coll Sci & Technol, Ningbo 315000, Zhejiang, Peoples R China.
EM luoting@nbu.edu.cn
RI jiang, gang/KII-8233-2024
OI zhou, wujie/0000-0002-3055-2493
FU Natural Science Foundation of China [61501270, 61671258, 61871247];
   Zhejiang Provincial Natural Science Foundation of China [LY19F020009];
   National High-tech R&D Program of China [2015AA015901]; K. C. Wong Magna
   Fund in Ningbo University
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61501270, 61671258, 61871247, Zhejiang Provincial Natural
   Science Foundation of China under Grant No.LY19F020009, National
   High-tech R&D Program of China under Grant No. 2015AA015901. It was also
   sponsored by the K. C. Wong Magna Fund in Ningbo University.
CR Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Agilandeeswari L, 2018, MULTIMED TOOLS APPL, V77, P25431, DOI 10.1007/s11042-018-5800-4
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Belferdi W, 2018, MULTIDIM SYST SIGN P, P1
   Chou CH, 2003, EURASIP J ADV SIG PR, V1, P1
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Fang H, 2013, J COMPUT, V8, P2844, DOI 10.4304/jcp.8.11.2844-2850
   Feng BW, 2016, SIGNAL PROCESS-IMAGE, V41, P1, DOI 10.1016/j.image.2015.10.007
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Huang SY, 2001, PROCEEDINGS OF THE ASP-DAC 2001: ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE 2001, P313, DOI 10.1109/ASPDAC.2001.913325
   Imran M, 2017, KSII T INTERNET INF, V11, P883, DOI 10.3837/tiis.2017.02.014
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XT, 2017, IEEE T NEUR NET LEAR, V28, P1787, DOI 10.1109/TNNLS.2016.2545400
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Luo T, 2018, MULTIMED TOOLS APPL, V77, P19027, DOI 10.1007/s11042-017-5356-8
   Luo T, 2016, MULTIMEDIA SYST, V22, P641, DOI 10.1007/s00530-015-0475-4
   Luo T, 2014, INT J COMPUT INT SYS, V7, P874, DOI 10.1080/18756891.2014.889843
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Renard N, 2009, IEEE T GEOSCI REMOTE, V47, P1123, DOI 10.1109/TGRS.2008.2008903
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Sun QD, 2016, J SUPERCOMPUT, V72, P2594, DOI 10.1007/s11227-015-1531-8
   Tuncer T, 2016, DISPLAYS, V41, P1, DOI 10.1016/j.displa.2015.10.005
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Yan B, 2016, MULTIMED TOOLS APPL, V75, P13451, DOI 10.1007/s11042-015-2831-y
   Zhang JG, 2016, MULTIMEDIA SYST, V22, P343, DOI 10.1007/s00530-015-0464-7
NR 38
TC 29
Z9 29
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20133
EP 20155
DI 10.1007/s11042-019-7326-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800055
DA 2024-07-18
ER

PT J
AU Esfahani, R
   Akhaee, MA
   Norouzi, Z
AF Esfahani, Reza
   Akhaee, Mohammad Ali
   Norouzi, Zynolabedin
TI A fast video watermarking algorithm using dual tree complex wavelet
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Video piracy; Dual-tree complex wavelet transform;
   Robustness against comcording
ID ROBUST; COLOR; DECOMPOSITION; SCHEME
AB Illegal camcording as the most common source of video piracy, is the main concern of the film production companies. With the increased speed and convenience of access to the Internet and video sharing services, the distribution of pirated video copies is more than easy. Digital video watermarking is one of the possible ways to prevent the illegal recording and distribution of videos. In this paper, a blind digital video watermarking method based on Dual-Tree Complex Wavelet Transform (DTCWT) is proposed. Here, the generated watermark is embedded in the low frequency coefficients of the chrominance channel of the video frames. The watermark is generated in a way that the detection system does not need to know the size of the original video. To reduce the computational complexity of the proposed method, the embedding process is equivalently done in the spatial domain. The proposed method is compared to the state-of-art methods against different attacks. Experimental results show that the proposed method is more robust against various attacks while maintaining the perceptual quality of the original video significantly better than the compared methods. Also the proposed method is evaluated in terms of computational complexity which reveals that the proposed method performs faster than the compared methods.
C1 [Esfahani, Reza; Norouzi, Zynolabedin] Imam Hossein Univ, Informat Technol & Commun Fac, Tehran, Iran.
   [Akhaee, Mohammad Ali] Univ Tehran, Sch Elect Engn, Fac Engn, Tehran, Iran.
   [Akhaee, Mohammad Ali] Univ Tehran, Sch Comp Engn, Fac Engn, Tehran, Iran.
C3 University of Tehran; University of Tehran
RP Esfahani, R (corresponding author), Imam Hossein Univ, Informat Technol & Commun Fac, Tehran, Iran.
EM resfahani@ihu.ac.ir; akhaee@ut.ac.ir; zy_norozi@ihu.ac.ir
CR Amirjan P, 2017, IRAN CONF ELECTR ENG, P1560, DOI 10.1109/IranianCEE.2017.7985292
   [Anonymous], NY TIMES
   [Anonymous], INFORM HIDING
   [Anonymous], 2004, P 2004 WORKSHOP MULT
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Asikuzzaman M, 2012, INT C DIG IM COMP TE, P1
   Asikuzzaman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P277, DOI 10.1109/PCS.2015.7170090
   Bhardwaj A., 2017, MULTIMED TOOLS APPL, P1
   Cedillo-Hernandez A, 2018, J VIS COMMUN IMAGE R, V52, P106, DOI 10.1016/j.jvcir.2018.02.007
   Chan PW, 2005, IEEE T CIRC SYST VID, V15, P1638, DOI 10.1109/TCSVT.2005.856932
   Coria LE, 2008, IEEE T INF FOREN SEC, V3, P466, DOI 10.1109/TIFS.2008.927421
   Das Soumik, 2018, International Journal of Information Technology, V10, P21, DOI 10.1007/s41870-017-0054-3
   Garrod S, 2007, ADV BEHAV BRAIN SCI, P1
   Joshi A, 2017, PROC CVPR IEEE, P455, DOI 10.1109/CVPR.2017.56
   Kingsbury, 1998, P 8 IEEE DSP WORKSH, V86, P120
   Kingsbury N, 1999, INT CONF ACOUST SPEE, P1221, DOI 10.1109/ICASSP.1999.756198
   Kingsbury N., 1998, P 9 EUR SIGN PROC C, P1
   Kingsbury Nick, 2005, HUMAN VISION
   Kwitt R, 2009, 16 INT C DIG SIGN PR, P1
   Lee MJ, 2012, DIGIT SIGNAL PROCESS, V22, P190, DOI 10.1016/j.dsp.2011.08.001
   Li J, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P430, DOI 10.1109/IFITA.2009.236
   Lin ET, 2004, IEEE T SIGNAL PROCES, V52, P3007, DOI 10.1109/TSP.2004.833866
   Liu Y, 2010, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON PRODUCT INNOVATION MANAGEMENT, VOLS I AND II, P675
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mabtoul S, 2007, IEEE I C ELECT CIRC, P534, DOI 10.1109/ICECS.2007.4511046
   Parraga CA, 1998, J OPT SOC AM A, V15, P563, DOI 10.1364/JOSAA.15.000563
   Rana S, 2015, EUR SIGNAL PR CONF, P46, DOI 10.1109/EUSIPCO.2015.7362342
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Sake A, 2018, MATER TODAY-PROC, V5, P1470, DOI 10.1016/j.matpr.2017.11.235
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   Wubiao Chen, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1682, DOI 10.1109/IMCEC.2018.8469393
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 32
TC 13
Z9 13
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16159
EP 16175
DI 10.1007/s11042-018-6892-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500019
DA 2024-07-18
ER

PT J
AU Ibrahim, ZA
   Ferrane, I
   Joly, P
AF Ibrahim, Zein Al Abidin
   Ferrane, Isabelle
   Joly, Philippe
TI Temporal relation algebra for audiovisual content analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audiovisual document analysis; Classification; Structuring;
   Representation; Event detection; Temporal relations algebra
ID REPRESENTATION; NETWORKS
AB The context of this work is to characterize the content and the structure of audiovisual documents by analysing the temporal relationships between basic events resulted from different segmentations of the same document. For this objective, we need to represent and reason about time. We propose a parametric representation of temporal relation between segments (points or intervals) in which the parameters are used to characterize the relationship between two non-convex intervals corresponding to two segmentations in the video analysis domain. The relationship is represented by a co-occurrences matrix noted as Temporal Relation Matrix (TRM). Each document is represented by a set of TRMs computed between each couple of segmentations of the same document using different features. The TRMs are analysed later to detect semantic events, highlight clues about the video content structure or to classify documents based on their types. For higher-level semantic events and documents' structure, we needed to apply some operations on the basic temporal relations and TRMs such as composition, disjunction, complement, intersection, etc. These operations brought to light more complex patterns; e.g. event 1 occurs at the same time of event 2 followed by event 3. In the work presented in this paper, we define a temporal relation algebra including its set of operations based on the parametric representation and TRM defined above. Several experimentations have been done on different audio and video documents to show the efficiency of the proposed representation and the defined operations for audiovisual content analysing.
C1 [Ibrahim, Zein Al Abidin] Lebanese Univ, Fac Sci Hadath, LARIFA Team, Beirut, Lebanon.
   [Ferrane, Isabelle; Joly, Philippe] Univ Paul Sabatier, IRIT, SAMOVA Team, Toulouse, France.
C3 Lebanese University; Universite de Toulouse; Universite Toulouse III -
   Paul Sabatier
RP Ibrahim, ZA (corresponding author), Lebanese Univ, Fac Sci Hadath, LARIFA Team, Beirut, Lebanon.
EM zein.ibrahim@ul.edu.lb; Isabelle.Ferrane@irit.fr; Philippe.Joly@irit.fr
RI Ibrahim, Zein Al Abidin/HSA-8288-2023
OI Ibrahim, Zein Al Abidin/0000-0002-9888-8161
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Anant B, 2015, IEEE INT C CONS EL I
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 1992, ISO10744 ANSI
   [Anonymous], 1990, Readings in Qualitative Reasoning About Physical Systems
   Avrithis Y, 2000, IEEE INT C MULT EXP
   Balbiani P, 1999, JOURN NAT MOD RAIS J
   Balbiani P, 2003, SPATIAL COGNITION 3
   Bigot B, 2012, MULTIMED TOOLS APPL, V60, P347, DOI 10.1007/s11042-010-0609-9
   Bonzanini A, 2001, INT C VER LOW BITR V
   Buchanan C, 1993, ACM INT C MULT
   Chittaro L, 1996, KNOWL ENG REV, V11, P281, DOI 10.1017/S026988890000792X
   Chittaro L, 2000, ANN MATH ARTIF INTEL, V28, P47, DOI 10.1023/A:1018900105153
   Condotta J-F, 2000, PROBLEMES SATISFACTI
   Cukierman D, 2004, INT FLOR ART INT RES
   DECHTER R, 1991, ARTIF INTELL, V49, P61, DOI 10.1016/0004-3702(91)90006-6
   Dingeldein D, 1994, EUR WORKSH OBJ OR GR
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Duan L-Y, 2005, IEEE T MULTIMEDIA
   Duda A, 1995, IEEE INT WORKSH MULT
   Eickeler S, 1999, IEEE INT C AC SPEECH
   FREKSA C, 1992, ARTIF INTELL, V54, P199, DOI 10.1016/0004-3702(92)90090-K
   Geng Y, 2017, INT C ART NEUR NETW
   GOLUMBIC MC, 1993, J ACM, V40, P1108, DOI 10.1145/174147.169675
   GRAVES A, 2013, CORR, DOI [DOI 10.1109/ICASSP.2013.6638947, 10.1109/ICASSP.2013.6638947. U R L, 10.1109/ICASSP.2013.6638947]
   Han M, 2002, ACM INT C MULT
   Hayes Patrick., 1996, A Catalog of Temporal Theories
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hiroki I, 2012, INT C PATT REC ICPR
   Ibrahim Z., 2006, P 11 INT C INF PROC
   Ibrahim ZAA, 2007, CARACTERISATION STRU
   Ibrahim ZA, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/537372
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kautz H, 1991, AAAI 91
   Khalifa A, 2017, IEEE INT SYMP CIRC S
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krokhin A, 2003, J ACM, V50, P591, DOI 10.1145/876638.876639
   Ladkin P., 1987, The Logic of Time Representation
   Ladkin P, 1986, NAT C ART INT PENNS
   LIGOZAT G, 1989, INFORM PROCESS LETT, V32, P177, DOI 10.1016/0020-0190(89)90040-9
   Ligozat G, 1991, NAT C ART INT AAAI 9
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meiri I., 1996, ARTIF INTELL, V87, P295
   MOULIN B, 1992, KNOWL-BASED SYST, V5, P183, DOI 10.1016/0950-7051(92)90030-J
   Navarette I, 1997, INT JOINT C ART INT
   NEBEL B, 1995, J ACM, V42, P43, DOI 10.1145/200836.200848
   Pani AK, 2001, MATH COMPUT MODEL, V34, P55, DOI 10.1016/S0895-7177(01)00049-8
   Petrovic M, 2002, IEEE INT C MULT EXP
   Pujari A, 1999, INT JOINT C ART INT
   Qiu Z, 2017, IEEE C COMP VIS PATT
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross G, 2015, IEEE INT C COMP VIS
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sattar Abdul, 1999, AUSTR JOINT C ART IN
   Schwalb E., 1998, Constraints, V3, P129, DOI 10.1023/A:1009717525330
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Tang S, 2015, IEEE INT C SOFTW ENG
   TARSKI A, 1941, J SYMBOLIC LOGIC, V6, P73, DOI DOI 10.2307/2268577
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tovinkere V, 2001, IEEE INT C MULT EXP
   Van Beek P., 1990, Computational Intelligence, V6, P132, DOI 10.1111/j.1467-8640.1990.tb00130.x
   VILA L, 1994, AI COMMUN, V7, P4
   Vilain M, 1986, NAT C ART INT AAAI86
   Vilain MB, 1982, NAT C ART INT AAAI82
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wetprasit R, 1998, NAT C ART INT AAAI M
   Yu H, 2016, IEEE INT CONF COMMUN
   Zha S, 2015, BRIT MACH VIS C
   Zhang G, 2017, INT C INT DAT ENG AU
   Zhang SC, 2002, APPL ARTIF INTELL, V16, P1, DOI 10.1080/088395102753365771
   Zhou W, 2000, ACM WORKSH MULT NEW
NR 74
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15275
EP 15316
DI 10.1007/s11042-018-6771-1
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700050
DA 2024-07-18
ER

PT J
AU Li, G
   Hu, RM
   Wang, XC
   Zhang, R
AF Li, Gang
   Hu, Ruimin
   Wang, Xiaochen
   Zhang, Rui
TI A near-end listening enhancement system by RNN-based noise cancellation
   and speech modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NELE; Speech intelligibility; Noise cancellation; Phase prediction; RNN
ID INTELLIGIBILITY ENHANCEMENT; PARALLEL FRAMEWORK
AB When people listen to the phone in noisy environments, near-end listening enhancement (NELE) is a technology to enhance speech intelligibility against environmental noise. The complex environments in mobile communications have inspired many scholars to engage in NELE researches. Although they have proposed a lot of NELE systems, they only focus on the speech modification to enhance the intelligibility. Few scholars have attempted to further enhance the intelligibility by noise cancellation. Because traditional noise cancellation is based on adaptive filtering. If the adaptive filtering is used in the most common handset mode, the noise cancellation result will be poor because of inadequate feedback caused by the feedback microphone exposed to complex environments. With the booming of the deep neural network (DNN), DNN is able to predict noise signals for noise cancellation without the feedback microphone, especially for recurrent neural network (RNN). In this study, we propose a NELE System by RNN-based noise cancellation and speech modification (RNC-SM), which introduce a noise cancellation function after speech modification. Compared with existing NELE systems, RNC-SM system effectively improves the objective speech intelligibility index (SII) scores and the subjective listening quality.
C1 [Li, Gang; Hu, Ruimin; Wang, Xiaochen; Zhang, Rui] Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Hubei, Peoples R China.
   [Li, Gang; Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Hubei, Peoples R China.
   [Li, Gang; Hu, Ruimin] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Hubei, Peoples R China.; Hu, RM (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Hubei, Peoples R China.; Hu, RM (corresponding author), Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
EM hrm@whu.edu.cn
FU National Key R&D Program of China [2017YFB1002803]; National Nature
   Science Foundation of China [61801334, 61762005, U1736206]
FX This work was supported by National Key R&D Program of China (No.
   2017YFB1002803) and National Nature Science Foundation of China (No.
   61801334, No. 61762005, No. U1736206).
CR [Anonymous], COMPUTER SCI
   [Anonymous], 103224 ETSI TS
   [Anonymous], 800 ITUT P
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 2014, DISCRETE COSINE TRAN
   [Anonymous], 2016, IEEE AASP CHALLENGE
   [Anonymous], 2023961 ETSI EG
   [Anonymous], 2014, DEEP LEARNING METHOD
   ANSI, 1997, AM NAT STAND METH CA
   Ballou G., 2015, HDB SOUND ENG, V5th
   Ben Aicha A, 2017, MULTIMED TOOLS APPL, V76, P23661, DOI 10.1007/s11042-016-4145-0
   Chen Z, 2017, INT CONF ACOUST SPEE, P246, DOI 10.1109/ICASSP.2017.7952155
   Cooke M, 2014, COMPUT SPEECH LANG, V28, P543, DOI 10.1016/j.csl.2013.08.003
   George NV, 2013, SIGNAL PROCESS, V93, P363, DOI 10.1016/j.sigpro.2012.08.013
   Jokinen E, 2017, IEEE-ACM T AUDIO SPE, V25, P1985, DOI 10.1109/TASLP.2017.2740004
   Jokinen E, 2016, INTERSPEECH, P2771, DOI 10.21437/Interspeech.2016-143
   Kakouros S, 2017, INTERSPEECH, P3211, DOI 10.21437/Interspeech.2017-1237
   Khademi S, 2017, IEEE-ACM T AUDIO SPE, V25, P1694, DOI 10.1109/TASLP.2017.2714424
   Kleijn WB, 2015, IEEE SIGNAL PROC MAG, V32, P43, DOI 10.1109/MSP.2014.2365594
   Koutsogiannaki Maria, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4648, DOI 10.1109/ICASSP.2014.6854483
   Koutsogiannaki M, 2017, INTERSPEECH, P1973, DOI 10.21437/Interspeech.2017-1157
   Kuo SM, 1999, P IEEE, V87, P943, DOI 10.1109/5.763310
   NIEDERJOHN RJ, 1978, IEEE T ACOUST SPEECH, V26, P378, DOI 10.1109/TASSP.1978.1163100
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Petkov PN, 2015, IEEE-ACM T AUDIO SPE, V23, P327, DOI 10.1109/TASLP.2014.2384271
   Piczak K. J., 2015, IEEE INT WORKS MACH, P1
   Priyanka SS, 2017, 2017 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT)
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   SPANIAS AS, 1994, P IEEE, V82, P1541, DOI 10.1109/5.326413
   Taal CH, 2014, COMPUT SPEECH LANG, V28, P858, DOI 10.1016/j.csl.2013.11.003
   THOMAS IB, 1968, J AUDIO ENG SOC, V16, P412
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   West N. E., 2017, 2017 IEEE INT S DYN, P1, DOI [10.1109/DySPAN.2017.7920754., DOI 10.1109/DYSPAN.2017.7920754]
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yu D, 2017, IEEE-CAA J AUTOMATIC, V4, P396, DOI 10.1109/JAS.2017.7510508
   Zorila TC, 2017, J ACOUST SOC AM, V141, P189, DOI 10.1121/1.4973533
   Zorila TC, 2016, IEEE-ACM T AUDIO SPE, V24, P1808, DOI 10.1109/TASLP.2016.2585864
   Zorila TC, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P634
NR 42
TC 5
Z9 5
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15483
EP 15505
DI 10.1007/s11042-018-6947-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700058
DA 2024-07-18
ER

PT J
AU Sert, M
   Boyaci, E
AF Sert, Mustafa
   Boyaci, Emel
TI Sketch recognition using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch recognition; Transfer learning; Convolutional neural networks
   (CNNs); Feature fusion
AB Humans have an excellent ability to recognize freehand sketch drawings despite their abstract and sparse structures. Understanding freehand sketches with automated methods is a challenging task due to the diversity and abstract structures of these sketches. In this paper, we propose an efficient freehand sketch recognition scheme, which is based on the feature-level fusion of Convolutional Neural Networks (CNNs) in the transfer learning context. Specifically, we analyse different layer performances of distinct ImageNet pretrained CNNs and combine best performing layer features within the CNN-SVM pipeline for recognition. We also employ Principal Component Analysis (PCA) to reduce the fused deep feature dimensions to ensure the efficiency of the recognition application on the limited-capacity devices. We perform evaluations on two real sketch benchmark datasets, namely the Sketchy and the TU-Berlin to show the effectiveness of the proposed scheme. Our experimental results show that, the feature-level fusion scheme with the PCA achieves a recognition accuracy of 97.91% and 72.5% on the Sketchy and TU-Berlin datasets, respectively. This result is promising when compared with the human recognition accuracy of 73.1% on the TU-Berlin dataset. We also develop a sketch recognition application for smart devices to demonstrate the proposed scheme.
C1 [Sert, Mustafa; Boyaci, Emel] Baskent Univ, Dept Comp Engn, TR-06790 Ankara, Turkey.
C3 Baskent University
RP Sert, M (corresponding author), Baskent Univ, Dept Comp Engn, TR-06790 Ankara, Turkey.
EM msert@baskent.edu.tr; 21310038@mail.baskent.edu.tr
RI SERT, Mustafa/AAB-8673-2019
OI SERT, Mustafa/0000-0002-7056-4245
CR Aihkisalo Tommi, 2012, 2012 IEEE Eighth World Congress on Services, P100, DOI 10.1109/SERVICES.2012.55
   ANGELOVA A, 2015, REAL TIME PEDESTRIAN
   [Anonymous], 2011, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2010.266
   [Anonymous], 2015, NIPS
   [Anonymous], P IEEE INT C CONS EL
   [Anonymous], IEEE INT ENER CONF
   [Anonymous], 2016, ICLR
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632
   [Anonymous], 2016, ECCV
   [Anonymous], 2015, ARXIV150607224
   [Anonymous], ACM T GRAPH TOG
   [Anonymous], 2018, ARXIV180102753
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], ACM C MULT
   [Anonymous], 2015, FREEHAND SKETCH RECO
   [Anonymous], FISHER KERNEL DEEP N
   [Anonymous], BMVC
   [Anonymous], 2016, P ADV NEURAL INFORM
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arjovsky M., 2017, ARXIV170107875
   Chen X, 2016, 2016 AUSTRALIAN CONTROL CONFERENCE (AUCC), P180, DOI 10.1109/AUCC.2016.7868184
   Creswell Antonia, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P798, DOI 10.1007/978-3-319-46604-0_55
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Ergun H, 2016, INT J SEMANT COMPUT, V10, P379, DOI 10.1142/S1793351X16400158
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Jahani-Fariman H, 2018, MULTIMED TOOLS APPL, V77, P1997, DOI 10.1007/s11042-017-4368-8
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Liu K, 2017, MULTIMED TOOLS APPL, V76, P12819, DOI 10.1007/s11042-016-3700-z
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Platt JC, 2000, ADV NEUR IN, P61
   Qian X, 2015, RSC GREEN CHEM SER, V34, P1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Seddati O, 2017, MULTIMED TOOLS APPL, V76, P22333, DOI 10.1007/s11042-017-4799-2
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Srinivas S, 2016, FRONT ROBOT AI, V2, DOI 10.3389/frobt.2015.00036
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wagh Kishor., 2012, Journal of Information Engineering and Applications, V2, P12
   Wang LD, 2018, IEEE INT CONF AUTOMA, P83, DOI 10.1109/FG.2018.00022
   Wu S, 2017, MULTIMED TOOLS APPL, V76, P20167, DOI 10.1007/s11042-017-4568-2
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 55
TC 10
Z9 14
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17095
EP 17112
DI 10.1007/s11042-018-7067-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500061
DA 2024-07-18
ER

PT J
AU Hu, B
   Li, LD
   Qian, JS
AF Hu, Bo
   Li, Leida
   Qian, Jiansheng
TI Internal generative mechanism driven blind quality index for deblocked
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; No-reference; Internal generative mechanism;
   Entropy; Curvelet transform
ID FREE-ENERGY PRINCIPLE; SHARPNESS ASSESSMENT; BLOCKING ARTIFACTS; BLUR
   ASSESSMENT; STATISTICS; REGULARITY; STRENGTH; BRAIN
AB Blocking artifact is one of the most common distortion types in JPEG compression. Extensive deblocking algorithms have been proposed to improve the quality of JPEG compressed images. However, very little work has been dedicated to the quality assessment of deblocked images, which may hinder further development of image deblocking techniques. The deblocked images are usually contaminated by multiple distortions, typically blocking artifacts and blur. Although various quality metrics have been reported, they are not designed specially for deblocked images, so they cannot accurately predict the quality of deblocked images. To fill this gap, we propose a new quality metric for deblocked images. Inspired by the internal generative mechanism theory, a deblocked image is first decomposed into two portions, i.e., the predicted and disorderly portions. Then the distortions in the two portions are evaluated separately. For the predicted portion, the distortion-specific features are extracted to separately evaluate blocking artifacts and blur in the spatial domain. Then the joint effect of blocking artifacts and blur is evaluated by extracting energy-based features in the Curvelet domain. For the disorderly portion, Renyi entropy is employed to measure the uncertain information introduced in the deblocking process. Finally, all features are combined to train a random forest model for quality prediction of deblocked images. Experimental results conducted on a newly released DeBlocked Image Database (DBID) demonstrate the superiority of the proposed method over the existing quality metrics. Moreover, the proposed metric is less dependent on the number of training images.
C1 [Hu, Bo; Li, Leida; Qian, Jiansheng] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Qian, JS (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM Hubo0523@cumt.edu.cn; lileida@cumt.edu.cn; qianzhangiqa@163.com
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022
FU Natural Science Foundation of Jiangsu Province [BK20181354]; National
   Natural Science Foundation of China [61379143, 61771473]; Six Talent
   Peaks High-level Talents in Jiangsu Province [XYDXX-063]; Qing Lan
   Project
FX This work was supported by Natural Science Foundation of Jiangsu
   Province (BK20181354), National Natural Science Foundation of China
   (61379143 and 61771473), the Six Talent Peaks High-level Talents in
   Jiangsu Province (XYDXX-063) and the Qing Lan Project.
CR Acharya J, 2017, IEEE T INFORM THEORY, V63, P38, DOI 10.1109/TIT.2016.2620435
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Criminisi A., 2012, FOUNDATIONS AND TREN, V7, P81
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Golestaneh SA, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013018
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Gu K, 2013, IEEE WORKSHOP SIG, P241, DOI 10.1109/SiPS.2013.6674512
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Jahne B., 1999, HDB COMPUTER VISION, VVolume 2, P125
   Jenadeleh M, 2017, MULTIMED TOOLS APPL, V76, P13859, DOI 10.1007/s11042-016-3785-4
   Jenssen R, 2003, IEEE IJCNN, P523
   Joshi P, 2018, VISUAL COMPUT, V34, P1739, DOI 10.1007/s00371-017-1460-z
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee S, 2012, SIGNAL PROCESS-IMAGE, V27, P31, DOI 10.1016/j.image.2011.08.002
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li LD, 2016, NEUROCOMPUTING, V177, P572, DOI 10.1016/j.neucom.2015.11.063
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P918, DOI 10.1109/LSP.2014.2320743
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P122, DOI 10.1109/LSP.2013.2294333
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Lu W, 2016, MULTIMED TOOLS APPL, V75, P14417, DOI 10.1007/s11042-016-3519-7
   Ma B, 2000, IEEE IMAGE PROC, P481, DOI 10.1109/ICIP.2000.901000
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Qian JS, 2014, DIGIT SIGNAL PROCESS, V33, P125, DOI 10.1016/j.dsp.2014.06.009
   Rezaie F, 2018, MULTIMED TOOLS APPL, V77, P2529, DOI 10.1007/s11042-017-4432-4
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shen J, 2011, IEEE T IMAGE PROCESS, V20, P2089, DOI 10.1109/TIP.2011.2108661
   Shiwen Shen, 2012, Proceedings of the 2012 International Conference on Computer Science and Information Processing (CSIP), P135, DOI 10.1109/CSIP.2012.6308813
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   Vasconcelos M, 2009, IEEE T PATTERN ANAL, V31, P228, DOI 10.1109/TPAMI.2008.77
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P16, DOI 10.1016/j.image.2016.05.008
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Zhan YB, 2017, IEEE SIGNAL PROC LET, V24, P760, DOI 10.1109/LSP.2017.2688371
NR 55
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12583
EP 12605
DI 10.1007/s11042-018-6823-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900067
DA 2024-07-18
ER

PT J
AU Yan, QS
   Zhu, Y
   Zhang, YN
AF Yan, Qingsen
   Zhu, Yu
   Zhang, Yanning
TI Robust artifact-free high dynamic range imaging of dynamic scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range imaging; Multi-exposure fusion; Rank minimization;
   Optical flow; Motion blur; Ghost removal
AB The irradiance range of the real-world scene is often beyond the capability of digital cameras. Therefore, High Dynamic Range (HDR) images can be generated by fusing images with different exposure of the same scene. However, moving objects pose the most severe problem in the HDR imaging, leading to the annoying ghost artifacts in the fused image. In this paper, we present a novel HDR technique to address the moving objects problem. Since the input low dynamic range (LDR) images captured by a camera act as static linear related backgrounds with moving objects during each individual exposures, we formulate the detection of foreground moving objects as a rank minimization problem. Meanwhile, in order to eliminate the image blurring caused by background slightly change of LDR images, we further rectify the background by employing the irradiances alignment. Experiments on image sequences show that the proposed algorithm performs significant gains in synthesized HDR image quality compare to state-of-the-art methods.
C1 [Yan, Qingsen; Zhu, Yu; Zhang, Yanning] Northwest Polytech Univ, Sch Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Zhu, Y (corresponding author), Northwest Polytech Univ, Sch Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
EM yqs@mail.nwpu.edu.cn; yuzhu@nwpu.edu.cn
FU NSF of China [61231016, 61301193, 61303123, 61301192]; Natural Science
   Basis research Plan in Shaanxi Province of China [2013JQ8032]; Chang
   Jiang Scholars Program of China [100017GH030150, 15GH0301]
FX The work is supported by grants NSF of China (61231016, 61301193,
   61303123, 61301192), Natural Science Basis research Plan in Shaanxi
   Province of China (No. 2013JQ8032), Chang Jiang Scholars Program of
   China (100017GH030150, 15GH0301). Yanning Zhang has helped with
   acquisition of funding, technical editing of the manuscript and served
   as scientific advisors. Yu Zhu has helped with writing assistance,
   technical editing and language editing of the manuscript. Jinqiu Sun has
   helped with general supervision of our research group and language
   editing of the manuscript.
CR Bogoni L, 2000, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2000.903475
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   ERIK R, 2005, HIGH DYNAMIC RANGE I
   Gallo O., 2009, P IEEE INT C COMP PH, P1
   Gong D, 2017, AAAI
   Gong D, 2017, IEEE I CONF COMP VIS, P1670, DOI 10.1109/ICCV.2017.184
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   Gong D, 2016, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2016.202
   GROSCH T, 2006, VISION MODELING VISU, P277
   Heo YS, 2011, LECT NOTES COMPUT SC, V6495, P486, DOI 10.1007/978-3-642-19282-1_39
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23
   Jinno T, 2008, IEEE IMAGE PROC, P1304, DOI 10.1109/ICIP.2008.4712002
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Lee C, 2014, IEEE SIGNAL PROC LET, V21, P1045, DOI 10.1109/LSP.2014.2323404
   Liu C, 2014, IEEE T PATTERN ANAL, V36, P346, DOI 10.1109/TPAMI.2013.127
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 30 AAAI C ART INT
   Liu Y, INT JOINT C ART INT
   Liu Y, PREDICTING URBAN WAT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338
   Oh TH, 2013, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.2013.6738163
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001
   Yan QS, 2017, NEUROCOMPUTING, V269, P160, DOI 10.1016/j.neucom.2017.03.083
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zimmer H, 2011, COMPUT GRAPH FORUM, V30, P405, DOI 10.1111/j.1467-8659.2011.01870.x
NR 39
TC 15
Z9 15
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11487
EP 11505
DI 10.1007/s11042-018-6625-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900018
DA 2024-07-18
ER

PT J
AU Arivazhagan, S
   Shebiah, RN
AF Arivazhagan, S.
   Shebiah, Newlin R.
TI Versatile loitering detection based on non-verbal cues using dense
   trajectory descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Loitering; Wavelet transform; Dense trajectory descriptors;
   Co-occurrence features; Spatio - temporal features; Motion boundary
   histogram
ID GAIT; CLASSIFICATION; SEGMENTATION; RECOGNITION; HISTOGRAMS; CONSENSUS;
   FEATURES
AB Loitering analytics is widely explored nowadays since it anticipates crimes by identifying suspicious behavioural pattern displayed by offenders and reacts to the circumstances without delay. The challenge in loitering detection lies in effective discrimination of the behavioural pattern of offensive loiter and innocuous loiter. In this paper, certain embodiments were proposed with dense trajectory features representing human gait parameters since, many of the Personality traits are manifested in it. Here, frame differencing of effectively represented frames by wavelet transform is used for moving blob detection. With the prior model developed from benchmark datasets using co-occurrence features, the motion blobs were classified as pedestrian or other moving objects using SVM classifier. Short term biometric features like the clothing colour and texture are successfully used to track the person in successive frames. Since the perceiver can make judgment on the target within 10s under unacquainted condition, here short sequences of frames representing 10s of video is used for processing. For the short sequence, data association matrix relating the frame number and the associated pedestrians in each frame based on minimum Euclidean distance is proposed. Missing tracks due to occlusion can be effectively handled by a completely unsupervised system using the proposed data association matrix. From the developed matrix the person staying in the Region of Interest for a long duration is identified and behavioural cues displayed by the person are extracted. Here, the spatio- temporal features extracted from Dense Trajectories and Motion Boundary Descriptors from the pre-learned model is used to characterize the person as loiter or not. To evaluate the performance of the proposed method, PETS 2006, PETS 2007 and PETS 2016 datasets were used and the experiments show promising results comparable with the state of art techniques.
C1 [Arivazhagan, S.; Shebiah, Newlin R.] Mepco Schlenk Engn Coll, Dept Elect & Commun Engn, Ctr Image Proc & Pattern Recognit, Sivakasi 626005, Tamil Nadu, India.
C3 Mepco Schlenk Engineering College
RP Shebiah, RN (corresponding author), Mepco Schlenk Engn Coll, Dept Elect & Commun Engn, Ctr Image Proc & Pattern Recognit, Sivakasi 626005, Tamil Nadu, India.
EM newlinshebiah@yahoo.co.in
RI S, Arivazhagan/T-3033-2019; Alsaif, Amal/IUO-9428-2023; R, Newlin
   Shebiah/S-9970-2019
OI S, Arivazhagan/0000-0002-2579-501X; Alsaif, Amal/0000-0002-8204-0326; R,
   Newlin Shebiah/0000-0002-0835-5848
CR Ahmed Imran, 2016, Proceedings of the World Congress on Engineering 2016, P484
   ALBRIGHT L, 1988, J PERS SOC PSYCHOL, V55, P387, DOI 10.1037/0022-3514.55.3.387
   Albright L, 1997, J PERS SOC PSYCHOL, V72, P558, DOI 10.1037/0022-3514.72.3.558
   Allili MS, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P503, DOI 10.1109/CRV.2007.7
   [Anonymous], P SPIE C BIOM TECHN
   [Anonymous], 2012, P IEEE S PHOT OPT MA
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], TPAMI
   [Anonymous], BMVC
   [Anonymous], 2004, CALTECH 101 DATASET
   [Anonymous], PETS 2016 DATASET CH
   [Anonymous], PROCEEDINGS OF THE 2
   [Anonymous], INT C ADV INF TECHN
   [Anonymous], 14 IEEE INT C ADV VI
   [Anonymous], P IEEE INT C INF AUT
   [Anonymous], KOREA AEROSPACE U
   [Anonymous], INT C SYST SIGN IM P
   [Anonymous], NEURAL NETWORKS IJCN
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], HINDAWI ADV MULTIMED
   [Anonymous], ARXIV150203167
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2009, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.23.124
   [Anonymous], INT WORKSH VIS SURV
   [Anonymous], 2014, ECCV CVRSUAD WORKSH
   [Anonymous], INT C ART INT MOD SI
   [Anonymous], J ORTHOP SPORTS PHYS
   [Anonymous], IMAGE PROCESSING
   [Anonymous], SIGGRAPH POSTERS
   [Anonymous], 2017, THESIS
   [Anonymous], 2013, 9 INT C COMP INF TEC
   [Anonymous], 10 IEEE INT WORKSH P
   [Anonymous], THESIS
   [Anonymous], INT C EL CONTR ENG I
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1976, DOI 10.1016/j.patrec.2006.05.008
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1875, DOI 10.1016/j.patrec.2006.04.013
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P3197, DOI 10.1016/j.patrec.2003.08.005
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Black J, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P189
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12
   Dadashi BA, 2009, PROC INT C IMAGE SIG, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   de Almeida C. W. D., 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P2487, DOI 10.1109/ICSMC.2010.5641934
   Deng XY, 2008, INT CONF ACOUST SPEE, P1013
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Frizera A, 2012, P IEEE RAS-EMBS INT, P1087, DOI 10.1109/BioRob.2012.6290264
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Guo JJ, 2017, IOP CONF SER-MAT SCI, V242, DOI 10.1088/1757-899X/242/1/012115
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang CH, 2009, LECT NOTES COMPUT SC, V5414, P771, DOI 10.1007/978-3-540-92957-4_67
   Huang JC, 2004, ELECTRON LETT, V40, P798, DOI 10.1049/el:20040534
   Huang JC, 2003, ELECTRON LETT, V39, P1380, DOI 10.1049/el:20030909
   Jianwei Ding, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P82, DOI 10.1007/978-3-642-19309-5_7
   Kekre H.B., 2010, International Journal of Computer Theory and Engineering, P695
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Kou L, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040402
   Kovac J, 2019, MULTIMED TOOLS APPL, V78, P5621, DOI 10.1007/s11042-017-5469-0
   강주형, 2014, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V17, P15, DOI 10.9717/kmms.2014.17.1.015
   Lee B., 2002, IMAGE VISION COMPUT, P315
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Lim MK, 2014, EXPERT SYST APPL, V41, P4704, DOI 10.1016/j.eswa.2014.02.003
   Liu Jianquan, 2016, P 24 ACM INT C MULT, P675
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Nam Y, 2015, MULTIMED TOOLS APPL, V74, P2939, DOI 10.1007/s11042-013-1763-7
   Nandy A, 2014, ADV INTELL SYST, V236, P729, DOI 10.1007/978-81-322-1602-5_78
   Pacifici F, 2009, REMOTE SENS ENVIRON, V113, P1276, DOI 10.1016/j.rse.2009.02.014
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Sahoo M., 2011, P 2 NAT C COMP COMM, P34
   Satchell L, 2017, J NONVERBAL BEHAV, V41, P35, DOI 10.1007/s10919-016-0240-1
   Sengar SS, 2016, OPTIK, V127, P6258, DOI 10.1016/j.ijleo.2016.03.061
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   Tan D., 2007, P IEEE C COMPUTER VI, P1
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P673
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P222
   Tan DL, 2006, INT C PATT RECOG, P1000
   Taylor Charles., 1991, Philosophical Arguments
   Thi Thi Zin, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P680, DOI 10.1109/IIHMSP.2010.172
   Thoresen JC, 2012, COGNITION, V124, P261, DOI 10.1016/j.cognition.2012.05.018
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Whittle M., 2007, Gait Analysis: an Introduction
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Yao L, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0145-2
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   [郑淑丹 Zheng Shudan], 2014, [遥感学报, Journal of Remote Sensing], V18, P868
NR 94
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10933
EP 10963
DI 10.1007/s11042-018-6618-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400062
DA 2024-07-18
ER

PT J
AU Fang, H
   Zhou, H
   Ma, ZH
   Zhang, WM
   Yu, NH
AF Fang, Han
   Zhou, Hang
   Ma, Zehua
   Zhang, Weiming
   Yu, Nenghai
TI A robust image watermarking scheme in DCT domain based on adaptive
   texture direction quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active forensics; Robust watermarking; Gabor filter; Texture direction;
   Direction-coefficient mapping
AB This paper proposes a novel robust image watermarking scheme in Discrete Cosine Transform (DCT) domain for active forensics. We investigate the relation between the positions and the modification magnitudes of DCT coefficients and directions of texture blocks. By exploring such relation, a direction-coefficient mapping is designed. First, the texture direction of each image block is estimated by Gabor filter. And then, according to the direction-coefficient mapping, one watermark bit is embedded into each block along its texture direction. Compared with existing schemes, the proposed method utilizes the direction features of texture blocks better . Therefore, the improvements in watermarked image quality and the robustness of watermark signal against image processing attacks are both achieved.
C1 [Fang, Han; Zhou, Hang; Ma, Zehua; Zhang, Weiming; Yu, Nenghai] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.
EM fanghan@mail.ustc.edu.cn; zh2991@mail.ustc.edu.cn;
   mzh045@mail.ustc.edu.cn; zhangwm@ustc.edu.cn; ynh@ustc.edu.cn
RI Zhou, Hang/AAI-5565-2021; fang, han/GSN-6404-2022
OI Zhang, Weiming/0000-0001-5576-6108; Ma, Zehua/0000-0002-8153-341X
FU Natural Science Foundation of China [U1636201, 61572452]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1636201, 61572452.
CR Amiri T, 2016, MULTIMED TOOLS APPL, V75, P8527, DOI 10.1007/s11042-015-2770-7
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cui LH, 2011, IEEE T IMAGE PROCESS, V20, P1047, DOI 10.1109/TIP.2010.2079551
   HAMID M, 2016, IEEE IWSSIP 2016 201, V2016, P1
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604
   Lou OJ, 2014, INT SYMP PARAL ARCH, P278, DOI 10.1109/PAAP.2014.19
   Lutovac B, 2017, MULTIMED TOOLS APPL, V76, P23333, DOI 10.1007/s11042-016-4127-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang CY, 2017, MULTIMED TOOLS APPL, V76, P16291, DOI 10.1007/s11042-016-3909-x
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhao JH, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9078598
NR 23
TC 9
Z9 10
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8075
EP 8089
DI 10.1007/s11042-018-6596-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800011
DA 2024-07-18
ER

PT J
AU Rani, R
   Singh, AP
   Kumar, R
AF Rani, Ritu
   Singh, Amit Prakash
   Kumar, Ravinder
TI Impact of reduction in descriptor size on object detection and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Classification; Feature extraction; Sequential
   Forward Selection; Principal Component Analysis; SVM Classifier
ID PRINCIPAL COMPONENT ANALYSIS; DIMENSIONALITY REDUCTION; MACHINE;
   SELECTION; SYSTEM
AB Extraction of distinctive and robust features in image/video analysis and processing has attracted the attention of researchers in the recent years. Elimination of irrelevant and less important features reduces the computational complexity to a great extent at the cost of a very marginal reduction in accuracy. This paper presents a framework for dimensionality reduction of the binary features to obtain a low dimension feature vector for object detection. The process of identification and selection of the most relevant feature is performed in three steps: extraction of features using binary descriptors; Selection of best feature subset using Sequential Forward Selection (SFS) and Principal Component Analysis; classification using SVM classifier. The experimental results show that BRISK and LATCH descriptors perform better even when the dimensionality is reduced from 256, 128, and 64 to 32 bits with an acceptable classification accuracy and significant reduction in run time. However, there is slight decrease in the classification accuracy of LBP, FREAK, BRIEF, and ORB. A classification rate of 84.93% is obtained with LATCH descriptor for a descriptor size of 32 bits.
C1 [Rani, Ritu; Singh, Amit Prakash; Kumar, Ravinder] GGSIPU, New Delhi, India.
C3 GGS Indraprastha University
RP Rani, R (corresponding author), GGSIPU, New Delhi, India.
EM ritujangra00@gmail.com; aps.ipu@gmail.com; ravinder_y@yahoo.com
RI Rani, Ritu/IYS-9372-2023; Singh, Amit/J-9317-2016
OI Rani, Dr.Ritu/0000-0001-6219-8751; Singh, Amit/0000-0002-8675-6903
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], ARXIV160401841
   [Anonymous], P ECML PKDD IDDM WOR
   [Anonymous], 2010, P 15 COMP VIS WINT W
   [Anonymous], 1996, STANFORD INFOLAB
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2014, INT J COMPUTATIONAL
   [Anonymous], 2003, Advances in Neural Informaiton Processing Systems
   Baccini A, 1996, ST CLASS DAT ANAL, P359
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Ghodsi A., 2006, DIMENSIONALITY REDUC, V37, P38
   Gudigar A, 2016, MULTIMED TOOLS APPL, V75, P333, DOI 10.1007/s11042-014-2293-7
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Howley T, 2006, BCS CONF SERIES, P209, DOI 10.1007/1-84628-224-1_16
   Hussain S.U., 2010, BMVC 2010-British Machine Vision Conference, P112
   Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kang K, 2016, MULTIMED TOOLS APPL, V75, P1443, DOI 10.1007/s11042-014-2142-8
   Ke QF, 2005, PROC CVPR IEEE, P739
   Keller S, 2016, HYPERSPECTRAL IMAGE, P1
   Kosmopoulos Aris., 2014, Information Access Evaluation. Multilinguality, Multimodality, and Interaction - 5th International Conference of the CLEF Initiative, CLEF 2014, Sheffield, UK, September 15-18, P160
   Kumar Ravinder, 2014, International Journal of Computational Intelligence Studies, V3, P292, DOI 10.1504/IJCISTUDIES.2014.067032
   Kumar R, 2016, J INF PROCESS SYST, V12, P83, DOI 10.3745/JIPS.02.0020
   Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Levi G, 2016, APPL COMPUTER VISION, P1
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P13, DOI 10.1007/978-0-85729-748-8_2
   Rani R, 2018, PATTERN ANAL APPL, V21, P1, DOI 10.1007/s10044-017-0641-8
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Shlens J., 2014, A tutorial on principal component analysis
   Tapu R, 2017, MULTIMED TOOLS APPL, V76, P11771, DOI 10.1007/s11042-016-3617-6
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
NR 39
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8965
EP 8979
DI 10.1007/s11042-018-6911-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800059
DA 2024-07-18
ER

PT J
AU Som, S
   Mitra, A
   Palit, S
   Chaudhuri, BB
AF Som, Sukalyan
   Mitra, Abhijit
   Palit, Sarbani
   Chaudhuri, B. B.
TI A selective bitplane image encryption scheme using chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial image encryption; Auto-correlation function; Bitplane; Tent map;
   Uniformity test; Correlation coefficient; Key sensitivity; Differential
   attack; Cropping attack; Replacement attack
AB Partial encryption is one of the viable solutions for low power, high speed, real time secure multimedia communication. In this paper, a chaotic tent map based selective bitplane encryption technique is proposed for both gray scale and color images. After decomposing the original image into eight bitplanes, each bitplane is classified into either significant or non-significant category by defining a flexible threshold value of 0.3, deduced experimentally. Following this segregation, only the significant bitplanes are encrypted with the key stream sequences generated by a chaos-based pseudo-random binary number generator. The cipher image is then transmitted through public channel. The proposed scheme has three important contributions v.i.z. a) determination of significant bitplanes, b) encryption of only the significant bitplanes leading to reduction in computational complexity and c) elimination of the need for separate channel for transmitting the information about the significant bitplanes. It is shown that the proposed partial encryption scheme saves around 35% computation on the image database used here. Different types of attacks against this scheme are also analysed to show the robustness of this approach.
C1 [Som, Sukalyan] Barrackpore Rastraguru Surendranath Coll, Dept Comp Sci, Kolkata, W Bengal, India.
   [Mitra, Abhijit] Gargi Mem Inst Technol, Kolkata 144, India.
   [Palit, Sarbani; Chaudhuri, B. B.] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, W Bengal, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Som, S (corresponding author), Barrackpore Rastraguru Surendranath Coll, Dept Comp Sci, Kolkata, W Bengal, India.
EM sukalyan.s@gmail.com; mitra.ece@gmail.com; sarbanip@isical.ac.in;
   bbc@isical.ac.in
RI Mitra, Abhijit/C-7713-2009
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alsaedi M, 2017, MULTIMED TOOLS APPL, V76, P24527, DOI 10.1007/s11042-016-4206-4
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2009, EUR J SCI RES
   [Anonymous], 4 IMAGE ENCRYPTION S
   [Anonymous], 2007, 4 IEEE GCC C EXH GUL
   [Anonymous], 2010, NIST SPECIAL PUBLICA
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], 1985, ANSI/IEEE Standard 754-1985, P1, DOI [DOI 10.1109/IEEESTD.1985.82928, 10.1109/IEEESTD.1985.82928]
   [Anonymous], 2008, P SMCIS 2008
   [Anonymous], COLOR IMAGE ENCRYPTI
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], NONLINEAR DYN
   [Anonymous], INT J COMPUT SCI INF
   [Anonymous], ADV PARTIAL IMAGE EN
   [Anonymous], P WORKSH MOB SYST WO
   [Anonymous], 2002, P 5 NORD SIGN PROC S
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Box GE, 1994, TIME SERIES ANAL FOR
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Granado JM, 2009, MICROELECTRON J, V40, P1032, DOI 10.1016/j.mejo.2008.11.044
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Jolfaei A., 2011, COMPUT INFORM SCI, V4, P172
   Jui-Cheng Yen, 1999, 1999 IEEE Workshop on Signal Processing Systems. SiPS 99. Design and Implementation (Cat. No.99TH8461), P430, DOI 10.1109/SIPS.1999.822348
   Kuppusamy K., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P236, DOI 10.1109/ICPRIME.2012.6208350
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Marsaglia G., 1995, DIEHARD Statistical Tests
   Narendra P., 2010, IJNS, V10, P32
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Panduranga H. T., 2013, P INT C OPT IM SENS, P1, DOI 10.1109/ICOISS.2013.6678417.
   Parameshachari B. D., 2013, Int. J. Comput. Appl., V63, P33
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1322, DOI 10.1109/APSCC.2008.105
   Sasidharan S., 2011, INT J ADV ENG TECHNO, V1, P322
   Som Sukalyan, 2014, 2014 2nd International Conference on Business and Information Management (ICBIM), P58, DOI 10.1109/ICBIM.2014.6970933
   Uhl A., 2005, ADV INFORM SECURITY, V15
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Zhang XJ, 2013, SIGNAL PROCESS, V93, P2422, DOI 10.1016/j.sigpro.2013.03.017
NR 50
TC 21
Z9 21
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10373
EP 10400
DI 10.1007/s11042-018-6539-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400039
DA 2024-07-18
ER

PT J
AU Di, FQ
   Zhang, MQ
   Liao, X
   Liu, J
AF Di, Fuqiang
   Zhang, Minqing
   Liao, Xin
   Liu, Jia
TI High-fidelity reversible data hiding by Quadtree-based pixel value
   ordering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Pixel value ordering; Quadtree partition; Block
   complexity
ID PREDICTION-ERROR EXPANSION; WATERMARKING; DIFFERENCE; FRAMEWORK;
   CAPACITY
AB Recently, the pixel value ordering (PVO) method has received a great deal of attention in the field of high-fidelity reversible data hiding. To improve the embedding performance of the PVO-based method, a quadtree-based pixel value ordering (QPVO) method based on dynamic quadtree partition is proposed in this paper. Instead of using equal-sized blocks, blocks in various sizes are adaptively generated based on the quadtree partitioning and block complexity. Smooth regions are divided into smaller blocks to obtain high embedding capacity, while rough regions are divided into larger blocks to avoid distortion. The decoder can recover the original image as well as the original quadtree structure by the block complexity. Extensive experiments demonstrate that the proposed QPVO method could significantly improve the embedding performance of these PVO-based methods, especially for a relatively small embedding payload.
C1 [Di, Fuqiang; Zhang, Minqing; Liu, Jia] Engn Univ Chinese Peoples Armed Police, Dept Elect Technol, Xian 710086, Shaanxi, Peoples R China.
   [Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Liao, Xin] Hunan Police Acad, Key Lab Network Crime Invest, Hunan Prov Coll, Changsha 410138, Hunan, Peoples R China.
C3 Hunan University
RP Zhang, MQ (corresponding author), Engn Univ Chinese Peoples Armed Police, Dept Elect Technol, Xian 710086, Shaanxi, Peoples R China.
EM 1054165690@qq.com
RI Liao, Xin/ITT-1021-2023; Liao, Xin/X-2736-2018
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [61379152, 61403417,
   61402530, 61402162]; Shaanxi Provincial Natural Science Foundation
   [2014JQ8301]; Hunan Provincial Natural Science Foundation of China
   [2017JJ3040]; Open Research Fund of Key Laboratory of Network Crime
   Investigation of Hunan Provincial Colleges [2017WLFZZC001]
FX This work is partially supported by National Natural Science Foundation
   of China (No. 61379152, 61403417, 61402530 and 61402162), Shaanxi
   Provincial Natural Science Foundation (2014JQ8301), Hunan Provincial
   Natural Science Foundation of China (Grant No. 2017JJ3040), and the Open
   Research Fund of Key Laboratory of Network Crime Investigation of Hunan
   Provincial Colleges (no. 2017WLFZZC001).
CR Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Goljan M, 2001, P 4 INF HID WORKSH, V27, P41
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   LI X, 1933, TIP, V20, P3524, DOI DOI 10.1109/TIP.2011.2150233
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Soleymani S.H., 2018, ARXIV180311286
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian J, 2014, MULTIMED TOOLS APPL, V69, P1, DOI 10.1007/s11042-013-1680-9
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
NR 32
TC 24
Z9 25
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7125
EP 7141
DI 10.1007/s11042-018-6469-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700032
DA 2024-07-18
ER

PT J
AU Hong, Y
   Kim, J
AF Hong, Yiyu
   Kim, Jongweon
TI Art painting detection and identification based on deep learning and
   image local features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Art painting detection; Art painting identification; Art painting
   dataset; Image local feature; Deep learning; Machine learning; Feature
   extraction
ID CLASSIFICATION; RECOGNITION
AB Many art paintings are placed in film scenes or TV programs as decoration. To prevent using unauthorized copyrighted art paintings, we propose a method that combines a deep learning based object detector and hand-crafted image local features to identify copyrighted art paintings from images that contain them. The object detector is trained with our collected data to be able to detect art paintings. If a query image is input, the object detector will detect the art painting regions, then, the copyrighted art paintings can be identified by matching image local features between the art painting regions and the original copyrighted art paintings that have already been stored in advance. To test the ability of the proposed method from different aspects, we prepared four different kinds of test images: Famous, Monitor Easy, Monitor Hard, and Print. Finally, we provide a practicability analysis of our method based on the experimental results on these test images. Additionally, compared with Scale Invariant Feature Transform (SIFT), our approach outperformed by more than 20%.
C1 [Hong, Yiyu] Sangmyung Univ, Dept Copyright Protect, Seoul, South Korea.
   [Kim, Jongweon] Sangmyung Univ, Dept Elect Engn, Seoul, South Korea.
C3 Sangmyung University; Sangmyung University
RP Kim, J (corresponding author), Sangmyung Univ, Dept Elect Engn, Seoul, South Korea.
EM hongyiyu@cclabs.kr; jwkim@smu.ac.kr
RI Kim, Jongweon/AAO-2221-2020
OI Kim, Jongweon/0000-0002-8916-6431
FU Ministry of Culture, Sports and Tourism(MCST); Korea Creative Content
   Agency(KOCCA) in the Culture Technology (CT) Research & Development
   Program
FX This research is supported by Ministry of Culture, Sports and
   Tourism(MCST) and Korea Creative Content Agency(KOCCA) in the Culture
   Technology (CT) Research & Development Program 2017.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], ARXIV160403540
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dai J, ARXIV160506409
   Deac AI, 2006, LECT NOTES COMPUT SC, V4105, P354
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Keren D, 2002, INT C PATT RECOG, P474, DOI 10.1109/ICPR.2002.1048341
   Kim K.-H., 2016, ARXIV160808021
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li J, 2004, IEEE T IMAGE PROCESS, V13, P338, DOI 10.1109/TIP.2003.821349
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lombardi T., 2004, P 6 ACM SIGMM INT WO, P107, DOI DOI 10.1145/1026711.1026729
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Martinel N, 2013, IEEE SIGNAL PROC LET, V20, P1024, DOI 10.1109/LSP.2013.2279014
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Miksik O, 2012, INT C PATT RECOG, P2681
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J., 2017, CVPR 2017, DOI DOI 10.1142/9789812771728_0012
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   XU L, 1993, CVGIP-IMAG UNDERSTAN, V57, P131, DOI 10.1006/ciun.1993.1009
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Zagoruyko S, 2016, P BRIT MACH VIS C 20, DOI [10.5244/C.30.15, DOI 10.5244/C.30.15]
   Zhai A, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P515, DOI 10.1145/3041021.3054201
NR 39
TC 11
Z9 11
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6513
EP 6528
DI 10.1007/s11042-018-6387-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700005
DA 2024-07-18
ER

PT J
AU Adewole, KS
   Anuar, NB
   Kamsin, A
   Sangaiah, AK
AF Adewole, Kayode Sakariyah
   Anuar, Nor Badrul
   Kamsin, Amirrudin
   Sangaiah, Arun Kumar
TI SMSAD: a framework for spam message and spam account detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online social network; Microblog; Spam message; Spam account;
   Evolutionary computation; Machine learning
ID MALICIOUS ACCOUNTS
AB Short message communication media, such as mobile and microblogging social networks, have become attractive platforms for spammers to disseminate unsolicited contents. However, the traditional content-based methods for spam detection degraded in performance due to many factors. For instance, unlike the contents posted on social networks like Facebook and Renren, SMS and microblogging messages have limited size with the presence of many domain specific words, such as idioms and abbreviations. In addition, microblogging messages are very unstructured and noisy. These distinguished characteristics posed challenges to existing email spam detection models for effective spam identification in short message communication media. The state-of-the-art solutions for social spam accounts detection have faced different evasion tactics in the hands of intelligent spammers. In this paper, a unified framework is proposed for both spam message and spam account detection tasks. We utilized four datasets in this study, two of which are from SMS spam message domain and the remaining two from Twitter microblog. To identify a minimal number of features for spam account detection on Twitter, this paper studied bio-inspired evolutionary search method. Using evolutionary search algorithm, a compact model for spam account detection is proposed, which is incorporated in the machine learning phase of the unified framework. The results of the various experiments conducted indicate that the proposed framework is promising for detecting both spam message and spam account with a minimal number of features.
C1 [Adewole, Kayode Sakariyah; Anuar, Nor Badrul; Kamsin, Amirrudin] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
   [Adewole, Kayode Sakariyah] Univ Ilorin, Fac Commun & Informat Sci, Dept Comp Sci, Ilorin, Nigeria.
   [Sangaiah, Arun Kumar] VIT Univ, Vellore 632014, Tamil Nadu, India.
C3 Universiti Malaya; University of Ilorin; Vellore Institute of Technology
   (VIT); VIT Vellore
RP Adewole, KS; Anuar, NB (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.; Adewole, KS (corresponding author), Univ Ilorin, Fac Commun & Informat Sci, Dept Comp Sci, Ilorin, Nigeria.
EM adewole.ks@siswa.um.edu.my; badrul@um.edu.my; amir@um.edu.my;
   arunkumarsangaiah@gmail.com
RI Sangaiah, Arun Kumar/U-6785-2019; KAMSIN, AMIRRUDIN/B-8220-2010;
   Adewole, Kayode Sakariyah/AAI-1852-2019; Anuar, Nor Badrul/B-3101-2010
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; KAMSIN,
   AMIRRUDIN/0000-0003-2796-3459; Adewole, Kayode
   Sakariyah/0000-0002-0155-7949; Anuar, Nor Badrul/0000-0003-4380-5303
FU University Malaya Research Grant Programme (Equitable Society)
   [RP032B-16SBS]
FX The work of the authors is supported by University Malaya Research Grant
   Programme (Equitable Society) under grant RP032B-16SBS.
CR Ab Razak MF, 2016, J NETW COMPUT APPL, V75, P58, DOI 10.1016/j.jnca.2016.08.022
   Adewole KS, 2017, J NETW COMPUT APPL, V79, P41, DOI 10.1016/j.jnca.2016.11.030
   Aggarwal A., 2012, ECRIME RES SUMMIT EC, P1
   Ahmed F., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P602, DOI 10.1109/TrustCom.2012.83
   Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   Almeida T., 2013, JiSS, V2, P1
   Alsaleh M, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P463, DOI 10.1109/ICMLA.2014.81
   Amazon, 2016, AM WEB SERV AWS
   [Anonymous], 2011, P 2011 ACM SIGCOMM C
   [Anonymous], 2008, INTERACTIVE TECHNIQU, DOI DOI 10.1145/1394669.1394685
   [Anonymous], 2010, 7 ANN COLL EL MESS A
   [Anonymous], 2015, TWITT RAT LIM SEARCH
   Balakrishnan V, 2016, MALAYS J COMPUT SCI, V29, P45, DOI 10.22452/mjcs.vol21no1.4
   Bozan YS, 2015, 2015 23 SIGN PROC CO
   Chan PPK, 2015, NEUROCOMPUTING, V155, P167, DOI 10.1016/j.neucom.2014.12.034
   Chen CM, 2014, INFORM SCIENCES, V289, P133, DOI 10.1016/j.ins.2014.07.030
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Cormack G. V., 2007, P 16 ACM C C INF KNO
   Cui X., 2016, Identifying Suspended Accounts
   Egele M, 2017, IEEE T DEPEND SECURE, V14, P447, DOI 10.1109/TDSC.2015.2479616
   El-Alfy EM, 2016, FUTURE GENER COMP SY, V64, P98, DOI 10.1016/j.future.2016.02.018
   FERRARA E, 2012, THESIS
   Ghosh S., 2012, P INT C WORLD WID WE, P61
   Google, 2015, GOOGL SAF BROWS API
   Grier C, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P27, DOI 10.1145/1866307.1866311
   Hu X., 2013, P 23 INT JOINT C ART
   Khan MUS, 2018, IEEE T DEPEND SECURE, V15, P551, DOI 10.1109/TDSC.2016.2616879
   Lee K, 2010, SIGIR 2010
   Lee S, 2014, COMPUT COMMUN, V54, P48, DOI 10.1016/j.comcom.2014.08.006
   Liu DH, 2015, LECT NOTES COMPUT SC, V9098, P554, DOI 10.1007/978-3-319-21042-1_61
   Liu Y, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P942, DOI 10.1109/ASONAM.2014.6921699
   Manurung Hisar, 2004, An evolutionary algorithm approach to poetry generation
   Martinez-Romo J, 2013, EXPERT SYST APPL, V40, P2992, DOI 10.1016/j.eswa.2012.12.015
   Metsis V., 2006, CEAS, V17, P28
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Nguyen H., 2013, RES REPORT 2013 STAT
   PhishTank, 2015, PHISHT API
   Sadan Z, 2011, J NETW COMPUT APPL, V34, P1717, DOI 10.1016/j.jnca.2011.06.004
   Shyni C E., 2016, Asian Journal of Information Technology, V15, P1253
   Stanford University, 2008, CHI SQ FEAT SEL
   Twitter, 2016, TWITT RUL
   Yang C, 2013, IEEE T INF FOREN SEC, V8, P1280, DOI 10.1109/TIFS.2013.2267732
   Yoon JW, 2010, COMPUT SECUR, V29, P446, DOI 10.1016/j.cose.2009.11.003
   Zainal K, 2015, PROCEDIA COMPUT SCI, V59, P152, DOI 10.1016/j.procs.2015.07.530
   Zhang H.-Y, 2009, 2009 INT C INF ENG C
   Zhang Y, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0324-2
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
   Zi Chu, 2012, Applied Cryptography and Network Security. Proceedings 10th International Conference, ACNS 2012, P455, DOI 10.1007/978-3-642-31284-7_27
NR 48
TC 21
Z9 21
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 3925
EP 3960
DI 10.1007/s11042-017-5018-x
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200005
DA 2024-07-18
ER

PT J
AU Chiang, HH
   Chen, WM
   Chao, HC
   Tsai, DL
AF Chiang, Hsin-Hung
   Chen, Wei-Ming
   Chao, Han-Chieh
   Tsai, De-Li
TI A virtual tutor movement learning system in eLearning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eLearning; Motion capture; Depth sensing
AB This paper provides a training system with an augmented reality interactive body movement for movement learning, such as gymnastics, martial arts, sports or dance learners. The technology of depth image sensor is used to detect, track and measure the body's movements to collect the path of body's movement in 3D space, and all images has been further modified to reveal the function of feedback immediately. The learner follows up the pre-recorded tutor's movement to imitate tutor's movement step by step. The training system would judge whether the learner's movement correct or not, compares with tutor's, and offer an analysis result in-situ. The learner could get a training as well as real expert guides without any constraints of space and time and with low cost in this system.
C1 [Chiang, Hsin-Hung; Chao, Han-Chieh] Natl Dong Hwa Univ, Dept Elect Engn, Hualien, Taiwan.
   [Chen, Wei-Ming; Tsai, De-Li] Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
C3 National Dong Hwa University; National Ilan University
RP Chiang, HH (corresponding author), Natl Dong Hwa Univ, Dept Elect Engn, Hualien, Taiwan.
EM d9823008@gms.ndhu.edu.tw; wmchen88@gmail.com; hcc@mail.ndhu.edu.tw;
   a5973149@gmail.com
CR Alexiadis D.S., 2011, ACM international conference on Multimedia, P659
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Moore JL, 2011, INTERNET HIGH EDUC, V14, P129, DOI 10.1016/j.iheduc.2010.10.001
   Muneesawang P, 2015, IEEE MULTIMEDIA, V22, P80, DOI 10.1109/MMUL.2015.73
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Sehra S, 2014, INT J INF COMMUN TEC, V4, P823
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Vrettaros J, 2012, INT J SOC HUMANIST C, V1, P363, DOI [10.1504/IJSHC.2012.053161, DOI 10.1504/IJSHC.2012.053161]
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
NR 11
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4835
EP 4850
DI 10.1007/s11042-018-5922-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200047
DA 2024-07-18
ER

PT J
AU Iqbal, MM
   Farhan, M
   Jabbar, S
   Saleem, Y
   Khalid, S
AF Iqbal, Muhammad Munwar
   Farhan, Muhammad
   Jabbar, Sohail
   Saleem, Yasir
   Khalid, Shehzad
TI Multimedia based IoT-centric smart framework for eLearning paradigm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia-centric Internet of Thing (mm-IoT); FUNF; Question answering;
   Multimedia contents; eLearning; Multimedia-aware IoT system; Sensors
ID SYSTEM
AB Multimedia content boosts the learning trends. This paper is aimed to presents an electronic learning system based on Internet of Things (IoT) for the synchronous and asynchronous communications. The infrastructure of IoT provides the adaptable, scalable and open access for the eLearning paradigm. The multimedia-based IoT-centric environment is suitable to enhance the effectiveness of the delivery of learning contents. Students can take full advantage of 7As of IoT, which provides the opportunity to the students that they can access everything on the internet at any time and place. It creates a flexible eLearning paradigm for the teachers and students. The proposed eLearning modeluses sensors to detect the student location, temperature, and mobile camera to identify the student activeness in thelearning environment. Virtual campuses are controlled from a centralized location that may be called the head office. The MAQAS framework provides the solutions to the problems and analyzes the results for the efficient and connected eLearning paradigm. The MAQAS system is used to answer student's queries, which are responded to automatically by agent-based question answering system. The results show that the students' participation towards learning and teacher's pedagogy are more efficient in synchronous and asynchronous modes. Performance evaluated by comparison to the existing question answering Live QA Trak, Quora Yoda QA Live and AskMSR-QA with MAQAS.
C1 [Iqbal, Muhammad Munwar] Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
   [Iqbal, Muhammad Munwar; Saleem, Yasir] Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
   [Farhan, Muhammad] COMSATS Inst Informat Technol, Dept Comp Sci, Sahiwal, Pakistan.
   [Jabbar, Sohail] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
   [Khalid, Shehzad] Bahria Univ, Dept Comp Engn, Islamabad, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Lahore; COMSATS University Islamabad (CUI); National
   Textile University - Pakistan
RP Jabbar, S (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM sjabbar.research@gmail.com
RI Saleem, Yasir/JDM-9428-2023; Iqbal, Muhammad Munwar/AEW-4112-2022;
   Farhan, Muhammad/F-8071-2011; Jabbar, Sohail/E-3052-2012
OI Iqbal, Muhammad Munwar/0000-0001-7212-1408; Farhan,
   Muhammad/0000-0002-3649-5717; Jabbar, Sohail/0000-0002-2127-1235
CR [Anonymous], 2014, PROC 1 ACM C INFORM, DOI DOI 10.1145/2660129.2660144
   [Anonymous], 2004, P 13 INT WORLD WID W
   [Anonymous], 2014, J APPL ENVIRON BIOL
   [Anonymous], SCI INT
   Domingo MC, 2012, J NETW COMPUT APPL, V35, P584, DOI 10.1016/j.jnca.2011.10.015
   Effelsberg W, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2502434
   Farhan M., 2012, 2012 11th Mexican International Conference on Artificial Intelligence and Applications (MICAI 2012), P63, DOI 10.1109/MICAI.2012.18
   Farhan M, 2018, MULTIMED TOOLS APPL, V77, P4909, DOI 10.1007/s11042-016-4212-6
   Grois D, 2013, IEEE GLOB ENG EDUC C, P1141, DOI 10.1109/EduCon.2013.6530252
   Höffner K, 2017, SEMANT WEB, V8, P895, DOI 10.3233/SW-160247
   Iqbal MM, 2015, SCI INT, V26, P2541
   Jabbar S, 2016, J SUPERCOMPUT, V72, P58, DOI 10.1007/s11227-015-1488-7
   Jacobsen WC, 2011, CYBERPSYCH BEH SOC N, V14, P275, DOI 10.1089/cyber.2010.0135
   Juwattana P, 2012, INT J COMPUT COMMUN, V1, P135, DOI [10.7763/IJCCE.2012.V1.37, DOI 10.7763/IJCCE.2012.V1.37]
   Khalid S, 2017, J REAL-TIME IMAGE PR, V13, P449, DOI 10.1007/s11554-015-0545-z
   Khan M.A., 2016, International Journal of Computer Science and Information Security, V14, P545
   Li ZC, 2017, IEEE INTERNET THINGS, V4, P505, DOI 10.1109/JIOT.2016.2583465
   Malik KR, 2016, MULTIMED TOOLS APPL, V75, P12727, DOI 10.1007/s11042-015-2918-5
   Malik KR, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/9103265
   Munwar Iqbal M, 2014, J APPL ENV BIOL SCI, V4, P9
   Naseer Muhammad Kashif, 2014, COMPUTER APPL RES WS, P1
   Osseiran A, 2014, IEEE COMMUN MAG, V52, P26, DOI 10.1109/MCOM.2014.6815890
   Ozcan A, 2014, LAB CHIP, V14, P3187, DOI 10.1039/c4lc00010b
   Palwasha R. I., 2016, International Journal of Experiential Learning Case Studies, V1, P17
   Patil S, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-015-0313-x
   Poluru RK., 2017, J. Eng. Sci. Technol. Rev, V10, P50, DOI [10.25103/jestr.105.06, DOI 10.25103/JESTR.105.06]
   Ramlee RA, 2013, BLUETOOTH REMOTE HOM, P1
   Shariff F, 2015, EXPERT SYST APPL, V42, P1730, DOI 10.1016/j.eswa.2014.10.007
   Sun H, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1045, DOI 10.1145/2736277.2741651
   Usbeck R., 2017, P 4 SEMWEBEVAL CHALL, V769, P59, DOI [10.1007/978, 10.1007/978-3-319-69146-6_6, DOI 10.1007/978-3-319-69146-6_6]
   Wang TH, 2014, COMPUT EDUC, V73, P189, DOI 10.1016/j.compedu.2013.12.002
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yuan JW, 2013, IEEE INFOCOM SER, P2652
   Zain-Ul-Abidin M, 2015, SCI ED INT, V27, P1171
   Zhang BC, 2017, MULTIMED TOOLS APPL, V76, P4243, DOI 10.1007/s11042-016-4244-y
   Zhu Q., 2010, IEEEIFIP 8 INT C EMB, P347, DOI [10.1109/EUC.2010.58, DOI 10.1109/EUC.2010.58]
NR 36
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3087
EP 3106
DI 10.1007/s11042-018-5636-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600022
DA 2024-07-18
ER

PT J
AU Peng, L
   Yang, Y
   Bin, Y
   Xie, N
   Shen, FM
   Ji, YL
   Xu, X
AF Peng, Liang
   Yang, Yang
   Bin, Yi
   Xie, Ning
   Shen, Fumin
   Ji, Yanli
   Xu, Xing
TI Word-to-region attention network for visual question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual question answering; Word attention; Image attention;
   Word-to-region
AB Visual attention, which allows more concentration on the image regions that are relevant to a reference question, brings remarkable performance improvement in Visual Question Answering (VQA). Most VQA attention models employ the entire reference question representation to query relevant image regions. Nonetheless, only certain salient words of the question play an effective role in an attention operation. In this paper, we propose a novel Word-to-Region Attention Network (WRAN), which can 1) simultaneously locate pertinent object regions instead of a uniform grid of image regions of euqal size and identify the corresponding words of the reference question; as well as 2) enforce consistency between image object regions and core semantics in questions. We evaluate the proposed model on the VQA v1.0 and VQA v2.0 datasets. Experimental results demonstrate the superiority of the proposed model as compared to the state-of-the-arts.
C1 [Peng, Liang; Yang, Yang; Bin, Yi; Xie, Ning; Shen, Fumin; Ji, Yanli; Xu, Xing] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Sichuan, Peoples R China.
   [Peng, Liang; Yang, Yang; Bin, Yi; Xie, Ning; Shen, Fumin; Ji, Yanli; Xu, Xing] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Yang, Y (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Sichuan, Peoples R China.; Yang, Y (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
EM pliang951125@outlook.com; dlyyang@gmail.com; yi.bin@hotmail.com;
   seanxiening@gmail.com; fumin.shen@gmail.com; yanliji@uestc.edu.cn;
   interxuxing@hotmail.com
RI yang, yang/GVT-5210-2022; Lang, Ming/HIK-0758-2022; yang,
   yang/HGT-7999-2022
OI Liang, Peng/0000-0002-0576-1429
FU National Natural Science Foundation of China [61572108, 61632007]; 111
   Project [B17008]
FX This work was supported in part by the National Natural Science
   Foundation of China under Project 61572108, Project 61632007 and the 111
   Project No. B17008.
CR [Anonymous], 2017, IEEE T NEURAL NETW L, DOI DOI 10.1109/TNNLS.2016.2636185
   [Anonymous], 2014, P SSST EMNLP 2014 8
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], C WORKSH NEUR INF PR
   [Anonymous], 2018, IEEE T NEUR NET LEAR, DOI DOI 10.1109/TNNLS.2018.2827036
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], 2019, IEEE T CYBERNETICS, DOI DOI 10.1109/TCYB.2018.2831447
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, ABS170707998 CORR
   [Anonymous], 2015, ARXIV150900685, DOI DOI 10.18653/V1/D15-1044
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Bengio Y., 2014, TECHNICAL REPORT
   Fukui A., 2016, P C EMP METH NAT LAN, P457
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   Ilievski I., 2017, NEURIPS, P551
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kazemi V., 2017, ARXIV170403162
   Kim J.-H., 2016, arXiv
   Kim JH, 2016, ADV NEUR IN, V29
   King DB, 2015, ACS SYM SER, V1214, P1
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li R., 2016, Advances in Neural Information Processing Systems, V29, P4655
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu P, 2017, ARXIV PREPRINT ARXIV
   Nam Hyeonseob, 2016, ARXIV161100471
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Simonyan K., 2014, 14091556 ARXIV
   Teney Damien., 2017, Tips and tricks for visual question answering: Learnings from the 2017 challenge
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331
   Zhang MX, 2017, LECT NOTES COMPUT SC, V10538, P261, DOI [10.1007/978-3-319-68155-9_20, 10.1145/3092703.3092731]
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang W, 2018, IEEE CONF COMPUT
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang W, 2018, NEUROCOMPUTING, V275, P781, DOI 10.1016/j.neucom.2017.09.012
   Zhu HY, 2018, IEEE T IMAGE PROCESS, V27, P2609, DOI 10.1109/TIP.2018.2806279
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
NR 53
TC 17
Z9 19
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3843
EP 3858
DI 10.1007/s11042-018-6389-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600065
DA 2024-07-18
ER

PT J
AU Zhou, QG
   Feng, F
   Shen, ZB
   Zhou, R
   Hsieh, MY
   Li, KC
AF Zhou, Qingguo
   Feng, Fang
   Shen, Zebang
   Zhou, Rui
   Hsieh, Meng-Yen
   Li, Kuan-Ching
TI A novel approach for mobile malware classification and detection in
   Android systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Mobile malware detection; System call; Innovative
   classification algorithm; Dynamic analysis
AB With the increasing number of malicious attacks, the way how to detect malicious Apps has drawn attention in mobile technology market. In this paper, we proposed a detection model to seek and track malware Apps actions in such devices. To characterize the behaviors of Apps, dynamic features of each App were constrained in 166-dimension and a novel machine learning classifier is employed to detect malware Apps, and alarm will be triggered if an Android-based App is detected as malicious. With such, we can avoid a detected malware spreading out in larger scale, affecting extensively our society. Detailed description of the detection model is provided, as well the core technologies of this novel machine learning classifier are presented. From experiments performed on a set of Android-based malware and benign Apps, we observe that the proposed classification algorithm achieves highest accuracy, true-positive rate, false-positive rate, precision, recall, f-measure in comparison to other methods as K-Nearest Neighbor (KNN), Naive Bayesian (NB), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (LR), Decision tree (DT), Linear Discriminant Analysis (LDA) and Back Propagation (BP). The proposed detection model is promising and can effectively be applied to Android malware detection, providing early detection and the prospect of warning users of threatens ahead.
C1 [Zhou, Qingguo; Feng, Fang; Shen, Zebang; Zhou, Rui] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
   [Feng, Fang] Lanzhou Inst Technol, Sch Elect & Informat Engn, Lanzhou, Gansu, Peoples R China.
   [Hsieh, Meng-Yen; Li, Kuan-Ching] Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Lanzhou University; Lanzhou Institute of Technology; Providence
   University - Taiwan
RP Li, KC (corresponding author), Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM zhouqg@lzu.edu.cn; fengf15@lzu.edu.cn; shenzb16@lzu.edu.cn;
   zr@lzu.edu.cn; mengyen@pu.edu.tw; kuancli@pu.edu.tw
RI Li, Kuan-Ching/F-4966-2010; Zhou, Qingguo/JZT-9724-2024; Li,
   K/S-4073-2019; Zhou, Rui/HRA-8327-2023
OI Li, Kuan-Ching/0000-0003-1381-4364; Zhou, Qingguo/0000-0001-8054-5446;
   Li, K/0000-0003-1381-4364; feng, fang/0000-0003-3120-2871
FU Ministry of Education - China Mobile Research Foundation [MCM20170206];
   Fundamental Research Funds for the Central Universities
   [lzujbky-2018-k12]; National Natural Science Foundation of China
   [61402210, 60973137]; Major National Project of High Resolution Earth
   Observation System [30-Y20A34-9010-15/17]; State Grid Corporation
   Science and Technology Project [SGGSKY00FJJS1700302]; Program for New
   Century Excellent Talents in University [NCET-12-0250]; Strategic
   Priority Research Program of the Chinese Academy of Sciences
   [XDA03030100]; Google
FX This work was supported by Ministry of Education - China Mobile Research
   Foundation under Grant No. MCM20170206, The Fundamental Research Funds
   for the Central Universities under Grant No. lzujbky-2018-k12, National
   Natural Science Foundation of China under Grant No. 61402210 and
   60973137, Major National Project of High Resolution Earth Observation
   System under Grant No. 30-Y20A34-9010-15/17, State Grid Corporation
   Science and Technology Project under Grant No. SGGSKY00FJJS1700302,
   Program for New Century Excellent Talents in University under Grant No.
   NCET-12-0250, Strategic Priority Research Program of the Chinese Academy
   of Sciences under Grant No. XDA03030100, Google Research Awards and
   Google Faculty Award.
CR 360 home, 2017, ANDROID MALWARE SPEC
   Alzaylaee M.K., 2017, Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics, P65, DOI DOI 10.1145/3041008.3041010
   [Anonymous], 2017, AUSTRALASIAN COMPUTE
   [Anonymous], 2017, Intrusion Detection Evaluation Dataset (CIC-IDS2017)
   [Anonymous], 2017, Smartphone OS Market Share, 2017 Q1
   [Anonymous], 2008, PATTERN RECOGNITION
   [Anonymous], 2012, P 2 ACM C DATA APPL, DOI DOI 10.1145/2133601.2133640
   Barrera D, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P73, DOI 10.1145/1866307.1866317
   Chan PPF, 2012, DROIDCHECKER ANAL AN, P125
   Chen HM, 2015, IEEE INT CONGR BIG, P134, DOI 10.1109/BigDataCongress.2015.28
   Chin E., 2011, P 9 INT C MOB SYST A, P239, DOI DOI 10.1145/1999995.2000018
   Das S, 2016, IEEE T INF FOREN SEC, V11, P289, DOI 10.1109/TIFS.2015.2491300
   Elish KO, 2015, COMPUT SECUR, V49, P255, DOI 10.1016/j.cose.2014.11.001
   Enck W, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P235
   Eskandari M, 2012, J VISUAL LANG COMPUT, V23, P154, DOI 10.1016/j.jvlc.2012.02.002
   Felt AdriennePorter., 2011, P 2 USENIX C WEB APP, P7
   G DATA, 2015, MOBILE MALWARE REPOR
   Isohara T, 2012, 7 INT C COMP INT SEC, V46, P1011
   Lin YD, 2013, COMPUT SECUR, V39, P340, DOI 10.1016/j.cose.2013.08.010
   Mahindru A, 2017, PROCEEDINGS OF THE 10TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, P202, DOI 10.1145/3021460.3021485
   Mylonas A, 2012, BOOK REV PRACTICAL M
   Sato R., 2013, Proceedings of the Asia-Pacific Advanced Network, V36, P23
   Shabtai A, 2012, J INTELL INF SYST, V38, P161, DOI 10.1007/s10844-010-0148-x
   Sohr K., 2011, Proceedings of the 2011 ACM Symposium on Applied Computing, P1494
   Statista, 2017, GLOB MOB OS MARK SHA
   Su X, 2012, 2012 EIGHTH INTERNATIONAL CONFERENCE ON MOBILE AD HOC AND SENSOR NETWORKS (MSN 2012), P153, DOI 10.1109/MSN.2012.43
   Suarez-Tangil G, 2014, IEEE COMMUN SURV TUT, V16, P961, DOI 10.1109/SURV.2013.101613.00077
   Tong F, 2017, J PARALLEL DISTR COM, V103, P22, DOI 10.1016/j.jpdc.2016.10.012
   Wu DJ, 2012, ASIA JT CONF INF SEC, P62, DOI 10.1109/AsiaJCIS.2012.18
   Yang W, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P303, DOI 10.1109/ICSE.2015.50
   Zhang M, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1105, DOI 10.1145/2660267.2660359
   Zhao H., 2016, ARXIV160203950
   Zheng M, 2014, INT WIREL COMMUN, P128, DOI 10.1109/IWCMC.2014.6906344
NR 33
TC 24
Z9 25
U1 1
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3529
EP 3552
DI 10.1007/s11042-018-6498-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600048
DA 2024-07-18
ER

PT J
AU Alabady, SA
   Salleh, MFM
   Al-Turjman, F
AF Alabady, Salah A.
   Salleh, Mohd Fadzli Mohd
   Al-Turjman, Fadi
TI A novel approach of error detection and correction for efficient energy
   in wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error correction; Error detection; Forward error correction; LDPC;
   Linear error detection; Wireless networking
ID NONBINARY LDPC CODES; DATA DELIVERY FRAMEWORK; PARITY-CHECK CODES;
   DECODER ARCHITECTURE; REDUCED-COMPLEXITY; SENSOR NETWORK; DESIGN;
   ALGORITHM; INTERNET; BINARY
AB This paper presents a novel linear error detection and correction approach for single and multiple bit error codes called low complexity parity check (LCPC) code. The LCPC code detects and corrects consecutive and non-consecutive bit errors. It can be used as a forward error correction scheme in the data transmission system of green wireless networks and the green Internet of Things. The proposed code improves network performance in terms of throughput, end-to-end delay, and bit error rate (BER). LCPC codes also have less complexity and lower memory requirements than Reed Solomon (RS) and low-density parity check (LDPC) codes because they have less non-zero elements in the generator matrix and the parity check matrix. Unlike LDPC codes, LCPC codes do not require reiteration in the decoding process. Various code rates of the LCPC code are proposed to reduce the complexity of the encoding and decoding process, which in turn decreases energy consumption. Simulation results show that the proposed LCPC (9, 4) code outperforms the popular LDPC codes. Compared with the LDPC (8, 4) with the decode bit flip algorithm, LCPC (9, 4) offers a coding gain of nearly 3dB at a BER equal to 10(-5).
C1 [Alabady, Salah A.] Univ Mosul, Dept Comp Engn, Coll Engn, Mosul, Iraq.
   [Salleh, Mohd Fadzli Mohd] Univ Sains Malaysia, Sch Elect & Elect Engn, Nibong Tebal, Pulau Pinang, Malaysia.
   [Al-Turjman, Fadi] Antalya Bilim Univ, Dept Comp Engn, Antalya, Turkey.
C3 University of Mosul; Universiti Sains Malaysia; Antalya Bilim University
RP Alabady, SA (corresponding author), Univ Mosul, Dept Comp Engn, Coll Engn, Mosul, Iraq.
EM eng.salah@uomosul.edu.iq; fadzlisalleh@usm.my;
   fadi.alturjman@antalya.edu.tr
RI Al-Turjman, Fadi/C-7891-2019; Mohd Salleh, Mohd Fadzli/AAA-8518-2020;
   Al-Turjman, Fadi/L-2998-2019; Abdulghani, Salah/B-6684-2018
OI Al-Turjman, Fadi/0000-0001-6375-4123; Mohd Salleh, Mohd
   Fadzli/0000-0002-1801-6049; Al-Turjman, Fadi/0000-0001-5418-873X;
   Abdulghani, Salah/0000-0001-9687-2724
CR Ai-Turjman F, 2019, FUTURE GENER COMP SY, V92, P1103, DOI 10.1016/j.future.2017.03.014
   Al-Turjman F, 2018, J NETW SYST MANAG, V26, P255, DOI 10.1007/s10922-017-9415-2
   Al-Turjman F, 2018, IEEE SENS J, V18, P470, DOI 10.1109/JSEN.2017.2761396
   Al-Turjman F, 2017, PERVASIVE MOB COMPUT, V42, P299, DOI 10.1016/j.pmcj.2017.05.001
   Al-Turjman FM, 2017, IEEE ACCESS, V5, P26808, DOI 10.1109/ACCESS.2017.2773834
   [Anonymous], NONBINARY ERROR CONT
   [Anonymous], P IEEE MIL COMM C MI
   [Anonymous], 1963, RES MONOGRAPH SERIES
   Ardakani M, 2006, IEEE T COMMUN, V54, P1235, DOI 10.1109/TCOMM.2006.877971
   Aruna S, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P566, DOI 10.1109/iccsp.2013.6577118
   Barnault L, 2003, 2003 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P70
   Belean Bogdan, 2013, 2013 IEEE 9th International Conference on Intelligent Computer Communication and Processing (ICCP 2013), P307, DOI 10.1109/ICCP.2013.6646126
   Bhargava L., 2013, P NAT C COMM NCC NEW, P1
   Biroli ADG, 2012, SENSORS-BASEL, V12, P1529, DOI 10.3390/s120201529
   Chen CY, 2010, IEEE T COMMUN, V58, P3140, DOI 10.1109/TCOMM.2010.091310.090327
   Chung SY, 2001, IEEE COMMUN LETT, V5, P58, DOI 10.1109/4234.905935
   Davey MC, 1998, 1998 INFORMATION THEORY WORKSHOP - KILLARNEY, IRELAND, P70, DOI 10.1109/ITW.1998.706440
   Declercq D, 2007, IEEE T COMMUN, V55, P633, DOI 10.1109/TCOMM.2007.894088
   GALLAGER RG, 1962, IRE T INFORM THEOR, V8, P21, DOI 10.1109/tit.1962.1057683
   Han GJ, 2010, IEEE COMMUN LETT, V14, P1053, DOI 10.1109/LCOMM.2010.100410.100998
   Huang J, 2009, COMPUT-SUPP COLLAB L, V10, P1, DOI 10.1007/978-0-387-77234-9_1
   Islam MR, 2011, SENSORS-BASEL, V11, P9887, DOI 10.3390/s111009887
   Jiang Y, 2010, PRATICAL GUIDE TO ERROR-CONTROL CODING USING MATLAB(R), P1
   Kou Y, 2001, IEEE T INFORM THEORY, V47, P2711, DOI 10.1109/18.959255
   Leiner B.M., 2005, LDPC COD BRIEF TUT, V8, P1
   Liao CH, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1644, DOI 10.1109/APCCAS.2008.4746352
   Lin J, 2013, IEEE INT SYMP CIRC S, P1688, DOI 10.1109/ISCAS.2013.6572189
   MacKay DJC, 1996, ELECTRON LETT, V32, P1645, DOI 10.1049/el:19961141
   MacKay DJC, 1999, IEEE T INFORM THEORY, V45, P399, DOI 10.1109/18.748992
   Miladinovic N, 2005, IEEE T INFORM THEORY, V51, P1594, DOI 10.1109/TIT.2005.844095
   Ngatched TMN, 2009, IEEE T COMMUN, V57, P302, DOI 10.1109/TCOMM.2009.02.060352
   Rani S, 2015, SENSORS-BASEL, V15, P28603, DOI 10.3390/s151128603
   Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P619, DOI 10.1109/18.910578
   Saeedi H, 2009, IEEE T COMMUN, V57, P6, DOI 10.1109/TCOMM.2009.0901.060118
   Sassatelli L, 2010, IEEE T INFORM THEORY, V56, P5314, DOI 10.1109/TIT.2010.2059910
   Song SM, 2009, IEEE T COMMUN, V57, P84, DOI 10.1109/TCOMM.2009.0901.060129
   TANNER RM, 1981, IEEE T INFORM THEORY, V27, P533, DOI 10.1109/TIT.1981.1056404
   Venkateshwari P., 2012, 2012 International Conference on Recent Trends in Information Technology (ICRTIT), P292, DOI 10.1109/ICRTIT.2012.6206782
   Voicila A, 2010, IEEE T COMMUN, V58, P1365, DOI 10.1109/TCOMM.2010.05.070096
   Wang J, 2013, J SYST ENG ELECTRON, V24, P215, DOI 10.1109/JSEE.2013.00028
   Xin Chen, 2008, 2008 11th IEEE International Conference on Communication Technology (ICCT 2008), P406, DOI 10.1109/ICCT.2008.4716279
   Xinmiao Zhang, 2010, Proceedings of the 2010 IEEE Workshop on Signal Processing Systems (SiPS 2010), P70, DOI 10.1109/SIPS.2010.5624765
   Zhang XM, 2011, IEEE T VLSI SYST, V19, P1229, DOI 10.1109/TVLSI.2010.2047956
   Zhong H, 2005, IEEE T CIRCUITS-I, V52, P766, DOI 10.1109/TCSI.2005.844113
NR 44
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1345
EP 1373
DI 10.1007/s11042-018-6282-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700006
DA 2024-07-18
ER

PT J
AU Feng, JG
   Zhang, SY
   Xiao, J
AF Feng, Jiageng
   Zhang, Songyang
   Xiao, Jun
TI Explorations of skeleton features for LSTM-based action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RNN; Action recognition; Skeletons; LSTM; Geometric features
AB Currently RNN-based methods achieve excellent performance on action recognition using skeletons. But the inputs of these approaches are limited to coordinates of joints, and they improve the performance mainly by extending RNN models in different ways and exploring relations of body parts directly from joint coordinates. Our method utilizes a universal spatial model perpendicular to the RNN model enhancement. Specifically, we propose two simple geometric features, inspired by previous work. With experiments on a 3-layer LSTM (Long Short-Term Memory) framework, we find that the geometric relational features based on vectors and normal vectors outperform other methods and achieve state-of-art results on two datasets. Moreover, we show that utilizing our features as input requires less data for training.
C1 [Feng, Jiageng; Zhang, Songyang; Xiao, Jun] Zhejiang Univ, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Xiao, J (corresponding author), Zhejiang Univ, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM junx@cs.zju.edu.cn
OI Zhang, Songyang/0000-0003-4316-3320
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 1995, International Workshop on Automatic Face- and Gesture-Recognition. IEEE Computer Society
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Breuer T., 2015, CONSEQUENCES POACHIN, P1, DOI DOI 10.1017/CBO9781107415324
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen C, 2011, IEEE T VIS COMPUT GR, V17, P1676, DOI 10.1109/TVCG.2010.272
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Hinton G. E., 2012, 12070580 ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Li WB, 2015, IEEE I CONF COMP VIS, P4444, DOI 10.1109/ICCV.2015.505
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Mahasseni B., 2016, IEEE C COMP VIS PATT
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Salakhutdinov, 2015, ARXIV151104119
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sheikh Y., 2005, ICCV
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vinagre M, 2015, LECT NOTES ELECTR EN, V325, P263, DOI 10.1007/978-3-319-10891-9_15
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 35
TC 9
Z9 10
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 591
EP 603
DI 10.1007/s11042-017-5290-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500033
DA 2024-07-18
ER

PT J
AU Jadhav, T
   Singh, K
   Abhyankar, A
AF Jadhav, Tushar
   Singh, Kulbir
   Abhyankar, Aditya
TI Volumetric estimation using 3D reconstruction method for grading of
   fruits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volumetric reconstruction; Silhouette; Camera calibration; Fuzzy rule
   based classification; Fruit maturity
ID VISION SYSTEM; CLASSIFICATION; MACHINE; INSPECTION; OBJECTS; SHAPE; SIZE
AB Grading of the fruits is one of the important post harvest tasks that the fruit processing agro-industries do. Although the internal quality of the fruit is important, the external quality of the fruit influences the consumers and the market price significantly. External quality of the fruit is based on the features such as color, maturity, shape, texture and size of the fruit. Apart from being expensive and time consuming, the manual grading process may face challenges such as subjectivity in grading, inconsistency and non-availability of the experts during peak seasons. On the other hand, computer vision based fruit grading systems using 2D techniques do not consider self occluding surface of the fruit and fail to determine the percentage of the matured region accurately. The grading systems which approximate the shape of the fruit to a known geometrical shape fail to compute the volume of the fruits with arbitrary shapes accurately. This paper presents a nondestructive and accurate fruit grading system based on the volume and maturity feature implemented using Fuzzy Rule Based Classifier (FRBC). The system estimates the volume of the fruit using volumetric 3D reconstruction method in multiple-camera environment and computes the percentage of the matured region of the fruit with high accuracy. The experimental results show that the accuracy of the proposed grading system in volume estimation and fruit grading is 98.5%. The ability of the proposed 3D reconstruction method to reconstruct the fruits with arbitrary shapes makes the grading system more robust and dynamic.
C1 [Jadhav, Tushar] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
   [Jadhav, Tushar] Vishwakarma Inst Informat Technol, Pune, Maharashtra, India.
   [Singh, Kulbir] Thapar Univ, Dept Elect & Commun Engn, Thapar Inst Engn & Technol, Patiala, Punjab, India.
   [Abhyankar, Aditya] Savitribai Phule Pune Univ, Dept Technol, Pune, Maharashtra, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology; Savitribai Phule Pune University
RP Jadhav, T (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.; Jadhav, T (corresponding author), Vishwakarma Inst Informat Technol, Pune, Maharashtra, India.
EM tushar.jadhav@viit.ac.in; ksingh@thapar.edu;
   aditya.abhyankar@unipune.ac.in
RI Singh, Kulbir/T-7453-2019; Jadhav, Tushar/GNO-9887-2022
OI Singh, Kulbir/0000-0001-8070-3395; Jadhav, Tushar/0000-0001-9397-9307
CR Abdullah MZ, 2006, J FOOD ENG, V76, P506, DOI 10.1016/j.jfoodeng.2005.05.053
   Abdullah MZ, 2002, J FOOD PROCESS PRES, V26, P213, DOI 10.1111/j.1745-4549.2002.tb00481.x
   [Anonymous], 2016, IEEE T CIRCUITS SYST, DOI DOI 10.1109/LGRS.2016.2517095
   Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167
   Blasco J, 2009, BIOSYST ENG, V103, P137, DOI 10.1016/j.biosystemseng.2009.03.009
   Bouguet Jean-Yves., 2006, CAMERA CALIBRATION T
   Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Forbes K. A., 1999, Elektron, V16, p14, 16
   Gallo A, 2014, J CULT HERIT, V15, P173, DOI 10.1016/j.culher.2013.04.009
   Garrido-Novell C, 2012, J FOOD ENG, V113, P281, DOI 10.1016/j.jfoodeng.2012.05.038
   Gejima Y, 2003, IEEE ASME INT C ADV, P1355
   Goel N, 2015, APPL SOFT COMPUT, V36, P45, DOI 10.1016/j.asoc.2015.07.009
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Imou K, 2006, T ASABE, V49, P449, DOI 10.13031/2013.20394
   Iqbal SM, 2005, P IEEE INT C IM INF, P1
   Jadhav T, 2018, TURK J ELECTR ENG CO, V26, P755, DOI 10.3906/elk-1704-144
   Jadhav T, 2017, J ENG RES-KUWAIT, V5, P50
   Jiménez AR, 2000, MACH VISION APPL, V11, P321, DOI 10.1007/s001380050117
   Jin L, 2018, IEEE T SYST MAN CY-S, V48, P693, DOI 10.1109/TSMC.2016.2627579
   Kamila N.K., 2015, HDB RES EMERGING PER, P367
   Kandi S.G., 2010, J LIFE SCI, V4, P39
   Lee DJ, 2011, IEEE T AUTOM SCI ENG, V8, P292, DOI 10.1109/TASE.2010.2087325
   Lee DJ, 2001, PROC SPIE, V4189, P258, DOI 10.1117/12.417201
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   MAY Z, 2011, INT J ENG SCI, V11, P30
   Mendoza F, 2006, POSTHARVEST BIOL TEC, V41, P285, DOI 10.1016/j.postharvbio.2006.04.004
   Milella A., 2006, Sensor Review, V26, P290, DOI 10.1108/02602280610692006
   Mizushima A, 2013, COMPUT ELECTRON AGR, V94, P29, DOI 10.1016/j.compag.2013.02.009
   Moreda GP, 2009, J FOOD ENG, V92, P119, DOI 10.1016/j.jfoodeng.2008.11.004
   Nandi CS, 2014, IEEE T INSTRUM MEAS, V63, P1722, DOI 10.1109/TIM.2014.2299527
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Radojevic RL, 2011, AFR J AGR RES, V6, P3131
   Semary NA, 2015, ADV INTELL SYST, V323, P401, DOI 10.1007/978-3-319-11310-4_35
   Siswantoro J, 2016, PROCEEDINGS OF 2016 2ND INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH) - INFORMATION SCIENCE FOR GREEN SOCIETY AND ENVIRONMENT, P74, DOI 10.1109/ICSITech.2016.7852611
   Sun C, 2007, PATTERN RECOGN LETT, V28, P1501, DOI 10.1016/j.patrec.2007.03.008
   Tsai R., 1981, IEEE J ROBOTIC AUTOM, V24, P381
   Xu LiJia Xu LiJia, 2014, INMATEH-Agricultural Engineering, V44, P93
   Yang W, 2017, IEEE ACCESS, V5, P24698, DOI 10.1109/ACCESS.2017.2766438
   Yimyam P, 2005, P ICCAS KOR
   Zhang BH, 2014, FOOD RES INT, V62, P326, DOI 10.1016/j.foodres.2014.03.012
NR 41
TC 27
Z9 29
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1613
EP 1634
DI 10.1007/s11042-018-6271-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700018
DA 2024-07-18
ER

EF